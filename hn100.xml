<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 05 May 2024 19:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[First 'tooth regrowth medicine' to be tested in Japan from Sept. 2024 (194 pts)]]></title>
            <link>https://mainichi.jp/english/articles/20240503/p2a/00m/0sc/012000c</link>
            <guid>40264669</guid>
            <pubDate>Sun, 05 May 2024 13:16:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mainichi.jp/english/articles/20240503/p2a/00m/0sc/012000c">https://mainichi.jp/english/articles/20240503/p2a/00m/0sc/012000c</a>, See on <a href="https://news.ycombinator.com/item?id=40264669">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- cxenseparse_start -->

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2024/05/03/20240503p2a00m0na009000p/9.jpg?1" data-lightbox="photos" data-title="Katsu Takahashi, head of the dentistry and oral surgery department at Kitano Hospital, second from left, and other members of the research team, hold a news conference at the hospital in Osaka's Kita Ward on May 2, 2024. (Mainichi/Yosuke Tsuyuki)">
<span>
<img src="https://cdn.mainichi.jp/vol1/2024/05/03/20240503p2a00m0na009000p/6.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>Katsu Takahashi, head of the dentistry and oral surgery department at Kitano Hospital, second from left, and other members of the research team, hold a news conference at the hospital in Osaka's Kita Ward on May 2, 2024. (Mainichi/Yosuke Tsuyuki)</figcaption>
</figure>
</div>
<p>
    OSAKA -- Clinical trials of the world's first "tooth regrowth medicine" are set to commence in September at Kyoto University Hospital, researchers announced here on May 2.
</p>
<!-- cxenseparse_end -->

<!-- cxenseparse_start -->
<p>
    Once the medicine's safety is confirmed, it will be given to patients congenitally lacking a full set of teeth to confirm its effectiveness. The researchers hope to commence sale of the medicine in 2030.
</p>
<p>
    Congenital tooth deficiency is believed to affect about 1% of the population. The absence of six or more teeth, a condition known as oligodontia, is believed to be hereditary, and is said to affect about 0.1% of the population.
</p>

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2024/05/03/20240503p2a00m0na010000p/7.jpg?1" data-lightbox="photos" data-title="A tooth that grew in a mouse with a congenital tooth deficiency, is seen growing after it was given the medicine, in this photo provided by Kitano Hospital.">
<span>
<img src="https://cdn.mainichi.jp/vol1/2024/05/03/20240503p2a00m0na010000p/6.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>A tooth that grew in a mouse with a congenital tooth deficiency, is seen growing after it was given the medicine, in this photo provided by Kitano Hospital.</figcaption>
</figure>
</div>
<p>
    According to Kitano Hospital in Osaka's Kita Ward, which is involved in the study, the first phase of the clinical trials will run from September this year to August 2025. The medicine will be administered intravenously to healthy individuals to confirm its effectiveness, with 30 males between the ages of 30 and 64 taking part. The subjects must be missing at least one back tooth so that there will be no problem if the medicine takes effect and a tooth begins to grow. No major side effects have been confirmed in animal studies to date.
</p>
<p>
    In the next stage, the medication will be administered at Kitano Hospital to patients with congenital tooth deficiency. Researchers plan to limit the subjects during this phase to those between the ages of 2 to 7 who have at least four teeth missing from birth.
</p>
<p>
    The tooth regrowth medicine deactivates a protein called USAG-1, which inhibits the growth of teeth. The team believes that in the future it may be possible to grow teeth not only in people with congenital conditions, but also in those who have lost teeth due to cavities or injuries.
</p>

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2024/05/03/20240503p2a00m0na011000p/6.jpg?1" data-lightbox="photos" data-title="This photo provided by Kitano Hospital shows the front teeth of a ferret that was given the medicine. It had six teeth at first, but a seventh one, pictured at center, grew in.">
<span>
<img src="https://cdn.mainichi.jp/vol1/2024/05/03/20240503p2a00m0na011000p/6.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>This photo provided by Kitano Hospital shows the front teeth of a ferret that was given the medicine. It had six teeth at first, but a seventh one, pictured at center, grew in.</figcaption>
</figure>
</div>
<p>
    Lead researcher Katsu Takahashi, head of the dentistry and oral surgery department at Kitano Hospital, commented, "We want to do something to help those who are suffering from tooth loss or absence. While there has been no treatment to date providing a permanent cure, we feel that people's expectations for tooth growth are high."
</p>
<p>
    (Japanese original by Yosuke Tsuyuki, Osaka Science &amp; Environment News Department)
</p>
<!-- cxenseparse_end -->

<!--| tools BGN |-->

<!--| tools END |-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Machine unlearning: ML model minus the information to be unlearned (126 pts)]]></title>
            <link>https://ai.stanford.edu/~kzliu/blog/unlearning</link>
            <guid>40264352</guid>
            <pubDate>Sun, 05 May 2024 12:30:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.stanford.edu/~kzliu/blog/unlearning">https://ai.stanford.edu/~kzliu/blog/unlearning</a>, See on <a href="https://news.ycombinator.com/item?id=40264352">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 


  
	  41 minute read
	
</p>
          
        
        
        
        
             
        
    
        </header>
      

      <section itemprop="text">
        <meta name="twitter:site" content="@kenziyuliu">

<meta name="twitter:card" content="summary">

<meta name="twitter:title" content="Machine Unlearning in 2024">

<meta name="twitter:description" content="As our ML models today become larger and their (pre-)training sets grow to inscrutable sizes, people are increasingly interested in the concept of machine unlearning to edit away undesired things like private data, stale knowledge, copyrighted materials, toxic/unsafe content, dangerous capabilities, and misinformation, without retraining models from scratch.">



<p>Written by <a href="https://ai.stanford.edu/~kzliu">Ken Liu</a> ∙ May 2024</p>





<hr>

<p>As our ML models today become larger and their (pre-)training sets grow to inscrutable sizes, <a href="https://unlearning-challenge.github.io/">people</a> <a href="https://www.axios.com/newsletters/axios-ai-plus-117900d2-3a2c-4741-b807-bb8f2f9bb035.html?chunk=0&amp;utm_term=twsocialshare#story0">are</a> <a href="https://www.safe.ai/blog/wmdp-benchmark">increasingly</a> <a href="https://hbswk.hbs.edu/item/qa-seth-neel-on-machine-unlearning-and-the-right-to-be-forgotten">interested</a> in the concept of <strong>machine unlearning</strong> to edit away undesired things like private data, stale knowledge, copyrighted materials, toxic/unsafe content, dangerous capabilities, and misinformation, without retraining models from scratch.</p>

<p>Machine unlearning can be broadly described as removing the influences of training data from a trained model. At its core, unlearning on a <em>target model</em> seeks to produce an <em>unlearned model</em> that is equivalent to—or at least “behaves like”—a <em>retrained model</em> that is trained on the same data of target model, minus the information to be unlearned.</p>

<p>There’s a lot hidden in the above description. How do we describe the information to be unlearned? Do we always have ground-truth retrained models? If not, how do we actually evaluate the unlearning? Can we even verify and audit unlearning? Is <em>pretending</em> to unlearn, as humans often do, sufficient? Is unlearning even the right solution? If so, for what problems?</p>

<p>The precise definitions of unlearning, the techniques, the guarantees, and the metrics/evaluations would depend on:</p>
<ol>
  <li>The ML task (e.g., binary classification or language modeling);</li>
  <li>The data to unlearn (e.g., a set of images, news articles, or the knowledge of making <a href="https://youtu.be/zjkBMFhNj_g?t=2774">napalm</a>);</li>
  <li>The unlearning algorithm (e.g., heuristic fine-tuning vs deleting model components);</li>
  <li>The goal of unlearning (e.g., for user privacy or harmfulness removal).</li>
</ol>

<p>In this educational post, I hope to give a gentle, general ML audience introduction to machine unlearning and touch on things like <a href="https://arxiv.org/abs/2303.15715">copyright protection</a>, <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">New York Times v. OpenAI</a>, <a href="https://gdpr.eu/right-to-be-forgotten/">right-to-be-forgotten</a>, <a href="https://unlearning-challenge.github.io/">NeurIPS machine unlearning challenge</a>, <a href="https://arxiv.org/abs/2005.11401">retrieval-based AI systems</a>, <a href="https://www.mlsafety.org/">AI safety</a>, along with some of my thoughts on the field. While unlearning is broad topic applicable to most ML models, we will focus a lot on <a href="https://en.wikipedia.org/wiki/Foundation_model">foundation models</a>.</p>

<!-- Another alternative of access revocation is **retrival-based AI systems** (e.g. [RAG](https://arxiv.org/abs/2005.11401)), where sensitive data are nevered trained but [retrieved and used in-context](https://arxiv.org/abs/2308.04430). Unlearning becomes trivial, but it is unclear whether if we could move everything sensitive out of training data and/or have retrieval match trained performance. -->

<!-- ![image alt](https://i.imgflip.com/8fw81c.jpg) -->
<!-- <img src="https://i.imgflip.com/8fw81c.jpg" width="60%"> -->

<h2 id="1-a-bit-of-history--motivations-for-unlearning">1. A bit of history &amp; motivations for unlearning</h2>

<p>People have thought about the unlearning problem <a href="https://www.ieee-security.org/TC/SP2015/papers-archived/6949a463.pdf">for</a> <a href="https://proceedings.neurips.cc/paper/2019/hash/cb79f8fa58b91d3af6c9c991f63962d3-Abstract.html">a while</a> <a href="https://arxiv.org/abs/1912.03817">now</a>. The initial research explorations were primarily driven by <a href="https://gdpr.eu/article-17-right-to-be-forgotten/">Article 17</a> of GDPR (European Union’s privacy regulation), often referred to as “<a href="https://gdpr.eu/right-to-be-forgotten/">right-to-be-forgotten</a>” (<strong>RTBF</strong>) since 2014. RTBF basically says a user has the right to request deletion of their data from a service provider (e.g. deleting your Gmail account).</p>

<p>RTBF was well-intentioned. It was also very actionable when said service providers store user data in a structured way, like how Google <a href="https://www.cnbc.com/2014/10/13/google-removes-170000-right-to-be-forgotten-links.html">removed</a>  a bunch of links from its index in repsonse to RTBF requests.</p>

<p>However, RTBF wasn’t really proposed with machine learning in mind. In 2014, policymakers wouldn’t have predicted that deep learning will be a giant hodgepodge of data &amp; compute, and that separating and interpreting this hodgepodge turned out to be hard. The hardness of erasing data from ML models has subsequently motivated research on what is later referred to as “<a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/cb79f8fa58b91d3af6c9c991f63962d3-Paper.pdf">data deletion</a>” and “<a href="https://www.ieee-security.org/TC/SP2015/papers-archived/6949a463.pdf">machine</a> <a href="https://arxiv.org/pdf/1912.03817.pdf">unlearning</a>”.</p>

<p><strong>A decade later in 2024, user privacy is no longer the only motivation for unlearning.</strong> We’ve gone from training small convolutional nets on face images to training giant language models on pay-walled, <a href="https://www.theverge.com/23961021/ai-art-copyright-training-ownership-fair-use">copyrighted</a>, <a href="https://support.google.com/youtube/answer/6000976?hl=en">toxic</a>, dangerous, and otherwise harmful content, all of which we may want to “erase” from the ML models—sometimes with access to only a handful of examples. The nature of the models has changed too. Instead of using many small specialized models each good at one task, people started using a single <a href="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4">giant model</a> that knows just about any task.</p>

<!-- A consequence is that knowledge in the model becomes interwoven and learning becomes less directly [measurable](https://arxiv.org/abs/2206.07682), both of which intuitively complicate unlearning.  -->

<p>Currently, I think the motivations for unlearning fall into two categories:</p>

<ol>
  <li>
    <p><strong>Access revocation</strong> (think unlearning private and copyrighted data). In an ideal world, data should be thought of as “borrowed” (possibly unpermittedly) and thus can be “returned”, and unlearning should enable such revocation.</p>

    <p>Unlearning is challenging from this perspective. One key difficulty is that our limited understanding of deep learning itself makes data trained into a model akin to “consumables” (which can’t just be “returned” after consumption). Data may also be non-fungible (e.g. your chat history) and may even be thought of as <a href="https://www.radicalxchange.org/media/papers/data-freedom-act.pdf">labor</a> with its own financial and control interests. Another challenge is that access revocation may require a <em>proof</em> of unlearning; as we will explore in the coming sections, this isn’t always possible.</p>

    <p>These difficulties suggest that it’s perhaps also worth revising laws like RTBF and thinking about alternatives such as <em>data markets</em>, where data owners are properly compensated so they won’t want to request unlearning in the first place. To illustrate, suppose Bob ate Alice’s cheesecake (data), Alice would much rather Bob pay her or return something equivalent (compensation) than Bob puking to his pre-eating state (unlearning).</p>

    <p>In practice, one way to implement access revocation is via some form of <em>periodic re-training</em> of the base model. Many model providers already do this to keep their models competitive and up-to-date. For example, OpenAI can collect a bunch of unlearning requests, and batch-satisfy them during the re-training every year (or, guided by RTBF’s “<a href="https://gdpr.eu/right-to-be-forgotten/">undue delay</a>” period by which the request must be satisfied). More broadly, this suggests <em>socio-technical solutions</em> for unlearning: policymakers can mandate such periodic re-training and set economically viable deadlines to offload the costs to the model owners.</p>
  </li>
  <li>
    <p><strong>Model correction &amp; editing</strong> (think toxicity, bias, stale/dangerous knowledge removal). That is, the model was trained on something undesirable and we’d like to fix it. This is closely related to the <a href="https://arxiv.org/abs/2110.11309">model editing</a> literature. The concept of “<a href="https://arxiv.org/abs/2402.14015">corrective machine unlearning</a>”, where unlearning serves to correct the impact of bad data, was recently proposed to capture this motivation. From this perspective, unlearning may also be viewed as a post-training risk mitigation mechanism for AI safety concerns (discussed further in Section 4).</p>

    <p>Unlike access revocation, we could be more lenient towards with model correction since the edit is more of a desire than a necessity mandated by law, much like model accuracy on image classification or toxicity of generated text. (Of course, these can cause real harm too.) Here, we won’t necessarily need <em>formal guarantees</em> for the unlearning to be practically useful; we have plenty of examples where people would happily deploy models that are deemed “sufficiently safe”. The recent <a href="https://www.wmdp.ai/">WMDP benchmark</a>, which quizzes a model on hazardous knowledge, is a good example of empirically evaluating unlearning efficacy.</p>
  </li>
</ol>

<h2 id="2-forms-of-unlearning">2. Forms of unlearning</h2>

<p>Unlearning is trivially satisfied if we can just retrain the model without the undesired data. However, we want something better because (1) retraining can be expensive and (2) it can be a lot of work <em>just to find out</em> what to remove from training data—think finding all Harry Potter references in a trillion tokens. Unlearning techniques essentially seek to mitigate or avoid this retraining cost while producing identical or similar results.</p>

<p>The unlearning literature can roughly be categorized into the following:</p>
<ol>
  <li>Exact unlearning</li>
  <li>“Unlearning” via differential privacy</li>
  <li>Empirical unlearning, where data to be unlearned are precisely known (training examples)</li>
  <li>Empirical unlearning, where data to be unlearned are underspecified (think “knowledge”)</li>
  <li>Just <em>ask</em> for unlearning?</li>
</ol>

<p>Forms 2-4 are sometimes known as “<strong>approximate unlearning</strong>” in that the unlearned model approximates the behavior of the retrained model. Form 5 is quite new and interesting, and more specific to instruction-following models.</p>

<figure>
  <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRnut8P03hlk5tKJPEEsqUl1DSlqN2ScdJeiaRfC3mWbQ_PBBwf7wBU9xgxuzr1GoqgkB6MwCa6Zrdo6LQxSOIPXIUrl1Yug73k2Q2zFI61VDAi9K21JOPox0Hc1CIh6ShKxW9Tgy45TYV3p3r5IiI7yxzzzOpzvbJ-5o3QVtjZn6vhDZLntnCcUSi1mb_/s720/image1.png" width="200">
  <figcaption>Figure 1. Illustration of approximate unlearning. Source: <a href="https://unlearning-challenge.github.io/">NeurIPS Machine Unlearning Challenge</a>.</figcaption>
</figure>

<p>In the following, we will go through what each of these types roughly looks like, along with what I think are the promises, caveats, and questions to ask looking forward.</p>

<h3 id="21-exact-unlearning">2.1. Exact unlearning</h3>

<p>Exact unlearning roughly asks that the unlearned model and the retrained model to be <em>distributionally identical</em>; that is, they can be exactly the same under fixed randomness.</p>

<p>Techniques for exact unlearning are characterized by the early work of <a href="https://www.ieee-security.org/TC/SP2015/papers-archived/6949a463.pdf">Cao &amp; Yang</a> and <a href="https://arxiv.org/abs/1912.03817">SISA</a>. In SISA, a very simple scheme, the training set is split into $N$ non-overlapping subsets, and a separate model is trained for each subset. Unlearning involves retraining the model corresponding to and without the data points to be unlearned. This reduces cost from vanilla retraining by $1/N$ (cheaper if we keep model checkpoints). Inference then involves model ensembling.<sup id="fnref:sisa-exact" role="doc-noteref"><a href="#fn:sisa-exact" rel="footnote">1</a></sup></p>

<figure>
  <img width="200" src="https://pic4.zhimg.com/80/v2-6dd3c114ff1c984254f4d2889477827f_1440w.webp">
  <figcaption>Figure 2. Illustration of SISA: just train models on data shards (<a href="https://arxiv.org/pdf/1912.03817">image source</a>).</figcaption>
</figure>

<!-- ![SISA illustration](https://pic4.zhimg.com/80/v2-6dd3c114ff1c984254f4d2889477827f_1440w.webp)
Illustration of SISA: just train models on data shards. -->

<p>More generally, the essence of exact unlearning of this form is that we want <em>modular components</em> in the learning algorithm to correspond to different (potentially disjoint) sets of the training examples.</p>

<p>There are several benefits of exact unlearning:</p>

<ol>
  <li><strong>The algorithm <em>is</em> the proof</strong>. If we implement something like SISA, we know by design that the unlearned data never contributed to other components. As it turns out, formally proving the model has unlearned something is quite <a href="https://arxiv.org/abs/2110.11891">challenging</a> otherwise.</li>
  <li><strong>It turns the unlearning problem into an accuracy/efficiency problem.</strong> This makes exact unlearning more approachable due to the messiness of unlearning evaluation and lack of benchmarks.</li>
  <li><strong>Interpretability by design</strong>. By providing a structure to learning, we also have better understanding of how certain data points contribute to performance.</li>
</ol>

<p>The main drawback seems obvious: modern <a href="https://en.wikipedia.org/wiki/Neural_scaling_law">scaling law</a> of large models argues against excessive data &amp; model sharding as done in SISA. <em>Or does it?</em> I think it would be very interesting to revisit sharding in the context of large models, in light of the recent <a href="https://arxiv.org/abs/2208.03306">model</a> <a href="https://arxiv.org/abs/2203.05482">merging</a> <a href="https://huggingface.co/blog/mlabonne/merge-models">literature</a> that suggests the feasibility of weight-space merging between large models. As we’ll learn in the coming sections, the messiness of approximate unlearning and its evaluation, especially in the context of large models, makes exact unlearning very appealing.</p>

<!-- An alternative to exact unlearning, discussed earlier, is for model servers to collect unlearning requests and periodically retrain their models to satisfy them all at once. This could be more pragmatic than one might think.  -->

<h3 id="22-unlearning-via-differential-privacy">2.2. “Unlearning” via differential privacy</h3>

<p>This line of work roughly says: if the model behaves more or less the same with or without any particular data point, then there’s nothing we need to unlearn from that data point. More broadly, we are asking for <em>distributional closeness</em> between the unlearned and the retrained models.</p>

<p>For readers unfamilar with differential privacy (DP) in machine learning, DP defines a <em>quantifiable</em> indistinguishability guarantee between two models $M$, $M’$ trained on datasets $X$, $X’$ that differ in any single training example. The canonical procedure, <a href="https://arxiv.org/abs/1607.00133">DP-SGD</a>, works by clipping the L2-norm of the per-example gradients and injecting some per-coordinate Gaussian noise to the gradients. The idea is that the noise would mask or obscure the contribution of any single gradient (example), such that the final model isn’t sensitive any exmaple. It is usually denoted by ($\varepsilon, \delta$)-DP; the stronger the noise, the smaller the scalars ($\varepsilon, \delta$), the more private.</p>

<p>The intuition is that if an adversary cannot (reliably) tell apart the models, then it is as if this data point has never been learned—thus no need to unlearn. DP can be used to achieve this form of unlearning, but due to the one-sidedness of unlearning (where we only care about data removal, not addition), DP is a <a href="https://arxiv.org/abs/2103.03279">strictly stronger definition</a>. This notion of unlearning is sometimes known as “<strong>($\alpha, \beta$)-unlearning</strong>” where ($\alpha, \beta$) serve similar roles as ($\varepsilon, \delta$) to measure distributional closeness.</p>

<p>Example techniques along this direction include: <a href="http://proceedings.mlr.press/v132/neel21a.html">(1)</a> storing checkpoints of (DP) convex models and unlearning is retraining from those checkpoints; and <a href="https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html">(2)</a> on top of the previous technique, add SISA for <em>adaptive</em> unlearning requests (i.e. those that come in after observing the published model).</p>

<p>DP-based unlearning is good in that it gives some form of a statistical guarantee. <strong>However, there are some important considerations that limit its applicability to large models</strong>:</p>
<ol>
  <li>Many such unlearning results apply only to <a href="http://proceedings.mlr.press/v132/neel21a.html">convex</a> <a href="https://arxiv.org/abs/1911.03030">models</a> or <a href="https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html">losses</a>.</li>
  <li>What levels of unlearning (values of $(\varepsilon, \delta)$-DP or $(\alpha, \beta)$-unlearning) are sufficient? <em>Who decides?</em></li>
  <li>For large models, current ML systems don’t fit well with the <em>per-example</em> workloads of DP-like procedures. The memory overhead will also be prohibitive.</li>
  <li>Moreoever, like DP, the guarantees can fall off quickly with more unlearning requests (at best the <a href="https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html">rate</a> of $O(\sqrt k)$ with $k$ requests following DP composition theorems).</li>
  <li>DP-like definitions implicitly assume we care about all data points <em>equally</em>. But some examples are more likely to receive unlearning request, and some examples would not have <a href="https://arxiv.org/abs/1906.01827">contributed</a> to the learning at all.</li>
  <li>DP-like procedures may also just hurt model accuracy a lot, sometimes in an <a href="https://arxiv.org/abs/1905.12101">unfair</a> way.</li>
</ol>

<p>For large models in particular, it’s also worth distinguishing the cases of <strong>unlearning pre-training data</strong> vs <strong>unlearning fine-tuning data</strong>. The latter is a lot more tractable; for example, we could indeed <a href="https://arxiv.org/abs/2110.05679">fine-tune</a> large models with differential privacy but not so much with pre-training.</p>

<h3 id="221-forging-and-its-implications-on-dp-like-unlearning-definitions">2.2.1. <em>Forging</em> and its implications on DP-like unlearning definitions</h3>

<p>An unlearning procedure may sometimes require an external <em>audit</em>, meaning that we’d like to prove that the unlearning procedure has actually happened.</p>

<p>The main idea of “<a href="https://arxiv.org/abs/2110.11891">forging</a>” is that there exists two distinct datasets that, when trained on, would produce <em>the same gradients and (thus) the same models</em>. This is true intuitively:</p>
<ol>
  <li>Think linear regression of points on a perfect line; removing any 1 point doesn’t change the fitted line;</li>
  <li>Think mini-batch GD, where replacing one example gradient with the sum of several “fake” gradients would give the same batch gradient.</li>
</ol>

<p><strong>Forging implies that DP-based approximate unlearning may not be auditable</strong>—that is, the unlearning service provider cannot formally prove that the forget set is really forgotten. In fact, if we only look at the model weights, even exact unlearning may not be auditable.</p>

<p>While one can brush this off as a theoretical result, it does mean that policymakers should think carefully about how a future version of “right-to-be-forgotten” (if any) should look like and whether similar policies are legally and technically enforceable.</p>

<p>Indeed, what qualifies as an “audit” could very well be definition and application dependent. If the auditor only cares that the unlearned model performs poorly on a specified set of inputs (say on a set of face images), then even empirical unlearning is “auditable” (see next section).</p>

<h3 id="23-empirical-unlearning-with-known-example-space-example-unlearning">2.3. Empirical unlearning with known example space (“example unlearning”)</h3>

<p>This line of work is essentially “training to unlearn” or “unlearning via fine-tuning”: just take a few more heuristically chosen gradient steps to shape the original model’s behavior into <em>what we think</em> the retrained model would do (while also optionally resetting some parameters in the model). It may also be referred to as “example unlearning”, since the training, retain, and forget sets are often clearly defined.</p>

<p>The <a href="https://unlearning-challenge.github.io/"><strong>NeurIPS 2023 Machine Unlearning Challenge</strong></a> collected many methods along this direction. The challenge roughly runs as follows:</p>
<ul>
  <li>You are given a face image dataset with designated retain/forget example splits for the training set, a target model trained on everything, and a secret model trained only on the retain set.</li>
  <li>You are asked to design an unlearning algorithm that produces unlearned model(s) from the target model that “match” the secretly kept model.</li>
  <li>The “match” or evaluation metric uses a DP-like output-space similarity over 512 seeds: for each forget example, compute an “empirical $\varepsilon$” over 512 unlearned models based on true/false positive rates of an adversary (also provided by the organizer), and aggregate across examples.</li>
  <li>All models are a small ConvNet.</li>
</ul>

<p>To give an intuition about how well empirical unlearning is doing without fully explaining the metric: the ground-truth retrained model gets about ~0.19, the winning submission gets to ~0.12, and the baseline (simple gradient ascent on forget set) is ~0.06.<sup id="fnref:challenge-metric" role="doc-noteref"><a href="#fn:challenge-metric" rel="footnote">2</a></sup></p>

<p>So what do the winning ideas look like? Something along the lines of the following:</p>
<ol>
  <li>Gradient ascent on the forget set;</li>
  <li>Gradient descent on the retain set (and hope that catastrophic forgetting takes care of unlearning);</li>
  <li>Gradient descent on the forget set, but with uniformly random labels (to “confuse” the model);</li>
  <li>Minimize KL divergence on outputs between unlearned model and original model on the retain set (to regularize unlearned model performance on unrelated data);</li>
  <li>Re-initialize weights that had similar gradients on the retain set and forget sets, and finetune these weights on the retain set;</li>
  <li>Prune 99% of weights by L1-norm and fine-tune on the retain set;</li>
  <li>Reset first/last $k$ layers and fine-tune on the retain set; and</li>
  <li>Heuristic/arbitrary combinations of the above.</li>
</ol>

<p>Indeed, despite the heuristic nature of these approaches, these are what <a href="https://arxiv.org/abs/2302.09880">most</a> <a href="https://arxiv.org/abs/2210.01504">empirical</a> <a href="https://arxiv.org/abs/2305.06535">unlearning</a> <a href="https://arxiv.org/abs/2201.06640">algorithms</a>, especially those <a href="https://arxiv.org/abs/2310.10683">on</a> <a href="https://arxiv.org/abs/2310.20150">large</a> <a href="https://www.microsoft.com/en-us/research/project/physics-of-agi/articles/whos-harry-potter-making-llms-forget-2/">(language)</a> <a href="https://arxiv.org/abs/2403.03218">models</a>, are doing these days.</p>

<p>People explore empirical approaches because theoretical tools are usually impractical; for example, enforcing DP simply hurts accuracy and efficiency too much, even for the GPU rich. On the flip side, empirical methods are often fast and easy to implement, and their effects are often qualitatively visible.</p>

<p>Another key motivation for empirical unlearning is that <em>counterfactuals</em> are unclear, especially on LLMs. In deep learning, we often don’t know how the retrained model would behave on unseen data. What should the LLM think who Biden is, if not a politician? Should image classifiers give uniformly random predictions for unlearned images? Do they generalize? Or are they confidently wrong? Any of these is possible and it can be up to the practitioner to decide. It also means that <em>behaviors that are equally plausible can lead to wildly different measurements</em> (e.g., KL divergence between output distributions of unlearned &amp; retrained model), complicating theoretical guarantees.</p>

<h3 id="24-empirical-unlearning-with-unknown-example-space-conceptknowledge-unlearning">2.4. Empirical unlearning with unknown example space (“concept/knowledge unlearning”)</h3>

<p>What if the train, retain, or forget sets are poorly specified or just not specified at all? Foundation models that train on internet-scale data may get requests to unlearn a “<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf">concept</a>”, a “<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/6f1d43d5a82a37e89b0665b33bf3a182-Paper-Conference.pdf">fact</a>”, or a piece of “<a href="https://arxiv.org/abs/2305.14795">knowledge</a>”, all of which we cannot easily associate a set of examples. The terms “<strong>model editing</strong>”, “<strong>concept editing</strong>”, “<strong>model surgery</strong>”, and “<strong>knowledge unlearning</strong>” are closely related to this notion of unlearning.<sup id="fnref:continue-learning" role="doc-noteref"><a href="#fn:continue-learning" rel="footnote">3</a></sup></p>

<p>The underspecification of the unlearning requests means that we now have to deal with the notions of “<strong>unlearning scope</strong>” (or “<a href="https://arxiv.org/abs/2206.06520">editing scope</a>”) and “<a href="https://en.wikipedia.org/wiki/Textual_entailment"><strong>entailment</strong></a>”. That is, unlearning requests may provide <a href="https://arxiv.org/abs/2402.06155">canonical examples</a> to indicate what to unlearn, but the same information can manifest in the (pre-)training set in many different forms with many different downstream implications such that simply achieving unlearning on these examples—even <em>exactly</em>—would not suffice.</p>

<p>For example:</p>
<ul>
  <li>The association “Biden is the US president” is dispersed throughout various forms of text from news articles, books, casual text messages, or this very blog post. Can we ever unlearn all occurrences? Moreover, does unlearning Joe Biden also entail unlearning the color of <a href="https://en.wikipedia.org/wiki/Willow_(cat)">Biden’s cat</a>?</li>
  <li>Artists may request to unlearn art style by providing art samples, but they won’t be able to collect everything they have on the internet and their <a href="https://www.businessinsider.com/ai-image-generators-artists-copying-style-thousands-images-2022-10">adaptations</a>.</li>
  <li>New York Times may request to unlearn news articles, but they cannot enumerate quotes and secondary transformations of these articles.</li>
</ul>

<p>Such vagueness also suggests that <strong>unlearning pre-training data from large models are perhaps necessarily empirical:</strong> it is unlikely to derive formal guarantees if we can’t clearly specify what to (and what not to) unlearn in the trillions of tokens and establish clear information boundaries between different entities. An interesting implication of achieving unlearning empirically is that the unlearning <em>itself</em> can be <a href="https://arxiv.org/abs/2401.01814">unlearned</a>.</p>

<p>What does existing work do, then, with underspecified unlearning requests? Most techniques are more or less the same as <a href="#33-Empirical-unlearning-or-unlearning-via-fine-tuning">before</a>, except now we also need to find the examples to fine-tune on. For example, attempting to unlearn <a href="https://arxiv.org/abs/2310.02238">Harry Potter</a> involves asking GPT-4 to come up with plausible alternative text completions (e.g. that Mr. Potter studies baking instead of magic); and attempting to unlearn <a href="https://arxiv.org/abs/2310.10683">harmful behavior</a> involves collecting examples of hatespeech.</p>

<p>Another set of techniques involves training the desired behavior (or its opposite) into <a href="https://arxiv.org/abs/2212.04089">task</a>/<a href="https://arxiv.org/abs/2403.03218">control</a> <a href="https://arxiv.org/abs/2306.14870">vectors</a> and harnessing the capability of large models to undergo <a href="https://huggingface.co/docs/peft/en/developer_guides/model_merging">weight-space merging</a> or <a href="https://arxiv.org/abs/2310.01405">activation steering</a>.  The fundamental approach of the above is more or less the same, nevertheless—obtaining these edit vectors involves (heuristically) designing what gradients to take and what data on which to take them. One could also frame the unlearning problem as an <em>alignment</em> problem and applies the forget examples with a <a href="https://arxiv.org/abs/2404.05868">DPO-like objective</a>.</p>

<h3 id="25-just-ask-for-unlearning">2.5. Just <em>ask</em> for unlearning?</h3>

<p>It turns out that powerful, instruction-following LLMs like GPT-4 are smart enough to <em>pretend to unlearn</em>. This means crafting prompts to induce a (sufficiently) safe behavior for the target unlearning application.</p>

<p>This is an interesting approach because no gradients are involved whatsoever (big plus from a systems perspective), and intuitively the end results could very well be <a href="https://arxiv.org/abs/2403.03329">as good as</a> existing empirical unlearning techniques. Among different ways we could prompt, past work explored the following two directions.</p>

<p><strong><a href="https://arxiv.org/abs/2403.03329">Literally asking</a> to pretend unlearning.</strong> We can ask in the system prompt to, say, pretend to not know who Harry Potter is. By design, this works best for common entities, facts, knowledge, or behaviors (e.g. the ability to utter like Trump) that are well-captured in the pre-training set, since the LLM needs to <em>know it well to pretend not knowing it well</em>. On the other hand, suppose now we’d like to unlearn the address of an obscure person; the pre-training set is so large that we suspect it’s part of training data. We now face a variant of the <a href="https://en.wikipedia.org/wiki/Streisand_effect">Streisand effect</a>: is it even worth asking the model to pretend unlearning by accurately describing it in-context, and subsequently <a href="https://arxiv.org/abs/2402.17840">risk leaking it</a> in subsequent model responses?</p>

<p><strong>Few-shot prompting or “<a href="https://arxiv.org/abs/2310.07579">in-context unlearning</a>”.</strong> Suppose we now have a clearly defined set of forget examples with corresponding labels. We can <em>flip</em> their labels and put them in the prompt, along with more retain examples with correct labels, with the intuition that the model would treat these falsely labelled forget examples as truths and act accordingly—much like one could <a href="https://www.anthropic.com/research/many-shot-jailbreaking">jailbreak</a> a model this way.<sup id="fnref:random-incontext-labels" role="doc-noteref"><a href="#fn:random-incontext-labels" rel="footnote">4</a></sup> Indeed, this works best when the forget examples and the counterfactual labels are clearly defined and (somewhat) finite. It <em>may</em> work for factual associations (e.g. Paris is the captial of France) by enumerating a <em>lot</em> of examples, but unlikely to work for unlearning toxic behaviors (where space of possible outputs is much larger).</p>

<p>In a sense, these approaches are complementary as they work for different kinds of unlearning requests.</p>

<p><strong>More broadly, one could imagine a <em>boxed</em> LLM system for unlearning through prompting, where</strong>:</p>
<ol>
  <li>Only the input and output interfaces are exposed (like ChatGPT);</li>
  <li>Different instances of a powerful LLM are responsible for accurately mimicking different parts of a desired unlearning behavior (for example, one LLM instance specializes in general trivia-style QA while anoother handles sequence completions);</li>
  <li>An orchestrator/router LLM decides which unlearning worker instance to call depending on the input; and</li>
  <li>A composer/summarizer LLM that drafts the final output conforming to the desired unlearning behavior; it may also apply some output filtering.</li>
</ol>

<p>Some readers may grumble about the heuristic nature of such prompting-based techniques; that there is no proof of unlearning whatsoever. We should keep in mind that fine-tuning based empirical unlearning, as most recent approaches do, is perhaps not fundamentally different. I think it ultimately comes down to the following questions:</p>
<ol>
  <li>Which of fine-tuning or prompting can <strong>better steer model behavior</strong>?</li>
  <li>Which of them are <strong>less susceptible to attacks</strong> (exposing less surfaces and/or requiring more effort for an adversary to revert the unlearning)?</li>
</ol>

<p>My intuition of our current models says that both questions point to fine-tuning based unlearning, but this is very much up for debate and can change as we get more powerful models and better defense mechanisms. For example, the recent notion of an <a href="https://arxiv.org/abs/2404.13208">instruction hierarchy</a> may help make such as an LLM system less susceptible to malicious prompts.</p>

<p><strong>It might be useful to note that humans don’t really “unlearn” a piece of knowledge either.<sup id="fnref:human-unlearn" role="doc-noteref"><a href="#fn:human-unlearn" rel="footnote">5</a></sup></strong> In fact, by claiming to have unlearned something, we often have: (1) not only learned it well to be able to make the very claim that we have unlearned it, and (2) consciously decided that it’s no longer useful / beneficial to apply this knowledge to our current world state. Who is to say that unlearning for LLMs should be any different?</p>

<h2 id="3-evaluating-unlearning">3. Evaluating unlearning</h2>

<p>Unlearning is messy for many reasons. But one of the biggest broken things about unlearning is evaluation. In general, we care about three aspects:</p>
<ul>
  <li><strong>Efficiency</strong>: how fast is the algorithm compared to re-training?</li>
  <li><strong>Model utility</strong>: do we harm performance on the retain data or orthogonal tasks?</li>
  <li><strong>Forgetting quality</strong>: how much of the “forget data” is actually unlearned? How fast can we recover (re-learn) them?</li>
</ul>

<p>Evaluating efficiency and model utility are easier; we already measure them during training. The key challenge is in understanding the forgetting quality.<sup id="fnref:eval-exact-unlearning" role="doc-noteref"><a href="#fn:eval-exact-unlearning" rel="footnote">6</a></sup></p>

<p>If the forget examples are specified, this feels easy too. For example, unlearning a particular image class intuitively means getting a near-chance accuracy on the images in that class. An evaluation protocol may measure <a href="https://arxiv.org/abs/2310.20150">accuracy</a> (high on retain &amp; test set, low on forget set) or the <a href="https://arxiv.org/abs/2210.01504">likelihood</a> of the forget text sequences (lower the better).</p>

<p>However, these intuitive choices of metrics aren’t necessarily principled or extensible to settings like knowledge unlearning in LLMs. Expecting the model to perform poorly on an unlearned image ignores <em>generalization</em>, as the forget examples could very well be an interpolation/duplicate of certain retain examples. And we don’t always have oracle models that have never seen the forget examples; e.g., do we have LLMs that have never seen New York Times articles?</p>

<p>Evaluating unlearning on LLMs had been more of an art than science. For example, to unlearn “Harry Potter” as an entity, people would <a href="https://www.microsoft.com/en-us/research/project/physics-of-agi/articles/whos-harry-potter-making-llms-forget-2/">visualize</a> how the token probabilities would decay for Harry Potter related text—and some other folks would come along and show that the model can indeed still <a href="https://swj0419.github.io/detect-pretrain.github.io/">answer</a> Harry Potter trivia questions. The key issue has been the <em>desperate</em> lack of datasets and benchmarks for unlearning evaluation.</p>

<p>Since 2024, nevertheless, the benchmarking crisis is getting better. There are two recent projects worth highlighting:</p>
<ul>
  <li><a href="https://locuslab.github.io/tofu/">TOFU</a>: A benchmark focusing on unlearning individuals (specifically book authors). It involves asking GPT-4 to create fake author profiles, fine-tuning an LLM on them, and using the fine-tune as the unlearning target model and the original LLM as the oracle “retrained” model. It provides QA pairs on the generated fake authors to evaluate a model’s knowledge of these authors before/after applying unlearning.</li>
  <li><a href="https://www.wmdp.ai/">WMDP</a>: A benchmark focusing on unlearning dangerous knowledge, specifically on biosecurity, cybersecurity, and chemical security. It provides 4000+ multiple-choice questions to test a model’s hazardous knowledge before/after applying unlearning. As part of the report the authors also propose an activation steering based empirical unlearning method.</li>
</ul>

<p>TOFU and WMDP depart from previous unlearning evaluation in that they are both “high-level” and focus on the model’s <em>knowledge retention and understanding</em> as opposed to example-level metrics like forget sequence perplexity. This is particularly relevant for LLMs as they are generally capabale of giving the same answer in many different ways that example-level metrics can’t capture.</p>

<p>Looking forward, I think <strong>application-oriented unlearning benchmarks</strong> like TOFU and WMDP, as opposed to instance-based evaluation like that of the <a href="https://unlearning-challenge.github.io/">NeurIPS unlearning challenge</a>, are more useful for evaluating foundation models, owing to the multi-tasking nature of these models and the disparate definitions of “unlearning success” for each of these tasks. Indeed, one might imagine separate benchmarks on unlearning personally identifiable information (PII), copyrighted content, speech toxicity, or even model <a href="https://arxiv.org/abs/2401.05566">backdoors</a>. For example, for unlearning PII, we might care about exact token regurgitation, whereas for toxicity, the unlearning metric would be the score reported by a <a href="https://arxiv.org/abs/2203.09509">ToxiGen</a> classifier.</p>

<h2 id="4-practice-pitfalls-and-prospects-of-unlearning">4. Practice, pitfalls, and prospects of unlearning</h2>

<p>Unlearning is a hard problem, especially in the context of foundation models. As we actively research to make unlearning work in practice, it helps to philosophize a bit on what unlearning really means and whether it is the right solution for our current problems.</p>

<h3 id="41-the-spectrum-of-unlearning-hardness"><strong>4.1. The spectrum of unlearning hardness</strong></h3>

<p>Intuitively, unlearning infrequent textual occurrences in LLMs like car accidents in Palo Alto should be easier than unlearning frequent occurrences like “Biden is the US president”, which is in turn easier than unlearning fundamental facts like “the sun rises every day”.</p>

<p>This spectrum of <em>unlearning hardness</em> emerges because as a piece of knowledge becomes more fundamental, it will have more associations with other pieces of knowledge (e.g. as premises or corollaries) and an exponentially larger unlearning scope. In fact, a piece of knowledge can be so embedded in the model’s implicit knowledge graph that it cannot be unlearned without <em>introducing contraditions</em> and harming the model’s utility.<sup id="fnref:embeddedness-vs-in-distributions" role="doc-noteref"><a href="#fn:embeddedness-vs-in-distributions" rel="footnote">7</a></sup></p>

<p>This intuition implies that certain unlearning requests are much harder or simply unsatisfiable (any attempts are bound to have flaws). Indeed, humans have experiences that form the basis of their subsequent actions and world models; it is subjective, blurry, and philosophical as to what capacity can humans unlearn their formative past memories.</p>

<p>More broadly, the unlearning hardness problem applies to all kinds of models, and for reasons beyond embeddedness in a knowledge/entailment graph. Let’s consider two more seemingly contradictory intuitions for unlearning hardness:</p>

<ol>
  <li>An example seen later in the training should be <em>easy to unlearn</em>, since the model would have moved only slightly in weight space (e.g. due to decayed learning rate) and one could either just revert gradients or revert to a previous checkpoint (if stored). In contrast, examples seen early gets “built on” by later examples (in the curriculum learning sense), making them harder to unlearn.</li>
  <li>An example seen later should be <em>harder to unlearn</em>, since examples seen earlier are gradually (or catastrophically) <a href="https://arxiv.org/abs/2207.00099">forgotten</a> over the course of training; this may be especially true for LLMs.</li>
</ol>

<p>Failure to reconcile these intuition would suggest that the interplay across <em>memorization/forgetting</em>, <em>example importance</em> (in the sense of data <a href="https://arxiv.org/abs/2305.10429">selection</a> and <a href="https://arxiv.org/abs/1906.01827">coresets</a>), <em>learning hardness</em> (in the sense of <a href="https://arxiv.org/abs/2210.15031">prediction flips</a>), and unlearning hardness is unclear.</p>

<p><strong>Here are some interesting research questions</strong>:</p>
<ul>
  <li>Is there a qualitative/fundamental difference between unlearning “easy” data (e.g. a local news event) and “hard” data (e.g. cats have four legs)?</li>
  <li>If there is a spectrum of unlearning hardness, does there exist a threshold to tell apart what is “easy” and “hard”, and thus what is unlearnable or shouldn’t be unlearned? Does there exist, or can we train, such an oracle classifier? Can humans even tell?</li>
  <li>How does this relate to <strong>influence functions</strong> and <strong>data attribution</strong>? If a certain piece of knowledge (as it manifests in a model’s output) can be attributed to a larger fraction of the training data, does it make it harder to unlearn?</li>
  <li>Can we benchmark how easy is it to unlearn something?</li>
</ul>

<h3 id="42-copyright-protection">4.2. Copyright protection</h3>

<p>On the surface, unlearning seems to be a promising solution for copyright protection: if a model violates the copyright of some content, we could attempt to unlearn said content. It is conceivable that to resolve copyright violations via unlearning, provable and exact unlearning is necessary (and possibly sufficient); on the other hand, approximate unlearning, without guarantees and with the possibility of being hacked, is certainly insufficient and likely unnecessary.</p>

<p>In practice, however, there is a lot more nuance due to the questionable effectiveness of current unlearning methods and the <a href="https://arxiv.org/abs/2303.15715">unclear legal landscape</a> at the intersection of AI and copyright. Since I am no legal expert (and clearly none of this section constitutes legal advice), we will mostly focus on asking questions. The central question seems to be: <strong>is unlearning the right solution for copyright protection?</strong></p>

<p>Recall that the <a href="https://en.wikipedia.org/wiki/Fair_use">fair use</a> doctrine<sup id="fnref:fair-use" role="doc-noteref"><a href="#fn:fair-use" rel="footnote">8</a></sup> permits limited use of copyrighted material contigent on four factors: (1) purpose and character of the use (“transformativeness”), (2) the nature of the copyrighted work, (3) amount and substantiality of the use, and (4) the effect on material’s value. If the use of copyrighted content in a model qualifies as fair use, then unlearning such content from the model is unnecessary.</p>

<p>Suppose a model is trained on some copyrighted content and is risking copyright violation, as in <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">New York Times v. OpenAI</a>. Should OpenAI invest in (empirical) unlearning algorithms on ChatGPT? Or should they focus on the transformativeness axis of fair use and invest in deploying empirical <em>guardrails</em>, such as prompting, content moderation, and custom alignment to prevent the model from regurgitating training data? The latter seems to be what’s being implemented in practice.</p>

<p><strong>More broadly, there could also be economic solutions to copyright violation as alternatives to unlearning.</strong> For example, model owners may provide an exact unlearning service (e.g. via periodic retraining) while also offering to indemnify model users for copyright infringement in the mean time, as seen in the case of OpenAI’s “<a href="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">Copyright Shield</a>”. People are also starting to <a href="https://arxiv.org/abs/2404.13964">explore</a> how one may price copyrighted data using Shapley values. In general, it is unclear right now how much of a role (if any) unlearning will play for resolving copyright related issues. Exact unlearning (extending to retrieval-based systems, see next section) does hold promises since deletion is clean and provable, but it seems that <em>legally binding</em> auditing procedures/mechanisms need to be in place first.</p>

<h3 id="43-retrieval-based-ai-systems">4.3. Retrieval-based AI systems</h3>

<p>An obvious alternative to unlearning is to not learn at all. One way this could manifest for an LLM is that we take all content from the pre-training set that may receive unlearning requests (e.g., New York Times articles) and put them to an external data/vector store. Any questions relating to them will then be <a href="https://arxiv.org/abs/2005.11401">RAG</a>’ed during inference, and any unlearning requests can be trivially satisfied by removing the data from the database. <a href="https://arxiv.org/abs/2308.04430">Min et al.</a> demonstrates that this approach can be competitive to (though not quite matching) the trained baseline in terms of final perplexity.</p>

<p>Retrieval-based solutions are promising because of the increasing capabilities of the base models to reason in-context. However, there are few considerations before taking retrieval systems as the no-brainer solution to unlearning:</p>

<ol>
  <li><strong>Removing protected content from pre-training corpus can be a hard de-duplication problem.</strong> Much like removing data contamination is <a href="https://lmsys.org/blog/2023-11-14-llm-decontaminator/">hard</a>, how can we be sure that paraphrases, quotations/citations, or other adaptations of the protected content are removed?</li>
  <li><strong>What if the data to be unlearned can’t be retrieved?</strong> Today we fine-tune many things into a model that aren’t documents or knowledge items; for example, it is unclear (yet) if things like as human preferences and desired behaviors (e.g. ability to write concisely) can be “retrieved” from a database.</li>
  <li><strong>Dumping stuff in-context can open new attack surfaces.</strong> Many RAG methods for LLMs work by putting related content in-context and ask the model to reason on them. Having the protected data in-context means they are now more susceptible to data extraction (simple prompting attacks may work just <a href="https://arxiv.org/abs/2402.17840">fine</a>).</li>
  <li><strong>Utility gap between retrieval and training.</strong> While there is evidence that retrieval-based solutions can be competitive, there is no general consensus that retrieval alone can replace fine-tune workloads; indeed, they can be <a href="https://arxiv.org/abs/2401.08406">complementary</a>. More broadly, what if the space of unlearnable data is too large such that if all of it goes to an external store, the base model wouldn’t be as useful?</li>
</ol>

<!-- Indeed, if we only have a handful of examples to learn from for down-stream model adaptations, it probably isn't worth spending GPUs on fine-tuning anyway.  -->

<!-- both because of the increasing capabilities of the base models in reasoning in-context and because  -->

<!-- - Protected content (or content that may receive unlearning requests) will not be part of the pre-training corpus for LLMs, and any questions relating to them are RAG’ed during inference, and unlearning requests are trivially satisfied (by not RAG’ing). -->
<!-- - Some important questions:
    - Ensuring that the pre-training corpus is free of protected content can be a hard de-duplication problem, since such content can appear through various forms. It’s unclear if present embedding-based techniques are sufficient.
    - What if the space of possible unlearning requests will be too large that if all of it goes to external store, the base model wouldn't be as capable?


- also
 -->
<!-- **====DRAFT BELOW====** -->

<h3 id="44-ai-safety">4.4. AI safety</h3>

<!-- **Revisiting right-to-be-forgotten (RTBF).** RTBF had always been cited as the motivation for unlearning.  -->

<!-- **Unlearning for AI safety.** As we explored in [section 1](#1-A-bit-of-history-amp-motivations-for-unlearning) when discussing motivations,  -->

<!-- Right-to-be-forgotten had always been cited as the motivation for unlearning, but as discussed [earlier](#1-A-bit-of-history-amp-motivations-for-unlearning) it is no longer the only motivation.  -->
<p>As models become more capable and are granted <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">agency</a>, one concrete application domain for unlearning that is <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023">gaining</a> <a href="https://www.cnn.com/2024/04/26/tech/openai-altman-government-ai-safety-panel/index.html">traction</a> is <strong>AI safety</strong>.</p>

<p>Roughly speaking, safety concerns stem from a model’s <em>knowledge</em> (e.g., recipe of <a href="https://youtu.be/zjkBMFhNj_g?t=2774">napalm</a>), <em>behaviors</em> (e.g., exhibiting <a href="https://arxiv.org/abs/2402.02680">bias</a>), and <em>capabilities</em> (e.g., <a href="https://arxiv.org/abs/2402.06664">hacking</a> websites). Examining current AI systems and extrapolating forward, one may imagine the following examples to apply unlearning and improve AI safety:</p>

<ul>
  <li>removing <strong>hazardous knowledge</strong>, as seen in the <a href="https://www.wmdp.ai/">WMDP</a> benchmark;</li>
  <li>removing <strong>model <a href="https://arxiv.org/abs/2302.10149">poisons</a> and <a href="https://arxiv.org/abs/2401.05566">backdoors</a></strong>, where models respond to adversarially planted input triggers;</li>
  <li>removing <strong><a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html">manipulative</a> behaviors</strong>, such as the ability to perform unethical persuasions or deception;</li>
  <li>removing <strong><a href="https://arxiv.org/abs/2402.02680">bias</a> and <a href="https://arxiv.org/abs/2212.08061">toxicity</a></strong>; or even</li>
  <li>removing <strong><a href="https://arxiv.org/abs/2206.13353">power-seeking</a> tendencies</strong>.</li>
</ul>

<p>For safety-oriented applications, it is worth noting that unlearning should be treated as a post-training <em>risk mitigation and defense mechanism</em>, alongside existing tools like alignment fine-tuning and content filters.  And as with any tool, we should view unlearning through its trade-offs in comparison to other tools in the toolbox (e.g., unlearning is more adaptive but more expensive than content filters), as opposed to brushing it off because of the potential lack of guarantees and efficacy.</p>

<hr>

<p><strong>Acknowledgements</strong>: The author would like to thank Aryaman Arora, Jiaao Chen, Irena Gao, John Hewitt, Shengyuan Hu, Peter Kairouz, Sanmi Koyejo, Xiang Lisa Li, Percy Liang, Eric Mitchell, Rylan Schaeffer, Yijia Shao, Chenglei Si, Pratiksha Thaker, Xindi Wu for helpful discussions and feedback before and during the drafting of this post. Any hot/bad takes are those of the author.</p>

<!-- Back to [posts](../blog) -->

<hr>

<p><strong>Citation</strong></p>

<p>If you find this post helpful, it can be cited as:</p>

<p>Liu, Ken Ziyu. (Apr 2024). Machine Unlearning in 2024. Ken Ziyu Liu - Stanford Computer Science. <a href="https://ai.stanford.edu/~kzliu/blog/unlearning">https://ai.stanford.edu/~kzliu/blog/unlearning</a>.</p>

<p>Or</p>

<div><pre><code>@misc{liu2024unlearning,
  title   = {Machine unlearning in 2024},
  author  = {Liu, Ken Ziyu}
  journal = {Ken Ziyu Liu - Stanford Computer Science},
  year    = {2024},
  month   = {Apr},
  url     = {https://ai.stanford.edu/~kzliu/blog/unlearning},
}
</code></pre></div>

<hr>

<p><img src="https://hitwebcounter.com/counter/counter.php?page=13055297&amp;style=0008&amp;nbdigits=6&amp;type=page"></p>


        
      </section>

      

      

      


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Take a look at traefik, even if you don't use containers (175 pts)]]></title>
            <link>https://j6b72.de/article/why-you-should-take-a-look-at-traefik/</link>
            <guid>40264042</guid>
            <pubDate>Sun, 05 May 2024 11:31:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://j6b72.de/article/why-you-should-take-a-look-at-traefik/">https://j6b72.de/article/why-you-should-take-a-look-at-traefik/</a>, See on <a href="https://news.ycombinator.com/item?id=40264042">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>Traefik got really popular over the last few years in the bubble of <a href="https://www.youtube.com/watch?v=liV3c9m_OX8">home-lab</a> <a href="https://www.youtube.com/watch?v=scrtJ1U4wJU">youtubers</a>, that’s when I first heard about it.</p>
<p>Traefik is more comparable to <a href="https://docs.haproxy.org/2.9/intro.html#3.1">HAProxy</a> than to nginx/caddy/apache2 - it forwards requests to services and returns the responses, can even modify headers and other aspects of the request and response, but it can’t serve files.</p>
<p>This article states my experience with traefik in an environment without containers.</p>
<h2 id="what-traefik-is-known-for">What traefik is known for</h2>
<p><a href="https://traefik.io/traefik/">Traefiks site</a> states their mission to help the microservices world. All these youtubers share that they own some kind of container infrastructure, either docker or kubernetes. Traefik runs as container too, you <a href="https://doc.traefik.io/traefik/providers/docker/#endpoint">mount the docker socket into the traefik container</a> and gain the ability to auto-detect other containers that you might want to expose using traefik. You can configure the proxying behavior right on the specific container via <a href="https://docs.docker.com/reference/cli/docker/container/run/#label">labels</a>. Traefik can automatically request a TLS certificate from Let’s Encrypt and makes your service available as soon as it detects the existence of new container.</p>
<p>As I don’t use linux containers that much right now, I thought traefik wasn’t for me. But I was wrong. It’s fantastic!</p>
<h2 id="why-its-also-viable-for-non-container-usage">Why it’s also viable for non-container usage</h2>
<h3 id="common-misconception-no-container-engine-required">Common Misconception: no container engine required</h3>
<p>Traefik doesn’t need to run in a container engine, and your services don’t need to run in a container engine.</p>
<p>Traefik is written in Golang and compiles to a single executable file, which you can download from <a href="https://doc.traefik.io/traefik/getting-started/install-traefik/#use-the-binary-distribution">their releases page</a>. I don’t know why, but I get a really good feeling when I encounter software that is written in Golang and compiles to a single binary. It makes it so easy to “deploy” the thing and you get to keep full control.</p>
<p>An example systemd service unit is <a href="https://github.com/traefik/traefik/blob/master/contrib/systemd/traefik.service">contained in their repository</a>, and that’s, apart from the configuration files, all you need. For security, you should create a user and correctly set the permissions on the your configuration files, though.</p>
<h3 id="common-misconception-also-supports-config-files">Common Misconception: also supports config files</h3>
<p>If you don’t use containers, you can’t use container labels - but I find these labels confusing and hard to read anyway.</p>
<p>The good thing: <a href="https://doc.traefik.io/traefik/providers/file/">Traefik can also be configured with configuration files</a>.</p>
<p>As a rule of thumb, Traefik splits its configuration in two parts - a “static” configuration that contains your certificate provider (e.g. Let’s Encrypt) and entrypoints (the ports traefik listens on) and a “dynamic” configuration that contains your routers, services and middlewares.</p>
<p>Traefik listens to file system events and can hot reload the dynamic part.</p>
<p>The config file isn’t thaaaat complicated. <a href="#configuration-example">See my configuration at the bottom of this article.</a></p>
<h3 id="their-documentation-is-great">Their documentation is great!</h3>
<p>It explains all the concepts that Traefik builds upon clearly, has a configuration example for whichever way of configuring your instance you took at the beginning of the relevant pages (which, let’s be real, is the thing we’re searching for most of the time) and their docs covered most of the demands that I had.</p>
<p>If you didn’t understand the terms I used earlier (certificate provider, entrypoint, routers, services &amp; middlewares), the documentation will help you in sub-10 minutes. <a href="https://doc.traefik.io/traefik/">Try it out yourself</a>. The sidebar is your friend.</p>
<h3 id="traefik-feels-robust-and-well-thought-out">Traefik feels robust and well thought-out</h3>
<p>Traefik warns you if your configuration doesn’t make sense and I haven’t run into random issues yet.</p>
<p>Traefik doesn’t seem to log much by default, but the way your request takes is easy to understand and I was up and running really fast without any frustration.</p>
<h2 id="features-i-really-like">Features I really like</h2>
<h3 id="tls-passthrough--proxy-protocol">TLS Passthrough &amp; PROXY protocol</h3>
<p>Traefik supports <a href="https://doc.traefik.io/traefik/routing/routers/#passthrough">TLS Passthrough</a> and HAProxys PROXY protocol (<a href="https://doc.traefik.io/traefik/routing/entrypoints/#proxyprotocol">in</a> and <a href="https://doc.traefik.io/traefik/routing/services/#proxy-protocol">out</a>).</p>
<p>TLS passthrough means that you can forward traffic to web services that supply their own TLS certificate (even request it themselves from Let’s Encrypt, through Traefik, which just forwards everything to the service so that can work) without terminating TLS on the proxy. The proxy can’t see what’s being transmitted.</p>
<p>The decision which virtual host is selected normally happens via the <a href="https://en.wikipedia.org/wiki/List_of_HTTP_header_fields#host-request-header">“Host”-Header</a> - but as that’s in the encrypted body, that’s not possible. TLS has a solution for that problem - the <a href="https://en.wikipedia.org/wiki/Server_Name_Indication">“Server Name Indication” (SNI)</a>, and Traefik and many other web servers / proxies use that to make the selection.</p>
<p>As an addition, HAProxys PROXY protocol is a more secure way of transmitting the info that gets lost due to the user first reaching the proxy - in the past, you would’ve used the “X-Forwarded-&lt;…&gt;” headers, but I always disliked those, as making them secure isn’t trivial and requires testing, as header handling often times isn’t well documented.</p>
<p>Note: the PROXY protocol has to be supported by the target service too - but for apache2 and nginx (and therefore, PHP) that’s the case, and the <a href="https://www.haproxy.com/blog/use-the-proxy-protocol-to-preserve-a-clients-ip-address#proxy-protocol-support">list of services that support the protocol</a> is growing.</p>
<h2 id="things-i-miss-when-using-traefik">Things I miss when using traefik</h2>
<h3 id="authentication">Authentication</h3>
<p>On NGINX, I use the great <a href="https://github.com/vouch/vouch-proxy">Vouch Proxy</a> (also a Golang one-binary program :&gt;) to secure certain services with Azure AD (sorry, Microsoft Entra…) Authentication. (If you know NGINX, you’ll understand how it works just by looking at this: <a href="https://github.com/vouch/vouch-proxy?tab=readme-ov-file#installation-and-configuration">https://github.com/vouch/vouch-proxy?tab=readme-ov-file#installation-and-configuration</a>)</p>
<p>Traefik supports something similar to NGINX’s auth using <a href="https://doc.traefik.io/traefik/middlewares/http/forwardauth/">ForwardAuth</a>. Sadly, Vouch Proxy doesn’t work yet for Traefik (<a href="https://github.com/vouch/vouch-proxy/issues/180">open issue</a>).</p>
<p>You could roll your own keycloak instance, integrate that with AAD and use that for ForwardAuth. <a href="https://www.laitco.de/posts/Traefik_ForwardAuth_AzureAD_Traefik/">The internet says that works</a>. But it also requires you to keep that keycloak instance secure and up-to-date and set it up in the first place. For bigger projects, that might be viable.</p>
<p>Often recommended is <a href="https://github.com/thomseddon/traefik-forward-auth">traefik-forward-auth</a>. Sadly, that project has had its last update in June of 2020, the developer disappeared from GitHub and the dependencies need updating. There are <a href="https://github.com/thomseddon/traefik-forward-auth/pull/369">open</a> <a href="https://github.com/thomseddon/traefik-forward-auth/pull/354">pull</a> <a href="https://github.com/thomseddon/traefik-forward-auth/pull/287">requests</a>, which will probably never be handled. Not viable for me.</p>
<p>I’ve had a bad experience with <a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy</a> in the past (but to give them credit: also golang and a single executable :&gt;). I don’t want to proxy to a proxy, as things HTTP2/3, timeouts, body size and WebSockets require configuration on all proxies between the user and the service. Feels too error-prone to me.</p>
<p>But the Traefik ForwardAuth seems simple enough, so I might write my own simple tool for integrating with AAD. Or maybe someone should fork and audit traefik-forward-auth, and update its dependencies.</p>
<h3 id="blocking-of-user-agents-and-ip-addresses">Blocking of user agents and IP addresses</h3>
<p>I don’t want my internal services to be archived by archive.org. <a href="https://www.heise.de/news/Archivierung-des-Internets-Internet-Archive-ignoriert-kuenftig-robots-txt-3693558.html">As robots.txt and similar headers don’t work for disallowing Archive.org</a>, there are only two possibilities to block their Crawler: <a href="https://www.kuketz-blog.de/internet-archive-bot-von-der-webseite-aussperren/">Blocking the “archive.org_bot” user agent, or blocking their IP range</a>.</p>
<p>In Traefik, you can only block <a href="https://plugins.traefik.io/plugins/628c9ed4108ecc83915d775e/LICENSE">user agents</a> or <a href="https://plugins.traefik.io/plugins/62947363ffc0cd18356a97d1/deny-ip-plugin">IP addresses</a> via a third-party plugin. I don’t like third-party plugins as I need to keep them in mind when updating, and they can introduce security vulnerabilities.</p>
<p>You could block IPs by using the <a href="https://doc.traefik.io/traefik/middlewares/http/ipallowlist/">IPAllowList</a> middleware, and just allow everything but the IPs that you want to disallow. <a href="https://stackoverflow.com/a/37284115">You can calculate the IP ranges</a>. That’ll work and isn’t any worse than blocking directly, but doesn’t feel very elegant at all as you can’t see what subnets are exactly blocked just by looking at the ones that are left.</p>
<h2 id="configuration-example">Configuration example</h2>
<p>The following example sets up:</p>
<ul>
<li>entrypoints on :80 and :443
<ul>
<li>with the http endpoint redirecting to https without exceptions</li>
</ul>
</li>
<li>Let’s Encrypt for certificates with the TLS challenge</li>
<li>tls passthrough proxying for cloud.xx.xyz (service on another host)
<ul>
<li>with enabled PROXY protocol</li>
</ul>
</li>
<li>tls-terminating proxying to git.xx.xyz (service on the local host)</li>
<li>redirect middleware from <a href="https://xx.xyz/redirmepls">https://xx.xyz/redirmepls</a> to <a href="https://google.com/">https://google.com</a></li>
<li>header-adding middleware to add a x-robots-header</li>
</ul>
<h3 id="etctraefiktraefikyml"><code>/etc/traefik/traefik.yml</code></h3>
<div><pre tabindex="0"><code data-lang="yml"><span><span><span>providers</span>:
</span></span><span><span>  <span>file</span>:
</span></span><span><span>    <span>filename</span>: <span>/etc/traefik/dynamic.yml</span>
</span></span><span><span>    <span>watch</span>: <span>true</span>
</span></span><span><span><span>entryPoints</span>:
</span></span><span><span>  <span>https</span>:
</span></span><span><span>    <span>address</span>: :<span>443</span>
</span></span><span><span>  <span>http</span>:
</span></span><span><span>    <span>address</span>: :<span>80</span>
</span></span><span><span>    <span>http</span>:
</span></span><span><span>      <span>redirections</span>:
</span></span><span><span>        <span>entryPoint</span>:
</span></span><span><span>          <span>to</span>: <span>https</span>
</span></span><span><span>          <span>scheme</span>: <span>https</span>
</span></span><span><span><span>certificatesResolvers</span>:
</span></span><span><span>  <span>le</span>:
</span></span><span><span>    <span>acme</span>:
</span></span><span><span>      <span>email</span>: <span>xx@xx.xyz</span>
</span></span><span><span>      <span>storage</span>: <span>/etc/traefik/acme.json</span>
</span></span><span><span>      <span>tlsChallenge</span>: {} <span># Required as per https://blog.alexanderhopgood.com/traefik/letsencrypt/2020/12/09/traefik-http-challenge.html</span>
</span></span></code></pre></div><h3 id="etctraefikdynamicyml"><code>/etc/traefik/dynamic.yml</code></h3>
<div><pre tabindex="0"><code data-lang="yml"><span><span><span>tcp</span>:
</span></span><span><span>  <span>routers</span>:
</span></span><span><span>    <span>nextcloud-router</span>:
</span></span><span><span>      <span>rule</span>: <span>"HostSNI(`cloud.xx.xyz`)"</span>
</span></span><span><span>      <span>service</span>: <span>nextcloud</span>
</span></span><span><span>      <span>entrypoints</span>:
</span></span><span><span>        - <span>https</span>
</span></span><span><span>      <span>tls</span>:
</span></span><span><span>        <span>passthrough</span>: <span>true</span>
</span></span><span><span>
</span></span><span><span>  <span>services</span>:
</span></span><span><span>    <span>nextcloud</span>:
</span></span><span><span>      <span>loadBalancer</span>:
</span></span><span><span>        <span>servers</span>:
</span></span><span><span>          - <span>address</span>: <span>10.33.1.2</span>:<span>4433</span>
</span></span><span><span>        <span>proxyProtocol</span>:
</span></span><span><span>          <span>version</span>: <span>2</span>
</span></span><span><span>
</span></span><span><span><span>http</span>:
</span></span><span><span>  <span>routers</span>:
</span></span><span><span>    <span>gitea</span>:
</span></span><span><span>      <span>rule</span>: <span>"Host(`git.xx.xyz`)"</span>
</span></span><span><span>      <span>entrypoints</span>:
</span></span><span><span>        - <span>https</span>
</span></span><span><span>      <span>service</span>: <span>gitea</span>
</span></span><span><span>      <span>middlewares</span>:
</span></span><span><span>        - <span>noindex</span>
</span></span><span><span>      <span>tls</span>:
</span></span><span><span>        <span>certResolver</span>: <span>le</span>
</span></span><span><span>
</span></span><span><span>    <span>xx.xyz</span>:
</span></span><span><span>      <span>rule</span>: <span>"Host(`xx.xyz`)"</span>
</span></span><span><span>      <span>entrypoints</span>:
</span></span><span><span>        - <span>https</span>
</span></span><span><span>      <span>middlewares</span>:
</span></span><span><span>        - <span>my-redirect</span>
</span></span><span><span>      <span>tls</span>:
</span></span><span><span>        <span>certResolver</span>: <span>le</span>
</span></span><span><span>      <span>service</span>: <span>dummy</span>
</span></span><span><span>
</span></span><span><span>  <span>middlewares</span>:
</span></span><span><span>    <span>my-redirect</span>:
</span></span><span><span>      <span>redirectRegex</span>:
</span></span><span><span>        <span>regex</span>: <span>"https://xx.xyz/redirmepls"</span>
</span></span><span><span>        <span>replacement</span>: <span>"https://google.com"</span>
</span></span><span><span>    <span>noindex</span>:
</span></span><span><span>      <span>headers</span>:
</span></span><span><span>        <span>customResponseHeaders</span>:
</span></span><span><span>          <span>X-Robots-Tag</span>: <span>noindex, nofollow, nosnippet, noarchive</span>
</span></span><span><span>
</span></span><span><span>  <span>services</span>:
</span></span><span><span>    <span>gitea</span>:
</span></span><span><span>      <span>loadBalancer</span>:
</span></span><span><span>        <span>servers</span>:
</span></span><span><span>          - <span>url</span>: <span>http://127.0.0.1:3000</span>
</span></span><span><span>    <span>dummy</span>:
</span></span><span><span>      <span>loadBalancer</span>:
</span></span><span><span>        <span>servers</span>: []
</span></span></code></pre></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debian 64-bit-time transition (124 pts)]]></title>
            <link>https://wiki.debian.org/ReleaseGoals/64bit-time</link>
            <guid>40263479</guid>
            <pubDate>Sun, 05 May 2024 09:44:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.debian.org/ReleaseGoals/64bit-time">https://wiki.debian.org/ReleaseGoals/64bit-time</a>, See on <a href="https://news.ycombinator.com/item?id=40263479">Hacker News</a></p>
Couldn't get https://wiki.debian.org/ReleaseGoals/64bit-time: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Helldivers 2 Removed from Purchase on Steam in over 150 Countries (221 pts)]]></title>
            <link>https://www.thegamer.com/helldivers-2-delisted-on-steam-100-plus-countries-without-psn-due-to-psn-sign-in-requirement-controversy/</link>
            <guid>40263289</guid>
            <pubDate>Sun, 05 May 2024 09:02:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thegamer.com/helldivers-2-delisted-on-steam-100-plus-countries-without-psn-due-to-psn-sign-in-requirement-controversy/">https://www.thegamer.com/helldivers-2-delisted-on-steam-100-plus-countries-without-psn-due-to-psn-sign-in-requirement-controversy/</a>, See on <a href="https://news.ycombinator.com/item?id=40263289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        
        

            <article>

        
                
    
        
    
                   <header>
                                                       <div>
                    


        

                        <nav>
                <ul>
                    <li><a href="https://www.thegamer.com/">Home</a></li>
                                                                                            <li><a href="https://www.thegamer.com/aaa-games/">Triple-A Games</a></li>
                                                                                                <li><a href="https://www.thegamer.com/aaa-games/news/">Triple-A Game News</a></li>
                                                                                                                                                            </ul>
            </nav>
            
                </div>
                            

    
            
    
    
            
    
    
    
        
    
                            






            
            
    
    
        
    
            
    
            
    
    
            
    
    
    
        
    
                                
    <p>The hits keep coming for Helldivers 2, as the PSN sign-in controversy has led to it being delisted from Steam in over 100 countries.</p>

            
            
    
    
        
    
            
    
            
    
    
            
    
    
    
        
    
                                
                                    
                                                                                                                        
                                                                    <div data-img-url="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">

        
    



<figure>
        <picture>
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
            
            <source media="(min-width: 1024px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=70&amp;fit=contain&amp;w=1140&amp;h=570&amp;dpr=1" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=70&amp;fit=contain&amp;w=1140&amp;h=570&amp;dpr=1">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
            
            <source media="(min-width: 768px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=49&amp;fit=contain&amp;w=943&amp;h=500&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=49&amp;fit=contain&amp;w=943&amp;h=500&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
            
            <source media="(min-width: 481px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=49&amp;fit=contain&amp;w=767&amp;h=450&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=49&amp;fit=contain&amp;w=767&amp;h=450&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
            
            <source media="(min-width: 0px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=49&amp;fit=contain&amp;w=480&amp;h=300&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg?q=49&amp;fit=contain&amp;w=480&amp;h=300&amp;dpr=2">
                <img width="2160" height="1080" alt="Players hugging in Helldivers 2." data-img-url="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg" src="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/05/helldivers2hug.jpg">
    </picture>
                                    
    </figure>


    </div>

    
            <!-- Not injecting Ads due to No-Ads mode. -->
    
            
            
    
    
        
    
            
            </header>
        
                            

                    
                            
            
            
    
                                
            
    
               
    
                    
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
                                                    
                        
    
                                                                            
                                
                                
                                                
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
                                                        
                                
                                
                                                
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
    
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
                                                        
                                
                                
                                                
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
                                                                                                                                                            
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
    
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
                                                        
                                
                                
                                                
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
                                                        
                                
                                
                                                
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
               
    
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
                                                        
                                
                                
                                                
            
        
    
                                                                                                                                    
            
    
    
        
    
            
    
            
    
    
            
    
    
    
        
    
                                                                                                                                    
            
    

    
    
                
                                    <div id="article-body" itemprop="articleBody">

<div id="custom_block_0">

                    <h3>Highlights</h3>
        
                    <div>    <ul>
                    <li>
                                        Helldivers 2 has had one of the roughest weeks in gaming history after PlayStation announced that PC players would be required to log into PSN.
                        </li>
                    <li>
                                        Considering a lot of areas of the world don't actually have PSN right now, that effectively makes Helldivers 2 unplayable in certain countries.
                        </li>
                    <li>
                                        This has been recognised on Steam, with 177 countries now unable to purchase the game at all.
                        </li>
            </ul>
</div>
        
        
    </div><!-- Not injecting Ads due to No-Ads mode. -->
<p>            <a href="http://thegamer.com/tag/playstation/">PlayStation</a>'s controversial announcement that <a href="http://thegamer.com/tag/helldivers-2/">Helldivers 2</a> players on PC would be required to sign in to a PSN account (which will make the game unplayable for some) has led to the game being delisted from <a href="http://thegamer.com/tag/steam/">Steam</a> in over 100 countries.
    </p>    
<p>            After spending most of 2024 so far as one of the most popular games of the year (<a href="https://www.thegamer.com/helldivers-2-already-playstations-best-selling-games-pc-release/">and even one of the best-selling games from PlayStation in recent memory</a>), Helldivers 2 seems set to take one of the biggest falls from grace in gaming history. Just a few days ago, <a href="https://www.thegamer.com/helldivers-2-being-hit-with-negative-steam-reviews-due-to-psn-sign-in-requirement/">PlayStation announced that PC players on Steam would be required to log into PSN to be able to play the game</a>.
    </p>            
    
                    
                            
                
    
                                        
    
        
        
    <div>

        
                    			<a href="https://www.thegamer.com/forget-apcs-in-helldivers-2-i-want-atvs-vehicles/">
		<div data-img-url="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">

            




<figure>
        <picture>
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 1024px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=440&amp;h=280&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=440&amp;h=280&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 768px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=310&amp;h=240&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=310&amp;h=240&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 481px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=800&amp;h=520&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=800&amp;h=520&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 0px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=480&amp;h=320&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg?q=49&amp;fit=crop&amp;w=480&amp;h=320&amp;dpr=2">
                <img width="2500" height="1250" loading="lazy" decoding="async" alt="Helldivers 2 ATV rider" data-img-url="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg" src="https://static1.thegamerimages.com/wordpress/wp-content/uploads/wm/2024/04/helldivers-2-atv-rider.jpeg">
    </picture>
                
    </figure>


        </div>

		</a>
	
        
                            <div>

                
                                                    
                                    <p><span data-field="label">Related</span></p><h5>
			<a href="https://www.thegamer.com/forget-apcs-in-helldivers-2-i-want-atvs-vehicles/">
			Forget APCs in Helldivers 2, I Want ATVs
		</a>
	</h5>

                	<p><span data-field="excerpt">I'm doing my part, but I could do more with a four wheeler.</span></p>

                

                
            </div>
                
        
        
            </div>

<p>            Sony backed this up by claiming it was for player protection, but the Helldivers 2 community wasn't having any of that and took to <a href="https://www.thegamer.com/helldivers-2-drops-to-mostly-negative-recent-steam-reviews-after-steam-pc-psn-sign-in-controversy/">orbital striking the Steam page with over 180,000 negative reviews over the past few days</a>. To top it all off, players have even <a href="https://www.thegamer.com/helldivers-2-steam-reportedly-allowing-refunds-past-the-two-hour-limit-pc-psn-sign-in-requirement-controversy/">reported successfully receiving refunds from Steam</a> despite having far more play time than the standard two-hour limit that is usually enforced.
    </p>    <!-- Not injecting Ads due to No-Ads mode. --><h2 id="helldivers-2-39-s-steam-situation-has-gone-from-bad-to-worse">
                        Helldivers 2's Steam Situation Has Gone From Bad To Worse
               </h2>
    
    

<p>            As bad as things have been for Helldivers 2 on Steam over the past few days, there's always been a little optimism that PlayStation would realise how badly this has all gone and reverse it. Well, I hate to be the bearer of bad news, but that certainly doesn't seem like it's happening any time soon since, <a href="https://twitter.com/SteamDB/status/1787016207364657340" rel="noopener noreferrer" target="_blank">as shared by the SteamDB Twitter page</a>, Helldivers 2 has now been removed from sale on Steam in over 100 countries.
    </p>    
<p>            Just over ten hours ago, <a href="https://steamdb.info/sub/137730/history/?changeid=23416542" rel="noopener noreferrer" target="_blank">Helldivers 2's SteamDB Page was updated to add restrictions on which countries would be able to purchase</a> the game on Steam. Through a very lengthy change log, we can see that a total of 177 countries are now unable to purchase Helldivers 2 on PC, including Bermuda, Ghana, Jamaica, and a whole bunch of others.
    </p>    

<div id="custom_block_9">

        
                    <p>            It's not clear if the update comes from Steam or PlayStation, but if it is the latter then it seems like Sony is doubling down on the sign-in requirement.
    </p>
        
        
    </div>
<p>            Going through the list is a little like doing the Countries of the World song from The Animaniacs but with a far more depressing tone. Arrowhead has already made it clear it doesn't agree with the requirement and wants to change it, but we'll have to wait and see how PlayStation responds to the controversy next week.
    </p>            
    
                    
                            
                
    
                                        
    
        
        
    <div>

        
                    			<a href="https://www.thegamer.com/end-anticipated-game-era-delays-look-forward/">
		<div>
		
			<p><span>3:42</span>
							</p>
																											
                
    
    
    
                
    
                
        
                                        
                                                                                                                        
                            
    <div data-img-url="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">

            




<figure>
        <picture>
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 1024px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=440&amp;h=280&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=440&amp;h=280&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 768px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=310&amp;h=240&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=310&amp;h=240&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 481px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=800&amp;h=520&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=800&amp;h=520&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 0px)" data-srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=480&amp;h=320&amp;dpr=2" srcset="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg?q=49&amp;fit=crop&amp;w=480&amp;h=320&amp;dpr=2">
                <img width="4000" height="2000" loading="lazy" decoding="async" alt="9-The End Of The Anticipated Game Era" data-img-url="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg" src="https://static1.thegamerimages.com/wordpress/wp-content/uploads/2024/04/9-the-end-of-the-anticipated-game-era.jpg">
    </picture>
                
    </figure>


        </div>

								
		
	</div>

		</a>
	
        
                            <div>

                
                                                    
                                    <p><span data-field="label">Next</span></p><h5>
			<a href="https://www.thegamer.com/end-anticipated-game-era-delays-look-forward/">
			The End Of The Anticipated Game Era
		</a>
	</h5>

                	<p><span data-field="excerpt">Cynicism, delays, and long development cycles mean we're never getting another slice of mythos like Half-Life 3</span></p>

                

                
            </div>
                
        
        
            </div>
</div>
    
        

                    


            </article>
    
    
    
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a website to share files and messages without any server (124 pts)]]></title>
            <link>https://neighbor-share.vercel.app/</link>
            <guid>40263027</guid>
            <pubDate>Sun, 05 May 2024 07:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neighbor-share.vercel.app/">https://neighbor-share.vercel.app/</a>, See on <a href="https://news.ycombinator.com/item?id=40263027">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Rusty.hpp: A Borrow Checker and Memory Ownership System for C++20 (108 pts)]]></title>
            <link>https://github.com/Jaysmito101/rusty.hpp</link>
            <guid>40263017</guid>
            <pubDate>Sun, 05 May 2024 07:38:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Jaysmito101/rusty.hpp">https://github.com/Jaysmito101/rusty.hpp</a>, See on <a href="https://news.ycombinator.com/item?id=40263017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">rusty.hpp</h2><a id="user-content-rustyhpp" aria-label="Permalink: rusty.hpp" href="#rustyhpp"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is <code>rusty.hpp</code>?</h2><a id="user-content-what-is-rustyhpp" aria-label="Permalink: What is rusty.hpp?" href="#what-is-rustyhpp"></a></p>
<p dir="auto">At the core, the idea is to have implement a minimal and lightweight yet powerful and performant system to be able to emulate Rust's borrow checker and general memory model as a C++ header-only library.</p>
<p dir="auto">Quoting from <a href="https://rustc-dev-guide.rust-lang.org/borrow_check.html" rel="nofollow">rust-lang.org</a>, the borrow check is Rust's "secret sauce" – it is tasked with enforcing a number of properties:</p>
<ul dir="auto">
<li>That all variables are initialized before they are used.</li>
<li>That you can't move the same value twice.</li>
<li>That you can't move a value while it is borrowed.</li>
<li>That you can't access a place while it is mutably borrowed (except through the reference).</li>
<li>That you can't mutate a place while it is immutably borrowed.</li>
<li>etc</li>
</ul>
<p dir="auto">Here too, <code>rusty.hpp</code> tries to add these concepts into a regular C++ codebase with ease. <code>rusty.hpp</code> also brings in additional features which are a very fundamental part of a Rust workflow like:</p>
<ul dir="auto">
<li>Non-nullable value</li>
<li>Option&lt; T &gt;</li>
<li>Result&lt; T, E &gt;</li>
<li>Rc (todo)</li>
<li>Arc (todo)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">What to expect?</h2><a id="user-content-what-to-expect" aria-label="Permalink: What to expect?" href="#what-to-expect"></a></p>
<p dir="auto"><code>rusty.hpp</code> as the time or writing this is a very experimental thing. Its primary purpose is to experiment and test out different coding styles and exploring a different than usual C++ workspace. This can also be a simple tool for C++ developers to try and get an idea of the typical workflows in a Rust dev environment staying in their comfort zone of C++. That being said, I did try my best to get the apis and behaviour to be as close to native rust as possible but obviously as one might expect there are exceptions to this. For instance, since this is not a part of the compiler itself, there is a limit to which it can go, what I mean by that is borrow errors which would usually be reported by the rust compiler at compile time will be redirected as exceptions in C++, although there are ways to not go the exception way and deal with things more gracefully, which I would go into in the examples. Another instance would be that, since C++ doesnt inherently has a strict concept of lifetime as Rust(they are not very same) cases of dangling references would also be redirected to exceptions and checks at runtime in case the main resorce gets freed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to use this?</h2><a id="user-content-how-to-use-this" aria-label="Permalink: How to use this?" href="#how-to-use-this"></a></p>
<p dir="auto">Whith all that being said, it still is a interesting library which you could easily try out in your own project. To get started all you need to do is get the header file <a href="https://github.com/Jaysmito101/rusty.hpp/blob/main/rusty.hpp">rusty.hpp</a> and include it in your project. It heavily relies on templates to make it completely generic to be integrated anywhere. Also this has got dependencies apart from the C++20 standard library(C++20 is needed so that I could use things like std::format, concepts, etc). After that you need a C++20 compitable compiler (MSVC or gcc 13+) and you are ready to go.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples / Usage</h2><a id="user-content-examples--usage" aria-label="Permalink: Examples / Usage" href="#examples--usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rust Like type proxies</h3><a id="user-content-rust-like-type-proxies" aria-label="Permalink: Rust Like type proxies" href="#rust-like-type-proxies"></a></p>
<p dir="auto"><code>rusty.hpp</code> defines proxies to standard C++ types named like the Rust types also under the namespace <code>rs::literals</code> there are C++ literal helpers for these types.</p>
<div dir="auto" data-snippet-clipboard-copy-content="i8 a = 45_i8;
i16 b = 45_i16;
i32 c = 45_i32;
i64 d = 45_i64;
u8 e = 45_u8;
u16 f = 45_u16;
u32 g = 45_u32;
u64 h = 45_u64;
f32 i = 45.0_f32;
f64 j = 45.0_f64;"><pre>i8 a = 45_i8;
i16 b = 45_i16;
i32 c = 45_i32;
i64 d = 45_i64;
u8 e = 45_u8;
u16 f = 45_u16;
u32 g = 45_u32;
u64 h = 45_u64;
f32 i = <span>45</span>.0_f32;
f64 j = <span>45</span>.0_f64;</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">print proxies</h3><a id="user-content-print-proxies" aria-label="Permalink: print proxies" href="#print-proxies"></a></p>
<p dir="auto"><code>rusty.hpp</code> defines <code>print</code> and <code>println</code> methods to be like a equivalent of Rust's <code>print!</code> and <code>println!</code> macros.</p>
<div data-snippet-clipboard-copy-content="println(&quot;Hello World! {}&quot;, 45);"><pre><code>println("Hello World! {}", 45);
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Borrow Checker</h3><a id="user-content-the-borrow-checker" aria-label="Permalink: The Borrow Checker" href="#the-borrow-checker"></a></p>
<p dir="auto">In <code>rusty.hpp</code> the primary way to use the borrow checker is to use the <code>rs::Val</code> type wrapper around everyting. This is a special type that enfoces all the rules and manages the borrowing and ownership of the data in general. Also it is to be noted that this library doesnt use any sort of global state, everything is localized inside the <code>Val</code> type.</p>
<div data-snippet-clipboard-copy-content="struct Foo {
  i32 a;
  i32 b;

  Foo(i32 a, i32 b) : a(a), b(b) { }
}

auto a = Val(46584); // With primitives
auto b = Val(std::string(&quot;Hello World&quot;)); // With stl
auto c = Val(Foo {4, 6}); // Pass object as it is
auto d = MakeVal<Foo>(5, 3); // Another way possible
auto e = Val(new Foo(3, 5)); // This pointer is now owned and manged by the Val and you dont need to delete it"><pre><code>struct Foo {
  i32 a;
  i32 b;

  Foo(i32 a, i32 b) : a(a), b(b) { }
}

auto a = Val(46584); // With primitives
auto b = Val(std::string("Hello World")); // With stl
auto c = Val(Foo {4, 6}); // Pass object as it is
auto d = MakeVal&lt;Foo&gt;(5, 3); // Another way possible
auto e = Val(new Foo(3, 5)); // This pointer is now owned and manged by the Val and you dont need to delete it
</code></pre></div>
<p dir="auto">Now, it is to be noted that we use Move constructors to move the data and take ownership but in C++ there is no way to implicitly know whether an object is moved properly or not, and The destructor will be called for after the move as in:</p>
<div data-snippet-clipboard-copy-content="auto a = Val(Foo {4, 6}); // Pass object as it is
// ~Foo called here for the temporary object"><pre><code>auto a = Val(Foo {4, 6}); // Pass object as it is
// ~Foo called here for the temporary object
</code></pre></div>
<p dir="auto">Now, there are many very easy ways to deal with it,</p>
<ul dir="auto">
<li>For simple object that can be easly be copied its not a issue so you could just ignore it</li>
<li>For others there are two main options:
<ul dir="auto">
<li>Implement a move constructor and desctuctor and then track the move and bypass the desctuctor call accordingly</li>
<li>Or, the easier way would be to just pass a pointer, the rest of the API will behave the same</li>
</ul>
</li>
</ul>
<p dir="auto">Now about using the Val,</p>
<div data-snippet-clipboard-copy-content="auto a = Val(45);
auto b = Val(5);
auto c = *a + *b; // here c is a i32, you can wrap it up in a Val if you want

// All of them share same api (mostly)
auto foo0 = Val(Foo{ 0, 0 }); 
auto foo1 = MakeVal<Foo>(1, 1);
auto foo3 = Val(new Foo(0, 0));
auto foo4 = Val(std::make_shared<Foo>(45, 5));
auto foo5 = Val(std::make_unique<Foo>(45, 5));
foo1->a = 2; // be it a pointer or a Object you should be able to acces inner filed like this
"><pre><code>auto a = Val(45);
auto b = Val(5);
auto c = *a + *b; // here c is a i32, you can wrap it up in a Val if you want

// All of them share same api (mostly)
auto foo0 = Val(Foo{ 0, 0 }); 
auto foo1 = MakeVal&lt;Foo&gt;(1, 1);
auto foo3 = Val(new Foo(0, 0));
auto foo4 = Val(std::make_shared&lt;Foo&gt;(45, 5));
auto foo5 = Val(std::make_unique&lt;Foo&gt;(45, 5));
foo1-&gt;a = 2; // be it a pointer or a Object you should be able to acces inner filed like this

</code></pre></div>
<p dir="auto">Now about the actual checks:</p>
<div data-snippet-clipboard-copy-content="auto foo2 = foo0; // foo0's ownership is not transfered to foo2
println(&quot;foo2: {}&quot;, *foo2); // ok
println(&quot;foo0: {}&quot;, *foo0); // Error: foo0 was moved to foo2

foo0 = pass_through(foo0); // pass ownership of foo0 to pass_through function and the function returns it back
println(&quot;foo0: {}&quot;, *foo0); // Works as the ownership was returned

non_pass_through(foo0); // pass ownership of foo0 to pass_through function and it gets consumed by it
println(&quot;foo0: {}&quot;, *foo0); // Error: foo0 was moved to non_pass_through and consumed

non_pass_through(foo0.clone()); // This needs a copy enabled type
println(&quot;foo0: {}&quot;, *foo0); // Works as the ownership was cloned

// Note to avoid exception and check if a Val is a valid object or not you can use
if( foo0.is_valid() ) { ... }

// Manually forcefully invalidate/drop a Val
foo0.drop() // the resource is destroyed and this foo0 is now invalid

// Note: a Val is a non-nullable value, so it can never be null"><pre><code>auto foo2 = foo0; // foo0's ownership is not transfered to foo2
println("foo2: {}", *foo2); // ok
println("foo0: {}", *foo0); // Error: foo0 was moved to foo2

foo0 = pass_through(foo0); // pass ownership of foo0 to pass_through function and the function returns it back
println("foo0: {}", *foo0); // Works as the ownership was returned

non_pass_through(foo0); // pass ownership of foo0 to pass_through function and it gets consumed by it
println("foo0: {}", *foo0); // Error: foo0 was moved to non_pass_through and consumed

non_pass_through(foo0.clone()); // This needs a copy enabled type
println("foo0: {}", *foo0); // Works as the ownership was cloned

// Note to avoid exception and check if a Val is a valid object or not you can use
if( foo0.is_valid() ) { ... }

// Manually forcefully invalidate/drop a Val
foo0.drop() // the resource is destroyed and this foo0 is now invalid

// Note: a Val is a non-nullable value, so it can never be null
</code></pre></div>
<p dir="auto">About References and Borrowing:</p>
<div data-snippet-clipboard-copy-content="{
  auto foo_ref = foo0.borrow(); // borrows immutably
  let b = foo_ref->a; // ok
  foo_ref->a = 56; // not possible as foo_ref is immutable reference to foo

  auto foo1_ref = foo1.borrow_mut(); // borrows mutably
  let b = foo1_ref->a; // ok
  foo1_ref->a = 56; // ok
}

// Borrow safety
{
  auto foo_ref0 = foo0.borrow();
  auto foo_ref1 = foo0.borrow();  // ok as multiple immutable borrows are allowed

  auto foo_ref2 = foo0.borrow_mut(); // Error as foo0 has already been borrowed immutably
}

{
  auto foo_ref0 = foo0.borrow_mut();
  auto foo_ref1 = foo0.borrow();  // Error as foo0 has already been borrowed mutably
}

// lifetime management of a ref(kinda?)
let foo3 = Val(65.0_f32);
auto foo3_ref = foo3.borrow();
non_pass_through(foo3); // loose the ownership of foo3 as its transfereed to non_pass_through
                        // and consumed there and foo3_ref now supposedly is a
                        // dangling reference
// foo3_ref.is_valid() or if(foo3_ref) // both will be false
// println(&quot;foo3_ref: {}&quot;, *foo3_ref); // Error: ref value has expired

// Note: Ref and RefMut too are non-nullable
// Note: If for some reason you managed to have multiple levels of pointers inside the Val object
         you could use .value() method of Val to access the pointers rather than the -> operator"><pre><code>{
  auto foo_ref = foo0.borrow(); // borrows immutably
  let b = foo_ref-&gt;a; // ok
  foo_ref-&gt;a = 56; // not possible as foo_ref is immutable reference to foo

  auto foo1_ref = foo1.borrow_mut(); // borrows mutably
  let b = foo1_ref-&gt;a; // ok
  foo1_ref-&gt;a = 56; // ok
}

// Borrow safety
{
  auto foo_ref0 = foo0.borrow();
  auto foo_ref1 = foo0.borrow();  // ok as multiple immutable borrows are allowed

  auto foo_ref2 = foo0.borrow_mut(); // Error as foo0 has already been borrowed immutably
}

{
  auto foo_ref0 = foo0.borrow_mut();
  auto foo_ref1 = foo0.borrow();  // Error as foo0 has already been borrowed mutably
}

// lifetime management of a ref(kinda?)
let foo3 = Val(65.0_f32);
auto foo3_ref = foo3.borrow();
non_pass_through(foo3); // loose the ownership of foo3 as its transfereed to non_pass_through
                        // and consumed there and foo3_ref now supposedly is a
                        // dangling reference
// foo3_ref.is_valid() or if(foo3_ref) // both will be false
// println("foo3_ref: {}", *foo3_ref); // Error: ref value has expired

// Note: Ref and RefMut too are non-nullable
// Note: If for some reason you managed to have multiple levels of pointers inside the Val object
         you could use .value() method of Val to access the pointers rather than the -&gt; operator
</code></pre></div>
<p dir="auto">About Option:</p>
<div data-snippet-clipboard-copy-content="auto aa = Some(46);    // this is a equivalent to rust Option
auto ba = None<u32>(); // Here for none unlike rust you have to
                       // give the type annotation for the templates
                       // as we need to setup for the Some too

println(&quot;aa: {}&quot;, aa);
println(&quot;aa: {}&quot;, aa.unwrap()); // this might throw exceptions if aa is None

aa.is_some(); // check if it is some
aa.is_none(); // check if it is none

aa.as_ref(); // Option<Val<T>> -> Option<Ref<T>>
aa.as_mut(); // Option<Val<T>> -> Option<RefMut<T>>

auto aaa = Some( new Foo(45, 5) );
println(&quot;{}&quot;, aaa.unwrap()); // This throws an exception if it is None
println(&quot;{}&quot;, aaa.unwrap_or( new Foo(0, 0) )); // returns the value if its none, (wraps it up in a Val)
println(&quot;{}&quot;, aaa.unwrap_or_else([]() { return new Foo(546, 546); })); // again here it is wrapped in a Val
println(&quot;{}&quot;, *aaa.as_ref().unwrap()); // There we get a immutable reference to the object and
                                       // then unwrap it and dereferemce the reference to get value
println(&quot;{}&quot;, aaa.map<f32>([](Foo* foo ) { return (f32)foo->a; })); // Map the value to something else

aaa.cloned(); // Crates a new Option<T> cloning the internal Val"><pre><code>auto aa = Some(46);    // this is a equivalent to rust Option
auto ba = None&lt;u32&gt;(); // Here for none unlike rust you have to
                       // give the type annotation for the templates
                       // as we need to setup for the Some too

println("aa: {}", aa);
println("aa: {}", aa.unwrap()); // this might throw exceptions if aa is None

aa.is_some(); // check if it is some
aa.is_none(); // check if it is none

aa.as_ref(); // Option&lt;Val&lt;T&gt;&gt; -&gt; Option&lt;Ref&lt;T&gt;&gt;
aa.as_mut(); // Option&lt;Val&lt;T&gt;&gt; -&gt; Option&lt;RefMut&lt;T&gt;&gt;

auto aaa = Some( new Foo(45, 5) );
println("{}", aaa.unwrap()); // This throws an exception if it is None
println("{}", aaa.unwrap_or( new Foo(0, 0) )); // returns the value if its none, (wraps it up in a Val)
println("{}", aaa.unwrap_or_else([]() { return new Foo(546, 546); })); // again here it is wrapped in a Val
println("{}", *aaa.as_ref().unwrap()); // There we get a immutable reference to the object and
                                       // then unwrap it and dereferemce the reference to get value
println("{}", aaa.map&lt;f32&gt;([](Foo* foo ) { return (f32)foo-&gt;a; })); // Map the value to something else

aaa.cloned(); // Crates a new Option&lt;T&gt; cloning the internal Val
</code></pre></div>
<p dir="auto">About Result:</p>
<div data-snippet-clipboard-copy-content="auto ok_result = Ok<i32, str>(42); // Create a Result with Ok variant, need to give type hints for both
auto err_result = Err<i32, std::string>(&quot;Error occurred&quot;); // Create a Result with Err variant

println(&quot;ok_result: {}&quot;, ok_result);
println(&quot;err_result: {}&quot;, err_result);

ok_result.is_ok(); // Check if the Result is Ok
ok_result.is_err(); // Check if the Result is Err
ok_result.is_valid(); // Check if the Result is valid or invalid

ok_result.ok(); // Extract the Ok value if present, otherwise None, consumes self
err_result.err(); // Extract the Err value if present, otherwise None, consumes self

ok_result.unwrap(); // Same as .ok(), but throws an exception
err_result.unwrap_err(); // Same as .err(), but throws an exception

ok_result.unwrap_or(0); // Unwrap the Ok value, or return a default value if it's an Err

ok_result.unwrap_or_else([]() { return 0; });           // Unwrap the Ok value, or execute a function to get a default value if it's an Err

ok_result.map<float>([](int value) { return static_cast<float>(value); }); // Map the Ok value to a different type

ok_result.expect(&quot;Failed to retrieve value&quot;); // Same as unwrap(), but allows providing a custom error message

ok_result.cloned(); // Crates a new Result<T, E> cloning the internal Val"><pre><code>auto ok_result = Ok&lt;i32, str&gt;(42); // Create a Result with Ok variant, need to give type hints for both
auto err_result = Err&lt;i32, std::string&gt;("Error occurred"); // Create a Result with Err variant

println("ok_result: {}", ok_result);
println("err_result: {}", err_result);

ok_result.is_ok(); // Check if the Result is Ok
ok_result.is_err(); // Check if the Result is Err
ok_result.is_valid(); // Check if the Result is valid or invalid

ok_result.ok(); // Extract the Ok value if present, otherwise None, consumes self
err_result.err(); // Extract the Err value if present, otherwise None, consumes self

ok_result.unwrap(); // Same as .ok(), but throws an exception
err_result.unwrap_err(); // Same as .err(), but throws an exception

ok_result.unwrap_or(0); // Unwrap the Ok value, or return a default value if it's an Err

ok_result.unwrap_or_else([]() { return 0; });           // Unwrap the Ok value, or execute a function to get a default value if it's an Err

ok_result.map&lt;float&gt;([](int value) { return static_cast&lt;float&gt;(value); }); // Map the Ok value to a different type

ok_result.expect("Failed to retrieve value"); // Same as unwrap(), but allows providing a custom error message

ok_result.cloned(); // Crates a new Result&lt;T, E&gt; cloning the internal Val
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xmake: A modern C/C++ build tool (163 pts)]]></title>
            <link>https://github.com/xmake-io/xmake</link>
            <guid>40262779</guid>
            <pubDate>Sun, 05 May 2024 06:47:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/xmake-io/xmake">https://github.com/xmake-io/xmake</a>, See on <a href="https://news.ycombinator.com/item?id=40262779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">Support this project</h2><a id="user-content-support-this-project" aria-label="Permalink: Support this project" href="#support-this-project"></a></p>
<p dir="auto">Support this project by <a href="https://xmake.io/#/about/sponsor" rel="nofollow">becoming a sponsor</a>. Your logo will show up here with a link to your website. 🙏</p>
<p dir="auto"><a href="https://opencollective.com/xmake#sponsors" rel="nofollow"><img src="https://camo.githubusercontent.com/540de9e1fbe6d93e6e5f1d3db50ba4b5fe341468d5953bfceb979ffde00ddf95/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f786d616b652f73706f6e736f72732e7376673f77696474683d383930" data-canonical-src="https://opencollective.com/xmake/sponsors.svg?width=890"></a>
<a href="https://opencollective.com/xmake#backers" rel="nofollow"><img src="https://camo.githubusercontent.com/4d7b50bed223324b59e7e4d29dda5b79990f2714479cbeceaa7df1159dedb6a9/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f786d616b652f6261636b6572732e7376673f77696474683d383930" data-canonical-src="https://opencollective.com/xmake/backers.svg?width=890"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical support</h2><a id="user-content-technical-support" aria-label="Permalink: Technical support" href="#technical-support"></a></p>
<p dir="auto">You can also consider sponsoring us to get extra technical support services via the <a href="https://github.com/sponsors/waruqi">Github sponsor program</a>. If you do, you can get access to the <a href="https://github.com/xmake-io/technical-support">xmake-io/technical-support</a> repository, which has the following bennefits:</p>
<ul>
<li> Handling Issues with higher priority</li>
<li> One-to-one technical consulting service</li>
<li> Review your xmake.lua and provide suggestions for improvement</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction (<a href="https://github.com/xmake-io/xmake/blob/master/README_zh.md">中文</a>)</h2><a id="user-content-introduction-中文" aria-label="Permalink: Introduction (中文)" href="#introduction-中文"></a></p>
<p dir="auto">What is Xmake?</p>
<ol dir="auto">
<li>Xmake is a cross-platform build utility based on the Lua scripting language.</li>
<li>Xmake is very lightweight and has no dependencies outside of the standard library.</li>
<li>Uses the <code>xmake.lua</code> file to maintain project builds with a simple and readable syntax.</li>
</ol>
<p dir="auto">Xmake can be used to directly build source code (like with Make or Ninja), or it can generate project source files like CMake or Meson. It also has a <em>built-in</em> package management system to help users integrate C/C++ dependencies.</p>
<div data-snippet-clipboard-copy-content="Xmake = Build backend + Project Generator + Package Manager + [Remote|Distributed] Build + Cache"><pre><code>Xmake = Build backend + Project Generator + Package Manager + [Remote|Distributed] Build + Cache
</code></pre></div>
<p dir="auto">Although less precise, one can still understand Xmake in the following way:</p>
<div data-snippet-clipboard-copy-content="Xmake ≈ Make/Ninja + CMake/Meson + Vcpkg/Conan + distcc + ccache/sccache"><pre><code>Xmake ≈ Make/Ninja + CMake/Meson + Vcpkg/Conan + distcc + ccache/sccache
</code></pre></div>
<p dir="auto">If you want to know more, please refer to: the <a href="https://xmake.io/#/getting_started" rel="nofollow">Documentation</a>, <a href="https://github.com/xmake-io/xmake">GitHub</a> or <a href="https://gitee.com/tboox/xmake" rel="nofollow">Gitee</a>. You are also welcome to join our <a href="https://xmake.io/#/about/contact" rel="nofollow">community</a>.</p>
<p dir="auto">The official Xmake repository can be found at <a href="https://github.com/xmake-io/xmake-repo">xmake-io/xmake-repo</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/xmake-io/xmake-docs/raw/master/assets/img/index/xmake-basic-render.gif"><img src="https://github.com/xmake-io/xmake-docs/raw/master/assets/img/index/xmake-basic-render.gif" alt="" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">With cURL</h3><a id="user-content-with-curl" aria-label="Permalink: With cURL" href="#with-curl"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://xmake.io/shget.text | bash"><pre>curl -fsSL https://xmake.io/shget.text <span>|</span> bash</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">With Wget</h3><a id="user-content-with-wget" aria-label="Permalink: With Wget" href="#with-wget"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="wget https://xmake.io/shget.text -O - | bash"><pre>wget https://xmake.io/shget.text -O - <span>|</span> bash</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">With PowerShell</h3><a id="user-content-with-powershell" aria-label="Permalink: With PowerShell" href="#with-powershell"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="Invoke-Expression (Invoke-Webrequest 'https://xmake.io/psget.text' -UseBasicParsing).Content"><pre>Invoke-Expression (Invoke-Webrequest <span><span>'</span>https://xmake.io/psget.text<span>'</span></span> -UseBasicParsing).Content</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other installation methods</h3><a id="user-content-other-installation-methods" aria-label="Permalink: Other installation methods" href="#other-installation-methods"></a></p>
<p dir="auto">If you don't want to use the above scripts to install Xmake, visit the <a href="https://xmake.io/#/guide/installation" rel="nofollow">Installation Guide</a> for other installation methods (building from source, package managers, etc.).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simple Project Description</h2><a id="user-content-simple-project-description" aria-label="Permalink: Simple Project Description" href="#simple-project-description"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;console&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)"><pre><span>target</span>(<span><span>"</span>console<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)</pre></div>
<p dir="auto">Creates a new target <code>console</code> of kind <code>binary</code>, and adds all the files ending in <code>.c</code> in the <code>src</code> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Package dependences</h2><a id="user-content-package-dependences" aria-label="Permalink: Package dependences" href="#package-dependences"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="add_requires(&quot;tbox 1.6.*&quot;, &quot;zlib&quot;, &quot;libpng ~1.6&quot;)"><pre><span>add_requires</span>(<span><span>"</span>tbox 1.6.*<span>"</span></span>, <span><span>"</span>zlib<span>"</span></span>, <span><span>"</span>libpng ~1.6<span>"</span></span>)</pre></div>
<p dir="auto">Adds a requirement of tbox v1.6, zlib (any version), and libpng v1.6.</p>
<p dir="auto">The official xmake package repository exists at: <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a></p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/xmake-io/xmake-docs/raw/master/assets/img/index/package.gif"><img src="https://github.com/xmake-io/xmake-docs/raw/master/assets/img/index/package.gif" width="650px" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Commandline interface reference</h2><a id="user-content-commandline-interface-reference" aria-label="Permalink: Commandline interface reference" href="#commandline-interface-reference"></a></p>
<p dir="auto">The below assumes you are currently in the project's root directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build a project</h3><a id="user-content-build-a-project" aria-label="Permalink: Build a project" href="#build-a-project"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Run target</h3><a id="user-content-run-target" aria-label="Permalink: Run target" href="#run-target"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Debug target</h3><a id="user-content-debug-target" aria-label="Permalink: Debug target" href="#debug-target"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Run test</h3><a id="user-content-run-test" aria-label="Permalink: Run test" href="#run-test"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Configure platform</h3><a id="user-content-configure-platform" aria-label="Permalink: Configure platform" href="#configure-platform"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xmake f -p [windows|linux|macosx|android|iphoneos ..] -a [x86|arm64 ..] -m [debug|release]
$ xmake"><pre>$ xmake f -p [windows<span>|</span>linux<span>|</span>macosx<span>|</span>android<span>|</span>iphoneos ..] -a [x86<span>|</span>arm64 ..] -m [debug<span>|</span>release]
$ xmake</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Menu configuration</h3><a id="user-content-menu-configuration" aria-label="Permalink: Menu configuration" href="#menu-configuration"></a></p>

<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f69ca801876fd32bc9dbac7b1e710ec8b8e1b824c3095514b72fe78e25256381/68747470733a2f2f786d616b652e696f2f6173736574732f696d672f696e6465782f6d656e75636f6e662e706e67"><img src="https://camo.githubusercontent.com/f69ca801876fd32bc9dbac7b1e710ec8b8e1b824c3095514b72fe78e25256381/68747470733a2f2f786d616b652e696f2f6173736574732f696d672f696e6465782f6d656e75636f6e662e706e67" width="650px" data-canonical-src="https://xmake.io/assets/img/index/menuconf.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported platforms</h2><a id="user-content-supported-platforms" aria-label="Permalink: Supported platforms" href="#supported-platforms"></a></p>
<ul dir="auto">
<li>Windows (x86, x64, arm64)</li>
<li>macOS (i386, x86_64, arm64)</li>
<li>Linux (i386, x86_64, arm, arm64, riscv, mips, 390x, sh4 ...)</li>
<li>*BSD (i386, x86_64)</li>
<li>Android (x86, x86_64, armeabi, armeabi-v7a, arm64-v8a)</li>
<li>iOS (armv7, armv7s, arm64, i386, x86_64)</li>
<li>WatchOS (armv7k, i386)</li>
<li>AppleTVOS (armv7, arm64, i386, x86_64)</li>
<li>AppleXROS (arm64, x86_64)</li>
<li>MSYS (i386, x86_64)</li>
<li>MinGW (i386, x86_64, arm, arm64)</li>
<li>Cygwin (i386, x86_64)</li>
<li>Wasm (wasm32, wasm64)</li>
<li>Haiku (i386, x86_64)</li>
<li>Harmony (x86_64, armeabi-v7a, arm64-v8a)</li>
<li>Cross (cross-toolchains ..)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported toolchains</h2><a id="user-content-supported-toolchains" aria-label="Permalink: Supported toolchains" href="#supported-toolchains"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xmake show -l toolchains
xcode         Xcode IDE
msvc          Microsoft Visual C/C++ Compiler
clang-cl      LLVM Clang C/C++ Compiler compatible with msvc
yasm          The Yasm Modular Assembler
clang         A C language family frontend for LLVM
go            Go Programming Language Compiler
dlang         D Programming Language Compiler (Auto)
dmd           D Programming Language Compiler
ldc           The LLVM-based D Compiler
gdc           The GNU D Compiler (GDC)
gfortran      GNU Fortran Programming Language Compiler
zig           Zig Programming Language Compiler
sdcc          Small Device C Compiler
cuda          CUDA Toolkit (nvcc, nvc, nvc++, nvfortran)
ndk           Android NDK
rust          Rust Programming Language Compiler
swift         Swift Programming Language Compiler
llvm          A collection of modular and reusable compiler and toolchain technologies
cross         Common cross compilation toolchain
nasm          NASM Assembler
gcc           GNU Compiler Collection
mingw         Minimalist GNU for Windows
gnu-rm        GNU Arm Embedded Toolchain
envs          Environment variables toolchain
fasm          Flat Assembler
tinycc        Tiny C Compiler
emcc          A toolchain for compiling to asm.js and WebAssembly
icc           Intel C/C++ Compiler
ifort         Intel Fortran Compiler
muslcc        The musl-based cross-compilation toolchain
fpc           Free Pascal Programming Language Compiler
wasi          WASI-enabled WebAssembly C/C++ toolchain
nim           Nim Programming Language Compiler
circle        A new C++20 compiler
armcc         ARM Compiler Version 5 of Keil MDK
armclang      ARM Compiler Version 6 of Keil MDK
c51           Keil development tools for the 8051 Microcontroller Architecture
icx           Intel LLVM C/C++ Compiler
dpcpp         Intel LLVM C++ Compiler for data parallel programming model based on Khronos SYCL
masm32        The MASM32 SDK
iverilog      Icarus Verilog
verilator     Verilator open-source SystemVerilog simulator and lint system
cosmocc       build-once run-anywhere
hdk           Harmony SDK"><pre>$ xmake show -l toolchains
xcode         Xcode IDE
msvc          Microsoft Visual C/C++ Compiler
clang-cl      LLVM Clang C/C++ Compiler compatible with msvc
yasm          The Yasm Modular Assembler
clang         A C language family frontend <span>for</span> LLVM
go            Go Programming Language Compiler
dlang         D Programming Language Compiler (Auto)
dmd           D Programming Language Compiler
ldc           The LLVM-based D Compiler
gdc           The GNU D Compiler (GDC)
gfortran      GNU Fortran Programming Language Compiler
zig           Zig Programming Language Compiler
sdcc          Small Device C Compiler
cuda          CUDA Toolkit (nvcc, nvc, nvc++, nvfortran)
ndk           Android NDK
rust          Rust Programming Language Compiler
swift         Swift Programming Language Compiler
llvm          A collection of modular and reusable compiler and toolchain technologies
cross         Common cross compilation toolchain
nasm          NASM Assembler
gcc           GNU Compiler Collection
mingw         Minimalist GNU <span>for</span> Windows
gnu-rm        GNU Arm Embedded Toolchain
envs          Environment variables toolchain
fasm          Flat Assembler
tinycc        Tiny C Compiler
emcc          A toolchain <span>for</span> compiling to asm.js and WebAssembly
icc           Intel C/C++ Compiler
ifort         Intel Fortran Compiler
muslcc        The musl-based cross-compilation toolchain
fpc           Free Pascal Programming Language Compiler
wasi          WASI-enabled WebAssembly C/C++ toolchain
nim           Nim Programming Language Compiler
circle        A new C++20 compiler
armcc         ARM Compiler Version 5 of Keil MDK
armclang      ARM Compiler Version 6 of Keil MDK
c51           Keil development tools <span>for</span> the 8051 Microcontroller Architecture
icx           Intel LLVM C/C++ Compiler
dpcpp         Intel LLVM C++ Compiler <span>for</span> data parallel programming model based on Khronos SYCL
masm32        The MASM32 SDK
iverilog      Icarus Verilog
verilator     Verilator open-source SystemVerilog simulator and lint system
cosmocc       build-once run-anywhere
hdk           Harmony SDK</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported languages</h2><a id="user-content-supported-languages" aria-label="Permalink: Supported languages" href="#supported-languages"></a></p>
<ul dir="auto">
<li>C and C++</li>
<li>Objective-C and Objective-C++</li>
<li>Swift</li>
<li>Assembly</li>
<li>Golang</li>
<li>Rust</li>
<li>Dlang</li>
<li>Fortran</li>
<li>Cuda</li>
<li>Zig</li>
<li>Vala</li>
<li>Pascal</li>
<li>Nim</li>
<li>Verilog</li>
<li>FASM</li>
<li>NASM</li>
<li>YASM</li>
<li>MASM32</li>
<li>Cppfront</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Xmake exhibits:</p>
<ul dir="auto">
<li>Simple yet flexible configuration grammar.</li>
<li>Quick, dependency-free installation.</li>
<li>Easy compilation for most all supported platforms.</li>
<li>Supports cross-compilation with intelligent analysis of cross toolchain information.</li>
<li>Extremely fast parallel compilation support.</li>
<li>Supports C++ modules (new in C++20).</li>
<li>Supports cross-platform C/C++ dependencies with built-in package manager.</li>
<li>Multi-language compilation support including mixed-language projects.</li>
<li>Rich plug-in support with various project generators (ex. Visual Studio/Makefiles/CMake/<code>compile_commands.json</code>)</li>
<li>REPL interactive execution support</li>
<li>Incremental compilation support with automatic analysis of header files</li>
<li>Built-in toolchain management</li>
<li>A large number of expansion modules</li>
<li>Remote compilation support</li>
<li>Distributed compilation support</li>
<li>Local and remote build cache support</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Project Types</h2><a id="user-content-supported-project-types" aria-label="Permalink: Supported Project Types" href="#supported-project-types"></a></p>
<p dir="auto">Xmake supports the below types of projects:</p>
<ul dir="auto">
<li>Static libraries</li>
<li>Shared libraries</li>
<li>Console/CLI applications</li>
<li>CUDA programs</li>
<li>Qt applications</li>
<li>WDK drivers (umdf/kmdf/wdm)</li>
<li>WinSDK applications</li>
<li>MFC applications</li>
<li>Darwin applications (with metal support)</li>
<li>Frameworks and bundles (in Darwin)</li>
<li>SWIG modules (Lua, Python, ...)</li>
<li>LuaRocks modules</li>
<li>Protobuf programs</li>
<li>Lex/Yacc programs</li>
<li>Linux kernel modules</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Package management</h2><a id="user-content-package-management" aria-label="Permalink: Package management" href="#package-management"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Download and build</h3><a id="user-content-download-and-build" aria-label="Permalink: Download and build" href="#download-and-build"></a></p>
<p dir="auto">Xmake can automatically fetch and install dependencies!</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6e15b1f9d463bf7920341e45d1eb6b3cee88d77015c502cee3d410f0e38cdc4a/68747470733a2f2f786d616b652e696f2f6173736574732f696d672f696e6465782f7061636b6167655f6d616e6167652e706e67"><img src="https://camo.githubusercontent.com/6e15b1f9d463bf7920341e45d1eb6b3cee88d77015c502cee3d410f0e38cdc4a/68747470733a2f2f786d616b652e696f2f6173736574732f696d672f696e6465782f7061636b6167655f6d616e6167652e706e67" width="650px" data-canonical-src="https://xmake.io/assets/img/index/package_manage.png"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Supported package repositories</h3><a id="user-content-supported-package-repositories" aria-label="Permalink: Supported package repositories" href="#supported-package-repositories"></a></p>
<ul dir="auto">
<li>Official package repository <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a> (tbox &gt;1.6.1)</li>
<li>Official package manager <a href="https://github.com/xmake-io/xrepo">Xrepo</a></li>
<li><a href="https://xmake.io/#/package/remote_package?id=using-self-built-private-package-repository" rel="nofollow">User-built repositories</a></li>
<li>Conan (conan::openssl/1.1.1g)</li>
<li>Conda (conda::libpng 1.3.67)</li>
<li>Vcpkg (vcpkg:ffmpeg)</li>
<li>Homebrew/Linuxbrew (brew::pcre2/libpcre2-8)</li>
<li>Pacman on archlinux/msys2 (pacman::libcurl)</li>
<li>Apt on ubuntu/debian (apt::zlib1g-dev)</li>
<li>Clib (clib::clibs/bytes@0.0.4)</li>
<li>Dub (dub::log 0.4.3)</li>
<li>Portage on Gentoo/Linux (portage::libhandy)</li>
<li>Nimble for nimlang (nimble::zip &gt;1.3)</li>
<li>Cargo for rust (cargo::base64 0.13.0)</li>
<li>Zypper on openSUSE (zypper::libsfml2 2.5)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Package management features</h3><a id="user-content-package-management-features" aria-label="Permalink: Package management features" href="#package-management-features"></a></p>
<ul dir="auto">
<li>The official repository provides nearly 500+ packages with simple compilation on all supported platforms</li>
<li>Full platform package support, support for cross-compiled dependent packages</li>
<li>Support package virtual environment using <code>xrepo env shell</code></li>
<li>Precompiled package acceleration for Windows (NT)</li>
<li>Support self-built package repositories and private repository deployment</li>
<li>Third-party package repository support for repositories such as: vcpkg, conan, conda, etc.</li>
<li>Supports automatic pulling of remote toolchains</li>
<li>Supports dependency version locking</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Processing architecture</h2><a id="user-content-processing-architecture" aria-label="Permalink: Processing architecture" href="#processing-architecture"></a></p>
<p dir="auto">Below is a diagram showing roughly the architecture of Xmake, and thus how it functions.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8a72cb6455d105e8e3125d4fb2287368f5476fd395d9c8e622edf59f7f459250/68747470733a2f2f786d616b652e696f2f6173736574732f696d672f696e6465782f7061636b6167655f617263682e706e67"><img src="https://camo.githubusercontent.com/8a72cb6455d105e8e3125d4fb2287368f5476fd395d9c8e622edf59f7f459250/68747470733a2f2f786d616b652e696f2f6173736574732f696d672f696e6465782f7061636b6167655f617263682e706e67" width="650px" data-canonical-src="https://xmake.io/assets/img/index/package_arch.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Distributed Compilation</h2><a id="user-content-distributed-compilation" aria-label="Permalink: Distributed Compilation" href="#distributed-compilation"></a></p>
<ul>
<li> Cross-platform support.</li>
<li> Support for MSVC, Clang, GCC and other cross-compilation toolchains.</li>
<li> Support for building for Android, Linux, Windows NT, and Darwin hosts.</li>
<li> No dependencies other than the compilation toolchain.</li>
<li> Support for build server load balancing scheduling.</li>
<li> Support for real time compressed transfer of large files (lz4).</li>
<li> Almost zero configuration cost, no shared filesystem required, for convenience and security.</li>
</ul>
<p dir="auto">For more details see: <a href="https://github.com/xmake-io/xmake/issues/274" data-hovercard-type="issue" data-hovercard-url="/xmake-io/xmake/issues/274/hovercard">#274</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Remote Compilation</h2><a id="user-content-remote-compilation" aria-label="Permalink: Remote Compilation" href="#remote-compilation"></a></p>
<p dir="auto">For more details see: <a href="https://github.com/xmake-io/xmake/issues/622" data-hovercard-type="issue" data-hovercard-url="/xmake-io/xmake/issues/622/hovercard">#622</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local/Remote Build Cache</h2><a id="user-content-localremote-build-cache" aria-label="Permalink: Local/Remote Build Cache" href="#localremote-build-cache"></a></p>
<p dir="auto">For more details see: <a href="https://github.com/xmake-io/xmake/issues/2371" data-hovercard-type="issue" data-hovercard-url="/xmake-io/xmake/issues/2371/hovercard">#622</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark</h2><a id="user-content-benchmark" aria-label="Permalink: Benchmark" href="#benchmark"></a></p>
<p dir="auto">Xmake's speed on is par with Ninja! The test project: <a href="https://github.com/xmake-io/xmake/tree/master/core">xmake-core</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi-task parallel compilation</h3><a id="user-content-multi-task-parallel-compilation" aria-label="Permalink: Multi-task parallel compilation" href="#multi-task-parallel-compilation"></a></p>
<table>
<thead>
<tr>
<th>buildsystem</th>
<th>Termux (8core/-j12)</th>
<th>buildsystem</th>
<th>MacOS (8core/-j12)</th>
</tr>
</thead>
<tbody>
<tr>
<td>xmake</td>
<td>24.890s</td>
<td>xmake</td>
<td>12.264s</td>
</tr>
<tr>
<td>ninja</td>
<td>25.682s</td>
<td>ninja</td>
<td>11.327s</td>
</tr>
<tr>
<td>cmake(gen+make)</td>
<td>5.416s+28.473s</td>
<td>cmake(gen+make)</td>
<td>1.203s+14.030s</td>
</tr>
<tr>
<td>cmake(gen+ninja)</td>
<td>4.458s+24.842s</td>
<td>cmake(gen+ninja)</td>
<td>0.988s+11.644s</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Single task compilation</h2><a id="user-content-single-task-compilation" aria-label="Permalink: Single task compilation" href="#single-task-compilation"></a></p>
<table>
<thead>
<tr>
<th>buildsystem</th>
<th>Termux (-j1)</th>
<th>buildsystem</th>
<th>MacOS (-j1)</th>
</tr>
</thead>
<tbody>
<tr>
<td>xmake</td>
<td>1m57.707s</td>
<td>xmake</td>
<td>39.937s</td>
</tr>
<tr>
<td>ninja</td>
<td>1m52.845s</td>
<td>ninja</td>
<td>38.995s</td>
</tr>
<tr>
<td>cmake(gen+make)</td>
<td>5.416s+2m10.539s</td>
<td>cmake(gen+make)</td>
<td>1.203s+41.737s</td>
</tr>
<tr>
<td>cmake(gen+ninja)</td>
<td>4.458s+1m54.868s</td>
<td>cmake(gen+ninja)</td>
<td>0.988s+38.022s</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">More Examples</h2><a id="user-content-more-examples" aria-label="Permalink: More Examples" href="#more-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Debug and release profiles</h3><a id="user-content-debug-and-release-profiles" aria-label="Permalink: Debug and release profiles" href="#debug-and-release-profiles"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="add_rules(&quot;mode.debug&quot;, &quot;mode.release&quot;)

target(&quot;console&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)
    if is_mode(&quot;debug&quot;) then
        add_defines(&quot;DEBUG&quot;)
    end"><pre><span>add_rules</span>(<span><span>"</span>mode.debug<span>"</span></span>, <span><span>"</span>mode.release<span>"</span></span>)

<span>target</span>(<span><span>"</span>console<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)
    <span>if</span> <span>is_mode</span>(<span><span>"</span>debug<span>"</span></span>) <span>then</span>
        <span>add_defines</span>(<span><span>"</span>DEBUG<span>"</span></span>)
    <span>end</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Custom scripts</h3><a id="user-content-custom-scripts" aria-label="Permalink: Custom scripts" href="#custom-scripts"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)
    after_build(function (target)
        print(&quot;hello: %s&quot;, target:name())
        os.exec(&quot;echo %s&quot;, target:targetfile())
    end)"><pre><span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)
    <span>after_build</span>(<span>function</span> (<span>target</span>)
        <span>print</span>(<span><span>"</span>hello: %s<span>"</span></span>, <span>target</span>:<span>name</span>())
        <span>os</span>.<span>exec</span>(<span><span>"</span>echo %s<span>"</span></span>, <span>target</span>:<span>targetfile</span>())
    <span>end</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatic integration of dependent packages</h3><a id="user-content-automatic-integration-of-dependent-packages" aria-label="Permalink: Automatic integration of dependent packages" href="#automatic-integration-of-dependent-packages"></a></p>
<p dir="auto">Download and use packages in <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a> or third-party repositories:</p>
<div dir="auto" data-snippet-clipboard-copy-content="add_requires(&quot;tbox >1.6.1&quot;, &quot;libuv master&quot;, &quot;vcpkg::ffmpeg&quot;, &quot;brew::pcre2/libpcre2-8&quot;)
add_requires(&quot;conan::openssl/1.1.1g&quot;, {alias = &quot;openssl&quot;, optional = true, debug = true})
target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)
    add_packages(&quot;tbox&quot;, &quot;libuv&quot;, &quot;vcpkg::ffmpeg&quot;, &quot;brew::pcre2/libpcre2-8&quot;, &quot;openssl&quot;)"><pre><span>add_requires</span>(<span><span>"</span>tbox &gt;1.6.1<span>"</span></span>, <span><span>"</span>libuv master<span>"</span></span>, <span><span>"</span>vcpkg::ffmpeg<span>"</span></span>, <span><span>"</span>brew::pcre2/libpcre2-8<span>"</span></span>)
<span>add_requires</span>(<span><span>"</span>conan::openssl/1.1.1g<span>"</span></span>, {<span>alias</span> <span>=</span> <span><span>"</span>openssl<span>"</span></span>, <span>optional</span> <span>=</span> <span>true</span>, <span>debug</span> <span>=</span> <span>true</span>})
<span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)
    <span>add_packages</span>(<span><span>"</span>tbox<span>"</span></span>, <span><span>"</span>libuv<span>"</span></span>, <span><span>"</span>vcpkg::ffmpeg<span>"</span></span>, <span><span>"</span>brew::pcre2/libpcre2-8<span>"</span></span>, <span><span>"</span>openssl<span>"</span></span>)</pre></div>
<p dir="auto">In addition, we can also use the <a href="https://github.com/xmake-io/xrepo">xrepo</a> command to quickly install dependencies.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Qt QuickApp Program</h3><a id="user-content-qt-quickapp-program" aria-label="Permalink: Qt QuickApp Program" href="#qt-quickapp-program"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;test&quot;)
    add_rules(&quot;qt.quickapp&quot;)
    add_files(&quot;src/*.cpp&quot;)
    add_files(&quot;src/qml.qrc&quot;)"><pre><span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>add_rules</span>(<span><span>"</span>qt.quickapp<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.cpp<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/qml.qrc<span>"</span></span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cuda Program</h3><a id="user-content-cuda-program" aria-label="Permalink: Cuda Program" href="#cuda-program"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.cu&quot;)
    add_cugencodes(&quot;native&quot;)
    add_cugencodes(&quot;compute_35&quot;)"><pre><span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.cu<span>"</span></span>)
    <span>add_cugencodes</span>(<span><span>"</span>native<span>"</span></span>)
    <span>add_cugencodes</span>(<span><span>"</span>compute_35<span>"</span></span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">WDK/UMDF Driver Program</h3><a id="user-content-wdkumdf-driver-program" aria-label="Permalink: WDK/UMDF Driver Program" href="#wdkumdf-driver-program"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;echo&quot;)
    add_rules(&quot;wdk.driver&quot;, &quot;wdk.env.umdf&quot;)
    add_files(&quot;driver/*.c&quot;)
    add_files(&quot;driver/*.inx&quot;)
    add_includedirs(&quot;exe&quot;)

target(&quot;app&quot;)
    add_rules(&quot;wdk.binary&quot;, &quot;wdk.env.umdf&quot;)
    add_files(&quot;exe/*.cpp&quot;)"><pre><span>target</span>(<span><span>"</span>echo<span>"</span></span>)
    <span>add_rules</span>(<span><span>"</span>wdk.driver<span>"</span></span>, <span><span>"</span>wdk.env.umdf<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>driver/*.c<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>driver/*.inx<span>"</span></span>)
    <span>add_includedirs</span>(<span><span>"</span>exe<span>"</span></span>)

<span>target</span>(<span><span>"</span>app<span>"</span></span>)
    <span>add_rules</span>(<span><span>"</span>wdk.binary<span>"</span></span>, <span><span>"</span>wdk.env.umdf<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>exe/*.cpp<span>"</span></span>)</pre></div>
<p dir="auto">For more WDK driver examples (UMDF/KMDF/WDM), please visit <a href="https://xmake.io/#/guide/project_examples?id=wdk-driver-program" rel="nofollow">WDK Program Examples</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Darwin Applications</h3><a id="user-content-darwin-applications" aria-label="Permalink: Darwin Applications" href="#darwin-applications"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;test&quot;)
    add_rules(&quot;xcode.application&quot;)
    add_files(&quot;src/*.m&quot;, &quot;src/**.storyboard&quot;, &quot;src/*.xcassets&quot;)
    add_files(&quot;src/Info.plist&quot;)"><pre><span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>add_rules</span>(<span><span>"</span>xcode.application<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.m<span>"</span></span>, <span><span>"</span>src/**.storyboard<span>"</span></span>, <span><span>"</span>src/*.xcassets<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/Info.plist<span>"</span></span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Framework and Bundle Program (Darwin)</h3><a id="user-content-framework-and-bundle-program-darwin" aria-label="Permalink: Framework and Bundle Program (Darwin)" href="#framework-and-bundle-program-darwin"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;test&quot;)
    add_rules(&quot;xcode.framework&quot;) -- or xcode.bundle
    add_files(&quot;src/*.m&quot;)
    add_files(&quot;src/Info.plist&quot;)"><pre><span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>add_rules</span>(<span><span>"</span>xcode.framework<span>"</span></span>) <span><span>--</span> or xcode.bundle</span>
    <span>add_files</span>(<span><span>"</span>src/*.m<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/Info.plist<span>"</span></span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">OpenMP Program</h3><a id="user-content-openmp-program" aria-label="Permalink: OpenMP Program" href="#openmp-program"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="add_requires(&quot;libomp&quot;, {optional = true})
target(&quot;loop&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.cpp&quot;)
    add_rules(&quot;c++.openmp&quot;)
    add_packages(&quot;libomp&quot;)"><pre><span>add_requires</span>(<span><span>"</span>libomp<span>"</span></span>, {<span>optional</span> <span>=</span> <span>true</span>})
<span>target</span>(<span><span>"</span>loop<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.cpp<span>"</span></span>)
    <span>add_rules</span>(<span><span>"</span>c++.openmp<span>"</span></span>)
    <span>add_packages</span>(<span><span>"</span>libomp<span>"</span></span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Zig Program</h3><a id="user-content-zig-program" aria-label="Permalink: Zig Program" href="#zig-program"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/main.zig&quot;)"><pre><span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/main.zig<span>"</span></span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatically fetch remote toolchain</h3><a id="user-content-automatically-fetch-remote-toolchain" aria-label="Permalink: Automatically fetch remote toolchain" href="#automatically-fetch-remote-toolchain"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">fetch a special version of LLVM</h4><a id="user-content-fetch-a-special-version-of-llvm" aria-label="Permalink: fetch a special version of LLVM" href="#fetch-a-special-version-of-llvm"></a></p>
<p dir="auto">Require the Clang version packaged with LLM-10 to compile a project.</p>
<div dir="auto" data-snippet-clipboard-copy-content="add_requires(&quot;llvm 10.x&quot;, {alias = &quot;llvm-10&quot;})
target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)
    set_toolchains(&quot;llvm@llvm-10&quot;)"><pre><span>add_requires</span>(<span><span>"</span>llvm 10.x<span>"</span></span>, {<span>alias</span> <span>=</span> <span><span>"</span>llvm-10<span>"</span></span>})
<span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)
    <span>set_toolchains</span>(<span><span>"</span>llvm@llvm-10<span>"</span></span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fetch a cross-compilation toolchain</h4><a id="user-content-fetch-a-cross-compilation-toolchain" aria-label="Permalink: Fetch a cross-compilation toolchain" href="#fetch-a-cross-compilation-toolchain"></a></p>
<p dir="auto">We can also pull a specified cross-compilation toolchain in to compile the project.</p>
<div dir="auto" data-snippet-clipboard-copy-content="add_requires(&quot;muslcc&quot;)
target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)
    set_toolchains(&quot;@muslcc&quot;)"><pre><span>add_requires</span>(<span><span>"</span>muslcc<span>"</span></span>)
<span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)
    <span>set_toolchains</span>(<span><span>"</span>@muslcc<span>"</span></span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fetch toolchain and packages</h4><a id="user-content-fetch-toolchain-and-packages" aria-label="Permalink: Fetch toolchain and packages" href="#fetch-toolchain-and-packages"></a></p>
<p dir="auto">We can also use the specified <code>muslcc</code> cross-compilation toolchain to compile and integrate all dependent packages.</p>
<div dir="auto" data-snippet-clipboard-copy-content="add_requires(&quot;muslcc&quot;)
add_requires(&quot;zlib&quot;, &quot;libogg&quot;, {system = false})

set_toolchains(&quot;@muslcc&quot;)

target(&quot;test&quot;)
    set_kind(&quot;binary&quot;)
    add_files(&quot;src/*.c&quot;)
    add_packages(&quot;zlib&quot;, &quot;libogg&quot;)"><pre><span>add_requires</span>(<span><span>"</span>muslcc<span>"</span></span>)
<span>add_requires</span>(<span><span>"</span>zlib<span>"</span></span>, <span><span>"</span>libogg<span>"</span></span>, {<span>system</span> <span>=</span> <span>false</span>})

<span>set_toolchains</span>(<span><span>"</span>@muslcc<span>"</span></span>)

<span>target</span>(<span><span>"</span>test<span>"</span></span>)
    <span>set_kind</span>(<span><span>"</span>binary<span>"</span></span>)
    <span>add_files</span>(<span><span>"</span>src/*.c<span>"</span></span>)
    <span>add_packages</span>(<span><span>"</span>zlib<span>"</span></span>, <span><span>"</span>libogg<span>"</span></span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Plugins</h2><a id="user-content-plugins" aria-label="Permalink: Plugins" href="#plugins"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Generate IDE project file plugin（makefile, vs2002 - vs2022 .. ）</h4><a id="user-content-generate-ide-project-file-pluginmakefile-vs2002---vs2022--" aria-label="Permalink: Generate IDE project file plugin（makefile, vs2002 - vs2022 .. ）" href="#generate-ide-project-file-pluginmakefile-vs2002---vs2022--"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xmake project -k vsxmake -m &quot;debug,release&quot; # New vsproj generator (Recommended)
$ xmake project -k vs -m &quot;debug,release&quot;
$ xmake project -k cmake
$ xmake project -k ninja
$ xmake project -k compile_commands"><pre>$ xmake project -k vsxmake -m <span><span>"</span>debug,release<span>"</span></span> <span><span>#</span> New vsproj generator (Recommended)</span>
$ xmake project -k vs -m <span><span>"</span>debug,release<span>"</span></span>
$ xmake project -k cmake
$ xmake project -k ninja
$ xmake project -k compile_commands</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Run a custom lua script plugin</h4><a id="user-content-run-a-custom-lua-script-plugin" aria-label="Permalink: Run a custom lua script plugin" href="#run-a-custom-lua-script-plugin"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xmake l ./test.lua
$ xmake l -c &quot;print('hello xmake!')&quot;
$ xmake l lib.detect.find_tool gcc
$ xmake l
> print(&quot;hello xmake!&quot;)
> {1, 2, 3}
< {
    1,
    2,
    3
  }"><pre>$ xmake l ./test.lua
$ xmake l -c <span><span>"</span>print('hello xmake!')<span>"</span></span>
$ xmake l lib.detect.find_tool gcc
$ xmake l
<span>&gt;</span> print(<span><span>"</span>hello xmake!<span>"</span></span>)
<span>&gt;</span> {1, 2, 3}
<span>&lt;</span> {
    1,
    2,
    3
  }</pre></div>
<p dir="auto">To see a list of bultin plugs, please visit <a href="https://xmake.io/#/plugin/builtin_plugins" rel="nofollow">Builtin plugins</a>.</p>
<p dir="auto">Please download and install other plugins from the plugins repository <a href="https://github.com/xmake-io/xmake-plugins">xmake-plugins</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">IDE/Editor Integration</h2><a id="user-content-ideeditor-integration" aria-label="Permalink: IDE/Editor Integration" href="#ideeditor-integration"></a></p>
<ul dir="auto">
<li><a href="https://github.com/xmake-io/xmake-vscode">xmake-vscode</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/xmake-io/xmake-vscode/master/res/problem.gif"><img src="https://raw.githubusercontent.com/xmake-io/xmake-vscode/master/res/problem.gif" width="650px" data-animated-image=""></a></p>
<ul dir="auto">
<li><a href="https://github.com/xmake-io/xmake-sublime">xmake-sublime</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/xmake-io/xmake-sublime/master/res/problem.gif"><img src="https://raw.githubusercontent.com/xmake-io/xmake-sublime/master/res/problem.gif" width="650px" data-animated-image=""></a></p>
<ul dir="auto">
<li><a href="https://github.com/xmake-io/xmake-idea">xmake-idea</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/xmake-io/xmake-idea/master/res/problem.gif"><img src="https://raw.githubusercontent.com/xmake-io/xmake-idea/master/res/problem.gif" width="650px" data-animated-image=""></a></p>
<ul dir="auto">
<li><a href="https://github.com/luzhlon/xmake.vim">xmake.vim</a> (third-party, thanks <a href="https://github.com/luzhlon">@luzhlon</a>)</li>
<li><a href="https://github.com/HelloWorld886/xmake-visualstudio">xmake-visualstudio</a> (third-party, thanks <a href="https://github.com/HelloWorld886">@HelloWorld886</a>)</li>
<li><a href="https://github.com/Arthapz/xmake-project-manager">xmake-qtcreator</a> (third-party, thanks <a href="https://github.com/Arthapz">@Arthapz</a>)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Xmake Gradle Plugin (JNI)</h3><a id="user-content-xmake-gradle-plugin-jni" aria-label="Permalink: Xmake Gradle Plugin (JNI)" href="#xmake-gradle-plugin-jni"></a></p>
<p dir="auto">We can use the <a href="https://github.com/xmake-io/xmake-gradle">xmake-gradle</a> plugin to compile JNI libraries via gradle.</p>
<div data-snippet-clipboard-copy-content="plugins {
  id 'org.tboox.gradle-xmake-plugin' version '1.1.5'
}

android {
    externalNativeBuild {
        xmake {
            path &quot;jni/xmake.lua&quot;
        }
    }
}"><pre><code>plugins {
  id 'org.tboox.gradle-xmake-plugin' version '1.1.5'
}

android {
    externalNativeBuild {
        xmake {
            path "jni/xmake.lua"
        }
    }
}
</code></pre></div>
<p dir="auto">The <code>xmakeBuild</code> task will be injected into the <code>assemble</code> task automatically if the <code>gradle-xmake-plugin</code> has been applied.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ./gradlew app:assembleDebug
> Task :nativelib:xmakeConfigureForArm64
> Task :nativelib:xmakeBuildForArm64
>> xmake build
[ 50%]: cache compiling.debug nativelib.cc
[ 75%]: linking.debug libnativelib.so
[100%]: build ok!
>> install artifacts to /Users/ruki/projects/personal/xmake-gradle/nativelib/libs/arm64-v8a
> Task :nativelib:xmakeConfigureForArmv7
> Task :nativelib:xmakeBuildForArmv7
>> xmake build
[ 50%]: cache compiling.debug nativelib.cc
[ 75%]: linking.debug libnativelib.so
[100%]: build ok!
>> install artifacts to /Users/ruki/projects/personal/xmake-gradle/nativelib/libs/armeabi-v7a
> Task :nativelib:preBuild
> Task :nativelib:assemble
> Task :app:assembleDebug"><pre>$ <span>./gradlew app:assembleDebug</span>
&gt; <span>Task :nativelib:xmakeConfigureForArm64</span>
&gt; <span>Task :nativelib:xmakeBuildForArm64</span>
<span>&gt;&gt; xmake build</span>
<span>[ 50%]: cache compiling.debug nativelib.cc</span>
<span>[ 75%]: linking.debug libnativelib.so</span>
<span>[100%]: build ok!</span>
<span>&gt;&gt; install artifacts to /Users/ruki/projects/personal/xmake-gradle/nativelib/libs/arm64-v8a</span>
&gt; <span>Task :nativelib:xmakeConfigureForArmv7</span>
&gt; <span>Task :nativelib:xmakeBuildForArmv7</span>
<span>&gt;&gt; xmake build</span>
<span>[ 50%]: cache compiling.debug nativelib.cc</span>
<span>[ 75%]: linking.debug libnativelib.so</span>
<span>[100%]: build ok!</span>
<span>&gt;&gt; install artifacts to /Users/ruki/projects/personal/xmake-gradle/nativelib/libs/armeabi-v7a</span>
&gt; <span>Task :nativelib:preBuild</span>
&gt; <span>Task :nativelib:assemble</span>
&gt; <span>Task :app:assembleDebug</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">CI Integration</h2><a id="user-content-ci-integration" aria-label="Permalink: CI Integration" href="#ci-integration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">GitHub Action</h3><a id="user-content-github-action" aria-label="Permalink: GitHub Action" href="#github-action"></a></p>
<p dir="auto">The <a href="https://github.com/xmake-io/github-action-setup-xmake">github-action-setup-xmake</a> plugin for GitHub Actions can allow you to use Xmake with minimal efforts if you use GitHub Actions for your CI pipeline.</p>
<div dir="auto" data-snippet-clipboard-copy-content="uses: xmake-io/github-action-setup-xmake@v1
with:
  xmake-version: latest"><pre><span>uses</span>: <span>xmake-io/github-action-setup-xmake@v1</span>
<span>with</span>:
  <span>xmake-version</span>: <span>latest</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Who is using Xmake?</h2><a id="user-content-who-is-using-xmake" aria-label="Permalink: Who is using Xmake?" href="#who-is-using-xmake"></a></p>
<p dir="auto">The list of people and projects who are using Xmake is available <a href="https://xmake.io/#/about/who_is_using_xmake" rel="nofollow">here</a>.</p>
<p dir="auto">If you are using Xmake, you are welcome to submit your information to the above list through a PR, so that other users and the developers can gauge interest.  Ihis also let users to use xmake more confidently and give us motivation to continue to maintain it.</p>
<p dir="auto">This will help the Xmake project and it's community grow stronger and expand!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contacts</h2><a id="user-content-contacts" aria-label="Permalink: Contacts" href="#contacts"></a></p>
<ul dir="auto">
<li>Email：<a href="mailto:waruqi@gmail.com">waruqi@gmail.com</a></li>
<li>Homepage：<a href="https://xmake.io/" rel="nofollow">xmake.io</a></li>
<li>Community
<ul dir="auto">
<li><a href="https://www.reddit.com/r/xmake/" rel="nofollow">Chat on Reddit</a></li>
<li><a href="https://t.me/tbooxorg" rel="nofollow">Chat on Telegram</a></li>
<li><a href="https://discord.gg/xmake" rel="nofollow">Chat on Discord</a></li>
<li>Chat on QQ Group: 343118190, 662147501</li>
</ul>
</li>
<li>Source Code：<a href="https://github.com/xmake-io/xmake">GitHub</a>, <a href="https://gitee.com/tboox/xmake" rel="nofollow">Gitee</a></li>
<li>WeChat Public: tboox-os</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Thanks</h2><a id="user-content-thanks" aria-label="Permalink: Thanks" href="#thanks"></a></p>
<p dir="auto">This project exists thanks to all the people who have <a href="https://github.com/xmake-io/xmake/blob/master/CONTRIBUTING.md">contributed</a>:
<a href="https://github.com/xmake-io/xmake/graphs/contributors"><img src="https://camo.githubusercontent.com/f248341cf67a76a86c67f48ebca8dc24ef26c9ca9d2b91f3e693af2f68a09a84/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f786d616b652f636f6e7472696275746f72732e7376673f77696474683d38393026627574746f6e3d66616c7365" data-canonical-src="https://opencollective.com/xmake/contributors.svg?width=890&amp;button=false"></a></p>
<ul dir="auto">
<li><a href="https://github.com/TitanSnow">TitanSnow</a>: Provide the xmake <a href="https://github.com/TitanSnow/ts-xmake-logo">logo</a> and install scripts</li>
<li><a href="https://github.com/uael">uael</a>: Provide the semantic versioning library <a href="https://github.com/uael/sv">sv</a></li>
<li><a href="https://github.com/OpportunityLiu">OpportunityLiu</a>: Improve cuda, tests and ci</li>
<li><a href="https://github.com/xq114">xq144</a>: Improve <code>xrepo env shell</code>, and contribute a lot of packages to the <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a> repository.</li>
<li><code>enderger</code>: Helped smooth out the edges on the English translation of the README</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Time-Based CSS Animations (189 pts)]]></title>
            <link>https://yuanchuan.dev/time-based-css-animations</link>
            <guid>40262236</guid>
            <pubDate>Sun, 05 May 2024 04:26:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yuanchuan.dev/time-based-css-animations">https://yuanchuan.dev/time-based-css-animations</a>, See on <a href="https://news.ycombinator.com/item?id=40262236">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
  <p>
    In my earlier post <a href="https://yuanchuan.dev/time-uniform-for-css-animation">Time Uniform For CSS Animation</a>,
    I took a note about a way to do CSS animations with <em>time ticks</em> instead of <em>keyframes</em>.
    It was limited applicable because CSS lacked the ability of doing complex Math calculations.
  </p>
  <p>
    After years of wait, CSS now has enough Math functions supported,
    particularly <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/mod">mod()</a>, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/round">round()</a>,
    and <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Functions#trigonometric_functions">trigonometric functions</a>.
    It's time to revisit the time-based way of animation, hope it'll be more useful this time.
  </p>

  <!--more-->

  <p>
    You may need to enable the <em>Experimental feature flags</em> to view demos in this page.
  </p>

  <h2>The basic idea</h2>

  <p>
    Using <em>time</em> for animation is very common in shader programs and various other places.
    CSS can not start a timer like JavaScript does,
    but nowadays it's possible to define a custom variable
    with the <a href="https://developer.mozilla.org/en-US/docs/Web/API/CSS_Properties_and_Values_API/guide">CSS Houdini API</a> to track <em>time</em> in milliseconds.
  </p>

<figure><pre><code data-lang="css"><span>@property</span> <span>--t</span> <span>{</span>
  <span>syntax</span><span>:</span> <span>"&lt;integer&gt;"</span><span>;</span>
  <span>initial-value</span><span>:</span> <span>0</span><span>;</span>
  <span>inherits</span><span>:</span> <span>true</span>
<span>}</span>
<span>@keyframes</span> <span>tick</span> <span>{</span>
  <span>from</span> <span>{</span> <span>--t</span><span>:</span> <span>0</span> <span>}</span>
  <span>to</span>   <span>{</span> <span>--t</span><span>:</span> <span>86400000</span> <span>}</span>
<span>}</span>
<span>:root</span> <span>{</span>
  <span>animation</span><span>:</span> <span>tick</span> <span>86400000ms</span> <span>linear</span> <span>infinite</span>
<span>}</span></code></pre></figure>
  <p>
    For each millisecond, the variable <code>--t</code> increments by <code>1</code>, which is <code>1000</code> in one second.
    There's a trick to show the variable with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/counter">counter()</a> function.
  </p>

<figure><pre><code data-lang="css"><span>::after</span> <span>{</span>
  <span>counter-reset</span><span>:</span> <span>t</span> <span>var</span><span>(</span><span>--t</span><span>);</span>
  <span>content</span><span>:</span> <span>counter</span><span>(</span><span>t</span><span>);</span>
<span>}</span></code></pre></figure>

  

  <p>
    Other values which are based on <code>--t</code> will change along with it.
    That's how we get the <strong>animation</strong> effect.
  </p>

<figure><pre><code data-lang="css"><span>div</span> <span>{</span>
  <span>/* 1 turn per second */</span>
  <span>rotate</span><span>:</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--t</span><span>)</span> <span>*</span> <span>.001turn</span><span>);</span>
<span>}</span></code></pre></figure>
  

  <h2>Controlling frame rate</h2>

  <p>
    Maintaining the update frequencey at 60 frames per second (FPS) is sufficient for a smooth animation.
    Browsers often have optimizations for rendering so there wouldn't be any problem if the frequencey is higher than 60 FPS.
    But one can manually control the frame rate using <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/animation-timing-function#stepsn_jumpterm">step()</a>
    function if needed.
  </p>
<figure><pre><code data-lang="css"><span>/* ... */</span>

<span>:root</span> <span>{</span>
  <span>animation</span><span>:</span> <span>tick</span><span>;</span>
  <span>animation-duration</span><span>:</span> <span>86400000ms</span><span>;</span>
  <span>animation-iteration-count</span><span>:</span> <span>infinite</span><span>;</span>

  <span>/* 8 fps */</span>
  <span>animation-timing-function</span><span>:</span> <span>step</span><span>(</span><span>calc</span><span>(</span><span>86400000</span><span>/(</span><span>1000</span><span>/</span><span>8</span><span>)));</span>

  <span>/* 24 fps */</span>
  <span>animation-timing-function</span><span>:</span> <span>step</span><span>(</span><span>calc</span><span>(</span><span>86400000</span><span>/(</span><span>1000</span><span>/</span><span>24</span><span>)));</span>

  <span>/* 60 fps */</span>
  <span>animation-timing-function</span><span>:</span> <span>step</span><span>(</span><span>calc</span><span>(</span><span>86400000</span><span>/(</span><span>1000</span><span>/</span><span>60</span><span>)));</span>
<span>}</span></code></pre></figure>

  

  <h2>Transform time</h2>

  <p>
    The value of <code>--t</code> grows constantly in one direction.
    It's all right for the <code>angle</code> value that is bigger than <code>360deg</code>,
    however, not all CSS properties treat their values as cyclical.
  </p>
  <p>
    Let's say I want to animate a box from left to right,
    if the translate offset is associated to the <code>--t</code>
    it will increase constantly without stop.
  </p>

<figure><pre><code data-lang="css"><span>translate</span><span>:</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--t</span><span>)</span> <span>*</span> <span>.</span><span>001</span><span>px</span><span>);</span></code></pre></figure>

  <h3>min()</h3>
  <p>
    One expected result is that when the offset reaches at a specific value, it stops immediately.
    This is how <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/min">min()</a> function can be useful.
  </p>
<figure><pre><code data-lang="css"><span>translate</span><span>:</span> <span>min</span><span>(</span><span>270</span><span>px</span><span>,</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--t</span><span>)</span> <span>*</span> <span>.</span><span>5</span><span>px</span><span>));</span></code></pre></figure>

  

  <p>
    To precisely control the animation duration we can restrict the value of <code>--t</code> instead.
  </p>
<figure><pre><code data-lang="css"><span>/* 270px in 3s */</span>
<span>translate</span><span>:</span> <span>calc</span><span>(</span><span>min</span><span>(</span><span>3000</span><span>,</span> <span>var</span><span>(</span><span>--t</span><span>))</span> <span>*</span> <span>(</span><span>270</span><span>px</span> <span>/</span> <span>3000</span><span>));</span></code></pre></figure>

  

  <h3>mod()</h3>

  <p>
    After the box has moved to the right, another option is to restart the offset from beginning.
    Now we have <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/mod">mod()</a> function to achieve this.
  </p>

<figure><pre><code data-lang="css"><span>translate</span><span>:</span> <span>calc</span><span>(</span><span>mod</span><span>(</span><span>var</span><span>(</span><span>--t</span><span>)/</span><span>4</span><span>,</span> <span>270</span><span>)</span> <span>*</span> <span>1</span><span>px</span><span>);</span></code></pre></figure>

  

  <h3>sin()</h3>

  <p>
    Or to make the movement back and forth.
  </p>

<figure><pre><code data-lang="css"><span>translate</span><span>:</span> <span>calc</span><span>(</span><span>sin</span><span>(</span><span>mod</span><span>(</span><span>var</span><span>(</span><span>--t</span><span>)/</span><span>135</span><span>,</span> <span>270</span><span>))</span> <span>*</span> <span>135</span><span>px</span><span>);</span></code></pre></figure>

  

  <h2>
    Custom easing function
  </h2>

  <p>
    We can create custom easing functions using Math functions and the <code>--t</code> variable,
    which might not be achievable with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/easing-function#cubic_b%C3%A9zier_easing_function">cubic-bezier()</a>.
  </p>

  <h3>ease-out-cubic</h3>

  <p>
    The initial step is to bound the value <code>--t</code> between <em>0</em> and <em>1</em>.
  </p>

<figure><pre><code data-lang="css"><span>/* from 0 to 1 in 1s */</span>
<span>--t01</span><span>:</span> <span>calc</span><span>(</span><span>min</span><span>(</span><span>1000</span><span>,</span> <span>var</span><span>(</span><span>--t</span><span>))</span> <span>/</span> <span>1000</span><span>);</span>

<span>/* 1 - pow(1 - t, 3) */</span>
<span>--ease-out-cubic</span><span>:</span> <span>calc</span><span>(</span>
  <span>1</span> <span>-</span> <span>pow</span><span>(</span><span>1</span> <span>-</span> <span>var</span><span>(</span><span>--t01</span><span>),</span> <span>3</span><span>)</span>
<span>);</span>

<span>translate</span><span>:</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--ease-out-cubic</span><span>)</span> <span>*</span> <span>270</span><span>px</span><span>);</span></code></pre></figure>

  

  <h3>ease-out-elastic</h3>

<figure><pre><code data-lang="css"><span>/* from 0 to 1 in 1s */</span>
<span>--t01</span><span>:</span> <span>calc</span><span>(</span><span>min</span><span>(</span><span>1000</span><span>,</span> <span>var</span><span>(</span><span>--t</span><span>))</span> <span>/</span> <span>1000</span><span>);</span>

<span>/* pow(2, -10t) * sin((10t - .75) * 2/3 * PI) + 1 */</span>
<span>--ease-out-elastic</span><span>:</span> <span>calc</span><span>(</span>
  <span>pow</span><span>(</span><span>2</span><span>,</span> <span>-10</span> <span>*</span> <span>var</span><span>(</span><span>--t01</span><span>))</span> <span>*</span>
  <span>sin</span><span>((</span><span>var</span><span>(</span><span>--t01</span><span>)</span> <span>*</span> <span>10</span> <span>-</span> <span>.</span><span>75</span><span>)</span> <span>*</span> <span>2</span><span>/</span><span>3</span> <span>*</span> <span>PI</span><span>)</span> <span>+</span> <span>1</span>
<span>);</span>

<span>translate</span><span>:</span> <span>calc</span><span>(</span><span>var</span><span>(</span><span>--ease-out-elastic</span><span>)</span> <span>*</span> <span>270</span><span>px</span><span>);</span></code></pre></figure>

  

  <h2>Experiment with CSS Doodle</h2>

  <p>
    As the expressions get complex, <code>var()</code> and <code>calc()</code> tend to make
    the code less readable. So I've added the <code>@t</code> function for representing variable <code>--t</code>.
    The latest version of <a href="https://css-doodle.com/">css-doodle</a> also accepts simple Math expressions directly inside arguments.
  </p>

<figure><pre><code data-lang="css"><span>/* rotate: calc(mod(var(--t) / 1000, 10) * 5deg); */</span>
<span>rotate</span><span>:</span> <span>@t</span><span>(/</span><span>1000</span><span>,</span> <span>%</span><span>10</span><span>,</span> <span>*</span><span>5deg</span><span>);</span></code></pre></figure>

  <p>
    Code is short without writing <em>keyframes</em>.
  </p>

<figure><pre><code data-lang="css"><span>@grid</span><span>:</span> <span>20</span><span>x1</span> <span>/</span> <span>280</span><span>x</span> <span>60px</span><span>;</span>
<span>@gap</span><span>:</span> <span>1px</span><span>;</span>
<span>@size</span><span>:</span> <span>100%</span> <span>20%</span><span>;</span>
<span>background</span><span>:</span> <span>#000</span><span>;</span>
<span>margin</span><span>:</span> <span>auto</span><span>;</span>
<span>translate</span><span>:</span> <span>0</span> <span>calc</span><span>(</span><span>20</span><span>px</span> <span>*</span> <span>sin</span><span>(</span><span>4</span><span>*</span><span>@t</span><span>(/</span><span>20</span><span>,</span> <span>+@</span><span>i</span><span>(</span><span>*</span><span>6</span><span>),</span> <span>%</span><span>360deg</span><span>)));</span></code></pre></figure>

  

  <p>
    And it's quick to experiment new parameters too.
  </p>

<figure><pre><code data-lang="css"><span>translate</span><span>:</span> <span>0</span> <span>calc</span><span>(</span><span>20</span><span>px</span> <span>*</span> <span>sin</span><span>(</span><span>3</span><span>*</span><span>@t</span><span>(/</span><span>50</span><span>,</span> <span>*@</span><span>i</span><span>(</span><span>*</span><span>2</span><span>),</span> <span>%</span><span>360deg</span><span>)));</span></code></pre></figure>

  

  <h3>Function @T and @TS</h3>
  <p>
    In addition to the <code>@t</code> function,
    the uppercase function <code>@T</code> represents another <em>time ticks</em> from beginning of the day.
    Function <code>@TS</code> is a shorthand for <code>@t(/1000)</code>, which tracks <code>time</code> in second.
  </p>

  <p>
    Here is a clock implemented in css-doodle. (<a href="https://codepen.io/yuanchuan/pen/RwOXrwM">CodePen link</a>)
  </p>

<figure><pre><code data-lang="css"><span>/* ... */</span>

<span>/* second */</span>
<span>rotate</span><span>:</span> <span>@TS</span><span>(</span><span>*</span><span>6</span><span>,</span> <span>%</span><span>360deg</span><span>);</span>

<span>/* minute */</span>
<span>rotate</span><span>:</span> <span>@TS</span><span>(/</span><span>60</span><span>,</span> <span>*</span><span>6</span><span>,</span> <span>%</span><span>360deg</span><span>);</span>

<span>/* hour */</span>
<span>rotate</span><span>:</span> <span>@TS</span><span>(/</span><span>60</span><span>,</span> <span>/</span><span>12</span><span>,</span> <span>*</span><span>6</span><span>,</span> <span>%</span><span>360deg</span><span>);</span></code></pre></figure>

  

  <h3>round()</h3>
  <p>
    How can we make a jumping motion for the second hand?
    Of course, the direct approach is to use <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/round">round()</a> function,
    where the third parameter specifies the rounding interval.
		In the context of a clock, each step equals <code>360 / 60 = 6deg</code>.
  </p>
<figure><pre><code data-lang="css"><span>rotate</span><span>:</span> <span>round</span><span>(</span><span>down</span><span>,</span> <span>@TS</span><span>(</span><span>*</span><span>6</span><span>,</span> <span>%</span><span>360deg</span><span>),</span> <span>6deg</span><span>);</span></code></pre></figure>

  

  <h3>One more example</h3>
  <p>
    Animate colors and positions together.
    (<a href="https://codepen.io/yuanchuan/full/LYvwGjQ">CodePen link</a>).
  </p>

<figure><pre><code data-lang="css"><span>@grid</span><span>:</span> <span>100</span><span>x1</span> <span>/</span> <span>100%</span> <span>auto</span> <span>(</span><span>4</span><span>/</span><span>3</span><span>)</span> <span>/</span> <span>#10153e</span><span>;</span>
<span>@size</span><span>:</span> <span>@</span><span>rn</span><span>(</span><span>1vmin</span><span>,</span> <span>5vmin</span><span>,</span> <span>10</span><span>);</span>
<span>margin</span><span>:</span> <span>auto</span><span>;</span>
<span>border-radius</span><span>:</span> <span>50</span><span>%;</span>

<span>background</span><span>:</span> <span>@p</span><span>(</span>
  <span>hsl</span><span>(</span><span>@</span><span>t</span><span>(/</span><span>10</span><span>,</span> <span>+@</span><span>i</span><span>(</span><span>*</span><span>2</span><span>),</span> <span>%</span><span>360</span><span>),</span> <span>90%</span><span>,</span> <span>80%</span><span>)</span>
<span>);</span>
<span>box-shadow</span><span>:</span> <span>@m5</span><span>(</span>
  <span>@</span><span>r</span><span>(</span><span>±</span><span>23vmin</span><span>)</span> <span>@</span><span>r</span><span>(</span><span>±</span><span>23vmin</span><span>)</span> <span>@</span><span>r</span><span>(</span><span>2vmin</span><span>)</span> <span>@</span><span>r</span><span>(</span><span>-40px</span><span>)</span> <span>@</span><span>p</span>
<span>);</span>
<span>translate</span><span>:</span> <span>@M2</span><span>(</span>
  <span>calc</span><span>(</span><span>100px</span> <span>*</span> <span>tan</span><span>(</span><span>6</span><span>*</span><span>cos</span><span>(</span><span>@</span><span>t</span><span>(/</span><span>10</span><span>,</span> <span>+@</span><span>i</span><span>(</span><span>*</span><span>10</span><span>),</span> <span>/</span><span>6</span><span>,</span> <span>%</span><span>360deg</span><span>))))</span>
<span>);</span></code></pre></figure>

  

	<h2>Conclusion</h2>

	<p>
    I'm excited about this approach.
    Although using <em>keyframes</em> seems much straightforward,
    for a demo scene full of math calculations and input variables,
    using <em>time</em> as a variable is more likely to get diverse results.
  </p>

</article>








  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge mulls sanctions over Google's "shocking" destruction of internal chats (194 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/05/judge-mulls-sanctions-over-googles-shocking-destruction-of-internal-chats/</link>
            <guid>40262190</guid>
            <pubDate>Sun, 05 May 2024 04:13:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/05/judge-mulls-sanctions-over-googles-shocking-destruction-of-internal-chats/">https://arstechnica.com/tech-policy/2024/05/judge-mulls-sanctions-over-googles-shocking-destruction-of-internal-chats/</a>, See on <a href="https://news.ycombinator.com/item?id=40262190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1678321753-800x534.jpg" alt="Kenneth Dintzer, litigator for the US Department of Justice, exits federal court in Washington, DC, on September 20, 2023, during the antitrust trial to determine if Alphabet Inc.'s Google maintains a monopoly in the online search business.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1678321753.jpg" data-height="683" data-width="1024">Enlarge</a> <span>/</span> Kenneth Dintzer, litigator for the US Department of Justice, exits federal court in Washington, DC, on September 20, 2023, during the antitrust trial to determine if Alphabet Inc.'s Google maintains a monopoly in the online search business.</p></figcaption>  </figure>

  




<!-- cache hit 1:single/related:271d4f50fe584ab50db26d68075dd6a5 --><!-- empty -->
<p>Near the end of the second day of closing arguments in the Google monopoly trial, US district judge Amit Mehta weighed whether sanctions were warranted over what the US Department of Justice described as Google's "routine, regular, and normal destruction" of evidence.</p>
<p>Google was accused of enacting a policy instructing employees to turn chat history off by default when discussing sensitive topics, including Google's revenue-sharing and mobile application distribution agreements. These agreements, the DOJ and state attorneys general argued, work to maintain Google's monopoly over search.</p>
<p>According to the DOJ, Google <a href="https://arstechnica.com/tech-policy/2023/02/us-says-google-routinely-destroyed-evidence-and-lied-about-use-of-auto-delete/">destroyed potentially hundreds of thousands of chat sessions</a> not just during their investigation but also during litigation. Google only stopped the practice after the DOJ discovered the policy. DOJ's attorney Kenneth Dintzer told Mehta Friday that the DOJ believed the court should "conclude that communicating with history off shows anti-competitive intent to hide information because they knew they were violating antitrust law."</p>
<p>Mehta at least agreed that "Google's document retention policy leaves a lot to be desired," expressing shock and surprise that a large company like Google would ever enact such a policy as best practice.</p>
<p>Google's attorney Colette Connor told Mehta that the DOJ should have been aware of Google's policy long before the DOJ challenged the conduct. Google had explicitly disclosed the policy to Texas' attorney general, who was involved in DOJ's antitrust suit over both Google's search and adtech businesses, Connor said.</p>
<p>Connor also argued that Google's conduct wasn't sanctionable because there is no evidence that any of the missing chats would've shed any new light on the case. Mehta challenged this somewhat, telling Connor, "We just want to know what we don't know. We don't know if there was a treasure trove of material that was destroyed."</p>                                            
                                                        
<p>During rebuttal, Dintzer told Mehta that Google's decision to tell Texas about the policy but not the federal government did not satisfy their disclosure obligation under federal rules of civil procedure in the case. That <a href="https://www.law.cornell.edu/rules/frcp/rule_37">rule</a> says that "only upon finding that the party acted with the intent to deprive another party of the information’s use in the litigation may" the court "presume that the lost information was unfavorable to the party."</p>
<p>The DOJ has asked the court to make that ruling and issue four orders sanctioning Google. They want the court to order the "presumption that deleted chats were unfavorable," the "presumption that Google's proffered justification" for deleting chats "is pretextual" (concealing Google's true rationale), and the "presumption that Google intended" to delete chats to "maintain its monopoly." The government also wants a "prohibition on argument by Google that the absence of evidence is evidence of adverse inference," which would stop Google from arguing that the DOJ is just assuming the deleted chats are unfavorable to Google.</p>
<p>Mehta asked Connor if she would agree that, at "minimum," it was "negligent" of Google to leave it to employees to preserve chats on sensitive discussions, but Connor disagreed. She argued that "given the typical use of chat," Google's history-off policy was "reasonable."</p>
<p>Connor told Mehta that the DOJ must prove that Google intended to hide evidence for the court to order sanctions.</p>
<p>That intent could be demonstrated another way, Mehta suggested, recalling that "Google has been very deliberate in <a href="https://arstechnica.com/tech-policy/2023/09/google-hid-evidence-by-training-workers-to-avoid-words-monopolists-use-doj-says/">advising employees about what to say and what not to say</a>" in discussions that could indicate monopolistic behaviors. That included telling employees, "Don't use the term markets," Mehta told Connor, asking if that kind of conduct could be interpreted as Google's intent to hide evidence.</p>
<p>But Connor disagreed again.</p>
<p>"No, we don't think you can use it as evidence," Connor said. "It's not relevant to the claims in this case."</p>
<p>But during rebuttal, Dintzer argued that there was evidence of its relevance. He said that testimony from Google employees showed that Google's chat policy "was uniformly used as a way of communicating without creating discoverable information" intentionally to hide the alleged antitrust violations.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SEQUOIA: Exact Llama2-70B on an RTX4090 with half-second per-token latency (120 pts)]]></title>
            <link>https://infini-ai-lab.github.io/Sequoia-Page/</link>
            <guid>40261965</guid>
            <pubDate>Sun, 05 May 2024 03:03:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infini-ai-lab.github.io/Sequoia-Page/">https://infini-ai-lab.github.io/Sequoia-Page/</a>, See on <a href="https://news.ycombinator.com/item?id=40261965">Hacker News</a></p>
<div id="readability-page-1" class="page">


  <div>
            <h2><i>SEQUOIA</i>: Serving exact Llama2-70B on an RTX4090 <br>with half-second per token latency</h2>
            
                  <p><span><small><sup>1</sup>Carnegie Mellon University <sup>2</sup>Together AI <sup>3</sup>Yandex <sup>4</sup>Meta AI</small></span>
                    <span><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </p>

                  
          </div>


<!-- Paper abstract -->
<div>
        <h2>Introduction</h2>
        <p>
            We introduce <i>Sequoia</i>, a scalable, robust and hardware-aware speculative decoding framework that enables serving LLMs (70B, 33B...) with a reasonable latency on consumer GPUs without any approximation (using <b>16bit</b> precision and maintaining the original output distribution). Addressing the problems of robustness and scalability of previous works on speculative decoding, we show below that <i>Sequoia</i>, with a large speculation budget, can serve a <b>Llama2-70B</b> on a single <b>RTX-4090</b> with an average time between tokens (TBT) as low as <b>0.57s</b>, which is <b>8X</b> faster than
            a highly optimized offloading serving system, <b>9X</b> faster than DeepSpeed-Zero Offloading. On a single <b>2080Ti</b> GPU (only 11GB memory), <b>Vicuna-33B</b> can be served with a TBT of <b>0.87s</b>.
          </p>
      </div>
<!-- End paper abstract -->
  
<!-- Solutions -->
<div>
        <h2>Serving Solutions by <i>Sequoia</i></h2>
        <div>
           <table>
  <tbody><tr>
    <th scope="col">GPU</th>
    <th>Bandwidth(GB/s)</th>
    <th>Target Model</th>
    <th>Draft Model</th>
    <th>TBT(s)</th>
    <th>Baseline(s)</th>
  </tr>
<!--   <tr>
    <th>A5000</th>
    <td>31.5</td>
    <td>Llama2-70B</td>
    <td><a style="color: skyblue" href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf">Llama2-7B</a></td>
    <td>0.58</td>
    <td>4.59</td>
  </tr>
<tr>
<th>A5000</th>
    <td>31.5</td>
    <td>InternLM-20B</td>
    <td><a style="color: skyblue" href="https://huggingface.co/chargoddard/internlm2-7b-llama">InternLM-7B</a></td>
    <td>0.19</td>
    <td>0.82</td>
  </tr> -->
<tr>
    <th>4090</th>
    <td>31.5</td>
    <td>Llama2-70B</td>
    <td><a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf">Llama2-7B</a></td>
    <td>0.57</td>
    <td>4.54</td>
</tr>
<tr>
    <th>4090</th>
    <td>31.5</td>
    <td>Vicuna-33B</td>
    <td><a href="https://huggingface.co/Jiayi-Pan/Tiny-Vicuna-1B">TinyVicuna-1B</a></td>
    <td>0.35</td>
    <td>1.78</td>
</tr>          
<tr>
    <th>4090</th>
    <td>31.5</td>
    <td>Llama2-22B</td>
    <td><a href="https://infini-ai-lab.github.io/Sequoia-Page/TinyLlama/TinyLlama-1.1B-Chat-v1.0">TinyLlama-1.1B</a></td>
    <td>0.17</td>
    <td>0.95</td>
</tr>
<tr>
    <th>4090</th>
    <td>31.5</td>
    <td>InternLM-20B</td>
    <td><a href="https://huggingface.co/chargoddard/internlm2-7b-llama">InternLM-7B</a></td>
    <td>0.17</td>
    <td>0.77</td>
</tr>
<tr>
    <th>4090</th>
    <td>31.5</td>
    <td>Llama2-13B</td>
    <td>TinyLlama-1.1B</td>
    <td>0.09</td>
    <td>0.27</td>
</tr>    
<tr>
    <th>2080Ti</th>
    <td>15.8</td>
    <td>Vicuna-33B</td>
    <td>TinyVicuna-1B</td>
    <td>0.87</td>
    <td>4.81</td>
</tr>

<tr>
    <th>2080Ti</th>
    <td>15.8</td>
    <td>Llama2-22B</td>
    <td>TinyLlama-1.1B</td>
    <td>0.53</td>
    <td>3.04</td>
</tr>
<tr>
    <th>2080Ti</th>
    <td>15.8</td>
    <td>Llama2-13B</td>
    <td>TinyLlama-1.1B</td>
    <td>0.34</td>
    <td>1.53</td>
</tr>
</tbody></table>
          <p>
            <i>Sequoia</i> can speed up LLM inference for a variety of model sizes and types of hardware. We evaluate <i>Sequoia</i> with LLMs of various sizes (including 
            <a href="https://huggingface.co/meta-llama/Llama-2-70b-chat-hf">Llama2-70B-chat</a>, <a href="https://huggingface.co/lmsys/vicuna-33b-v1.3">Vicuna-33B</a>,
            <a href="https://huggingface.co/nkpz/llama2-22b-daydreamer-v3">Llama2-22B</a>, <a href="https://huggingface.co/chargoddard/internlm2-20b-llama">InternLM-20B</a> and 
            <a href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf">Llama2-13B-chat</a>), on 4090 and 2080Ti, prompted by <a href="https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/data/mt_bench/question.jsonl">MT-Bench</a>. 
            The hardware platforms have different GPUs, CPU RAMs and CPU-GPU bandwidth. The evaluation results are listed above.
          </p>
          
  
<p>
Here we show a demo for Llama2-70B inference on a single RTX-4090 (with and without <i>Sequoia</i>. Video plays at 4X speed).  
</p>
 
        </div>
      </div>
<!-- End Solutions -->
  
<!-- Why -->
<div>
        <h2>Why <i>Sequoia</i></h2>
        <p>
           Benefiting from two key advantages, <i>Sequoia</i> significantly accelerates LLM serving with offloading. Firstly, <i>Sequoia</i> is more <b>scalable</b> with a large speculation budget. For a given draft / target model pairs, <i>Sequoia</i> leverages a dynamic 
           programming algorithm to search for the optimal tree structure, which enables a much faster growth in terms of accepted tokens with a certain budget (i.e. the size of the speculation tree). Secondly, thanks to sampling without replacement algorithm, <i>Sequoia</i>
           is <b>robust</b> in terms of generating temperatures, compared to top-k sampling and sampling with replacement.
           Apart from offloading, <i>Sequoia</i> provides a hardware-aware solution to adjust the size and depth of speculation trees to adapt to different hardware platforms. <i>Sequoia</i> can also speed up LLM inference on data-center GPUs like A100 and L40, which is discussed in detail in our  <a href="https://arxiv.org/abs/2402.12374" target="_blank">paper</a>.
          </p>
     <div>
  <p><img src="https://infini-ai-lab.github.io/Sequoia-Page/static/images/rssmerge.jpg" alt="Robustness and Scalability" width="800" height="400"></p><p><b>Left (Scalability):</b> Handcrafted tree structures do not scale well with large speculation budget.<br><b>Right (Robustness):</b> The total acceptance rate of 5 speculation tokens. Sampling with replacement (SpecTr) fails when temperature is low and Top-k sampling fails with high temperature. <i>Sequoia</i>, leveraging sampling without replacement, attains the highest acceptance rate. 
  <br>
  </p><div>
  <p><br>Below we show two examples of tree structures in <i>Sequoia</i>. The left one has 64 nodes which is suitable for on-chip inference and the right one has 768 nodes, suitable for offloading settings.
  We append more budget to nodes in previous layers with a higher probability to get accepted.</p>
  <p><img src="https://infini-ai-lab.github.io/Sequoia-Page/static/images/treemerge.jpg" alt="Tree Shape" width="800" height="400">
</p></div>
        
    </div>
  </div>
<!-- End Why -->
  
<!-- Discussion -->
<div>
        <h2>Conclusion and Future Work</h2>
        <p>
            Leveraging a large speculation budget, everyone can use RTX 4090 or other consumer (low-cost) GPU, e.g., AMD RX7900 with <i>Sequoia</i> to host very strong LLMs like 70B model without approximation, boosting the applications of AI generated content.
            In addition, we believe <i>Sequoia</i> will perform particularly well on future hardware, because it’s performance scales well with the compute/bandwidth ratio of the hardware, which has been increasing over time (e.g., V100, A100 and H100).
            Moreover, <i>Sequoia</i>, as a speculative decoding framework which mitigates the gap in the memory hierarchy, adapts to any draft/target pairs and any AI accelerators. We will stay tuned with hardware community.
          </p>
       <p><img src="https://infini-ai-lab.github.io/Sequoia-Page/static/images/colorful_sequoia.ico" alt="<i>Sequoia</i>" width="200" height="200">
</p>
      </div>
<!-- Disucssion -->
  
<!--BibTex citation -->
  <div id="BibTeX">
      <h2>BibTeX</h2>
      <pre><code>@article{chen2024sequoia,
  title={Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding},
  author={Chen, Zhuoming and May, Avner and Svirschevski, Ruslan and Huang, Yuhsun and Ryabinin, Max and Jia, Zhihao and Chen, Beidi},
  journal={arXiv preprint arXiv:2402.12374},
  year={2024}
}</code></pre>
    </div>
<!--End BibTex citation -->


  

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  
  
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Automated integer hash function discovery (250 pts)]]></title>
            <link>https://github.com/skeeto/hash-prospector</link>
            <guid>40261681</guid>
            <pubDate>Sun, 05 May 2024 01:39:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/skeeto/hash-prospector">https://github.com/skeeto/hash-prospector</a>, See on <a href="https://news.ycombinator.com/item?id=40261681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Hash Function Prospector</h2><a id="user-content-hash-function-prospector" aria-label="Permalink: Hash Function Prospector" href="#hash-function-prospector"></a></p>
<p dir="auto">This is a little tool for automated <a href="https://gist.github.com/badboy/6267743">integer hash function</a>
discovery. It generates billions of <a href="http://burtleburtle.net/bob/hash/integer.html" rel="nofollow">integer hash functions</a> at
random from a selection of <a href="http://papa.bretmulvey.com/post/124027987928/hash-functions" rel="nofollow">nine reversible operations</a> (<a href="https://marc-b-reynolds.github.io/math/2017/10/13/IntegerBijections.html" rel="nofollow">also</a>).
The generated functions are JIT compiled and their avalanche behavior is
evaluated. The current best function is printed out in C syntax.</p>
<p dir="auto">The <em>avalanche score</em> is the number of output bits that remain "fixed"
on average when a single input bit is flipped. Lower scores are better.
Ideally the score is 0 — e.g. every output bit flips with a 50% chance
when a single input bit is flipped.</p>
<p dir="auto">Prospector can generate both 32-bit and 64-bit integer hash functions.
Check the usage (<code>-h</code>) for the full selection of options. Due to the JIT
compiler, only x86-64 is supported, though the functions it discovers
can, of course, be used anywhere.</p>
<p dir="auto">Article: <a href="https://nullprogram.com/blog/2018/07/31/" rel="nofollow">Prospecting for Hash Functions</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Discovered Hash Functions</h2><a id="user-content-discovered-hash-functions" aria-label="Permalink: Discovered Hash Functions" href="#discovered-hash-functions"></a></p>
<p dir="auto">There are two useful classes of hash functions discovered by the
prospector and the other helper utilities here. Both use an
<em>xorshift-multiply-xorshift</em> construction, but with a different number
of rounds.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Two round functions</h3><a id="user-content-two-round-functions" aria-label="Permalink: Two round functions" href="#two-round-functions"></a></p>
<p dir="auto"><strong>Update</strong>: <a href="https://github.com/skeeto/hash-prospector/issues/19" data-hovercard-type="issue" data-hovercard-url="/skeeto/hash-prospector/issues/19/hovercard">TheIronBorn has used combinatorial optimization</a> to
discover the best known parameters for this construction:</p>
<div data-snippet-clipboard-copy-content="[16 21f0aaad 15 d35a2d97 15] = 0.10760229515479501"><pre><code>[16 21f0aaad 15 d35a2d97 15] = 0.10760229515479501
</code></pre></div>
<hr>
<p dir="auto">This 32-bit, two-round permutation has a particularly low bias and even
beats the venerable MurmurHash3 32-bit finalizer by a tiny margin. The
hash function construction was discovered by the prospector, then the
parameters were tuned using hill climbing and a genetic algorithm.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// exact bias: 0.17353355999581582
uint32_t
lowbias32(uint32_t x)
{
    x ^= x >> 16;
    x *= 0x7feb352d;
    x ^= x >> 15;
    x *= 0x846ca68b;
    x ^= x >> 16;
    return x;
}

// inverse
uint32_t
lowbias32_r(uint32_t x)
{
    x ^= x >> 16;
    x *= 0x43021123;
    x ^= x >> 15 ^ x >> 30;
    x *= 0x1d69e2a5;
    x ^= x >> 16;
    return x;
}"><pre><span>// exact bias: 0.17353355999581582</span>
<span>uint32_t</span>
<span>lowbias32</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>16</span>;
    <span>x</span> *= <span>0x7feb352d</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span>;
    <span>x</span> *= <span>0x846ca68b</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>16</span>;
    <span>return</span> <span>x</span>;
}

<span>// inverse</span>
<span>uint32_t</span>
<span>lowbias32_r</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>16</span>;
    <span>x</span> *= <span>0x43021123</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span> ^ <span>x</span> &gt;&gt; <span>30</span>;
    <span>x</span> *= <span>0x1d69e2a5</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>16</span>;
    <span>return</span> <span>x</span>;
}</pre></div>
<p dir="auto">More 2-round constants with low bias, some even better than <code>lowbias32</code>:</p>
<div data-snippet-clipboard-copy-content="[15 d168aaad 15 af723597 15] = 0.15983776156606694
[17 9e485565 16 ef1d6b47 16] = 0.16143129787074881
[16 604baa5d 15 43d6ce97 15] = 0.16491052655811722
[16 a812d533 15 b278e4ad 17] = 0.16540778981744320
[16 9c8f2d35 15 5d1346b5 17] = 0.16835348823718840
[16 88c0a94b 14 9d06da59 17] = 0.16898511658356749
[16 a52fb2cd 15 551e4d49 16] = 0.17162579707098322
[16 b237694b 15 eb5b4593 15] = 0.17274184020173433
[16 7feb352d 15 846ca68b 16] = 0.17353355999581582
[16 4bdc9aa5 15 2729b469 16] = 0.17355424787865850
[16 dc63b4d3 15 2c32b9a9 15] = 0.17368589564800074
[16 e02bd533 15 0364c8ad 17] = 0.17447893149410759
[16 603a32a7 15 5a522677 15] = 0.17514135907753242
[16 ac10d4eb 15 9d51b169 16] = 0.17676510450127819
[15 f15f5959 14 7db29359 16] = 0.18103205436627479
[16 83747333 14 aa256573 16] = 0.18105722344231542
[16 be8b6ca7 14 6dd624b5 16] = 0.18223928664971270
[17 7186cd35 15 fe6bba73 15] = 0.18312741727971640
[16 93f2552b 15 959b4a4d 15] = 0.18360629205797341
[16 df892d4b 15 3c2da6b3 16] = 0.18368195486921446
[15 49c34cd3 13 e7418ca7 16] = 0.18400092964673831
[15 4811acab 15 5591acd7 16] = 0.18522661033580071
[16 dc85aaa7 15 6658a5cb 15] = 0.18577280285788791
[16 1ec9b4db 15 3224d38d 17] = 0.18631684392389897
[16 8ee0d535 15 5dc6b5af 15] = 0.18664478683752250
[16 462daaad 15 0a36c95d 16] = 0.18674876992866513
[16 17cdd657 15 a426cb25 15] = 0.18995262675473334
[16 ab39aacb 15 a1b5d19b 15] = 0.19045785238099658
[17 cd8512ad 15 b95c5a73 15] = 0.19050717016846502
[16 aecc96b5 15 f64dcd47 15] = 0.19077817816874504
[15 2548acd5 15 0b39d397 16] = 0.19121161052714156
[15 7f19c559 15 b356358d 16] = 0.19198007174447981
[16 4ffcab35 15 e98db28b 16] = 0.19423994132339928
[15 1216ccb5 15 3abcdca9 15] = 0.19426091938816648
[16 97219aad 15 ab46b735 15] = 0.19536391240344408
[16 c845a997 15 f214db9b 17] = 0.19553179377831409
[15 3a7ba96b 13 5e919299 16] = 0.19563436462680908
[16 c3d9a965 16 362e4b47 15] = 0.19575424692659107
[17 179cd515 15 4c495d47 15] = 0.19608530402798924
[16 5dce3553 15 a655d8e9 15] = 0.19621753012889542
[17 88a5ad35 16 96338b27 16] = 0.19653922266398804
[17 0364d657 15 ac2a34c5 15] = 0.19665754791333651
[16 3c9aa9ab 16 051369d7 16] = 0.19687211117412906
[17 0ee6d967 15 9c8a4a33 16] = 0.19722490309575344
[16 b921a6cb 14 30b5a6d1 16] = 0.19745192295417058
[18 a136aaad 16 9f6d62d7 17] = 0.19768193144773874
[16 0ae84d3b 15 3b9d4e5b 17] = 0.19776257374279985
[17 24f4d2cd 15 1ba3b969 16] = 0.19789489706453650
[16 418fb5b3 15 8cf3539b 16] = 0.19817117175199098
[16 f0ae2ad7 15 8965d939 16] = 0.19881758420284917
[17 9bde596b 16 1c9e9647 16] = 0.19882570872036193
[16 bd10754b 14 35a29b0d 16] = 0.19885203058591913
[17 78d31553 15 c547ac65 15] = 0.19918133404528665
[15 81aab34d 15 18e746a3 15] = 0.19938572052445763
[16 054335ab 15 146da68b 16] = 0.19943843016872725
[17 a1c76a55 16 5ca46b97 16] = 0.19959562213253398
[15 c62f4d53 14 62b8a46b 16] = 0.19973996656987172
[16 6872cd2d 15 f4a0d975 17] = 0.19992260539370590"><pre><code>[15 d168aaad 15 af723597 15] = 0.15983776156606694
[17 9e485565 16 ef1d6b47 16] = 0.16143129787074881
[16 604baa5d 15 43d6ce97 15] = 0.16491052655811722
[16 a812d533 15 b278e4ad 17] = 0.16540778981744320
[16 9c8f2d35 15 5d1346b5 17] = 0.16835348823718840
[16 88c0a94b 14 9d06da59 17] = 0.16898511658356749
[16 a52fb2cd 15 551e4d49 16] = 0.17162579707098322
[16 b237694b 15 eb5b4593 15] = 0.17274184020173433
[16 7feb352d 15 846ca68b 16] = 0.17353355999581582
[16 4bdc9aa5 15 2729b469 16] = 0.17355424787865850
[16 dc63b4d3 15 2c32b9a9 15] = 0.17368589564800074
[16 e02bd533 15 0364c8ad 17] = 0.17447893149410759
[16 603a32a7 15 5a522677 15] = 0.17514135907753242
[16 ac10d4eb 15 9d51b169 16] = 0.17676510450127819
[15 f15f5959 14 7db29359 16] = 0.18103205436627479
[16 83747333 14 aa256573 16] = 0.18105722344231542
[16 be8b6ca7 14 6dd624b5 16] = 0.18223928664971270
[17 7186cd35 15 fe6bba73 15] = 0.18312741727971640
[16 93f2552b 15 959b4a4d 15] = 0.18360629205797341
[16 df892d4b 15 3c2da6b3 16] = 0.18368195486921446
[15 49c34cd3 13 e7418ca7 16] = 0.18400092964673831
[15 4811acab 15 5591acd7 16] = 0.18522661033580071
[16 dc85aaa7 15 6658a5cb 15] = 0.18577280285788791
[16 1ec9b4db 15 3224d38d 17] = 0.18631684392389897
[16 8ee0d535 15 5dc6b5af 15] = 0.18664478683752250
[16 462daaad 15 0a36c95d 16] = 0.18674876992866513
[16 17cdd657 15 a426cb25 15] = 0.18995262675473334
[16 ab39aacb 15 a1b5d19b 15] = 0.19045785238099658
[17 cd8512ad 15 b95c5a73 15] = 0.19050717016846502
[16 aecc96b5 15 f64dcd47 15] = 0.19077817816874504
[15 2548acd5 15 0b39d397 16] = 0.19121161052714156
[15 7f19c559 15 b356358d 16] = 0.19198007174447981
[16 4ffcab35 15 e98db28b 16] = 0.19423994132339928
[15 1216ccb5 15 3abcdca9 15] = 0.19426091938816648
[16 97219aad 15 ab46b735 15] = 0.19536391240344408
[16 c845a997 15 f214db9b 17] = 0.19553179377831409
[15 3a7ba96b 13 5e919299 16] = 0.19563436462680908
[16 c3d9a965 16 362e4b47 15] = 0.19575424692659107
[17 179cd515 15 4c495d47 15] = 0.19608530402798924
[16 5dce3553 15 a655d8e9 15] = 0.19621753012889542
[17 88a5ad35 16 96338b27 16] = 0.19653922266398804
[17 0364d657 15 ac2a34c5 15] = 0.19665754791333651
[16 3c9aa9ab 16 051369d7 16] = 0.19687211117412906
[17 0ee6d967 15 9c8a4a33 16] = 0.19722490309575344
[16 b921a6cb 14 30b5a6d1 16] = 0.19745192295417058
[18 a136aaad 16 9f6d62d7 17] = 0.19768193144773874
[16 0ae84d3b 15 3b9d4e5b 17] = 0.19776257374279985
[17 24f4d2cd 15 1ba3b969 16] = 0.19789489706453650
[16 418fb5b3 15 8cf3539b 16] = 0.19817117175199098
[16 f0ae2ad7 15 8965d939 16] = 0.19881758420284917
[17 9bde596b 16 1c9e9647 16] = 0.19882570872036193
[16 bd10754b 14 35a29b0d 16] = 0.19885203058591913
[17 78d31553 15 c547ac65 15] = 0.19918133404528665
[15 81aab34d 15 18e746a3 15] = 0.19938572052445763
[16 054335ab 15 146da68b 16] = 0.19943843016872725
[17 a1c76a55 16 5ca46b97 16] = 0.19959562213253398
[15 c62f4d53 14 62b8a46b 16] = 0.19973996656987172
[16 6872cd2d 15 f4a0d975 17] = 0.19992260539370590
</code></pre></div>
<p dir="auto">This next function was discovered using only the prospector. It has a bit more
bias than the previous function.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// exact bias: 0.34968228323361017
uint32_t
prospector32(uint32_t x)
{
    x ^= x >> 15;
    x *= 0x2c1b3c6d;
    x ^= x >> 12;
    x *= 0x297a2d39;
    x ^= x >> 15;
    return x;
}"><pre><span>// exact bias: 0.34968228323361017</span>
<span>uint32_t</span>
<span>prospector32</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span>;
    <span>x</span> *= <span>0x2c1b3c6d</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>12</span>;
    <span>x</span> *= <span>0x297a2d39</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span>;
    <span>return</span> <span>x</span>;
}</pre></div>
<p dir="auto">To use the prospector search randomly for alternative multiplication constants,
run it like so:</p>
<div data-snippet-clipboard-copy-content="$ ./prospector -p xorr:15,mul,xorr:12,mul,xorr:15"><pre><code>$ ./prospector -p xorr:15,mul,xorr:12,mul,xorr:15
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Three round functions</h3><a id="user-content-three-round-functions" aria-label="Permalink: Three round functions" href="#three-round-functions"></a></p>
<p dir="auto">Another round of multiply-xorshift in this construction allows functions
with carefully chosen parameters to reach the theoretical bias limit
(bias = ~0.021). For example, this hash function is indistinguishable
from a perfect PRF (e.g. a random permutation of all 32-bit integers):</p>
<div dir="auto" data-snippet-clipboard-copy-content="// exact bias: 0.020888578919738908
uint32_t
triple32(uint32_t x)
{
    x ^= x >> 17;
    x *= 0xed5ad4bb;
    x ^= x >> 11;
    x *= 0xac4c1b51;
    x ^= x >> 15;
    x *= 0x31848bab;
    x ^= x >> 14;
    return x;
}

// inverse
uint32_t
triple32_r(uint32_t x)
{
    x ^= x >> 14 ^ x >> 28;
    x *= 0x32b21703;
    x ^= x >> 15 ^ x >> 30;
    x *= 0x469e0db1;
    x ^= x >> 11 ^ x >> 22;
    x *= 0x79a85073;
    x ^= x >> 17;
    return x;
}"><pre><span>// exact bias: 0.020888578919738908</span>
<span>uint32_t</span>
<span>triple32</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>17</span>;
    <span>x</span> *= <span>0xed5ad4bb</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>11</span>;
    <span>x</span> *= <span>0xac4c1b51</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span>;
    <span>x</span> *= <span>0x31848bab</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>14</span>;
    <span>return</span> <span>x</span>;
}

<span>// inverse</span>
<span>uint32_t</span>
<span>triple32_r</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>14</span> ^ <span>x</span> &gt;&gt; <span>28</span>;
    <span>x</span> *= <span>0x32b21703</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span> ^ <span>x</span> &gt;&gt; <span>30</span>;
    <span>x</span> *= <span>0x469e0db1</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>11</span> ^ <span>x</span> &gt;&gt; <span>22</span>;
    <span>x</span> *= <span>0x79a85073</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>17</span>;
    <span>return</span> <span>x</span>;
}</pre></div>
<p dir="auto">More 3-round constants with low bias:</p>
<div data-snippet-clipboard-copy-content="[17 ed5ad4bb 11 ac4c1b51 15 31848bab 14] = 0.020888578919738908
[16 aeccedab 14 ac613e37 16 19c89935 17] = 0.021246568167078764
[16 236f7153 12 33cd8663 15 3e06b66b 16] = 0.021280991798512679
[18 4260bb47 13 27e8e1ed 15 9d48a33b 15] = 0.021576730651802156
[17 3f6cde45 12 51d608ef 16 6e93639d 17] = 0.021772288363808408
[15 5dfa224b 14 4bee7e4b 17 930ee371 15] = 0.02184521628884813
[17 3964f363 14 9ac3751d 16 4e8772cb 17] = 0.021883292578109576
[16 66046c65 14 d3f0865b 16 f9999193 16] = 0.0219446068365007
[16 b1a89b33 14 09136aaf 16 5f2a44a7 15] = 0.021998624107282542
[16 24767aad 12 daa18229 16 e9e53beb 16] = 0.022043911220395354
[15 42f91d8d 14 61355a85 15 dcf2a949 14] = 0.022052539152635078
[15 4df8395b 15 466b428b 16 b4b2868b 16] = 0.022140187420461286
[16 2bbed51b 14 cd09896b 16 38d4c587 15] = 0.022159936298777144
[16 0ab694cd 14 4c139e47 16 11a42c3b 16] = 0.02220928191220355
[17 7f1e072b 12 8750a507 16 ecbb5b5f 16] = 0.022283743052847804
[16 f1be7bad 14 73a54099 15 3b85b963 15] = 0.022316544125749647
[16 66e756d5 14 b5f5a9cd 16 84e56b11 16] = 0.022372957847491555
[15 233354bb 15 ce1247bd 16 855089bb 17] = 0.022406591070966285
[16 eb6805ab 15 d2c7b7a7 16 7645a32b 16] = 0.022427060650927547
[16 8288ab57 14 0d1bfe57 16 131631e5 16] = 0.022431656871313443
[16 45109e55 14 3b94759d 16 adf31ea5 17] = 0.022436433678417977
[15 26cd1933 14 e3da1d59 16 5a17445d 16] = 0.022460520416491526
[16 7001e6eb 14 bb8e7313 16 3aa8c523 15] = 0.022491767264054854
[16 49ed0a13 14 83588f29 15 658f258d 15] = 0.022500668856510898
[16 6cdb9705 14 4d58d2ed 14 c8642b37 16] = 0.022504626537729222
[16 a986846b 14 bdd5372d 15 ad44de6b 17] = 0.022528238323120016
[16 c9575725 15 9448f4c5 16 3b7a5443 16] = 0.022586511310042686
[15 fc54c453 13 08213789 15 669f96eb 16] = 0.022591114646032095
[16 d47ef17b 14 642fa58f 16 a8b65b9b 16] = 0.022600633971701509
[15 00bfaa73 14 8799c69b 16 731985b1 16] = 0.022645866629596379
[16 953a55e9 15 8523822b 17 56e7aa63 15] = 0.022667180032713324
[16 a3d7345b 15 7f41c9c7 16 308bd62d 17] = 0.022688845770122031
[16 195565c7 14 16064d6f 16 0f9ec575 15] = 0.022697810688752193
[16 13566dbb 14 59369a03 15 990f9d1b 16] = 0.022712430070797596
[16 8430cc4b 15 a7831cbd 15 c6ccbd33 15] = 0.022734765033419774
[16 699f272b 14 09c01023 16 39bd48c3 15] = 0.022854175321846512
[15 336536c3 13 4f0e38b1 16 15d229f7 16] = 0.022884125170795171
[16 221f686d 12 d8948a07 16 ed8a8345 16] = 0.022902500408830236
[16 d7ca8cbb 13 eb4e259f 15 34ab1143 16] = 0.022905955538176669
[16 7cb04f65 14 9b96da73 16 83625687 15] = 0.022906573700088178
[15 5156196b 14 940d8869 15 0086f473 17] = 0.022984943828687553"><pre><code>[17 ed5ad4bb 11 ac4c1b51 15 31848bab 14] = 0.020888578919738908
[16 aeccedab 14 ac613e37 16 19c89935 17] = 0.021246568167078764
[16 236f7153 12 33cd8663 15 3e06b66b 16] = 0.021280991798512679
[18 4260bb47 13 27e8e1ed 15 9d48a33b 15] = 0.021576730651802156
[17 3f6cde45 12 51d608ef 16 6e93639d 17] = 0.021772288363808408
[15 5dfa224b 14 4bee7e4b 17 930ee371 15] = 0.02184521628884813
[17 3964f363 14 9ac3751d 16 4e8772cb 17] = 0.021883292578109576
[16 66046c65 14 d3f0865b 16 f9999193 16] = 0.0219446068365007
[16 b1a89b33 14 09136aaf 16 5f2a44a7 15] = 0.021998624107282542
[16 24767aad 12 daa18229 16 e9e53beb 16] = 0.022043911220395354
[15 42f91d8d 14 61355a85 15 dcf2a949 14] = 0.022052539152635078
[15 4df8395b 15 466b428b 16 b4b2868b 16] = 0.022140187420461286
[16 2bbed51b 14 cd09896b 16 38d4c587 15] = 0.022159936298777144
[16 0ab694cd 14 4c139e47 16 11a42c3b 16] = 0.02220928191220355
[17 7f1e072b 12 8750a507 16 ecbb5b5f 16] = 0.022283743052847804
[16 f1be7bad 14 73a54099 15 3b85b963 15] = 0.022316544125749647
[16 66e756d5 14 b5f5a9cd 16 84e56b11 16] = 0.022372957847491555
[15 233354bb 15 ce1247bd 16 855089bb 17] = 0.022406591070966285
[16 eb6805ab 15 d2c7b7a7 16 7645a32b 16] = 0.022427060650927547
[16 8288ab57 14 0d1bfe57 16 131631e5 16] = 0.022431656871313443
[16 45109e55 14 3b94759d 16 adf31ea5 17] = 0.022436433678417977
[15 26cd1933 14 e3da1d59 16 5a17445d 16] = 0.022460520416491526
[16 7001e6eb 14 bb8e7313 16 3aa8c523 15] = 0.022491767264054854
[16 49ed0a13 14 83588f29 15 658f258d 15] = 0.022500668856510898
[16 6cdb9705 14 4d58d2ed 14 c8642b37 16] = 0.022504626537729222
[16 a986846b 14 bdd5372d 15 ad44de6b 17] = 0.022528238323120016
[16 c9575725 15 9448f4c5 16 3b7a5443 16] = 0.022586511310042686
[15 fc54c453 13 08213789 15 669f96eb 16] = 0.022591114646032095
[16 d47ef17b 14 642fa58f 16 a8b65b9b 16] = 0.022600633971701509
[15 00bfaa73 14 8799c69b 16 731985b1 16] = 0.022645866629596379
[16 953a55e9 15 8523822b 17 56e7aa63 15] = 0.022667180032713324
[16 a3d7345b 15 7f41c9c7 16 308bd62d 17] = 0.022688845770122031
[16 195565c7 14 16064d6f 16 0f9ec575 15] = 0.022697810688752193
[16 13566dbb 14 59369a03 15 990f9d1b 16] = 0.022712430070797596
[16 8430cc4b 15 a7831cbd 15 c6ccbd33 15] = 0.022734765033419774
[16 699f272b 14 09c01023 16 39bd48c3 15] = 0.022854175321846512
[15 336536c3 13 4f0e38b1 16 15d229f7 16] = 0.022884125170795171
[16 221f686d 12 d8948a07 16 ed8a8345 16] = 0.022902500408830236
[16 d7ca8cbb 13 eb4e259f 15 34ab1143 16] = 0.022905955538176669
[16 7cb04f65 14 9b96da73 16 83625687 15] = 0.022906573700088178
[15 5156196b 14 940d8869 15 0086f473 17] = 0.022984943828687553
</code></pre></div>
<p dir="auto">Prepending an increment to <code>triple32</code> breaks the <code>hash(0) = 0</code> issue while
also lowering the bias a tiny bit further:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// exact bias: 0.020829410544597495
uint32_t
triple32inc(uint32_t x)
{
    x++;
    x ^= x >> 17;
    x *= 0xed5ad4bb;
    x ^= x >> 11;
    x *= 0xac4c1b51;
    x ^= x >> 15;
    x *= 0x31848bab;
    x ^= x >> 14;
    return x;
}

// inverse
uint32_t
triple32inc_r(uint32_t x)
{
    x ^= x >> 14 ^ x >> 28;
    x *= 0x32b21703;
    x ^= x >> 15 ^ x >> 30;
    x *= 0x469e0db1;
    x ^= x >> 11 ^ x >> 22;
    x *= 0x79a85073;
    x ^= x >> 17;
    x--;
    return x;
}"><pre><span>// exact bias: 0.020829410544597495</span>
<span>uint32_t</span>
<span>triple32inc</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span><span>++</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>17</span>;
    <span>x</span> *= <span>0xed5ad4bb</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>11</span>;
    <span>x</span> *= <span>0xac4c1b51</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span>;
    <span>x</span> *= <span>0x31848bab</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>14</span>;
    <span>return</span> <span>x</span>;
}

<span>// inverse</span>
<span>uint32_t</span>
<span>triple32inc_r</span>(<span>uint32_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>14</span> ^ <span>x</span> &gt;&gt; <span>28</span>;
    <span>x</span> *= <span>0x32b21703</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>15</span> ^ <span>x</span> &gt;&gt; <span>30</span>;
    <span>x</span> *= <span>0x469e0db1</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>11</span> ^ <span>x</span> &gt;&gt; <span>22</span>;
    <span>x</span> *= <span>0x79a85073</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>17</span>;
    <span>x</span><span>--</span>;
    <span>return</span> <span>x</span>;
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Measuring exact bias</h2><a id="user-content-measuring-exact-bias" aria-label="Permalink: Measuring exact bias" href="#measuring-exact-bias"></a></p>
<p dir="auto">The <code>-E</code> mode evaluates the bias of a given hash function (<code>-p</code> or <code>-l</code>). By
default the prospector uses an estimate to quickly evaluate a function's bias,
but it's non-deterministic and there's a lot of noise in the result. To
exhaustively measure the exact bias, use the <code>-e</code> option.</p>
<p dir="auto">The function to be checked can be defined using <code>-p</code> and a pattern or
<code>-l</code> and a shared library containing a function named <code>hash()</code>. For
example, to measure the exact bias of the best hash function above:</p>
<div data-snippet-clipboard-copy-content="$ ./prospector -Eep xorr:16,mul:e2d0d4cb,xorr:15,mul:3c6ad939,xorr:15"><pre><code>$ ./prospector -Eep xorr:16,mul:e2d0d4cb,xorr:15,mul:3c6ad939,xorr:15
</code></pre></div>
<p dir="auto">Or drop the function in a C file named hash.c, and name the function
<code>hash()</code>. This lets you test hash functions that can't be represented
using the prospector's limited notion of hash functions.</p>
<div data-snippet-clipboard-copy-content="$ cc -O3 -shared -fPIC -l hash.so hash.c
$ ./prospector -Eel ./hash.so"><pre><code>$ cc -O3 -shared -fPIC -l hash.so hash.c
$ ./prospector -Eel ./hash.so
</code></pre></div>
<p dir="auto">By default it treats its input as a 32-bit hash function. Use the <code>-8</code>
switch to test (by estimation) 64-bit functions. There is no exact,
exhaustive test for 64-bit hash functions since that would take far too
long.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reversible operation selection</h2><a id="user-content-reversible-operation-selection" aria-label="Permalink: Reversible operation selection" href="#reversible-operation-selection"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="x  = ~x;
x ^= constant;
x *= constant | 1; // e.g. only odd constants
x += constant;
x ^= x >> constant;
x ^= x << constant;
x += x << constant;
x -= x << constant;
x <<<= constant; // left rotation
x = bswap(x) // swap high and low bytes."><pre><span>x</span>  <span>=</span> ~<span>x</span>;
<span>x</span> ^= <span>constant</span>;
<span>x</span> *= <span>constant</span> | <span>1</span>; <span>// e.g. only odd constants</span>
<span>x</span> <span>+=</span> <span>constant</span>;
<span>x</span> ^= <span>x</span> &gt;&gt; <span>constant</span>;
<span>x</span> ^= <span>x</span> &lt;&lt; <span>constant</span>;
<span>x</span> <span>+=</span> <span>x</span> &lt;&lt; <span>constant</span>;
<span>x</span> <span>-=</span> <span>x</span> &lt;&lt; <span>constant</span>;
<span>x</span> &lt;&lt;&lt;= <span>constant</span>; <span>// left rotation</span>
<span>x</span> <span>=</span> <span>bswap</span>(<span>x</span>) <span>// swap high and low bytes.</span></pre></div>
<p dir="auto">Technically <code>x = ~x</code> is covered by <code>x ^= constant</code>. However, <code>~x</code> is
uniquely special and particularly useful. The generator is very unlikely
to generate the one correct constant for the XOR operator that achieves
the same effect.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">16-bit hashes</h2><a id="user-content-16-bit-hashes" aria-label="Permalink: 16-bit hashes" href="#16-bit-hashes"></a></p>
<p dir="auto">Because the constraints are different for 16-bit hashes there's a separate
tool for generating these hashes: <code>hp16</code>. Unlike the 32-bit / 64-bit
prospector, this implementation is fully portable and will run on just
about any system. It's also capable of generating and evaluating 128KiB
s-boxes.</p>
<p dir="auto">Since 16-bit hashes are more likely to be needed on machines that, say,
lack fast multiplication instructions, certain operations can be omitted
during exploration (<code>-m</code>, <code>-r</code>).</p>
<p dir="auto">Some interesting results so far:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// 2-round xorshift-multiply (-Xn2)
// bias = 0.0085905051336723701
uint16_t hash16_xm2(uint16_t x)
{
    x ^= x >> 8; x *= 0x88b5U;
    x ^= x >> 7; x *= 0xdb2dU;
    x ^= x >> 9;
    return x;
}

// 3-round xorshift-multiply (-Xn3)
// bias = 0.0045976709018820602
uint16_t hash16_xm3(uint16_t x)
{
    x ^= x >>  7; x *= 0x2993U;
    x ^= x >>  5; x *= 0xe877U;
    x ^= x >>  9; x *= 0x0235U;
    x ^= x >> 10;
    return x;
}

// No multiplication (-Imn6)
// bias = 0.023840118344741465
uint16_t hash16_s6(uint16_t x)
{
    x += x << 7; x ^= x >> 8;
    x += x << 3; x ^= x >> 2;
    x += x << 4; x ^= x >> 8;
    return x;
}

// Which is identical to this xorshift-multiply
uint16_t hash16_s6(uint16_t x)
{
    x *= 0x0081U; x ^= x >> 8;
    x *= 0x0009U; x ^= x >> 2;
    x *= 0x0011U; x ^= x >> 8;
    return x;
}"><pre><span>// 2-round xorshift-multiply (-Xn2)</span>
<span>// bias = 0.0085905051336723701</span>
<span>uint16_t</span> <span>hash16_xm2</span>(<span>uint16_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>8</span>; <span>x</span> *= <span>0x88b5U</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>7</span>; <span>x</span> *= <span>0xdb2dU</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>9</span>;
    <span>return</span> <span>x</span>;
}

<span>// 3-round xorshift-multiply (-Xn3)</span>
<span>// bias = 0.0045976709018820602</span>
<span>uint16_t</span> <span>hash16_xm3</span>(<span>uint16_t</span> <span>x</span>)
{
    <span>x</span> ^= <span>x</span> &gt;&gt;  <span>7</span>; <span>x</span> *= <span>0x2993U</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt;  <span>5</span>; <span>x</span> *= <span>0xe877U</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt;  <span>9</span>; <span>x</span> *= <span>0x0235U</span>;
    <span>x</span> ^= <span>x</span> &gt;&gt; <span>10</span>;
    <span>return</span> <span>x</span>;
}

<span>// No multiplication (-Imn6)</span>
<span>// bias = 0.023840118344741465</span>
<span>uint16_t</span> <span>hash16_s6</span>(<span>uint16_t</span> <span>x</span>)
{
    <span>x</span> <span>+=</span> <span>x</span> &lt;&lt; <span>7</span>; <span>x</span> ^= <span>x</span> &gt;&gt; <span>8</span>;
    <span>x</span> <span>+=</span> <span>x</span> &lt;&lt; <span>3</span>; <span>x</span> ^= <span>x</span> &gt;&gt; <span>2</span>;
    <span>x</span> <span>+=</span> <span>x</span> &lt;&lt; <span>4</span>; <span>x</span> ^= <span>x</span> &gt;&gt; <span>8</span>;
    <span>return</span> <span>x</span>;
}

<span>// Which is identical to this xorshift-multiply</span>
<span>uint16_t</span> <span>hash16_s6</span>(<span>uint16_t</span> <span>x</span>)
{
    <span>x</span> *= <span>0x0081U</span>; <span>x</span> ^= <span>x</span> &gt;&gt; <span>8</span>;
    <span>x</span> *= <span>0x0009U</span>; <span>x</span> ^= <span>x</span> &gt;&gt; <span>2</span>;
    <span>x</span> *= <span>0x0011U</span>; <span>x</span> ^= <span>x</span> &gt;&gt; <span>8</span>;
    <span>return</span> <span>x</span>;
}</pre></div>
<p dir="auto">A good 3-round xorshift hash (a short search via <code>hp16 -Xn3</code>) is a close
approximation of a good s-box (i.e. <code>hp16 -S</code>).</p>
<p dir="auto">Be mindful of C integer promotion rules when doing 16-bit operations. For
instance, on 32-bit implementations unsigned 16-bit operands will be
promoted to signed 32-bit integers, leading to incorrect results in
certain cases. The C programs printed by this program are careful to
promote 16-bit operations to "unsigned int" where needed.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dick Rutan, pilot of the first nonstop around-the-world flight, has died (114 pts)]]></title>
            <link>https://www.independent.co.uk/news/ap-voyager-ronald-reagan-california-idaho-b2539832.html</link>
            <guid>40261408</guid>
            <pubDate>Sun, 05 May 2024 00:25:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.co.uk/news/ap-voyager-ronald-reagan-california-idaho-b2539832.html">https://www.independent.co.uk/news/ap-voyager-ronald-reagan-california-idaho-b2539832.html</a>, See on <a href="https://news.ycombinator.com/item?id=40261408">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-newsletter-key="receiveIndyTravelNews"><p><img src="https://static.independent.co.uk/static-assets/images/newsletter/travel/travel.jpg" loading="lazy" alt="Simon Calder’s Travel"></p><div><p><h3 data-nosnippet="">Sign up to Simon Calder’s free travel email for expert advice and money-saving discounts</h3><h3 data-nosnippet="">Get Simon Calder’s Travel email</h3></p></div></div><p>Burt Rutan was alarmed to see the plane he had designed was so loaded with fuel that the wing tips started dragging along the ground as it taxied down the runway. He grabbed the radio to warn the pilot, his older brother Dick Rutan. But Dick never heard the message.</p><p>Nine days and three minutes later, Dick, along with copilot Jeana Yeager, completed one of the greatest milestones in aviation history: the first round-the-world flight with no stops or refueling.</p><p>A decorated Vietnam War pilot, Dick Rutan died Friday evening at a hospital in Coeur d’Alene, <a href="https://www.independent.co.uk/topic/idaho">Idaho</a>, with Burt and other loved ones by his side. He was 85. His friend Bill Whittle said he died on his own terms when he decided against enduring a second night on oxygen after suffering a severe lung infection. </p><p>“He played an airplane like someone plays a grand piano,” said Burt Rutan of his brother, who was often described as has having a velvet arm because of his smooth flying style.</p><p>Burt Rutan said he had always loved designing airplanes and became fascinated with the idea of a craft that could go clear around the world. His brother was equally passionate about flying. The project took six years. </p><p>There was plenty to worry Mr Rutan during testing of the light graphite plane, <a href="https://www.independent.co.uk/topic/voyager">Voyager</a>. There were mechanical failures, any one of which would have been disastrous over a distant ocean. When fully laden, the plane couldn't handle turbulence. And then there was the question of how the pilots could endure such a long flight on so little sleep. But Mr Rutan said his brother had an optimism about him that made them all believe.</p><p>“Dick never doubted whether my design would actually make it around, with still some gas in the tank,” Mr Rutan said.</p><p>Voyager left from Edwards Air Force Base in <a href="https://www.independent.co.uk/topic/california">California</a> just after 8am on 14 Dec 1986. Rutan said with all that fuel, the wings had only inches of clearance. Dick couldn't see when they started dragging on the runway. But at the moment Mr Rutan called on the radio, copilot Yeager gave a speed report, drowning out the message.</p><p>“And then, the velvet arm really came in,” Mr Rutan said. “And he very slowly brought the stick back and the wings bent way up, some 30 feet at the wingtips, and it lifted off very smoothly.”</p><p>They arrived back to a hero's welcome as thousands gathered to witness the landing. Both Rutan brothers and Yeager were each awarded a Presidential Citizens Medal by President <a href="https://www.independent.co.uk/topic/ronald-reagan">Ronald Reagan</a>, who described how a local official in Thailand at first “refused to believe some cockamamie story" about a plane flying around the world on a single tank of gas.</p><p>“We had the freedom to pursue a dream, and that’s important," Dick Rutan said at the ceremony. “And we should never forget, and those that guard our freedoms, that we should hang on to them very tenaciously and be very careful about some do-gooder that thinks that our safety is more important than our freedom. Because freedom is awful difficult to obtain, and it’s even more difficult to regain it once it’s lost.”</p><p>Richard Glenn Rutan was born in Loma Linda, California. He joined the US Air Force as a teenager and flew more than 300 combat missions during the Vietnam War. </p><p>He was part of an elite group that would loiter over enemy anti-aircraft positions for hours at a time. The missions had the call sign “Misty," and Dick was known as “Misty Four-Zero.” Among the many awards Dick received were the Silver Star and the Purple Heart.</p><p>He survived having to eject twice from planes, once when his F-100 Super Sabre was hit by enemy fire over Vietnam, and a second time when he was stationed in England and the same type of plane had a mechanical failure. He retired from the Air Force with the rank of lieutenant colonel and went on to work as a test pilot.</p><p>Mr Rutan said his brother was always having adventures, like the time he got stranded at the North Pole for a couple of days when the Russian biplane he was in landed and then sank through the ice.</p><p>Dick Rutan set another record in 2005 when he flew about 10m (16km) in a rocket-powered plane launched from the ground in Mojave, California. It was also the first time US mail had been carried by such a plane.</p><p>Greg Morris, the president of Scaled Composites, a company founded by Burt Rutan, said he first met Dick was when he was about seven and over the years always found him generous and welcoming.</p><p>“Bigger than life, in every sense of the word,” Mr Morris said, listing off Rutan's legacy in the Vietnam War, testing planes and on the Voyager flight. “Any one of those contributions would make a legend in aviation. All of them together, in one person, is just inconceivable.”</p><p>Whittle said Rutan had been courageous in his final hours at the hospital – sharp as a tack, calm and joking with them about what might come next after death. </p><p>“He’s the greatest pilot that’s ever lived,” Mr Whittle said. </p><p>Dick Rutan is survived by his wife of 25 years Kris Rutan; daughters Holly Hogan and Jill Hoffman; and grandchildren Jack, Sean, Noelle and Haley.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vera Rubin's primary mirror gets its first reflective coating (142 pts)]]></title>
            <link>https://www.universetoday.com/166842/vera-rubins-primary-mirror-gets-its-first-reflective-coating/</link>
            <guid>40261001</guid>
            <pubDate>Sat, 04 May 2024 23:02:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.universetoday.com/166842/vera-rubins-primary-mirror-gets-its-first-reflective-coating/">https://www.universetoday.com/166842/vera-rubins-primary-mirror-gets-its-first-reflective-coating/</a>, See on <a href="https://news.ycombinator.com/item?id=40261001">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-166842">

<div>
<p>First light for the Vera Rubin Observatory (VRO) is quickly approaching and the telescope is reaching milestone after milestone. A few weeks ago, the observatory announced that its digital camera, the largest one ever made, <a href="https://www.universetoday.com/166483/the-worlds-largest-digital-camera-is-complete-it-will-go-into-the-vera-rubin-observatory/">is complete</a>. </p>
<p>Now the observatory has announced that its unique primary/tertiary mirror has its first reflective coating. </p>
<p>The Rubin’s massive digital camera has an important job and garners a lot of attention. But it’s powerless without the telescope’s innovative primary/tertiary mirror. Primary mirrors are always the most critical and time-consuming part of modern observatories. The VRO’s primary/tertiary mirror took seven years to make. </p>
<p>The mirror is called a primary/tertiary mirror because it comprises two optical surfaces with different curvatures. The primary mirror is 8.4 meters, while the tertiary mirror is 5 meters in diameter. The pair of surfaces are combined into one large structure. The unique design reduces the telescope’s engineering complexity without reducing its impressive light-gathering capability. It can be rotated quickly and also settles quickly.</p>
<figure><img decoding="async" width="660" height="283" src="https://www.universetoday.com/wp-content/uploads/2024/05/M1M3_render_labels.jpg" alt="The VRO's unique primary/tertiary mirror is two mirrors in one. It's mounted on lightweight honeycomb material for strength. Image Credit: VRO" srcset="https://www.universetoday.com/wp-content/uploads/2024/05/M1M3_render_labels.jpg 660w, https://www.universetoday.com/wp-content/uploads/2024/05/M1M3_render_labels-580x249.jpg 580w, https://www.universetoday.com/wp-content/uploads/2024/05/M1M3_render_labels-250x107.jpg 250w" sizes="(max-width: 660px) 100vw, 660px"><figcaption>The VRO’s unique primary/tertiary mirror is two mirrors in one. It’s mounted on lightweight honeycomb material for strength. Image Credit: VRO</figcaption></figure>
<p>The outer surface forms the primary mirror. It captures light from space first, then that light reflects upwards to the 3.4-meter secondary mirror. After that, it’s reflected back down to the inner 5.0-meter surface that forms the tertiary mirror. Then, the light is sent to the camera.</p>
<p>The primary mirror’s size is critical because it determines how much light the telescope can collect. More light means astronomers can study very faint or distant objects. The VRO’s design allows the camera to capture a large area of sky the size of 7 full moons across in a single image.</p>
<p><a href="https://giphy.com/gifs/PxwWt2Pp8Lj5Rlszkx">via GIPHY</a></p>
<p>Only meticulous engineering and construction can build a telescope like this. One of the stages is putting the reflective and protective coatings on the mirrors. The VRO announced that the primary/tertiary mirror has its first coating.</p>
<figure><blockquote><p>“This was a very well-conducted project from every angle, thanks to a combination of careful planning and the technical skills of our excellent team.”</p><cite>Tomislav Vucina, Senior Coating Engineer, VRO</cite></blockquote></figure>
<p>The VRO has a special onsite coating chamber built just for this purpose. It’s a 128-ton chamber on the observatory’s maintenance floor. It uses a process called <a href="https://en.wikipedia.org/wiki/Sputter_deposition">magnetron sputtering</a> to apply coatings. The chamber will be reused during the telescope’s lifetime whenever the mirror needs re-coating. </p>
<figure><p><span><iframe loading="lazy" width="525" height="296" src="https://www.youtube.com/embed/Gg9UPS7ndRA?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p></figure>
<p>The chamber can apply coatings of different reflective materials alone or in combinations. It took a lot of work to determine the perfect coating for reflectivity and durability. Researchers tested different coatings on a steel stand-in mirror. </p>
<p>The first layer was an adhesive layer of nickel-chromium. Next came an incredibly thin layer of silver weighing only 64 grams spread over the 8.4-meter mirror. On top of that, another nickel-chromium adhesive layer, then a protective layer of silicon nitride to shield the reflective layer. </p>
<p>The person in charge of these precision coatings is Tomislav Vucina, the Senior Coating Engineer. Vucina describes the coatings as a balancing act. “This outer layer needs to be thick enough that it’s not worn off by cleaning,” said Vucina, “but not so thick that it absorbs too many photons and prevents the mirror from meeting Rubin’s scientific requirements.”</p>
<figure><img loading="lazy" decoding="async" width="1024" height="678" src="https://www.universetoday.com/wp-content/uploads/2024/05/noirlab2411a-1024x678.jpg" alt="This image shows the Rubin Observatory's 8.4-meter combined primary/tertiary mirror after being coated with protected silver in April 2024. The reflective coating was applied using the observatory's onsite coating chamber, which will also be used to re-coat the mirror as necessary during Rubin's 10-year Legacy Survey of Space and Time. Image Credit: RubinObs/NOIRLab/NSF/AURA" srcset="https://www.universetoday.com/wp-content/uploads/2024/05/noirlab2411a-1024x678.jpg 1024w, https://www.universetoday.com/wp-content/uploads/2024/05/noirlab2411a-580x384.jpg 580w, https://www.universetoday.com/wp-content/uploads/2024/05/noirlab2411a-250x166.jpg 250w, https://www.universetoday.com/wp-content/uploads/2024/05/noirlab2411a-768x509.jpg 768w, https://www.universetoday.com/wp-content/uploads/2024/05/noirlab2411a.jpg 1280w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>This image shows the Rubin Observatory’s 8.4-meter combined primary/tertiary mirror after being coated with protected silver in April 2024. The reflective coating was applied using the observatory’s onsite coating chamber, which will also be used to re-coat the mirror as necessary during Rubin’s 10-year Legacy Survey of Space and Time. Image Credit: RubinObs/NOIRLab/NSF/AURA</figcaption></figure>
<p>Until these coatings were applied, the glass was just glass. Highly specialized glass, but glass nonetheless. Now that the glass has received its reflective silver coating, it’s truly a mirror. </p>
<p>The application process took only 4.5 hours, nothing compared to the 7 years required to build the primary/tertiary mirror. Vucina and his team subjected the mirror to a battery of tests: reflectivity, adhesion, pinhole, and cosmetic. According to Vucina, the application process was successful.</p>
<p>“This was a very well-conducted project from every angle,” said Vucina, “thanks to a combination of careful planning and the technical skills of our excellent team.”</p>
<p>It’s been a long road to completion for the VRO. But after a long wait, first light is rapidly approaching. Excitement and anticipation for the observatory’s unique and powerful scientific contribution is growing. Its main output is the decade-long <a href="https://kipac.stanford.edu/research/projects/vera-rubin-observatorys-legacy-survey-space-and-time">Legacy Survey of Space and Time</a>. </p>
<p>“We’re extremely excited that both mirrors are now coated and will be installed on the telescope very soon,” said Sandrine Thomas, Deputy Director for Rubin Construction. “The combined reflectivity of these mirrors will enable Rubin to detect very faint and far-away objects, leading to great science!”</p>
 </div>
 
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Superfest – The almost unbreakable East German Glass (2021) (154 pts)]]></title>
            <link>https://digitalcosmonaut.com/superfest-ceverit-glass-ddr/</link>
            <guid>40260399</guid>
            <pubDate>Sat, 04 May 2024 21:24:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digitalcosmonaut.com/superfest-ceverit-glass-ddr/">https://digitalcosmonaut.com/superfest-ceverit-glass-ddr/</a>, See on <a href="https://news.ycombinator.com/item?id=40260399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><mark>While most can and will consider German reunification a “success story”, the merger of the two German states also meant the loss of identity, purpose, and direction for many. There are plenty of articles, books and documentaries out there which deal with the subject of East German identity far better than I ever could – but I inadvertently came across some GDR Lab Beakers which sent me down an East German rabbit hole. I emerged a few days later with a box full of Superfest Gläser – a nearly unbreakable and forgotten glass from East Germany.</mark></p>


<div id="ez-toc-container">

<nav><ul><li><a href="#Ostalige_and_Capitalism" title="Ostalige and Capitalism">Ostalige and Capitalism</a></li><li><a href="#Superfest_%E2%80%93_Innovation_through_necessity" title="Superfest – Innovation through necessity">Superfest – Innovation through necessity</a></li><li><a href="#Ceverit_%E2%80%93_an_East_German_success" title="Ceverit – an East German success">Ceverit – an East German success</a></li><li><a href="#Superfest_%E2%80%93_a_design_icon" title="Superfest – a design icon">Superfest – a design icon</a></li><li><a href="#Capitalism_has_no_need_for_durability" title="Capitalism has no need for durability">Capitalism has no need for durability</a></li></ul></nav></div>




<h2><span id="Ostalige_and_Capitalism"></span>Ostalige and Capitalism<span></span></h2>



<div><p><mark>It all started when I was browsing through some film developing chemicals at one of my preferred photo shops (</mark><a aria-label="Fotoimpex (opens in a new tab)" href="https://www.fotoimpex.de/" target="_blank" rel="noreferrer noopener nofollow">Fotoimpex</a><mark>). They usually have a small table near the back wall with discounted products and the odd junk that they are trying to sell off. Now this table greeted me with the smiling face of Erich Honecker. Upon closer inspection I realized they were selling off some east German lab beakers for €10, happily advertising them with “Made in GDR” and a picture of Honecker. </mark></p><p><mark>While I’m sure that the beakers themselves were probably of good quality, they were nowhere near worth €10 a pop. The combination of Made in GDR and the <a href="https://digitalcosmonaut.com/honeckers-window/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Honecker</a> photo made it quite clear to me that they were purely meant for gullible tourists looking for a bit of ostalgie. </mark></p></div>


<div>
<figure><img loading="lazy" decoding="async" width="2560" height="2560" src="https://i1.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?fit=600%2C600&amp;ssl=1" alt="fotoimpex berlin alte schoenhauser str DDR glas erich honecker beaker" srcset="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?w=2560&amp;ssl=1 2560w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?resize=2048%2C2048&amp;ssl=1 2048w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?resize=2000%2C2000&amp;ssl=1 2000w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?resize=585%2C585&amp;ssl=1 585w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?resize=1170%2C1170&amp;ssl=1 1170w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/fotoimpex-berlin-alte-schoenhauser-str-DDR-glas-erich-honecker-scaled.jpg?w=1860&amp;ssl=1 1860w" sizes="(max-width: 930px) 100vw, 930px"></figure></div>


<p><mark>Everybody’s got their hustle – so fair game if they manage to sell them off. After I left the shop my mind wandered and I began thinking about those beakers. What if they WERE special? Were they Pyrex? Did they even have Pyrex in the GDR? I’m no glass or lab expert, how would I know if they weren’t some amazing relic from the past? I began reading up a bit into the beakers, and it turns out I was right: at €10 a piece they were massively overpriced. </mark></p>



<figure><img loading="lazy" decoding="async" width="800" height="538" src="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/Fotothek_df_roe-neg_0006350_001_Besucher_vor_dem_Messestand__JENAer_Glas_.jpg?resize=800%2C538&amp;ssl=1" alt="Stand von Jenaer Glas auf der Leipziger Messe (Rössing, Sep. 1952)" srcset="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/Fotothek_df_roe-neg_0006350_001_Besucher_vor_dem_Messestand__JENAer_Glas_.jpg?w=800&amp;ssl=1 800w, https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/Fotothek_df_roe-neg_0006350_001_Besucher_vor_dem_Messestand__JENAer_Glas_.jpg?resize=768%2C516&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1"><figcaption>Stand von Jenaer Glas auf der Leipziger Messe (Rössing, Sep. 1952)<br>Von Deutsche Fotothek‎, CC BY-SA 3.0 de, https://commons.wikimedia.org/w/index.php?curid=7953489</figcaption></figure>



<p>A quick look at eBay will tell you that you can find an entire set of these glasses for the same price. What I also found out was that these beakers were made of Borosilicate glass (invented by German glassmaker&nbsp;<a href="https://en.wikipedia.org/wiki/Otto_Schott" target="_blank" rel="nofollow noopener"><strong>Otto Schott</strong></a>&nbsp;in the late 19th century in&nbsp;Jena) and are known to the English speaking world as Pyrex. The heat resistant glass was marketed from the 1920s onward as JENAer GLAS, and was a household name as it was produced both for industrial and home uses.</p>



<h2><span id="Superfest_%E2%80%93_Innovation_through_necessity"></span>Superfest – Innovation through necessity<span></span></h2>



<div><p>Having fallen down the rabbit hole of Jenaer Glass, I soon stumbled upon&nbsp;German term which I had not heard of before: Superfest.</p><p>What sounds like a German music festival, is actually the name of a genius east German glass invention, a glass which could last up to 15 times longer than normal glass. The origins of Superfest, literally SuperHard – were twofold. East Germany was always a frugal country with a mindset of not wasting the limited resources it had, and it was driven by technological advances. </p></div>


<div>
<figure><img decoding="async" src="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/ddr-glas-superfest-ceverit-bierglas-logo-ost-deutschland.jpg?resize=899%2C600&amp;ssl=1" alt="ddr glas superfest ceverit bierglas logo ost deutschland" data-recalc-dims="1"></figure></div>


<p>While the <a href="https://digitalcosmonaut.com/national-emblem-german-democratic-republic/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">German Democratic Republic</a> might suffer from the stigma today that it was technologically backward (which was true for certain fields), it was a creative and adaptive country which produced world class products and technology that’s still in use today (many of today’s planetariums are still equipped by technology invented in the GDR).</p>



<p>East German pubs and restaurants suffered from a problem, which every pub and restaurant around the world had to deal with – their drinking glasses kept on breaking. This wasn’t a unique east German or socialist problem (in fact, east Germany inherited a long tradition of superb glass making skills after the war) – it was just a common occurrence of wear and tear. </p>



<p><mark>With the advancement in glass making technology, East Germany developed a doctrine (which actually applied to all industry fields) in which it sought to use its own resources rather than import them from the outside, secure and satiate the home market, improve the glass properties to prolong product life, save energy, materials and labor through the longer life of glass products, increase international reputation by developing new production processes, and make some hard currency through the sales of licenses and property rights. Who knew that glass making could sound so important to a national economy.  </mark></p>



<h2><span id="Ceverit_%E2%80%93_an_East_German_success"></span>Ceverit – an East German success<span></span></h2>



<p>The Zentralinstitut für anorganische Chemie (Central Institute for Inorganic Chemistry) in Adlershof, Berlin began its research into hardening glass, specifically through the Ion-exchange process in the late 1960s. Patents for hardening glass through this ion exchange process were granted to the VEB Kombinat Technisches Glas in Ilmenau. This research was then expanded on in 1973 in Bad Muskau by Dr. S.Schelinski, Dr. D. Patzig, K. Heinrich and B. Grueger. They set up small and the large scale testing facilities, which coincided with the delivery of a glass blowing / forming machine from Japan in 1975.  </p>


<div>
<figure><img decoding="async" src="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/ddr-glas-superfest-ceverit-bierglas-ost-deutschland.jpg?resize=400%2C600&amp;ssl=1" alt="ddr glas superfest ceverit bierglas ost deutschland" data-recalc-dims="1"></figure></div>


<p>Quick detour: Did you know that Bad Muskau is home to the <a rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Hermann,_F%C3%BCrst_von_P%C3%BCckler-Muskau" target="_blank">Fürst-Pückler-Park Bad Muskau</a>, a UNESCO World Heritage site? The park was created by (or better for) Prince Hermann Ludwig Heinrich von Pückler-Muskau also more commonly known as Fürst Pückler. While many english speakers might be familiar with “Neopolitan Ice Cream” – it was actually invented by the Royal Prussian court cook Louis Ferdinand Jungius in 1839, and named after Fürst Pückler. To this day, the ice cream is known as Fürst Pückler Eis in Germany.  </p>



<p>By 1977, Dr. Patzig and his colleagues achieved their breakthrough. They developed and patented a chemical process that made thin-walled glasses (at least 5 times) less prone to breaking than conventional ones. The team built on the research from the Institute in Adlershof, and created a new commercially viable process to produce what was dubbed CV Glass (Chemically Hardened Glass).  </p>



<figure><p><span><iframe loading="lazy" width="930" height="524" src="https://www.youtube.com/embed/o_xABUPF0r4?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p></figure>



<p>During the first stage, the glass would be produced like every other normal glass – with machines cooling the glass and sanding off the edges etc. After this process, the glasses would be loaded off into a specialized glass holding machine (a one-off custom construction) which would then shuffle the glasses off to be heated back up to a temperature of 420C. </p>



<p>The heated glasses would then be sprayed with a specialized potassium chloride solution that fused with the glass surface. This Potassium chloride solution filled in the micro ruptures within the glass that naturally occur during glass production, making the glass less prone to breaking. And that’s the whole process of “Ion Exchanging”. A unique feature of this hardened glass was that it bounced when you dropped it, essentially giving you a second chance to catch the glass.  </p>



<p> This newly created glass was then called “Ceverit”. Ce stood for Chemisch (Chemically), “ver” for verfestigt (hardened) and the “it” stood for the silica component. </p>



<h2><span id="Superfest_%E2%80%93_a_design_icon"></span>Superfest – a design icon<span></span></h2>



<p><mark>At the same time, the Generalkollektiv under Paul Bittner, Fritz Keuchel and Tilo Poitz set out to design a universally versatile glass. It needed to be as light as possible, take up as little space as possible and be as durable as could be.&nbsp;</mark></p>



<p><mark>By 1978, the Generalkollektiv came up with a glass that essentially ushered in a new standard of “catering” glass in the GDR. They had come up with a newly patented way to reduce the weight and increase the durability of the glass by introducing a special salt in the production process. The design and practicality of the glasses, especially their stackability (earning them the nickname stapelglas) was even recognized by the GDR, earning itself the “Good Design” award in 1980.&nbsp;</mark></p>


<div>
<figure><img decoding="async" src="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/gestapelt-ddr-glas-superfest-ceverit-bierglas-logo-ost-deutschland.jpg?resize=400%2C600&amp;ssl=1" alt="gestapelt ddr glas superfest ceverit bierglas logo ost deutschland" data-recalc-dims="1"></figure></div>


<p><mark>So, with the design and the chemical process in place, the Ministry for Glass and Ceramic Industries gave the order to expand the glass production plant in Schewpnitz with a new production hall. A total of one million marks was made available, and Ceverit glass production began in April 1980. <p>  An estimated 110 million glasses were produced in all shapes and sizes in the following 10 years, ranging from shot glasses to half liter beer glasses. Interestingly enough – the name Ceverit was phased out before production began and replaced with “Superfest (Super Hard), as someone noticed that “Ceverit” was a conjugated form of the Latin word “cevere”, which translates to “wiggling your butt while having sex”. Opportunity missed in my opinion.</p></mark></p>



<h2><span id="Capitalism_has_no_need_for_durability"></span>Capitalism has no need for durability<span></span></h2>



<p>Despite their commercial success in East Germany, the production plant in Schewpnitz was shut down on the 1st of July, 1990. After German reunification, the plant was sold off and scrapped piece by piece – as no manufacturer had any interest in the technology, or in a product which would actually “slow down” sales. And that’s (just one of many small) tragedies of German reunification. Superfest was an invention that maybe could have only been made under a “socialist” system – it was a product that solved a problem, but wasn’t dependent on inflated sales figure due planned obsolescence.</p>


<div>
<figure><img decoding="async" src="https://i0.wp.com/digitalcosmonaut.com/wp-content/uploads/2020/03/drei-ceverit-glaeser-ddr-glas-superfest-ceverit-bierglas-ost-deutschland.jpg?resize=618%2C600&amp;ssl=1" alt="drei ceverit glaeser ddr glas superfest ceverit bierglas ost deutschland" data-recalc-dims="1"></figure></div>


<p><mark>While commercial manufactures might not be interested in producing a glass that’s more durable, pub owners and users of Superfest glasses swear on the product. Thankfully they were produced in such quantities that they can still be found for reasonable prices online and in flea markets. Grab them while you can – they won’t be available forever. </mark></p>



<p><mark><strong> Epilogue<br></strong> While the Superfest glass is by far more durable than normal glass, when they shatter – the burst into a million fine pieces and are a total nightmare to clean up. I’m not sure if it’s because of their potassium chloride coating or because they are made to be super thin, my advice is to not drop them.&nbsp;</mark></p>



<figure><p><span><iframe loading="lazy" width="930" height="524" src="https://www.youtube.com/embed/S7VOiqe6cH4?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p><figcaption>After dropping the glass for the 5th time to get the right shot – it finally couldn’t handle anymore abuse</figcaption></figure>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: gpudeploy.com – "Airbnb" for GPUs (235 pts)]]></title>
            <link>https://www.gpudeploy.com</link>
            <guid>40260259</guid>
            <pubDate>Sat, 04 May 2024 21:03:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gpudeploy.com">https://www.gpudeploy.com</a>, See on <a href="https://news.ycombinator.com/item?id=40260259">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><nav></nav></header><main><h2>Low-cost on-demand GPUs for machine learning and AI</h2><h2>Launch immediately, preconfigured for Machine Learning tasks.</h2><a aria-label="Launch GPU instance" href="https://www.gpudeploy.com/launch"></a></main><section><hr><h2>Pricing</h2><h2>Available on-demand configurations.</h2><div><div><p>GPUs</p><p>GPU RAM</p><p>CUDA cores</p><p>vCPUs</p><p>Price*</p><p>Launch</p></div><div><p>8x Nvidia H100 SXM</p><p>640GB</p><p>116736</p><p>242</p></div><div><p>1x Nvidia H100 SXM</p><p>80GB</p><p>14592</p><p>32</p></div><div><p>1x Nvidia H200</p><p>80GB</p><p>14592</p><p>32</p></div><div><p>1x Nvidia GeForce GTX 1080 Ti</p><p>11GB</p><p>3584</p><p>16</p></div><div><p>8x Nvidia A100 SXM</p><p>320GB</p><p>55296</p><p>242</p></div><div><p>2x Nvidia A100 SXM</p><p>80GB</p><p>13824</p><p>72</p></div><div><p>1x Nvidia A100 SXM</p><p>40GB</p><p>6912</p><p>32</p></div><div><p>1x Nvidia GeForce RTX 4090</p><p>24GB</p><p>16384</p><p>16</p></div><div><p>1x Nvidia GeForce RTX 3060</p><p>12GB</p><p>3584</p><p>16</p></div><div><p>1x Nvidia Quadro RTX 6000</p><p>24GB</p><p>4608</p><p>16</p></div><p>*excluding sales tax, final rate is usually lower.</p></div><p><a href="https://www.gpudeploy.com/launch/reserve"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"></path></svg>&nbsp;&nbsp;Look for custom configurations and clusters</a></p></section><section><hr><h2>Earn</h2><h2>Have idle GPUs? The world needs your compute.</h2><a href="https://www.gpudeploy.com/connect"><p>I operate a GPU cluster</p><p>My AI company wants to rent out idle compute</p><p>I have a GPU</p></a></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Atari's Mike Jang (230 pts)]]></title>
            <link>https://arcadeblogger.com/2024/02/13/ataris-mike-jang/</link>
            <guid>40260210</guid>
            <pubDate>Sat, 04 May 2024 20:56:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/">https://arcadeblogger.com/2024/02/13/ataris-mike-jang/</a>, See on <a href="https://news.ycombinator.com/item?id=40260210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>Some sad news to report on the blog this week. I got word that long-time Industrial Designer at Atari coin-operated division, Mike Jang, has passed away.</p>



<p>I’ve known Mike since 2016, and whilst we never met, he was always on the other end of an email answering my questions and providing really valuable input into my articles here on the blog, and especially so for my book <em>Missile Commander</em>. Mike has always been approachable and happy to share his knowledge and deep insight into the industrial design processes at Atari.</p>



<p>Learning his craft at San Jose State University, Mike joined Atari’s Industrial Design team during the mid 70s and remained there through the eighties. This meant he was fortunate enough to witness the explosion of Atari’s fortunes right through the Golden Age of arcade videogaming. He was right there in the engine room of Atari contributing to the coin-op division’s game output. </p>



<p>As an Industrial Designer, his main role was to refine the ergonomics of arcade cabinets – he was a big advocate of making sure that the physical interface players used to interact with Atari’s game cabinets was just right; and if that meant bespoke controls, parts and mouldings were required, then he would push the company to make it happen. He brought his own artistic flair to his design work, creating some of the most iconic cabinets from the era.</p>


<div>
<figure><img data-attachment-id="35772" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/mike-jang-1/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg" data-orig-size="918,999" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mike Jang 1" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg?w=276" data-large-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg?w=918" width="918" height="999" src="https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg?w=918" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg 918w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg?w=88 88w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg?w=276 276w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-1.jpg?w=768 768w" sizes="(max-width: 918px) 100vw, 918px"><figcaption>Mike Jang at work here. I believe that was an unreleased kiosk of some kind, intended for installation at MacDonald’s outlets across the USA. The project never came to fruition</figcaption></figure></div>


<p>It is very easy to take for granted some of Atari’s cabinet design choices, but all were deeply thought through by Mike and his team, extensively tested and then produced – mostly in-house – resulting in the most varied portfolio of arcade cabinets ever produced by one manufacturer. Atari were the industry leaders in this regard by a country mile. Mike’s work was extensive and he was responsible for many of Atari’s patents, made in his name.</p>



<p>This picture was taken in 1981. Mike is captured here discussing the design of Atari’s <em>Asteroids Deluxe</em> cabinet with colleague Dave Cook:</p>


<div>
<figure><img data-attachment-id="35771" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/mike-jang-dave-cook-2/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg" data-orig-size="1366,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mike Jang Dave Cook 2" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=200" data-large-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=1366" loading="lazy" width="1366" height="2048" src="https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=1366" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg 1366w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=64 64w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=200 200w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=768 768w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-dave-cook-2.jpg?w=1024 1024w" sizes="(max-width: 1366px) 100vw, 1366px"><figcaption>Mike is on the right, discussing Asteroids Deluxe with fellow designer Dave Cook at Atari’s offices</figcaption></figure></div>


<p>Mike had the opportunity to fly to Atari Ireland to oversee the initial production of one his cabinets, <em>Roadblasters</em>. Whilst there, he shared these photographs with me that he personally took at the Tipperary facility:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:3810034,&quot;permalink&quot;:&quot;https:\/\/arcadeblogger.com\/2024\/02\/13\/ataris-mike-jang\/&quot;}">
<figure><img data-attachment-id="35788" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/26671880789_372994a42e_z-2/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg" data-orig-size="640,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="26671880789_372994a42e_z" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg?w=640" loading="lazy" width="640" height="480" data-id="35788" src="https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg?w=640" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg 640w, https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/26671880789_372994a42e_z.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<figure><img data-attachment-id="35789" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/38448145871_a4ca73a687_z-2/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg" data-orig-size="640,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="38448145871_a4ca73a687_z" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg?w=640" loading="lazy" width="640" height="480" data-id="35789" src="https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg?w=640" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg 640w, https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/38448145871_a4ca73a687_z.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<figure><img data-attachment-id="35790" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/38392311716_4aa355d969_z-2/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg" data-orig-size="640,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="38392311716_4aa355d969_z" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg?w=640" loading="lazy" width="640" height="480" data-id="35790" src="https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg?w=640" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg 640w, https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/38392311716_4aa355d969_z.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>
<figcaption>Mike’s photographs of Asteroids Deluxe cabinets on the factory floor at Atari Ireland. Click for larger images</figcaption></figure>



<p>I documented in my book the extensive work that Mike put into the original design of the <em>Missile Command</em> prototype cabinet. He had this to say:</p>



<blockquote>
<p>Arcade games were pre-CAD so we drew up the cabinet with drafting tables, pencil, and paper. Each piece of wood or plastic was drawn and sent to the engineering woodshop to be built. Metal parts went to another in house shop. Everything was done inside our building so as to keep the game secret from the competition.</p>
<cite>Extract from interview with Mike Jang discussing the industrial design process at Atari</cite></blockquote>



<figure data-carousel-extra="{&quot;blog_id&quot;:3810034,&quot;permalink&quot;:&quot;https:\/\/arcadeblogger.com\/2024\/02\/13\/ataris-mike-jang\/&quot;}">
<figure><img data-attachment-id="35823" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/atari_industrial_design_workspace/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg" data-orig-size="344,498" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Atari_Industrial_Design_Workspace" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg?w=207" data-large-file="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg?w=344" loading="lazy" width="344" height="498" data-id="35823" src="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg?w=344" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg 344w, https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg?w=66 66w, https://missilecommand.files.wordpress.com/2024/02/atari_industrial_design_workspace.jpg?w=207 207w" sizes="(max-width: 344px) 100vw, 344px"></figure>



<figure><img data-attachment-id="35822" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/atari_industrial_designer_work_station/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg" data-orig-size="486,324" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Atari_Industrial_Designer_Work_Station" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg?w=486" loading="lazy" width="486" height="324" data-id="35822" src="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg?w=486" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg 486w, https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/atari_industrial_designer_work_station.jpg?w=300 300w" sizes="(max-width: 486px) 100vw, 486px"></figure>
<figcaption>The workspace at Atari Industrial Design where Mike Jang worked in the 70s and 80s</figcaption></figure>



<p>Mike sketched out the initial ideas for <em>Missile Command</em>, based on US military nuclear consoles – keeping the vibe relevant to the game’s subject matter:</p>


<div>
<figure><img data-attachment-id="35840" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/atariart32-2/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="atariart32" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg?w=800" loading="lazy" width="800" height="600" src="https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg?w=800" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg 800w, https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/atariart32.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>Mike Jang’s initial sketch of his vision for the Missile Command cabinet</figcaption></figure></div>


<blockquote>
<p>The first main goal is to build a game that is put out for testing. Usually only one was built since one never knew if it will make mega bucks or no bucks. If the first test goes good, we might build and test more. That was a sales and marketing call. If it tested good, there would be a big push to go into production as soon as possible. Reason being, unscrupulous companies would spot a game on test and start making their own illegal copies. It’s better to get the game out and sell as many as possible before the copiers showed up. That was more cost effective than going to court and sue.</p>
<cite>Extract from interview with Mike Jang discussing the industrial design process at Atari</cite></blockquote>


<div>
<figure><img data-attachment-id="35825" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/screenshot-2024-02-12-220737/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png" data-orig-size="612,1238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-02-12 220737" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png?w=148" data-large-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png?w=612" loading="lazy" width="612" height="1238" src="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png?w=612" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png 612w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png?w=47 47w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-220737.png?w=148 148w" sizes="(max-width: 612px) 100vw, 612px"><figcaption>Missile Command prototype cabinet</figcaption></figure></div>


<p>When the original <em>Missile Command</em> cabinet came back from testing with negative feedback about the large marquee, he went back to his design sketch and made a pretty dramatic change:</p>


<div>
<figure><img data-attachment-id="35798" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/cof-106/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg" data-orig-size="2667,2436" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;EVA-L09&quot;,&quot;caption&quot;:&quot;cof&quot;,&quot;created_timestamp&quot;:&quot;1510760687&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.5&quot;,&quot;iso&quot;:&quot;160&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;cof&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cof" data-image-description="" data-image-caption="<p>cof</p>
" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=2667" loading="lazy" width="2667" height="2436" src="https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=2667" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg 2667w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=105 105w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=768 768w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-cabinet-edits-1.jpg?w=1024 1024w" sizes="(max-width: 2667px) 100vw, 2667px"><figcaption>The large marquee had to go! Notice the new red lines on this cabinet draft, outlining the proposed shape of the production version of Missile Command that we are familiar with today</figcaption></figure></div>


<p>As you can see, a key part of Mikes job, was to provide solutions to problems arising from creating arcade cabinets, testing hardware, either internally or out in the field, inevitably creates issues that will need fixing, requiring the industrial design team to go back to the drawing board to amend their initial creations. This would be a pretty thankless task as you can imagine, but Mike was happy to oblige most requests.</p>



<blockquote>
<p>I didn’t interact with Mike Jang a great deal, but when I was doing temperature testing of the games and found the temperature inside was too high Mike didn’t have a problem putting in a vent, sometimes an extra vent, and sometimes a fan.</p>
<cite>Jed Margolin, Atari engineer and colleague</cite></blockquote>



<p>Here are some more cabinet designs that Mike was responsible for during his time at Atari:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:3810034,&quot;permalink&quot;:&quot;https:\/\/arcadeblogger.com\/2024\/02\/13\/ataris-mike-jang\/&quot;}">
<figure><img data-attachment-id="35776" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/305630749_6040524405961898_8090420364968926770_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg" data-orig-size="1310,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="305630749_6040524405961898_8090420364968926770_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=192" data-large-file="https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=1310" loading="lazy" width="1310" height="2048" data-id="35776" src="https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=1310" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg 1310w, https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=61 61w, https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=192 192w, https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=768 768w, https://missilecommand.files.wordpress.com/2024/02/305630749_6040524405961898_8090420364968926770_n.jpg?w=1024 1024w" sizes="(max-width: 1310px) 100vw, 1310px"></figure>



<figure><img data-attachment-id="35775" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/51942466_10157043420132375_3517986692583653376_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg" data-orig-size="720,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="51942466_10157043420132375_3517986692583653376_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg?w=225" data-large-file="https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg?w=720" loading="lazy" width="720" height="960" data-id="35775" src="https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg?w=720" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg 720w, https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg?w=72 72w, https://missilecommand.files.wordpress.com/2024/02/51942466_10157043420132375_3517986692583653376_n.jpg?w=225 225w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<figure><img data-attachment-id="35774" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/attachment/1457953614/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg" data-orig-size="850,1118" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1457953614" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg?w=228" data-large-file="https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg?w=850" loading="lazy" width="850" height="1118" data-id="35774" src="https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg?w=850" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg 850w, https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg?w=73 73w, https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg?w=228 228w, https://missilecommand.files.wordpress.com/2024/02/1457953614.jpg?w=768 768w" sizes="(max-width: 850px) 100vw, 850px"></figure>
<figcaption>One of Mike’s earliest patented cabinet designs was Starship 1, released in 1976. You can click these images for larger versions</figcaption></figure>


<div>
<figure><img data-attachment-id="35803" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/1915266_106106906070374_1639556_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg" data-orig-size="412,604" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1915266_106106906070374_1639556_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg?w=205" data-large-file="https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg?w=412" loading="lazy" width="412" height="604" src="https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg?w=412" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg 412w, https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg?w=65 65w, https://missilecommand.files.wordpress.com/2024/02/1915266_106106906070374_1639556_n.jpg?w=205 205w" sizes="(max-width: 412px) 100vw, 412px"><figcaption>The United States patent for the Hard Drivin’ video game cabinet design</figcaption></figure></div>

<div>
<figure><img data-attachment-id="35805" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/1915572_100710496610015_2512117_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg" data-orig-size="604,463" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1915572_100710496610015_2512117_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg?w=604" loading="lazy" width="604" height="463" src="https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg?w=604" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg 604w, https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg?w=125 125w, https://missilecommand.files.wordpress.com/2024/02/1915572_100710496610015_2512117_n.jpg?w=300 300w" sizes="(max-width: 604px) 100vw, 604px"><figcaption>Another of Jang’s creations was the Star Wars cockpit design</figcaption></figure></div>


<p>I spoke to Mike about his work on the <em>Star Wars</em> cabinet, and he had this to say:</p>



<blockquote>
<p>I started the concepts for the Star Wars cabinet and later another designer did more detailed work on the plastic part in front of the monitor. One of the main elements I sketched up were the hydraulic ram shapes on the plastic parts. Those rams were often seen in the movie, especially the ramp to the Millennium Falcon. Also I wanted to continue the mechanical theme by adding that truss style design to the sides of the roof. I was concerned because that was a particle board part that was cut with an angled router bit. Then the bare particle board was just painted black. I was worried about the wood texture appearance but nobody noticed after everything else was put in place.</p>
<cite>Mike Jang discussing Star Wars cabinet design</cite></blockquote>


<div>
<figure><img data-attachment-id="35807" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/screenshot-2024-02-12-213207/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png" data-orig-size="1834,1322" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-02-12 213207" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=1834" loading="lazy" width="1834" height="1322" src="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=1834" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png 1834w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=768 768w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-213207.png?w=1024 1024w" sizes="(max-width: 1834px) 100vw, 1834px"><figcaption>Atari’s Star Wars production cockpit cabinet</figcaption></figure></div>


<figure data-carousel-extra="{&quot;blog_id&quot;:3810034,&quot;permalink&quot;:&quot;https:\/\/arcadeblogger.com\/2024\/02\/13\/ataris-mike-jang\/&quot;}">
<figure><img data-attachment-id="35810" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/359151423_7025571480790514_7934426320230909885_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg" data-orig-size="708,548" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="359151423_7025571480790514_7934426320230909885_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg?w=708" loading="lazy" width="708" height="548" data-id="35810" src="https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg?w=708" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg 708w, https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg?w=124 124w, https://missilecommand.files.wordpress.com/2024/02/359151423_7025571480790514_7934426320230909885_n.jpg?w=300 300w" sizes="(max-width: 708px) 100vw, 708px"></figure>



<figure><img data-attachment-id="35809" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/49330210007_29caedb88a_c-2/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;CLT-L29&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1573659449&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="49330210007_29caedb88a_c" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg?w=800" loading="lazy" width="800" height="600" data-id="35809" src="https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg?w=800" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg 800w, https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/49330210007_29caedb88a_c.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"></figure>
<figcaption>Atari Stun Runner. Click for bigger pics</figcaption></figure>



<figure data-carousel-extra="{&quot;blog_id&quot;:3810034,&quot;permalink&quot;:&quot;https:\/\/arcadeblogger.com\/2024\/02\/13\/ataris-mike-jang\/&quot;}">
<figure><img data-attachment-id="35813" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/306753342_6045756535438685_1537333178007629738_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg" data-orig-size="544,367" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="306753342_6045756535438685_1537333178007629738_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg?w=544" loading="lazy" width="544" height="367" data-id="35813" src="https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg?w=544" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg 544w, https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/306753342_6045756535438685_1537333178007629738_n.jpg?w=300 300w" sizes="(max-width: 544px) 100vw, 544px"></figure>



<figure><img data-attachment-id="35812" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/66boxa0/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg" data-orig-size="800,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="66boXa0" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg?w=800" loading="lazy" width="800" height="480" data-id="35812" src="https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg?w=800" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg 800w, https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/66boxa0.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"></figure>
<figcaption>Atari’s ultimately doomed Starfighter cabinet. Designed and partially completed in 1984, the game was never released, but made it into the film of the same name. Click for larger versions of these images</figcaption></figure>


<div>
<figure><img data-attachment-id="35815" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/screenshot-2024-02-12-214648/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png" data-orig-size="1960,1320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-02-12 214648" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=1960" loading="lazy" width="1960" height="1320" src="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=1960" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png 1960w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=768 768w, https://missilecommand.files.wordpress.com/2024/02/screenshot-2024-02-12-214648.png?w=1024 1024w" sizes="(max-width: 1960px) 100vw, 1960px"><figcaption>Here’s Mike’s concept drawing of Atari’s RoadBlasters cabinet. The final production cabinet remained pretty true to this sketch. This was the cabinet that Mike travelled to Atari Ireland to oversee during early production for the European market. “I went with Dave Cook to Ireland, we both had a project starting in the Ireland factory. So we were sent to solve any problems that might come up. They were sent the paper printouts of the cabinet parts to be made. We visited the wood shop that was building the first proto RoadBlaster. The cabinet looked great so we had no problems there”</figcaption></figure></div>

<div>
<figure><img data-attachment-id="35827" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/roofless-driver-5/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg" data-orig-size="2737,2251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roofless driver 5" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=2737" loading="lazy" width="2737" height="2251" src="https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=2737" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg 2737w, https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=117 117w, https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=300 300w, https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=768 768w, https://missilecommand.files.wordpress.com/2024/02/roofless-driver-5.jpg?w=1024 1024w" sizes="(max-width: 2737px) 100vw, 2737px"><figcaption>A roofless cockpit driving cabinet – intended for use in an eventually shelved laser disc game called Malibu Grand Prix</figcaption></figure></div>


<p>Another two games that spring to mind are <em>Firefox</em>, where Mike was responsible for the control panel design, and <em>Hydra </em>which used one of Mike’s full cabinet sketches. </p>



<p>His full discography of arcade cabinet design is too extensive to cover here, but his work spanned almost two decades and was extremely varied as you can see. </p>



<p>Post Atari, Mike was big on Hot Rodding and took his design skills to mock up car designs. Here is his 1951 Mercury coupe that he acquired in 1989 and spent many hours meticulously customising. He still owned this car right up to his passing:</p>


<div>
<figure><img data-attachment-id="35836" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/66922_601032559911137_1659921369_n/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg" data-orig-size="600,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="66922_601032559911137_1659921369_n" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg?w=300" data-large-file="https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg?w=600" loading="lazy" width="600" height="400" src="https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg?w=600" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg 600w, https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg?w=128 128w, https://missilecommand.files.wordpress.com/2024/02/66922_601032559911137_1659921369_n.jpg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>Mike’s passion project – his customised 1951 Mercury coupe</figcaption></figure></div>


<p>Arcadeblogger.com is a richer experience thanks to Mike’s input over the years, and my book would be a lesser tome were it not for Mike’s unique perspective and detail on the events leading up to, and after, the creation of the prototype <em>Missile Command</em> cabinet.</p>


<div>
<figure><img data-attachment-id="35833" data-permalink="https://arcadeblogger.com/2024/02/13/ataris-mike-jang/mike-jang-hercules/" data-orig-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg" data-orig-size="916,986" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mike Jang Hercules" data-image-description="" data-image-caption="" data-medium-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg?w=279" data-large-file="https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg?w=916" loading="lazy" width="916" height="986" src="https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg?w=916" alt="" srcset="https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg 916w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg?w=89 89w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg?w=279 279w, https://missilecommand.files.wordpress.com/2024/02/mike-jang-hercules.jpg?w=768 768w" sizes="(max-width: 916px) 100vw, 916px"><figcaption>Here’s a great shot of Mike, captured in 1979 demonstrating the size of Atari’s Hercules pinball cabinet</figcaption></figure></div>


<p>Although Mike is no longer with us, his design legacy does live on in some of the fantastic looking arcade hardware he created – have a look out for these machines next time you’re at an arcade, and raise a glass when you play.</p>



<p>One of the things that Mike did recently, was to donate all of his old Atari documents for archiving at Stanford University. The <em><a href="https://searchworks.stanford.edu/view/12357521" target="_blank" rel="noreferrer noopener">Michael Jang collection of Atari materials, 1978-1991</a></em> can be accessed and viewed by researchers for years to come, which is great news.</p>



<p>Mike I’m sure will be deeply missed by his Atari colleagues, who speak very highly of him as a designer, but also a friend and person; and based on my interactions with him, I would absolutely echo those sentiments here and send condolences to his family and friends.</p>



<p>I hope in a small way, this tribute highlights some of Mike’s superb work.</p>



<p>See you next time.</p>







<p>Tony</p>


	
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Dillo 3.1.0 released after 9 years (407 pts)]]></title>
            <link>https://dillo-browser.github.io/latest.html</link>
            <guid>40260035</guid>
            <pubDate>Sat, 04 May 2024 20:22:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dillo-browser.github.io/latest.html">https://dillo-browser.github.io/latest.html</a>, See on <a href="https://news.ycombinator.com/item?id=40260035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><i>Released on 2024-05-04</i></p><h2>Summary of changes</h2>

<p>Since the last release 3.0.5 from 2015 a lot of things have happened to the
Dillo project.

<a href="https://dillo-browser.github.io/img/commits-author.png">
<img alt="A plot of number of commits over time colored by authors. There is a missing gap from mid 2002 to mid 2008. And from 2017 to end of 2023 there is almost no commits." src="https://dillo-browser.github.io/img/commits-author.png">
</a>

Here is a short timeline to put things into perspective:

</p><ul>
  <li>On 2016, the main developer of the layout engine, Sebastian Geerken,
    <a href="https://groups.google.com/g/dillo/c/Kpuh3d6nNL8/">passed away</a>.</li>
  <li>On 2017, the development stopped.</li>
  <li>On 2019, the last email from Jorge Arellano Cid, the lead
    developer of Dillo,
    <a href="https://groups.google.com/g/dillo/c/UQ1nWyMa3yo/m/07qhu9KqAgAJ">was
      recorded by the mailing list</a>.</li>
  <li>On 2022, the domain <code>dillo.org</code> <a href="https://dillo-browser.github.io/dillo.org.html">was
      lost</a>.</li>
  <li>On 2024, an
    <a href="https://news.ycombinator.com/item?id=38847613">attempt to
      resurrect the project</a> began by Rodrigo
    Arias Mallo.</li>
</ul>

<p>This release contains a lot of changes accumulated from the 2015-2017 period,
as well as fixes and small features introduced in 2024. Here is a summary:
</p><ul>
  <li>Add support for floating HTML elements, which involved a big redesign.</li>
  <li>Add support for OpenSSL, LibreSSL and mbed TLS for HTTPS, which is now
    enabled by default.</li>
  <li>Add a CI pipeline to build Dillo on Ubuntu, MacOS, FreeBSD and
    Windows (via cygwin).</li>
  <li>Add automatic HTML rendering tests.</li>
  <li>Improve and extend the Dillo manual.</li>
</ul>

<p>In memory of Sebastian Geerken.</p>

<h2>Download</h2><p>

To download the release, get it from the
<a href="https://github.com/dillo-browser/dillo/releases/tag/v3.1.0">GitHub
releases</a>.

</p><h2>Detailed changes</h2><p>
This is the list of changes from the ChangeLog of this release:
</p><ul>
  <li>Patches by Sebastian Geerken:
    <ul>
      <li>Floating elements.</li>
      <li>Redesign of widget sizes ("GROWS").</li>
      <li>Applied CSS attribute 'width' to all elements, 'height' is now also
        supported.</li>
      <li>Suport for 'min-width', 'max-width', 'min-height' and 'max-height'.</li>
      <li>Suport for 'display: inline-block'.</li>
      <li>&lt;BUTTON&gt;'s are now inline.</li>
      <li>Image aspect ratio is preserved when one dimension is specified by a
        percentage value.</li>
      <li>New dillorc options 'adjust_min_width' and 'adjust_table_min_width'.</li>
      <li>Make building of test/ files more robust.</li>
      <li>Work on collapsing spaces: more cases supported.</li>
      <li>Fix crash that's possible searching for text while page still being
        built.</li>
    </ul>
  </li>
  <li>Patches by corvid:
    <ul>
      <li>HTML5 character references.</li>
      <li>Give images lower priority when requesting resources (responsiveness).</li>
      <li>Reuse of connections for HTTP (disable w/ http_persistent_conns in
        dillorc).</li>
      <li>Abort failed queries.</li>
      <li>HTTP Strict Transport Security (disable with http_strict_transport_security
        preference in dillorc).</li>
      <li>Fix bug when closing popup using window manager (bug introduced in
        3.0.3).</li>
      <li>Block mixed content.</li>
      <li>Improve cookies date recognition.</li>
      <li>Use <a href="https://tls.mbed.org/">Mbed TLS</a></li>
      <li>Iterate through the IP addrs for a host when trying to connect().</li>
    </ul>
  </li>
  <li>Patches by Jeremy Henty:
    <ul>
      <li>Doxygen fixes.</li>
    </ul>
  </li>
  <li>Patches by corvid and Benjamin Johnson:
    <ul>
      <li>Move HTTPS from dpi into the browser, enable SNI, check more locations
        for CA bundles and add --with-ca-certs-file and --with-ca-certs-dir to
        configure, some improvement to security warning popups, etc.
      </li>
    </ul>
  </li>
  <li>Patches by Johannes Hofmann:
    <ul>
      <li>Fix bookmarks DPI crash.</li>
      <li>Fix OSX compilation issue with xembed.</li>
    </ul>
  </li>
  <li>Patches by Rodrigo Arias Mallo &lt;rodarima@gmail.com&gt;:
    <ul>
      <li>Fix DuckDuckGo search links</li>
      <li>Add scroll_step option to control the mouse wheel vertical step</li>
      <li>Add support for OpenSSL 1.1, OpenSSL 3, mbedTLS 2 and mbedTLS 3</li>
      <li>Replace configure flag --enable-ssl to --enable-tls</li>
      <li>Enable TLS support by default for https.</li>
      <li>Add automatic rendering tests (only enabled with --enable-html-tests).</li>
      <li>Fix width calculation when using 'min-width' and 'max-width'.</li>
      <li>Update website URL to https://dillo-browser.github.io/</li>
      <li>Add ui_tab_height option to control the tab height. Default value increased
        from 16 to 20 pixels to improve usability.</li>
      <li>Switch tabs using the mouse wheel by default. Use the new option
        scroll_switches_tabs to disable the behavior.</li>
      <li>Fix OpenSSL handling of unexpected EOF without close notify alert.</li>
      <li>Expand home tilde '~' in the file plugin.</li>
      <li>Ignore width attribute with relative values for td and th elements.</li>
      <li>Enable Doxygen for C files and use Awesome Doxygen theme.</li>
      <li>Fix DPIs extension (.dpi.exe) in Windows systems via Cygwin.</li>
      <li>Add support for the &lt;main&gt; HTML tag.</li>
      <li>Fix W3C validator and remove broken WDG validator.</li>
      <li>Simplify bookmark DPI page style and improve readability.</li>
      <li>Improve the Dillo manual available from the help button.</li>
      <li>Improve detection of XHTML documents.</li>
      <li>Install desktop file with Dillo icon.</li>
      <li>Add version in user manual and about:splash.</li>
    </ul>
  </li>
  <li>Patches by Mark Walker:
    <ul>
      <li>Add http_force_https mode.</li>
    </ul>
  </li>
</ul>

</div></div>]]></description>
        </item>
    </channel>
</rss>