<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 25 Mar 2024 07:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Format Dialog in Windows NT (129 pts)]]></title>
            <link>https://twitter.com/davepl1968/status/1772042158046146792</link>
            <guid>39811604</guid>
            <pubDate>Sun, 24 Mar 2024 23:52:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/davepl1968/status/1772042158046146792">https://twitter.com/davepl1968/status/1772042158046146792</a>, See on <a href="https://news.ycombinator.com/item?id=39811604">Hacker News</a></p>
Couldn't get https://twitter.com/davepl1968/status/1772042158046146792: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[“Emergent” abilities in LLMs actually develop gradually and predictably – study (114 pts)]]></title>
            <link>https://www.quantamagazine.org/how-quickly-do-large-language-models-learn-unexpected-skills-20240213/</link>
            <guid>39811155</guid>
            <pubDate>Sun, 24 Mar 2024 22:36:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/how-quickly-do-large-language-models-learn-unexpected-skills-20240213/">https://www.quantamagazine.org/how-quickly-do-large-language-models-learn-unexpected-skills-20240213/</a>, See on <a href="https://news.ycombinator.com/item?id=39811155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Two years ago, in a project called the <a href="https://arxiv.org/abs/2206.04615">Beyond the Imitation Game benchmark</a>, or BIG-bench, 450 researchers compiled a list of 204 tasks designed to test the capabilities of large language models, which power chatbots like ChatGPT. On most tasks, performance improved predictably and smoothly as the models scaled up — the larger the model, the better it got. But with other tasks, the jump in ability wasn’t smooth. The performance remained near zero for a while, then performance jumped. Other studies found similar leaps in ability.</p>
<p>The authors described this as “breakthrough” behavior; other researchers have likened it to a phase transition in physics, like when liquid water freezes into ice. In <a href="https://arxiv.org/abs/2206.07682">a paper</a> published in August 2022, researchers noted that these behaviors are not only surprising but unpredictable, and that they should inform the evolving conversations around AI safety, potential and risk. They called the abilities “<a href="https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/">emergent</a>,” a word that describes collective behaviors that only appear once a system reaches a high level of complexity.</p>
<p>But things may not be so simple. <a href="https://arxiv.org/abs/2304.15004">A new paper</a> by a trio of researchers at Stanford University posits that the sudden appearance of these abilities is just a consequence of the way researchers measure the LLM’s performance. The abilities, they argue, are neither unpredictable nor sudden. “The transition is much more predictable than people give it credit for,” said <a href="https://cs.stanford.edu/~sanmi/">Sanmi Koyejo</a>, a computer scientist at Stanford and the paper’s senior author. “Strong claims of emergence have as much to do with the way we choose to measure as they do with what the models are doing.”</p>

<p>We’re only now seeing and studying this behavior because of how large these models have become. Large language models train by analyzing enormous <a href="https://openai.com/research/language-unsupervised">datasets of text</a> — words from online sources including books, web searches and Wikipedia — and finding links between words that often appear together. The size is measured in terms of parameters, roughly analogous to all the ways that words can be connected. The more parameters, the more connections an LLM can find. GPT-2 had 1.5 billion parameters, while GPT-3.5, the LLM that powers ChatGPT, uses 350 billion. GPT-4, which debuted in March 2023 and now underlies Microsoft Copilot, reportedly uses 1.75 trillion.</p>
<p>That rapid growth has brought an astonishing surge in performance and efficacy, and no one is disputing that large enough LLMs can complete tasks that smaller models can’t, including ones for which they weren’t trained. The trio at Stanford who cast emergence as a “mirage” recognize that LLMs become more effective as they scale up; in fact, <a href="https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/">the added complexity</a> of larger models should make it possible to get better at more difficult and diverse problems. But they argue that whether this improvement looks smooth and predictable or jagged and sharp results from the choice of metric — or even a paucity of test examples — rather than the model’s inner workings.</p>

<p>Three-digit addition offers an example. In the 2022 BIG-bench study, researchers reported that with fewer parameters, both GPT-3 and another LLM named LAMDA failed to accurately complete addition problems. However, when GPT-3 trained using 13 billion parameters, its ability changed as if with the flip of a switch. Suddenly, it could add — and LAMDA could, too, at 68 billion parameters. This suggests that the ability to add emerges at a certain threshold.</p>
<p>But the Stanford researchers point out that the LLMs were judged only on accuracy: Either they could do it perfectly, or they couldn’t. So even if an LLM predicted most of the digits correctly, it failed. That didn’t seem right. If you’re calculating 100 plus 278, then 376 seems like a much more accurate answer than, say, −9.34.</p>
<p>So instead, Koyejo and his collaborators tested the same task using a metric that awards partial credit. “We can ask: How well does it predict the first digit? Then the second? Then the third?” he said.</p>
<p>Koyejo credits the idea for the new work to his graduate student Rylan Schaeffer, who he said noticed that an LLM’s performance seems to change with how its ability is measured. Together with Brando Miranda, another Stanford graduate student, they chose new metrics showing that as parameters increased, the LLMs predicted an increasingly correct sequence of digits in addition problems. This suggests that the ability to add isn’t emergent — meaning that it undergoes a sudden, unpredictable jump — but gradual and predictable. They find that with a different measuring stick, emergence vanishes.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Monolith – CLI tool for saving complete web pages as a single HTML file (433 pts)]]></title>
            <link>https://github.com/Y2Z/monolith</link>
            <guid>39810378</guid>
            <pubDate>Sun, 24 Mar 2024 20:48:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Y2Z/monolith">https://github.com/Y2Z/monolith</a>, See on <a href="https://news.ycombinator.com/item?id=39810378">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://github.com/Y2Z/monolith/actions?query=workflow%3AGNU%2FLinux"><img src="https://github.com/Y2Z/monolith/workflows/GNU%2FLinux/badge.svg" alt="monolith build status on GNU/Linux"></a>
<a href="https://github.com/Y2Z/monolith/actions?query=workflow%3AmacOS"><img src="https://github.com/Y2Z/monolith/workflows/macOS/badge.svg" alt="monolith build status on macOS"></a>
<a href="https://github.com/Y2Z/monolith/actions?query=workflow%3AWindows"><img src="https://github.com/Y2Z/monolith/workflows/Windows/badge.svg" alt="monolith build status on Windows"></a></p>
<div data-snippet-clipboard-copy-content=" _____     ______________    __________      ___________________    ___
|     \   /              \  |          |    |                   |  |   |
|      \_/       __       \_|    __    |    |    ___     ___    |__|   |
|               |  |            |  |   |    |   |   |   |   |          |
|   |\     /|   |__|    _       |__|   |____|   |   |   |   |    __    |
|   | \___/ |          | \                      |   |   |   |   |  |   |
|___|       |__________|  \_____________________|   |___|   |___|  |___|"><pre><code> _____     ______________    __________      ___________________    ___
|     \   /              \  |          |    |                   |  |   |
|      \_/       __       \_|    __    |    |    ___     ___    |__|   |
|               |  |            |  |   |    |   |   |   |   |          |
|   |\     /|   |__|    _       |__|   |____|   |   |   |   |    __    |
|   | \___/ |          | \                      |   |   |   |   |  |   |
|___|       |__________|  \_____________________|   |___|   |___|  |___|
</code></pre></div>
<p dir="auto">A data hoarder’s dream come true: bundle any web page into a single HTML file. You can finally replace that gazillion of open tabs with a gazillion of .html files stored somewhere on your precious little drive.</p>
<p dir="auto">Unlike the conventional “Save page as”, <code>monolith</code> not only saves the target document, it embeds CSS, image, and JavaScript assets <strong>all at once</strong>, producing a single HTML5 document that is a joy to store and share.</p>
<p dir="auto">If compared to saving websites with <code>wget -mpk</code>, this tool embeds all assets as data URLs and therefore lets browsers render the saved page exactly the way it was on the Internet, even when no network connection is available.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://crates.io/crates/monolith" rel="nofollow">Cargo</a> (cross-platform)</h4><a id="user-content-using-cargo-cross-platform" aria-label="Permalink: Using Cargo (cross-platform)" href="#using-cargo-cross-platform"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Via <a href="https://formulae.brew.sh/formula/monolith" rel="nofollow">Homebrew</a> (macOS and GNU/Linux)</h4><a id="user-content-via-homebrew-macos-and-gnulinux" aria-label="Permalink: Via Homebrew (macOS and GNU/Linux)" href="#via-homebrew-macos-and-gnulinux"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Via <a href="https://community.chocolatey.org/packages/monolith" rel="nofollow">Chocolatey</a> (Windows)</h4><a id="user-content-via-chocolatey-windows" aria-label="Permalink: Via Chocolatey (Windows)" href="#via-chocolatey-windows"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Via <a href="https://ports.macports.org/port/monolith/summary" rel="nofollow">MacPorts</a> (macOS)</h4><a id="user-content-via-macports-macos" aria-label="Permalink: Via MacPorts (macOS)" href="#via-macports-macos"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo port install monolith"><pre><span>sudo port install monolith</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://snapcraft.io/monolith" rel="nofollow">Snapcraft</a> (GNU/Linux)</h4><a id="user-content-using-snapcraft-gnulinux" aria-label="Permalink: Using Snapcraft (GNU/Linux)" href="#using-snapcraft-gnulinux"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://packages.guix.gnu.org/packages/monolith" rel="nofollow">Guix</a> (GNU/Linux)</h4><a id="user-content-using-guix-gnulinux" aria-label="Permalink: Using Guix (GNU/Linux)" href="#using-guix-gnulinux"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://aur.archlinux.org/packages/monolith" rel="nofollow">AUR</a> (Arch Linux)</h4><a id="user-content-using-aur-arch-linux" aria-label="Permalink: Using AUR (Arch Linux)" href="#using-aur-arch-linux"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://pkgs.alpinelinux.org/packages?name=monolith" rel="nofollow">aports</a> (Alpine Linux)</h4><a id="user-content-using-aports-alpine-linux" aria-label="Permalink: Using aports (Alpine Linux)" href="#using-aports-alpine-linux"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://svnweb.freebsd.org/ports/head/www/monolith/" rel="nofollow">FreeBSD packages</a> (FreeBSD)</h4><a id="user-content-using-freebsd-packages-freebsd" aria-label="Permalink: Using FreeBSD packages (FreeBSD)" href="#using-freebsd-packages-freebsd"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://www.freshports.org/www/monolith/" rel="nofollow">FreeBSD ports</a> (FreeBSD)</h4><a id="user-content-using-freebsd-ports-freebsd" aria-label="Permalink: Using FreeBSD ports (FreeBSD)" href="#using-freebsd-ports-freebsd"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd /usr/ports/www/monolith/
make install clean"><pre><span>cd /usr/ports/www/monolith/</span>
<span>make install clean</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://pkgsrc.se/www/monolith" rel="nofollow">pkgsrc</a> (NetBSD, OpenBSD, Haiku, etc)</h4><a id="user-content-using-pkgsrc-netbsd-openbsd-haiku-etc" aria-label="Permalink: Using pkgsrc (NetBSD, OpenBSD, Haiku, etc)" href="#using-pkgsrc-netbsd-openbsd-haiku-etc"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd /usr/pkgsrc/www/monolith
make install clean"><pre><span>cd /usr/pkgsrc/www/monolith</span>
<span>make install clean</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://www.docker.com/" rel="nofollow">containers</a></h4><a id="user-content-using-containers" aria-label="Permalink: Using containers" href="#using-containers"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker build -t Y2Z/monolith .
sudo install -b dist/run-in-container.sh /usr/local/bin/monolith"><pre><span>docker build -t Y2Z/monolith .</span>
<span>sudo install -b dist/run-in-container.sh /usr/local/bin/monolith</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">From <a href="https://github.com/Y2Z/monolith">source</a></h4><a id="user-content-from-source" aria-label="Permalink: From source" href="#from-source"></a></p>
<p dir="auto">Dependency: <code>libssl</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Y2Z/monolith.git
cd monolith
make install"><pre><span>git clone https://github.com/Y2Z/monolith.git</span>
<span>cd monolith</span>
<span>make install</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using <a href="https://github.com/Y2Z/monolith/releases">pre-built binaries</a> (Windows, ARM-based devices, etc)</h4><a id="user-content-using-pre-built-binaries-windows-arm-based-devices-etc" aria-label="Permalink: Using pre-built binaries (Windows, ARM-based devices, etc)" href="#using-pre-built-binaries-windows-arm-based-devices-etc"></a></p>
<p dir="auto">Every release contains pre-built binaries for Windows, GNU/Linux, as well as platforms with non-standard CPU architecture.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="monolith https://lyrics.github.io/db/P/Portishead/Dummy/Roads/ -o portishead-roads-lyrics.html"><pre><span>monolith https://lyrics.github.io/db/P/Portishead/Dummy/Roads/ -o portishead-roads-lyrics.html</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="cat index.html | monolith -aIiFfcMv -b https://original.site/ - > result.html"><pre><span>cat index.html | monolith -aIiFfcMv -b https://original.site/ - &gt; result.html</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<ul dir="auto">
<li><code>-a</code>: Exclude audio sources</li>
<li><code>-b</code>: Use custom <code>base URL</code></li>
<li><code>-B</code>: Forbid retrieving assets from specified domain(s)</li>
<li><code>-c</code>: Exclude CSS</li>
<li><code>-C</code>: Read cookies from <code>file</code></li>
<li><code>-d</code>: Allow retrieving assets only from specified <code>domain(s)</code></li>
<li><code>-e</code>: Ignore network errors</li>
<li><code>-E</code>: Save document using custom <code>encoding</code></li>
<li><code>-f</code>: Omit frames</li>
<li><code>-F</code>: Exclude web fonts</li>
<li><code>-h</code>: Print help information</li>
<li><code>-i</code>: Remove images</li>
<li><code>-I</code>: Isolate the document</li>
<li><code>-j</code>: Exclude JavaScript</li>
<li><code>-k</code>: Accept invalid X.509 (TLS) certificates</li>
<li><code>-M</code>: Don't add timestamp and URL information</li>
<li><code>-n</code>: Extract contents of NOSCRIPT elements</li>
<li><code>-o</code>: Write output to <code>file</code> (use “-” for STDOUT)</li>
<li><code>-s</code>: Be quiet</li>
<li><code>-t</code>: Adjust <code>network request timeout</code></li>
<li><code>-u</code>: Provide custom <code>User-Agent</code></li>
<li><code>-v</code>: Exclude videos</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Whitelisting and blacklisting domains</h2><a id="user-content-whitelisting-and-blacklisting-domains" aria-label="Permalink: Whitelisting and blacklisting domains" href="#whitelisting-and-blacklisting-domains"></a></p>
<p dir="auto">Options <code>-d</code> and <code>-B</code> provide control over what domains can be used to retrieve assets from, e.g.:</p>
<div dir="auto" data-snippet-clipboard-copy-content="monolith -I -d example.com -d www.example.com https://example.com -o example-only.html"><pre><span>monolith -I -d example.com -d www.example.com https://example.com -o example-only.html</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="monolith -I -B -d .googleusercontent.com -d googleanalytics.com -d .google.com https://example.com -o example-no-ads.html"><pre><span>monolith -I -B -d .googleusercontent.com -d googleanalytics.com -d .google.com https://example.com -o example-no-ads.html</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dynamic content</h2><a id="user-content-dynamic-content" aria-label="Permalink: Dynamic content" href="#dynamic-content"></a></p>
<p dir="auto">Monolith doesn't feature a JavaScript engine, hence websites that retrieve and display data after initial load may require usage of additional tools.</p>
<p dir="auto">For example, Chromium (Chrome) can be used to act as a pre-processor for such pages:</p>
<div dir="auto" data-snippet-clipboard-copy-content="chromium --headless --incognito --dump-dom https://github.com | monolith - -I -b https://github.com -o github.html"><pre><span>chromium --headless --incognito --dump-dom https://github.com | monolith - -I -b https://github.com -o github.html</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Proxies</h2><a id="user-content-proxies" aria-label="Permalink: Proxies" href="#proxies"></a></p>
<p dir="auto">Please set <code>https_proxy</code>, <code>http_proxy</code>, and <code>no_proxy</code> environment variables.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Please open an issue if something is wrong, that helps make this project better.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Related projects</h2><a id="user-content-related-projects" aria-label="Permalink: Related projects" href="#related-projects"></a></p>
<ul dir="auto">
<li>Monolith Chrome Extension: <a href="https://github.com/rhysd/monolith-of-web">https://github.com/rhysd/monolith-of-web</a></li>
<li>Pagesaver: <a href="https://github.com/distributed-mind/pagesaver">https://github.com/distributed-mind/pagesaver</a></li>
<li>Personal WayBack Machine: <a href="https://github.com/popey/pwbm">https://github.com/popey/pwbm</a></li>
<li>Hako: <a href="https://github.com/dmpop/hako">https://github.com/dmpop/hako</a></li>
<li>Monk: <a href="https://github.com/monk-dev/monk">https://github.com/monk-dev/monk</a></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">To the extent possible under law, the author(s) have dedicated all copyright related and neighboring rights to this software to the public domain worldwide.
This software is distributed without any warranty.</p>
<hr>

<p dir="auto"><sub>Keep in mind that <code>monolith</code> is not aware of your browser’s session</sub></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The new Windows update made me think I'd installed malware (105 pts)]]></title>
            <link>https://www.pcgamer.com/software/windows/the-new-windows-update-made-me-think-id-installed-malware-but-it-was-just-microsofts-latest-attempt-to-try-and-fool-me-into-using-bing/</link>
            <guid>39809478</guid>
            <pubDate>Sun, 24 Mar 2024 19:15:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/software/windows/the-new-windows-update-made-me-think-id-installed-malware-but-it-was-just-microsofts-latest-attempt-to-try-and-fool-me-into-using-bing/">https://www.pcgamer.com/software/windows/the-new-windows-update-made-me-think-id-installed-malware-but-it-was-just-microsofts-latest-attempt-to-try-and-fool-me-into-using-bing/</a>, See on <a href="https://news.ycombinator.com/item?id=39809478">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="A furious woman punches through her laptop. screen." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg"><source type="image/jpeg" alt="A furious woman punches through her laptop. screen." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg"><img src="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-320-80.jpg" alt="A furious woman punches through her laptop. screen." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/YgVMHiCZdp2AnfHQHez6Dj.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: SI Photography via Getty Images)</span>
</figcaption>
</div>

<div id="article-body">
<p>Not for the first time, Microsoft has struck upon a winning formula for irritating the hell out of Windows users: pop-up ads in your browser! The latest Windows update was released several days ago, though I only got around to it today, and after installation inserts pop-up adverts into Google Chrome.</p><p>I couldn't believe what I was seeing: a little box comes up in the bottom right corner of the browser, advertising the Bing search engine and BingAI. My first thought was that I'd downloaded something malicious, perhaps while fiddling with mods, because the pop-up didn't exactly look classy, more like the kind of thing you see on suspicious websites. But I set off a quick antivirus scan and googled the issue (in Chrome naturally), and quickly found plenty of folk complaining about the same thing.</p><p>So first of all: Really, Microsoft? Most of us rely on Windows, it has an absolute stranglehold on the OS market, and is therefore able to intrude on our PC experience like few other companies (outside perhaps Google itself). This particular pop-up will, if you click "yes" to its prompt, set Bing as the default search engine within Chrome.</p><p>It did this last year, too, adding pop-ups to Windows 10 and 11 that <a data-analytics-id="inline-link" href="https://www.theverge.com/2023/8/30/23851902/microsoft-bing-popups-windows-11-malware" target="_blank" data-url="https://www.theverge.com/2023/8/30/23851902/microsoft-bing-popups-windows-11-malware"><u>appeared over the top of other apps</u></a> suggesting Microsoft-made alternatives, before removing them due to "unintended behaviour."</p><p>Microsoft has confirmed the pop-ups are genuine Microsoft adverts, and says they should only appear once. Well, I've seen at least two, and frankly don't trust Redmond on this, because it's just always coming up with new ways to taint the Windows experience.</p><p>"This is a one-time notification giving people the choice to set Bing as their default search engine on Chrome," Microsoft comms director <a data-analytics-id="inline-link" href="https://www.theverge.com/2024/3/15/24101887/microsoft-bing-popups-windows-11-google-chrome" target="_blank" data-url="https://www.theverge.com/2024/3/15/24101887/microsoft-bing-popups-windows-11-google-chrome"><u>Caitlin Roulston told The Verge</u></a>. Almost unbelievably she frames this as a perk for users, who get some Copilot bonuses if they accept the BingAI prompt, then ends with this magnificently brazen claim: "We value providing our customers with choice, so there is an option to dismiss the notification."</p><p>What really annoys me about Windows is that it doesn't respect my choices over time, but seems to override them on a whim in certain updates and make my machine start doing things Microsoft wants but I don't want. I wouldn't be so bothered about Microsoft's various attempts to fool me into using Bing if I could just say "no thanks" at some point and have that respected over multiple updates.&nbsp;</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-hbKqpcu45pavAoR4UREVqD"><section><p>Sign up to get the best content of the week, and great gaming deals, as picked by the editors.</p></section></div><p>When Windows is annoying, Windows has failed. And Windows has become increasingly annoying over recent years, like when it added those <a data-analytics-id="inline-link" href="https://www.pcgamer.com/how-to-banish-those-irritating-pictures-from-your-windows-search-bar/" target="_blank" data-before-rewrite-localise="https://www.pcgamer.com/how-to-banish-those-irritating-pictures-from-your-windows-search-bar/"><u>irritating pictures to Windows search bar</u></a>, or tried to add <a data-analytics-id="inline-link" href="https://www.pcgamer.com/the-latest-windows-11-preview-feature-is-a-bing-and-edge-exclusive-search-box-on-your-desktop/" target="_blank" data-before-rewrite-localise="https://www.pcgamer.com/the-latest-windows-11-preview-feature-is-a-bing-and-edge-exclusive-search-box-on-your-desktop/"><u>a Bing and Edge searchbox to your taskbar</u></a>. It's done updates that automatically launch an Edge browser session once complete, and just generally every time there's an update I wonder what fresh torture Microsoft's engineers have come up with. Hell, it's enough to <a data-analytics-id="inline-link" href="https://www.pcgamer.com/clippy-did-nothing-wrong/" target="_blank" data-before-rewrite-localise="https://www.pcgamer.com/clippy-did-nothing-wrong/"><u>make you nostalgic for Clippy</u></a>.</p>
</div>
<div id="slice-container-authorBio-hbKqpcu45pavAoR4UREVqD"><p>Rich is a games journalist with 15 years' experience, beginning his career on Edge magazine before working for a wide range of outlets, including Ars Technica, Eurogamer, GamesRadar+, Gamespot, the Guardian, IGN, the New Statesman, Polygon, and Vice. He was the editor of Kotaku UK, the UK arm of Kotaku, for three years before joining PC Gamer. He is the author of a Brief History of Video Games, a full history of the medium, which the Midwest Book Review described as "[a] must-read for serious minded game historians and curious video game connoisseurs alike."</p></div>



</section>


<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>







</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists traced a mysterious Covid case back to six toilets (101 pts)]]></title>
            <link>https://www.technologyreview.com/2024/03/22/1090059/how-scientists-traced-a-mysterious-covid-case-back-to-six-toilets/</link>
            <guid>39809369</guid>
            <pubDate>Sun, 24 Mar 2024 19:00:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.technologyreview.com/2024/03/22/1090059/how-scientists-traced-a-mysterious-covid-case-back-to-six-toilets/">https://www.technologyreview.com/2024/03/22/1090059/how-scientists-traced-a-mysterious-covid-case-back-to-six-toilets/</a>, See on <a href="https://news.ycombinator.com/item?id=39809369">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>That virus likely came from a single employee who happened to be shedding an enormous quantity of a very weird variant. The researchers would desperately like to find that person. <strong>But what if that person doesn’t want to be found?</strong></p>  <p>A few years ago, Marc Johnson, a virologist at the University of Missouri, became obsessed with weird covid variants he was seeing in wastewater samples. The ones that caught his eye were odd in a couple of different ways: they didn’t match any of the common variants, and they didn’t circulate. They would pop up in a single location, persist for some length of time, and then often disappear—a blip. Johnson found his first blip in Missouri. <strong>“It drove me nuts,” he says. “I was like, ‘What the hell was going on here?’”&nbsp;</strong></p> 
 <p>Then he teamed up with colleagues in New York, and they found a few more.</p>  <p>Hoping to pin down even more lineages, Johnson put a call out on Twitter (now X) for wastewater. In January 2022, he got another hit in a wastewater sample shipped from a Wisconsin treatment plant. He and David O’Connor, a virologist at the University of Wisconsin, started working with state health officials to track the signal—from the treatment plant to a pumping station and then to the outskirts of the city, “one manhole at a time,” Johnson says. “Every time there was a branch in the road, we would check which branch [the signal] was coming from.”</p> 
 <p>They chased some questionable leads. The researchers were suspicious the virus might be coming from an animal. At one point O’Connor took people from his lab to a dog park to ask dog owners for poop samples. “There were so many red herrings,” Johnson says.</p>  <p>Finally, after sampling about 50 manholes, the researchers found <em>the</em> manhole, the last one on the branch that had the variant. They got lucky. “The only source was this company,” Johnson says. <a href="https://www.thelancet.com/journals/lanmic/article/PIIS2666-5247(23)00372-5/fulltext">Their results</a><em> </em>came out in March in<em> Lancet Microbe</em>.&nbsp;</p>  <p><strong>Wastewater surveillance might seem like a relatively new phenomenon, born of the pandemic, but it goes back decades.</strong> A team of Canadian researchers outlines several historical examples <a href="https://theconversation.com/targeted-wastewater-surveillance-has-a-history-of-social-and-ethical-concerns-183570">in this story</a>. In <a href="https://journals.sagepub.com/doi/10.1177/146642405107100109">one example</a>, a public health official traced a 1946 typhoid outbreak to the wife of a man who sold ice cream at the beach. Even then, the researcher expressed some hesitation. The study didn’t name the wife or the town, and he cautioned that infections probably shouldn’t be traced back to an individual “except in the presence of an outbreak.”</p>  <p>In <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1830615/">a similar study published in 1959</a>, scientists traced another typhoid epidemic to one woman, who was then banned from food service and eventually talked into having her gallbladder removed to eliminate the infection. Such publicity can have a “devastating effect on the carrier,” they remarked in their write-up of the case. “From being a quiet and respected citizen, she becomes a social pariah.”</p> </div><div> <p>When Johnson and O’Connor traced the virus to that last manhole, things got sticky. Until that point, the researchers had suspected these cryptic lineages were coming from animals. Johnson had even developed a theory involving organic fertilizer from a source further upstream. Now they were down to a single building housing a company with about 30 employees. They didn’t want to stigmatize anyone or invade their privacy. But someone at the company was shedding an awful lot of virus. “Is it ethical to not tell them at that point?” Johnson wondered.</p>  <p>O’Connor and Johnson had been working with state health officials from the very beginning. They decided the best path forward would be to approach the company, explain the situation, and ask if they could offer voluntary testing. The decision wasn’t easy. “We didn’t want to cause panic and say there’s a dangerous new variant lurking in our community,” Ryan Westergaard, the state epidemiologist for communicable diseases at the Wisconsin Department of Health Services, told <em>Nature</em>. But they also wanted to try to help the person who was infected.&nbsp;</p>  <p><strong>The company agreed to testing, and 19 of its 30 employees turned up for nasal swabs. They were all negative.</strong></p>  <p>That may mean one of the people who didn’t test was carrying the infection. Or could it mean that the massive covid infection in the gut didn’t show up on a nasal swab? “This is where I would use the shrug emoji if we were doing this over email,” O’Connor says.</p> 

 <p>At the time, the researchers had the ability to test stool samples for the virus, but they didn’t have approval. Now they do, and they’re hoping stool will lead them to an individual infected with one of these strange viruses who can help answer some of their questions. Johnson has identified about 50 of these cryptic covid variants in wastewater. “The more I study these lineages, the more I am convinced that they are replicating in the GI tract,” Johnson says. “It wouldn’t surprise me at all if that’s the only place they were replicating.”&nbsp;</p>  <p><strong>But how far should they go to find these people? That’s still an open question. </strong>O’Connor can imagine a dizzying array of problems that might arise if they did identify an individual shedding one of these rare variants. The most plausible hypothesis is that the lineages arise in individuals who have immune disorders that make it difficult for them to eliminate the infection. That raises a whole host of other thorny questions: what if that person had a compromised immune system due to HIV in addition to the strange covid variant? What if that person didn’t know they were HIV positive, or didn’t want to divulge their HIV status? What if the researchers told them about the infection, but the person couldn’t access treatment? “If you imagine what the worst-case scenarios are, they’re pretty bad,” O’Connor says.</p>  <p>On the other hand, O’Connor says, they think there are a lot of these people around the country and the world. <strong>“Isn't there also an ethical obligation to try to learn what we can so that we can try to help people who are harboring these viruses?” he asks.</strong></p>  <hr>  <h2>Now read the rest of The Checkup</h2>  <h3><strong>More from MIT Technology Review</strong></h3>  <p>Longevity specialists aim to help people live longer and healthier lives. But they have yet to establish themselves as a credible medical field. Expensive longevity clinics that cater to the wealthy worried well aren’t helping. Jessica Hamzelou takes us inside <a href="https://www.technologyreview.com/2024/03/18/1089888/the-quest-to-legitimize-longevity-medicine/">the quest to legitimize longevity medicine</a>.</p> </div><div><p>Drug developers bet big on AI to help speed drug development. But when will we see our first generative drug? Antonio Regalado <a href="https://www.technologyreview.com/2024/03/20/1089939/a-wave-of-drugs-dreamed-up-by-ai-is-on-its-way/">has the story</a>.&nbsp;</p>  <h3><strong>Read more from MIT Technology Review’s archive</strong></h3>  <p>The covid pandemic brought the tension between privacy and public health into sharp relief, <a href="https://www.technologyreview.com/2020/03/24/950361/coronavirus-is-forcing-a-trade-off-between-privacy-and-public-health/">wrote Karen Hao in 2020</a>.&nbsp;</p>  <p>That same year Genevieve Bell <a href="https://www.technologyreview.com/2020/04/12/999186/covid-19-contact-tracing-surveillance-data-privacy-anonymity/">argued</a> that we can reimagine contact tracing in a way that protects privacy.</p>  <p>In 2021, Antonio Regalado <a href="https://www.technologyreview.com/2021/02/08/1017609/the-fast-spreading-coronavirus-variant-is-so-prevalent-its-turning-up-in-us-sewers/?utm_source=the_checkup&amp;utm_medium=email&amp;utm_campaign=the_checkup.unpaid.engagement&amp;utm_content=*%7Cdate:m-d-y%7C*">covered</a> some of the first efforts to track the spread of covid variants using wastewater.&nbsp;&nbsp;</p> 
 <p>Earlier this year I wrote about <a href="https://www.technologyreview.com/2024/01/26/1087215/how-wastewater-could-offer-an-early-warning-system-for-measles/">using wastewater to track measles</a>.<strong>&nbsp;</strong></p>  <h3><strong>From around the web</strong></h3>  <p>Surgeons have transplanted a kidney from a genetically engineered pig into a 62-year-old man in Boston. (<a href="https://www.nytimes.com/2024/03/21/health/pig-kidney-organ-transplant.html">New York Times</a>)<br>→ Surgeons transplanted a similar kidney into a brain-dead patient in 2021. (<a href="https://www.technologyreview.com/2021/10/20/1037752/pig-kidney-human-patient-xenotransplantation/">MIT Technology Review</a>)&nbsp;<br>→ Researchers are also looking into how to transplant other organs. Just a few months ago, surgeons connected a genetically engineered pig liver to another brain-dead patient. (<a href="https://www.technologyreview.com/2024/01/18/1086791/brain-dead-man-gene-edited-pig-liver/">MIT Technology Review</a>)</p> 
 <p>The FDA has approved a new gene therapy for a rare but fatal genetic disorder in children. Its $4.25 million price tag will make it the world’s most expensive medicine, but it promises to give children with the disease a shot at a normal life. (<a href="https://www.cnn.com/2024/03/19/health/gene-therapy-orchard-mld/index.html">CNN</a>)<br>→ Read Antonio Regalado’s take on the curse of the costliest drug. (<a href="https://www.technologyreview.com/2024/03/20/1089996/there-is-a-new-most-expensive-drug-in-the-world-price-tag-4-25-million/">MIT Technology Review</a>)</p>  <p>People who practice intermittent fasting have an increased risk of dying of heart disease, according to new research presented at the American Heart Association meeting in Chicago. There are, of course, caveats. (<a href="https://www.washingtonpost.com/wellness/2024/03/18/intermittent-fasting-time-restricted-eating/">Washington Post</a> and <a href="https://www.statnews.com/2024/03/19/intermittent-fasting-study-heart-risk/">Stat</a>)</p>  <p>Some parents aren’t waiting to give their young kids the new miracle drug to treat cystic fibrosis. They’re starting the treatment in utero. (<a href="https://www.theatlantic.com/health/archive/2024/03/cystic-fibrosis-treatment-babies-trikafta/677799/">The Atlantic</a>)&nbsp; </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Majority of web apps could just run on a single server (229 pts)]]></title>
            <link>https://old.reddit.com/r/webdev/comments/1bmfrjm/majority_of_web_apps_could_just_run_on_a_single/</link>
            <guid>39809342</guid>
            <pubDate>Sun, 24 Mar 2024 18:56:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/webdev/comments/1bmfrjm/majority_of_web_apps_could_just_run_on_a_single/">https://old.reddit.com/r/webdev/comments/1bmfrjm/majority_of_web_apps_could_just_run_on_a_single/</a>, See on <a href="https://news.ycombinator.com/item?id=39809342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This sentiment gets stronger every day I follow the web development scene. Surely there are many ( in absolute numbers ) that require complex infra but majority of websites and apps get &lt;10 rps and 50 on a busy day. </p>

<p>Obviously latency is lower if there are endpoints around the world but the data still needs to be accessed. What's the point of being 20ms away from client if the db is 200ms away from that endpoint? And yes, someone has to pay for all that infrastructure.</p>

<p>Obviously caching is useful but that's something you get with a cdn or just plain http caching. Often the whole thing can live on cdn, just push the new files after updates. Maybe a few api endpoints are needed for some dynamic functionality but that can be handled for example with JavaScript. </p>

<p>Most projects might as well run in container on $5 vps. That would likely be faster as well, at least it's running and probably with a local db.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4, without specialized training, beat a GPT-3.5 class model that cost $10M (148 pts)]]></title>
            <link>https://www.threads.net/@ethan_mollick/post/C46AfItO8RS</link>
            <guid>39809177</guid>
            <pubDate>Sun, 24 Mar 2024 18:34:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.threads.net/@ethan_mollick/post/C46AfItO8RS">https://www.threads.net/@ethan_mollick/post/C46AfItO8RS</a>, See on <a href="https://news.ycombinator.com/item?id=39809177">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Aegis v3.0 – a free, secure and open source 2FA app for Android (278 pts)]]></title>
            <link>https://github.com/beemdevelopment/Aegis/releases/tag/v3.0</link>
            <guid>39808921</guid>
            <pubDate>Sun, 24 Mar 2024 18:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/beemdevelopment/Aegis/releases/tag/v3.0">https://github.com/beemdevelopment/Aegis/releases/tag/v3.0</a>, See on <a href="https://news.ycombinator.com/item?id=39808921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:beemdevelopment/Aegis" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="sjyJKx4ZlgLQetgbBXjhXVCkc4xqlQDzzdISdGWYdeywZlOfhfiCPdzAT9FYKNF8f6wX9MZM9KOaX8tq0XFGvA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="beemdevelopment/Aegis" data-current-org="beemdevelopment" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=8rYaT9jwTSs4FfbnVAgiWJHzEwCIYKBngA%2BZRMKFfmMI6yVYviOhF0ZCCKU2vcI527m6Xzul1WtubMiVjNtbyhT5CfLwbOuqcgvgW6%2FuHTi9HOwyy0Bu3DSsxlj%2B4yBl82TXNmXy82gf%2BD4e9T8jmkNDHrRSmlqK7B3dXfEW88%2BIsrbcr9LnOMZi34DBx1sXocZaZFKsgio7rjspjts0QcKCBaVv6hX42aEENuSTE4LfSpUtaMycvxBOEEphMifoFrahHi0YZfcrQ2Nom%2F5gGrCc7FvtGiB27E5FTwDxAhQuO7FybtINpGX4ZZynUwWS%2BVhPll%2F6leszdI4V0Yy%2FemMBDG7defVUVDpLAFlXUO4f52efhkPJzbg6FjYiiDnw2577gaqv487xVNps1DFWJhHNK5fl%2BavNvkSWo0IzAlrGU9hFfP7RNIMjGmvXqaqxwgWlL%2FzGnZRfXX8HuVEGkCMGohOBuyZ5W4JTmOV%2FMG4S%2BH36%2BRhBTevWpaiSwf6qNXJ3ujItr8EbMeZifcTTN8ScNvwK6T4vea2nkXGc%2F7yzrFVLuiVZN5WA--sSQ6WCib8apyR3Nu--o4M2sVejC3o6%2FFUjD4gcaQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Freleases%2Fshow&amp;source=header-repo&amp;source_repo=beemdevelopment%2FAegis" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/beemdevelopment/Aegis/releases/tag/v3.0&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="c7bf8ab17d7a68e50099e6384c9c4c054d0daa6a718affd01c1af5c4bd7dd2af" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/releases/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[China blocks use of Intel and AMD chips in government computers: Report (136 pts)]]></title>
            <link>https://www.channelnewsasia.com/business/china-blocks-use-intel-and-amd-chips-government-computers-report-4218101</link>
            <guid>39808664</guid>
            <pubDate>Sun, 24 Mar 2024 17:27:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.channelnewsasia.com/business/china-blocks-use-intel-and-amd-chips-government-computers-report-4218101">https://www.channelnewsasia.com/business/china-blocks-use-intel-and-amd-chips-government-computers-report-4218101</a>, See on <a href="https://news.ycombinator.com/item?id=39808664">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>China has introduced guidelines to phase out US microprocessors from Intel and AMD from government personal computers and servers, the Financial Times reported on Sunday (Mar 24).</p>

<p>The procurement guidance also seeks to sideline Microsoft's Windows operating system and foreign-made database software in favour of domestic options, the report said.</p>

<p>Government agencies above the township level have been told to include criteria requiring "safe and reliable" processors and operating systems when making purchases, the newspaper said.</p>

<p>China's industry ministry in late December issued a statement with three separate lists of CPUs, operating systems and centralised database deemed "safe and reliable" for three years after the publication date, all from Chinese companies, Reuters checks showed.</p>

<p>The State Council Information Office, which handles media queries for the council, China's Cabinet, did not immediately respond to a faxed request for comment.</p>

<p>Intel and AMD did not immediately respond to Reuters' request for comment.</p>

<p>The US has been aiming to boost domestic semiconductor output and reduce reliance on China and Taiwan with the Biden administration's 2022 CHIPS and Science Act.</p>

<p>It is designed to bolster US semiconductors and contains financial aid for domestic production with subsidies for production of advanced chips.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C++ left arrow operator (2016) (125 pts)]]></title>
            <link>https://www.atnnn.com/p/operator-larrow/</link>
            <guid>39808616</guid>
            <pubDate>Sun, 24 Mar 2024 17:22:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.atnnn.com/p/operator-larrow/">https://www.atnnn.com/p/operator-larrow/</a>, See on <a href="https://news.ycombinator.com/item?id=39808616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on July 29, 2016
    
</p>

<p>Sometimes you have a pointer to a class, and you want to invoke a method. You can use the <code>-&gt;</code> operator for that.</p>
<p>So what do you do when you have a pointer to a method, and want to invoke it on a class? Use the <code>&lt;-</code> operator!</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>#include </span><span>&lt;iostream&gt;</span></span>
<span id="cb1-2"> </span>
<span id="cb1-3"><span>template</span><span>&lt;</span><span>class</span> T<span>&gt;</span></span>
<span id="cb1-4"><span>struct</span> larrow <span>{</span></span>
<span id="cb1-5">    larrow<span>(</span>T<span>*</span> <span>a_</span><span>)</span> <span>:</span> a<span>(</span><span>a_</span><span>)</span> <span>{</span> <span>}</span></span>
<span id="cb1-6">    T<span>*</span> a<span>;</span></span>
<span id="cb1-7"><span>};</span></span>
<span id="cb1-8"> </span>
<span id="cb1-9"><span>template</span> <span>&lt;</span><span>class</span> T<span>,</span> <span>class</span> R<span>&gt;</span></span>
<span id="cb1-10">R <span>operator</span><span>&lt;(</span>R <span>(</span>T<span>::*</span> f<span>)(),</span> larrow<span>&lt;</span>T<span>&gt;</span> it<span>)</span> <span>{</span></span>
<span id="cb1-11">    <span>return</span> <span>(</span>it<span>.</span>a<span>-&gt;*</span>f<span>)();</span></span>
<span id="cb1-12"><span>}</span></span>
<span id="cb1-13"> </span>
<span id="cb1-14"><span>template</span><span>&lt;</span><span>class</span> T<span>&gt;</span></span>
<span id="cb1-15">larrow<span>&lt;</span>T<span>&gt;</span> <span>operator</span><span>-(</span>T<span>&amp;</span> a<span>)</span> <span>{</span></span>
<span id="cb1-16">    <span>return</span> larrow<span>&lt;</span>T<span>&gt;(&amp;</span>a<span>);</span></span>
<span id="cb1-17"><span>}</span></span>
<span id="cb1-18"> </span>
<span id="cb1-19"><span>struct</span> C <span>{</span></span>
<span id="cb1-20">    <span>void</span> f<span>()</span> <span>{</span> <span>std::</span>cout<span> &lt;&lt;</span> <span>"foo</span><span>\n</span><span>"</span><span>;</span> <span>}</span>    </span>
<span id="cb1-21"><span>};</span></span>
<span id="cb1-22"> </span>
<span id="cb1-23"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb1-24">    C x<span>;</span></span>
<span id="cb1-25">    <span>(&amp;</span>C<span>::</span>f<span>)&lt;-</span>x<span>;</span></span>
<span id="cb1-26"><span>}</span></span></code></pre></div>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ü/ü Conundrum (128 pts)]]></title>
            <link>https://unravelweb.dev/2024/02/12/the-u-u-conundrum/</link>
            <guid>39808357</guid>
            <pubDate>Sun, 24 Mar 2024 16:50:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unravelweb.dev/2024/02/12/the-u-u-conundrum/">https://unravelweb.dev/2024/02/12/the-u-u-conundrum/</a>, See on <a href="https://news.ycombinator.com/item?id=39808357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
			<main id="main">

<article id="post-1020">

	<!-- .entry-header -->

	<div>
		
<p id="9c3e">I implemented search and filtering for entities on our product at epilot. The users were heavily using the feature, however, a unique issue surfaced: difficulties in filtering file names containing diacritical marks like umlauts (<code>Äpfel</code>,&nbsp;<code>über</code>,&nbsp;<code>schön</code>, etc.).</p>



<p id="b54a">Intrigued, I delved into the logic to investigate. Initially, everything seemed in order. For instance, a file named “blöb” was saved precisely as “blöb” — no bizarre encoding alterations were apparent.</p>



<p id="0f99">Can you spot any difference between “blöb” and “blöb”?</p>



<p id="9a66">This time instead of typing the word in the search bar, I copied it from the uploaded and saved filename, and and voilà, the search functioned perfectly! 🤯. This definitely meant the file name was subtly altered upon upload, hinting at a background encoding transformation.</p>



<p id="49f9">So, as anyone would, I employed the power of&nbsp;<code>encodeURIComponent</code>&nbsp;to see for myself what really was different.</p>



<p>There it was! The different types of encoding forms that led to this. Now you might be wondering (<em>I was wondering too!</em>):</p>



<p><em>As if worrying about encoding wasn’t enough, now we’ve got to stress over its different types too 🤦‍♀ and wait, its 2024, and we are still grappling with Unicode character encoding problems?</em></p>



<figure><img decoding="async" width="536" height="260" src="https://unravelweb.dev/wp-content/uploads/2024/02/image.png" alt="" srcset="https://unravelweb.dev/wp-content/uploads/2024/02/image.png 536w, https://unravelweb.dev/wp-content/uploads/2024/02/image-300x146.png 300w" sizes="(max-width: 536px) 100vw, 536px"></figure>



<p>The culprits in this case were these two contrasting encoding types:&nbsp;<code><strong>%C3%BC</strong></code>&nbsp;and&nbsp;<code><strong>%CC%88</strong></code>, leading to the search malfunction. This is a well-known issue with NFD/NFC encoding forms.<br>There is a detailed explanation&nbsp;<a href="https://unicode.org/reports/tr15/#Norm_Forms" target="_blank" rel="noreferrer noopener">here</a>.</p>



<figure><img decoding="async" src="https://unravelweb.dev/wp-content/uploads/2024/02/10kVUt4jpUmk_aS0qk0riPA.png" alt=""></figure>



<div><p><em>Now imagine explaining this technical jargon that to a user!&nbsp;</em>😃</p><p>To fix it, I aligned the encoding type of the searched filename with that of the saved filename.<br>On <strong>MacOS</strong>, the encoding was NFD (for ö: 111 + 776), whereas on <strong>Linux</strong>, it switched to NFC (ö: 246).</p><p><strong>The solution?</strong></p><p>– Post-upload, before saving the file as an entity, I applied&nbsp;<code>.normalize()</code>&nbsp;to the filename, ensuring it was uniformly searchable.</p><p>– Additionally, as a cleanup step — to write a migration script to normalize the names of all existing files with non-ASCII characters.</p><p>A simple string normalise proved effective in this case. ✅<br>Read more about&nbsp;<code>String.prototype.normalize()</code>&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/normalize#canonical_equivalence_normalization" target="_blank" rel="noreferrer noopener">here</a>. There is also a specific normalization option to pass to ensure canonically equivalent normalization — for example:&nbsp;<code>string.normalize("NFC")</code></p><p>Here’s a visual representation of the problem with the solution output:</p></div>



<p><a href="https://drive.google.com/file/d/1Jkp8ye47iRfDoeTaMQkkskY_BTHegj_D/view">https://drive.google.com/file/d/1Jkp8ye47iRfDoeTaMQkkskY_BTHegj_D/view</a><br></p>



<figure><video controls="" src="https://drive.google.com/file/d/1Jkp8ye47iRfDoeTaMQkkskY_BTHegj_D/view"></video></figure>



<p>Hope it helps!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-1020 -->

<!-- #comments -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>			</main><!-- #main -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Happens When a Fifteen Year Old Pumps and Dumps with a Net Profit of $800k? (2002) (166 pts)]]></title>
            <link>http://www.kentlaw.edu/faculty/rwarner/classes/legalaspects_ukraine/securities/case_studies/ledbed.htm</link>
            <guid>39807967</guid>
            <pubDate>Sun, 24 Mar 2024 15:52:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.kentlaw.edu/faculty/rwarner/classes/legalaspects_ukraine/securities/case_studies/ledbed.htm">http://www.kentlaw.edu/faculty/rwarner/classes/legalaspects_ukraine/securities/case_studies/ledbed.htm</a>, See on <a href="https://news.ycombinator.com/item?id=39807967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><b>Case Study: What Happens When a Fifteen Year Old Pumps and Dumps,
Obtaining a Net Profit of Nearly $800,000?<span>�
</span>The SEC Settles for $285,000.<o:p></o:p></b></p>



<p>Jonathan Lebed and
two of his friends came in fourth place in a stock-picking contest sponsored by
CNBC when he was just twelve years old.<span>�
</span>They had managed to turn an imaginary $10,000 into $240,000 during the
first round of the competition.<span>� </span>From
there, Lebed was able to convince his parents to invest money in the stock
market on his behalf.<span>� </span>His parents first
opened an Ameritrade account for him, and upon his mother�s decision to close
that account, his father opened an E*Trade account for him.<span>� </span>During two years of trading, Lebed made a
minimum of 27 trades, and netted nearly $800,000.<span>� </span>The SEC later investigated these 27 trades and eventually
declared eleven of them as illegal trades and forced to Lebed to pay
approximately $272,000 in fines and over $12,000 in interest.<span>� </span>In particular, these eleven trades occurred
during the five and a half month period between August 23, 1999, and February
4, 2000.<span>� </span>While Lebed never admitted or
denied the findings by the SEC, he consented to entry of the findings and the
imposition of sanctions.<a href="#_ftn1" name="_ftnref1" title=""><span><span><!--[if !supportFootnotes]-->[1]<!--[endif]--></span></span></a></p>

<p>The SEC findings
asserted that Lebed would purchase large blocks of thinly traded microcap
stocks, post between 200 and 300 messages on the Yahoo! Finance message boards,
hyping the stocks he had just purchased, and then sell all of the stocks he had
purchased, usually within twenty-four hours of said purchase.<span>� </span>The messages that Lebed posted would predict
marked increases in the stocks value, i.e. he would post comments that this
stock would be the �next stock to gain 1,000%� or that a stock currently
trading at just over a dollar would be trading at more than $20 per share �very
soon.�<span>� </span>In response to Lebed�s messages,
trading volume of these stocks would soar on average from 60,000 shares per day
to over a million shares on the days he posted his messages.<span>�� </span>For the eleven trades that the SEC declared
its findings, Lebed realized a net profit of $272,826.<span>� </span>The individual gross profits ranged from
over $11,000 per trade to nearly $74,000.<span>�
</span>Lebed professes that he did nothing wrong � he did nothing different
from Wall Street analysts.<span>� </span>He states
that he learned how people react to the stock market and acted on that
knowledge.<span>� </span>According to Lebed�s
friends, even Lebed�s teachers would follow his advice regarding the stock
market.<span>� </span>While one of Lebed�s friends
lost a significant amount of money on one of the trades Lebed pushed, he states
�[i]n the stock market, you go in knowing you can lose.<span>� </span>We were just doing what Jon was doing, but not
doing as good a job at it.�<a href="#_ftn2" name="_ftnref2" title=""><span><span><!--[if !supportFootnotes]-->[2]<!--[endif]--></span></span></a></p>

<p>Depending on who
you talk to, Lebed was either viewed as a person who knowingly abused the
system and broke the law, or someone who acted no differently than Wall Street
analysts acted and was able to use the system to his advantage, actually
performing no wrong-doing.<span>� </span>Lebed�s own
father stated on 60 Minutes that he was proud of his son and that he hadn�t
done anything wrong.<span>� </span>This belief can
also be evinced by the fact that after Lebed�s first meeting with the SEC,
while his mother closed the Ameritrade account, Lebed�s father opened an
E*Trade account so that Lebed could continue to trade stocks.<span>� </span>The SEC, however, stated that Lebed violated
Section 17(a) of the Securities Act and Section 10(b) and Rule 10b-5 of the
Exchange Act.<span>� </span>These Acts �prohibit
acts, transactions, practices or course of business that operate as a fraud or
deceit in connection with the offer, purchase or sale of securities, including
misrepresentation and omissions of material fact.�<a href="#_ftn3" name="_ftnref3" title=""><span><span><!--[if !supportFootnotes]-->[3]<!--[endif]--></span></span></a><span>� </span>The SEC therefore ordered Lebed pay his fine
and to �cease and desist� from causing any further violation of Section 17(a).</p>

<p>Even the news
articles that covered Lebed�s actions appear split on whether he had done
anything wrong.<span>� </span>While an article
written by Peter Carbonara for Money Magazine<a href="#_ftn4" name="_ftnref4" title=""><span><span><!--[if !supportFootnotes]-->[4]<!--[endif]--></span></span></a>
appears to favor the SEC decision (albeit wondering why the SEC let Lebed keep
the remaining $500,000 of profit), Michael Lewis, writing for New York Times
Magazine,<a href="#_ftn5" name="_ftnref5" title=""><span><span><!--[if !supportFootnotes]-->[5]<!--[endif]--></span></span></a>
acknowledges that there were victims who suffered from Lebed�s actions, yet asserts
that the SEC only settled because they believed they would not be able to win
in court, and that its evidence was not as strong as it had alleged. </p>

</div><div><!--[if !supportFootnotes]--><br clear="all">

<hr size="1">

<!--[endif]-->

<p><a href="#_ftnref1" name="_ftn1" title=""><span><span><!--[if !supportFootnotes]-->[1]<!--[endif]--></span></span></a> In Re:
Lebed, No. 3-10291, 2000 SEC LEXIS 1964, at *1 (Sept. 20, 2000).</p>

<p><a href="#_ftnref2" name="_ftn2" title=""><span><span><!--[if !supportFootnotes]-->[2]<!--[endif]--></span></span></a> Michael
Lewis, <i>He Wanted to Get Rich.<span>� </span>He Wanted to Tune Out his School-Kid
Life.<span>� </span>And Neither His Parents Nor the
S.E.C. was in a Position to Stop Him: Jonathan Lebed�s Extracurricular
Activities</i>, New York Times Magazine, February 25, 2001.</p>

<p><a href="#_ftnref3" name="_ftn3" title=""><span><span><!--[if !supportFootnotes]-->[3]<!--[endif]--></span></span></a> <i>Id.</i> at *6.</p>

<p><a href="#_ftnref4" name="_ftn4" title=""><span><span><!--[if !supportFootnotes]-->[4]<!--[endif]--></span></span></a> March 2001, <i>available at</i>
http://www62.homepage.villanova.edu/john.matthews/conkid.html</p>

<p><a href="#_ftnref5" name="_ftn5" title=""><span><span><!--[if !supportFootnotes]-->[5]<!--[endif]--></span></span></a> February 25,
2001, <i>available at</i> http://www62.homepage.villanova.edu/john.matthews/conkid.html
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Glossarie – a new, immersive way to learn a language (233 pts)]]></title>
            <link>https://glossarie.app/</link>
            <guid>39807912</guid>
            <pubDate>Sun, 24 Mar 2024 15:43:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://glossarie.app/">https://glossarie.app/</a>, See on <a href="https://news.ycombinator.com/item?id=39807912">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="315" data-elementor-post-type="page">
						<div data-id="9f7aa30" data-element_type="section">
					<div data-id="1af7f31" data-element_type="column">
						<div data-id="8a0cead" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" width="433" height="94" src="https://glossarie.app/wp-content/uploads/2023/04/logo_white.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2023/04/logo_white.png 433w, https://glossarie.app/wp-content/uploads/2023/04/logo_white-300x65.png 300w" sizes="(max-width: 433px) 100vw, 433px">													</p>
				</div>
				
				
				<div data-id="92a868e" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
							<h3>Learn vocabulary the natural, immersive way. Build your skills in French, Italian or Spanish whilst you read your favourite books.</h3>						</p>
				</div>
				
					</div>
				<div data-id="cc856bf" data-element_type="column" data-widget_type="image.default">
				<p><img decoding="async" width="483" height="1024" src="https://glossarie.app/wp-content/uploads/2023/08/full-483x1024.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2023/08/full-483x1024.png 483w, https://glossarie.app/wp-content/uploads/2023/08/full-141x300.png 141w, https://glossarie.app/wp-content/uploads/2023/08/full-768x1629.png 768w, https://glossarie.app/wp-content/uploads/2023/08/full-724x1536.png 724w, https://glossarie.app/wp-content/uploads/2023/08/full-966x2048.png 966w, https://glossarie.app/wp-content/uploads/2023/08/full.png 1178w" sizes="(max-width: 483px) 100vw, 483px">													</p>
				</div>
					</div>
				<div data-id="28fdac2" data-element_type="section" data-widget_type="heading.default">
				<p>
			<h2>Features</h2>		</p>
				</div>
				<div data-id="45628746" data-element_type="section">
					<div data-id="4cc6363" data-element_type="column" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="1530" height="3036" src="https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2.png 1530w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2-151x300.png 151w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2-516x1024.png 516w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2-768x1524.png 768w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2-774x1536.png 774w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_09-2-1032x2048.png 1032w" sizes="(max-width: 1530px) 100vw, 1530px">													</p>
				</div>
				<div data-id="613e7c2" data-element_type="column">
						<div data-id="2bbf3b7" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						Learn new words and phrases as you read					</span>
				</h3>
									<p>
						Build your vocabulary over time, learning in context - the natural way - using spaced repetition to reinforce your learning					</p>
							</div>
				
				<div data-id="faa884f" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						Progress via multiple levels of difficulty					</span>
				</h3>
									<p>
						Start with basic words and progress to intermediate grammar and advanced vocabulary					</p>
							</div>
					</div>
					</div>
				
				<div data-id="2a45c01" data-element_type="section">
					<div data-id="14fe7f70" data-element_type="column">
						<div data-id="475b5371" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						Get detailed explanations of each translation					</span>
				</h3>
									<p>
						Learn how each word relates in the translation: verb conjugations, root words, typical usage					</p>
							</div>
				
				<div data-id="2b5e3ee" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						Learn correct pronunciation					</span>
				</h3>
									<p>
						Listen to words and phrases as they should be spoken					</p>
							</div>
					</div>
				<div data-id="305d86c5" data-element_type="column" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="1178" height="2498" src="https://glossarie.app/wp-content/uploads/2023/07/explanation.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2023/07/explanation.png 1178w, https://glossarie.app/wp-content/uploads/2023/07/explanation-141x300.png 141w, https://glossarie.app/wp-content/uploads/2023/07/explanation-483x1024.png 483w, https://glossarie.app/wp-content/uploads/2023/07/explanation-768x1629.png 768w, https://glossarie.app/wp-content/uploads/2023/07/explanation-724x1536.png 724w, https://glossarie.app/wp-content/uploads/2023/07/explanation-966x2048.png 966w" sizes="(max-width: 1178px) 100vw, 1178px">													</p>
				</div>
					</div>
				
				<div data-id="aa0ffbb" data-element_type="section">
					<div data-id="348bf08" data-element_type="column" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="1530" height="3036" src="https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38.png 1530w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38-151x300.png 151w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38-516x1024.png 516w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38-768x1524.png 768w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38-774x1536.png 774w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-18_38-1032x2048.png 1032w" sizes="(max-width: 1530px) 100vw, 1530px">													</p>
				</div>
				<div data-id="4f152f1" data-element_type="column">
						<div data-id="7d0e8da" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						Start with one of dozens of free ebooks....					</span>
				</h3>
									<p>
						With many more to come					</p>
							</div>
				
				<div data-id="6b3b524" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						...or upload your own					</span>
				</h3>
									<p>
						Currently supports epub and txt files					</p>
							</div>
					</div>
				<div data-id="3a04a0f" data-element_type="column" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="1178" height="2498" src="https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122.png 1178w, https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122-141x300.png 141w, https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122-483x1024.png 483w, https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122-768x1629.png 768w, https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122-724x1536.png 724w, https://glossarie.app/wp-content/uploads/2023/04/Screenshot_20230424_153122-966x2048.png 966w" sizes="(max-width: 1178px) 100vw, 1178px">													</p>
				</div>
					</div>
				
				<div data-id="2e5ccac" data-element_type="section">
					<div data-id="8bf75d6" data-element_type="column" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="516" height="1024" src="https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14-516x1024.png" alt="" srcset="https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14-516x1024.png 516w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14-151x300.png 151w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14-768x1524.png 768w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14-774x1536.png 774w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14-1032x2048.png 1032w, https://glossarie.app/wp-content/uploads/2024/02/iFrameScreenshot-07_02_2024-16_14.png 1530w" sizes="(max-width: 516px) 100vw, 516px">													</p>
				</div>
				<div data-id="a1402d6" data-element_type="column" data-settings="{&quot;_animation&quot;:&quot;fadeInLeft&quot;,&quot;_animation_delay&quot;:&quot;400&quot;}" data-widget_type="icon-box.default">
				<h3>
					<span>
						Practice your vocabulary					</span>
				</h3>
									<p>
						Test yourself on useful phrases in your target language, with helpful guidance for incorrect answers					</p>
							</div>
					</div>
				
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Super memory': Why Emily Nash is sharing her brain with science (134 pts)]]></title>
            <link>https://www.ctvnews.ca/w5/why-18-year-old-canadian-emily-nash-is-sharing-her-unique-brain-with-science-1.6818765</link>
            <guid>39807759</guid>
            <pubDate>Sun, 24 Mar 2024 15:19:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ctvnews.ca/w5/why-18-year-old-canadian-emily-nash-is-sharing-her-unique-brain-with-science-1.6818765">https://www.ctvnews.ca/w5/why-18-year-old-canadian-emily-nash-is-sharing-her-unique-brain-with-science-1.6818765</a>, See on <a href="https://news.ycombinator.com/item?id=39807759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     
    <p> An 18-year-old from near Ottawa has become what appears to be the first Canadian, and among the youngest people in the world, to have a rare but extraordinary super memory.</p> <p> Emily Nash learned she has highly superior autobiographical memory (HSAM) after being tested by researchers in the U.S.</p> <p> She now jokingly calls it her “superpower,” relieved to learn that the trait she tried to hide was actually a verifiable phenomenon.</p> <p> “I just felt so much relief knowing that I'm not alone, that it's not something I made up. It's something that actually exists,” she told CTV W5 in an exclusive interview.</p> <ul>  <li> <strong><a href="https://www.ctvnews.ca/w5">Watch the latest W5 investigations</a></strong></li> </ul> <p> Emily is a straight-A student. In her last year of high school, she is decidedly composed and modest about her skill. But she now joins a small and unique tribe of about 100 people confirmed with HSAM around the world.</p> <p> For most of us, memories fade with time.</p> <p> Ask anyone to tell you what happened on Oct. 21, 2021 and you will usually be met with a lengthy pause as they struggle to recall events of that day.</p> <p> But ask Emily and the response comes within seconds, with precision. “October 21, 2021? Oh, the Alec Baldwin ‘Rust’ shooting. That was a Thursday,” she quickly responded.</p> <p> March 4, 2019? “Luke Perry died,” she stated, noting she never watched the actor’s show, but rather just heard about his passing. “ My mom took me home for lunch, and I remember in the car we had the radio on and they said Luke Perry passed away.” That is all it took for her to remember this detail four-and-a-half years later.</p> <p> <img src="https://www.ctvnews.ca/content/dam/ctvnews/en/images/2024/3/23/emily-nash--ctv-w5-1-6819460-1711199260433.jpeg" alt=""><span>Emily Nash said her memories are filed in a mental calendar, in video form (CTV W5) </span></p> <p> Emily said her memories are filed in a mental calendar, in video form. “Each day kind of represents a little movie, where I can rewind and fast forward and replay various points throughout my day,” she said.</p> <p> Her parents, Jason Nash and Julie Farnworth, said they spotted Emily’s uncanny recall as a young child.</p> <p> Her father, Jason, said he would show Emily a series of coloured bowling pins for about 10 seconds and then spin her around, asking her to name the order they were in.</p> <p> “She would knock them off right away in terms of identifying every pin, in terms of, you know, red, yellow, green, blue,” he said.</p> <p> Her mother, Julie, discovered Emily -- at age five -- could watch a Peanuts cartoon and then recall and repeat the dialogue from any point in the episode.</p> <p> “We knew that at that point in time there was something going on with her memory, but we couldn't quite pinpoint what it was like. So we thought we should just let it develop a little more naturally on its own to try and figure out what it is,” Julie said.</p> <p> They finally figured it out, coincidentally, on Remembrance Day 2021.</p> <ul>  <li> <a href="https://www.ctvnews.ca/app"><strong>The information you need to know, sent directly to you: Download the CTV News App</strong></a></li> </ul> <ul>  <li> <a href="https://www.ctvnews.ca/newsletters"><strong>Sign up for breaking news alerts from CTV News, right at your fingertips</strong></a></li> </ul> <p> As Julie was designing a tombstone for her parents, she was asked by the headstone designer for specific dates of their births and marriage. Julie joked that she would contact “Wikipedia” -- the family pet name for Emily -- who rapidly texted back all the correct dates.</p> <p> That’s when the headstone designer suggested Emily might have the same sort of unusual memory first documented in a "60 Minutes" program from 2010, featuring American actress Marilu Henner. The Broadway star and main character of the 1970s sitcom “Taxi” revealed she has a super autobiographical memory for dates and events.</p> <p> “It was a jaw-dropping moment when I realized the similarities," said Julie, after watching the documentary program. That's when the pointed questions to their daughter began.</p> <p> “We said, ‘well, can you name the day of the week? Can you go back, you know, a year and tell us exactly what you did on that date? You know, what were you wearing? What did you eat?’ She was able to explain all those things,” said Jason. For Emily, it was validation that she wasn’t, as she puts, it “weird.”</p> <p> “Knowing that other people have it in the world, I just felt so much relief knowing that I'm not alone,” she said.</p> <p> <img src="https://www.ctvnews.ca/content/dam/ctvnews/en/images/2024/3/23/emily-nash-was-formally-tested-by-scientists-1-6819462-1711199410329.jpg" alt=""><span>Emily Nash was formally tested by scientists at Northwestern University in Chicago, and by Carmen Westerberg, a psychology and sleep researcher at Texas State University (CTV W5).</span></p> <p> Emily was then formally tested by scientists at Northwestern University in Chicago, and by Carmen Westerberg, a psychology and sleep researcher at Texas State University. The test usually involves giving someone random dates, asking them to specify the day of the week, personal experiences, along with verifiable events around that time.</p> <p> But because Emily is among the youngest the team had assessed, they had to adjust the screening questions to adapt to the life experiences of a teen.</p> <p> “That was one thing that stuck out," said Westerberg. Any time we asked her a pop culture question, she was all over it, but she didn't have as much knowledge about world events.”</p> <p> CTV W5 was able to film a sample test, where Emily was asked about a variety of dates, starting with Nov. 26, 2021.</p> <p> “That was a Friday,” said Emily.</p> <p> “Do you recall a verifiable event from around that time?” asked Westerberg.</p> <p> “Let's see,” said Emily, who then amazingly rattled off a comprehensive list.</p> <p> “A Netflix film called ‘Tick, Tick Boom’ was released on Nov. 10th, 2021.</p> <p> “’The House of Gucci,’ released Nov. 24th, 2021.</p> <p> “’West Side Story’ -- that came in theaters Dec. 3rd, I'm pretty sure, 2021,” she said.</p> <p> She was 100 percent correct.</p> <p> When Emily was asked if she wanted researchers to help understand HSAM to see if it might unlock clues to help those with memory loss, she didn’t hesitate. She lives with the memory of watching two of her grandparents suffer because of dementia. “ I want to help in the best way possible with my memory,” said Emily.</p> <h2> Super memory as a way of tackling memory loss</h2> <p> Scientists only began studying HSAM in 2006. They have confirmed it’s not related to IQ and that those with superior memory don’t use tricks to remember. It is found more often in people with obsessive- compulsive disorder (OCD), though in Emily’s case her mother confirms her only obsession is her school work.</p> <p> The most intriguing discovery of people with HSAM, say scientists, is that their memories don’t decay like the vast majority of people. “They're not really taking in more information. It's just that they are not forgetting it like most people do.” said Westerberg.</p> <p> In a world where there are an estimated 10 million people a year developing memory loss linked to dementia and Alzheimers, HSAM is a “juicy phenomenon,” according to Giuliana Mazzoni, a researcher at the University of Rome.</p> <p> Mazzoni is studying the phenomenon in a group of Italians with HSAM because of the intriguing lessons they may hold. Westerberg agrees, saying, “If we can figure out what's going right with memory, maybe we can help with what's going wrong.”</p> <p> Mazzoni is among a group of scientists who are trying to identify the regions of the brain that appear more active in those with highly superior autobiographical memory. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010945219300887?via%3Dihub" target="_blank">Her early work </a>suggested more grey matter in parts of the brain along with a higher emphasis on visual recording of daily events.</p> <p> There are also tests starting to apply what’s being learned. A group of patients with early Alzheimer’s disease are receiving transcranial magnetic stimulation, targeting the circuit identified in HSAM as part of a trial at the University of Perugia and University of Trento. The question: will the signals improve patients memory?</p> <p> <img src="https://www.ctvnews.ca/content/dam/ctvnews/en/images/2024/3/23/the-experiment-is-led-by-prof--costanza-papagno-1-6819455-1711198823110.jpeg" alt=""><span>The experiment is led by Prof. Costanza Papagno, professor of neurology at the University of Trento (Photo courtesy of Costanza Papagno)</span></p> <h2> Emily’s sleep</h2> <p> The study that Emily has signed up for has her putting on her pajamas.</p> <p> In a sleep laboratory in the basement of a building on the campus of Texas State University, in Austin, a technician glues sensors to her head and chest for an overnight sleep study. It’s all in the name of dementia research.</p> <p> Sleep is where scientists believe memories are cemented into the brain.</p> <p> Westerberg and colleagues at Northwestern University in Chicago have been probing how sleep might help those with superior autobiographical memory. The team is about halfway through a study comparing 12 adults with HSAM against 24 normal controls. Emily is patient number nine.</p> <p> Both groups, says Westerberg, sleep about the same total time. But those with HSAM differ in one important area -- sleep spindles.</p> <ul>  <li> <strong><a href="https://www.ctvnews.ca/sci-tech">Top science and technology headlines, all in one place</a></strong></li> </ul> <p> On an electroencephalogram (EEG), the test used to track brain waves during sleep, spindles look like random, tiny, jagged lines along the otherwise smooth brain signals of early sleep. But this pattern is how some scientists think our brains synchronize memories and deposit them for future use.</p> <p> As Westerberg compares the results, she says she is finding people with HSAM have more sleep spindles, almost double, than people with normal memory, along with an unusual pattern with the early slow ways of sleep. She calls it “exciting.”</p> <p> “This is suggesting that maybe they are consolidating their memories of what happened to them during the day more strongly or more efficiently than other people, which could help explain why they're not forgetting as much,” Westerberg said.</p> <p> Her study will be completed later in 2024, but it does raise some tantalizing possibilities.</p> <p> People with cognitive decline and dementia have often troubled sleep and, interestingly, disrupted or abnormal <a href="https://pubmed.ncbi.nlm.nih.gov/32853916/" target="_blank">sleep spindles</a> and slow wave phase sleep patterns. So could helping restore normal sleep and those spindles improve their memories? Westerberg points to studies that show some sleep medications have been shown to increase spindles, and slow wave sleep.</p> <p> “By getting better sleep and, in particular, you know, these slow oscillations linked with the sleep spindles…maybe that could improve memory,” she said.</p> <h2> The road forward for a girl who can’t forget</h2> <p> As soon as Emily returned from testing in Austin, she began to receive acceptance from every university program to which she applied. Her plan is a career in scientific research.</p> <p> “I'm thinking either like biomedical science, biotechnology,” she said.</p> <p> Emily has another shorter term goal. That is to meet others with this “gift.” While HSAM has its benefits, there is a serious drawback. Those with superior memory remember the good, but they will also never forget the bad. They feel the pain as if it were today. Some with HSAM struggle with anxiety and depression as a result.</p> <p> While Emily hasn’t yet suffered much rejection or loss, she’s felt the sting of the past hurts. “It's like I just re-lived them 5 minutes ago. So it can be difficult for me to push through,” said Emily.</p> <p> That’s why Julie, a psychiatric nurse, is putting great effort into coaching her daughter on how to manage that burden.</p> <p> “I've tried to teach her that everybody has heartbreak. That is part of life,” said Julie. “There will be breakups, and she has to expect that, and it's part of our growth.”</p> <p> But it worries Julie. “I won't lie. Sometimes it does keep me up at night thinking,....how will it be for her? I don't think any of us can quite conceptualize what it will be like for her” she said.</p> <ul>  <li> <a href="https://www.ctvnews.ca/newsletters"><strong>5 Things to Know newsletter: Sign up to start your day with the top stories</strong></a></li> </ul> <p> Markie Pasternak said she can understand Emily’s situation, perfectly.</p> <p> The 29-year-old from Minneapolis discovered she had HSAM while sitting in a university class, discussing the power of memory and posting blogs on her website, <a href="https://livingwithtotalrecall.home.blog/" target="_blank">Living with Total Recall</a>.</p> <p> Pasternak has met three others with HSAM. Emily is her fourth.</p> <p> “I think it's courageous. I think it's courageous to take that step, to admit that you have this,” said Pasternak of Emily’s decision to go public. They chatted for about half-an-hour by Zoom as Emily, clearly happy to meet someone from her unusual tribe, asked a raft of questions.</p> <p> “How does your memory work? Like, mine's like a calendar,” she said.</p> <p> Markie described hers as more of a board game. “Each day is different, like square and like, they're different colors, and it kind of zig zags around. It's almost like I can go forward and backwards,” she said.</p> <p> “Do you let people know that you have HSAM or do you wait until it's brought up?” asked Emily.</p> <p> “With friendships and acquaintances and stuff or work, even, I just wait until it comes up, and it usually does,” responded Markie, warning that there is a vulnerability to allowing people to ask her to pull up memories. Some may bring happiness, others, sharp pain.</p> <p> “It’s like my most precious gem, my like, most … sacred thing to me,” said Markie, describing her memories. “And I'm going to open up to you and you can ask me any day in my life and I'm going to tell you what I did that day.”</p> <p> Another question: “Does your brain ever stop thinking? Or is your brain just flying with memories like 24-7?” asked Emily.</p> <p> “My default was always just reminiscing, nostalgia,” said Markie, who added she copes by journaling. “I've learned to compartmentalize (and) have worked on my own mental health, too, and my own personal boundaries with that,” she said.</p> <p> The most important advice she offered Emily is that if you can’t forget, you need to cultivate forgiveness.</p> <p> “Everyone gets hurt by other people at some point because we're all human. And most people, again, they have their forgetfulness to kind of ease that and move on,” said Markie. “We don't have that. And so we have to rely so hard on the virtue of forgiveness and recognizing that people are human and they make mistakes.”</p> <h2> Think you have HSAM? Test it out</h2> <p> While there are only about 100-200 verified cases of HSAM in the world, scientists suspect there are many more.</p> <p> Prof. Valerio Santangelo, a professor of cognitive psychology at the University of Perugia in Italy, has calculated that theoretically 0.01 per cent of the population could have a highly superior autobiographical memory. That could mean 700,000 people around the world who fit the criteria but have not been formally tested.</p> <p> Part of this may be because there have been few scientists studying this form of memory, and has to be culturally and age appropriate. In Emily’s case, researchers at Northwestern University and The University of Texas, Austin, had to make questions appropriate for an 18-year-old who prefers movies and music to world affairs.</p> <p> While there is no online screening tool, Dr. James McGaugh, a now retired professor emeritus at the <a href="https://cnlm.uci.edu/" target="_blank">Center for the Neurobiology of Learning and Memory</a> at the University of California, Irvine, who helped discover HSAM, told CTV’s W5 that people can start with their own screening test.</p> <p> They begin by selecting well-known events and asking the person for the date and the day of the week when the event occurred.</p> <p> They can also randomly select a day or date, and ask for verifiable events around that date.</p> <p> He added that “it is critically important to emphasize that HSAM is a strong ability to recall autobiographical experiences, along with the day and dates.” In creating questions, the advice is to use events that are noteworthy and that occurred after the test subject was about 15 years old.</p> <p> <strong>For example: </strong></p> <p> <em>Day and Date of Super Bowl in 2015?</em></p> <p> Answer: Feb. 1.</p> <p> <em>Day and Date of Canadian Thanksgiving in 2017?</em></p> <p> Answer: Monday, Oct. 9, 2017.</p> <p> Or you can ask, <em>what event occurred Feb 1, 2015? </em></p> <p> Answer: The Superbowl.</p> <p> Researchers use something called the "10 Date Quiz," using randomly selected dates, picked by an <a href="https://www.random.org/calendar-dates/" target="_blank">online calculator like this one</a>.</p> <p> Test subjects get a point for identifying the event, the day of the week, the month and the year.</p> <p> Individuals were asked to provide three different categories of information for each of the 10 dates generated:</p> <p> (1) the day of the week;</p> <p> (2) a description of a verifiable event that could be confirmed via an online search</p> <p> (3) a description of a personal autobiographical event the individual participated in.</p> <p> That’s a maximum of three possible points per date and 30 total. The percentage scored for each category (date/day/event) as well as the total score, the average of all three categories, was calculated.</p> <p> A total score of 65 per cent indicates that a person is likely to have HSAM and would merit further testing by researchers at a center studying this autobiographical memory.</p> <p> <em>Watch W5's documentary 'Total Recall' in our video player at the top of this article</em></p> <p> <em>With files from producers&nbsp;</em><em>Maya Hamovitch and&nbsp;</em><em>Kevin O'Keefe</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Weather Planning for Eclipse Day (124 pts)]]></title>
            <link>https://eclipsophile.com/eclipse-day-weather/</link>
            <guid>39807463</guid>
            <pubDate>Sun, 24 Mar 2024 14:31:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclipsophile.com/eclipse-day-weather/">https://eclipsophile.com/eclipse-day-weather/</a>, See on <a href="https://news.ycombinator.com/item?id=39807463">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" role="main">

			
<article id="post-4101" class="page">
	<!-- .entry-header -->
	<div>
		
<p><span><strong>Quick links</strong></span></p>
<p>The following quick-link tables lead to useful sources of satellite imagery and numerical (model) forecasts.&nbsp; A fuller explanation of the sources can be found below the tables.</p>
<p><span><span><em>Satellites</em></span></span></p>
<div id="wptb-table-id-4149" data-wptb-version="1.4.13" data-wptb-pro-status="false"><table data-reconstraction="1" data-wptb-table-tds-sum-max-width="621" data-wptb-cells-width-auto-count="1" data-wptb-horizontal-scroll-status="false" data-wptb-extra-styles="LyogRW50ZXIgeW91ciBjdXN0b20gQ1NTIHJ1bGVzIGhlcmUgKi8=" role="table" data-wptb-even-row-background-color="#F9F0ACFF" data-wptb-odd-row-background-color="#F9F0ACFF" data-wptb-header-background-color="#B6E5F6FF" data-table-columns="3"><tbody><tr><td data-y-index="0" data-x-index="0"><div><p><strong>Site</strong></p></div></td><td data-y-index="0" data-x-index="1"><div><p><strong>Description</strong></p></div></td><td data-y-index="0" data-x-index="2" data-wptb-css-td-auto-width="true"><div><p><strong>Go-to Link</strong><br></p></div></td></tr><tr><td data-y-index="1" data-x-index="0"><div><p><strong>College of DuPage</strong><br></p></div></td><td data-y-index="1" data-x-index="1"><div><p>A site used by storm chasers and one of the quickest to update with new images at 5-minute intervals . No mouse-wheel zoom, but can select from many high-resolution sectors. All wavelengths including colour composites. Can overlay radar, highways, and station weather reports, making this site the most useful for quick relocation to a more favourable spot. Auto refresh.</p></div></td><td data-y-index="1" data-x-index="2" data-wptb-css-td-auto-width="true"><div>            <a id="CoD" href="https://weather.cod.edu/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>CoD</p></div>            </a>        </div></td></tr><tr><td data-y-index="2" data-x-index="0"><div><p><strong>Windy</strong></p></div></td><td data-y-index="2" data-x-index="1"><div><p>A commercial site popular with eclipse chasers in 2023. Zoom with mouse wheel. Auto-refresh.</p></div></td><td data-y-index="2" data-x-index="2" data-wptb-css-td-auto-width="true"><div>            <a href="https://windy.com/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>Windy.com</p></div>            </a>        </div></td></tr><tr><td data-y-index="3" data-x-index="0"><div><p><strong>US National Weather Service GOES Image Viewer:</strong></p></div></td><td data-y-index="3" data-x-index="1"><div><p>A comprehensive site for the United States and nearby Canada and Mexico. All wavelengths available. No zoom, but continent is divided into high-resolution sectors. Can be set to auto-refresh.</p></div></td><td data-y-index="3" data-x-index="2" data-wptb-css-td-auto-width="true"><div>            <a href="https://www.star.nesdis.noaa.gov/goes/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>NWS GOES<br></p></div>            </a>        </div></td></tr></tbody></table></div>

<p><em><span>Numerical Models</span></em></p>
<div id="wptb-table-id-4151" data-wptb-version="1.4.13" data-wptb-pro-status="false"><table data-reconstraction="1" data-wptb-table-tds-sum-max-width="351" data-wptb-cells-width-auto-count="1" data-wptb-horizontal-scroll-status="false" data-wptb-extra-styles="LyogRW50ZXIgeW91ciBjdXN0b20gQ1NTIHJ1bGVzIGhlcmUgKi8=" role="table" data-wptb-apply-table-container-max-width="1" data-wptb-table-container-max-width="700" data-wptb-header-background-color="#FFDC82FF" data-wptb-even-row-background-color="#C2F9F9FF" data-wptb-odd-row-background-color="#C2F9F9FF" data-table-columns="3"><tbody><tr><td data-y-index="0" data-x-index="0"><div><p>Model Source<br></p></div></td><td data-y-index="0" data-x-index="1"><div><p>Link</p></div></td><td data-y-index="0" data-x-index="2" data-wptb-css-td-auto-width="true"><div><p>Description</p></div></td></tr><tr><td data-y-index="1" data-x-index="0" data-wptb-cell-vertical-alignment="center"><div><p>Windy</p></div></td><td data-y-index="1" data-x-index="1" data-wptb-cell-vertical-alignment="center"><div>            <a href="https://windy.com/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>Windy<br></p></div>            </a>        </div></td><td data-y-index="1" data-x-index="2" data-wptb-css-td-auto-width="true"><div><p>Windy free version opens in global ECMWF model, generally regarded as the best of the long-range predictions. Five other models available for quick comparison. Many parameters available but cloud is likely the most critical. NAM and HRRR models don’t go much beyond the US borders but ICON and GFS are global.</p></div></td></tr><tr><td data-y-index="2" data-x-index="0"><div><p>College of DuPage<br></p></div></td><td data-y-index="2" data-x-index="1"><div>            <a href="https://weather.cod.edu/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>CoD</p></div>            </a>        </div></td><td data-y-index="2" data-x-index="2" data-wptb-css-td-auto-width="true"><div><p>A favourite storm-chaser’s site with a limited number of models available, mostly from Canada and the U.S. Not all models show cloud cover. The NAMNST model has a simulated satellite image of future cloud, out to 60 hours. Very limited ECMWF data. GFS model goes out 16 days.<br></p></div></td></tr><tr><td data-y-index="3" data-x-index="0"><div><p>Spot Weather<br></p></div></td><td data-y-index="3" data-x-index="1"><div>            <a href="https://spotwx.com/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>Spotwx</p></div>            </a>        </div></td><td data-y-index="3" data-x-index="2" data-wptb-css-td-auto-width="true"><div><p>Spotwx provides you with graphical displays of weather parameters at a single location (which can be anywhere on the globe). Easy to use, with several models available for North America. You’ll have to go to the other sites above to look around for better weather, but if you are not trying to move, it will help you monitor what the numerical world thinks is coming to you at your site. No ECMWF.<br></p></div></td></tr><tr><td data-x-index="0" data-y-index="4"><div><p>Pivotal Weather<br></p></div></td><td data-x-index="1" data-y-index="4" data-wptb-cell-vertical-alignment="center"><div>            <a id="pivotwx" href="https://home.pivotalweather.com/">                <div data-wptb-element-bg-color="#329d3f" data-wptb-element-color="#FFFFFF" data-wptb-element-hover-bg-color="null" data-wptb-element-hover-text-color="null" data-wptb-element-hover-scale="1"><p>Pivotal Weather<br></p></div>            </a>        </div></td><td data-x-index="2" data-y-index="4" data-wptb-css-td-auto-width="true"><div><p>Pivotal Weather, also a favourite with storm chasers, offers access to a large number of long- and short-range models(ECMWF, GFS, GDPS, NAM, and so on). You may wish to explore the GEFS and the CMCE models, which are ensemble models (the average of many models) that extend to 16 and 10 days respectively and show cloud cover. See the description below. Watch out for the colour scheme: clear areas are white and cloudy areas are blue. Your cursor will show forecast cloud amount in percent. One of my favourites, but no satellite images. For an early look at eclipse day, the CFS model goes out 32 days but doesn't include cloud cover.<br></p></div></td></tr></tbody></table></div>

<p><span><em><span>Background notes about the satellites</span></em></span></p>
<p>The 2024 TSE could be a meteorological challenge.&nbsp; While the <em>Eclipsophile</em> climate studies are useful for long-range planning, they becomes less and less helpful when eclipse day is less than a week away. By late March, 2024, eclipse-day tactics should turn to the regular long- and short-range forecasts available from a number of agencies. On the day before the eclipse, numerical forecasts have lost much of their value and should be augmented by satellite and radar data and by reports from surface weather stations.</p>
<p>Satellites maintain a continuous watch across North America and the satellite of choice for this event is <em>GOES East</em>, located over the equator and streaming images at 5-minute intervals. There are many public and commercial web sites that can do proper justice to the resolution of GOES E imagery, but you will probably appreciate those that show full-colour images.</p>
<figure id="attachment_4106" aria-describedby="caption-attachment-4106"><a href="https://eclipsophile.com/wp-content/uploads/2023/08/GOES-Sample.jpg"><img decoding="async" src="https://eclipsophile.com/wp-content/uploads/2023/08/GOES-Sample.jpg" alt="GOES East view of North America " width="625" height="375" srcset="https://eclipsophile.com/wp-content/uploads/2023/08/GOES-Sample.jpg 625w, https://eclipsophile.com/wp-content/uploads/2023/08/GOES-Sample-300x180.jpg 300w" sizes="(max-width: 625px) 100vw, 625px"></a><figcaption id="caption-attachment-4106"><span>Figure 1: A view of North America from GOES East. Note that night has fallen over the Atlantic and eastern seaboard where cloud depictions have a different appearance.</span></figcaption></figure>
<p>This eclipse comes in the middle of the day for the most part and so satellite images in visible wavelengths will be available for a few hours before the shadow reaches Mazatlán and for the whole day by the time it reaches Bonavista, Newfoundland. Even so, if you anticipate a long trip to clear skies, you will have to make use of the infrared images, which work at night.</p>
<p>The raw satellite data arrive at receiving stations as gray-scale images in many different wavelengths. Among those wavelengths, the current mix of geostationary satellites collect scenes in red, green, and blue frequencies during the daytime—a mixture that can be combined into a colour image as long as the Sun is up. When the Sun is down, a “pseudo-colour” image can be assembled from a mix of infrared wavelengths that mimics the appearance of daytime clouds (Figure 1). The day and night images merge well together—almost seamlessly—and now many sites offer the combination (GEOCOLOR) on their web sites.</p>
<p>Images from single wavebands are also commonly available, and you may wish to look at some of these, most likely at night if you are confronted by a difficult situation such as overnight fog.</p>
<p>For the most part, images from one Internet site are similar to those from another, but they differ in their interfaces and ability to zoom. The capability to put highways and station reports on top of the satellite image in the College of Dupage site could be valuable in a difficult, fast-changing situation.</p>
<p><em><span>A short primer on numerical models</span></em></p>
<p>Satellite photos are OK for what is happening now, but they are pretty limited in predicting what the weather will do two days in the future.&nbsp; For that information, we need to use computer forecasts (usually referred to as numerical forecasts or model forecasts). There are many types of numerical forecasts,&nbsp; way more than a dozen if you go looking. They are usually models run by countries for their own interests, but they share the code used in the models, so they are not completely independent of each other.</p>
<p><span>Types of models</span></p>
<p>There are two types of models: global long-range ones and regional short-range forecasts. In the U.S., the main long-range model is the GFS (15 days); short-range models are the NAM (84 hours), the RAP (21 hours), and the HRRR (18 hours). Canada contributes the GDPS for long range (15 days), and the RDPS (84 hours).&nbsp; The most commonly used European long-range model is the ECMWF, generally regarded as the most reliable, but it’s a commercial product and you have to look around to get the parts of it you’d like, but it’s readily available on windy.com. There are many more, especially if you chase eclipses somewhere other than North America.</p>
<p>For the most part (but changing rapidly), long-range models have lower resolution than short-range versions. Windy.com displays the model resolutions on their menu page: ECMWF, 9 km; GFS, 22 km; ICON, 13 km; NAM, 5 km; HRRR, 3 km. High resolution doesn’t necessarily mean better, but high-resolution models do update more frequently, essentially updating the forecast. The differences between the models are embedded in the code that runs the models, and so are not visible to you. The internal bits include such things as how cloud cover and precipitation are calculated, so you must expect some substantial differences between models. With luck (?), they will converge on the correct answer as eclipse day approaches.</p>
<p>A special type of numerical forecast is a type called an ensemble model. These show an average of many different model calculations (runs), each one slightly varying the starting parameters. There are several of them available at Pivotal Weather, but only the American GEFS and Canada’s CMCE show cloud cover. The CFS climate model available on Pivotal Weather goes out for 32 days, well past eclipse time, but the day-to-day forecasts are so erratic that they can’t be used for planning. It is designed for long-range climate predictions.</p>
<p>Almost all of the commonly available forecast outputs in North America are models maintained by NOAA’s modelling arm, including those that are presented in your evening news broadcast. Only a few of the largest private companies maintain their own models. For the most part, large commercial companies don’t give you much choice on satellite images or numerical models, but they’ll probably focus on where to watch the eclipse on the days ahead and that professional opinion could be invaluable.</p>
<p><span>How do you handle all of this?</span></p>
<p>Pick two long-range and two short-range models and run with them. I guarantee total confusion if you use more—they are just too variable unless eclipse day is nearby.</p>
<p>Commercial sites usually only show you “their” model, as they don’t want to imply that there is some uncertainty in the future they foresee. In many cases, their model is the National Weather Service model with some fancy graphics attached.</p>
<p><span>Don’t rely on models until eclipse day is around the corner</span></p>
<p>A word of caution: models aren’t really very good until about a week ahead of an event, and should improve steadily as the moment approaches. You might use the NAM and the RDPS for the two-three days ahead of the eclipse and the long-range models before. Once the models start to look like each other, with similar cloud patterns and precipitation amounts and when successive model runs keep the same forecast, you can begin to trust them. There will always be differences between them, but even that will tell you where things are uncertain and help you decide whether you might want to move to a spot where they all agree about good weather.</p>
<p>When eclipse day arrives and the weather at your site is looking iffy, the local weather channel or a satellite image may be all that you need. For the most part, it concentrates on what’s happening now and what will happen in the next few hours. That may be all you need. In the end, preparation and mobility will be important contributors to your success.</p>
<p>Good luck on eclipse day. Don’t forget to watch the shadow go by in the satellite images afterward.</p>
<p>Return to <a href="https://eclipsophile.com/">Eclipsosphile</a>.</p>
<p>Updated February 2024</p>
	</div><!-- .entry-content -->
</article><!-- #post-4101 -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ARM64EC (and ARM64X) Explained (103 pts)]]></title>
            <link>http://www.emulators.com/docs/abc_arm64ec_explained.htm</link>
            <guid>39806746</guid>
            <pubDate>Sun, 24 Mar 2024 12:16:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.emulators.com/docs/abc_arm64ec_explained.htm">http://www.emulators.com/docs/abc_arm64ec_explained.htm</a>, See on <a href="https://news.ycombinator.com/item?id=39806746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<div>
				<p><b><span face="Verdana" size="5">(c) 2024 by Darek Mihocka,&nbsp;founder, Emulators.com.</span></b></p>
				<p><b><span face="Verdana" size="5">updated 
				January 23 2024</span></b></p></div>
			<p><span face="Verdana" size="2">
			<b><a href="http://www.emulators.com/docs/nx44_intro_to_woa.htm#abc">[ARM64 Boot Camp: Table Of Contents]</a></b> <span color="#FF0000">
			&nbsp;</span><b><a href="http://www.emulators.com/index.htm">[Return to Emulators.com]</a></b></span></p><hr>
			
			<p><b><span face="Verdana" size="4">ARM64EC (and ARM64X) Explained<br>
			</span></b><span face="Verdana" size="2">
			<br>
			Probably the most confused looks I get from other developers when I 
			discuss Windows and ARM64 is when 
			I used the term "<b>ARM64EC</b>".&nbsp; They ask is the same thing 
			as ARM64?&nbsp; Is it a different instruction set than ARM64?&nbsp; How can you 
			tell if an application is or ARM64 ARM64EC?</span></p>
			<p><span face="Verdana" size="2">This tutorial will answer those 
			questions by de-mystifying and explaining the difference between 
			what can be called "<b>classic ARM64</b>" 
			as it existed since Windows 10, and this new "<b>ARM64<i>EC</i></b>" 
			which was introduced in Windows 11 in 2021.</span></p>
			<hr>
			<p><b><span face="Verdana">TL;DR</span></b></p>
			<p><span face="Verdana" size="2">In short, these are the ten quick 
			facts you need to know about ARM64EC and ARM64X:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">- <b>ARM64EC is not a new 
				instruction set</b>, it uses the same 64-bit ARMv8 instruction 
				set as used in Windows 10 for ARM, on your Google Pixel Android 
				phone, or your Apple Silicon based Macbook.&nbsp; Rather, <b>it 
				is an alternate ABI</b> (application binary interface, i.e. a 
				calling convention) for ARM64 which provides <b>interoperability 
				with non-native binaries</b> (a.k.a "foreign binaries") compiled 
				for 64-bit x64.</span></p>
				<p><span face="Verdana" size="2">- ARM64EC-built code is 
				compiled in a way to make it is "<b>E</b>mulation <b>C</b>ompatible", 
				thus the name ARM64<i>EC</i>.&nbsp; ARM64EC code can easily call 
				emulated x64 code, and vice versa, without even any source code 
				changes since all the heavy lifting is done seamlessly by the 
				compiler, linker, C runtimes, and the OS.&nbsp; Contrast this 
				with traditional mechanisms such as PInvoke or JNI where 
				interoperability explicitly requires source code modifications.</span></p>
				<p><span face="Verdana" size="2">- <b>ARM64X</b> is an <b>ARM64</b> 
				e<b>X</b>tension to the standard Windows PE (portable 
				executable) file format allowing ARM64 code and emulated Intel 
				x64 code to interoperate with each other <i>within the same 
				binary</i> - differentiating it from the "either-or" approach of 
				a fat binary.&nbsp; This is called a <b>hybrid binary</b>.&nbsp; 
				ARM64X format is backward compatible with older OSes such as 
				Windows 10 for ARM and older debuggers and development tools, 
				although the interoperability extensions will be ignored and 
				only the ARM64 codebytes will be exposed.</span></p>
				<p><span face="Verdana" size="2">- Almost every 64-bit binary 
				that ships in <b>Windows 11 on ARM is built as ARM64X</b>, 
				allowing them to be used by both classic ARM64 applications and 
				emulated x64 applications.</span></p>
				<p><span face="Verdana" size="2">- ARM64EC functions compiled to 
				ARM64 bytecode export an Intel compatible entry point called a
				<b>Fast Forward Sequence</b> which contains a stub of x64 
				codebytes.&nbsp; The FFS is compatible with
				<a href="https://learn.microsoft.com/en-us/windows/win32/api/libloaderapi/nf-libloaderapi-getprocaddress">
				GetProcAddress()</a> allowing legacy Intel applications and 
				games to do things like hotpatch NTDLL.DLL and other system 
				binaries - completely oblivious to the fact that the body of the 
				function is actually ARM64.&nbsp; Think of an ARM64EC function 
				as an ahead-of-time precompiled x64 function with an ARM64 body 
				and an x64 skin.</span></p>
				<p><span face="Verdana" size="2">- <b>Visual Studio 2022</b> 
				versions 17.4 and later officially support ARM64EC code 
				generation and emitting ARM64X binaries.&nbsp; Earlier versions 
				of VS had partial and incomplete support - don't use them!&nbsp; 
				Paired with Visual Studio you should use <b>build 22621 of the 
				Windows SDK</b> when building ARM64EC applications.&nbsp; 
				Preferably you should always use the latest Visual Studio and 
				SDK available, which is currently Visual Studio 2022 17.8.5 and 
				Windows SDK build 26020 at the time of this writing.</span></p>
				<p><span face="Verdana" size="2">- The Windows 11 for ARM kernel 
				maintains a <b>per-process "EC bitmap"</b> which marks every 
				single 4K page of address space as either native or foreign.&nbsp; 
				This bitmap is updated any time an EXE or DLL is loaded or 
				unloaded into the process, address space is allocated or freed, 
				or the app itself is setting up a JIT buffer and wishes to 
				specify which architecture it will be jitting for.&nbsp; The 
				address space of a process can be probed at run time (using the
				<a href="https://learn.microsoft.com/en-us/windows/win32/api/winnt/nf-winnt-rtliseccode">
				RtlIsEcCode()</a> function exposed by the Windows SDK) to 
				determine whether a given address is foreign or native.</span></p>
				<p><span face="Verdana" size="2">- <b>64-bit Intel x64 emulation</b> 
				in Windows 11 is built around ARM64X binaries and the ARM64EC 
				interoperability.&nbsp; This is very different how the 32-bit Intel 
				x86 emulation was implemented for Windows 10 where the WOW64 
				layer mediates the interoperability.</span></p>
				<p><span face="Verdana" size="2">- With the new ARM64EC build 
				target in Visual Studio, you can easily <b>rebuild an x64 
				application as ARM64EC in a matter of minutes</b>.&nbsp; This is 
				thanks to the
				<a href="https://www.youtube.com/watch?v=HmI6ip4o9as">incremental porting</a> 
				that is made possible by the tight coupling of ARM64EC and the 
				x64 emulator, allowing you to port individual functions and 
				leave others unported while still having a runnable working 
				application each step of the way.&nbsp; Porting a large application's code to a new 
				architecture has traditionally been an "all-or-nothing" affair 
				requiring weeks or months of effort before the newly ported app 
				can boot and run correctly.&nbsp; In some cases years, as when I 
				was involved in the Microsoft Office port to PowerPC back in the 
				1990's - the end-of-to-end port took over 2 years until 
				finally launching as
				<a href="https://news.microsoft.com/1999/04/26/office-98-built-for-the-mac-from-the-ground-up/">
				Microsoft Office 98</a>.&nbsp; </span></p>
				<p><span face="Verdana" size="2">- ARM64EC makes use of a 
				library called <b>soft intrinsics</b> (or "softintrins") which 
				is implemented by the SDK's <b>softintrin.h</b> header and <b>
				softintrin.lib</b> static library (and also mostly implemented 
				by yours truly).&nbsp; Softintrins allow legacy C/C++ source code that 
				contains
				<a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">
				Intel intrinsics</a> to compile with the native ARM64 compiler, 
				even supporting such Intel intrinsics as
				<a href="https://learn.microsoft.com/en-us/cpp/intrinsics/cpuid-cpuidex?view=msvc-170">
				__cpuid()</a>, as well as about 500 SSE intrinsics - this makes incremental porting possible.&nbsp; A 
				piece of source code, whether compiled as x64 and emulated, or 
				whether compiled as ARM64EC, will behave identically at runtime 
				as portion of it are incrementally ported.</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">With these quick facts in your head 
			you should be able to now make sense of
			<a href="https://learn.microsoft.com/en-us/windows/arm/arm64ec-abi">
			Microsoft's ARM64EC documentation</a> which can be a little daunting 
			at first without this background.&nbsp; Or keep reading this 
			tutorial as I 
			take you into a deeper dive of how this all works under the hood and 
			what some problem areas are.</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="The_Deep_Dive">The Deep Dive</a></span></b></p>
			<p><span face="Verdana" size="2">As one of the engineers at Microsoft 
			who along with my colleagues Pedro and Pavel and few others helped 
			architect and implement ARM64EC I can give you my 
			front row perspective of <b>what</b> ARM64EC is, <b>how</b> and <b>
			when</b> to use it as a developer, the thought process behind <b>why</b> we went 
			down a different design path that had been used in previous 
			emulation implementations, and <b>which</b> outstanding bugs still 
			keep me awake at night.</span></p>
			<p><span face="Verdana" size="2">Let's rewind a few decades.&nbsp; 
			Back in the 16-bit days of Windows 2.0 or 3.1, the Windows 
			distribution was pretty simple: the OS was installed into a 
			directory called <b>C:\Windows</b> and most of the user mode system 
			components ("the system DLLs") lived in the subdirectory <b>
			C:\Windows\System</b>. This approach works great when the CPU and 
			the OS only support one single ISA (namely 16-bit 8086).&nbsp; But 
			what happens then when your CPU supports some new instruction 
			set and mode of execution (e.g. 32-bit protect mode introduced with 
			the Intel 80386) and you want to release an OS such as Windows NT 
			which supports both 16-bit and 32-bit Intel binaries?</span></p>
			<p><span face="Verdana" size="2">There are several options when an 
			operating system is being ported to a new architecture (such as 
			32-bit x86, 64-bit x64, or ARM64) and needs to deal with multiple instruction 
			sets and foreign binaries:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">- <b>Do nothing</b>.&nbsp; We 
				already know that Windows RT had no foreign binary support, 
				provided only a limited set of native ARM built-in apps, and 
				required third-party developers to port their applications to 
				ARM if they wanted to run on Windows RT at all.&nbsp; When not 
				enough developers bought in on this (as happened with RT) the OS 
				ended up being of little value to paying consumers and eventually 
				died.</span></p>
				<p><span face="Verdana" size="2">- <b>User mode emulation only.</b>&nbsp; 
				Linux users are familiar with user mode emulation via
				<a href="https://www.qemu.org/docs/master/user/index.html">QEMU</a> 
				(and nowadays even
				<a href="https://developer.apple.com/documentation/virtualization/running_intel_binaries_in_linux_vms_with_rosetta">
				Rosetta 2</a>).&nbsp; Emulation allows something like an ARM64 
				distribution of Linux to run an ELF binary compiled for say 
				ARM32 or x86.&nbsp; QEMU or Rosetta act as both the binary 
				loader and the virtual CPU which emulates that foreign binary.&nbsp; 
				System calls get "marshalled" or "thunked" to the native host OS 
				since the kernel mode and kernel drivers themselves are native 
				and not emulated.&nbsp; This method is one way I've tested QEMU again 
				Rosetta and Microsoft's emulator&nbsp; - by writing little x86 
				or x64 test binaries and running them under QEMU's emulation to 
				see how accurately it compares.</span></p>
				<p><span face="Verdana" size="2">- <b>Fat binaries + user mode 
				emulation</b>.&nbsp; This was and still is Apple's approach 
				every time they transitioned CPU architectures - from 68K to 
				PowerPC, from PowerPC to Intel x86/x64, and from Intel x86/x64 
				to ARM64.&nbsp; Their "<a href="https://apple.fandom.com/wiki/Fat_binary">fat 
				binary</a>" format contains multiple "slices" of code, each 
				slice containing bytecode for a different ISA (such as PowerPC, 
				x86, or ARM64).&nbsp; Most of the operating system itself is 
				compiled as fat binaries.&nbsp; When a non-native application is 
				launched the OS (in their case macOS) will invoke an emulator (the
				<a href="https://en.wikipedia.org/wiki/Mac_68k_emulator">68020 
				emulator</a>,
				<a href="https://en.wikipedia.org/wiki/Rosetta_(software)">
				Rosetta</a>, or
				<a href="https://support.apple.com/en-us/HT211861">Rosetta 2</a>) 
				to run the foreign slices of each fat binary.&nbsp; As the name 
				implies, _fat_ binaries are larger than just a pure native 
				binary, since they contain two even three slices of code.&nbsp; 
				This approach fattens up the disk footprint of the entire OS and 
				makes distribution of apps fatter as well.&nbsp; One upside of 
				fat binaries (or "<a href="https://developer.apple.com/documentation/apple-silicon/building-a-universal-macos-binary">Universal 
				Binaries</a>" as Apple calls them) is that the end user only 
				sees one binary and need not concern themselves over which 
				architecture binary to download.</span></p>
				<p><span face="Verdana" size="2">- <b>Multiple binaries + user 
				mode emulation</b>.&nbsp; This has been Microsoft's approach for 
				over 30 years since the Windows NT days.&nbsp; Microsoft does 
				not use fat binaries; instead it separates binaries of different 
				architectures and places them in separate subdirectories.&nbsp; 
				i.e. Microsoft's approach puts multiple variants of the same binary 
				(one variant for each different ISA) into different subdirectories.&nbsp; 
				When Windows 10 for ARM launched in 2018 it contained no fewer 
				than 3 copies of most OS binaries - one set of directories for 
				native ARM64, one set for 32-bit ARM32/Thumb2, and one set for 
				32-bit x86!</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">Let's look deeper at Microsoft's 
			past implementation of foreign binary support.</span></p>
			<p><span face="Verdana" size="2">When Windows NT and Windows 95 
			launched in the 1990's, both added new <b>C:\Windows\System32</b> 
			subdirectory containing (no surprise) 32-bit system DLLs and the 
			32-bit kernel.&nbsp; At this point there were two variants of the 
			system DLLs - one 16-bit and one 32-bit.&nbsp; Only 32-bit binaries 
			were considered <i>native</i>, while older 16-bit MS-DOS and "Win16" 
			binaries were considered <i>foreign</i>.&nbsp; Microsoft created two 
			subsystems called
			<a href="https://learn.microsoft.com/en-us/windows/compatibility/ntvdm-and-16-bit-app-support">
			NTVDM</a> and
			<a href="https://en.wikipedia.org/wiki/Windows_on_Windows">WOW</a> 
			(or "WOW32) for running legacy MS-DOS and Windows 3.1 binaries 
			respectively.&nbsp; The reason 16-bit code is considered foreign is 
			that on a 32-bit operating system you cannot just load a 16-bit 
			binary and run it directly in 32-bit mode.&nbsp; You have to sandbox 
			and emulate the 16-bit code in some way.&nbsp; On Intel processors, 
			there is a hardware sandboxing mode which allows direct 
			hardware context switching from 32-bit mode to 16-bit mode and back.&nbsp; 
			So in effect "emulation" of 16-bit mode on 32-bit Intel processors 
			is really done in hardware and microcode; with occasional 
			"trap-and-emulate".&nbsp; This hardware sandboxing 
			functionality has been in use
			<a href="https://www.groovypost.com/howto/enable-16-bit-application-support-windows-10/">
			right on through to Windows 10</a> until all the old 16-bit support 
			was dropped in Windows 11.&nbsp; This is not surprising since the long-term 
			roadmap for Intel seems to involve completely
			<a href="https://www.groovypost.com/howto/enable-16-bit-application-support-windows-10/">
			dropping hardware support for 16-bit mode</a> and possibly even 
			32-bit mode.</span></p>
			<p><span face="Verdana" size="2">So far so good - System is for 
			16-bit binaries, System32 is for 32-bit binaries.&nbsp; One could 
			naturally assume that a 64-bit OS would then some day add a 
			C:\Windows\System64 directory, right?&nbsp; Wrong!</span></p>
			<p><span face="Verdana" size="2">For one reason or another, 
			Microsoft chose to keep the System32 subdirectory as the fixed 
			location of the native system binaries.&nbsp; So what Microsoft did 
			in 64-bit Windows XP, 64-bit Windows 7, right on up to today's 
			64-bit-only Windows 11 is that the 32-bit binaries got moved to a 
			new C:\Windows\<i><b>SysWOW64</b></i> directory, while new native 64-bit 
			system binaries were placed in the existing C:\Windows\<b><i>System32</i></b>.</span></p>
			<p><span face="Verdana" size="2">Got that?&nbsp; WOW64 == 32-bit 
			binaries, and System32 == 64-bit binaries!&nbsp; For Windows 10 and 
			11 on ARM there is even third subdirectory C:\Windows\SysArm32 which 
			as the name suggests hold the 32-bit ARM/Thumb2 system binaries.&nbsp; 
			And yes, the 32-bit x86 binaries in C:\Windows\SysWOW64 are 
			identical both in Intel distributions of Windows 11 and ARM64 
			distributions of Windows 11, since 32-bit x86 is considered 
			"foreign" on both.</span></p>
			<p><span face="Verdana" size="2">You can see this in action quite 
			easily.&nbsp; All Windows 11 builds have a new 
			column in <b>Task Manager</b> called "<b>Architecture</b>" which displays not only the "bitness" 
			of a given running process (32-bit or 64-bit), but also its ISA 
			(instruction set architecture).&nbsp; If 
			you are running on an AMD Ryzen or Intel Core i7 system, the distinction between 
			"bitness" and ISA is moot, since you are either running a 
			process as a 32-bit x86 process or a 64-bit x64 process; there are 
			no other combinations.&nbsp; For 
			example on my AMD 5950X machine if I bring up Task Manager and go to the "<b>Details</b>" 
			tab, you can see that I have several instances of the command line 
			prompt (CMD.EXE) running as 32-bit processes, and several running as 64-bit 
			processes:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar1.jpg"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Even in say XP or Windows 7 which 
			lacked the Architecture column you could tell based on the "<b>Image path name</b>" 
			column (and as you can see above with CMD.EXE) by which 
			directory path the binary is in.&nbsp; The 32-bit instances of CMD.EXE launched from 
			the C:\Windows\<i><b>SysWOW64</b></i> directory, while native 64-bit 
			version launched from C:\Windows\<b><i>System32</i></b> as I 
			described above.</span></p>
			<p><span face="Verdana" size="2">There is neat way to <b>launch a specific 
			architecture</b> of, say, the command prompt when multiple variants 
			of the binary exist.&nbsp; The Windows <b>
			START</b> command for launching new processes has an option <b>/MACHINE</b> to force 
			a specific architecture of the new process:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar3.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Notice that it accepts "x86" 
			"amd64" "arm" and "arm64" and there is 
			no "arm64ec" since that is not a separate architecture!</span></p>
			<p><span face="Verdana" size="2"><b>Pro tip:</b> Microsoft is often 
			inconsistent with its naming of architectures across its various 
			tools, using "amd64" and "x64" 
			interchangeably, and "arm" "ARM32" and "Thumb2" interchangeably.&nbsp; 
			So just understand that <b>amd64 or (AMD64) == x64</b>, and <b>arm 
			(or ARM) == ARM32</b> (which on Windows is really Thumb2).&nbsp; Got 
			it? :-)</span></p>
			<p><span face="Verdana" size="2">So what does it look like if you try to 
			<b>launch the 4 different architectures of CMD.EXE on an ARM64 
			device</b>?&nbsp; Let's try it!&nbsp; Using Windows 11 SV2 Nickel on 
			my Samsung Pro 360, I launched 4 CMD.EXE 
			instances using each of the 4 different /MACHINE options.&nbsp; 4 
			command line windows opened up and looked identical, so let's take a look at 
			what Task Manager showed:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/tm4.jpeg"></p>
			</blockquote>
			<p><span face="Verdana" size="2">As expected, the native ARM64 
			instance launched from C:\Windows\<i>System32</i>, the emulated x86 
			instance launched from C:\Windows\<i>SysWOW64</i>, and the 32-bit 
			ARM instance launched from C:\Windows\<i>SyArm32</i>.</span></p>
			<p><span face="Verdana" size="2">But look at the supposed x64 
			instance, it shows up as "<b>ARM64 (x64 compatible)</b>" and <b>
			claims to be the same binary</b> as the native ARM64 version.&nbsp; 
			This is clearly NOT the usual pattern of adding yet another new 
			subdirectory of additional binary files.&nbsp; In Windows 11 you 
			will not find, say, a C:\Windows\SysAmd64 subdirectory.&nbsp; Why is 
			that?</span></p>
			<p><span face="Verdana" size="2">On factor that we considered is 
			that many apps and setup programs hardcode the "System32" path and 
			blindly copy their own binaries or open handles to system DLLs (such 
			as USER32.DLL, KERNEL32.DLL, MSVCRT.DLL etc.) using the hardcoded 
			C:\Windows\System32 path name.&nbsp; For things to work correctly 
			with foreign binaries, the
			<a href="https://learn.microsoft.com/en-us/windows/win32/winprog64/wow64-implementation-details">
			WOW64 emulation layer</a> magically performs some hidden file 
			redirection, <b>changing the path name</b> from C:\System\System32 
			to either C:\System\SYSWOW64 or C:\System\SysArm32 as appropriate 
			for x86 and ARM32/Thumb2 architectures respectively.&nbsp; WOW64 has 
			been doing this since the days of Windows XP, and also <b>invokes 
			the correct 32-bit emulator</b> for each architecture (either the 
			hardware sandbox for x86 on Intel hosts, a different hardware 
			sandbox for ARM32 on ARM64 hosts, or the xtajit.dll binary 
			translator for ARM64 hosts).</span></p>
			<p><span face="Verdana" size="2">The kernel team were dreading 
			adding yet another architecture to WOW64 and having to have yet 
			another set of file redirections to worry about.&nbsp; Worse, the 
			concept of WOW has for 30+ years always implied a smaller bitness - 
			i.e. 16-on-32, or 32-on-64.&nbsp; The Windows code base was just not 
			set up for the concept of WOW sandboxing 64-on-64 bitness.&nbsp; Worse, many 
			applications frequently call the
				<a href="https://learn.microsoft.com/en-us/windows/win32/api/wow64apiset/nf-wow64apiset-iswow64process">
				IsWow64Process()</a> function to determine if a process (even itself) 
				is running under WOW64, and if so they falsely assume a) that the 
				sandboxed process under WOW64 is 32-bit, or b) that the host CPU is AMD/Intel x64.&nbsp; 
				Both these assumptions would clearly be wrong and would break many applications if x64 
				emulation was implemented as a WOW64 client.&nbsp; <b>Using the 
			WOW approach was off the table</b>.&nbsp; And similarly fat binaries 
			were off the table because this had never been done before in 
			Windows and no toolset could easily support this.&nbsp; This seeming 
			dead end is one reason work on 64-bit emulation kept getting put off 
			because the existing methodology just wasn't going to work.</span></p>
			<p><span face="Verdana" size="2">Obviously we solved the problem and 
			today even the Microsoft Office on ARM64 is built using ARM64EC for 
			interoperability with older Office plug-ins compiled for Intel x64.&nbsp; 
			You can easily verify in Task Manager that all of the Office 
			applications show up as "ARM64 (x64 compatible)" rather 
			than just "ARM64":</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar5.jpg"></p>
			</blockquote>
			<p><span face="Verdana" size="2">So does that mean that CMD.EXE and the 
			Microsoft Office on ARM64 are not native ARM64?&nbsp; Are they emulated 
			x64?&nbsp; Let's go back to about mid-2019 to...</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="The_birth_of_ARM64EC">The birth of ARM64EC</a></span></b></p>
			<p><span face="Verdana" size="2">So if WOW64 is off the table, file 
			redirection is off the table, and fat binaries are off the table, 
			what else is left?!?!?&nbsp; We already know this is not entirely an unsolved 
			problem, since
			<a href="https://www.qemu.org/docs/master/user/main.html#features">
			User Mode QEMU</a> as well as
			<a href="https://gitlab.winehq.org/wine/wine/-/releases/wine-9.0">
			Wine</a> already exist today on Linux to run <b>non-native user-mode 
			applications</b> written for other CPU architectures, and/or for Windows.&nbsp; 
			The "non-native user-mode application" is the key similarity between 
			those use cases and the emulation of x64 in Windows.</span></p>
			<p><span face="Verdana" size="2">I had alread been prototyping a 
			user mode 64-bit x64 interpreter called <b>xtabase</b> to try to 
			model a 64-bit user mode emulator.&nbsp; I went down a similar path 
			as user mode QEMU: I compiled the x64 interpreter as a native ARM64 binary and then used it 
			to manually load and fix up a x64 test binary, which it then starts interpreting 
			as x64 
			at the binary's entry point.&nbsp; The Windows OS is completely 
			oblivious to what is happening since the emulator is doing all the 
			work.&nbsp; This is great for 
			running super trivial toy binaries, since Visual Studio allows you 
			to compile and build a single C function as a standalone 
			binary.&nbsp; If you have trivial test code such as an 8queens 
			benchmark which takes no input and simply returns a single integer 
			result, this approach is perfect and allowed me to have a working x64 interpreter up and running in a few months, capable of 
			running small test functions to validate correctness.</span></p>
			<p><span face="Verdana" size="2">But what happens when that x64 
			binary goes to call printf(), malloc(), GetTickCount() or some other 
			runtime function that needs to be found in another binary such as 
			UCRTBASE.DLL or KERNEL32.DLL?&nbsp; I used the common trick 
			of
			<a href="https://learn.microsoft.com/en-us/cpp/dotnet/calling-native-functions-from-managed-code?view=msvc-170">
			function call marshalling</a>, which is similarly used by user mode 
			QEMU or any time 
			managed code in .NET or Java calls out to native system code.&nbsp; 
			xtabase takes the function call arguments (or in the case of GetTickCount, no arguments) and then makes a native function 
			call to the 
			target function.&nbsp; When that native function returns, the return 
			value is then placed back in the emulated state and emulation 
			continues at the point past the call.</span></p>
			<p><span face="Verdana" size="2">To get a fairly simple Windows 
			"hello world" x64 binary to emulate in this fashion only requires 
			marshalling about 40 or so C runtime and Win32 
			functions: there is the 
			obvious call to printf(), and if you
			<a href="https://learn.microsoft.com/en-us/cpp/build/reference/entry-entry-point-symbol?view=msvc-170">
			fudge the entry point of the test EXE</a> to directly point to the <b>main()</b> function itself, then yes, 
			you only have to marshal 
			the printf() call.&nbsp; To run something more complex or a 
			benchmark you likely need to also marshal malloc(), free(), 
			GetTickCount(), fopen(), fread,&nbsp; and handful of other common APIs.&nbsp; 
			This way I was able to bootstrap up to running small benchmarks which 
			actually read the clock and computed performance and displayed 
			output to 
			the screen.</span></p>
			<p><span face="Verdana" size="2">To truly be able to run an 
			unmodified "hello world" you need to also marshal all of the system 
			calls that the C runtime startup code calls during initialization on 
			its way to eventually calling the main() function.&nbsp; And then 
			there is the C runtime shutdown code which implicitly gets called 
			when main() returns - think exit() function and a bunch of file 
			close operations.&nbsp; So that is where 
			the whole 40 
			functions in total comes about.&nbsp; And this is basically what Wine does on 
			Linux - over the years they just marshal more and more Win32 
			functions over to Linux system calls, to where today Wine is able to 
			run many Windows 10 applications and even applications that rely on 
			DirectX.</span></p>
			<p><span face="Verdana" size="2">Function call marshalling is also 
			done by WOW64 layer itself when it has to marshal arguments between 32-bit 
			user mode and 64-bit system calls.&nbsp; Arguments such as pointers 
			need to be widened from type __ptr32 to type __ptr64, and similarly 
			"pointer sized integers" such as uintptr_t and intptr_t arguments 
			need to be zero-extended and sign-extended.&nbsp; Anyone who's 
			written a Window message loop is familiar with the
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/winuser/nf-winuser-sendmessage">
			SendMessage()</a> 
			function, but <b>how many of you realize that the width of the 
			lParam is not fixed?</b>&nbsp; The lParam's argument's LPARAM type 
			is actually a pointer-sized integer and thus has to be extended when 
			being passed from 32-bit mode to 64-bit mode, as you can see in its 
			definition in the Windows SDK:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar4.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Another aspect of 32-bit emulation 
			in WOW64 is that <b>two stacks have to be used</b>: - the 32-bit 
			x86 stack where everything is 4-byte aligned and pointers are 4 
			bytes wide, and the 64-bit native ARM64 stack which is (by hardware 
			design) 16-byte aligned and pointers are 8 bytes wide.&nbsp;&nbsp; 
			32-bit x86 code and native ARM64 code cannot share data in memory or 
			even on the same stack because the data layouts are different.&nbsp; 
			All <b>data structures have to be marshaled</b> as well, not just 
			the pointers to them.</span></p>
			<p><span face="Verdana" size="2">Emulating 32-bit on a 64-bit system 
			is thus very messy (and why it took many years to get the initial 
			32-bit x86 emulation on ARM64 to work well).&nbsp; But I wasn't 
			aiming to emulate x86, I was modeling x64.&nbsp; 64-bit applications have their own 
			differences and calling conventions as per this table comparing 
			32-bit x86, 64-bit x64, and 64-bit ARM64 and you can see there is 
			quite a difference:</span></p>
			<blockquote>
				<table>
					<colgroup>
						<col width="370">
						<col width="370" span="3">
					</colgroup>
					<tbody><tr height="19">
						<td>
						&nbsp;</td>
						<td>
						x86</td>
						<td>
						x64</td>
						<td>
						ARM64</td>
					</tr>
					<tr height="19">
						<td>
						__cdecl function argument passing</td>
						<td>
						on stack, caller pops stack</td>
						<td>
						first 4 in registers, the rest on stack</td>
						<td>
						first 8 in registers, the rest on stack</td>
					</tr>
					<tr height="19">
						<td>
						__stdcall function argument passing</td>
						<td>
						on stack, callee pops stack</td>
						<td>
						first 4 in registers, the rest on stack</td>
						<td>
						first 8 in registers, the rest on stack</td>
					</tr>
					<tr height="19">
						<td>
						__fastcall function argument passing</td>
						<td>
						2 32-bit in registers, the rest on the stack</td>
						<td>
						first 4 in registers, the rest on stack</td>
						<td>
						first 8 in registers, the rest on stack</td>
					</tr>
					<tr height="19">
						<td>
						argument registers</td>
						<td>
						ECX, EDX</td>
						<td>
						RCX, RDX, R8, R9</td>
						<td>
						X0, X1, X2, X3, X4, X5, X6, X7</td>
					</tr>
					<tr height="19">
						<td>
						return value registers</td>
						<td>
						EAX, EDX</td>
						<td>
						RAX, RDX</td>
						<td>
						X0, X1</td>
					</tr>
					<tr height="19">
						<td>
						stack alignment</td>
						<td>
						4 bytes</td>
						<td>
						16 bytes</td>
						<td>
						16 bytes</td>
					</tr>
					<tr height="19">
						<td>
						stack pointer size</td>
						<td>
						4 bytes</td>
						<td>
						8 bytes</td>
						<td>
						8 bytes</td>
					</tr>
					<tr height="19">
						<td>
						program counter size</td>
						<td>
						4 bytes</td>
						<td>
						8 bytes</td>
						<td>
						8 bytes</td>
					</tr>
					<tr height="19">
						<td>
						pointer size</td>
						<td>
						4 bytes</td>
						<td>
						8 bytes</td>
						<td>
						8 bytes</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2">Since the x64 ABI was developed a 
			good 10 years after x86, it has some nice simplifications which also 
			carried over to ARM64.&nbsp; One thing should be popping out at you 
			right now, which is that at the C/C++ function call level...</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="Similar">ARM64 and AMD64 (x64) calling conventions 
			are extremely similar!</a></span></b></p>
			<p><span face="Verdana" size="2">As I was writing marshaling 
			functions for x64-to-ARM64 I came to realize that many of those 
			functions are effectively a NOP.&nbsp; For as long as fewer than 5 
			function arguments are being passed and there is no funky passing of 
			structures or floating point values,
			<a href="https://learn.microsoft.com/en-us/cpp/build/x64-software-conventions?view=msvc-170">
			x64 calling convention</a> and
			<a href="https://learn.microsoft.com/en-us/cpp/build/arm64-windows-abi-conventions?view=msvc-170">
			ARM64 calling convention</a> have a remarkable amount of common overlap.&nbsp; 
			Simple calls like GetTickCount() and GetProcessId() and GetLastError() 
			which take no arguments and just return a value really don't need 
			any marshalling.&nbsp; Functions which do take arguments such as SetLastError() also require no marshaling since no memory is 
			touched, no stack is modified.</span></p>
			<p><span face="Verdana" size="2">So I found that I didn't have to 
			write a separate marshalling wrapper for each of the 40 or so C runtime 
			and Win32 
			functions that I needed for "hello world".&nbsp; The emulator could instead assume a default where a 
			function takes no more than 4 integer arguments and returns an 
			integer.&nbsp; This meant that my xtabase emulator <b> <i>could</i> 
			call directly</b> into function entry points of the native ARM64 
			binaries in C:\Windows\System32 and pass pointers and data structures
			<b>as-is</b> - no separate x64 binaries required, 
			no fat binaries requires, no WOW64 layer.</span></p>
			<p><span face="Verdana" size="2">There is also an obvious 1:1 
			register mapping that arises from looking at the calling 
			conventions and which registers are used to pass arguments to 
			function calls and return values:&nbsp; RCX-&gt;X0, RDX-&gt;X1, R8-&gt;X2, R9-&gt;X3 and then on 
			return X0-&gt;RAX, X1-&gt;RDX.&nbsp; Notice that X1 and RDX even map to each 
			other in both directions.</span></p>
			<p><span face="Verdana" size="2">So Pedro and I started thinking...</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">- what if there was <b>no WOW64</b> 
				layer required?</span></p>
				<p><span face="Verdana" size="2">- what if there was <b>no 
				additional directory</b> of binaries required?</span></p>
				<p><span face="Verdana" size="2">- what if there was <b>no need 
				the original x64 binaries</b> at all?</span></p>
				<p><span face="Verdana" size="2">- what if there even <b>was no 
				second stack</b> and instead x64 and ARM64 shared the same 
				stack?</span></p>
				<p><span face="Verdana" size="2">- what if there was a nice <b>
				1:1 mapping of x64 registers to ARM64 registers</b> so no 
				marshalling was required?</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">Again, at this point this was not purely 
			hypothetical because I had a working x64 interpreter running as 
			ARM64 code that was able to run simple test binaries like "hello world" 
			and the "8queens" benchmark.&nbsp; Memory allocation, timing 
			functions, screen output was all working.&nbsp; But that last point 
			- the 1:1 register mapping - is extremely critical for cases that 
			involve exception handling and stack unwinding filters or when an app 
			calls <b>GetThreadContext()</b> or <b>SetThreadContext()</b>.&nbsp; In those 
			scenarios a data structure called <b>CONTEXT</b> is passed around, 
			which as you can see by peeking at <b>winnt.h</b> the
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-context">
			x64 CONTEXT</a> is quite different layout and size than the
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-arm64_nt_context">
			ARM64 CONTEXT</a> or for that matter the
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-wow64_context">
			x86 CONTEXT</a>.&nbsp; This implies that some kind of WOW64 
			marshalling layer would still be require to translate the CONTEXT layouts 
			back and forth.&nbsp; <b>But what does that even mean?</b>&nbsp; How 
			do the 80-bit x87 floating registers map to ARM64 state?&nbsp; How 
			do ARM64's 32 128-bit NEON registers map to x86's 16 128-bit SSE 
			registers?&nbsp; How do the arithmetic flags map?&nbsp; We were 
			trying to pair a square peg with a round hole.</span></p>
			<p><span face="Verdana" size="2">What we really 
			needed was a complete 1:1 register mapping.&nbsp; So far, all we had was 4 
			registers that sort of lined and made toy test binaries run.&nbsp; We 
			can trivially also map the stack pointers (RSP &lt;-&gt; SP) and the program counters 
			(RIP &lt;-&gt; PC).&nbsp; And we can sort of map the NZVC (Negative, Zero, 
			Overflow, Carry) arithmetic flags to Intel's SZOC (Sign, Zero, 
			Overflow, Carry).&nbsp; Progress!</span></p>
			<p><span face="Verdana" size="2">When we wrote down all of the 
			interesting x64 user-mode registers and compared against the ARM64 
			user-mode registers, including how wide they are and whether they 
			are <b>volatile</b> (caller-save, or "scratch" registers) or <b>
			non-volatile</b> (callee-save) we little-by-little matched up more 
			of the registers.</span></p>
			<p><span face="Verdana" size="2">Fortunately ARM64 with its 32 
			integer registers and 32 vector registers has enough registers to 
			fit the x64 register state (including MMX, x87, and SSE's XMM 
			registers).&nbsp; If you carefully try to map volatile-to-volatile, 
			and non-volatile to non-volatile, you come up with one possible 
			mapping (of many) of an <b>ARM64 emulation compatible</b> register state:</span></p>
			<blockquote>
				<table>
					<colgroup>
						<col width="126" span="3">
					</colgroup>
					<tbody><tr height="19">
						<td>
						x64</td>
						<td>
						ARM64</td>
						<td>
						register volatility</td>
					</tr>
					<tr height="19">
						<td>
						RCX</td>
						<td>
						X0</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						RDX</td>
						<td>
						X1</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						R8</td>
						<td>
						X2</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						R9</td>
						<td>
						X3</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						R10</td>
						<td>
						X4</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						R11</td>
						<td>
						X5</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST1</td>
						<td>
						X6</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST2</td>
						<td>
						X7</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						RAX</td>
						<td>
						X8</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST3</td>
						<td>
						X9</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST4</td>
						<td>
						X10</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST5</td>
						<td>
						X11</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST6</td>
						<td>
						X12</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						-</td>
						<td>
						X13</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						-</td>
						<td>
						X14</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST7</td>
						<td>
						X15</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						exponents 0-3</td>
						<td>
						X16</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						exponents 0-7</td>
						<td>
						X17</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						GS base</td>
						<td>
						X18 (TEB)</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						R12</td>
						<td>
						X19</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						R13</td>
						<td>
						X20</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						R14</td>
						<td>
						X21</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						R15</td>
						<td>
						X22</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						-</td>
						<td>
						X23</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						-</td>
						<td>
						X24</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						RSI</td>
						<td>
						X25</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						RDI</td>
						<td>
						X26</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						RBX</td>
						<td>
						X27</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						-</td>
						<td>
						X28</td>
						<td>
						unused</td>
					</tr>
					<tr height="19">
						<td>
						RBP</td>
						<td>
						X29 (frame pointer)</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						ST0</td>
						<td>
						X30</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						RSP</td>
						<td>
						X31 (SP)</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						RIP</td>
						<td colspan="2">
						PC (program counter)</td>
					</tr>
					<tr height="19">
						<td>
						XMM0-XMM5</td>
						<td>
						V0-V5</td>
						<td>
						volatile</td>
					</tr>
					<tr height="19">
						<td>
						XMM6-XMM15</td>
						<td>
						V6-V15</td>
						<td>
						non-volatile</td>
					</tr>
					<tr height="19">
						<td>
						-</td>
						<td>
						V16-V31</td>
						<td>
						non-volatile</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2">Note that all of what in x64 are 
			considered to be "scratch registers" such as RAX RCX R10 R11 etc. 
			all map to like scratch registers on ARM64 nicely map to X0 through 
			X8.&nbsp; And all the x64 
			non-volatile callee-save registers which have to be preserved across 
			function calls are also mapped to like registers - RSI RDI RBX RBP 
			R12-R15 nicely map to the X19-X29 non-volatiles.</span></p>
			<p><span face="Verdana" size="2">There is some 
			funny register shuffling that you might notice:</span></p>
			<p><span face="Verdana" size="2"><b>X18 is special</b>, it points to 
			the thread's environment block (TEB) and is constant to a give 
			thread.&nbsp; It is equivalent to the FSBASE register in x86 or the 
			GSBASE register in x64.&nbsp; So this register can be derived.</span></p>
			<p><span face="Verdana" size="2"><b>X28 is also special</b>, as 
			Microsoft's C/C++ compiler (and thus most Windows binaries and 
			Microsoft apps) never makes use of this register!&nbsp; Try it, 
			single-step through any ARM64 native code generated by Visual Studio 
			and you'll never see the x28 register show up.</span></p>
			<p><span face="Verdana" size="2"><b>X16 and X17</b> are funny, as 
			they contain the 8 16-bit exponents of the x87 floating point 
			registers.&nbsp; Since the shared MMX/x87 state is volatile and not 
			preserved (and rarely if ever even used in 64-bit x64 code) the fact 
			that their layout is munged up like that is really not important.&nbsp; 
			X16 and X17 are normally used as scratch registers for indirect 
			jumps to DLLs, so by design they get trashed during most calls 
			anyway.</span></p>
			<p><span face="Verdana" size="2">The problem is there are some gaps.&nbsp; 
			ARM64 has 2 too many scratch registers, 2 too many non-volatile 
			registers, and obviously double the number of vector registers.&nbsp; 
			This means that <b>X13 X14 X23 X24 and V16-V31 cannot be mapped</b> 
			to x64 state!</span></p>
			<p><span face="Verdana" size="2">V16-V31 could very easily be mapped if 
			Microsoft's emulator supported AVX/AVX2 and thus 16 256-bit YMM 
			register state would map nicely to 32 128-bit NEON register state, 
			but alas, they choose not to support the larger AVX state at this 
			time.&nbsp; (To this day in 2024, Microsoft still has not support 
			for AVX or AVX2 instruction or the YMM register state in the 
			emulators).</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="Context">ARM64EC_NT_CONTEXT</a></span></b></p>
			<p><span face="Verdana" size="2">Now armed with our (mostly) 1:1 
			register mapping, it was possible to take the existing x64 CONTEXT 
			structure which has been around for 20 years and re-imagine it as an 
			ARM64 (but emulation compatible) context structure.&nbsp; Starting with the Windows 11 SDK, the
			<b>ARM64EC_NT_CONTEXT</b> exists in the <b>winnt.h</b> header file as its own data structure.&nbsp; But it is not a 
			<i>different</i> data structure from the original x64 CONTEXT structure - 
			the layouts are identical.&nbsp; Here is a small sample from winnt.h 
			(build 26020) showing the fields using the ARM64 register names in 
			ARM64EC_NT_CONTEXT and the layout of the Intel integer registers in 
			the x64 CONTEXT:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar6.gif">
				<img src="http://www.emulators.com/docs/abc_ar7.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">The layout of the two states is 
			intentionally identical by design!&nbsp; That was the whole point of the 
			register mapping exercise - to make x64 and ARM64 appear nearly 
			identically in functionality when compiling C/C++ code.</span></p>
			<p><span face="Verdana" size="2">What this means for 
			interoperability is that emulated x64 code can raise an exception 
			which can be caught either by other x64 code, or by newly ported 
			ARM64EC code.&nbsp; When each examines the context structure they 
			are both seeing x64 context layout even though the ARM64EC is using 
			ARM64EC_NT_CONTEXT.&nbsp; So whether the exception filter is looking 
			at the Rcx or X0 fields does not matter - they are the same byte 
			offset into the structure.&nbsp; 
			Rip and Pc are the same offset.&nbsp; Rsp and Sp are the same offset.&nbsp; 
			R15 and X22 are the same register at the same offset in the 
			structure.&nbsp; And so on.</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="Difference">The key difference when building ARM64EC 
			vs. ARM64 code</a></span></b></p>
			<p><span face="Verdana" size="2">I hope you have now realized that 
			ARM64EC is a way of compiling ARM64 native code in a way which makes 
			that ARM64 code interoperable with emulated x64 code in the same process.&nbsp; 
			An emulated binary can call <b>CreateFile()</b> and not worry which 
			architecture CreateFile() is implemented as.&nbsp; And if the same 
			x64 code is now 
			recompiled as ARM64EC it should work identically, including that 
			"<b>sizeof</b>" keyword returns the same values for the 
			same data structures, whether x64 and 
			ARM64EC.</span></p>
			<p><span face="Verdana" size="2">Under the hood, a lot of this is 
			made to work using C preprocessor tricks.&nbsp; The C/C++ compiler 
			itself knows 
			<i>nothing</i> about Windows data structures, so the way we ensure that the 
			correct data structures get pulled in is by <b>lying to the compiler 
			preprocessor</b> by pretending that we are compiling for a native 
			x64 target, not native ARM64. This way source code (including 
			Windows SDK header files and C runtime header files) is parsed as 
			if targeting AMD and Intel.&nbsp; The resulting intermediate 
			language (IL) representation of the parsed code is 
			then passed through to the native <b>ARM64 compiler back end</b> 
			(the code optimizer and code generator) which then emits native 
			ARM64 instruction codebytes, not x64 codebytes!</span></p>
			<p><span face="Verdana" size="2">You can see this using a Visual 
			C/C++ compiler switch <b>-Bd</b> which dumps the actual switches 
			being passed to the compiler passes (c1.dll, c1xx.dll, and c2.dll).&nbsp; If I open the <b>vcvars64</b> 
			x64 development environment and compile any code with -Bd added, 
			part of the output will show the pre-defined macros being passed to 
			the C preprocessor (using <b>
			<a href="https://learn.microsoft.com/en-us/cpp/build/reference/d-preprocessor-definitions?view=msvc-170">
			-D</a></b> to define a macro), and these will include:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar8.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Compare this against the using the
			<b>vcvarsarm64</b> native ARM64 compiler to target classic ARM64:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar9.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Notice the difference?&nbsp; Both 
			define _WIN32 and _WIN64, which are necessary pre-defined macros to 
			indicate that we are compiling for Win32 and compiling for a 64-bit 
			target.&nbsp; By when targeting x64 the <b>_M_AMD64</b> and <b>
			_M_X64</b> (the AMD preferred macro and the Intel preferred macro 
			are defined) while when targeting ARM64 the <b>_M_ARM64</b> macro is 
			defined.</span></p>
			<p><span face="Verdana" size="2">What happens when we use the same 
			ARM64 compiler but also now pass the <b>-arm64EC</b> switch?</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar10.gif"><img src="http://www.emulators.com/docs/abc_ar11.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">The preprocessor is told that we 
			are targeting x64 _and_ ARM64EC, but not ARM64.&nbsp; If the C/C++ 
			source code you are compiling is not "enlightened" and knows nothing 
			about either ARM64 or ARM64EC, it will blissfully compile as if for 
			an Intel target, even through the resulting binary will contain 
			ARM64 code!</span></p>
			<p><span face="Verdana" size="2">But if your code _is_ enlightened 
			and you want to specifically have code paths always only execute on 
			ARM devices, you can set up your #defines like this:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar12.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Notice in the above snippet from winnt.h 
			that the header specifically wants to define the same 
			ARM64-specific compiler intrinsic for both ARM64 and ARM64EC.&nbsp; 
			This makes sense, since 
			these intrinsics are only meaningful to the ARM64 code generator.</span></p>
			<p><span face="Verdana" size="2">Similarly, winnt.h plays the 
			opposite game when declaring x86- or x64-only intrinsics which have 
			no meaning to ARM64, such as the intrinsic for Intel's 
			<a href="https://www.felixcloutier.com/x86/intn:into:int3:int1">INT 0x2C</a> 
			instruction:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar13.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Notice how the use of <b>
			!defined(_ARM64EC_)</b> prevents Intel-only intrinsics from 
			accidentally being passed to the ARM64 back end.&nbsp; You will see 
			this particular preprocessing pattern (#if _M_AMD64 &amp;&amp; !_M_ARM64EC) in hundreds of places throughout the C headers and 
			Windows SDK headers where definitions specific to AMD and Intel 
			hardware are being defined.</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar2.jpg"></p>
			</blockquote>
			<p><span face="Verdana" size="2">But the main thing I want you to 
			remember is that to build ARM64EC targets you need to pass <b>-arm64EC</b> to the compiler 
			driver (cl.exe).&nbsp; <b>Pro tip:</b> If you are using Visual 
			Studio 2022 this will be done automatically when you add "ARM64EC" 
			as a specific build target, as shown in the screen shot of the 
			Xformer 10 project settings above.</span></p><hr>
			<p><b><span face="Verdana"><a name="ARM64X">ARM64X hybrid PE file format</a></span></b></p>
			<p><span face="Verdana" size="2">So now it should make sense to you what the Task 
			Manager meant by "ARM64 (x64 Compatible)".&nbsp; I have explained 
			the <b>what</b> ARM64EC is, and <b>why</b> it is the way it is, but 
			I have not full explained how the mixed code plumbing works.</span></p>
			<p><span face="Verdana" size="2">You have probably deduced that <b>
			C:\Windows\System32\CMD.EXE is built with ARM64EC</b>, and therefore 
			contains native ARM64 code which can be run as a native ARM64 
			process, or, as an "emulation compatible" process.&nbsp; When 
			launched as ARM64EC, even CMD.EXE itself believes that it is running 
			as x64.&nbsp; Compare the output of the <b>set</b> command (to dump 
			out the environment variables) when CMD.EXE is launched as two 
			different architectures:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">start /machine <b>amd64</b> 
				cmd.exe</span></p>
				<p><img src="http://www.emulators.com/docs/abc_ar14.gif"></p>
				<p><span face="Verdana" size="2">start /machine <b>arm64</b> 
				cmd.exe</span></p>
				<p><img src="http://www.emulators.com/docs/abc_ar15.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">If the main executable of the 
			application (e.g. the CMD.EXE file) is compiled using -arm64EC, how 
			does the OS kernel know which mode to launch it in by 
			default?&nbsp; <i>Microsoft Office is clearly launching as ARM64EC by 
			default.</i></span></p>
			<p><span face="Verdana" size="2">The answer turns out to be a small 
			modification to the Windows PE file format for ARM64 binaries, an <b>
			ARM64</b> e<b>X</b>tension so to speak, that we named "<b>ARM64X</b>".&nbsp; 
			If you use the Visual Studio linker's <b>-dump -headers</b> command 
			on a given .EXE or .DLL file, it will show you the architecture of the 
			binary, a.k.a. a machine type.&nbsp; The machine type constants are 
			defined in, you guessed it, winnt.h:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar19.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">You can see that 64-bit AMD/Intel 
			targets are machine type <b>8664</b>, while ARM64 is machine type <b>
			AA64</b>.&nbsp; So when we dump the header of CMD.EXE we see:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar16.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">The machine type of the binary is
			<b>AA64</b> (indicating a native ARM64 binary) but there is 
			extra <b>metadata</b> which flags it as an ARM64X binary containing ARM64EC 
			code.&nbsp; Therefore ARM64EC is _not_ considered to be a new 
			machine type or a new CPU architecture.&nbsp; This would break 
			backward compatibility with Windows 10 for ARM as well as probably 
			breaking older version of debuggers and linkers and other tools 
			since 
			AA64 has been around for well over 6 or 7 years now.&nbsp; 
			Therefore, ARM64X 
			<i>extends</i> the existing AA64 ARM64 binary file format.</span></p>
			<p><span face="Verdana" size="2">But watch this, let's dump the 
			header of one of the Office binaries, such as <b>EXCEL.EXE</b>:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar17.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">AHA!&nbsp; <b>Mystery solved!</b>&nbsp; It 
			is legal to mark an ARM64X binary either as machine type AA64 
			(ARM64) or 8664 (AMD64/x64).&nbsp; Which machine type determines how 
			the application is launched by default:&nbsp; AA64+ARM64X launches as 
			plain native ARM64 process, while x64+ARM64X launches as emulated 
			x64.</span></p>
			<p><span face="Verdana" size="2">The mix of x64 and ARM64 bytecode 
			that an ARM64X binary  
			contains is up the developer who builds the binary - it could 
			contain almost 100% ARM64 code with a handful of x64 entry points 
			(this is the ideal case), 
			or it could be at the other end of the spectrum and be practically 
			100% x64 code with a few ARM64EC entry points (this would be the 
			case early in porting of a project).&nbsp; This is <b>what 
			distinguishes ARM64X from a traditional fat binary</b> - there are 
			not two complete versions of all code, therefore there is less code 
			bloat than the full 2x doubling of all code, and there are 
			advantages to taking a 100% Intel x64 codebase and <b>incrementally 
			porting</b> it over to ARM64EC and eventually to full ARM64.&nbsp; 
			With traditional porting of say x86 to x64, or x64 to ARM64, porting 
			is an <b>all-or-nothing</b> effort, where the ported app does not 
			build and run until every last bit of C, C++, and ASM code has been 
			ported over.&nbsp; That porting effort could take weeks or months!</span></p>
			<p><span face="Verdana" size="2">With ARM64EC, you can literally 
			start by first flipping the ARM64X attribute on your existing x64 
			build, then start to add <b>-arm64EC</b> switch to your C and C++ 
			files, and finally port over that gnarly hand-coded ASM code from 
			x64 to ARM64.</span></p><hr>
			<p><b><span face="Verdana"><a name="FFS">Fast forward sequences, entry and exit thunks</a></span></b></p>
			<p><span face="Verdana" size="2">I have 
			still not explained how ARM64EC deals with the &gt;4 arguments function 
			call marshalling issue.&nbsp; This is handled by additional blocks 
			of code which are automatically generated by the linker called: FFSs (Fast 
			Forward Sequences), entry thunks, and exit thunks.</span></p>
			<p><span face="Verdana" size="2">Let's say you compiled a function main() which calls a function work() and 
			both are compiled as ARM64EC.&nbsp; The compiled main() will use a BL 
			instruction to directly call to the work() function - "BL" is the 
			ARM64 equivalent of the x86/x64 "CALL" instruction.&nbsp; But what 
			if either main() or work() was compiled as x64?&nbsp; ARM64X augments the 
			existing ARM64 binary format to handle such a situation using these 
			three types of additional code blocks:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">- An <b>entry thunk</b> is a small 
			native ARM64 funclet which marshals any state coming in from the x64 
			caller and then calls the target ARM64EC function.&nbsp; i.e. it is 
			a wrapper from x64 caller to ARM64EC callee.</span></p>
				<p><span face="Verdana" size="2">- Similarly an <b>exit thunk</b> is a small ARM64 funclet which 
				marshals state coming from an 
			ARM64EC caller going to an x64 callee.</span></p>
				<p><span face="Verdana" size="2">- A <b>fast-forward sequence</b> is an 
				x64 bytecode entry point stub to each exported ARM64EC function, typically used 
			in system DLLs such as NTDLL.DLL to offer "Intel-looking" entry 
			points to what are actually native ARM64EC functions.&nbsp; FFSs are 
			usually automatically generated by the linker and are typically 16 
			bytes in size, but can be overridden manually.&nbsp; If either x64 or ARM64EC code calls GetProcAddress() on an exported function, it will receive the 
			address of the FFS - not the raw ARM64 code of the function itself.&nbsp; 
			This is not unlike <b>native-entry points</b> in managed runtimes 
			such as .NET where exported C# functions which may be called by 
			native code need to export some kind of native entry point.</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">The purpose of the FFS is to allow 
			legacy x64 applications that are not ARM64-aware to patch entry 
			points of DLLs.&nbsp; This is very frequently done by anti-cheat 
			code in games, by debuggers, and, well, malware!&nbsp; When we first 
			brought up x64 emulation (but without proper FFSs), several video games designed for AMD/Intel processors did not work correctly 
			because they were unable to discover valid x64 code to patch.&nbsp; 
			Allowing an emulated application to believe that it is patching a 
			real x64 
			function when that function is really an ARM64EC function is <b>necessary for compatibility</b>.</span></p>
			<p><span face="Verdana" size="2">If you use Visual Studio's linker 
			to disassemble almost any ARM64X binary, for example 
			C:\Windows\System32\NTDLL.DLL, you will see that it begins with 
			these similar looking code sequences which are clearly Intel code:</span></p>
			<blockquote>
				<table>
					<colgroup>
						<col width="72">
						<col width="64" span="8">
					</colgroup>
					<tbody><tr height="18">
						<td colspan="6">
						C:\Windows\System32&gt;link -dump -disasm ntdll.dll</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						Microsoft (R) COFF/PE Dumper Version 14.39.33321.0</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						Copyright (C) Microsoft Corporation.&nbsp; All rights 
						reserved.</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						Dump of file ntdll.dll</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						File Type: DLL</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						<b>&nbsp; 0000000180001000: 48 8B C4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						rax,rsp</b></td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="9">
						<b>&nbsp; 0000000180001003: 48 89 58 20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						qword ptr [rax+20h],rbx</b></td>
					</tr>
					<tr height="18">
						<td colspan="7">
						<b>&nbsp; 0000000180001007: 55&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; push&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						rbp</b></td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						<b>&nbsp; 0000000180001008: 5D&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pop&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						rbp</b></td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="8">
						<b>&nbsp; 0000000180001009: E9 D2 9C 1C 00&nbsp;&nbsp;&nbsp;&nbsp; jmp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						00000001801CACE0</b></td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						<b>&nbsp; 000000018000100E: CC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3</b></td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						<b>&nbsp; 000000018000100F: CC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3</b></td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000000180001010: 48 8B C4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						rax,rsp</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="9">
						&nbsp; 0000000180001013: 48 89 58 20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qword 
						ptr [rax+20h],rbx</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000000180001017: 55&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; push&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rbp</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000000180001018: 5D&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pop&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rbp</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="8">
						<b>&nbsp; 0000000180001019: E9 02 9E 1C 00&nbsp;&nbsp;&nbsp;&nbsp; jmp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						00000001801CAE20</b></td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						&nbsp; 000000018000101E: CC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						&nbsp; 000000018000101F: CC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000000180001020: 48 8B C4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						rax,rsp</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="9">
						&nbsp; 0000000180001023: 48 89 58 20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qword 
						ptr [rax+20h],rbx</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000000180001027: 55&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; push&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rbp</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000000180001028: 5D&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pop&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rbp</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="8">
						<b>&nbsp; 0000000180001029: E9 32 9E 1C 00&nbsp;&nbsp;&nbsp;&nbsp; jmp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						00000001801CAE60</b></td>
						<td>&nbsp;</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2">These are the individual Fast 
			Forward Sequences.&nbsp; Each is 16 bytes long, each is a MOV MOV 
			PUSH POP JMP sequence which mimics <b>a typical x64 C function prolog</b> 
			(the spilling of RBP to create a stack frame and the spilling of RBX 
			to the caller's "homeparam" area) and <b>epilog</b> (popping the stack 
			frame) followed by tail-jump to another function.&nbsp; Two INT 3 
			padding bytes to round each FFS up to 16 bytes since by design an 
			FFS must begin at a 16-byte alignment.</span></p>
			<p><span face="Verdana" size="2">This sequence is not the original 
			FFS we shipped in Windows 11 SV1 (build 22000) back in 2021.&nbsp; 
			We had a simpler sequence but as it turned out this broke some video 
			games because we used x64 instructions that their hotpatchers were 
			not used to seeing.&nbsp; After a constructive email exchange with 
			the folks at Valve we zeroed in on this much more compatible code 
			sequence.&nbsp; <b>Pro tip:</b> This is why Windows 11 SV2 (build 
			22621) is the minimum version of Windows on ARM you should be using 
			your ARM64 device.&nbsp; If your device came with build 22000 or 
			even Windows 10 build 19041, or you are building using a Windows SDK 
			prior to build 22621, upgrade it!</span></p>
			<p><span face="Verdana" size="2">Notice that the only difference 
			between each FFS is the target address of the final jump 
			instruction.&nbsp; Each FFS jumps to a different ARM64EC 
			function which that particular FFS is associated with.&nbsp; And if 
			we look at the entire "link -dump -disasm ntdll.dll" output and 
			search for those target addresses, we see for example that those 
			first two targets very much appear to be jumping to native ARM64 code:</span></p>
			<blockquote>
				<table>
					<colgroup>
						<col width="72">
						<col width="64" span="6">
					</colgroup>
					<tbody><tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CACE0: A9BD7BFD&nbsp; stp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fp,lr,[sp,#-0x30]!</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CACE4: A90153F3&nbsp; stp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						x19,x20,[sp,#0x10]</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CACE8: A9025BF5&nbsp; stp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						x21,x22,[sp,#0x20]</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						&nbsp; 00000001801CACEC: 910003FD&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fp,sp</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CACF0: 9403BD00&nbsp; bl&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						00000001802BA0F0</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						&nbsp; 00000001801CACF4: D10143FF&nbsp; sub&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sp,sp,#0x50</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						&nbsp; 00000001801CACF8: AA0003F3&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x19,x0</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CAE20: 58000108&nbsp; ldr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						x8,00000001801CAE40</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CAE24: F805401F&nbsp; stur&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; xzr,[x0,#0x54]</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CAE28: 58000109&nbsp; ldr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						x9,00000001801CAE48</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CAE2C: A9042009&nbsp; stp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						x9,x8,[x0,#0x40]</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CAE30: 18000108&nbsp; ldr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						w8,00000001801CAE50</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000001801CAE34: B9005008&nbsp; str&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; w8,[x0,#0x50]</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						&nbsp; 00000001801CAE38: D65F03C0&nbsp; ret</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2">Some obvious questions should 
				come to mind:&nbsp; how does the linker know to display one 
				section of code as x64 and another block of code as ARM64?&nbsp; 
				Remember, these are in the same binary.&nbsp; And at runtime, 
				how does the x64 emulator know to transition from the emulated 
				JMP instruction to what is obviously not emulated native ARM64 
				code?</span></p>
			<p><span face="Verdana" size="2">Well, let's dive in further and 
			attach a debugger...</span></p><hr>
			<p><b><span face="Verdana"><a name="Bitmap">The EC bitmap and the duality of context</a></span></b></p>
			<p><span face="Verdana" size="2">If you use "start /machine amd64 
			cmd.exe" to launch CMD.EXE in emulation compatible mode and then 
			attach the debugger to that process (use Task Manager to look up the 
			process ID, then the -p switch to specify that process ID):</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar1.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">As the debugger loads up, you can 
			see that the system DLLs&nbsp;which CMD.EXE references (and CMD.EXE 
			itself) are coming from C:\Windows\System32.&nbsp; Notice also the 
			loading of <b>xtajit64.dll</b> immediately after NTDLL.DLL loads.&nbsp; 
			NTDLL is the first DLL that loads into any process and takes care of 
			bootstrapping the rest of the process launch.&nbsp; When a process 
			is launched as x64 compatible, NTDLL immediately loads the 
			x64-to-ARM64 translator - xtajit64.dll.&nbsp; <b>Pro tip:</b> This 
			is an implementation detail - xtajit64.dll could be loaded on demand 
			only when emulated x64 code is hit, but for simplicity the 
			translator 
			is currently <i>always</i> loaded if there is even the possibility 
			that emulation will take place.&nbsp; That also implies that an EC 
			bitmap is also always created for any ARM64EC process.</span></p>
			<p><span face="Verdana" size="2">And where we broke in NTDLL.DLL is 
			in fact ARM64 bytecode.&nbsp; And if I <b>type r</b> for a register 
			dump, I am shown ARM64 register state:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar2.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Note that <b>X13 X14 X23 X24 X28 
			are zero</b>, as they should be because they are unused in an 
			ARM64EC process and therefore should hold no valid data.</span></p>
			<p><span face="Verdana" size="2">Note also that the <b>debugger 
			displays "ARM64EC"</b> at the prompt, indicating that we are in an 
			"emulation compatible" process, not a classic ARM64 native process, 
			even though we happen to be at a function that compiled in ARM64 
			bytecode.</span></p>
			<p><span face="Verdana" size="2">Ok, let's exit the debugger and 
			repeat this, but this time we will make use of the <b>.effmach</b> 
			debugger command to switch between "<b>AMD64 view</b>" (i.e. x64) 
			and "<b>ARM64EC view</b>".&nbsp; Launch the debugger and first type 
			in <b>.effmach arm64</b> and dump the registers using <b>r</b>.&nbsp; 
			Then type <b>.effmach amd64</b> and <b>r</b> look at the register 
			dump <i>that</i> produces:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar5.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Remember, we are stopped at the same breakpoint at 
			the same RET instruction, and yet the debugger is able represent the 
			ARM64 state as a valid x64 state.&nbsp; Compare the registers 
			and you will see X0 ==RCX, X1 == RDX, PC == RIP, SP == RSP.&nbsp; 
			Even if you didn't have the register mapping table I presented 
			above, and you didn't peek at winnt.h, you could through trial and 
			error derive the register mapping by modifying a given register in 
			one view and then use .effmach to switch views and see which 
			register is modified.&nbsp; You can confirm for yourself that there 
			is in fact a 1:1 register mapping between x64 and ARM64EC.</span></p>
			<p><span face="Verdana" size="2">Notice that in <i>both</i> views, the 
			debugger still displays "ARM64EC" at the prompt and disassembles the 
			correct ARM64 RET instruction at the program counter.&nbsp; First it 
			would not make sense to try to disassemble the bytecode D65F03C0 as 
			Intel code.&nbsp; But second, how does the debugger <i>know</i> this 
			is ARM64 bytecode and not x64 bytecode?&nbsp; (This is the same 
			question I raised earlier about how does "link -dump -disasm" know)</span></p>
			<p><span face="Verdana" size="2">That's where it <b>EC Bitmap</b> 
			comes in, the data structure I mentioned which maintains the 
			architecture state of <b>every single 4K page</b> of the address 
			space of a process.&nbsp; Yes, that's a lot of bits, since 64-bit 
			Windows processes contain 47 bits of address space (or 128 
			terabytes) which dividing by 4096 bytes-per-page means there are 32 
			billion pages or 4 gigabytes of bitmap - per process!.&nbsp; That's 
			ok, the bitmap is sparsely allocated by the kernel and allocated 
			only as modules (EXEs and DLLs) are mapped in, so the true memory 
			footprint of the EC bitmap in each process is miniscule.</span></p>
			<p><span face="Verdana" size="2">It is during the loading of 
			binaries into a process that the OS checks the ARM64X metadata, 
			which contains a table of ranges specifying which address ranges of 
			the binary are ARM64EC and which are not.&nbsp; <b>The metadata is 
			how the linker knows</b> and how link -dump -disasm knows the 
			architecture of a given instruction.&nbsp; You can view this 
			metadata in an ARM64X binary by using the linker's
			<a href="https://learn.microsoft.com/en-us/cpp/build/reference/loadconfig?view=msvc-170">
			-loadconfig</a> command:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">link -dump <b>-loadconfig</b> 
				cmd.exe</span></p>
				<p><img src="http://www.emulators.com/docs/abc_ar20.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Note that CMD.EXE contains _3_ 
			types of code ranges: classic ARM64, ARM64EC, and x64.&nbsp; The x64 
			is the smallest section since it contains mainly the Fast Forward 
			Sequences which will only be accessed during emulation.&nbsp; A 
			larger section is pure classic ARM64 which is unique to when CMD.EXE 
			is launched as classic ARM64.&nbsp; But the vast majority of the 
			code is ARM64EC as expected.&nbsp; The ARM64EC sections (two of 
			them, one contains functions, the other contains thunks) are commom, 
			meaning:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">- when running as a "classic" 
				ARM64 process, both the ARM64 and ARM64EC code sections will be 
				used and executed natively.</span></p>
				<p><span face="Verdana" size="2">- when running as an emulated 
				x64 process or an ARM64EC process (same thing!), the x64 and 
				ARM64EC sections will be used.&nbsp; The code in the classic 
				ARM64 range will be inaccessible.</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">The Windows SDK exports a function 
			called
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/winnt/nf-winnt-rtliseccode">
			RtlIsEcCode()</a> which allows a user mode process to query its own 
			EC bitmap to determine if a target function address is valid a ARM64EC 
			target or a foreign x64 target.&nbsp;
			<b>The EC bitmap is how the debugger knows</b> the architecture of a 
			code page at run time, and 
			that's how the x64 emulator itself knows when it is emulating an 
			Intel CALL or JMP or RET which architecture it is branching to.</span></p>
			<p><span face="Verdana" size="2">To answer the question "<b>is 
			Microsoft Office on ARM64 native or emulated?</b>" let's do the same 
			thing on say, Outlook.exe and Excel.exe:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">link -dump -loadconfig <b>
				outlook.exe</b></span></p>
				<p><img src="http://www.emulators.com/docs/abc_ar21.gif"></p>
			</blockquote>
			<blockquote>
				<p><span face="Verdana" size="2">link -dump -loadconfig <b>
				excel.exe</b></span></p>
				<p><img src="http://www.emulators.com/docs/abc_ar22.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">You can see that the vast majority 
			of the code - over 34 megabytes of Outlook.exe and over 51 megabytes 
			of Excel.exe - are in fact ARM64EC native code ranges.&nbsp; There 
			is on the order of 100 kilobytes of x64 code in each, which a quick 
			disassembly shows to be a lot of entry/exit thunks, but 
			interestingly also what looks to be some hand coded assembly which 
			is likely related to interacting with legacy x64 Office plugins.</span></p>
			<p><span face="Verdana" size="2">So far so good, it would appear 
			that the main application .EXE binaries are almost entirely native 
			ARM64 code.&nbsp; Let's dig further...</span></p>
			<p><span face="Verdana" size="2">I'll cover code translation in more 
			detail in the emulation tutorial.&nbsp; A quick way to tell if an 
			application is generating a lot of x86-to-ARM64 or x64-to-ARM64 
			translations (which indicates emulation is taking place) is to look 
			in the subdirectory <b>C:\Windows\XtaCache</b>.&nbsp; This is where 
			both xtajit and xtajit64 cache their code translations.&nbsp; You 
			can judge by the size of a <b>.JC</b> (jit cache) file how much 
			emulator code each specific binary is generating.&nbsp; So I go and 
			launch Outlook, Word, Excel, and PowerPoint and use them a bit and 
			exit, I can now check the XtaCache subdirectory and sort by date to 
			see exactly which binaries are touched by the emulator and how much:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">C:\Windows&gt; <b>dir /a /Od 
				XtaCache</b></span></p>
				<p><span face="Verdana" size="2"><b>01/23/2024 05:54 AM 88,680 
				OUTLOOK.EXE.BB1C9B41ACF02FA754BB74F904EEECF8.28F307BCA34BF44EAC10A7104D0E223C.x64.mp.1.jc<br>
				</b>01/23/2024 05:54 AM 168,606 
				WEBVIEW2LOADER.DLL.F7A965A9458230A54892AF2CE984AA46.00050C948F07C2E25A75BC49121A5924.x64.mp.1.jc<br>
				01/23/2024 06:09 AM 71,468 
				TAIL.EXE.EF21B14F854F1EBED50BA626799C7F79.9BFA6B654B9A942355FC2ED954ABDC5D.x64.mp.1.jc<br>
				01/23/2024 06:22 AM 131,234 
				OART.DLL.601AFE7C3A54F2E89F06B7CF0CC4C696.3CE8CCE3ED05781A877981D0D62BB5BF.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,982 
				SFC_OS.DLL.351F330D27A1F357C71B6E108284D2AC.D236FAC5EC48DFACF4D07604F5D89D5F.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,048 
				SERVICINGCOMMON.DLL.A4EBC5AC7F9BFC175E09FF86605E2F53.03C17FC63C439D666569F49B0C4B66F4.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,426 
				CONTAB32.DLL.78710E60F2BBAAD78F442006830850EF.7C9E924620167D6A093C8F2B0743E55C.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 193,772 
				WWLIB.DLL.3F3C95BF9729B8E9B90DFC1B47CF136F.AB7A77F4F0ADB0704A3A4F3944FCE7F5.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 67,952 
				MSOARIA.DLL.49F64D2FFD552D2AEE0066FBB20AC0AA.0B433D08299C6A4B80472261F938961C.x64.mp.1.jc<br>
				<b>01/23/2024 06:23 AM 64,994 
				POWERPNT.EXE.0FA4B625156C7E22114674F97117F987.445CA6519BAA38F94D96C608ACABDE83.x64.mp.1.jc<br>
				</b>01/23/2024 06:23 AM 67,568 
				IGX.DLL.E55FD01ED682C0CF6A860F3CCF40C1E4.598722777E595BE921B62125D4A45EFC.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 74,072 
				GFX.DLL.4688A841C810BE4AA33EBE0CC4EE9D48.527266E60435F17D2ED348AD598F7C0F.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,498 
				OUTLOOKSERVICING.DLL.E6FDC7D94FC2E5DC2ED8E44510929958.B52DE03B38FCB44C156D2A5D271CBB55.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 80,202 
				OLMAPI32.DLL.2459AF91A6F406820638793C24F46439.FF855104181457CA8B68CE7523A432FE.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,804 
				WINDOWS.DEVICES.BLUETOOTH.DLL.F3D86AA7C586DFA66FC92CC3EECB5472.20B53A6F8C40E20B7B39964CFD7BEC2A.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 157,296 
				IEAWSDC.DLL.32343461F32FEFA26DDDFF1F55DAD5E7.12E5B9EC4939B165D34C06332FD04F16.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,798 
				MSO.FRAMEPROTOCOLWIN32.DLL.1533364B4506B30B0A426EA7E5C0D7AA.5547EB87D6620BA52AD21FE6168D5FC5.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,940 
				AI.DLL.17F946C18BF38EFAB445C810E0A8E658.81CE4E787F0D8C3956C9BB8B8BE9A173.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,948 
				D3D10WARP.DLL.ED3CAD011000588D0F1B27DAF50378CA.2B79EFF5B5150C5D9F1B98A59A0AAABE.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 778,368 
				C2R64.DLL.4FBA42E853A27A798097E91F9242FF56.07F9EDD226D7954A96572137A070070F.x64.mp.4.jc<br>
				01/23/2024 06:23 AM 167,564 
				MSO40UIWIN32CLIENT.DLL.E4E546F2451CDD2988FDFFE4D8B5F687.7C398CFCDD2F68E26F7D60CBCB13E10F.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 132,570 
				MSVCP140.DLL.7D64A17BAE313AF8A41A9F525D5C147A.491D6ABD6095F2F3EFC2D0D5ED69012B.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 64,748 
				COML2.DLL.992843969650CA2377CBC402C350B364.9D89F87B63B4EC2898AFC3C8949E19AE.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 163,008 
				MSO30WIN32CLIENT.DLL.8026AB5960DA1C94D238D79D552A6FC1.23547E6FFC5402E4271FB5950548C91D.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 169,744 
				MSO20WIN32CLIENT.DLL.52241F82F91457A9740F7D4E6C37FA0B.148AC8FF5A06F17BE0DAD9227B368A09.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 65,440 
				MSO50WIN32CLIENT.DLL.E1E2A4C4771314BFFFADAFF2BF28E6A7.2C5A97CB7AF417BF3592C61A341161C7.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 167,360 
				MSO98WIN32CLIENT.DLL.60710D27D93488345B89FB617875154D.64EB2117462B7AB775BD80631DCF8FB5.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 73,824 
				RICHED20.DLL.E76058D10B247544B77BD6DC2FE82963.6DE16CA9E2C7064821B871D72BFA6DBF.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,734 
				MSOHEV.DLL.A7CEAACAC2F7E67007AD26927159E2C1.E1F23C163A3F14CC3D4AD152FDC96AE3.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 66,090 
				WINDOWS.UI.IMMERSIVE.DLL.0A0ACBA56219A13F710D183F9FD359D7.36C9170AEE59318A9028824AF69056BA.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,680 
				MSIMG32.DLL.8049E381C74F44B50018150D632B01BC.38C4A4D39935EA16464DAAC785851C75.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 395,018 
				REACT-NATIVE-SDK.DLL.F3043F77194AE0F4C21CE74B7D9464A6.9E567FEA2EFC0D5C4FEF6F0B2FA7FB82.x64.mp.2.jc<br>
				01/23/2024 06:23 AM 1,202,206 
				REACT-NATIVE-WIN32.DLL.D6B56BAB43AFD6336C03A817CBDB0CDC.6FB9042A6F80A92B33FCAB32858EAD30.x64.mp.4.jc<br>
				01/23/2024 06:23 AM 234,600 
				DBGHELP.DLL.54150AE99DD539FA29D651AACC8BD84F.C2C0596729F902FC996F7554F8B0EA35.x64.mp.2.jc<br>
				01/23/2024 06:23 AM <b>12,092,252 V8JSI.DLL</b>.77EF9D00D06826F42D239C173D7616EB.40BBABEA5574359C895135C00FD90774.x64.mp.3.jc<br>
				01/23/2024 06:23 AM 65,804 
				MSPTLS.DLL.CD4A6C848C221A6DA8137B3A64CDBB97.6D7A5B97D3C262509BB94C419198FF3A.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,720 
				APPRESOLVER.DLL.87B32F3998415F26C49E025AA88BD6A2.48BBBD5A5247C146A18392947AC2AFC1.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,034 
				LINKINFO.DLL.FB6621014A23792FFDCD0913064BE8B3.B25146DF7344407349E964EBF28AAAC3.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 65,352 
				NTSHRUI.DLL.A7A81FAC6039E083FABB705A626E8BC7.44F6EF8031A06207D3BEC4029856E74D.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 64,678 
				SRVCLI.DLL.ECF2D659185A38F2A8D3733469034E76.5C98E5AD07C5553505AFAB58B19493F6.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 66,040 
				DAVHLPR.DLL.16C01681FB54FA1B6DA875892C04DA86.C8F7FF58332D95F94BF3421AFF0EAA78.x64.mp.1.jc<br>
				01/23/2024 06:23 AM 1,219,144 
				PIDGENX.DLL.DA3CAEEDF156B2C82D46AEF97CE8BE27.44F6D28474847DB417F8F6F598DFEB6E.x64.mp.1.jc<br>
				01/23/2024 06:24 AM 137,104 
				OMICAUT.DLL.467B6171F144A7200EDD116CE9B15AFA.7A2FE638A220E7A3361054D629B1A6CC.x64.mp.1.jc<br>
				01/23/2024 06:24 AM 67,988 
				CHART.DLL.491FC0D80B97CE83C481C1E0BDBB511F.0B6935B3D0768B91A40430A95D3D2067.x64.mp.1.jc<br>
				<b>01/23/2024 06:24 AM 192,108 
				EXCEL.EXE.D8F34D98A8555E44F03BB09747513981.F1A0C4312A02C493D9D234D7959E03E3.x64.mp.2.jc<br>
				</b>01/23/2024 06:30 AM 64,664 
				MPR.DLL.43D30D29C847C32A8BAA0238326F22F9.C0B39412D82CAD166EC5C7155491CC38.x64.mp.1.jc<br>
				01/23/2024 06:30 AM 64,934 
				DRPROV.DLL.C4A971894F781B8492150A06533D03C5.BB6DE8A28144321073E8D067731720A0.x64.mp.1.jc<br>
				01/23/2024 06:30 AM 64,984 
				DAVCLNT.DLL.BB6DF1D9CB70F9F020E0F9FEEA55521B.227C73329CE2A2A671136EF7B3D8EDCC.x64.mp.1.jc<br>
				01/23/2024 06:30 AM 65,298 
				NTLANMAN.DLL.458B6CC1D2185C6A8C1C4EB29D333898.1750F958BA966845BF0706126AE93C3A.x64.mp.1.jc<br>
				01/23/2024 06:30 AM 185,022 
				MSO.DLL.F7FC0169653B6BB4EA1CAD28F12A178B.D10D3D991194B3DA43A846284A9B7284.x64.mp.2.jc<br>
				01/23/2024 06:30 AM 285,790 
				PPCORE.DLL.D439B9AFD7A8A76DBB5F880225629F3D.5714731BA7ED35CEA09870B29CF1C6BC.x64.mp.3.jc<br>
				01/23/2024 06:30 AM 64,694 
				WUCEFFECTS.DLL.8857335A8A1977C011360E9BE680C087.B67DD01A9FE27B8FBE0F2BA8B4012AD8.x64.mp.1.jc<br>
				01/23/2024 06:30 AM 64,676 
				DXVA2.DLL.4ECAA6EAC676A95E7CB7CA8D69C44063.5DC28671247C0A07EAD917B0636A6E68.x64.mp.1.jc<br>
				01/23/2024 06:31 AM 134,102 
				URLMON.DLL.DC87D10943754E912602DA54DC0A3A52.CCE2FF813765365C077865A69087FFA4.x64.mp.2.jc</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">Needless to say, Office uses a lot 
			of DLLs and because each process (outlook.exe, winword.exe, 
			excel.exe, powerpnt.exe) is running as ARM64EC, any DLL that they 
			load also has to run in ARM64EC mode which means the emulator is 
			invoked on every single DLL as well.</span></p>
			<p><span face="Verdana" size="2">For technical reasons the minimum 
			size of a .JC file is about 44 kilobytes, so the fact that most of 
			these cached translations are in the 64K to slightly over 100K range 
			is a good sign.</span></p>
			<p><span face="Verdana" size="2">The one cached translation that 
			clearly pops out as heavily emulated (due to the 12 megabytes of 
			cached translation) is <b>V8JSI.DLL</b> which is related to the
			<a href="https://github.com/microsoft/v8-jsi">V8 Javascript</a> 
			engine.&nbsp; So finding that DLL in the Office installation and 
			dumping the header:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar23.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2"><b>Busted!</b>&nbsp; We clearly see 
			that <b>V8JSI.DLL is not ARM64X</b> but rather is a pure-x64 legacy 
			binary of machine type <b>8664</b> and therefore has not been ported 
			to ARM64EC.&nbsp; This means that when executing scripts in Office 
			on ARM64 you will be hitting emulation overhead.&nbsp; "Emulation 
			Compatible" interoperability in action!</span></p><hr>
			<p><b><span face="Verdana"><a name="New_Tricks">Interoperability in action - with some 
			new tricks!</a></span></b></p>
			<p><span face="Verdana" size="2">So let's take an even deeper look at an actual 
			ARM64X binary - <b>KERNEL32.DLL</b>.</span></p>
			<p><span face="Verdana" size="2">I choose KERNEL32.DLL because it 
			and NTDLL.DLL are probably the most patched DLLs in the history of 
			Windows.&nbsp; Every debugger, tracing tool, and game anti-cheat 
			mechanism relies on patching certain low-level system calls in 
			KERNEL32 and NTDLL.</span></p>
			<p><span face="Verdana" size="2">Let's make a stupid simple test 
			program which does nothing but return the current tick count returned 
			by the system function
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/sysinfoapi/nf-sysinfoapi-gettickcount">
			GetTickCount()</a>.&nbsp; Below is my sample C source code, the 
			compiled x64 binary code, and the output of the program when I run 
			it from the command line:</span></p>
			<blockquote>
				<table>
					<colgroup>
						<col width="72">
						<col width="64" span="6">
					</colgroup>
					<tbody><tr height="18">
						<td colspan="3">
						#include &lt;windows.h&gt;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						int main()</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						{</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						&nbsp;&nbsp;&nbsp; return GetTickCount();</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						}</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						main&nbsp;&nbsp;&nbsp; PROC</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						; 5&nbsp;&nbsp;&nbsp; : {</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 00000 48 83 ec 28&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sub&nbsp;&nbsp;&nbsp;&nbsp; rsp, 
						40&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ; 00000028H</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						; 6&nbsp;&nbsp;&nbsp; :&nbsp;&nbsp;&nbsp;&nbsp; return GetTickCount();</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						&nbsp; 00004 ff 15 00 00 00</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; call&nbsp;&nbsp;&nbsp; QWORD PTR __imp_GetTickCount</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						; 7&nbsp;&nbsp;&nbsp; : }</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="7">
						&nbsp; 0000a 48 83 c4 28&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; add&nbsp;&nbsp;&nbsp;&nbsp; rsp, 
						40&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ; 00000028H</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						&nbsp; 0000e c3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ret&nbsp;&nbsp;&nbsp;&nbsp; 0</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						main&nbsp;&nbsp;&nbsp; ENDP</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						D:\GTC_DEMO&gt;gtc &amp; echo %errorlevel%</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						785812390</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						D:\GTC_DEMO&gt;gtc &amp; echo %errorlevel%</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						785812921</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						D:\GTC_DEMO&gt;gtc &amp; echo %errorlevel%</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						785815703</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2"><b>Pro tip:</b> every Windows 
			application returns an exit code, just as this test program does.&nbsp; 
			You can query the <b>ERRORLEVEL</b> environment variable to see this 
			return value by using the <b>echo</b> command as shown above.</span></p>
			<p><span face="Verdana" size="2">Notice how the return value above 
			is a nice monotonically increasing value as expected from a 
			millisecond tick 
			counter.&nbsp; If we attach a debugger and single-step the execution 
			of the main() function as it calls into GetTickCount(), it is a 
			straightforward sequence of execution for a grand total of 10 
			instructions:</span></p>
			<blockquote>
				<table>
					<colgroup>
<!--StartFragment-->
 <col width="72">
						<col width="64" span="17">
					</colgroup>
					<tbody><tr height="18">
						<td colspan="2">
						0:000&gt; bp main</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; g</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						Breakpoint 0 hit</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						gtc!main:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						00007ff6`9fea7330 4883ec28&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sub&nbsp;&nbsp;&nbsp;&nbsp; rsp,28h</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						gtc!main+0x4:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="18">
						00007ff6`9fea7334 ff15c69c0900&nbsp;&nbsp;&nbsp; call&nbsp;&nbsp;&nbsp; qword ptr [gtc!_imp_GetTickCount 
						(00007ff6`9ff41000)] 
						ds:00007ff6`9ff41000={KERNEL32!GetTickCount 
						(00007ffb`0769f540)}</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						KERNEL32!GetTickCount:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="11">
						00007ffb`0769f540 b92003fe7f&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp; ecx,offset 
						SharedUserData+0x320 (00000000`7ffe0320)</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						KERNEL32!GetTickCount+0x5:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="12">
						00007ffb`0769f545 488b09&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp; rcx,qword ptr 
						[rcx] ds:00000000`7ffe0320=000000000179d8ff</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						KERNEL32!GetTickCount+0x8:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="15">
						00007ffb`0769f548 8b04250400fe7f&nbsp; mov&nbsp;&nbsp;&nbsp;&nbsp; eax,dword ptr 
						[SharedUserData+0x4 (00000000`7ffe0004)] 
						ds:00000000`7ffe0004=0fa00000</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						KERNEL32!GetTickCount+0xf:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						00007ffb`0769f54f 480fafc1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; imul&nbsp;&nbsp;&nbsp; rax,rcx</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						KERNEL32!GetTickCount+0x13:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						00007ffb`0769f553 48c1e818&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; shr&nbsp;&nbsp;&nbsp;&nbsp; rax,18h</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="3">
						KERNEL32!GetTickCount+0x17:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="5">
						00007ffb`0769f557 c3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ret</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						gtc!main+0xa:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="6">
						00007ff6`9fea733a 4883c428&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; add&nbsp;&nbsp;&nbsp;&nbsp; rsp,28h</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						0:000&gt; t</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						gtc!main+0xe:</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="5">
						00007ff6`9fea733e c3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ret<!--EndFragment --></td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2">main() returns back to the C 
			runtime which ultimately returns the error code as it terminates the 
			process.</span></p>
			<p><span face="Verdana" size="2">Now the trace above was done on an 
			actual AMD processor, so no ARM64 or emulation is involved.&nbsp; Let's run this exact same binary on an ARM64 device and 
			single-step it in the debugger.&nbsp; Notice that as expected the 
			xtajit64.dll emulator is loaded immediately after NTDLL.DLL:</span></p>
			<blockquote>
				<p><img src="http://www.emulators.com/docs/abc_ar18.gif"></p>
			</blockquote>
			<p><span face="Verdana" size="2">Now single-step, and notice 
			the <b>"EXP+#" name decoration</b> added to the GetTickCount() 
			function in KERNEL32.DLL, this actually the name decoration used on 
			fast forward sequences:</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; bp main
0:000:ARM64EC&gt; g
Breakpoint 0 hit
gtc!main:
00007ff6`7b407270 4883ec28        sub     rsp,28h
0:000&gt; t
gtc!main+0x4:
00007ff6`7b407274 ff15869d0900    call    qword ptr [gtc!_imp_GetTickCount (00007ff6`7b4a1000)] ds:00007ff6`7b4a1000={KERNEL32!EXP+#GetTickCount (00007ffb`9c4b1070)}
0:000&gt; t
KERNEL32!<b>EXP+#GetTickCount</b>:
00007ffb`9c4b1070 b92003fe7f      mov     ecx,offset SharedUserData+0x320 (00000000`7ffe0320)
0:000&gt; t
KERNEL32!EXP+#GetTickCount+0x5:
00007ffb`9c4b1075 488b09          mov     rcx,qword ptr [rcx] ds:00000000`7ffe0320=000000000302228a
0:000&gt; t
KERNEL32!EXP+#GetTickCount+0x8:
00007ffb`9c4b1078 8b04250400fe7f  mov     eax,dword ptr [SharedUserData+0x4 (00000000`7ffe0004)] ds:00000000`7ffe0004=0fa00000
0:000&gt; t
KERNEL32!EXP+#GetTickCount+0xf:
00007ffb`9c4b107f 480fafc1        imul    rax,rcx
0:000&gt; t
KERNEL32!EXP+#GetTickCount+0x13:
00007ffb`9c4b1083 48c1e818        shr     rax,18h
0:000&gt; t
KERNEL32!EXP+#GetTickCount+0x17:
00007ffb`9c4b1087 c3              ret
0:000&gt; t
gtc!main+0xa:
00007ff6`7b40727a 4883c428        add     rsp,28h
0:000&gt; t
gtc!main+0xe:
00007ff6`7b40727e c3              ret</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">Aha, surprise!&nbsp; I tricked you!&nbsp; 
			I am showing a very <b>cool performance optimization</b> in the 
			latest (post-SV2) Windows Insider builds.&nbsp; Remember I said that 
			a fast forward sequence is the x64 entry point for a native ARM64EC 
			function and that normally a FFS is a 16-byte block of code 
			generated by the linker.&nbsp; That is the <i>default</i> behaviour.&nbsp; 
			A developer is able to override this and provide <i>any</i> x64 code 
			sequence as a FFS for a given function.</span></p>
			<p><span face="Verdana" size="2">So what Microsoft has done in the 
			case of GetTickCount() is (after obviously analyzing performance 
			data) is 
			they chosen to replace the default fast-forward sequence which would 
			have invoked native code to 
			instead remain in emulation and emulate the entirety of GetTickCount().&nbsp; And you 
			can see this FFS implementation of GetTickCount() is identical to the true x64 implementation of 
			GetTickCount() as witnessed on the AMD machine earlier.</span></p>
			<p><span face="Verdana" size="2">Why do this?&nbsp; The cost of transitioning out of 
			emulation to native ARM64EC code and then back into emulation is 
			about 100 to 200 clock cycles, whereas leaving a small function like 
			GetTickCount() emulated only 
			costs a dozen clock cycles or so.&nbsp; <b>Pro tip:</b> Since 
			Windows 11 SV2, Microsoft has gone 
			and accelerated several common Win32 function calls with these 
			custom fast-forward sequences.&nbsp; You can see these by disassembling other parts of that 
			same code page:</span></p>
			<blockquote>
				<pre><span>KERNEL32!<b>EXP+#GetCurrentProcessId</b>:
00007ffb`9c4b1000 65488b042540000000 mov   rax,qword ptr gs:[40h]
00007ffb`9c4b1009 c3              ret</span></pre>
				<pre><span>KERNEL32!<b>EXP+#GetCurrentProcess</b>:
00007ffb`9c4b1010 4883c8ff        or      rax,0FFFFFFFFFFFFFFFFh
00007ffb`9c4b1014 c3              ret</span></pre>
				<pre><span>KERNEL32!<b>EXP+#GetCurrentThreadId</b>:
00007ffb`9c4b1020 65488b042548000000 mov   rax,qword ptr gs:[48h]
00007ffb`9c4b1029 c3              ret

KERNEL32!<b>EXP+#GetCurrentThread</b>:
00007ffb`9c4b1030 48c7c0feffffff  mov     rax,0FFFFFFFFFFFFFFFEh
00007ffb`9c4b1037 c3              ret</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">Common functions such as 
			GetCurrentProcessId(), GetCurrentProcess(), GetCurrentThreadId(), 
			and GetCurrentThread() are all accelerated.&nbsp; The vast majority 
			of Win32 calls are not accelerated of course and will have the default 16-byte FFS.&nbsp; You can poke 
			around and view these for a given module by listing 
			all the "EXP+" symbols and then looking at how they are implemented.&nbsp; 
			For example this a few lines of output (of hundreds) for 
			KERNEL32.DLL:</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; <b>X kernel32!EXP*</b>
00007ffb`9c3c1ef0 KERNEL32!EXP+#EnableThreadProfiling (EXP+#EnableThreadProfiling)
00007ffb`9c3c3c50 KERNEL32!EXP+#LZDone (EXP+#LZDone)
00007ffb`9c3c3470 KERNEL32!EXP+#GetUserDefaultLCID (EXP+#GetUserDefaultLCID)
00007ffb`9c3c5420 KERNEL32!EXP+#VDMConsoleOperation (EXP+#VDMConsoleOperation)
00007ffb`9c3c42a0 KERNEL32!EXP+#QueryActCtxW (EXP+#QueryActCtxW)
00007ffb`9c3c1200 KERNEL32!EXP+#BaseCleanupAppcompatCacheSupportWorker (EXP+#BaseCleanupAppcompatCacheSupportWorker)
00007ffb`9c3c15a0 KERNEL32!EXP+#BasepReleasePackagedAppInfo (EXP+#BasepReleasePackagedAppInfo)
00007ffb`9c3c5960 KERNEL32!EXP+#lstrcat (EXP+#lstrcat)
00007ffb`9c3c39b0 KERNEL32!EXP+#IsValidCalDateTime (EXP+#IsValidCalDateTime)
<b>00007ffb`9c3c4350 KERNEL32!EXP+#QueryPerformanceFrequency</b> (EXP+#QueryPerformanceFrequency)</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">The next thing to know: <b>if you drop the "EXP+" portion</b> 
			of the name decoration, the resulting function name, e.g. #GetTickCount, 
			is the <b>true ARM64EC entry point of the function</b>.</span></p>
			<p><span face="Verdana" size="2">So let's take a look at another 
			function exported by KERNEL32.DLL which is currently not accelerated 
			in build 26020 at the time of this writing,
			<a href="https://learn.microsoft.com/en-us/windows/win32/api/profileapi/nf-profileapi-queryperformancefrequency">
			QueryPerformanceFrequency()</a>.&nbsp; If we disassemble its 
			fast-forward sequence we see the default 16-byte pattern:</span></p>
			<blockquote>
				<pre><span>KERNEL32!EXP+#QueryPerformanceFrequency:
<b>00007ffb`9c3c4350</b> 488bc4          mov     rax,rsp
00007ffb`9c3c4353 48895820        mov     qword ptr [rax+20h],rbx
00007ffb`9c3c4357 55              push    rbp
00007ffb`9c3c4358 5d              pop     rbp
00007ffb`9c3c4359 e902af0600      jmp     KERNEL32!#QueryPerformanceFrequencyStub (<b>00007ffb`9c42f260</b>)
00007ffb`9c3c435e cc              int     3
00007ffb`9c3c435f cc              int     3</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">Given that QPF returns a fixed 
			value during the whole time an application is running, one could argue this function should be accelerated ;-)&nbsp; 
			But I digress.</span></p>
			<p><span face="Verdana" size="2">If we follow that target address of 
			the JMP (and notice the target symbol is decorated only with the <b>#</b> so we know 
			the target is going to be ARM64EC code and thus ARM64 bytecode, and voila...):</span></p>
			<pre><span>KERNEL32!#QueryPerformanceFrequencyStub:
<b>00007ffb`9c42f260</b> 17fff5a4 b           KERNEL32!#QueryPerformanceFrequency (<b>00007ffb`9c42c8f0</b>)</span></pre>
			<p><span face="Verdana" size="2">ok so now let's follow that jump 
			which clearly targets another ARM64EC function:</span></p>
			<blockquote>
				<pre><span>KERNEL32!#QueryPerformanceFrequency:
<b>00007ffb`9c42c8f0</b> f00006f0 adrp        xip0,KERNEL32!_imp_aux_SetThreadPreferredUILanguages (<b>00007ffb`9c50b000</b>)
00007ffb`9c42c8f4 f9430a10 ldr         xip0,[xip0,#0x<b>610</b>]
00007ffb`9c42c8f8 d61f0200 br          xip0</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">and we see that KERNEL32's 
			QueryPerformanceFrequency() is just a DLL import stub, so we follow that 
			indirect jump (the import address is loaded by the ADRP + LDR 
			instructions above, so I use the debugger's <b>dq</b> command to 
			dump the memory being loaded and then disassemble that address):</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; dq <b>00007ffb`9c50b000 + 610</b>
00007ffb`9c50b610  <b>00007ffb`9e11a220</b> 00000000`00000000</span></pre>
			</blockquote>
			<pre><span face="Verdana" size="2">This address ultimately leads to NTDLL!'s RtlQueryPerformanceFrequency() which truly implements the function and returns the 
			value:</span></pre>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; u <b>00007ffb`9e11a220</b> 
<b>ntdll!#RtlQueryPerformanceFrequency</b>:
00007ffb`9e11a220 d2806008 mov         x8,#0x300
00007ffb`9e11a224 f2afffc8 movk        x8,#0x7FFE,lsl #0x10
00007ffb`9e11a228 f9400108 ldr         x8,[x8]
00007ffb`9e11a22c f9000008 str         x8,[x0]
00007ffb`9e11a230 52800020 mov         w0,#1
00007ffb`9e11a234 d65f03c0 ret</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">So to summarize: x64 FFS jumps to 
			ARM64EC stub which jumps to ARM64EC import thunk which jumps to 
			ARM64EC target function.&nbsp; Whew!</span></p>
			<p><span face="Verdana" size="2">Let's compile a 
			QueryPerformanceFrequency() test case as x64 and verify this is what 
			happens:</span></p>
			<blockquote>
				<table>
					<colgroup>
						<col width="72">
						<col width="64" span="3">
					</colgroup>
					<tbody><tr height="18">
						<td colspan="3">
						#include &lt;windows.h&gt;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						int main()</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						{</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						&nbsp;&nbsp;&nbsp; __int64 f;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						&nbsp;&nbsp;&nbsp; QueryPerformanceFrequency(&amp;f);</td>
					</tr>
					<tr height="18">
						<td colspan="2">
						&nbsp;&nbsp;&nbsp; return (int)f;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						}</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
				</tbody></table>
				<table>
					<colgroup>
						<col width="72">
						<col width="64" span="3">
					</colgroup>
					<tbody><tr height="18">
						<td colspan="4">
						D:\GTC_DEMO&gt;qpf &amp; echo %ERRORLEVEL%</td>
					</tr>
					<tr height="18">
						<td>
						10000000</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						D:\GTC_DEMO&gt;qpf &amp; echo %ERRORLEVEL%</td>
					</tr>
					<tr height="18">
						<td>
						10000000</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td>
						</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
					<tr height="18">
						<td colspan="4">
						D:\GTC_DEMO&gt;qpf &amp; echo %ERRORLEVEL%</td>
					</tr>
					<tr height="18">
						<td>
						10000000</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
						<td>&nbsp;</td>
					</tr>
				</tbody></table>
			</blockquote>
			<p><span face="Verdana" size="2">That looks good, 10 MHz is the 
			usual value returned by Windows 11.&nbsp; Ok, now let's debug it on 
			an ARM64 device!</span></p>
			<p><span face="Verdana" size="2">We know that main() is x64 code, so 
			we need to type .effmach amd64 just to make sure the debugger 
			disassembles correctly.&nbsp; We see that the compiled calls to QueryPerformanceFrequency() 
			resolves to an indirect call through an import table entry to 
			KERNEL32.DLL and points at an obvious FFS:</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; <b>.effmach amd64</b>
Effective machine: x64 (AMD64)

0:000&gt; u main
qpf!main [</span><span>D:\GTC_DEMO\qpf.c</span><span> @ 5]:
00007ff6`5ec07270 4883ec38        sub     rsp,38h
00007ff6`5ec07274 488d4c2420      lea     rcx,[rsp+20h]
00007ff6`5ec07279 ff15819d0900    call    qword ptr [qpf!_imp_QueryPerformanceFrequency (<b>00007ff6`5eca1000</b>)]
00007ff6`5ec0727f 8b442420        mov     eax,dword ptr [rsp+20h]
00007ff6`5ec07283 4883c438        add     rsp,38h
00007ff6`5ec07287 c3              ret

0:000&gt; <b>dq 00007ff6`5eca1000</b>
00007ff6`5eca1000  <b>00007ffb`9c3c4350</b> 00007ffb`9c3c4340

0:000&gt; u <b>00007ffb`9c3c4350</b>
KERNEL32!EXP+#QueryPerformanceFrequency:
00007ffb`9c3c4350 488bc4          mov     rax,rsp
00007ffb`9c3c4353 48895820        mov     qword ptr [rax+20h],rbx
00007ffb`9c3c4357 55              push    rbp
00007ffb`9c3c4358 5d              pop     rbp
00007ffb`9c3c4359 e902af0600      jmp     KERNEL32!#QueryPerformanceFrequencyStub (<b>00007ffb`9c42f260</b>)
</span></pre>
			</blockquote>
			<pre><span>At this point we know the target of the FFS is going to be ARM64 bytecode, so we switch views back to ARM64EC and follow that target.  That target itself has an indirect jump through another import table entry which eventually leads us to the real function in NTDLL.DLL:</span></pre>
			<blockquote>
				<pre><span>
0:000&gt; <b>.effmach arm64ec</b>
Effective machine: ARM64EC (CHPEv2 on X64) (ARM64EC)
0:000:ARM64EC&gt; u 00007ffb`9c42f260
KERNEL32!#QueryPerformanceFrequencyStub:
00007ffb`9c42f260 17fff5a4 b           KERNEL32!#QueryPerformanceFrequency (<b>00007ffb`9c42c8f0</b>)

0:000:ARM64EC&gt; u <b>00007ffb`9c42c8f0</b>
KERNEL32!#QueryPerformanceFrequency:
00007ffb`9c42c8f0 f00006f0 adrp        xip0,KERNEL32!_imp_aux_SetThreadPreferredUILanguages (<b>00007ffb`9c50b000</b>)
00007ffb`9c42c8f4 f9430a10 ldr         xip0,[xip0,#0x<b>610</b>]
00007ffb`9c42c8f8 d61f0200 br          xip0

0:000:ARM64EC&gt; dq <b>00007ffb`9c50b000 + 610</b>
00007ffb`9c50b610  <b>00007ffb`9e11a220</b> 00000000`00000000

0:000:ARM64EC&gt; u <b>00007ffb`9e11a220</b>
ntdll!<b>#RtlQueryPerformanceFrequency</b>:
00007ffb`9e11a220 d2806008 mov         x8,#0x300
00007ffb`9e11a224 f2afffc8 movk        x8,#0x7FFE,lsl #0x10
00007ffb`9e11a228 f9400108 ldr         x8,[x8]
00007ffb`9e11a22c f9000008 str         x8,[x0]
00007ffb`9e11a230 52800020 mov         w0,#1
00007ffb`9e11a234 d65f03c0 ret</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">Note the <b>#</b> name decoration, which 
			indicates (as expected) that NTDLL is an ARM64X binary and the 
			RtlQueryPerformanceFrequency function is actually ARM64EC.</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="Marshalling">Function argument marshalling</a></span></b></p>
			<p><span face="Verdana" size="2">But I've skipped a step between 
			when we were in the FFS and then magically appeared in ARM64EC code - 
			the argument 
			and return value marshalling.&nbsp; The caller main() passes a 
			pointer in RCX which needs to be marshaled to the callee's X0, and 
			the callee RtlQueryPerformanceFrequency() returns a boolean in W0 
			which needs to be marshaled back to the caller's EAX.&nbsp; Where is 
			the code which marshals those arguments?</span></p>
			<p><span face="Verdana" size="2">As I explained with xtabase, the emulator could blindly assume a mapping RCX-&gt;X0, RDX-&gt;X1, 
			etc. and this would work fine most of the time (since that is the 
			ARM64EC_NT_CONTEXT mapping), but not always.&nbsp; When the call 
			involves more than 4 arguments, or data structures being passed by 
			value, arguments might need to be swizzled around.&nbsp; And we 
			definitely know <b>the return value does need marshalling</b> since the 
			ARM64EC will return the value in W0 or X0 (which corresponds to the 
			x64 ECX or RCX registers) but it needs to end up in EAX/RAX 
			(W8/X8).&nbsp; I did not show any such code above.</span></p>
			<p><span face="Verdana" size="2">This is where a special detail of 
			ARM64EC comes in - all ARM64EC functions (compiled C/C++ as well as ASM and FFS) need to be 16-byte aligned.&nbsp; This is pretty good 
			advice anyway since most x64 compilers and ARM64 compilers already 
			16-byte-align their functions.&nbsp; Functions don't generally end on a 
			perfect 16-byte boundary so compilers insert padding bytes such as 
			zeroes or NOP instructions to bump the code up to the next 16-byte 
			boundary.&nbsp; ARM64EC takes advantage of this padding by placing a 
			<b>special 32-bit value</b> into the 4 bytes preceding the start of an 
			ARM64EC function.</span></p>
			<p><span face="Verdana" size="2">Let's disassemble ntdll!#RtlQueryPerformanceFrequency 
			as we just did above, but this time starting 4 bytes earlier:</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; u 00007ffb`9e11a220 <b>- 4</b>
00007ffb`9e11a21c <b>001296d9</b> ???
ntdll!#RtlQueryPerformanceFrequency:
00007ffb`9e11a220 d2806008 mov         x8,#0x300
00007ffb`9e11a224 f2afffc8 movk        x8,#0x7FFE,lsl #0x10
00007ffb`9e11a228 f9400108 ldr         x8,[x8]
00007ffb`9e11a22c f9000008 str         x8,[x0]
00007ffb`9e11a230 52800020 mov         w0,#1
00007ffb`9e11a234 d65f03c0 ret</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">That special non-zero (and clearly 
			bogus ARM64 instruction) is actually a <b>signed 32-bit offset</b>.&nbsp; 
			For 
			technical reasons the low bit is always set, so really the value we care 
			about in this case is 0x001296D8.&nbsp; What happens if we apply that offset 
			value to 
			the address of the function:</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; u 00007ffb`9e11a220 + <b>001296d8</b>
ntdll!$<b>ientry_thunk</b>$cdecl$i8$i8:
00007ffb`9e2438f8 d503237f pacibsp
00007ffb`9e2438fc adbb1fe6 stp         q6,q7,[sp,#-0xA0]!
00007ffb`9e243900 ad0127e8 stp         q8,q9,[sp,#0x20]
00007ffb`9e243904 ad022fea stp         q10,q11,[sp,#0x40]
00007ffb`9e243908 ad0337ec stp         q12,q13,[sp,#0x60]
00007ffb`9e24390c ad043fee stp         q14,q15,[sp,#0x80]
00007ffb`9e243910 a9bf7bfd stp         fp,lr,[sp,#-0x10]!
00007ffb`9e243914 910003fd mov         fp,sp
00007ffb`9e243918 d63f0120 <b>blr         x9</b>
00007ffb`9e24391c aa0003e8 <b>mov         x8,x0</b>
00007ffb`9e243920 a8c17bfd ldp         fp,lr,[sp],#0x10
00007ffb`9e243924 ad443fee ldp         q14,q15,[sp,#0x80]
00007ffb`9e243928 ad4337ec ldp         q12,q13,[sp,#0x60]
00007ffb`9e24392c ad422fea ldp         q10,q11,[sp,#0x40]
00007ffb`9e243930 ad4127e8 ldp         q8,q9,[sp,#0x20]
00007ffb`9e243934 acc51fe6 ldp         q6,q7,[sp],#0xA0
00007ffb`9e243938 d50323ff autibsp
00007ffb`9e24393c d00005d0 adrp        xip0,ntdll!LdrpGuardArm64xDispatchIcallNoESFptr+0x5628 (00007ffb`9e2fd000)
00007ffb`9e243940 f9462a10 ldr         xip0,[xip0,#0xC50]
00007ffb`9e243944 d61f0200 br          xip0</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">Aha, an <b>entry thunk</b>!&nbsp; The C/C++ compiler emits 
			entry and exit thunks since it best knows the function signatures 
			of the functions it is compiling.&nbsp; The linker then magically 
			injects the 32-bit signed offset to the entry thunk to the 4 bytes 
			prior to the start of the ARM64EC function.&nbsp; The <b>x64 
			emulator knows to look there</b> as it dispatches the JMP 
			instruction in the FFS, and in reality transitions to the entry thunk, 
			passing the address of the target ARM64EC function in the <b>X9</b> 
			register.&nbsp; That is hidden step I skipped earlier: the emulator 
			does not jump directly from the FFS to the start of the ARM64EC 
			function, but rather to its entry thunk.</span></p>
			<p><span face="Verdana" size="2">You can see above the entry thunk 
			clearly 
			creates a stack frame (the STP FP,LR instruction), calls the ARM64EC function via the "BL X9" 
			instruction, and then upon return it correctly moves the return 
			value from RCX/X0 to RAX,X8, tears down the stack frame, and then 
			tail-jumps through a pointer which leads it back into the x64 
			emulator.</span></p>
			<p><span face="Verdana" size="2">To save code space, entry thunks 
			are not unique for each ARM64EC function; rather, they are unique 
			per call signature.&nbsp; In this case, the name of the entry thunk 
			says it all:</span></p>
			<blockquote>
				<pre><span>ntdll!$ientry_thunk$cdecl$<b>i8</b>$<b>i8</b>:</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">The first $i8 indicates that the 
			return value is an 8-byte integer (i.e. int64).&nbsp; The second $i8 
			indicates that the first function argument is also an 8-byte integer, really a 64-bit pointer in this case.</span></p>
			<p><span face="Verdana" size="2">Why all the <b>spilling of Q6-Q15 
			vector registers</b>?&nbsp; This has to do with subtle differences 
			between 
			<a href="https://learn.microsoft.com/en-us/cpp/build/x64-software-conventions?view=msvc-170">Windows x64 ABI</a> and 
			<a href="https://learn.microsoft.com/en-us/cpp/build/arm64-windows-abi-conventions?view=msvc-170">Windows ARM64 ABI</a>.&nbsp; The Intel x64 
			calling convention considers registers XMM6-XMM15 to be 
			non-volatile, i.e. callee-save.&nbsp; These registers must not be 
			destroyed by the called function.&nbsp; On the other hand, the ARM64 
			calling convention considers portions of all 32 NEON vector 
			registers as scratch.&nbsp; <b>This difference was not reconciled 
			for ARM64EC</b> code generation, so unfortunately the C/C++ compiler 
			has to be conservative and preserve those registers in the entry 
			thunk - even though in this case QueryPerformanceFrequency() clearly 
			does not touch any vector registers.</span></p>
			<p><span face="Verdana" size="2">The easy workaround would have been 
			for Microsoft to slightly harden the ARM64EC ABI (and possibly even 
			the native ARM64 ABI) to always preserve the full registers Q8-Q15 
			in the callee by marking them as non-volatile while only preserving 
			Q6 and Q7.&nbsp; <b>This unfortunate omission</b> means that all 
			x64-to-ARM64EC round trips take this additional penalty of 5 extra 
			STP instructions and 5 extra LDP instructions on every round trip 
			and add slight code bloat to all ARM64X binaries.&nbsp; Remember I 
			mentioned it takes 100 to 200 clock cycles for such a transition, 
			well you're exactly looking at one of the reasons why.</span></p>
			<p><span face="Verdana" size="2">When incrementally porting your 
			application from Intel to ARM, be aware that <b>transitioning between 
			modes has cost</b>, and it will create <b>additional stack frames</b> which would not normally be there 
			on a pure x64 hardware or on classic ARM64.&nbsp; Notice if I set a 
			breakpoint in ntdll!#RtlQueryPerformanceFrequency and then dump the 
			call stack using the <b>k</b> command:</span></p>
			<blockquote>
				<pre><span>Breakpoint 1 hit
ntdll!#RtlQueryPerformanceFrequency:
0:000:ARM64EC&gt; <b>k</b>
 #   Arch   Child-SP          RetAddr               Call Site
</span><span>00</span><span>  ARM64EC 00000062`e6d6fc10 00007ffb`9c4adf14     ntdll!#RtlQueryPerformanceFrequency
</span><span>01</span><span>  ARM64EC 00000062`e6d6fc10 00007ff6`5ec0727f     <b>KERNEL32!$ientry_thunk$cdecl$i8$i8+0x24</b>
</span><span>02</span><span>    AMD64 00000062`e6d6fcc0 00007ff6`5ec074cc     qpf!main+0xf [qpf.c @ 9] 
</span><span>03</span><span>    AMD64 (Inline Function) --------`--------     qpf!invoke_main+0x22 [</span><span>D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl</span><span> @ 78] 
</span><span>04</span><span>    AMD64 00000062`e6d6fd00 00007ffb`9c4ae76c     qpf!__scrt_common_main_seh+0x10c [</span><span>D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl</span><span> @ 288] 
</span><span>05</span><span>  ARM64EC 00000062`e6d6fd40 00007ffb`9c42f568     <b>KERNEL32!$iexit_thunk$cdecl$i8$i8+0x1c</b>
</span><span>06</span><span>  ARM64EC 00000062`e6d6fd70 00007ffb`9e16d1e4     KERNEL32!#BaseThreadInitThunk+0x48
</span><span>07</span><span>  ARM64EC 00000062`e6d6fd80 00000000`00000000     ntdll!#RtlUserThreadStart+0x54</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">The <b>entry thunk stack frame is 
			visible</b> on the call stack.&nbsp; Similarly when the thread 
			initialization code in KERNEL32.DLL (which is ARM64EC) calls in to the test binary 
			and transitions to emulated x64, the <b>exit thunk frame is also 
			visible</b> on the call stack.&nbsp; Keep this in mind if you are 
			writing any kind of tool which performs stack walking.&nbsp; 
			Regardless, this is a small 
			price to pay for seamless argument marshalling.</span></p>
			<p><span face="Verdana" size="2"><b>Pro tip:</b> on the topic of 
			small functions, the Visual C/C++ 
			compiler does not always honor the "inline" keyword which may cause 
			C++ member functions marked as inline to actually be emitted either 
			as x64 or ARM64EC code.&nbsp; Use the __forceinline keyword on small 
			functions to help avoid the x64-&gt;ARM64EC-&gt;x64 mode transitions and 
			the additional thunk frames when porting such small functions.</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="Folding">Hybrid vs. Fat - code folding</a></span></b></p>
			<p><span face="Verdana" size="2">Now I compile the same QueryPerformanceFrequency test 
			case as plain "classic" ARM64, no -arm64EC switch specified.&nbsp; 
			If we load that binary into the debugger we can easily see the flow 
			of control from main() to the implemented of RtlQueryPerformanceFrequency.&nbsp; Note that no 
			fast-forward sequences, thunks, or emulation is involved, as 
			expected.&nbsp; All execution remains as native ARM64 codebytes:</span></p>
			<blockquote>
				<pre><span>0:000:ARM64EC&gt; u main
qpf!main [qpf.c @ 5]:
00007ff6`40df4838 a9be7bfd stp         fp,lr,[sp,#-0x20]!
00007ff6`40df483c 910003fd mov         fp,sp
00007ff6`40df4840 910043e0 add         x0,sp,#0x10
00007ff6`40df4844 94000548 bl          qpf!QueryPerformanceFrequency (<b>00007ff6`40df5d64</b>)
00007ff6`40df4848 f9400be8 ldr         x8,[sp,#0x10]
00007ff6`40df484c 2a0803e0 mov         w0,w8
00007ff6`40df4850 2a0003e0 mov         w0,w0
00007ff6`40df4854 a8c27bfd ldp         fp,lr,[sp],#0x20
00007ff6`40df4858 d65f03c0 ret</span></pre>
				<pre><span>0:000:ARM64EC&gt; u <b>00007ff6`40df5d64</b>
qpf!QueryPerformanceFrequency:
00007ff6`40df5d64 90000530 adrp        xip0,qpf!_hybrid_auxiliary_iat (<b>00007ff6`40e99000</b>)
00007ff6`40df5d68 f940b210 ldr         xip0,[xip0,#0x<b>160</b>]
00007ff6`40df5d6c d61f0200 br          xip0

0:000:ARM64EC&gt; dq <b>00007ff6`40e99000 + 160</b>
00007ff6`40e99160  <b>00007ffb`9c42f260</b> 00007ffb`9c42f290

0:000:ARM64EC&gt; u <b>00007ffb`9c42f260</b>
KERNEL32!#QueryPerformanceFrequencyStub:
00007ffb`9c42f260 17fff5a4 b           KERNEL32!#QueryPerformanceFrequency (<b>00007ffb`9c42c8f0</b>)

0:000:ARM64EC&gt; u <b>00007ffb`9c42c8f0</b>
KERNEL32!#QueryPerformanceFrequency:
00007ffb`9c42c8f0 f00006f0 adrp        xip0,KERNEL32!_imp_aux_SetThreadPreferredUILanguages (<b>00007ffb`9c50b000</b>)
00007ffb`9c42c8f4 f9430a10 ldr         xip0,[xip0,#0x<b>610</b>]
00007ffb`9c42c8f8 d61f0200 br          xip0

0:000:ARM64EC&gt; dq <b>00007ffb`9c50b000 + 610</b>
00007ffb`9c50b610  <b>00007ffb`9e11a220</b> 00000000`00000000

0:000:ARM64EC&gt; u <b>00007ffb`9e11a220</b>
ntdll!<b>#</b>RtlQueryPerformanceFrequency:
00007ffb`9e11a220 d2806008 mov         x8,#0x300
00007ffb`9e11a224 f2afffc8 movk        x8,#0x7FFE,lsl #0x10
00007ffb`9e11a228 f9400108 ldr         x8,[x8]
00007ffb`9e11a22c f9000008 str         x8,[x0]
00007ffb`9e11a230 52800020 mov         w0,#1
00007ffb`9e11a234 d65f03c0 ret</span></pre>
			</blockquote>
			<p><span face="Verdana" size="2">Note the <b>same # name decoration</b> 
			- because ARM64EC compiled bytecode _is_ valid ARM64 code, the 
			ARM64EC and the ARM64 versions of RtlQueryPerformanceFrequency are 
			in fact one and the same function in memory and in the binary.&nbsp; 
			We can see that both my x64 test binary and the classic ARM64 test 
			binary both end up at the same code address - 7FFB9E11A220 the 
			common address of the ARM64EC RtlQueryPerformanceFrequency() 
			function.</span></p>
			<p><span face="Verdana" size="2">Therefore, whether the caller was emulated x64 or classic ARM64, <b>we 
			arrived at the exact same called function</b> which is 
			both ARM64EC _and_ ARM64.&nbsp; This is called "<b>folding</b>" and 
			is performance by the linker so that there are no duplicate (yet 
			identical) ARM64EC and ARM64 versions of the same function in the 
			binary.</span></p>
			<p><span face="Verdana" size="2">This is the clearest example of the 
			difference between <b>fat binary vs. hybrid binary</b>:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">- In a fat binary there would 
				have been both x64 and classic ARM64 versions of every single 
				function spread across two slices, roughly doubling the size of 
				the binary over a pure classic ARM64 binary.</span></p>
				<p><span face="Verdana" size="2">- In a hybrid binary there is 
				generally only one copy a function (as ARM64 bytecode) which can 
				be called from either emulated x64, native ARM64EC, or native 
				classic ARM64 callers.&nbsp; In practice an ARM64X hybrid binary 
				will have about 30% code bloat over a pure classic ARM64 binary 
				(due to thunks and FFS overhead).</span></p>
				<p><span face="Verdana" size="2">- As I demonstrated with the 
				GetTickCount() example, it is possible to replace an ARM64EC's 
				FFS with the full body of that function.&nbsp; Taking this to 
				the extreme and emitting a FFS for <i>every</i> ARM64EC function 
				with the x64 compilation of that same function, you would end up 
				with what is essentially a fat binary.&nbsp; Fat binaries are 
				just a special extreme case of hybrid binaries.</span></p>
			</blockquote>
			<p><span face="Verdana" size="2">The hybrid binary approach 
			of having only one full version of a function in a binary ultimately 
			saved hundreds of megabytes of disk space in Windows 11 compared to a 
			fat binary or multiple binary approach.</span></p>
			<hr>
			<p><b><span face="Verdana"><a name="Debt">The drawbacks of and technical debt in 
			ARM64EC</a></span></b></p>
			<p><span face="Verdana" size="2">It would not be fair for me to end 
			this tutorial without highlight some pitfalls and known problems 
			with the ARM64EC design.&nbsp; I've already pointed out the overhead 
			of switching between x64 and ARM64EC modes and the additional stack 
			frames caused by thunks.&nbsp; That is by design.&nbsp; In fact 
			Apple's original 68020 emulator for PowerPC had a similar concept to 
			the additional stack frames from switch modes.&nbsp; If I remember 
			correctly they were called "switch frames".&nbsp; Now lets look at 
			some undesirable behavior.</span></p>
			<p><span face="Verdana" size="2"><b>One big gotcha</b> to look for - 
			because the entry thunks are generated at compile time of the caller 
			function, <b>make sure that caller and callee's function 
			signatures match!</b>&nbsp; Particularly if one side uses varargs 
			and the other side declares a very specific function signature, 
			ARM64EC argument marshalling will break.&nbsp; This is true in any 
			kind of cross-process function call marshalling but with ARM64EC can 
			occur even in the same process in the same binary.&nbsp; This is not 
			a bug of the ARM64EC design per se, but rather a result of buggy 
			source code.</span></p>
			<p><span face="Verdana" size="2">I hit this gotcha myself when porting the Xformer 10 Atari 8-bit emulator to ARM64EC 
			a couple of years ago.&nbsp; 
			For years the Xformer code base compiled and ran just fine as 32-bit x86, 64-bit 
			x64, and even 64-bit ARM64, but the whole time was masking a real bug in my source 
			code.&nbsp; In my header files I was lazily declaring some functions 
			signatures using "<b>...</b>" syntax which makes them varags.&nbsp; But the 
			functions themselves were not implemented using varargs - I was just 
			lazy defining my function signatures.&nbsp; This worked by accident 
			for 30 years, but once compiled ARM64EC it crashed every time a 
			specific function was called.</span></p>
			<p><span face="Verdana" size="2">If you look my
			<a href="https://github.com/softmac/xformer10">Github repository for 
			Xformer 10</a> and look at the git log and specifically this commit 
			which finally fixed the problem:
			<a href="https://github.com/softmac/xformer10/commit/77af224d59d2b8182e0ea6d81d6d91b89910e77a?diff=unified&amp;w=1#diff-e3c4e227c47f93d39b4b6229c653d54d6d575b35e5cfabee7b177f91f85c6ed2">
			77af224d59d2b8182e0ea6d81d6d91b89910e77a</a> you will see what I 
			mean.&nbsp; I had two different sets of functions with different 
			function signatures which I was calling using the same varargs 
			declaration.&nbsp; Fortunately it took me under an hour to track down and fix this 
			issue and get the ARM64EC build working and tested, technically more than 
			the "matter of minutes" that I promised.</span></p>
			<p><span face="Verdana" size="2">To add to my stupidity the compiler 
			was warning me, but I was ignoring the compiler warning.&nbsp; <b>
			Pro tip:</b>&nbsp; don't ignore compiler warnings. :-)</span></p>
			<p><span face="Verdana" size="2"><b>A design limitation</b> of 
			x64 emulation, ARM64EC, and softintrinsics today is that only Intel 
			SSE instructions and Intel intrinsics are supported (up to and including 
			SSE4.2 with AES).&nbsp; This is due to us choosing not to map the 
			high 16 NEON registers into the ARM64EC context (where they could 
			serve as the upper halves of the YMM0-YMM15 registers), motivated by 
			an upper management decision that <b>SSE4.2 support was "good 
			enough"</b>.&nbsp; SSE4.2 is sufficient to satisfy Windows 11 
			minimum hardware requirements on AMD and Intel hardware.&nbsp; The
			<a href="https://support.microsoft.com/en-us/surface/surface-go-2-specs-and-features-0fc6a657-2851-484f-6f82-bd3c589ed92c">
			Microsoft Surface Go tablet</a> for example is a Windows 
			11-compatible device which only supports SSE4.2 (due to its use of 
			the Intel Pentium Gold processor).&nbsp; I actually use the Surface 
			Go as a reference device since it very close matches in hardware 
			what the emulator implements in software.</span></p>
			<p><span face="Verdana" size="2">What this means is that in ARM64EC, 
			soft intrinsics, and in x64 emulation <b>there is no AVX or AVX2 support</b> or 
			any kind of 256-bit register state support.&nbsp; This is not a 
			problem in the vast majority of Windows apps _yet_, since most either 
			don't use AVX, don't use Intel intrinsics at all, or can #ifdef out 
			such code to build a pure SSE version of the binary to stay 
			compatible with older Windows 7 machines.&nbsp; But Windows 
			developers don't sit still, they target new hardware features.</span></p>
			<p><span face="Verdana" size="2">One only need track the
			<a href="https://store.steampowered.com/hwsurvey">Steam Hardware 
			Survey</a> to see that in the past two years alone the prevalence of 
			AVX and AVX2 capability in Steam users' hardware has jumped to 96% 
			for AVX and 92% for AVX2.&nbsp; (as expected the prevalence of SSE3 
			and SSE4.x is in the 99% to 100% range, of course it is).&nbsp; Two 
			years ago the AVX still in the 80's percentage, so that it is now at 
			96% today worries me a lot.</span></p>
			<p><span face="Verdana" size="2">When I was still at Microsoft in 2022 
			I was arguing the case that it was time to implement AVX and AVX2 
			across the board, but I failed to convince management or my peers of 
			the urgency of this proposal.&nbsp; <b>The big risk to Windows on 
			ARM</b> is that as more games and  
			benchmarks (such as
			<a href="https://www.maxon.net/en/tech-info-cinebench">Cinebench 
			2024</a>) drop SSE support entirely and <i>require</i> AVX2, the usefulness 
			of Microsoft's emulator (and thus ARM64EC) may diminish in the near future.&nbsp; And 
			without adequate Intel compatibility the Windows on ARM platform may 
			die.&nbsp; To believe that thousands of independent Windows 
			developers will all magically port their apps to native ARM64 is 
			foolish, and Windows RT and Windows Phone are prime example of 
			Microsoft failing to rally enough developers onto a new platform.&nbsp; 
			Not to mention the whole point of why I am writing these tutorials 
			is because I can plainly see that most Windows developers know 
			nothing about ARM64 or ARM64EC.&nbsp; So providing rock solid 
			reliable emulation is crucial, and must keep evolving hand-in-hand 
			with ARM64EC to support AVX and AVX2 as soon as possible.</span></p>
			<p><span face="Verdana" size="2">I'll discuss emulation in more 
			detail in a separate tutorial and the concept of <b>developing a 
			third-party x64 emulator to replace xtajit64</b>.</span></p>
			<p><span face="Verdana" size="2">There are some known <b>Visual 
			C/C++ compiler bugs</b> that I find surprising.&nbsp; The first is 
			that AVX/AVX2 calling convention and data types are not supported by the ARM64EC 
			compiler.&nbsp; For example if I try to compile this trivial line of 
			code with the -arm64EC switch:</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">D:\&gt; <b>type i256.c</b><p>
				
				#include &lt;windows.h&gt;<br>
				#include &lt;intrin.h&gt;<br>
				__m256i __vectorcall same(__m256i vector) { return vector; }</p><p>
				
				D:\&gt; <b>cl -Gv -O2 -c -FAsc -arm64EC i256.c</b><br>
				cl : Command line warning D9002 : ignoring unknown option '-Gv'<br>
				i256.c<br>
				D:\i256.c : error C7302: AVX types (__m256) are not currently 
				supported in ARM64EC code<br>
				D:\i256.c : error C7301: __vectorcall calling convention is not 
				currently supported<br>
				D:\i256.c : error C7302: AVX types (__m256) are not currently 
				supported in ARM64EC code</p></span></p>
			</blockquote>
			<p><span face="Verdana" size="2">Not only does the compiler not 
			understand the
			<a href="https://learn.microsoft.com/en-us/cpp/build/reference/gd-gr-gv-gz-calling-convention?view=msvc-170">
			-Gv</a> command line switch (which x86 and x64 do) but it <b>refuses 
			to compile</b> the code.&nbsp; Even if you ignore the -Gv warning 
			and try to define a custon __m256 data type, the compiled code would 
			not be able to interoperate since the default entry and exit thunks 
			would be bogus and marshalling would break.</span></p>
			<p><span face="Verdana" size="2">If I change the source to only use 
			__m128i but keep the
			<a href="https://learn.microsoft.com/en-us/cpp/cpp/vectorcall?view=msvc-170">
			__vectorcall</a> keyword, it crashes the compiler!</span></p>
			<blockquote>
				<p><span face="Verdana" size="2">D:\&gt; <b>type i128.c<br>
				</b><br>
				#include &lt;windows.h&gt;<br>
				#include &lt;intrin.h&gt;<p>
				
				__m128i __vectorcall same(__m128i vector)<br>
				{<br>
				return vector;<br>
				}</p><p>
				
				
				D:\&gt; <b>cl -Gv -O2 -c -FAsc -arm64EC i128.c<br>
				</b>Microsoft (R) C/C++ Optimizing Compiler Version 19.39.33321 
				for ARM64<br>
				Copyright (C) Microsoft Corporation. All rights reserved.</p><p>
				
				cl : Command line warning D9002 : ignoring unknown option '-Gv'<br>
				i128.c<br>
				D:\i128.c : error C7301: __vectorcall calling convention is not 
				currently supported<br>
				<b>D:\i128.c : fatal error C1001: Internal compiler error.<br>
				</b>(compiler file 'D:\a\_work\1\s\src\vctools\Compiler\Utc\src\p2\main.c', 
				line 235)<br>
				To work around this problem, try simplifying or changing the 
				program near the locations listed above.<br>
				If possible please provide a repro here: https://developercommunity.visualstudio.com<br>
				Please choose the Technical Support command on the Visual C++<br>
				Help menu, or open the Technical Support help file for more 
				information</p></span></p>
			</blockquote>
			<p><span face="Verdana" size="2">These three bugs have been a known 
			blockers for ARM64EC for years.&nbsp; I even formally filed the __vectorcall bug 
			a year ago after I'd left Microsoft so I could track the issue, and 
			it is still unfixed:</span></p>
			<p><span face="Verdana" size="2">
			<a href="https://developercommunity.visualstudio.com/t/VC-176-preview-1-x86-compiler-bad-cod/10291481">
			https://developercommunity.visualstudio.com/t/VC-176-preview-1-x86-compiler-bad-cod/10291481</a></span></p>
			<p><span face="Verdana" size="2">The __vectorcall keyword turns out 
			to be 
			problematic even with the Intel 32-bit x86 compiler (which in theory 
			supported this keyword since 2013) as per this bug I 
			filed a year ago which remains unfixed but looks like it may be getting a fix soon:</span></p>
			<p><span face="Verdana" size="2">
			<a href="https://developercommunity.visualstudio.com/t/VC-176-preview-1-x86-compiler-bad-cod/10291483">
			https://developercommunity.visualstudio.com/t/VC-176-preview-1-x86-compiler-bad-cod/10291483</a></span></p>
			<p><span face="Verdana" size="2">Microsoft should be much 
			more concerned that ARM64EC is not quite complete.&nbsp; Even though 
			it exited "experimental" mode starting with VS2022 17.4, until there 
			is parity with AVX2 the product is not complete.&nbsp; Agree?</span></p>
			<p><span face="Verdana" size="2">Thank you for sticking through a 
			rather technical tutorial.&nbsp; And if you missed the link at the beginning, 
			do watch Pedro's
			<a href="https://www.youtube.com/watch?v=HmI6ip4o9as">incremental porting</a> 
			tutorial and please let me know (or him) if you do try porting an 
			app and run into problems like the ones I described.</span></p>
			<hr>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TinySSH is a small SSH server using NaCl, TweetNaCl (287 pts)]]></title>
            <link>https://github.com/janmojzis/tinyssh</link>
            <guid>39806139</guid>
            <pubDate>Sun, 24 Mar 2024 10:04:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/janmojzis/tinyssh">https://github.com/janmojzis/tinyssh</a>, See on <a href="https://news.ycombinator.com/item?id=39806139">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h3 tabindex="-1" dir="auto">Introduction</h3><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<ul dir="auto">
<li>tinysshd is a minimalistic SSH server which implements only a subset of SSHv2 features.</li>
<li>tinysshd supports only secure cryptography (minimum 128-bit security, protected against cache-timing attacks)</li>
<li>tinysshd doesn't implement older crypto (such as RSA, DSA, HMAC-MD5, HMAC-SHA1, 3DES, RC4, ...)</li>
<li>tinysshd doesn't implement unsafe features (such as password or hostbased authentication)</li>
<li>tinysshd doesn't have features such: SSH1 protocol, compression, port forwarding, agent forwarding, X11 forwarding ...</li>
<li>tinysshd doesn't use dynamic memory allocation (no allocation failures, etc.)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Crypto primitives</h3><a id="user-content-crypto-primitives" aria-label="Permalink: Crypto primitives" href="#crypto-primitives"></a></p>
<ul dir="auto">
<li>State-of-the-art crypto: ssh-ed25519, curve25519-sha256, <a href="mailto:chacha20-poly1305@openssh.com">chacha20-poly1305@openssh.com</a></li>
<li>Older standard: <strike>ecdsa-sha2-nistp256, ecdh-sha2-nistp256, aes256-ctr, hmac-sha2-256</strike> removed in version 20190101</li>
<li>Postquantum crypto: <a href="mailto:sntrup761x25519-sha512@openssh.com">sntrup761x25519-sha512@openssh.com</a>, <a href="mailto:chacha20-poly1305@openssh.com">chacha20-poly1305@openssh.com</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Project timelime</h3><a id="user-content-project-timelime" aria-label="Permalink: Project timelime" href="#project-timelime"></a></p>
<ul dir="auto">
<li><strike>experimental: 2014.01.01 - 2014.12.31 (experimentation)</strike></li>
<li><strike>alpha(updated): 2015.01.01 - 2017.12.31 (not ready for production use, ready for testing)</strike></li>
<li>beta(updated): 2018.01.01 - ????.??.?? (ready for production use)</li>
<li>stable: expected ????.??.?? - (ready for production use - including post-quantum crypto)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Current release (20240101)</h3><a id="user-content-current-release-20240101" aria-label="Permalink: Current release (20240101)" href="#current-release-20240101"></a></p>
<ul dir="auto">
<li>has 63899 words of code</li>
<li>beta release</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How-to run</h3><a id="user-content-how-to-run" aria-label="Permalink: How-to run" href="#how-to-run"></a></p>
<div data-snippet-clipboard-copy-content="       TCPSERVER
              tcpserver -HRDl0 0.0.0.0 22 /usr/sbin/tinysshd -v /etc/tinyssh/sshkeydir &amp;

       BUSYBOX
              busybox tcpsvd 0 22 tinysshd -v /etc/tinyssh/sshkeydir &amp;

       INETD
           /etc/inetd.conf:
               ssh stream tcp nowait root /usr/sbin/tinysshd tinysshd -l -v /etc/tinyssh/sshkeydir

       SYSTEMD
           tinysshd.socket:
               [Unit]
               Description=TinySSH server socket
               ConditionPathExists=!/etc/tinyssh/disable_tinysshd

               [Socket]
               ListenStream=22
               Accept=yes

               [Install]
               WantedBy=sockets.target

           tinysshd@.service:
               [Unit]
               Description=Tiny SSH server
               After=network.target auditd.service

               [Service]
               ExecStartPre=-/usr/sbin/tinysshd-makekey -q /etc/tinyssh/sshkeydir
               EnvironmentFile=-/etc/default/tinysshd
               ExecStart=/usr/sbin/tinysshd ${TINYSSHDOPTS} -- /etc/tinyssh/sshkeydir
               KillMode=process
               SuccessExitStatus=111
               StandardInput=socket
               StandardError=journal

               [Install]
               WantedBy=multi-user.target"><pre><code>       TCPSERVER
              tcpserver -HRDl0 0.0.0.0 22 /usr/sbin/tinysshd -v /etc/tinyssh/sshkeydir &amp;

       BUSYBOX
              busybox tcpsvd 0 22 tinysshd -v /etc/tinyssh/sshkeydir &amp;

       INETD
           /etc/inetd.conf:
               ssh stream tcp nowait root /usr/sbin/tinysshd tinysshd -l -v /etc/tinyssh/sshkeydir

       SYSTEMD
           tinysshd.socket:
               [Unit]
               Description=TinySSH server socket
               ConditionPathExists=!/etc/tinyssh/disable_tinysshd

               [Socket]
               ListenStream=22
               Accept=yes

               [Install]
               WantedBy=sockets.target

           tinysshd@.service:
               [Unit]
               Description=Tiny SSH server
               After=network.target auditd.service

               [Service]
               ExecStartPre=-/usr/sbin/tinysshd-makekey -q /etc/tinyssh/sshkeydir
               EnvironmentFile=-/etc/default/tinysshd
               ExecStart=/usr/sbin/tinysshd ${TINYSSHDOPTS} -- /etc/tinyssh/sshkeydir
               KillMode=process
               SuccessExitStatus=111
               StandardInput=socket
               StandardError=journal

               [Install]
               WantedBy=multi-user.target
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lezer: A parsing system for CodeMirror, inspired by Tree-sitter (130 pts)]]></title>
            <link>https://marijnhaverbeke.nl/blog/lezer.html</link>
            <guid>39805591</guid>
            <pubDate>Sun, 24 Mar 2024 07:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marijnhaverbeke.nl/blog/lezer.html">https://marijnhaverbeke.nl/blog/lezer.html</a>, See on <a href="https://news.ycombinator.com/item?id=39805591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="full">
  
  <p>I keep coming across people who consider parser technology a
forbidding, scary field of programming. This is nonsense—a small
parser can be <a href="http://eloquentjavascript.net/12_language.html#h_cpTTNxAWkQ">very, very
simple</a>,
and provide a wholesome exercise in recursive thinking. At the same
time, it is true that you <em>can</em> make parsing extremely complicated.
Mostly, this tends to happen when you generalize parsing techniques to
work for different grammars. Since compiler textbooks usually describe
general approaches to parsing, they may be to blame for putting people
off.</p>
<p>This post describes a <a href="https://lezer.codemirror.net/">new parsing
system</a> I wrote for
<a href="https://codemirror.net/">CodeMirror</a>, a source code editor. It frames
the system with some history, and digresses into some neat
architectural details.</p>
<p>Editor features like syntax highlighting, bracket matching, code
folding, and autocompletion all involve some level of parsing.
Unfortunately, since editors have to handle many different languages,
they require a generalized approach to parsing.</p>
<p>CodeMirror is in the process of being rewritten, and I wanted to
improve the way it parses its content. Parsing inside of an editor
comes with its own unique set of constraints, which can be hard to
satisfy. Though I had been planning new approaches for years, all I
had to show for it so far were a pile of dead ends.</p>
<p>The constraints that make the parsing problem in a code editor hard
are roughly these:</p>
<ul>
<li>
<p>The document is constantly changing.</p>
</li>
<li>
<p>You can't do anything expensive. If the parsing works takes too
long, it'll introduce latency that makes editing feel
<a href="https://input-delay.glitch.me/">slugglish</a> and unresponsive.</p>
</li>
<li>
<p>The input is often not in a finished, syntactically correct form.
But you still have to make some sense of it—nobody wants an editor
where most features stop working when you have a syntax error in
your document.</p>
</li>
<li>
<p>You often want to be able to mix several languages/grammars in a
single document (think HTML with JavaScript and CSS embedded in
it).</p>
</li>
</ul>
<p>Keeping those in mind, let's go over the approaches I've tried.</p>
<h2 id="a-brief-history-of-codemirror-parsing">A Brief History of CodeMirror Parsing</h2>
<p>The system in as it exists in CodeMirror 5 now (which is pretty
much what we've been using from the very beginning) is a <a href="http://marijnhaverbeke.nl/blog/codemirror-mode-system.html">simple
one</a>. For
each language, you write a tokenizer which splits the input into
pieces, and labels each piece with some syntactic category (such as
<code>variable</code>, <code>keyword</code>, or <code>number</code>). The tokenizers can be stateful,
which allows them to secretly be full parsers if they want to.</p>
<p>This state must by copyable, so that the editor can strategically
store tokenizer states from a previous run, and after a change, resume
one close to that change to avoid re-tokenizing the entire document.
Because we are usually only interested in the code in the visible
viewport, this means the complexity of re-tokenizing is bounded by the
distance between the change and the end of the viewport. Since most
changes happen inside of that viewport, this works well in practice.</p>
<hr>
<p>Such tokenizers are awkward to write directly, so over the years
several attempts have been made to build abstractions over them. The
first was the <a href="https://github.com/mozilla/skywriter/wiki/Common-JavaScript-Syntax-Highlighting-Specification">Common JavaScript Syntax Highlighting
Specification</a>,
an attempt by the authors of Mozilla Skywriter (formerly Bespin, later
merged into <a href="https://ace.c9.io/">ACE</a>) to define a declarative format
for describing tokenizers as state machines with regular expressions
(describing the tokens) as edges. The ACE project ended up with an
incompatible but similar format (too entangled with their internals to
use in CodeMirror, unfortunately). I did an implementation of the
original spec for CodeMirror, and then another incompatible
<a href="http://cm/demo/simplemode.html">extension</a> because the base spec was
too limiting. There are a few CodeMirror modes still based on that
code, but it was no real success.</p>
<p>I think the reason such state machines (and the somewhat related
<a href="https://macromates.com/manual/en/language_grammars">TextMate
grammars</a> which
are in wide use in desktop editors) never felt like a great solution
is that, once you get past trivial grammars (where their declarative
simplicity does look really nice), they don't really help that much
with abstraction. Manually designing complicated state machines is a
chore. Regular expressions, which are bad enough on their own, become
downright
<a href="https://github.com/jeff-hykin/cpp-textmate-grammar/blob/e7b680238e59a87231322159749d74351c9d774a/syntaxes/cpp.tmLanguage.yaml#L264">terrifying</a>
when you have to construct all your edges out of them, often stuffing
multiple tokens into a single expression to avoid creating
intermediate states. This “abstraction” has a tendency to produce
uglier, less maintainable code than what you'd get when writing the
tokenizer as plain code.</p>
<hr>
<p>So in 2017, I started an ambitious project to create a better way to
abstractly define incremental tokenizers. I had concluded that
classical parser generators based on context-free grammars were never
going to work in this context (for reasons that I'll come back to
later on). But I kept coming across <a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing expression
grammars</a>,
which weren't based on context-free grammars and had some interesting
properties, such as being able to combine multiple grammars to create
a new grammar (which is great for mixed-language documents).</p>
<p>So I spent several months building a parsing system that took a
PEG-like grammar, compiled it down to a state machine, and made it
possible to run that state machine as a CodeMirror language mode.</p>
<p>This <a href="https://github.com/codemirror/grammar-mode">system</a> is a marvel.
It uses a moderately sophisticated <a href="https://www.youtube.com/watch?v=1qIee0aHOhY">optimizing
compiler</a> to generate the
state machines. The result works quite well, and is used in several
real-world systems today. But unfortunately, if I'm honest, it is a
tragically bad idea taken way too far.</p>
<p>Parsing expression grammars are parsed by backtracking. And as such,
they are very poorly suited for implementing a stateful tokenizer. In
a backtracking system, you never know when you've <em>definitely</em> parsed
a piece of content—later input might require you to backtrack again.
So what I ended up with was actually not PEG at all, but a system
where you had to explicitly annotate where the parser should look
ahead. Though grammars written this way were relatively readable, they
involved a lot of finicky, error-prone kludges to resolve local
ambiguity.</p>
<p>Also, parsing PEG is just really inefficient. Such grammars are
“scannerless” meaning they don't make a distinction between tokenizing
and parsing. When parsing in that way naively, you basically have to
run your whole parsing logic for every input character. Probably
multiple times, due to backtracking. A lot of the magic in the
compiler was intended to recover the tokens that were implicit in the
grammar, in order to recover some efficiency. But the system never
came close to hand-written language modes in terms of speed.</p>
<h2 id="tree-sitter">Tree-sitter</h2>
<p>So, though I knew I needed a new approach, I went into the CodeMirror
6 rewrite without any specific idea on what that approach would look
like.</p>
<p>And then I saw
<a href="http://tree-sitter.github.io/tree-sitter/">tree-sitter</a>, and was
enlightened.</p>
<p>Tree-sitter is a parser system written with the code editor use case
in mind, and is in the process of being integrated into the <a href="https://atom.io/">Atom
editor</a>. It takes a much more ambitious approach to
what a parser inside an editor should do: It builds up a full,
accurate syntax tree for the content.</p>
<p>You can do so much more with an actual syntax tree than with a
sequence of tokens. Whereas tokens, possibly augmented with some
information stored in the tokenizer state, allow you to sort of
approximate understanding some aspects of the code's structure, a tree
usually gives you precisely the information you need.</p>
<p>Most of the ideas that tree-sitter uses aren't new, in fact a
<a href="https://www.researchgate.net/profile/SL_Graham/publication/2377179_Efficient_and_Flexible_Incremental_Parsing/links/004635294e13f23ef1000000/Efficient-and-Flexible-Incremental-Parsing.pdf">paper</a> from 2000
describes a somewhat similar system. But as far as I know, tree-sitter
is the first system that puts them all together into a practical piece
of software.</p>
<p>Unfortunately, tree-sitter is written in C, which is still awkward to
run in the browser (and CodeMirrror targets non-WASM browsers). It
also generates very hefty grammar files because it makes the
size/speed trade-off in a different way than a web system would.</p>
<p>But good ideas can be ported. <a href="https://lezer.codemirror.net/">Lezer</a> is
a JavaScript-based system heavily inspired by tree-sitter.</p>
<h2 id="lr-parsing-and-context-free-grammars">LR Parsing and Context-Free Grammars</h2>
<p>For a long time, I was firmly convinced that classical parser system
based on context-free grammars and
<a href="https://en.wikipedia.org/wiki/LL_parser">LL</a> or
<a href="https://en.wikipedia.org/wiki/LR_parser">LR</a> parsing algorithms were
just not suitable for the editor use case. My arguments for this
were...</p>
<p><em>Context-free grammars are a limiting abstraction that breaks down as
soon as the language does anything funky. Needing the grammar to be LR
or LL to please the parser generator further pins you into a corner.</em></p>
<p>This is not wrong. Expressing operator precedence in a pure
context-free grammar requires writing a silly formulaic rule for each
level of precedence. And when you need to implement something like
automatic semicolon insertion or whitespace-sensitivity, which would
be a couple of lines of code in a hand-written grammar, you can't
express that directly, and have to somehow escape the context-free
abstraction.</p>
<p>Making such a grammar suitable for an LR parser generator can be even
more tricky, and often requires you to have a rather deep
understanding of how the parser generator works.</p>
<p>But like many things, once you get to know them, they aren't that bad.
Parser generators can support precedence declarations, which make
operator parsing a lot less terrible. They can even output decent
error messages.</p>
<p>Supporting dynamic resolution of ambiguities through something like
<a href="https://en.wikipedia.org/wiki/GLR_parser">GLR parsing</a> can provide a
practical way out of situations that parser generators are
traditionally bad at.</p>
<p>And contrary to some of the abstractions I mentioned before, this one
actually gets us something. Context-free grammars, when combined with
a proper parser generator, really do give us fast parsers from
readable, compact grammar declarations.</p>
<p><em>A strict separation between the tokenizer and parser is
problematic.</em></p>
<p>It is, in many languages (think of JavaScript's ambiguity between
regular expressions and the division operator). It also tends to make
mixed-language parsing harder.</p>
<p>But just because this type of parser is traditionally ran with a
completely separate tokenizer doesn't mean it has to be. Having the
parse state drive the tokenizer is largely unproblematic. You can even
have the parser generator set this up
<a href="#contextual-tokens">automatically</a>, without user involvement.</p>
<p><em>Generated parsers are way too big.</em></p>
<p>A naively generated LR parser is <em>huge</em>, and many tools spit out
embarrassingly big files. But with careful parser state deduplication
and table compression such a parser can be made about as compact as a
hand-written one.</p>
<p><em>Making such a parser error-tolerant is extremely cumbersome.</em></p>
<p>If you search the scholarly literature for approaches to
error-tolerance in LR parser systems, you get a lot of results, with a
lot of different approaches, but none of them are very practical. Most
require the grammar writer to explicitly annotate the grammar with
error-recovery strategies, bloating the grammar and putting the
responsibility for getting it right on every grammar author.</p>
<p>Tree-sitter ingeniously abuses <a href="https://en.wikipedia.org/wiki/GLR_parser">GLR
parsing</a>, where the parser
can try multiple interpretations simultaneously, to integrate
automatic error-correction without a lot of extra complexity. Lezer
copies <a href="#error-recovery">this approach</a>.</p>
<h2 id="lezer">Lezer</h2>
<p>I called my tree-sitter copycat project
<a href="https://lezer.codemirror.net/">Lezer</a>, which is the Dutch word for
<em>reader</em> (and pronounced a lot like <em>laser</em>). It is a bit less
advanced than tree-sitter in some areas, a bit more advanced in
others, and simply different on quite a lot of points, as determined
by a different set of priorities and tastes.</p>
<p>CodeMirror 6 will retain the ability to run a classical stateful
tokenizer, but its recommended way to define a language mode is to
write a Lezer grammar and wrap it in a CodeMirror-specific packages
that adds some editor-related metadata.</p>
<p>Lezer is an <a href="https://en.wikipedia.org/wiki/LR_parser">LR</a> (with opt-in
<a href="https://en.wikipedia.org/wiki/GLR_parser">GLR</a>) parser generator. It
has support for incremental parsing, where you can cheaply re-parse a
document after local changes have been made to it by reusing pieces
of the old parse tree. It automatically tries to recover and continue
parsing when it runs into a syntax error, leaving markers in the
output tree that indicate where the recovery happened.</p>
<p>Lezer consists of an off-line parser generator tool, which takes a
grammar description and outputs a JavaScript module containing a
parser for that grammar, and a parser run-time system (which such
output files depend on) to do the actual parsing. Only the run-time
system and the generated parser need to be loaded by the editor.</p>
<p>The parser outputs non-abstract syntax trees, meaning that it just
creates a raw tree structure containing the constructs it parsed (with
information on where it found them), without organizing them into a
clean, easy-to-use data structure.</p>
<p>The system is optimized for compactness, both in parser table size and
syntax tree size. It needs to be practical to ship a bunch of parsers
to a user on the web without producing megabytes of network traffic,
and it needs to be realistic to keep syntax trees for large documents
around without running out of memory.</p>
<p>The <a href="https://lezer.codemirror.net/docs/guide/">Lezer guide</a> provides a
more thorough introduction, as well as a description of its grammar
notation. In this blog post, I want to go into the neat implementation
details that aren't relevant in user documentation.</p>
<h2 id="error-recovery">Error Recovery</h2>
<p>The point where I became convinced that I definitely needed to use or
copy tree-sitter was when I understood its error recovery strategy.</p>
<p>Say you reach a point where you can no longer proceed normally because
there is a syntax error. The rest of the input, after the error, is
probably full of meaningful constructs that could still be parsed. We
want those constructs in our syntax tree. But our regular parsing
process is stuck—it doesn't know how to get from the error to a state
where the parse can continue.</p>
<p>I definitely did not want to require the grammar author to add error
recovery hints to their grammar. These tend to clutter up the grammar
and are error-prone to write. Writing a grammar is hard enough
without that distraction.</p>
<p>You can see error recovery as a search problem. There might be a parse
state and input position (past the error) where the parse can
meaningfully continue. We just have to find it.</p>
<p>The actions encoded in the parse tables, along with some
recovery-specific actions that the parser wouldn't normally take,
provide a kind of search tree. You start at the state(s) where the
error occurred, and keep exploring new states from there.</p>
<p>But what does the accept condition look like? When do you know that
you've found an acceptable solution? You could define that precisely,
for example as the state that can handle the next N tokens without
further errors. But we can also be vague.</p>
<p>The solution found by <a href="https://github.com/maxbrunsfeld">Max Brunsfeld</a>
in tree-sitter is to use the same mechanism that's used to parse
ambiguous grammars. A GLR parser can split its parse stack and run
both sides alongside each other for a while until it becomes clear
which one works out.</p>
<p>That's pretty much exactly what a search algorithm does—it tracks a
number of branches that it still has to explore, and continues to
explore them, possibly pruning unpromising branches with some
heuristic, until it finds a solution.</p>
<p>To be able to get good results, or at least <em>some</em> result, in messy
situations like longer stretches of invalid input, each branch has a
badness score associated with it, which is increased (linearly) each
time a recovery action is taken, and decreased (asymptotically) every
time it can consume a token normally.</p>
<p>What we want to do is, after an error, try all kinds of possible
recovery tricks, which recursively branch off a large amount of states.
But then, after a bit of that, we should consolidate to one or, at
most, a few parse states again, because parsing input in a whole bunch
of different ways is expensive.</p>
<p>To get this effect, Lezer forbids states with a badness higher than a
given multiple of the best state's badness (or some maximum threshold)
from applying further recovery actions, effectively dropping those
branches when they can't proceed normally. In the case where one
branch finds a good way to continue, that branch's badness will
converge to zero and eventually stop all worse branches. In cases
where the input continues to make no sense, all branches will
eventually get a badness score exceeding the maximum, and the parser
will only continue one of them.</p>
<p>The recovery strategies used are:</p>
<ul>
<li>
<p>Skip the next token, and try again with the same state after that.</p>
</li>
<li>
<p>Invent a token—take any of the tokens that are valid in this state,
and continue to the state that consuming them would produce. This
is the main source of branching, since many states allow a lot of
tokens.</p>
</li>
<li>
<p>Force the end of the innermost production that's currently being
parsed.</p>
</li>
</ul>
<p>There are situations where the result of this approach isn't entirely
optimal, but it usually does well. The important thing is that it
always keeps parsing, and does so in a way that remains tractable
(exponential searches are quickly dampened). The system is biased a
bit towards the token-skipping rule, so that if all else fails it'll,
in effect, just continue skipping tokens until it stumbles into a
situation where it can continue parsing.</p>
<h2 id="post-order-parser-output">Post-Order Parser Output</h2>
<p>When you have a parser that may be splitting its state—a lot—and build
up parts of the tree multiple times, that duplicate tree building and
the bookkeeping involved in it can cause a lot of unnecessary work.</p>
<p>The order in which an LR parser creates nodes is inner-to-outer. It
will, for example, first create the node for the operands, and then
later the node for the operator expression. This suggests an approach:
What if, instead of building a tree structure right away, the parser
just keeps a flat log of the nodes it created. This can be an array in
which the nodes are arranged in <a href="https://en.wikipedia.org/wiki/Tree_traversal#Post-order_(LRN)">post-order</a>, with children
coming before parents.</p>
<p>The parser just appends to this array. When splitting the state, one
state keeps the existing array, and the other gets a new empty array
along with a pointer to the state that has the rest of the array, and
the length of that array at the time of the split.</p>
<p>Now splitting involves no node copying at all. You do need to copy the
state stack, which LR parser use to track context, but that is
generally shallow.</p>
<p>In addition, node allocation becomes as cheap as appending a few
numbers to an array. For actions that don't result in tree nodes
(Lezer allows you to mark rules as uninteresting, to keep the tree
small), you don't have to do anything at all. The control stacks
stores the output array position at the start of each rule, and can
use that to emit enough data to later reconstruct parent-child
relationships.</p>
<p>After a parse finishes successfully, the final state's parent-array
pointers can be used to find all the nodes that make up the tree, and
construct an actual tree structure out of them.</p>
<p>One tricky issue occurs when skipped content (whitespace and comments)
produces nodes. If you have code like this...</p>
<pre><code>if (true) something()
// Comment
otherStatement()
</code></pre>
<p>... the comment should <em>not</em> be part of the if statement's node. Yet
the parser only knows for sure that it can finish that node after
seeing the next statement (there might be an <code>else</code> still coming).</p>
<p>In cases like this, where the output array contains skipped nodes
immediately in front of a reduction, the parser has to move them
forward and store the end of the node <em>before</em> them. Fortunately, this
occurs relatively rarely (unless you add nodes for whitespace, in
which case it'll happen at the end of every rule that has a possible
continuation).</p>
<h2 id="buffer-trees">Buffer Trees</h2>
<p>A nice thing about the flat post-order tree representation is that it
is compact. Tree structures constructed the usual way, as separately
allocated nodes, incur a lot of extra overhead for pointers and
allocation headers. They can also have terrible locality, since who
knows how far from each other the memory allocator will put the nodes.</p>
<p>Unfortunately, we can't just use a flat representation for our syntax
trees. The incremental parser has to be able to reuse parts of it
without copying those parts into a different buffer.</p>
<p>But we <em>can</em> use it for parts of the tree. Storing the coarse
structure as a classical tree, but the content of smaller nodes (say
less than a few thousand characters long) as flat arrays, gives us the
best of both worlds. Since most nodes, by number, live in the fine
structure, this saves a large amount of overhead (and helps with
locality).</p>
<p>That does mean that we can't reuse small nodes. But since their size
is limited, the amount of work that is involved in re-parsing them is
also limited. And by removing them from consideration, the incremental
parser can avoid quite a bit of the work involved in preparing and
scanning the tree for reuse.</p>
<p>A small node stores its content in a typed array of 16-bit unsigned
integers. It uses 4 such numbers (64 bits) per node, storing a type, a
start position, an end position, and a child count for each node.
Contrary to the array created by the parser, these arrays are in
<a href="https://en.wikipedia.org/wiki/Tree_traversal#Pre-order_(NLR)">pre-order</a>,
because that makes forward iteration (which tends to be more common
than backward iteration) cheaper. The child count was almost obsolete
(the end position can sort of tell you which nodes are children), but
Lezer supports zero-length nodes, which might land on the end of their
parent node and make it ambiguous whether they belong to it or not.</p>
<p>Client code, of course, doesn't want to deal with this representation.
Lezer provides an abstract interface to searching in and walking
through trees that hides the buffer structure, allowing you to
conceptually work with a uniform tree of nodes.</p>
<p>Lezer, like tree-sitter, stores the result of repetitions in the
grammar (produced by the <code>*</code> and <code>+</code> operators) as balanced subtrees.
This means that, unless your input is pathological (say, a thousand
applications of a single binary operator in a row), you tend to get
shallow, well-balanced syntax trees, which are cheap to search and
allow effective reuse.</p>
<h2 id="contextual-tokens">Contextual Tokens</h2>
<p>Depending on the grammar's complexity, an LR parser generator creates
between a dozen and a few thousand parse states for your grammar.
These represent syntactic positions like “after the opening paren of
an argument list” or “after an expression, possibly expecting some
expression suffix”.</p>
<p>The parser generator can figure out which tokens are valid in a given
state. It can also, for tokens specified as part of the grammar,
automatically determine which tokens conflict (match the same input,
or some prefix of each other).</p>
<p>A well-known example of conflicting tokens is the division operator
versus regular expression syntax in JavaScript. But others are
keywords that can also appear as property names, and the bitwise right
shift operator (<code>&gt;&gt;</code>) versus two closing angle brackets in C++.</p>
<p>Lezer will not complain about overlapping tokens if the tokens do not
appear in the same parse states. This implicitly resolves the regular
expression and property name issues, without any user interaction.</p>
<p>When conflicting tokens do appear in the same place, such as division
operators and C-style comments, you have to specify an explicit
precedence ordering (comments take precedence) to tell the tool that
you know what you're doing.</p>
<p>Contextual tokenization is implemented with a concept called token
groups. Tokens that have unresolved conflicts with other tokens are
assigned to one or more groups, where each group contains only
non-conflicting tokens. Each state is assigned a single group (if it
expects tokens that conflict with each other that's an error). This
group is passed to the tokenizer, which then takes care to only return
tokens that are either in that group, or don't conflict with any other
tokens. The check is optimized by storing group membership in a
bitset, and seeing if the right bit is set with binary <em>and</em>.</p>
<p>Tokens are compiled down to a single deterministic state machine,
which is ran on the input character stream. In cases like the
regexp-versus-division issue, you don't want the machine to go running
through regexp-specific states in a situation where you only allow
division, since that would be wasteful. Therefore, each tokenizer
state is also tagged with a bitset that tells you which groups the
tokens reachable from that state belong to, and the tokenizer stops
running when it hits a state that has no overlap with the allowed
tokens for the parse state.</p>
<h2 id="skip-expressions">Skip Expressions</h2>
<p>Almost all programming languages have special syntactic elements like
whitespace and comments that may occur between any tokens. Encoding
these directly in the grammar is extremely tedious for most languages.</p>
<p>Traditionally, tokenizer just skip such elements when reading the next
token. That works well in most contexts, but makes it awkward to
include the elements in the parse tree.</p>
<p>Lezer treats skipped things like they are part of the grammar (though
in an optimized way to avoid increasing the size of the parse tables).
It is possible to skip things that aren't single tokens (to implement
something like nestable comments, for example, or to make sure your
block comment nodes consist of smaller nodes so that you can
incrementally parse giant block comments).</p>
<p>Each rule or group of rules may have its own set of skipped
expressions, so that you can express different sublanguages in a
grammar, for example something like the content of interpolated
strings, without allowing spacing in places where the language doesn't
allow it.</p>
<p>Each parse state has a pointer to a (shared) set of skip actions,
which, for the skipped tokens or tokens that start a compound skipped
expression, contains the actions to take for those tokens. For
single-token skipped elements, that action just tells the parser to
skip the token and stay in the same state. For compound elements, it
causes the state that handles the rest of the element to be pushed
onto the control stack.</p>
<h2 id="tree-node-tagging">Tree Node Tagging</h2>
<p>The languages that a tool like Lezer needs to handle are wildly
different, from JavaScript to Haskell to CSS to YAML. As such, it is
difficult to find a cross-language vocabulary to describe their
constructs. In fact, it seems like that would be a separate multi-year
project, and pull in a serious amount of complexity.</p>
<p>Yet it would be nice if the parser output comes with some information
that can be interpreted without knowing what language you are working
with.</p>
<p>After several iterations, what I decided on was a system where nodes
have <em>names</em>, which only have a meaning within the language, and
<em>props</em>, which are values associated with tags defined by external
code. Integrating a language grammar into CodeMirror involves
assigning values for some of these props to the node types used by the
language—things like syntax highlighting style information and how to
<a href="https://marijnhaverbeke.nl/blog/indent-from-tree.html">indent</a> such nodes.</p>
<p>Since the number of node types in a language is limited, we can
allocate an object for each node type to hold this information, and
have all nodes of that type point to the same object.</p>
<p>To allow code outside the grammar to add props without mutating global
state, parser instances can be extended with additional props,
creating a copy that will output nodes with the props attached. This
is especially useful in the context of mixed-language trees.</p>
<p>Lezer has support for a limited form of grammar nesting. If language A
can appear inside a document in language B, and the end of the region
covered by A can be unambiguously found by scanning for a specific
token, Lezer can temporarily switch to another set of parse tables
while parsing such a region.</p>
<p>The syntax tree will then contain nodes from both grammars. Having
props directly attached to the nodes makes it much easier to work with
such trees (as opposed to using a language-specific table that
associates node names with metadata).</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>