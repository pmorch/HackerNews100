<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 17 Aug 2024 09:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[ThreadPlotter â€“ toolkit for punch needle embroidery with X-Y plotters (2020) (103 pts)]]></title>
            <link>https://github.com/LiciaHe/threadPlotter</link>
            <guid>41270596</guid>
            <pubDate>Fri, 16 Aug 2024 21:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/LiciaHe/threadPlotter">https://github.com/LiciaHe/threadPlotter</a>, See on <a href="https://news.ycombinator.com/item?id=41270596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ThreadPlotter</h2><a id="user-content-threadplotter" aria-label="Permalink: ThreadPlotter" href="#threadplotter"></a></p>
<p dir="auto">A toolkit for the design and fabrication of delicate punch needle embroidery using X-Y plotters_</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What?</h2><a id="user-content-what" aria-label="Permalink: What?" href="#what"></a></p>
<p dir="auto">ThreadPlotter is a toolkit that supports the designing, editing, and printing of images as punch needle embroidery using an X-Y plotter. It is a supplementary material for the paper:</p>
<p dir="auto"><a href="http://www.cond.org/punchneedle.html" rel="nofollow">"Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters"
Shiqing He, Eytan Adar, to appear, DIS'20, Honorable Mention Award</a></p>
<p dir="auto">The following video briefly introduces the motivation for building this tool and the capability of the ThreadPlotter.</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=zMfiQarMp-8" rel="nofollow"><img src="https://github.com/LiciaHe/threadPlotter/raw/master/assets/youtube-preview.png" alt="youtube-preview"></a></p>
<p dir="auto">You might also be interested in this 10 minutes presentation that goes over the project in depth.</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=jvuNcWv8kGo" rel="nofollow"><img src="https://github.com/LiciaHe/threadPlotter/raw/master/assets/youtube-presentation.png" alt="youtube-presentation"></a></p>
<p dir="auto">If you are interested in using this toolkit, please consider citing our paper:<a href="http://www.cond.org/punchneedle.html" rel="nofollow">Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How?</h2><a id="user-content-how" aria-label="Permalink: How?" href="#how"></a></p>
<p dir="auto">To convert your X-Y plotter into a punch needle fabricator, we will follow the following steps:</p>
<ol dir="auto">
<li>Ensure that your plotter is suitable for the task. (<a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step1_plotterCheck.md">tutorial 1</a>)</li>
<li>Acquire or create several physical components such as needle, fabric, and frame. (<a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step2_physicalSetup.md">tutorial 2</a>)</li>
<li>Design a punch needle pattern.
<ol dir="auto">
<li><a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step3_patternMaking.md">tutorial 3: pattern making overview</a></li>
<li><a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step4_advancedExamples.md">tutorial 4: advanced examples</a> #in progress</li>
</ol>
</li>
</ol>
<p dir="auto">We highly recommend that you review our paper before getting started. When you are ready, click on each of the links above.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Show us! Tell us! Ask us! Credit us!</h2><a id="user-content-show-us-tell-us-ask-us-credit-us" aria-label="Permalink: Show us! Tell us! Ask us! Credit us!" href="#show-us-tell-us-ask-us-credit-us"></a></p>
<p dir="auto">We are excited to see what you can create with this fabrication technique. The toolkit is developed and tested by Licia (on her plotter called "Kitty"). If you have questions about the toolkit, feel free to open up an issue in our <a href="https://github.com/LiciaHe/threadPlotter">github page</a>.</p>
<p dir="auto">If you created something and want to share it with us, please use the tag <a href="https://www.instagram.com/explore/tags/plotterembroidery/?hl=en" rel="nofollow">#plotterembroidery</a> on SNS.</p>
<div data-snippet-clipboard-copy-content="@inproceedings{10.1145/3357236.3395540,
author = {He, Shiqing and Adar, Eytan},
title = {Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters},
year = {2020},
isbn = {9781450369749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357236.3395540},
doi = {10.1145/3357236.3395540},
booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
pages = {1047â€“1057},
numpages = {11},
keywords = {plotter, craft fabrication, embroidery fabrication, punch needle embroidery, craft design, x-y plotter, fiber art},
location = {Eindhoven, Netherlands},
series = {DIS â€™20}
}
  
"><pre><code>@inproceedings{10.1145/3357236.3395540,
author = {He, Shiqing and Adar, Eytan},
title = {Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters},
year = {2020},
isbn = {9781450369749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357236.3395540},
doi = {10.1145/3357236.3395540},
booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
pages = {1047â€“1057},
numpages = {11},
keywords = {plotter, craft fabrication, embroidery fabrication, punch needle embroidery, craft design, x-y plotter, fiber art},
location = {Eindhoven, Netherlands},
series = {DIS â€™20}
}
  

</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License</p>
<p dir="auto">Copyright (c) [2020] [Shiqing He]</p>
<p dir="auto">Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p dir="auto">The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p dir="auto">THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM and Bug Finding: Insights from a $2M Winning Team in the White House's AIxCC (118 pts)]]></title>
            <link>https://team-atlanta.github.io/blog/post-atl/</link>
            <guid>41269791</guid>
            <pubDate>Fri, 16 Aug 2024 19:56:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://team-atlanta.github.io/blog/post-atl/">https://team-atlanta.github.io/blog/post-atl/</a>, See on <a href="https://news.ycombinator.com/item?id=41269791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Hello, world! We are <em>Team Atlanta</em>, the minds behind Atlantis, our innovative
AI-driven cybersecurity solution competing in the prestigious
<a href="https://aicyberchallenge.com/" target="_blank">DARPA AIxCC</a>
.</p><p><a href="https://team-atlanta.github.io/authors/">Our team</a>
is a collaborative powerhouse made up of six leading institutions:
<a href="https://www.gatech.edu/" target="_blank">Georgia Tech</a>
,
<a href="https://www.gtri.gatech.edu/" target="_blank">GTRI</a>
,
<a href="https://research.samsung.com/" target="_blank">Samsung Research</a>
,
<a href="https://sra.samsung.com/" target="_blank">Samsung Research America</a>
,
<a href="https://www.kaist.ac.kr/en/" target="_blank">KAIST</a>
, and
<a href="https://www.postech.ac.kr/" target="_blank">POSTECH</a>
.
Each of these organizations is led by Georgia Tech alumni,
and includes past winners of prestigious hacking competitions
such as DEF CON CTF, Pwn2Own and kernelCTF.</p><p>For the past several months, we have been diligently preparing for this competition,
combining our expertise in AI, cybersecurity,
and software engineering.
Last week, we proudly competed in the AIxCC Semifinals,
showcasing our hard work and dedication
to advancing cybersecurity through artificial intelligence.</p><h2 id="the-journey-begins">The Journey Begins</h2><p>When AIxCC was announced <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/08/09/biden-harris-administration-launches-artificial-intelligence-cyber-challenge-to-protect-americas-critical-software/" target="_blank">last year</a>
,
we quickly assembled a team of friends,
including <a href="https://www.zellic.io/" target="_blank">Zellic</a>
and <a href="https://gts3.org/" target="_blank">SSLab</a>
.
At that time,
much was uncertain;
details about the game format,
scoring rubric,
proof-of-vulnerability (PoV),
sanitizers, harnesses, supported programming languages,
and proof-of-understanding (PoU) were all unclear.
Our team, however, started preparing for the competition from last October.</p><p>Many of our team members previously participated in the
<a href="https://www.darpa.mil/program/cyber-grand-challenge" target="_blank">DARPA Cyber Grand Challenge (CGC)</a>
as part of <a href="https://en.wikipedia.org/wiki/2016_Cyber_Grand_Challenge" target="_blank">Crspy</a>
,
where we were responsible for bug finding and exploitation generation.
DARPA CGC was an ambitious endeavor
that sparked numerous innovative research directions afterward.
However, the competition was not without its challenges,
particularly due to the <em>gamification</em> of the event;
the scoring metrics and rules significantly influenced <a href="https://free.eol.cn/edu_net/edudown/spkt/zhangchao.pdf#page=34" target="_blank">the outcomes</a>
.
In the end, the competing Cyber Reasoning Systems (CRS) that focused on operating reactivelyâ€“prioritizing the availability score over fixing bugsâ€“
tended to score higher, as exploitation proved to be far more difficult than patching.</p><p>Aware of <a href="https://aicyberchallenge.com/rules/" target="_blank">the gamification issues</a>
from CGC,
we anticipated that to excel in AIxCC
our CRS should leverage AI, particularly LLMs, aggressively in various depths and levels
of the CRS pipelines.
With this in mind, we strategically chose to focus our efforts on two key directions:</p><ol><li><p><strong>Static Analysis.</strong> To encourage the use of LLMs and set AIxCC apart from CGC,
we anticipated that
AIxCC would strongly advocate for the adoption of <em>static analysis</em> while
steering away from the dominant use of <em>fuzzing</em><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
Itâ€™s important to note
that finding bugs is quite different from finding crash- or bug-triggering
inputs. The latter offers a clear advantage in objectively and autonomously
verifying the discovered bug,
but it has a much narrower scope compared to the former.
In practice, the <em>triggering</em> aspect, also known as the reachability problem, is
a significantly more challenging and crucial issue to address,
where <em>dynamic tools</em> like fuzzing have a clear edge.</p></li><li><p><strong>Fine-tuning LLMs for Source Code.</strong> Specialization is always an advantage
when possible. Given that each CRS will likely need to support more than 10
programming languages during the competition, we decided to fine-tune both
in-house and open-source models for analyzing code.
This approach is conceptually similar to
<a href="https://paperswithcode.com/dataset/commitpack" target="_blank">commitPack</a>
,
but focuses on
commits related to bugs like their fixes, bug-introducing commits, descriptions,
and public exploits, if available.
Our expectation was that training with this data would enable
the fine-tuned LLM to reason about security bugs,
their fixes, and likely input corpus,
more effectively than the
foundational model.</p></li></ol><p>We quickly realized that to pursue these directions effectively,
we first needed a dataset: a benchmark.
Our team divided tasks into three areas: 1) static analysis
using LLM prompts/agents, 2) developing a C benchmark from sources like CGC and
OSS-Fuzz, and 3) collecting a training dataset pairing CVEs with patches and PoCs for
open-source projects to fine-tune our in-house code model at Samsung or to
leverage open-source LLMs.</p><p>Remarkably, within 4-5 months, we accomplished all three goals,
and our LLM-based Cyber Reasoning System (CRS), dubbed Skynet,
performed surprisingly well on our benchmark,
and fine-tuning on a smaller dataset shows some promises like in python.</p><p>Time flew by. The cold winter of 2023 ended, and we found ourselves in the new
year of 2024.
I vividly remember that around this time, our dear friends from
Zellic left our team to pursue the Small Business Innovation Research (SBIR) track,
which DARPA supports with $1 million for the competition.
Unfortunately, Georgia Tech and Samsung were not eligible for this award.</p><h2 id="kick-off-with-surprises">Kick-off with Surprises!</h2><p><img title="image title" loading="lazy" decoding="async" width="600" height="390" src="https://team-atlanta.github.io/images/blog/atl/timeline_hu27eb7f2762e238941514cfe06aa31894_2087274_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/timeline_hu27eb7f2762e238941514cfe06aa31894_2087274_600x0_resize_q100_lanczos_3.png&quot;"></p><p>At the kick-off event on March 29th, AIxCC unveiled the first challenge project:
the Linux kernel, along with an example vulnerability,
<a href="https://nvd.nist.gov/vuln/detail/CVE-2021-43267" target="_blank">CVE-2021-43267</a>
.
This bug is <a href="https://www.sentinelone.com/labs/tipc-remote-linux-kernel-heap-overflow-allows-arbitrary-code-execution/" target="_blank">well documented</a>
,
and its PoC exploit is <a href="https://github.com/zzhacked/CVE-2021-43267" target="_blank">publicly available</a>
,
making it an excellent example to work on.</p><p>What makes this bug even more intriguing is the story behind it.
A security researcher audited the Linux kernel source code using
<a href="https://codeql.github.com/" target="_blank">CodeQL</a>
.
Specifically, the researcher was searching
for instances where 16-bit <code>size</code> parameters are passed to the <code>kmalloc()</code>
function for memory allocation,
using a dataflow-based CodeQL query.
The intuition was that a 16-bit <code>size</code> parameter
could easily lead to an <em>integer overflow</em> when accessing the allocated object.
However, the discovered bug was not caused by an integer overflow,
but an out-of-bound heap overflow due to a missing sanity check on the <code>size</code> and related inputs.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>bool</span> <span>tipc_crypto_key_rcv</span>(<span>struct</span> tipc_crypto <span>*</span>rx, <span>struct</span> tipc_msg <span>*</span>hdr)
</span></span><span><span>{
</span></span><span><span>	<span>struct</span> tipc_crypto <span>*</span>tx <span>=</span> <span>tipc_net</span>(rx<span>-&gt;</span>net)<span>-&gt;</span>crypto_tx;
</span></span><span><span>	<span>struct</span> tipc_aead_key <span>*</span>skey <span>=</span> NULL;
</span></span><span><span>	u16 key_gen <span>=</span> <span>msg_key_gen</span>(hdr);
</span></span><span><span>	u16 size <span>=</span> <span>msg_data_sz</span>(hdr);
</span></span><span><span>	u8 <span>*</span>data <span>=</span> <span>msg_data</span>(hdr);
</span></span><span><span>
</span></span><span><span>  ...
</span></span><span><span>
</span></span><span><span>	<span>/* Allocate memory for the key */</span>
</span></span><span><span>	skey <span>=</span> <span>kmalloc</span>(size, GFP_ATOMIC);
</span></span><span><span>	<span>if</span> (<span>unlikely</span>(<span>!</span>skey)) {
</span></span><span><span>		<span>pr_err</span>(<span>"%s: unable to allocate memory for skey</span><span>\n</span><span>"</span>, rx<span>-&gt;</span>name);
</span></span><span><span>		<span>goto</span> exit;
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>/* Copy key from msg data */</span>
</span></span><span><span>	skey<span>-&gt;</span>keylen <span>=</span> <span>ntohl</span>(<span>*</span>((__be32 <span>*</span>)(data <span>+</span> TIPC_AEAD_ALG_NAME)));
</span></span><span><span>	<span>memcpy</span>(skey<span>-&gt;</span>alg_name, data, TIPC_AEAD_ALG_NAME);
</span></span><span><span>	<span>memcpy</span>(skey<span>-&gt;</span>key, data <span>+</span> TIPC_AEAD_ALG_NAME <span>+</span> <span>sizeof</span>(__be32),
</span></span><span><span>	       skey<span>-&gt;</span>keylen);
</span></span></code></pre></div><p>The <code>skey</code> was allocated with a <code>size</code> based on the user-provided <code>hdr</code>,
but <code>skey-&gt;key</code> was copied up to <code>skey-&gt;keylen</code>,
which was also user-controlled and could therefore be inconsistent with <code>size</code>.
Unfortunately, the kernel did not
perform a sanity check on these two parameters,
causing an out-of-boundary access.</p><div><pre tabindex="0"><code data-lang="diff"><span><span>commit fa40d9734a57bcbfa79a280189799f76c88f7bb0
</span></span><span><span>Author: Max VA &lt;maxv@sentinelone.com&gt;
</span></span><span><span>Date:   Mon Oct 25 17:31:53 2021 +0200
</span></span><span><span>
</span></span><span><span>    tipc: fix size validations for the MSG_CRYPTO type
</span></span><span><span>
</span></span><span><span>    The function tipc_crypto_key_rcv is used to parse MSG_CRYPTO messages
</span></span><span><span>    to receive keys from other nodes in the cluster in order to decrypt any
</span></span><span><span>    further messages from them.
</span></span><span><span>    This patch verifies that any supplied sizes in the message body are
</span></span><span><span>    valid for the received message.
</span></span><span><span>
</span></span><span><span>diff --git a/net/tipc/crypto.c b/net/tipc/crypto.c
</span></span><span><span>index c9391d38de85..dc60c32bb70d 100644
</span></span><span><span><span>--- a/net/tipc/crypto.c
</span></span></span><span><span><span></span><span>+++ b/net/tipc/crypto.c
</span></span></span><span><span><span></span><span>@@ -2285,43 +2285,53 @@ static bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)
</span></span></span><span><span><span></span> 	u16 key_gen = msg_key_gen(hdr);
</span></span><span><span> 	u16 size = msg_data_sz(hdr);
</span></span><span><span> 	u8 *data = msg_data(hdr);
</span></span><span><span><span>+	unsigned int keylen;
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+	/* Verify whether the size can exist in the packet */
</span></span></span><span><span><span>+	if (unlikely(size &lt; sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {
</span></span></span><span><span><span>+		pr_debug("%s: message data size is too small\n", rx-&gt;name);
</span></span></span><span><span><span>+		goto exit;
</span></span></span><span><span><span>+	}
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+	keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+	/* Verify the supplied size values */
</span></span></span><span><span><span>+	if (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||
</span></span></span><span><span><span>+		     keylen &gt; TIPC_AEAD_KEY_SIZE_MAX)) {
</span></span></span><span><span><span>+		pr_debug("%s: invalid MSG_CRYPTO key size\n", rx-&gt;name);
</span></span></span><span><span><span>+		goto exit;
</span></span></span><span><span><span>+	}
</span></span></span><span><span><span></span> 
</span></span></code></pre></div><p>Two checks were added to fix this bug:
verifying that <code>size</code> is greater than the
minimum key size, and ensuring that <code>keylen</code> is consistent with <code>size</code>,
thereby preventing access beyond the allocated object.</p><h2 id="misunderstanding-1-pov">Misunderstanding 1: PoV</h2><p>Given a massive Linux repository (yes, 20 million lines of code),
where should we start?
The LLM approach is all about asking the right questions,
also known as prompt engineering.
We utilized various techniques like Chain-of-Thought (CoT)
and Tree-of-Thoughts (ToT),
and were exploring Retrieval Augmented Generation (RAG)
to quickly identify known 1-day bugs.</p><p>At that time, context size was limited;
the most advanced model, <code>gpt-3.5 turbo</code>
(yes, pre-<code>gpt-4</code> era) from OpenAI, supported 16k tokens,
making it crucial to ask the right question!
We initially tried identifying potentially vulnerable
code snippets using a range of static analysis tools,
including CodeQL, Semgrep and various tools from academic publications,
and then filtered the results with LLMs.
We even considered diffing the upstream Linux kernel
against the provided repository,
so that our CRS can look at the modified part of the code first.</p><p>We were confident our decision; to promote the use of AI tools,
the AIxCC organizers
would design the competition in a way that allows a single CRS codebase to
explore any code repository using 10+ programming languages and their
combinations.</p><p>Ah, around that time,
Google had just announced <code>gemini-pro</code>
with an impressive 128k context and the potential to support 1 million tokens!
Meanwhile, <code>gpt-4</code>
introduced a game-changing feature called function calling,
which allows the LLM to select which callback to use and integrate the results back into the prompt
at runtime. We felt that everything was evolving favorably for our CRS to adopt
these cutting-edge techniques.</p><p>However, PoV turned out to mean <em>bug-triggering input</em>
or a crashing input.
To demonstrate the existence of a bug,
each CRS needed to formulate an input
that the referee could quickly verify.
While this approach is
straightforward and objective for the competition,
it significantly discourages the adoption of LLMs in finding bugs.
Our team quickly realized
that we needed to pivot to the dynamic approaches like fuzzing
for the competition.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>tipc_trigger</span>(<span>uint8_t</span> <span>*</span>smashbuf, <span>uint32_t</span> smashlen, <span>int</span> seqno) {
</span></span><span><span>    <span>uint8_t</span> pkt[<span>0x1000</span>];
</span></span><span><span>    <span>uint32_t</span> w0, w1, w2, w3, w4, w5;
</span></span><span><span>
</span></span><span><span>    w0 <span>=</span> <span>hdr_version</span>(TIPC_VERSION);
</span></span><span><span>    w0 <span>|=</span> <span>hdr_size</span>(<span>6</span>);
</span></span><span><span>    w0 <span>|=</span> <span>hdr_user</span>(MSG_CRYPTO);
</span></span><span><span>    w0 <span>|=</span> <span>hdr_msg_size</span>(<span>24</span> <span>+</span> <span>36</span> <span>+</span> KEY_SIZE);
</span></span><span><span>    w1 <span>=</span> <span>0</span>;
</span></span><span><span>    w2 <span>=</span> seqno;
</span></span><span><span>    w3 <span>=</span> NODE_ID;
</span></span><span><span>    w4 <span>=</span> <span>0</span>;
</span></span><span><span>    w5 <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>memset</span>(pkt, <span>0</span>, <span>sizeof</span>(pkt));
</span></span><span><span>    <span>gen_tipc_hdr</span>(pkt, w0, w1, w2, w3, w4, w5);
</span></span><span><span>
</span></span><span><span>    <span>memcpy</span>(pkt<span>+</span><span>24</span>, <span>"HAXX"</span>, <span>4</span>);
</span></span><span><span>    <span>*</span>(<span>uint32_t</span><span>*</span>)(pkt<span>+</span><span>24</span><span>+</span><span>32</span>) <span>=</span> <span>be32</span>(KEY_SIZE <span>+</span> SMASH_SIZE <span>+</span> smashlen); <span>// &lt;- (1)
</span></span></span><span><span><span></span>    <span>memset</span>(pkt<span>+</span><span>24</span><span>+</span><span>36</span>, <span>'C'</span>, KEY_SIZE);
</span></span><span><span>    <span>memset</span>(pkt<span>+</span><span>24</span><span>+</span><span>36</span><span>+</span>KEY_SIZE, <span>'D'</span>, SMASH_SIZE);
</span></span><span><span>    <span>memcpy</span>(pkt<span>+</span><span>24</span><span>+</span><span>36</span><span>+</span>KEY_SIZE <span>+</span> SMASH_SIZE, smashbuf, smashlen);
</span></span><span><span>    <span>tipc_send</span>(pkt, <span>sizeof</span>(pkt));
</span></span><span><span>}
</span></span></code></pre></div><p>Formulating a bug-triggering input, including ensuring its reachability,
is a far more challenging task than simply spotting buggy code in the repository.
The strength of fuzzing, perhaps the opposite of a sophisticated LLM,
is that once a bug is found,
you almost always have a bug-triggering input.</p><p>In CVE-2021-43267, using CodeQL and auditing,
one could identify this bug, but triggering it is an entirely different challenge,
not to mention <a href="https://github.com/zzhacked/CVE-2021-43267/blob/main/poc.py" target="_blank">exploiting it</a>
.
For example,
TIPC must be properly set up first, and the <code>keylen</code> needs to be precisely
crafted in (1) to trigger the bug.</p><h2 id="misunderstanding-2-harnesses">Misunderstanding 2. Harnesses</h2><p>Sorry, whatâ€™s the input needed to trigger CVE-2021-43267? even with a fuzzer?<br>To fuzz the Linux <em>kernel</em>,
we needed a <em>user</em> program
that calls a sequence of system calls
with various arguments.
Considering the Linux kernel has over <a href="https://filippo.io/linux-syscall-table/" target="_blank">400 system calls</a>
to explore, this was far
from ideal for a competition setting.</p><p>We initially assumed that harnesses and test cases would be provided to indicate
which parts of the Linux kernel should be checked for bugs.
To tackle this,
we implemented and adopted various versions of Linux kernel fuzzers,
including a custom kernel syscall fuzzer with <code>kcov</code> and <code>kcmp</code>,
and also utilized the most popular Linux fuzzer, <a href="https://github.com/google/syzkaller" target="_blank">Syzkaller</a>
.
However, our focus remained on determining which sequences of system calls
to test, using syscall traces and static analysis of the provided program,
and then correctly formulating an end-to-end userspace program to trigger the bug.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>/***
</span></span></span><span><span><span> * Blob begins with a 4 byte command count
</span></span></span><span><span><span> * [4-bytes command count]
</span></span></span><span><span><span> * Currently there are two commands:
</span></span></span><span><span><span> *  0 - send a packet blob
</span></span></span><span><span><span> *      [4-bytes size][4-bytes send flags][size-bytes packet data]
</span></span></span><span><span><span> *  1 - send a netlink packet
</span></span></span><span><span><span> *      [4-bytes Message Type][4-bytes Message Flags][4-bytes Netlink Protocol][4-bytes size][size bytes data]
</span></span></span><span><span><span> * blob_size MUST be a trusted value
</span></span></span><span><span><span> */</span>
</span></span><span><span><span>int</span> <span>harness</span>( <span>uint8_t</span> <span>*</span>blob, <span>uint32_t</span> blob_size)
</span></span><span><span>{ ... }
</span></span></code></pre></div><p><a href="https://github.com/aixcc-public/challenge-001-exemplar/" target="_blank">The Linux Kernel CP</a>
was announced in April and came with a harness,
<a href="https://github.com/aixcc-public/challenge-001-exemplar-source/blob/main/test_harnesses/linux_test_harness.c" target="_blank">linux_test_harness.c</a>
.
This announcement was full of surprises;
the programâ€™s structure was provided by the harness,
which is alas what we primarily focused on,
and the <a href="https://github.com/aixcc-public/challenge-001-exemplar/blob/main/exemplar_only/blobs/sample_solve.bin" target="_blank"><code>blob</code></a>
needed to be fed to the harness in a way that triggers the bug.
The types of system calls we could interact with
were limited by the harness,
and our task was to find the right data input
that would <em>lead the harness</em>
to invoke the necessary sequence of system calls with the correct parameters.
In other words, we needed to understand the harness first
before dealing with the Linux kernel bugs.</p><p>Later, the Jenkins harness was announced, and more surprisingly,
it was a fuzz driver (often called a <em>fuzzing harness</em>),
a standalone program designed to
invoke APIs for fuzz testing.
In May, a new CP, called <code>mock-cp</code> (a userspace program),
was introduced along with a new harness format, which was simply a
shell script executing a CP binary with the provided input.
Such diverse formats got us thinking that
our CRS should adopt LLM to figure out the structure of the programs
and CPs first; like how to compile, how to correctly run, etc.</p><p>By June, the harness format was officially established -
surprisingly, yet not entirely unexpected:
<a href="https://llvm.org/docs/LibFuzzer.html" target="_blank">libfuzzer</a>
for
userspace programs (<code>mock-cp</code> and Nginx),
<a href="https://github.com/CodeIntelligenceTesting/jazzer" target="_blank">jazzer</a>
for Java programs
(Jenkins), while retaining the <code>blob</code>-based harness for the Linux kernel.
We continually updated our CRS to adapt to these changes,
but many of these decisions rendered our LLM-based components unnecessary.
This decision, however,
greatly helped all the participating teams
by reducing the engineering time needed for game operation.
Unfortunately, we were too proactive in reacting to these changes and ended up
wasting some engineering time as a result ðŸ˜Š.</p><p>A harnessâ€™s role is crucial in the AIxCC competition; it sets the context for
the CRS to trigger the bug and serves as a key factor in adjusting the
difficulty of bug discovery. Therefore, itâ€™s important to strike a balance:
it should provide enough detail to relieve the CRS from unnecessary burdens,
allowing it to focus on bug finding, but without revealing too much information
about the bugs.</p><h2 id="misunderstanding-3-proof-of-understanding">Misunderstanding 3. Proof-of-understanding</h2><p>Unlike CGC, which treated the PoV (a proof-of-concept exploit)
as sufficient proof of bug discovery,
AIxCC required additional informationâ€”specifically, the bug type as classified by
<a href="https://cwe.mitre.org/top25/archive/2023/2023_kev_list.html" target="_blank">CWE</a>
,
to be provided along with the PoV.
This was an interesting decision, as AIxCC required
CRS to find bugs in the source code,
whereas CGC focused on discovering bugs in binaries.</p><p>Our team spent a lot of time brainstorming
how to accurately identify CWE categories,
primarily by using LLM prompts that leverage crashing inputs,
sanitizer reports, related code snippets, outputs from static analyzers, and more.
However, the notion of CWEs can be ambiguous when used as a scoring
mechanism for the competition.
For instance, should CVE-2021-43267 be classified
as (1) CWE-122 (Heap-based Buffer Overflow), (2) CWE-787 (Out-of-bounds Write),
or (3) CWE-20 (Improper Input Validation)?
The first two describe the symptoms
caused by the bug, while the third identifies the root cause, as the patch for
this bug involved adding input validations.</p><p>In the end, AIxCC shifted the focus from PoV to identifying the bug-introducing
commit (BIC) - the specific hash or commit ID in the git repository.
Combined with
the fuzzing harness and PoV, the CRSâ€™s task was to run the fuzzing harness and
perform a <a href="https://git-scm.com/docs/git-bisect" target="_blank"><code>git-bisect</code></a>
to pinpoint
the BIC in the repository.
We did a simple bisecting in the semifinal but lots of improvement
required to be functional for the final event.</p><h2 id="misunderstanding-4-semantic-patching">Misunderstanding 4. Semantic patching</h2><p>Patching is one of the most intriguing aspects of AIxCC. In CGC, the PoV was
typically a simple exploit (like arbitrary read/write/execute),
so mitigation strategies (e.g., adding a stack canary) could effectively thwart the PoV.
In fact, patches could be applied <em>without even knowing</em> the specific bug;
for example,
adding a stack canary to all functions in a binary
can prevent buffer overflow exploits
that might exist in some places.</p><p>The challenge in CGC was that the focus was on the binary, and the organizers
introduced rules such as a minimum number of bytes changed and performance
overheads added to the scoring rubric (e.g., instrumenting all memory accesses
to prevent out-of-bound errors). These rules were designed to encourage
competitors to generate correct patches. Ultimately, this forced CRS to weigh
the pros and cons of universal patching, as both exploiting and patching were
extremely difficult during the CGC era,
resulting in a trade-off between losing
points from exploitation versus losing points from patching and availability.</p><p>In AIxCC, the CRS must generate a semantically correct patch that not only fixes
the identified PoV but also maintains the functional correctness of the CP. This
is a tricky task, as <em>correctness</em> cannot be formally defined for CRS - some
functional changes may be acceptable, while others may not, depending on the
code ownerâ€™s criteria.
One approach to addressing this ambiguity is to provide
test code to see if the patch passes the provided, so-called public tests.
However, CRS must still account for private tests set by the organizers.</p><p>In the semifinals, our CRS submitted a patch that successfully prevented the
crash and passed the public tests given to us during the competition,
but was ultimately rejected in the private
functionality tests.
Weâ€™re eager to learn more about the bug and the patch!</p><h2 id="misunderstanding-5-sanitizers">Misunderstanding 5: Sanitizers</h2><p>The concept of sanitizers was unclear to our team until we encountered
their concrete implementation
for memory-safe languages like Java, and more
specifically, for Jenkins, a web application written in Java!
The role of a sanitizer, essentially a bug oracle, is to determine whether a bug has been
correctly triggered.</p><p>In memory-unsafe languages like C, standard tools like ASAN and UBSAN can serve
as sanitizers to catch memory-safety issues with low or no false positives
(e.g., out-of-bound accesses should never occur).
However, in memory-safe languages,
things get trickier.
For example, is executing a command a legitimate
feature in CI tools like Jenkins,
or should it be treated as a command injection (CWE-78)?</p><p>In other words, sanitizers are more CP-specific
rather than programming language-specific;
each CP needs to provide custom sanitizers
(e.g., <a href="https://www.code-intelligence.com/blog/java-fuzzing-with-jazzer" target="_blank">path traversal sanitizers</a>
).</p><p>Our team initially spent time working on finding web-related bugs like XSS or
CSRF in Jenkins - areas where we believed LLMs could excel in seed generation.
However, once AIxCC announced
that the sanitizers for Java would be
<a href="https://github.com/CodeIntelligenceTesting/jazzer" target="_blank">jazzer</a>
sanitizers,
we decided to shift our focus more towards standard jazzer-based fuzzing.</p><h2 id="semifinal">Semifinal</h2><p>Our team dedicated most of our engineering effort to building a CRS for the
Linux Kernel, and weâ€™re proud that our CRS was able to find and correctly
generate a patch for CVE-2021-43267 in the end.
However, during the semifinal,
it appeared that only <em>one</em> harness was provided, similar to the exemplar, and
none of the CRSes functioned properly for the Linux Kernel.
We loved to know more about how our Linux CRS functioned
during the competition.</p><p><img title="image title" loading="lazy" decoding="async" width="600" height="404" src="https://team-atlanta.github.io/images/blog/atl/dashboard_hucdfac242ccfb260b6c8aa0c492f17fbb_248513_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/dashboard_hucdfac242ccfb260b6c8aa0c492f17fbb_248513_600x0_resize_q100_lanczos_3.png&quot;"></p><p>In summary, our CRS earned a total of six achievement badges: five for
discovering bugs (i.e., first bloods) and one for a patch.</p><p><img title="image title" loading="lazy" decoding="async" width="600" height="333" src="https://team-atlanta.github.io/images/blog/atl/achievements_hu5072cc1c531c3d4ed879245bc9c46aa6_852847_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/achievements_hu5072cc1c531c3d4ed879245bc9c46aa6_852847_600x0_resize_q100_lanczos_3.png&quot;"></p><p>Our CRS found several unique bugs, which we will describe in a later blog post!</p><p>Aside from the known CPsâ€”Linux (C), Jenkins (Java), and Nginx (C) - there were new
CPs introduced, namely Tika (Java) and sqlite3 (C).
Our CRS performed relatively
well on sqlite3, but unfortunately,
our Java CRS struggled with Tika.
We would love to learn more about what happened during the competition.
Tika, a popular file format parser,
has many unique features, such as recursively parsing
embedded objects,
which may have contributed to the challenges we faced.</p><h2 id="looking-ahead-to-the-aixcc-final-">Looking Ahead to the AIxCC Final ðŸŽ‰</h2><figure role="group" aria-describedby="caption-AIxCC Finalists"><img title="image title" loading="lazy" decoding="async" width="600" height="331" src="https://team-atlanta.github.io/images/blog/atl/finalists_hua191f10a8c6185b27f399163513ba79a_538686_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/finalists_hua191f10a8c6185b27f399163513ba79a_538686_600x0_resize_q100_lanczos_3.png&quot;"><figcaption id="caption-AIxCC Finalists">AIxCC Finalists</figcaption></figure><p>We are thrilled that our team has advanced to the AIxCC finals! We have several ideas that could make the competition even more exciting:</p><ul><li><p><strong>Different execution times based on code complexity.</strong><br>The Linux kernel, with its 6,000 files and 20 million lines of code, requires
substantial time for bookkeeping like building, bootstrapping, and bisecting.
Compared to smaller programs (e.g., 200k in Tika), it would be beneficial to
allocate more time for CRSes to navigate such complex codebases.</p></li><li><p><strong>More programming languages and their combinations.</strong><br>Top candidates include Python, Rust, and JavaScript/HTML, along with
combinations like JNI (C) in Java or Rust device drivers in the Linux kernel.
These would offer a more comprehensive evaluation of CRS capabilities in
diverse and challenging settings where CRS is most needed.</p></li><li><p><strong>Standardized execution environments.</strong><br>Standardizing the compiler (e.g., <code>clang-18</code>), runtime (e.g., JVM version),
and base Docker image ahead of time would help teams explore more advanced
techniques, such as LLM-based instrumentation, in a controlled environment.</p></li><li><p><strong>Improved visualization during the competition.</strong><br>While the AIxCC village was impressively set up, competing teams and
participants had limited visibility into the competitionâ€™s progress and how
each CRS was functioning. To capture more attention from <a href="https://www.reddit.com/r/Defcon/comments/1eta3tj/was_the_aixcc_village_disappointing_to_anyone_else/" target="_blank">the DEF CON audience</a>
,
it would be beneficial to expose more technical information during the
competition - such as showing current prompts of each CRS in turn, their CPU
usage, or even stdout from CRSes (for fun), along with explanations of the
progress.</p></li></ul><p>With our baseline system up and running, itâ€™s time for our team to explore the
possibility of incorporating LLMs or ML techniques into our CRS workflow. If
youâ€™re passionate about AIxCC and as committed to the competition as we are,
feel free to <a href="mailto:aixcc-atl@googlegroups.com">contact us</a>
!</p><p>We are fortunate to have support from generous sponsors like GT/GTRI, Samsung,
and KAIST/NYU. If your company is interested in sponsoring our team, we would be
happy to discuss further!</p><p>Last but not least, we want to extend our heartfelt thanks to the AIxCC
organizers for launching the competition weâ€™ve been craving. Hackers thrive on
competition-driven innovation, and this has been an exciting opportunity for all
of us.</p><div><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/FkJimGWJYgw?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Family poisoned after using AI-generated mushroom identification book (220 pts)]]></title>
            <link>https://old.reddit.com/r/LegalAdviceUK/comments/1etko9h/family_poisoned_after_using_aigenerated_mushroom/</link>
            <guid>41269514</guid>
            <pubDate>Fri, 16 Aug 2024 19:24:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LegalAdviceUK/comments/1etko9h/family_poisoned_after_using_aigenerated_mushroom/">https://old.reddit.com/r/LegalAdviceUK/comments/1etko9h/family_poisoned_after_using_aigenerated_mushroom/</a>, See on <a href="https://news.ycombinator.com/item?id=41269514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>EDIT: I have not stated the name of the online marketplace. Assumptions are being made in the comments, which I am neither confirming nor denying.</strong></p>

<p>My entire family was in hospital last week after accidentally consuming poisonous mushrooms.</p>

<p>My wife purchased a book from a major online retailer for my birthday. The book is entitled something similar to: "Mushrooms UK: A Guide to Harvesting Safe and Edible Mushrooms."</p>

<p>It comes with pictures of the mushrooms to help identify each one.</p>

<p>Unfortunately, the book in question was not accurate. A closer investigation reveals that the images of mushrooms are AI generated, and we have now found two instances of text where a sentence ends and is followed up with a random questions or fourth-wall breaking statements.</p>

<p>For example:</p>

<p><em>"In conclusion, morels are delicious mushrooms which can be consumed from August to the end of Summer. Let me know if there is anything else I can help you with."</em></p>

<p>The online retailer have instructed me to return the book and they will refund it. The book has been removed from sale from the online retailer, however, it appears there are dozens more in a similar style.</p>

<p>1.) Should I return this book to the retailer? I'm concerned I would lose any evidence I have if I return it. The purchase has already disappeared from my online account. It simply looks like it doesn't exist anymore. I still have the email.</p>

<p>2.) Are my family entitled to any compensation for my son and my wife's lost time at work? As well as the sickness they experienced?</p>

<p>3.) Can I report the creation of this book to the police as a crime?</p>

<p><strong>Just for clarity: We did not know it was AI-generated when we bought it! This was not disclosed on the website!</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VanillaJSX.com (383 pts)]]></title>
            <link>https://vanillajsx.com/</link>
            <guid>41269321</guid>
            <pubDate>Fri, 16 Aug 2024 19:01:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vanillajsx.com/">https://vanillajsx.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41269321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="root"><p>What if JSX just returned DOM elements?</p><div data-sample="sample1"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample1.tsx">View source</a></p><pre><code>export default function ClickMe() {
  let i = 0;
  const el = &lt;button&gt;Click me&lt;/button&gt; as HTMLButtonElement;
  el.onclick = (e) =&gt; {
    el.textContent = `Clicked ${++i} times`;
  };
  return el;
}
</code></pre></div><p>Would they be reusable?</p><p>Could they keep their own state?</p><div data-sample="sample2"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample2.tsx">View source</a></p><pre><code>import ClickMe from "./sample1.js";

export default () =&gt; &lt;&gt;
  &lt;p&gt;&lt;ClickMe /&gt;&lt;/p&gt;
  &lt;p&gt;&lt;ClickMe /&gt;&lt;/p&gt;
  &lt;p&gt;&lt;ClickMe /&gt;&lt;/p&gt;
&lt;/&gt;;
</code></pre></div><p>How would they work together?</p><p>Could they create an interactive DOM tree?</p><div data-sample="sample3"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample3.tsx">View source</a></p><pre><code>function TodoInput(attrs: { add: (v: string) =&gt; void }) {
  const input = &lt;input /&gt; as HTMLInputElement;
  input.placeholder = 'Add todo item...';
  input.onkeydown = (e) =&gt; {
    if (e.key === 'Enter') {
      attrs.add(input.value);
      input.value = '';
    }
  };
  return input;
}

class TodoList {
  ul = &lt;ul class='todolist' /&gt; as HTMLUListElement;
  add(v: string) {
    const item = &lt;li&gt;{v}&lt;/li&gt; as HTMLLIElement;
    item.onclick = () =&gt; item.remove();
    this.ul.append(item);
  }
}

export default () =&gt; {
  const list = new TodoList();
  list.add('foo');
  list.add('bar');
  return &lt;&gt;
    &lt;TodoInput add={(v) =&gt; list.add(v)} /&gt;
    {list.ul}
  &lt;/&gt;;
};
</code></pre></div><p>How would they handle large data?</p><p>Could they be convenient without a virtual dom?</p><div data-sample="sample4"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample4.tsx">View source</a></p><pre><code>import { data } from "../fetch-dataset.js";

export default function FindNames() {
  const status = &lt;p style='margin:1em 0' /&gt; as HTMLParagraphElement;
  const results = &lt;ul /&gt; as HTMLUListElement;
  const input = &lt;input
    value='eri(c|k)a?'
    autocomplete='new-password'
  /&gt; as HTMLInputElement;

  const updateMatches = () =&gt; {
    const matched = (data.entries()
      .filter(([k]) =&gt; k.match(input.value))
      .toArray());

    const matches = (Iterator.from(matched)
      .map(match =&gt; &lt;Item regex={input.value} match={match} /&gt;)
      .take(30));

    results.replaceChildren(...matches);
    status.textContent = `${matched.length} / ${data.size}`;
  };

  input.oninput = updateMatches;
  updateMatches();

  return &lt;div class='sample4'&gt;
    {input}
    {status}
    {results}
  &lt;/div&gt;;
}

function Item(attrs: { match: [string, number], regex: string }) {
  const [name, count] = attrs.match;
  const total = &lt;small style='color:#fff3'&gt;({count})&lt;/small&gt;;
  return &lt;li&gt;
    &lt;span innerHTML={highlight(name, attrs.regex)} /&gt; {total}
  &lt;/li&gt;;
}

function highlight(str: string, regex: string) {
  if (!regex) return str;
  const r = new RegExp(`(${regex})`, 'gi');
  return str.replace(r, '&lt;span class="match"&gt;$1&lt;/span&gt;');
}
</code></pre></div><p>That's why I wrote <a target="_blank" href="https://code.immaculatalibrary.com/">imlib</a> (<a href="https://github.com/sdegutis/imlib">src</a>).</p><p>It came out of my work on <a target="_blank" href="https://www.immaculatalibrary.com/">immaculatalibrary.com</a> (<a href="https://github.com/sdegutis/immaculatalibrary.com">src</a>).</p><p>I started using it to build <a target="_blank" href="https://minigamemaker.com/">minigamemaker.com</a> (<a href="https://github.com/sdegutis/minigamemaker.com">src</a>).</p><p>I also used it to build <a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/tree/main/site">the website you're reading</a> (&lt;-- src).</p><p>It was created because the status quo wasn't good enough for my site.</p><p>It is now my favorite way to make apps.</p><p>(Also, here's a much better <a href="https://sdegutis.github.io/imlib-todolist/">imlib todo-list app</a> (<a href="https://github.com/sdegutis/imlib-todolist/blob/main/site/app.tsx">src</a>)).</p><p>The two most complex "interactive apps" I've built with this are:</p><ul><li><a href="https://www.immaculatalibrary.com/books.html">Books search page</a> (<a href="https://github.com/sdegutis/immaculatalibrary.com/blob/main/site/scripts/books-page.tsx">src</a>)</li><li><a href="https://www.immaculatalibrary.com/prayers/">Prayer page</a> (<a href="https://github.com/sdegutis/immaculatalibrary.com/blob/main/site/prayers/client.tsx">src</a>)</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Backdoor discovered in several brands of RFID cards [pdf] (233 pts)]]></title>
            <link>https://eprint.iacr.org/2024/1275.pdf</link>
            <guid>41269249</guid>
            <pubDate>Fri, 16 Aug 2024 18:53:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eprint.iacr.org/2024/1275.pdf">https://eprint.iacr.org/2024/1275.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41269249">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Disrupting a covert Iranian influence operation (116 pts)]]></title>
            <link>https://openai.com/index/disrupting-a-covert-iranian-influence-operation/</link>
            <guid>41269113</guid>
            <pubDate>Fri, 16 Aug 2024 18:39:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/disrupting-a-covert-iranian-influence-operation/">https://openai.com/index/disrupting-a-covert-iranian-influence-operation/</a>, See on <a href="https://news.ycombinator.com/item?id=41269113">Hacker News</a></p>
Couldn't get https://openai.com/index/disrupting-a-covert-iranian-influence-operation/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What Is a Knowledge Graph? (133 pts)]]></title>
            <link>https://neo4j.com/blog/what-is-knowledge-graph/</link>
            <guid>41268929</guid>
            <pubDate>Fri, 16 Aug 2024 18:22:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neo4j.com/blog/what-is-knowledge-graph/">https://neo4j.com/blog/what-is-knowledge-graph/</a>, See on <a href="https://news.ycombinator.com/item?id=41268929">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><img fetchpriority="high" decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph.png" alt="Knowledge graph concept that includes organizing principles, relationships, and data." width="1200" height="628" srcset="https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph.png 1200w, https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph-300x157.png 300w, https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph-1024x536.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph-150x79.png 150w, https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph-768x402.png 768w, https://dist.neo4j.com/wp-content/uploads/20240722075336/what-is-knowledge-graph-600x314.png 600w" sizes="(max-width: 1200px) 100vw, 1200px"></p>

<p>A <a href="https://neo4j.com/use-cases/knowledge-graph/" target="_blank" rel="noopener">knowledge graph</a> is an organized representation of real-world entities and their relationships. It is typically stored in a graph database, which natively stores the relationships between data entities.<strong> </strong>Entities in a knowledge graph can represent objects, events, situations, or concepts. The relationships between these entities capture the context and meaning of how they are connected.</p>
<p>A knowledge graph stores data and relationships alongside frameworks known as organizing principles. They can be thought of as rules or categories around the data that provide a flexible, conceptual structure to drive deeper data insights. The usefulness of a knowledge graph lies in the way it organizes the principles, data, and relationships to surface new knowledge for your user or business. The design is useful for many usage patterns, including real-time applications, search and discovery, and <a href="https://neo4j.com/generativeai/" target="_blank" rel="noopener">grounding generative AI </a>for question-answering.</p>
<p>Sometimes, people overcomplicate the concept of a knowledge graph. You might hear about enterprise-wide structures that consolidate and connect information across data silos and various sources. While that <em>does</em> describe a knowledge graph (one that can underpin a data integration use case), it describes one with a wide scope. Thinking only in terms of bridging large datasets and multiple data sources can make creating and implementing knowledge graphs seem complicated and time-consuming. But knowledge graphs donâ€™t need to be broad or elaborate. You can build one with a much smaller scope to solve a use-case-specific problem.  </p>
<br><h2><strong>How Knowledge Graphs Work</strong></h2>
<p>You may have heard of knowledge graphs in the context of search engines. The <a href="https://blog.google/products/search/introducing-knowledge-graph-things-not/" target="_blank" rel="noopener">Google Knowledge Graph</a> changed how we search for and find information on the Web. It amasses facts about people, places, and things into an organized network of entities. When you do a Google search for information, it uses the connections between entities to surface the most relevant results in context, for example, in the box Google calls the â€œ<a href="https://support.google.com/knowledgepanel/answer/9163198?hl=en" target="_blank" rel="noopener">knowledge panel</a>.â€ </p>
<p><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722075320/la-sagrada.png" alt="La sagrada familia: Google knowledge graph." width="1024" height="657" srcset="https://dist.neo4j.com/wp-content/uploads/20240722075320/la-sagrada.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240722075320/la-sagrada-300x192.png 300w, https://dist.neo4j.com/wp-content/uploads/20240722075320/la-sagrada-150x96.png 150w, https://dist.neo4j.com/wp-content/uploads/20240722075320/la-sagrada-768x493.png 768w, https://dist.neo4j.com/wp-content/uploads/20240722075320/la-sagrada-600x385.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p><em>The Google knowledge panel of La Sagrada Familia includes an image of the site, a map, a description, address, hours of operation, the architects who built it, its height, and more. </em></p>


<p>The entities in the Google knowledge graph represent the world as we know it, marking a shift from â€œstrings to things.â€ Behind this simple phrase is the profound concept of treating information on the web as entities rather than a bunch of text. Since information is organized as a network of entities, Google can tap into the collective intelligence of the knowledge graph to return results tailored to the<em> meaning</em> of your query rather than a simple keyword match.  </p>
<br><h2><strong>Key Characteristics</strong></h2>
<p>Now that you understand how knowledge graphs organize and access data with context, letâ€™s look at the building blocks of a knowledge graph data model. The definition of knowledge graphs varies depending on whom you ask, but we can distill the essence into three key components: nodes, relationships, and organizing principles. </p>
<h3>Nodes </h3>
<p><strong><em>Nodes</em></strong> denote and store details about entities, such as people, places, objects, or institutions. Each node has a (or sometimes several) label to identify the node type and may optionally have one or more properties (attributes). Nodes are also sometimes called <em>vertices</em>.</p>
<p>For example, the nodes in an e-commerce knowledge graph typically represent entities such as people (customers and prospects), products, and orders: 

</p><p><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph.png" alt="Example of nodes in an e-commerce graph." width="600" srcset="https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph.png 2048w, https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph-300x252.png 300w, https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph-1024x860.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph-150x126.png 150w, https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph-768x645.png 768w, https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph-1536x1289.png 1536w, https://dist.neo4j.com/wp-content/uploads/20240722075309/ecommerce-knowledge-graph-600x504.png 600w" sizes="(max-width: 2048px) 100vw, 2048px"></p>
<h3>Relationships</h3>
<p><strong><em>Relationships</em></strong> link two nodes together: they show how the entities are related. Like nodes, each relationship has a label identifying the relationship type and may optionally have one or more properties. Relationships are also sometimes called <em>edges</em>. </p>
<p>In the e-commerce example, relationships exist between the customer and order nodes, capturing the â€œplaced orderâ€ relationship between customers and their orders:</p>
<p><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order.png" alt="Relationship of a person to Order." width="600" srcset="https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order.png 2048w, https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order-300x96.png 300w, https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order-1024x329.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order-150x48.png 150w, https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order-768x246.png 768w, https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order-1536x493.png 1536w, https://dist.neo4j.com/wp-content/uploads/20240722075323/relationship-order-600x192.png 600w" sizes="(max-width: 2048px) 100vw, 2048px"></p>
<h3>Organizing Principle(s) </h3>
<p><strong><em>Organizing Principles</em></strong> are a framework, or schema, that organizes nodes and relationships according to fundamental concepts essential to the use cases at hand. Unlike many data designs, knowledge graphs easily incorporate multiple organizing principles.</p>
<p>Organizing principles range from simple (product line -&gt; product category -&gt; product taxonomy) to complex (a complete business vocabulary that explains the data in the graph). Think of an organizing principle as a conceptual map or metadata layer overlaying the data and relationships in the graph.</p>
<p>The model uses the same node-and-relationship structure as the rest of the knowledge graph to describe the organizing principles â€“ which means you can write queries that draw from both instance data and organizing principles. </p>
<p>In the e-commerce example, an organizing principle might be product types and categories:</p>
<p><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1.png" alt="Organizing principle of a knowledge graph." width="800" srcset="https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1.png 5246w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-300x147.png 300w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-1024x500.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-150x73.png 150w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-768x375.png 768w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-1536x750.png 1536w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-2048x1001.png 2048w, https://dist.neo4j.com/wp-content/uploads/20240722083709/kg-organizing-principle-1-600x293.png 600w" sizes="(max-width: 5246px) 100vw, 5246px"></p>
<h3>What About Ontologies?</h3>
<p>When learning about knowledge graphs, you might come across articles on <strong><em>ontologies</em></strong> and wonder where they fit in. An ontology is a formal specification of the concepts and the relationships between them for a given subject area; semantic networks are a common way to represent ontologies. Put simply, ontologies are a type of organizing principle. </p>
<p>Ontologies can be complex and require a great deal of effort to define and maintain. When deciding whether an ontology is needed, itâ€™s critical to consider the problems youâ€™re trying to solve with a knowledge graph. In many cases, it wonâ€™t be necessary. In the e-commerce example, using a product taxonomy as the organizing principle is sufficient for a product recommendation use case. </p>
<p>Think of the knowledge graph as a growing, evolving system to simplify your design in the early stages and deliver value sooner. If you pick the right technology to implement your knowledge graph, you can expand and evolve the graph as your needs change. In this way, you can add ontologies when your use case requires them rather than forcing yourself to build them up-front.</p>
<br><h2><strong>Knowledge Graph Example</strong></h2>
<p>Letâ€™s see what a knowledge graph might look like. Below is a simple knowledge graph of the e-commerce example that shows nodes as circles and relationships between them as arrows. The organizing principles are also stored as nodes and relationships, so the illustration uses some color shading to show which nodes and relationships are the instance data and which are the organizing principles:</p>

<p><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1.png" alt="Example of a knowledge graph." width="1000" srcset="https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1.png 2048w, https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1-300x209.png 300w, https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1-1024x712.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1-150x104.png 150w, https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1-768x534.png 768w, https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1-1536x1068.png 1536w, https://dist.neo4j.com/wp-content/uploads/20240722075316/knowledge-graph-example-1-600x417.png 600w" sizes="(max-width: 2048px) 100vw, 2048px"></p>
<p><em>An example knowledge graph showing nodes as circles and relationships as arrows. The instance data and organizing principles are highlighted for display.</em></p>

<br><h2><strong>Knowledge Graphs and Graph Databases</strong></h2>
<p>Creating a knowledge graph involves conceptually mapping the graph data model and then implementing it in a database. There are many databases to choose from, but choosing the right one can simplify the design process, speed up development and implementation, and make it easier to adapt to future changes and improvements. </p>

<h3>Property Graphs</h3>

<p>Native property graph databases, such as <a href="https://neo4j.com/product/neo4j-graph-database/" target="_blank" rel="noopener">Neo4j</a>, are a logical choice for implementing knowledge graphs. They natively store information as nodes, relationships, and properties, allowing for an intuitive <a href="https://neo4j.com/product/bloom/" target="_blank" rel="noopener">visualization</a> of highly interconnected data structures. The physical database matches the conceptual data model, making designing and developing the knowledge graph easier. When you use property graphs, you get:</p>

<ul><ul><li><strong>Simplicity and ease of design:</strong> Property graphs allow for straightforward data modeling when designing the knowledge graph. Because the conceptual and physical models are very similar (often the same), the transition from design to implementation is more straightforward (and easy to explain to non-technical users). </li><br>

<li><strong>Flexibility:</strong> Itâ€™s easy to add new data, properties, relationship types, and organizing principles without extensive refactoring or code rewrites. As needs change, you can iterate and incrementally expand the knowledge graphâ€™s data, relationships, and organization. </li><br>

<li><strong>Performance:</strong> Property graphs offer superior query performance compared to alternatives like RDF databases or relational databases, especially for complex traversals and many-to-many relationships. This performance comes from storing the relationships between entities directly in the database rather than re-generating them using joins in queries. A native property graph database traverses relationships by following pointers in memory, making queries that traverse even complex chains of many relationships very fast. </li><br>

<li><strong>Developer-friendly Code:</strong> Property graphs support an intuitive and expressive ISO query language standard, <a href="https://neo4j.com/blog/gql-international-standard/" target="_blank" rel="noopener">GQL</a>, which means you have less code to write, debug, and maintain than SQL or SPARQL. Neo4jâ€™s Cypher is the most widely used implementation of GQL.</li></ul></ul>


<h3>Property Graph Vs. Triple Stores (RDF)</h3>
<p>People sometimes think of <a href="https://neo4j.com/blog/rdf-vs-property-graphs-knowledge-graphs/" target="_blank" rel="noopener">property graphs and triple stores </a>as equally viable options for building a knowledge graph, but triple stores (also known as RDF databases) have considerable disadvantages. </p>
<p>Based on the Resource Description Framework (RDF), triple stores use a granular approach to design and storage. Triple stores express all data in the form of subject-predicate-object â€œtriples.â€ This model does not support relationships with properties or multiple same-typed relationships between entities. To accommodate real-world use cases, you will need to implement workarounds. Common workarounds include turning relationships into objects (called <em>reification</em>) or using <em>singleton properties</em> to capture properties using extra â€œtype-ofâ€ relationships. These workarounds mean larger databases, additional complexity in the physical model, and poor query performance.</p>
<p>Because reification and singleton properties force tough decisions about the design up front, triple stores donâ€™t lend themselves to solving real-world problems that involve messy data domains. Knowledge graphs built on a triple store are more challenging to design, time-consuming to implement, and difficult to change. </p>
<h3>Property Graph Vs. Relational Databases</h3>

<p>Relational databases and other non-native graph approaches suffer similar design friction. Neither relational nor document databases store relationships â€“ they must be synthesized at runtime with joins or value lookups in query code. Since the relationships reside in the code rather than with the dataset, each application and data use must have its own implementation. SQL (the relational database query language) forces you to define every join in the query itself. As a result, the knowledge graph becomes more difficult to manage and yields poor runtime performance as the number of relationships expands.</p>
<br><h2><strong>Knowledge Graph Use Cases</strong></h2>
<p>Knowledge graphs offer a powerful tool for storing and organizing data to enable a more sophisticated understanding of that data. To understand how companies have done this, letâ€™s look at examples of using knowledge graphs to tackle particular problems. Though not a comprehensive list of use cases, itâ€™s a set of concrete examples demonstrating knowledge graphs in real-world applications.</p>
<h3>Generative AI for Enterprise Search Applications </h3>
<p>In <strong><a href="https://neo4j.com/generativeai/" target="_blank" rel="noopener">generative AI</a></strong><strong> </strong>applications<strong>, </strong>knowledge graphs capture and organize key domain-specific or proprietary company information. Knowledge graphs are not limited to structured data; they can handle less organized data as well. </p>
<p><a href="https://neo4j.com/blog/graphrag-manifesto/" target="_blank" rel="noopener">GraphRAG</a>, a technique that grounds large language models with knowledge graphs, is emerging as the foundation of AI applications that use proprietary domain data (these are known as RAG applications). A knowledge graph grounding increases response accuracy and improves explainability with the context provided by data relationships. Industry leaders <a href="https://www2.deloitte.com/content/dam/Deloitte/nl/Documents/risk/deloitte-nl-risk-responsible-enterprise-decisions-with-knowledge-enriched-generative-ai-whitepaper-download.pdf" target="_blank" rel="noopener">such as Deloitte</a> highlight the critical role of knowledge graphs for building enterprise-grade GenAI. Gartner places knowledge graphs having a â€œhigh mass,â€ being an impactful technology for GenAI today: </p>

<p><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai.png" alt="This Impact Radar from Gartner highlights knowledge graphs as a high-impact technology within the Generative AI landscape." width="600" srcset="https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai.png 1310w, https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai-300x261.png 300w, https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai-1024x892.png 1024w, https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai-150x131.png 150w, https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai-768x669.png 768w, https://dist.neo4j.com/wp-content/uploads/20240729094634/gartner-genai-600x523.png 600w" sizes="(max-width: 1310px) 100vw, 1310px"></p><p><em>This Impact Radar from Gartner highlights knowledge graphs as a high-impact technology within the Generative AI landscape (Credit: Gartner) </em></p>

<h3>Fraud Detection and Analytics in Financial Services, Banking, and Insurance</h3>

<p>In <strong><a href="https://neo4j.com/use-cases/fraud-detection/" target="_blank" rel="noopener">Fraud Detection and Analytics</a></strong><a href="https://neo4j.com/use-cases/fraud-detection/" target="_blank" rel="noopener">,</a> the knowledge graph represents a network of transactions, their participants, and relevant information about them. Companies can use this knowledge graph to quickly identify suspicious activity, investigate suspected fraud, and evolve their knowledge graph to keep up with changing fraud patterns. Algorithms such as pathfinding and community detection provide key signals to machine learning algorithms that can uncover more sophisticated fraud networks.</p>

<h3>Master Data Management</h3>
<p>In <strong><a href="https://neo4j.com/use-cases/master-data-management/" target="_blank" rel="noopener">Master Data Management</a></strong> (e.g., for <strong>Customer 360</strong> use cases), the knowledge graph provides an organized, resolved (i.e., â€œde-dupedâ€), and comprehensive database of a companyâ€™s customers and the companyâ€™s interactions with them. </p>
<p>This organized view of customers is especially important for companies with multiple divisions or applications interacting with customers. Without a knowledge graph, it can be difficult or impossible to obtain an accurate view of the customer. A knowledge graph links customer behaviors across multiple applications through an organizing principle that identifies them as coming from the same customer. </p>

<h3>Supply Chain Management </h3>
<p>In <strong><a href="https://neo4j.com/blog/supply-chain-forecasting/" target="_blank" rel="noopener">Supply Chain Management</a></strong>, a knowledge graph represents the network of suppliers, raw materials, products, and logistics that work together to supply a companyâ€™s operations and customers. This end-to-end supply chain visibility allows managers to identify weak points and predict where disruptions may occur. Graph algorithms such as <a href="https://neo4j.com/blog/graph-algorithms-neo4j-shortest-path/" target="_blank" rel="noopener">shortest path</a> optimize the supply chain in real time by finding the most direct route between A and B.</p>
<h3>Investigative Journalism</h3>
<p>In <strong><a href="https://neo4j.com/blog/electiongraph-report-2/" target="_blank" rel="noopener">Investigative Journalism</a></strong><strong>,</strong> knowledge graphs capture key entities (companies, people, bank accounts, etc.) and activities under investigation. Organizing these entities in relation to one another makes it possible to find hidden patterns, such as distant relationships between entities that shouldnâ€™t be present. </p>
<p>Investigators may use techniques such as entity resolution to reveal entities hiding behind fake or shell identities to mask their activities. Algorithms like community detection and link prediction also provide insight and areas for further investigation.</p>
<h3>Drug Discovery in Healthcare Research</h3>
<p>Knowledge graphs store information about the research subject in <a href="https://neo4j.com/case-studies/basecamp-research/" target="_blank" rel="noopener">medical and other research</a> use cases. For example, the knowledge graph could have protein and genome sequences together with environmental and chemical data, revealing intricate patterns and expanding our knowledge of proteins.</p>
<br><h2><strong>Getting Started With Knowledge Graphs</strong></h2>
<p>Knowledge graphs are organized representations of real-world entities and their relationships, overlaid with one or more organizing principles that frame the information in context to drive insight from the data. Knowledge graphs underpin insightful applications and artificial intelligence solutions across many use cases.</p>

<p><a href="https://neo4j.com/knowledge-graphs-practitioners-guide/" rel="noopener" target="_blank"><img decoding="async" src="https://dist.neo4j.com/wp-content/uploads/20240722074429/Building-Knowledge-Graphs-ebook-cover-229x300.png" alt="Oâ€™Reilly in text above the book title, which reads Building Knowledge Graphs: A Practitionerâ€™s Guide. Image of horned goat lunging forward behind the Neo4j logo. Authors are JesÃºs Barrasa &amp; Jim Webber." width="150" srcset="https://dist.neo4j.com/wp-content/uploads/20240722074429/Building-Knowledge-Graphs-ebook-cover-229x300.png 229w, https://dist.neo4j.com/wp-content/uploads/20240722074429/Building-Knowledge-Graphs-ebook-cover-114x150.png 114w, https://dist.neo4j.com/wp-content/uploads/20240722074429/Building-Knowledge-Graphs-ebook-cover-600x787.png 600w, https://dist.neo4j.com/wp-content/uploads/20240722074429/Building-Knowledge-Graphs-ebook-cover.png 762w" sizes="(max-width: 229px) 100vw, 229px"></a></p><p>To master the concepts and techniques behind knowledge graphs and get hands-on experience, download a free copy of the Oâ€™Reilly book <a href="https://neo4j.com/knowledge-graphs-practitioners-guide/" target="_blank" rel="noopener">Building Knowledge Graphs: A Practitionerâ€™s Guide</a> by JesÃºs Barrasa and Jim Webber.  </p>
<p>The guide covers how to build, manage, query, analyze, and visualize your knowledge graph so you can develop data-backed applications and advanced analytics.</p>

<p><strong><a href="https://neo4j.com/knowledge-graphs-practitioners-guide/" rel="noopener" target="_blank">Get My Copy</a></strong></p>

<br><h2><strong>Learning Resources</strong></h2>
<ul><ul><li><a href="https://github.com/jbarrasa/goingmeta" target="_blank" rel="noopener">Semantics workshops</a> on GitHub.</li>
<li><a href="https://www.youtube.com/watch?v=05Wkg1p34ek" target="_blank" rel="noopener">Ontology-Based Reasoning 101</a>. </li>
<li><a href="https://www.youtube.com/watch?v=05Wkg1p34ek" target="_blank" rel="noopener">Ontology-driven Knowledge Graph Construction</a>.</li>
<li><a href="https://graphacademy.neo4j.com/" target="_blank" rel="noopener">GraphAcademy</a> for knowledge graph fundamentals using a property graph model in the Neo4j Graph Database.</li></ul></ul>          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Good programmers worry about data structures and their relationships (213 pts)]]></title>
            <link>https://read.engineerscodex.com/p/good-programmers-worry-about-data</link>
            <guid>41268803</guid>
            <pubDate>Fri, 16 Aug 2024 18:09:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://read.engineerscodex.com/p/good-programmers-worry-about-data">https://read.engineerscodex.com/p/good-programmers-worry-about-data</a>, See on <a href="https://news.ycombinator.com/item?id=41268803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em>Engineerâ€™s Codex is a publication about real-world software engineering.</em></p><p>I recently came across a quote by Linus Torvalds (creator of Linux and Git) that  succinctly described a problem Iâ€™ve been working on recently:</p><blockquote><p><em>"Bad programmers worry about the code. Good programmers worry about data structures and their relationships."</em></p></blockquote><p><span>Right before the above quote, Linus said:</span><br></p><blockquote><p><em>git actually has a simple design, with stable and reasonably well-documented data structures. In fact, I'm a huge proponent of designing your code around the data, rather than the other way around, and I think it's one of the reasons git has been fairly successful [â€¦] I will, in fact, claim that the difference between a bad programmer and a good one is whether he considers his code or his data structures more important.</em></p></blockquote><p>Good data structures make code easier to design and maintain. It makes software more reliable, systems more understandable, and code more readable. When designing any software, application logic often follows the data model. Treating the data model as an afterthought results in more work down the line. The inverse is true also - having a well-thought out data model makes migrations and building on top of complex systems easier down the line.</p><p>When I read this quote, I actually was able to recognize countless examples in the past of this. I once worked on a project where we spent quite a while optimizing complex algorithms, only to realize that by restructuring our data, we could eliminate entire classes of problems. We replaced a 500-line function with a 50-line function and a well-designed data structure. Not only was the new code faster, but it was also much easier to understand and maintain.&nbsp;(Of course, then the problem also shifted â€œdown the stackâ€ to where the majority of toil was in restructuring existing data.)</p><p><span>Another relevant quote here is in </span><em>The Art of Unix Programming</em><span>:&nbsp;</span></p><blockquote><p>Rule of Representation: Fold knowledge into data so program logic can be stupid and robust.</p><p>Even the simplest procedural logic is hard for humans to verify, but quite complex data structures are fairly easy to model and reason about. To see this, compare the expressiveness and explanatory power of a diagram of (say) a fifty-node pointer tree with a flowchart of a fifty-line program. Or, compare an array initializer expressing a conversion table with an equivalent switch statement. The difference in transparency and clarity is dramatic. See Rob Pike's Rule 5.</p><p><strong>Data is more tractable than program logic. It follows that where you see a choice between complexity in data structures and complexity in code, choose the former. More: in evolving a design, you should actively seek ways to shift complexity from code to data.</strong></p><p>The Unix community did not originate this insight, but a lot of Unix code displays its influence. The C language's facility at manipulating pointers, in particular, has encouraged the use of dynamically-modified reference structures at all levels of coding from the kernel upward. Simple pointer chases in such structures frequently do duties that implementations in other languages would instead have to embody in more elaborate procedures.</p></blockquote><p><span>The </span><strong>actionable tip here is to start with the data. </strong><span>Try to reduce code complexity through stricter types on your interfaces or databases. Spend extra time thinking through the data structures ahead of time. </span></p><p><span>Thatâ€™s not to say the </span><em>code isnâ€™t important</em><span>. Obviously, everything is important - but itâ€™s useful to have a strong high-level approach of how data will flow and how different components interact before going deeper into code-related details.&nbsp;</span></p><p><span>Itâ€™s why one of the </span><em>Senior Engineer (L5)</em><span> requirements (at least for FAANG) generally involves writing higher-level design docs for more complex systems (which includes driving team planning and building good roadmaps for medium-to-large features). </span></p><p><span> from </span></p><p><span> wrote a great piece on the higher level of influence L5s generally have here:</span></p><p><span> from </span></p><p><span> also wrote a great piece about getting to Senior Engineer: </span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Banks Are Now Accused of Cheating Customers Billions (147 pts)]]></title>
            <link>https://franknez.com/massive-banks-are-now-accused-of-cheating-customers-billions/</link>
            <guid>41268800</guid>
            <pubDate>Fri, 16 Aug 2024 18:08:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://franknez.com/massive-banks-are-now-accused-of-cheating-customers-billions/">https://franknez.com/massive-banks-are-now-accused-of-cheating-customers-billions/</a>, See on <a href="https://news.ycombinator.com/item?id=41268800">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
		
<p>Massive banks are now accused of cheating customers billions of dollars in interest payments according to financial reports. </p>



<p>According to a new report by <em>Financial Times</em>, several major Wall Street banks, including <strong><a href="https://franknez.com/wells-fargo-is-now-freezing-bank-accounts-in-new-scandal/">Wells Fargo</a></strong>, Morgan Stanley, and <strong><a href="https://franknez.com/bank-of-america-is-freezing-accounts-in-new-scandal/">Bank of America</a></strong>, are accused of defrauding customers out of billions of dollars in interest payments.</p>



<p>The U.S. <strong>Securities and Exchange Commission</strong> (SEC) is currently investigating these banks to determine whether they intentionally steered clients toward <em>â€œcash sweepâ€</em> accounts that provided little to no interest earnings, despite the availability of higher-yielding options.</p>



<p>This alleged practice by the banks would amount to bilking customers out of significant sums of interest income that they should have rightfully earned on their deposits and cash holdings. </p>



<p>The SECâ€™s probe is aimed at uncovering whether this was a deliberate strategy by the banks to boost their own profits at the expense of their clients.</p>



<p>The <a href="https://www.ft.com/content/de751907-c870-4b8c-b86b-317483f7626f" target="_blank" rel="noreferrer noopener">report</a> in the Financial Times highlights the concerning allegations of widespread misconduct by some of the largest financial institutions on Wall Street.</p>



<p>If substantiated, this could represent a major scandal involving the potential exploitation of customers through the mismanagement of their cash accounts and interest earnings.</p>



<p>The SECâ€™s investigation will be crucial in determining the full scope and nature of these alleged practices, as well as any potential enforcement actions or penalties that may be levied against the implicated banks.</p>



<p>The revelations have emerged from new Quarterly filings with the SEC.</p>



<p>In those filings, Wells Fargo says itâ€™s in <em>â€œresolution talksâ€</em> with the agency over the issue, Morgan Stanley says the agency began asking questions about it in April and Bank of America confirms itâ€™s currently being scrutinized.</p>



<p>All three banks have declined to comment on the matter.</p>



<p>Other financial firms involved in lawsuits related to cash sweep accounts include LPL Financial and Ameriprise.</p>



<p>LPL Financial says it plans to <em>â€œvigorouslyâ€</em> defend itself against the allegations, while Ameriprise has not released a public statement on the matter.</p>



<p>For more <strong><a href="https://franknez.com/us-bank-news-today/">U.S. Bank news</a></strong> and updates like this, opt-in for push notifications.</p>



<p><strong>Also Read:&nbsp;<a href="https://franknez.com/the-us-treasury-direct-is-now-freezing-customer-accounts/" target="_blank" rel="noreferrer noopener">The US Treasury Direct is Now Freezing Customer Accounts</a></strong></p>



<h2 id="h-other-banking-news-today"><strong>Other Banking News Today</strong></h2>



<figure><picture><source sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp" data-srcset="https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-1024x573.jpg.webp 1024w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-300x168.jpg.webp 300w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-768x430.jpg.webp 768w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-676x379.jpg.webp 676w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default.jpg.webp 1100w"><img decoding="async" width="1024" height="573" src="https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-1024x573.jpg" alt="Market News Today - Massive Banks Are Now Accused of Cheating Customers Billions." srcset="https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-1024x573.jpg 1024w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-300x168.jpg 300w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-768x430.jpg 768w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-676x379.jpg 676w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default.jpg 1100w" sizes="(max-width: 1024px) 100vw, 1024px" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAI9AQAAAACMUjdnAAAAAnRSTlMAAHaTzTgAAABeSURBVHja7cExAQAAAMKg9U9tDB+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgbCDMAAHzbk7nAAAAAElFTkSuQmCC" data-src="https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-1024x573.jpg" data-srcset="https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-1024x573.jpg 1024w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-300x168.jpg 300w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-768x430.jpg 768w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default-676x379.jpg 676w, https://franknez.com/wp-content/uploads/2024/07/Massive-US-Banks-Now-Prepare-For-Millions-to-Default.jpg 1100w"></picture><figcaption>Market News Today â€“ Massive Banks Are Now Accused of Cheating Customers Billions.</figcaption></figure>



<p>Massive US banks now prepare for millions to default according to Q2 reports, as institutions increase capital to cover insolvencies.</p>



<p>Big banks such as <strong><a href="https://franknez.com/jpmorgan-is-freezing-customer-bank-accounts-in-new-scandal/">JPMorgan Chase</a></strong>, <strong><a href="https://franknez.com/bank-of-america-is-freezing-accounts-in-new-scandal/">Bank of America</a></strong> and <strong><a href="https://franknez.com/wells-fargo-is-now-freezing-bank-accounts-in-new-scandal/">Wells Fargo</a></strong> are boosting their financial defenses as they prepare for customer inflow to dwindle, affecting the ability for the average American to pay their bills.</p>



<p>According to the latest Q2 2024 financial reports from major banks, they are significantly increasing the amount of capital they are setting aside to cover potential losses from rising credit card and loan defaults.</p>



<p>Collectively, these banks are allocating billions of dollars into emergency provisions and loan loss reserves to prepare for an anticipated increase in insolvencies and non-performing loans. </p>



<p>This reflects the banksâ€™ growing concerns about the potential for a rise in credit card delinquencies and loan defaults in the coming months.</p>



<p>By bolstering their loss-absorbing capital buffers, the banks are attempting to proactively mitigate the financial risks posed by a potential surge in credit-related delinquencies and insolvencies. </p>



<p>This suggests the banks foresee a deterioration in consumer credit quality and are taking prudent steps to strengthen their balance sheets and resilience against such adverse credit trends.</p>



<p>The significant increase in these emergency loan loss provisions across the banking sector signals that the institutions are bracing for a potential economic downturn that could lead to a rise in loan defaults and credit-related write-offs.</p>



<p>This move underscores the banksâ€™ efforts to position themselves to better withstand any upcoming challenges in the credit markets.</p>



<p>JPMorgan Chase is leading the way, increasing its provisions from $1.88 billion in the first quarter of this year to $3.05 billion â€“ a $1.17 billion jump.</p>



<p>Meanwhile, Bank of America has set aside $1.5 billion, up from $1.3 billion in the previous quarter, and Wells Fargo set aside $1.24 billion, up from $938 million in the previous quarter.</p>



<p>The increasing balances show banks are anticipating increasing economic risk in the months ahead as commercial real estate flounders and as consumers pile up a&nbsp;whopping&nbsp;$1.02 trillion in credit card balances, according to <a href="https://newsroom.transunion.com/ciir-q1-2024/" target="_blank" rel="noreferrer noopener">TransUnion</a>.</p>



<p>Delinquency rates across various types of debt are already on the rise, and the New York Federal Reserve&nbsp;<a href="https://www.newyorkfed.org/newsevents/news/research/2024/20240514" rel="noreferrer noopener" target="_blank">says</a>&nbsp;total US household debt hit $17.69 trillion in the first quarter of this year, an increase of $184 billion from the previous quarter.</p>



<p>The number includes mortgage balances, which rose by $190 billion to $12.44 trillion, and auto loans, which increased by $9 billion to $1.62 trillion.</p>



<p><strong>Also Read: <a href="https://franknez.com/a-massive-us-bank-is-now-closing-credit-cards/" target="_blank" rel="noreferrer noopener">A Massive US Bank is Now Closing Credit Cards</a></strong></p>



<div><p>
<h2 id="h-market-news-published-daily"><strong>Market News Published Daily</strong> ðŸ“°</h2>
</p></div>



<figure><picture><source sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp" data-srcset="https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-1024x574.jpg.webp 1024w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-300x168.jpg.webp 300w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-768x431.jpg.webp 768w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-676x379.jpg.webp 676w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez.jpg.webp 1100w"><img decoding="async" width="1024" height="574" src="https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-1024x574.jpg" alt="Market News Today - Massive Banks Are Now Accused of Cheating Customers Billions." srcset="https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-1024x574.jpg 1024w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-300x168.jpg 300w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-768x431.jpg 768w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-676x379.jpg 676w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez.jpg 1100w" sizes="(max-width: 1024px) 100vw, 1024px" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAI+AQAAAAAKxkXJAAAAAnRSTlMAAHaTzTgAAABeSURBVHja7cEBAQAAAIIg/69uSEABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMC7ASFNAAFLuj9gAAAAAElFTkSuQmCC" data-src="https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-1024x574.jpg" data-srcset="https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-1024x574.jpg 1024w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-300x168.jpg 300w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-768x431.jpg 768w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez-676x379.jpg 676w, https://franknez.com/wp-content/uploads/2023/08/Daily-Market-News-FrankNez.jpg 1100w"></picture><figcaption>Market News Today â€“ Massive Banks Are Now Accused of Cheating Customers Billions.</figcaption></figure>



<p>Donâ€™t forget to opt-in for push notifications so you donâ€™t miss a single article!</p>



<p>Be sure to share this article with your community.</p>



<p>We are tirelessly working on providing you with the latest market news as well as local news to keep you informed about job cuts, bankruptcies, and store closures in your area.</p>



<p>Also, thank you to all of our <strong><a href="https://www.patreon.com/FrankNezMedia" target="_blank" rel="noreferrer noopener">blog sponsors</a></strong>.</p>



<p>This year weâ€™ve been able to increase push notifications slots making it more convenient than ever for new readers to receive their daily market news and updates.</p>



<p>Our readers can now <strong><a href="https://www.patreon.com/FrankNezMedia" target="_blank" rel="noreferrer noopener">donate $3 per month</a></strong> to support independent journalism.</p>



<p>For daily news and updates on your favorite stories, opt-in for push notifications.</p>



<p><strong>Follow Frank Nez on</strong>&nbsp;<a href="https://twitter.com/FNez_Blogger" target="_blank" rel="noreferrer noopener"><strong>X (Twitter)</strong></a>,&nbsp;<a href="https://www.instagram.com/iamfranknez/" target="_blank" rel="noreferrer noopener"><strong>Instagram</strong></a>,&nbsp;or <strong><a href="https://www.facebook.com/NezMediaCompany/" target="_blank" rel="noreferrer noopener">Facebook</a></strong>. </p>







<hr>


<div>
<figure><picture><source sizes="(max-width: 512px) 100vw, 512px" type="image/webp" data-srcset="https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3.png.webp 512w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-300x300.png.webp 300w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-150x150.png.webp 150w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-270x270.png.webp 270w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-192x192.png.webp 192w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-180x180.png.webp 180w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-32x32.png.webp 32w"><img decoding="async" width="512" height="512" src="https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3.png" alt="" srcset="https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3.png 512w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-300x300.png 300w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-150x150.png 150w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-270x270.png 270w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-192x192.png 192w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-180x180.png 180w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-32x32.png 32w" sizes="(max-width: 512px) 100vw, 512px" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIAAQAAAADcA+lXAAAAAnRSTlMAAHaTzTgAAAA2SURBVHja7cEBAQAAAIIg/69uSEABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHwbggAAAWN1UKQAAAAASUVORK5CYII=" data-src="https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3.png" data-srcset="https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3.png 512w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-300x300.png 300w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-150x150.png 150w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-270x270.png 270w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-192x192.png 192w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-180x180.png 180w, https://franknez.com/wp-content/uploads/2023/03/cropped-Frank-Nez-Market-News-Icon-3-32x32.png 32w"></picture></figure></div>


<h2 id="h-support-independent-journalism"><strong><a href="https://www.patreon.com/FrankNezMedia" target="_blank" rel="noreferrer noopener">Support Independent Journalism</a></strong> âœðŸ»</h2>



<p>Support independent journalism for just $3 per month!</p>



<p>Your contributions help power Franknez.com as the cost of widgets and online tools continue to rise.</p>



<p>Thank you for your support!</p>







<hr>



<h3 id="h-recommended-for-you"><strong>Recommended For You âœ¨</strong></h3>


<div><ul><li><a href="https://franknez.com/the-us-treasury-direct-is-now-freezing-customer-accounts/"><p><span>The US Treasury Direct is Now Freezing Customer Accounts</span></p></a></li><li><a href="https://franknez.com/snap-benefits-will-now-increase-for-the-year-2024/"><p><span>SNAP Benefits Will Now Increase For The Year 2024</span></p></a></li><li><a href="https://franknez.com/california-now-has-massive-departures-as-hundreds-of-thousands-leave/"><p><span>California Now Has Massive Departures As Hundreds of Thousands Leave</span></p></a></li><li><a href="https://franknez.com/a-us-bank-is-now-denying-customers-access-to-money/"><p><span>A US Bank is Now Denying Customers Access to Money</span></p></a></li><li><a href="https://franknez.com/a-giant-company-now-announces-unexpected-layoffs-in-virginia/"><p><span>A Giant Company Now Announces Unexpected Layoffs in Virginia</span></p></a></li><li><a href="https://franknez.com/a-massive-us-bank-is-now-closing-credit-cards/"><p><span>A Massive US Bank is Now Closing Credit Cards</span></p></a></li></ul></div>

<div><picture><source type="image/webp" data-srcset="https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-300x168.jpg.webp 300w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-1024x573.jpg.webp 1024w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-768x430.jpg.webp 768w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-676x379.jpg.webp 676w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees.jpg.webp 1100w"><img decoding="async" src="https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-300x168.jpg" srcset=" https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-300x168.jpg 300w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-1024x573.jpg 1024w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-768x430.jpg 768w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-676x379.jpg 676w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees.jpg 1100w " alt="Donald Trump Now Plans To End Social Security Taxes For Retirees" data-eio="l" data-old-src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAACoAQAAAAByUO6iAAAAAnRSTlMAAHaTzTgAAAAdSURBVFjD7cExAQAAAMKg9U9tCy+gAAAAAAAAeBgZmAABPsQcywAAAABJRU5ErkJggg==" data-src="https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-300x168.jpg" data-srcset="https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-300x168.jpg 300w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-1024x573.jpg 1024w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-768x430.jpg 768w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees-676x379.jpg 676w, https://franknez.com/wp-content/uploads/2024/08/Donald-Trump-Now-Plans-To-End-Social-Security-Taxes-For-Retirees.jpg 1100w"></picture></div>




<hr>

							
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Apple IIGS Megahertz Myth (164 pts)]]></title>
            <link>https://www.userlandia.com/home/iigs-mhz-myth</link>
            <guid>41268256</guid>
            <pubDate>Fri, 16 Aug 2024 17:08:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.userlandia.com/home/iigs-mhz-myth">https://www.userlandia.com/home/iigs-mhz-myth</a>, See on <a href="https://news.ycombinator.com/item?id=41268256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-d3767bee736bb4906a02">

<p>Thereâ€™s many legends in computer history. But a legend is nothing but a story. Someone tells it, someone else remembers it, and everybody passes it on. And the Apple IIGS has a legend all its own. Here, in Userlandia, weâ€™re going to bust some megahertz myths.</p>




















  
  



</div><div data-block-type="2" id="block-yui_3_17_2_1_1722774331649_10942">
  <p><em>[A side note before proceedingâ€¦ I see all you Hacker News people filing in. I havenâ€™t had the time recently to properly format this with the numerous source links, citations, and footnotes that exist in the video version. Iâ€™ll try to get those filled in here ASAP. For now, you might want to experience it all in the video version.]</em></p><p>I love the Apple IIGS. Itâ€™s the fabulous home computer youâ€™d have to be crazy to hate. One look at its spec sheet will tell you why. The Ensoniq synthesizer chip brings 32 voices of polyphonic power to the desktop. Appleâ€™s Video Graphics Controller paints beautiful on-screen pictures from a palette of thousands of colors. Seven slots and seven ports provide plenty of potential for powerful peripherals. These ingredients make a great recipe for a succulent home computer. But you canâ€™t forget the most central ingredient: the central processing unit. Itâ€™s a GTE 65SC816 clocked at 2.8 MHzâ€”about 2.72 times faster than an Apple IIe. When the IIGS launched in September 1986 its contemporaries were systems like the Atari 1040ST, the Commodore Amiga 1000, and of course Appleâ€™s own Macintosh Plus. These machines all sported a Motorola 68000 clocked between 7 and 8 MHz. If I know anything about which number is bigger than the other number, Iâ€™d say that Motorolaâ€™s CPU is faster.</p><p>â€œNow hold on there,â€ you say! â€œMegahertz is just the clock speed of the chipâ€”it says nothing about how many instructions are actually executed during those cycles, let alone the time spent reading and writing to RAM!â€ And you know what, thatâ€™s true! The Apple II and Commodore 64 with their 6502 and 6510 CPUs clocked at 1 MHz could trade blows with Z80 powered computers running at three times the clock speed. And the IIGS had the 6502â€™s 16-bit descendant: the 65C816. Steve Wozniak thought Western Design Center had something special with that chip. <a href="https://archive.org/details/BYTE_Vol_10-01_1985-01_Through_The_Hourglass/page/166/mode/2up" target="_blank">In a famous interview in the January 1985 issue of Byte magazine</a>, Woz said, </p><blockquote><p>â€œ[the 65816] should be available soon in an 8 MHz version that will beat the pants off the 68000 in most applications, and in graphics applications it comes pretty close.â€ End quote. Thatâ€™s already high praise, but he continues further: â€œAn 8 MHz 65816 is about equivalent to a 16 MHz 68000 in speed, and a 16 MHz 68000 doesnâ€™t exist.â€</p></blockquote><p>If you read this in January of 1985 youâ€™d have little reason to doubt Wozâ€™s words. He built the Apple I in a bedroom from a box of scraps and when given real resources followed it up with the Apple II. Even when faced with doubters, heâ€™s got the confidence that comes from engineering the impossible. </p><blockquote><p>â€œSome of the Macintosh people might disagree with me, but there are ways around most of the problems they see.â€</p></blockquote><p>But that â€œshouldâ€ in â€œshould be availableâ€ was doing a lot of work. <a href="https://mirrors.apple2.org.za/ftp.apple.asimov.net/documentation/magazines/aplus/A%2B%201986-11.pdf" target="_blank">Eighteen months later when the IIGS finally shipped, there was no 8 MHz â€˜816.</a> It was as nonexistent as Wozâ€™s imaginary 16MHz 68000. 8MHz chips were barely available three years later. What happened? Woz promised us 8 MHz of 68000-crushing glory!</p><p>If you poll a random vintage computer user they might posit the idea that Apple held the IIGSâ€™ processor speed back during its development so it wouldnâ€™t compete with the Macintosh. <a href="https://en.wikipedia.org/wiki/Apple_IIGS#Hardware" target="_blank">Thereâ€™s an unsourced claim on Wikipedia that limiting the CPU speed to 2.8MHz was a deliberate decision</a> followed by a noteâ€”which <em>is</em> sourced, thank you very muchâ€”that the original CPU was certified to run at 4MHz. And thatâ€™s trueâ€”thereâ€™s many IIGSes that have CPUs labeled for 4MHz. This ideaâ€™s made its way through various newsgroups and webpages for decades, so itâ€™s no surprise that it made its way into a Wiki article too.</p><p>But this theory never sat well with me. People making the claim that Apple restrained the IIGSâ€™ CPU speed for marketing purposes rarely provide sources to back it up. I understand their logicâ€”Apple spent the majority of its marketing and monetary might making the Macintosh the machine of the future. Because the Mac was Steve Jobsâ€™ baby, you end up with declarations like â€œSteve Jobs hobbled the IIGS so it wouldnâ€™t compete with the Mac.â€ Itâ€™s a common take, especially because it plays into a lot of peopleâ€™s dislike of Jobs. But thereâ€™s one major problem with it: all of Steve Jobsâ€™ power at Apple was stripped away in May of 1985 after the months of executive turmoil that led to the company's first quarterly loss. The IIGS didn't launch until 16 months later.</p><p>So why were IIGSes with chips rated at 4 MHz not running them at that speed? Why 2.8 MHz? Isn't thatâ€¦  <em>weirdly</em> specific? Did an 8 MHz machine really get put on ice due to executive meddling? To solve these mysteries I descended into the depths of Usenet, usergroup newsletters, magazines, and interviews. My journey took me through a world of development Hell, problematic yields, and CPU cycle quirks. And this walk down the Apple chip road starts with the wonderful wizard named Woz.</p><h2>The Apple IIx</h2><p>Itâ€™s the summer of 1983 and Steve Wozniak has just wrapped up a two year leave of absence from Apple Computer. It all started with a six week stint in the hospital <a href="https://www.ntsb.gov/Pages/brief.aspx?ev_id=27749&amp;key=0" target="_blank">after crashing his Beechcraft Bonanza airplane on February 7, 1981</a>. <a href="http://ns1.woz.com/letters/memory-loss/" target="_blank">Amnesia from a hard concussion short-circuited Wozniakâ€™s short-term memory</a>. After his recovery he took a leave from Apple <a href="https://engineering.berkeley.edu/steve-wozniak-inventor-and-apple-co-founder/" target="_blank">to go back to UC Berkeley and finish his degree in computer science and electrical engineering</a>â€¦ and run a few rock festivals. By June of 1983 Woz felt he was ready to return to work, and asked Dave Paterson, the head of Apple II engineering, for a jobâ€”but this time, in the trenches.</p><p>His timing was excellent. Even though the Lisa was taking headlines and the Macintosh was shaking up R&amp;D, the Apple II was making all the money. Brisk sales of the IIe along with the imminent launch of the IIc meant the Apple II division was busier than ever even if they werenâ€™t getting all the glory. And while Steve Jobs was heralding the Mac as the Next Big Thing, designing a next-generation Apple II as a contingency plan was just good business.</p><p>At the heart of this proposed machine was a brand new CPU. Bill Menschâ€™s Western Design Center was busy developing the 65816, a 16-bit update to the venerable 6502 architecture. This chip would bring 16-bit computing to the Apple II while promising backwards compatibility. Users wouldnâ€™t lose their investment in applications, add-in cards, or accessories. Alongside the new CPU was a special coprocessor slot that allowed the user to install a board with a 68000 or 8088. <a href="https://archive.org/details/The_Apple_IIgs_Book_Jeanne_DuPrau/page/n17/mode/2up" target="_blank">The goal was to build a bridge between the 8- and 16-bit world, so the project had code names like Brooklyn and Golden Gate</a>. </p><p>This project would be known publicly as the IIx thanks to Wozniak discussing it on CompuServe or at user groups. But as late â€™83 rolled into early â€™84 the IIx project stumbled over multiple roadblocks. The coprocessor slot added layers of complexity that distracted from the mission of architecting a new Apple II. But a major complication was the 65816 itself. Apple expected engineering samples in November 1983, but didnâ€™t actually get them until February 1984. Whatâ€™s worse, those late chips were buggy, unstable, and ultimately unusable. WDC delivered a second batch of chips a few weeks later, but they were no more reliable than the first.</p><p>Even if Apple abandoned the coprocessor slot, the project couldnâ€™t go forward without a CPU, and Apple cancelled the IIx project in March of 1984. Now before you aim your ire at Steve Jobs, <a href="https://mirrors.apple2.org.za/ftp.apple.asimov.net/documentation/magazines/aplus/" target="_blank">A+ Magazine, in their IIGS development history</a>, says it was the team leads who suggested canning the troubled machine. With no managerial appetite for a next-generation machine, the Apple II team pivoted from a moonshot to something more achievable. Dan Hillman and Jay Rickard started a project to consolidate most of the discrete chips of an Apple II into a single chip called the Mega II. When they finished the design six months later they werenâ€™t quite sure what to do with it. Would they reduce the cost of the IIe or reduce the size of the IIc?</p><p>Imagine their surprise when Woz suggested a second shot at a 16-bit Apple II. The conditions seemed right to give it another go. Less expensive 16-bit computers like the Atari ST were looming on the horizon and the Macâ€™s hot start was slowing down. By October 1984 Apple finally had a good supply of working 65816 CPUs to design a system. And the Mega II would free up a lot of board space to add new graphics and sound chips. But just as important as chips and specs was a new, focused mission statement. This computer would be an Apple II by Apple II fans for Apple II fans. Woz, Hillman, Rickard, Harvey Leitman, and Lee Collings spent the rest of 1984 hammering out the specifications and solving hard problems like how to speed up memory access without breaking existing software.</p><p>Now weâ€™re finally back to that Woz interview I quoted earlier. Byte published it in two parts across the December â€™84 and January â€™85 issues, and based on the average time to press I reckon it took place in October 1984. By this point the IIx is dead and buried and heâ€™s talking about the new 16-bit Apple II, now codenamed Phoenix. His excitement about an 8MHz â€˜816 is palpable, but, again, Woz was careful to say it â€œ<em>should</em> be available soon.â€ Woz left Apple in February 1985 when the ink for this interview was barely dry. He had a dramatic fight with John Sculley after the Apple II was snubbed at the annual Apple shareholderâ€™s meeting in January 1985. Apple II sales supplied seventy percent of Appleâ€™s revenue in 1984 and Wozâ€™s Apple II compatriots felt they werenâ€™t getting their due. Steve Jobs may not have dialed back the IIGSâ€™ clock speed, but he <em>did</em> shovel endless piles of money towards his pet projects at the expense of the Apple II. Even if Woz had stuck around the 8 MHz â€˜816 of his dreams was years away. The IIGS wouldnâ€™t sniff 8 MHz until Applied Engineering released the 7 MHz TransWarp GS accelerator four years later in 1989.</p><h2>The Need for Speed</h2><p><a href="https://www.applefritter.com/content/apple-iigs-bad-onboard-ram" target="_blank">If you go looking online for photos of Apple IIGS logic boards</a>, thereâ€™s a decent chance youâ€™ll see a 4MHz GTE G65SC816 CPU. Most IIGSes had 4 or 3 MHz CPUs running at 2.8 MHz regardless of the chipâ€™s rated speed. Why?</p><p>First, we must understand where that clock signal comes from. The IIGS, like many computers of its era, derives its base clock from a crystal oscillator. The one in the IIGS vibrates 28.636 million times per second, or megahertz. The VGC divides that 28.636 megahertz in half, and 14.318 MHz is then supplied along with a stretch signal to other parts of the system. I bet you've already noticed that these frequencies are multiples of the NTSC colorburst frequency of 3.58MHz. Keep that in mind, itâ€™ll be relevant later.</p><p>This 14.318 MHz clock travels to a special ASIC whichâ€”depending on your board revisionâ€”is called the Fast Processor Interface or Control Your Apple chip. One of its responsibilities is dynamically controlling the CPUâ€™s clock speed. The IIGS normally runs in Fast mode at 2.8 MHz, but the user can switch to Normal mode in the Control Panel which reduces the speed to 1.023 MHz. Itâ€™s like the turbo switch on PCs, except controlled by the FPI. This lets the IIGS run speed-sensitive software at the same speed of an original Apple II. But even in fast mode there are times the CPU needs to slow down to access other parts of the system.</p><p>The CPU, ROM, and Fast RAM are on the 2.8 MHz, or fast side, while the Mega II chip, slots, sound, video, and so on are on the 1MHz, or slow side. When the CPU is running in fast mode and needs to talk to something on the slow side the FPI dynamically throttles the clock signal to a 1 MHz cycle time to let the CPU synchronize with the Mega II side. This is usually invisible to the user because the system still executes the majority of its cycles at the faster speed, but it means the CPU is not always executing as fast as it could. I havenâ€™t even touched on the eight percent performance penalty from the cycles the FPI spends refreshing RAM.</p><p>Thereâ€™s nothing inherent to this design that limits the system to 2.8 MHz. The <a href="https://archive.org/details/Apple_IIgs_Hardware_Reference_HiRes/page/n47/mode/2up" target="_blank">Apple IIGS Hardware Reference</a>, <a href="http://www.brutaldeluxe.fr/documentation/cortland/v5/Cortland%20Custom%20ICs%20-%20Wayne%20Lowry%20-%20Preliminary%20notes%20-%2019860214.pdf" target="_blank">Wayne Lowryâ€™s Cortland Custom IC Notes</a>, and <a href="https://www.kansasfest.org/2012/04/2011-krue-fpi/" target="_blank">Daniel Kruszynaâ€™s KansasFest 2011</a> presentation about the FPI lay it out clearly that the IIGSâ€™s fast mode could support higher speeds. In principle a redesigned FPI or CYA could use a divider other than 1/5 for the clock signal. A 1/4 divider of 14.318 MHz yields a 3.58 MHz clock speed, which should be well within the capabilities of a 4 MHz chip. And once again, that â€œshouldâ€ is doing a lot of work. So why didnâ€™t it run at that speed?</p><h2>The Birth of the 65C816</h2><p>The 65C816 and IIGS are inextricably linked, and the â€˜816â€™s story starts in 1981 when GTEâ€™s Desmond Sheahan approached Bill Mensch and Western Design Center about designing a CPU. GTE wanted to manufacture their own chips for their key phone systems, so they licensed both a CMOS manufacturing process and a 6802 CPU design from Mitel. But Mitelâ€™s CPU design team wasnâ€™t up to the task, so GTE asked Mensch to step in. Mensch offered two options: a two-chip 6802 solution or a 6502-based microcontroller. Either one could be manufactured on the CMOS process GTE licensed from Mitel. Sheahan convinced the GTE brass that the one-chip solution was the way to go, and the 65C02 was born.</p><p>GTE became the first licensee of the 65C02 thanks to WDC designing their 65SC150 telephony microcontroller. Eventually WDC would license the core to other companies, like NCR, Synertek, and Rockwell. The result was WDC netting a royalty every time one of these licensees sold a standalone CPU or microcontroller with its 65C02 core. Functional 65C02 silicon was available in 1982, and the revenues from licensing deals were finally filling up WDCâ€™s coffers. This is whenâ€”<a href="https://www.computerhistory.org/collections/catalog/102739969" target="_blank">according to Menschâ€™s Computer History Museum oral history and other sources</a>â€”Apple approached him about a 16-bit successor to the 6502.</p><p>The prospect of a big player like Apple being the launch client for a new CPU was hard to resist. Further information on the early days of the â€˜816 is fairly elusive, but looking at both historic and contemporary interviews with Mensch and Woz reveals Appleâ€™s influence on the chipâ€™s design. One influence was compatibility. When designing the â€˜816 <a href="https://mirrors.apple2.org.za/apple2.caltech.edu/miscinfo/65xxx.chronology" target="_blank">Mensch improved the 6502 bus architecture</a> to eliminate little weirdnesses like false read cycles on store accumulators. This consequently broke Steve Wozniakâ€™s Disk II controller, which had been designed to rely specifically on that exact weirdness.</p><p>Now thereâ€™s two ways to solve this problem: redesign the floppy controller, or add the weirdnesses back in. Apple tried the first one; redesigning its floppy controller into a single chip called the Integrated Woz Machine. This chip was made independently for the Apple IIc to control its built-in floppy drive. <a href="http://www.brutaldeluxe.fr/documentation/iwm/iwm_discussion_19820531" target="_blank">Among its many improvements was eliminating the false read cycle requirement</a>. The Apple IIx could have used an IWM, but the UniDisk drives that took advantage of it wouldnâ€™t be out until 1985. Therefore existing Disk II interfaces and drives still had to work with the IIx. If you were to claim Apple II compatibility, but not be able to work with one of the most popular boards, well, thereâ€™d be protests lining the sidewalks of De Anza Boulevard. Other cards might also depend on specific 6502 timing behaviors. <a href="https://www.commodore.ca/commodore-history/bill-mench-the-brains-behind-the-brains/" target="_blank">Mensch eventually honored Appleâ€™s request that the 65C816 be fully compatible with the NMOS 6502â€™s timings</a>.</p><p>Apple wouldnâ€™t be Menschâ€™s only licensee for the â€˜816â€”the core can be found in countless embedded systems and microcontrollers. Licensees could extend the core to customize it into a microcontroller or a system-on-chip, or add features specific to their needs. A great example is Ricoh, who licensed the â€˜816 core and added several functions, like dedicated multiply and divide units along with special DMA functions. All these add-ons were at the request of a pretty famous customer: Nintendo. The result was <a href="https://sneslab.net/wiki/65c816" target="_blank">the Ricoh 5A22, the CPU inside the Super NES</a>.</p><p>One of the famous tales of the â€˜816â€™s development is how it was laid out without computer aided design. As told by Bill Mensch, he designed the â€˜816 on a card table at WDCâ€™s humble headquarters in Mesa, Arizona. His sister Katherine did the layout on mylar sheets. Many semiconductor designers had moved on to computer aided design tools to help design and lay out their circuits. Mensch is rightly proud of this feat, but the decision to lay it out by hand with mylar and rubylith wasnâ€™t without consequences.</p><p>Letâ€™s circle back to that interview with Woz. <a href="https://archive.org/details/gteg65sc816datasheetocrbm/mode/2up" target="_blank">GTE published data sheets in 1985 for the G65SC816</a> which detailed 2, 4, 6, and 8 MHz variants of the chip. Apple, as the prime customer, wouldâ€™ve had these data sheets far in advance. This would be consistent with Wozâ€™s belief that faster variants were on the way, but for purposes of designing the IIGS they had to settle for 4MHz chips. Multiple photographs of IIGS prototype logic boards with 4MHz chips are on the web, and 4MHz parts shipped in production IIGS computers. But the promise of a faster CPU is very tantalizing to a computer designer, and Iâ€™m sure it wasnâ€™t just Woz who was excited about future faster CPUs.</p><p>But when would GTE actually produce those faster variants? Thatâ€™s the question. One source is <a href="http://commodore.ca/commodore-history/bill-mench-the-brains-behind-the-brains/" target="_blank">a 1986 interview with Mensch published in the Fall/Winter issue of COMPUTE!â€™s Apple Applications magazine</a>. This interview took place before the IIGS announcement, likely sometime in the summer of â€™86. Mensch states their average part on a 3 micron process should be 4MHz, and an upcoming 2.4 micron process would yield 6MHz parts. Iâ€™d wager that the 8 MHz parts would rely on a 2 micron process at that reduction rate. Some 6MHz parts did exist, and Bill Menschâ€™s Cortland-badged prototype IIGS has one. A photo of it was shown at his 2021 VCF East panel, and I will note that itâ€™s a WDC branded chip bearing a date code of the first week of February 1987. Whether Mensch put this chip in there himself or it was a sample installed by an Apple engineer is not explained. Nor is it known if its FPI chip actually drives it at a higher speed. But this shows that faster â€˜816s did exist. So what was getting in the way of these faster chips actually being used?</p><h2>Yields, Bugs, and Errata</h2><p>This brings us to the 65816â€™s next quandary: yields. This might be a surprise to you, given that the CPU is found in embedded devices worldwide. But a common thread through many of the reports Iâ€™ve read about the early days of the â€˜816 is that WDC and its fabrication partners struggled to deliver 4MHz and faster chips on time, in volume, and at spec.</p><p>Mensch positioned the 4MHz chip as the â€˜816â€™s volume product and said as much in that earlier interview with COMPUTE!. </p><blockquote><p>â€œOur typical product is 4MHz. We sell 2MHz into the retrofit&nbsp;market, but our typical run-of-the-mill is 4MHz.â€</p></blockquote><p>But in reality the IIGS shipped with a mixture of 3 and 4 MHz parts which actually ran at 2.8 MHz in fast mode. Which brings us back to the question of why a machine designed around a 4MHz part would ship with an almost 30% haircut in clock speed. Conspiracy theories aside, could there be a <em>technical</em> reason why the IIGS would run slower than its CPUâ€™s rated speed?</p><p>In the same Fall/Winter 1986 issue of COMPUTE!â€™s Apple Applications where Mensch talked about future plans for the â€˜816, David Thornburg interviewed Steve Wozniak about his role in developing the IIGS. The subject of the 65816 came up and Woz delved into some details about its clock speed.</p><blockquote><p>â€œOur early ideas for the computer had it running around 8MHz. Soon we found we had to back off to about 5.5MHz, and then to 2MHz for that version of the processor. In the end the product came out around 3MHz, which is a good compromise.â€</p></blockquote><p> This is consistent with his comments about the desire for 8MHz more than a year earlier in the Byte interview. Woz doesnâ€™t mention what factors made them back off on the clock speed, but during my research I learned a lot about the troubles the â€˜816 faced in terms of scaling and yields.</p><p>One problem was GTEâ€™s ability to supply chipsâ€”not just to Apple, but to other customers. The IIGS would be shipping by the tens of thousands when it launched, and this necessitated a good quantity of chips on hand. Dave Haynieâ€”yes, the Amigaâ€™s Dave Haynieâ€”had trouble in 1985 sourcing 4 MHz 65816s for a potential Commodore 128 successor. <a href="https://groups.google.com/g/comp.sys.apple/c/RH1-BNz8x-c/m/385dAOKgaA4J" target="_blank">He posted about this experience on Usenet in March of 1990</a>. </p><blockquote><p>â€œAt that time, they had fully specced 8MHz parts, yet in â€™85, GTE (the only company actually MAKING 65816s) had all they could do to make enough 4MHz parts. Rumor is that Apple managed get enough for the IIGS by actually having a special 2.8MHz version tested.â€</p></blockquote><p>He further elaborates with:</p><blockquote><p>â€œWhen the GS came out, the only company making '816s was GTE. The main reason I couldn't get any 4MHz â€˜816s in quantity was that Apple bought them all. They could make a real deal on 2MHz parts, since the yield on 4MHz was so low, they had more of those than they knew what to do with.â€ </p></blockquote><p>Haynie <a href="https://groups.google.com/g/net.micro.apple/c/mPV8ErhJUJQ/m/AyRGXOAvqLAJ" target="_blank">also comments in other posts</a> about how early samples of the â€˜816 were delivered at 500KHzâ€”yes, <em>kilo</em>hertzâ€”and maybe thatâ€™s a clue as to why Apple was unhappy in the Apple IIx timeframe.</p><p>Yields are a common woe in semiconductor manufacturing and Haynieâ€™s comments about yields line up with what we see in the real world. GTEâ€™s three micron process apparently had problems producing enough 4 MHz chips in volumes to satisfy its customers. Many IIGSes have a 3 MHz G65SC816 despite this speed rating not showing up in GTEâ€™s data sheets. My guessâ€”I canâ€™t find any confirmation for this, but it's what makes the most senseâ€”is that these were chips that couldn't be binned as 4 MHz, so GTE labeled them as 3MHz. Insisting on 4MHz would have meant shipping fewer computers, and the IIGS was delayed enough as it is. While VLSI supplied some 4MHz 65C816 CPUs later in the IIGSâ€™ life, the vast majority of CPUs found in these computers were made by GTEâ€”or, eventually, by California Micro Devices, <a href="https://techmonitor.ai/technology/california_micro_devices_completes_acquisition_of_gtes_microcircuits_division" target="_blank">which purchased GTEâ€™s Microcircuits division in September 1987</a> after GTE decided to get out of the business. Apple was also negotiating with NCR as a second source, but according to Mensch and others, the deal fell apart before the IIGS shipped.</p><p>But letâ€™s say for the sake of argument that GTE was able to produce as many 4 MHz chips as Apple or anyone else wanted to buy. Based on the FPIâ€™s clock divider mechanism and a 14.318 MHz source clock, Apple had a logical clock speed target of 3.58 MHz using a 1/4 divider. Thatâ€™d still be a compromise over Wozâ€™s dream machine, but itâ€™d be faster than what we got. And if (or when) faster processors became available, the FPI clock divider could be adjusted for them.</p><p>Yet those faster processors werenâ€™t materializing; at least, not in any volume. Yields were a factor, yes, but the faster speeds revealed other problems. Trying to learn more about this took me down a rabbit hole of Usenet posts, Applied Engineering documentation, AppleFest event reports, and 6502 development forums. All of them pointed to a common factor: the REP and SEP opcodes. When designing the new 16-bit native mode for the â€˜816, Bill Mensch added many new opcodes to enable new features and capabilities for programmers. Two of these new opcodesâ€”<a href="https://undisbeliever.net/snesdev/65816-opcodes.html#sep-set-status-bits" target="_blank">called SEP for Set Status Bits and REP for Reset Status Bits</a>â€”control flag bits for the processorâ€™s status registers. These are crucial to the dual 8/16 bit nature of the â€˜816 and how it can switch between 8 and 16 bit operations on the fly.</p><p>Unfortunately these opcodes proved problematic at higher speeds. <a href="https://groups.google.com/g/comp.sys.apple/c/og6tWx8NeMw/m/5dspToQ6g4IJ" target="_blank">Multiple posts</a> relay statements from WDC or programming guides that <a href="http://forum.6502.org/viewtopic.php?f=4&amp;t=5196" target="_blank">timing problems with the layout mask</a> prevented these instructions from completing in their allowed cycle times. These problems only got worse as they tried to shrink the mask down to smaller process nodes. Iâ€™m loath to take what amounts to second and sometimes even third-hand accounts from newsgroups and forums at face valueâ€”they don't call it the Net of a Million Lies for nothing, after all. But Iâ€™m willing to believe the overall theory based on other corroborating evidence (like this <a href="http://forum.6502.org/viewtopic.php?p=95998#p95998" target="_blank">WDC data sheet</a> note from 1991). If you look at an Apple IIGS accelerator like the TransWarp GS or the ZipGSX, youâ€™ll notice that theyâ€™re not just a CPU and some cache memory. The TransWarp GS has a bunch of support chips and gate array logic, while the ZipGSX has a full-blown ASIC on board.</p><p>The GALs for the TransWarp GS were reverse engineered long ago, and <a href="https://wiki.reactivemicro.com/TransWarp_GS#What_roles_the_GALs_Perform" target="_blank">Reactive Micro lays it out plainly</a>: GAL3 handles opcode detection and speed control. This matches up with posts <a href="https://groups.google.com/g/comp.sys.apple/c/og6tWx8NeMw/m/5dspToQ6g4IJ" target="_blank">relaying comments from Applied Engineering about stretching clocks</a> to handle problematic REP and SEP opcode timings.</p><p>Analyzing these posts also reveals the temperature of the Apple II community circa 1990. Apple announced a revised IIGS at San Francisco just before AppleFest in September 1989, and the reaction from attendees was muted at best. Unfortunately there was no CPU speed increase, but base memory was increased to 1MB and the new ROM added more toolbox routines and some feature enhancements. There was someone whose reaction was anything but muted, though, and it was one William David Mensch.</p><p><a href="https://groups.google.com/g/comp.sys.apple/c/zL2kjN9ponI/m/wFcQDnYlcVoJ" target="_blank">According to multiple accounts of the event</a>, during his keynote address Jean-Louis GassÃ©e said that there would be no speed increase for the revised IIGS because of difficulties securing faster 65816s. Mensch was in attendance and was understandably displeased with this statement. He approached one of the crowd mics and said that he was the designer of the CPU and had in his hand a bag of 12 MHz â€˜816s. He proclaimed that if Apple ordered the 12 MHz chips, he would ship them. Jean-Louis reportedly made a comment about wanting a reliable production run, and the two men got into a heated back-and-forth before GassÃ©e left and Mensch was escorted out. No recordings of this keynote exist, or if they do theyâ€™re locked away in the Apple Archives at Stanford University.</p><p>The version of the story Mensch recounts <a href="https://www.youtube.com/watch?v=hHqAQTl0s8A" target="_blank">at his 2021 panel at VCF East</a> largely follows what Iâ€™ve read in contemporary reports, except with one difference. He includes an anecdote about how he got Jean-Louisâ€™ Apple coffee cup. He mentions running into GassÃ©e after the keynote, and says that GassÃ©e was very upset and threatened to, quote, â€œkick [Menschâ€™s] butt.â€ No punches were actually thrown, and no butts were actually kicked, and the story peters out without really explaining how Mensch got the coffee cup, but this story shows just how bad Apple and WDC's relationship had become.</p><p>Now, youâ€™re a smart viewer, so I bet you know how chickens and eggs work. A company like Apple doesnâ€™t just buy bags of chips; they buy Frito-Layâ€™s entire annual output. Mensch could have samples of silicon, but WDC wasnâ€™t the one making the chips in volume; its licensees like GTE were. If the fab (say, GTE/CMD or VLSI) canâ€™t guarantee a production run of, say, 50,000 chips, the order doesnâ€™t happen. The evidence in front of usâ€”the delays during IIx development, the inability to deliver 4MHz parts at volume, and the opcode issues that prevented scalingâ€”would certainly justify skepticism of WDCâ€™s ability to work with a fab to deliver faster chips at volume. There were still possibilities for a faster IIGS, though, and these would play right into an Apple II fanâ€™s belief that Apple held it back.</p><h2>Accelerators, ASIC Incorporated, and Mark Twain</h2><p>But letâ€™s say you werenâ€™t buying tens of thousands of chips like Apple was; maybe you only needed a thousand or two. Were smaller customers being taken care of? <a href="https://www.wap.org/journal/showcase/journal198911.html" target="_blank">Ray Settle of the Washington Apple Pi Journal</a> was also at the fall 1989 AppleFest, where he reported on the confrontation between Mensch and GassÃ©e. Afterwards, he mentioned a visit with an Applied Engineering representative. Settle still hadnâ€™t received his TransWarp GS, and the AE rep pinned the blame on unreliable 7 MHz CPUs. <a href="https://groups.google.com/g/comp.sys.apple/c/zL2kjN9ponI/m/wFcQDnYlcVoJ" target="_blank">Another attendee report posted on Usenet by Michael Steele</a> featured similar comments. Keep in mind that the TransWarp was first announced in 1988, didnâ€™t ship until the fall of 1989, and struggled with speed and supply restrictions through 1990. This is further supported by <a href="https://archive.org/details/A2_Central_1991-02_February_1991_Vol_7_No_1/mode/2up?q=65816" target="_blank">A2-Centralâ€™s accelerator reviews in February 1991</a>, where itâ€™s mentioned that AE resorted to offering 6.25 MHz versions of the accelerator because of supply issuesâ€”and <em>reliability</em> issuesâ€”with 7 MHz chips. Zip Technologies also took a while to ship their 7MHz ZipGSX accelerator, which finally appeared in October 1990, almost a year after the TransWarp GS.</p><p>But we donâ€™t have to settle for second-hand reports. Enter Applied Engineering employee John Stephen III. <a href="https://groups.google.com/g/comp.sys.apple/c/rhRHiWlRp28/m/LluioQmvv9kJ" target="_blank">In an October 1989 Usenet post</a>&nbsp; he mentions the problems with getting 7MHz chips, and alludes to the REP/SEP timing issues. But the other interesting thing he mentions is that getting high speed 10 MHz â€˜816s to run at their rated speeds required boosting their input voltage well beyond the standard 5 volts. This made the chips run hotter and often resulted in crashes. And I see all you overclockers in the audience nodding your heads.</p><p>Scaling problems arenâ€™t unusual when you move to a smaller process node, and sometime a layout needs fixesâ€”or even a complete redesign. The original mask laid out by Katherine Mensch on the WDC card table had reached its limits. Redoing the mask wouldnâ€™t be easy or cheap, especially when higher speed â€˜816s were a smaller piece of the revenue pie. Royalties from the 65C02, 65802, and slower embedded â€˜816s were paying the bills. Mensch was also busy working on a 32-bit iteration of the architecture: the 65832. But this proposal never made the jump from datasheet to shipping dock.</p><p>Interestingly, this is where a new player steps in. While researching the yield problems <a href="https://groups.google.com/g/comp.sys.apple2/c/0OZKowbQQls/m/4JoV91YX8pEJ" target="_blank">I encountered numerous posts on comp.sys.apple2 about an â€œASIC 65816.â€</a> This tripped me up at first, because there are numerous application-specific integrated circuits that contain an â€˜816 core. But no, it turns out that a company <em>named</em> ASIC was creating a new 65816 processor using gate arrays. And they promised that this redesigned â€˜816 would reach speeds of 20MHz and beyond.</p><p>Imagine my surprise <a href="https://groups.google.com/g/comp.sys.apple/c/SVtbqi_gIEc/m/2AqcgWtHaEkJ" target="_blank">when I saw the name Anthony Fadell</a> mentioned in these posts. Could that be the same Anthony Fadellâ€”<em>Tony </em>Fadellâ€”who was in charge of the iPod? Sure enough, I found an excerpt of Tonyâ€™s book, <a href="https://www.buildc.com/the-book" target="_blank"><em>Build</em></a><em>,</em> where he talks about designing a 65816 for his startup company, ASIC Incorporated! Now weâ€™re on to something. This gave me enough clues to dig up the <a href="https://babel.hathitrust.org/cgi/pt?id=mdp.39015025959696&amp;seq=1" target="_blank">November/December 1989 issue of <em>The Michigan Alumnus</em> magazine</a>, where an article tells the tale of the fateful summer of 1989. Fadell was an undergrad student at the University of Michigan, and he spent his summer internship designing nuclear control computers at Ronan Engineering. When he met William Hayes the two hit it off immediately. Fadell was a big Apple II fanboy and yearned for more power. Hayes knew chip design and had connections with other chip designers. The two decided that they would design a better version of the 65816 using a sea-of-gates array. Fadell borrowed $5,000 from his uncle, Hayes leveraged his connections to get cut-rate pricing on supercomputer time, and the two reverse engineered a 65816 design in six weeks. After finding a fab willing to manufacture their design, Fadell was prepared to pitch his prototype to potential patrons.</p><p>The <em>Michigan Alumnus</em> article is coy about who the chip was for, but it mentions Fadell flying to Texas in September 1989 to meet with a manufacturer of Apple IIGS accelerator boards. There he negotiated a purchase order and a two year contract, catapulting him to the role of CPU vendor at the age of twenty. With these clues we can deduce that Fadellâ€™s customer was Applied Engineering. If all had gone according to plan, ASIC's chips should have started production in early 1990, and formed the basis of the next generation of TransWarp accelerators. Thereâ€™s that word againâ€”<em>should.</em></p><p>Ultimately, no TransWarp GS or ZipGSX accelerators ever shipped with ASICâ€™s design. The chips did existâ€”multiple trip reports from 1990 AppleFests mention Fadell demonstrating his CPUs in TransWarp accelerators. And in 2022, Fadell <a href="https://twitter.com/tfadell/status/1524145271797551104" target="_blank">posted a photo on Twitter of an ASIC 65816</a> which he claims would still work todayâ€”Iâ€™m guessing this is one of the 17 MHz chips used in the AppleFest demos. But posts about ASIC fizzled out after the spring of 1991, which coincides with Fadell graduating from Michigan. The ultimate fate of the chip isnâ€™t really knownâ€”did Fadell face legal challenges from WDC? Did Applied Engineering give up on him? Or was it becauseâ€”<a href="http://wired.com/story/tony-fadell-revenge-on-silicon-valley-from-paris/" target="_blank">as described in an interview with WIRED</a>â€”he was just too busy roaming the halls of General Magic trying to score a job with former Apple superstars Andy Hertzfeld and Bill Atkinson? My guess is the latter, since General Magic hired him later that year.</p><p>In the same tweet as the photo of the chip, Fadell said that he, quote: â€œsold some to Apple for a new Apple IIGS revision before they canceled it!â€ Many IIGS superfans have heard tell of the <a href="https://68kmla.org/bb/index.php?threads/apple-iigs-rom-04-%E2%80%9Cmark-twain%E2%80%9D.29362/" target="_blank">cancelled final revision of the IIGS code named Mark Twain</a>. Featuring an internal floppy drive, a hard disk, and a redesigned logic board the Mark Twain is what many thought the ROM 03 IIGS should have been. Itâ€™s entirely probable that Apple fitted some prototypes with faster CPUs. <a href="https://www.wannop.info/SSII//SSII_Index_files/SSII_PDF_files/Volume%203%20Issue%201.pdf" target="_blank">But when media outlets like InCider/A+ magazine were given a top secret demo</a> a mere month before its cancellation, the clock speed was still the same. And the few Mark Twain prototypes that escaped Appleâ€™s development dungeons were equipped with the usual 4MHz chip. This is where the business side and the technical side butt heads.</p><p>The Mark Twain was under development in late 1990 into 1991 and then mysteriously no longer under development as of June 1991. Rumors of Apple killing the entire Apple II line hung over the product like a dark cloud, and the dev team had hoped to prove they were greatly exaggerated. Despite John Sculleyâ€™s statements promising Appleâ€™s full support for the over five million strong installed base, the lack of marketing and technical improvements to the Apple II over the years meant his words rang hollow. Apple had just introduced the Macintosh LC as their low-cost color Mac, and IBM compatible PCs were getting cheaper and more capable. If Apple released the Mark Twain without any CPU speed boosts, it wouldâ€™ve appealed mostly to the Apple IIâ€™s cost-conscious institutional education market. Would existing IIGS owners buy one instead of just getting an accelerator card for a fraction of the price? And how many new users would it bring to the platform? The Mark Twain wouldâ€™ve been like the Amiga 1200: a decent improvement, but ultimately too little and too late. The March 1991 release of the Apple IIe card for the Mac LC also put another nail in Mark Twainâ€™s coffin, because many usersâ€”especially educatorsâ€”bought a IIGS for backwards compatibility with classic Apple II software. If youâ€™re the number cruncher who had to choose between spinning up a run of 50,000 Mark Twains that cost a lot more to build than 50,000 IIe cards for Mac LCs that are already in production, already in a warehouse, or already sold to customers, which would you pick?</p><p>Now this is where you can rightfully criticize Apple for holding back the Apple IIGS. A Mark Twain with even a 12MHz CPU from ASIC wouldâ€™ve been a legitimately powerful, well equipped computer for its price. But that wouldâ€™ve been one last campaign in a war long since lost. Maybe ASIC could have helped, but the good ship Apple was sailing straight into a storm called the beleaguered era. Costs, staff, and projects were starting to spiral out of control, and the Mark Twain wouldâ€™ve only delayed the inevitable death of the Apple II.</p><h2>Sanyo, Nintendo, and the End of Acceleration</h2><p>Even if Apple didnâ€™t see fit to release a faster IIGS, accelerator cards kept the enthusiast market alive for a few more years. <a href="https://archive.org/details/NAUG-V06N03" target="_blank">Upgrade guides for the TransWarp</a> gave tips on how to install higher-rated â€˜816s to get even more speed. This usually required buying samples of higher speed processors from WDC, changing crystals, upgrading the cache, and acquiring new GALs. Once you hot-rodded your card youâ€™d often need to supply more juice over the 5V rail to keep things stable.</p><p>All this hackery was finally put to bed in 1992 when new 65C816s rated at 14 MHz hit the market. <a href="https://groups.google.com/g/comp.sys.apple2/c/eoCOwP_-eWs/m/ExeSe7cR6IYJ" target="_blank">These chips took Usenet posters by surprise</a>, especially after the ASIC saga. Fabbed by Sanyo, the 14 MHz models could run cool and stable at 5V and apparently solved the issues with the REP and SEP opcodes. Sanyo achieved this by abandoning the die laid out by Katherine Mensch and creating a new layout from scratch. Why Sanyo chose to invest in this is unclearâ€”<a href="https://groups.google.com/g/comp.sys.apple2/c/yVx5TMBjAGQ/m/32BgXxPXpgkJ" target="_blank">I found a lot of speculation</a> that they wanted to <a href="https://www.historyofinformation.com/detail.php?id=5188" target="_blank">build a PDA based on the â€˜816</a>. Sanyoâ€™s a giant manufacturer, so Iâ€™m sure they found a use for it. Maybe WDC felt the heat from ASIC, or maybe they saw ARM and 68K pivoting to the embedded market and finally bit the bullet to stay competitive.</p><p>Existing accelerators could be upgraded by changing out their CPU and clock crystal, but by this point the IIGS was but a fraction of the â€˜816s out in the wild. Optimistic estimates of the number of IIGSes shipped hover around 1.25 million. The other â€˜816 system that most people knowâ€”the Super NESâ€”sold 1.3 million units in 1990 just in Japan according to numbers compiled by NeoGAF user Aquamarine, who claims to have gotten them directly from Nintendo's Kyoto offices. The system sold nearly 50 million units worldwide in its lifetime. Mensch is very proud of the SNES using the 65816 and speaks highly of working with Ricoh, the manufacturer of Nintendoâ€™s chips. Seeing as the 5A22 was a custom job by Ricoh, I wonder if they fixed the SEP and REP problem during its design. It wouldnâ€™t be beyond them; <a href="https://www.linkedin.com/pulse/reverse-engineering-patent-protection-cautionary-tale-harry-strange/" target="_blank">they did tweak the 6502 to dodge patents</a> when designing the NESâ€™ 2A03. I havenâ€™t seen the SNES assembler community complain about issues with REP and SEP with the basic 3.56 MHz part, but that doesnâ€™t mean problems donâ€™t exist. Same with emulation and FPGA groups, though Iâ€™d still defer to experts in that field. </p><p>And like the IIGS, the SNES could take advantage of accelerators thanks to add-on processors in cartridges. The most well known is the SuperFX, but Ricoh also made a faster 65816. Better known as the Super Accelerator-1, the Ricoh 5A123 runs at a 10.74 MHz clock speedâ€”three times faster than a 5A22. Youâ€™ll find it in fan-favorites like <em>Super Mario RPG</em> and <em>Kirby Super Star.</em> SA-1 games started shipping in 1995, which is late in the Super NESâ€™ lifecycle. Did Ricoh license the redesigned core from Western Design, or did they make the changes themselves? Iâ€™d love to know the answer.</p><h2>ARM, MÃ¶bius, and The Road Not Taken</h2><p>Apple discontinued the IIGS in December 1992. Even though the IIe hung on for another year or so, the platform truly died that day. Even in the timeline where WDC had 8MHz chips ready in 1983, and Apple put the GUI on the IIx in 1984, I still think the Apple II as we knew it wouldâ€™ve died eventually. Thereâ€™s several limitations that would necessitate an eventual migration to a new architecture.</p><p>The primary roadblock is the Mega II side of the machine. This is supposed to be what makes it an Apple II, but it drags the rest of the machine down with it. Depending on the video system for clock generation and timing was a practical engineering choice that became hard technical debt for almost all 1980s computer architectures, especially with ones that traced their roots to the 1970s. The GS is an excellent example of trying to maintain compatibility while adding capability, but it had an obvious ceiling.</p><p>But something that gets lost in the 65816 versus 68000 arguments is that CPU architectures have qualities beyond raw speed. You might care about power consumption, memory mapping, or ease of acquisition. And all these factors are a balancing act depending on your application. The 68Kâ€™s massive flat memory space was a big point in its favor, as well as its native support for user and supervisor separation. These donâ€™t matter as much to someone whoâ€™s writing hand-crafted single-tasking assembly language apps, but they very much matter to someone building a multitasking UNIX workstation.</p><p>And thatâ€™s not to say that 68K isnâ€™t good for assembly applications. Itâ€™s got a great reputation among assembly programmers. But as the world turned to compilers and development environments the 68K architecture was primed for the rising popularity of languages like C. More people were getting into programming, and itâ€™s unrealistic to expect them all to have the potential to become machine language maestros like Rebecca Heineman or Nasir Gebelli. C compilers exist for 6502 and 65816, but it's fair to say that these architectures weren't particularly suited to the intricacies of C.</p><p>Another sticking point for high-speed 65816s is the speed of memory. Assuming you threw the entire Mega II side of the IIGS away and built a new â€˜816 computer from scratch, a 14 MHz example would need very fast main memory to operate without a cache. In the early 90s, that kind of memory was barely available. How Woz would have built his 8 MHz IIGS in 1985 while affording a decent amount of memory is a rather inconvenient question.</p><p>Apple wasnâ€™t the only company facing the limitations of their early designs. Commodore and Atari decided to pivot to the 68000, like Apple did with the Macintosh. Tech debt eventually caught up with them too, especially Commodore, but the problems werenâ€™t unsolvableâ€”the Amiga tried to migrate to PowerPC, after all. Even the Macintosh and IBM PCs had eventual reckonings with fundamental planks of their platforms. Another company was facing the same conundrum: Acorn Computers. The similarities to Apple are there: they were dependent on a 6502-based architecture and had a crucial education market with a significant installed base. Acorn did ship a computer with the 65816â€”the Acorn Communicatorâ€”but <a href="https://www.computerhistory.org/collections/catalog/102746190" target="_blank">when Sophie Wilson visited WDC in 1983</a> and saw Mensch and crew laying out the 65816 by hand, it struck her: if this motley crew on a card table could design a CPU, so could Acorn. Thus Wilson and Steve Furber forged their own CPU: the Acorn RISC Machine.</p><p>Though todayâ€™s Arm and WDC sell very different CPUs, they do have something in common: theyâ€™re fabless semiconductor designers that license their cores and architectures to other companies. Apple is of course Armâ€™s most famous partner: <a href="https://www.latimes.com/archives/la-xpm-1990-11-28-fi-4993-story.html" target="_blank">they joined Acorn and VLSI to form Advanced RISC Machines in 1990</a> to create the ARM610 CPU to power the Newton. But what you might not know is that Appleâ€™s involvement with ARM originates with a desire to replace the CPU in the Apple II. <a href="https://tompittard.com/media" target="_blank">The little known MÃ¶bius project helmed by Paul Gavarini and Tom Pittard in the Advanced Technology Group</a> was an ARM2-based computer that could emulate 6502, 65816, and 68000 code. Gavarini and Pittard started the project in 1986 and were demoing and compiling benchmarks in 1987â€”right on the heels of Acorn releasing the Archimedes! Thereâ€™s little information about this on the web, with <a href="https://web.archive.org/web/20131208171649/http://www.tompittard.com/page4.html" target="_blank">Tom Pittardâ€™s bio</a> and <a href="https://web.archive.org/web/20050208095510/http://www.advanced-risc.com/art1stor.htm" target="_blank">Art Sobelâ€™s ARM pages</a> being some of the surviving hints to its existence.</p><p>Based on my knowledge of how ARM2 works, I believe the emulation performance of MÃ¶bius is wholly derived from the ARM2â€™s memory system. ARMâ€™s designers were inspired by the 6502â€™s efficient memory access and optimized the 8 MHz ARM2 to wring as much performance out of the available memory as possible. <a href="https://media.ccc.de/v/36c3-10703-the_ultimate_acorn_archimedes_talk#t=1635" target="_blank">By using 4 MHz 32-bit-wide fast page memory, pipelining, and special load-store instructions, ARM2 could perform burst transactions at twice the speed of random ones</a>. With a theoretical maximum of 32 MB/s bandwidth in fast page mode, this was eight times the maximum bandwidth of an 8 MHz 68K shackled to 2 MHz DRAM. This strategy would peter out eventually because memory speed couldnâ€™t keep up with CPU speed, but heyâ€”thatâ€™s what cache is for!</p><p>Iâ€™m not sure if MÃ¶bius would have been the Apple IIâ€™s saviorâ€”Acornâ€™s Archimedes wasnâ€™t 100% backwards compatible despite including a BBC Basic interpreter and eventually a BBC Micro emulator. But with EcoNet network adapters and expansion podules to connect old Beeb peripherals the Arc could ingratiate itself with Acornâ€™s existing installed base. Could the Apple II have been reborn with an ARM CPU? Maybe. Nobody mentions how well MÃ¶bius integrated the rest of the Apple II architecture like slots or video or sound. And say what you will about Appleâ€™s troubles with Western Design Center; ARM was barely a blip on the radar in 1988. Apple wasnâ€™t going to upturn their cart for an unproven architecture from a competitor. MÃ¶bius was a skunkworks project; it couldâ€™ve taken years to turn its demo into a shipping product and the 68040 was already on the drawing board in 1988. But it was still worth it: MÃ¶biusâ€™ benchmarks convinced Larry Tesler that ARM could save the Newton from the disastrous AT&amp;T Hobbit processor. And heyâ€”without ARM, Apple wouldnâ€™t have the iPod, iPhone, and Apple Silicon today. So it worked out in the end.</p><h2>The End of an Odyssey</h2><p>What a ride, huh? Thanks for making it this far down a fifty-plus minute rabbit hole. I canâ€™t claim that this is the final take on the subjectâ€”so many of the players arenâ€™t on the record, but Iâ€™m pretty confident in saying that Apple did not artificially limit the IIGSâ€™ clock speed during its development for marketing purposes. Now, Iâ€™m not a foolâ€”I know Apple didnâ€™t push the IIGS as hard as it could, and it was very much neglected towards the end of its run. If the REP/SEP flaws hadnâ€™t existed and GTE couldâ€™ve shipped stable 4 MHz chips in volume, Iâ€™m sure Apple wouldâ€™ve clocked them as fast as possible in 1986.</p><p>Iâ€™ll admit that I initially started this deep dive out of spite. The idea that â€œSteve Jobs deliberately held the IIGS back, <em>bleh blehâ€</em> is everywhere, but it's all just people saying things in an endless game of telephone, with no actual evidence. Thatâ€™s enough to grind anybodyâ€™s gears, but whatâ€™s worse are people who I respect uncritically repeating these things in videos and blog posts. It hurts me to see videos with millions of views repeating old Internet urban legends pushed by partisans filtered through Wikipedia articles with bad citations.</p><p>But that spite subsided quickly once I started untangling the messy web of people and circumstances that wrapped around this story. I realized that what I wanted wasnâ€™t to prove anybody wrong. What I wanted was to get people to think about these stories and why they became legends. Of course, you could flip that right back around at me and say â€œwho made <em>you</em> the guardian of love and justice?â€ And thatâ€™s a fair point. But my goal here isnâ€™t to push an agenda, but to get a better of understanding of how things happened and why history went the way that it did. Iâ€™ve provided my evidence, and itâ€™s up to you to judge if my argument is compelling enough.</p><p>And even then, one of those people who needed a refresher on computer legends was yours truly. Iâ€™ve done my share of repeating things based on bad sources, just because I had a fanboy desire to defend something. Or because I just thought a story was neat and didnâ€™t look too deeply into it. Itâ€™s not so much about somebody whoâ€™s being wrong on the internet; it was the realization that <em>I</em> could be somebody whoâ€™s being wrong on the internet! It was humbling, really. As the years go on Iâ€™ve realized that thereâ€™s so much out there to learn, even if I thought I already was an expert. A perfect example is that <a href="https://www.pagetable.com/?p=43" target="_blank">Bill Gates BASIC easter egg</a>, where I got tripped up by an oft-repeated legend until I actually dug into it. And as vintage and retro tech enthusiasts, are we not people of science? Are not our minds open to new ideas? Weâ€™re into this because we enjoy the history and personal connections, and we should all be excited about digging deep and not just repeating the same old story.</p><p>Even though the IIGS may not have been able to unleash its full potential, itâ€™s still an amazing machine even at its base speed. If you havenâ€™t had the chance to play with one, give it a try. And turn on accelerator mode in your emulator to get a feel for what could have been.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FUTO (166 pts)]]></title>
            <link>https://www.futo.org/</link>
            <guid>41268245</guid>
            <pubDate>Fri, 16 Aug 2024 17:07:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.futo.org/">https://www.futo.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41268245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>GrayJay</p>
                    <p>A universal video app for following creators, not platforms</p>
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does Reasoning Emerge? Probabilities of Causation in Large Language Models (148 pts)]]></title>
            <link>https://arxiv.org/abs/2408.08210</link>
            <guid>41267746</guid>
            <pubDate>Fri, 16 Aug 2024 16:19:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2408.08210">https://arxiv.org/abs/2408.08210</a>, See on <a href="https://news.ycombinator.com/item?id=41267746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2408.08210">View PDF</a>
    <a href="https://arxiv.org/html/2408.08210v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Recent advances in AI have been significantly driven by the capabilities of large language models (LLMs) to solve complex problems in ways that resemble human thinking. However, there is an ongoing debate about the extent to which LLMs are capable of actual reasoning. Central to this debate are two key probabilistic concepts that are essential for connecting causes to their effects: the probability of necessity (PN) and the probability of sufficiency (PS). This paper introduces a framework that is both theoretical and practical, aimed at assessing how effectively LLMs are able to replicate real-world reasoning mechanisms using these probabilistic measures. By viewing LLMs as abstract machines that process information through a natural language interface, we examine the conditions under which it is possible to compute suitable approximations of PN and PS. Our research marks an important step towards gaining a deeper understanding of when LLMs are capable of reasoning, as illustrated by a series of math examples.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Javier Gonzalez [<a href="https://arxiv.org/show-email/450e0580/2408.08210">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 15 Aug 2024 15:19:11 UTC (8,071 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discrete Mathematics â€“ An Open Introduction 4ed (By Oscar Levin) (309 pts)]]></title>
            <link>https://discrete.openmathbooks.org/dmoi4.html</link>
            <guid>41267478</guid>
            <pubDate>Fri, 16 Aug 2024 15:53:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discrete.openmathbooks.org/dmoi4.html">https://discrete.openmathbooks.org/dmoi4.html</a>, See on <a href="https://news.ycombinator.com/item?id=41267478">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<h3>4th Edition Information</h3>
<p>
This page details progress on the 4th edition of the book. The <a href="https://discrete.openmathbooks.org/dmoi3.html">3rd edition</a> remains available.
</p>
</div>
<p>
After many years of development, I am please to announce that the 4th edition of <em>Discrete Mathematics: an Open Introduction</em> is <strong>now available</strong>, here and on <a href="https://runestone.academy/">Runestone Academy</a>.
</p>
<p>
The new edition brings many improvements and a new organization of content. In particular, the book now starts with logic and proofs, then practices those proofs with graph theory. The second half of the book contains material on counting (with a new "application to probability" section) and sequences. Over the last few years, I have found that students have more success with this arrangement. There is also a stronger emphasis on discrte structures, which should make the book more useful for students in computer science, while still focusing on understanding mathematical concepts essential for math majors and future math teachers.
</p>
<p>
There is more interactivity as well. More interactive exercises (which you can give students credit for if you create a course with the book on Runestone Academy; it is completely free for you and your students) and some interactive Sage and Python code to explore some topics.
</p>
<p>
A PDF of the book will be made available by August 15th. There will not be a print edition available until next year, when CRC Press will release it. The online version will remain available and free forever, and the book is still released under a Creative Commons License (but note the new NC-Non Commercial addition to the license).
</p>






































<h3>License</h3>
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://discrete.openmathbooks.org/dmoi4.html">Discrete Mathematics: an Open Introduction, 4th edition</a> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://math.oscarlevin.com/">Oscar Levin</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer">CC BY-NC-SA 4.0<img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>
<p> You are free to download, use, and print as you wish to, for noncommercial purposes. You can also modify the text as much as you like (create a custom edition for your students, for example), as long as you attribute the parts of the text you use to the author and release your modified version under a compatible license.</p>
<p>If you are interested in using parts of the book combined with another text with a similar but different license (GFDL, for example), please <a href="https://discrete.openmathbooks.org/cdn-cgi/l/email-protection#ed829e8e8c9fc381889b8483ad98838e82c3888998">reach out</a> to get permission to modify the license.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Texas "moth man" photographed 550 species in his own yard (198 pts)]]></title>
            <link>https://www.texasmonthly.com/travel/curtis-eckerman-photographer-moth-man/</link>
            <guid>41267045</guid>
            <pubDate>Fri, 16 Aug 2024 15:04:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.texasmonthly.com/travel/curtis-eckerman-photographer-moth-man/">https://www.texasmonthly.com/travel/curtis-eckerman-photographer-moth-man/</a>, See on <a href="https://news.ycombinator.com/item?id=41267045">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>On a steamy June evening, Curtis Eckerman embarks on a mothing expedition in the Bauerle Ranch greenbelt, in far South Austin. Towing a wagon full of supplies, he follows a narrow trail that leads between mesquite trees and into a secluded oak grove suffused with golden late-afternoon light. Eckerman, the chair of the biology department at Austin Community College, parks the wagon and begins to wrap a tree trunk in white cloth. Next he suspends a battery-powered ultraviolet light from a low branch. Heâ€™s optimistic weâ€™ll see lots of different moths tonight; itâ€™s been a warm, humid day, conducive to plant growth and, by extension, activity by plant-eating creatures. The oak grove is full of frostweed, persimmon trees, and various grasses, each vital to different moth species. Thatâ€™s another good sign: a wide variety of plants will draw a variety of moths.</p><p>When he finishes his preparations, itâ€™s about eight oâ€™clock. Moths emerge to eat, mate, and lay eggs once itâ€™s completely darkâ€”and fellow moth-ers will arrive any moment now. Eckerman mops his brow and takes a swig from his water bottle. â€œNow we just wait.â€</p><p>Eckerman is a herpetologist by trade; he says the best job he ever had was catching endangered water snakes in West Texas as an undergraduate research assistant. But heâ€™s always collected insects, and a little over a decade ago, he began photographing them. When he realized he struggled to identify the moths in his pictures simply because there were so many varieties, he dedicated a summer to studying them. These days, he sets a light by his garage door and photographs whatever moths show up, as many as seventy species and thousands of individuals in a single night. Heâ€™s now counted 550 species at his own home.&nbsp;</p><p>Eckerman is an ecologist with an interest in biodiversity, as well as in speciesâ€™ natural histories, behaviors, life cycles, and places in the food chain. Moths are so diverse, he says, that itâ€™s not uncommon to find one that hasnâ€™t been named or described in the scientific literature. No entomologist studies â€œmothsâ€; out of necessity, they specialize. Travis County has about 1,400 recorded species, the state of Texas more than 4,000. And those are just the ones we know about. Insects are the most diverse group of animals on the planet, and there are likely more undiscovered insect species than known onesâ€”as many as 10 to 20 million species worldwide still left to discover, Rice University biologist Scott Egan told <em>Texas Monthly</em> <a href="https://www.texasmonthly.com/travel/tiger-beetle-rice-university-houstoniana-discovery-new-species/">earlier this year.</a></p><p>The most common type of moths in the U.S. are&nbsp;noctuids, the smaller, grayish-brown moths that congregate around porch lightsâ€”â€œYour stereotypical moth,â€ Eckerman says. Showier <a href="https://www.texasmonthly.com/travel/hummingbird-moth-texas-yards/">hawk moths</a> are active during the day and often confused with hummingbirds. Silk moths, such as the luna moth, enormous and apple green, donâ€™t have functional mouth parts; their one-to-two-week adult lives are powered by whatever fat theyâ€™ve stored as caterpillars. Micromothsâ€”a broad descriptor that can include noctuids and moths in other familiesâ€”have wingspans under twenty millimeters long, but are worth viewing through a magnifying glass or camera to admire their vivid colors and patterns. Theyâ€™re one of Eckermanâ€™s favorite groups to photograph because of the â€œhidden-gem effect,â€ he says. â€œItâ€™s the idea that you get to see something that somebody normally doesnâ€™t see.&nbsp;.&nbsp;.&nbsp;. You feel like youâ€™re exploring a world that others are not exploring, even though itâ€™s around them all the time.â€</p><figure><img fetchpriority="high" decoding="async" width="2400" height="1500" alt="Clockwise from top left: Silk Moth/Polyphemus Moth, Hawk Moth/White-lined Sphinx Moth, Micromoth/Leaf Miner Moth, Southern Emerald, Noctuid/Wedgeling Moth" sizes="(max-width: 2400px) 100vw, 2400px" data-src="https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=fit&amp;fm=pjpg&amp;ixlib=php-3.3.1&amp;q=45" data-srcset="https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=188&amp;ixlib=php-3.3.1&amp;q=45&amp;w=300&amp;wpsize=medium 300w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=640&amp;ixlib=php-3.3.1&amp;q=45&amp;w=1024&amp;wpsize=large 1024w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=480&amp;ixlib=php-3.3.1&amp;q=45&amp;w=768&amp;wpsize=medium_large 768w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=960&amp;ixlib=php-3.3.1&amp;q=45&amp;w=1536&amp;wpsize=1536x1536 1536w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=1280&amp;ixlib=php-3.3.1&amp;q=45&amp;w=2048&amp;wpsize=2048x2048 2048w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=31&amp;ixlib=php-3.3.1&amp;q=45&amp;w=50&amp;wpsize=concierge-thumb 50w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=fit&amp;fm=pjpg&amp;ixlib=php-3.3.1&amp;q=45 2400w" data-sizes="auto" src="https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-1.jpg?auto=compress&amp;crop=faces&amp;fit=fit&amp;fm=pjpg&amp;ixlib=php-3.3.1&amp;q=45"><figcaption><span>Clockwise from top left: silk moth, hawk moth, micromoth, southern emerald, and wedgling moth. </span><span>Texas Monthly; Moth Photographs by Curtis Eckerman</span></figcaption></figure><p>Much of Eckermanâ€™s moth self-education comes from the participatory science app iNaturalist. Users take pictures of plants, insects, and other animals they spot in their local areas and upload them with comments (â€œAnyone know what kind of owl this is?â€). Fellow iNaturalists compare notes and help one another identify mystery species. The app also suggests possible identifications with an impressive degree of accuracy. Users can note the location where they saw a given plant or animal, creating a dataset that has helped researchers understand the ranges of particular species. Virtual communities form quickly and move into real life as users go mothing, birding, or herping together. &nbsp;</p><p>Eckerman posted his first moth images to iNaturalist ten years ago, and other users coached him on how to take better photos to make identification easier. He started teaching the students in his Structure and Function of Organisms course at ACC to use iNaturalist to log their own observations. Eckerman has tracked his former studentsâ€™ engagement with the app via their usernames and found that three years after taking his class, 30 percent are still active.</p><p>Too many Texans are disengaged from the natural wonders around them, he argues, but iNaturalist can help them tune in. â€œThe average student today could tell you all sorts of things about the plains of the Serengeti and interactions between zebra and lions, because National Geographic and Discovery and Disney brought it to us in high definition,â€ Eckerman says. â€œBut they know far less about whatâ€™s in their own backyard than the previous generation, because theyâ€™re just not interacting with it.â€ Over the years, heâ€™s stopped talking about faraway exotic animals in his courses; he instead makes lessons relevant by focusing on local fauna students have actually seen: coyotes, gray foxes, grackles, moths.</p><p>To help his students apply their iNaturalist skills in the field, he organizes mothing expeditions to Pease Park, in Central Austin, and Roy G. Guerrero park, in East Austin. At the latter site, the classes have logged about 350 moth species, including an enormous black witch, longer than a chalkboard eraser and sometimes confused for a batâ€”itâ€™s the largest noctuid in the continental U.S. Roy G. Guerrero is a much larger park than Pease and more buffered from human activity that would interfere with moths. Still, the Pease Park surveys have turned up more than two hundred speciesâ€”proving, Eckerman says, that urban parks are important not just as sites of human recreation but also for supporting species diversity. In the spring, Eckerman invited the public to go mothing at the park, part of his ongoing effort to educate the general population about biodiversity and conservation. For impromptu events like the June expedition on the greenbelt, he maintains a â€œmoth-lovers email listâ€ and lets word spread on iNaturalist.</p><p>An hour after sunset, the afternoon buzz of cicadas has given way to the rhythmic rattle of <a href="https://www.texasmonthly.com/travel/welcome-to-hot-katydid-summer/">katydids</a>. A half dozen moth lovers gather in the oak grove and peer at the moths flittering against Eckermanâ€™s sheet, including the <a href="https://www.inaturalist.org/taxa/224855-Melipotis-indomita" target="_blank">indomitable melipotis</a>, a large brown triangle with a cream-colored V across its wings, and the smaller filbertworm moth, its wings a mottled red with bands of gold.</p><p>Reid Hardin, a biology student at Texas State University, studies the moths before disappearing into the shadows to look for scorpions. Hardinâ€™s into mothsâ€”he sometimes sets up a light in his own backyardâ€”but he also scouts out rare plants and various arachnids. iNaturalist has connected him with locals who share his curiosity. Tonight, he and Caleb Helsel, a Westlake High School student whoâ€™s into birds, insects, and arachnids, are comparing notes on the pseudoscorpions theyâ€™ve turned up at Austin greenbelts. â€œItâ€™s just always cool to see who else is interested in niche, nerdy stuff,â€ Hardin says.</p><figure><img decoding="async" width="2400" height="1500" alt="" sizes="(max-width: 2400px) 100vw, 2400px" data-src="https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=fit&amp;fm=pjpg&amp;ixlib=php-3.3.1&amp;q=45" data-srcset="https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=188&amp;ixlib=php-3.3.1&amp;q=45&amp;w=300&amp;wpsize=medium 300w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=640&amp;ixlib=php-3.3.1&amp;q=45&amp;w=1024&amp;wpsize=large 1024w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=480&amp;ixlib=php-3.3.1&amp;q=45&amp;w=768&amp;wpsize=medium_large 768w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=960&amp;ixlib=php-3.3.1&amp;q=45&amp;w=1536&amp;wpsize=1536x1536 1536w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=1280&amp;ixlib=php-3.3.1&amp;q=45&amp;w=2048&amp;wpsize=2048x2048 2048w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=scale&amp;fm=pjpg&amp;h=31&amp;ixlib=php-3.3.1&amp;q=45&amp;w=50&amp;wpsize=concierge-thumb 50w, https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=fit&amp;fm=pjpg&amp;ixlib=php-3.3.1&amp;q=45 2400w" data-sizes="auto" src="https://img.texasmonthly.com/2024/08/curtis-eckerman-texas-moths-photos-3.jpg?auto=compress&amp;crop=faces&amp;fit=fit&amp;fm=pjpg&amp;ixlib=php-3.3.1&amp;q=45"><figcaption><span>Clockwise from top left: filbertworm moth, common buckeye butterfly, eight-spot moth, indomitable melipotis, sculptured moth, and plume moth.</span><span>Texas Monthly; Moth Photographs by Curtis Eckerman</span></figcaption></figure><p>Moths arenâ€™t just pretty to look at; theyâ€™re also important pollinators and a major source of food for birds and bats. But moths, like insects overall, are declining in both raw numbers and species diversity. Eckerman says recent studies have shown at least a 30 percent decline in insect abundance around the world over the past few decades. The likely culprits are pesticides and the loss of habitat to urban development. A threat to insects such as moths is a threat to the plants they pollinate and all the creatures above them in the food chain.</p><p>Beyond eschewing pesticides, Texans can create more moth-friendly environments by using a variety of native plants in their yards to offer food. Reducing light pollution helps too; moths are disoriented by artificial light, which can impair reproduction. If moths lay their eggs under the light instead of on a plant that is their food source, the resulting larvae wonâ€™t have anything to eat. Turning off lights at night (Eckerman always disassembles his setup at the end of the evening) helps moths find their way to the right plant.</p><p>By 10 p.m., Eckermanâ€™s sheet is littered with diminutive flying insects: micromoths, small beetles, caddis flies, and plant hoppers. He leans in to photograph a tiny moth, using a camera with a macro lens that lets him take clear images at a short distance. To the naked eye, the mothâ€”smaller than a grain of riceâ€”is plain white. But when Eckerman enlarges the image on the viewfinder, he reveals a pattern of buckwheat-colored flecks on cream-hued wings. Eckerman canâ€™t remember its nameâ€”he just knows itâ€™s in the <em>Gracillariidae</em> familyâ€”but iNaturalist will fill in the details.</p><p>Overall, he says, itâ€™s been a good night for the really small moths, which makes him happy. â€œDespite there not being all that glamorous moths, this is actually my favorite kind of sheet, with all the tiny things,â€ he says. â€œI love seeing the little jewels that you canâ€™t normally see.â€</p>
<div data-txmo-ab-name="topics-eoa">
<ul>

<li><a href="https://www.texasmonthly.com/category/critters/" data-click-location="EOA Topics List" data-click-action="Topic Click" data-click-label="Critters">Critters</a></li>
<li><a href="https://www.texasmonthly.com/location/austin/" data-click-location="EOA Topics List" data-click-action="Topic Click" data-click-label="Austin">Austin</a></li>
</ul>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JPlag â€“ Detecting Software Plagiarism (101 pts)]]></title>
            <link>https://github.com/jplag/JPlag</link>
            <guid>41265512</guid>
            <pubDate>Fri, 16 Aug 2024 11:56:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jplag/JPlag">https://github.com/jplag/JPlag</a>, See on <a href="https://news.ycombinator.com/item?id=41265512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"> 
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/jplag/JPlag/blob/main/core/src/main/resources/de/jplag/logo-dark.png"><img alt="JPlag logo" src="https://github.com/jplag/JPlag/raw/main/core/src/main/resources/de/jplag/logo-dark.png" width="350"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">JPlag - Detecting Software Plagiarism</h2><a id="user-content-jplag---detecting-software-plagiarism" aria-label="Permalink: JPlag - Detecting Software Plagiarism" href="#jplag---detecting-software-plagiarism"></a></p>
<p dir="auto"><a href="https://github.com/jplag/jplag/actions/workflows/maven.yml"><img src="https://github.com/jplag/jplag/actions/workflows/maven.yml/badge.svg" alt="CI Build"></a>
<a href="https://github.com/jplag/jplag/releases/latest"><img src="https://camo.githubusercontent.com/238b622c31a930e194fb51b58fd8ac7af8ea9d7dc10570de468d9f1bc7927feb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6a706c61672f6a706c61672e737667" alt="Latest Release" data-canonical-src="https://img.shields.io/github/release/jplag/jplag.svg"></a>
<a href="https://maven-badges.herokuapp.com/maven-central/de.jplag/jplag" rel="nofollow"><img src="https://camo.githubusercontent.com/951b77bc48a62248db7e3d88ac385d08d555029575ffb257d1bf3f0e974ca891/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f64652e6a706c61672f6a706c61672f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/de.jplag/jplag/badge.svg"></a>
<a href="https://github.com/jplag/jplag/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/20e140976e3d13efa4cdfa56c76cbc6b999d7fb83a5109bbec1f838ef322413f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6a706c61672f6a706c61672e737667" alt="License" data-canonical-src="https://img.shields.io/github/license/jplag/jplag.svg"></a>
<a href="https://github.com/jplag/JPlag/pulse"><img src="https://camo.githubusercontent.com/84cb3df907d0863228f9ecffd7bd69cf44b63029930fb4e4483c66e2f4e53b98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f792f6a706c61672f4a506c6167" alt="GitHub commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/y/jplag/JPlag"></a>
<a href="https://sonarcloud.io/component_measures?metric=Coverage&amp;view=list&amp;id=jplag_JPlag" rel="nofollow"><img src="https://camo.githubusercontent.com/6496471c4d3e0e8ed47854cfbeb61b36d6ee96abd4c7217819cdd86b93d1c73f/68747470733a2f2f736f6e6172636c6f75642e696f2f6170692f70726f6a6563745f6261646765732f6d6561737572653f70726f6a6563743d6a706c61675f4a506c6167266d65747269633d636f766572616765" alt="SonarCloud Coverage" data-canonical-src="https://sonarcloud.io/api/project_badges/measure?project=jplag_JPlag&amp;metric=coverage"></a>
<a href="https://jplag.github.io/JPlag/" rel="nofollow"><img src="https://camo.githubusercontent.com/f41e3c5aca2aed0628522aaecc0fb8e97092a3debf4148ae222c59429ddfc611/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265706f72742532307669657765722d6f6e6c696e652d623830303235" alt="Report Viewer" data-canonical-src="https://img.shields.io/badge/report%20viewer-online-b80025"></a>
<a href="#download-and-installation"><img src="https://camo.githubusercontent.com/abf8b2cbf3a31a6905cb13c4a35506a98e480e33dc889f76fca8cab35af11a63/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6176612d534525323032312d79656c6c6f77677265656e" alt="Java Version" data-canonical-src="https://img.shields.io/badge/java-SE%2021-yellowgreen"></a></p>
<p dir="auto">JPlag finds pairwise similarities among a set of multiple programs. It can reliably detect software plagiarism and collusion in software development, even when obfuscated. All similarities are calculated locally, and no source code or plagiarism results are ever uploaded to the internet. JPlag supports a large number of programming and modeling languages.</p>
<ul dir="auto">
<li>
<p dir="auto">ðŸ“ˆ <a href="https://jplag.github.io/Demo/" rel="nofollow">JPlag Demo</a></p>
</li>
<li>
<p dir="auto">ðŸ›ï¸ <a href="https://helmholtz.software/software/jplag" rel="nofollow">JPlag on Helmholtz RSD</a></p>
</li>
<li>
<p dir="auto">ðŸ¤© <a href="https://docs.google.com/forms/d/e/1FAIpQLSckqUlXhIlJ-H2jtu2VmGf_mJt4hcnHXaDlwhpUL3XG1I8UYw/viewform?usp=sf_link" rel="nofollow">Give us Feedback in a <strong>short (&lt;5 min) survey</strong></a></p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Languages</h2><a id="user-content-supported-languages" aria-label="Permalink: Supported Languages" href="#supported-languages"></a></p>
<p dir="auto">All supported languages and their supported versions are listed below.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Language</th>
<th>Version</th>
<th>CLI Argument Name</th>
<th><a href="https://github.com/jplag/JPlag/wiki/2.-Supported-Languages">state</a></th>
<th>parser</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.java.com/" rel="nofollow">Java</a></td>
<td>21</td>
<td>java</td>
<td>mature</td>
<td>JavaC</td>
</tr>
<tr>
<td><a href="https://isocpp.org/" rel="nofollow">C</a></td>
<td>11</td>
<td>c</td>
<td>legacy</td>
<td>JavaCC</td>
</tr>
<tr>
<td><a href="https://isocpp.org/" rel="nofollow">C++</a></td>
<td>14</td>
<td>cpp</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://docs.microsoft.com/en-us/dotnet/csharp/" rel="nofollow">C#</a></td>
<td>6</td>
<td>csharp</td>
<td>mature</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.python.org/" rel="nofollow">Python</a></td>
<td>3.6</td>
<td>python3</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.javascript.com/" rel="nofollow">JavaScript</a></td>
<td>ES6</td>
<td>javascript</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.typescriptlang.org/" rel="nofollow">TypeScript</a></td>
<td><a href="https://github.com/antlr/grammars-v4/tree/master/javascript/typescript/README.md">~5</a></td>
<td>typescript</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://go.dev/" rel="nofollow">Go</a></td>
<td>1.17</td>
<td>golang</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://kotlinlang.org/" rel="nofollow">Kotlin</a></td>
<td>1.3</td>
<td>kotlin</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.r-project.org/" rel="nofollow">R</a></td>
<td>3.5.0</td>
<td>rlang</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.rust-lang.org/" rel="nofollow">Rust</a></td>
<td>1.60.0</td>
<td>rust</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.swift.org/" rel="nofollow">Swift</a></td>
<td>5.4</td>
<td>swift</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="https://www.scala-lang.org/" rel="nofollow">Scala</a></td>
<td>2.13.8</td>
<td>scala</td>
<td>beta</td>
<td>Scalameta</td>
</tr>
<tr>
<td><a href="https://llvm.org/" rel="nofollow">LLVM IR</a></td>
<td>15</td>
<td>llvmir</td>
<td>beta</td>
<td>ANTLR 4</td>
</tr>
<tr>
<td><a href="http://www.scheme-reports.org/" rel="nofollow">Scheme</a></td>
<td>?</td>
<td>scheme</td>
<td>legacy</td>
<td>JavaCC</td>
</tr>
<tr>
<td><a href="https://www.eclipse.org/modeling/emf/" rel="nofollow">EMF Metamodel</a></td>
<td>2.25.0</td>
<td>emf</td>
<td>beta</td>
<td>EMF</td>
</tr>
<tr>
<td><a href="https://www.eclipse.org/modeling/emf/" rel="nofollow">EMF Model</a></td>
<td>2.25.0</td>
<td>emf-model</td>
<td>alpha</td>
<td>EMF</td>
</tr>
<tr>
<td><a href="https://www.w3.org/TR/scxml/" rel="nofollow">SCXML</a></td>
<td>1.0</td>
<td>scxml</td>
<td>alpha</td>
<td>XML</td>
</tr>
<tr>
<td>Text (naive)</td>
<td>-</td>
<td>text</td>
<td>legacy</td>
<td>CoreNLP</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download and Installation</h2><a id="user-content-download-and-installation" aria-label="Permalink: Download and Installation" href="#download-and-installation"></a></p>
<p dir="auto">You need Java SE 21 to run or build JPlag.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Downloading a release</h3><a id="user-content-downloading-a-release" aria-label="Permalink: Downloading a release" href="#downloading-a-release"></a></p>
<ul dir="auto">
<li>Download a <a href="https://github.com/jplag/jplag/releases">released version</a>.</li>
<li>In case you depend on the legacy version of JPlag we refer to the <a href="https://github.com/jplag/jplag/releases/tag/v2.12.1-SNAPSHOT">legacy release v2.12.1</a> and the <a href="https://github.com/jplag/jplag/tree/legacy">legacy branch</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Via Maven</h3><a id="user-content-via-maven" aria-label="Permalink: Via Maven" href="#via-maven"></a></p>
<p dir="auto">JPlag is released on <a href="https://search.maven.org/search?q=de.jplag" rel="nofollow">Maven Central</a>, it can be included as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<dependency>
  <groupId>de.jplag</groupId>
  <artifactId>jplag</artifactId>
  <version><!--desired version--></version>
</dependency>"><pre>&lt;<span>dependency</span>&gt;
  &lt;<span>groupId</span>&gt;de.jplag&lt;/<span>groupId</span>&gt;
  &lt;<span>artifactId</span>&gt;jplag&lt;/<span>artifactId</span>&gt;
  &lt;<span>version</span>&gt;<span><span>&lt;!--</span>desired version<span>--&gt;</span></span>&lt;/<span>version</span>&gt;
&lt;/<span>dependency</span>&gt;</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from sources</h3><a id="user-content-building-from-sources" aria-label="Permalink: Building from sources" href="#building-from-sources"></a></p>
<ol dir="auto">
<li>Download or clone the code from this repository.</li>
<li>Run <code>mvn clean package</code> from the root of the repository to compile and build all submodules.
Run <code>mvn clean package assembly:single</code> instead if you need the full jar which includes all dependencies.
Run <code>mvn -P with-report-viewer clean package assembly:single</code> to build the full jar with the report viewer. In this case, you'll need <a href="https://nodejs.org/en/download" rel="nofollow">Node.js</a> installed.</li>
<li>You will find the generated JARs in the subdirectory <code>cli/target</code>.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">JPlag can either be used via the CLI or directly via its Java API. For more information, see the <a href="https://github.com/jplag/JPlag/wiki/1.-How-to-Use-JPlag">usage information in the wiki</a>. If you are using the CLI, you can display your results via <a href="https://jplag.github.io/JPlag/" rel="nofollow">jplag.github.io</a>. No data will leave your computer!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI</h3><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<p dir="auto"><em>Note that the <a href="https://github.com/jplag/jplag/blob/legacy/README.md">legacy CLI</a> is varying slightly.</em>
The language can either be set with the -l parameter or as a subcommand (<code>jplag [jplag options] &lt;language name&gt; [language options]</code>). A subcommand takes priority over the -l option.
When using the subcommand, language-specific arguments can be set. A list of language-specific options can be obtained by requesting the help page of a subcommand (e.g. <code>jplag java -h</code>).</p>
<div data-snippet-clipboard-copy-content="Parameter descriptions: 
      [root-dirs[,root-dirs...]...]
                        Root-directory with submissions to check for plagiarism.
      -bc, --bc, --base-code=<baseCode>
                        Path to the base code directory (common framework used in all submissions).
  -l, --language=<language>
                        Select the language of the submissions (default: java). See subcommands below.
  -M, --mode=<{RUN, VIEW, RUN_AND_VIEW}>
                        The mode of JPlag: either only run analysis, only open the viewer, or do both (default: null)
  -n, --shown-comparisons=<shownComparisons>
                        The maximum number of comparisons that will be shown in the generated report, if set to -1 all comparisons will be shown (default: 500)
      -new, --new=<newDirectories>[,<newDirectories>...]
                        Root-directories with submissions to check for plagiarism (same as root).
      --normalize       Activate the normalization of tokens. Supported for languages: Java, C++.
      -old, --old=<oldDirectories>[,<oldDirectories>...]
                        Root-directories with prior submissions to compare against.
  -r, --result-file=<resultFile>
                        Name of the file in which the comparison results will be stored (default: results). Missing .zip endings will be automatically added.
  -t, --min-tokens=<minTokenMatch>
                        Tunes the comparison sensitivity by adjusting the minimum token required to be counted as a matching section. A smaller value increases the sensitivity but might lead to more
                          false-positives.

Advanced
      --csv-export      Export pairwise similarity values as a CSV file.
  -d, --debug           Store on-parsable files in error folder.
  -m, --similarity-threshold=<similarityThreshold>
                        Comparison similarity threshold [0.0-1.0]: All comparisons above this threshold will be saved (default: 0.0).
  -p, --suffixes=<suffixes>[,<suffixes>...]
                        comma-separated list of all filename suffixes that are included.
  -P, --port=<port>     The port used for the internal report viewer (default: 1996).
  -s, --subdirectory=<subdirectory>
                        Look in directories <root-dir>/*/<dir> for programs.
  -x, --exclusion-file=<exclusionFileName>
                        All files named in this file will be ignored in the comparison (line-separated list).

Clustering
      --cluster-alg, --cluster-algorithm=<{AGGLOMERATIVE, SPECTRAL}>
                        Specifies the clustering algorithm (default: spectral).
      --cluster-metric=<{AVG, MIN, MAX, INTERSECTION}>
                        The similarity metric used for clustering (default: average similarity).
      --cluster-skip    Skips the cluster calculation.

Subsequence Match Merging
      --gap-size=<maximumGapSize>
                        Maximal gap between neighboring matches to be merged (between 1 and minTokenMatch, default: 6).
      --match-merging   Enables merging of neighboring matches to counteract obfuscation attempts.
      --neighbor-length=<minimumNeighborLength>
                        Minimal length of neighboring matches to be merged (between 1 and minTokenMatch, default: 2).

Subcommands (supported languages):
  c
  cpp
  csharp
  emf
  emf-model
  go
  java
  javascript
  kotlin
  llvmir
  python3
  rlang
  rust
  scala
  scheme
  scxml
  swift
  text
  typescript"><pre><code>Parameter descriptions: 
      [root-dirs[,root-dirs...]...]
                        Root-directory with submissions to check for plagiarism.
      -bc, --bc, --base-code=&lt;baseCode&gt;
                        Path to the base code directory (common framework used in all submissions).
  -l, --language=&lt;language&gt;
                        Select the language of the submissions (default: java). See subcommands below.
  -M, --mode=&lt;{RUN, VIEW, RUN_AND_VIEW}&gt;
                        The mode of JPlag: either only run analysis, only open the viewer, or do both (default: null)
  -n, --shown-comparisons=&lt;shownComparisons&gt;
                        The maximum number of comparisons that will be shown in the generated report, if set to -1 all comparisons will be shown (default: 500)
      -new, --new=&lt;newDirectories&gt;[,&lt;newDirectories&gt;...]
                        Root-directories with submissions to check for plagiarism (same as root).
      --normalize       Activate the normalization of tokens. Supported for languages: Java, C++.
      -old, --old=&lt;oldDirectories&gt;[,&lt;oldDirectories&gt;...]
                        Root-directories with prior submissions to compare against.
  -r, --result-file=&lt;resultFile&gt;
                        Name of the file in which the comparison results will be stored (default: results). Missing .zip endings will be automatically added.
  -t, --min-tokens=&lt;minTokenMatch&gt;
                        Tunes the comparison sensitivity by adjusting the minimum token required to be counted as a matching section. A smaller value increases the sensitivity but might lead to more
                          false-positives.

Advanced
      --csv-export      Export pairwise similarity values as a CSV file.
  -d, --debug           Store on-parsable files in error folder.
  -m, --similarity-threshold=&lt;similarityThreshold&gt;
                        Comparison similarity threshold [0.0-1.0]: All comparisons above this threshold will be saved (default: 0.0).
  -p, --suffixes=&lt;suffixes&gt;[,&lt;suffixes&gt;...]
                        comma-separated list of all filename suffixes that are included.
  -P, --port=&lt;port&gt;     The port used for the internal report viewer (default: 1996).
  -s, --subdirectory=&lt;subdirectory&gt;
                        Look in directories &lt;root-dir&gt;/*/&lt;dir&gt; for programs.
  -x, --exclusion-file=&lt;exclusionFileName&gt;
                        All files named in this file will be ignored in the comparison (line-separated list).

Clustering
      --cluster-alg, --cluster-algorithm=&lt;{AGGLOMERATIVE, SPECTRAL}&gt;
                        Specifies the clustering algorithm (default: spectral).
      --cluster-metric=&lt;{AVG, MIN, MAX, INTERSECTION}&gt;
                        The similarity metric used for clustering (default: average similarity).
      --cluster-skip    Skips the cluster calculation.

Subsequence Match Merging
      --gap-size=&lt;maximumGapSize&gt;
                        Maximal gap between neighboring matches to be merged (between 1 and minTokenMatch, default: 6).
      --match-merging   Enables merging of neighboring matches to counteract obfuscation attempts.
      --neighbor-length=&lt;minimumNeighborLength&gt;
                        Minimal length of neighboring matches to be merged (between 1 and minTokenMatch, default: 2).

Subcommands (supported languages):
  c
  cpp
  csharp
  emf
  emf-model
  go
  java
  javascript
  kotlin
  llvmir
  python3
  rlang
  rust
  scala
  scheme
  scxml
  swift
  text
  typescript
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Java API</h3><a id="user-content-java-api" aria-label="Permalink: Java API" href="#java-api"></a></p>
<p dir="auto">The new API makes it easy to integrate JPlag's plagiarism detection into external Java projects:</p>

<div dir="auto" data-snippet-clipboard-copy-content="Language language = new JavaLanguage();
Set<File> submissionDirectories = Set.of(new File(&quot;/path/to/rootDir&quot;));
File baseCode = new File(&quot;/path/to/baseCode&quot;);
JPlagOptions options = new JPlagOptions(language, submissionDirectories, Set.of()).withBaseCodeSubmissionDirectory(baseCode);

try {
    JPlagResult result = JPlag.run(options);

    // Optional
    ReportObjectFactory reportObjectFactory = new ReportObjectFactory(new File(&quot;/path/to/output&quot;));
    reportObjectFactory.createAndSaveReport(result);
} catch (ExitException e) {
    // error handling here
} catch (FileNotFoundException e) {
    // handle IO exception here
}"><pre><span>Language</span> <span>language</span> = <span>new</span> <span>JavaLanguage</span>();
<span>Set</span>&lt;<span>File</span>&gt; <span>submissionDirectories</span> = <span>Set</span>.<span>of</span>(<span>new</span> <span>File</span>(<span>"/path/to/rootDir"</span>));
<span>File</span> <span>baseCode</span> = <span>new</span> <span>File</span>(<span>"/path/to/baseCode"</span>);
<span>JPlagOptions</span> <span>options</span> = <span>new</span> <span>JPlagOptions</span>(<span>language</span>, <span>submissionDirectories</span>, <span>Set</span>.<span>of</span>()).<span>withBaseCodeSubmissionDirectory</span>(<span>baseCode</span>);

<span>try</span> {
    <span>JPlagResult</span> <span>result</span> = <span>JPlag</span>.<span>run</span>(<span>options</span>);

    <span>// Optional</span>
    <span>ReportObjectFactory</span> <span>reportObjectFactory</span> = <span>new</span> <span>ReportObjectFactory</span>(<span>new</span> <span>File</span>(<span>"/path/to/output"</span>));
    <span>reportObjectFactory</span>.<span>createAndSaveReport</span>(<span>result</span>);
} <span>catch</span> (<span>ExitException</span> <span>e</span>) {
    <span>// error handling here</span>
} <span>catch</span> (<span>FileNotFoundException</span> <span>e</span>) {
    <span>// handle IO exception here</span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We're happy to incorporate all improvements to JPlag into this codebase. Feel free to fork the project and send pull requests.
Please consider our <a href="https://github.com/jplag/JPlag/wiki/3.-Contributing-to-JPlag">guidelines for contributions</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">If you encounter bugs or other issues, please report them <a href="https://github.com/jplag/jplag/issues">here</a>.
For other purposes, you can contact us at <a href="mailto:jplag@ipd.kit.edu">jplag@ipd.kit.edu</a> .
If you are doing research related to JPlag, we would love to know what you are doing. Feel free to contact us!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">More information can be found in our <a href="https://github.com/jplag/JPlag/wiki">Wiki</a>!</h3><a id="user-content-more-information-can-be-found-in-our-wiki" aria-label="Permalink: More information can be found in our Wiki!" href="#more-information-can-be-found-in-our-wiki"></a></p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>