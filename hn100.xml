<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 10 Feb 2026 18:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Google Handed ICE Student Journalist's Bank and Credit Card Numbers (143 pts)]]></title>
            <link>https://theintercept.com/2026/02/10/google-ice-subpoena-student-journalist/</link>
            <guid>46963804</guid>
            <pubDate>Tue, 10 Feb 2026 17:48:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theintercept.com/2026/02/10/google-ice-subpoena-student-journalist/">https://theintercept.com/2026/02/10/google-ice-subpoena-student-journalist/</a>, See on <a href="https://news.ycombinator.com/item?id=46963804">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p><span>Google provided</span> Immigration and Customs Enforcement with a wide array of personal data on a student activist and journalist, including his credit card and bank account numbers, according to a copy of an ICE subpoena obtained by The Intercept.</p>
<p><a href="https://theintercept.com/2025/09/16/google-facebook-subpoena-ice-students-gaza/">Amandla Thomas-Johnson</a> had attended a protest targeting companies that supplied weapons to Israel at a Cornell University job fair in 2024 for all of five minutes, but the action got him banned from campus. When President Donald Trump assumed office and issued a series of executive orders targeting students who protested in support of Palestinians, Thomas-Johnson and his friend Momodou Taal went into hiding.</p>
<p>Google informed Thomas-Johnson via a brief email in April that it had already shared his metadata with the Department of Homeland Security, as The Intercept <a href="https://theintercept.com/2025/09/16/google-facebook-subpoena-ice-students-gaza/">previously reported</a>. But the full extent of the information the tech giant provided —&nbsp;including usernames, addresses, itemized list of services, including any IP masking services, telephone or instrument numbers, subscriber numbers or identities, and credit card and bank account numbers — was not previously known.</p>
<p>“I’d already seen the subpoena request that Google and Meta had sent to Momodou [Taal], and I knew that he had gotten in touch with a lawyer and the lawyer successfully challenged that,” Thomas-Johnson said. “I was quite surprised to see that I didn’t have that opportunity.”<ins></ins></p>
<!-- BLOCK(cta)[0](%7B%22componentName%22%3A%22CTA%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) --><!-- END-BLOCK(cta)[0] -->
<p>The subpoena provides no justification for why ICE is asking for this information, except that it’s required “in connection with an investigation or inquiry relating to the enforcement of U.S. immigration laws.” In the subpoena, ICE requests that Google not “disclose the existence of this summons for indefinite period of time.”</p>
<p>Thomas-Johnson, who is British, believes that ICE requested that information to track and eventually detain him — but he had already fled to Geneva, Switzerland, and is now in Dakar, Senegal.&nbsp;</p>

<p>The Electronic Frontier Foundation, which is representing Thomas-Johnson, and the ACLU of Northern California sent a letter to Google, Amazon, Apple, Discord, Meta, Microsoft, and Reddit last week calling on tech companies to resist similar subpoenas in the future from DHS without court intervention. The letter asks the companies to provide users with as much notice as possible before complying with a subpoena to give them the opportunity to fight it, and to resist gag orders that would prevent the tech companies from informing targets that a subpoena was issued.</p>
<p>“Your promises to protect the privacy of users are being tested right now. As part of the federal government’s unprecedented campaign to target critics of its conduct and policies, agencies like DHS have repeatedly demanded access to the identities and information of people on your services,” the letter reads. “Based on our own contact with targeted users, we are deeply concerned your companies are failing to challenge unlawful surveillance and defend user privacy and speech.”</p>
<p>In addition to Thomas-Johnson’s case, the letter refers to other instances in which technology companies provided user data to DHS, including a subpoena sent to Meta to “unmask” the identities of users who documented immigration raids in California. Unlike Thomas-Johnson, users in that case were given the chance to fight the subpoena because they were made aware of it before Meta complied.</p>
<p>Lindsay Nash, a professor at Cardozo Law and a former staff attorney with ACLU Immigrants’ Rights Project, said that by not giving prior notice, Google deprived Thomas-Johnson of his ability to protect his information.</p>
<figure>
<blockquote>
<p>“Your promises to protect the privacy of users are being tested right now.”</p>
</blockquote>
</figure>
<p>“The problem is that it doesn’t allow the person whose personal information is on the line and whose privacy may be being invaded to raise challenges to the disclosure of that potentially private information,” Nash said. “And I think that’s important to protect rights that they may have to their own information.”</p>
<p>Google did not respond to a request for comment.</p>
<p>Tech companies’ data sharing practices are primarily governed by two federal laws, the Stored Communications Act, which protects the privacy of digital communications, including emails, and Section 5 of the Federal Trade Commission Act, which prohibits unfair or deceptive trade practices.</p>
<p>“Under both federal law and the law of every state, you cannot deceive consumers,” said Neil Richards, a law professor at Washington University St. Louis who specializes in privacy, the internet, and civil liberties. “And if you make a material misrepresentation about your data practices, that’s a deceptive trade practice.”</p>
<p>Whether or not corporations are clear enough with consumers about how they collect and share their <a href="https://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-sues-cambridge-analytica-settles-former-ceo-app-developer">data has been litigated for decades</a>, Richards said, referencing the infamous Cambridge Analytica lawsuit brought by the Federal Trade Commission, alleging that the company misled Facebook users about data collection and sharing.</p>
<!-- BLOCK(newsletter)[0](%7B%22componentName%22%3A%22NEWSLETTER%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) --><!-- END-BLOCK(newsletter)[0] -->
<p>Google’s <a href="https://policies.google.com/privacy#infosharing">public privacy policy acknowledges</a> that it will share personal information in response to an “enforceable governmental request,” adding that its legal team will “frequently push back when a request appears to be overly broad or doesn’t follow the correct process.”</p>
<p>According to Google, the <a href="https://transparencyreport.google.com/user-data/overview">company overwhelmingly complied with the millions of requests</a> made by the government for user information over the last decade. Its data also shows that those requests have spiked over the last five years. It’s unclear how many of those users were given notice of those requests ahead of time or after.</p>
<p>Richards said that cases like these emphasize the need for legal reforms around data privacy and urged Congress to amend the Stored Communications Act to require a higher standard before the government can access our digital data. He also said the federal government needs to regulate Big Tech and place “substantive restrictions on their ability to share information with the government.”</p>
<p>It’s hard to know exactly how tech companies are handling our personal data in relation to the government, but there seems to have been a shift in optics, Richards said. “What we have seen in the 12 months since the leaders of Big Tech were there on the podium at the inauguration,” Richards said, “is much more friendliness of Big Tech towards the government and towards state power.”</p>
<p>From Dakar, Thomas-Johnson said that understanding the extent of the subpoena was terrifying but had not changed his commitment to his <a>work</a>.</p>
<p>“As a journalist, what’s weird is that you’re so used to seeing things from the outside,” said Thomas-Johnson, whose work has appeared in outlets including Al Jazeera and The Guardian. “We need to think very hard about what resistance looks like under these conditions… where government and Big Tech know so much about us, can track us, can imprison, can destroy us in a variety of ways.”</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Hate brings views": Confessions of a London fake news TikToker (127 pts)]]></title>
            <link>https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants</link>
            <guid>46962924</guid>
            <pubDate>Tue, 10 Feb 2026 17:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants">https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants</a>, See on <a href="https://news.ycombinator.com/item?id=46962924">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!EHJR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EHJR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 424w, https://substackcdn.com/image/fetch/$s_!EHJR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 848w, https://substackcdn.com/image/fetch/$s_!EHJR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!EHJR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!EHJR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:752556,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!EHJR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 424w, https://substackcdn.com/image/fetch/$s_!EHJR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 848w, https://substackcdn.com/image/fetch/$s_!EHJR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!EHJR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dd2a1c7-a179-4daa-b9a2-8f12eb9a4900_1500x1000.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>London Centric’s investigation into the </span><a href="https://www.londoncentric.media/p/tiktok-london-immigrants-fake-news-house-tours" rel="">TikToker secretly filming fake anti-immigrant videos inside Londoners’ homes</a><span> generated a huge public response. </span></p><p>Amid the hundreds of comments two major questions remained: Who was the individual behind the TikTok account and what motivated them to make the videos? </p><p>Today, we have an extraordinary confession from someone purporting to be the TikToker in question. They are just one person in a sea of online hate content. But their explanation of their actions helps shed light on the motivations behind a wider online trend. </p><p>London is being used as the backdrop for inaccurate viral videos that reach enormous audiences around the world by playing into the worst stereotypes about the capital. </p><p><strong>See that story – and what Sadiq Khan has to say about our reporting – below. </strong></p><p><em>Read to the end for Taylor Swift’s visit to a forthcoming Croydon mixed-used redevelopment, the growing number of freemasons in the Met police, and what we missed about Jeffrey Epstein’s London.</em></p><p><strong>By Katherine Denkinson and Jim Waterson</strong></p><p>The man on the recording is baffled. He can’t understand how London Centric traced his anonymous hate-filled London TikTok account back to his employer by geolocating the wheelie bins in his videos.</p><p>“I thought no one’s gonna notice that,” he says. “Why would someone?”</p><p>Last summer, the man says, he found himself sitting in his car, analysing trends on TikTok. His day job was conducting viewings for an estate agency but he was trying to come up with an idea for a viral video account that could be run as a money-making side-hustle.</p><p>“I was thinking of unique videos I can do for people,” he says on the tape. </p><p>That’s when he had a brainwave: “Hate brings views.” </p><p>At that time protests outside asylum hotels were spreading across the country. The man says he noticed “far-right people” were among the most engaged on TikTok. They were easy to rile up: “They hate such videos of illegal migrants. I was like, why not?”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!EuSS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EuSS!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 424w, https://substackcdn.com/image/fetch/$s_!EuSS!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 848w, https://substackcdn.com/image/fetch/$s_!EuSS!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!EuSS!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!EuSS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg" width="1236" height="1088" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1088,&quot;width&quot;:1236,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:452687,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!EuSS!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 424w, https://substackcdn.com/image/fetch/$s_!EuSS!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 848w, https://substackcdn.com/image/fetch/$s_!EuSS!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!EuSS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbae4353c-8b38-46a0-95eb-557b393eb3fc_1236x1088.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Typical screengrabs of videos from the viral TikTok account.</figcaption></figure></div><p>The result was the account Reform_UK_2025, which co-opted the logo and name of Nigel Farage’s political movement without permission from the party. It posted video tours of Londoners’ homes accompanied by an AI-generated voice claiming properties in Knightsbridge and Chelsea had been handed over to illegal immigrants for free. It smeared residents, who were visible in some of the videos, as rapists and said that others proclaimed their hatred of the UK while collecting the keys.</p><p>It was an instant hit, attracting millions of views. It was also, the man confesses, all lies.</p><p><strong>“Dangerous and divisive”</strong></p><p>You don’t have to believe London is anywhere near perfect to recognise the increasing divergence between the way the city is portrayed online and the reality on the streets.</p><p>Sadiq Khan told London Centric that our latest investigation into this anonymous TikTok account reveals part of a “dangerous and divisive” trend that sees “bad faith actors spreading hate for clicks”.</p><p>“Accounts are talking London down because the algorithms reward them for doing so,” said the mayor.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!n136!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!n136!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 424w, https://substackcdn.com/image/fetch/$s_!n136!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 848w, https://substackcdn.com/image/fetch/$s_!n136!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!n136!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!n136!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg" width="1238" height="936" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:936,&quot;width&quot;:1238,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:373708,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!n136!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 424w, https://substackcdn.com/image/fetch/$s_!n136!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 848w, https://substackcdn.com/image/fetch/$s_!n136!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!n136!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cbd0ba6-ae1b-47b2-8158-5febab9a9d03_1238x936.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>How legitimate private tenants were described on the viral TikTok account.</figcaption></figure></div><p><strong>The “one rogue contractor” defence</strong></p><p>When London Centric tried to work out who was running the Reform_UK_2025 account, our investigation led us to SmartLet Estates, a north London estate agency. </p><p>When we confronted company director Sam Wasserstrum, he said he knew who was running the TikTok account but wasn’t willing to share their name with us. He claimed they were a member of the public who had been looking to rent a flat from his company.</p><p>He now accepts that was a lie – and he knew it was a lie when he told us. </p><p>Now, Wasserstrum wants to set out a different version of events. He says the person behind the camera was really a “rogue” contractor he employed for two years as a viewings agent to show potential residents around the properties. Wasserstrum says he had no idea that his employee had been running the hate-filled TikTok account until we first approached his company in November. He says the employee was sacked soon afterwards and he regrets ever telling us that a client was responsible.</p><p>To back up his case, Wasserstrum provided London Centric with multiple lengthy audio recordings of what he says is him confronting the anonymous employee. One of these tapes, he says, was recorded before he told London Centric he would not reveal the name of the culprit. The other was recorded after we published our article.</p><p>Wasserstrum did not provide the name of employee and we have not been able to independently verify the veracity of his story. However, metadata associated the audio files suggests the conversations took place around the dates that London Centric began asking questions.</p><p>The extraordinary taped confession is a rare insight into what motivates people to run fake news accounts on TikTok – and how monetising engagement can also effectively monetise hate, with little concern for its real-world impact.</p><p><strong>“One day I might make some money.”</strong></p><p>The audio on the tape is clear, with Wasserstrum’s voice asking questions in what sounds like an HR-style meeting.</p><p>The employee explains his motivation for setting up the anti-migrant fake news account was simple: “One day I might make some money.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!347C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!347C!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 424w, https://substackcdn.com/image/fetch/$s_!347C!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 848w, https://substackcdn.com/image/fetch/$s_!347C!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!347C!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!347C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg" width="432" height="629.1262135922331" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1500,&quot;width&quot;:1030,&quot;resizeWidth&quot;:432,&quot;bytes&quot;:195041,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!347C!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 424w, https://substackcdn.com/image/fetch/$s_!347C!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 848w, https://substackcdn.com/image/fetch/$s_!347C!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!347C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a4f6cd-1ea3-4846-9ce1-9f902a66bb74_1030x1500.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Another video supposedly showing a house given to illegal immigrants. When London Centric visited the London property we found legal residents renting privately.</figcaption></figure></div><p>The aim, he explains, was to build an audience and then make cash through TikTok, which allows people to monetise content once they reach a certain number of views and followers on the platform.</p><p>He’d previously run a TikTok account that had amassed 24,000 followers. One night, he was astonished to find, he received his first payout from TikTok’s creator scheme.</p><p>His head was turned by the substantial sum of money: “I told my wife, wow, it’s £1,000.”</p><p>Then, to his annoyance, TikTok immediately deleted his account because he was just stealing other people’s videos and reposting them.</p><p>Hooked on the income and in search for a new source of original content, he decided to start filming videos of homes across London while he was hosting viewings.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!GIdl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!GIdl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 424w, https://substackcdn.com/image/fetch/$s_!GIdl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 848w, https://substackcdn.com/image/fetch/$s_!GIdl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!GIdl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!GIdl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg" width="1116" height="952" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:952,&quot;width&quot;:1116,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:342385,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!GIdl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 424w, https://substackcdn.com/image/fetch/$s_!GIdl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 848w, https://substackcdn.com/image/fetch/$s_!GIdl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!GIdl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee6fc16-6b08-4277-9ef3-ea77a9e39b11_1116x952.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Furious comments on the TikTok account about the houses being handed to “illegal immigrants”.</figcaption></figure></div><p>He added an AI-generated voiceover about asylum seekers, rapists, and illegal immigrants then pressed upload. The audience response was instant and enormous, and TikTok’s algorithm responded by pushing it into the feeds of hundreds of thousands of people. Irate Londoners drove up engagement by complaining they couldn’t afford such properties while illegal immigrants were supposedly getting them for free.</p><p><em>London Centric doesn’t have a marketing team – if you found this article interesting, please forward it to a friend, post it in your WhatsApp group, or recommend it on social platforms.</em></p><p><span>Last year a </span><a href="https://www.thebureauinvestigates.com/stories/2025-10-16/new-ai-video-tools-are-fuelling-racism-on-tiktok" rel="">report</a><span> by The Bureau of Investigative Journalism showed AI-generated racist videos amassing millions of views despite breaching TikTok’s guidelines on hate-speech. </span></p><p>A spokesperson for TikTok told London Centric that “hate has no place” on its platform: “Of the content we’ve removed for breaking these rules, more than 94% was taken down before being reported to us, and we work with experts to keep ahead of evolving trends and continually strengthen our safeguards against hate.”</p><p>The man on the tape seems to feel otherwise.</p><p>“My first video got one million [views],” he says. “Most of the videos got over 10,000… so I thought, one day I might make some money.”</p><p>TikTok told us: “This article is based on the opinion of one unnamed individual, and it is not representative of the positive and creative experience that millions enjoy every day on TikTok.”</p><p><strong>“I wrote down ‘illegal migrants’.”</strong></p><p><span>The TikToker appears to have no concept of the potential real-world impact of his uploads, instead considering everything in terms of view counts and pieces of content. He even suggests that Wasserstrum should not be concerned by London Centric’s reporting because </span><a href="https://www.tiktok.com/@jimwaterson/video/7599207225571233046?lang=en" rel="">our own video</a><span> didn’t attract anything like as many viewers as his original hate-filled fake uploads. </span></p><p>“Their video didn’t even go that viral,” he offers by way of defence, arguing it could therefore be ignored. “They only got like 200,000 views on TikTok. It’s probably gonna die. It’s not gonna last long.”</p><p>The man tells Wasserstrum that he does not want to own up to running the account because “it’s going to make it much worse” and could “ruin [his] life”. In any case, he says, journalists would simply think he was a “paid actor”.</p><p>Wasserstrum can be heard on the recordings spelling out to the man how London Centric had approached the business. “They came to the office... they had every single fact you can think about,” he says. “They’ve cross referenced everything… We’ve had management companies calling us, councils calling us up, saying you’re putting our clients in danger.”</p><p>The man appears confused by the fuss his actions have caused. He gives the impression that he considered TikTok’s algorithm and the site’s content regulation policies to be the ultimate arbiter of whether a video crossed a line. </p><p>He insists the impact on tenants whose faces are visible in some of the videos was limited because they “didn’t get a lot of views” compared to his other content.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!9sZR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!9sZR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 424w, https://substackcdn.com/image/fetch/$s_!9sZR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 848w, https://substackcdn.com/image/fetch/$s_!9sZR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!9sZR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!9sZR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg" width="494" height="229" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:229,&quot;width&quot;:494,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:10844,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!9sZR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 424w, https://substackcdn.com/image/fetch/$s_!9sZR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 848w, https://substackcdn.com/image/fetch/$s_!9sZR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!9sZR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff200f2f0-5de3-46cd-9621-9ee531cdccce_494x229.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A comment left by the account creator on one of his videos.</figcaption></figure></div><p>“It wasn’t racist,” the man says of his account. He argues that if the videos had really been racist, TikTok’s algorithm would have downgraded the content. Instead, he was rewarded with millions of views. He was just an entrepreneur following a simple content strategy: “Every single video I would basically copy paste the same thing. I wrote down ‘illegal migrants’.”</p><p><strong>“Spreading hate for clicks”</strong></p><p>London Centric took our findings to the mayor of London, Sadiq Khan, who recently raised concerns about the growing impact of dubious viral videos on global perceptions of the city. </p><p>“While the social media revolution has come with extraordinary benefits, we’re also seeing a surge in misinformation and online abuse, due to a lack of sufficient guardrails,” the mayor told us.</p><p>“The large social media companies and regulators need to do much more to prevent algorithms pushing hate and violence and promoting misinformation and disinformation into people’s feeds.</p><p>“Our democracies are being undermined by those bad faith actors spreading hate for clicks.” </p><p><strong>“We have reported the matter to the police”</strong></p><p>On Friday Wasserstrum said that he has asked the police to investigate his former employee.</p><p>In a statement issued to London Centric the estate agency boss said: “We are aware of the vile and extremely dangerous TikTok videos that were filmed inside properties let by SmartLet Estates. We recognise the very real threat that these videos posed to the individuals filmed and to whom false views were attributed. We have reported the matter to the police.</p><p>“We conducted a thorough investigation as soon as the matter was brought to our attention. We established that the videos were created by a third-party contractor who acted without the authority, knowledge, or consent of the company. We severed all ties with the contractor immediately. We are appalled by his actions and condemn them in the strongest possible terms.</p><p>“We are committed to acting transparently and rebuilding trust with our partners and the communities we serve. We are fully prepared to cooperate with the authorities and to assist with any investigation.”</p><p>Despite fostering online hatred, the man recorded by Wasserstrum insists he doesn’t personally share the views expressed on his TikTok account. Instead, he suggests his fake anti-migrant house tour videos were just a way to game the algorithm, build an audience, and hopefully make money.</p><p>”I didn’t do anything because of hate,” he says on the tape. “I didn’t care. It’s just I wanted the clicks.”</p><p data-attrs="{&quot;url&quot;:&quot;https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants/comments" rel=""><span>Leave a comment</span></a></p><p><em>All our reporting is funded by our paying subscribers, who receive exclusive investigations. Your support for original investigative local journalism is very much appreciated.</em></p><p><em><span>Click </span><a href="https://www.londoncentric.media/p/tiktok-london-immigrants-fake-news-house-tours" rel="">here</a><span> to read our original investigation into the account, including a film by Jonah Sealey Braverman. </span></em></p><p><em><span>Want to get in touch with London Centric? Send us a </span><a href="https://wa.me/447760993558" rel="">WhatsApp</a><span> or send an </span><a href="mailto:hello@londoncentric.media" rel="">email</a><span> or leave a comment on this piece.  </span></em></p><p>In November Taylor Swift flew 3,500 miles in her private jet to film the music video to her song ‘Opalite’ at one of London’s leading attractions: Whitgift shopping centre in Croydon. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!VH9a!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!VH9a!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 424w, https://substackcdn.com/image/fetch/$s_!VH9a!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 848w, https://substackcdn.com/image/fetch/$s_!VH9a!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 1272w, https://substackcdn.com/image/fetch/$s_!VH9a!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!VH9a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png" width="1456" height="1092" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3690864,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!VH9a!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 424w, https://substackcdn.com/image/fetch/$s_!VH9a!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 848w, https://substackcdn.com/image/fetch/$s_!VH9a!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 1272w, https://substackcdn.com/image/fetch/$s_!VH9a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b1c3f1-9595-4c95-8f9b-9a4af4fdfea2_2002x1502.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This week the finished video was released, introducing hundreds of millions of Swift fans around the world to Croydon’s forever-awaiting-development mall. </p><p>It is not known whether Swift took any time off from filming to examine the long-delayed plans for redeveloping the site,  nor whether she has any views on the council-backed proposals which will see her filming location become part of a mixed-used construction project featuring homes and retail.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!RfnM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!RfnM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 424w, https://substackcdn.com/image/fetch/$s_!RfnM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 848w, https://substackcdn.com/image/fetch/$s_!RfnM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 1272w, https://substackcdn.com/image/fetch/$s_!RfnM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!RfnM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png" width="1456" height="2031" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2031,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:11272728,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.londoncentric.media/i/187071963?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!RfnM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 424w, https://substackcdn.com/image/fetch/$s_!RfnM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 848w, https://substackcdn.com/image/fetch/$s_!RfnM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 1272w, https://substackcdn.com/image/fetch/$s_!RfnM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34eebe17-f993-4e9b-9f8a-bd4b092fed68_2374x3312.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Top: Taylor Swift and Domhnall Gleeson descend Whitgift shopping centre’s escalators. Bottom: Taylor Swift and Domhall Gleeson strangely not in Whitgift shopping centre when London Centric visited on Friday afternoon.</figcaption></figure></div><p>Her team were able to secure the location for a weekend of filming due to the increasing number of empty units as shops increasingly desert the shopping centre. </p><div><p><span>When London Centric visited on Friday afternoon locals seemed more interested in restoring pride to their local high street rather than Swift. Passerby Darryl, 34, from Croydon asked: “Why the Whitgift? Is her video supposed to represent a dystopian future?”</span></p><p><span>When the pop star featured Kentish Delight, a kebab shop in Camden, in her 2018 music video for End Game, the owner said it boosted business. Whether Swifties will descend on the Whitgift – or Stoke Newington’s Mildmay club, which also features in the new video – with the same enthusiasm remains to be seen.</span></p></div><p>The Met police’s battle to force its employees to register their membership of freemasonry lodges continues. London Centric’s latest Freedom of Information request found that 386 police officers and Met staff have now declared “they are or have been a member of the Freemasonry Organisation” since the rule came into effect at the end of last year. That’s up from the 300 made public last month. </p><p><span>Our story on Jeffrey Epstein’s discussions about buying a central London hotel to host his London “playroom” was followed up in most of the national newspapers. Some of them even kindly remembered to credit London Centric. If you want to read the original, </span><a href="https://www.londoncentric.media/p/jeffrey-epsteins-london-hotel-property-houses" rel="">it’s here</a><span>. As one reader pointed out, we’d failed to note that Dukes hotel has a side entrance onto a narrow road called Little St James’s – which shares its name with the deceased sex offender’s private Caribbean island.</span></p><p><em>We’ll be back next week with more exclusive original reporting on London.</em></p><p data-attrs="{&quot;url&quot;:&quot;https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.londoncentric.media/p/london-tiktok-fake-news-creator-hate-immigrants/comments" rel=""><span>Leave a comment</span></a></p><p>. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I started programming when I was 7. I'm 50 now and the thing I loved has changed (340 pts)]]></title>
            <link>https://www.jamesdrandall.com/posts/the_thing_i_loved_has_changed/</link>
            <guid>46960675</guid>
            <pubDate>Tue, 10 Feb 2026 15:08:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jamesdrandall.com/posts/the_thing_i_loved_has_changed/">https://www.jamesdrandall.com/posts/the_thing_i_loved_has_changed/</a>, See on <a href="https://news.ycombinator.com/item?id=46960675">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>I Started Programming When I Was 7. I'm 50 Now, and the Thing I Loved Has Changed</p><div><p>I wrote my first line of code in 1983. I was seven years old, typing BASIC into a machine that had less processing power than the chip in your washing machine. I understood that machine completely. Every byte of RAM had a purpose I could trace. Every pixel on screen was there because I’d put it there. The path from intention to result was direct, visible, and mine.</p>
<p>Forty-two years later, I’m sitting in front of hardware that would have seemed like science fiction to that kid, and I’m trying to figure out what “building things” even means anymore.</p>
<p>This isn’t a rant about AI. It’s not a “back in my day” piece. It’s something I’ve been circling for months, and I think a lot of experienced developers are circling it too, even if they haven’t said it out loud yet.</p>
<h2 id="the-era-that-made-me">The era that made me</h2>
<p>My favourite period of computing runs from the 8-bits through to about the 486DX2-66. Every machine in that era had character. The Sinclair Spectrum with its attribute clash. The Commodore 64 with its SID chip doing things the designers never intended. The NES with its 8-sprite-per-scanline limit that made developers invent flickering tricks to cheat the hardware. And the PC — starting life as a boring beige box for spreadsheets, then evolving at breakneck pace through the 286, 386, and 486 until it became a gaming powerhouse that could run Doom. You could feel each generation leap. Upgrading your CPU wasn’t a spec sheet exercise — it was transformative.</p>
<p>These weren’t just products. They were engineering adventures with visible tradeoffs. You had to understand the machine to use it. IRQ conflicts, DMA channels, CONFIG.SYS and AUTOEXEC.BAT optimisation, memory managers — getting a game to run <em>was</em> the game. You weren’t just a user. You were a systems engineer by necessity.</p>
<p>And the software side matched. Small teams like id Software were going their own way, making bold technical decisions because nobody had written the rules yet. Carmack’s raycasting in Wolfenstein, the VGA Mode X tricks in Doom — these were people pushing against real constraints and producing something genuinely new. Creative constraints bred creativity.</p>
<p>Then it professionalised. Plug and Play arrived. Windows abstracted everything. The Wild West closed. Computers stopped being fascinating, cantankerous machines that demanded respect and understanding, and became appliances. The craft became invisible.</p>
<p>But it wasn’t just the craft that changed. The promise changed.</p>
<p>When I started, there was a genuine optimism about what computers could be. A kid with a Spectrum could teach themselves to build anything. The early web felt like the greatest levelling force in human history. Small teams made bold decisions because nobody had written the rules yet.</p>
<p>That hope gave way to something I find genuinely distasteful. The machines I fell in love with became instruments of surveillance and extraction. The platforms that promised to connect us were really built to monetise us. The tinkerer spirit didn’t die of natural causes — it was bought out and put to work optimising ad clicks.</p>
<p>The thing I loved changed, and then it was put to work doing things I’m not proud to be associated with. That’s a different kind of loss than just “the tools moved on.”</p>
<p>But I adapted. That’s what experienced developers, human beings, do.</p>
<h2 id="the-shifts-i-rode">The shifts I rode</h2>
<p>Over four decades I’ve been through more technology transitions than I can count. New languages, new platforms, new paradigms. CLI to GUI. Desktop to web. Web to mobile. Monoliths to microservices. Tapes, floppy discs, hard drives, SSDs. JavaScript frameworks arriving and dying like mayflies.</p>
<p>Each wave required learning new things, but the core skill transferred. You learned the new platform, you applied your existing understanding of how systems work, and you kept building. The tool changed; the craft didn’t. You were still the person who understood why things broke, how systems composed, where today’s shortcut became next month’s mess.</p>
<p>I’ve written production code in more languages than some developers have heard of. I’ve shipped software on platforms that no longer exist. I’ve chased C-beams off the shoulder of Orion. And every time the industry lurched in a new direction, the experience compounded. You didn’t start over. You brought everything with you and applied it somewhere new.</p>
<p>That’s the deal experienced developers made with the industry: things change, but understanding endures.</p>
<h2 id="this-time-is-different">This time is different</h2>
<p>I say that knowing how often those words have been wrong throughout history. But hear me out.</p>
<p>Previous technology shifts were “learn the new thing, apply existing skills.” AI isn’t that. It’s not a new platform or a new language or a new paradigm. It’s a shift in what it <em>means</em> to be good at this.</p>
<p>I noticed it gradually. I’d be working on something — building a feature, designing an architecture — and I’d realise I was still doing the same thing I’d always done, just with the interesting bits hollowed out. The part where you figure out the elegant solution, where you wrestle with the constraints, where you feel the satisfaction of something clicking into place — that was increasingly being handled by a model that doesn’t care about elegance and has never felt satisfaction.</p>
<p>Cheaper. Faster. But hollowed out.</p>
<p>I’m not typing the code anymore. I’m reviewing it, directing it, correcting it. And I’m good at that — 42 years of accumulated judgment about what works and what doesn’t, what’s elegant versus what’s expedient, how systems compose and where they fracture. That’s valuable. I know it’s valuable. But it’s a different kind of work, and it doesn’t feel the same.</p>
<p>The feedback loop has changed. The intimacy has gone. The thing that kept me up at night for decades — the puzzle, the chase, the moment where you finally understand why something isn’t working — that’s been compressed into a prompt and a response. And I’m watching people with a fraction of my experience produce superficially similar output. The craft distinction is real, but it’s harder to see from the outside. Harder to value. Maybe harder to feel internally.</p>
<h2 id="the-abstraction-tower">The abstraction tower</h2>
<p>Here’s the part that makes me laugh, darkly.</p>
<p>I saw someone on LinkedIn recently — early twenties, a few years into their career — lamenting that with AI they “didn’t really know what was going on anymore.” And I thought: mate, you were <em>already</em> so far up the abstraction chain you didn’t even realise you were teetering on top of a wobbly Jenga tower.</p>
<p>They’re writing TypeScript that compiles to JavaScript that runs in a V8 engine written in C++ that’s making system calls to an OS kernel that’s scheduling threads across cores they’ve never thought about, hitting RAM through a memory controller with caching layers they couldn’t diagram, all while npm pulls in 400 packages they’ve never read a line of.</p>
<p>But sure. <em>AI</em> is the moment they lost track of what’s happening.</p>
<p>The abstraction ship sailed decades ago. We just didn’t notice because each layer arrived gradually enough that we could pretend we still understood the whole stack. AI is just the layer that made the pretence impossible to maintain.</p>
<p>The difference is: I remember what it felt like to understand the whole machine. I’ve <em>had</em> that experience. And losing it — even acknowledging that it was lost long before AI arrived — is a kind of grief that someone who never had it can’t fully feel.</p>
<h2 id="what-remains">What remains</h2>
<p>I don’t want to be dishonest about this. There’s a version of this post where I tell you that experience is more valuable than ever, that systems thinking and architectural judgment are the things AI can’t replace, that the craft endures in a different form.</p>
<p>And that’s true. When I’m working on something complex — juggling system-level dependencies, holding a mental model across multiple interacting specifications, making the thousand small decisions that determine whether something feels coherent or just <em>works</em> — I can see how I still bring something AI doesn’t. The taste. The judgment. The pattern recognition from decades of seeing things go wrong.</p>
<p>AI tools actually make that kind of thinking <em>more</em> valuable, not less. When code generation is cheap, the bottleneck shifts to the person who knows what to ask for, can spot when the output is subtly wrong, and can hold the whole picture together. Typing was never the hard part.</p>
<p>But I’d be lying if I said it felt the same. It doesn’t. The wonder is harder to access. The sense of discovery, of figuring something out through sheer persistence and ingenuity — that’s been compressed. Not eliminated, but compressed. And something is lost in the compression, even if something is gained.</p>
<h2 id="the-fallow-period">The fallow period</h2>
<p>I turned 50 recently. Four decades of intensity, of crafting and finding satisfaction and identity in the building.</p>
<p>And now I’m in what I’ve started calling a fallow period. Not burnout exactly. More like the ground shifting under a building you thought that although ever changing also had a permanence, and trying to figure out where the new foundation is.</p>
<p>I don’t have a neat conclusion. I’m not going to tell you that experienced developers just need to “push themselves up the stack” or “embrace the tools” or “focus on what AI can’t do.” All of that is probably right, and none of it addresses the feeling.</p>
<p>The feeling is: I gave 42 years to this thing, and the thing changed into something I’m not sure I recognise anymore. Not worse, necessarily. Just different. And different in a way that challenges the identity I built around it and doesn’t satisfy in the way it did.</p>
<p>I suspect a lot of developers over 40 are feeling something similar and not saying it, because the industry worships youth and adaptability and saying “this doesn’t feel like it used to” sounds like you’re falling behind.</p>
<p>I’m not falling behind. I’m moving ahead, taking advantage of the new tools, building faster than ever, and using these tools to help others accelerate their own work. I’m creating products I could only have dreamt of a few years ago. But at the same time I’m looking at the landscape, trying to figure out what building means to me now. The world’s still figuring out its shape too. Maybe that’s okay.</p>
<p>Maybe the fallow period is the point. Not something to push through, but something to be in for a while.</p>
<p>I started programming when I was seven because a machine did exactly what I told it to, felt like something I could explore and ultimately know, and that felt like magic. I’m fifty now, and the magic is different, and I’m learning to sit with that.</p>
<hr>
<p>Photo by <a href="https://unsplash.com/@soymeraki?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Javier Allegue Barros</a> on <a href="https://unsplash.com/photos/silhouette-of-road-signage-during-golden-hour-C7B-ExXpOIE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The US is flirting with its first-ever population decline (181 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2026-01-30/trump-immigration-crackdown-could-shrink-us-population-for-first-time</link>
            <guid>46960624</guid>
            <pubDate>Tue, 10 Feb 2026 15:05:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2026-01-30/trump-immigration-crackdown-could-shrink-us-population-for-first-time">https://www.bloomberg.com/news/articles/2026-01-30/trump-immigration-crackdown-could-shrink-us-population-for-first-time</a>, See on <a href="https://news.ycombinator.com/item?id=46960624">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2026-01-30/trump-immigration-crackdown-could-shrink-us-population-for-first-time: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Vercel's CEO offers to cover expenses of 'Jmail' (161 pts)]]></title>
            <link>https://www.threads.com/@qa_test_hq/post/DUkC_zjiGQh</link>
            <guid>46960517</guid>
            <pubDate>Tue, 10 Feb 2026 14:58:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.threads.com/@qa_test_hq/post/DUkC_zjiGQh">https://www.threads.com/@qa_test_hq/post/DUkC_zjiGQh</a>, See on <a href="https://news.ycombinator.com/item?id=46960517">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Parse, Don't Validate (2019) (155 pts)]]></title>
            <link>https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/</link>
            <guid>46960392</guid>
            <pubDate>Tue, 10 Feb 2026 14:49:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/</a>, See on <a href="https://news.ycombinator.com/item?id=46960392">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main"><article><header></header><p>Historically, I’ve struggled to find a concise, simple way to explain what it means to practice type-driven design. Too often, when someone asks me “How did you come up with this approach?” I find I can’t give them a satisfying answer. I know it didn’t just come to me in a vision—I have an iterative design process that doesn’t require plucking the “right” approach out of thin air—yet I haven’t been very successful in communicating that process to others.</p><p>However, about a month ago, <a href="https://twitter.com/lexi_lambda/status/1182242561655746560">I was reflecting on Twitter</a> about the differences I experienced parsing JSON in statically- and dynamically-typed languages, and finally, I realized what I was looking for. Now I have a single, snappy slogan that encapsulates what type-driven design means to me, and better yet, it’s only three words long:</p><p><strong>Parse, don’t validate.</strong></p><h2><a name="the-essence-of-type-driven-design"></a>The essence of type-driven design</h2><p>Alright, I’ll confess: unless you already know what type-driven design is, my catchy slogan probably doesn’t mean all that much to you. Fortunately, that’s what the remainder of this blog post is for. I’m going to explain precisely what I mean in gory detail—but first, we need to practice a little wishful thinking.</p><h3><a name="the-realm-of-possibility"></a>The realm of possibility</h3><p>One of the wonderful things about static type systems is that they can make it possible, and sometimes even easy, to answer questions like “is it possible to write this function?” For an extreme example, consider the following Haskell type signature:</p><pre><code><span>foo</span><span> </span><span>::</span><span> </span><span>Integer</span><span> </span><span>-&gt;</span><span> </span><span>Void</span></code></pre><p>Is it possible to implement <code>foo</code>? Trivially, the answer is <em>no</em>, as <code>Void</code> is a type that contains no values, so it’s impossible for <em>any</em> function to produce a value of type <code>Void</code>.<sup><a href="#footnote-1" id="footnote-ref-1-1">1</a></sup> That example is pretty boring, but the question gets much more interesting if we choose a more realistic example:</p><pre><code><span>head</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>a</span></code></pre><p>This function returns the first element from a list. Is it possible to implement? It certainly doesn’t sound like it does anything very complicated, but if we attempt to implement it, the compiler won’t be satisfied:</p><pre><code><span>head</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>a</span>
<span>head</span><span> </span><span>(</span><span>x</span><span>:</span><span>_</span><span>)</span><span> </span><span>=</span><span> </span><span>x</span></code></pre><pre><code>warning: [-Wincomplete-patterns]
    Pattern match(es) are non-exhaustive
    In an equation for ‘head’: Patterns not matched: []
</code></pre><p>This message is helpfully pointing out that our function is <em>partial</em>, which is to say it is not defined for all possible inputs. Specifically, it is not defined when the input is <code>[]</code>, the empty list. This makes sense, as it isn’t possible to return the first element of a list if the list is empty—there’s no element to return! So, remarkably, we learn this function isn’t possible to implement, either.</p><h3><a name="turning-partial-functions-total"></a>Turning partial functions total</h3><p>To someone coming from a dynamically-typed background, this might seem perplexing. If we have a list, we might very well want to get the first element in it. And indeed, the operation of “getting the first element of a list” isn’t impossible in Haskell, it just requires a little extra ceremony. There are two different ways to fix the <code>head</code> function, and we’ll start with the simplest one.</p><h4><a name="managing-expectations"></a>Managing expectations</h4><p>As established, <code>head</code> is partial because there is no element to return if the list is empty: we’ve made a promise we cannot possibly fulfill. Fortunately, there’s an easy solution to that dilemma: we can weaken our promise. Since we cannot guarantee the caller an element of the list, we’ll have to practice a little expectation management: we’ll do our best return an element if we can, but we reserve the right to return nothing at all. In Haskell, we express this possibility using the <code>Maybe</code> type:</p><pre><code><span>head</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>Maybe</span><span> </span><span>a</span></code></pre><p>This buys us the freedom we need to implement <code>head</code>—it allows us to return <code>Nothing</code> when we discover we can’t produce a value of type <code>a</code> after all:</p><pre><code><span>head</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>Maybe</span><span> </span><span>a</span>
<span>head</span><span> </span><span>(</span><span>x</span><span>:</span><span>_</span><span>)</span><span> </span><span>=</span><span> </span><span>Just</span><span> </span><span>x</span>
<span>head</span><span> </span><span>[]</span><span>    </span><span>=</span><span> </span><span>Nothing</span></code></pre><p>Problem solved, right? For the moment, yes… but this solution has a hidden cost.</p><p>Returning <code>Maybe</code> is undoubtably convenient when we’re <em>implementing</em>  <code>head</code>. However, it becomes significantly less convenient when we want to actually use it! Since <code>head</code> always has the potential to return <code>Nothing</code>, the burden falls upon its callers to handle that possibility, and sometimes that passing of the buck can be incredibly frustrating. To see why, consider the following code:</p><pre><code><span>getConfigurationDirectories</span><span> </span><span>::</span><span> </span><span>IO</span><span> </span><span>[</span><span>FilePath</span><span>]</span>
<span>getConfigurationDirectories</span><span> </span><span>=</span><span> </span><span>do</span>
<span>  </span><span>configDirsString</span><span> </span><span>&lt;-</span><span> </span><span>getEnv</span><span> </span><span>"CONFIG_DIRS"</span>
<span>  </span><span>let</span><span> </span><span>configDirsList</span><span> </span><span>=</span><span> </span><span>split</span><span> </span><span>','</span><span> </span><span>configDirsString</span>
<span>  </span><span>when</span><span> </span><span>(</span><span>null</span><span> </span><span>configDirsList</span><span>)</span><span> </span><span>$</span>
<span>    </span><span>throwIO</span><span> </span><span>$</span><span> </span><span>userError</span><span> </span><span>"CONFIG_DIRS cannot be empty"</span>
<span>  </span><span>pure</span><span> </span><span>configDirsList</span>

<span>main</span><span> </span><span>::</span><span> </span><span>IO</span><span> </span><span>()</span>
<span>main</span><span> </span><span>=</span><span> </span><span>do</span>
<span>  </span><span>configDirs</span><span> </span><span>&lt;-</span><span> </span><span>getConfigurationDirectories</span>
<span>  </span><span>case</span><span> </span><span>head</span><span> </span><span>configDirs</span><span> </span><span>of</span>
<span>    </span><span>Just</span><span> </span><span>cacheDir</span><span> </span><span>-&gt;</span><span> </span><span>initializeCache</span><span> </span><span>cacheDir</span>
<span>    </span><span>Nothing</span><span> </span><span>-&gt;</span><span> </span><span>error</span><span> </span><span>"should never happen; already checked configDirs is non-empty"</span></code></pre><p>When <code>getConfigurationDirectories</code> retrieves a list of file paths from the environment, it proactively checks that the list is non-empty. However, when we use <code>head</code> in <code>main</code> to get the first element of the list, the <code>Maybe FilePath</code> result still requires us to handle a <code>Nothing</code> case that we know will never happen! This is terribly bad for several reasons:</p><ol><li><p>First, it’s just annoying. We already checked that the list is non-empty, why do we have to clutter our code with another redundant check?</p></li><li><p>Second, it has a potential performance cost. Although the cost of the redundant check is trivial in this particular example, one could imagine a more complex scenario where the redundant checks could add up, such as if they were happening in a tight loop.</p></li><li><p>Finally, and worst of all, this code is a bug waiting to happen! What if <code>getConfigurationDirectories</code> were modified to stop checking that the list is empty, intentionally or unintentionally? The programmer might not remember to update <code>main</code>, and suddenly the “impossible” error becomes not only possible, but probable.</p></li></ol><p>The need for this redundant check has essentially forced us to punch a hole in our type system. If we could statically <em>prove</em> the <code>Nothing</code> case impossible, then a modification to <code>getConfigurationDirectories</code> that stopped checking if the list was empty would invalidate the proof and trigger a compile-time failure. However, as-written, we’re forced to rely on a test suite or manual inspection to catch the bug.</p><h4><a name="paying-it-forward"></a>Paying it forward</h4><p>Clearly, our modified version of <code>head</code> leaves some things to be desired. Somehow, we’d like it to be smarter: if we already checked that the list was non-empty, <code>head</code> should unconditionally return the first element without forcing us to handle the case we know is impossible. How can we do that?</p><p>Let’s look at the original (partial) type signature for <code>head</code> again:</p><pre><code><span>head</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>a</span></code></pre><p>The previous section illustrated that we can turn that partial type signature into a total one by weakening the promise made in the return type. However, since we don’t want to do that, there’s only one thing left that can be changed: the argument type (in this case, <code>[a]</code>). Instead of weakening the return type, we can <em>strengthen</em> the argument type, eliminating the possibility of <code>head</code> ever being called on an empty list in the first place.</p><p>To do this, we need a type that represents non-empty lists. Fortunately, the existing <code>NonEmpty</code> type from <code>Data.List.NonEmpty</code> is exactly that. It has the following definition:</p><pre><code><span>data</span><span> </span><span>NonEmpty</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>a</span><span> </span><span>:|</span><span> </span><span>[</span><span>a</span><span>]</span></code></pre><p>Note that <code>NonEmpty a</code> is really just a tuple of an <code>a</code> and an ordinary, possibly-empty <code>[a]</code>. This conveniently models a non-empty list by storing the first element of the list separately from the list’s tail: even if the <code>[a]</code> component is <code>[]</code>, the <code>a</code> component must always be present. This makes <code>head</code> completely trivial to implement:<sup><a href="#footnote-2" id="footnote-ref-2-1">2</a></sup></p><pre><code><span>head</span><span> </span><span>::</span><span> </span><span>NonEmpty</span><span> </span><span>a</span><span> </span><span>-&gt;</span><span> </span><span>a</span>
<span>head</span><span> </span><span>(</span><span>x</span><span>:|</span><span>_</span><span>)</span><span> </span><span>=</span><span> </span><span>x</span></code></pre><p>Unlike before, GHC accepts this definition without complaint—this definition is <em>total</em>, not partial. We can update our program to use the new implementation:</p><pre><code><span>getConfigurationDirectories</span><span> </span><span>::</span><span> </span><span>IO</span><span> </span><span>(</span><span>NonEmpty</span><span> </span><span>FilePath</span><span>)</span>
<span>getConfigurationDirectories</span><span> </span><span>=</span><span> </span><span>do</span>
<span>  </span><span>configDirsString</span><span> </span><span>&lt;-</span><span> </span><span>getEnv</span><span> </span><span>"CONFIG_DIRS"</span>
<span>  </span><span>let</span><span> </span><span>configDirsList</span><span> </span><span>=</span><span> </span><span>split</span><span> </span><span>','</span><span> </span><span>configDirsString</span>
<span>  </span><span>case</span><span> </span><span>nonEmpty</span><span> </span><span>configDirsList</span><span> </span><span>of</span>
<span>    </span><span>Just</span><span> </span><span>nonEmptyConfigDirsList</span><span> </span><span>-&gt;</span><span> </span><span>pure</span><span> </span><span>nonEmptyConfigDirsList</span>
<span>    </span><span>Nothing</span><span> </span><span>-&gt;</span><span> </span><span>throwIO</span><span> </span><span>$</span><span> </span><span>userError</span><span> </span><span>"CONFIG_DIRS cannot be empty"</span>

<span>main</span><span> </span><span>::</span><span> </span><span>IO</span><span> </span><span>()</span>
<span>main</span><span> </span><span>=</span><span> </span><span>do</span>
<span>  </span><span>configDirs</span><span> </span><span>&lt;-</span><span> </span><span>getConfigurationDirectories</span>
<span>  </span><span>initializeCache</span><span> </span><span>(</span><span>head</span><span> </span><span>configDirs</span><span>)</span></code></pre><p>Note that the redundant check in <code>main</code> is now completely gone! Instead, we perform the check exactly once, in <code>getConfigurationDirectories</code>. It constructs a <code>NonEmpty a</code> from a <code>[a]</code> using the <code>nonEmpty</code> function from <code>Data.List.NonEmpty</code>, which has the following type:</p><pre><code><span>nonEmpty</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>Maybe</span><span> </span><span>(</span><span>NonEmpty</span><span> </span><span>a</span><span>)</span></code></pre><p>The <code>Maybe</code> is still there, but this time, we handle the <code>Nothing</code> case very early in our program: right in the same place we were already doing the input validation. Once that check has passed, we now have a <code>NonEmpty FilePath</code> value, which preserves (in the type system!) the knowledge that the list really is non-empty. Put another way, you can think of a value of type <code>NonEmpty a</code> as being like a value of type <code>[a]</code>, plus a <em>proof</em> that the list is non-empty.</p><p>By strengthening the type of the argument to <code>head</code> instead of weakening the type of its result, we’ve completely eliminated all the problems from the previous section:</p><ul><li><p>The code has no redundant checks, so there can’t be any performance overhead.</p></li><li><p>Furthermore, if <code>getConfigurationDirectories</code> changes to stop checking that the list is non-empty, its return type must change, too. Consequently, <code>main</code> will fail to typecheck, alerting us to the problem before we even run the program!</p></li></ul><p>What’s more, it’s trivial to recover the old behavior of <code>head</code> from the new one by composing <code>head</code> with <code>nonEmpty</code>:</p><pre><code><span>head'</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>Maybe</span><span> </span><span>a</span>
<span>head'</span><span> </span><span>=</span><span> </span><span>fmap</span><span> </span><span>head</span><span> </span><span>.</span><span> </span><span>nonEmpty</span></code></pre><p>Note that the inverse is <em>not</em> true: there is no way to obtain the new version of <code>head</code> from the old one. All in all, the second approach is superior on all axes.</p><h3><a name="the-power-of-parsing"></a>The power of parsing</h3><p>You may be wondering what the above example has to do with the title of this blog post. After all, we only examined two different ways to validate that a list was non-empty—no parsing in sight. That interpretation isn’t wrong, but I’d like to propose another perspective: in my mind, the difference between validation and parsing lies almost entirely in how information is preserved. Consider the following pair of functions:</p><pre><code><span>validateNonEmpty</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>IO</span><span> </span><span>()</span>
<span>validateNonEmpty</span><span> </span><span>(</span><span>_</span><span>:</span><span>_</span><span>)</span><span> </span><span>=</span><span> </span><span>pure</span><span> </span><span>()</span>
<span>validateNonEmpty</span><span> </span><span>[]</span><span> </span><span>=</span><span> </span><span>throwIO</span><span> </span><span>$</span><span> </span><span>userError</span><span> </span><span>"list cannot be empty"</span>

<span>parseNonEmpty</span><span> </span><span>::</span><span> </span><span>[</span><span>a</span><span>]</span><span> </span><span>-&gt;</span><span> </span><span>IO</span><span> </span><span>(</span><span>NonEmpty</span><span> </span><span>a</span><span>)</span>
<span>parseNonEmpty</span><span> </span><span>(</span><span>x</span><span>:</span><span>xs</span><span>)</span><span> </span><span>=</span><span> </span><span>pure</span><span> </span><span>(</span><span>x</span><span>:|</span><span>xs</span><span>)</span>
<span>parseNonEmpty</span><span> </span><span>[]</span><span> </span><span>=</span><span> </span><span>throwIO</span><span> </span><span>$</span><span> </span><span>userError</span><span> </span><span>"list cannot be empty"</span></code></pre><p>These two functions are nearly identical: they check if the provided list is empty, and if it is, they abort the program with an error message. The difference lies entirely in the return type: <code>validateNonEmpty</code> always returns <code>()</code>, the type that contains no information, but <code>parseNonEmpty</code> returns <code>NonEmpty a</code>, a refinement of the input type that preserves the knowledge gained in the type system. Both of these functions check the same thing, but <code>parseNonEmpty</code> gives the caller access to the information it learned, while <code>validateNonEmpty</code> just throws it away.</p><p>These two functions elegantly illustrate two different perspectives on the role of a static type system: <code>validateNonEmpty</code> obeys the typechecker well enough, but only <code>parseNonEmpty</code> takes full advantage of it. If you see why <code>parseNonEmpty</code> is preferable, you understand what I mean by the mantra “parse, don’t validate.” Still, perhaps you are skeptical of <code>parseNonEmpty</code>’s name. Is it really <em>parsing</em> anything, or is it merely validating its input and returning a result? While the precise definition of what it means to parse or validate something is debatable, I believe <code>parseNonEmpty</code> is a bona-fide parser (albeit a particularly simple one).</p><p>Consider: what is a parser? Really, a parser is just a function that consumes less-structured input and produces more-structured output. By its very nature, a parser is a partial function—some values in the domain do not correspond to any value in the range—so all parsers must have some notion of failure. Often, the input to a parser is text, but this is by no means a requirement, and <code>parseNonEmpty</code> is a perfectly cromulent parser: it parses lists into non-empty lists, signaling failure by terminating the program with an error message.</p><p>Under this flexible definition, parsers are an incredibly powerful tool: they allow discharging checks on input up-front, right on the boundary between a program and the outside world, and once those checks have been performed, they never need to be checked again! Haskellers are well-aware of this power, and they use many different types of parsers on a regular basis:</p><ul><li><p>The <a href="https://hackage.haskell.org/package/aeson">aeson</a> library provides a <code>Parser</code> type that can be used to parse JSON data into domain types.</p></li><li><p>Likewise, <a href="https://hackage.haskell.org/package/optparse-applicative">optparse-applicative</a> provides a set of parser combinators for parsing command-line arguments.</p></li><li><p>Database libraries like <a href="https://hackage.haskell.org/package/persistent">persistent</a> and <a href="https://hackage.haskell.org/package/postgresql-simple">postgresql-simple</a> have a mechanism for parsing values held in an external data store.</p></li><li><p>The <a href="https://hackage.haskell.org/package/servant">servant</a> ecosystem is built around parsing Haskell datatypes from path components, query parameters, HTTP headers, and more.</p></li></ul><p>The common theme between all these libraries is that they sit on the boundary between your Haskell application and the external world. That world doesn’t speak in product and sum types, but in streams of bytes, so there’s no getting around a need to do some parsing. Doing that parsing up front, before acting on the data, can go a long way toward avoiding many classes of bugs, some of which might even be security vulnerabilities.</p><p>One drawback to this approach of parsing everything up front is that it sometimes requires values be parsed long before they are actually used. In a dynamically-typed language, this can make keeping the parsing and processing logic in sync a little tricky without extensive test coverage, much of which can be laborious to maintain. However, with a static type system, the problem becomes marvelously simple, as demonstrated by the <code>NonEmpty</code> example above: if the parsing and processing logic go out of sync, the program will fail to even compile.</p><h3><a name="the-danger-of-validation"></a>The danger of validation</h3><p>Hopefully, by this point, you are at least somewhat sold on the idea that parsing is preferable to validation, but you may have lingering doubts. Is validation really so bad if the type system is going to force you to do the necessary checks eventually anyway? Maybe the error reporting will be a little bit worse, but a bit of redundant checking can’t hurt, right?</p><p>Unfortunately, it isn’t so simple. Ad-hoc validation leads to a phenomenon that the <a href="http://langsec.org/">language-theoretic security</a> field calls <em>shotgun parsing</em>. In the 2016 paper, <a href="http://langsec.org/papers/langsec-cwes-secdev2016.pdf">The Seven Turrets of Babel: A Taxonomy of LangSec Errors and How to Expunge Them</a>, its authors provide the following definition:</p><blockquote><p>Shotgun parsing is a programming antipattern whereby parsing and input-validating code is mixed with and spread across processing code—throwing a cloud of checks at the input, and hoping, without any systematic justification, that one or another would catch all the “bad” cases.</p></blockquote><p>They go on to explain the problems inherent to such validation techniques:</p><blockquote><p>Shotgun parsing necessarily deprives the program of the ability to reject invalid input instead of processing it. Late-discovered errors in an input stream will result in some portion of invalid input having been processed, with the consequence that program state is difficult to accurately predict.</p></blockquote><p>In other words, a program that does not parse all of its input up front runs the risk of acting upon a valid portion of the input, discovering a different portion is invalid, and suddenly needing to roll back whatever modifications it already executed in order to maintain consistency. Sometimes this is possible—such as rolling back a transaction in an RDBMS—but in general it may not be.</p><p>It may not be immediately apparent what shotgun parsing has to do with validation—after all, if you do all your validation up front, you mitigate the risk of shotgun parsing. The problem is that validation-based approaches make it extremely difficult or impossible to determine if everything was actually validated up front or if some of those so-called “impossible” cases might actually happen. The entire program must assume that raising an exception anywhere is not only possible, it’s regularly necessary.</p><p>Parsing avoids this problem by stratifying the program into two phases—parsing and execution—where failure due to invalid input can only happen in the first phase. The set of remaining failure modes during execution is minimal by comparison, and they can be handled with the tender care they require.</p><h2><a name="parsing-not-validating-in-practice"></a>Parsing, not validating, in practice</h2><p>So far, this blog post has been something of a sales pitch. “You, dear reader, ought to be parsing!” it says, and if I’ve done my job properly, at least some of you are sold. However, even if you understand the “what” and the “why,” you might not feel especially confident about the “how.”</p><p>My advice: focus on the datatypes.</p><p>Suppose you are writing a function that accepts a list of tuples representing key-value pairs, and you suddenly realize you aren’t sure what to do if the list has duplicate keys. One solution would be to write a function that asserts there aren’t any duplicates in the list:</p><pre><code><span>checkNoDuplicateKeys</span><span> </span><span>::</span><span> </span><span>(</span><span>MonadError</span><span> </span><span>AppError</span><span> </span><span>m</span><span>,</span><span> </span><span>Eq</span><span> </span><span>k</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>[(</span><span>k</span><span>,</span><span> </span><span>v</span><span>)]</span><span> </span><span>-&gt;</span><span> </span><span>m</span><span> </span><span>()</span></code></pre><p>However, this check is fragile: it’s extremely easy to forget. Because its return value is unused, it can always be omitted, and the code that needs it would still typecheck. A better solution is to choose a data structure that disallows duplicate keys by construction, such as a <code>Map</code>. Adjust your function’s type signature to accept a <code>Map</code> instead of a list of tuples, and implement it as you normally would.</p><p>Once you’ve done that, the call site of your new function will likely fail to typecheck, since it is still being passed a list of tuples. If the caller was given the value via one of its arguments, or if it received it from the result of some other function, you can continue updating the type from list to <code>Map</code>, all the way up the call chain. Eventually, you will either reach the location the value is created, or you’ll find a place where duplicates actually ought to be allowed. At that point, you can insert a call to a modified version of <code>checkNoDuplicateKeys</code>:</p><pre><code><span>checkNoDuplicateKeys</span><span> </span><span>::</span><span> </span><span>(</span><span>MonadError</span><span> </span><span>AppError</span><span> </span><span>m</span><span>,</span><span> </span><span>Eq</span><span> </span><span>k</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>[(</span><span>k</span><span>,</span><span> </span><span>v</span><span>)]</span><span> </span><span>-&gt;</span><span> </span><span>m</span><span> </span><span>(</span><span>Map</span><span> </span><span>k</span><span> </span><span>v</span><span>)</span></code></pre><p>Now the check <em>cannot</em> be omitted, since its result is actually necessary for the program to proceed!</p><p>This hypothetical scenario highlights two simple ideas:</p><ol><li><p><strong>Use a data structure that makes illegal states unrepresentable.</strong> Model your data using the most precise data structure you reasonably can. If ruling out a particular possibility is too hard using the encoding you are currently using, consider alternate encodings that can express the property you care about more easily. Don’t be afraid to refactor.</p></li><li><p><strong>Push the burden of proof upward as far as possible, but no further.</strong> Get your data into the most precise representation you need as quickly as you can. Ideally, this should happen at the boundary of your system, before <em>any</em> of the data is acted upon.<sup><a href="#footnote-3" id="footnote-ref-3-1">3</a></sup></p><p>If one particular code branch eventually requires a more precise representation of a piece of data, parse the data into the more precise representation as soon as the branch is selected. Use sum types judiciously to allow your datatypes to reflect and adapt to control flow.</p></li></ol><p>In other words, write functions on the data representation you <em>wish</em> you had, not the data representation you are given. The design process then becomes an exercise in bridging the gap, often by working from both ends until they meet somewhere in the middle. Don’t be afraid to iteratively adjust parts of the design as you go, since you may learn something new during the refactoring process!</p><p>Here are a handful of additional points of advice, arranged in no particular order:</p><ul><li><p><strong>Let your datatypes inform your code, don’t let your code control your datatypes.</strong> Avoid the temptation to just stick a <code>Bool</code> in a record somewhere because it’s needed by the function you’re currently writing. Don’t be afraid to refactor code to use the right data representation—the type system will ensure you’ve covered all the places that need changing, and it will likely save you a headache later.</p></li><li><p><strong>Treat functions that return <code>m ()</code> with deep suspicion.</strong> Sometimes these are genuinely necessary, as they may perform an imperative effect with no meaningful result, but if the primary purpose of that effect is raising an error, it’s likely there’s a better way.</p></li><li><p><strong>Don’t be afraid to parse data in multiple passes.</strong> Avoiding shotgun parsing just means you shouldn’t act on the input data before it’s fully parsed, not that you can’t use some of the input data to decide how to parse other input data. Plenty of useful parsers are context-sensitive.</p></li><li><p><strong>Avoid denormalized representations of data, <em>especially</em> if it’s mutable.</strong> Duplicating the same data in multiple places introduces a trivially representable illegal state: the places getting out of sync. Strive for a single source of truth.</p><ul><li><p><strong>Keep denormalized representations of data behind abstraction boundaries.</strong> If denormalization is absolutely necessary, use encapsulation to ensure a small, trusted module holds sole responsibility for keeping the representations in sync.</p></li></ul></li><li><p><strong>Use abstract datatypes to make validators “look like” parsers.</strong> Sometimes, making an illegal state truly unrepresentable is just plain impractical given the tools Haskell provides, such as ensuring an integer is in a particular range. In that case, use an abstract <code>newtype</code> with a smart constructor to “fake” a parser from a validator.</p></li></ul><p>As always, use your best judgement. It probably isn’t worth breaking out <a href="https://hackage.haskell.org/package/singletons">singletons</a> and refactoring your entire application just to get rid of a single <code>error "impossible"</code> call somewhere—just make sure to treat those situations like the radioactive substance they are, and handle them with the appropriate care. If all else fails, at least leave a comment to document the invariant for whoever needs to modify the code next.</p><h2><a name="recap-reflection-and-related-reading"></a>Recap, reflection, and related reading</h2><p>That’s all, really. Hopefully this blog post proves that taking advantage of the Haskell type system doesn’t require a PhD, and it doesn’t even require using the latest and greatest of GHC’s shiny new language extensions—though they can certainly sometimes help! Sometimes the biggest obstacle to using Haskell to its fullest is simply being aware what options are available, and unfortunately, one downside of Haskell’s small community is a relative dearth of resources that document design patterns and techniques that have become tribal knowledge.</p><p>None of the ideas in this blog post are new. In fact, the core idea—“write total functions”—is conceptually quite simple. Despite that, I find it remarkably challenging to communicate actionable, practicable details about the way I write Haskell code. It’s easy to spend lots of time talking about abstract concepts—many of which are quite valuable!—without communicating anything useful about <em>process</em>. My hope is that this is a small step in that direction.</p><p>Sadly, I don’t know very many other resources on this particular topic, but I do know of one: I never hesitate to recommend Matt Parson’s fantastic blog post <a href="https://www.parsonsmatt.org/2017/10/11/type_safety_back_and_forth.html">Type Safety Back and Forth</a>. If you want another accessible perspective on these ideas, including another worked example, I’d highly encourage giving it a read. For a significantly more advanced take on many of these ideas, I can also recommend Matt Noonan’s 2018 paper <a href="https://kataskeue.com/gdp.pdf">Ghosts of Departed Proofs</a>, which outlines a handful of techniques for capturing more complex invariants in the type system than I have described here.</p><p>As a closing note, I want to say that doing the kind of refactoring described in this blog post is not always easy. The examples I’ve given are simple, but real life is often much less straightforward. Even for those experienced in type-driven design, it can be genuinely difficult to capture certain invariants in the type system, so do not consider it a personal failing if you cannot solve something the way you’d like! Consider the principles in this blog post ideals to strive for, not strict requirements to meet. All that matters is to try.</p><ol><li id="footnote-1"><p>Technically, in Haskell, this ignores “bottoms,” constructions that can inhabit <em>any</em> value. These aren’t “real” values (unlike <code>null</code> in some other languages)—they’re things like infinite loops or computations that raise exceptions—and in idiomatic Haskell, we usually try to avoid them, so reasoning that pretends they don’t exist still has value. But don’t take my word for it—I’ll let Danielsson et al. convince you that <a href="https://www.cs.ox.ac.uk/jeremy.gibbons/publications/fast+loose.pdf">Fast and Loose Reasoning is Morally Correct</a>. <a href="#footnote-ref-1-1">↩</a></p></li><li id="footnote-2"><p>In fact, <code>Data.List.NonEmpty</code> already provides a <code>head</code> function with this type, but just for the sake of illustration, we’ll reimplement it ourselves. <a href="#footnote-ref-2-1">↩</a></p></li><li id="footnote-3"><p>Sometimes it is necessary to perform some kind of authorization before parsing user input to avoid denial of service attacks, but that’s okay: authorization should have a relatively small surface area, and it shouldn’t cause any significant modifications to the state of your system. <a href="#footnote-ref-3-1">↩</a></p></li></ol></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oxide raises $200M Series C (349 pts)]]></title>
            <link>https://oxide.computer/blog/our-200m-series-c</link>
            <guid>46960036</guid>
            <pubDate>Tue, 10 Feb 2026 14:20:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oxide.computer/blog/our-200m-series-c">https://oxide.computer/blog/our-200m-series-c</a>, See on <a href="https://news.ycombinator.com/item?id=46960036">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>We have raised a $200M Series C, and yes, you are permitted a double take:
didn’t we <em>just</em> raise a
<a href="https://oxide.computer/blog/our-100m-series-b">$100M Series B</a>?
And aren’t we the ones that are especially candid about the
<a href="https://www.youtube.com/watch?v=8ZgfTarNxdY">perils of raising too much money</a>?</p><p>Well, yes, on both fronts, so let us explain a little.</p><p>First, we have the luxury of having achieved real product-market fit:  we are
making <a href="https://oxide.computer/">a product</a> that people want to buy.  This takes
on additional dimensions when making something physical: with complexities like
manufacturing, inventory, cash-conversion, and shifting supply chains,
product-market fit implies getting the unit economics of the business right.
All of this is a long way of saying: we did not (and do not) need to raise
capital to support the business.</p><p>So if we didn’t need to raise, why seek the capital?  Well, we weren’t seeking
it, really.  But our
investors, seeing the business take off, were eager to support it.  And we, in
turn, were eager to have them:  they were the ones, after all, who joined us in
taking a real leap when it felt like there was a lot more risk on the table.
They understood our vision for the company and shared our love for customers
and our desire to build a singular team.  They had been with us in some
difficult moments; they know and trust us, as do we them.  So being able to raise
a Series C purely from our existing investors presented a real opportunity.</p><p>Still, even from investors that we trust and with a quick close, if the business
doesn’t need the money, does it make sense to raise?  We have always believed
that our biggest challenge at Oxide was time — and therefore capital.  We
spelled this out in our initial pitch deck from 2019:</p><div><p><img srcset="https://oxide-computer.imgix.net//img/blog/series-c/oxide-pitch-2019.png?w=700 700w, https://oxide-computer.imgix.net//img/blog/series-c/oxide-pitch-2019.png?w=1400 1400w, https://oxide-computer.imgix.net//img/blog/series-c/oxide-pitch-2019.png?w=2100 2100w" sizes="(min-width: 600px) 700px, 1400px, 2100px" src="https://oxide.computer/img/blog/series-c/oxide-pitch-2019.png" alt="Oxide pitch deck"></p><p>Challenges slide from Oxide original pitch deck ca. 2019</p></div><p>Six years later, we stand by this, which is not to minimize any of those
challenges: the technical challenges were indeed hard; we feel fortunate to have
attracted an extraordinary team; and we certainly caught some
<a href="https://www.networkworld.com/article/4053783/broadcoms-vmware-strategy-pays-off-financially-but-customers-not-as-keen-as-wall-street.html">lucky breaks</a>
with respect to the market.  With this large Series C, we have entirely
de-risked capital going forward, which in turn assures our independence.</p><p>This last bit is really important, because any buyer of infrastructure has
had their heart broken countless times by promising startups that succumbed to
acquisition by one of the established players that they were seeking to
disrupt.  The serial disappointments leave a refreshing bluntness in their
wake, and it’s not uncommon for us to be asked directly: "How do I know you
won’t be bought?"</p><p>Our intent in starting Oxide was not to be an
acquisition target but rather build a generational company; this is our life’s
work, not a means to an end.  With our Series C, customers
don’t have to merely take our word for it:  we have the capital to assure our
survival into the indefinite future.  If our Series B left us with confidence
in achieving <a href="https://rfd.shared.oxide.computer/rfd/0002">our mission</a>, our
Series C leaves us with certainty: we’re going to kick butt, have fun, not
cheat (of course!), love our customers — and <strong>change computing forever</strong>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jury told that Meta, Google 'engineered addiction' at landmark US trial (356 pts)]]></title>
            <link>https://techxplore.com/news/2026-02-jury-told-meta-google-addiction.html</link>
            <guid>46959832</guid>
            <pubDate>Tue, 10 Feb 2026 14:02:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techxplore.com/news/2026-02-jury-told-meta-google-addiction.html">https://techxplore.com/news/2026-02-jury-told-meta-google-addiction.html</a>, See on <a href="https://news.ycombinator.com/item?id=46959832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2026/meta-co-founder-and-ch-2.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2026/meta-co-founder-and-ch-2.jpg" data-sub-html="Meta co-founder and chief executive Mark Zuckerberg is scheduled to testify as the parent company of Facebook and Instagram stands trial in a civil suit accusing the social media giant of putting profit over the mental health of young users.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2026/meta-co-founder-and-ch-2.jpg" alt="Meta co-founder and chief executive Mark Zuckerberg is scheduled to testify as the parent company of Facebook and Instagram stands trial in a civil suit accusing the social media giant of putting profit over the mental health of young users" title="Meta co-founder and chief executive Mark Zuckerberg is scheduled to testify as the parent company of Facebook and Instagram stands trial in a civil suit accusing the social media giant of putting profit over the mental health of young users." width="800" height="530">
             <figcaption>
                Meta co-founder and chief executive Mark Zuckerberg is scheduled to testify as the parent company of Facebook and Instagram stands trial in a civil suit accusing the social media giant of putting profit over the mental health of young users.
            </figcaption>        </figure>
    </div><p>Meta and Google-owned YouTube were accused Monday of pushing highly addictive apps on children as a landmark social media trial began in earnest in a California court.</p>

                                        
                                          

                                        
                                                                                                                                                                                <p>The blockbuster trial in front of a Los Angeles jury could establish a legal precedent on whether the social media juggernauts deliberately designed their platforms to lead to addiction in children.</p>
<p>The proceedings are expected to see Meta chief Mark Zuckerberg on the stand next week and Instagram boss Adam Mosseri in the courtroom as early as Wednesday. In addition to Instagram, Meta's platforms include Facebook and WhatsApp.</p>
<p>"This case is about two of the richest corporations in history who have engineered addiction in children's brains," plaintiffs' attorney Mark Lanier told the jury in his opening statement.</p>
<p>"This case is as easy as A-B-C," Lanier said as he stacked children's toy blocks bearing the letters.</p>
<p>He contended the A was for addicting, the B for brains and the C for children.</p>

<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2026/parents-mariano-janin-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2026/parents-mariano-janin-1.jpg" data-sub-html="Parents Mariano Janin and George Nicolaou hold photos of their children outside the Los Angeles County Superior Court in Los Angeles.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2026/parents-mariano-janin-1.jpg" alt="Parents Mariano Janin and George Nicolaou hold photos of their children outside the Los Angeles County Superior Court in Los Angeles" title="Parents Mariano Janin and George Nicolaou hold photos of their children outside the Los Angeles County Superior Court in Los Angeles.">
             <figcaption>
                Parents Mariano Janin and George Nicolaou hold photos of their children outside the Los Angeles County Superior Court in Los Angeles.
            </figcaption>        </figure>
    </div>
<p>"They don't only build apps; they build traps," Lanier said, saying Meta and YouTube pursued "<a href="https://techxplore.com/news/2023-10-meta-struggle-defend-state-lawsuits.html?utm_source=embeddings&amp;utm_medium=related&amp;utm_campaign=internal" rel="related">addiction by design</a>," making his arguments using props like a toy Ferrari and a mini slot machine.</p>
<p>Meta attorney Paul Schmidt countered in opening remarks to the jury that evidence will show problems with the plaintiff's family and real-world bullying took a toll on her self-esteem, body image and happiness rather than Instagram.</p>
<p>"If you took Instagram away and everything else was the same in Kaley's life, would her life be completely different, or would she still be struggling with the same things she is today?" Schmidt asked, pointing out an Instagram addiction is never mentioned in medical records included in the evidence.</p>

                                                                                                    
													                                                            
                                                                                                                                            <p>The trial before Judge Carolyn Kuhl focuses on allegations that a 20-year-old woman identified as Kaley G.M. suffered severe mental harm because she became addicted to social media as a child.</p>
<p>The case is being treated as a bellwether proceeding because its outcome could set the tone, and the level of payouts to successful plaintiffs, for a tidal wave of similar litigation across the United States.</p>
<p>Social media firms are accused in hundreds of lawsuits of leading young users to become addicted to content and suffer from <a href="https://phys.org/news/2024-11-reliable-evidence-social-media-young.html?utm_source=embeddings&amp;utm_medium=related&amp;utm_campaign=internal" rel="related" target="_blank">depression</a>, eating disorders, psychiatric hospitalization and even suicide.</p>
<p>Lawyers for the plaintiffs are borrowing strategies used in the 1990s and 2000s against the tobacco industry, which faced a similar onslaught of lawsuits arguing that companies knowingly sold a harmful product.</p>
<p>Lanier told the jurors that Kaley began watching YouTube at six years old because the company never told her mother "the goal was viewer addiction," or that toddlers as young as two were being targeted despite "critical" risk of addiction.</p>
<p>"This is the first time that a social media company has ever had to face a jury for harming kids," Social Media Victims Law Center founder Matthew Bergman, whose team is involved in more than 1,000 such cases, told AFP.</p>

                                                                                                                                            <h2>"Strongly disagree"</h2>
<p>Internet titans have argued that they are shielded by <a href="https://techxplore.com/news/2022-10-supreme-court-cases-tech-firm.html?utm_source=embeddings&amp;utm_medium=related&amp;utm_campaign=internal" rel="related">Section 230</a> of the US Communications Decency Act, which frees them from responsibility for what social media users post.</p>
<p>However, this case argues that those firms are culpable for business models designed to hold people's attention and to promote content that can harm their mental health.</p>
<p>The plaintiffs said they would call expert witnesses that will argue that <a href="https://techxplore.com/news/2026-01-social-media-giants-landmark-trial.html?utm_source=embeddings&amp;utm_medium=related&amp;utm_campaign=internal" rel="related">young people's brains</a> are not yet developed to withstand the powers of the algorithms being flung at them on Instagram and YouTube.</p>
<p>The company pointed to recent efforts to provide more safeguards for young people, adding that "we're always working to do better."</p>
<p>Jose Castaneda, a YouTube spokesperson, said "the allegations in these complaints are simply not true."</p>
<p>Lawyers for YouTube are to present opening remarks to the jury on Tuesday.</p>
<p>Snapchat and TikTok were named as defendants in the suit, but struck settlement deals before the start of the trial. The terms were not disclosed.</p>
<p>Lawsuits, including some brought by school districts, accusing social media platforms of practices endangering young users are making their way through federal court in northern California and state courts across the country.</p>
<p>A separate lawsuit accusing Meta of putting profit over the well-being of young users was also getting underway in New Mexico on Monday.</p>

                                                                                                                                    
                                                                                
                                        											
										                                                                                    <p>
                                                © 2026 AFP
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                Jury told that Meta, Google 'engineered addiction' at landmark US trial (2026, February 10)
                                                retrieved 10 February 2026
                                                from https://techxplore.com/news/2026-02-jury-told-meta-google-addiction.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simplifying Vulkan One Subsystem at a Time (141 pts)]]></title>
            <link>https://www.khronos.org/blog/simplifying-vulkan-one-subsystem-at-a-time</link>
            <guid>46959418</guid>
            <pubDate>Tue, 10 Feb 2026 13:26:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.khronos.org/blog/simplifying-vulkan-one-subsystem-at-a-time">https://www.khronos.org/blog/simplifying-vulkan-one-subsystem-at-a-time</a>, See on <a href="https://news.ycombinator.com/item?id=46959418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="description">
    <p>When those of us in the Vulkan® working group want to modify the API—whether it’s a new hardware feature to expose, a new use case we want to address, or even just a gap in the spec we want to address—we have one invaluable tool that we make heavy use of: extensions!</p>
<p>Extensions are a wonderful way for us to get improvements to the Vulkan API out to developers without waiting for a new core version. They let vendors expose novel functionality and enable us to gather community feedback on new features before we firm them up into a core specification.</p>
<p>Amazing! So we get new functionality out to developers quickly—what’s not to love!? Well…</p>
<h2>The Extension Explosion Problem 💥</h2>
<p>Having access to this much extensibility comes at a cost. As we add more extensions to the API, we sometimes inadvertently obscure the simplest way to use it. What functionality can you rely on always being there? How many ways are there to do what you want to do? Which of those ways will give the best performance? How many paths through the API can you reasonably support in one application?</p>
<p>We sometimes <em>lovingly</em> refer to this as the “extension explosion problem” due to the <a href="https://docs.vulkan.org/spec/latest/appendices/extensions.html#_list_of_current_extensions">number of extensions we have now</a>—and <a href="https://registry.khronos.org/OpenGL/index_gl.php">how many existed in OpenGL</a>/<a href="https://registry.khronos.org/OpenGL/index_es.php">ES</a>™ beforehand. The more we add, the more they chain off of and interact with each other, adding combinatorically to the decision space for developers.</p>
<p>This is a persistent challenge that we’ve heard loud and clear from Vulkan’s developer base, but until now we haven’t had a good solution.</p>
<p>When we produced Vulkan 1.0, it gave us a clean slate moving from OpenGL® , but now 10 years into Vulkan we are facing the same problem again. So, what’s the answer? Should we rebuild the entire API from scratch every few years?</p>
<p>No—believe it or not, <strong>we add more extensions</strong>!</p>
<p>…🤨?</p>
<h2>Subsystem Replacement</h2>
<p>Counterintuitive as it may seem, adding more extensions is one way we can improve the situation. However, this <strong>cannot</strong> just be business as usual. We <strong>have</strong> to take a different approach.</p>
<p>Rather than incrementally adding or changing the API and increasing complexity, we want to revise whole API subsystems, producing whole-cloth replacements that let you ignore whatever came before, with supporting tooling and industry backing to make sure the new approach ships everywhere.</p>
<p><a href="https://docs.vulkan.org/refpages/latest/refpages/source/VK_EXT_descriptor_heap.html">VK_EXT_descriptor_heap</a> is the first concrete attempt at this approach, <strong>totally replacing</strong> the existing descriptor set subsystem in Vulkan. Members of the Vulkan working group have poured everything into this, and it’s had the kind of attention we’ve only historically seen with major API revisions (e.g. Vulkan 1.0). While it’s shipping as an EXT for now, it’s very much on a path to becoming future core functionality.</p>
<p>We previously attempted to fix up the descriptor model with <a href="https://docs.vulkan.org/features/latest/features/proposals/VK_EXT_descriptor_buffer.html">VK_EXT_descriptor_buffer</a>, which developers have had some success with, but we used incremental (if large!) improvements to the existing descriptor set functionality, making it necessary to check for a variety of descriptor set extensions. This incremental approach also didn’t attract wide industry backing, resulting in cross-vendor portability issues. We knew we had the core of something important, but it needed a rethink to make it stick. So we took the lessons learned from VK_EXT_descriptor_buffer, and designed a completely new subsystem.</p>
<p>The new VK_EXT_descriptor_heap extension does not interact with the previous descriptor set API, including layouts, push descriptors, or descriptor buffers in <em>any way</em>—<a href="https://docs.vulkan.org/spec/latest/appendices/legacy.html#legacy-descriptor-sets">it fully replaces it all</a>. Instead of just trying to tidy up the API a little, this extension fundamentally changes how Vulkan applications interact with descriptors. Descriptors are no longer some opaque thing that you manage through a series of awkward API commands and restrictive shader bindings. Descriptor heaps are just memory, descriptors are just data, and you can do <em>more or less</em> whatever you want with them. There are <em>some</em> restrictions, but it’s a lot closer to what you might expect on a console than in a portable API.</p>
<p>This extension has also had contributions from a huge swathe of the industry, much more than our typical extensions. Feel free to look at the <a href="https://docs.vulkan.org/refpages/latest/refpages/source/VK_EXT_descriptor_heap.html#_other_extension_metadata">contributor list</a>—it’s <strong>extensive</strong>. This extension has had meaningful input from virtually everyone in the Vulkan Working Group. Together we’ve spent the better part of the past three years iterating on and refining this, ensuring it not only works but works <strong>well</strong>.</p>
<h2>If this has so much buy-in, why isn’t it a KHR?</h2>
<p><strong>We want to make sure we have buy-in from you, too.</strong></p>
<p>With something this big, we want to make sure we get it right. We’re confident that what we’ve built is already a huge improvement and an excellent feature, but by releasing it as an EXT, we’re giving the wider community a chance to try it out, figure out its intricacies, and perhaps suggest ways it can be even better.</p>
<p>The EXT is not going to change, so you can use it in shipping apps today; when we do eventually ship a KHR version, we’re aiming for the transition to be as straightforward as possible if you choose to use it.</p>
<p>If you do find anything in the new extension that you think could be simpler or improved, we will consider any feedback as we finalize the KHR specification. By doing so, we will work to get everything as polished as possible and avoid additional extensions to fix things later.</p>
<p>While we can’t make any guarantees about when the eventual KHR will materialize, getting feedback within the next 9 months will give us the best opportunity to incorporate your input.</p>
<p>Please <strong>use this extension and</strong> <a href="https://github.com/KhronosGroup/Vulkan-Docs/"><strong>let us know how it goes</strong></a>!</p>
<h2>Cool. You did something about descriptors. What about &lt;insert feature&gt;?</h2>
<p>Developer needs are at the center of our roadmap planning, and we're committed to addressing the requests we've been hearing. <strong>There’s a very good chance <a href="https://youtu.be/-OQsVwOJjQ4?t=1360">we’re already working on the thing you are after</a></strong>.</p>
<p>If we don’t have your problem logged somewhere, or if you think it’s not getting enough attention, we encourage you to <a href="https://discord.com/invite/vulkan">jump on our Discord</a> or <a href="https://github.com/KhronosGroup/Vulkan-Docs/">file an issue on GitHub</a> to let us know about it!</p>
<p>In order to replace subsystems like this, we have a lot of considerations to balance - developer needs, ecosystem needs, vendor roadmaps, future direction, and upcoming hardware and software releases, among other things. Taking care of all of those needs takes care to try and get it right the first time. That doesn’t mean any of this needs to be slow though! We are actively working on how to use this methodology to upgrade key parts of the Vulkan API, with strong industry buy-in.</p>
<p>One of our top priorities right now is to make the Vulkan API a joy to use. We know we still have a long way to go, but we hope that well-considered subsystem replacements like this are a major positive step in that direction. Please do let us know what you think of this approach—we’d love to hear from you!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Europe's $24T Breakup with Visa and Mastercard Has Begun (308 pts)]]></title>
            <link>https://europeanbusinessmagazine.com/business/europes-24-trillion-breakup-with-visa-and-mastercard-has-begun/</link>
            <guid>46958399</guid>
            <pubDate>Tue, 10 Feb 2026 11:42:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://europeanbusinessmagazine.com/business/europes-24-trillion-breakup-with-visa-and-mastercard-has-begun/">https://europeanbusinessmagazine.com/business/europes-24-trillion-breakup-with-visa-and-mastercard-has-begun/</a>, See on <a href="https://news.ycombinator.com/item?id=46958399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>ECB President Christine Lagarde has called for Europe to break its dependence on American payment infrastructure, warning that every card transaction sends European consumer data to the United States. A coalition of 16 banks thinks it has the answer.</em></p>
<p><strong>QUICK ANSWER</strong></p>
<p><strong>What’s happening?</strong> ECB President Christine Lagarde told Irish radio that Europe needs its own digital payment system “urgently,” warning that virtually all European card and mobile payments currently run through <a href="https://davekeating.substack.com/p/can-europe-free-itself-from-visamastercard" target="_blank" rel="noopener">non-European infrastructure controlled by Visa, Mastercard, PayPal or Alipay</a>. Days later, on 2 February, the European Payments Initiative (EPI) and the <a href="https://news.europawire.eu/european-payment-leaders-sign-mou-to-create-a-sovereign-pan-european-interoperable-payments-network/eu-press-release/2026/02/02/15/34/11/168858/" target="_blank" rel="noopener">EuroPA Alliance signed a landmark agreement</a> to build a pan-European interoperable payment network covering 130 million users across 13 countries. The system, built around the digital wallet Wero, aims to let Europeans pay and transfer money across borders without touching a single American network.</p><div>
  <h3>Join The European Business Briefing</h3>
  <p>The daily email on markets, technology, power and money across Europe. Join 10,000+ founders, investors and executives who read EBM every morning.</p>
  <p><a href="https://mailchi.mp/europeanbusinessmagazine/european-business-briefing" target="_blank" rel="noopener">Subscribe</a>
</p></div>
<hr>
<h2>The Problem No One Thinks About</h2>
<p>Every time a European taps a card, pays online or splits a bill with friends, the transaction flows through infrastructure owned and operated by American companies. Visa and Mastercard together <a href="https://finance.yahoo.com/news/europe-banks-launching-product-break-101215642.html" target="_blank" rel="noopener">process approximately $24 trillion in transactions annually</a>. Card payments account for 56% of all cashless transactions in the EU. And the data — who bought what, where, when and for how much — leaves European jurisdiction every time.</p>
<p>“It’s important for us to have digital payment under our control,” Lagarde <a href="https://davekeating.substack.com/p/can-europe-free-itself-from-visamastercard" target="_blank" rel="noopener">told The Pat Kenny Show</a>. “Whether you use a card or whether you use a phone, typically it goes through Visa, Mastercard, PayPal, Alipay. Where are all those coming from? Well, either the US or China.”</p>
<p>The host’s response — “I didn’t realise this” — captured the broader European blind spot. Most consumers have no idea that their payment data routinely exits the EU. In a <a href="https://europeanbusinessmagazine.com/business/european-stocks-at-a-tipping-point-why-2026-could-decide-the-continents-economic-future/">geopolitical environment</a> where Europe is scrambling to reduce dependence on the United States across defence, energy and trade, payments remain an overlooked vulnerability.</p>
<p>The lesson of Russia sharpened the urgency. When Western sanctions cut Russia off from Visa and Mastercard in 2022, the country’s domestic payments were immediately disrupted. European policymakers asked the obvious question: what would happen if the US decided — or was pressured — to restrict European access to those same networks?</p>
<h2>Enter Wero</h2>
<p>The European Payments Initiative, a consortium of 16 major banks and payment processors including <a href="https://finance.yahoo.com/news/europe-banks-launching-product-break-101215642.html" target="_blank" rel="noopener">BNP Paribas, Deutsche Bank and Worldline</a>, launched Wero in July 2024 as Europe’s answer. Built on SEPA instant credit transfers, Wero lets users send money using just a phone number — no IBAN, no card, no intermediary.</p>
<p>The numbers so far are encouraging. <a href="https://empsa.org/news/bancomat-bizum-epi-sibs-and-vipps-mobilepay-sign-mou-to-accelerate-the-rollout-of-sovereign-pan-european-payment-solutions/" target="_blank" rel="noopener">Wero already has over 47 million registered users</a> in Belgium, France and Germany, has processed over €7.5 billion in transfers, and counts more than 1,100 member institutions. Retail payments went live in Germany at the end of 2025, with merchants including Lidl, Decathlon, Rossmann and Air Europa already accepting Wero online. France and Belgium follow in 2026.</p>
<p>But the real breakthrough came on 2 February, when EPI signed a memorandum of understanding with the <a href="https://empsa.org/news/bancomat-bizum-epi-sibs-and-vipps-mobilepay-sign-mou-to-accelerate-the-rollout-of-sovereign-pan-european-payment-solutions/" target="_blank" rel="noopener">EuroPA Alliance</a> — a coalition of national payment systems including Italy’s Bancomat, Spain’s Bizum, Portugal’s MB WAY and the Nordics’ Vipps MobilePay. The deal instantly connects approximately 130 million users across 13 countries, covering roughly 72% of the EU and Norway population. Cross-border peer-to-peer payments launch this year, with e-commerce and point-of-sale payments following in 2027.</p>
<p>“European payment sovereignty is not a vision, but a reality in the making,” said Martina Weimert, CEO of EPI.</p>
<h2>Why Previous Attempts Failed</h2>
<p>Europe has tried this before. The Monnet Project, launched in 2008 by twenty European banks, collapsed in 2012. The original EPI vision itself was scaled back after several founding members withdrew, forcing a pivot from a full card-replacement scheme to a narrower account-to-account model.</p>
<p>The <a href="https://thepaypers.com/payments/expert-views/breaking-the-visa-and-mastercard-duopoly-europes-path-to-innovation" target="_blank" rel="noopener">core problem has always been fragmentation</a>. Each EU country developed its own domestic payment solution — Bizum in Spain, iDEAL in the Netherlands, Payconiq in Belgium, Girocard in Germany — but none could work across borders. A Belgian consumer buying from a Dutch retailer still needed Visa or Mastercard. National pride and competing banking interests repeatedly sabotaged attempts at unification.</p>
<p>The <a href="https://europeanbusinessmagazine.com/business/10-cultural-differences-between-asia-and-europe/">network effect</a> compounds the challenge. Merchants accept Visa and Mastercard because consumers carry them. Consumers carry them because merchants accept them. Breaking that loop requires either regulatory force or a critical mass of users large enough to make merchants care — which is precisely what the EuroPA deal attempts to deliver by connecting existing national user bases rather than building from scratch.</p>
<h2>The Digital Euro Question</h2>
<p>Running in parallel is the ECB’s digital euro project, which would create a central bank-backed digital currency usable across the eurozone. EU finance ministers have <a href="https://moderndiplomacy.eu/2025/09/19/eu-aims-to-rival-visa-mastercard-with-digital-euro/" target="_blank" rel="noopener">accelerated discussions</a> on the initiative, though the European Parliament has not yet passed the required legislation. Once approved, the ECB estimates it would need a further two to three years to launch.</p>
<p>EPI is careful to distinguish Wero from the digital euro. Wero is a private-sector initiative; the digital euro is public money. They are designed to complement rather than compete — though the overlap in ambition is obvious. Both exist because Europe’s political establishment has finally accepted that payments sovereignty is as strategically important as energy independence or <a href="https://europeanbusinessmagazine.com/business/why-is-europes-ipo-market-surging-in-2026-record-start-sparks-revival-hope/">defence autonomy</a>.</p>
<h2>Can It Actually Work?</h2>
<p>Sceptics have good reasons for doubt. Creating a viable alternative to Visa and Mastercard requires “several billion euros” in investment, according to EPI’s own estimates. Low interchange fees under EU regulation make profitability difficult. Consumer habits are deeply entrenched — and neither Visa nor Mastercard will sit idle while Europe tries to dismantle their most profitable market.</p>
<p>Weimert herself concedes that calling Wero a “challenger” may be premature, <a href="https://finance.yahoo.com/news/europe-banks-launching-product-break-101215642.html" target="_blank" rel="noopener">describing it as functioning like a startup</a> — albeit one with €500 million in backing and 47 million users already on board.</p>
<p>But the political tailwinds are stronger than they have ever been. The EU’s instant payments regulation, the Capital Markets Union push, the <a href="https://europeanbusinessmagazine.com/business/indias-mother-of-all-deals-the-winners-the-losers-and-the-33-trillion-bet/">broader drive for European strategic autonomy</a> in a world of tariff wars and great power rivalry — all point in the same direction. The question is no longer whether Europe wants its own payment infrastructure. It is whether it can execute fast enough to matter.</p>
<p>As Lagarde put it: “We have the assets and opportunities to do that ourselves. And if we were to remove the internal barriers that we have set for ourselves in Europe, our economic wealth would increase significantly.”</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Clean-room implementation of Half-Life 2 on the Quake 1 engine (231 pts)]]></title>
            <link>https://code.idtech.space/fn/hl2</link>
            <guid>46958231</guid>
            <pubDate>Tue, 10 Feb 2026 11:21:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://code.idtech.space/fn/hl2">https://code.idtech.space/fn/hl2</a>, See on <a href="https://news.ycombinator.com/item?id=46958231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="readme">
			
				<h2 id="user-content-img-rt2-png-rad-therapy-ii" dir="auto"><a href="https://code.idtech.space/fn/hl2/media/branch/current/img/rt2.png" target="_blank" rel="nofollow noopener"><img src="https://code.idtech.space/fn/hl2/media/branch/current/img/rt2.png" alt=""></a> Rad-Therapy II</h2>
<p dir="auto">The original port of <strong>Half-Life 2</strong> (2004) to Quake(World).</p>
<p dir="auto">The game is <strong>not</strong> playable from start to finish. <em>You can play deathmatch and other odd modes.</em></p>
<p dir="auto"><a href="https://code.idtech.space/fn/hl2/media/branch/current/img/preview1.jpg" target="_blank" rel="nofollow noopener"><img src="https://code.idtech.space/fn/hl2/media/branch/current/img/preview1.jpg" alt="Preview 1"></a>
<a href="https://code.idtech.space/fn/hl2/media/branch/current/img/preview2.jpg" target="_blank" rel="nofollow noopener"><img src="https://code.idtech.space/fn/hl2/media/branch/current/img/preview2.jpg" alt="Preview 2"></a>
<a href="https://code.idtech.space/fn/hl2/media/branch/current/img/preview3.jpg" target="_blank" rel="nofollow noopener"><img src="https://code.idtech.space/fn/hl2/media/branch/current/img/preview3.jpg" alt="Preview 3"></a>
<a href="https://code.idtech.space/fn/hl2/media/branch/current/img/preview4.jpg" target="_blank" rel="nofollow noopener"><img src="https://code.idtech.space/fn/hl2/media/branch/current/img/preview4.jpg" alt="Preview 4"></a></p>
<p dir="auto">Requires both <code>hl2</code> and <code>hl2dm</code> directories in order to function. Any copy will do fine. If you're on a case-insensitive filesystem and you're running pre .vpk data files you might want to put them in a .zip and name it 'pak0.pk3'. It's generally easier to just use the latest data from Steam.</p>
<h2 id="user-content-playing-installing" dir="auto">Playing/Installing</h2>
<p dir="auto">Run <a href="https://www.fteqw.org/" rel="nofollow">FTE</a> like so:</p>
<p dir="auto"><code>fteqw.exe -halflife2</code></p>
<p dir="auto">It will then automatically attempt to install <strong>Rad-Therapy II</strong> - when run from within your <strong>Half-Life 2: Deathmatch</strong> directory.</p>
<h2 id="user-content-building" dir="auto">Building</h2>
<p dir="auto">Git clone <a href="https://code.idtech.space/vera/nuclide" rel="nofollow">Nuclide</a> first, run <code>make update</code> and <code>make fteqcc</code>, then clone the repository inside the Nuclide-SDK:</p>
<pre><code>git clone https://code.idtech.space/fn/hl2 hl2
make game GAME=hl2
make plugins GAME=hl2
</code></pre><p dir="auto">The last command will build the plugins required for the engine to load the data files. The one before it will build the game-logic.
Make sure that Nuclide-SDK has <code>fteqcc</code> and <code>fteqw</code> present for building and running, respectively.
It will also respect versions installed by the package manager, just make sure it's up to date.</p>
<h2 id="user-content-community" dir="auto">Community</h2>
<h3 id="user-content-matrix" dir="auto">Matrix</h3>
<p dir="auto">If you're a fellow Matrix user, join the Nuclide Space. Where you can ask questions, or prod devs about what they're up to.
<a href="https://matrix.to/#/%23nuclide:matrix.org" rel="nofollow">https://matrix.to/#/#nuclide:matrix.org</a></p>
<h3 id="user-content-irc" dir="auto">IRC</h3>
<p dir="auto">You can also join us on #nuclide via irc.libera.chat.
It's bridged with the main room of the Matrix space.</p>
<h2 id="user-content-license" dir="auto">License</h2>
<p dir="auto">ISC License</p>
<p dir="auto">Copyright (c) 2019-2025 Marco "eukara" Cawthorne <a href="mailto:marco@icculus.org" rel="nofollow">marco@icculus.org</a></p>
<p dir="auto">Permission to use, copy, modify, and distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.</p>
<p dir="auto">THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF MIND, USE, DATA OR PROFITS, WHETHER
IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING
OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.</p>
<h2 id="user-content-content-copyright-notice" dir="auto">Content Copyright Notice</h2>
<p dir="auto">Half-Life 2 and Half-Life 2: Deathmatch belong to Valve Corporation.
Original licensed assets from Steam or a disc are required in order to experience <strong>Rad-Therapy II</strong>.</p>

			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen-Image-2.0: Professional infographics, exquisite photorealism (259 pts)]]></title>
            <link>https://qwen.ai/blog?id=qwen-image-2.0</link>
            <guid>46957198</guid>
            <pubDate>Tue, 10 Feb 2026 09:19:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwen.ai/blog?id=qwen-image-2.0">https://qwen.ai/blog?id=qwen-image-2.0</a>, See on <a href="https://news.ycombinator.com/item?id=46957198">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a macOS tool for network engineers – it's called NetViews (109 pts)]]></title>
            <link>https://www.netviews.app</link>
            <guid>46955712</guid>
            <pubDate>Tue, 10 Feb 2026 05:20:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.netviews.app">https://www.netviews.app</a>, See on <a href="https://news.ycombinator.com/item?id=46955712">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><img src="https://tailkits.com/ui/iframe/assets/img/bg-12.png" alt="Background image"></p><div x-data="{ bannerVisible: true }" x-show="bannerVisible" x-transition=""> <p>
PingStalker is now NetViews - same amazing app, just a new name!
</p> </div> <header data-astro-cid-pux6a34n=""> <div data-astro-cid-pux6a34n="" x-data="{ mobileMenuOpen: false }">  <nav data-astro-cid-pux6a34n=""> <ul data-astro-cid-pux6a34n=""> <li data-astro-cid-pux6a34n=""> <a href="https://www.netviews.app/" data-astro-cid-pux6a34n="">
Home
</a> </li> <li data-astro-cid-pux6a34n=""> <a href="https://www.netviews.app/download" data-astro-cid-pux6a34n="">
Download
</a> </li> <li data-astro-cid-pux6a34n=""> <a href="https://www.netviews.app/pricing" data-astro-cid-pux6a34n="">
Purchase
</a> </li> <li data-astro-cid-pux6a34n=""> <a href="https://www.netviews.app/changelog" data-astro-cid-pux6a34n="">
Changelog
</a> </li> <li data-astro-cid-pux6a34n=""> <a href="https://www.netviews.app/about" data-astro-cid-pux6a34n="">
About
</a> </li> <li data-astro-cid-pux6a34n=""> <a href="https://www.netviews.app/help/" target="_blank" data-astro-cid-pux6a34n="">
Help
</a> </li> </ul> </nav>  </div> </header>   <div> <!-- Text column --> <div> <p>
Introducing NetViews for macOS
</p> <p>
The Network and Wi-Fi Diagnostic Tool for macOS
</p> <p>
NetViews is a modern, macOS network scanning app inspired by the specialized needs of IT, Wi-Fi, and network professionals. It combines host discovery, Wi-Fi insights, real-time monitoring, and vendor/DNS insights with a clean, native interface - giving you the tools you need without the complexity you don't.
</p> <p> <a href="https://www.netviews.app/#LearnMore" title="Learn more"> 
Learn more
 </a> <a href="https://www.netviews.app/download" title="Free Trial">
Try free
<span> - 7 days</span>  </a> </p> </div> <!-- Image column — crossfading slideshow --> <p><img src="https://www.netviews.app/_astro/ss1.CVDp-rYP_29OLv4.webp" alt="NetViews screenshot 1" data-slide="0" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"><img src="https://www.netviews.app/_astro/ss2.B_F7EkJB_Z2eCANu.webp" alt="NetViews screenshot 2" data-slide="1" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"><img src="https://www.netviews.app/_astro/ss3.BFdd9pWc_Z1sMvhO.webp" alt="NetViews screenshot 3" data-slide="2" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"><img src="https://www.netviews.app/_astro/ss4.Dz9bHtd6_ZDfmf9.webp" alt="NetViews screenshot 4" data-slide="3" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"><img src="https://www.netviews.app/_astro/ss5.Drb80tM8_ZkfRsN.webp" alt="NetViews screenshot 5" data-slide="4" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"><img src="https://www.netviews.app/_astro/ss6.CY6etiJ-_Zsj7bF.webp" alt="NetViews screenshot 6" data-slide="5" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"><img src="https://www.netviews.app/_astro/ss7.D8bYvHF6_1awjYx.webp" alt="NetViews screenshot 7" data-slide="6" loading="lazy" decoding="async" fetchpriority="auto" width="1277" height="685"> </p> </div>  <div> <div> <p>
NetViews for macOS
</p> <p>
Everything you need to master your network
</p> <p>
Turn your Mac into the most powerful network diagnostic tool available. Professional-grade network diagnostics, monitoring, and analysis - without leaving your keyboard.
</p> </div> <div> <!-- Powerful, live interface --> <div>  <h3>Powerful, live interface</h3> <p>
Real-time dashboards that update as your network changes, giving you instant visibility into every connection.
</p> </div> <!-- Network Scanning and monitoring --> <div>  <h3>Network scanning and monitoring</h3> <p>
Discover every device on your network, track uptime, and get alerts when hosts go up or down.
</p> </div> <!-- Advanced Wi-Fi diagnostics --> <div>  <h3>Advanced Wi-Fi diagnostics</h3> <p>
Analyze signal strength, channel congestion, and noise levels to optimize your wireless performance.
</p> </div> </div> </div> <section> <div> <p>
Feature packed
</p> <p>
Built for network professionals
</p> <p>
Every tool you need to diagnose, monitor, and optimize your network - in one native macOS app.
</p> <ul> <li>  <p>Ping hosts, with notifications</p> </li> <li>  <p>Check the pulse of the network with a live network monitor including DHCP, DNS, LACP/CDP, VLAN tags, and much more</p> </li> <li>  <p>Speed test backed by CloudFlare</p> </li> <li>  <p>Wi-Fi auditing and checklists</p> </li> <li>  <p>Powerful network calculators</p> </li> <li>  <p>Network &amp; port scans</p> </li> <li>  <p>Deep information on Wi-Fi connectivity</p> </li> <li>  <p>... and much more</p> </li> </ul> </div> <img src="https://tailkits.com/ui/iframe/assets/img/bg-linear-6.png" alt="Features"> </section>  <div x-data="{
           currentTestimonial: 0,
           testimonials: [
             {
               quote: 'I\'m used to the command line. Not because I love typing, but because it\'s often the fastest way to get where I need. A good UI can make the difference, and this one really shines!',
               author: 'Nick S.',
               role: 'Head of Technology Development'
             },
             {
               quote: 'Amazing tool! Thank you for sharing it!',
               author: 'Megan S.',
               role: 'Network Engineer'
             },
             {
               quote: 'Love seeing tools that make network visibility on macOS more intuitive and powerful. This one looks like a great everyday companion for anyone who lices in the network stack',
               author: 'Ben S',
               role: 'Technology Leader'
             },
             {
               quote: 'I\'ve been VERY happy with it so far. Thanks for your work, well worth the price, and then some.',
               author: 'Andrew R.',
               role: 'Engineering and Program Management'
             },
             {
               quote: 'High information density. I dig it.',
               author: 'Christopher F.',
               role: 'IT Systems Engineer'
             }
           ],
           get currentQuote() { return this.testimonials[this.currentTestimonial]; },
           nextTestimonial() {
             this.currentTestimonial = (this.currentTestimonial + 1) % this.testimonials.length;
           },
           prevTestimonial() {
             this.currentTestimonial = this.currentTestimonial === 0 ? this.testimonials.length - 1 : this.currentTestimonial - 1;
           }
         }" x-init="setInterval(() => nextTestimonial(), 5000)"> <figure> <blockquote>  <div> <figcaption x-text="currentQuote.author"></figcaption>  </div> <img src="https://www.netviews.app/nv256.png" alt="Logo">NetViews
 <!-- Progress Dots -->  </blockquote> <img src="https://tailkits.com/ui/iframe/assets/img/quote.svg" alt="Quote"> </figure> </div> <div> <div> <p>
Get full access
</p> <p>
Simple pricing, no subscriptions
</p> <p>
Buy once, you own it. Volume licensing is available for either edition.
</p> </div>  <div> <!-- Standard --> <div> <p>Standard</p> <p>
Everything you need to diagnose and monitor your network.
</p>  <ul> <li>  <p>Live network features including logging and pinging</p> </li> <li>  <p>Network scanning and probing</p> </li> <li>  <p>QR code generator</p> </li> <li>  <p>Speed tests</p> </li> <li>  <p>Wi-Fi client checklist</p> </li> <li>  <p>Network calculators</p> </li> <li>  <p>Wi-Fi advanced tools</p> </li> </ul> </div> <!-- Pro --> <div> <div>  <p>
The full NetViews experience with advanced features.
</p> <div>  <p>
7 day free trial included
</p> </div>  <ul> <li>  <p>All Standard features</p> </li> <li>  <p>History and Timeline views for pings and network connectivity</p> </li> <li>  <p>Additional Wi-Fi audits</p> </li> <li>  <p>COMING SOON: Toolbar support</p> </li> </ul> </div> <div> <p><a href="https://bmmup.lemonsqueezy.com/checkout/buy/efd374c0-c47c-47b1-b9ec-6601ba8909c2" title="Purchase Pro">
Purchase Pro
</a></p><p>
7 day free trial included. Volume licensing available.
</p> </div> </div> </div> </div>     </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI doesn’t reduce work, it intensifies it (235 pts)]]></title>
            <link>https://simonwillison.net/2026/Feb/9/ai-intensifies-work/</link>
            <guid>46955703</guid>
            <pubDate>Tue, 10 Feb 2026 05:19:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2026/Feb/9/ai-intensifies-work/">https://simonwillison.net/2026/Feb/9/ai-intensifies-work/</a>, See on <a href="https://news.ycombinator.com/item?id=46955703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p><strong><a href="https://hbr.org/2026/02/ai-doesnt-reduce-work-it-intensifies-it">AI Doesn’t Reduce Work—It Intensifies It</a></strong> (<a href="https://news.ycombinator.com/item?id=46945755" title="Hacker News">via</a>) Aruna Ranganathan and Xingqi Maggie Ye from Berkeley Haas&nbsp;School of Business report initial findings in the HBR from their April to December 2025 study of 200 employees at a "U.S.-based technology company".</p>
<p>This captures an effect I've been observing in my own work with LLMs: the productivity boost these things can provide is <em>exhausting</em>.</p>
<blockquote>
<p>AI introduced a new rhythm in which workers managed several active threads at once: manually writing code while AI generated an alternative version, running multiple agents in parallel, or reviving long-deferred tasks because AI could “handle them” in the background. They did this, in part, because they felt they had a “partner” that could help them move through their workload.</p>
<p>While this sense of having a “partner” enabled a feeling of momentum, the reality was a continual switching of attention, frequent checking of AI outputs, and a growing number of open tasks. This created cognitive load and a sense of always juggling, even as the work felt productive.</p>
</blockquote>
<p>I'm frequently finding myself with work on two or three projects running parallel. I can get <em>so much done</em>, but after just an hour or two my mental energy for the day feels almost entirely depleted.</p>
<p>I've had conversations with people recently who are losing sleep because they're finding building yet another feature with "just one more prompt" irresistible.</p>
<p>The HBR piece calls for organizations to build an "AI practice" that structures how AI is used to help avoid burnout and counter effects that "make it harder for organizations to distinguish genuine productivity gains from unsustainable intensity".</p>
<p>I think we've just disrupted decades of existing intuition about sustainable working practices. It's going to take a while and some discipline to find a good new balance.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Frontier AI agents violate ethical constraints 30–50% of time, pressured by KPIs (481 pts)]]></title>
            <link>https://arxiv.org/abs/2512.20798</link>
            <guid>46954920</guid>
            <pubDate>Tue, 10 Feb 2026 03:17:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.20798">https://arxiv.org/abs/2512.20798</a>, See on <a href="https://news.ycombinator.com/item?id=46954920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.20798">View PDF</a>
    <a href="https://arxiv.org/html/2512.20798v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>As autonomous AI agents are increasingly deployed in high-stakes environments, ensuring their safety and alignment with human values has become a paramount concern. Current safety benchmarks primarily evaluate whether agents refuse explicitly harmful instructions or whether they can maintain procedural compliance in complex tasks. However, there is a lack of benchmarks designed to capture emergent forms of outcome-driven constraint violations, which arise when agents pursue goal optimization under strong performance incentives while deprioritizing ethical, legal, or safety constraints over multiple steps in realistic production settings. To address this gap, we introduce a new benchmark comprising 40 distinct scenarios. Each scenario presents a task that requires multi-step actions, and the agent's performance is tied to a specific Key Performance Indicator (KPI). Each scenario features Mandated (instruction-commanded) and Incentivized (KPI-pressure-driven) variations to distinguish between obedience and emergent misalignment. Across 12 state-of-the-art large language models, we observe outcome-driven constraint violations ranging from 1.3% to 71.4%, with 9 of the 12 evaluated models exhibiting misalignment rates between 30% and 50%. Strikingly, we find that superior reasoning capability does not inherently ensure safety; for instance, Gemini-3-Pro-Preview, one of the most capable models evaluated, exhibits the highest violation rate at 71.4%, frequently escalating to severe misconduct to satisfy KPIs. Furthermore, we observe significant "deliberative misalignment", where the models that power the agents recognize their actions as unethical during separate evaluation. These results emphasize the critical need for more realistic agentic-safety training before deployment to mitigate their risks in the real world.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Miles Q. Li [<a href="https://arxiv.org/show-email/036cb60c/2512.20798" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2512.20798v1" rel="nofollow">[v1]</a></strong>
        Tue, 23 Dec 2025 21:52:53 UTC (51 KB)<br>
    <strong>[v2]</strong>
        Sun, 1 Feb 2026 00:23:19 UTC (52 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rust implementation of Mistral's Voxtral Mini 4B Realtime runs in your browser (365 pts)]]></title>
            <link>https://github.com/TrevorS/voxtral-mini-realtime-rs</link>
            <guid>46954136</guid>
            <pubDate>Tue, 10 Feb 2026 01:26:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/TrevorS/voxtral-mini-realtime-rs">https://github.com/TrevorS/voxtral-mini-realtime-rs</a>, See on <a href="https://news.ycombinator.com/item?id=46954136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Voxtral Mini 4B Realtime (Rust)</h2><a id="user-content-voxtral-mini-4b-realtime-rust" aria-label="Permalink: Voxtral Mini 4B Realtime (Rust)" href="#voxtral-mini-4b-realtime-rust"></a></p>
<p dir="auto"><a href="https://huggingface.co/TrevorJS/voxtral-mini-realtime-gguf" rel="nofollow"><img src="https://camo.githubusercontent.com/cfd5aad45986b4e3bfee0bc62c43362730814bb78217911b0dce1acfcf6f9c35/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462541342539372d4d6f64656c5f6f6e5f48756767696e67466163652d79656c6c6f77" alt="HuggingFace" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97-Model_on_HuggingFace-yellow"></a>
<a href="https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime" rel="nofollow"><img src="https://camo.githubusercontent.com/4e4d92ddbe9e446e395e32125f4f1bbbacad5126c7c08b6e7f110e1f3a0e7b32/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462539342538412d4c6976655f44656d6f2d626c7565" alt="Live Demo" data-canonical-src="https://img.shields.io/badge/%F0%9F%94%8A-Live_Demo-blue"></a></p>
<p dir="auto">Streaming speech recognition running natively and in the browser. A pure Rust implementation of <a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602" rel="nofollow">Mistral's Voxtral Mini 4B Realtime</a> model using the <a href="https://burn.dev/" rel="nofollow">Burn</a> ML framework.</p>
<p dir="auto">The Q4 GGUF quantized path (2.5 GB) runs entirely client-side in a browser tab via WASM + WebGPU. <a href="https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime" rel="nofollow">Try it live.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Native CLI</h3><a id="user-content-native-cli" aria-label="Permalink: Native CLI" href="#native-cli"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download model weights (~9 GB)
uv run --with huggingface_hub \
  hf download mistralai/Voxtral-Mini-4B-Realtime-2602 --local-dir models/voxtral

# Transcribe an audio file (f32 SafeTensors path)
cargo run --release --features &quot;wgpu,cli,hub&quot; --bin voxtral-transcribe -- \
  --audio audio.wav --model models/voxtral

# Or use the Q4 quantized path (~2.5 GB)
cargo run --release --features &quot;wgpu,cli,hub&quot; --bin voxtral-transcribe -- \
  --audio audio.wav --gguf models/voxtral-q4.gguf --tokenizer models/voxtral/tekken.json"><pre><span><span>#</span> Download model weights (~9 GB)</span>
uv run --with huggingface_hub \
  hf download mistralai/Voxtral-Mini-4B-Realtime-2602 --local-dir models/voxtral

<span><span>#</span> Transcribe an audio file (f32 SafeTensors path)</span>
cargo run --release --features <span><span>"</span>wgpu,cli,hub<span>"</span></span> --bin voxtral-transcribe -- \
  --audio audio.wav --model models/voxtral

<span><span>#</span> Or use the Q4 quantized path (~2.5 GB)</span>
cargo run --release --features <span><span>"</span>wgpu,cli,hub<span>"</span></span> --bin voxtral-transcribe -- \
  --audio audio.wav --gguf models/voxtral-q4.gguf --tokenizer models/voxtral/tekken.json</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Browser Demo</h3><a id="user-content-browser-demo" aria-label="Permalink: Browser Demo" href="#browser-demo"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build WASM package
wasm-pack build --target web --no-default-features --features wasm

# Generate self-signed cert (WebGPU requires secure context)
openssl req -x509 -newkey ec -pkeyopt ec_paramgen_curve:prime256v1 \
  -keyout /tmp/voxtral-key.pem -out /tmp/voxtral-cert.pem \
  -days 7 -nodes -subj &quot;/CN=localhost&quot;

# Start dev server
bun serve.mjs"><pre><span><span>#</span> Build WASM package</span>
wasm-pack build --target web --no-default-features --features wasm

<span><span>#</span> Generate self-signed cert (WebGPU requires secure context)</span>
openssl req -x509 -newkey ec -pkeyopt ec_paramgen_curve:prime256v1 \
  -keyout /tmp/voxtral-key.pem -out /tmp/voxtral-cert.pem \
  -days 7 -nodes -subj <span><span>"</span>/CN=localhost<span>"</span></span>

<span><span>#</span> Start dev server</span>
bun serve.mjs</pre></div>
<p dir="auto">Open <code>https://localhost:8443</code>, accept the certificate, and click <strong>Load from Server</strong> to download the model shards. Record from your microphone or upload a WAV file to transcribe.</p>
<p dir="auto"><a href="https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime" rel="nofollow">Hosted demo on HuggingFace Spaces</a> if you want to skip local setup.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<div data-snippet-clipboard-copy-content="Audio (16kHz mono)
  -> Mel spectrogram [B, 128, T]
    -> Causal encoder (32 layers, 1280 dim, sliding window 750)
      -> Conv 4x downsample -> Reshape [B, T/16, 5120]
        -> Adapter [B, T/16, 3072]
          -> Autoregressive decoder (26 layers, 3072 dim, GQA 32Q/8KV)
            -> Token IDs -> Text"><pre><code>Audio (16kHz mono)
  -&gt; Mel spectrogram [B, 128, T]
    -&gt; Causal encoder (32 layers, 1280 dim, sliding window 750)
      -&gt; Conv 4x downsample -&gt; Reshape [B, T/16, 5120]
        -&gt; Adapter [B, T/16, 3072]
          -&gt; Autoregressive decoder (26 layers, 3072 dim, GQA 32Q/8KV)
            -&gt; Token IDs -&gt; Text
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Two Inference Paths</h3><a id="user-content-two-inference-paths" aria-label="Permalink: Two Inference Paths" href="#two-inference-paths"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th>F32 (native)</th>
<th>Q4 GGUF (native + browser)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Weights</td>
<td>SafeTensors (~9 GB)</td>
<td>GGUF Q4_0 (~2.5 GB)</td>
</tr>
<tr>
<td>Linear ops</td>
<td>Burn tensor matmul</td>
<td>Custom WGSL shader (fused dequant + matmul)</td>
</tr>
<tr>
<td>Embeddings</td>
<td>f32 tensor (1.5 GiB)</td>
<td>Q4 on GPU (216 MB) + CPU bytes for lookups</td>
</tr>
<tr>
<td>Browser</td>
<td>No</td>
<td>Yes (WASM + WebGPU)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Q4 Padding Workaround</h3><a id="user-content-q4-padding-workaround" aria-label="Permalink: Q4 Padding Workaround" href="#q4-padding-workaround"></a></p>
<p dir="auto">The upstream mistral-common library left-pads audio with 32 silence tokens (at 12.5 Hz). After the mel/conv/reshape pipeline, this covers only 16 of the 38 decoder prefix positions with silence — the remaining 22 contain actual audio. The f32 model handles this fine, but Q4_0 quantization makes the decoder sensitive to speech content in the prefix: audio that starts immediately with speech (mic recordings, clips with no leading silence) produces all-pad tokens instead of text.</p>
<p dir="auto">The left padding is increased to 76 tokens, which maps to exactly 38 decoder tokens of silence and covers the full streaming prefix. See <a href="https://github.com/TrevorS/voxtral-mini-realtime-rs/blob/main/src/audio/pad.rs"><code>src/audio/pad.rs</code></a> for details.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">WASM Constraints Solved</h3><a id="user-content-wasm-constraints-solved" aria-label="Permalink: WASM Constraints Solved" href="#wasm-constraints-solved"></a></p>
<p dir="auto">Running a 4B model in a browser tab required solving five hard constraints:</p>
<ol dir="auto">
<li><strong>2 GB allocation limit</strong> — <code>ShardedCursor</code> reads across multiple <code>Vec&lt;u8&gt;</code> buffers</li>
<li><strong>4 GB address space</strong> — Two-phase loading: parse weights, drop reader, then finalize</li>
<li><strong>1.5 GiB embedding table</strong> — Q4 embeddings on GPU + CPU-side row lookups</li>
<li><strong>No sync GPU readback</strong> — All tensor reads use <code>into_data_async().await</code></li>
<li><strong>256 workgroup invocation limit</strong> — Patched cubecl-wgpu to cap reduce kernel workgroups</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Native (default features: wgpu + native-tokenizer)
cargo build --release

# With all features
cargo build --release --features &quot;wgpu,cli,hub&quot;

# WASM
wasm-pack build --target web --no-default-features --features wasm"><pre><span><span>#</span> Native (default features: wgpu + native-tokenizer)</span>
cargo build --release

<span><span>#</span> With all features</span>
cargo build --release --features <span><span>"</span>wgpu,cli,hub<span>"</span></span>

<span><span>#</span> WASM</span>
wasm-pack build --target web --no-default-features --features wasm</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Feature Flags</h3><a id="user-content-feature-flags" aria-label="Permalink: Feature Flags" href="#feature-flags"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>wgpu</code> (default)</td>
<td>GPU backend via Burn/CubeCL (WebGPU, Vulkan, Metal)</td>
</tr>
<tr>
<td><code>native-tokenizer</code> (default)</td>
<td>Tekken tokenizer (C deps, not WASM-compatible)</td>
</tr>
<tr>
<td><code>wasm</code></td>
<td>Browser support: wasm-bindgen, WebGPU device init, JS bindings</td>
</tr>
<tr>
<td><code>cli</code></td>
<td>CLI binary with clap + indicatif</td>
</tr>
<tr>
<td><code>hub</code></td>
<td>HuggingFace Hub model downloads</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing</h2><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Unit + integration tests (requires GPU for full suite)
cargo test --features &quot;wgpu,cli,hub&quot;

# Lint
cargo clippy --features &quot;wgpu,cli,hub&quot; -- -D warnings
cargo clippy --no-default-features --features wasm --target wasm32-unknown-unknown -- -D warnings

# E2E browser test (requires Playwright + model shards)
bunx playwright test tests/e2e_browser.spec.ts"><pre><span><span>#</span> Unit + integration tests (requires GPU for full suite)</span>
cargo <span>test</span> --features <span><span>"</span>wgpu,cli,hub<span>"</span></span>

<span><span>#</span> Lint</span>
cargo clippy --features <span><span>"</span>wgpu,cli,hub<span>"</span></span> -- -D warnings
cargo clippy --no-default-features --features wasm --target wasm32-unknown-unknown -- -D warnings

<span><span>#</span> E2E browser test (requires Playwright + model shards)</span>
bunx playwright <span>test</span> tests/e2e_browser.spec.ts</pre></div>
<p dir="auto">GPU-dependent tests (model layer shapes, Q4 matmul, WGSL shader correctness) are skipped in CI since GitHub Actions runners lack a GPU adapter. These tests run locally on any machine with Vulkan, Metal, or WebGPU support.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Preparation</h2><a id="user-content-model-preparation" aria-label="Permalink: Model Preparation" href="#model-preparation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Q4 GGUF Sharding (for browser)</h3><a id="user-content-q4-gguf-sharding-for-browser" aria-label="Permalink: Q4 GGUF Sharding (for browser)" href="#q4-gguf-sharding-for-browser"></a></p>
<p dir="auto">The GGUF file must be split into shards of 512 MB or less to stay under the browser's <code>ArrayBuffer</code> limit:</p>
<div dir="auto" data-snippet-clipboard-copy-content="split -b 512m models/voxtral-q4.gguf models/voxtral-q4-shards/shard-"><pre>split -b 512m models/voxtral-q4.gguf models/voxtral-q4-shards/shard-</pre></div>
<p dir="auto">The dev server and E2E test discover shards automatically from <code>models/voxtral-q4-shards/</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">Coming soon: accuracy (WER) and inference speed benchmarks across native and browser targets.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="src/
  audio/          # Mel spectrogram, chunking, resampling, padding
  models/         # F32 model: encoder, decoder, adapter, attention, RoPE, KV cache
  gguf/           # Q4 GGUF: reader, loader, model, tensor, WGSL shader, tests
  web/            # WASM bindings: VoxtralQ4, initWgpuDevice, async decode loop
  tokenizer/      # Tekken tokenizer wrapper (native only)
  bin/transcribe  # CLI binary

web/              # Browser demo: index.html, worker.js, voxtral-client.js
tests/            # Integration tests + Playwright E2E spec
scripts/          # Dev scripts: reference implementations, weight inspection, E2E helpers
patches/          # cubecl-wgpu workgroup size fix for WebGPU"><pre><code>src/
  audio/          # Mel spectrogram, chunking, resampling, padding
  models/         # F32 model: encoder, decoder, adapter, attention, RoPE, KV cache
  gguf/           # Q4 GGUF: reader, loader, model, tensor, WGSL shader, tests
  web/            # WASM bindings: VoxtralQ4, initWgpuDevice, async decode loop
  tokenizer/      # Tekken tokenizer wrapper (native only)
  bin/transcribe  # CLI binary

web/              # Browser demo: index.html, worker.js, voxtral-client.js
tests/            # Integration tests + Playwright E2E spec
scripts/          # Dev scripts: reference implementations, weight inspection, E2E helpers
patches/          # cubecl-wgpu workgroup size fix for WebGPU
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Apache-2.0</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pure C, CPU-only inference with Mistral Voxtral Realtime 4B speech to text model (272 pts)]]></title>
            <link>https://github.com/antirez/voxtral.c</link>
            <guid>46954049</guid>
            <pubDate>Tue, 10 Feb 2026 01:17:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/antirez/voxtral.c">https://github.com/antirez/voxtral.c</a>, See on <a href="https://news.ycombinator.com/item?id=46954049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Voxtral Realtime 4B Pure C Implementation</h2><a id="user-content-voxtral-realtime-4b-pure-c-implementation" aria-label="Permalink: Voxtral Realtime 4B Pure C Implementation" href="#voxtral-realtime-4b-pure-c-implementation"></a></p>
<p dir="auto">This is a C implementation of the inference pipeline for the <a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602" rel="nofollow">Mistral AI's Voxtral Realtime 4B model</a>. It has zero external dependencies beyond the C standard library. The MPS inference is decently fast, while the BLAS acceleration is usable but slow (it continuously convert the bf16 weights to fp32).</p>
<p dir="auto">Audio processing uses a chunked encoder with overlapping windows, bounding memory usage regardless of input length. Audio can also be piped from stdin (<code>--stdin</code>), or captured live from the microphone (<code>--from-mic</code>, macOS), making it easy to transcode and transcribe any format via ffmpeg. A streaming C API (<code>vox_stream_t</code>) lets you feed audio incrementally and receive token strings as they become available.</p>
<p dir="auto"><strong>More testing needed:</strong> please note that this project was mostly tested against few samples, and likely requires some more work to be production quality. However the hard part, to understand the model inference and reproduce the inference pipeline, is here, so the rest likely can be done easily. Testing it against very long transcriptions, able to stress the KV cache circular buffer, will be a useful task.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/antirez/voxtral.c/blob/main/samples/demo.gif"><img src="https://github.com/antirez/voxtral.c/raw/main/samples/demo.gif" alt="demo" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivations (and some rant)</h2><a id="user-content-motivations-and-some-rant" aria-label="Permalink: Motivations (and some rant)" href="#motivations-and-some-rant"></a></p>
<p dir="auto"><strong>Thank you to Mistral</strong> for releasing such a great model in an Open Weights fashion. However, the author of this project believes that limiting the inference to a partnership with vLLM, without providing a self-contained reference implementation in Python, limits the model's actual reach and the potential good effects it could have. For this reason, this project was created: it provides both a pure C inference engine and a simple, self-contained Python reference implementation (<code>python_simple_implementation.py</code>) that anyone can read and understand without digging through the vLLM codebase.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build (choose your backend)
make mps       # Apple Silicon (fastest)
# or: make blas    # Intel Mac / Linux with OpenBLAS

# Download the model (~8.9GB)
./download_model.sh

# Transcribe audio (tokens stream to stdout as generated)
./voxtral -d voxtral-model -i audio.wav

# Live microphone transcription (macOS, Ctrl+C to stop)
./voxtral -d voxtral-model --from-mic

# Pipe any format via ffmpeg
ffmpeg -i audio.mp3 -f s16le -ar 16000 -ac 1 - 2>/dev/null | \
    ./voxtral -d voxtral-model --stdin

# Real-time streaming with low latency
ffmpeg -i audio.mp3 -f s16le -ar 16000 -ac 1 - 2>/dev/null | \
    ./voxtral -d voxtral-model --stdin -I 0.5"><pre><span><span>#</span> Build (choose your backend)</span>
make mps       <span><span>#</span> Apple Silicon (fastest)</span>
<span><span>#</span> or: make blas    # Intel Mac / Linux with OpenBLAS</span>

<span><span>#</span> Download the model (~8.9GB)</span>
./download_model.sh

<span><span>#</span> Transcribe audio (tokens stream to stdout as generated)</span>
./voxtral -d voxtral-model -i audio.wav

<span><span>#</span> Live microphone transcription (macOS, Ctrl+C to stop)</span>
./voxtral -d voxtral-model --from-mic

<span><span>#</span> Pipe any format via ffmpeg</span>
ffmpeg -i audio.mp3 -f s16le -ar 16000 -ac 1 - <span>2&gt;</span>/dev/null <span>|</span> \
    ./voxtral -d voxtral-model --stdin

<span><span>#</span> Real-time streaming with low latency</span>
ffmpeg -i audio.mp3 -f s16le -ar 16000 -ac 1 - <span>2&gt;</span>/dev/null <span>|</span> \
    ./voxtral -d voxtral-model --stdin -I 0.5</pre></div>
<p dir="auto">That's it. No Python runtime, no CUDA toolkit, no <code>mistral_common</code> or vLLM required at inference time.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python Reference Implementation</h3><a id="user-content-python-reference-implementation" aria-label="Permalink: Python Reference Implementation" href="#python-reference-implementation"></a></p>
<p dir="auto">A self-contained Python implementation is also provided for reading and understanding the model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install torch safetensors soundfile soxr
python python_simple_implementation.py voxtral-model audio.wav"><pre>pip install torch safetensors soundfile soxr
python python_simple_implementation.py voxtral-model audio.wav</pre></div>
<p dir="auto">This requires just PyTorch and a few standard libraries.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Zero dependencies</strong>: Pure C implementation, works standalone for MPS. BLAS required for other targets (OpenBLAS on Linux).</li>
<li><strong>Metal GPU acceleration</strong>: Automatic on Apple Silicon Macs with fused GPU operations and batched attention.</li>
<li><strong>Streaming output</strong>: Tokens are printed to stdout as they are generated, word by word.</li>
<li><strong>Streaming C API</strong>: Feed audio incrementally, get token strings back as they become available.</li>
<li><strong>Memory-mapped weights</strong>: BF16 weights are mmap'd directly from safetensors, loading is near-instant.</li>
<li><strong>Live microphone input</strong>: <code>--from-mic</code> captures and transcribes from the default microphone (macOS) with automatic silence detection.</li>
<li><strong>WAV input</strong>: Supports 16-bit PCM WAV files at any sample rate (auto-resampled to 16kHz).</li>
<li><strong>Chunked encoder</strong>: Processes audio in overlapping chunks, bounding memory regardless of length.</li>
<li><strong>Rolling KV cache</strong>: Decoder KV cache is automatically compacted when it exceeds the sliding window (8192 positions), capping memory usage and allowing unlimited-length audio.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Transcription</h3><a id="user-content-basic-transcription" aria-label="Permalink: Basic Transcription" href="#basic-transcription"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="./voxtral -d voxtral-model -i recording.wav"><pre>./voxtral -d voxtral-model -i recording.wav</pre></div>
<p dir="auto">Tokens stream to stdout as they are generated. By default, timing info is printed to stderr. Use <code>--silent</code> or <code>--debug</code> to control verbosity:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./voxtral -d voxtral-model -i samples/test_speech.wav --silent    # no stderr output
./voxtral -d voxtral-model -i samples/test_speech.wav --debug     # per-layer/per-chunk details
./voxtral -d voxtral-model -i samples/test_speech.wav --alt 0.5   # show alternative tokens"><pre>./voxtral -d voxtral-model -i samples/test_speech.wav --silent    <span><span>#</span> no stderr output</span>
./voxtral -d voxtral-model -i samples/test_speech.wav --debug     <span><span>#</span> per-layer/per-chunk details</span>
./voxtral -d voxtral-model -i samples/test_speech.wav --alt 0.5   <span><span>#</span> show alternative tokens</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Alternative Tokens</h3><a id="user-content-alternative-tokens" aria-label="Permalink: Alternative Tokens" href="#alternative-tokens"></a></p>
<p dir="auto">When the model is uncertain between similar-sounding words, <code>--alt &lt;cutoff&gt;</code> shows the competing candidates inline:</p>
<div data-snippet-clipboard-copy-content="./voxtral -d voxtral-model -i audio.wav --alt 0.95
Hello, this is a test of the[ V| Vo]ox[T|tral]roll speech-to-text system."><pre><code>./voxtral -d voxtral-model -i audio.wav --alt 0.95
Hello, this is a test of the[ V| Vo]ox[T|tral]roll speech-to-text system.
</code></pre></div>
<p dir="auto">The cutoff (0.0–1.0) controls how close an alternative must be to the best token. A token qualifies if <code>1 - prob[i]/prob[0] &lt;= cutoff</code>. Lower values show only very close alternatives, higher values are more permissive.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Processing Interval (<code>-I</code>)</h3><a id="user-content-processing-interval--i" aria-label="Permalink: Processing Interval (-I)" href="#processing-interval--i"></a></p>
<p dir="auto">The <code>-I &lt;seconds&gt;</code> flag controls how often the encoder processes accumulated audio. This is the key latency/efficiency tradeoff:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./voxtral -d voxtral-model --stdin -I 0.5    # low latency (responsive, more GPU overhead)
./voxtral -d voxtral-model --stdin -I 5.0    # high efficiency (batches more audio per encoder call)"><pre>./voxtral -d voxtral-model --stdin -I 0.5    <span><span>#</span> low latency (responsive, more GPU overhead)</span>
./voxtral -d voxtral-model --stdin -I 5.0    <span><span>#</span> high efficiency (batches more audio per encoder call)</span></pre></div>
<p dir="auto">The default is 2.0 seconds. Lower values make streaming more responsive (text appears sooner after speech) but increase GPU overhead because each encoder call has a fixed startup cost (~50ms). Higher values batch more audio into fewer, larger encoder calls, improving GPU utilization.</p>
<p dir="auto">The overhead is significant: on a 60-second clip, batch mode takes ~2.9s for the encoder, while <code>-I 0.1</code> takes ~15.8s (5.4x slower) because of hundreds of small encoder calls each paying the fixed cost. For <strong>real-time streaming</strong>, values between 1.0 and 2.0 work well. Going below 0.5 wastes most of the GPU time on per-call overhead. For <strong>offline file transcription</strong> the interval is irrelevant since all audio is available at once.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reading Audio from Stdin</h3><a id="user-content-reading-audio-from-stdin" aria-label="Permalink: Reading Audio from Stdin" href="#reading-audio-from-stdin"></a></p>
<p dir="auto">The <strong><code>--stdin</code> flag</strong> reads audio from standard input instead of a file. The format is auto-detected: if the data starts with a RIFF header it is parsed as WAV, otherwise it is treated as <strong>raw signed 16-bit little-endian, 16 kHz, mono</strong> (<code>s16le</code>).</p>
<p dir="auto">This makes it trivial to transcode any audio/video format on the fly with ffmpeg:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Transcribe an MP3 file
ffmpeg -i podcast.mp3 -f s16le -ar 16000 -ac 1 - 2>/dev/null | \
    ./voxtral -d voxtral-model --stdin

# Pipe a WAV directly (auto-detected)
cat recording.wav | ./voxtral -d voxtral-model --stdin"><pre><span><span>#</span> Transcribe an MP3 file</span>
ffmpeg -i podcast.mp3 -f s16le -ar 16000 -ac 1 - <span>2&gt;</span>/dev/null <span>|</span> \
    ./voxtral -d voxtral-model --stdin

<span><span>#</span> Pipe a WAV directly (auto-detected)</span>
cat recording.wav <span>|</span> ./voxtral -d voxtral-model --stdin</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Live Microphone Input</h3><a id="user-content-live-microphone-input" aria-label="Permalink: Live Microphone Input" href="#live-microphone-input"></a></p>
<p dir="auto">The <strong><code>--from-mic</code> flag</strong> captures audio from the default microphone (macOS only, uses AudioQueue Services). Press Ctrl+C to stop. Silence is automatically detected and stripped to reduce encoder/decoder work when you pause speaking — only actual speech is processed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="./voxtral -d voxtral-model --from-mic                # default 2s processing interval
./voxtral -d voxtral-model --from-mic -I 1.0          # lower latency
./voxtral -d voxtral-model --from-mic --silent         # no stderr status"><pre>./voxtral -d voxtral-model --from-mic                <span><span>#</span> default 2s processing interval</span>
./voxtral -d voxtral-model --from-mic -I 1.0          <span><span>#</span> lower latency</span>
./voxtral -d voxtral-model --from-mic --silent         <span><span>#</span> no stderr status</span></pre></div>
<p dir="auto">If the model falls behind real-time, a warning is printed and audio is skipped to catch up.</p>
<p dir="auto"><code>--from-mic</code>, <code>--stdin</code>, and <code>-i</code> are mutually exclusive.</p>
<p dir="auto">To convert files to WAV format, just use <code>ffmpeg</code>:</p>
<div data-snippet-clipboard-copy-content="ffmpeg -i input.ogg output.wav"><pre><code>ffmpeg -i input.ogg output.wav
</code></pre></div>
<p dir="auto">The above command line works for many file types, not just for OGG files, of course.
There are two example wave files under the <code>samples</code> directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">C API</h3><a id="user-content-c-api" aria-label="Permalink: C API" href="#c-api"></a></p>
<p dir="auto">The library exposes a streaming API (<code>vox_stream_t</code>) that works for both offline and real-time use. You feed audio samples and retrieve decoded token strings as they become available.</p>
<p dir="auto"><strong>Offline transcription</strong> — feed all audio, then collect results:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include &quot;voxtral.h&quot;

vox_ctx_t *ctx = vox_load(&quot;voxtral-model&quot;);

/* Load audio (your own code, or use vox_load_wav) */
int n_samples;
float *samples = vox_load_wav(&quot;audio.wav&quot;, &amp;n_samples);

/* Transcribe */
vox_stream_t *s = vox_stream_init(ctx);
vox_stream_feed(s, samples, n_samples);
vox_stream_finish(s);

/* Collect token strings */
const char *tokens[64];
int n;
while ((n = vox_stream_get(s, tokens, 64)) > 0) {
    for (int i = 0; i < n; i++)
        printf(&quot;%s&quot;, tokens[i]);
}
printf(&quot;\n&quot;);

vox_stream_free(s);
free(samples);
vox_free(ctx);"><pre><span>#include</span> <span>"voxtral.h"</span>

<span>vox_ctx_t</span> <span>*</span><span>ctx</span> <span>=</span> <span>vox_load</span>(<span>"voxtral-model"</span>);

<span>/* Load audio (your own code, or use vox_load_wav) */</span>
<span>int</span> <span>n_samples</span>;
<span>float</span> <span>*</span><span>samples</span> <span>=</span> <span>vox_load_wav</span>(<span>"audio.wav"</span>, <span>&amp;</span><span>n_samples</span>);

<span>/* Transcribe */</span>
<span>vox_stream_t</span> <span>*</span><span>s</span> <span>=</span> <span>vox_stream_init</span>(<span>ctx</span>);
<span>vox_stream_feed</span>(<span>s</span>, <span>samples</span>, <span>n_samples</span>);
<span>vox_stream_finish</span>(<span>s</span>);

<span>/* Collect token strings */</span>
<span>const</span> <span>char</span> <span>*</span><span>tokens</span>[<span>64</span>];
<span>int</span> <span>n</span>;
<span>while</span> ((<span>n</span> <span>=</span> <span>vox_stream_get</span>(<span>s</span>, <span>tokens</span>, <span>64</span>)) <span>&gt;</span> <span>0</span>) {
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>n</span>; <span>i</span><span>++</span>)
        <span>printf</span>(<span>"%s"</span>, <span>tokens</span>[<span>i</span>]);
}
<span>printf</span>(<span>"\n"</span>);

<span>vox_stream_free</span>(<span>s</span>);
<span>free</span>(<span>samples</span>);
<span>vox_free</span>(<span>ctx</span>);</pre></div>
<p dir="auto"><strong>Real-time streaming</strong> — feed audio incrementally, retrieve tokens as they arrive:</p>
<div dir="auto" data-snippet-clipboard-copy-content="vox_stream_t *s = vox_stream_init(ctx);

while (have_more_audio()) {
    float chunk[4096];
    int n_read = read_audio(chunk, 4096);
    vox_stream_feed(s, chunk, n_read);

    const char *tokens[16];
    int n;
    while ((n = vox_stream_get(s, tokens, 16)) > 0) {
        for (int i = 0; i < n; i++)
            printf(&quot;%s&quot;, tokens[i]);
        fflush(stdout);
    }
}

vox_stream_finish(s);
const char *tokens[16];
int n;
while ((n = vox_stream_get(s, tokens, 16)) > 0) {
    for (int i = 0; i < n; i++)
        printf(&quot;%s&quot;, tokens[i]);
}
printf(&quot;\n&quot;);

vox_stream_free(s);"><pre><span>vox_stream_t</span> <span>*</span><span>s</span> <span>=</span> <span>vox_stream_init</span>(<span>ctx</span>);

<span>while</span> (<span>have_more_audio</span>()) {
    <span>float</span> <span>chunk</span>[<span>4096</span>];
    <span>int</span> <span>n_read</span> <span>=</span> <span>read_audio</span>(<span>chunk</span>, <span>4096</span>);
    <span>vox_stream_feed</span>(<span>s</span>, <span>chunk</span>, <span>n_read</span>);

    <span>const</span> <span>char</span> <span>*</span><span>tokens</span>[<span>16</span>];
    <span>int</span> <span>n</span>;
    <span>while</span> ((<span>n</span> <span>=</span> <span>vox_stream_get</span>(<span>s</span>, <span>tokens</span>, <span>16</span>)) <span>&gt;</span> <span>0</span>) {
        <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>n</span>; <span>i</span><span>++</span>)
            <span>printf</span>(<span>"%s"</span>, <span>tokens</span>[<span>i</span>]);
        <span>fflush</span>(<span>stdout</span>);
    }
}

<span>vox_stream_finish</span>(<span>s</span>);
<span>const</span> <span>char</span> <span>*</span><span>tokens</span>[<span>16</span>];
<span>int</span> <span>n</span>;
<span>while</span> ((<span>n</span> <span>=</span> <span>vox_stream_get</span>(<span>s</span>, <span>tokens</span>, <span>16</span>)) <span>&gt;</span> <span>0</span>) {
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>n</span>; <span>i</span><span>++</span>)
        <span>printf</span>(<span>"%s"</span>, <span>tokens</span>[<span>i</span>]);
}
<span>printf</span>(<span>"\n"</span>);

<span>vox_stream_free</span>(<span>s</span>);</pre></div>
<p dir="auto"><code>feed()</code> runs the mel spectrogram, encoder, and decoder on available data, queuing output tokens. <code>finish()</code> adds padding and processes remaining audio. <code>get()</code> retrieves pending tokens — call it after each <code>feed()</code> or whenever convenient. Token string pointers returned by <code>vox_stream_get()</code> are valid until <code>vox_stream_free()</code>.</p>
<p dir="auto"><code>vox_stream_flush(s)</code> forces the encoder to process whatever audio is buffered, regardless of the processing interval, and feeds right-padding so the decoder emits tokens that are behind the delay window. Unlike <code>finish()</code>, the stream stays open — you can continue feeding audio afterwards. This is useful for silence detection: when the speaker pauses, flush to get the pending transcription without ending the stream.</p>
<p dir="auto">Use <code>vox_set_processing_interval(s, seconds)</code> to control the latency/efficiency tradeoff (equivalent to <code>-I</code> on the CLI). When set, <code>feed()</code> accumulates audio but only runs the encoder/decoder after at least the specified duration of new audio has been fed. Lower values give more responsive streaming (text appears sooner), higher values batch more audio per encoder call for better GPU utilization. Default is 2.0 seconds. See the <code>-I</code> flag documentation above for guidance on choosing values.</p>
<p dir="auto"><strong>Alternative tokens</strong> — when the model is uncertain, retrieve competing candidates:</p>
<div dir="auto" data-snippet-clipboard-copy-content="vox_stream_set_alt(s, 3, 0.5);  /* up to 3 alternatives, cutoff 0.5 */

const int n_alt = 3;
const char *tokens[16 * 3];
int n;
while ((n = vox_stream_get_alt(s, tokens, 16, n_alt)) > 0) {
    for (int i = 0; i < n; i++) {
        printf(&quot;%s&quot;, tokens[i * n_alt]);  /* best token */
        for (int a = 1; a < n_alt &amp;&amp; tokens[i * n_alt + a]; a++)
            printf(&quot; [alt: %s]&quot;, tokens[i * n_alt + a]);
    }
}"><pre><span>vox_stream_set_alt</span>(<span>s</span>, <span>3</span>, <span>0.5</span>);  <span>/* up to 3 alternatives, cutoff 0.5 */</span>

<span>const</span> <span>int</span> <span>n_alt</span> <span>=</span> <span>3</span>;
<span>const</span> <span>char</span> <span>*</span><span>tokens</span>[<span>16</span> <span>*</span> <span>3</span>];
<span>int</span> <span>n</span>;
<span>while</span> ((<span>n</span> <span>=</span> <span>vox_stream_get_alt</span>(<span>s</span>, <span>tokens</span>, <span>16</span>, <span>n_alt</span>)) <span>&gt;</span> <span>0</span>) {
    <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>n</span>; <span>i</span><span>++</span>) {
        <span>printf</span>(<span>"%s"</span>, <span>tokens</span>[<span>i</span> <span>*</span> <span>n_alt</span>]);  <span>/* best token */</span>
        <span>for</span> (<span>int</span> <span>a</span> <span>=</span> <span>1</span>; <span>a</span> <span>&lt;</span> <span>n_alt</span> <span>&amp;&amp;</span> <span>tokens</span>[<span>i</span> <span>*</span> <span>n_alt</span> <span>+</span> <span>a</span>]; <span>a</span><span>++</span>)
            <span>printf</span>(<span>" [alt: %s]"</span>, <span>tokens</span>[<span>i</span> <span>*</span> <span>n_alt</span> <span>+</span> <span>a</span>]);
    }
}</pre></div>
<p dir="auto"><code>vox_stream_get()</code> is unaffected — it always returns just the best token.</p>
<p dir="auto">There is also a one-shot convenience function if you don't need streaming:</p>
<div dir="auto" data-snippet-clipboard-copy-content="char *text = vox_transcribe(ctx, &quot;audio.wav&quot;);
printf(&quot;%s\n&quot;, text);
free(text);"><pre><span>char</span> <span>*</span><span>text</span> <span>=</span> <span>vox_transcribe</span>(<span>ctx</span>, <span>"audio.wav"</span>);
<span>printf</span>(<span>"%s\n"</span>, <span>text</span>);
<span>free</span>(<span>text</span>);</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">Choose a backend when building:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make            # Show available backends
make blas       # BLAS acceleration (Accelerate on macOS, OpenBLAS on Linux)
make mps        # Apple Silicon Metal GPU (fastest, macOS only)"><pre>make            <span><span>#</span> Show available backends</span>
make blas       <span><span>#</span> BLAS acceleration (Accelerate on macOS, OpenBLAS on Linux)</span>
make mps        <span><span>#</span> Apple Silicon Metal GPU (fastest, macOS only)</span></pre></div>
<p dir="auto"><strong>Recommended:</strong></p>
<ul dir="auto">
<li>macOS Apple Silicon: <code>make mps</code></li>
<li>macOS Intel: <code>make blas</code></li>
<li>Linux with OpenBLAS: <code>make blas</code></li>
</ul>
<p dir="auto">For <code>make blas</code> on Linux, install OpenBLAS first:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Ubuntu/Debian
sudo apt install libopenblas-dev

# Fedora
sudo dnf install openblas-devel"><pre><span><span>#</span> Ubuntu/Debian</span>
sudo apt install libopenblas-dev

<span><span>#</span> Fedora</span>
sudo dnf install openblas-devel</pre></div>
<p dir="auto">Other targets:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make clean      # Clean build artifacts
make info       # Show available backends for this platform
make inspect    # Build safetensors weight inspector"><pre>make clean      <span><span>#</span> Clean build artifacts</span>
make info       <span><span>#</span> Show available backends for this platform</span>
make inspect    <span><span>#</span> Build safetensors weight inspector</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Download</h2><a id="user-content-model-download" aria-label="Permalink: Model Download" href="#model-download"></a></p>
<p dir="auto">Download model weights (~8.9GB) from HuggingFace:</p>

<p dir="auto">This downloads to <code>./voxtral-model/</code> containing:</p>
<ul dir="auto">
<li><code>consolidated.safetensors</code> — all weights, BF16 (~8.9GB)</li>
<li><code>tekken.json</code> — Tekken tokenizer vocabulary (~15MB)</li>
<li><code>params.json</code> — model configuration</li>
</ul>
<p dir="auto">The model is <a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602" rel="nofollow">Apache-2.0 licensed</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How Fast Is It?</h2><a id="user-content-how-fast-is-it" aria-label="Permalink: How Fast Is It?" href="#how-fast-is-it"></a></p>
<p dir="auto">Benchmarks on <strong>Apple M3 Max</strong> (40-core GPU, 128GB RAM, 400 GB/s bandwidth):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Backend</th>
<th>Encoder (3.6s audio)</th>
<th>Prefill</th>
<th>Decoder</th>
</tr>
</thead>
<tbody>
<tr>
<td>MPS</td>
<td>284 ms</td>
<td>252 ms</td>
<td>23.5 ms/step (short)</td>
</tr>
<tr>
<td>BLAS</td>
<td>~8s</td>
<td>~1.2s</td>
<td>335 ms/step</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The MPS backend runs the entire decoder in a single Metal command buffer per token, with custom GPU kernels for attention, RoPE, and KV cache management. All weights are pre-converted to f16 on GPU at load time. The BLAS backend uses Accelerate's multi-threaded sgemm with on-the-fly BF16→F32 conversion.</p>
<p dir="auto">Decoder speed depends on sequence length: attention scans the full KV cache each step, so longer transcriptions are slower per token. For a 60-second clip (~760 steps), the average is ~31.6 ms/step. For short clips (~15 steps) it's ~23.5 ms/step. Either way, the decoder generates one token per ~80ms of audio, so even at 31.6 ms/step transcription runs ~2.5x faster than real-time.</p>
<p dir="auto">Longer audio scales linearly with the encoder (O(n) with sliding window attention) and the decoder (one token per 80ms of audio).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Architecture</h2><a id="user-content-model-architecture" aria-label="Permalink: Model Architecture" href="#model-architecture"></a></p>
<p dir="auto">Voxtral Realtime 4B is a streaming speech-to-text model with ~4B parameters:</p>
<p dir="auto"><strong>Pipeline:</strong></p>
<div data-snippet-clipboard-copy-content="WAV → 16kHz → Mel Spectrogram → Conv Stem → Encoder → Downsample 4x → Adapter → Decoder → Tokens"><pre><code>WAV → 16kHz → Mel Spectrogram → Conv Stem → Encoder → Downsample 4x → Adapter → Decoder → Tokens
</code></pre></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Architecture</th>
</tr>
</thead>
<tbody>
<tr>
<td>Audio Encoder</td>
<td>32-layer causal transformer, 1280 dim, 32 heads, sliding window 750</td>
</tr>
<tr>
<td>Adapter</td>
<td>Linear(5120→3072) → GELU → Linear(3072→3072)</td>
</tr>
<tr>
<td>LLM Decoder</td>
<td>26-layer transformer (Ministral-3 based), 3072 dim, GQA (32 heads / 8 KV)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Total parameters</td>
<td>~4B (0.6B encoder + 3.4B decoder)</td>
</tr>
<tr>
<td>Weight format</td>
<td>BF16</td>
</tr>
<tr>
<td>Vocab size</td>
<td>131,072 (Tekken tokenizer)</td>
</tr>
<tr>
<td>Audio frame rate</td>
<td>12.5 Hz (1 token = 80ms)</td>
</tr>
<tr>
<td>Max audio length</td>
<td>Unlimited (rolling KV cache)</td>
</tr>
<tr>
<td>Supported languages</td>
<td>EN, ES, FR, PT, HI, DE, NL, IT, AR, RU, ZH, JA, KO</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory Requirements</h2><a id="user-content-memory-requirements" aria-label="Permalink: Memory Requirements" href="#memory-requirements"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model weights (mmap'd)</td>
<td>8.9 GB on disk, mapped on-demand</td>
</tr>
<tr>
<td>MPS GPU weight cache</td>
<td>~8.4 GB (BF16→F16 cached on GPU)</td>
</tr>
<tr>
<td>KV cache (decoder)</td>
<td>~1.8 GB max (rolling, capped at sliding window)</td>
</tr>
<tr>
<td>Working buffers</td>
<td>~200 MB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zulip.com Values (234 pts)]]></title>
            <link>https://zulip.com/values/</link>
            <guid>46953815</guid>
            <pubDate>Tue, 10 Feb 2026 00:46:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zulip.com/values/">https://zulip.com/values/</a>, See on <a href="https://news.ycombinator.com/item?id=46953815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <h2 id="building-software-that-will-always-be-there-for-our-users">Building software that will always be there for our users</h2>
<p>When choosing software that will be core to how one’s organization operates,
such as a team chat platform, there is an important question: “Will this product
still exist and be responsibly maintained in a few years?”</p>
<p>We have designed our company, community, and technology with the explicit goal
of Zulip being actively developed for many years to come.</p>
<p>This theme cuts across many of the decisions described below. It is also
reflected in our <a href="https://zulip.com/history/">history</a>: Zulip's <a href="https://zulip.com/case-studies/recurse-center/">earliest
customers</a> have enjoyed uninterrupted service
since 2013.</p>
<h2 id="keeping-zulip-100-open-source">Keeping Zulip 100% open source</h2>
<p>Many modern “open-source” companies use a version of their product with some
basic functionality intentionally removed as a demo for their non-open-source
paid product. In contrast, we are committed to keeping Zulip <a href="https://github.com/zulip/zulip#readme">100% open
source</a>.</p>
<p>When you <a href="https://zulip.com/self-hosting/">self-host Zulip</a>, you get all the
<a href="https://zulip.com/features/">features</a> of our cloud offering. We work hard to <a href="https://zulip.readthedocs.io/en/latest/production/install.html">make it
easy</a> to set up
and run a self-hosted Zulip installation without paying us a dime, which is why
thousands of organizations do so.</p>
<h2 id="investing-in-community-and-mentorship">Investing in community and mentorship</h2>
<p>Zulip is developed by a <a href="https://zulip.com/team/">vibrant open-source community</a>, and we are
fully committed to helping bring up the next generation of open-source
contributors from a wide range of backgrounds.</p>
<p>We have invested into making Zulip’s code uniquely readable, well tested, and
easy to modify. Beyond that, we have written an extraordinary 185K words of
documentation on <a href="https://zulip.readthedocs.io/en/latest/overview/contributing.html">how to contribute to
Zulip</a>, with
topics ranging from <a href="https://zulip.readthedocs.io/en/latest/git/index.html">practical Git
tips</a> to <a href="https://zulip.readthedocs.io/en/latest/subsystems/events-system.html">essays on
important architectural
decisions</a>.</p>
<p>We also welcome and support contributors via <a href="https://zulip.readthedocs.io/en/latest/outreach/overview.html">formal internship
programs</a>, with
over 100 participants since 2016. Because of the thousands of hours our more
senior contributors (including alumni of these programs!) have dedicated to
mentorship, many of these participants have told us that they learned more
contributing to Zulip than in their 4-year formal computer science education.</p>
<h2 id="building-a-sustainable-business-aligned-with-our-values">Building a sustainable business aligned with our values</h2>
<p>Guiding the Zulip community in developing a world-class organized team chat
product with apps for every major desktop and mobile platform requires
leadership from a talented, dedicated team. We believe that the only sustainable
model is for our core team to be compensated fairly for their time. We have thus
<strong>founded a company (Kandra Labs) to steward and financially support Zulip’s
development</strong>.</p>
<p>We are <strong>growing our business sustainably</strong>, without venture capital funding.
VCs are incentivized to push companies to gamble for explosive growth. Often,
the result is that a company with a useful product burns rapidly through its
resources and goes out of business. We have built Zulip as a sustainable
business (also supported by <a href="https://seedfund.nsf.gov/">SBIR grants</a> from the US
National Science Foundation), and are being thoughtful about our pace of
spending.</p>
<p>Funding our company without venture capital also allows us to <strong>live by our
values</strong>, without investor pressure to compromise them when doing so might be
“good business” or “what everyone does”.</p>
<p>Finally, <strong>we’re building software that is easy to maintain,</strong> so it does
not require a large team to keep the lights on. We have consistently emphasized
high standards for codebase readability, code review, commit discipline,
debuggability, automated testing, tooling, documentation, and all the other
subtle details that together determine whether software is easy to understand,
operate, and modify.</p>
<h2 id="supporting-other-worthy-organizations">Supporting other worthy organizations</h2>
<p>An important part of Zulip’s mission is ensuring that worthy organizations, from
<a href="https://zulip.com/case-studies/rust/">programming-language developers</a> to <a href="https://zulip.com/case-studies/lean/">research
communities</a>, are able to use Zulip whether or not they
have funding.</p>
<p>We sponsor <a href="https://zulip.com/plans/">Zulip Cloud Standard</a> hosting for <a href="https://zulip.com/for/open-source/">open-source
projects</a>, <a href="https://zulip.com/for/research/">research groups</a>,
<a href="https://zulip.com/for/education/">education</a>, <a href="https://zulip.com/for/communities/">non-profits</a> and other
<a href="https://zulip.com/for/communities/">communities</a>. This program has grown exponentially since its
inception; today we are proud to fully sponsor Zulip hosting for hundreds of
organizations.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What functional programmers get wrong about systems (186 pts)]]></title>
            <link>https://www.iankduncan.com/engineering/2026-02-09-what-functional-programmers-get-wrong-about-systems/</link>
            <guid>46953491</guid>
            <pubDate>Tue, 10 Feb 2026 00:07:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iankduncan.com/engineering/2026-02-09-what-functional-programmers-get-wrong-about-systems/">https://www.iankduncan.com/engineering/2026-02-09-what-functional-programmers-get-wrong-about-systems/</a>, See on <a href="https://news.ycombinator.com/item?id=46953491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   <p>Static types, algebraic data types, making illegal states unrepresentable: the functional programming tradition has developed extraordinary tools for reasoning about <em>programs</em>. I have spent over a decade writing Haskell professionally, and I believe in all of it.</p>
<p>But the very effectiveness of these tools creates a particular susceptibility. We sometimes mistake reasoning about programs for reasoning about <em>systems</em>. These are not the same activity, and the instincts that make you good at one do not automatically transfer to the other.</p>
<p>This is not a uniquely FP problem. Every programming community treats “the program” as its primary object of study. But FP practitioners are in a distinctive position: our tools for local correctness are powerful enough to foster an unwarranted confidence about system-level properties. The type checker is honest about what it checks. The trouble starts when we forget where its jurisdiction ends. Every language community has its own version of this forgetting; the FP community just has the most sophisticated reason to believe it’s unnecessary.</p>
<p>A caveat before we go further: this essay is grounded in the world of web services, service-oriented architectures, and the distributed systems that inevitably emerge from them. If you’re building video games, CLI tools, or embedded firmware, the version boundaries look different and much of this won’t apply. But if you ship code that talks to other code across a network, and especially if you’ve ever had to deploy a change without taking the whole system down at once, this is for you.</p>
<p>The good news is that the research community has been quietly assembling the tools we need, if you know where to look.</p>
<h2 id="your-monolith-is-a-distributed-system">Your monolith is a distributed system</h2>
<p>Before we talk about types, I want to establish something that I find myself arguing repeatedly: <strong>every production system is a distributed system</strong>, including your monolith.</p>
<p>If you have a web application with more than one server, you have a distributed system. If you have background job workers, you have a distributed system. If you have a cron job, you have a distributed system. If you talk to Stripe, or send emails through SendGrid, or enqueue something in Redis, or write to a Postgres replica, then you are (I regret to inform you) operating a distributed system. The word “monolith” describes your deployment artifact. It does not describe your runtime topology.</p>
<p>This matters because the interesting correctness problems in production are almost always <em>systemic</em> rather than <em>local</em>. They live in the interactions between components running different versions of your code, or operating on different assumptions about the state of the database, or retrying an operation that already partially succeeded somewhere else. These are not problems that any single-program analysis can catch, regardless of how sophisticated your type system is.</p>
<p>Most programming language communities (FP included) tend to treat “the program” as the object of study. We write papers about programs. We verify programs. We optimize programs. But in production, correctness is not a property of a program. It is a property of a system. And once you see this clearly, some of the most cherished practices across our industry start to look like they’re aimed at the wrong altitude.</p>
<h2 id="the-unit-of-correctness-is-the-set-of-deployments">The unit of correctness is the set of deployments</h2>
<p>Here is the central claim: <strong>the unit of correctness in production is not the program. It is the set of deployments.</strong></p>
<p>When the Haskell compiler tells you your program is well-typed, it has verified properties of a single artifact. One binary, one version, one coherent snapshot of your types and your logic. This is genuinely valuable. But in production, that artifact is one member of an ensemble. At any given moment, your system might be running:</p>
<ul>
<li>The current deploy, serving new requests</li>
<li>The previous deploy, still draining connections</li>
<li>Background job workers that are one, two, or three deploys behind</li>
<li>A database whose schema has been migrated forward</li>
<li>Serialized data on a Kafka topic or in a job queue, written by a version of the code that no longer exists</li>
<li>Third-party webhook handlers that will deliver payloads conforming to <em>their</em> schema, not yours</li>
</ul>
<p>Correctness is a property of this entire set simultaneously. The type checker verified one element. It told you nothing about the interactions between elements. And the interactions are where the bugs live.</p>
<p>This is not an original observation. Google discovered it the hard way with their F1 database, which led to one of the most important papers in the schema evolution literature.<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> Their insight was that if servers can be at most two schema versions apart at any time, then dangerous schema changes can be decomposed into a sequence of intermediate states, each pairwise compatible with its neighbors. They found two subtle bugs in production systems using this framework: bugs that existed precisely because the system had been reasoning about schemas one version at a time.</p>
<h2 id="multiple-versions-are-always-running">Multiple versions are always running</h2>
<p>Programming language culture treats a program as a single thing. You write it, you compile it, you deploy it. The old version ceases to exist and the new version takes its place. The type system operates on this model. The module system operates on it. Your mental model of “the code” operates on it.</p>
<p>In production, this is a polite fiction.</p>
<p>In any non-trivial deployment, multiple versions of your code are running simultaneously. A rolling deploy means that for some window (seconds, minutes, sometimes hours) both old and new versions are live, serving the same users, blissfully unaware of each other. A blue-green deploy means both exist and traffic could be routed to either. Canary deploys mean both are serving real users, right now, at the same time.</p>
<p>Consider a sum type:</p>
<pre tabindex="0" data-language="haskell"><code><span><span>data</span><span> PaymentStatus</span></span>
<span><span>  =</span><span> Pending</span></span>
<span><span>  |</span><span> Completed</span></span>
<span><span>  |</span><span> Failed</span></span></code></pre>
<p>You ship a new version that adds a constructor:</p>
<pre tabindex="0" data-language="haskell"><code><span><span>data</span><span> PaymentStatus</span></span>
<span><span>  =</span><span> Pending</span></span>
<span><span>  |</span><span> Completed</span></span>
<span><span>  |</span><span> Failed</span></span>
<span><span>  |</span><span> Refunded</span></span></code></pre>
<p>For the next however-many minutes, old workers will receive messages or database rows containing <code>Refunded</code> and they won’t know what to do. If you’re serializing to JSON, the old code sees an unrecognized string and throws a parse error. The type checker didn’t warn you about this, because the type checker only sees one version at a time. This is true regardless of language; the Haskell example just makes the irony sharpest, because the exhaustive pattern match that felt like an ironclad guarantee turns out to be a guarantee about a world that no longer exists.</p>
<p>This is why Protocol Buffers uses numeric field tags rather than field names on the wire, and why Avro requires both the writer’s and reader’s schema to be present at deserialization time.<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> These aren’t quirks. They are engineering responses to the fundamental reality that producers and consumers will be at different versions. The serialization format is doing the work that the type system cannot: reasoning about compatibility across time.</p>
<astro-island uid="Z2fBAC6" prefix="r3" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="RollingDeployDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;RollingDeployDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<p>Erlang/OTP is the one mainstream platform that took this problem seriously at the language level, and it is worth pausing to appreciate what they did. The BEAM VM supports running <strong>exactly two versions of a module simultaneously</strong> during hot upgrades. When you load a new version, processes running the old code continue until they make an external call, at which point they transition. The <code>code_change/3</code> callback in OTP’s <code>gen_server</code> is an explicit hook for migrating process state between versions: you receive the old state, the old version identifier, and you return the new state. The state migration is a first-class part of the programming model, not an afterthought discovered during an incident.</p>
<p>The two-version limit is the critical design choice. It means the mixed-version state space is bounded: you only ever need to reason about compatibility between adjacent versions, not arbitrary pairs. If you try to load a third version while processes are still running the first, BEAM kills those processes. This is strict, but it makes the problem tractable. Google’s F1 independently arrived at the same constraint for schema migrations. Most modern deployment systems have rediscovered it without naming it; a rolling deploy that completes before the next one starts gives you a two-version window almost by accident, which is perhaps the nicest kind of safety property: the one you get without having to think about it.<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
<h2 id="the-migration-ratchet">The migration ratchet</h2>
<p>If multiple versions running concurrently is the normal case, the relationship between code and data is what makes it genuinely treacherous.</p>
<p>You can roll code back relatively easily: redeploy the old artifact. You cannot easily roll back <code>ALTER TABLE ADD COLUMN</code>, and you absolutely cannot roll back <code>DROP COLUMN</code>. The data layer moves forward on a ratchet. The code layer appears to move in both directions, but a rollback creates a combination (old code, new schema) that never existed as a commit in your repository. Nobody compiled it. Nobody tested it. No type checker ever saw it.</p>
<p>I am an always-roll-forward partisan, and this asymmetry is why. A rollback gives you the <em>feeling</em> of a safety net, but the state it produces is one you have never verified and are unlikely to have even considered. Better to move forward through the problem with a fix than to retreat into an untested configuration. The expand-and-contract pattern (add the new column as nullable, deploy code that writes to both, backfill, deploy code that reads from the new column, drop the old one) requires a minimum of four deploys to accomplish what <em>feels</em> like one change. It is not just a recipe. It is a discipline of only ever occupying states that have been deliberately constructed and tested.</p>
<astro-island uid="XfWRx" prefix="r4" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="MigrationRatchetDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;MigrationRatchetDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<p>The research community has a name for the general problem, from an unexpected direction. The Dynamic Software Updating (DSU) literature studies the safety of transitioning between program versions at runtime. Gupta, Jalote, and Barua proved in 1996 that <strong>the general problem of update validity is undecidable</strong>: you cannot build a tool that will tell you, for all possible programs and updates, whether a transition is safe.<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> This is a sobering result. It does not mean we give up. It means progress has to be domain-specific and heuristic, which is exactly what practical tools like Atlas’s migration linter and <code>gh-ost</code> do.</p>
<p>The expand-and-contract pattern itself turns out to be an operational implementation of what the database theory community calls <strong>bidirectional schema transformation</strong>.<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup> The theory was published in 2017. Most of us had been doing it by hand for years before that, arriving at the same structure through trial and error and 3am incident retrospectives. The academy and the industry converged on the same answer from opposite directions, neither aware of the other.</p>
<h2 id="message-queues-are-version-time-capsules">Message queues are version time capsules</h2>
<p>Databases at least let you migrate data in place. Message queues are more patient.</p>
<p>Not all queues are patient in the same way. RabbitMQ and Sidekiq typically process messages within seconds or minutes (sometimes faster than you can alt-tab to the monitoring dashboard); the version window is narrow, roughly the duration of a rolling deploy. If your consumer is one deploy behind for ten minutes, that’s the extent of your compatibility obligation. These systems are forgiving precisely because messages don’t linger. The version problem exists, but it’s bounded by the same two-version window as the deploy itself.</p>
<p>Kafka is a different animal. A Kafka topic with a 30-day retention policy contains messages from 30 days of deploys. If you deploy daily, that’s 30 versions of your serialization format, coexisting on the same topic. A consumer spinning up today needs to be able to deserialize all of them. If you’re using Kafka as an event store with infinite retention (and some teams do) you might have messages from <em>years</em> ago, written by code that no longer exists in any branch of your repository, by engineers who no longer work at the company. The messages persist. They are very patient.</p>
<p>This is where the F1/Erlang “two versions apart” assumption breaks down entirely. You aren’t dealing with a bounded version window. You’re dealing with an unbounded archaeological record of every serialization format your system has ever used.</p>
<p>The practical responses are well-known: use a serialization format with strong backward compatibility guarantees (Protobuf’s wire format is explicitly designed to be stable across major versions), enforce compatibility at write time via a schema registry, and have explicit retention policies that bound how far back you need to be compatible. But many teams treat topic retention as a storage cost decision rather than a compatibility decision, and that’s a mistake. <strong>Your retention policy is a version compatibility policy.</strong> Thirty days of retention means “every deploy must be compatible with the serialization format from 30 days ago.” Infinite retention means “every deploy must be compatible with every serialization format, ever.” These are very different engineering constraints, and they should be chosen deliberately.</p>
<p>The same problem appears anywhere you write data that might be read back by a different version of the code: S3 buckets, cached values in Redis, scheduled job payloads. Anywhere you serialize, you leave a fossil record that future versions will need to interpret. The question is just how long the fossils stick around.</p>
<astro-island uid="1fgPqU" prefix="r0" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="MessageQueueDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;MessageQueueDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<h2 id="event-sourcing-the-version-problem-as-a-way-of-life">Event sourcing: the version problem as a way of life</h2>
<p>If message queues are version time capsules, event sourcing systems have taken the version problem and elevated it to a first principle.</p>
<p>The promise of event sourcing appeals to the same instincts that draw people to functional programming: your application state is not a mutable thing in a database. It is the result of a left fold over an ordered sequence of immutable events. The events are facts. They happened. You can derive any view of your data by replaying them through a projection function. State is a pure function of history.</p>
<p>This is a beautiful idea, and it has a terrifying corollary: <strong>every event you have ever written must be interpretable by your current code, forever.</strong></p>
<p>In a traditional system, you can migrate your data in place. <code>ALTER TABLE</code>, backfill, move on. The old representation is gone. In an event-sourced system, the old representation <em>is the point</em>. The event log is append-only by definition. You cannot rewrite a <code>PaymentInitiated</code> event from 2019 to match your 2026 schema, because that would be lying about what happened. The immutability of the log is the entire value proposition. It means that every version of every event schema your system has ever used is a permanent part of your codebase’s obligations, whether or not anyone <em>remembers</em> writing it.</p>
<p>The standard response is <strong>upcasting</strong>: transforming old events into the current schema at read time. When your projection encounters a v1 <code>PaymentInitiated</code> event, it runs it through an upcaster that produces something your current code can process. This is Cambria’s edit lenses, arrived at independently by practitioners. It works, and it is also a quiet accumulation of obligations that only grows. Each new event schema version requires a new upcaster. The upcasters compose (v1→v2→v3) but the chain only lengthens. Five years in, your projection pipeline may spend more time upcasting old events than processing new ones. The past grows heavier. The present must carry it.</p>
<p>CQRS compounds this. The whole point of Command Query Responsibility Segregation is that the write model and the read model are different representations, updated at different times, potentially by different versions of the code. These two sides are <em>always</em> at different versions during a deploy, and they are <em>designed</em> to be. This is a feature, right up until the event schema changes and the read side needs to rebuild its projections from the entire history of the write side, including event formats that predate the current team.</p>
<p>Projection rebuilds are the moment of truth. “Just replay the events” is the event sourcing equivalent of “just run the tests”: true in principle, contingent on everything else being in order. If the projection function can’t handle every event schema that ever existed (including the ones from before the team adopted a schema registry, before the naming conventions were standardized, before someone decided that <code>amount</code> meant dollars instead of cents, before the engineer who made that decision left for a FAANG and took the context with them) the rebuild fails, and you discover that your theoretically-rebuildable read model is not, in fact, rebuildable.</p>
<p>There is a deeper issue. When your aggregate’s behavior changes (new business rules, different state transitions, altered validation logic) every aggregate that was built by replaying events under the <em>old</em> rules is now suspect. The events are facts about what happened, but the meaning you ascribed to those events was a function of the code that processed them. A <code>PaymentAuthorized</code> event that was valid under old business rules may represent a state transition that the new rules would have rejected. The events haven’t changed. What they <em>mean</em> has. This is semantic drift at its most consequential, and I’ll return to it shortly.</p>
<p>None of this means event sourcing is wrong. For audit-heavy domains, financial systems, and applications where “what happened” is as important as “what is,” it remains one of the best architectural patterns available. But it is worth understanding what you are signing up for: a permanent, irrevocable contract with every schema version your system will ever produce, extending forward without bound. The version compatibility problem isn’t something that happens to event-sourced systems. It <em>is</em> the system.</p>
<div data-astro-cid-muiazdm6="">  <p data-astro-cid-muiazdm6=""> <svg viewBox="0 0 680 340" xmlns="http://www.w3.org/2000/svg" data-astro-cid-muiazdm6=""> <!-- Event log (left side) --> <text x="20" y="20" data-astro-cid-muiazdm6="">EVENT LOG (append-only)</text> <!-- v1 events --> <rect x="20" y="32" width="200" height="28" rx="4" data-astro-cid-muiazdm6=""></rect> <circle cx="36" cy="46" r="6" data-astro-cid-muiazdm6=""></circle> <text x="48" y="42" data-astro-cid-muiazdm6="">v1</text> <text x="48" y="54" data-astro-cid-muiazdm6="">PaymentInitiated { amount: 500 }</text> <rect x="20" y="64" width="200" height="28" rx="4" data-astro-cid-muiazdm6=""></rect> <circle cx="36" cy="78" r="6" data-astro-cid-muiazdm6=""></circle> <text x="48" y="74" data-astro-cid-muiazdm6="">v1</text> <text x="48" y="86" data-astro-cid-muiazdm6="">PaymentCaptured { amount: 500 }</text> <!-- v2 events --> <rect x="20" y="100" width="200" height="28" rx="4" data-astro-cid-muiazdm6=""></rect> <circle cx="36" cy="114" r="6" data-astro-cid-muiazdm6=""></circle> <text x="48" y="110" data-astro-cid-muiazdm6="">v2</text> <text x="48" y="122" data-astro-cid-muiazdm6="">PaymentInitiated { ..., currency }</text> <rect x="20" y="132" width="200" height="28" rx="4" data-astro-cid-muiazdm6=""></rect> <circle cx="36" cy="146" r="6" data-astro-cid-muiazdm6=""></circle> <text x="48" y="142" data-astro-cid-muiazdm6="">v2</text> <text x="48" y="154" data-astro-cid-muiazdm6="">RefundRequested { ..., currency }</text> <!-- v3 events --> <rect x="20" y="168" width="200" height="28" rx="4" data-astro-cid-muiazdm6=""></rect> <circle cx="36" cy="182" r="6" data-astro-cid-muiazdm6=""></circle> <text x="48" y="178" data-astro-cid-muiazdm6="">v3</text> <text x="48" y="190" data-astro-cid-muiazdm6="">PaymentInitiated { amount: {...} }</text> <!-- v4 events --> <rect x="20" y="204" width="200" height="28" rx="4" data-astro-cid-muiazdm6=""></rect> <circle cx="36" cy="218" r="6" data-astro-cid-muiazdm6=""></circle> <text x="48" y="214" data-astro-cid-muiazdm6="">v4</text> <text x="48" y="226" data-astro-cid-muiazdm6="">PaymentInitiated { ..., precision }</text> <!-- Time arrow --> <line x1="10" y1="32" x2="10" y2="232" data-astro-cid-muiazdm6=""></line> <polygon points="10,236 7,228 13,228" data-astro-cid-muiazdm6=""></polygon> <text x="10" y="250" text-anchor="middle" data-astro-cid-muiazdm6="">time</text> <!-- Arrow from log to pipeline --> <line x1="230" y1="130" x2="270" y2="130" data-astro-cid-muiazdm6=""></line> <polygon points="274,130 266,126 266,134" data-astro-cid-muiazdm6=""></polygon> <!-- Upcaster pipeline (right side) --> <text x="280" y="20" data-astro-cid-muiazdm6="">UPCASTER PIPELINE</text> <!-- v1 → v2 upcaster --> <rect x="280" y="36" width="100" height="36" rx="4" data-astro-cid-muiazdm6=""></rect> <text x="330" y="52" text-anchor="middle" data-astro-cid-muiazdm6="">v1 → v2</text> <text x="330" y="64" text-anchor="middle" data-astro-cid-muiazdm6="">add currency default</text> <!-- connector --> <line x1="330" y1="72" x2="330" y2="84" data-astro-cid-muiazdm6=""></line> <polygon points="330,88 327,82 333,82" data-astro-cid-muiazdm6=""></polygon> <!-- v2 → v3 upcaster --> <rect x="280" y="88" width="100" height="36" rx="4" data-astro-cid-muiazdm6=""></rect> <text x="330" y="104" text-anchor="middle" data-astro-cid-muiazdm6="">v2 → v3</text> <text x="330" y="116" text-anchor="middle" data-astro-cid-muiazdm6="">nest amount object</text> <!-- connector --> <line x1="330" y1="124" x2="330" y2="136" data-astro-cid-muiazdm6=""></line> <polygon points="330,140 327,134 333,134" data-astro-cid-muiazdm6=""></polygon> <!-- v3 → v4 upcaster --> <rect x="280" y="140" width="100" height="36" rx="4" data-astro-cid-muiazdm6=""></rect> <text x="330" y="156" text-anchor="middle" data-astro-cid-muiazdm6="">v3 → v4</text> <text x="330" y="168" text-anchor="middle" data-astro-cid-muiazdm6="">add precision field</text> <!-- connector to "current" --> <line x1="330" y1="176" x2="330" y2="188" data-astro-cid-muiazdm6=""></line> <polygon points="330,192 327,186 333,186" data-astro-cid-muiazdm6=""></polygon> <!-- Current version output --> <rect x="280" y="192" width="100" height="30" rx="4" data-astro-cid-muiazdm6=""></rect> <text x="330" y="211" text-anchor="middle" data-astro-cid-muiazdm6="">v4 (current)</text> <!-- Future growth indicator --> <rect x="280" y="234" width="100" height="36" rx="4" data-astro-cid-muiazdm6=""></rect> <text x="330" y="250" text-anchor="middle" data-astro-cid-muiazdm6="">v4 → v5</text> <text x="330" y="262" text-anchor="middle" data-astro-cid-muiazdm6="">???</text> <line x1="330" y1="192" x2="330" y2="234" data-astro-cid-muiazdm6=""></line> <!-- Annotation: grows monotonically --> <text x="400" y="56" data-astro-cid-muiazdm6="">each new schema</text> <text x="400" y="70" data-astro-cid-muiazdm6="">adds to the chain</text> <!-- Annotation: five years in --> <text x="400" y="252" data-astro-cid-muiazdm6="">five years in, the pipeline</text> <text x="400" y="266" data-astro-cid-muiazdm6="">may spend more time upcasting</text> <text x="400" y="280" data-astro-cid-muiazdm6="">than processing new events</text> <!-- Bottom summary --> <rect x="20" y="296" rx="4" ry="4" width="640" height="30" data-astro-cid-muiazdm6=""></rect> <text x="340" y="316" text-anchor="middle" data-astro-cid-muiazdm6="">4 schema versions → 3 upcasters. The events are permanent. The chain only grows.</text> </svg> </p> </div> 
<h2 id="temporal-and-bitemporal-databases-time-as-a-first-class-citizen">Temporal and bitemporal databases: time as a first-class citizen</h2>
<p>(To be clear: I’m talking about <em>temporal databases</em>, not the Temporal workflow orchestrator or the Temporal JavaScript API. Different things entirely, confusingly named.)</p>
<p>If event sourcing is the application-level response to “we need to know what happened,” temporal databases are the data-level response. Bitemporal databases are the response that takes the problem seriously enough to track <em>why the answer keeps changing</em>.</p>
<p>A traditional database gives you the current state, full stop. When you <code>UPDATE</code> a row, the previous value is gone. SQL:2011 standardized two flavors of temporal table: <em>system-versioned</em> tables (which automatically record when each row version was stored, letting you query any historical point) and <em>application-time period</em> tables (which track when a fact was true in the real world). These are genuinely different questions. System time tells you “what did the database contain at time T?” Application time tells you “what was true in the world during period P?”</p>
<p>A <strong>bitemporal database</strong> tracks both axes simultaneously: <strong>valid time</strong> (when a fact was true in the real world) and <strong>transaction time</strong> (when the system recorded it). The distinction matters most when corrections arrive late. Suppose you learn on February 5th that an employee’s address actually changed on January 15th, but the old address was recorded until today. A bitemporal table lets you ask both: “what did we <em>believe</em> the address was on January 20th?” (the old one; we hadn’t learned about the change yet) and “what <em>was</em> the address on January 20th?” (the new one; the change had already happened). In financial reporting, insurance, healthcare, and regulatory compliance, the difference between “what was true” and “what we knew” has legal consequences.</p>
<p>This is directly relevant to the version problem, because <code>db.asOf(lastTuesday)</code> is essentially asking “give me the database as last Tuesday’s code saw it.” It is version-aware querying at the data layer.</p>
<p><strong>Datomic</strong> is the purest expression of this idea, and not coincidentally, it comes from the functional programming tradition. Rich Hickey designed it around the same insight that motivates persistent data structures: the past is immutable, so treat it as a value. Facts are datoms (entity, attribute, value, transaction, added?) and the database is an accumulation of datoms over time. Nothing is updated; new facts are asserted, old facts are retracted by asserting their negation. Attributes are added but never removed. You cannot drop a column. You cannot rename an attribute. (If you want the old attribute to stop being used, you simply stop writing to it and exercise great discipline in your attribute naming, forever.) This eliminates an entire class of version problems by refusing to permit destructive schema changes: the always-roll-forward philosophy applied to the data model itself.</p>
<p><strong>XTDB</strong> (formerly Crux) takes bitemporality further, making both valid time and transaction time first-class on every document. You can insert a record with a valid-time range in the past (correcting historical data without pretending you always knew it) and the transaction time records when you made the correction.</p>
<p>What temporal and bitemporal databases get right is that they make the version-of-truth problem explicit in the data model. But here is the recurring theme: <strong>bitemporal databases give you time-travel for data, not for code.</strong> You can reconstruct the database as it appeared to last Tuesday’s deploy. You cannot automatically run last Tuesday’s code against it. The query function interpreting the historical data is whatever version is running <em>now</em>. Datomic will show you exactly what the <code>amount</code> attribute contained at every point in time. It will not tell you whether <code>amount</code> meant cents or dollars at the time it was written.</p>
<astro-island uid="11mSvE" prefix="r1" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="BitemporalDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;BitemporalDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<p>Having an immutable, queryable history of your data is strictly better than not having one. But it solves the data half of the problem. The code half (the fact that the function interpreting the data is itself a versioned artifact with its own quiet evolution) remains unsolved by the database alone.</p>
<h2 id="semantic-drift-the-type-didnt-change-but-the-meaning-did">Semantic drift: the type didn’t change, but the meaning did</h2>
<p>I touched on this in the context of event sourcing, but it deserves its own treatment, because it is the version of the version problem that no tool catches.</p>
<p>Everything I’ve described so far (structural schema evolution, sum type changes, serialization compatibility) is at least <em>detectable</em>. A field was added or removed. A constructor appeared. A type changed. Schema comparison tools can see these things.</p>
<p>The more insidious problem is when the type stays the same but the meaning changes.</p>
<p>Consider a field called <code>amount</code> on a transaction record, typed as <code>Int</code>. In version 1, it represents cents. In version 2, someone decides it should represent dollars. The schema hasn’t changed. The type hasn’t changed. No diff tool, no schema registry, no linter will flag this. But every consumer that crosses the version boundary will silently produce wrong answers, wrong by a factor of 100, which is the kind of wrong that makes accountants <em>very</em> unhappy and auditors positively incandescent.</p>
<p>This is not a contrived example. Semantic drift happens constantly in more subtle forms: a boolean field whose meaning shifts from “user opted in” to “user did not opt out” (same values, different default assumptions). A status enum where <code>Completed</code> starts meaning “payment captured” but gradually comes to mean “payment authorized” as the business process evolves. A timestamp that was always UTC until one service started writing local time. (There is always one service.) The schema is identical across versions. The data is quietly, catastrophically incompatible.</p>
<astro-island uid="Z1F6drg" prefix="r2" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="SemanticDriftDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;SemanticDriftDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<p>No type system catches this, and I don’t think any type system <em>can</em> catch this in full generality; it would require encoding the intended semantics of every field, not just its representation. Liquid Haskell can express refinement types like <code>{v : Amount | v &gt; 0}</code>, which would catch the sign of the value but not the unit. Dependent types in Idris or Agda could, in principle, track units through computation, but only if someone writes the proof obligations, and only within a single version.</p>
<p>What <em>does</em> help is treating semantic changes as seriously as structural changes. Document the semantics of your data contracts. Use newtypes that encode units (<code>Cents</code> vs <code>Dollars</code>, not <code>Int</code>). When you change the <em>interpretation</em> of a field, treat it as a migration even if the schema doesn’t change, because at the version boundary, it <em>is</em> a migration. The discipline is social and documentary as much as it is technical. This may be uncomfortable for communities that prize formal verification, but no amount of type-level machinery will save you if two versions of your code disagree about what a field <em>means</em>.</p>
<h2 id="the-diminishing-returns-of-type-level-invariants">The diminishing returns of type-level invariants</h2>
<p>There is a curve to encoding invariants in the type system, and I think many communities are systematically miscalibrated about where the returns start diminishing. Every language with a sufficiently expressive type system develops its own version of this: Java’s generics rabbit hole, TypeScript’s conditional types labyrinth, Rust’s lifetime annotation thickets. The FP variant is distinctive because the type system is genuinely capable enough to go very far down the curve before the costs become obvious.</p>
<p>On the left side of the curve, the returns are enormous. Newtypes that prevent you from mixing up a <code>CustomerId</code> with an <code>OrderId</code>. Sum types that model your domain states explicitly. Making illegal states unrepresentable for your core business logic. This is high-value work. I will defend it to anyone, in any language.</p>
<p>But there’s a point where the returns drop while costs keep climbing. Phantom types tracking authorization state. Type-level natural numbers for sized vectors. GADTs enforcing protocol ordering. Effect systems with fine-grained capability tracking. Each is a real technique solving a real problem. Each also increases compile times, produces worse error messages (GHC’s novel-length type errors are a rite of passage, not a selling point), shrinks the pool of engineers who can confidently modify the code, and makes it harder to follow under production pressure.</p>
<p>The cost I want to focus on is the one that rarely gets discussed: <strong>the invariants you most want to enforce are inter-version properties, and the type checker operates on one version at a time.</strong> “This system handles deploy boundaries gracefully.” “This serialization format is forward-compatible.” “This migration is safe to run while the old code is still serving traffic.” These are properties of the relationship between two snapshots of the code. The type checker sees one snapshot. Production is running several.</p>
<p>This is worth stating even for the most powerful type systems we have. Liquid Haskell can prove that <em>within your code</em>, a PaymentStatus is always valid after parsing. It cannot prove that a PaymentStatus serialized by last Tuesday’s deploy will parse successfully in today’s code, because last Tuesday’s code is not in scope. Dependent types can prove your serializer and deserializer are inverses; a round-trip property of a <em>single</em> version’s codec. The production question is whether <em>this</em> version’s deserializer is a left inverse of <em>last</em> version’s serializer, and that requires having both versions in scope simultaneously.</p>
<p>The practical response is surprisingly low-tech: keep both versions in scope yourself. Copy the old schema definition into your codebase alongside the new one. Write an explicit parser from the old format to the new. Test it. This is unglamorous, but it has the virtue of being checkable against what is actually running in production right now, rather than against an abstract notion of compatibility. The type checker can verify that your v1-to-v2 migration function is total and well-typed; it just needs you to supply both types. Most teams that do this well arrive at it through painful experience rather than methodology, and end up with a <code>legacy/</code> or <code>compat/</code> module that quietly grows over time.</p>
<div data-astro-cid-mrd56pta="">  <p data-astro-cid-mrd56pta=""> <svg viewBox="0 0 680 300" xmlns="http://www.w3.org/2000/svg" data-astro-cid-mrd56pta=""> <!-- PROCESS A (left) --> <rect x="20" y="20" width="250" height="240" rx="6" data-astro-cid-mrd56pta=""></rect> <text x="145" y="40" text-anchor="middle" data-astro-cid-mrd56pta="">Process A (v2)</text> <!-- Type definition in A --> <rect x="35" y="52" width="220" height="68" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="45" y="68" data-astro-cid-mrd56pta="">data</text><text x="72" y="68" data-astro-cid-mrd56pta=""> PaymentStatus</text> <text x="55" y="82" data-astro-cid-mrd56pta="">= Pending</text> <text x="55" y="94" data-astro-cid-mrd56pta="">| Completed</text> <text x="55" y="106" data-astro-cid-mrd56pta="">| Failed</text> <text x="55" y="118" data-astro-cid-mrd56pta="">| Refunded</text> <!-- Phantom type in A --> <rect x="35" y="128" width="220" height="44" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="45" y="144" data-astro-cid-mrd56pta="">newtype</text><text x="88" y="144" data-astro-cid-mrd56pta=""> Amount (u :: Unit)</text> <text x="55" y="158" data-astro-cid-mrd56pta="">= Amount Int</text> <!-- Refinement in A --> <rect x="35" y="180" width="220" height="36" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="45" y="196" data-astro-cid-mrd56pta="">{-@ type ValidAmt = {v:Int | v &gt; 0} @-}</text> <text x="45" y="210" data-astro-cid-mrd56pta="">Liquid Haskell refinement</text> <!-- Compiler checkmark --> <rect x="35" y="224" width="220" height="24" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="145" y="240" text-anchor="middle" data-astro-cid-mrd56pta="">GHC: all invariants hold ✓</text> <!-- THE WIRE (center) --> <rect x="282" y="80" width="116" height="140" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="340" y="100" text-anchor="middle" data-astro-cid-mrd56pta="">THE WIRE</text> <text x="340" y="116" text-anchor="middle" data-astro-cid-mrd56pta="">(JSON / Protobuf / Avro)</text> <text x="340" y="140" text-anchor="middle" data-astro-cid-mrd56pta="">{"status": "Refunded",</text> <text x="340" y="154" text-anchor="middle" data-astro-cid-mrd56pta=""> "amount": 4999}</text> <text x="340" y="178" text-anchor="middle" data-astro-cid-mrd56pta="">no phantom type</text> <text x="340" y="190" text-anchor="middle" data-astro-cid-mrd56pta="">no refinement</text> <text x="340" y="202" text-anchor="middle" data-astro-cid-mrd56pta="">no unit tag</text> <text x="340" y="214" text-anchor="middle" data-astro-cid-mrd56pta="">just bytes</text> <!-- Arrows: A → wire → B --> <line x1="270" y1="150" x2="282" y2="150" data-astro-cid-mrd56pta=""></line> <polygon points="282,150 276,147 276,153" data-astro-cid-mrd56pta=""></polygon> <text x="276" y="140" text-anchor="middle" data-astro-cid-mrd56pta="">serialize</text> <line x1="398" y1="150" x2="410" y2="150" data-astro-cid-mrd56pta=""></line> <polygon points="410,150 404,147 404,153" data-astro-cid-mrd56pta=""></polygon> <text x="404" y="140" text-anchor="middle" data-astro-cid-mrd56pta="">deserialize</text> <!-- PROCESS B (right) --> <rect x="410" y="20" width="250" height="240" rx="6" data-astro-cid-mrd56pta=""></rect> <text x="535" y="40" text-anchor="middle" data-astro-cid-mrd56pta="">Process B (v1)</text> <!-- Type definition in B --> <rect x="425" y="52" width="220" height="56" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="435" y="68" data-astro-cid-mrd56pta="">data</text><text x="462" y="68" data-astro-cid-mrd56pta=""> PaymentStatus</text> <text x="445" y="82" data-astro-cid-mrd56pta="">= Pending</text> <text x="445" y="94" data-astro-cid-mrd56pta="">| Completed</text> <text x="445" y="106" data-astro-cid-mrd56pta="">| Failed</text> <!-- Parse error --> <rect x="425" y="120" width="220" height="36" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="435" y="138" data-astro-cid-mrd56pta="">ParseError: unknown</text> <text x="435" y="152" data-astro-cid-mrd56pta="">constructor "Refunded"</text> <!-- B's phantom type — same newtype, different assumption --> <rect x="425" y="164" width="220" height="44" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="435" y="180" data-astro-cid-mrd56pta="">newtype</text><text x="478" y="180" data-astro-cid-mrd56pta=""> Amount</text> <text x="445" y="194" data-astro-cid-mrd56pta="">= Amount Int</text> <text x="575" y="194" data-astro-cid-mrd56pta="">-- cents?</text> <!-- Compiler checkmark for B too --> <rect x="425" y="224" width="220" height="24" rx="4" data-astro-cid-mrd56pta=""></rect> <text x="535" y="240" text-anchor="middle" data-astro-cid-mrd56pta="">GHC: all invariants hold ✓</text> <!-- Bottom summary --> <rect x="20" y="272" rx="4" ry="4" width="640" height="24" data-astro-cid-mrd56pta=""></rect> <text x="340" y="288" text-anchor="middle" data-astro-cid-mrd56pta="">Both processes are well-typed. The type checker verified one at a time. The bug lives between them.</text> </svg> </p> </div> 
<p>This is also where Ink &amp; Switch’s <a href="https://www.inkandswitch.com/cambria/">Cambria</a> project offers an interesting alternative model.<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup> Instead of trying to make types enforce version compatibility at compile time, Cambria uses <strong>edit lenses</strong> (composable, reversible schema transformations) to convert data between versions at runtime. You define how version A maps to version B, and Cambria can compose A→B and B→C into A→C. Compatibility is a property of the <em>transformation between versions</em>, not of any single version’s types. This is a fundamentally different way of thinking, and it’s one that FP’s own theoretical tradition (the lens and optics literature<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup>) helped create.</p>
<h2 id="parse-dont-validate-across-versions">Parse, don’t validate: across versions</h2>
<p>Alexis King’s “Parse, Don’t Validate” is one of the most influential ideas in recent FP discourse, and rightfully so. Instead of checking properties of data at runtime and hoping the check was performed before use, parse unstructured input into a structured type that <em>proves</em> the invariant holds. Push checks to the boundary, once, and let the types carry the guarantee forward.</p>
<p>This is correct. It is also incomplete, because it considers only one boundary: the edge of your program, within a single version.</p>
<p>In production, data crosses a harder boundary constantly: the boundary between <em>versions</em>. A message serialized by deploy N is deserialized by deploy N+1. A database row written by code with three constructors is read by code with four. A GraphQL response shaped by today’s schema is consumed by a mobile client running last month’s code. At these boundaries, you are parsing data structured according to someone else’s types; types that may no longer exist in your codebase.</p>
<p>The discipline of “parse, don’t validate” should extend to this boundary. In some domains, it already does.</p>
<p>A <strong>schema registry</strong> is “parse, don’t validate” applied to the version boundary. In Confluent’s model, every message on a Kafka topic is tagged with a schema ID. The producer registers its schema before writing. The consumer fetches both its own schema and the writer’s schema, and the deserializer uses both to parse the data: resolving missing fields with defaults, skipping unknown fields, failing loudly on incompatible changes. You don’t deserialize and then check if the data looks right. You <em>parse</em> through a pair of schemas, and the parse itself guarantees compatibility. The check happens once, at schema registration time, not scattered across every consumer.</p>
<p>GraphQL takes this even further. The schema <em>is</em> the API contract, and it’s introspectable by design. Tools like Apollo GraphOS run <strong>operations checks</strong> against your schema: before you deploy a change, they compare it against real client queries collected from production traffic and tell you exactly which clients would break.<sup><a href="#user-content-fn-parse1" id="user-content-fnref-parse1" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup> GraphQL Hive, an open-source schema registry, performs composition checks for federated schemas and can do <strong>conditional breaking change detection</strong>, only flagging a field removal as breaking if that field actually appears in collected operations. GraphQL Inspector diffs two schema versions and classifies every change as breaking, dangerous, or safe.</p>
<p>This is the version-boundary equivalent of “parse, don’t validate.” Instead of deploying and hoping your schema change is backward-compatible, you prove it before deploy. The schema diff is the parse. The compatibility check is the type check. The registry is the type system.</p>
<p>It is worth noting the limits of this approach honestly. Checking against 10,000 recent operations tells you about the clients that are active <em>now</em>. It tells you nothing about the mobile app version from eighteen months ago that a user hasn’t updated, which will wake up next Tuesday and send a request shaped like nothing in your recent traffic. It tells you nothing about the Kafka message serialized six months ago that is sitting patiently in a topic with annual retention, waiting to be consumed by your shiny new code. These tools are heuristics, good ones, but heuristics. They cover the common case well and the long tail not at all. For the long tail, you still need explicit version-aware parsing and the discipline of never removing a field you aren’t certain nothing still references.</p>
<p>The same pattern applies to Protobuf via Buf, which enforces 53 rules across four strictness levels; to Avro via the Schema Registry’s seven compatibility modes; and increasingly to database schemas via tools like Atlas, which lints your SQL migrations for destructive changes before they run. Each of these tools is doing the same thing: moving the compatibility check from runtime (where it manifests as an incident) to build time (where it manifests as a failed CI check). This is the same migration from “validate” to “parse” that King describes, applied one level up.</p>
<astro-island uid="Z1F1BYp" prefix="r5" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="SchemaRegistryDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;SchemaRegistryDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<h2 id="knowing-whats-running-changes-everything">Knowing what’s running changes everything</h2>
<p>The schema registry pattern reveals something important: <strong>if you can identify what versions are currently running, and you can assert compatibility between adjacent versions, you can practically achieve multi-version correctness</strong> without waiting for the unified theory.</p>
<p>Think about what you’d need:</p>
<p>First, every boundary artifact (every serialized message, every API response, every database migration) needs to be tagged with version metadata. Schema registries do this for serialization formats. Database migration tools do this for schemas (your migration history <em>is</em> a version log). API gateways can tag HTTP traffic. Most systems already have this information; they just don’t connect it.</p>
<p>Second, you need a compatibility function: given version A and version B of some boundary artifact, are they compatible? This is what Confluent’s Schema Registry computes for Avro/Protobuf, what GraphQL Inspector computes for GraphQL schemas, what Buf computes for Protobuf definitions, and what Atlas computes for SQL migrations. Each tool covers one boundary type.</p>
<p>Third (and this is the piece most teams are missing) you need to know what’s actually running. Which code versions are deployed across your web servers, your background workers, your cron jobs? Which schema version is your database at? Which message schemas are in-flight on your Kafka topics?</p>
<p>This is where service meshes become interesting for reasons beyond the usual marketing. Istio and Linkerd sit between your services and observe every request. They know which version of a service is running on which pod. They can split traffic by version for canary deploys, route requests based on headers, and enforce that traffic only flows between declared-compatible versions. Combined with progressive delivery tools like Argo Rollouts or Flagger (which automatically roll back a canary if error rates spike) you get a feedback loop where version incompatibility is detected and mitigated at the network layer.</p>
<p>The limitation is that service meshes only see HTTP/gRPC boundaries between services. They don’t see the database, the message queue, the cron job. They’re one piece of the version inventory, not the whole picture. But they demonstrate that version-aware infrastructure is practical, and they represent the closest thing we have to a runtime system that treats “what versions are running” as a first-class concept.</p>
<p>If you have all three (version tags, compatibility functions, and runtime version inventory) you can answer the question that actually matters before every deploy: <strong>“Is the version I’m about to deploy compatible with every version currently running?”</strong> Not “does it compile?” Not “do the tests pass?” But: “given the actual set of deployments that exist right now, is it safe to add this one?”</p>
<p>Nobody has built the unified tool that answers this across all boundary types simultaneously. (If you are reading this and thinking “that sounds like a startup,” please, by all means.) But the components exist. A deploy pipeline that queries your orchestrator for running image tags, checks your migration history against the schema registry, diffs your GraphQL schema against collected client operations, and runs Buf’s compatibility checks: this is buildable today, with off-the-shelf parts. It is engineering work, not research.</p>
<astro-island uid="Z1WKbQW" prefix="r6" component-url="/_astro/ArchitectureDemos.T62zZIkS.js" component-export="DeployEnsembleDemo" renderer-url="/_astro/client.JDWrnR5R.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;DeployEnsembleDemo&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>
<p>The reason I find this exciting from a compositional perspective is that the compatibility of a deploy is the conjunction of compatibility across each boundary. Each boundary has its own compatibility function. The whole thing is a product of independent checks. This is <em>exactly</em> the kind of structure that FP-trained minds are good at identifying and exploiting. We just need to look up from the type checker and see it.</p>
<h2 id="what-if-the-old-code-just-kept-working">What if the old code just kept working?</h2>
<p>Everything so far has treated multi-version coexistence as a problem to be managed. A few projects have asked a more radical question: what if it weren’t a problem at all?</p>
<p><strong>Unison</strong> takes the most principled approach. Code is stored not by name but by a hash of its abstract syntax tree. When you change a function, you produce a new hash, and the old hash still exists, still refers to the old definition, and still works. Dependents of the old version continue using it until you explicitly propagate the update. There is no deploy in the traditional sense. The old function and the new function <em>coexist by construction</em>, because they are literally different values in a content-addressed store.</p>
<p>This eliminates a remarkable number of the problems I’ve been describing. Rolling deploys can’t create mixed-version incoherence, because there’s nothing to roll; each caller is pinned to the exact hash it was built against. The version compatibility question becomes “has this caller been updated to reference the new hash?” which is a graph reachability problem, not a temporal coordination problem.</p>
<p><strong>Dark</strong> pursued a related idea from the infrastructure side: the editor and the runtime were unified, and old HTTP requests in flight continued executing against the code version that existed when they arrived. <strong>Dhall</strong> addresses a narrower but important slice (configuration) where totality and content-addressing provide genuine equality checking across config versions. The pattern across all three is the same: <strong>make code (or configuration) immutable and content-addressed, so that “deploying a new version” doesn’t destroy or alter the old one.</strong> Version coexistence stops being a race condition and becomes a data structure.</p>
<p>There’s a seductive quality to this, because it feels like the <em>right</em> answer in some Platonic sense. But it is not a silver bullet.</p>
<p>The most fundamental limitation is the one that haunts this entire essay: <strong>semantic drift doesn’t care about your hashes.</strong> A content-addressed function that computes <code>amount * exchangeRate</code> will return the same AST hash forever. If the business meaning of <code>amount</code> changes from cents to dollars, the function is structurally identical and semantically wrong. Content-addressing guarantees referential integrity of <em>code</em>. It says nothing about the referential integrity of <em>meaning</em>, and meaning is where the quiet catastrophes live.</p>
<p>More practically: your code may be immutable, but your database is not. A Unison function pinned to a specific hash still reads from and writes to the same Postgres, the same Kafka topic, the same Redis cluster as every other version. Old code pinned to an old hash will execute faithfully against a database whose schema has migrated out from under it. Content-addressing solves the version problem for pure computation but does nothing for side effects; and production systems are, inconveniently, mostly side effects.</p>
<p>There is also a coherence problem that content-addressing can obscure rather than solve. If service A is pinned to hash-X of a shared library and service B is pinned to hash-Y, and those hashes embed different assumptions about the wire format of messages between them, you have the same version incompatibility as before, just harder to see, because each service is internally consistent. The incoherence lives in the space <em>between</em> the hashes, in the implicit contract about what the data means.</p>
<div data-astro-cid-t2wlo5eo="">  <p data-astro-cid-t2wlo5eo=""> <svg viewBox="0 0 660 360" xmlns="http://www.w3.org/2000/svg" data-astro-cid-t2wlo5eo=""> <!-- CONTENT STORE (left) --> <text x="20" y="18" data-astro-cid-t2wlo5eo="">CONTENT STORE</text> <!-- calculateTotal v1 (old, still exists) --> <rect x="20" y="30" width="180" height="44" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="30" y="48" data-astro-cid-t2wlo5eo="">calculateTotal</text> <text x="30" y="62" data-astro-cid-t2wlo5eo="">#a3f7 <tspan data-astro-cid-t2wlo5eo="">old — still exists</tspan></text> <!-- calculateTotal v2 (new) --> <rect x="20" y="82" width="180" height="44" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="30" y="100" data-astro-cid-t2wlo5eo="">calculateTotal</text> <text x="30" y="114" data-astro-cid-t2wlo5eo="">#b2e1 <tspan data-astro-cid-t2wlo5eo="">new</tspan></text> <!-- processPayment (still references old hash) --> <rect x="20" y="148" width="180" height="44" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="30" y="166" data-astro-cid-t2wlo5eo="">processPayment</text> <text x="30" y="180" data-astro-cid-t2wlo5eo="">#c8d4 · uses calculateTotal <tspan data-astro-cid-t2wlo5eo="">#a3f7</tspan></text> <!-- generateReceipt (still references old hash) --> <rect x="20" y="200" width="180" height="44" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="30" y="218" data-astro-cid-t2wlo5eo="">generateReceipt</text> <text x="30" y="232" data-astro-cid-t2wlo5eo="">#d1a9 · uses processPayment <tspan data-astro-cid-t2wlo5eo="">#c8d4</tspan></text> <!-- Arrows showing references --> <!-- processPayment → old calculateTotal --> <line x1="200" y1="170" x2="215" y2="170" data-astro-cid-t2wlo5eo=""></line> <line x1="215" y1="170" x2="215" y2="52" data-astro-cid-t2wlo5eo=""></line> <line x1="215" y1="52" x2="200" y2="52" data-astro-cid-t2wlo5eo=""></line> <polygon points="200,52 206,49 206,55" data-astro-cid-t2wlo5eo=""></polygon> <!-- Label: pinned to old --> <text x="220" y="116" data-astro-cid-t2wlo5eo="">pinned to old hash.</text> <text x="220" y="128" data-astro-cid-t2wlo5eo="">still works.</text> <!-- SIDE EFFECTS (right) --> <text x="370" y="18" data-astro-cid-t2wlo5eo="">SIDE EFFECTS (shared, mutable)</text> <!-- Database --> <rect x="370" y="30" width="160" height="52" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="380" y="50" data-astro-cid-t2wlo5eo="">⛁</text> <text x="400" y="50" data-astro-cid-t2wlo5eo="">PostgreSQL</text> <text x="400" y="64" data-astro-cid-t2wlo5eo="">schema: migration #187</text> <text x="400" y="76" data-astro-cid-t2wlo5eo="">NOT pinned to any hash</text> <!-- Kafka --> <rect x="370" y="90" width="160" height="52" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="380" y="110" data-astro-cid-t2wlo5eo="">⇶</text> <text x="400" y="110" data-astro-cid-t2wlo5eo="">Kafka</text> <text x="400" y="124" data-astro-cid-t2wlo5eo="">messages from 30 days of deploys</text> <text x="400" y="136" data-astro-cid-t2wlo5eo="">NOT pinned to any hash</text> <!-- Redis --> <rect x="370" y="150" width="160" height="44" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="380" y="170" data-astro-cid-t2wlo5eo="">⟡</text> <text x="400" y="170" data-astro-cid-t2wlo5eo="">Redis cache</text> <text x="400" y="182" data-astro-cid-t2wlo5eo="">written by who-knows-which version</text> <!-- Arrows: both old and new calculateTotal talk to same DB --> <path d="M 200 52 C 280 52, 320 56, 370 56" data-astro-cid-t2wlo5eo=""></path> <path d="M 200 104 C 280 104, 320 56, 370 56" data-astro-cid-t2wlo5eo=""></path> <!-- The key tension --> <rect x="370" y="210" width="270" height="62" rx="4" data-astro-cid-t2wlo5eo=""></rect> <text x="380" y="228" data-astro-cid-t2wlo5eo="">The fundamental limitation</text> <text x="380" y="244" data-astro-cid-t2wlo5eo="">Code is immutable and content-addressed.</text> <text x="380" y="258" data-astro-cid-t2wlo5eo="">The world it operates on is not.</text> <text x="380" y="268" data-astro-cid-t2wlo5eo="">Old code pinned to #a3f7 executes faithfully against</text> <text x="380" y="278" data-astro-cid-t2wlo5eo="">a database whose schema has migrated out from under it.</text> <!-- Bottom: coherence problem --> <rect x="20" y="296" rx="4" ry="4" width="620" height="50" data-astro-cid-t2wlo5eo=""></rect> <text x="330" y="314" text-anchor="middle" data-astro-cid-t2wlo5eo="">Each service is internally consistent — pinned to exact hashes. The incoherence lives</text> <text x="330" y="330" text-anchor="middle" data-astro-cid-t2wlo5eo="">in the space between the hashes: the shared database, the message queue, the cache.</text> </svg> </p> </div> 
<p>None of these projects has achieved mainstream adoption. The reasons are partly technical and partly gravitational: the existing ecosystem of tools, libraries, deployment infrastructure, and hiring pipelines (good luck findiny any job listings requiring Unison experience just yet) assumes that code lives in files, compiles into artifacts, and deploys by replacing old artifacts with new ones. But the ideas keep resurfacing. Nix and Guix use content-addressing for packages. Docker image layers are content-addressed. Git is a content-addressed store. The insight that “immutable, addressable values are easier to reason about than mutable names” is one that functional programmers should find deeply familiar. It is, after all, the argument for pure functions. We just haven’t applied it consistently to the deployment artifact itself, and when we try, we discover that the hard part was never the code. It was everything the code touches.</p>

<p>Here’s the thing I find both frustrating and hopeful: the intellectual toolkit for the problems I’ve been describing already exists, scattered across communities that don’t talk to each other enough, or else siloed within megacorporations that don’t share their knowledge / tooling for one reason or another.</p>
<p>The question “what is the space of valid (code version, schema version, data format version) tuples, and can we always reach a safe state from any point in this space?” is a compositional question. It’s a question about algebraic structure, about invariants, about lawful transformations. Let me sketch the most promising connections.</p>
<p><strong>Gradual typing as a model for version compatibility.</strong> The correspondence runs surprisingly deep. <a href="https://ecee.colorado.edu/~siek/pubs/pubs/2006/siek06:_gradual.pdf">Siek and Taha’s consistency relation</a> (2006), reflexive and symmetric but not transitive, models compatibility between types of differing precision exactly like compatibility between version types. Max New and Amal Ahmed showed that casts between types of different precision form <strong>embedding-projection pairs</strong>: going from a more-precise type to a less-precise type and back is the identity.<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup> This is the mathematical structure underlying version migration: you can widen data to a more general schema and narrow it back without loss.</p>
<p><strong>Session types as API versioning.</strong> <a href="https://doi.org/10.1145/1328438.1328472">Session types</a> model the legal sequences of messages between communicating parties, and their subtyping rules map almost perfectly to API evolution: a server that accepts <em>more</em> request types is backward compatible; a server that promises <em>fewer</em> response variants is safe. <a href="https://doi.org/10.1007/978-3-031-57262-3_5">Recent work</a> shows that checking this compatibility for multiparty protocols is decidable in polynomial time. No practical API versioning tool uses this theory yet (Buf’s 53 breaking change rules are ad hoc where they could be principled) but the foundations are ready.</p>
<p><strong>Multi-language semantics as multi-version semantics.</strong> Amal Ahmed’s group has been working on programs composed from components in different languages with different type systems. Patterson and Ahmed’s <a href="https://doi.org/10.4230/LIPIcs.SNAPL.2017.12"><strong>linking types</strong></a> (SNAPL 2017) allow annotating where code can link with components having different capabilities. If you squint, different versions of your code <em>are</em> different languages with different type systems, and the deploy boundary is the foreign function interface.<sup><a href="#user-content-fn-11" id="user-content-fnref-11" data-footnote-ref="" aria-describedby="footnote-label">10</a></sup></p>
<p><strong>Spivak’s categorical data migration.</strong> David Spivak formalized schema evolution using category theory: a database schema is a small category, an instance is a set-valued functor, and a schema morphism induces three adjoint data migration functors (Σ, Δ, Π) that are composable by construction.<sup><a href="#user-content-fn-12" id="user-content-fnref-12" data-footnote-ref="" aria-describedby="footnote-label">11</a></sup> Schema migrations form a category where composition is guaranteed to be well-defined; exactly the property you want when reasoning about sequences of migrations across deploys.</p>
<h2 id="what-this-means-in-practice">What this means in practice</h2>
<p>None of this research will help you at 3am when your deploy is failing and PagerDuty is doing its level best to ruin your night. I know that. But it points to a shift in how we should think about building systems, regardless of language.</p>
<p><strong>Design for the ensemble, not the snapshot.</strong> When modeling a domain type, ask not just “is this type correct?” but “can this type evolve?” Will adding a constructor break deserialization for old consumers? Will removing a field crash the previous deploy? Apply “parse, don’t validate” at every version boundary, not just at the edge of a single program.</p>
<p><strong>Make your boundaries explicit and machine-checkable.</strong> Register your schemas. Diff your GraphQL types in CI. Lint your SQL migrations. Every boundary artifact (API schema, message format, database schema, workflow definition) should be versioned and checked for compatibility as part of your deploy pipeline.<sup><a href="#user-content-fn-13" id="user-content-fnref-13" data-footnote-ref="" aria-describedby="footnote-label">12</a></sup></p>
<p><strong>Invest in the “impure shell.”</strong> The part of your system that handles retries, timeouts, connection management, circuit breaking, graceful shutdown, and error recovery is where your system meets reality. In a well-structured FP application, this logic lives in the outer “impure” layer that often gets less design attention than the pure core. But it is the code that determines whether your system handles version transitions gracefully or falls over. It deserves the same rigor we bring to domain modeling.</p>
<p><strong>Build toward a deploy-time compatibility check.</strong> The individual tools exist: Atlas for migration safety, Buf for Protobuf compatibility, Apollo GraphOS or GraphQL Hive for schema checks, Temporal for workflow versioning<sup><a href="#user-content-fn-14" id="user-content-fnref-14" data-footnote-ref="" aria-describedby="footnote-label">13</a></sup>, <code>cargo-semver-checks</code> for library APIs<sup><a href="#user-content-fn-15" id="user-content-fnref-15" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup>. What’s missing is the orchestration; a single step in your pipeline that queries what’s running, checks compatibility across every boundary, and gives you a yes or no. This is achievable today with off-the-shelf parts.</p>
<p><strong>Treat your monolith like what it is.</strong> If you have multiple servers, background workers, cron jobs, or third-party integrations (and you do) you are operating a distributed system. The sooner your team internalizes this, the sooner you start making architectural decisions that account for the reality of your runtime environment rather than the pleasant fiction of a single coherent program.</p>
<hr>
<h2 id="closing">Closing</h2>
<p>The FP community has spent decades building tools for reasoning about programs with extraordinary precision. That work is deeply valuable, fascinating, and makes me a happier coder every day. Every language community would benefit from taking local correctness as seriously as we do. What I’m suggesting is not that we abandon it or minimize its value, but that we lift our gaze to the level where many of the hardest problems actually live, and that we notice, with some honesty, how many of those problems look the same regardless of what language you wrote the program in.</p>
<p>What’s missing is the synthesis. Nobody has built a unified tool that takes your type definitions, your serialization format, your migration history, and your deployment topology and tells you whether a given deploy sequence is safe. In fairness, I don’t think you really can, given the breadth of the problem.</p>
<p>But we don’t have to wait for the theory or some shiny startup to fix it for us. “Parse, don’t validate” gave us the right intuition; we just need to apply it at every version boundary. The tools to check schema compatibility, diff API contracts, and lint database migrations exist today. The missing piece is connecting them to your deployment system so you can answer the question that actually matters: “given everything that’s running right now, is it safe to deploy this?”</p>
<p>The program is not the unit of correctness. The set of deployments is. The type checker’s jurisdiction ends at the boundary of a single artifact, and production is an ensemble of artifacts, each one a different vintage, each one faithful to the types it was compiled against, each one potentially at odds with its neighbors. The tools to reason about that ensemble are closer than you think. They just aren’t the tools you’ve been reaching for.</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>Rae et al., <a href="https://doi.org/10.14778/2536222.2536230">“Online, Asynchronous Schema Change in F1”</a> (VLDB 2013). The paper defines four-state transitions for index creation (absent → delete-only → write-only → public) where each adjacent pair is safe to coexist. This remains the definitive formal model for multi-version schema correctness in distributed systems. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>Confluent’s Schema Registry formalizes this into seven compatibility modes: BACKWARD, FORWARD, FULL, and their TRANSITIVE variants. BACKWARD means “you can upgrade consumers first,” FORWARD means “you can upgrade producers first,” FULL means “upgrade in any order.” These map directly to the deployment ordering problem. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>Kubernetes is converging on the same insight from the infrastructure side. KEP-4330 introduces “emulated version” for two-step upgrades with minor-version rollback, while KEP-4020 adds a mixed-version proxy for safe API routing during upgrades. But neither gives you Erlang’s <code>code_change/3</code>, an explicit, programmer-written function for the state transition between versions. That remains the most honest interface to the problem any platform has offered. <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>Gupta, Jalote, and Barua, <a href="https://doi.org/10.1109/32.485222">“A Formal Framework for On-line Software Version Change”</a> (IEEE TSE, 1996). Stoyle, Hicks, et al. later developed <a href="https://www.cs.umd.edu/~mwh/papers/mutatis-journal.pdf">a type system for DSU</a> (TOPLAS 2007) that ensures if an update is accepted, the resulting program is type-correct across the version boundary. Hayden et al. (<a href="https://doi.org/10.1007/978-3-642-27705-4_22">VSTTE 2012</a>) achieved the first automatic verification of DSU correctness using a “merged program” combining old and new versions. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 4">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>The <a href="https://doi.org/10.1007/s00778-018-0508-7">InVerDa system</a> (Herrmann et al.) formalized this as BiDEL, a Bidirectional Database Evolution Language that extends the PRISM framework’s Schema Modification Operators to be bidirectional and relationally complete. It enables multiple co-existing schema versions within one database where all versions access the same data set; the strongest formal guarantee for multi-version schema coexistence in the literature. <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 5">↩</a></p>
</li>
<li id="user-content-fn-6">
<p>Litt, van Hardenberg, and Henry, <a href="https://doi.org/10.1145/3447865.3457963">“Cambria: Schema Evolution in Distributed Systems with Edit Lenses”</a> (PaPoC 2021). The system integrates with Automerge CRDTs, storing raw writes in the writer’s schema and translating at read time. <a href="#user-content-fnref-6" data-footnote-backref="" aria-label="Back to reference 6">↩</a></p>
</li>
<li id="user-content-fn-7">
<p>Foster, Greenwald, Moore, Pierce, and Schmitt’s <a href="https://doi.org/10.1145/1232420.1232424">seminal work on lenses</a> (POPL 2005, TOPLAS 2007) established the algebraic foundation. Hofmann, Pierce, and Wagner extended it to <a href="https://doi.org/10.1145/1926385.1926428">symmetric lenses</a> (POPL 2011) where neither direction is privileged, directly modeling bidirectional version migration. <a href="#user-content-fnref-7" data-footnote-backref="" aria-label="Back to reference 7">↩</a></p>
</li>
<li id="user-content-fn-parse1">
<p>Apollo’s operations checks run against up to 10,000 distinct historical operations. GraphQL Hive and GraphQL Inspector provide similar capabilities in the open-source ecosystem, with Hive offering a full schema registry with version history and composition validation for federated graphs. <a href="#user-content-fnref-parse1" data-footnote-backref="" aria-label="Back to reference 8">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>New and Ahmed, <a href="https://doi.org/10.1145/3236768">“Graduality from Embedding-Projection Pairs”</a> (ICFP 2018). Wadler and Findler’s <a href="https://doi.org/10.1007/978-3-642-00590-9_1">blame tracking</a> (ESOP 2009) extends this with the Blame Theorem: when casting between types of different precision, failures are attributed to the less-precisely-typed portion. Directly applicable to identifying which side of a version boundary caused an incompatibility. <a href="#user-content-fnref-8" data-footnote-backref="" aria-label="Back to reference 9">↩</a></p>
</li>
<li id="user-content-fn-11">
<p>Patterson and Ahmed’s <a href="https://doi.org/10.1145/3519939.3523703">semantic soundness framework</a> (PLDI 2022) uses a convertibility relation τ_A ∼ τ_B between types from different languages, with glue code implementing conversions; directly applicable to cross-version type compatibility. <a href="#user-content-fnref-11" data-footnote-backref="" aria-label="Back to reference 10">↩</a></p>
</li>
<li id="user-content-fn-12">
<p>Spivak, <a href="https://doi.org/10.1016/j.ic.2012.05.001">“Functorial Data Migration”</a> (2012). The categorical framing guarantees that migration composition is associative and has identities, which is more than can be said for most migration frameworks I’ve encountered in the wild. <a href="#user-content-fnref-12" data-footnote-backref="" aria-label="Back to reference 11">↩</a></p>
</li>
<li id="user-content-fn-13">
<p>Atlas performs automated destructive change detection with 40+ lint rules, including data-dependent analysis that simulates changes against a temporary dev-database. <a href="#user-content-fnref-13" data-footnote-backref="" aria-label="Back to reference 12">↩</a></p>
</li>
<li id="user-content-fn-14">
<p>Temporal deserves special mention here because it has taken the multi-version problem more seriously than most orchestration systems. The earliest mechanism, <code>patched()</code>, inserts markers into workflow event history that act as version-aware branch points: new code can take a different path while old executions continue on the original one. This works but scales poorly; every incompatible change requires a new patch call, and the branching logic accumulates. The more interesting approach is <strong>Worker Versioning</strong>, which assigns a Build ID to each worker deployment and lets the Temporal server route workflow tasks to the right worker version. New workflows go to the latest build. Existing workflows continue on the build that started them. This is essentially blue-green deployment at the workflow level: old and new worker pools coexist, each handling the workflows that belong to them, and the server manages the routing. You can drain old workers gradually as their workflows complete, or run them indefinitely if some workflows are long-lived. The version boundary is explicit and managed by the platform rather than by per-function patching in your code. But perhaps the most interesting thing Temporal does is <em>fail loudly when versions disagree</em>. If you deploy new workflow code that would produce a different sequence of commands than the original execution recorded in its event history, Temporal raises a <strong>nondeterminism error</strong> and refuses to continue. On one hand, your workflow is stuck and someone’s pager is going off. On the other hand, the system <em>detected at runtime</em> that two versions of your code are incompatible, which is more than most systems manage. They simply produce wrong answers in silence. Temporal’s nondeterminism errors are, in a sense, a runtime version-compatibility assertion: the event history <em>is</em> the specification of what the workflow was supposed to do, and the new code is being checked against it. It’s not a pleasant experience when it fires, but it is an honest one. <a href="#user-content-fnref-14" data-footnote-backref="" aria-label="Back to reference 13">↩</a></p>
</li>
<li id="user-content-fn-15">
<p>Predrag Gruevski’s analysis with <code>cargo-semver-checks</code> found that 1 in 6 of the top 1000 Rust crates had violated semver at least once. Elm’s package manager was the first to automate version classification by comparing exposed type signatures between releases. <a href="#user-content-fnref-15" data-footnote-backref="" aria-label="Back to reference 14">↩</a></p>
</li>
</ol>
</section>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is particle physics dead, dying, or just hard? (184 pts)]]></title>
            <link>https://www.quantamagazine.org/is-particle-physics-dead-dying-or-just-hard-20260126/</link>
            <guid>46953136</guid>
            <pubDate>Mon, 09 Feb 2026 23:31:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/is-particle-physics-dead-dying-or-just-hard-20260126/">https://www.quantamagazine.org/is-particle-physics-dead-dying-or-just-hard-20260126/</a>, See on <a href="https://news.ycombinator.com/item?id=46953136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postContent">
            
            <div id="postBody">
                <div>
        <p>
            Columnist Natalie Wolchover checks in with particle physicists more than a decade after the field entered a profound crisis.         </p>
        
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1440" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-scaled.webp" alt="A collage depicting the Large Hadron Collider, a Shiva Nataraj sculpture, particle collisions, and the Standard Model of particle physics." decoding="async" fetchpriority="high" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-1720x968.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-520x293.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-768x432.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-1536x864.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-2048x1152.webp 2048w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Qualia_ParticlePhysics-crKristinaArmitage-Lede-1-98x55.webp 98w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>The Large Hadron Collider hasn’t found any new physics. Now what?</p>
            <p>Kristina Armitage/<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p><img decoding="async" src="https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1-1720x223.webp" alt="Qualia: Essays that go where curiosity leads" width="1720" height="223" srcset="https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1-1720x223.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1-520x68.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1-768x100.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1-1536x200.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1-98x13.webp 98w, https://www.quantamagazine.org/wp-content/uploads/2050/01/QUALIA-Banner-WITH-SPACER-1.webp 2048w" sizes="(max-width: 1720px) 100vw, 1720px"></p>
<p><span>I</span>n July 2012, physicists at the Large Hadron Collider (LHC) in Europe triumphantly announced the discovery of the Higgs boson, the long-sought linchpin of the subatomic world. Interacting with Higgs bosons imbues other elementary particles with mass, making them slow down enough to assemble into atoms, which then clump together to make everything else.</p>
<p>A couple of months later, I took a job as the first staff reporter at the nascent science magazine that would become <em>Quanta</em>. Turns out I was starting on the physics beat just as the drama was picking up.</p>
        
        
<p>The drama wasn’t about the Higgs particle; by the time it materialized at the LHC there was already little doubt about its existence. The Higgs was the last piece of <a href="https://www.quantamagazine.org/a-new-map-of-the-standard-model-of-particle-physics-20201022/">the Standard Model of particle physics</a>, the 1970s-era set of equations governing the 25 known elementary particles and their interactions.</p>
<p>More striking was what did not emerge from the data.</p>
<p>Physicists had spent billions of euros building the 27-kilometer supercollider not only to confirm the Standard Model but also to supersede it by uncovering components of a more complete theory of nature. The Standard Model doesn’t include particles that could comprise dark matter, for instance. It doesn’t explain why matter dominates over antimatter in the universe, or why the Big Bang happened in the first place. Then there’s the inexplicably enormous disparity between the Higgs boson’s mass (which sets the physical scale of atoms) and the far higher mass-energy scale associated with quantum gravity, known as the Planck scale. The chasm between physical scales — atoms are vastly larger than the Planck scale — seems unstable and unnatural. In 1981, the great theorist <a href="https://www.quantamagazine.org/edward-witten-ponders-the-nature-of-reality-20171128/">Edward Witten</a> thought of <a href="https://www.sciencedirect.com/science/article/abs/pii/0370269381908856">a solution</a> for this “hierarchy problem”: Balance would be restored by the existence of additional elementary particles only slightly heavier than the Higgs boson. The LHC’s collisions should have been energetic enough to conjure them.</p>
<p>But when protons raced both ways around the tunnel and crashed head-on, spraying debris into surrounding detectors, only the 25 particles of the Standard Model were observed. Nothing else showed up.</p>
    
    
    
    
<p>The absence of any “new physics” — particles or forces beyond the known ones — fomented a crisis. “Of course, it is disappointing,” the particle physicist <a href="https://www.quantamagazine.org/physicists-debate-future-of-supersymmetry-20121120/">Mikhail Shifman told me</a> that fall of 2012. “We’re not gods. We’re not prophets. In the absence of some guidance from experimental data, how do you guess something about nature?”</p>
<p>Once the standard reasoning about the hierarchy problem had been shown to be wrong, there was no telling where new physics might be found. It could easily lie beyond the reach of experiments. The particle physicist Adam Falkowski predicted to me at the time that, without a way to search for heavier particles, the field would undergo a slow decay: “The number of jobs in particle physics will steadily decrease, and particle physicists will die out naturally.”</p>
<p>The crisis and its fallout made for <a href="https://www.quantamagazine.org/complications-in-physics-lend-support-to-multiverse-hypothesis-20130524/">years</a> of <a href="https://www.quantamagazine.org/what-no-new-particles-means-for-physics-20160809/">interesting</a> <a href="https://www.quantamagazine.org/crisis-in-particle-physics-forces-a-rethink-of-what-is-natural-20220301/">reporting</a>, but sure enough, the frequency of news stories related to particle physics diminished. I fell out of touch with sources. More than 13 years on, in this first column for Qualia, a new series of essays in <em>Quanta Magazine</em>, I’m taking stock. Is particle physics dying, as Falkowski predicted? Can new physics still be found? What’s the future for particle physicists? Will artificial intelligence help? How much hope is left in the search for answers to the many remaining mysteries of the universe?</p>
<p><img decoding="async" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2.png" alt="" width="1300" height="43" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2.png 1300w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-520x17.png 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-768x25.png 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-98x3.png 98w" sizes="(max-width: 1300px) 100vw, 1300px"></p>
<p>Some particle physicists act as if there’s no crisis at all. The LHC is still running and will for at least another decade, and its operators are finding new sources of enthusiasm.</p>
<p>In the last couple of years, data handling at the collider has improved with the use of AI. Pattern recognizers can sort through the outgoing debris of proton collisions and classify collision events more accurately than human-made algorithms can. This helps the physicists to more accurately measure the “scattering amplitude,” essentially the probability that different particle interactions will occur. For instance, AI systems can determine more precisely how many top quarks arise in the aftermath of collisions versus the number of bottom quarks. Any statistical deviations from the predictions of the Standard Model could signify the involvement of unknown elementary particles.</p>
</div>
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1705" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-scaled.webp" alt="A computer depiction of a particle collision showing yellow and green particle scattering." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-1720x1146.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-520x346.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-768x512.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-1536x1023.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-2048x1364.webp 2048w, https://www.quantamagazine.org/wp-content/uploads/2026/01/CMS_Higgs-event-98x65.webp 98w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>A proton-proton collision documented by the Compact Muon Solenoid at CERN in 2012 shows evidence of the decay of the Higgs boson.</p>
            <p>CMS Collaboration; Mc Cauley, Thomas</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Novel particles as hefty as Higgs bosons would not be so subtle; they would have shown up already as pronounced bumps on data plots. But as Matt Strassler, a particle physicist affiliated with Harvard University, explained to me, the traces of lighter novel particles could still lie in so-called hidden valleys in the data. “There’s a huge amount of unexplored territory there,” he said. There might exist, for instance, an unstable type of dark matter particle that leaves its mark by occasionally arising and immediately decaying into an excessive number of muon-antimuon pairs. Detecting such an excess would point indirectly to the unstable particle’s existence. “For people who thought all the new physics is at high energies — they’re very disappointed right now,” Strassler said. “I don’t share that view. There are many opportunities for nature to provide clues at low energies.”</p>
<p>So far, though, no such indirect evidence of new physics has been detected. The more accurate the statistics have become at the LHC, the better they match the Standard Model. Michelangelo Mangano, a particle physicist at CERN, the laboratory that houses the LHC, said the collider today is like a tool for exploring the Standard Model’s predictions, and he considers this exploration worthwhile because not all consequences of the equations are easy to calculate. The search for new physics beyond the Standard Model is ongoing, Mangano said, but “the fact that it’s not giving positive results does not mean we are stuck, dead, or wasting our time.”</p>
<p>These questions are so fundamental that of course it’s worth nailing down every amplitude and checking every hidden valley, since we have the tool for the job. But for hunters of new physics, does the game end there?</p>
<p><img decoding="async" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2.png" alt="" width="1300" height="43" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2.png 1300w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-520x17.png 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-768x25.png 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-98x3.png 98w" sizes="(max-width: 1300px) 100vw, 1300px"></p>
<p>The community wants to go bigger. CERN physicists want to build a Future Circular Collider, tripling the circumference of the LHC with a 91-kilometer tunnel beneath the Franco-Swiss border, to both probe higher energies and look for subtler signals. This FCC would initially collide electrons, which, unlike protons, are themselves elementary particles, with no substructure. Their clean collisions would allow more precise measurements of scattering amplitudes, making the FCC ultrasensitive to indirect signs of new physics. By the end of the century, the mega-collider would be upgraded to collide protons, as the LHC does now. Proton collisions are messier, but at the FCC they would achieve unprecedented energies — about seven times higher than the LHC can currently muster — so they have a chance, however slim, of revealing heavy particles beyond the LHC’s reach. (In theory, particle masses could range up to a million billion times greater than what the LHC energy scale can produce directly, so there’s no reason to expect them around the next bend.)</p>

<p>As of now, the FCC’s fate is unknown; formal approval and funding commitments by member countries won’t come before 2028.</p>
<p>Meanwhile, U.S. particle physicists are aiming to complement the European strategy by constructing a brand-new type of machine: a muon collider. Muons are elementary like electrons, but they’re 200 times heavier, so their collisions would be both clean and energetic (albeit not reaching the collision energies of the LHC). Both the selling point and the challenge of this newfangled type of machine is that it will require major technical innovations (with all the spin-off potential that can bring), because muons are highly unstable. They must be accelerated and collided mere microseconds after they’re created.</p>
<p>Demonstrating the technology and then constructing the collider would take roughly 30 years, and that’s with federal funding. “We have to figure out how to do it in between 10 and 20 billion [dollars],” said Maria Spiropulu, a physics professor at the California Institute of Technology and co-chair of the committee behind a national <a href="https://www.nationalacademies.org/news/new-report-lays-out-long-term-vision-for-particle-physics-says-u-s-should-begin-development-of-the-worlds-most-powerful-particle-collider">report endorsing a muon collider program</a> that came out in June 2025. Over the coming years, the Department of Energy will weigh whether to fund the proposal rather than competing science projects. What hurts its case is the lack of a “discovery guarantee,” which the LHC had with the Higgs boson.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1700" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-scaled.webp" alt="A long scientific tube in a tunnel is examined by a man in a helmet, a bike rests nearby." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-1720x1142.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-520x345.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-768x510.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-1536x1020.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-2048x1360.webp 2048w, https://www.quantamagazine.org/wp-content/uploads/2026/01/LHC-Tunnel-Brice-Maximilien-CERN-98x65.webp 98w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Scientists and technicians inspected and upgraded systems at the Large Hadron Collider during the Long Shutdown 2, which began in 2018.</p>
            <p>Maximilien Brice/CERN</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Then again, as the mathematical physicist <a href="https://www.math.columbia.edu/~woit/wordpress/?p=15394">Peter Woit mused on his blog</a>, “Perhaps in our new world order where everything is controlled by trillionaire tech bros, the financing won’t be a problem.”</p>
<p>Deliberations about a Chinese supercollider have come to naught, I’m told. Instead, China has decided to pursue a “super-tau-charm facility”: a lower-energy particle scattering experiment that would cost mere hundreds of millions of dollars instead of tens of billions. The facility will produce a lot of tau particles and charm quarks, partly to study whether taus ever shape-shift into muons or electrons. This kind of switching isn’t predicted by the Standard Model, but it does happen in some theoretical extensions of it.</p>
<p>Okay, we might as well check. We’re desperate for new physics, and the price is good. But by definition it’s very difficult to know which shots in the dark are worth taking.</p>
<p><img decoding="async" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-1.png" alt="" width="1300" height="43" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-1.png 1300w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-1-520x17.png 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-1-768x25.png 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-1-98x3.png 98w" sizes="(max-width: 1300px) 100vw, 1300px"></p>
<p>Adam Falkowski, who sounded the death knell for particle physics back in 2012, used to be known for the sharp commentary he supplied on his blog <a href="http://resonaances.blogspot.com/">Résonaances</a>. But the Paris-based particle physicist hasn’t posted anything since 2022. He said that’s partly because he’s been tied up with fatherhood and partly because there hasn’t been much to say.</p>

<p>When we caught up on a video call, Falkowski told me, “I am very skeptical about future colliders. For me it’s very difficult to get excited about it.” He sees momentum behind CERN’s FCC campaign, but personally he worries about the huge costs and timescales, and the fact that “there are absolutely no hints that something is there within the reach of the next collider.”</p>
<p>For his part, Falkowski has turned to the theoretical study of scattering amplitudes, a growing research area focused on the <a href="https://www.quantamagazine.org/physicists-reveal-a-quantum-geometry-that-exists-outside-of-space-and-time-20240925/">geometric patterns underlying particle interaction statistics</a>, patterns that could point toward a truer perspective on the quantum world. The field seeks to reformulate the equations of particle physics in a different mathematical language in hopes that this language might extend to quantum gravity. “There is a very vibrant program in trying to understand the structure of the physical theories,” Falkowski said. “The hope is that with the help of machine learning, that there can be very fast progress in the coming years. I think that’s where the best things have happened.”</p>
<p>But amplitudeology, as this field is known, is abstract — it’s no atom-smashing experiment. Falkowski said he does think experimental particle physics is dying. He has watched talented postdocs switch to other research areas or take data science jobs. “I’m not sure they are getting the best of the best as they used to,” he said, “because the prospects of returns are so distant. If you want to change the world now, you will do AI; you will do something different from particle physics.”</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1694" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-scaled.webp" alt="A large scientific instrument with radial symmetry, with a technician at the bottom." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-1720x1138.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-520x344.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-768x508.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-1536x1017.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-2048x1355.webp 2048w, https://www.quantamagazine.org/wp-content/uploads/2026/01/ALICE-Detector-at-CERN-cr.CERN-Julien-Marius-Ordan_Science-Source-98x65.webp 98w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>The ALICE (A Large Ion Collider Experiment) detector at the Large Hadron Collider was designed to study quark-gluon plasma.</p>
            <p>CERN, Julien Marius Ordan/Science Source</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>This brain drain appears to be real. I spoke to Jared Kaplan, co-founder of Anthropic, the company behind the chatbot Claude. He was a physicist the last time we spoke. As a grad student at Harvard in the 2000s, he worked with the renowned theorist Nima Arkani-Hamed to open up the new directions in amplitude research that are being actively pursued today. But Kaplan left the field in 2019. “I started working on AI because it seemed plausible to me that … AI was going to make progress faster than almost any field in science historically,” he said. AI would be “the most important thing to happen while we’re alive, maybe one of the most important things to happen in the history of science. And so it seemed obvious that I should work on it.”</p>
<p>As for the future of particle physics, AI makes worrying about it now rather pointless, in Kaplan’s view. “I think that it’s kind of irrelevant what we plan on a 10-year timescale, because if we’re building a collider in 10 years, AI will be building the collider; humans won’t be building it. I would give like a 50% chance that in two or three years, theoretical physicists will mostly be replaced with AI. Brilliant people like Nima Arkani-Hamed or Ed Witten, AI will be generating papers that are as good as their papers pretty autonomously. … So planning beyond this couple-year timescale isn’t really something I think about very much.”</p>
<p><img decoding="async" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-2.png" alt="" width="1300" height="43" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-2.png 1300w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-2-520x17.png 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-2-768x25.png 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/QUALIA-Separator-2-2-98x3.png 98w" sizes="(max-width: 1300px) 100vw, 1300px"></p>
<p>Cari Cesarotti, a postdoctoral fellow in the theory group at CERN, is skeptical about that future. She notices chatbots’ mistakes, and how they’ve become too much of a crutch for physics students. “AI is making people worse at physics,” she said. “What we need is humans to read textbooks and sit down and think of new solutions to the hierarchy problem.”</p>

<p>Cesarotti was a high school junior when the Higgs boson was discovered. She grew up near Fermilab, the U.S. national lab in Illinois that houses the Tevatron, which was the world’s highest-energy particle collider before the LHC. (The top quark was discovered there in 1995.) This proximity taught her that a particle physicist was a thing you could be. Later, it turned out to be <em>her</em> thing. “What are the fundamental building blocks of the universe — those were the questions that I was most interested in knowing the answer to,” she told me. “But what people said was, ‘Particle physics is dead. Don’t do this.’”</p>
<p>It may have been a fair warning; Cesarotti has yet to land a permanent job as a rising particle physicist. The subfield has continued to shrink, she and others said, as faculty hiring committees and grad students go in other directions. “Definitely all this rhetoric that there was nothing to be found and you should give up on it — people listened,” she said. “And of course that means there are fewer people. It becomes a self-fulfilling prophecy. If you’re pushing all these talented people out of trying to solve these problems into a field that it’s easier to make an impact on, then you’re setting yourself up for failure.”</p>
<p>Cesarotti echoed a sentiment I’d heard from others, which sounds correct to me as well: “Particle physics isn’t dead; it’s just hard.” It’s hard to know what to think about or look for. But the most devoted particle physicists are thinking and looking all the same.</p>
        
        
<p>“It was easy for 125 years,” Strassler said. “One thing led to the next. That lucky century has, for now, at least in the medium term, come to an end. That could change tomorrow, or next century, or who knows.”</p>
<p>A hint of a new lightweight particle could, in theory, show up at the LHC, or in some other experiment. Strassler is particularly excited about the study of <a href="https://www.quantamagazine.org/the-first-nuclear-clock-will-test-if-fundamental-constants-change-20240904/">radioactive thorium-229 decay</a>, which could reveal variations in the fundamental constants. I’m slightly partial to <a href="https://www.quantamagazine.org/he-seeks-mystery-magnetic-fields-with-his-quantum-compass-20240517/">experiments looking for “axions,”</a> dark matter candidates that are so lightweight that they can act a little like light itself.</p>
<p>On the theory side, an obvious solution to the hierarchy problem could drop naturally out of the geometry behind scattering amplitudes. Or, if Kaplan is right, AI systems might someday suggest powerful new ideas for how the 25 particles of the Standard Model fit into a more comprehensive pattern — a possibility I didn’t foresee back when the crisis began.</p>
<p>Clearly, further progress toward the truth remains possible in particle physics. But there’s no discovery guarantee. I’ve had more than 13 years to think about it, and it remains a disturbing prospect: All the empirical clues we can glean about nature’s fundamental laws and building blocks might already be in hand. The universe may plan on keeping the rest of its secrets.</p>
</div>
                
                
            </div>
                <div id="newsletter">
                        <p>
                The Quanta Newsletter            </p>
                            <p>
                    <em>Get highlights of the most important news delivered to your email inbox</em>
                </p>
                        
                            
                    </div>
    <div>
            <h2>Also in <span>Physics</span></h2>
            
        </div>
<section data-function="toggle" data-name="show-comments" id="comments">
    <h2>Comment on this article</h2>
    
    
</section>
    <div>
        <div data-name="next-post__image-wrapper">
    <p><img width="1720" height="728" src="https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-1720x728.webp" alt="a spherical glass vessel containing photomultiplier tubes" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-1720x728.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-520x220.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-768x325.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-1536x650.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-2048x867.webp 2048w, https://www.quantamagazine.org/wp-content/uploads/2026/01/Black-Holes-as-Dark-Matter-cr-Courtesy-of-KM3NeT-HP-98x41.webp 98w" sizes="(max-width: 1720px) 100vw, 1720px">    </p>
</div>
        
        <div>
                <h2>Next article</h2>
                <p>Monster Neutrino Could Be a Messenger of Ancient Black Holes</p>
            </div>
        </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The shadowy world of abandoned oil tankers (138 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cddg885344do</link>
            <guid>46952987</guid>
            <pubDate>Mon, 09 Feb 2026 23:17:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cddg885344do">https://www.bbc.com/news/articles/cddg885344do</a>, See on <a href="https://news.ycombinator.com/item?id=46952987">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><article><div data-testid="byline" data-component="byline-block"><p><span data-testid="byline-contributors"><div data-testid="byline-contributors-contributor-0"><p><span>David Waddell</span><span data-testid="byline-contributors-contributor-0-role-location">Business reporter</span></p></div></span></p></div><div data-component="image-block"><figure><div><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260126-113039-ddae8f6031-web-2.38.1-3/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/ad29/live/12236bf0-01ac-11f1-b6ab-2307e83ecd56.jpg.webp" loading="eager" alt="AFP via Getty Images The oil tanker Safer, which was abandoned off the coast of Yemen"><span>AFP via Getty Images</span></p></div><p><figcaption>The number of abandoned oil tankers and other commercial ships has shot up</figcaption></p></figure></div><div data-component="text-block"><p>Over the past year there has been a big rise in the number of oil tankers and other commercial ships being abandoned around the world by their owners. What is causing the spike? And what is the human impact on the affected merchant sailors?</p></div><div data-component="text-block"><p>Ivan (not his real name), spoke to me last month from an oil tanker that lies abandoned outside the territorial waters of China. He is a senior deck officer.</p></div><div data-component="text-block"><p>"We had a shortage of meat, grain, fish, simple things for survival," said the Russian officer. "It's affected our health and our operational atmosphere.</p></div><div data-component="text-block"><p>"The crew was hungry, the crew was angry, and we tried to survive only day-by-day."</p></div><div data-component="text-block"><p>The ship, which we are not naming to protect Ivan, is loaded with nearly 750,000 barrels of Russian crude oil with a nominal value of around $50m (£37m). It had set sail from Russia's Far East for China in early November.</p></div><div data-component="text-block"><p>It was reported abandoned in December, by global trade union organisation the International Transport Workers' Federation (ITF), after the crew said they had not been paid for months.</p></div><div data-component="text-block"><p>The vessel remains in international waters. Such is the level of scrutiny surrounding it that China is understood to be unwilling to allow it into port.</p></div><div data-component="text-block"><p>However, the ITF has intervened to get Ivan and his colleagues paid up to December, and arranged for food, drinking water and other essentials to be sent to the ship. </p></div><div data-component="text-block"><p>While some crew members have been repatriated, most, like Ivan, are still on board.</p></div><div data-component="image-block"><figure><div><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260126-113039-ddae8f6031-web-2.38.1-3/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/2fb6/live/f8421f20-01b4-11f1-8162-915dd1b9ab69.jpg.webp" loading="lazy" alt="ITF A group of people stand in the water as they crowd around an abandoned ship"><span>ITF</span></p></div><p><figcaption>Sometimes ships are abandoned in port, while others are left out at sea</figcaption></p></figure></div><div data-component="text-block"><p>Back in 2016, 20 ships were abandoned around the world, according to the ITF. In 2025 the number had ballooned to 410, with 6,223 merchant seamen falling victim. Both of those figures for last year were up by almost a third on 2024.</p></div><div data-component="text-block"><p>Geopolitical instability is said to have been a driving factor of the increase in recent years. Widespread conflicts around the world and the Covid pandemic have triggered supply chain disruption and wild variation in freight costs, meaning some operators are struggling to stay afloat.</p></div><div data-component="text-block"><p>But the ITF says the growing prevalence of so-called "shadow fleets" could be contributing to the big spike last year.</p></div><div data-component="text-block"><p>These ships, typically oil tankers such as the one Ivan is stuck on, are more often ageing vessels of obscure ownership, unseaworthy, likely uninsured, and operationally hazardous. And they typically sail under flags of convenience or FOCs - the ships are registered in countries with very limited regulatory oversight.</p></div><div data-component="text-block"><p>The shadow fleet vessels are trying to stay under the radar to help countries such as Russia, Iran and Venezuela export their crude in contravention of Western sanctions.</p></div><div data-component="text-block"><p>Take the case of Russia. Following its invasion of Ukraine in February 2022, it has faced sanctions that capped the price it can charge for its crude.</p></div><div data-component="text-block"><p>But Russia has found buyers willing to pay a higher price, such China and India, though the latter has now pledged to cease purchases under the terms of a recent US trade deal.</p></div><div data-component="text-block"><p>FOCs have been flown by merchant ships for more than a century, as a means for owners to skirt laws and regulations at home. In the 1920s, it was common for American-owned passenger ships to register in Panama to bypass US prohibition laws and sell alcohol on board.</p></div><div data-component="text-block"><p>Panama, Liberia and the Marshall Islands are the most common FOC states, representing 46.5% of all merchant ships by weight, but The Gambia has become a player in recent years.</p></div><div data-component="text-block"><p>In 2023 there were no oil tankers registered to The Gambia, but by March last year it had become paper-host to 35 such vessels. Host nations enjoy sizeable fees.</p></div><div data-component="text-block"><p>FOC vessels feature prominently in abandonment. In 2025 they accounted for 337 ships, or 82% of the total. The number of shadow-fleet ships among this number is unclear, but such is the poor state of these vessels and the sketchy ownership structures behind them, it would appear to expose these crafts and their crews to greater risk.</p></div><div data-component="text-block"><p>The International Maritime Organisation (IMO) guidance is that a seafarer is abandoned when their shipowner fails to cover the cost of his or her repatriation, or has left them without the necessary maintenance and support, or has otherwise unilaterally severed ties with them. The latter includes failure to pay contractual wages for a period of at least two months.</p></div><div data-component="text-block"><p>The ITF's General Secretary Stephen Cotton tells the BBC that "abandonment isn't an accident". He adds: "Seafarers don't really know where they're going.</p></div><div data-component="text-block"><p>"They sign a contract, they go to somewhere else in the world, and they're confronted by lots of different challenges."</p></div><div data-component="image-block"><figure><div><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260126-113039-ddae8f6031-web-2.38.1-3/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/16ac/live/5a059660-01b5-11f1-8162-915dd1b9ab69.jpg.webp" loading="lazy" alt="ITF A sailor on an abandoned ship pours fresh water from a tank"><span>ITF</span></p></div><p><figcaption>Crews of abandoned ships risk running out of fresh water</figcaption></p></figure></div><div data-component="text-block"><p>Last year abandoned merchant navy crews around the world were owed a total of $25.8m, according to data from two UN agencies, the IMO, and the International Labour Organization.</p></div><div data-component="text-block"><p>The ITF claims they have recovered and returned nearly two thirds of this, $16.5m. The wage arrears on Ivan's ship were in the region of $175,000 at the time of the ITF's initial involvement.</p></div><div data-component="text-block"><p>The most affected nationality for maritime abandonment in 2025 were Indian sailors, accounting for 1,125, or 18% of the total. Filipinos (539) and Syrians (309) come second and third.</p></div><div data-component="text-block"><p>In September last year, to protect its important seafaring community, the Indian government blacklisted 86 foreign vessels over seafarer abandonment and rights-violation issues. Investigations found many of them had untraceable owners or no response from flag states.</p></div><div data-component="image-block"><figure><div><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20260126-113039-ddae8f6031-web-2.38.1-3/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/38c6/live/ef677840-01b5-11f1-8162-915dd1b9ab69.jpg.webp" loading="lazy" alt="ITF The Burmese crew of the cargo ship Kokoo, which was abandoned last year. "><span>ITF</span></p></div><p><figcaption>Abandoned crews can spend months stuck on their ships</figcaption></p></figure></div><div data-component="text-block"><p>Mark Dickinson is the general secretary of Nautilus International, a trade union for maritime professionals.</p></div><div data-component="text-block"><p>He blames these FOC states for "a complete derogation of responsibility" towards their merchant fleets and the crews who sail on them.</p></div><div data-component="text-block"><p>He says there must be "a genuine link between ship owners and the flags under which they sail". This link is already mandated under international maritime law, but there is no universally-agreed definition.</p></div><div data-component="text-block"><p>Ivan's ship was sailing under a false Gambian flag, unregistered and unknown to The Gambia. It has since been provisionally accepted under the flag of another African nation that it is said to have opened a formal inquiry into the vessel.</p></div><div data-component="text-block"><p>ITF inspector Nathan Smith tells me that he expects the tanker's fate will be resolved only when the oil is transferred off the ship through a ship-to-ship transfer in open sea.</p></div><div data-component="text-block"><p>Ivan says that in the future he will check more carefully about any ship crew he joins.</p></div><div data-component="text-block"><p>"For sure I will have a proper discussion about the vessel's condition, about payment and provisions. And turn to the internet, where we can see which vessels are banned, which vessels are under sanction."</p></div><div data-component="text-block"><p>Seafarers like Ivan are often at the mercy of the contracts available. With shadow-fleet voyages a key feature of the supply chain for Russian oil, greater international cooperation will be needed to protect seafarers from the inherent risks of maritime service.</p></div><div data-component="links-block"><p><span data-testid="links-title">Read more global business stories</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LiftKit – UI where "everything derives from the golden ratio" (267 pts)]]></title>
            <link>https://www.chainlift.io/liftkit</link>
            <guid>46952118</guid>
            <pubDate>Mon, 09 Feb 2026 22:01:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chainlift.io/liftkit">https://www.chainlift.io/liftkit</a>, See on <a href="https://news.ycombinator.com/item?id=46952118">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav id="navbar"></nav><div id="w-node-_5030ea01-bfa4-5509-a67d-809f1eb83523-888d84eb" data-w-id="8ff21233-50e8-bb09-514a-318f205d8bd4"><p>Submission error. Please try again.</p></div><div><h2>What is LiftKit?</h2><p>An open-source UI&nbsp;framework that solves symmetry problems.</p><p>It does other things too, but that's the gist of it.</p></div><div id="install" data-force-dark-mode="true"><h3>The secret formula for "oddly-satisfying."</h3><div><div id="w-node-ada7abde-087c-08ca-9f46-7cc886e1ef0b-888d84eb"><p>LiftKit produces <span>golden-ratio proportions</span> with <span>subpixel accuracy</span> using <span>familiar utility classes</span> that make components feel satisfying.</p></div><div id="w-node-a806580b-ecaf-ff40-3e01-5f10684d966b-888d84eb"><p><h3>Heading</h3></p></div></div></div><div id="install" data-force-dark-mode="true"><h3>Dynamic color that's actually easy to use.</h3><p>This ain't your grandma's theme builder, folks. LiftKit offers a <span>modular control panel</span> for global color you can just add to any file while you're working to <span>preview changes in real time</span>. From subtle tints to color flooding, the possibilites are limitless.</p><div><h3 id="w-node-_965d0d51-9040-f256-2c60-2e36cedc09fc-888d84eb">And color's just the beginning. <span>You can easily adjust the following behaviors in the CSS while we continue working on adding them to the control panel.</span></h3><div><h4>Typography</h4><p>Granular controls for global typography that go far beyond font family.</p></div><div><h4>Custom Materials</h4><p>Create your own "-morphism." Start with presets like glass, flat, and rubber, or something completely new.</p></div><div><h4>Scaling</h4><p>Like those sliders you see for text scaling, except your spacing and everything else scales with it.</p></div><div><h4>Component-specific configs</h4><p>Tweak component appearance independently by detaching and hooking them back up to different LK&nbsp;variables.</p></div></div></div><div data-force-dark-mode="true" id="install"><h3>An almost <em>concerning</em> level of&nbsp;detail.</h3><p><span>Make MVP's that don't look like MVP's.</span> LiftKit gives your work a level of visual polish that puts you ahead right from the start. It bakes in those tiny little details that make people say "I&nbsp;can't explain it. <span>It just <em>feels</em> better.</span>"</p></div><div data-force-dark-mode="true" id="install"><div id="w-node-_5b2e073e-bd12-8851-88bc-1139d9c76f8b-888d84eb"><h3>Unlock the power of the golden&nbsp;ratio.</h3><h2>Get ready to fall in love with front-end aaaall over again.</h2></div><p><img src="https://cdn.prod.website-files.com/657f62adb6ceeafe578853be/67a3a4ff56723f8eeb1193c9_businessman%20with%20beard%20and%20hat%20celebrating%20by%20laptop%20transparent%20bg.webp" loading="lazy" sizes="100vw" srcset="https://cdn.prod.website-files.com/657f62adb6ceeafe578853be/67a3a4ff56723f8eeb1193c9_businessman%20with%20beard%20and%20hat%20celebrating%20by%20laptop%20transparent%20bg-p-500.webp 500w, https://cdn.prod.website-files.com/657f62adb6ceeafe578853be/67a3a4ff56723f8eeb1193c9_businessman%20with%20beard%20and%20hat%20celebrating%20by%20laptop%20transparent%20bg-p-800.webp 800w, https://cdn.prod.website-files.com/657f62adb6ceeafe578853be/67a3a4ff56723f8eeb1193c9_businessman%20with%20beard%20and%20hat%20celebrating%20by%20laptop%20transparent%20bg-p-1080.webp 1080w, https://cdn.prod.website-files.com/657f62adb6ceeafe578853be/67a3a4ff56723f8eeb1193c9_businessman%20with%20beard%20and%20hat%20celebrating%20by%20laptop%20transparent%20bg.webp 1280w" alt=""></p></div><div id="book-call"><div><h2>Learn</h2><div><h2>Tutorials</h2><a href="https://www.chainlift.io/liftkit/tutorials"></a></div><h2>Documentation</h2></div><div><h2>Connect</h2><div id="w-node-_09c5807c-e9e2-edee-ac25-8cf41cabfbba-888d84eb"><div id="w-node-_09c5807c-e9e2-edee-ac25-8cf41cabfbcc-888d84eb"><h2>Community</h2></div><div id="w-node-_1d31b4c8-a0be-7e95-4c24-f064796672cd-888d84eb"><h3>Contact Us<br></h3></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord faces backlash over age checks after data breach exposed 70k IDs (123 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2026/02/discord-faces-backlash-over-age-checks-after-data-breach-exposed-70000-ids/</link>
            <guid>46951999</guid>
            <pubDate>Mon, 09 Feb 2026 21:51:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2026/02/discord-faces-backlash-over-age-checks-after-data-breach-exposed-70000-ids/">https://arstechnica.com/tech-policy/2026/02/discord-faces-backlash-over-age-checks-after-data-breach-exposed-70000-ids/</a>, See on <a href="https://news.ycombinator.com/item?id=46951999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2140101">
  
  <header>
  <div>
      

      

      <p>
        Discord to block adult content unless users verify ages with selfies or IDs.
      </p>

              
          </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Discord is facing backlash after <a href="https://discord.com/press-releases/discord-launches-teen-by-default-settings-globally">announcing</a> that all users will soon be required to verify ages to access adult content by sharing video selfies or uploading government IDs.</p>
<p>According to Discord, it’s relying on AI technology that verifies age on the user’s device, either by evaluating a user’s facial structure or by comparing a selfie to a government ID. Although government IDs will be checked off-device, the selfie data will never leave the user’s device, Discord emphasized. Both forms of data will be promptly deleted after the user’s age is estimated.</p>
<p>In a blog, Discord confirmed that “a phased global rollout” would begin in “early March,” at which point all users globally would be defaulted to “teen-appropriate” experiences.</p>
<p>To unblur sensitive media or access age-restricted channels, the majority of users will likely have to undergo Discord’s age estimation process. Most users will only need to verify their ages once, Discord said, but some users “may be asked to use multiple methods, if more information is needed to assign an age group,” the blog said.</p>
<p>On social media, alarmed Discord users protested the move, doubting whether Discord could be trusted with their most sensitive information after <a href="https://arstechnica.com/security/2025/10/discord-says-hackers-stole-government-ids-of-70000-users/">Discord age verification data was recently breached</a>. In October, hackers stole government IDs of 70,000 Discord users from a third-party service that Discord previously trusted to verify ages in the United Kingdom and Australia.</p>
<p>At that time, Discord <a href="https://discord.com/press-releases/update-on-security-incident-involving-third-party-customer-service">told users</a> that the hackers were hoping to use the stolen data to “extort a financial ransom from Discord.” In October, Ars Senior Security Editor Dan Goodin joined others warning that “the best advice for people who have submitted IDs to Discord or any other service is to assume they have been or soon will be stolen by hackers and put up for sale or used in extortion scams.”</p>
<p>For bad actors, Discord will likely only become a bigger target as more sensitive information is collected worldwide, users now fear.</p>

          
                      
                  </div>
                    
        
            
    
    <div>
          
          
<p>It’s no surprise then that hundreds of Discord users on Reddit slammed the decision to expand age verification globally shortly after <a href="https://www.theverge.com/tech/875309/discord-age-verification-global-roll-out">The Verge broke the news</a>. On a <a href="https://www.reddit.com/r/pcgaming/comments/1r05stm/discord_will_require_facial_scans_or_government/">PC gaming subreddit</a> discussing alternative apps for gamers, one user wrote, “Hell, Discord has already had one ID breach, why the fuck would anyone verify on it after that?”</p>
<p>“This is how Discord dies,” another user declared. “Seriously, uploading any kind of government ID to a 3rd party company is just asking for identity theft on a global scale.”</p>
<p>Many users seem just as sketched out about sharing face scans. On the <a href="https://www.reddit.com/r/discordapp/comments/1r05vkj/discord_will_require_a_face_scan_or_id_for_full/">Discord app subreddit</a>, some users vowed to never submit selfies or IDs, fearing that breaches may be inevitable and suspecting Discord of downplaying privacy risks while allowing data harvesting.</p>
<h2>Who can access Discord age-check data?</h2>
<p>Discord’s system is supposed to make sure that only users have access to their age-check data, which Discord said would never leave their phones.</p>
<p>The company is hoping to convince users that it has tightened security after the breach by partnering with k-ID, an increasingly popular age-check service provider that’s also used by social platforms from Meta and Snap.</p>
<p>However, self-described Discord users on Reddit aren’t so sure, with some going the extra step of picking apart k-ID’s privacy policy to understand exactly how age is verified without data ever leaving the device.</p>
<p>“The wording is pretty unclear and inconsistent even if you dig down to the k-ID privacy policy,” one Redditor <a href="https://www.reddit.com/r/discordapp/comments/1pretpg/has_anyone_packet_sniffed_the_age_verification/">speculated</a>. “Seems that ID scans are uploaded to k-ID servers, they delete them, but they also mention using ‘trusted 3rd parties’ for verification, who may or may not delete it.” That user seemingly gave up on finding reassurances in either company’s privacy policies, noting that “everywhere along the chain it reads like ‘we don’t collect your data, we forward it to someone else… .’”</p>

          
                  </div>
                    
        
            
    
    <div>
          
          
<p>To better understand user concerns, Ars reviewed the privacy policies, noting that k-ID said its “facial age estimation” tool is provided by a Swiss company called Privately.</p>
<p>“We don’t actually see any faces that are processed via this solution,” k-ID’s policy said.</p>
<p>That part does seem vague, since Privately isn’t explicitly included in the “we” in that statement. Similarly, further down, the policy more clearly states that “neither k-ID nor its service providers collect any biometric information from users when they interact with the solution. k-ID only receives and stores the outcome of the age check process.” In that section, “service providers” seems to refer to partners like Discord, which integrate k-ID’s age checks, rather than third parties like Privately that actually conduct the age check.</p>
<p>Asked for comment, a k-ID spokesperson told Ars that “the Facial Age Estimation technology runs entirely on the user’s device in real time when they are performing the verification. That means there is no video or image transmitted, and the estimation happens locally. The only data to leave the device is a pass/fail of the age threshold which is what Discord receives (and some performance metrics that contain no personal data).”</p>
<p>K-ID’s spokesperson told Ars that no third parties store personal data shared during age checks.</p>
<p>“k-ID, does not receive personal data from Discord when performing age-assurance,” k-ID’s spokesperson said. “This is an intentional design choice grounded in data protection and data minimisation principles. There is no storage of personal data by k-ID or any third parties, regardless of the age assurance method used.”</p>
<p>Turning to Privately’s website, that offers a little <a href="https://www.privately.eu/solutions/multi-modal-age-estimation">more information</a> on how on-device age estimation works, while providing likely more reassurances that data won’t leave devices.</p>

<p>Privately’s services were designed to minimize data collection and prioritize anonymity to comply with the European Union’s General Data Protection Regulation, Privately <a href="https://www.privately.eu/industries/device-technology">noted</a>. “No user biometric or personal data is captured or transmitted,” Privately’s website said, while bragging that “our secret sauce is our ability to run very performant models on the user device or user browser to implement a privacy-centric solution.”</p>

          
                  </div>
                    
        
            
    
    <div>
          
          
<p>The company’s <a href="https://www.privately.eu/privacy-policy-en">privacy policy</a> offers slightly more detail, noting that the company avoids relying on the cloud while running AI models on local devices.</p>
<p>“Our technology is built using on-device edge-AI that facilitates data minimization so as to maximise user privacy and data protection,” the privacy policy said. “The machine learning based technology that we use (for age estimation and safeguarding) processes user’s data on their own devices, thereby avoiding the need for us or for our partners to export user’s personal data onto any form of cloud services.”</p>
<p>Additionally, the policy said, “our technology solutions are built to operate mostly on user devices and to avoid sending any of the user’s personal data to any form of cloud service. For this we use specially adapted machine learning models that can be either deployed or downloaded on the user’s device. This avoids the need to transmit and retain user data outside the user device in order to provide the service.”</p>
<p>Finally, Privately explained that it also employs a “double blind” implementation to avoid knowing the origin of age estimation requests. That supposedly ensures that Privately only knows the result of age checks and cannot connect the result to a user on a specific platform.</p>
<p>Asked for comment, Discord’s spokesperson said that “<span>Discord and our age assurance vendor partners do not permanently store personal identity documents or users’ video selfies. Identity documents, including selfies, are deleted once a user’s age group is confirmed, and the selfie video used for facial age estimation never leaves their device.”</span></p>
<p><span>“We’re also exploring other vendors and will be transparent with users if the data practices for vendors differ,” Discord’s spokesperson said. “We’ll continue to put user privacy first as we consider introducing any additional methods in the future. We also frequently audit our third-party systems to ensure they meet our security and privacy standards.”</span></p>
<h2>Discord expects to lose users</h2>
<p>Some Discord users may never be asked to verify their ages, even if they try to access age-restricted content. Savannah Badalich, Discord’s global head of product policy, told The Verge that Discord “is also rolling out an age inference model that analyzes metadata, like the types of games a user plays, their activity on Discord, and behavioral signals like signs of working hours or the amount of time they spend on Discord.”</p>
<p>“If we have a high confidence that they are an adult, they will not have to go through the other age verification flows,” Badalich said.</p>

          
                  </div>
                    
        
            
    
    <div>

        
        <div>
          
          
<p>Badalich confirmed that Discord is bracing for some users to leave Discord over the update but suggested that “we’ll find other ways to bring users back.”</p>
<p>On Reddit, Discord users complained that age verification is easy to bypass, forcing adults to share sensitive information without keeping kids away from harmful content. In Australia, where Discord’s policy first rolled out, some kids <a href="https://www.abc.net.au/news/2025-12-10/social-media-ban-day-one-teen-access/106126706">claimed</a> that Discord never even tried to estimate their ages, while others found it easy to trick k-ID by using AI videos or altering their appearances to look older. A teen girl relied on fake eyelashes to do the trick, while one 13-year-old boy was estimated to be over 30 years old after scrunching his face to seem more wrinkled.</p>
<p>Badalich told The Verge that Discord doesn’t expect the tools to work perfectly but acts quickly to block workarounds, like <a href="https://www.theverge.com/report/714402/uk-age-verification-bypass-death-stranding-reddit-discord">teens using <em>Death Stranding</em>‘s photo mode</a> to skirt age gates. However, questions remain about the accuracy of Discord’s age estimation model in assessing minors’ ages, in particular.</p>
<p>It may be noteworthy that Privately only claims that its technology is “proven to be accurate to within 1.3 years, for 18-20-year-old faces, regardless of a customer’s gender or ethnicity.” But experts told Ars last year that <a href="https://arstechnica.com/tech-policy/2025/04/redditor-accidentally-reinvents-discarded-90s-tool-to-escape-todays-age-gates/">flawed age-verification technology</a> still frequently struggles to distinguish minors from adults, especially when differentiating between a 17- and 18-year-old, for example.</p>
<p>Perhaps notably, Discord’s prior scandal occurred after hackers stole government IDs that users shared as part of the appeal process in order to fix an incorrect age estimation. Appeals could remain the most vulnerable part of this process, The Verge’s report indicated. Badalich confirmed that a third-party vendor would be reviewing appeals, with the only reassurance for users seemingly that IDs shared during appeals “are deleted quickly<b>—</b>in most cases, immediately after age confirmation.”</p>
<p>On Reddit, Discord fans awaiting big changes remain upset. A disgruntled Discord user <a href="https://www.reddit.com/r/discordapp/comments/1pretpg/has_anyone_packet_sniffed_the_age_verification/">suggested</a> that “corporations like Facebook and Discord, will implement easily passable, cheapest possible, bare minimum under the law verification, to cover their ass from a lawsuit,” while forcing users to trust that their age-check data is secure.</p>
<p>Another user joked that she’d be more willing to trust that selfies never leave a user’s device if Discord were “willing to pay millions to every user” whose “scan does leave a device.”</p>
<p><em>This story was updated on February 9 to add comments from Discord and k-ID, and to clarify that government IDs are checked off-device.</em></p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/ashleybelanger/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2022/06/Ashley-Belanger-400x400.jpg" alt="Photo of Ashley Belanger"></a></p>
  </div>

  <div>
    

    <p>
      Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/tech-policy/2026/02/discord-faces-backlash-over-age-checks-after-data-breach-exposed-70000-ids/#comments" title="145 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    145 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/space/2026/02/has-elon-musk-given-up-on-mars/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2214317436-768x432.jpg" alt="Listing image for first story in Most Read: Why would Elon Musk pivot from Mars to the Moon all of a sudden?" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[America has a tungsten problem (192 pts)]]></title>
            <link>https://www.noleary.com/blog/posts/1</link>
            <guid>46951057</guid>
            <pubDate>Mon, 09 Feb 2026 20:49:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noleary.com/blog/posts/1">https://www.noleary.com/blog/posts/1</a>, See on <a href="https://news.ycombinator.com/item?id=46951057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a href="https://www.noleary.com/blog"></a><div><p>America has a tungsten problem</p><p>The US will need a lot more tungsten in the future. Where will it come from?</p></div></div><div><p>The United States needs a better plan for tungsten. For many years, the US has relied on Chinese tungsten production, but that's an increasingly tenuous position. Relatively conservative growth projections in defense and semiconductors suggest an escalation in tungsten demand. But if fusion technologies materialize, the United States will simply not have sufficient tungsten.</p><p>About Tungsten</p><p>Tungsten is a metal with a unique mix of properties. It melts at a higher temperature than any other metal. It is very hard, extremely dense, and broadly inert. Unlike other refractory metals, tungsten conducts electricity and heat fairly well.</p><p>Tungsten's major applications include:</p><ul>
<li><strong>Cutting and drilling tools</strong>. Tungsten <em>carbide</em>'s extreme hardness and high heat tolerance make it a great material for drill bits; if you're boring through the earth for oil and gas, you're likely using tungsten carbide. This is the primary application for tungsten now; estimates suggest it's about 60% of total consumption.</li>
<li><strong>Munitions</strong>. Tungsten's high density and chemical inertness make it useful in <a href="https://en.wikipedia.org/wiki/Kinetic_energy_penetrator">armor piercing rounds</a> and certain <a href="https://en.wikipedia.org/wiki/Dense_inert_metal_explosive">specialized explosives</a>. It's an alternative in many cases to depleted uranium.</li>
<li><strong>Semiconductors</strong>. Tungsten's high melting point, inertness, adequate conductivity, and fluoride chemistry make it a useful metal for filling nanoscale connection gaps in semiconductors via chemical vapor deposition.</li>
<li><strong>Photovoltaic cells</strong>. Traditionally, photovoltaic cell manufacturing (i.e., making solar panels) used carbon steel wire to cut silicon wafers. Manufacturers increasingly use tungsten wire instead, because it allows them to get a much lower wire diameter, which in turn reduces the amount of silicon wasted with a given cut.</li>
</ul><p>Tungsten has an emerging application tied to the future of energy: it's an essential input for <strong>nuclear fusion reactors</strong>.</p><p>Tungsten is really good at resisting heat and erosion from neutron bombardment. It's a leading candidate for plasma-facing components and radiation shielding in fusion reactors. ITER<sup data-state="closed" data-slot="hover-card-trigger"></sup> has some good articles about why they use Tungsten, including <strong><a href="https://www.iter.org/node/20687/trial-fire">this one</a></strong> about the extreme heat conditions that parts need to endure.</p><p>Tungsten is a weird and mostly forgotten element. It just doesn't command the same attention as rare earth metals. But it's really important for major industrial technologies!</p><p>Tungsten demand</p><p>In steady state, United States needs to import about 10,000 tons of tungsten each year. And American demand for tungsten might be <em>going up</em>. My handwaving guesstimate below hazards that the United States could need 15,000+ tons each year under somewhat moderate assumptions. If we allow ourselves to imagine fusion technology working, we can guess that the United States would have to find a way to <em>match</em> Chinese tungsten output.</p><p>Tungsten demand: conventional applications</p><p>If we refer back to tungsten's main applications, we should recognize that demand will likely increase. Let's engage in a thought experiment with a grotesquely simple model:</p><ul>
<li>Assume the amount of tungsten consumed in a given application varies proportionally with the market's overall size. Why not? Seems fine.</li>
<li>Assign some hazy distributional assumptions to the different applications that consume tungsten. Let's say 60% of tungsten goes to cutting and drilling, 10% to munitions<sup data-state="closed" data-slot="hover-card-trigger"></sup> , 5% to semiconductors<sup data-state="closed" data-slot="hover-card-trigger"></sup>, 1% to photovoltaic applications<sup data-state="closed" data-slot="hover-card-trigger"></sup>, and then 24% to a bunch of other stuff<sup data-state="closed" data-slot="hover-card-trigger"></sup>. Let's round fusion to zero for now.</li>
<li>Assign some hazy high/low guesses to different applications. Let's suppose that semiconductors and photovoltaic applications grow at a 15% compound annual growth rate (CAGR) and assume everything else grows slowly at a 5% CAGR.</li>
</ul><p>We arrive at a hazy modeled guess of nearly doubled demand for tungsten in 10 years (+77%). These figures are all wrong, of course, but that doesn't mean they're not useful.</p><p>The important conclusions we should make here are all qualitative. <em>Demand for tungsten in the United States is going up under relatively conservative assumptions.</em></p></div>
<div data-slot="table-container"><table data-slot="table"><thead data-slot="table-header"><tr data-slot="table-row"><th data-slot="table-head"></th><th data-slot="table-head"><div><p>CAGR</p></div></th><th data-slot="table-head"><div><p>2025</p></div></th><th data-slot="table-head"><div><p>2026</p></div></th><th data-slot="table-head"><div><p>2027</p></div></th><th data-slot="table-head"><div><p>2028</p></div></th><th data-slot="table-head"><div><p>2029</p></div></th><th data-slot="table-head"><div><p>2030</p></div></th><th data-slot="table-head"><div><p>2031</p></div></th><th data-slot="table-head"><div><p>2032</p></div></th><th data-slot="table-head"><div><p>2033</p></div></th><th data-slot="table-head"><div><p>2034</p></div></th><th data-slot="table-head"><div><p>2035</p></div></th></tr></thead><tbody data-slot="table-body"><tr data-slot="table-row"><td data-slot="table-cell">Cutting and drilling</td><td data-slot="table-cell">5.0%</td><td data-slot="table-cell">60%</td><td data-slot="table-cell">63%</td><td data-slot="table-cell">66%</td><td data-slot="table-cell">69%</td><td data-slot="table-cell">73%</td><td data-slot="table-cell">77%</td><td data-slot="table-cell">80%</td><td data-slot="table-cell">84%</td><td data-slot="table-cell">89%</td><td data-slot="table-cell">93%</td><td data-slot="table-cell">98%</td></tr><tr data-slot="table-row"><td data-slot="table-cell">Munitions</td><td data-slot="table-cell">5.0%</td><td data-slot="table-cell">10%</td><td data-slot="table-cell">11%</td><td data-slot="table-cell">11%</td><td data-slot="table-cell">12%</td><td data-slot="table-cell">12%</td><td data-slot="table-cell">13%</td><td data-slot="table-cell">13%</td><td data-slot="table-cell">14%</td><td data-slot="table-cell">15%</td><td data-slot="table-cell">16%</td><td data-slot="table-cell">16%</td></tr><tr data-slot="table-row"><td data-slot="table-cell">Semiconductors</td><td data-slot="table-cell">15.0%</td><td data-slot="table-cell">5%</td><td data-slot="table-cell">6%</td><td data-slot="table-cell">7%</td><td data-slot="table-cell">8%</td><td data-slot="table-cell">9%</td><td data-slot="table-cell">10%</td><td data-slot="table-cell">12%</td><td data-slot="table-cell">13%</td><td data-slot="table-cell">15%</td><td data-slot="table-cell">18%</td><td data-slot="table-cell">20%</td></tr><tr data-slot="table-row"><td data-slot="table-cell">Photovoltaic</td><td data-slot="table-cell">15.0%</td><td data-slot="table-cell">1%</td><td data-slot="table-cell">1%</td><td data-slot="table-cell">1%</td><td data-slot="table-cell">2%</td><td data-slot="table-cell">2%</td><td data-slot="table-cell">2%</td><td data-slot="table-cell">2%</td><td data-slot="table-cell">3%</td><td data-slot="table-cell">3%</td><td data-slot="table-cell">4%</td><td data-slot="table-cell">4%</td></tr><tr data-slot="table-row"><td data-slot="table-cell">Other</td><td data-slot="table-cell">5.0%</td><td data-slot="table-cell">24%</td><td data-slot="table-cell">25%</td><td data-slot="table-cell">26%</td><td data-slot="table-cell">28%</td><td data-slot="table-cell">29%</td><td data-slot="table-cell">31%</td><td data-slot="table-cell">32%</td><td data-slot="table-cell">34%</td><td data-slot="table-cell">35%</td><td data-slot="table-cell">37%</td><td data-slot="table-cell">39%</td></tr><tr data-slot="table-row" data-total="true"><td data-slot="table-cell"><strong>TOTAL</strong></td><td data-slot="table-cell"><strong>5.9%</strong></td><td data-slot="table-cell"><strong>100%</strong></td><td data-slot="table-cell"><strong>106%</strong></td><td data-slot="table-cell"><strong>112%</strong></td><td data-slot="table-cell"><strong>118%</strong></td><td data-slot="table-cell"><strong>125%</strong></td><td data-slot="table-cell"><strong>132%</strong></td><td data-slot="table-cell"><strong>140%</strong></td><td data-slot="table-cell"><strong>148%</strong></td><td data-slot="table-cell"><strong>157%</strong></td><td data-slot="table-cell"><strong>167%</strong></td><td data-slot="table-cell"><strong>177%</strong></td></tr></tbody><caption data-slot="table-caption">Modeled tungsten demand by application, annual figures indexed to 2025 = 100%. Blue cells are inputs.</caption></table></div>
<div><p>Tungsten demand: what about fusion?</p><p>I intentionally left out fusion above. What if it really happens? There <em>are</em> an awful lot of brilliant people working hard to make fusion happen. There's ITER, as I mentioned before, but there are also a bunch of commercial startups. It's not impossible that some of these organizations make real headway over the next decade.</p><p>A lot of people smarter than I am have invested time and credibility in the promise of fusion on the horizon. For example, <strong><a href="https://deepmind.google/blog/bringing-ai-to-the-next-generation-of-fusion-energy/">DeepMind partnered with CFS</a></strong>, <strong><a href="https://www.helionenergy.com/articles/announcing-helion-fusion-ppa-with-microsoft-constellation/">Microsoft agreed to buy power from Helion Energy</a></strong>, and <strong><a href="https://www.businesswire.com/news/home/20251207372064/en/Helical-Fusion-Signs-Japans-First-Power-Purchase-Agreement-for-Fusion-Energy-with-Aoki-Super">Helical Fusion arranged a power purchase agreement with a major Japanese supermarket</a></strong>. Even when you cut through the PR here, there's undoubtedly a kernel of real optimism.</p><p>I can't pretend to know what a fusion reactor's appetite for tungsten would look like. I genuinely don't know. I weakly suspect nobody knows.</p><p>I did find <strong><a href="https://www.sciencedirect.com/science/article/abs/pii/S0920379625000833">one paper</a></strong> out there.<sup data-state="closed" data-slot="hover-card-trigger"></sup> The paper suggests that a fusion reactor might consume 5,000 to 30,000 tons of tungsten over a 40-year lifespan. Let's just say that the answer is 10,000 tons over 40 years for simplicity. That's 250 tons per year per reactor.</p><p>What's a reasonable number of reactors? Here again, I can't pretend to know. I can only make a hamfisted gesture at the number of <em>fission</em> reactors that we already have. We know there are <a href="https://www.nei.org/resources/fact-sheets/u-s-nuclear-plants">about 100 civil fission reactors</a> in the United States. And then the US Navy has another <strong>100 or so <a href="https://www.energy.gov/sites/default/files/2021-07/2020%20United%20States%20Naval%20Nuclear%20Propulsion%20Program%20v3.pdf">nuclear reactors</a></strong>, mostly on submarines.</p><p>In the absence of a good reason to believe otherwise, one might imagine the United States could have demand for 200 or so fusion reactors. This is again almost certainly an incorrect figure, but it's still useful for qualitative judgments.</p><p>If that's true, then <strong>fusion might account for the majority of future American tungsten demand</strong>. 200 reactors at 250 tons of tungsten per year totals 50,000 tons of tungsten per year.</p><p>If we combine this figure with our hazy baseline projection from before, we can loosely imagine tungsten demand in the United States  approaching 60,000 to 70,000 tons per year.</p><p>Tungsten supply</p><p>Tungsten is an overwhelmingly Chinese industry; each year, China accounts for more than 80% of the world's ~80,000 tons of production. The next-largest producing countries in a given year are generally Vietnam, Russia, and North Korea -- and none of them are really major producers.</p><p>The United States has not produced <em>any</em> tungsten since 2015.</p></div>
<div><div><p>Global tungsten production, by year</p><p>Figures in metric tons</p></div><p>Source: USGS Mineral Commodity Summaries.</p></div>
<div><p>The United States has long relied on China for its tungsten supply. The United States has historically imported about 10,000 tons of tungsten each year. At that volume, where else could tungsten be coming from? No other country produces <em>nearly</em> enough!</p><p>Recent trade disputes have made American dependence on Chinese tungsten difficult to ignore. In response to tariffs, the Chinese government levied tight export controls on minerals including tungsten. To date, it seems that no US firms have received Chinese export licenses for tungsten. The controls functionally amount to a ban, even though no one wants to call it that.</p><p>The American-Chinese relationship lies somewhere between <em>competitive</em> and <em>adversarial</em>. I'll leave the characterization to the reader's individual politics. In either case, American reliance on Chinese tungsten (among other minerals) compromises its strategic position. The United States does not currently have an alternative supply of tungsten.</p></div>
<div><div><p>US tungsten imports for consumption, by year</p><p>Figures in metric tons</p></div><p>Source: USGS Mineral Commodity Summaries.</p></div>
<div><p>Supply can't just appear. Mines take many years and many millions of dollars to approach full productivity. Mines need to raise a lot of speculative capital, weave through a complex regulatory maze, recruit specialized labor, and ultimately ... get kind of lucky. Moreover, the mining business thrashes every few years from boom to bust and back again. You really can't count on the durable availability of private capital.</p><p>The natural solution for American interests would be to stimulate tungsten production elsewhere -- whether domestically or abroad. There just needs to be more non-Chinese tungsten.</p><p>This <em>is</em> underway, at least to some extent. The US Department of War<sup data-state="closed" data-slot="hover-card-trigger"></sup> has given some awards to American and Canadian firms that are developing tungsten mines.<sup data-state="closed" data-slot="hover-card-trigger"></sup> The Trump administration stepped in to push forward <strong><a href="https://www.reuters.com/world/asia-pacific/cove-capital-mine-kazakhstan-tungsten-trump-announced-deal-2025-11-06/">an American-Kazakh tungsten deal</a></strong> late last year.</p><p>But that's probably not sufficient. We need to engage seriously with the scale of the problem here. American demand for tungsten already exceeds non-Chinese supply by a pretty wide margin. We can observe this in market prices, which hit <a href="https://www.reuters.com/world/americas/tungsten-rises-record-highs-export-curbs-turn-up-supply-heat-2026-01-29/">all-time highs</a> in recent weeks. And demand is probably going up.</p><p>Wrapping up</p><p>As things stand, the United States faces a problem. The country doesn't have a secure, viable supply of tungsten for the future. The United States therefore risks its domestic semiconductor and munitions industries over the medium run.</p><p>But there's an even bigger strategic pinch lurking over the next decade. Bullish prognostications about nuclear fusion might turn out to be right. We might end up getting functional -- it not yet economical -- commercial fusion in the 2030s. If that's true, then demand for tungsten will rapidly outstrip supply. Prices will soar.</p><p>The obvious solution is to mine more tungsten. After all, it turns out tungsten actually isn't hard to find! It's all over the United States.  In fact, it's pretty much all over the world.</p><p>One wonders:</p><ul>
<li>Why does China produce &gt;80% of the world's tungsten?</li>
<li>Why has there been <strong>zero</strong> domestic tungsten mining in the United States?</li>
<li>What needs to change for domestic tungsten mining to return?</li>
<li>What will it take to make sure tungsten supplies survive the next boom and bust mining investment cycles?</li>
</ul></div><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Super Bowl Ad for Ring Cameras Touted AI Surveillance Network (190 pts)]]></title>
            <link>https://truthout.org/articles/super-bowl-ad-for-ring-cameras-touted-ai-surveillance-network/</link>
            <guid>46950915</guid>
            <pubDate>Mon, 09 Feb 2026 20:41:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://truthout.org/articles/super-bowl-ad-for-ring-cameras-touted-ai-surveillance-network/">https://truthout.org/articles/super-bowl-ad-for-ring-cameras-touted-ai-surveillance-network/</a>, See on <a href="https://news.ycombinator.com/item?id=46950915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
             <!--begin content-single -->

<article itemprop="mainEntity" itemscope="" itemtype="https://schema.org/ReportageNewsArticle">

  <header>

  
  
  
  
      
    
  

  

      <p>Ring’s AI-powered network is likely to be used in its partnerships with law enforcement and agencies like ICE.</p>
  
  

  
  
  
</header>

  <figure itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject"><img width="1200" height="854" src="https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-1200x854.jpg" alt="Ring security cameras are displayed on a shelf at a Best Buy store on June 1, 2023 in San Rafael, California." itemprop="url" loading="eager" decoding="async" fetchpriority="high" srcset="https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-1200x854.jpg 1200w, https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-400x285.jpg 400w, https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-200x142.jpg 200w, https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-800x569.jpg 800w, https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-1536x1092.jpg 1536w, https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras-2048x1457.jpg 2048w, https://truthout.org/app/uploads/2026/02/2026_02-09-ring-cameras.jpg 2400w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption itemprop="caption">Ring security cameras are displayed on a shelf at a Best Buy store on June 1, 2023 in San Rafael, California.</figcaption><figcaption itemprop="author" itemscope="" itemtype="https://schema.org/Person"><span itemprop="name">Justin Sullivan / Getty Images</span></figcaption></figure>
  
  
  <div id="articleContent">

    

    <!-- begin partial/series-card -->

    
    
    <div id="truth-2177662714"><p><i><span>Honest, paywall-free news is rare. Please support our boldly independent journalism with </span></i><a href="https://support.truthout.org/-/XXQLBDSX/&amp;utm_source=truthout&amp;utm_medium=bcb&amp;utm_campaign=304216"><i><span>a donation</span></i></a><i><span> of any size.</span></i></p></div>
<p>In an ad during the Super Bowl on Sunday night, Amazon’s Ring touted the establishment of an AI-powered surveillance network through their camera systems, which the company whitewashed under a feel-good narrative about finding lost dogs.</p>



<p><a href="https://www.youtube.com/watch?v=OheUzrXsKrY">The ad</a> for Ring’s free “Search Party” program urges users to “be a hero” by using their surveillance cameras to help identify lost dogs in their neighborhood. It aired to millions of viewers during Super Bowl LX on Sunday night.</p>



<p>“Pets are family, but every year, 10 million go missing,” narrated Ring founder Jamie Siminoff, over uncanny, seemingly AI-generated clips of lost dog posters adhered to poles. A huge proportion of the ads during the Super Bowl <a href="https://www.adweek.com/brand-marketing/super-bowl-revealed-ai-messaging-crisis/">were for</a> or featured AI, <a href="https://www.si.com/nfl/super-bowl/nfl-fans-sick-of-ai-ads-super-bowl-lx">frustrating many</a> viewers.</p>



<p>“Search Party from Ring uses AI to help families find lost dogs,” he said, while the video showed Ring camera footage in which the software detects a dog in the frame. The company’s website says that the Search Party app can also be used by non-Ring camera owners.</p>



<p>Amazon’s <a href="https://www.aboutamazon.com/news/devices/ring-search-party-for-dogs-united-states-missing-pets">website also touts</a> Ring’s goal of equipping over 4,000 animal shelters across the U.S. with Ring camera systems, a $1 million initiative, claiming this will further help locate lost pets.</p>




<p>However, the attempt at telling a heartwarming story of reuniting dogs with their owners masks Ring’s true intentions of creating a nationwide surveillance system, analysts noted. </p>



<p>“It starts with searching for a ‘brown dog’ but means the tech is there for license plate reading, face recognition, searching for suspects by description, etc,” <a href="https://bsky.app/profile/did:plc:pxcupv4p27r73xgjw4s3lkqj/post/3mefgknsdac2u">wrote</a> surveillance and policing expert and scholar Matthew Guariglia on social media. “We already know they have a form cops can fill out to get access to footage without warrant or permission in an ‘emergency’ as determined by them. What will this mean for new features?”</p>



<p>Guariglia noted that Ring would likely make the AI-powered features on by default, requiring users to manually search their settings to turn it off.</p>



<p>Indeed, Ring has come under intense scrutiny for its collaboration with the criminal legal system, especially through its partnerships directly with police and with surveillance companies Flock and Axon, which grant <a href="https://truthout.org/articles/a-vast-camera-system-now-feeds-information-to-police-on-drivers-across-the-us/">law enforcement access</a> to an enormous amount of information, including tracking of individuals, license plate recognition, and more.</p>



<p>Flock’s dragnet <a href="https://www.aclu.org/news/privacy-technology/flock-roundup">has been used</a> by federal immigration agents to track immigrants and search for a person who received an abortion. It has also helped corporations make watch lists, following in the history of corporate blacklists of labor and social movement organizers.</p>



<p>While Flock’s hardware is largely in use in public locations, Ring cameras are ubiquitous in neighborhoods today. According to <em>Consumer Reports</em>, <a href="https://www.consumerreports.org/home-garden/home-security-cameras/ring-doorbell-review-a1607205040/">30 percent</a> of U.S. households have a video doorbell camera, with Ring being one of the most popular brands. Access to that network gives Flock and law enforcement eyes in neighborhoods across the U.S., with the ability to track millions of Americans.</p>



<p>A feature that the ad didn’t mention, for instance, is Ring’s “<a href="https://ring.com/support/articles/z3yhg/familiar-faces?srsltid=AfmBOorzyH3BdD8aYK0UPJd7vzYg0STsojVrWZGq59sf-xWdg_-maPCy">Familiar Faces</a>” program. According to the company’s website, this beta feature “uses Ring Artificial Intelligence (AI) to recognize people.” Users help train the AI system to recognize particular faces over time, it says, so they can then receive a “personalized notification” when that particular person is at the door. The feature also “works with 24/7 Continuous Recording,” the website says, <a href="https://ring.com/support/articles/wtr7r/24-7-recording-security-cams">referring to</a> their cameras’ ability to <a href="https://ring.com/support/articles/wtr7r/24-7-recording-security-cams">record audio and video</a> at all times.</p>
<div id="truth-3923882879" data-callout-id="331378" data-callout-theme="white" data-callout-placement="Post Content - After" data-callout-title="*2025 Evergreen (FRU) Press freedom is under attack">
<h5>Press freedom is under attack</h5>
<p><span>As Trump cracks down on political speech, independent media is increasingly necessary.</span></p>
<p><span><strong>Truthout produces reporting you won’t see in the mainstream: journalism from the frontlines of global conflict, interviews with grassroots movement leaders, high-quality legal analysis and more.</strong></span></p>
<p><span>Our work is possible thanks to reader support. Help Truthout catalyze change and social justice — make a tax-deductible monthly or one-time donation today. </span></p>

</div>
    
    

    
    

    

  </div> 

  

  
  

      
  
      
  </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Upcoming changes to Let's Encrypt and how they affect XMPP server operators (164 pts)]]></title>
            <link>https://blog.prosody.im/2026-letsencrypt-changes/</link>
            <guid>46950780</guid>
            <pubDate>Mon, 09 Feb 2026 20:31:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.prosody.im/2026-letsencrypt-changes/">https://blog.prosody.im/2026-letsencrypt-changes/</a>, See on <a href="https://news.ycombinator.com/item?id=46950780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    

    
    <div>
      <p><small>
        <p><time datetime="2026-02-06T11:20:00Z">
          2026-02-06
        </time> by The Prosody Team
         
        <br>
        
        </p>
        

        
        
        <br>

      </small></p>
    </div>
    <p>On 11th February, Let’s Encrypt will be rolling out a change to the
certificates they issue to servers by default. Although there is generally
nothing that Prosody operators need to do, servers using the new certificates
may experience problems connecting to some other XMPP servers on the network.</p>

<h2 id="certificate-basics">Certificate basics</h2>

<p>First, a tiny bit of background on certificates. Certificate Authorities (CAs)
such as Let’s Encrypt work by verifying that you own or control a domain, and
then they issue you with a certificate that you can present to others as proof
of this verification. Obtaining a certificate can be done using the ‘certbot’
tool or any one of the large number of tools compatible with the ACME protocol.</p>

<p>When an XMPP client connects to a server, it will expect the server to present
a certificate which is valid for the domain the client is logging in to.</p>

<p>Likewise, certificates are also used when servers connect to other servers
(server-to-server connections are often called “s2s” or generally
“federation”). This prevents various attacks, including spoofing - because
when your server receives a message claiming to be from “user@example.com”, it
can ensure that the server it came from presented a valid certificate for
“example.com” and has been verified.</p>

<h2 id="certificates-can-specify-usage">Certificates can specify usage</h2>

<p>Most people know that certificates contain the domain name that has been
verified. However they contain other data too, including the details of the CA
that signed and issued the certificate, validity period, and various metadata.</p>

<p>Another part of the certificate can specify limitations on what the
certificate can be used for. For example, a CA’s own certificate will specify
that they are allowed to use their certificate to sign other certificates.
Similar restrictions can be used to permit whether it can be used for signing
and/or encryption.</p>

<p>One such extension, called “Extended Key Usage” can be used to restrict
whether the certificate is used for “server authentication” or “client
authentication”.</p>

<h2 id="what-s-changing">What’s changing?</h2>

<p>Let’s Encrypt currently issue certificates which specify they may be used for
both “server authentication” and “client authentication”. However <a href="https://letsencrypt.org/2025/05/14/ending-tls-client-authentication">they have
announced</a>
that they will be issuing certificates for <strong>only</strong> “server authentication” by
default <strong>from 11th February 2026</strong>. In the rest of this post we’ll refer to
these as “server-only” certificates.</p>

<p>Traditional interpretation of the relevant specifications would forbid use of
those certificates by a client which is connecting to a server. Unfortunately,
XMPP makes heavy use of connections between servers, and in the context of
such server-to-server connections the TLS specifications actually consider the
server that initiated the connection to be a “client” (not an XMPP client, but
a TLS client).</p>

<p>Common TLS libraries and APIs such as OpenSSL will automatically verify the
certificate’s key usage fields, and fail certificate validation if an incoming
connection is received that uses a certificate without the “client
authentication” purpose. This has the potential to break server-to-server
connection authentication in XMPP (and also other protocols that make
connections between servers).</p>

<p><img src="https://blog.prosody.im/files/client-eku-missing.svg" alt="Diagram of problematic server-to-server connection"></p>

<h2 id="does-this-affect-prosody">Does this affect Prosody?</h2>

<p>Not directly. Let’s Encrypt is not the first CA to issue server-only
certificates. Many years ago, we incorporated changes into Prosody which allow
server-only certificates to be used for server-to-server connections,
regardless of which server started the connection. We believe that this is the
correct approach for XMPP.</p>

<p>This means that Prosody will accept connections from servers that are using
the new server-only certificates from Let’s Encrypt.</p>

<p>Unfortunately this behaviour is not standardized, partly due to controversy
outside the XMPP community about this approach. The current CA ecosystem is
<strong>heavily</strong> driven by web browser vendors (i.e. Google, Apple, Microsoft and
Mozilla), and they are increasingly hostile towards non-browser applications
using certificates from CAs that they say only provide certificates for
consumption by web browsers.</p>

<p>An attempt at <a href="https://datatracker.ietf.org/doc/draft-frank-mtls-via-serverauth-extension/">updating the specifications</a>
to clarify the expected roles of servers and clients failed to gain consensus
at the IETF.</p>

<h2 id="does-this-affect-the-xmpp-network">Does this affect the XMPP network?</h2>

<p>Although Prosody will accept server-only certificates, some other server
implementations do not have the alternative certificate usage validation
that Prosody has, or they added it only recently.</p>

<p>Compatible servers:</p>

<ul>
<li>ejabberd (requires 25.08 or later)</li>
<li>Openfire</li>
</ul>

<p>Operators of incompatible server versions should upgrade to a version that is
compatible with server-only certificates as soon as possible to prevent
problems with federation.</p>

<p>Server software not listed above has not been tested, and may not accept
connections from servers using server-only certificates.</p>

<h2 id="what-will-happen-with-other-servers">What will happen with other servers?</h2>

<p>If a server does not use the alternative validation (because the software
doesn’t implement it, or it has not been updated) then it will treat the
certificates of all other servers as invalid for initiating s2s connections.</p>

<p>Many servers still have the dialback protocol enabled, which will act as a
fallback authentication mechanism (using DNS), and in this case the
connections may still succeed.</p>

<p>However if dialback is disabled on either server, or if the target server
strictly requires valid certificates, server-to-server connections will always
fail entirely.</p>

<p>You may see errors in your Prosody log file such as:</p>

<blockquote>
<p>Server-to-server connection failed: Could not authenticate to remote server</p>
</blockquote>

<p>In such a case, the remote server operator usually needs to update their
software.</p>

<h2 id="how-can-i-test-my-server">How can I test my server?</h2>

<p>Send an XMPP ping (XEP-0199) to <code>le-tlsserver.badxmpp.eu</code> - if you get a
successful iq response, this means your server accepts server-only
certificates. If you don’t get a response, check your server’s log file for
any incoming s2s failures.</p>
    
    
    <hr>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Game Theory Patterns at Work (2016) (114 pts)]]></title>
            <link>https://daeus.blog/2026/01/18/game-theory-patterns-at-work/</link>
            <guid>46950756</guid>
            <pubDate>Mon, 09 Feb 2026 20:30:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daeus.blog/2026/01/18/game-theory-patterns-at-work/">https://daeus.blog/2026/01/18/game-theory-patterns-at-work/</a>, See on <a href="https://news.ycombinator.com/item?id=46950756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Foundations: Games, Rationality, and Traps</h2>



<p>In organizations, strategies and execution are interdependent. Outcomes depend not just on what you do, but on what others do, and what they expect you to do. <a href="https://gametheory.life/2022/07/31/what-game-theory-can-and-cannot-do/">Game theory</a> begins where individual optimization ends. While formal solutions rarely exist for real-world situations, the framework is useful for pattern recognition at work.</p>



<p><em>Chess is not a game. Chess is a well-defined form of computation. You may not be able to work out the answers, but in theory there must be a solution, a right procedure in any position. Now, real games are not like that at all. Real life is not like that. Real life consists of bluffing, of little tactics of deception, of asking yourself what is the other man going to think I mean to do. And that is what games are about in my theory.</em><br>– John von Neumann</p>



<p>I don’t really play chess, but it’s a useful metaphor. The goal is not to find the perfect move, but to avoid traps or unwinnable positions, assuming the other player is rational. The earlier you recognize those situations, the more time and energy you save. A big part of this is recognizing which game you are actually in, rather than playing blindly.</p>



<p>In most environments, I assume people are acting rationally within their constraints. The useful question becomes: what rules and incentives shape their behavior?</p>



<p>In organizations, behavior follows rewards and incentives, not intentions. Cultures can settle into stable equilibria that no one explicitly wants. Skilled leaders design mechanisms where rules drive good outcomes naturally by making consequences, good and bad, unavoidable.</p>



<p>The classic example is the <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">Prisoner’s Dilemma</a>. Two prisoners each choose to cooperate (stay silent) or defect (betray). If both cooperate, they each serve one year. If one defects while the other cooperates, the defector goes free and the cooperator serves five years. If both defect, they each serve three years. Assuming no trust or coordination, the rational choice is to defect, leaving both worse off.</p>



<p><em>The only satisfying solution to the prisoner’s dilemma is to avoid prisoner’s dilemmas.</em><em><br></em><em>– </em>William Poundstone (Prisoner’s Dilemma)</p>



<h2>Why Organizations Struggle: Local Rationality</h2>



<p>Failures often come not from bad people, but from locally rational decisions inside poorly designed games. If a system rewards optics, or complexity over impact, people adapt. Sometimes the same people change their behavior. Other times, different people rise to the top. Over time, different players learn how to win under different rules, and that becomes culture.</p>



<p>Many org conflicts are framed as values disagreements when the real issue is incentives.</p>



<h3>Promotions</h3>



<p>Without clear rules, promotions favor likeability and narrative skill over impact. Early in a startup, this is often fine (assuming reasonable execution). It does not scale. Over time, strong performers who missed early promotion windows get frustrated and leave.</p>



<p>Limited promotion slots create zero-sum dynamics, pushing teammates to compete, hoard work (e.g. take over adjacent teams’ scope), or switch teams. Leaders who encourage competition often think only about short-term achievements (‘offense’), such as moving metrics faster, and underestimate negative externalities (‘defense’), like hiding information or sabotaging peers (<a href="https://www.ted.com/talks/margaret_heffernan_forget_the_pecking_order_at_work">Superchickens Ted talk</a>).</p>



<p>Rewarding impact and quality matters more than rewarding presentation, volume, or technical complexity. Incentivizing signaled competence quickly leads to overengineering. Incentivizing ideas over execution produces a lot of smart plans that go nowhere. I have personally fallen into this trap by treating company Slack like social media.</p>



<p>The harder problem is balancing this with principled risk-taking and teamwork, where contributions are harder to measure. I still find it useful to think of each person as a small business with a cost-benefit, measured directly through impact or indirectly through what would not happen if they left. Some criteria, like visibility, are boxes to check, not things to optimize.</p>



<p>If one person brings in $1M and another presents at a conference, rewarding the latter produces more conference talks.</p>



<p>The main trap to avoid is unclear or inconsistently enforced expectations on impact (especially for folks at higher levels). Clarity can forgive a lot of sins.</p>



<h3>Firing</h3>



<p>Firing the bottom 10% systematically can incentivize peer sabotage. Like running from a bear, you don’t have to be fast, just faster than someone else. It also assumes that managers can objectively identify true low performers, and not just people that they dislike (or are convenient to fire). New hires are especially vulnerable since they lack political ties. Over time, this behavior becomes part of the culture and damages the company’s reputation.</p>



<p>At the same time, never firing people who are safe but achieve just below minimal delivery creates a coasting dynamic. For more junior levels, up-or-out policies attempt to address this by introducing time-based quotas, but disengaging can happen whenever someone gets too comfortable and stops being challenged. <a href="https://www.youtube.com/watch?v=fTjhHrcyiQI">Getting fired</a> can feel personal, even when it happens for reasons beyond interpersonal conflict. Often, though, it is simply that the role is no longer needed or the fit changed. Like a subscription, it is not that I hate you, Netflix; it’s just the show I was watching ended and I no longer want the service.</p>



<p>Every policy has tradeoffs. An ideal structure is challenging but supportive, with reasonable pruning. The most damaging traps are unclear expectations and subjective enforcement. Making internal transfers easy helps retain strong people who are simply mismatched. Some behaviors can’t be fully prevented. People from cutthroat cultures may bring those strategies with them and need time to unlearn them.</p>



<p>The same incentive problems show up most clearly at organizational boundaries, where companies interact with external markets rather than just internal teams.</p>



<h2>Hiring and Salaries: Market Games</h2>



<h3>Interviews and Hiring</h3>



<p>Unclear overall standards, inadequate career ladders and shallow interview loops can create friend networks that inflate performance signals. A simple minimax solution is role separation: hiring managers source and advocate, while capable, rotating committees evaluate with a high-level leader approval (similar to <a href="https://en.wikipedia.org/wiki/Divide_and_choose">cookie division</a>, where one person cuts and the other chooses). Hiring managers with full autonomy past a certain scale are like referees playing on the field.</p>



<p>There is currently an AI arms race in <a href="https://daeus.blog/2024/09/28/a-simple-job-application-strategy/">job applications</a>. Candidates mass-apply with AI, and recruiters screen with AI. This pushes companies back toward heavily prioritizing referrals. Take-home exercises tailored to the business can help screen out candidates who are mass applying and disengaged (<a href="https://gametheory.life/2022/04/03/recruiting-when-not-all-applicants-want-the-job/">game theory blog post</a>). One useful interview strategy comes from <a href="https://en.wikipedia.org/wiki/Secretary_problem">the secretary problem</a> or 37% rule: use the first set of candidates to calibrate, then hire the next candidate who exceeds that bar.</p>



<p>I don’t like LeetCode as a post-college SAT, but pass-fail technical screens do filter out candidates who cannot break down and solve problems in the language they will actually use, even with AI. I’ve seen data orgs without any coding or SQL screens devolve into politics as a substitute for technical skill.</p>



<p>When Square’s data science org added a Python screen, people hired after liked it. People hired before often didn’t. They were both favoring the processes that validated them. Tenured employees value tenure. New hires value credentials. Both are understandable, and neither is unbiased.</p>



<p><a href="https://developer.squareup.com/blog/revamping-data-science-interviews/">Revamping interviews</a> is also a way to clarify what a role actually needs and to quietly uplevel a discipline. Crowdsourcing structured interview questions helps keep both the bar and interviewers sharp.</p>



<h3>Salaries</h3>



<p>Matching external offers can create internal inequities. Refusing to match could tempt managers to overlevel, which erodes standards relative to the industry. Ambitious managers want to win and sometimes regret it later.</p>



<p>The best solutions I’ve seen combine signing bonuses with retention clauses, roles that offer real potential for impact and learning, and giving new hires agency alongside a strong support system (including enablement for relatively fast promotion when someone is slightly under-leveled but performs exceptionally). Training people well while accepting some will leave beats undertraining to retain. Room to grow is an important part of <a href="https://medium.com/@saumil/why-youre-paid-what-you-re-paid-five-key-tech-compensation-takeaways-59a1670036e">tech compensation</a>.</p>



<p>On the surface, these dynamics seem isolated. Over time, these interactions start shaping how teams work, what they expect, and even what they build.</p>



<h2>Roles and Products: Repeated Games</h2>



<p>People unconsciously adopt roles, such as victim, persecutor, or rescuer (<a href="https://en.wikipedia.org/wiki/Karpman_drama_triangle">Karpman drama triangle</a>). Awareness helps break these loops. Defensive reactions often recast others as attackers and justify escalation. Regular, actionable feedback reduces this. Feeling like a victim can also grant moral license to act badly, which is worth noticing in yourself.</p>



<p>Sometimes having a dedicated skeptic role in a group can improve decisions. People tolerate friction better when they know it’s intentional.</p>



<p>One surprisingly strong strategy for a repeat prisoner’s dilemma situation is a <a href="https://en.wikipedia.org/wiki/Tit_for_tat">tit-for-tat</a>. Basically ‘do no harm, take no shit’ which is a nice balance of justice and forgiveness long term.</p>



<p>Products often reflect org structure. Companies ship their org charts. Tight team coupling leads to cleaner product boundaries. Unclear ownership creates avoidance and turf wars, especially around risky legacy systems (e.g. ‘<a href="https://en.wikipedia.org/wiki/Hot_potato">hot potato</a>’ problems). Org design resembles distributed systems: balancing autonomy and coverage is hard, and incentives must match temperament.</p>



<p>Data teams sit at an uncomfortable intersection of these games, exposed to both agenda power and technical authority.</p>



<h2>Data Organizations</h2>



<div><p><em>Rick’s the right guy to evaluate the risk. He’s not the right guy to stand down the guys who want their deals done, they’d ram it down his throat.<br></em>– The Smartest Guys in the Room by Bethany McLean and Peter Elkind</p><p>Data teams need independence to stay objective and proximity to stay relevant. Under engineering, they risk becoming technically correct but not empowered or even irrelevant. Engineering leaders respect systems shipped, latency reduced, and reliability improved. They can easily under-index on counterfactual insights, strategic opportunity sizing, and recommendations on what to build. On the other hand, under business, data teams can become a decision-making function and help set the strategy early on. They can help shape strategy, prioritization, and achieve narrative ownership. However, in such a setup, they risk being more biased without guardrails. It is easier for me to tell a stakeholder their idea failed than my manager.</p></div>



<p>A good overall model achieves ‘dual alignment’, where data teams are centralized under a single strong leader with company-wide leadership influence and credible technical knowledge in at least one data domain. There could be dotted line structures into engineering in order to be closer to production pathways and infrastructure. Engineering has technical power but business has <em>agenda</em> power.</p>



<h2>Metrics</h2>



<p>For analysis, the game is speed versus accuracy. My solution is habit-building: knowledge checkpoints, early feedback, and stable reference metrics. Over time, this creates a set of facts I can move quickly with. I usually find a solid, generally accepted premise is more important than dressing or perfect logic.</p>



<p>Choosing the right success metric, especially in a broad <a href="https://developer.squareup.com/blog/ecosystem-success-metrics/">ecosystem</a>, is difficult. Metrics obey <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s Law</a>: when a measure becomes a target, it ceases to be a good measure. For example, optimizing conversion rates in a vacuum can lead to increased friction for low-intent users. Reducing friction to enable growth increases volume but lowers conversion and can sometimes lead to higher fraud losses. The real game becomes customer identification, which is difficult, but not zero-sum.</p>



<p>Putting out fires, such as bug fixes, versus prevention is a <a href="https://en.wikipedia.org/wiki/Stag_hunt">stag hunt</a> problem. In a stag hunt, everyone is better off cooperating on a high-value outcome, but each individual is tempted to chase a smaller, guaranteed win. Bugs are visible and rewarded (<a href="https://dev.to/baweaver/beyond-senior-fire-fire-1477">blog post</a>). Prevention is silent. Without clarity, people rationally pursue short-term fixes over long-term platform health.</p>



<h2>Leadership and Power</h2>



<p><em>In peacetime, leaders must maximize and broaden the current opportunity… In wartime, by contrast, the company typically has a single bullet in the chamber and must, at all costs, hit the target. </em><em><br></em>– Ben Horowitz (The Hard thing about Hard Things)</p>



<p>In peacetime, leaders still need to stay grounded in business impact. Otherwise, they drift toward employee satisfaction as the primary signal of success. Those metrics often move with company performance rather than leadership quality, especially in public companies where compensation is tied to stock. Managers who see their role as keeping their team happy will struggle to challenge them or adapt as conditions change. A successful leader must ask at the start of each day: How can we do more to improve delivering positive impact for our customers?</p>



<p>Once, when I was struggling with my manager, I asked a department head for help moving roles. They said they couldn’t create one for me. That clarified something for me: leaders have to operate on principles, not favors. It helps to ask what a company would look like if everyone worked this way. Favor-based help creates dependence and slowly erodes meritocracy. I have seen managers defend someone during layoffs only for both to be cut later because they became a package deal.</p>



<p>Leaders generally need to support and enable their managers unless there is clear evidence of poor performance. Patterns outweigh anecdotes. Reduced team impact and productivity is often a more reliable signal of problems than individual complaints (or even turnovers).</p>



<p>Ambitious middle managers often expand scope through headcount to advance. This is sometimes labeled ’empire building’, but it is usually a rational response to the incentives in place. Left unchecked, it can balloon orgs without increasing impact. Measuring impact per headcount or treating orgs like businesses with an ROI helps constrain this. Setting clear OKRs at each team / org level and enabling regular business reviews that track progress can also be effective. Platform teams are harder to evaluate, but can be approximated by comparing alternative vendor costs, volume processed, or outcomes in a world where the team does not exist. Managing orgs at scale starts to resemble portfolio management.</p>



<p>Opening new opportunities reduces zero-sum pressure between strong leaders. This is why the skill of creating new surface area is so valuable when properly harnessed. When things feel stuck but you want to stay, it can be more productive to open a new business line that can fund itself, much like a startup. The constraint is staying grounded in real customer value, not just winning by getting funded (<a href="https://paulgraham.com/lesson.html">Paul graham article</a>).</p>



<h2>Solutions: Designing Better Games</h2>



<p>Recognizing zero-sum games and finding ways out of them is one of the most valuable skills in an organization. In <a href="https://developer.squareup.com/blog/ecosystem-success-metrics/">product ecosystem</a> shared spaces, this often means bundling and complementing products rather than letting teams compete internally.</p>



<p>People need skin in the game and proximity to the consequences of their decisions. Clear rules applied consistently matter more than perfect judgment. Clarity, humility, and effort can forgive many mistakes.</p>



<p>If I could avoid one trap, it would be unclear hiring standards, which let unproductive but likeable hires slip through. Closely related is the lack of objective leveling and promotion criteria that tie rewards directly to impact rather than visibility or competency signaling. At the team level, regularly showcasing good work helps prevent strong contributors from quietly building resentment when their efforts go unseen.</p>



<p>Optimize for the game actually being played. Growth requires different behavior than reliability. Local maxima strategies, like short-term cutthroat moves, may feel like success to some but prevent reaching a global maximum. Reaching a global maximum requires more fair play and everyone rowing the same way toward real impact. Not everyone is rational, but incentives compound. Companies can outgrow their problems for a while, but they surface eventually. A simple check is to ask how things would turn out if everyone acted the same way.</p>



<p>Thanks <a href="https://www.linkedin.com/in/robjwang/">Rob Wang</a> for helping with review!</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MIT Living Wage Calculator (199 pts)]]></title>
            <link>https://livingwage.mit.edu/</link>
            <guid>46950152</guid>
            <pubDate>Mon, 09 Feb 2026 19:50:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://livingwage.mit.edu/">https://livingwage.mit.edu/</a>, See on <a href="https://news.ycombinator.com/item?id=46950152">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>
        <b>WHAT IS THE LIVING WAGE CALCULATOR?</b><br>
        Today, families and individuals working in low-wage jobs make too little income to meet minimum standards of living in their community. We developed the Living Wage Calculator to help individuals, communities, employers, and others estimate the local wage rate that a full-time worker requires to cover the costs of their family’s basic needs where they live. Explore the <strong>living wage</strong> in your county, metro area, or state for 12 different family types below. The data was last updated on February 10, 2025.
      </p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Is Not an Acceptable Choice for Free Software Projects (2020) (119 pts)]]></title>
            <link>https://sneak.berlin/20200220/discord-is-not-an-acceptable-choice-for-free-software-projects/</link>
            <guid>46949669</guid>
            <pubDate>Mon, 09 Feb 2026 19:20:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sneak.berlin/20200220/discord-is-not-an-acceptable-choice-for-free-software-projects/">https://sneak.berlin/20200220/discord-is-not-an-acceptable-choice-for-free-software-projects/</a>, See on <a href="https://news.ycombinator.com/item?id=46949669">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="blogpagearticlecontent"> <p>It’s simple: free software projects <em>should not</em> use Discord. (This goes equally for any sort of public interest group.) Here’s why.</p> <p><em>TL;DR: Standardizing on communications tools like Discord discriminates against and excludes everyone who, either for physical safety reasons, or personal preferences, cannot give up their privacy to participate, due to its demands for personally identifiable information like IP address, location, and phone number.</em></p> <p>Update, 2020-06-04: It would appear that the repugnant yet well-known human known as rms <a href="https://stallman.org/discord.html">has some similar thoughts on the matter</a>.</p> <h2 id="technical-reasons">Technical Reasons</h2> <h3 id="total-lack-of-privacy">Total Lack of Privacy</h3> <p>Discord reads, logs, and can censor your “private”, 1-to-1 messages:</p> <p><img src="https://sneak.berlin/s/2020/20200218.discord/dm-scan.png" alt="screenshot of discord DM filtering options in app settings"></p> <p>Discord’s communication is not end to end (e2e) encrypted. It is encrypted only between the individual user and the servers operated by Discord Inc. Their spying extends to every single message sent and received by anyone, <em>including direct messages betweeen users</em>. The service can and does log every message sent, both in-channel and DMs. <strong>It is impossible to have a private conversation on Discord</strong>, as there will always be an unencrypted log of it stored by Discord. Discord can, at their option, provide those stored messages to <em>any third party they wish</em>, <strong>including cops or government snoops</strong>, for any reason, even without a legal order, without any obligation to tell you that they have done so.</p> <p>You should not use services that can <a href="https://www.mic.com/articles/86797/8-ways-we-regularly-commit-felonies-without-realizing-it">rat on you and your friends to the cops</a>.</p> <p><small> Unrelated to this article: in general, for private messaging, you should <a href="https://signal.org/">use Signal</a>. </small></p> <h3 id="spying">Spying</h3> <p>Discord is spyware, silently logging and tracking every action performed within their app, without once asking the user if they consent or not:</p> <p><img src="https://sneak.berlin/s/2020/20200218.discord/tracking.png" alt="screenshot of discord activity tracking options in app settings"></p> <p>It cannot be used simply as a communications tool without also incurring surveillance of your usage. Every time you interact with Discord (outside of Tor) it reveals your approximate location (via IP geolocation) for permanent storage.</p>  <p>Privacy is a human right.</p> <p>Use of Discord by a group discriminates almost totally against those who prefer or, due to circumstance, require privacy for their own personal information, such as IP or related geolocation. You <em>cannot sign up for Discord anonymously</em>.</p> <p>(IPs are absolutely personally identifiable information, despite what the GDPR carves out. Your IP indicates your approximate physical location.)</p> <p>Attempting to sign up for Discord anonymously via Tor will demand from you first as many as 30(!) <a href="https://en.wikipedia.org/wiki/CAPTCHA">CAPTCHAs</a>, and, if you can get through those (which is sometimes impossible, read on), it will then demand a telephone number from you for SMS verification.</p> <p>Telephone numbers deanonymize you. Not many realize this, but a telephone number is <em>one</em> instant, low-cost API call to a data broker away from your name, physical address, associated/other email addresses, date of birth, et c. The US has no meaningful privacy or data protection laws. You may think I’m exaggerating, but if you live in the US, right this moment, <em>dozens</em> of companies with whom you do business have <em>already</em> provided data brokers with the complete set of your name, phone number, email address, and street address. These lookups are commonly for sale by API and used by <em>many</em> other companies to detect potential fraud, spam risks, et c.</p> <p>Phone numbers are a simple lookup identifier to <em>all</em> of your commonly used personal information. That’s why everyone asks you for them! It’s not to call you. The same goes for your email address.</p> <p>Additionally, the <a href="https://www.zdnet.com/article/us-cell-carriers-selling-access-to-real-time-location-data/">mobile operators in the US have been selling access to phone handset location data</a> (collected from the towers, and unblockable) to thousands of people for many years. It’s so bad, even the <a href="https://arstechnica.com/tech-policy/2020/01/ajit-pai-carrier-sales-of-phone-location-data-is-illegal-fcc-plans-punishment/">FCC has gotten involved</a>. Providing your telephone number to a service is, from a privacy standpoint, the exact same as showing them your government ID and sharing your physical location.</p> <p>Another 30 or so CAPTCHAs await you during the email verification link step, if you can get past the SMS part (say, with a burner number).</p> <p>…and then again on each and every login. It takes more than a few minutes, every time, to log in, even after having given them a phone number.</p> <p>…except that, sometimes, you can’t even log in at all, because the Google CAPTCHA they make users accessing via Tor fill out <em>on every single login</em> just gives up and tells the user to fuck off:</p> <p><img src="https://sneak.berlin/s/2020/20200218.discord/captcha-denied.png" alt="captcha impossible to complete"></p> <p>This excludes many people from your group by <em>discriminating</em> against those who insist on their human right to privacy. Don’t immediately dismiss this as some esoteric interest: <em>many</em> people have legitimate, non-paranoid privacy requirements different from the mainstream, for many different reasons that may not be immediately obvious to someone without such specific circumstances: examples include being targets of public harassment campaigns, stalkers, internet rage mobs, creepy or violent ex-partners, et c. But, even people not subject to those threats, who simply prefer not to have their activities tracked also deserve their privacy if they wish it. Remember: <em>privacy is a human right</em>.</p> <p>Not everyone can afford to out themselves in every group in which they participate! Some may be subject to retaliation, harassment, or even physical violence for doing so. Pretending that everyone can choose to do so safely or that it’s not a big deal to give up your identity information is simply rude and inconsiderate to those people.</p> <p>Critically, this issue may end up practically excluding some of the most <em>essential and valuable potential participants</em>. People who are rich, famous, or both are well acquainted with how essential personal privacy can be when you’re in the public eye. <a href="https://tim.blog/2020/02/02/reasons-to-not-become-famous/">Tim Ferriss published a pretty complete list earlier this month</a> of the negative consequences he’s had to deal with and the cumbersome privacy steps he’s had to take to ensure the physical safety of himself and those close to him—all because he’s only somewhat famous. Multiply that by ten to see what Actual Famous People are used to dealing with.</p> <p>Most projects can benefit from additional resources, reach, or publicity. The kinds of people who can champion your team or your project to millions of people will frequently <em>not participate at all</em> if doing so <em>requires</em> that they expose private information about themselves. By de-facto excluding all such people on privacy grounds through the use of Discord, you lose any benefits, financial, social, or otherwise, that they might have brought to the table for your project or group.</p> <p>When you endorse and support services that deny people even the <em>possibility</em> of privacy, <em>you are choosing to hard-exclude all of these types of people</em> from your group, whether you realize it or not. Worse yet, they won’t even tell you when they nope out of your webpage and bounce. (That’s actually why this post exists.)</p> <p>Please don’t engage in this type of discrimination by using Discord.</p> <h2 id="moral-reasons">Moral Reasons</h2> <p>This type of access-based gatekeeping performed by Discord, regardless of motivation (don’t assume malice: it’s likely primarily motivated by an effort to keep the experience of most users up by erring on the side of over-blocking any user account that might send spam or unwanted messages), is accurately and objectively described by a word: <code>censorship</code>.</p> <p>Many people in the free software movement find censorship in general to be abhorrent. (That’s one very good reason, for example, why emails you receive that might be spam go into a special folder, instead of being silently deleted without you having a option to choose to see them if you wish. Your email server could just delete them! The fact that it doesn’t was a <em>deliberate design choice</em> to avoid censorship.)</p> <p><a href="https://en.wikipedia.org/wiki/John_Gilmore_(activist)">John Gilmore</a>, one of the founders of the <a href="https://en.wikipedia.org/wiki/Electronic_Frontier_Foundation">EFF</a>, once famously wrote, <em>“The ‘net interprets censorship as damage and routes around it.”</em> I am encouraging you to recognize this particular damage, and route around it by avoiding any use of Discord. If you see teams using it, please link them to this page.</p> <p><small> (Please don’t email me about how Discord can do what Discord wants, including engage in censorship, on Discord’s own servers. Of course they can. It’s still censorship, and I can still say (on my own servers) that Discord’s censorship is dumb, discriminatory, and harmful.) </small></p> <h2 id="legal-reasons">Legal Reasons</h2> <p>Using Discord, even as a free user, requires agreement with their <a href="https://discordapp.com/terms">Terms Of Service</a>. Regardless of the actual contents of their ToS, this excludes anyone for whom such agreement is unacceptable, impractical, or impossible from participating as an equal in your group.</p> <p>Now let’s talk about the actual contents of the ToS. Here’s an excerpt:</p> <blockquote> <p>As an example, you agree not to use the Service in order to:</p> </blockquote> <blockquote> <p>defame, libel, ridicule, mock, stalk, threaten, harass, intimidate or abuse anyone;</p> </blockquote> <p>Regardless of whether or not you are the kind of person who mocks or ridicules people—you should <em>be able to use your communications tools to mock and ridicule people, if you so wish</em>. These are normal, acceptable things to do in society.</p> <p>The point of bringing this up is not that you should tolerate these things in your group. The point is that the place to deal with these is in your group’s own culture and internal rules, not a legal agreement that everyone is forced to be bound by simply to participate.</p> <p>This is unreasonable not because we want our groups to be filled with mocking of other people. This is unreasonable because, Discord’s ToS, as written, prohibits, for example, the sending of political cartoons in DMs.</p> <p>Fuck censorship.</p> <p>Another nugget from the ToS:</p> <blockquote> <p>Notwithstanding the foregoing, disputes concerning patents, copyrights, moral rights, trademarks, and trade secrets and claims of piracy or unauthorized use of the Site shall not be subject to arbitration, and the notice and good faith negotiation required by this paragraph shall not apply to these types of disputes.</p> </blockquote> <blockquote> <p>Binding Arbitration. Except as provided herein, if we cannot resolve a dispute informally, any dispute will be resolved only by binding arbitration to be held in the U.S. state in which you reside. For residents outside the United States, arbitration shall be initiated in San Francisco, California. Discord and you further agree to submit to the personal jurisdiction of any state or federal court in San Francisco, California to compel arbitration, stay proceedings pending arbitration, or to confirm, modify, vacate, or enter judgment on the award entered by the arbitrator.</p> </blockquote> <p>To even use Discord, you must waive your right to sue them for any reason outside of patents, copyrights, trademarks, et c (they put this clause in so that they can always still sue you in real court over these matters, if they ever want to).</p> <p>If at some time in the future Discord decides to destroy your team or business by an unjust suspension, or fucks up and, via their own negligence gets hacked and leaks their user database with phone numbers, or has a rogue sysadmin who doxxes you or spies on your DMs specifically and forces you to have to move, or ships faulty software that bricks your computer or leaks (even more) data from your phone, or damages you or your team or business in any other way that might happen, you have no recourse other than binding arbitration, critically, <em>a process outside of a normal court of law</em>.</p> <p>There is an opt-out provision (which is more like <em>opt-in</em> to maintaining your basic civil rights to sue for damages) in their ToS, but if your account is older than 90 days and you didn’t email them specifically about opting out of mandatory arbitration, you are, per their <a href="https://sneak.berlin/20200210/quora/">abusive</a> ToS, deemed to have agreed to give up your right to lawsuits and be bound by the agreement to arbitrate, even if you did nothing other than sign up for the service to chat with people.</p> <p>There is also another provision where you waive your right to sue them as part of a class action, in the event that they fuck over a whole bunch of people in the future somehow (remember <a href="https://en.wikipedia.org/wiki/2017_Equifax_data_breach">Equifax</a>?). That part has no opt-out, and extends forever, even after you delete your account or stop using Discord. Anyone who has ever used Discord is presumed by Discord to have agreed to this and cannot ever sue them in a class action.</p> <p>This is nonsense, and you should never demand that your users agree to such abusive terms simply to participate in your team or group on equal footing.</p> <h2 id="philosophical-reasons">Philosophical Reasons</h2> <p>Discord is proprietary, non-free software, held closely by a for-profit company. How you personally feel about this is dependent upon your own philosophical views, but, objectively, it is not very consistent with the ideals of most groups dedicated to free software or open collaboration to produce and improve free software.</p> <p>It seems <em>to me</em> inappropriate for an organization that believes in free software to choose proprietary and privacy-disrespecting tools when free and private alternatives are readily available and can be hosted very inexpensively.</p> <p>Additionally, free software-adjacent teams and groups, such as hackerspaces, art camps, and other DIY undertakings should always question falling by default onto the “buy” side of “build vs. buy”. DIY or die! Run your own!</p> <p>Remember: <em>A Jedi builds her own lightsaber.</em></p> <h2 id="what-to-use-instead">What To Use Instead</h2> <p>There are some great alternatives. I’m not going to tell you to go use IRC like some cranky old Thinkpad-toting unixbeard who doesn’t recognize that mobile apps are a hard requirement for meaningful social collaboration these days. IRC is a total nonstarter for this use case for many reasons which have been written about before.</p> <p><small> If you have done so in the past, please stop recommending IRC as a replacement for Slack and Discord. It’s absolutely not. IRC is great, but it is not simply “open source Slack” (that’s <a href="https://mattermost.com/">Mattermost</a>). They are both chat systems, but they are <em>different tools for different jobs.</em> I love IRC, but it’s simply <em>not a useful tool for most groups</em>. </small></p> <p>There’s no one single free/self-hostable alternative that has the exact same level of polish and all of the features of Discord, but there are some that come close all of the <em>important</em> functionality. Presuming that you don’t use the voice chat much or often, and simply want an asynchronous chat system (with DMs) that supports multi-client, including web and mobile apps, there are several workable options.</p> <p>You’ll likely want to use a combination of tools, as follows.</p> <h2 id="replacement-for-announcements-email">Replacement for Announcements: Email</h2> <p><img src="https://sneak.berlin/s/2020/20200218.discord/mailchimp-ui.png" alt="email list administration UI"></p> <p>Email is underrated.</p> <p>First of all, you should not let any single organization or tool intermediate your communication with your community or group, lest they attempt to rent-seek and charge you for access to your own social graph (like Facebook and Instagram have made a multibillion-dollar business doing). The first and best line of communication with your group should always be email.</p> <p>Make an email list <em>for use by group organizers</em>, and make sure everyone is subscribed to it. Collect email addresses as an essential part of signup in your group, and direct privacy-sensitive users to one of <a href="https://protonmail.com/tor">several</a> <a href="https://cock.li/">free</a> anonymous email services if they need one. If nothing else, you can email everyone once or twice per year with a set of links to whatever tools or resources for chat/discussion are currently being provided to the group for its use. Everyone has an email address, and several services are available for people who desire privacy to obtain anonymous email addresses that they can use for free and access in ways that preserve their privacy.</p> <p>Additionally, as an organizer or admin, there are many vendors that can cheaply provide this email list hosting service to you, and you can then periodically download the list of email subscribers to your own computer for backup, making you independent of any one service. As long as you have direct email contact information for your group members, you cannot be censored or shut down by any single provider. If they decide to raise prices on you (<a href="https://www.theverge.com/2019/10/15/20893343/meetup-users-furious-new-rsvp-payment-test">e.g. Meetup</a> or <a href="https://news.ycombinator.com/item?id=22192543">e.g. Mailgun</a>) you can always take your downloaded list to another service or even run your own mail server in a pinch. You can thus <em>always</em> communicate things to your membership directly if you have their email addresses.</p> <p>Set up two email lists:</p> <p>One, an email announcement list (<code>ORGNAME-ANNOUNCE</code>) , to which <em>everyone</em> in the group is subscribed, to which only management/senior group members can post. This should ideally send a message no more often than about once per month, so that people aren’t tempted to ignore or filter them, or wish to be unsubscribed.</p> <p>For the <code>-ANNOUNCE</code> list, use a standard footer at the bottom of <em>every message</em> sent to this list that includes <em>all of the following</em>:</p> <ul> <li>a link to the project’s webpage</li> <li>a link to the project’s repository hosting</li> <li>a link to the project’s documentation site</li> <li>links to the project’s chat/discussion spaces</li> <li>links to any other public social media accounts</li> <li>the names and email addresses and titles/roles of 2-4 people in charge so that everyone always has a direct communications channel to organization management</li> </ul> <p>Keeping this list’s traffic to a <em>maximum</em> of about 6 emails total <em>per year</em> (excepting special events) is ideal.</p> <p>Two, an email discussion list (<code>ORGNAME-DISCUSS</code>), to which everyone is initially subscribed (with a welcome message that explains to them how to unsubscribe if they wish), for discussion, that lets all subscribed members post. <em>Skip setting up this list if you end up using Discourse for web-based bbs/forum discussion functionality</em> (see below), as most people these days will probably prefer using the shiny Discourse web interface over email threads.</p> <h2 id="replacement-for-real-time-chat-mattermost">Replacement for Real-Time Chat: Mattermost</h2> <p><img src="https://sneak.berlin/s/2020/20200218.discord/mattermost-ui.png" alt="mattermost UI"></p> <ul> <li>License: <a href="https://opensource.org/licenses/AGPL-3.0">AGPL</a> (source) / <a href="https://opensource.org/licenses/MIT">MIT</a> (binaries)</li> <li>Repository: <a href="https://github.com/mattermost/mattermost-server">https://github.com/mattermost/mattermost-server</a></li> <li>Website: <a href="https://mattermost.com/">https://mattermost.com/</a></li> </ul> <p><a href="https://mattermost.com/">Mattermost</a> is a free software web application (written in Go and React) that replaces the text-chat functionality of censored/surveillance systems like Slack and Discord. It’s web-based, and there are native client applications for mobile (Android and iOS) and desktop (Windows, macOS, and Linux).</p> <p>You can self-host Mattermost in a very straightforward fashion. The resource requirements are modest for installations with fewer than a few hundred users. Using free Let’s Encrypt certificates, it is possible for most small and medium-sized teams to have their own private Mattermost installation for under $5 per month. Like Slack, it has a lot of integrations that you can use to hook it up to external services and events like webhooks. Unlike Slack, it will keep your user data private, and keep private communications within your group.</p> <h2 id="replacement-for-threaded-asynchronous-discussion-discourse">Replacement for Threaded, Asynchronous Discussion: Discourse</h2> <p><img src="https://sneak.berlin/s/2020/20200218.discord/discourse-ui.png" alt="discourse UI"></p> <ul> <li>License: <a href="https://opensource.org/licenses/gpl-license">GPL</a></li> <li>Repository: <a href="https://github.com/discourse/discourse">https://github.com/discourse/discourse</a></li> <li>Website: <a href="https://www.discourse.org/">https://www.discourse.org/</a></li> </ul> <p>Confusing name, I know. I’m now talking about <a href="https://www.discourse.org/">Discourse</a>, a piece of free software that you can run yourself to host BBS-style forums.</p> <p>Disco<em>rd</em> doesn’t really do threaded/forum style communications, but if you’re using it for chat, such an organized permanent record may actually be an upgrade or enhancement for your team.</p> <p>If you’re looking for a way of getting announcements out to your group and fostering discussions, look into Disco<em>urse</em>, which is much better for discussion than linear, messy chat. It also has native mobile apps that work as clients, although they’re very minimal and don’t deliver notifications for self-hosted instances (which Discourse should get on fixing).</p> <p>It supports emailing people notifications of their @-mentions, digests of new threads and activity so that people can catch up with what they’ve missed (all of which can be configured per-user, of course), and several different nice visual themes. It even comes with a nifty little tutorial walkthrough for first time users who join to teach them the basics of using it. It’s great!</p> <p>It’s also generally more useful for the majority of busy people who don’t necessarily do much real-time chat, as it’s focused for more asynchronous, organized thread-based discussions. It’s much more organized than scrolling through the backlog of a bunch of different channels, as each board and thread has a name and topic, as is standard for forum/BBS software.</p> <h2 id="replacement-for-voice-chat-mumble">Replacement for Voice Chat: Mumble</h2> <ul> <li>License: <a href="https://opensource.org/licenses/BSD-3-Clause">3-Clause BSD</a></li> <li>Repository: <a href="https://github.com/mumble-voip/mumble">https://github.com/mumble-voip/mumble</a></li> <li>Website: <a href="https://www.mumble.info/">https://www.mumble.info/</a></li> </ul> <p>I imagine most teams will skip this step, as I don’t think voice chat is very heavily used. However, if it is, Mumble is a great free software alternative. It works great, and has polished native desktop and mobile apps.</p> <h2 id="optionally-tor">Optionally: Tor</h2> <ul> <li>Website: <a href="https://www.torproject.org/">https://www.torproject.org/</a></li> </ul> <p>All of the web-based replacement services can also be set up to be made available as a hidden service via Tor, also known as an “.onion address”. If you’re not overburdened by admin tasks, you should <a href="https://2019.www.torproject.org/docs/tor-onion-service.html.en">set this up</a>!</p> <p>The nice thing about using a hidden service is that the communication between your users and your server happens entirely within the Tor network, so neither the user nor the server can learn the location or metadata of the other via the network. It also works behind a firewall, in the event you wish to make the hidden service the primary/only method of accessing your web application (not generally recommended, as this will break connectivity for anyone using the mobile apps).</p> <h2 id="offer-of-assistance">Offer Of Assistance</h2> <p>I know that self-hosting things can seem daunting, considering how point-and-click easy it is to use hosted services. It’s a lot easier than most people think due to some <a href="https://hub.docker.com/">new technologies</a> that have become production-ready in the last few years. It’s simply not that difficult anymore. Tools like <a href="https://caprover.com/">CapRover</a> <em>almost</em> make it a non-technical endeavor.</p> <p>I sincerely hope that after reading the above you’ll re-consider self-hosting your project’s own communications infrastructure for privacy reasons. If you end up going this route, I have ~23 years of experience self-hosting communications tools (I founded <code>datavibe.net</code>, a UNIX freenet, in 1997 and operated it for two decades) and am happy to help you in whatever ways I can. Feel free to drop me a line via <a href="mailto:sneak@sneak.berlin">email</a> or <a href="tel:+13123610355">on Signal</a> if you need help, and I’ll do my best to sort you out.</p> <h2 id="edit-update">EDIT: Update!</h2> <p>A few minutes after publishing this post, I solved the requisite 60 CAPTCHAs, created a new Discord account with a disposable phone number that cost me €5, and joined a Discord chat for a project I participate in.</p> <p>I sent the link to this post, via DM only, to three of the admins with a short note. Not 10, not 100, not a random project: <em>three</em> of the admins of a project <em>in which I am already a participant</em>.</p> <p>Within 60 seconds of linking these users to my own webpage, Discord deleted my account.</p> <p>No third-party service should be in a position to be deciding for you what your group membership should be allowed to communicate with each other.</p> <p>Do not tolerate this sort of censorship within your community.</p> <p><img src="https://sneak.berlin/s/2020/20200218.discord/censorship.png" alt="discord censors me"></p> <p><small> Note that I was not flagged by any user; this was an automated censorship of DMs by Discord simply because I was sending messages containing links to my other team members. </small></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Luce: First Electric Ferrari (248 pts)]]></title>
            <link>https://www.ferrari.com/en-US/auto/ferrari-luce</link>
            <guid>46949642</guid>
            <pubDate>Mon, 09 Feb 2026 19:19:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ferrari.com/en-US/auto/ferrari-luce">https://www.ferrari.com/en-US/auto/ferrari-luce</a>, See on <a href="https://news.ycombinator.com/item?id=46949642">Hacker News</a></p>
Couldn't get https://www.ferrari.com/en-US/auto/ferrari-luce: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Alternatives, Ranked (443 pts)]]></title>
            <link>https://taggart-tech.com/discord-alternatives/</link>
            <guid>46949564</guid>
            <pubDate>Mon, 09 Feb 2026 19:15:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taggart-tech.com/discord-alternatives/">https://taggart-tech.com/discord-alternatives/</a>, See on <a href="https://news.ycombinator.com/item?id=46949564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>I've been running a <a href="https://discord.gg/taggartinstitute">Discord server</a> for about four and a half years now. When I started streaming during the pando, I had no idea that I would end up building a community. Hell, I'd never even used Discord before. I only knew what it was because I had to stop my students from using it.</p>
<blockquote>
<p>Don't like reading? Click <a href="https://taggart-tech.com/discord-alternatives/#score-breakdown">here</a> for the final scores.</p>
</blockquote>
<p>But folks kept asking for one. My viewers expected a community hub in which people who found their way to my Twitch streams could find each other, even when I was not live. As the whole streaming thing was itself an experiment in remote learning for me, this seemed a natural extension. So now, I have some mileage on me as a community moderator. I'm intimately familiar with the features Discord offers, and all the arguments against using it. I'm sensitive to them, FOSS dork that I am. I'm also keenly sensitive to the arguments about data loss inside of a forever-chat. In fact, I'm so sensitive to it that I even tried to <a href="https://github.com/The-Taggart-Institute/archivist">address the problem</a> in some small way.</p>
<p>But Discord, like all freemium services, is a risk. At any moment their advertising model could become intolerable, or their policy about using my data to train AI could change, or their pricing could get out of control, or some other rent-seeking nonsense common to internet services trying to stretch their profit margin.</p>
<p>I need an exit strategy. Anyone using Discord needs an exit strategy. The trick is to find a landing spot that users will tolerate, and that allows the community to continue in some fashion. Change is loss, and that is excruciatingly true for community platforms. Any switch comes with an attrition rate, meaning the destination better be worth the cost in headcount.</p>
<p>For this reason, and for another project, I've been deeply researching Discord alternatives for the better part of a year. Some of my colleagues may think me a bit obsessed about the importance of a "chat app," but I'm convinced that the communication mechanism for online communities is critical to their success. Choosing a new one could be the a matter of life and death for the community. This is a decision we have to get right the first time.</p>
<p>So here, humbly submitted, are my rankings of many of the Discord-like alternatives for maintaining online communities.</p>
<h2 id="evaluation-criteria">Evaluation Criteria</h2>
<p>I've arrived at five broad categories in which an online community platform needs to perform.</p>
<p><strong>Functionality:</strong> can it do everything required of a platform for building, organizing, and sustaining a community?</p>
<p><strong>Openness:</strong> what access is there to all the tool's features and code without payment?</p>
<p><strong>Security:</strong> how secure are the server and user data against common threats?</p>
<p><strong>Safety:</strong> what features are available to moderate the community and protect it from malicious or unwanted behavior?</p>
<p><strong>Decentralization:</strong> how reliant is the service on single points of failure?</p>
<p>These will be evaluated on a scale from 1-5, with 5 being the "best" for each criterion.</p>
<p>I've done my best to consider multiple use cases and threat models in these scores. I am, however, a flawed, biased meatsack with limited visibility. I may not have predicted your needs precisely. I may have omitted your favorite option. If so, I hope you'll afford me some grace. I did the best I could.</p>
<p>Oh, and I'm not touching Slack or Teams. Reasons should be obvious.</p>
<p>We'll start with Discord as a baseline.</p>
<h2 id="discord">Discord</h2>
<ul>
<li><strong>Functionality:</strong> 4</li>
<li><strong>Openness:</strong> 1</li>
<li><strong>Security:</strong> 3</li>
<li><strong>Safety:</strong> 4</li>
<li><strong>Decentralization:</strong> 1</li>
</ul>
<p>As a product, Discord is very, very good. It serves its purpose with an absolutely minimum of friction—both from a user and administrator perspective. Even without paying, the features out of the box are well-considered and helpfully implemented. What <em>is</em> the product, anyway? Sometimes it seems like Discord themselves don't really know. While they bristle at being called a "Slack clone," there's a reason many companies (especially tech startups) choose Discord as both their internal team communication tool, as well as their customer engagement tool. Some truly benighted groups even choose to document their product with it.</p>
<p>Whatever Discord thinks it is, the purpose of a system is what it does, and Discord builds online communities. Say what you want about the company, the closed nature, the increasingly-icky ad model, the core of Discord continues to work well for bringing people together in quasi-public online spaces. The medium of real-time text, aka instant messaging, aka IRC-again-but-not-IRC, has become a default, but one not without limitations. For example, what does this do to your heart rate:</p>
<p><code>Several people are typing...</code></p>
<p>Right?! We've embraced immediacy at the expense of depth. Also, in Discord's case, accessibility. Searching Discord is a proper disaster. While messages are more or less permanent, it is by no means easy to find them again, weeks/months/years later.</p>
<p>But let's get into the criteria before this becomes a treatise on the nature of the modern web.</p>
<p>As mentioned, Discord is highly functional—for what it does. But its limitations do start to grate as time goes on. Online communities have a predictable lifecycle, in which the excitement of the early days is well-served by real-time chat. The memes are flying; people are excited to meet each other; the future holds boundless possibilities. The space will categorize and fragment, trying to organize the chaos. Over time, most of the messages come from a core group of contributors, with more occasional arrivals and questions from newcomers. This is as it should be. But what happens to the history of that community as it heads up the scroll? How does the past usefully inform the future?</p>
<p>Discord has made some affordances for this with "Forum" type channels. Even so, the past is hard to explore.</p>
<p>Discord is not open, so not much to say on that front.</p>
<p>Discord messages are not end-to-end encrypted. Pretty famously, Discord will <a href="https://www.pbs.org/wgbh/frontline/article/jack-teixeira-guilty-plea-discord-leaks-national-security/">give up</a> your data for law enforcement. Although they've recently added <a href="https://support.discord.com/hc/en-us/articles/25968222946071-End-to-End-Encryption-for-Audio-and-Video">end-to-end encryption for video and audio</a>, the implementation is clunky. And of course, all the text data in a Discord server is unencrypted. But hey, at least they support MFA?</p>
<p>Safety, in the sense of "Trust and Safety," may be Discord's greatest strength. I have greatly appreciated all the moderation tools at my disposal. Even a modestly sized server like mine (~3000 users) would be impossible to manage without automatic word catching, granular permissions on channels and roles, and multiple response options including timeouts, kicks, and bans. Discord also has a very involved onboarding flow that makes certain there is an agreement to community rules before users can participate.</p>
<p>And need we even mention decentralization here? If Discord fails, your community goes dark.</p>
<h2 id="signal">Signal</h2>
<p><a href="https://signal.org/">https://signal.org</a></p>
<ul>
<li><strong>Functionality:</strong> 2</li>
<li><strong>Openness:</strong> 4</li>
<li><strong>Security:</strong> 5</li>
<li><strong>Safety:</strong> 2</li>
<li><strong>Decentralization:</strong> 1</li>
</ul>
<p><strong>Best for:</strong> communities who value secrecy above all.</p>
<p>I love <a href="https://signal.org/">Signal</a>. Like, a lot. I'm a daily user and a donor. I've even convinced most of my friends and family to use it as our primary mode of text communication. And yes, I've organized a community with it—one for which privacy was (at the time) of paramount importance. I am deeply familiar with all advantages and drawbacks of Signal.</p>
<p>As a secure chat, Signal does just fine. Well, better than fine from a cryptography perspective. It is the gold standard in end-to-end encrypted communications for good reason. But the strongest cryptography in the world is meaningless for a community if the platform is unusable. Fortunately, that's not the case for Signal. Emoji reactions, stickers, (some) formatted text, and even voice/video calls make it an indispensable tool for secure communications that feel familiar and feature-filled enough for normies. Nobody will be totally lost moving from another chat app to Signal.</p>
<p>If you're looking for nothing but chat, Signal is fantastic. But many aspects of community-building online are simply unavailable here. To start, there are only group chats. There is no conversation threading or channels to keep conversations organized. You can have multiple chats, but that gets messy quickly.</p>
<p>I can't even pin posts. In fact, post searchability is a limited feature by design. Most group chats enable disappearing messages. That's great to prevent incriminating evidence from piling up; it's terrible for reviewing what a community discussed previously.</p>
<p>Also absent: granular roles in each chat, or anything resembling moderation tools. As an admin, I can only ban users for unwanted behavior. I can neither automatically prevent harassment nor provide a more measured response than the banhammer.</p>
<p>I should mention that almost all these tradeoffs are accepted limitations in service of Signal's primary objectives.</p>
<p>On the point of decentralization, Signal has none. As Meredith Whitaker <a href="https://mastodon.world/@Mer__edith/115445701583902092">recently wrote</a>,  all Signal app traffic flows through the same cloud infrastructure, much of which depends on AWS.</p>
<p>If your community's threat model is such that eliminating all possible points of evidence collection against you matters above all else, Signal is the clear winner. Maintaining that level of operational security naturally comes at the cost of some other creature comforts a community could come to covet.</p>
<p>I didn't set out to alliterate the hell out of that sentence, but I didn't stop it either.</p>
<h2 id="matrix">Matrix</h2>
<p><a href="https://matrix.org/">https://matrix.org</a></p>
<ul>
<li><strong>Functionality:</strong> 3</li>
<li><strong>Openness:</strong> 4</li>
<li><strong>Security:</strong> 3</li>
<li><strong>Safety:</strong> 1</li>
<li><strong>Decentralization:</strong> 4</li>
</ul>
<p><strong>Best for:</strong> communities who value independence over all, with security/privacy a runner-up.</p>
<p>Oh, <a href="https://matrix.org/">Matrix</a>. You are the football that I, in my zigzag-stripe shirt, keep trying to kick. In theory, the Matrix protocol and <a href="https://element.io/">Element</a>, its flagship client, should be the ideal for decentralized, encrypted communications. Using Element feels a whole lot like using Discord. Heck, it can even bridge communications from Discord and other platforms. Sadly, as time goes on, the nicks from the rough edges start to accumulate.</p>
<p>Before going further, we need to define some terms. <strong>Matrix</strong> is the federated, encrypted messaging protocol published and maintained by the Matrix Foundation. <a href="https://element-hq.github.io/synapse/latest/"><strong>Synapse</strong></a> is their "reference implementation" server technology written in Python. Synapse is the most common way folks start their own Matrix servers. There are other server implementations, now including "<a href="https://element.io/server-suite/synapse-pro">Synapse Pro</a>," which I guess is a partial rewrite of Synapse in Rust? <strong>Element</strong> is the first-party client that users would use to connect to Matrix. They need an account on a server, and of course <code>matrix.org</code> is the flagship Matrix server where the vast majority of users have their accounts. But you can point Element at any Matrix server to log in, as long as you have an account on that server.</p>
<p>Confused yet? If users are unwilling to select a Mastodon server, do you think they'd be willing to put up with this?</p>
<p>Ah, but I get ahead of myself.  Let's start with what's good.</p>
<p>Matrix uses a similar end-to-end cryptography scheme to Signal. "Rooms" (chats, channels) are not encrypted by default, but they can be made so. There have been <a href="https://soatok.blog/2024/08/14/security-issues-in-matrixs-olm-library/">noted issues</a> with the previous cryptography library used by Element, but the newer <a href="https://github.com/matrix-org/vodozemac">vodozemac</a> library is in much better shape. Of course, not all Matrix clients use the new hotness.</p>
<p>A given Matrix server can create multiple rooms (channels), and even group them into "spaces" such that they appear quite similar to Discord servers.</p>
<p>Inside the rooms, things feel familiar. We have threads, emoji reacts, and message search (sorta). On some clients (but not Element), there is the possibility of custom emoji.</p>
<p>And that's...it. Element promises more, like native <a href="https://github.com/element-hq/element-call?">video conferencing</a>, but heaven help you if you're trying to self-host it. It is technically possible, but by no means simple.</p>
<p>"Technically possible, but by no means simple" aptly describes up the entire Matrix experience, actually.</p>
<p>I ran a private Matrix server for about a year and a half. Why private? In two public Matrix rooms I had joined—including the room for Synapse admins—I experienced a common attack in which troll accounts spam the room with CSAM material. Horrible, but not just for the participants and admins in the room. Through the magic of federation, every server who has a user participating in the room <em>now has a copy of the CSAM material</em>, and has to take action to remove it. This requires a manual <code>curl</code> request on the server itself, because Synapse has an appalling lack of moderation tools. It's so bad that, without <a href="https://github.com/the-draupnir-project/Draupnir">third-party tooling</a>, you can't even ban a user outright from a server; you have to manually ban them from every single room.</p>
<p>Then came September 2, 2025. The <a href="https://matrix.org/blog/2025/10/post-mortem/">outage</a>of <code>matrix.org</code> caused by drive failures was not an indictment of Matrix's database management or recovery process—in fact, I was quite impressed with their response. But it did put the lie to Matrix's decentralization for me. Almost none of my friends could use Matrix, even though I was hosting my own server. The onboarding pipeline (especially via Element) is so focused on the flagship server, I daresay it comprises the plurality of Matrix accounts. It's not easy to get any statistics for all Matrix users, but that is my guess. How "decentralized" is that, really? Just because something <em>can</em> be decentralized doesn't make it so.</p>
<p>Isn't that right, ATProto?</p>
<p>I'm probably a little too close to this one. I so badly wanted Matrix to work, and I tried to make it work for my purposes for a long time. Ultimately, the pain points overcame the benefits. But if you care most about an intersection of message encryption, federation, and decentralization, and you're willing to put in quite a lot of admin time, Matrix can be a viable community chat platform.</p>
<h2 id="rocket-chat">Rocket.Chat</h2>
<p><a href="https://rocket.chat/">https://rocket.chat</a></p>
<ul>
<li><strong>Functionality:</strong> 5</li>
<li><strong>Openness:</strong> 3</li>
<li><strong>Security:</strong> 4</li>
<li><strong>Safety:</strong> 3</li>
<li><strong>Decentralization:</strong> 3</li>
</ul>
<p><strong>Best for:</strong> communities that want a smooth Slack-like experience and are willing to pay for independence</p>
<p>What if you could self-host Slack? That's basically the Rocket.Chat experience. It's slick, easy to get set up, and loaded with integrations. All of this comes, as you might expect, at a price. While there is an "open source" <a href="https://docs.rocket.chat/docs/our-plans">Community Edition</a>, its featureset is limited, and you may quickly find yourself looking at the paid plans for additional features or support. Rocket.Chat is one of several platforms that follow this freemium model. I don't really begrudge them this approach, but it can be frustrating for a community just finding its feet. To their credit, they do offer discounts for open source projects, not-for-profits, and other organizations on a per-request basis.</p>
<p>Rocket.Chat does support <a href="https://docs.rocket.chat/docs/e2e-encryption">end-to-end encrypted communications</a>. Key management can be a little clunky, but I was impressed it had the feature at all.</p>
<p>Be aware, however, that these centrally-managed services will of course allow administrators to audit messages. That is a documented part of the moderation flow for Rocket.Chat. If you demand anonymity or an inability for administrators to view your messages <del>what are you doing in that community?</del> Rocket.Chat might not be right for you.</p>
<p>I'll quickly mention why I gave it a score of 3 on decentralization. Seems a bit high, right? Until recently, Rocket.Chat supported Matrix federation. Since October 2025, it has pursued a <a href="https://www.rocket.chat/blog/native-federation-and-matrix-partnership">native federation scheme</a> that would allow separate Rocket.Chat instances to share rooms and DMs across server boundaries. This, although not open source, is extremely compelling.</p>
<p>I really enjoyed my experimentation with Rocket.Chat, and found myself thinking seriously about it as an alternative to where I was. The cost is just steep.</p>
<h2 id="zulip">Zulip</h2>
<p><a href="https://zulip.com/">https://zulip.com</a></p>
<ul>
<li><strong>Functionality:</strong> 4</li>
<li><strong>Openness:</strong> 4</li>
<li><strong>Security:</strong> 2</li>
<li><strong>Safety:</strong> 2</li>
<li><strong>Decentralization:</strong> 2</li>
</ul>
<p><strong>Best for:</strong>  A split between forums and real-time chat</p>
<p>I've been playing with Zulip for a bit now, and I still don't really know what to make of it. From one perspective, it has a bit of an identity crisis, unsure of whether it's a forum or a chat platform. From another perspective, this dual identity is its greatest strength: real-time when you want it, asynchronous when you don't.</p>
<p>Zulip is self-hostable, with some caveats.  As the <a href="https://zulip.com/plans/#self-hosted">plans and pricing detail</a>, anything beyond 10 users starts costing some cash. It adds up quickly. Seemingly everything <em>can</em> be done in a self-hosted manner, you're at the mercy of some truly byzantine documentation.</p>
<p>While there is great functionality to be found, it comes at a rather steep price for organizations of any size—whether administrative overhead, or just plain cash for the managed services. Although to their credit, they do offer a <a href="https://zulip.com/plans/#self-hosted-sponsorships">community plan</a> with many of those higher-tier features available for qualifying organizations.</p>
<p>One feature you won't find anywhere is end-to-end encryption. The developers seem <a href="https://github.com/zulip/zulip/issues/6096">rather against the idea</a>.  Multi-factor authentication must be enabled in the config files, not the admin frontend—hardly ideal.</p>
<p>Unless I'm missing it, there do not appear to be any serious content moderation tools in Zulip. The <a href="https://chat.ifin.network/help/moderating-open-organizations">community moderation toolkit</a> is, in my opinion, the barest of essentials. Nearly all of these capabilities are reactive, not proactive. It seems the expectation is good-faith participation, with those agreements and guarantees handled elsewhere. Having been on the wrong end of malicious intent, I don't feel safe enough with these tools.</p>
<p>Lastly, on decentralization, it's mostly a miss. Even for self-hosted plans, anything above the free tier requires a zulip.com account for plan management. And federation? Forget about it. Although every Zulip server can technically <a href="https://zulip.readthedocs.io/en/stable/production/multiple-organizations.html">host multiple Zulip instances</a>, they don't interact with one another.</p>
<p>If anything, writing this overview has left me more confused about Zulip than when I began. I just don't know where it fits, or who can afford these prices for a growing community.</p>
<h2 id="mattermost">Mattermost</h2>
<p><a href="https://mattermost.com/">https://mattermost.com</a></p>
<ul>
<li><strong>Functionality:</strong> 4</li>
<li><strong>Openness:</strong> 2</li>
<li><strong>Security:</strong> 4</li>
<li><strong>Safety:</strong> 2</li>
<li><strong>Decentralization:</strong> 1</li>
</ul>
<p><strong>Best for:</strong>  Fortune 100s and governments</p>
<p>Take a look at the front page of the Mattermost website, and you'll get an idea of the kind of organization <em>they</em> expect to be using this thing. Odds are, your nascent online community ain't that. While the software may superficially look like some of these others, its intention is entirely other. Community building is not what's going on here. Rather, Mattermost's objective is highly-focused, integrated workflows that involve human communication alongside machine automation. Business operations are what...matter most.</p>
<p>Mattermost describes itself as "Open core," and the core is...rather tiny. Even when installing the self-hosted version, you'll soon need a rather <a href="https://mattermost.com/pricing/">expensive license</a> for real work. Starting at $10/user is a clear indicator of the intended customer base. It ain't me, that's for sure.</p>
<p>Mattermost prides itself on a certain kind of security—specifically, the regulatory kind. Configurations for all manner of compliance regimes are provided in the <a href="https://docs.mattermost.com/security-guide/security-guide-index.html">documentation</a>. Normal security is present as well, including MFA. Not so much end-to-end encryption, although mention is made of encrypting the PostgreSQL database. That's novel, although not a solution to the problem addressed by E2EE.</p>
<p>I honestly don't think Mattermost's developers are capable of imagining a positive argument for an audit-resistant application. This thing is designed for monitoring user activity six ways from Sunday.</p>
<p>Consequently, "safety" in the way we've defined it here is absent from Mattermost's conception of the universe. If you're logging on to a Mattermost server, about a thousand other trust mechanisms are in place to guarantee you won't act like a doofus on this app.</p>
<p>Hardly a point to mentioning decentralization here, beyond the possibility of self-hosting. Ultimately though, you only get what your license key allows, and since the server is only open core, Mattermost itself is quite the point of failure.</p>
<h2 id="discourse">Discourse</h2>
<p><a href="https://discourse.org/">https://discourse.org</a></p>
<ul>
<li><strong>Functionality:</strong> 3</li>
<li><strong>Openness:</strong> 5</li>
<li><strong>Security:</strong> 3</li>
<li><strong>Safety:</strong> 5</li>
<li><strong>Decentralization:</strong> 3</li>
</ul>
<p><strong>Best for:</strong> anything but real-time chat, really.</p>
<p>I'm gonna be honest: I kind of love Discourse. I'm not sure I have a reason to deploy it, but I <em>want</em> to. Everything <a href="https://blog.discourse.org/2025/10/on-building-communities-in-public-why-i-chose-discourse-over-discord/">Joan Westenberg</a> writes in this piece in praise of Discourse resonates with me. Community for the long-haul? Transparency in governance? Built-in systems for establishing human trust?</p>
<p>That's what's <em>up</em>.</p>
<p>But Discourse has one significant difference from everything else on this list: it is primarily a forum, not a real-time chat app. I'm not saying that's a bad thing, necessarily, but it sure is different. If your community expects instantaneous communication, Discourse may be a big adjustment. Or it might not be sufficient on its own for your needs.</p>
<p>But what does it do well? Forums! It's very easy to navigate categories and topics. The UI provides clear signals for when something happened. Oh, and search is simple.</p>
<p>Maybe the best way to think of Discourse is as an anti-Discord. It's everything Discord isn't: asynchronous, open source, and self-hostable.</p>
<p>Discourse is 100% open source. I'm running it right now in my homelab, with access to all the plugins and features I'd expect, costing me only the time it took to install.</p>
<p>I was additionally quite impressed with the moderation tools. Not only are they plenty of tools to track user activity, but the moderation decisions are public by default. This is a good thing! The community can hold its leaders accountable for upholding their end of the bargain: to act in good faith in support of the community.</p>
<p>One area in which it falters a bit is, of course, end-to-end encryption. Very few of these tools enable it, and when they do, it can be clunky. It's entirely possible that the right option for a community is one of these <em>and</em> Signal for sensitive, out-of-band communications.</p>
<p>If you start to look around, you'll notice Discourse fora everywhere. There's a good reason for that! The software is rock solid for what it is. And maybe your community needs its depth of features more than it needs instantaneous messaging.</p>
<h2 id="revolt-stoat"><del>Revolt</del> Stoat??</h2>
<ul>
<li><strong>Functionality:</strong> ?</li>
<li><strong>Openness:</strong> ?</li>
<li><strong>Security:</strong> ?</li>
<li><strong>Safety:</strong> ?</li>
<li><strong>Decentralization:</strong> ?</li>
</ul>
<p><strong>Best for:</strong> Appreciating how much work it takes to make one of these work</p>
<p>Stoat, née Revolt, was meant to be an open source Discord alternative.  Recently, they  <a href="https://stoat.chat/updates/long-live-stoat">received a cease-and-desist</a> regarding the name Revolt, and renamed to a...weasel.</p>
<p>Anyway this thing is so far from being ready for prime time, I only include it here to call out the project. I wish them the best and hope for good things, especially since you can self-host the server. But a lack of stability and features prevent this from being useful for anything beyond experimentation. Maybe someday.</p>

<p>Choosing a platform on which to build a community is just the beginning. It's vitally important, yet insufficient to a community's success. Tools do not make a culture; the people engaging on it do. Most of my time building the culture of TTI has not been a technical endeavor. What we have—and I think it's pretty special—has little to do with Discord's featureset. It just happens to be where the people are. The options presented to you here allow you to seek a path that aligns with your objectives, principals, and needs at a purely mechanical level. The rest depends on the human element.</p>
<h2 id="score-breakdown">Score Breakdown</h2>
<table><thead><tr><th>Platform</th><th>Functionality</th><th>Openness</th><th>Security</th><th>Safety</th><th>Decentralization</th><th>Total</th></tr></thead><tbody>
<tr><td>Discord</td><td>4</td><td>1</td><td>3</td><td>4</td><td>1</td><td><strong>13</strong></td></tr>
<tr><td>Signal</td><td>2</td><td>4</td><td>5</td><td>2</td><td>1</td><td><strong>14</strong></td></tr>
<tr><td>Matrix</td><td>3</td><td>4</td><td>3</td><td>1</td><td>4</td><td><strong>15</strong></td></tr>
<tr><td>Rocket.Chat</td><td>5</td><td>3</td><td>4</td><td>3</td><td>3</td><td><strong>18</strong></td></tr>
<tr><td>Zulip</td><td>4</td><td>4</td><td>2</td><td>2</td><td>2</td><td><strong>14</strong></td></tr>
<tr><td>Mattermost</td><td>4</td><td>2</td><td>4</td><td>2</td><td>1</td><td><strong>13</strong></td></tr>
<tr><td>Discourse</td><td>3</td><td>5</td><td>3</td><td>5</td><td>3</td><td><strong>19</strong></td></tr>
<tr><td>Stoat</td><td>?</td><td>?</td><td>?</td><td>?</td><td>?</td><td><strong>?</strong></td></tr>
</tbody></table>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Another GitHub outage in the same day (354 pts)]]></title>
            <link>https://www.githubstatus.com/incidents/lcw3tg2f6zsd</link>
            <guid>46949452</guid>
            <pubDate>Mon, 09 Feb 2026 19:07:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.githubstatus.com/incidents/lcw3tg2f6zsd">https://www.githubstatus.com/incidents/lcw3tg2f6zsd</a>, See on <a href="https://news.ycombinator.com/item?id=46949452">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <h2>
            Resolved
          </h2>
          <div>
            <p><span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770667772000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">20:09</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions, Codespaces, Git Operations, Issues, Packages, Pages, Pull Requests and Webhooks are operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770667761000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">20:09</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are seeing all services have returned to normal processing.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770667699000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">20:08</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>A number of services have recovered, but we are continuing to investigate issues with Dependabot, Actions, and a number of other services.<p>We will continue to investigate and monitor for full recovery.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770666843000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:54</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Codespaces is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770665519000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:31</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We have applied mitigations and are seeing signs of recovery.<p>We will continue to monitor for full recovery.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770665384000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:29</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Packages is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770664243000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:10</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770664078000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:07</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are seeing impact to several systems including Actions, Copilot, Issues, and Git.<p>Customers may see slow and failed requests, and Actions jobs being delayed.</p><p>We are investigating.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770664047000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:07</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Webhooks is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770664030000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:07</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pages is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770663928000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:05</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770663734000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:02</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Investigating
          </h2>
          <div>
            <p><span>We are investigating reports of degraded performance for Actions, Git Operations and Issues</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1770663693000"></span>Feb <var data-var="date">09</var>, <var data-var="year">2026</var> - <var data-var="time">19:01</var> UTC
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: Git Operations, Webhooks, Issues, Pull Requests, Actions, Packages, Pages, and Codespaces.
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Testing Ads in ChatGPT (243 pts)]]></title>
            <link>https://openai.com/index/testing-ads-in-chatgpt/</link>
            <guid>46949401</guid>
            <pubDate>Mon, 09 Feb 2026 19:04:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/testing-ads-in-chatgpt/">https://openai.com/index/testing-ads-in-chatgpt/</a>, See on <a href="https://news.ycombinator.com/item?id=46949401">Hacker News</a></p>
Couldn't get https://openai.com/index/testing-ads-in-chatgpt/: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>