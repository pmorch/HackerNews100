<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 29 Dec 2024 20:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Toronto man creates tiny mobile homes to help unhoused people escape the cold (117 pts)]]></title>
            <link>https://www.cbc.ca/lite/story/1.7419805</link>
            <guid>42541173</guid>
            <pubDate>Sun, 29 Dec 2024 17:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/lite/story/1.7419805">https://www.cbc.ca/lite/story/1.7419805</a>, See on <a href="https://news.ycombinator.com/item?id=42541173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><div><article id="article"><p>CBC News | Posted: December 28, 2024 10:23 PM | Last Updated: 21 hours ago</p><p>Homes are attached to bicycles; include heat, electricity and safety features </p><div role="figure" data-pw="imageEmbed"><p>Image  |  ryan donais tiny homes </p><p>Caption: Ryan Donais build his first tiny mobile home this summer, and has now built three homes — one of which is pictured behind him — that can act as temporary shelters for those experiencing homelessness.  (Saeed Dehghani/CBC)</p></div><p>After seeing people sleeping outside in the cold year-after-year, a Toronto man is building tiny mobile homes attached to bicycles to give temporary relief to those who are unhoused.</p><p>Ryan Donais started building the small modular homes this summer as he watched the city's housing crisis becoming more dire. He said he didn't want to go through another winter seeing people living on the streets, so he put his background in construction to use. </p><p>"I just don't see any changes. It's been many years with people outside and it's not changing. I couldn't imagine being outside for years, you know?"</p><p>Since then, Donais has built three homes at a cost of about $10,000 each, most of which has been paid for through donations to his GoFundMe page. </p><div role="figure" data-pw="imageEmbed" dir="ltr"><p>Image  |  tiny tiny homes example </p><p>Caption: Each home built by Donais has heat, electricity and running water, plus safety features including a smoke detector and carbon monoxide alarm.  (Saeed Dehghani/CBC)</p></div><p>He took inspiration form <a href="https://www.cbc.ca/lite/story/1.5920822">Khaleel Seivwright</a>, a carpenter who built wooden shelters during the pandemic — until the city removed them, claiming they were a fire hazard. </p><p>Not wanting his tiny homes to suffer the same fate, Donais said he designed his mobile shelters to hopefully avoid backlash from the city. </p><p>Each of the small units have electricity and heat, running water and a bed, as well as safety features like smoke and carbon monoxide detectors and a fire extinguisher. Donais said the units are also designed with Ontario's e-bike regulations in mind so that they can legally travel on the city's bike lanes if they have to be moved. </p><p><em><strong>WATCH | Step inside his 1st tiny mobile home prototype: </strong></em><span><div role="figure" aria-label="Media Video | CBC News Toronto :  Tiny mobile home creator hopes to offer temporary relief to unhoused people"><p>Media Video | CBC News Toronto :  Tiny mobile home creator hopes to offer temporary relief to unhoused people</p><p>Caption: A Toronto man is building tiny mobile homes attached to bicycles with the hope of offering temporary relief to those who are unhoused. CBC’s Dale Manucdoc has the details.</p><a aria-label="Open full embed in new tab (external link)" href="https://www.cbc.ca/player/play/9.6517158" target="_blank" rel="noreferrer">Open Full Embed in New Tab <svg xmlns="http://www.w3.org/2000/svg" viewBox="-125 -125 600 450" height="1em" width="1em"><title>(external link)</title><path d="M216 12.1v24c0 6.6 5.4 12 12 12h74L194.1 156c-2.3 2.3-3.6 5.3-3.6 8.5s1.3 6.2 3.6 8.5l16.9 16.9c2.3 2.3 5.3 3.6 8.5 3.6s6.3-1.3 8.5-3.6L335.9 82l.1 74c0 6.6 5.4 12 12 12h24c6.6 0 12-5.4 12-12V12c0-6.6-5.4-12-12-12L228 .1c-6.6 0-12 5.4-12 12z"></path><path d="M288 192v132c0 6.6-5.4 12-12 12H60c-6.6 0-12-5.4-12-12V108c0-6.6 5.4-12 12-12h132V48H12C5.4 48 0 53.4 0 60v312c0 6.6 5.4 12 12 12h312c6.6 0 12-5.4 12-12V192h-48z"></path></svg></a><p><span>Loading external pages may require significantly more data usage.</span></p></div></span></p><p>So far, Donais said he hasn't encountered any issues. </p><p>Terra Sawler moved into one of Donais' mobile homes about a month and a half ago after spending close to three years living on the street. </p><p>"This is definitely the safest and warmest I've been since I've been out here."</p><div role="figure" data-pw="imageEmbed" dir="ltr"><p>Image  |  Terra Sawler </p><p>Caption: Terra Sawler has been living one of the tiny mobile homes built by Ryan Donais for more than a month.  (Saeed Dehghani/CBC)</p></div><p>After burning down two tents just trying to stay warm, Sawler says this is definitely a safer option. In addition to keeping her warm, Sawler says the tiny home has also allowed her to have something she hadn't had in years — a good night's sleep. </p><p>"When you're out on the street, you don't sleep every night. You sleep every couple nights," she said. </p><p>"And you gotta take turns and shifts with people, right? 'Cause I mean, I've had my shoes stolen off my feet, I've had my [sleeping] bag cut off, it's a dog-eat-dog world out here." </p><p><em><strong>WATCH | Woman experiencing homelessness grateful for tiny mobile home: </strong></em><span><div role="figure" aria-label="Media Video | CBC News Toronto :  'Tiny Tiny Homes' builder presents another Toronto resident with place to stay"><p>Media Video | CBC News Toronto :  'Tiny Tiny Homes' builder presents another Toronto resident with place to stay</p><p>Caption: A Toronto man who started building small shelters for those in need gave someone a new place to live today. As Naama Weingarten reports, while unhoused people appreciate his efforts, he wishes he never had to build the homes.</p><a aria-label="Open full embed in new tab (external link)" href="https://www.cbc.ca/player/play/9.6601656" target="_blank" rel="noreferrer">Open Full Embed in New Tab <svg xmlns="http://www.w3.org/2000/svg" viewBox="-125 -125 600 450" height="1em" width="1em"><title>(external link)</title><path d="M216 12.1v24c0 6.6 5.4 12 12 12h74L194.1 156c-2.3 2.3-3.6 5.3-3.6 8.5s1.3 6.2 3.6 8.5l16.9 16.9c2.3 2.3 5.3 3.6 8.5 3.6s6.3-1.3 8.5-3.6L335.9 82l.1 74c0 6.6 5.4 12 12 12h24c6.6 0 12-5.4 12-12V12c0-6.6-5.4-12-12-12L228 .1c-6.6 0-12 5.4-12 12z"></path><path d="M288 192v132c0 6.6-5.4 12-12 12H60c-6.6 0-12-5.4-12-12V108c0-6.6 5.4-12 12-12h132V48H12C5.4 48 0 53.4 0 60v312c0 6.6 5.4 12 12 12h312c6.6 0 12-5.4 12-12V192h-48z"></path></svg></a><p><span>Loading external pages may require significantly more data usage.</span></p></div></span></p><div dir="ltr"><p>As part of its </p><a href="https://www.toronto.ca/community-people/housing-shelter/affordable-housing-developments/modular-housing-initiative/#:~:text=The%20City%20of%20Toronto%20is,new%20modular%20homes%20in%20Toronto." target="_blank" rel="noreferrer">housing action plan<svg xmlns="http://www.w3.org/2000/svg" viewBox="-125 -125 600 450" height="1em" width="1em"><title>(external link)</title><path d="M216 12.1v24c0 6.6 5.4 12 12 12h74L194.1 156c-2.3 2.3-3.6 5.3-3.6 8.5s1.3 6.2 3.6 8.5l16.9 16.9c2.3 2.3 5.3 3.6 8.5 3.6s6.3-1.3 8.5-3.6L335.9 82l.1 74c0 6.6 5.4 12 12 12h24c6.6 0 12-5.4 12-12V12c0-6.6-5.4-12-12-12L228 .1c-6.6 0-12 5.4-12 12z"></path><path d="M288 192v132c0 6.6-5.4 12-12 12H60c-6.6 0-12-5.4-12-12V108c0-6.6 5.4-12 12-12h132V48H12C5.4 48 0 53.4 0 60v312c0 6.6 5.4 12 12 12h312c6.6 0 12-5.4 12-12V192h-48z"></path></svg></a><p> released in 2020, the City of Toronto has committed to creating 1,000 new modular homes for people experiencing homelessness. So far, the city has completed 216 homes on city-owned sites, its website says. </p></div><p>Other municipalities in Ontario have started to use modular homes to address a lack of housing. </p><div dir="ltr"><a href="https://www.cbc.ca/lite/story/1.7138608"><u>Peterborough started a modular housing community</u></a><p> filled with cabins in the site of a former parking lot </p></div><div dir="ltr"><a href="https://www.cbc.ca/lite/story/1.7347274"><u>Waterloo also</u></a><p> has a tiny home shelter run by the region that opened last year, while </p><a href="https://www.cbc.ca/lite/story/1.7414830"><u>Hamilton </u></a><p>is expected to open an outdoor shelter made up of tiny modular homes next month following some delays. </p></div><p>Since building his first tiny home in the summer, Donais has since registered his own not-for-profit organization, Tiny Tiny Homes, to help create more. </p><p>He says he's happy to be able to give people like Sawler an escape from the cold with his mini modular homes. But his homes aren't meant to be permanent, and he wishes he didn't have to build them at all. </p><p>"It's a terrible that we're letting people sleep outside. Housing is the answer."</p></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Was Wrong about the Ethics Crisis (Moshe Vardi, CACM) (165 pts)]]></title>
            <link>https://cacm.acm.org/opinion/i-was-wrong-about-the-ethics-crisis/</link>
            <guid>42540862</guid>
            <pubDate>Sun, 29 Dec 2024 16:23:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cacm.acm.org/opinion/i-was-wrong-about-the-ethics-crisis/">https://cacm.acm.org/opinion/i-was-wrong-about-the-ethics-crisis/</a>, See on <a href="https://news.ycombinator.com/item?id=42540862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		
		
					<p>Is Big Tech supporting the public good, and if not, what should Big Tech workers do about it?</p>
		
		

			<figure>
			<p><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg" alt="Moshe Y. Vardi" loading="eager" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2024/08/080224.OP_.Moshe-Vardi-2400x1350-1.jpg?resize=2048,1152 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></p>		</figure>

		
	</div><div>
		<article><section id="sec1" lang="en"><p id="p-1">The ethics crisis in computing was “launched” in 2018. In March of that year,&nbsp;<i>The Boston Globe</i> asserted, “Computer science faces an ethics crisis. The Cambridge Analytica scandal proves it!” This was in response to the <a href="https://www.brookings.edu/books/techlash/" data-jats-ext-link-type="uri">Techlash</a>,<a href="#fn1" data-jats-ref-type="fn" data-jats-rid="fn1"><sup>a</sup></a> where <i>Wall Street Journal</i> columnist Peggy Noonan described Silicon Valley executives as “moral Martians who operate on some weird new postmodern ethical wavelength” and Niall Ferguson, a Hoover Institution historian, described cyberspace as “cyberia, a dark and lawless realm where malevolent actors range.”</p><p id="p-2">But in my January 2019 <i>Communications</i> <a href="https://cacm.acm.org/opinion/are-we-having-an-ethical-crisis-in-computing/" data-jats-ext-link-type="uri">column</a>,<a href="#fn2" data-jats-ref-type="fn" data-jats-rid="fn2"><sup>b</sup></a> I dismissed the ethical-crisis vibe. I wrote, “If society finds the surveillance business model offensive, then the remedy is public policy, in the form of laws and regulations, rather than an ethics outrage.” I now think, however, I was wrong. I think I was right to advocate for laws and regulation to address the adverse impacts of computing, but I now believe we do have an ethics crisis in computing.</p><p id="p-3">What changed my mind? First, my anxiety about the ills brought on by computing has risen dramatically, as a perusal of my column over the past five years shows.<a href="#fn3" data-jats-ref-type="fn" data-jats-rid="fn3"><sup>c</sup></a> I <a href="https://cacm.acm.org/opinion/to-serve-humanity/" data-jats-ext-link-type="uri">bemoaned</a> that humanity seems to be serving technology rather than the other way around. I <a href="https://cacm.acm.org/opinion/the-winner-takes-all-tech-corporation/" data-jats-ext-link-type="uri">argued</a> that tech corporations have become too powerful and their power must be <a href="https://cacm.acm.org/opinion/the-people-vs-tech/" data-jats-ext-link-type="uri">curtailed</a>. I <a href="https://cacm.acm.org/opinion/advancing-computing-as-a-science-and-profession-but-to-what-end/" data-jats-ext-link-type="uri">asked</a> that ACM dedicate itself to the public good. I <a href="https://cacm.acm.org/opinion/acm-ethics-and-corporate-behavior/" data-jats-ext-link-type="uri">pointed out</a> that Big Tech’s business models are unethical. I explained how technology <a href="https://cacm.acm.org/opinion/technology-and-democracy/" data-jats-ext-link-type="uri">increases</a> societal polarization. I wailed that computing has blood on its hands. About two years ago, I started giving <a href="https://www.youtube.com/watch?v=OF3GlEwQBRg" data-jats-ext-link-type="uri">talks</a><a href="#fn4" data-jats-ref-type="fn" data-jats-rid="fn4"><sup>d</sup></a> on how to be an ethical computing technologist.</p><p id="p-4">But I have yet, until now, to point at the elephant in the room and ask whether it is ethical to work for Big Tech, taking all of the above into consideration. ACM’s Code of Ethics<a href="#fn5" data-jats-ref-type="fn" data-jats-rid="fn5"><sup>e</sup></a> does offer a clear ethical guideline. It opens with the following sentences: “Computing professionals’ actions change the world. To act responsibly, they should reflect upon the wider impacts of their work, consistently supporting the public good.” So, the ethical star we should follow is the support of the public good.</p><p id="p-5">Supporting the public good is not always straightforward. All of us must navigate the trade-off between “me” and “we.” A famous Talmudic quote states: “If I am not for myself, who will be for me? If I am only for myself, what am I?” We must balance optimizing for oneself with optimizing for others, including the public good. So how does working for Big Tech thread this needle? This is the question that people who work for Big Tech must ask themselves.</p><p id="p-6">The profit motive is not inherently against the public good. As Adam Smith pointed out, “They are led by an invisible hand…and thus without intending it, without knowing it, advance the interest of the society.” But the belief in the magical power of the free market always to serve the public good has <a href="https://cacm.acm.org/opinion/a-computational-lens-on-economics/" data-jats-ext-link-type="uri">no theoretical basis</a>.<a href="#fn6" data-jats-ref-type="fn" data-jats-rid="fn6"><sup>f</sup></a> In fact, our current climate crisis is a demonstrated <a href="https://www.amazon.com/Big-Myth-American-Business-Government/dp/1635573572" data-jats-ext-link-type="uri">market failure</a>.<a href="#fn7" data-jats-ref-type="fn" data-jats-rid="fn7"><sup>g</sup></a> To take an extreme example, Big Tobacco surely does not support the public good, and most of us would agree that it is unethical to work for Big Tobacco. The question, thus, is whether Big Tech is supporting the public good, and if not, what should Big Tech workers do about it.</p><p id="p-7">Of course, there is no simple answer to such a question, and the only reasonable answer to the question of whether it is ethical to work for Big Tech is, “It depends.” But consider Uber. In 2023, <i>Wired</i> magazine <a href="https://www.wired.com/story/uber-ceo-will-always-say-his-company-sucks/" data-jats-ext-link-type="uri">reported</a><a href="#fn8" data-jats-ref-type="fn" data-jats-rid="fn8"><sup>h</sup></a> that “…Travis Kalanick, had built an enormous, enthusiastic user base by subsidizing rides with the company’s vast reservoir of VC funding. Under Kalanick, Uber skirted regulations, shrugged off safety issues, and presided over a workplace rife with sexual harassment.” Was it ethical to have worked at Uber under Kalanick? I am sure many Uber employees were not aware of Kalanick’s shenanigans, but many were, and yet they continued to work at Uber. It was only in 2022 that a whistleblower leaked more than 124,000 company files to the <em>Guardian</em>, exposing its misdeeds.</p><p id="p-8">“It is difficult to get a man to understand something, when his salary depends on his not understanding it,” said the writer and political activist Upton Sinclair. By and large, Big Tech workers do not seem to be asking themselves hard questions, I believe, hence my conclusion that we do indeed suffer from an ethics crisis.</p></section></article>
</div><div>
			<div>
			<p>
				Submit an Article to CACM			</p>
			<p>
				CACM welcomes unsolicited <a href="https://cacm.acm.org/author-guidelines/#CACMsubmission">submissions</a> on topics of relevance and value to the computing community.			</p>
		</div>

<section>
	<div>
		<p>
			You Just Read		</p>
		<h4>
			I Was Wrong about the Ethics Crisis		</h4>
					<a href="https://dl.acm.org/doi/10.1145/3704959">
								View in the ACM Digital Library							</a>
			</div>
	<p>© 2024 Copyright held by the owner/author(s).</p>
</section>
		</div><div data-component="ctaMembership">
	
		<div>
				<h3>
					Shape the Future of Computing				</h3>
									<p>
						ACM encourages its members to take a direct hand in shaping the future of the association. There are more ways than ever to get involved.					</p>
													<p><a href="https://www.acm.org/about-acm/get-involved">
						Get Involved											</a>
							</p></div>

		
		<div>
				<h3>
					Communications of the ACM (CACM) is now a fully Open Access publication.				</h3>
									<p>
						By opening CACM to the world, we hope to increase engagement among the broader computer science community and encourage non-members to discover the rich resources ACM has to offer.					</p>
													<p><a href="https://cacm.acm.org/news/cacm-is-becoming-open-access">
						Learn More											</a>
							</p></div>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[China turns members of its diaspora into spies (211 pts)]]></title>
            <link>https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies</link>
            <guid>42540427</guid>
            <pubDate>Sun, 29 Dec 2024 15:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies">https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies</a>, See on <a href="https://news.ycombinator.com/item?id=42540427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><p><span><a href="https://www.economist.com/china" data-analytics="sidebar:section"><span>China</span></a></span><span> | <!-- -->Eyes everywhere</span></p><h2>America is on the hunt for these non-traditional agents. But its efforts risk backfiring</h2></section><section><figure><img alt="Illustration depicting a stylized eye with the Chinese flag as the iris, connected by yellow network lines to two red-tinted globes on either side, symbolizing global surveillance or influence. The background is black with red dots, creating a striking and" fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250104_CND001.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250104_CND001.jpg"><figcaption><span>Illustration: Ben Jones</span></figcaption></figure></section><div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">A</span><small>MONG EXILED</small> Chinese dissidents, Tang Yuanjun was well known. He had participated in the Tiananmen Square protests of 1989 and landed in prison as a result. He later defected to Taiwan, swimming to one of its outlying islands from a fishing boat. America granted him asylum and he settled in New York, becoming the leader of Chinese pro-democracy groups. But in August 2024 he was arrested by the <small>FBI</small>. He admits to having used his position to collect information for the Chinese government and to report on his fellow activists. He did this so that the government would allow him to return to China to see his ailing parents.</p></section><p><h3 id="article-tags">Explore more</h3><nav aria-labelledby="article-tags"><a href="https://www.economist.com/topics/china" data-analytics="tags:china"><span>China</span></a><a href="https://www.economist.com/topics/united-states" data-analytics="tags:united_states"><span>United States</span></a></nav></p></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Average American Spent 2.5 Months on Their Phone in 2024 (114 pts)]]></title>
            <link>https://www.pcmag.com/articles/yikes-the-average-american-spent-25-months-on-their-phone-in-2024</link>
            <guid>42539474</guid>
            <pubDate>Sun, 29 Dec 2024 12:16:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcmag.com/articles/yikes-the-average-american-spent-25-months-on-their-phone-in-2024">https://www.pcmag.com/articles/yikes-the-average-american-spent-25-months-on-their-phone-in-2024</a>, See on <a href="https://news.ycombinator.com/item?id=42539474">Hacker News</a></p>
Couldn't get https://www.pcmag.com/articles/yikes-the-average-american-spent-25-months-on-their-phone-in-2024: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[We've not been trained for this: life after the Newag DRM disclosure [video] (310 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure</link>
            <guid>42538914</guid>
            <pubDate>Sun, 29 Dec 2024 09:48:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure">https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure</a>, See on <a href="https://news.ycombinator.com/item?id=42538914">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[BioTerrorism Will Save Your Life with the 4 Thieves Vinegar Collective [video] (104 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-bioterrorism-will-save-your-life-with-the-4-thieves-vinegar-collective</link>
            <guid>42538903</guid>
            <pubDate>Sun, 29 Dec 2024 09:47:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-bioterrorism-will-save-your-life-with-the-4-thieves-vinegar-collective">https://media.ccc.de/v/38c3-bioterrorism-will-save-your-life-with-the-4-thieves-vinegar-collective</a>, See on <a href="https://news.ycombinator.com/item?id=42538903">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Dr.+Mix%C3%A6l+Swan+Laufer">Dr. Mixæl Swan Laufer</a>

</p>

<p><a href="https://media.ccc.de/c/38c3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
Playlists:
<a href="https://media.ccc.de/v/38c3-bioterrorism-will-save-your-life-with-the-4-thieves-vinegar-collective/playlist">'38c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/38c3-bioterrorism-will-save-your-life-with-the-4-thieves-vinegar-collective/audio">audio</a></p>
<!-- %h3 About -->
<p>Governments have criminalized the practice of managing your own health. Despite the fact that for most of human history bodily autonomy, and self-managed health was the norm, it is now required that most aspects of your health must be mediated by an institution deputized by the state. Taking those rights back for yourself is then labeled "BioTerrorism". So be it. Let's learn how.</p>

<p>We all know that custom, hand-made, artisan-crafted, boutique tools are always better than something factory made. A guitar, a wood chisel, a chef's knife, a built racing engine, a firearm, a suit, a pair of shoes. Given that this is so well-known, and so universally understood, it's peculiar at best that this is not seen by most people when it comes to medicine. It is however also true. </p>

<p>Given, however, that the traditional rôle of pharmacists who used to have the freedom to compound custom medicines for the people they were serving has been revoked, and now despite their extensive training, have been limited to being able to do little more than count pills in most cases, we have to do this ourselves. </p>

<p>The problem is that this has been criminalized. The moment you stop groveling for permission from medical authorities, and start becoming actively involved in managing your own health, you are a criminal in most countries in the world. Practicing medicine without a license, manufacture of drugs, possession of laboratory tools, possession of precursor chemicals... the list of felonies goes on. </p>

<p>The choice is yours. Would you like to be the sickest law-abiding citizen, or the healthiest BioTerrorist? If you want the red pill, you'll have to manufacture it yourself. The blue pill is prescription-only, and if you manage to get a prescription, and you're rich maybe you can afford to buy it. </p>

<p>Come learn about the long list of medications which went through the research and development processes, but are never going to be commercially available. Learn how to find more of these, and learn the many ways you can make them yourself.</p>

<p>Licensed to the public under http://creativecommons.org/licenses/by/4.0</p>

<h3>Download</h3>
<div>

<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[38C3: Illegal Instructions (378 pts)]]></title>
            <link>https://media.ccc.de/c/38c3</link>
            <guid>42537631</guid>
            <pubDate>Sun, 29 Dec 2024 04:54:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/c/38c3">https://media.ccc.de/c/38c3</a>, See on <a href="https://news.ycombinator.com/item?id=42537631">Hacker News</a></p>
Couldn't get https://media.ccc.de/c/38c3: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[WebGL Fluid Simulation (294 pts)]]></title>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid>42537567</guid>
            <pubDate>Sun, 29 Dec 2024 04:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paveldogreat.github.io/WebGL-Fluid-Simulation/">https://paveldogreat.github.io/WebGL-Fluid-Simulation/</a>, See on <a href="https://news.ycombinator.com/item?id=42537567">Hacker News</a></p>
Couldn't get https://paveldogreat.github.io/WebGL-Fluid-Simulation/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Personal Mail Server on OpenBSD (2019) (104 pts)]]></title>
            <link>https://nicolascarpi.github.io/openbsd/2019/04/03/openbsd-mail-server.html</link>
            <guid>42536750</guid>
            <pubDate>Sun, 29 Dec 2024 01:58:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicolascarpi.github.io/openbsd/2019/04/03/openbsd-mail-server.html">https://nicolascarpi.github.io/openbsd/2019/04/03/openbsd-mail-server.html</a>, See on <a href="https://news.ycombinator.com/item?id=42536750">Hacker News</a></p>
Couldn't get https://nicolascarpi.github.io/openbsd/2019/04/03/openbsd-mail-server.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Jeju Air accident in South Korea kills at least 47 (220 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</link>
            <guid>42536647</guid>
            <pubDate>Sun, 29 Dec 2024 01:40:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap">https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</a>, See on <a href="https://news.ycombinator.com/item?id=42536647">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[38C3: Blinkencity, radio controlling street lamps and power plants [video] (168 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants</link>
            <guid>42535622</guid>
            <pubDate>Sat, 28 Dec 2024 23:02:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants">https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants</a>, See on <a href="https://news.ycombinator.com/item?id=42535622">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[All You Need Is 4x 4090 GPUs to Train Your Own Model (108 pts)]]></title>
            <link>https://sabareesh.com/posts/llm-rig/</link>
            <guid>42535453</guid>
            <pubDate>Sat, 28 Dec 2024 22:37:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sabareesh.com/posts/llm-rig/">https://sabareesh.com/posts/llm-rig/</a>, See on <a href="https://news.ycombinator.com/item?id=42535453">Hacker News</a></p>
Couldn't get https://sabareesh.com/posts/llm-rig/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Finding and exploiting hidden features of Animal Crossing's NES emulator (2018) (123 pts)]]></title>
            <link>https://jamchamb.net/2018/07/11/animal-crossing-nes-emulator-hacks.html</link>
            <guid>42535333</guid>
            <pubDate>Sat, 28 Dec 2024 22:22:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jamchamb.net/2018/07/11/animal-crossing-nes-emulator-hacks.html">https://jamchamb.net/2018/07/11/animal-crossing-nes-emulator-hacks.html</a>, See on <a href="https://news.ycombinator.com/item?id=42535333">Hacker News</a></p>
Couldn't get https://jamchamb.net/2018/07/11/animal-crossing-nes-emulator-hacks.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fish 4.0: The Fish of Theseus (775 pts)]]></title>
            <link>https://fishshell.com/blog/rustport/</link>
            <guid>42535217</guid>
            <pubDate>Sat, 28 Dec 2024 22:07:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fishshell.com/blog/rustport/">https://fishshell.com/blog/rustport/</a>, See on <a href="https://news.ycombinator.com/item?id=42535217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>About two years ago, our head maintainer @ridiculousfish opened what quickly became our most-read pull request:</p>

<ul>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/9512">#9512 - Rewrite it in Rust</a></li>
</ul>

<p>Truth be told, we did not quite expect that to be as popular as it was.
It was written as a bit of an in-joke for the fish developers first, and not really as a press release to be shared far and wide.
We didn’t post it anywhere, but other people did, and we got a lot of reactions.</p>

<p>Observant readers will note that the PR was a proposal to rewrite the entirety of fish in Rust, from C++.</p>

<p>Fish is no stranger to language changes - it was ported from pure C to C++ earlier in its life,
but this was a much bigger project, porting to a much more different language that didn’t even exist when fish was started in 2007.</p>

<p>Now that we’ve released the beta of fish 4.0, containing 0% C++ and almost 100% pure Rust, let’s look back to see what we’ve learned, what went well, what could have gone better and what we can do now.</p>

<p>We’re writing this so others can learn from our experience, but it is <em>our</em> experience and not an exhaustive study.
We hope that you’ll be able to follow along even if you have never written any rust, but
experience with a roughly C++-shaped language should help.</p>

<h2 id="why-are-we-doing-this-again">Why are we doing this again?</h2>

<p>We’ve experienced some pain with C++. In short:</p>

<ul>
  <li>tools and compiler/platform differences</li>
  <li>ergonomics and (thread) safety</li>
  <li>community</li>
</ul>

<p>Frankly, the tooling around the language isn’t good, and we had to take on some additional pain in order to support our users.
We want to provide up-to-date fish packages for systems that aren’t up-to-date, like LTS Linux and older macOS.
But there is no ‘rustup’ for C++, no standard way to install recent C++ compilers on these operating systems.
This means adopting recent C++ standards would complicate the lives of packagers and would-be contributors<sup id="fnref:Contributions"><a href="#fn:Contributions" rel="footnote" role="doc-noteref">1</a></sup>.
For example, we started using C++11 in 2016, and yet we still needed to upgrade the compilers on our build machines until 2020.</p>

<p>Fish also uses threads for its award-winning (<em>note to editor</em>: find an actual award) autosuggestions and syntax highlighting,
and one long-term project is to add concurrency to the language.</p>

<p>Here’s a dirty secret: while external commands run in parallel, fish’s execution of internal commands (builtins and functions) is currently serial and can’t be backgrounded. Lifting this limitation will enable features like asynchronous prompts or non-blocking completions, as well as performance gains.</p>

<p>POSIX shells use subshells to get around this, but subshells are a leaky abstraction that can bite you in the behind when you least expect it.
For instance, you can’t set variables from inside a pipe (except on some shells, but only in the last part of the pipe, maybe, if you have enabled the correct option).
We would like to avoid that, and so the heavy hand of forking off a process isn’t appealing.</p>

<p>We prototyped true multithreaded execution in C++, but it just didn’t work out. For example, it was too easy to accidentally share objects across threads, with only post-hoc tools like Thread Sanitizer to prevent it.</p>

<p>The ergonomics of C++ are also simply not good - header files are annoying, templates are complicated, you can easily cause a compile error that throws <em>pages</em> of overloads in the standard library at you. Many functions are unsafe to use. C++ string handling is very verbose with
easily confusable overloads of many methods, making it attractive to drop down to C-style char pointers, which are quite unsafe.</p>

<p>And the standard prioritizes performance over ergonomics. Consider for instance string_view, which provides a non-owning slice of a string. This is an extremely modern, well-liked feature that C++ programmers often claim is a great reason to switch to C++17. And it is extremely easy to run into use-after-free bugs with it, because the ergonomics weren’t a priority.</p>

<p>One good case study of the deficiencies of C++-in-practice is a C library: curses. This is a venerable library to access terminal features, and we use it to access the terminfo database, which describes differences in terminal features and behavior.</p>

<p>This not only caused us grief by being unsafe to use in weird ways - the “cur_term” pointer (or sometimes macro!) can be NULL, and it is dereferenced in surprising places, but also caused a surprisingly high number of issues when building from source. This was either because there are multiple implementations of it with differences as useless as “this function takes a char on system X but an int on system Y”, but also because users kept coming to us with new and exciting(ly terrible) ways to package and install it. The dependency system is the system package manager.</p>

<p>Finally, subjectively, C++ isn’t drawing in the crowds. We have never had a lot of C++ contributors. Over the 11 years fish used C++, only 17 people have at least 10 commits to the C++ code. We also don’t know a lot of people who would love to work on a C++ codebase in their free time.</p>

<p>Some parting thoughts we can give the C++ community: We would like to see improvements to ergonomics and safety of the language and the tools prioritized over performance, and we would like to see efforts to make C++ compilers easier to upgrade on real systems.</p>

<h2 id="why-rust">Why Rust?</h2>

<p>We need to get one thing out of the way: Rust is cool. It’s fun.</p>

<p>It’s tempting to try to sweep this under the rug because it feels gauche to say, but it’s actually important for a number of reasons.</p>

<p>For one, fish is a hobby project, and that means we want it to be fun for us. Nobody is being paid to work on fish, so we <em>need</em> it to be fun.
Being fun and interesting also attracts contributors.</p>

<p>Rust also has great tooling. The tools have really paid a lot of attention to use, and the compiler errors are terrific. Not even “compared to C++”, they just actually rule. And as we have tried to pay attention to our own error messages (fish has a bespoke error for if it thinks a file you told it to run has Windows line endings),
we like it.</p>

<p>And it is <em>easy</em> to get that tooling installed - <code>rustup</code> is magic, and allows people to get started quickly, with minimal fuss or root permissions.
When the answer to “how to upgrade C++ compiler” is “find a repository (with root permissions), compile it yourself, install some <em>other</em> repository or a docker image”,
it is amazing how the Rust answer can just be “use rustup”.</p>

<p>Rust has great ergonomics - the difference between C++’s pointers (which can always be NULL) and Rust’s Options are apparent very quickly even to those of us who had never used it before. We did have a backport of C++’s optional, and liked using it, but it was never as integrated as Rust’s Options were.</p>

<p>Having an explicit <code>use</code> system where you know exactly which function comes from which module is a great improvement over <code>#include</code>.</p>

<p>Rust makes it nice to add dependencies. We don’t want to go overboard with it, but we do want to change our history format from our homegrown “I can’t believe it’s not YAML” to something specified that other tools can actually read, and Rust makes it easy to add support for YAML/JSON/KDL.</p>

<p>But the killer feature of Rust, from fish-shell’s perspective, is Send and Sync, statically enforcing rules around threading. “Fearless concurrency” is too strong - you can still blow your leg off with fork or signal handlers - but Send and Sync will be the key to unlocking fully multithreaded execution, with confidence in its correctness.</p>

<p>We did not do a comprehensive survey of other languages. We were confident Rust was up to the task and either already knew it or wanted to learn it, so we picked it.</p>

<h2 id="platform-support">Platform Support</h2>

<p>A lot of hay has also been made online about Rust’s platform support (e.g. <a href="https://lwn.net/Articles/998115/">in the git project</a>). We don’t see a big problem here - all of our big platforms (macOS, Linux, the BSDs) are supported, as are Opensolaris/Illumos and Haiku. We have never heard of anyone trying to run fish on NonStop.</p>

<p>Architecture support is even less of a problem - going by <a href="https://popcon.debian.org/">Debian’s popcon</a>, 99.9995% (the actual result, not an exaggeration) of machines run an architecture that has Rust packages in Debian. Given that fish is <a href="https://qa.debian.org/popcon.php?package=fish">installed on 1.92% of Debian systems</a>, we would project two (2) or three (3) machines of the quarter million responses to have fish on an unsupported architecture <sup id="fnref:stats"><a href="#fn:stats" rel="footnote" role="doc-noteref">2</a></sup>.</p>

<p>Unlike what some online have assumed, a native Windows port was not a reason for switching to Rust as it was never in the cards. Fish is, at heart, a UNIX shell that relies not only on UNIX APIs but also their semantics, and exposes them in the scripting language. What would <code>test -x</code> say on Windows, which has no executable bit? These are issues that <em>could</em> be solved with a lot of work, but we’re unix nerds making a unix shell, not one for Windows.</p>

<p>The one platform we care about a bit that it does not currently seem to have enough support for is Cygwin, which is sad, but we have to make a cut somewhere.</p>

<h2 id="the-story-of-the-port">The Story Of The Port</h2>

<p>We had decided we were gonna do a “Fish <a href="https://en.wikipedia.org/wiki/Ship_of_Theseus">Of Theseus</a>” port - we would move over, component by component, until no C++ was left.
And at every stage of that process, it would remain a working fish.</p>

<p>This was a necessity - if we didn’t, we would not have a working program for months, which is not only demoralizing but would also have precluded us from
using most of our test suite - which is end-to-end tests that run a script or fake a terminal interaction. We would also not have been able to do another C++ release,
putting some cool improvements into the hands of our users.</p>

<p>Had we chosen to disappear into a hole we might not have finished at all, and we would have to re-do a bunch of work once it became testable.
We also mostly kept the structure of the C++ code intact - if a function is in the “env” subsystem, it would stay there. Resisting the temptation to
clean up allowed us to compare the before and after to find places where we had mistranslated something.</p>

<p>So we used <a href="https://google.github.io/autocxx/">autocxx</a> to generate bindings between C++ and Rust code, allowing us to port one component at a time.</p>

<p>We started<sup id="fnref:technically"><a href="#fn:technically" rel="footnote" role="doc-noteref">3</a></sup> by porting the builtins. These are essentially little self-contained programs, with their own arguments, streams, exit code, etc.
That means it’s easy to port them separately from the rest of the shell once you have a way to call a Rust builtin from C++, which we had as part of the initial pull request.</p>

<p>Where they connected to the main shell, we used one of three approaches:</p>

<ol>
  <li>Add some FFI glue to the C++ to make it callable from Rust, port the caller and leave the callee for later</li>
  <li>Move the callee to Rust and, if necessary, make it callable from C++</li>
  <li>Write a Rust version of the callee and call it from the ported caller, but leave the C++ version around</li>
</ol>

<p>For instance, almost every builtin needs to parse its options. We have our own implementation of getopt, that we reimplemented in Rust in the initial PR,
but the C++ version stuck around until it had no more callers remaining. Otherwise we would have had to write a C++-to-Rust bridge and adjust the C++ callers to use it.</p>

<p>Or the <code>builtin</code> builtin (the builtin called <code>builtin</code>) needs access to the names of all builtins to print them for <code>builtin --get-names</code>. In that case we bridged some access to what amounts to a constant vector of strings in the C++, and eventually moved it over once the users were in Rust.</p>

<p>That’s how it went for a while, but we finally hit the more entangled systems, where porting larger chunks felt more productive,
since that reduced the amount of tricky FFI code to be written only to be thrown away. These were ported in solo efforts.
This includes the input/output “reader”, which is, unsurprisingly, one of fish’s biggest parts, ending up at about 13000 lines of Rust.</p>

<p>During the port, we hit a bunch of snags with (auto)cxx. Sometimes it would just not understand a particular C++ construct, and we spent a lot of time trying to figure out ways to please it. As an example, we introduced a struct on the C++ side that wrapped C++’s <code>vector</code>, because for some reason autocxx liked to complain about <code>vector&lt;wstring&gt;</code>. We had to fork it to add support for wstring/wchar, which is understandable because using wchar is a horrible decision - we only do it because it’s a historical mistake.</p>

<p>Similarly, we had to wrap some C++ variables in <code>unique_ptr</code> and similar to make the ownership rules understandable to (auto)cxx, or copy values that didn’t strictly need to be copied. This caused the performance during the port to go down quite a bit, but we regained all of it in most spots, and even beat the C++ version in some.</p>

<p>We also patched autocxx to remove the requirement to use <code>unsafe</code> to invoke any C++ API, because that would have obscured uses of <code>unsafe</code> that wouldn’t disappear just by porting the callee. We were building something temporary, so sometimes it is okay to do something a little underhanded.
If you used this for a permanent bridge between Rust and C++ in a few parts of your code, the <code>unsafe</code> markers might be useful, but in our case they were noise.</p>

<p>Because autocxx generated a lot of code, some tools also were less helpful than they’d usually be. rust-analyzer for instance was extremely slow.</p>

<p>So, even though our codebase was fairly amenable to being moved to Rust because we didn’t use exceptions or a lot of templates, autocxx isn’t the easiest to work with.
It is absolutely magical that it works at all, and it enabled us to do this port, but it has a hard task to perform and isn’t perfect at it.</p>

<h3 id="the-timeline">The Timeline</h3>

<ul>
  <li>
    <p>The initial PR was opened on 28th January 2023, merged on 19th February 2023</p>
  </li>
  <li>
    <p>fish 3.7.0, another release in the C++ branch to flush out some accumulated improvements, was released in January 2024</p>
  </li>
  <li>
    <p>The last C++ code was removed in January 2024 (and some additional test code was ported from C++ to C 12th of June 2024)</p>
  </li>
  <li>
    <p>The first beta was released 17th of December 2024</p>
  </li>
</ul>

<p>The initial PR had a timeline of “handwaving, half a year”. It was clear to all of us that it might very well be entirely off, and we’re not
disappointed that it was. Frankly, 14 months was still a pretty good pace, especially considering that we made a C++ release in-between, so it did not throw off our usual release cadence.</p>

<p>Most of the work was done by 7 people (going by those with at least 10 commits to “.rs” files), but we got a lot of help from interested community members.</p>

<p>The delay after that was down to a few reasons:</p>

<ol>
  <li>The “second 90%” - testing that everything worked. We flushed out a lot of bugs in this time, and if we made a release at that time it would have been a bad one.</li>
  <li>Having something to release that’s visible to users - there’s no point in making a release that does the same thing in new code, you need it to do different things.
So we held off until we had something.</li>
  <li>Simple availability - sometimes, some of us took time off.</li>
</ol>

<p>So if you are trying to draw any conclusions from this, consider the context: A group of people working on a thing in their free time,
diverting some effort to work on something else, <em>and</em> deciding that after the work is finished it actually isn’t.</p>

<h2 id="the-gripes">The Gripes</h2>

<p>It won’t surprise anyone who has spent any time on this world of ours that Rust is not, in fact, perfect. We have some gripes with it.</p>

<p>Chief among them is how Rust handles portability. While it offers many abstractions over systems, allowing you to target a variety of systems with the same code,
when it comes to <em>adapting</em> your code to systems at a lower-level, it’s all based on enumerating systems by hand, using checks like <code>#[cfg(any(target_os = "freebsd", target_os = "netbsd", target_os = "openbsd"))]</code>.</p>

<p>This is an imperfect solution, allowing you to miss systems and ignoring version differences entirely. From what we can tell, if FreeBSD 12 gains a function that we want to use, libc would add it, but calling it would then fail on FreeBSD 11 without a good way to check, at the moment.</p>

<p>But listing targets in our code is also fundamentally duplicating work that the libc crate (in our case) has already done. If you want to call libc::X, which is only defined on systems A, B and C, you need to put in that check for A, B and C yourself and if libc adds system D you need to add it as well. Instead of doing that, we are using our own <a href="https://github.com/mqudsi/rsconf">rsconf</a> crate to do compile-time feature detection in build.rs.</p>

<p>Most of this would be solved if Rust had some form of saying “compile this if that function exists” - <code>#[cfg(has_fn = "fstatat")]</code>. With that, the libc crate could do whatever checks it wants and fish would just follow what it did, and we could remove a lot of the use for rsconf. It would not really help support older distributions that lack some features, tho. That could be solved by something like the <a href="https://github.com/rust-lang/rfcs/pull/3036">min_target_API_version</a> cfg.</p>

<p>While we’re on portability, the tools also sometimes fail to consider other targets - clippy may warn about a conversion being useless when it isn’t on another system, it is often better to use <code>if cfg!(...)</code> instead of <code>#[cfg(...)]</code> because code behind the latter is eliminated very early, so it may be entirely wrong and only shows up when building on the affected system.</p>

<p>We’ve also had issues with localization - a lot of the usual Rust relies on format strings that are checked at compile-time, but unfortunately they aren’t translatable.
We ported printf from musl, which we required for our own <code>printf</code> builtin anyway, which allows us to reuse our preexisting format strings at runtime.</p>

<h3 id="the-mistakes">The Mistakes</h3>

<p>We’ve hit some false starts, dead ends and other kinds of mistakes. For instance we originally used a fancy macro to allow us to write our strings as <code>"foo"L</code>, but that did not end up carrying its weight and we removed it in favor of a regular <code>L!("foo")</code> macro call.</p>

<p>We were confused by a deprecation warning in the libc crate, which explains that “time_t” will be switched to 64-bit on musl in the future.
We initially tried to work around it, adding a lot of wrappers to try to stay agnostic on that size, but only later figured out that it does not affect us,
as we do not pass a time_t we get from one C library to another. (https://github.com/fish-shell/fish-shell/issues/10634)</p>

<p>Some bugs appeared because we missed subtleties of the original code.
Often this turned into a crash because we used asserts or assert’s modern cousin “.unwrap()”. This was often the easiest way to translate the C++,
and sometimes it simply turned out to be not accurate, and had to be replaced with different error handling.</p>

<p>But overall most of these were, once found, pretty shallow - “it panics here, why would it do that? oh, this can be an Err? Okay, what leads to that? Ah, okay, let’s handle that in this way”.</p>

<p>We’ve also caused some friction by turning on link-time-optimization combined with having release builds as the default in CMake (currently needed to run the full test suite),
which makes it easy to accidentally have very long build time.</p>

<h2 id="the-good">The Good</h2>

<p>A lot of the benefits of porting to Rust will appear over time, but some are already here.</p>

<p>Remember our issues with (n)curses? We will no longer have any, because we no longer use curses. Instead we switched to <a href="https://github.com/meh/rust-terminfo">a Rust crate</a> that gives us just what we need, which is access to terminfo and expanding its sequences. This removes some awkward global state, and means those building from source no longer need to ensure that curses is installed “correctly” on their system - cargo just downloads a crate and builds it.</p>

<p>We do still read terminfo, which means users need to install that, but that can be done at runtime, is preinstalled on all mainstream systems <em>and</em> if it can’t be found we just use an included copy of the xterm-256color definitions<sup id="fnref:terminfo"><a href="#fn:terminfo" rel="footnote" role="doc-noteref">4</a></sup>.</p>

<p>We have also managed to create “self-installable” fish packages that include all the functions, completions and other asset files in the fish binary to be written out at runtime.
That allowed us to create statically linked versions of fish (for linux this uses musl, because glibc has unavoidable crashes!), so for the first time we have <em>one file</em> you can download and run on <em>any linux</em> (the only requirement being that the architecture matches!).</p>

<p>This is a pretty big boon for people who want to use fish but sometimes ssh to servers, where they might not have root access to install a package. So they can just <code>scp</code> a single file and it’s available.</p>

<p>This might be possible with C23’s <code>#embed</code>, but Rust allowed us to do it now and, overall, pretty easily.</p>

<h2 id="the-sad">The Sad</h2>

<p>The one goal of the port we did not succeed in was removing CMake.</p>

<p>That’s because, while <code>cargo</code> is great at <em>building</em> things, it is very simplistic at <em>installing</em> them. Cargo wants everything in a few neat binaries,
and that isn’t our use case. Fish has about 1200 .fish scripts (961 completions, 217 associated functions), as well as about 130 pages of documentation (as html and man pages),
and the web-config tool and the man page generator (both written in python).</p>

<p>It also has a test suite that is light on unit tests but heavy on end-to-end script and interactive tests. The scripted tests run through our own littlecheck tool,
which runs a script and compares its output to embedded comments. The interactive tests are driven by pexpect, which fakes terminal interaction and checks that the right thing happens when you press buttons.</p>

<p>We kept cmake, in a simplified form, for these tasks, but let it hand over the responsibility of <em>building</em> to cargo.</p>

<p>It would be possible to switch all that to a simpler task runner like Just or even plain old makefiles, but since we already have this system we’re keeping it for now.
The upside is that the build process hasn’t really changed for packagers.</p>

<p>We’re also losing Cygwin as a supported platform for the time being, because there is no Rust target for Cygwin and so no way to build binaries targeting it.
We hope that this situation changes in future, but we had also hoped it would improve during the almost two years of the port.
For now, the only way to run fish on Windows is to use WSL.</p>

<h2 id="the-present--the-future">The Present &amp; The Future</h2>

<p>We’ve succeeded. This was a gigantic project and <em>we made it</em>. The sheer scale of this is perhaps best expressed in numbers:</p>

<ul>
  <li>1155 files changed, 110247 insertions(+), 88941 deletions(-) (excluding translations)</li>
  <li>2604 commits by over 200 authors</li>
  <li>498 issues</li>
  <li>Almost 2 years of work</li>
  <li>57K Lines of C++ to 75K Lines of Rust <sup id="fnref:formatting"><a href="#fn:formatting" rel="footnote" role="doc-noteref">5</a></sup> (plus 400 lines of C <sup id="fnref:ccode"><a href="#fn:ccode" rel="footnote" role="doc-noteref">6</a></sup>)</li>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/10564">C++–</a></li>
</ul>

<p>The beta works very well. Performance is usually slightly better in terms of time taken, memory use has a slightly higher floor but a lower ceiling - it will use 8M instead of 7M at rest, but e.g. globbing a big directory won’t make it go up as much. These things can all be improved, of course, but for a first result it is encouraging.</p>

<p>Fish is still a bit of an odd duck…fish as a Rust program. It has some bits that smell like C spirit, directly using the C API and e.g. passing around file descriptors instead of File objects. It still uses UTF-32 strings - which is why we are using a fork of the pcre2 crate because we couldn’t convince the pcre2-crate maintainer to add UTF-32 support. We hope to find a nicer solution here, but it wasn’t necessary for the first release.</p>

<p>The port wasn’t without challenges, and it did not all go <em>entirely</em> as planned. But overall, it went pretty dang well. We’re now left with a codebase that we like a lot more, that has already gained some features that would have been much more annoying to add with C++,
with more on the way, and we did it while creating a separate 3.7 release that also included some cool stuff.</p>

<p>And we had fun doing it.</p>

<hr>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel's $475M error: the silicon behind the Pentium division bug (316 pts)]]></title>
            <link>https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</link>
            <guid>42535071</guid>
            <pubDate>Sat, 28 Dec 2024 21:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html">https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</a>, See on <a href="https://news.ycombinator.com/item?id=42535071">Hacker News</a></p>
Couldn't get https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Family of OpenAI whistleblower Suchir Balaji demand FBI investigate death (270 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</link>
            <guid>42535057</guid>
            <pubDate>Sat, 28 Dec 2024 21:46:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji">https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</a>, See on <a href="https://news.ycombinator.com/item?id=42535057">Hacker News</a></p>
Couldn't get https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Anki AI Utils (198 pts)]]></title>
            <link>https://github.com/thiswillbeyourgithub/AnkiAIUtils</link>
            <guid>42534931</guid>
            <pubDate>Sat, 28 Dec 2024 21:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/thiswillbeyourgithub/AnkiAIUtils">https://github.com/thiswillbeyourgithub/AnkiAIUtils</a>, See on <a href="https://news.ycombinator.com/item?id=42534931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Anki AI Utils</h2><a id="user-content-anki-ai-utils" aria-label="Permalink: Anki AI Utils" href="#anki-ai-utils"></a></p>
<p dir="auto">A powerful suite of AI-powered tools to enhance your <a href="https://en.wikipedia.org/wiki/Anki_(software)" rel="nofollow">Anki</a> flashcard learning experience by automatically improving cards you struggle with, tested through medical school. For example think of it like this: every time you fail a card you get a ChatGPT explanation, a Dall-E illustration, mnemonics, etc but supporting your own mnemonics.</p>
<p dir="auto"><strong>Check out my other Anki and AI related projects on my <a href="https://github.com/thiswillbeyourgithub">GitHub profile</a>!</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Simple example</h3><a id="user-content-simple-example" aria-label="Permalink: Simple example" href="#simple-example"></a></p>
<p dir="auto"><strong>Those scripts make it so that every failed note will automatically have new fields containing explanations, mnemonics, and illustrations.</strong> This is done in a way that respects <strong>your own mnemonics</strong>, can even use the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">major system</a>, and has <strong>many</strong> more features.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developer's note / call for help</h2><a id="user-content-developers-note--call-for-help" aria-label="Permalink: Developer's note / call for help" href="#developers-note--call-for-help"></a></p>
<p dir="auto">This collection of scripts is the culmination of my efforts to contributes the AI features I wish existed when I started medical school. All scripts should be working but I released them hastily after documenting them heavily with the help of <a href="https://aider.chat/" rel="nofollow">aider</a>. It is possible that some aspects of the documentation is slightly off or imprecise. It is also possible that some of the scripts where slighly broken during the release process. In any case, <strong>by releasing this project made with love and care my hope is to motivate others to package it into addons.</strong> I have too little time to learn how to package those scripts into addons and make the appropriate GUI so any help is absolutely welcome.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Adaptive Learning</strong>: Uses <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> to dynamically match your cards with the most relevant examples from your training datasets. The more examples you add, the better it gets!</p>
</li>
<li>
<p dir="auto"><strong>Personalized Memory Hooks</strong>: Reuses consistent mnemonics from your custom collection, building a personalized memory system. Includes a dedicated tool to help create and manage your mnemonic library.</p>
</li>
<li>
<p dir="auto"><strong>Automation Ready</strong>: Run programmatically - for example, use cron to automatically enhance cards you struggled with yesterday, making them easier to remember through images, mnemonics, and explanations.</p>
</li>
<li>
<p dir="auto"><strong>Universal Compatibility</strong>: Modifies Anki notes directly in-place, working seamlessly across all Anki clients (Windows, Mac, Linux, Android, iOS). Extensive logging ensures you can track changes and rollback if needed.</p>
</li>
<li>
<p dir="auto"><strong>Provider Agnostic</strong>: Supports all LLM providers and models through LiteLLM, letting you choose the best option for your needs.</p>
</li>
<li>
<p dir="auto"><strong>Infinitely Extensible</strong>: Add as many examples as you want to your training datasets - the semantic filtering automatically picks the most relevant ones for each card.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator" aria-label="Permalink: Illustrator" href="#illustrator"></a></p>
<p dir="auto">Creates custom mnemonic images for your cards using AI image generation. It:</p>
<ul dir="auto">
<li>Analyzes card content to identify key concepts</li>
<li>Generates creative visual memory hooks</li>
<li>Preserves a history of generated images</li>
<li>Supports both DALL-E2, DALL-E3 and Stable Diffusion</li>
<li>Automatically formats images for optimal display (centered, proper sizing)</li>
<li>Handles multiple images per card with consistent layout</li>
</ul>
<p dir="auto">Perfect for visual learners or complex topics that benefit from imagery.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, I had this French flashcard:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever.png" alt=""></a></p>
<details>
<summary>Click here if you can't read French</summary>
<p dir="auto">Here's the note content translated to English:</p>
<div data-snippet-clipboard-copy-content="Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total"><pre><code>Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total
</code></pre></div>
</details>
<p dir="auto"><code>illustrator.py</code> generated to me this image:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever_generated.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever_generated.png" alt=""></a></p>
<p dir="auto">As well as this text content to understand its thought process: (Note that this part is always in English no matter the original language)</p>
<div data-snippet-clipboard-copy-content="Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]"><pre><code>Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]
</code></pre></div>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator" aria-label="Permalink: Reformulator" href="#reformulator"></a></p>
<p dir="auto">An intelligent tool that rephrases your flashcards while preserving their core meaning and structure. It helps when:</p>
<ul dir="auto">
<li>Cards are poorly worded or unclear</li>
<li>You want to vary the phrasing to strengthen recall</li>
<li>Cards need to be more concise or natural sounding</li>
<li>Your preferred card format has evolved over time</li>
</ul>
<p dir="auto">The tool uses LLMs to reformulate content while carefully preserving cloze deletions and media. This is especially valuable for long-term Anki users - for example, during medical school, your idea of what makes a "perfect" flashcard often evolves after a few semesters. The Reformulator lets you easily update all your older cards to match your current preferred format and style.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, given this poorly worded flashcard:</p>
<div data-snippet-clipboard-copy-content="bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}"><pre><code>bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}
</code></pre></div>
<p dir="auto">The reformulator would improve it to:</p>
<div data-snippet-clipboard-copy-content="What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}"><pre><code>What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}
</code></pre></div>
<p dir="auto">Note how the reformulation:</p>
<ul dir="auto">
<li>Makes the question grammatically complete and clear</li>
<li>Structures it as a proper question</li>
<li>Makes the answer self-contained by repeating key context</li>
<li>Preserves the exact medical terminology</li>
<li>Maintains the cloze deletion format</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator"></a></p>
<p dir="auto">Generates memorable mnemonics tailored to your cards by:</p>
<ul dir="auto">
<li>Creating multiple mnemonic options per card</li>
<li>Using proven memory techniques like the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a></li>
<li>Incorporating your existing memory anchors</li>
<li>Preserving context and accuracy</li>
</ul>
<p dir="auto">Helps create lasting memory connections, especially for numbers and sequences.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiMnemonics field:</p>
<hr>
<ol dir="auto">
<li>'Heureux Hephaistos fébrile tend sa banane unique près du feu'<br>* <b>Heureux </b> Âge supérieur à 1 an  Heureux évoque la maturité et donc un âge déjà avancé, supérieur à 1 an <br>* <b>Hephaistos fébrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  Hephaistos évoque la fièvre du fait de son rôle de forgeron et fébrile réitère ce concept <br>* <b>tend sa banane unique </b> 1 unique crise par épisode fébrile donné  banane unique évoque une seule occurrence, ici la crise unique par épisode fébrile <br>* <b>près du feu </b> Moins de 3 épisodes au total  feu évoque la fièvre et sa proximité suggère une limite, ici moins de 3 épisodes en tout <p>2.  'Un enfant trébuche dans le feu, danse symétriquement, a un seul coup et moins de trois feux'<br>* <b>Un enfant trébuche </b> Âge supérieur à 1 an  l'idée d'un enfant qui commence juste à marcher évoque l'âge juste après un an <br>* <b>dans le feu, </b> Survenue de la crise avec une fièvre supérieure à 38°C  le feu évoque la chaleur, donc la fièvre <br>* <b>danse symétriquement, </b> Manifestations motrices symétriques  danser évoque le mouvement, et symétriquement évoque les deux côtés du corps bougeant de la même manière <br>* <b>a un seul coup </b> 1 unique crise par épisode fébrile donné  un seul coup évoque l'unicité de la crise pendant l'épisode fébrile <br>* <b>et moins de trois feux </b> Moins de 3 épisodes au total  moins de trois feux évoque le nombre total d'épisodes, utilisant l'analogie avec la fièvre comme feu </p><p>3.  'Un enfant febrile symetrique forge une unique bulle dans la prairie'<br>* <b>Un enfant </b> Âge supérieur à 1 an  enfant indique que le sujet concerne un jeune individu, donc plus d'un an <br>* <b>febrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  fébrile se lie à la notion de fièvre <br>* <b>symetrique </b> Manifestations motrices symétriques  directement lié à symétrique <br>* <b>forge </b> durant moins de 15 minutes et sans déficit  forger évoque une action courte et intense, comme la crise qui dure moins de 15 minutes sans laisser de séquelles <br>* <b>une unique </b> 1 unique crise par épisode fébrile donné  unique précise le nombre de crises <br>* <b>bulle </b> Moins de 3 épisodes au total  une bulle évoque quelque chose de rare et limité, semblable à moins de 3 épisodes au total <br>* <b>dans la prairie </b> hyperthermique  la prairie évoque un espace ouvert et naturel, hyperthermique évoque la chaleur comme celle du soleil sur une prairie </p><p>[DATE:09/04/2024 VERSION:2.1 MODEL:openai/gpt-4-0125-preview]</p></li>
</ol>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Explainer</h3><a id="user-content-explainer" aria-label="Permalink: Explainer" href="#explainer"></a></p>
<p dir="auto">Provides clear, detailed explanations when you struggle with cards by:</p>
<ul dir="auto">
<li>Breaking down complex concepts</li>
<li>Highlighting key relationships</li>
<li>Adding helpful context</li>
<li>Using analogies and examples</li>
</ul>
<p dir="auto">Particularly useful for understanding why you got a card wrong and filling knowledge gaps.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiExplainer field (I translated it french to English for universal documentation):</p>
<hr>
<ul dir="auto">
<li><b>EXPLANATION</b> A simple febrile seizure is characterized by its uniqueness and brevity during a febrile episode, which helps distinguish it from complex seizures or other neurological disorders.<br>* <b>MECHANISM</b> Fever can lower the seizure threshold in certain children, which explains why an elevation in body temperature can trigger a seizure in predisposed individuals.<p>[DATE:09/04/2024 VERSION:1.7 LLMMODEL:openai/gpt-4-0125-preview]</p></li>
</ul>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Helper</h3><a id="user-content-mnemonics-helper" aria-label="Permalink: Mnemonics Helper" href="#mnemonics-helper"></a></p>
<p dir="auto">A lightweight interactive CLI tool for quick mnemonic generation that:</p>
<ul dir="auto">
<li>Takes a concept and finds semantically similar existing mnemonics</li>
<li>Generates multiple new mnemonic options using LLMs</li>
<li>Lets you choose from generated options with vim-style navigation</li>
<li>Automatically saves selected mnemonics for future reference</li>
<li>Works independently of Anki, perfect for brainstorming sessions</li>
</ul>
<p dir="auto">Unlike the Mnemonics Creator which processes Anki cards in batch, this tool provides an interactive interface for generating mnemonics one concept at a time. Those new mnemonics can automatically be added to a dataset file that can readily be used by the other tools. This allows rapidly tailoring the scripts to your own imagination.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are the core benefits of those tools?</h3><a id="user-content-what-are-the-core-benefits-of-those-tools" aria-label="Permalink: What are the core benefits of those tools?" href="#what-are-the-core-benefits-of-those-tools"></a></p>
<p dir="auto">Basically if you run these tools each evening on cards you failed that day it will steadily improve your deck quality and learning effectiveness:</p>
<ul dir="auto">
<li>Automatically enhance cards you struggle with</li>
<li>Save time on manual card improvements</li>
<li>Create stronger memory connections</li>
<li>Track improvements with detailed history</li>
<li>Preserve card structure while enhancing content</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What is the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a>?</h3><a id="user-content-what-is-the-major-system" aria-label="Permalink: What is the Major System?" href="#what-is-the-major-system"></a></p>
<p dir="auto">The Major System is a powerful memory technique that converts numbers into consonant sounds, which can then be turned into memorable words. For example:</p>
<ul dir="auto">
<li>0 = S sound (as in "sea")</li>
<li>1 = T sound (as in "tea")</li>
<li>2 = N sound (as in "new")</li>
<li>etc.</li>
</ul>
<p dir="auto">This makes it easier to remember numbers by turning them into words. For example, "92" could become "pen" (P=9, N=2).</p>
<p dir="auto">You can read more about it <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">on wikipedia</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are Memory Anchors?</h3><a id="user-content-what-are-memory-anchors" aria-label="Permalink: What are Memory Anchors?" href="#what-are-memory-anchors"></a></p>
<p dir="auto">Memory anchors are existing associations you already know well that can be used to create new memories. For example, if you already strongly associate "Napoleon" with "France", you can use Napoleon as an anchor when learning new facts about French history.</p>
<p dir="auto">The tools can use your personal set of memory anchors to generate mnemonics that build on your existing knowledge.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Which LLM providers are supported?</h3><a id="user-content-which-llm-providers-are-supported" aria-label="Permalink: Which LLM providers are supported?" href="#which-llm-providers-are-supported"></a></p>
<p dir="auto">The tools use <a href="https://docs.litellm.ai/docs/" rel="nofollow">LiteLLM</a> which provides a unified interface to virtually any LLM provider including:</p>
<ul dir="auto">
<li>OpenAI</li>
<li>Anthropic</li>
<li>Google</li>
<li>OpenRouter</li>
<li>Azure</li>
<li>AWS Bedrock</li>
<li>Local models</li>
<li>And many more</li>
</ul>
<p dir="auto">Just specify the model in LiteLLM format (e.g. "openai/gpt-4" or "anthropic/claude-3-opus") and it will handle the rest.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What languages are supported?</h3><a id="user-content-what-languages-are-supported" aria-label="Permalink: What languages are supported?" href="#what-languages-are-supported"></a></p>
<p dir="auto">The tools work in any language supported by the LLM you choose to use. Since these scripts support virtually all LLM providers through LiteLLM, you can use any model that works well with your language. For example:</p>
<ul dir="auto">
<li>OpenAI's models support 100+ languages</li>
<li>Anthropic's Claude supports 100+ languages</li>
<li>You can use local models specifically trained for your language</li>
<li>etc.</li>
</ul>
<p dir="auto">The tools will preserve all language-specific formatting, including:</p>
<ul dir="auto">
<li>Right-to-left text</li>
<li>Special characters and diacritics</li>
<li>Language-specific punctuation</li>
<li>etc.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How do the Mnemonics Work?</h3><a id="user-content-how-do-the-mnemonics-work" aria-label="Permalink: How do the Mnemonics Work?" href="#how-do-the-mnemonics-work"></a></p>
<p dir="auto">The mnemonics tools use several proven memory techniques:</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a> for numbers</li>
<li>Vivid imagery and visualization</li>
<li>Personal memory anchors</li>
<li>Phonetic similarities</li>
<li>Humor and absurdity</li>
<li>Story-based connections</li>
</ul>
<p dir="auto">This creates memorable associations that help strengthen recall while preserving accuracy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where can I find example datasets for each tool?</h3><a id="user-content-where-can-i-find-example-datasets-for-each-tool" aria-label="Permalink: Where can I find example datasets for each tool?" href="#where-can-i-find-example-datasets-for-each-tool"></a></p>
<p dir="auto">The <code>examples/</code> folder contains training datasets and example files for each tool. While these were originally written in French and hastily translated to English, they provide good templates for creating your own datasets. Check the Example Files section below for details on each file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the future of this project?</h3><a id="user-content-whats-the-future-of-this-project" aria-label="Permalink: What's the future of this project?" href="#whats-the-future-of-this-project"></a></p>
<p dir="auto">This toolkit was developed and battle-tested while studying tens of thousands of Anki cards during medical school. It proved invaluable for maintaining and enhancing a large flashcard collection during intense study periods.</p>
<p dir="auto">However, as research commitments have grown, I now have limited time to transform these scripts into a more user-friendly package. The tools work well but need:</p>
<ul dir="auto">
<li>Packaging as a proper Anki addon</li>
<li>Installation via PyPI</li>
<li>Code deduplication and cleanup</li>
<li>Better documentation</li>
</ul>
<p dir="auto">I'm actively looking for contributors of all skill levels to help make these tools more accessible to the wider Anki community. Whether you're a seasoned developer or just getting started, all contributions are welcome! I can provide guidance and direction based on extensive experience with the codebase, while you help with the technical aspects of packaging and distribution.</p>
<p dir="auto">Check out the detailed roadmap below to see what needs improving. If you're interested in helping transform these battle-tested scripts into a polished Anki addon, please don't hesitate to reach out - I'm always happy to chat and help you get started!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why is there code duplication across the tools?</h3><a id="user-content-why-is-there-code-duplication-across-the-tools" aria-label="Permalink: Why is there code duplication across the tools?" href="#why-is-there-code-duplication-across-the-tools"></a></p>
<p dir="auto">This project evolved organically alongside my Python skills while solving real needs during medical school. Each tool was developed independently when needed, prioritizing functionality over code elegance. While they all work reliably, there's significant opportunity to unify their codebases around a common API.</p>
<p dir="auto">I can provide detailed guidance on refactoring and consolidating the code, but lack the time to implement these changes myself. Check the roadmap below if you're interested in helping streamline the codebase while preserving its battle-tested functionality.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">When Should I Use Each Tool?</h3><a id="user-content-when-should-i-use-each-tool" aria-label="Permalink: When Should I Use Each Tool?" href="#when-should-i-use-each-tool"></a></p>
<ul dir="auto">
<li><strong>Mnemonics Creator</strong>: Best for memorizing numbers, sequences, lists, and abstract concepts</li>
<li><strong>Illustrator</strong>: Ideal for visual learners and complex topics that benefit from imagery</li>
<li><strong>Reformulator</strong>: Use when card wording is unclear or you want variety in phrasing. Don't worry about running it on well-formatted cards - the LLM is trained to recognize and preserve cards that already follow best practices, avoiding unnecessary changes that could disrupt your learning</li>
<li><strong>Explainer</strong>: Great for understanding why you got a card wrong and filling knowledge gaps</li>
<li><strong>Mnemonics Helper</strong>: Simple script to quickly ask an LLM to come up with new mnemonics by taking into accountsthe <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> of the new subject vs your previous mnemonics.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What happens if I run a script multiple times on the same card?</h3><a id="user-content-what-happens-if-i-run-a-script-multiple-times-on-the-same-card" aria-label="Permalink: What happens if I run a script multiple times on the same card?" href="#what-happens-if-i-run-a-script-multiple-times-on-the-same-card"></a></p>
<p dir="auto">For most tools (Mnemonics Creator, Illustrator, Explainer), the previous content will be preserved in a collapsible HTML section using the <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code> tags. The new content appears above this section. This makes it easy to:</p>
<ul dir="auto">
<li>See the latest generated content first</li>
<li>Access previous versions by expanding the collapsible sections</li>
<li>Track how the card evolved over time</li>
</ul>
<p dir="auto">The Reformulator works differently - it replaces the content of the original field directly, but saves all previous versions and metadata in a separate <code>AnkiReformulator</code> field. This preserves the card's readability while maintaining a complete history.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How can I track which cards were modified?</h3><a id="user-content-how-can-i-track-which-cards-were-modified" aria-label="Permalink: How can I track which cards were modified?" href="#how-can-i-track-which-cards-were-modified"></a></p>
<p dir="auto">Each tool meticulously tracks modifications through tags and metadata to ensure transparency and reversibility. For example, when a tool processes a card, it adds a dated tag like <code>AnkiIllustrator::done::02/07/2023</code>. This makes it easy to:</p>
<ul dir="auto">
<li>Quickly identify which cards were modified by each tool</li>
<li>Track when modifications were made</li>
<li>Find cards that haven't been processed yet</li>
<li>Rollback changes if needed (especially with the Reformulator)</li>
</ul>
<p dir="auto">You can use these tags in the Anki browser to assess how many cards could benefit from each tool and review the modifications made. Note that notes for which a script failed will have a tag added to it. For example <code>AnkiI ::failed</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How much does it cost to run these tools?</h3><a id="user-content-how-much-does-it-cost-to-run-these-tools" aria-label="Permalink: How much does it cost to run these tools?" href="#how-much-does-it-cost-to-run-these-tools"></a></p>
<p dir="auto">The cost depends on your usage patterns and which features you enable:</p>
<ul dir="auto">
<li>Start small with a few cards to get comfortable with each tool</li>
<li>Built-in safeguards prevent accidental overspending:
<ul dir="auto">
<li>Maximum cards per run can be limited</li>
<li>Cost tracking per script is stored in the database</li>
<li>Failed API calls don't count towards your quota</li>
<li>You can set hard spending limits</li>
</ul>
</li>
<li>Typical costs per card:
<ul dir="auto">
<li>Reformulator: ~$0.02-0.04 (text only)</li>
<li>Mnemonics: ~$0.02-0.04 (text only)</li>
<li>Explainer: ~$0.03-0.06 (more complex reasoning)</li>
<li>Illustrator: ~$0.02 + image cost ($0.04-0.12 per image)</li>
</ul>
</li>
</ul>
<p dir="auto">The database tracks total spending per script, making it easy to budget and monitor costs. You can also use cheaper models for initial testing before scaling up to more capable ones.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Can I use these tools on mobile?</h3><a id="user-content-can-i-use-these-tools-on-mobile" aria-label="Permalink: Can I use these tools on mobile?" href="#can-i-use-these-tools-on-mobile"></a></p>
<p dir="auto">While you need to run the scripts themselves from a computer (not your phone), all changes are made directly to your Anki notes. This means:</p>
<ul dir="auto">
<li>Run the scripts from your computer/server</li>
<li>Sync Anki on your computer</li>
<li>The improved cards will appear on AnkiMobile/AnkiDroid after syncing</li>
<li>All generated content (reformulations, mnemonics, images, etc.) works perfectly on mobile</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Files</h3><a id="user-content-example-files" aria-label="Permalink: Example Files" href="#example-files"></a></p>
<p dir="auto">The <code>examples/</code> folder contains example files to help you get started. Note that these examples were originally written in French (except for system prompts) and were quickly translated to English - some examples may not make perfect sense but should still demonstrate the basic usage:</p>
<ul dir="auto">
<li><code>anki_ai_utils_tmux_launcher.sh</code>: A tmux-based launcher script I used every morning to automatically process cards I struggled with the previous day</li>
<li><code>anchors.json</code>: Example memory anchors mapping file</li>
<li><code>dataset_anchors.txt</code>: Training examples for memory anchor processing</li>
<li><code>explainer_dataset.txt</code>: Examples for the Explainer tool</li>
<li><code>illustrator_dataset.txt</code>: Training data for image generation</li>
<li><code>illustrator_sanitize_dataset.txt</code>: Examples for sanitizing image prompts</li>
<li><code>mnemonics_dataset.txt</code>: Training data for mnemonic generation</li>
<li><code>reformulator_dataset.txt</code>: Examples for card reformulation</li>
<li><code>string_formatting.py</code>: Handles cloze deletions and text formatting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the format of dataset files?</h3><a id="user-content-whats-the-format-of-dataset-files" aria-label="Permalink: What's the format of dataset files?" href="#whats-the-format-of-dataset-files"></a></p>
<p dir="auto">Dataset files (like <code>explainer_dataset.txt</code>, <code>reformulator_dataset.txt</code>, etc.) are simple text files where messages are separated by <code>----</code>. The first message is assumed to be a system prompt, followed by alternating user and assistant messages. This format mirrors a typical LLM conversation flow while remaining easy to read and edit.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Reformulator</h4><a id="user-content-reformulator-1" aria-label="Permalink: Reformulator" href="#reformulator-1"></a></p>
<p dir="auto">The Reformulator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python reformulator.py \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/reformulator_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --main_field_index 0 \
    --llm &quot;openai/gpt-4&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --max_token 4000 \
    --llm_temp 0"><pre>python reformulator.py \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/reformulator_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --main_field_index 0 \
    --llm <span><span>"</span>openai/gpt-4<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --max_token 4000 \
    --llm_temp 0</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for reformulation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>main_field_index</code>: Index of the field to reformulate (0 for first field)</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>max_token</code>: Maximum tokens per query</li>
<li><code>llm_temp</code>: LLM temperature (0 for consistent output)</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if already reformulated</li>
<li><code>--print_db_then_exit</code>: Display database contents and exit</li>
<li><code>--parallel</code>: Number of parallel processes (default 4)</li>
<li><code>--exclude_media</code>: Skip cards containing media</li>
<li><code>--mode</code>: Either 'reformulate' or 'reset' to restore original content. Note that the 'reset' feature is not absolutely guaranteed to work, but if things go wrong there are tons of logs on purpose to make sure you don't lose anything.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics</h4><a id="user-content-mnemonics" aria-label="Permalink: Mnemonics" href="#mnemonics"></a></p>
<p dir="auto">The Mnemonics Creator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/mnemonics_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --n_mnemonic 1"><pre>python mnemonics.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/mnemonics_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --n_mnemonic 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for mnemonic generation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>n_mnemonic</code>: Number of mnemonics to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have mnemonics</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics Creator CLI</h4><a id="user-content-mnemonics-creator-cli" aria-label="Permalink: Mnemonics Creator CLI" href="#mnemonics-creator-cli"></a></p>
<p dir="auto">The Mnemonics Creator CLI provides an interactive interface for generating mnemonics:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embed_model &quot;openai/text-embedding-3-small&quot;"><pre>python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embed_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span></pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>top_k</code>: Number of similar existing mnemonics to use as examples (default: 100)</li>
<li><code>n_gen</code>: Number of new mnemonics to generate per query (default: 10)</li>
<li><code>model</code>: LLM model to use in litellm format</li>
<li><code>embed_model</code>: Model for semantic similarity search</li>
<li><code>query</code>: Optional initial query to process</li>
<li><code>gui</code>: Enable GUI interface (not yet implemented)</li>
</ul>
<p dir="auto">The CLI provides an interactive interface where you can:</p>
<ul dir="auto">
<li>Enter concepts to generate mnemonics for</li>
<li>See similar existing mnemonics as context</li>
<li>Choose from multiple generated options</li>
<li>Navigate with vim-style keys (j/k) or numbers</li>
<li>Save selected mnemonics to your collection</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Explainer</h4><a id="user-content-explainer-1" aria-label="Permalink: Explainer" href="#explainer-1"></a></p>
<p dir="auto">The Explainer can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python explainer.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/explainer_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --llm_max_token 3000"><pre>python explainer.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/explainer_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --llm_max_token 3000</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for generating explanations</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>llm_max_token</code>: Maximum tokens per query</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have explanations</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Illustrator</h4><a id="user-content-illustrator-1" aria-label="Permalink: Illustrator" href="#illustrator-1"></a></p>
<p dir="auto">The Illustrator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python illustrator.py \
    --field_names &quot;front,back&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/illustrator_dataset.txt&quot; \
    --dataset_sanitize_path &quot;data/illustrator_sanitize.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --n_image 1"><pre>python illustrator.py \
    --field_names <span><span>"</span>front,back<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/illustrator_dataset.txt<span>"</span></span> \
    --dataset_sanitize_path <span><span>"</span>data/illustrator_sanitize.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --n_image 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for image generation</li>
<li><code>dataset_sanitize_path</code>: Examples for sanitizing unsafe prompts</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>n_image</code>: Number of images to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have illustrations</li>
<li><code>--disable_notif</code>: Disable ntfy.sh notifications</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Roadmap</h3><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><i>This TODO list is maintained automatically by <a href="https://github.com/thiswillbeyourgithub/MdXLogseqTODOSync">MdXLogseqTODOSync</a></i></p>

<ul dir="auto">
<li>turn those scripts into addons</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Applies to all tools</h3><a id="user-content-applies-to-all-tools" aria-label="Permalink: Applies to all tools" href="#applies-to-all-tools"></a></p>
</li>
<li>use beartype everywhere</li>
<li>add an arg to include tags or not in the LLM context for a given note, as otherwise the LLM can get confused by some acronyms
<ul dir="auto">
<li>but with a regex arg to keep only the tags that match the regex. This way we can keep only a portion of them for the LLM</li>
</ul>
</li>
<li>store all inference in a compressed sqlite db instead of a json. It gets too large</li>
<li>add check that we indeed removed all the done tags</li>
<li>actually there's no need to store the "Done" tags because all important info is stored in the field</li>
<li>use xml formatting for the examples
<ul dir="auto">
<li>make use of  tags too</li>
</ul>
</li>
<li>make it installable with a setup.py on pypi</li>
<li>add images to illustrate the benefits of using each</li>
<li>do a unique class that could be used to unify all those codes
<ul dir="auto">
<li>arguments:
<ul dir="auto">
<li>name (to differentiate each children: for example "illustrator")</li>
<li>string_format (can be overloaded)</li>
<li>in the init, check that indeed there is a version attribute</li>
</ul>
</li>
</ul>
</li>
<li>use toml instead of json, it allows setting comments too</li>
<li>tell user how much time each answer took</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator-1" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator-1"></a></p>
<ul dir="auto">
<li>Add keybindings
<ul dir="auto">
<li>binding e to edit a proposition</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator-2" aria-label="Permalink: Illustrator" href="#illustrator-2"></a></p>
</li>
<li>use an llm to extract numbers
<ul dir="auto">
<li>ask it to do quick transformations like turn 48h into 2 days, modify units, etc,</li>
</ul>
</li>
<li>add support for note containing media like audio, images etc</li>
<li>add a mode without actually creating images. This could be used like a mnemonics after all.</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator-2" aria-label="Permalink: Reformulator" href="#reformulator-2"></a></p>
</li>
<li>Add 5 to 10 example for the LLM of how to manage media like iimages etc then add support for them</li>
<li>make it work with specific fstring template for field replacement. Otherwise it can only reformulate a single field
<ul dir="auto">
<li>better: add an arg to specify the single output field, and an arg to specify a comma separated list of input fields</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">explainer</h3><a id="user-content-explainer-2" aria-label="Permalink: explainer" href="#explainer-2"></a></p>
</li>
<li>compute all embeddings at the start, making it faster</li>
<li>it's actually quite terrible. Use one LLM call to ask for which follow up questions to ask, then another LLM call to answer each using async
<ul dir="auto">
<li>save each new question answer as a <details> tag to make it easy to access on phones by touching the field</details></li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ankimnemonics</h3><a id="user-content-ankimnemonics" aria-label="Permalink: Ankimnemonics" href="#ankimnemonics"></a></p>
</li>
<li>comment out the mnemonics that dont respect the rule of adding the subject first</li>
<li>understand why it sometimes hangs during a run</li>
<li>make it distinguish 'has to appear in plain' vs 'has to appear as mnemonic'?</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">AnkiAiFilter</h3><a id="user-content-ankiaifilter" aria-label="Permalink: AnkiAiFilter" href="#ankiaifilter"></a></p>
</li>
<li>use an eval llm like in <a href="https://wdoc.readthedocs.io/en/latest/" rel="nofollow">wdoc</a> to better filer an anki query
<ul dir="auto">
<li>actually wdoc can already be used for that! Maybe it should be converted into an addon?</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tagger (In project)</h2><a id="user-content-tagger-in-project" aria-label="Permalink: Tagger (In project)" href="#tagger-in-project"></a></p>
</li>
<li>always prepend tags by ankitagger: but customizable</li>
<li>always sort those tags by alphabetical order</li>
<li>add modes:
<ul dir="auto">
<li>mode "predefined": the user gives a list of tags and the LLM finds which to apply to each note given a query
<ul dir="auto">
<li>loop over each note and ask it to generate tags</li>
</ul>
</li>
</ul>
</li>
<li>arg for image support if media found
<ul dir="auto">
<li>if the card contains an image, it should be hashed, then a cached call to a func that asks a vision model to describe the type of image, then use the embedding of this answer to suggest the appropriate tags to suggest to the LLM for classification</li>
</ul>
</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">This project makes heavy use of <a href="https://git.foosoft.net/alex/anki-connect" rel="nofollow">AnkiConnect</a> to interact with Anki.</p>
</details>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU law mandating universal chargers for devices comes into force (255 pts)]]></title>
            <link>https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</link>
            <guid>42534851</guid>
            <pubDate>Sat, 28 Dec 2024 21:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force">https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</a>, See on <a href="https://news.ycombinator.com/item?id=42534851">Hacker News</a></p>
Couldn't get https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>