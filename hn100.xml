<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 10 Oct 2025 09:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[My approach to building large technical projects (2023) (144 pts)]]></title>
            <link>https://mitchellh.com/writing/building-large-technical-projects</link>
            <guid>45535202</guid>
            <pubDate>Fri, 10 Oct 2025 03:45:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mitchellh.com/writing/building-large-technical-projects">https://mitchellh.com/writing/building-large-technical-projects</a>, See on <a href="https://news.ycombinator.com/item?id=45535202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Whether it's building a new project from scratch, implementing a big feature,
or beginning a large refactor, it can be difficult to stay motivated and
complete large technical projects. A method that works really well for me
is to continuously see real results and to order my work based on that.</p>
<p>We've all experienced that feeling of excitement starting a new project.
The first few weeks you can't wait to get on the computer to work. Then
slowly over time you get distracted or make up excuses and work on it less.
If this is for real work, you forcibly slog your way to the finish line but
every day is painful. If this is for fun, you look back years from now and
remember what could've been.</p>
<p>I've learned that when I break down my large tasks in chunks that result
in seeing tangible forward progress, I tend to finish my work and retain
my excitement throughout the project. People are all motivated and driven
in different ways, so this may not work for you, but as a broad generalization
I've not found an engineer who doesn't get excited by a good demo. And the
goal is to always give yourself a good demo.</p>
<p>I'm not claiming that anything I say in this post is novel. It definitely
shares various aspects of well-known software engineering or management
practices. I'm just sharing the way I approach the larger technical work
that I do and why I do it this way.</p>
<p>I'll use <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/mitchellh/status/1662217955424493570">my terminal emulator project</a>
as an example throughout this post so that there is realistic, concrete
experience I can share. There's plenty of other projects I could've used but
I'll choose this one since it's not related to my professional work and
it is recent enough to be fresh in my mind.</p>
<div><p>I want to be crystal clear that I am not shaming anyone for not completing
projects. As long as you're having fun and feel accomplished (or simply don't
care), good for you and more power to you. This blog post is aimed
at people who <em>want to finish projects more</em> or simply want to learn how
I strive to finish projects more.</p></div>
<hr>
<h2 id="the-starting-line">The Starting Line</h2>
<p>Initially, you have some large project and you have to figure <em>how to start</em>.
For me, this is the hardest part and I can spend hours
-- sometimes days -- waffling over the right starting point.</p>
<p>For my terminal emulator, there were a number of large components that
I knew would have to exist if I ever intended to finish this project:
terminal parsing, running and managing a shell process, font rendering,
grid rendering, input handling (keyboard/mouse), etc. There are hundreds
of relatively large sub-projects on the path to "done."</p>
<p>If my initial goal was to see a launchable terminal that could run Neovim,
I'd be in big trouble. Even with <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/There_are_unknown_unknowns">unknown unknowns</a>,
this goal just <em>sounds too big</em>. I can intuitively realize that
there are a lot of components on that path: rendering a GUI, process launching,
terminal parsing and state management. This is a bad goal, it's too big and
I'd probably lose interest a month or two in.</p>
<p>Instead, I try to think what a <em>realistic</em> project is where I can
<em>see results as soon as possible</em>. Once you apply that filter, the number
of viable sub-projects shrinks dramatically. Here are some examples:</p>
<ul>
<li>VT Parsing - parsing the terminal escape sequences</li>
<li>Blank window rendering - open a window and draw a blank canvas</li>
<li>Child process lanching - launch a child shell such as bash, zsh, fish,
setup the TTY and be able to read output from it (i.e. the initial
shell prompt)</li>
</ul>
<p>I don't try to enumerate all the big sub-projects at this stage. I just
kind of get an idea of the <em>rough shape</em> the project will take and find
one that I can build in isolation and also physically see some sort of
real results.</p>
<div><p>This is the phase where experience helps the most. Engineers with
more experience are usually able to more effectively paint the picture
of the rough shape a project will take. They can identify various
subcomponents with more accuracy and see how they pieces fit together.
With less experience, or in a domain I'm unfamiliar with, I just take
a best guess and expect there is a higher likelihood I'll throw my work
away at some point.</p></div>
<hr>
<h2 id="early-results">Early Results</h2>
<p>Early work tends to not be very <em>visible</em> and that makes seeing
tangible results seem difficult. For example, if I chose to work on
VT parsing for my terminal, I can't <em>see</em> it work without also hooking up
a UI of some sort. Or for some other project if I chose to work on a
database schema and minimal API, I similarly can't see that work without
writing a client along with a CLI or GUI.</p>
<p>If the initial subproject you choose to work on is a UI, then you can
quickly see some results of course! For various reasons, I rarely start
frontend first and usually start backend first. And in any situation, you'll
eventually get to the backend and reach a similar challenge.</p>
<p>The best tool to get past this phase is automated testing (usually unit
testing at this stage). Automated tests let you actually run some code and
see it is working and also has the benefit of being good hygiene.</p>
<p>This gives you another guiding point for picking out your first few tasks:
if it isn't graphical, you want to pick something that is testable without
too much fuss so you can see some results.</p>
<p>For my terminal, I decided to start with VT parsing first, because it
was a part of a terminal at the time that I didn't know too much about and
it felt like something that I could very easily test: give it some example
input as a string, expect some parsed action or event as output.</p>
<p>Seeing the progression of "1 test passed", "4 tests passed," "13 tests passed"
and so on is super exciting to me. I'm running some code I wrote <em>and it's
working</em>. And I know that I'm progressing on some critical sub-component of
a larger project.</p>
<hr>
<h2 id="sprint-to-demos">Sprint to Demos</h2>
<p>My goal with the early sub-projects isn't to build a <em>finished sub-component</em>,
it is to build a <em>good enough sub-component</em> so I can move on to the next
thing on the path to a <em>demo</em>. ✨</p>
<p>This tradeoff isn't just manifested in functionality. It may be manifested
in algorithmic or design considerations. For example, you may know that
in the future, you'll need to use something like a real database or a fancy
data structure or support streaming data. But for the initial set of work,
you can just use in-memory contents, built-in data structures such as
dictionaries, and require all your inputs/outputs up front.</p>
<p>I think this is an important tradeoff so I will repeat it: <strong>do not let
perfection be an enemy of progress.</strong> Going further, do not let future
improvements you <em>know you'll have to make</em> stop you from moving on to
the next thing. The goal is to get to a demo.</p>
<p>No matter what I'm working on, I try to build one or two demos per week
intermixed with automated test feedback as explained in the previous section.</p>
<p>Building a demo also provides you with invaluable product feedback. You
can quickly intuit whether something <em>feels good</em>, even if it isn't fully
functional. These aren't "minimum viable products", because they really aren't
viable, but they're good enough to provide an engineer some valuable
self-reflection.</p>
<div><p>This is an area where I think experience actually hurts. I've seen senior
engineers get bogged down building the perfect thing and by the time
they get a demo, they realize <em>it sucks</em>. The implementation doesn't suck,
but the product or feature itself actually sucks.</p></div>
<p>Recall that for the terminal the first task I chose was VT parsing. In
the early stages, I only saw automated tests work. To get to my first demo,
I built a shell script that would run some command, capture its output,
feed it to my VT parser, and output everything it parsed (or couldn't).
Over time, I iterated on this CLI as my first "UI" -- I would render
the terminal grid using ASCII.</p>
<p>This gave me immense satisfaction since I could run simple programs like
<code>man</code> or <code>ls</code> or more complex programs like <code>vim</code> and see my parser work (or break,
which is equally exciting in its own way).</p>
<p>In this scenario, the CLI I was writing was relatively useless long term
(I ended up throwing it away rather quickly). But the day or two I spent
building it as a demo provided me with an important feeling of progress and
<em>seeing</em> something work helped keep me motivated.</p>
<hr>
<h2 id="build-for-yourself">Build for Yourself</h2>
<p>This section will apply more to personal projects than to work-assigned
projects. Even if you aspire to release some software for others, build
<em>only what you need as you need it</em> and <em>adopt your software as quickly
as possible</em>.</p>
<p>I'm always more motivated working on a problem I'm experiencing myself<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>.
And if a product designed for you doesn't work for you, it's very likely
not going to work well for others, either.
Therefore, my path from demos to an actual real-world usable product is
to find the shortest path to building only the functionality I think I need.</p>
<p>For my terminal, that meant first being able to load my shell configuration
(fish) and from there being able to launch and use Neovim. So I beelined
all my work to only the functionality needed for that: only the escape
sequences those programs used, only rendering the font I use daily, etc.
Examples of features I initially omitted: scrolling, mouse selection,
search, tabs/splits, etc.</p>
<p>Then I started using my terminal as a daily driver. This step usually
has a few false starts; you realize you actually need some feature
you omitted or forgot. In my initial runs of my terminal, I realized my
arrow keys didn't do anything, there were subtle (but workflow-breaking)
rendering bugs, etc. So I'd go abandon using it, but it gave me tangible
tasks to work on next.</p>
<p>Additionally, I always feel a lot of pride using software with code
that I wrote and that usually helps keep me motivated to continue
working on it.</p>
<hr>
<h2 id="packaging-it-up">Packaging it Up</h2>
<ol>
<li>
<p>Decompose a large problem into smaller problems. Importantly,
each small problem must have some clear way you can see the results
of your work.</p>
</li>
<li>
<p>Only solve the smaller problem enough to progress on a demo-aspect
of the larger problem, then move on to the next small problem.</p>
</li>
<li>
<p>Only solve enough small problems to be able to begin building
runnable demos of your software, then continue to iterate on more
functionality. Make demos as frequently as you can.</p>
</li>
<li>
<p>Prioritize functionality that enables you to adopt your own software,
if applicable (a personal project, a work project solving a problem
you actually have, etc.). Then continue to solve your own problems first.</p>
</li>
<li>
<p>Go back and iterate on each component as needed for future improvements,
repeating this process as needed.</p>
</li>
</ol>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>And that's pretty much it. I've followed this general pattern on personal
projects, group projects, work projects, school projects, etc. and it's
how I keep myself motivated<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>.</p>
<p>Note that I didn't mention a lot of things! I don't talk about shipping.
I know a lot of people find shipping motivational. I don't think you need
to ship a project for it to be successful. And for me, I find shipping
too big of an event to motivate me long-term. I don't talk about tooling
(Git workflows, CI, etc.). I've used my process across multiple jobs and fit
it into whatever process is established. And so on.</p>
<p>I think that helps show how much of a <em>personal process</em> this is. Everyone
I think needs to find some process to reinforce their motivation in a healthy
way. I realized seeing results motivates me really strongly, I've
built my work style around that, and it has worked well for me thus far.</p>
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1">
<p>This is why I've tried to only ever worked at companies that build
or sell products that I would use. A personal choice. <a href="#user-content-fnref-1" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>Ironically, my preferred method of <em>learning</em> is to read reference
material cover to cover, which is pretty much the exact opposite of the
way I approach <em>building</em> something. <a href="#user-content-fnref-2" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The RubyGems "Security Incident" (123 pts)]]></title>
            <link>https://andre.arko.net/2025/10/09/the-rubygems-security-incident/</link>
            <guid>45535149</guid>
            <pubDate>Fri, 10 Oct 2025 03:30:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andre.arko.net/2025/10/09/the-rubygems-security-incident/">https://andre.arko.net/2025/10/09/the-rubygems-security-incident/</a>, See on <a href="https://news.ycombinator.com/item?id=45535149">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>09 Oct 2025</p><p>Ruby Central posted an extremely concerning “<a href="https://rubycentral.org/news/rubygems-org-aws-root-access-event-september-2025/">Incident Response Timeline</a>” today, in which they make a number of exaggerated or purely misleading claims. Here’s my effort to set the record straight.</p><p>First, and most importantly: <strong>I was a primary operator of RubyGems.org, securely and successfully, for over ten years. Ruby Central does not accuse me of any harms or damages in their post, in fact stating “we have no evidence to indicate that any RubyGems.org data was copied or retained by unauthorized parties, including Mr. Arko.”</strong></p><p>The actions I took during a time of great confusion and uncertainty (created by Ruby Central!) were careful, specific, and aimed to defend both Ruby Central the organization and RubyGems.org the service from potential threats.</p><p>The majority of the team, including developers in the middle of paid full-time work for Ruby Central, had just had all of their permissions on GitHub revoked. And then restored six days later. And then revoked again the next day. Even after the second mass-deletion of team permissions, Marty Haught sent an email to the team within minutes, at 12:47pm PDT, saying he was (direct quote) “terribly sorry” and “I messed up”. <small><strong>Update</strong>: Added email timestamp.</small></p><p>The erratic and contradictory communication supplied by Marty Haught, and the complete silence from Shan and the board, made it impossible to tell exactly who had been authorized to take what actions. As this situation occurred, I was the primary on-call. My contractual, paid responsibility to Ruby Central was to defend the RubyGems.org service against potential threats.&nbsp;</p><p>Marty’s final email clearly stated “I’ll follow up more on this and engage with the governance rfc in good faith.”. Just a few minutes after that email, at 1:01pm PDT, Marty also posted <a href="https://github.com/rubygems/rfcs/pull/61#issuecomment-3309461815">a public GitHub comment</a>, where he agreed to participate in the proposed governance process and stated “I’m committed to find the right governance model that works for us all. More to come.” <small><strong>Update</strong>: screenshot of comment removed and replaced with link, since the comment appears to still be visible (at least to logged out users) on GitHub.</small></p><p>Given Marty’s claims, the sudden permission deletions made no sense. Worried about the possibility of hacked accounts or some sort of social engineering, I took action as the primary on-call engineer to lock down the AWS account and prevent any actions by possible attackers. I did not change the email addresses on any accounts, leaving them all owned by a team-shared email at rubycentral.org, to ensure the organization retained overall control of the accounts, even if individuals were somehow taking unauthorized actions.</p><p>Within a couple of days, Ruby Central made an (unsigned) public statement, and various board members agreed to talk directly to maintainers. At that point, I realized that what I thought might have been a malicious takeover was both legitimate and deliberate, and Marty would never “fix the permissions structure”, or “follow up more” as he said.</p><p>Once I understood the situation, I backed off to let Ruby Central take care of their “security audit”. I left all accounts in a state where they could recover access. I did not alter, or try to alter, anything in the Ruby Central systems or GitHub repository after that. I was confident, at the time, that Ruby Central’s security experts would quickly remove all outside access.</p><p>My confidence was sorely misplaced.</p><p>Almost two weeks later, someone asked if I still had access and I discovered (to my great alarm), that Ruby Central’s “security audit” had failed. Ruby Central also had not removed me as an “owner” of the Ruby Central GitHub Organization. They also had not rotated any of the credentials shared across the operational team using the RubyGems 1Password account.</p><p>I believe Ruby Central confused themselves into thinking the “Ruby Central” 1Password account was used by operators, and they did revoke my access there. However, that 1Password account was not used by the open source team of RubyGems.org service operators. Instead, we used the “RubyGems” 1Password account, which was full of operational credentials. Ruby Central did not remove me from the “RubyGems” 1Password account, even as of today.</p><p>Aware that I needed to disclose this surprising access, but also aware that it was impossible for anyone except former operators to exploit this security failure, I immediately wrote an email to Ruby Central to disclose the problem.</p><p>Here is a copy of my disclosure email, in full.</p><pre tabindex="0"><code>From: André Arko &lt;andre@arko.net&gt;
Subject: Re: RubyGems.org access
Date: September 30, 2025 at 10:23:12 AM PDT
To: Marty Haught &lt;marty@rubycentral.org&gt;

Hi Marty,

It has come to my attention that despite the statements in [your] email, I have had uninterrupted access to RubyGems.org production environments from September 18 until today, September 30, via the root credentials of the Ruby Central AWS account, as well as continued and ongoing access to the full feed of production alerts and logs in DataDog.

It seems that the only permissions I have had removed are from the GitHub organization named "rubygems", which as you know is unrelated to the RubyGems.org production access you mention in your email.

I have also noticed I am still, as of September 30, the owner of the GitHub organizations named "rubycentral" and "rubytogether".

I am unable to transfer the HelpScout or PagerDuty accounts, as you have disabled my andre@rubygems.org Google account.

Please advise as to your desired resolution of this situation.

Thank you,
André Arko
</code></pre><p>Ruby Central did not reply to this email for over three days.</p><p>When they finally did reply, they seem to have developed some sort of theory that I was interested in “access to PII”, which is entirely false. <strong>I have no interest in any PII, commercially or otherwise</strong>. As my private email published by Ruby Central demonstrates, my entire proposal was based solely on company-level information, with no information about individuals included in any way. Here’s their response, over three days later.</p><pre tabindex="0"><code>From: Marty Haught &lt;marty@rubycentral.org&gt;
Subject: Re: RubyGems.org access
Date: October 3, 2025 at 6:54:01 PM MDT
To: André Arko &lt;andre@arko.net&gt;

Hi André,

Please confirm that you cannot access the Ruby Central AWS root account credentials, either through the console or by access keys.

In addition, please confirm whether you are in possession of any RubyGems.org production data, &nbsp;including, but not limited to, server logs, access logs, PII, or other organizational data.

Thank you,
Marty
</code></pre><p>In addition to ignoring the (huge) question of how Ruby Central failed to secure their AWS Root credentials for almost two weeks, and <strong>appearing to only be aware of it because I reported it to them</strong>, their reply also failed to ask whether any other shared credentials might still be valid. There were more.</p><pre tabindex="0"><code>From: André Arko &lt;andre@arko.net&gt;
Subject: Re: RubyGems.org access
Date: October 5, 2025 at 11:59:35 AM PDT
To: Marty Haught &lt;marty@rubycentral.org&gt;

Hi Marty,

Thanks for letting me know you got my email disclosing my unintended access. I’m concerned that security must not be a very high priority for Ruby Central since no one acknowledged my disclosure for more than three days, but I appreciate the confirmation.

As far as I can tell, I can no longer access the Ruby Central AWS root account either through the console or via access keys.

I confirm I did not download or save any production data after your email of September 18, including server logs, access logs, PII, or other organizational data.

However, while checking AWS credentials in order to write this email, I discovered that several other service credentials have not been rotated, and are still valid for production AWS access. That means both myself and the other former operators all still have access to AWS via those previously-shared credentials.

I would appreciate it if you could answer the request from my first email, and reply with your desired resolution for this remaining unintended production access, as well as the GitHub organization ownership.

Thanks,
André
</code></pre><p>Unbeknownst to me, while I was answering Marty’s email in good faith, Ruby Central’s attorney was sending my lawyer a letter alleging I had committed a federal crime, on the theory that I had “hacked” Ruby Central’s AWS account. On the contrary, my actions were taken in defense of the service that Ruby Central was paying me to support and defend.</p><p>With my side of the story told, I’ll leave it to you to decide whether you think it’s true that “Ruby Central remains committed to transparent, responsible stewardship of the RubyGems infrastructure and to maintaining the security and trust that the Ruby ecosystem depends on.”</p><p>My time to write is sponsored by <a href="https://spinel.coop/">Spinel</a>. If your company could use some world-class expertise on gems, Rails, CI, or developer productivity, check out <a href="https://spinel.coop/">spinel.coop</a> and hire us!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open source, logical multi-master PostgreSQL replication (109 pts)]]></title>
            <link>https://github.com/pgEdge/spock</link>
            <guid>45533870</guid>
            <pubDate>Thu, 09 Oct 2025 22:53:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pgEdge/spock">https://github.com/pgEdge/spock</a>, See on <a href="https://news.ycombinator.com/item?id=45533870">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Spock Multi-Master Replication for PostgreSQL</h2><a id="user-content-spock-multi-master-replication-for-postgresql" aria-label="Permalink: Spock Multi-Master Replication for PostgreSQL" href="#spock-multi-master-replication-for-postgresql"></a></p>
<p dir="auto"><a href="https://github.com/pgEdge/spock/actions/workflows/spockbench.yml"><img src="https://github.com/pgEdge/spock/actions/workflows/spockbench.yml/badge.svg" alt="Regression Tests and Spockbench"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="https://github.com/pgEdge/spock/blob/main/README.md#building-the-spock-extension">Building the Spock Extension</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/README.md#building-the-spock-documentation">Building the Spock Documentation</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/README.md#basic-configuration-and-usage">Basic Configuration and Usage</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/upgrading_spock.md">Upgrading a Spock Installation</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/install_spock.md#advanced-configuration-options-for-spock">Advanced Configuration Options</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/managing/index.md">Spock Management Features</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/modify/index.md">Modifying a Cluster</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/monitoring/index.md">Monitoring your Cluster</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/spock_functions/index.md">Spock Functions</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/modify/spockctrl/index.md">Using spockctrl Management Functions</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/spock_release_notes.md">Release Notes</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/limitations.md">Limitations</a></li>
<li><a href="https://github.com/pgEdge/spock/blob/main/docs/FAQ.md">FAQ</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Spock Multi-Master Replication for PostgreSQL - Prerequisites and Requirements</h2><a id="user-content-spock-multi-master-replication-for-postgresql---prerequisites-and-requirements" aria-label="Permalink: Spock Multi-Master Replication for PostgreSQL - Prerequisites and Requirements" href="#spock-multi-master-replication-for-postgresql---prerequisites-and-requirements"></a></p>
<p dir="auto">The Spock extension provides multi-master replication for PostgreSQL versions 15 and later.  Take the following requirements into consideration as you design your cluster:</p>
<ul dir="auto">
<li>
<p dir="auto">You will need to install the <code>Spock</code> extension on each node in your cluster.  If you're performing a major version upgrade, the old node can be running a recent version of pgLogical2 before upgrading it to become a Spock node.</p>
</li>
<li>
<p dir="auto">On each node in your cluster, tables must have the same name and reside in the same schema. To check the table name and schema name of an existing table, you can connect to the database with <a href="https://www.postgresql.org/docs/17/app-psql.html" rel="nofollow">psql</a> and use the <code>\d</code> meta-command:</p>
</li>
</ul>
<p dir="auto"><code>SELECT schemaname, tablename FROM pg_tables ORDER BY schemaname, tablename;</code></p>
<p dir="auto">For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lcdb=# \d
               List of relations
 Schema |      Name      |   Type   |  Owner
--------+----------------+----------+----------
 public | table_a        | table    | ec2-user
 public | table_a_id_seq | sequence | ec2-user
 public | table_b        | table    | ec2-user
 public | table_b_id_seq | sequence | ec2-user
 public | table_c        | table    | ec2-user
 public | table_c_id_seq | sequence | ec2-user
(6 rows)
"><pre>lcdb<span>=</span><span><span>#</span> \d</span>
               List of relations
 Schema |      Name      |   Type   |  Owner
<span><span>--</span>------+----------------+----------+----------</span>
 public | table_a        | table    | ec2<span>-</span>user
 public | table_a_id_seq | sequence | ec2<span>-</span>user
 public | table_b        | table    | ec2<span>-</span>user
 public | table_b_id_seq | sequence | ec2<span>-</span>user
 public | table_c        | table    | ec2<span>-</span>user
 public | table_c_id_seq | sequence | ec2<span>-</span>user
(<span>6</span> rows)
</pre></div>
<ul dir="auto">
<li>Each table must also have the same columns and primary keys, with the same data types in each column.  To review detailed information for all tables within a specific schema, connect to the database with psql and use the <code>\d schema_name.*</code> command; for example:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="lcdb=# \d public.*
                                   Table &quot;public.table_a&quot;
   Column   |           Type           | Collation | Nullable |           Default
------------+--------------------------+-----------+----------+------------------------------
 id         | bigint                   |           | not null | generated always as identity
 name       | text                     |           | not null |
 qty        | integer                  |           | not null |
 created_at | timestamp with time zone |           | not null | now()
Indexes:
    &quot;table_a_pkey&quot; PRIMARY KEY, btree (id)

                       Sequence &quot;public.table_a_id_seq&quot;
  Type  | Start | Minimum |       Maximum       | Increment | Cycles? | Cache
--------+-------+---------+---------------------+-----------+---------+-------
 bigint |     1 |       1 | 9223372036854775807 |         1 | no      |     1
Sequence for identity column: public.table_a.id

     Index &quot;public.table_a_pkey&quot;
 Column |  Type  | Key? | Definition
--------+--------+------+------------
 id     | bigint | yes  | id
primary key, btree, for table &quot;public.table_a&quot;
..."><pre>lcdb<span>=</span><span><span>#</span> \d public.*</span>
                                   Table <span><span>"</span>public.table_a<span>"</span></span>
   Column   |           Type           | Collation | Nullable |           Default
<span><span>--</span>----------+--------------------------+-----------+----------+------------------------------</span>
 id         | <span>bigint</span>                   |           | <span>not null</span> | generated always <span>as</span> identity
 name       | <span>text</span>                     |           | <span>not null</span> |
 qty        | <span>integer</span>                  |           | <span>not null</span> |
 created_at | <span>timestamp with time zone</span> |           | <span>not null</span> | now()
Indexes:
    <span><span>"</span>table_a_pkey<span>"</span></span> <span>PRIMARY KEY</span>, btree (id)

                       Sequence <span><span>"</span>public.table_a_id_seq<span>"</span></span>
  Type  | Start | Minimum |       Maximum       | Increment | Cycles? | Cache
<span><span>--</span>------+-------+---------+---------------------+-----------+---------+-------</span>
 <span>bigint</span> |     <span>1</span> |       <span>1</span> | <span>9223372036854775807</span> |         <span>1</span> | no      |     <span>1</span>
Sequence for identity column: <span>public</span>.<span>table_a</span>.id

     Index <span><span>"</span>public.table_a_pkey<span>"</span></span>
 Column |  Type  | Key? | Definition
<span><span>--</span>------+--------+------+------------</span>
 id     | <span>bigint</span> | yes  | id
<span>primary key</span>, btree, for table <span><span>"</span>public.table_a<span>"</span></span>
...</pre></div>
<ul dir="auto">
<li><code>CHECK</code> constraints and <code>NOT NULL</code> constraints must be the same or more permissive on any standby node that acts only as a subscriber.</li>
</ul>
<p dir="auto">For more information about the Spock extension's advanced functionality, visit <a href="https://github.com/pgEdge/spock/blob/main/docs/features.md">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building the Spock Extension</h2><a id="user-content-building-the-spock-extension" aria-label="Permalink: Building the Spock Extension" href="#building-the-spock-extension"></a></p>
<p dir="auto">You will need to build the Spock extension on a patched PostgreSQL source tree to which you have applied version-specific <code>.diff</code> files from the <code>spock/patches/Postgres-version</code> directory. The high-level steps to build Postgres and the spock extension are:</p>
<ol dir="auto">
<li>
<p dir="auto">Get the <a href="https://www.postgresql.org/docs/current/install-getsource.html" rel="nofollow">Postgres source</a>.</p>
</li>
<li>
<p dir="auto">Copy the patch files to the base repository; the patches for each Postgres version are in a version-specific subdirectory of the <a href="https://github.com/pgEdge/spock/tree/main/patches">spock repo</a>.  Then, apply each patch, use the command:</p>
</li>
</ol>
<p dir="auto"><code>patch -p1 &lt; path_to_patch/patch_name</code></p>
<p dir="auto">Note that you must apply the patches in the numerical order designated by their prefixes in the <code>spock</code> repository (for example, <code>pg16-015-patch-name</code>, then <code>pg16-020-patch-name</code>, then <code>pg16-025-patch-name</code>).</p>
<ol start="3" dir="auto">
<li>
<p dir="auto"><code>configure</code>, <code>make</code>, and <code>make install</code> the Postgres server as described in the <a href="https://www.postgresql.org/docs/current/install-make.html" rel="nofollow">PostgreSQL documentation</a>.</p>
</li>
<li>
<p dir="auto">When the build completes, add the location of your <code>pg_config</code> file to your <code>PATH</code> variable:</p>
</li>
</ol>
<p dir="auto"><code>export PATH=path_to_pg_config_file</code></p>
<ol start="5" dir="auto">
<li>
<p dir="auto">Then, clone the <code>pgedge/spock</code> repository:</p>
<p dir="auto"><code>git clone https://github.com/pgEdge/spock.git</code></p>
</li>
<li>
<p dir="auto">Next, <code>make</code> and then <code>make-install</code> spock.</p>
</li>
<li>
<p dir="auto">Then, update your Postgres <code>postgresql.conf</code> file, setting:</p>
<div dir="auto" data-snippet-clipboard-copy-content="shared_preload_libraries = 'spock'
track_commit_timestamp = on # needed for conflict resolution"><pre>shared_preload_libraries = <span><span>'</span>spock<span>'</span></span>
track_commit_timestamp = on <span><span>#</span> needed for conflict resolution</span></pre></div>
</li>
<li>
<p dir="auto">Then, connect to the server and use the <code>CREATE EXTENSION</code> command to create the spock extension on each node in the database you wish to replicate:</p>
<p dir="auto"><code>CREATE EXTENSION spock;</code></p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building the Spock Documentation</h2><a id="user-content-building-the-spock-documentation" aria-label="Permalink: Building the Spock Documentation" href="#building-the-spock-documentation"></a></p>
<p dir="auto">The Spock documentation uses <a href="https://www.mkdocs.org/" rel="nofollow">MkDocs</a> with the <a href="https://squidfunk.github.io/mkdocs-material/" rel="nofollow">Material theme</a> to generate styled static HTML documentation from Markdown files in the <code>docs</code> directory.</p>
<p dir="auto">To build the documentation, and run a development server for live previewing:</p>
<ol dir="auto">
<li>
<p dir="auto">Create a Python virtual environment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m venv spock-docs-venv"><pre>python3 -m venv spock-docs-venv</pre></div>
</li>
<li>
<p dir="auto">Activate the virtual environment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="source spock-docs-venv/bin/activate"><pre><span>source</span> spock-docs-venv/bin/activate</pre></div>
</li>
<li>
<p dir="auto">Install MkDocs:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install mkdocs mkdocs-material"><pre>pip install mkdocs mkdocs-material</pre></div>
</li>
<li>
<p dir="auto">Run the local MkDocs server for testing:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdocs serve
INFO    -  Building documentation...
INFO    -  Multirepo plugin importing docs...
INFO    -  Cleaning site directory
INFO    -  Multirepo plugin is cleaning up temp_dir/
INFO    -  Documentation built in 0.18 seconds
INFO    -  [14:32:14] Watching paths for changes: 'docs', 'mkdocs.yml'
INFO    -  [14:32:14] Serving on http://127.0.0.1:8000/"><pre>mkdocs serve
INFO    -  Building documentation...
INFO    -  Multirepo plugin importing docs...
INFO    -  Cleaning site directory
INFO    -  Multirepo plugin is cleaning up temp_dir/
INFO    -  Documentation built <span>in</span> 0.18 seconds
INFO    -  [14:32:14] Watching paths <span>for</span> changes: <span><span>'</span>docs<span>'</span></span>, <span><span>'</span>mkdocs.yml<span>'</span></span>
INFO    -  [14:32:14] Serving on http://127.0.0.1:8000/</pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Configuration and Usage</h3><a id="user-content-basic-configuration-and-usage" aria-label="Permalink: Basic Configuration and Usage" href="#basic-configuration-and-usage"></a></p>
<p dir="auto">Before configuring a replication cluster, you will need to perform the following steps on each node of the cluster:</p>
<ul dir="auto">
<li>build Postgres and Spock, and create the Spock extension.</li>
<li>initialize identical databases.</li>
<li>modify the <code>postgresql.conf</code> file to support logical decoding automatic DDL replication.</li>
<li>modify the <code>pg_hba.conf</code> file and any firewalls to ensure you have connectivity between nodes.</li>
</ul>
<p dir="auto"><strong>Configuration Settings</strong></p>
<p dir="auto">Modify the <code>postgresql.conf</code> file, adding:</p>
<div data-snippet-clipboard-copy-content="wal_level = 'logical'
max_worker_processes = 10   # one per database needed on provider node
                            # one per node needed on subscriber node
max_replication_slots = 10  # one per node needed on provider node
max_wal_senders = 10        # one per node needed on provider node
shared_preload_libraries = 'spock'
track_commit_timestamp = on # needed for conflict resolution"><pre><code>wal_level = 'logical'
max_worker_processes = 10   # one per database needed on provider node
                            # one per node needed on subscriber node
max_replication_slots = 10  # one per node needed on provider node
max_wal_senders = 10        # one per node needed on provider node
shared_preload_libraries = 'spock'
track_commit_timestamp = on # needed for conflict resolution
</code></pre></div>
<p dir="auto">You'll also want to enable automatic ddl replication on each node; add these GUCs to the <code>postgresql.conf</code> file as well:</p>
<div data-snippet-clipboard-copy-content="spock.enable_ddl_replication=on
spock.include_ddl_repset=on"><pre><code>spock.enable_ddl_replication=on
spock.include_ddl_repset=on
</code></pre></div>
<p dir="auto">You also need to configure your <code>pg_hba.conf</code> file to allow connections between your nodes and ensure that firewalls do not block access. Logical replication connections are treated by <code>pg_hba.conf</code> as regular connections to the provider database.</p>
<p dir="auto">After modifying the configuration files, restart the Postgres server; for example:</p>
<p dir="auto"><code>pg_ctl -D /path/to/data_directory restart</code></p>
<p dir="auto"><strong>Configuring Replication</strong></p>
<p dir="auto">First, we'll invoke the <code>spock.node_create</code> command on each node in the cluster.  For example, the following command creates a node named <code>n1</code> that can be accessed via the connection string specified with the <code>dsn</code> variable:</p>
<div data-snippet-clipboard-copy-content="SELECT spock.node_create(
    node_name := 'n1',
    dsn := 'host=10.0.0.5 port=5432 dbname=acctg'
);"><pre><code>SELECT spock.node_create(
    node_name := 'n1',
    dsn := 'host=10.0.0.5 port=5432 dbname=acctg'
);
</code></pre></div>
<p dir="auto">Use the following command to create a node named n2:</p>
<div data-snippet-clipboard-copy-content="SELECT spock.node_create(
    node_name := 'n2',
    dsn := 'host=10.0.0.7 port=5432 dbname=acctg'
);"><pre><code>SELECT spock.node_create(
    node_name := 'n2',
    dsn := 'host=10.0.0.7 port=5432 dbname=acctg'
);
</code></pre></div>
<p dir="auto">Next, create the subscriptions between the nodes. Since this is multi-master replication, each node acts as both a subscriber and provider. The first command creates a subscription between <code>n1</code> and <code>n2</code>:</p>
<div data-snippet-clipboard-copy-content="SELECT spock.sub_create(
    subscription_name := 'sub_n1n2',
    provider_dsn := 'host=10.0.0.7 port=5432 dbname=acctg'
);"><pre><code>SELECT spock.sub_create(
    subscription_name := 'sub_n1n2',
    provider_dsn := 'host=10.0.0.7 port=5432 dbname=acctg'
);
</code></pre></div>
<p dir="auto">The command invoked on <code>n1</code> specifies the subscription name (<code>sub_n1n2</code>) and the connection string for the node it is subscribing to (<code>n2</code>).  Next, create a subscription on <code>n2</code> that connects to <code>n1</code>:</p>
<div data-snippet-clipboard-copy-content="SELECT spock.sub_create(
    subscription_name := 'sub_n2n1',
    provider_dsn := 'host=10.0.0.5 port=5432 dbname=acctg'
);"><pre><code>SELECT spock.sub_create(
    subscription_name := 'sub_n2n1',
    provider_dsn := 'host=10.0.0.5 port=5432 dbname=acctg'
);
</code></pre></div>
<p dir="auto">To start replication, we'll add tables with <a href="https://www.postgresql.org/docs/current/pgbench.html" rel="nofollow">pgbench</a>; since we enabled automatic ddl replication, we'll add the tables on <code>n1</code>, and they'll automatically propagate to <code>n2</code>:</p>
<div data-snippet-clipboard-copy-content="/path to pgbench/pgbench -i -s 10 acctg"><pre><code>/path to pgbench/pgbench -i -s 10 acctg
</code></pre></div>
<p dir="auto">Then, to confirm replication, you can connect to both <code>n1</code> and <code>n2</code> with psql and check for pgbench tables.</p>
<div data-snippet-clipboard-copy-content="psql (17.x)
Type &quot;help&quot; for help.

bench=# \dt
               List of relations
 Schema |       Name        | Type  |  Owner
--------+-------------------+-------+---------
 public | pgbench_accounts  | table | postgres
 public | pgbench_branches  | table | postgres
 public | pgbench_history   | table | postgres
 public | pgbench_tellers   | table | postgres
(4 rows)"><pre><code>psql (17.x)
Type "help" for help.

bench=# \dt
               List of relations
 Schema |       Name        | Type  |  Owner
--------+-------------------+-------+---------
 public | pgbench_accounts  | table | postgres
 public | pgbench_branches  | table | postgres
 public | pgbench_history   | table | postgres
 public | pgbench_tellers   | table | postgres
(4 rows)
</code></pre></div>
<p dir="auto"><strong>Deploying Spock Clusters in Containers and with Ansible</strong></p>
<p dir="auto">The pgEdge Github sites hosts repositories that contain artifacts that you can use to simplify spock cluster deployment; for more information, visit:</p>
<ul dir="auto">
<li><a href="https://github.com/pgEdge/pgedge-ansible">Deploying spock with Ansible</a></li>
<li><a href="https://docs.pgedge.com/container" rel="nofollow">Deploying spock in a Container</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Upgrading</h3><a id="user-content-upgrading" aria-label="Permalink: Upgrading" href="#upgrading"></a></p>
<p dir="auto">You cannot roll back an upgrade because of changes to the catalog tables; before starting an upgrade, make sure you have a current backup of your cluster so you can recreate the original cluster if needed.</p>
<p dir="auto">Then, to upgrade the version of spock that you use to manage your replication cluster, you can remove, build, and upgrade the spock extension like you would any other <a href="https://www.postgresql.org/docs/17/extend-extensions.html#EXTEND-EXTENSIONS-UPDATES" rel="nofollow">PostgreSQL extension</a>.</p>
<p dir="auto">To review the spock license, visit <a href="https://github.com/pgEdge/spock/blob/main/LICENSE.md">here</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A built-in 'off switch' to stop persistent pain (161 pts)]]></title>
            <link>https://penntoday.upenn.edu/news/select-neurons-brainstem-may-hold-key-treating-chronic-pain</link>
            <guid>45532685</guid>
            <pubDate>Thu, 09 Oct 2025 20:27:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://penntoday.upenn.edu/news/select-neurons-brainstem-may-hold-key-treating-chronic-pain">https://penntoday.upenn.edu/news/select-neurons-brainstem-may-hold-key-treating-chronic-pain</a>, See on <a href="https://news.ycombinator.com/item?id=45532685">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-palette-static="1">
                



          
          



  <header>
    <div>
        
        
                  <p>
              J. Nicholas Betley has led collaborative research seeking the neural basis of long-term sustained pain and finds that a critical hub in the brainstem holds a mechanism for stopping pain signals from reaching the rest of the brain. Their findings could help clinicians better understand chronic pain and lead to new, more efficacious treatments.

          </p>
                        <p>
          4 min. read
      </p>
      </div></header>
  
    
    <main id="main-content">
    
        
            
                <p>
        <h4>More from</h4>
        <menu>
                                    <li>
                <a href="https://penntoday.upenn.edu/schools/school-arts-sciences">
                  <span>School of Arts &amp; Sciences</span>
                </a>
              </li>
                          <li>
                <a href="https://penntoday.upenn.edu/schools/perelman-school-medicine">
                  <span>Perelman School of Medicine</span>
                </a>
              </li>
                                                          <li>
                <a href="https://penntoday.upenn.edu/subtopic/neuroscience">
                  <span>Neuroscience</span>
                </a>
              </li>
                          <li>
                <a href="https://penntoday.upenn.edu/subtopic/faculty">
                  <span>Faculty</span>
                </a>
              </li>
                          <li>
                <a href="https://penntoday.upenn.edu/subtopic/research">
                  <span>Research</span>
                </a>
              </li>
                          <li>
                <a href="https://penntoday.upenn.edu/subtopic/graduate-students">
                  <span>Graduate Students</span>
                </a>
              </li>
                              </menu> 
    </p>
      </main>
</div><div id="main-content">
	
	
	

		<main id="main-content">
		<div data-feed-items="">
  <article>
  
</article>


  <article>
  <div>
    <p><a href="https://penntoday.upenn.edu/news/womens-labor-and-political-agency-delhi-rashi-sabherwal-india-political-science">
      <span>
<span>Women’s labor and political agency in Delhi</span>
</span>
    </a></p>
        <div>
      
      <h4>
        <span>
<span>Women’s labor and political agency in Delhi</span>
</span>
      </h4>
      <p>
                    Rashi Sabherwal, a doctoral student in political science, explores how women engage politically in society in informal roles through her research in India.

              </p>
      
          </div>
  </div>
</article>


  <article>
  
</article>


  <article>
  <div>
    <p><a href="https://penntoday.upenn.edu/news/penn-engineering-navigating-landscapes-lunar-robots-moon-and-mars">
      <span>
<span>Helping robots work together to explore the Moon and Mars</span>
</span>
    </a></p>
        <div>
      
      <h4>
        <span>
<span>Helping robots work together to explore the Moon and Mars</span>
</span>
      </h4>
      <p>
                    Penn Engineers, NASA, and five other universities tested robotic systems designed to help unmanned explorers cooperate in the dunes of White Sands, New Mexico, paving the way for Moon and Mars exploration.

              </p>
      
          </div>
  </div>
</article>


</div>
		
		
	</main>
		

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Burrows-Wheeler Transform (129 pts)]]></title>
            <link>https://sandbox.bio/concepts/bwt</link>
            <guid>45532352</guid>
            <pubDate>Thu, 09 Oct 2025 20:00:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sandbox.bio/concepts/bwt">https://sandbox.bio/concepts/bwt</a>, See on <a href="https://news.ycombinator.com/item?id=45532352">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!----><h3>The Burrows-Wheeler Transform</h3> <p>By <a href="https://robert.bio/" target="_blank">Robert Aboukhalil</a></p> <p><small>October 9, 2025</small></p> <p>In this interactive article, we explore the borderline-magical algorithm known as the Burrows-Wheeler Transform (BWT). It
		powers data compression in <code>bzip2</code>, and is used by sequence alignment tools like <code>bowtie</code> and <code>bwa</code>, both of which were named after the algorithm.</p> <p>The BWT has 2 key properties:</p> <ol><li>It shuffles strings such that <strong>identical letters tend to be grouped together</strong>, e.g. the BWT of <code>coconut</code> is <code>tooccun</code>.</li> <li>The transform <strong>can be reversed</strong> to get the original string back, which is what makes it useful.</li></ol> <p>Before we dive in, you should know that the BWT has a <strong>third, unofficial property: it is not intuitive</strong>. Many
		of the steps in the algorithm will seem arbitrary and it might not be clear why you're even doing them. I'm hoping this
		article helps you build some intuition around the BWT.</p> <!----><h4 id="encode"><a href="#encode"><i></i><!----></a> The BWT algorithm<!----></h4><!----><!----> <p>To apply the BWT on a string like <!--[!--><!--]--><!---->, there are 3 steps to follow:</p><!----></div><div><!----><!----><h5 id="intuition"><a href="#intuition"><i></i><!----></a> What's the dollar sign for?<!----></h5><!----><!----> <p>The <code>$</code> marks the end of the string, and is needed to make the BWT reversible. Without that marker, you could still
		regenerate the matrix in Step <i></i><!---->, but you wouldn't know which row contains the original string. If it's
		an English word, you might guess it's <code>banana</code> and not <code>nabana</code>, but that's harder to do with DNA because most rotations will look reasonable.</p> <!----><h5 id="intuition"><a href="#intuition"><i></i><!----></a> Intuition behind the BWT<!----></h5><!----><!----> <p>In Step <i></i><!---->, the sorting causes rows that start the same to be more likely to be grouped together. As a
		result, the character that comes right before (i.e. the character in the last column) is also likely to be similar, based on
		repeated patterns in the English language, and also in DNA sequences!</p> <p>For example, in the BWT of <!--[!--><!--]--><!---->,
		the letter <code>c</code> is grouped because it's always followed by an <code>o</code>. Although <code>o</code> is followed by
		either <code>c</code> or <code>n</code>, it still clusters in the BWT because its corresponding rows end up being sorted next
		to each other.</p> <p>If there was a row in Step <i></i><!----> that started with a letter in between <code>c</code> and <code>n</code>, the <code>o</code>'s would no longer cluster. For example, what happens to the <code>o</code>'s if you add an <code>i</code> to <code>coconut</code>: <!--[!--><!--]--><!---->. Would the <code>o</code>'s
		cluster if you tried <!--[!--><!--]--><!---->?</p> <p>Now it's your turn: try encoding your name or a repetitive string. Which characters can you add or remove to make the BWT
		cluster more or less?</p> <!----> <!----><h4 id="decode"><a href="#decode"><i></i><!----></a> Decoding the BWT<!----></h4><!----><!----> <p>Given the encoded string, we can reconstruct the matrix from Step <i></i><!----> as follows: Start with an empty matrix,
		prepend the BWT string, sort the strings, and repeat until the matrix is filled. Keep clicking <i>Next</i> below until you reconstruct
		the matrix; the matrix on the right shows the final answer we're working towards.</p><!----></div><div><!----><p>Once the matrix is filled, we can read off the string from any of the rows since we have the <code>$</code> marker.</p> <!----><h5 id="intuition-decoding"><a href="#intuition-decoding"><i></i><!----></a> Intuition behind the decoding algorithm<!----></h5><!----><!----> <p>Starting from an empty matrix, note that adding the BWT column and sorting gives you the <strong>first column</strong> of the
		expected BWT matrix. If you then prepend and sort a second time, you now have the <strong>first two columns</strong> of the BWT
		matrix. You can keep going to recreate the whole matrix.</p> <p>To understand why this works, let's consider a scenario where I give you the first 2 columns of the BWT matrix and ask you to
		figure out the rest. Remember that the BWT is the last column of the matrix, i.e. the characters that come right before the
		first column. So by prepending the BWT to the first column, we're still preserving the relationships between the substrings we
		reconstructed so far (you can imagine the BWT matrix rotates on itself to connect the first and last column together). Then,
		sorting the current set of substrings gives us the first 3 columns of the BWT matrix.</p> <!----> <!----><h4 id="alignment"><a href="#alignment"><i></i><!----></a> How to use BWT for sequence alignment<!----></h4><!----><!----> <p>So far, we've seen how to use the Burrows-Wheeler Transform to encode and decode strings. That's nice and all, but how can we
		use the BWT for sequence alignment, i.e. looking for a small string in a much larger string?</p> <p>To do that, I first need to introduce yet another magical property of the BWT: <i>Last-to-first Mapping</i>.</p> <!----><h5 id="lf-mapping"><a href="#lf-mapping"><i></i><!----></a> Last-to-first Mapping property<!----></h5><!----><!----> <p>This property states that the <strong>order in which you see a letter in the first column is the same order in which you see it in the last column</strong>!</p> <p>Let's consider the word <code>banana</code>: if we annotate each letter with the number of times it occurs in the string
		before creating the BWT matrix, the letter <code>a</code> appears in the same order in both the first and last column: a<sub>2</sub>, a<sub>1</sub>, a<sub>0</sub>!</p> <div><!--[--><!--[--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--]--></div> <!----><h5 id="substring"><a href="#substring"><i></i><!----></a> Find a substring<!----></h5><!----><!----> <p>With that in mind, let's find all occurences of the pattern <code>an</code> within <code>banana</code>, using only the first
		and last columns. Let's begin by finding rows that start with the last character of the pattern (i.e. <code>n</code>)—you'll see why in a second:</p> <div><!--[--><!--[--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--]--></div> <p>Now that we have an <code>n</code> in the first column, we know that the last column is the character that comes right before <code>n</code>, so we can look for an <code>a</code> in that last column. We find two matches: a<sub>1</sub> and a<sub>0</sub>, so we can visit rows that have those characters in the first column:</p> <div><!--[--><!--[--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--[--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>n<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--[--><p><span>$<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>b<!----><sub>undefined</sub><!----></span></p><!--]--><!--[!--><p><span>a<!----><sub>undefined</sub><!----></span></p><!--]--><!--]--><!----> <br><!--]--></div> <p>And voilà, we found the only matches for our search query of <code>an</code> within <code>banana</code>.</p> <!----><h5 id="lf-decoding"><a href="#lf-decoding"><i></i><!----></a> Wait a minute...<!----></h5><!----><!----> <p>A few sections ago, we decoded the BWT string by recreating the entire BWT matrix, which was a lot of work. Could we instead
		use this LF property to decode the BWT string? As a matter of fact, we can!</p> <p>You can think of decoding the BWT string as a special case of searching, where we're looking for whichever string ends with <code>$</code>. So we can start by finding the <code>$</code> character, then hop around between the first and column until we find the <code>$</code> once more and we'll have recreated the reverse of the original string.</p> <!----> <!----><h4 id="next"><a href="#next"><i></i><!----></a> What's next?<!----></h4><!----><!----> <p>If you somehow made it all the way here <small>(let me know at <a href="https://sandbox.bio/cdn-cgi/l/email-protection" data-cfemail="6e1c010c0b1c1a2e0103090b000103070d1d400d0103">[email&nbsp;protected]</a>)</small>, and you can't get enough of the
		BWT, there's a lot more you can learn about:</p> <ul><li><strong>Suffix Arrays</strong>: It turns out the way we generated the BWT transform <a href="#encode">above</a> was quite
			inefficient. A string of length <code>n</code> has <code>n</code> rotations, so sorting that list of strings has a time
			complexity of <i>O(n)</i> rotations * <i>O(n log n)</i> comparisons = <i>O(n<sup>2</sup> log n)</i>. There's an interesting data structure
			called a Suffix Array that you can use to more efficiently generate that matrix. You can learn more about that from Ben
			Langmead's lecture notes about <a href="https://www.cs.jhu.edu/~langmea/resources/lecture_notes/09_suffix_arrays_v2.pdf" target="_blank" rel="noreferrer"><!----><!---->suffix arrays<!----></a><!----> and <a href="https://www.cs.jhu.edu/~langmea/resources/lecture_notes/bwt_and_fm_index.pdf" target="_blank" rel="noreferrer"><!----><!---->BWT and the FM index<!----></a><!---->.
			Ben's lab maintains the <a href="https://bowtie-bio.sourceforge.net/bowtie2/manual.shtml" target="_blank" rel="noreferrer"><!----><!---->bowtie2<!----></a><!----> sequence aligner,
			so his slides are a great in-depth resource.</li> <li><strong>FM Index</strong>: In the examples above, the searches were small enough that we hopped between the first and last
			column by eye by looking at every single row. But making millions of queries within a large string like the human genome
			with 3 billion basepairs would be too slow. If you want to learn about how to mitigate those issues in practice, check out
			Ben Langmead's lecture notes on the <a href="https://www.cs.jhu.edu/~langmea/resources/lecture_notes/bwt_and_fm_index.pdf#page=32" target="_blank" rel="noreferrer"><!----><!---->FM index<!----></a><!---->.</li> <li><strong>Compression</strong>: As I mentioned above, BWT helps with compression because of how it tends to cluster characters
			together. You can learn more about compression from Carl Kingsford's lecture notes on <a href="https://www.cs.cmu.edu/~15451-f18/lectures/lec25-bwt.pdf#page=7" target="_blank" rel="noreferrer"><!----><!---->BWT and compression<!----></a><!---->.</li></ul> <p>✨ Thanks to Ben Langmead, Niema Moshiri, Maria Nattestad, and Zamin Iqbal for their insightful feedback on this article.</p><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Examples Are the Best Documentation (130 pts)]]></title>
            <link>https://rakhim.exotext.com/examples-are-the-best-documentation</link>
            <guid>45532090</guid>
            <pubDate>Thu, 09 Oct 2025 19:34:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rakhim.exotext.com/examples-are-the-best-documentation">https://rakhim.exotext.com/examples-are-the-best-documentation</a>, See on <a href="https://news.ycombinator.com/item?id=45532090">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>When I'm searching for docs, 95% of the time a single example would suffice. Yet, 95% of the time I can't find one in any official source.</p>
<p>It seems that by default formal technical documentation is targeted towards someone who's deeply immersed in the ecosystem. But many developers have to juggle a lot of "worlds" in their heads daily. When jumping between projects, languages and frameworks, it takes a considerable amount of mental energy to restore the context and understand what is going on.</p>
<p>Consider this <a href="https://docs.python.org/3/library/functions.html#max">example</a> from the Python 3 docs:</p>
<blockquote>
<p><code>max(iterable, /, *, key=None)</code>
Return the largest item in an iterable or the largest of two or more arguments.... <em>[followed by 5 short paragraphs]</em>.</p>
</blockquote>
<p>You need to know quite a bit about Python in order to understand this:</p>
<ul>
<li>What <code>*</code> means in the function definition.</li>
<li>What <code>/</code> means in the function definition.</li>
<li>What's a "positional-only parameter separator"</li>
<li>What's an iterable.</li>
<li>What are keyword-only arguments.</li>
<li>What <code>key</code> usually means.</li>
</ul>
<p>Then you have to read some text in order to understand what values you can pass and how to actually call the function.</p>
<p>Granted, these are important details that can't be omitted for brevity. But I bet a lot of developers looked at that page simply because they needed to quickly find out how to pass a custom sorting function. This example would've quickly helped them:</p>
<pre><code><span>max</span>(<span>4</span>, <span>6</span>) <span># → 6</span>

<span>max</span>([<span>1</span>, <span>2</span>, <span>3</span>]) <span># → 3</span>

<span>max</span>([<span>'x'</span>, <span>'y'</span>, <span>'abc'</span>],  key=<span>len</span>) <span># → 'abc'</span>

<span>max</span>([]) <span># ValueError: max() arg is an empty sequence</span>

<span>max</span>([], default=<span>5</span>) <span># → 5</span>
</code></pre><p>Easy, right?</p>
<p>One popular community-based project in the Clojure world is <a href="https://clojuredocs.org/">clojuredocs.org</a>, a site where people contribute examples for built in functions. It's fantastic and, in my experience, indispensable in day-to-day coding. For example, check out the pages about <a href="https://clojuredocs.org/clojure.core/into">into</a> or <a href="https://clojuredocs.org/clojure.core/spit">spit</a> or <a href="https://clojuredocs.org/clojure.core/map">map</a>. Note that examples often include related functions, not only those in question. This increases the real-world usefulness and practicality.</p>
<p>Since even major software projects rarely offer <a href="https://www.divio.com/blog/documentation/">4 distinct kinds of documentation</a>, I am often hesitant to click on a "Documentation" link. Chances are, it's a terse, difficult to read, automatically generated API reference. I often choose to find a tutorial, not because I need a walk-through, but because I need examples.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The government ate my name (123 pts)]]></title>
            <link>https://slate.com/life/2025/10/passport-name-change-united-states-mexico-spain-immigration.html</link>
            <guid>45531721</guid>
            <pubDate>Thu, 09 Oct 2025 19:03:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slate.com/life/2025/10/passport-name-change-united-states-mexico-spain-immigration.html">https://slate.com/life/2025/10/passport-name-change-united-states-mexico-spain-immigration.html</a>, See on <a href="https://news.ycombinator.com/item?id=45531721">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-uri="slate.com/_components/article/instances/cmggoyz9a006qv1j8bbx74ufk@published" data-has-roadblock="false" data-rubric="life" data-article-type="article" itemscope="" itemtype="http://schema.org/Article">  

  

<header>

  <a href="https://slate.com/life/life">      Life</a>

  <h2 itemprop="headline">How the Government Ate My Name</h2>

<h2 itemprop="alternativeHeadline">I’ve made two international moves. The hardest part was learning my own name.</h2>


    </header>
<div>
      <figure data-uri="slate.com/_components/image/instances/cmggoyz9a006kv1j84fb3v59v@published" data-editable="imageInfo"><p><img alt="A U.S. passport with red tape on it." src="https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0" srcset="https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=320 320w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=480 480w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=600 600w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=840 840w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=960 960w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1280 1280w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1440 1440w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1600 1600w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1920 1920w,
https://compote.slate.com/images/46427e40-5481-401e-9bd3-c51a1502e9ed.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=2200 2200w" sizes="(min-width: 1440px)970px,
(min-width: 1024px)709px,
(min-width: 768px)620px,
calc(100vw - 30px)" width="1560" height="1040">
      </p>
<figcaption>
<span>Photo illustration by Slate. Photos by Getty Images Plus.</span>
</figcaption>
</figure>

  </div>
  

  <section>
      


      

    <div itemprop="mainEntityOfPage">
          <p data-word-count="21" data-uri="slate.com/_components/slate-paragraph/instances/cmggp08yf000w3b795q6t0xhk@published"><em><a href="https://slate.com/theslatest?utm_source=slate&amp;utm_medium=article&amp;utm_campaign=article_plain_text_topper">Sign up for the Slatest</a> to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.</em></p>

  <p data-word-count="43" data-uri="slate.com/_components/slate-paragraph/instances/cmggoyz9a006lv1j8c0ovmath@published">The Starbucks barista calls out “Joe, grande latte for Joe!” It takes him two tries before I remember I’m Joe and go pick up my coffee. A minor episode in the long history of non-Anglo immigrants changing their names after moving to America.</p>

  <p data-word-count="135" data-uri="slate.com/_components/slate-paragraph/instances/cmggp2o5v001b3b79iuoxw29p@published">If your family immigrated to the United States in the 19<sup>th</sup> century and/or you took middle-school social studies in the States, you’ve probably heard&nbsp;that officials at Ellis Island often changed newcomers’ names, either because they couldn’t spell them or because they wanted to make them sound more American. In fact, authorities in New York never actually wrote down anyone’s name, they just checked each immigrant against the ship’s passenger list, which would have been compiled by employees of the steamship companies. That means that your grandpa Szymańczyk turned into Simmons before he even set foot on the boat. My case, though, is less about forced reinvention than about bureaucratic drift. Names are bearers of our identity, history, and culture, but a lot can happen when they are run through the machinery of another culture’s bureaucracy.</p>

  

  <p data-word-count="109" data-uri="slate.com/_components/slate-paragraph/instances/cmggp2o5x001c3b79pg6nnt6e@published">I was born in Mexico City, and my parents named me Leonel Giovanni García Fenech. It might sound a little baroque to Americans, but having four names is standard in Spanish-speaking countries. And it can be surprisingly useful if one of your last names happens to be García, the most common surname in Spain and the second most common in Mexico. Or if you were my former co-worker, who shared a name with someone convicted of running over a child while drunk. That was the first thing anyone saw if they Googled her, so an extra name or two could have spared her countless awkward explanations during job interviews.</p>

  <p data-word-count="59" data-uri="slate.com/_components/slate-paragraph/instances/cmggp37wt001i3b7934jccnu0@published">As the firstborn, I was named after both of my grandfathers: Leonel hints at my father’s Spanish Jewish ancestry; diaspora families with the name Yehuda<em> </em>often used variations of the translation for <em>lion</em>, the traditional symbol for the Tribe of Yehuda. Giovanni, on the other hand, came from my Sicilian grandfather, and is just the Italian version of John.</p>

  


  


  


  


  <p data-word-count="93" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3b0k001o3b79cl4aibzb@published">Same with my last names: García is my father’s, Fenech my mother’s. I didn’t find out until I was an adult that Fenech is not actually Italian, as my family always assumed. It’s Maltese, it means <em>rabbit</em>, and it’s one of Malta’s most common surnames. Furthermore, it turns out my family has been mispronouncing it all along—it’s FE-neck, not fe-NECH. Famous people named Fenech include the ’70s soft-porn actress Edwige Fenech and, more recently, Yorgen Fenech, a Maltese businessman currently facing criminal charges for corruption, money laundering, and the murder of a journalist.</p>

  <p data-word-count="76" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3drp001u3b796m3dcn30@published">In Mexico, everyone called me Giovanni, never Leonel. (I only recently learned it was because my dad couldn’t stand his own father.) When we moved to the U.S. I always introduced myself as Giovanni. I never understood why Americans were embarrassed by their middle names—except for that time when President Barack Obama joked that he envied Willard Mitt Romney being able to go by his middle name. The punchline being, of course, that Obama’s is Hussein.</p>

  


  <p data-word-count="95" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3idv00203b79tspzfnuq@published">When I was sworn in as a U.S. citizen, the clerk surprised me when he announced I could now change my name to whatever<em> </em>I wanted. “Even Ronald Reagan!” he joked. (Not quite as weird as it sounds, as Reagan was still in office.) I almost said, “OK, let’s do that!” but thought better of it. Caught off guard, I simply asked him to drop Leonel. Four names only seemed to confuse Americans, and I never used it anyway, so why not make life easier? That’s how I became an American named Giovanni Garcia Fenech.</p>

  


  <p data-word-count="32" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3mmx00263b79ad6f0lb3@published">But the cut didn’t solve any problems. Everyone I met still called me “Gio” without asking. My girlfriend’s grandmother went with Geronimo. I also often received mail addressed to Giovanni Garcia French.</p>

  


  <p data-word-count="103" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3q1k002c3b79mw4a40ua@published">And of course, the bureaucrats still weren’t having it. When I got my driver’s license, the DMV insisted on cramming everything into a “first, middle, last” format and turned me into Giovanni F Garcia (sans acute accent). The passport office, trying slightly harder to keep the order of my names correct, made Garcia my middle name (again, no acute accent) and Fenech my last. In typical Gen X fashion, I was apathetic about the mess. Oh well, whatever, never mind. I just started hyphenating my last name to Garcia-Fenech and left it at that. Nobody seemed to care. The bank cashed my checks.</p>

  


  <p data-word-count="106" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3tw3002i3b79tiu3s64f@published">But there were other things happening in the world. In response to 9/11, Congress had passed <a href="https://slate.com/business/2025/05/real-id-delayed-again-why.html">the REAL ID Act</a>, requiring a new type of identification to board domestic flights (because nothing terrifies a terrorist like having to spend a day at the DMV). However, since the feds didn’t fund it, nothing happened, and I didn’t even hear about it until 2019, when the government announced that, this time for real, you’d need Real ID to fly. Like a sucker, I believed them and decided it was time to fix my documents. (It’s been postponed twice since then. The new deadline is now 2027, wink wink.)</p>

  


  


  <p data-word-count="136" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3w6n002o3b79smo9zlx9@published">I could have used this as an opportunity to change my driver’s license to match my passport, but convenience won out. Every important document I had—Social Security, bank accounts, marriage certificate, school records—listed me as <em>Giovanni F. Garcia</em>, and the thought of having to change all of that made me dizzy. Thankfully, the passport office didn’t object.<br>In November 2024, my wife and I decided to <a href="https://slate.com/news-and-politics/2025/04/living-abroad-downsides-trump-america.html">move to Spain (you can guess why)</a>. We could do this because she’s German, and as an EU citizen she’s allowed to take her spouse along. As we researched our move, I discovered that Latin Americans can apply for Spanish citizenship after just two years of residency, instead of the usual 10 for others. Only catch: I needed a Mexican passport, and didn’t have one—or any Mexican documents, for that matter.</p>

  


  


  <p data-word-count="70" data-uri="slate.com/_components/slate-paragraph/instances/cmggp3zuj002u3b79aesoa0gt@published">The consulate in New York happily issued me a birth certificate, but balked at a passport. They explained that my birth certificate listed me as Leonel Giovanni García Fenech but my American ID said my name was Giovanni F. Garcia. Never mind that they were the ones that had just given me the certificate. And so, to Spain I went, with my wife, my butchered name, and my American passport.</p>

  <p data-word-count="92" data-uri="slate.com/_components/slate-paragraph/instances/cmggp42h100303b79r7v48c4x@published">We’d been warned about Spanish bureaucracy, and I pictured Dickensian clerks with sleeve garters and green eyeshades demanding documents in triplicate. But what we encountered in Seville wasn’t that different from the American equivalent: bad websites, confusing instructions, long lines. They did enjoy stamping documents, but they were no better with names. My new foreigner’s ID listed me as Giovanni F García—acute accent restored!—but when I opened a bank account, I discovered my first name had become “Giovanni F.” Not Giovanni, not Giovanni plus middle initial. Giovanni F. Still, better than “Gio.”</p>

  


  

  <p data-word-count="248" data-uri="slate.com/_components/slate-paragraph/instances/cmggp44j400363b79grnwl2ec@published">Not ready to give up on an expedited European passport, I decided to visit Madrid to try my luck at the Mexican consulate there. If I couldn’t get a Mexican passport with my full name, I’d at least get to visit some world-class museums. The good news first: The museums were fantastic. As for the consulate, after a couple of hours of waiting, they called out my <em>full</em> name: “Leonel Giovanni García Fenech!” The official didn’t give me a chance to speak. “Look into here,” he said, pointing to some goggle-like device. “We need to photograph your irises for biometric identification.” Oh wow, this was actually going to work. “Now stand there for your photograph.” I grinned. The joy didn’t last long. “This is provisional, good for one year,” the official explained. “We can’t give you a regular passport until you bring us documentation with your full name. See here?” He ran his finger over the name on my naturalization document. “It just says Giovanni Garcia Fenech. And your U.S. passport is even worse—they’ve changed Fenech to just a single F! Have them fix it and then we can proceed.” I tried to explain that if not even Starbucks can get my name right, what were the chances the American government would? But he wasn’t interested, and there was a long line of people with dependable names waiting to get their irises scanned. Dejected, I went back to Seville with my ever-growing folder of documents under different names.</p>

  


  


  


  


  <p data-word-count="122" data-uri="slate.com/_components/slate-paragraph/instances/cmggp47nb003c3b79n2us490t@published">I spent a few days at home weighing my options. Could my parents find other Mexican documents with my original name? Could I legally change it back in the U.S., or would that just tangle my paperwork in Spain? How much more Kafkaesque could this get? Then something happened that made me reconsider everything. I was standing in line at the local <em>bazar</em> (the Spanish version of a dollar store) when an elderly woman ahead of me asked the Chinese owner her name. “Lola,” she said. “<em>Lola!</em> And how did you get that name?” the woman pressed. The owner shrugged. “People kept coming in asking for a Lola who used to work here, so eventually I just started saying that was <span>me.”</span></p>

  <div data-list="The Slatest" data-uri="slate.com/_components/newsletter-signup/instances/cmggoyz9a006ov1j85h107hd8@published">
          <h2>Get the best of news and politics</h2>
      <p><span>Sign up for Slate's evening newsletter.</span>
    </p></div>

  

</div>

      <ul>
<li>
            <a href="https://slate.com/tag/immigration">
              Immigration
            </a>
          </li><li>
            <a href="https://slate.com/tag/international">
              International
            </a>
          </li>      </ul>

  </section>

      

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacker News Live Feed (206 pts)]]></title>
            <link>https://jerbear2008.github.io/hn-live/</link>
            <guid>45531367</guid>
            <pubDate>Thu, 09 Oct 2025 18:33:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jerbear2008.github.io/hn-live/">https://jerbear2008.github.io/hn-live/</a>, See on <a href="https://news.ycombinator.com/item?id=45531367">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <div id="main">
    <header>
      <img src="https://news.ycombinator.com/y18.svg">
      <b><a href="https://news.ycombinator.com/news">Hacker News</a></b>
      &nbsp;&nbsp;
      <a href="https://news.ycombinator.com/newest">new</a>&nbsp;|
      threads |&nbsp;
      <a href="https://news.ycombinator.com/front">past</a>&nbsp;|&nbsp;
      <a href="https://news.ycombinator.com/newcomments">comments</a>&nbsp;|&nbsp;
      <a href="https://news.ycombinator.com/ask">ask</a>&nbsp;|&nbsp; 
      <a href="https://news.ycombinator.com/show">show</a>&nbsp;|&nbsp;
      <a href="https://news.ycombinator.com/jobs">jobs</a>&nbsp;|&nbsp;
      <a href="https://news.ycombinator.com/submit">submit</a>&nbsp;|&nbsp;
      <a href="#">live</a>
      <span>
        <a href="https://github.com/jerbear2008/hn-live">repo</a>
      </span>
    </header>
    
    <main></main>
  </div>

  

  
  
  <template id="comment-template">
    <article class="comment">
      <img class="comment-upvote" src="https://news.ycombinator.com/triangle.svg" alt="">
      <div>
        <div class="comment-header">
          <a id="comment-user" href="https://news.ycombinator.com/user?id=[username]">[username]</a>
          <a id="comment-time" href="https://news.ycombinator.com/item?id=[id]">0 minutes ago</a>
          |
          <a id="comment-parent" href="https://news.ycombinator.com/item?id=[parent id]">parent</a>
        </div>
        <div class="comment-body" id="comment-body">[comment body HTML]</div>
      </div>
    </article>
    <style>
      .comment {
        margin-left: 8px;
        margin-bottom: 20px;
        font-size: 9pt;
        display: flex;
        align-items: flex-start;
        padding-right: 20px;
      }
      .comment-upvote {
        width: 10px;
        margin-right: 7px;
        margin-top: 1px;
      }
      .comment-header {
        font-size: 8pt;
        color: #828282;
        margin-bottom: 6px;
        a {
          text-decoration: none;
          &:hover {
            text-decoration: underline;
          }
        }
      }
      .comment-body {
        a:visited {
          color: #828282;
        }
      }
      a {
        color: inherit;
      }
      p {
        margin-top: 8px;
        margin-bottom: 0px;
      }
    </style>
  </template>
  
  <template id="story-template">
    <article class="story">
      <img class="story-upvote" src="https://news.ycombinator.com/triangle.svg" alt="">
      <div>
        <div class="story-titleline">
          <a class="story-title" id="story-title">[title]</a>
          <span class="story-domain">(<a id="story-domain" href="https://news.ycombinator.com/from?site=[domain]">[domain]</a>)</span>
        </div>
        <div class="story-subline">
          <span id="story-points">[points]</span>
          by
          <a id="story-user" href="https://news.ycombinator.com/user?id=[username]">[username]</a>
          <a id="story-time" href="https://news.ycombinator.com/item?id=[id]">0 minutes ago</a>
          |
          <a id="story-past" href="https://hn.algolia.com/?query=[title]&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a>
          |
          <a id="story-comments" href="https://news.ycombinator.com/item?id=[id]">0 comments</a>
        </div>
      </div>
    </article>
    <style>
      .story {
        margin-left: 9px;
        margin-bottom: 20px;
        font-size: 10pt;
        display: flex;
        align-items: flex-start;
        padding-right: 20px;
        a {
          text-decoration: none;
          &:hover {
            text-decoration: underline;
          }
        }
        p {
          margin-top: 8px;
          margin-bottom: 0px;
        }
      }
      .story-upvote {
        width: 10px;
        margin-right: 7px;
        margin-top: 1px;
      }
      .story-titleline {
        margin-bottom: 5px;
      }
      .story-title {
        a:visited {
          color: #828282;
        }
      }
      .story-domain {
        color: #828282;
        font-size: 8pt;
      }
      .story-subline {
        font-size: 7pt;
        color: #828282;
        margin-bottom: 6px;
      }
      a {
        color: inherit;
      }
    </style>
  </template>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Banned an App That Simply Archived Videos of ICE Abuses (124 pts)]]></title>
            <link>https://www.404media.co/apple-banned-an-app-that-simply-archived-videos-of-ice-abuses/</link>
            <guid>45531042</guid>
            <pubDate>Thu, 09 Oct 2025 18:05:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/apple-banned-an-app-that-simply-archived-videos-of-ice-abuses/">https://www.404media.co/apple-banned-an-app-that-simply-archived-videos-of-ice-abuses/</a>, See on <a href="https://news.ycombinator.com/item?id=45531042">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>Apple removed an app for preserving TikToks, Instagram reels, news reports, and videos documenting abuses by ICE, 404 Media has learned. The app, called Eyes Up, differs from other banned apps such as ICEBlock which were designed to report sightings of ICE officials in real-time to warn local communities. Eyes Up, meanwhile, was more of an aggregation service pooling together information to preserve evidence in case the material is needed in the future in court.</p><p>The news shows <a href="https://www.404media.co/iceblock-owner-after-apple-removes-app-we-are-determined-to-fight-this/"><u>that Apple</u></a> <a href="https://www.404media.co/google-calls-ice-agents-a-vulnerable-group-removes-ice-spotting-app-red-dot/"><u>and Google’s</u></a> crackdown on ICE-spotting apps, which started after pressure from the Department of Justice against Apple, is broader in scope than apps that report sightings of ICE officials. It has also impacted at least one app that was more about creating a historical record of ICE’s activity during its mass deportation effort.</p><p>“Our goal is government accountability, we aren’t even doing real-time tracking,” the administrator of Eyes Up, who said their name was Mark, told 404 Media. Mark asked 404 Media to only use his first name to protect him from retaliation. “I think the [Trump] admin is just embarrassed by how many incriminating videos we have.”</p><div><p>💡</p><p><b><strong>Do you work at Apple or Google and know anything else about these app removals? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.</strong></b></p></div><p>Mark said the app was removed on October 3. At the time of writing, the Apple App Store says “This app is currently not available in your country or region” when trying to download Eyes Up.</p>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rubygems.org AWS Root Access Event – September 2025 (264 pts)]]></title>
            <link>https://rubycentral.org/news/rubygems-org-aws-root-access-event-september-2025/</link>
            <guid>45530832</guid>
            <pubDate>Thu, 09 Oct 2025 17:48:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubycentral.org/news/rubygems-org-aws-root-access-event-september-2025/">https://rubycentral.org/news/rubygems-org-aws-root-access-event-september-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45530832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>As part of standard incident-response practice, Ruby Central is publishing the following post-incident review to the public. This document summarizes the September 2025 AWS root-access event, what occurred, what we verified, and the actions we’ve taken to strengthen our security processes<strong>.</strong></p><p>On September 30th, a <a href="https://web.archive.org/web/20250930213611id_/https://joel.drapper.me/p/ruby-central-security-measures/"><u>blog post</u></a> raised concerns that a former maintainer continued to have access to the RubyGems.org production environment after administrative access was removed from several accounts earlier that month. We want to share the outcome of our investigation including: what happened, the extent of what we verified, what we got wrong, and the actions we have taken to strengthen our security processes going forward.</p><p>When this situation came to light, our immediate concern was the integrity and safety of the RubyGems.org service and its data. We take seriously our responsibility to steward the open-source infrastructure that millions of developers rely on each day. While we have found no evidence that user data or production operations were harmed, we recognize that the existence of an unrevoked shared credential and unclear communication created understandable alarm and frustration. For that, we are sincerely sorry.</p><h2 id="incident-response-timeline">Incident Response Timeline</h2><h4 id="september-30-2025">September 30 2025</h4><ul><li><strong>17:23 UTC:</strong> A former maintainer, André Arko, emails the Director of Open Source at Ruby Central stating that he still has access to the RubyGems.org production environment and associated monitoring tools.<br><em><strong>Note:</strong> This is the first and only disclosure to Ruby Central about this access by Mr. Arko.</em></li><li><strong>17:30 UTC:</strong> Joel Drapper (unaffiliated with Ruby Central) publishes a <a href="https://web.archive.org/web/20250930213611id_/https://joel.drapper.me/p/ruby-central-security-measures/"><u>public blog post</u></a> within minutes describing this access with screenshots taken earlier that day showing root account access.</li><li><strong>17:51 UTC: </strong>Ruby Central engages its board members and OSS staff to verify the veracity of the report, assembles an incident team, and enumerates all services and credentials to assess exposure scope and ensure complete remediation.<strong>&nbsp;</strong></li><li><strong>18:20 UTC:</strong> Ruby Central begins its emergency review and learns that the existing credentials for the AWS root account in our password vault are no longer valid.</li><li><strong>18:24 UTC:</strong> Ruby Central initiates an AWS password-reset procedure, validates multi-factor authentication, and regains control of the AWS root account.</li><li><strong>18:30 UTC</strong>: Ruby Central downloads a “Credentials Report” from the AWS console to understand why we could not access the root account, and learns that the root account password was changed by an unauthorized party on September 19th at 04:35 UTC.</li><li><strong>20:45 UTC:</strong> After an examination of AWS CloudTrail logs, DataDog alerts, and IAM configurations, Ruby Central identifies and revokes all associated sub-accounts and legacy credentials, issues new MFA tokens to the remaining accounts, and migrates the new root access credentials into a secure vault under Ruby Central’s sole control.</li></ul><h2 id="analysis-of-events">Analysis of Events</h2><p>By way of background, Ruby Central’s infrastructure runs on Amazon Web Services (AWS). The root account credentials, essentially the highest level of administrative control, are stored in a shared enterprise password manager in a shared vault to which only three individuals had access: two current Ruby Central staff members and one former maintainer, André Arko.</p><h4 id="september-18-2025">September 18 2025</h4><ul><li><strong>18:40 UTC:</strong> Ruby Central notifies Mr. Arko, via email, of the board’s decision to remove his RubyGems.org production access, and the termination of his on-call services. During that transition, our teams remove the AWS security credentials belonging to Mr. Arko for accessing the production systems, but we fail to rotate the AWS root account password in tandem.</li></ul><h4 id="september-19-2025">September 19, 2025</h4><ul><li><strong>04:34 UTC:</strong> An unauthorized actor originating from a San Francisco, California IP address starts a root account session on the AWS Rubygems.org AWS account.&nbsp;</li><li><strong>04:35 UTC:</strong> The unauthorized actor changes the root account password. <br><em><strong>Note: </strong>After this point, and until the AWS root credentials were reset by Ruby Central on Sept 30th, all subsequent actions taken on the AWS root account originate from the unauthorized actor.&nbsp;</em></li><li><strong>04:37 UTC:</strong> The unauthorized actor removes authorized users from groups and detaches access policies which reduces the privileges of authorized Rubygems.org AWS account holders.&nbsp;</li><li><strong>04:39 UTC: </strong>The unauthorized actor rapidly enumerates the IAM posture of the entire AWS account.&nbsp;</li></ul><h4 id="september-28th-2025">September 28th, 2025</h4><ul><li><strong>05:49 UTC: </strong>An unauthorized actor originating from a Tokyo, Japan IP address starts a&nbsp; root account session and uses IAM introspection API calls to check users’ group membership, last usage date, and last usage date of associated access tokens and policies.<br><em><strong>Note:</strong> This unauthorized access occurs adjacent to the </em><a href="https://web.archive.org/web/20250929050252id_/https://kaigionrails.org/2025/"><em><u>Kaigi on Rails conference</u></em></a><em> also in Tokyo, Japan from Sept 26th - 27th. As a result, we attribute this access to the same unauthorized actor.</em></li></ul><h4 id="september-30th-2025">September 30th, 2025</h4><ul><li><strong>15:25 UTC:</strong> An unauthorized actor originating from a Los Angeles, California IP address starts a root account session.</li><li><strong>15:35:24 UTC:</strong> The unauthorized actor issues a&nbsp;<code>PutCredentials</code> command to obtain user credentials, which match the screenshot shared in the blog post announcing the security vulnerability. The <a href="https://web.archive.org/web/20250930213611id_/https://joel.drapper.me/p/ruby-central-security-measures/#the-front-door"><u>blog post asserts</u></a> that this action was taken by Mr. Arko. </li></ul><figure><img src="https://rubycentral.org/content/images/2025/10/image-1.png" alt="" loading="lazy" width="676" height="314" srcset="https://rubycentral.org/content/images/size/w600/2025/10/image-1.png 600w, https://rubycentral.org/content/images/2025/10/image-1.png 676w"></figure><ul><li><strong>18:24 UTC: </strong>As we mentioned previously, Ruby Central performs the AWS password-reset operation to take back control of the root account.<br><em><strong>Note:</strong></em> <em>After this point, all actions taken on the AWS root account can be attributed back to authorized actors.</em></li></ul><h2 id="extent-of-the-incident">Extent of the Incident</h2><p>After a careful review, Ruby Central is relieved to report<strong> that we see no evidence</strong> that this security incident <strong>compromised end user data, accounts, gems, or infrastructure availability</strong>. In addition:</p><ul><li>RubyGems.org remained fully operational throughout.</li><li>No personally identifiable information (PII) of RubyGems.org users nor Ruby Central financial data was accessed or transferred.</li><li>The production database, S3 buckets, and CI/CD pipeline were unaffected.</li></ul><p>Nonetheless, the existence of unrotated credentials and the public disclosure of continued access constitute a serious procedural failure, and we are treating it as such.</p><h2 id="how-was-the-incident-resolved">How Was The Incident Resolved?</h2><p>After regaining control of the AWS account, Ruby Central:</p><ol><li><strong>Revoked all existing root and IAM credentials</strong>, created new MFA-protected access, and moved them to a restricted vault with per-user audit logs.</li><li><strong>Rotated all related secrets and tokens</strong>, including DataDog, GitHub Actions, and other external system integrations.</li><li><strong>Enabled AWS CloudTrail, GuardDuty, and DataDog alerting</strong> for any root login, password change, or IAM modification.</li><li><strong>Reviewed all IAM roles and policies</strong> to ensure least-privilege access and removed legacy permissions.</li><li><strong>Began a full end-to-end security audit</strong> with external advisors, covering infrastructure, credential storage, and incident-response procedures.</li><li><strong>Updated the Ruby Central Security Runbook</strong> to include immediate password and key rotation upon personnel or role changes, quarterly credential reviews, and coordinated communication steps for any future incident.</li></ol><h2 id="root-cause-analysis">Root Cause Analysis</h2><p>After a post-mortem review, the root cause of the security incident was two-fold: </p><ol><li>While Ruby Central correctly removed access to shared credentials through its enterprise password manager prior to the incident, our staff did not consider the possibility that this credential may have been copied or exfiltrated to other password managers outside of Ruby Central’s visibility or control.&nbsp;&nbsp;</li><li>Ruby Central failed to rotate the AWS root account credentials (password and MFA) after the departure of personnel with access to the shared vault.</li></ol><p>Both of these events enabled the unauthorized actor to access RubyGems.org production infrastructure where they attempted unsuccessfully to lock out authorized personnel and frustrate recovery efforts.</p><h2 id="what-we-are-doing-to-prevent-future-incidents">What We Are Doing to Prevent Future Incidents?</h2><p>RubyGems.org is a critical service that the entire Ruby community depends on, and we take that responsibility seriously. For RubyGems.org to succeed, it must not only maintain near-perfect operational uptime but also earn the community’s trust that it is operated professionally, that its operators can attest to the integrity of both the data and the code it serves to millions of Ruby applications worldwide, and that the privacy of the data we hold remains intact.</p><p>To that end, we commit to the following improvements:</p><ol><li>Update our access revocation procedures and checklists to ensure access is also revoked to the Ruby Central enterprise password manager.</li><li>Update our access revocation procedures to ensure any non-federated credentials (particularly shared credentials) are rotated quickly after a personnel separation.&nbsp;</li><li>Commission <strong>an independent security audit</strong> of Ruby Central’s systems and access.</li><li>Finalize formal Operator and Contributor Agreements to clearly define who may hold production access and under what conditions</li></ol><h2 id="why-did-ruby-central-treat-this-event-as-a-security-incident">Why Did Ruby Central Treat This Event as a Security Incident?</h2><p><a href="https://rubycentral.org/news/our-stewardship-where-we-are-whats-changing-and-how-well-engage/"><u>As part of our recent actions</u></a>, we determined that many RubyGems.org systems were controlled by a single individual; an untenable situation for a service of this importance.</p><p>To provide additional context to the community about our decision to formalize production access through Operator and Contributor Agreements, and to explain why we treated this incident as a genuine security event, we are sharing context from conversations between Mr. Arko and Ruby Central personnel leading up to the September 18th access changes.</p><p>In early August 2025, Ruby Central began reviewing its open source contractor budget, which totaled approximately $762,000 in 2024. On-call coverage is critical for a service like RubyGems.org and allows us to ensure operational continuity and rapid response to production incidents. Every on-call shift has a primary who is directly responsible for responding to incidents, and a secondary who is there to serve as a back up and an escalation point, if and when needed.</p><p>For RubyGems.org, the secondary on-call rotation, which serves as a backup layer, was rarely activated. Ruby Central’s long-term goal was to transition this limited paid function into a distributed network of volunteer operators who could share those responsibilities without additional cost, ensuring both operational continuity and financial sustainability.</p><p>Following these budget adjustments, Mr. Arko’s consultancy, which had been receiving approximately $50,000 per year for providing the secondary on-call service, submitted a proposal offering to provide secondary on-call services at no cost in exchange for access to production HTTP access logs, containing IP addresses and other personally identifiable information (PII). The offer would have given Mr. Arko’s consultancy access to that data, so that they could monetize it by analyzing access patterns and potentially sharing it with unrelated third-parties.</p><figure><img src="https://rubycentral.org/content/images/2025/10/data-src-image-74018b71-3432-478c-8aea-7186f3d4ab11.png" alt="" loading="lazy" width="1600" height="1027" srcset="https://rubycentral.org/content/images/size/w600/2025/10/data-src-image-74018b71-3432-478c-8aea-7186f3d4ab11.png 600w, https://rubycentral.org/content/images/size/w1000/2025/10/data-src-image-74018b71-3432-478c-8aea-7186f3d4ab11.png 1000w, https://rubycentral.org/content/images/2025/10/data-src-image-74018b71-3432-478c-8aea-7186f3d4ab11.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>The board and leadership team determined that this proposal crossed important ethical and legal boundaries, introducing privacy, conflict-of-interest, and governance concerns inconsistent with Ruby Central’s responsibilities as stewards of the ecosystem. These concerns set in motion Ruby Central’s decision to adopt the new operating model and governance structure detailed <a href="https://rubycentral.org/news/our-stewardship-where-we-are-whats-changing-and-how-well-engage/"><u>in this blog post</u></a>.&nbsp; With this context in mind, when we discovered that Mr. Arko had retained access to production systems containing PII, it prompted us to consider it as a security incident and to respond immediately.</p><p>Based on our preliminary investigation, as of the publication of this post, we have no evidence to indicate that any RubyGems.org data was copied or retained by unauthorized parties, including Mr. Arko.</p><p>We recognize that these events have raised valid questions within the community and tested confidence in how Ruby Central fulfills its stewardship role. Our intent in sharing this level of detail is to be transparent about what occurred, what we have learned, and what we are doing to prevent it from happening again. We are hopeful that this openness marks a meaningful step toward rebuilding trust in our stewardship and demonstrating that accountability and collaboration remain central to how we serve the Ruby ecosystem.</p><p>We are deeply grateful to the community for holding us accountable and for the patience and professionalism shown during this process. Ruby Central remains committed to transparent, responsible stewardship of the RubyGems infrastructure and to maintaining the security and trust that the Ruby ecosystem depends on.</p><p>Sincerely,</p><p>Shan Cureton<br>Executive Director</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Subway Builder: A realistic subway simulation game (245 pts)]]></title>
            <link>https://www.subwaybuilder.com/</link>
            <guid>45530744</guid>
            <pubDate>Thu, 09 Oct 2025 17:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.subwaybuilder.com/">https://www.subwaybuilder.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45530744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.subwaybuilder.com/"><img alt="Subway Builder Logo" loading="lazy" width="400" height="400" decoding="async" data-nimg="1" src="https://www.subwaybuilder.com/bigLogoBlackVector.svg"><img alt="Subway Builder Logo" loading="lazy" width="400" height="400" decoding="async" data-nimg="1" src="https://www.subwaybuilder.com/bigLogoBlackVector.svg"></a></p><div><div><p>What is Subway Builder?</p><p>Subway Builder is a hyperrealistic transit simulation game. Build a new subway system from the ground up while dealing with real-world constraints and costs.</p></div><div><p>Features</p><div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M3 3v16a2 2 0 0 0 2 2h16"></path><path d="M7 16h8"></path><path d="M7 11h12"></path><path d="M7 6h3"></path></svg><p>Real-world passenger simulation</p></div><div><p>Millions of commuters are generated from</p><!-- --> <p><a href="https://lehd.ces.census.gov/data/">Census</a></p><!-- --><p>and</p><!-- --> <p><a href="https://redistricter.com/">Redistricter</a></p><!-- --><p>data and simulated using the same pathfinding algorithms you use. Your job is to design a route network that gets the most people to their destination as fast as possible. Juggle station placement, transfer dynamics, and train frequency to maximize ridership.</p></div></div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="m15 12-8.373 8.373a1 1 0 1 1-3-3L12 9"></path><path d="m18 15 4-4"></path><path d="m21.5 11.5-1.914-1.914A2 2 0 0 1 19 8.172V7l-2.26-2.26a6 6 0 0 0-4.202-1.756L9 2.96l.92.82A6.18 6.18 0 0 1 12 8.4V10l2 2h1.172a2 2 0 0 1 1.414.586L18.5 14.5"></path></svg><p>Realistic construction challenges</p></div><p>Build your system under realistic constraints and costs. Tunnels, viaducts, cut-and-cover, all have trade offs. Negotiate with real-world buildings foundations, geography and road layouts as you expand your network</p></div><div><p>Explore how individual commuters weight use various variables like wait times, transfers, income distribution, delays, and more, to pick their commute. Understand which routes, stations, and trains your commuters take and use that information to optimize your network.</p></div><div><p>Find the right balance between cost and time. Too many trains on a line or an overcrowded station will cause delays.</p></div></div></div><div><p>Frequently Asked Questions</p><ul><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs are mortally terrified of exceptions (223 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1976077806443569355</link>
            <guid>45530486</guid>
            <pubDate>Thu, 09 Oct 2025 17:16:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1976077806443569355">https://twitter.com/karpathy/status/1976077806443569355</a>, See on <a href="https://news.ycombinator.com/item?id=45530486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I wrote a full text search engine in Go (101 pts)]]></title>
            <link>https://github.com/wizenheimer/blaze</link>
            <guid>45530388</guid>
            <pubDate>Thu, 09 Oct 2025 17:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/wizenheimer/blaze">https://github.com/wizenheimer/blaze</a>, See on <a href="https://news.ycombinator.com/item?id=45530388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Blaze</h2><a id="user-content-blaze" aria-label="Permalink: Blaze" href="#blaze"></a></p>

<p dir="auto">A high-performance full-text search engine in Go with inverted indexing, boolean queries, phrase search, proximity queries, and BM25 ranking—powered by a flexible query engine, roaring bitmaps, and skip lists.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#core-concepts">Core Concepts</a>
<ul dir="auto">
<li><a href="#inverted-index">Inverted Index</a></li>
<li><a href="#skip-lists">Skip Lists</a></li>
<li><a href="#text-analysis-pipeline">Text Analysis Pipeline</a></li>
<li><a href="#search-operations">Search Operations</a></li>
</ul>
</li>
<li><a href="#query-builder-api">Query Builder API</a>
<ul dir="auto">
<li><a href="#why-use-builder-pattern">Why Use Builder Pattern</a></li>
<li><a href="#query-builder-quick-start">Quick Start</a></li>
<li><a href="#query-builder-core-methods">Core Methods</a></li>
<li><a href="#boolean-operations">Boolean Operations</a></li>
<li><a href="#query-patterns">Query Patterns</a></li>
<li><a href="#query-builder-performance">Performance</a></li>
<li><a href="#query-builder-best-practices">Best Practices</a></li>
</ul>
</li>
<li><a href="#api-reference">API Reference</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#performance-characteristics">Performance Characteristics</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#use-cases">Use Cases</a></li>
<li><a href="#testing">Testing</a></li>
<li><a href="#architecture">Architecture</a></li>
<li><a href="#best-practices">Best Practices</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">Blaze is a Go engine that provides fast, full-text search capabilities through an inverted index implementation. It's designed for applications that need to search through text documents efficiently without relying on external search engines.</p>
<p dir="auto"><strong>Key Highlights:</strong></p>
<ul dir="auto">
<li><strong>Inverted Index</strong>: Maps terms to document positions for instant lookups</li>
<li><strong>Skip Lists</strong>: Probabilistic data structure providing O(log n) operations</li>
<li><strong>Query Builder</strong>: Type-safe, fluent API for boolean queries with roaring bitmaps</li>
<li><strong>Advanced Search</strong>: Phrase search, BM25 ranking, proximity ranking, and boolean queries</li>
<li><strong>BM25 Algorithm</strong>: Industry-standard relevance scoring with IDF and length normalization</li>
<li><strong>Text Analysis</strong>: Tokenization, stemming, stopword filtering, and case normalization</li>
<li><strong>Thread-Safe</strong>: Concurrent indexing with mutex protection</li>
<li><strong>Serialization</strong>: Efficient binary format for persistence</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Search Capabilities</h3><a id="user-content-search-capabilities" aria-label="Permalink: Search Capabilities" href="#search-capabilities"></a></p>
<ul dir="auto">
<li><strong>Term Search</strong>: Find documents containing specific terms</li>
<li><strong>Phrase Search</strong>: Exact multi-word matching ("quick brown fox")</li>
<li><strong>Boolean Queries</strong>: Type-safe AND, OR, NOT operations with query builder</li>
<li><strong>BM25 Ranking</strong>: Industry-standard relevance scoring (used by Elasticsearch, Solr)</li>
<li><strong>Proximity Ranking</strong>: Score results by term proximity</li>
<li><strong>Position Tracking</strong>: Track exact word positions within documents</li>
<li><strong>Roaring Bitmaps</strong>: Compressed bitmap operations for fast boolean queries</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Text Processing</h3><a id="user-content-text-processing" aria-label="Permalink: Text Processing" href="#text-processing"></a></p>
<ul dir="auto">
<li><strong>Tokenization</strong>: Unicode-aware text splitting</li>
<li><strong>Stemming</strong>: Snowball (Porter2) stemmer for English</li>
<li><strong>Stopword Filtering</strong>: Remove common words (the, a, is, etc.)</li>
<li><strong>Case Normalization</strong>: Case-insensitive search</li>
<li><strong>Configurable Pipeline</strong>: Customize analysis behavior</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Structures</h3><a id="user-content-data-structures" aria-label="Permalink: Data Structures" href="#data-structures"></a></p>
<ul dir="auto">
<li><strong>Skip Lists</strong>: O(log n) search, insert, and delete operations</li>
<li><strong>Inverted Index</strong>: Efficient term-to-position mapping</li>
<li><strong>Binary Serialization</strong>: Compact storage format</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go get github.com/wizenheimer/blaze"><pre>go get github.com/wizenheimer/blaze</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    // Create a new inverted index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    idx.Index(1, &quot;The quick brown fox jumps over the lazy dog&quot;)
    idx.Index(2, &quot;A quick brown dog runs fast&quot;)
    idx.Index(3, &quot;The lazy cat sleeps all day&quot;)

    // Search for documents containing &quot;quick&quot; and &quot;brown&quot;
    matches := idx.RankProximity(&quot;quick brown&quot;, 10)

    // Print results
    for _, match := range matches {
        fmt.Printf(&quot;Document %d (score: %.2f)\n&quot;,
            int(match.Offsets[0].DocumentID),
            match.Score)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create a new inverted index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index some documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"The quick brown fox jumps over the lazy dog"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"A quick brown dog runs fast"</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>"The lazy cat sleeps all day"</span>)

    <span>// Search for documents containing "quick" and "brown"</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"quick brown"</span>, <span>10</span>)

    <span>// Print results</span>
    <span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>fmt</span>.<span>Printf</span>(<span>"Document %d (score: %.2f)<span>\n</span>"</span>,
            <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>),
            <span>match</span>.<span>Score</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Document 2 (score: 1.00)
Document 1 (score: 0.50)"><pre><code>Document 2 (score: 1.00)
Document 1 (score: 0.50)
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core Concepts</h2><a id="user-content-core-concepts" aria-label="Permalink: Core Concepts" href="#core-concepts"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Inverted Index</h3><a id="user-content-inverted-index" aria-label="Permalink: Inverted Index" href="#inverted-index"></a></p>
<p dir="auto">An inverted index is like the index at the back of a book. Instead of scanning every document to find a word, the index tells you exactly where each word appears.</p>
<p dir="auto"><strong>Example:</strong></p>
<p dir="auto">Given these documents:</p>
<div data-snippet-clipboard-copy-content="Doc 1: &quot;the quick brown fox&quot;
        Pos:0    1     2     3

Doc 2: &quot;the lazy dog&quot;
        Pos:0   1    2

Doc 3: &quot;quick brown dogs&quot;
        Pos:0    1     2"><pre><code>Doc 1: "the quick brown fox"
        Pos:0    1     2     3

Doc 2: "the lazy dog"
        Pos:0   1    2

Doc 3: "quick brown dogs"
        Pos:0    1     2
</code></pre></div>
<p dir="auto">The inverted index looks like:</p>
<div data-snippet-clipboard-copy-content="┌─────────┬────────────────────────────────────┐
│  Token  │         Posting List               │
├─────────┼────────────────────────────────────┤
│ &quot;quick&quot; │ → [Doc1:Pos1] → [Doc3:Pos0]        │
│ &quot;brown&quot; │ → [Doc1:Pos2] → [Doc3:Pos1]        │
│ &quot;fox&quot;   │ → [Doc1:Pos3]                      │
│ &quot;lazy&quot;  │ → [Doc2:Pos1]                      │
│ &quot;dog&quot;   │ → [Doc2:Pos2]                      │
│ &quot;dogs&quot;  │ → [Doc3:Pos2]                      │
└─────────┴────────────────────────────────────┘"><pre><code>┌─────────┬────────────────────────────────────┐
│  Token  │         Posting List               │
├─────────┼────────────────────────────────────┤
│ "quick" │ → [Doc1:Pos1] → [Doc3:Pos0]        │
│ "brown" │ → [Doc1:Pos2] → [Doc3:Pos1]        │
│ "fox"   │ → [Doc1:Pos3]                      │
│ "lazy"  │ → [Doc2:Pos1]                      │
│ "dog"   │ → [Doc2:Pos2]                      │
│ "dogs"  │ → [Doc3:Pos2]                      │
└─────────┴────────────────────────────────────┘
</code></pre></div>
<p dir="auto"><strong>Visual Representation:</strong></p>
<div data-snippet-clipboard-copy-content="                    Inverted Index
                    ┌──────────┐
                    │ Map      │
                    │ [string] │
                    │ SkipList │
                    └────┬─────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   &quot;quick&quot;          &quot;brown&quot;           &quot;fox&quot;
   SkipList         SkipList         SkipList
   ┌──────┐        ┌──────┐         ┌──────┐
   │ HEAD │        │ HEAD │         │ HEAD │
   └──┬───┘        └──┬───┘         └──┬───┘
      │               │                 │
      ▼               ▼                 ▼
   ┌──────┐        ┌──────┐         ┌──────┐
   │Doc1:1│        │Doc1:2│         │Doc1:3│
   └──┬───┘        └──┬───┘         └──────┘
      │               │
      ▼               ▼
   ┌──────┐        ┌──────┐
   │Doc3:0│        │Doc3:1│
   └──────┘        └──────┘"><pre><code>                    Inverted Index
                    ┌──────────┐
                    │ Map      │
                    │ [string] │
                    │ SkipList │
                    └────┬─────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   "quick"          "brown"           "fox"
   SkipList         SkipList         SkipList
   ┌──────┐        ┌──────┐         ┌──────┐
   │ HEAD │        │ HEAD │         │ HEAD │
   └──┬───┘        └──┬───┘         └──┬───┘
      │               │                 │
      ▼               ▼                 ▼
   ┌──────┐        ┌──────┐         ┌──────┐
   │Doc1:1│        │Doc1:2│         │Doc1:3│
   └──┬───┘        └──┬───┘         └──────┘
      │               │
      ▼               ▼
   ┌──────┐        ┌──────┐
   │Doc3:0│        │Doc3:1│
   └──────┘        └──────┘
</code></pre></div>
<p dir="auto"><strong>Benefits:</strong></p>
<ul dir="auto">
<li>Instant term lookups (no document scanning)</li>
<li>Phrase search via position checking</li>
<li>Proximity ranking by measuring distances</li>
<li>Efficient boolean queries (AND, OR, NOT)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Skip Lists</h3><a id="user-content-skip-lists" aria-label="Permalink: Skip Lists" href="#skip-lists"></a></p>
<p dir="auto">A skip list is a probabilistic data structure that maintains sorted data with O(log n) average time complexity for search, insertion, and deletion.</p>
<p dir="auto"><strong>Visual Representation:</strong></p>
<div data-snippet-clipboard-copy-content="Skip List with Multiple Levels (Express Lanes)
═══════════════════════════════════════════════════════════════

Level 3: HEAD ────────────────────────────────────────────────────────────> [30] ────────> NULL
              ↓                                                                ↓
Level 2: HEAD ─────────────────────────────> [15] ────────────────────────> [30] ────────> NULL
              ↓                                ↓                               ↓
Level 1: HEAD ─────────────> [10] ─────────> [15] ────────> [20] ─────────> [30] ────────> NULL
              ↓                ↓                ↓              ↓                ↓
Level 0: HEAD ──> [5] ──> [10] ──> [15] ──> [20] ──> [25] ──> [30] ──> [35] ──> NULL
         (ALL NODES AT LEVEL 0)

         ┌───────┐
         │ Node  │  Each node has a &quot;tower&quot; of forward pointers
         ├───────┤
         │ Key   │  Example: Node [15]
         ├───────┤
         │ Lvl 3 │ ──> [30]      (skip far ahead)
         │ Lvl 2 │ ──> [30]      (skip ahead)
         │ Lvl 1 │ ──> [20]      (skip a little)
         │ Lvl 0 │ ──> [20]      (next node)
         └───────┘"><pre><code>Skip List with Multiple Levels (Express Lanes)
═══════════════════════════════════════════════════════════════

Level 3: HEAD ────────────────────────────────────────────────────────────&gt; [30] ────────&gt; NULL
              ↓                                                                ↓
Level 2: HEAD ─────────────────────────────&gt; [15] ────────────────────────&gt; [30] ────────&gt; NULL
              ↓                                ↓                               ↓
Level 1: HEAD ─────────────&gt; [10] ─────────&gt; [15] ────────&gt; [20] ─────────&gt; [30] ────────&gt; NULL
              ↓                ↓                ↓              ↓                ↓
Level 0: HEAD ──&gt; [5] ──&gt; [10] ──&gt; [15] ──&gt; [20] ──&gt; [25] ──&gt; [30] ──&gt; [35] ──&gt; NULL
         (ALL NODES AT LEVEL 0)

         ┌───────┐
         │ Node  │  Each node has a "tower" of forward pointers
         ├───────┤
         │ Key   │  Example: Node [15]
         ├───────┤
         │ Lvl 3 │ ──&gt; [30]      (skip far ahead)
         │ Lvl 2 │ ──&gt; [30]      (skip ahead)
         │ Lvl 1 │ ──&gt; [20]      (skip a little)
         │ Lvl 0 │ ──&gt; [20]      (next node)
         └───────┘
</code></pre></div>
<p dir="auto"><strong>How Heights are Assigned (Probabilistic):</strong></p>
<div data-snippet-clipboard-copy-content="Coin Flip Algorithm:
┌─────────┬─────────────┬─────────────┐
│ Height  │ Probability │ Visual      │
├─────────┼─────────────┼─────────────┤
│    1    │    50%      │ ▓▓▓▓▓       │
│    2    │    25%      │ ▓▓▓         │
│    3    │   12.5%     │ ▓▓          │
│    4    │   6.25%     │ ▓           │
└─────────┴─────────────┴─────────────┘

For 1000 nodes, expected distribution:
Level 0: ~1000 nodes (all)    ████████████████████████████████████████
Level 1: ~500 nodes           ████████████████████
Level 2: ~250 nodes           ██████████
Level 3: ~125 nodes           █████
Level 4: ~62 nodes            ██"><pre><code>Coin Flip Algorithm:
┌─────────┬─────────────┬─────────────┐
│ Height  │ Probability │ Visual      │
├─────────┼─────────────┼─────────────┤
│    1    │    50%      │ ▓▓▓▓▓       │
│    2    │    25%      │ ▓▓▓         │
│    3    │   12.5%     │ ▓▓          │
│    4    │   6.25%     │ ▓           │
└─────────┴─────────────┴─────────────┘

For 1000 nodes, expected distribution:
Level 0: ~1000 nodes (all)    ████████████████████████████████████████
Level 1: ~500 nodes           ████████████████████
Level 2: ~250 nodes           ██████████
Level 3: ~125 nodes           █████
Level 4: ~62 nodes            ██
</code></pre></div>
<p dir="auto"><strong>Search Algorithm</strong> (finding 20):</p>
<div data-snippet-clipboard-copy-content="Step-by-Step Search for Key = 20:

Level 3: [HEAD] ───────────────────────────────> [30]        (30 > 20, drop down)
           ↓
Level 2: [HEAD] ──────────────> [15] ─────────> [30]        (15 < 20, advance)
                                   ↓
Level 2:                         [15] ─────────> [30]        (30 > 20, drop down)
                                   ↓
Level 1:                         [15] ──> [20]               (20 = 20, FOUND!)
                                          ^^^^

Journey Recorded:
┌───────────┬─────────────────┐
│ Level 3   │ HEAD            │  Predecessor at each level
│ Level 2   │ [15]            │  Used for insertions/deletions
│ Level 1   │ [15]            │
│ Level 0   │ [15]            │
└───────────┴─────────────────┘"><pre><code>Step-by-Step Search for Key = 20:

Level 3: [HEAD] ───────────────────────────────&gt; [30]        (30 &gt; 20, drop down)
           ↓
Level 2: [HEAD] ──────────────&gt; [15] ─────────&gt; [30]        (15 &lt; 20, advance)
                                   ↓
Level 2:                         [15] ─────────&gt; [30]        (30 &gt; 20, drop down)
                                   ↓
Level 1:                         [15] ──&gt; [20]               (20 = 20, FOUND!)
                                          ^^^^

Journey Recorded:
┌───────────┬─────────────────┐
│ Level 3   │ HEAD            │  Predecessor at each level
│ Level 2   │ [15]            │  Used for insertions/deletions
│ Level 1   │ [15]            │
│ Level 0   │ [15]            │
└───────────┴─────────────────┘
</code></pre></div>
<ol dir="auto">
<li>Start at HEAD, Level 3</li>
<li>Level 3: Move to 30? No (30 &gt; 20), drop to Level 2</li>
<li>Level 2: Move to 15? Yes (15 &lt; 20), advance to 15</li>
<li>Level 2: Move to 30? No (30 &gt; 20), drop to Level 1</li>
<li>Level 1: Move to 20? Yes! Found it!</li>
</ol>
<p dir="auto"><strong>Time Complexity: O(log n) on average</strong></p>
<p dir="auto"><strong>Why Skip Lists?</strong></p>
<ul dir="auto">
<li>O(log n) operations without complex balancing</li>
<li>Simpler than AVL or Red-Black trees</li>
<li>Better cache locality than trees</li>
<li>Easier to make lock-free for concurrency</li>
<li>Used in Redis, LevelDB, and other databases</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Text Analysis Pipeline</h3><a id="user-content-text-analysis-pipeline" aria-label="Permalink: Text Analysis Pipeline" href="#text-analysis-pipeline"></a></p>
<p dir="auto">Blaze transforms raw text into searchable tokens through a multi-stage pipeline:</p>
<p dir="auto"><strong>Pipeline Stages:</strong></p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────┐
│                     Text Analysis Pipeline                          │
└─────────────────────────────────────────────────────────────────────┘
                              │
                              ▼
         ┌────────────────────────────────────────┐
         │  1. Tokenization                       │
         │  Split on non-alphanumeric chars       │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  2. Lowercasing                        │
         │  Normalize case (&quot;Quick&quot; → &quot;quick&quot;)    │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  3. Stopword Filtering                 │
         │  Remove common words (the, a, is)      │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  4. Length Filtering                   │
         │  Remove tokens < 2 chars               │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  5. Stemming (Snowball/Porter2)        │
         │  Reduce to root (&quot;running&quot; → &quot;run&quot;)    │
         └────────────────┬───────────────────────┘
                          ▼
                    Final Tokens"><pre><code>┌─────────────────────────────────────────────────────────────────────┐
│                     Text Analysis Pipeline                          │
└─────────────────────────────────────────────────────────────────────┘
                              │
                              ▼
         ┌────────────────────────────────────────┐
         │  1. Tokenization                       │
         │  Split on non-alphanumeric chars       │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  2. Lowercasing                        │
         │  Normalize case ("Quick" → "quick")    │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  3. Stopword Filtering                 │
         │  Remove common words (the, a, is)      │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  4. Length Filtering                   │
         │  Remove tokens &lt; 2 chars               │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  5. Stemming (Snowball/Porter2)        │
         │  Reduce to root ("running" → "run")    │
         └────────────────┬───────────────────────┘
                          ▼
                    Final Tokens
</code></pre></div>
<p dir="auto"><strong>Example Transformation:</strong></p>
<div data-snippet-clipboard-copy-content="Input:  &quot;The Quick Brown Fox Jumps!&quot;
        │
        ├─ Step 1: Tokenization
        │  └─> [&quot;The&quot;, &quot;Quick&quot;, &quot;Brown&quot;, &quot;Fox&quot;, &quot;Jumps&quot;]
        │
        ├─ Step 2: Lowercasing
        │  └─> [&quot;the&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;, &quot;jumps&quot;]
        │
        ├─ Step 3: Stopword Filtering (remove &quot;the&quot;)
        │  └─> [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;, &quot;jumps&quot;]
        │
        ├─ Step 4: Length Filtering (all pass >= 2 chars)
        │  └─> [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;, &quot;jumps&quot;]
        │
        └─ Step 5: Stemming (&quot;jumps&quot; → &quot;jump&quot;)
           └─> [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;, &quot;jump&quot;]"><pre><code>Input:  "The Quick Brown Fox Jumps!"
        │
        ├─ Step 1: Tokenization
        │  └─&gt; ["The", "Quick", "Brown", "Fox", "Jumps"]
        │
        ├─ Step 2: Lowercasing
        │  └─&gt; ["the", "quick", "brown", "fox", "jumps"]
        │
        ├─ Step 3: Stopword Filtering (remove "the")
        │  └─&gt; ["quick", "brown", "fox", "jumps"]
        │
        ├─ Step 4: Length Filtering (all pass &gt;= 2 chars)
        │  └─&gt; ["quick", "brown", "fox", "jumps"]
        │
        └─ Step 5: Stemming ("jumps" → "jump")
           └─&gt; ["quick", "brown", "fox", "jump"]
</code></pre></div>
<p dir="auto"><strong>Configuration:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Use default configuration
tokens := blaze.Analyze(&quot;The quick brown fox&quot;)

// Custom configuration
config := blaze.AnalyzerConfig{
    MinTokenLength:  3,      // Only keep tokens >= 3 chars
    EnableStemming:  false,  // Disable stemming
    EnableStopwords: true,   // Keep stopword filtering
}
tokens := blaze.AnalyzeWithConfig(&quot;The quick brown fox&quot;, config)"><pre><span>// Use default configuration</span>
<span>tokens</span> <span>:=</span> <span>blaze</span>.<span>Analyze</span>(<span>"The quick brown fox"</span>)

<span>// Custom configuration</span>
<span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>3</span>,      <span>// Only keep tokens &gt;= 3 chars</span>
    <span>EnableStemming</span>:  <span>false</span>,  <span>// Disable stemming</span>
    <span>EnableStopwords</span>: <span>true</span>,   <span>// Keep stopword filtering</span>
}
<span>tokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>"The quick brown fox"</span>, <span>config</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Search Operations</h3><a id="user-content-search-operations" aria-label="Permalink: Search Operations" href="#search-operations"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">1. Basic Term Search</h4><a id="user-content-1-basic-term-search" aria-label="Permalink: 1. Basic Term Search" href="#1-basic-term-search"></a></p>
<p dir="auto">Find all occurrences of a single term:</p>
<div dir="auto" data-snippet-clipboard-copy-content="idx := blaze.NewInvertedIndex()
idx.Index(1, &quot;the quick brown fox&quot;)
idx.Index(2, &quot;quick brown dogs&quot;)

// Find first occurrence of &quot;quick&quot;
pos, err := idx.First(&quot;quick&quot;)
if err == nil {
    fmt.Printf(&quot;Found at Doc %d, Pos %d\n&quot;,
        int(pos.DocumentID), int(pos.Offset))
}

// Find next occurrence
nextPos, _ := idx.Next(&quot;quick&quot;, pos)"><pre><span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
<span>idx</span>.<span>Index</span>(<span>1</span>, <span>"the quick brown fox"</span>)
<span>idx</span>.<span>Index</span>(<span>2</span>, <span>"quick brown dogs"</span>)

<span>// Find first occurrence of "quick"</span>
<span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>First</span>(<span>"quick"</span>)
<span>if</span> <span>err</span> <span>==</span> <span>nil</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"Found at Doc %d, Pos %d<span>\n</span>"</span>,
        <span>int</span>(<span>pos</span>.<span>DocumentID</span>), <span>int</span>(<span>pos</span>.<span>Offset</span>))
}

<span>// Find next occurrence</span>
<span>nextPos</span>, <span>_</span> <span>:=</span> <span>idx</span>.<span>Next</span>(<span>"quick"</span>, <span>pos</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">2. Phrase Search</h4><a id="user-content-2-phrase-search" aria-label="Permalink: 2. Phrase Search" href="#2-phrase-search"></a></p>
<p dir="auto">Find exact sequences of words:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents containing &quot;quick brown fox&quot; as a phrase
matches := idx.FindAllPhrases(&quot;quick brown fox&quot;, blaze.BOFDocument)

for _, match := range matches {
    start, end := match[0], match[1]
    fmt.Printf(&quot;Found in Doc %d from Pos %d to %d\n&quot;,
        int(start.DocumentID), int(start.Offset), int(end.Offset))
}"><pre><span>// Find documents containing "quick brown fox" as a phrase</span>
<span>matches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>"quick brown fox"</span>, <span>blaze</span>.<span>BOFDocument</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
    <span>start</span>, <span>end</span> <span>:=</span> <span>match</span>[<span>0</span>], <span>match</span>[<span>1</span>]
    <span>fmt</span>.<span>Printf</span>(<span>"Found in Doc %d from Pos %d to %d<span>\n</span>"</span>,
        <span>int</span>(<span>start</span>.<span>DocumentID</span>), <span>int</span>(<span>start</span>.<span>Offset</span>), <span>int</span>(<span>end</span>.<span>Offset</span>))
}</pre></div>
<p dir="auto"><strong>Algorithm:</strong></p>
<div data-snippet-clipboard-copy-content="Searching for phrase: &quot;brown fox&quot;

Document: &quot;the quick brown dog jumped over the brown fox&quot;
Positions: 0     1     2    3     4      5    6     7    8

Phase 1: Find END (last word &quot;fox&quot;)
┌─────────────────────────────────────────────────────────┐
│ Find &quot;brown&quot; → Doc:Pos2                                 │
│ Find &quot;fox&quot; after Pos2 → Doc:Pos8  ← END position       │
└─────────────────────────────────────────────────────────┘

Phase 2: Walk BACKWARDS from END to find START
┌─────────────────────────────────────────────────────────┐
│ From Pos9, find previous &quot;brown&quot; → Doc:Pos7  ← START   │
└─────────────────────────────────────────────────────────┘

Phase 3: Validate
┌─────────────────────────────────────────────────────────┐
│ Start: Pos7, End: Pos8                                  │
│ Distance: 8 - 7 = 1                                     │
│ Expected: 2 words - 1 = 1  MATCH!                      │
│                                                          │
│      &quot;brown&quot;  &quot;fox&quot;                                     │
│        ▲       ▲                                        │
│       Pos7    Pos8    (consecutive positions)           │
└─────────────────────────────────────────────────────────┘"><pre><code>Searching for phrase: "brown fox"

Document: "the quick brown dog jumped over the brown fox"
Positions: 0     1     2    3     4      5    6     7    8

Phase 1: Find END (last word "fox")
┌─────────────────────────────────────────────────────────┐
│ Find "brown" → Doc:Pos2                                 │
│ Find "fox" after Pos2 → Doc:Pos8  ← END position       │
└─────────────────────────────────────────────────────────┘

Phase 2: Walk BACKWARDS from END to find START
┌─────────────────────────────────────────────────────────┐
│ From Pos9, find previous "brown" → Doc:Pos7  ← START   │
└─────────────────────────────────────────────────────────┘

Phase 3: Validate
┌─────────────────────────────────────────────────────────┐
│ Start: Pos7, End: Pos8                                  │
│ Distance: 8 - 7 = 1                                     │
│ Expected: 2 words - 1 = 1  MATCH!                      │
│                                                          │
│      "brown"  "fox"                                     │
│        ▲       ▲                                        │
│       Pos7    Pos8    (consecutive positions)           │
└─────────────────────────────────────────────────────────┘
</code></pre></div>
<ol dir="auto">
<li>Find END: Locate the last word of the phrase</li>
<li>Walk BACKWARDS: Find previous occurrences of earlier words</li>
<li>Validate: Check if positions are consecutive</li>
<li>Recurse: Continue searching for more matches</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">3. Proximity Search</h4><a id="user-content-3-proximity-search" aria-label="Permalink: 3. Proximity Search" href="#3-proximity-search"></a></p>
<p dir="auto">Find documents containing all terms (not necessarily consecutive):</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with both &quot;quick&quot; and &quot;fox&quot;
cover := idx.NextCover([]string{&quot;quick&quot;, &quot;fox&quot;}, blaze.BOFDocument)
start, end := cover[0], cover[1]

// Calculate proximity score
distance := end.Offset - start.Offset
score := 1.0 / distance  // Closer terms = higher score"><pre><span>// Find documents with both "quick" and "fox"</span>
<span>cover</span> <span>:=</span> <span>idx</span>.<span>NextCover</span>([]<span>string</span>{<span>"quick"</span>, <span>"fox"</span>}, <span>blaze</span>.<span>BOFDocument</span>)
<span>start</span>, <span>end</span> <span>:=</span> <span>cover</span>[<span>0</span>], <span>cover</span>[<span>1</span>]

<span>// Calculate proximity score</span>
<span>distance</span> <span>:=</span> <span>end</span>.<span>Offset</span> <span>-</span> <span>start</span>.<span>Offset</span>
<span>score</span> <span>:=</span> <span>1.0</span> <span>/</span> <span>distance</span>  <span>// Closer terms = higher score</span></pre></div>
<p dir="auto"><strong>Cover Algorithm:</strong></p>
<div data-snippet-clipboard-copy-content="Searching for: [&quot;quick&quot;, &quot;fox&quot;] (any order, not necessarily consecutive)

Document: &quot;the quick brown dog jumped over the lazy fox&quot;
Positions: 0     1     2    3     4      5    6    7    8

Phase 1: Find COVER END (furthest term)
┌──────────────────────────────────────────────────────────────┐
│ Find &quot;quick&quot; after BOF → Doc:Pos1                           │
│ Find &quot;fox&quot; after BOF → Doc:Pos8  ← FURTHEST (cover end)     │
└──────────────────────────────────────────────────────────────┘

Phase 2: Find COVER START (earliest term before end)
┌──────────────────────────────────────────────────────────────┐
│ Find &quot;quick&quot; before Pos9 → Doc:Pos1  ← EARLIEST (cover start)│
│ Find &quot;fox&quot; before Pos9 → Doc:Pos8                           │
└──────────────────────────────────────────────────────────────┘

Phase 3: Validate &amp; Return
┌──────────────────────────────────────────────────────────────┐
│ Cover: [Pos1, Pos8]                                          │
│ Same document? Yes                                           │
│ All terms present? Yes                                       │
│                                                               │
│ &quot;quick&quot; ... ... ... ... ... ... ... &quot;fox&quot;                    │
│    ▲                                   ▲                     │
│   Pos1                                Pos8                   │
│   └────────── Cover Range ──────────────┘                    │
│                                                               │
│ Proximity Score: 1 / (8 - 1 + 1) = 1/8 = 0.125             │
└──────────────────────────────────────────────────────────────┘"><pre><code>Searching for: ["quick", "fox"] (any order, not necessarily consecutive)

Document: "the quick brown dog jumped over the lazy fox"
Positions: 0     1     2    3     4      5    6    7    8

Phase 1: Find COVER END (furthest term)
┌──────────────────────────────────────────────────────────────┐
│ Find "quick" after BOF → Doc:Pos1                           │
│ Find "fox" after BOF → Doc:Pos8  ← FURTHEST (cover end)     │
└──────────────────────────────────────────────────────────────┘

Phase 2: Find COVER START (earliest term before end)
┌──────────────────────────────────────────────────────────────┐
│ Find "quick" before Pos9 → Doc:Pos1  ← EARLIEST (cover start)│
│ Find "fox" before Pos9 → Doc:Pos8                           │
└──────────────────────────────────────────────────────────────┘

Phase 3: Validate &amp; Return
┌──────────────────────────────────────────────────────────────┐
│ Cover: [Pos1, Pos8]                                          │
│ Same document? Yes                                           │
│ All terms present? Yes                                       │
│                                                               │
│ "quick" ... ... ... ... ... ... ... "fox"                    │
│    ▲                                   ▲                     │
│   Pos1                                Pos8                   │
│   └────────── Cover Range ──────────────┘                    │
│                                                               │
│ Proximity Score: 1 / (8 - 1 + 1) = 1/8 = 0.125             │
└──────────────────────────────────────────────────────────────┘
</code></pre></div>
<ol dir="auto">
<li>Find FURTHEST occurrence of any term (cover end)</li>
<li>Find EARLIEST occurrence of each term before end (cover start)</li>
<li>Validate all terms are in the same document</li>
<li>Return [start, end] positions</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">4. BM25 Ranking</h4><a id="user-content-4-bm25-ranking" aria-label="Permalink: 4. BM25 Ranking" href="#4-bm25-ranking"></a></p>
<p dir="auto"><strong>BM25 (Best Matching 25)</strong> is a probabilistic ranking function used by search engines to estimate the relevance of documents to a given search query. It's the industry standard used by Elasticsearch, Solr, and Lucene.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Search and rank using BM25
results := idx.RankBM25(&quot;machine learning&quot;, 10)

for _, match := range results {
    fmt.Printf(&quot;Doc %d: Score %.2f\n&quot;,
        match.DocID,
        match.Score)
}"><pre><span>// Search and rank using BM25</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"machine learning"</span>, <span>10</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"Doc %d: Score %.2f<span>\n</span>"</span>,
        <span>match</span>.<span>DocID</span>,
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>What BM25 Considers:</strong></p>
<div data-snippet-clipboard-copy-content="+------------------+-------------------------------------------------------+
| Factor           | Description                                           |
+------------------+-------------------------------------------------------+
| Term Frequency   | How often does the term appear?                       |
|                  | More occurrences = higher relevance                   |
+------------------+-------------------------------------------------------+
| TF Saturation    | Diminishing returns                                   |
|                  | 3->10 occurrences matters less than 0->3             |
+------------------+-------------------------------------------------------+
| Document Length  | Normalize by document size                            |
|                  | Prevents long docs from dominating results            |
+------------------+-------------------------------------------------------+
| Term Rarity      | Rare terms are more important than common ones        |
|                  | &quot;quantum&quot; > &quot;the&quot; in importance                       |
+------------------+-------------------------------------------------------+"><pre><code>+------------------+-------------------------------------------------------+
| Factor           | Description                                           |
+------------------+-------------------------------------------------------+
| Term Frequency   | How often does the term appear?                       |
|                  | More occurrences = higher relevance                   |
+------------------+-------------------------------------------------------+
| TF Saturation    | Diminishing returns                                   |
|                  | 3-&gt;10 occurrences matters less than 0-&gt;3             |
+------------------+-------------------------------------------------------+
| Document Length  | Normalize by document size                            |
|                  | Prevents long docs from dominating results            |
+------------------+-------------------------------------------------------+
| Term Rarity      | Rare terms are more important than common ones        |
|                  | "quantum" &gt; "the" in importance                       |
+------------------+-------------------------------------------------------+
</code></pre></div>
<p dir="auto"><strong>Complete BM25 Formula:</strong></p>
<div data-snippet-clipboard-copy-content="                    IDF(q_i) × TF(q_i, D) × (k1 + 1)
BM25(D, Q) = SUM  ─────────────────────────────────────────
             q_i  TF(q_i, D) + k1 × (1 - b + b × |D|/avgdl)
            in Q

Where:
    D       = Document being scored
    Q       = Query (set of terms q_1, q_2, ..., q_n)
    q_i     = Individual query term"><pre><code>                    IDF(q_i) × TF(q_i, D) × (k1 + 1)
BM25(D, Q) = SUM  ─────────────────────────────────────────
             q_i  TF(q_i, D) + k1 × (1 - b + b × |D|/avgdl)
            in Q

Where:
    D       = Document being scored
    Q       = Query (set of terms q_1, q_2, ..., q_n)
    q_i     = Individual query term
</code></pre></div>
<p dir="auto"><strong>Component Breakdown:</strong></p>
<div data-snippet-clipboard-copy-content="+-------------------+-----------------------------------------------------+
|    Component      |                   Definition                        |
+-------------------+-----------------------------------------------------+
| IDF(q_i)          | Inverse Document Frequency                          |
|                   |                                                     |
|                   |          N - df(q_i) + 0.5                          |
|                   | log( ─────────────────────── + 1 )                  |
|                   |            df(q_i) + 0.5                            |
|                   |                                                     |
|                   | N  = Total documents in corpus                      |
|                   | df = Documents containing term q_i                  |
|                   |                                                     |
|                   | Effect: Rare terms get higher weights              |
+-------------------+-----------------------------------------------------+
| TF(q_i, D)        | Term Frequency                                      |
|                   | = Number of times q_i appears in document D         |
|                   |                                                     |
|                   | Effect: More occurrences = higher relevance         |
+-------------------+-----------------------------------------------------+
| k1                | Term Frequency Saturation Parameter                 |
|                   | = 1.5 (default)                                     |
|                   | Range: [1.2, 2.0]                                   |
|                   |                                                     |
|                   | Effect: Controls diminishing returns                |
|                   |         Higher k1 = less saturation                 |
+-------------------+-----------------------------------------------------+
| b                 | Length Normalization Parameter                      |
|                   | = 0.75 (default)                                    |
|                   | Range: [0, 1]                                       |
|                   |                                                     |
|                   | Effect: Controls length penalty                     |
|                   |         b=1  = full normalization                   |
|                   |         b=0  = no normalization                     |
+-------------------+-----------------------------------------------------+
| |D|               | Document Length                                     |
|                   | = Number of terms in document D                     |
+-------------------+-----------------------------------------------------+
| avgdl             | Average Document Length                             |
|                   | = Total terms / Total documents                     |
+-------------------+-----------------------------------------------------+"><pre><code>+-------------------+-----------------------------------------------------+
|    Component      |                   Definition                        |
+-------------------+-----------------------------------------------------+
| IDF(q_i)          | Inverse Document Frequency                          |
|                   |                                                     |
|                   |          N - df(q_i) + 0.5                          |
|                   | log( ─────────────────────── + 1 )                  |
|                   |            df(q_i) + 0.5                            |
|                   |                                                     |
|                   | N  = Total documents in corpus                      |
|                   | df = Documents containing term q_i                  |
|                   |                                                     |
|                   | Effect: Rare terms get higher weights              |
+-------------------+-----------------------------------------------------+
| TF(q_i, D)        | Term Frequency                                      |
|                   | = Number of times q_i appears in document D         |
|                   |                                                     |
|                   | Effect: More occurrences = higher relevance         |
+-------------------+-----------------------------------------------------+
| k1                | Term Frequency Saturation Parameter                 |
|                   | = 1.5 (default)                                     |
|                   | Range: [1.2, 2.0]                                   |
|                   |                                                     |
|                   | Effect: Controls diminishing returns                |
|                   |         Higher k1 = less saturation                 |
+-------------------+-----------------------------------------------------+
| b                 | Length Normalization Parameter                      |
|                   | = 0.75 (default)                                    |
|                   | Range: [0, 1]                                       |
|                   |                                                     |
|                   | Effect: Controls length penalty                     |
|                   |         b=1  = full normalization                   |
|                   |         b=0  = no normalization                     |
+-------------------+-----------------------------------------------------+
| |D|               | Document Length                                     |
|                   | = Number of terms in document D                     |
+-------------------+-----------------------------------------------------+
| avgdl             | Average Document Length                             |
|                   | = Total terms / Total documents                     |
+-------------------+-----------------------------------------------------+
</code></pre></div>
<p dir="auto"><strong>Visual Example - Term Frequency Saturation:</strong></p>
<div data-snippet-clipboard-copy-content="Score Contribution (with k1=1.5, b=0.75)
    ^
    |                            /---------------  (saturation)
    |                          /
 3  |                       /
    |                     /
 2  |                  /
    |               /
 1  |            /
    |         /
 0  |______/
    +---+---+---+---+---+---+---+---+---+---+---> Term Frequency
    0   1   2   3   4   5   6   7   8   9   10

Key Insight: Going from 0->3 occurrences adds more to the score
             than going from 7->10 occurrences (diminishing returns)"><pre><code>Score Contribution (with k1=1.5, b=0.75)
    ^
    |                            /---------------  (saturation)
    |                          /
 3  |                       /
    |                     /
 2  |                  /
    |               /
 1  |            /
    |         /
 0  |______/
    +---+---+---+---+---+---+---+---+---+---+---&gt; Term Frequency
    0   1   2   3   4   5   6   7   8   9   10

Key Insight: Going from 0-&gt;3 occurrences adds more to the score
             than going from 7-&gt;10 occurrences (diminishing returns)
</code></pre></div>
<p dir="auto"><strong>Visual Example - Document Length Normalization:</strong></p>
<div data-snippet-clipboard-copy-content="Scenario: Same term frequency, different document lengths

Document A: 100 words, &quot;learning&quot; appears 3 times
Document B: 1000 words, &quot;learning&quot; appears 3 times

Raw TF:  Both have TF = 3
Density: Doc A = 3/100  = 3.0%    <- Higher density
         Doc B = 3/1000 = 0.3%    <- Lower density

BM25 adjusts: Doc A gets HIGHER score (term is more prominent)
              Doc B gets LOWER score (term is less prominent)

Length Penalty Formula:

    Penalty = k1 × (1 - b + b × docLen/avgDocLen)

    If docLen > avgDocLen: Penalty increases (score decreases)
    If docLen < avgDocLen: Penalty decreases (score increases)"><pre><code>Scenario: Same term frequency, different document lengths

Document A: 100 words, "learning" appears 3 times
Document B: 1000 words, "learning" appears 3 times

Raw TF:  Both have TF = 3
Density: Doc A = 3/100  = 3.0%    &lt;- Higher density
         Doc B = 3/1000 = 0.3%    &lt;- Lower density

BM25 adjusts: Doc A gets HIGHER score (term is more prominent)
              Doc B gets LOWER score (term is less prominent)

Length Penalty Formula:

    Penalty = k1 × (1 - b + b × docLen/avgDocLen)

    If docLen &gt; avgDocLen: Penalty increases (score decreases)
    If docLen &lt; avgDocLen: Penalty decreases (score increases)
</code></pre></div>
<p dir="auto"><strong>Step-by-Step Scoring Example:</strong></p>
<div data-snippet-clipboard-copy-content="SETUP:
------
Query:  &quot;machine learning&quot;
Corpus: 1000 documents, average length 150 words
Target: Document 1 (200 words)
        - &quot;machine&quot; appears 3 times (df=100 docs have &quot;machine&quot;)
        - &quot;learning&quot; appears 2 times (df=50 docs have &quot;learning&quot;)

Parameters: k1=1.5, b=0.75


STEP 1: Calculate IDF for each term
----------------------------------------

IDF(machine):
    N = 1000, df = 100

    IDF = log((1000 - 100 + 0.5) / (100 + 0.5) + 1)
        = log(900.5 / 100.5 + 1)
        = log(8.96 + 1)
        = log(9.96)
        ≈ 2.30

IDF(learning):
    N = 1000, df = 50

    IDF = log((1000 - 50 + 0.5) / (50 + 0.5) + 1)
        = log(950.5 / 50.5 + 1)
        = log(18.82 + 1)
        = log(19.82)
        ≈ 2.99

    Note: &quot;learning&quot; is rarer (df=50) than &quot;machine&quot; (df=100)
          so it gets a higher IDF weight


STEP 2: Calculate normalized TF for &quot;machine&quot;
----------------------------------------------

TF = 3 (appears 3 times)
docLen = 200
avgdl = 150

Numerator   = TF × (k1 + 1)
            = 3 × (1.5 + 1)
            = 3 × 2.5
            = 7.5

Denominator = TF + k1 × (1 - b + b × (docLen / avgdl))
            = 3 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 3 + 1.5 × (0.25 + 0.75 × 1.333)
            = 3 + 1.5 × (0.25 + 1.0)
            = 3 + 1.5 × 1.25
            = 3 + 1.875
            = 4.875

Normalized TF = 7.5 / 4.875 ≈ 1.54

Contribution = IDF × Normalized TF
             = 2.30 × 1.54
             ≈ 3.54


STEP 3: Calculate normalized TF for &quot;learning&quot;
-----------------------------------------------

TF = 2 (appears 2 times)
docLen = 200
avgdl = 150

Numerator   = 2 × 2.5 = 5.0

Denominator = 2 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 2 + 1.875
            = 3.875

Normalized TF = 5.0 / 3.875 ≈ 1.29

Contribution = IDF × Normalized TF
             = 2.99 × 1.29
             ≈ 3.86


STEP 4: Calculate final BM25 score
-----------------------------------

BM25(Document 1, &quot;machine learning&quot;) = 3.54 + 3.86 = 7.40

                    +----------+----------+
                    | Term     | Score    |
                    +----------+----------+
                    | machine  | 3.54     |
                    | learning | 3.86     |
                    +----------+----------+
                    | TOTAL    | 7.40     |
                    +----------+----------+"><pre><code>SETUP:
------
Query:  "machine learning"
Corpus: 1000 documents, average length 150 words
Target: Document 1 (200 words)
        - "machine" appears 3 times (df=100 docs have "machine")
        - "learning" appears 2 times (df=50 docs have "learning")

Parameters: k1=1.5, b=0.75


STEP 1: Calculate IDF for each term
----------------------------------------

IDF(machine):
    N = 1000, df = 100

    IDF = log((1000 - 100 + 0.5) / (100 + 0.5) + 1)
        = log(900.5 / 100.5 + 1)
        = log(8.96 + 1)
        = log(9.96)
        ≈ 2.30

IDF(learning):
    N = 1000, df = 50

    IDF = log((1000 - 50 + 0.5) / (50 + 0.5) + 1)
        = log(950.5 / 50.5 + 1)
        = log(18.82 + 1)
        = log(19.82)
        ≈ 2.99

    Note: "learning" is rarer (df=50) than "machine" (df=100)
          so it gets a higher IDF weight


STEP 2: Calculate normalized TF for "machine"
----------------------------------------------

TF = 3 (appears 3 times)
docLen = 200
avgdl = 150

Numerator   = TF × (k1 + 1)
            = 3 × (1.5 + 1)
            = 3 × 2.5
            = 7.5

Denominator = TF + k1 × (1 - b + b × (docLen / avgdl))
            = 3 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 3 + 1.5 × (0.25 + 0.75 × 1.333)
            = 3 + 1.5 × (0.25 + 1.0)
            = 3 + 1.5 × 1.25
            = 3 + 1.875
            = 4.875

Normalized TF = 7.5 / 4.875 ≈ 1.54

Contribution = IDF × Normalized TF
             = 2.30 × 1.54
             ≈ 3.54


STEP 3: Calculate normalized TF for "learning"
-----------------------------------------------

TF = 2 (appears 2 times)
docLen = 200
avgdl = 150

Numerator   = 2 × 2.5 = 5.0

Denominator = 2 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 2 + 1.875
            = 3.875

Normalized TF = 5.0 / 3.875 ≈ 1.29

Contribution = IDF × Normalized TF
             = 2.99 × 1.29
             ≈ 3.86


STEP 4: Calculate final BM25 score
-----------------------------------

BM25(Document 1, "machine learning") = 3.54 + 3.86 = 7.40

                    +----------+----------+
                    | Term     | Score    |
                    +----------+----------+
                    | machine  | 3.54     |
                    | learning | 3.86     |
                    +----------+----------+
                    | TOTAL    | 7.40     |
                    +----------+----------+
</code></pre></div>
<p dir="auto"><strong>Why BM25 Works:</strong></p>
<div data-snippet-clipboard-copy-content="+------------------------+------------------------------------------------+
| Advantage              | Explanation                                    |
+------------------------+------------------------------------------------+
| Industry Standard      | Used by Elasticsearch, Solr, Lucene           |
|                        | Battle-tested in production systems            |
+------------------------+------------------------------------------------+
| Probabilistic          | Based on probability ranking principle         |
|                        | Solid theoretical foundation                   |
+------------------------+------------------------------------------------+
| Term Rarity (IDF)      | Rare terms contribute more to score            |
|                        | &quot;quantum&quot; > &quot;the&quot; in importance                |
+------------------------+------------------------------------------------+
| Saturation             | Diminishing returns for repeated terms         |
|                        | 0->3 occurrences: HIGH impact                  |
|                        | 7->10 occurrences: LOW impact                  |
+------------------------+------------------------------------------------+
| Length Normalization   | Prevents long documents from dominating        |
|                        | Adjusts for document size bias                 |
+------------------------+------------------------------------------------+
| Tunable                | Adjust k1 and b for domain-specific needs     |
|                        | Customize behavior without changing algorithm  |
+------------------------+------------------------------------------------+"><pre><code>+------------------------+------------------------------------------------+
| Advantage              | Explanation                                    |
+------------------------+------------------------------------------------+
| Industry Standard      | Used by Elasticsearch, Solr, Lucene           |
|                        | Battle-tested in production systems            |
+------------------------+------------------------------------------------+
| Probabilistic          | Based on probability ranking principle         |
|                        | Solid theoretical foundation                   |
+------------------------+------------------------------------------------+
| Term Rarity (IDF)      | Rare terms contribute more to score            |
|                        | "quantum" &gt; "the" in importance                |
+------------------------+------------------------------------------------+
| Saturation             | Diminishing returns for repeated terms         |
|                        | 0-&gt;3 occurrences: HIGH impact                  |
|                        | 7-&gt;10 occurrences: LOW impact                  |
+------------------------+------------------------------------------------+
| Length Normalization   | Prevents long documents from dominating        |
|                        | Adjusts for document size bias                 |
+------------------------+------------------------------------------------+
| Tunable                | Adjust k1 and b for domain-specific needs     |
|                        | Customize behavior without changing algorithm  |
+------------------------+------------------------------------------------+
</code></pre></div>
<p dir="auto"><strong>Comparison with Simple TF-IDF:</strong></p>
<div data-snippet-clipboard-copy-content="Simple TF-IDF:
    Score = TF × IDF
    Problem: Linear relationship with TF
             10 occurrences = 10x score of 1 occurrence

    TF-IDF Score
        ^
        |                                        /
     10 |                                      /
        |                                    /
      5 |                                  /
        |                                /
      0 |______________________________/
        +---+---+---+---+---+---+---+---+---> Term Frequency
        0   2   4   6   8   10  12  14  16

BM25:
    Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)
    Benefit: Sublinear relationship with TF
             Saturation prevents spam

    BM25 Score
        ^
        |                    /----------------  (plateau)
      4 |                  /
        |                /
      2 |             /
        |          /
      0 |________/
        +---+---+---+---+---+---+---+---+---> Term Frequency
        0   2   4   6   8   10  12  14  16

    Key: BM25 saturates, preventing keyword stuffing exploits"><pre><code>Simple TF-IDF:
    Score = TF × IDF
    Problem: Linear relationship with TF
             10 occurrences = 10x score of 1 occurrence

    TF-IDF Score
        ^
        |                                        /
     10 |                                      /
        |                                    /
      5 |                                  /
        |                                /
      0 |______________________________/
        +---+---+---+---+---+---+---+---+---&gt; Term Frequency
        0   2   4   6   8   10  12  14  16

BM25:
    Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)
    Benefit: Sublinear relationship with TF
             Saturation prevents spam

    BM25 Score
        ^
        |                    /----------------  (plateau)
      4 |                  /
        |                /
      2 |             /
        |          /
      0 |________/
        +---+---+---+---+---+---+---+---+---&gt; Term Frequency
        0   2   4   6   8   10  12  14  16

    Key: BM25 saturates, preventing keyword stuffing exploits
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">5. Proximity Ranking</h4><a id="user-content-5-proximity-ranking" aria-label="Permalink: 5. Proximity Ranking" href="#5-proximity-ranking"></a></p>
<p dir="auto">Score and rank documents by term proximity:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Search and rank results
matches := idx.RankProximity(&quot;machine learning&quot;, 10)

for _, match := range matches {
    fmt.Printf(&quot;Doc %d: Score %.2f\n&quot;,
        int(match.Offsets[0].DocumentID),
        match.Score)
}"><pre><span>// Search and rank results</span>
<span>matches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"machine learning"</span>, <span>10</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"Doc %d: Score %.2f<span>\n</span>"</span>,
        <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>),
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>Scoring Formula:</strong></p>
<div data-snippet-clipboard-copy-content="For each cover in a document:
    score += 1 / (coverEnd - coverStart + 1)

┌────────────────────────────────────────────────────────────────┐
│ Proximity Scoring Examples                                     │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 1: &quot;machine learning is machine learning&quot;                  │
│         Pos:0      1      2  3       4                          │
│                                                                 │
│   Cover 1: [Pos 0-1]  → score += 1/(1-0+1) = 1/2 = 0.500      │
│   Cover 2: [Pos 3-4]  → score += 1/(4-3+1) = 1/2 = 0.500      │
│                         ─────────────────────────────           │
│   Total Score: 1.000                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 2: &quot;learning about machine and learning&quot;                   │
│         Pos:0       1     2       3   4                         │
│                                                                 │
│   Cover 1: [Pos 0-2]  → score += 1/(2-0+1) = 1/3 = 0.333      │
│   Cover 2: [Pos 2-4]  → score += 1/(4-2+1) = 1/3 = 0.333      │
│                         ─────────────────────────────           │
│   Total Score: 0.666                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 3: &quot;machine ... ... ... ... learning&quot;                      │
│         Pos:0    1   2   3   4   5                              │
│                                                                 │
│   Cover 1: [Pos 0-5]  → score += 1/(5-0+1) = 1/6 = 0.167      │
│                         ─────────────────────────────           │
│   Total Score: 0.167                                            │
│                                                                 │
└────────────────────────────────────────────────────────────────┘

Ranking: Doc 1 (1.000) > Doc 2 (0.666) > Doc 3 (0.167)
          ▲               ▲               ▲
      Terms closest   Terms medium   Terms far apart"><pre><code>For each cover in a document:
    score += 1 / (coverEnd - coverStart + 1)

┌────────────────────────────────────────────────────────────────┐
│ Proximity Scoring Examples                                     │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 1: "machine learning is machine learning"                  │
│         Pos:0      1      2  3       4                          │
│                                                                 │
│   Cover 1: [Pos 0-1]  → score += 1/(1-0+1) = 1/2 = 0.500      │
│   Cover 2: [Pos 3-4]  → score += 1/(4-3+1) = 1/2 = 0.500      │
│                         ─────────────────────────────           │
│   Total Score: 1.000                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 2: "learning about machine and learning"                   │
│         Pos:0       1     2       3   4                         │
│                                                                 │
│   Cover 1: [Pos 0-2]  → score += 1/(2-0+1) = 1/3 = 0.333      │
│   Cover 2: [Pos 2-4]  → score += 1/(4-2+1) = 1/3 = 0.333      │
│                         ─────────────────────────────           │
│   Total Score: 0.666                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 3: "machine ... ... ... ... learning"                      │
│         Pos:0    1   2   3   4   5                              │
│                                                                 │
│   Cover 1: [Pos 0-5]  → score += 1/(5-0+1) = 1/6 = 0.167      │
│                         ─────────────────────────────           │
│   Total Score: 0.167                                            │
│                                                                 │
└────────────────────────────────────────────────────────────────┘

Ranking: Doc 1 (1.000) &gt; Doc 2 (0.666) &gt; Doc 3 (0.167)
          ▲               ▲               ▲
      Terms closest   Terms medium   Terms far apart
</code></pre></div>
<p dir="auto"><strong>Why This Works:</strong></p>
<ul dir="auto">
<li>Smaller distances → larger scores (inverse relationship)</li>
<li>Multiple occurrences → higher scores (additive)</li>
<li>Documents with terms close together rank higher</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Query Builder API</h2><a id="user-content-query-builder-api" aria-label="Permalink: Query Builder API" href="#query-builder-api"></a></p>
<p dir="auto">The Query Builder provides a <strong>type-safe, fluent API</strong> for constructing complex boolean queries with roaring bitmaps. No string parsing, no syntax errors - just clean, composable code.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why Use Builder Pattern</h3><a id="user-content-why-use-builder-pattern" aria-label="Permalink: Why Use Builder Pattern" href="#why-use-builder-pattern"></a></p>
<p dir="auto"><strong>String Parsing Approach:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Error-prone, runtime failures
results, err := index.ExecuteQuery(&quot;(machine AND learning) OR python&quot;)
if err != nil {
    // Handle parsing errors
}"><pre><span>// Error-prone, runtime failures</span>
<span>results</span>, <span>err</span> <span>:=</span> <span>index</span>.<span>ExecuteQuery</span>(<span>"(machine AND learning) OR python"</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>// Handle parsing errors</span>
}</pre></div>
<p dir="auto"><strong>Builder Pattern Approach:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Type-safe, compile-time checks, IDE autocomplete!
results := blaze.NewQueryBuilder(index).
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&quot;machine&quot;).And().Term(&quot;learning&quot;)
    }).
    Or().
    Term(&quot;python&quot;).
    Execute()"><pre><span>// Type-safe, compile-time checks, IDE autocomplete!</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>index</span>).
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>"machine"</span>).<span>And</span>().<span>Term</span>(<span>"learning"</span>)
    }).
    <span>Or</span>().
    <span>Term</span>(<span>"python"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Quick Start</h3><a id="user-content-query-builder-quick-start" aria-label="Permalink: Query Builder Quick Start" href="#query-builder-quick-start"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Single Term Query</h4><a id="user-content-single-term-query" aria-label="Permalink: Single Term Query" href="#single-term-query"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find all documents containing &quot;machine&quot;
results := blaze.NewQueryBuilder(idx).
    Term(&quot;machine&quot;).
    Execute()

fmt.Printf(&quot;Found %d documents\n&quot;, results.GetCardinality())"><pre><span>// Find all documents containing "machine"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"machine"</span>).
    <span>Execute</span>()

<span>fmt</span>.<span>Printf</span>(<span>"Found %d documents<span>\n</span>"</span>, <span>results</span>.<span>GetCardinality</span>())</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">AND Query</h4><a id="user-content-and-query" aria-label="Permalink: AND Query" href="#and-query"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with BOTH &quot;machine&quot; AND &quot;learning&quot;
results := blaze.NewQueryBuilder(idx).
    Term(&quot;machine&quot;).
    And().
    Term(&quot;learning&quot;).
    Execute()"><pre><span>// Find documents with BOTH "machine" AND "learning"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"machine"</span>).
    <span>And</span>().
    <span>Term</span>(<span>"learning"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">OR Query</h4><a id="user-content-or-query" aria-label="Permalink: OR Query" href="#or-query"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &quot;python&quot; OR &quot;javascript&quot;
results := blaze.NewQueryBuilder(idx).
    Term(&quot;python&quot;).
    Or().
    Term(&quot;javascript&quot;).
    Execute()"><pre><span>// Find documents with "python" OR "javascript"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"python"</span>).
    <span>Or</span>().
    <span>Term</span>(<span>"javascript"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">NOT Query</h4><a id="user-content-not-query" aria-label="Permalink: NOT Query" href="#not-query"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &quot;python&quot; but NOT &quot;snake&quot;
results := blaze.NewQueryBuilder(idx).
    Term(&quot;python&quot;).
    And().Not().
    Term(&quot;snake&quot;).
    Execute()"><pre><span>// Find documents with "python" but NOT "snake"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"python"</span>).
    <span>And</span>().<span>Not</span>().
    <span>Term</span>(<span>"snake"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Complex Grouped Query</h4><a id="user-content-complex-grouped-query" aria-label="Permalink: Complex Grouped Query" href="#complex-grouped-query"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// (machine OR deep) AND learning
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&quot;machine&quot;).Or().Term(&quot;deep&quot;)
    }).
    And().
    Term(&quot;learning&quot;).
    Execute()"><pre><span>// (machine OR deep) AND learning</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>"machine"</span>).<span>Or</span>().<span>Term</span>(<span>"deep"</span>)
    }).
    <span>And</span>().
    <span>Term</span>(<span>"learning"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Phrase Query</h4><a id="user-content-phrase-query" aria-label="Permalink: Phrase Query" href="#phrase-query"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find exact phrase &quot;machine learning&quot;
results := blaze.NewQueryBuilder(idx).
    Phrase(&quot;machine learning&quot;).
    Execute()"><pre><span>// Find exact phrase "machine learning"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Phrase</span>(<span>"machine learning"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">BM25 Ranked Results</h4><a id="user-content-bm25-ranked-results" aria-label="Permalink: BM25 Ranked Results" href="#bm25-ranked-results"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Get top 10 results ranked by relevance
matches := blaze.NewQueryBuilder(idx).
    Term(&quot;machine&quot;).
    And().
    Term(&quot;learning&quot;).
    ExecuteWithBM25(10)

for _, match := range matches {
    fmt.Printf(&quot;Doc %d: score=%.2f\n&quot;, match.DocID, match.Score)
}"><pre><span>// Get top 10 results ranked by relevance</span>
<span>matches</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"machine"</span>).
    <span>And</span>().
    <span>Term</span>(<span>"learning"</span>).
    <span>ExecuteWithBM25</span>(<span>10</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"Doc %d: score=%.2f<span>\n</span>"</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Core Methods</h3><a id="user-content-query-builder-core-methods" aria-label="Permalink: Query Builder Core Methods" href="#query-builder-core-methods"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>NewQueryBuilder(index *InvertedIndex) *QueryBuilder</code></h4><a id="user-content-newquerybuilderindex-invertedindex-querybuilder" aria-label="Permalink: NewQueryBuilder(index *InvertedIndex) *QueryBuilder" href="#newquerybuilderindex-invertedindex-querybuilder"></a></p>
<p dir="auto">Creates a new query builder instance.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb := blaze.NewQueryBuilder(idx)"><pre><span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>Term(term string) *QueryBuilder</code></h4><a id="user-content-termterm-string-querybuilder" aria-label="Permalink: Term(term string) *QueryBuilder" href="#termterm-string-querybuilder"></a></p>
<p dir="auto">Adds a single term to the query. Uses roaring bitmaps for O(1) document lookup.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto"><code>Phrase(phrase string) *QueryBuilder</code></h4><a id="user-content-phrasephrase-string-querybuilder" aria-label="Permalink: Phrase(phrase string) *QueryBuilder" href="#phrasephrase-string-querybuilder"></a></p>
<p dir="auto">Adds an exact phrase match. Combines bitmap efficiency with skip list position checking.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Phrase(&quot;machine learning&quot;)"><pre><span>qb</span>.<span>Phrase</span>(<span>"machine learning"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>And() *QueryBuilder</code></h4><a id="user-content-and-querybuilder" aria-label="Permalink: And() *QueryBuilder" href="#and-querybuilder"></a></p>
<p dir="auto">Combines results with intersection (both must match). Uses bitmap AND operation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Term(&quot;machine&quot;).And().Term(&quot;learning&quot;)"><pre><span>qb</span>.<span>Term</span>(<span>"machine"</span>).<span>And</span>().<span>Term</span>(<span>"learning"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>Or() *QueryBuilder</code></h4><a id="user-content-or-querybuilder" aria-label="Permalink: Or() *QueryBuilder" href="#or-querybuilder"></a></p>
<p dir="auto">Combines results with union (either can match). Uses bitmap OR operation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Term(&quot;cat&quot;).Or().Term(&quot;dog&quot;)"><pre><span>qb</span>.<span>Term</span>(<span>"cat"</span>).<span>Or</span>().<span>Term</span>(<span>"dog"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>Not() *QueryBuilder</code></h4><a id="user-content-not-querybuilder" aria-label="Permalink: Not() *QueryBuilder" href="#not-querybuilder"></a></p>
<p dir="auto">Negates the next term (exclude from results). Uses bitmap difference operation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Term(&quot;python&quot;).And().Not().Term(&quot;snake&quot;)"><pre><span>qb</span>.<span>Term</span>(<span>"python"</span>).<span>And</span>().<span>Not</span>().<span>Term</span>(<span>"snake"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>Group(fn func(*QueryBuilder)) *QueryBuilder</code></h4><a id="user-content-groupfn-funcquerybuilder-querybuilder" aria-label="Permalink: Group(fn func(*QueryBuilder)) *QueryBuilder" href="#groupfn-funcquerybuilder-querybuilder"></a></p>
<p dir="auto">Creates a sub-query with its own scope for precedence control.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Group(func(q *blaze.QueryBuilder) {
    q.Term(&quot;machine&quot;).Or().Term(&quot;deep&quot;)
}).And().Term(&quot;learning&quot;)"><pre><span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
    <span>q</span>.<span>Term</span>(<span>"machine"</span>).<span>Or</span>().<span>Term</span>(<span>"deep"</span>)
}).<span>And</span>().<span>Term</span>(<span>"learning"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>Execute() *roaring.Bitmap</code></h4><a id="user-content-execute-roaringbitmap" aria-label="Permalink: Execute() *roaring.Bitmap" href="#execute-roaringbitmap"></a></p>
<p dir="auto">Executes the query and returns a bitmap of matching document IDs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="results := qb.Execute()
docCount := results.GetCardinality()"><pre><span>results</span> <span>:=</span> <span>qb</span>.<span>Execute</span>()
<span>docCount</span> <span>:=</span> <span>results</span>.<span>GetCardinality</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>ExecuteWithBM25(maxResults int) []Match</code></h4><a id="user-content-executewithbm25maxresults-int-match" aria-label="Permalink: ExecuteWithBM25(maxResults int) []Match" href="#executewithbm25maxresults-int-match"></a></p>
<p dir="auto">Executes the query with BM25 ranking and returns top results.</p>
<div dir="auto" data-snippet-clipboard-copy-content="matches := qb.ExecuteWithBM25(10)  // Top 10 results"><pre><span>matches</span> <span>:=</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>10</span>)  <span>// Top 10 results</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Boolean Operations</h3><a id="user-content-boolean-operations" aria-label="Permalink: Boolean Operations" href="#boolean-operations"></a></p>
<p dir="auto">The Query Builder provides convenient shorthand functions for common boolean operations:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>AllOf(index *InvertedIndex, terms ...string) *roaring.Bitmap</code></h4><a id="user-content-allofindex-invertedindex-terms-string-roaringbitmap" aria-label="Permalink: AllOf(index *InvertedIndex, terms ...string) *roaring.Bitmap" href="#allofindex-invertedindex-terms-string-roaringbitmap"></a></p>
<p dir="auto">Shorthand for documents containing ALL terms (AND operation).</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &quot;machine&quot; AND &quot;learning&quot; AND &quot;python&quot;
results := blaze.AllOf(idx, &quot;machine&quot;, &quot;learning&quot;, &quot;python&quot;)

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term(&quot;machine&quot;).And().Term(&quot;learning&quot;).And().Term(&quot;python&quot;).
    Execute()"><pre><span>// Find documents with "machine" AND "learning" AND "python"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>AllOf</span>(<span>idx</span>, <span>"machine"</span>, <span>"learning"</span>, <span>"python"</span>)

<span>// Equivalent to:</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"machine"</span>).<span>And</span>().<span>Term</span>(<span>"learning"</span>).<span>And</span>().<span>Term</span>(<span>"python"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>AnyOf(index *InvertedIndex, terms ...string) *roaring.Bitmap</code></h4><a id="user-content-anyofindex-invertedindex-terms-string-roaringbitmap" aria-label="Permalink: AnyOf(index *InvertedIndex, terms ...string) *roaring.Bitmap" href="#anyofindex-invertedindex-terms-string-roaringbitmap"></a></p>
<p dir="auto">Shorthand for documents containing ANY term (OR operation).</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &quot;cat&quot; OR &quot;dog&quot; OR &quot;bird&quot;
results := blaze.AnyOf(idx, &quot;cat&quot;, &quot;dog&quot;, &quot;bird&quot;)

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term(&quot;cat&quot;).Or().Term(&quot;dog&quot;).Or().Term(&quot;bird&quot;).
    Execute()"><pre><span>// Find documents with "cat" OR "dog" OR "bird"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>AnyOf</span>(<span>idx</span>, <span>"cat"</span>, <span>"dog"</span>, <span>"bird"</span>)

<span>// Equivalent to:</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"cat"</span>).<span>Or</span>().<span>Term</span>(<span>"dog"</span>).<span>Or</span>().<span>Term</span>(<span>"bird"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>TermExcluding(index *InvertedIndex, include string, exclude string) *roaring.Bitmap</code></h4><a id="user-content-termexcludingindex-invertedindex-include-string-exclude-string-roaringbitmap" aria-label="Permalink: TermExcluding(index *InvertedIndex, include string, exclude string) *roaring.Bitmap" href="#termexcludingindex-invertedindex-include-string-exclude-string-roaringbitmap"></a></p>
<p dir="auto">Shorthand for term with exclusion (AND NOT operation).</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &quot;python&quot; but NOT &quot;snake&quot;
results := blaze.TermExcluding(idx, &quot;python&quot;, &quot;snake&quot;)

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term(&quot;python&quot;).And().Not().Term(&quot;snake&quot;).
    Execute()"><pre><span>// Find documents with "python" but NOT "snake"</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>TermExcluding</span>(<span>idx</span>, <span>"python"</span>, <span>"snake"</span>)

<span>// Equivalent to:</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"python"</span>).<span>And</span>().<span>Not</span>().<span>Term</span>(<span>"snake"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Patterns</h3><a id="user-content-query-patterns" aria-label="Permalink: Query Patterns" href="#query-patterns"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pattern 1: Broad to Narrow</h4><a id="user-content-pattern-1-broad-to-narrow" aria-label="Permalink: Pattern 1: Broad to Narrow" href="#pattern-1-broad-to-narrow"></a></p>
<p dir="auto">Start with a broad category, then filter down with specific criteria.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find programming content about Python or JavaScript, excluding beginner material
results := blaze.NewQueryBuilder(idx).
    Term(&quot;programming&quot;).
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&quot;python&quot;).Or().Term(&quot;javascript&quot;)
    }).
    And().Not().
    Term(&quot;beginner&quot;).
    ExecuteWithBM25(10)"><pre><span>// Find programming content about Python or JavaScript, excluding beginner material</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"programming"</span>).
    <span>And</span>().
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>"python"</span>).<span>Or</span>().<span>Term</span>(<span>"javascript"</span>)
    }).
    <span>And</span>().<span>Not</span>().
    <span>Term</span>(<span>"beginner"</span>).
    <span>ExecuteWithBM25</span>(<span>10</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pattern 2: Multi-Criteria Matching</h4><a id="user-content-pattern-2-multi-criteria-matching" aria-label="Permalink: Pattern 2: Multi-Criteria Matching" href="#pattern-2-multi-criteria-matching"></a></p>
<p dir="auto">Match documents that satisfy multiple independent criteria.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents about (machine learning OR deep learning) AND (python OR tensorflow)
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Phrase(&quot;machine learning&quot;).Or().Phrase(&quot;deep learning&quot;)
    }).
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&quot;python&quot;).Or().Term(&quot;tensorflow&quot;)
    }).
    ExecuteWithBM25(20)"><pre><span>// Find documents about (machine learning OR deep learning) AND (python OR tensorflow)</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Phrase</span>(<span>"machine learning"</span>).<span>Or</span>().<span>Phrase</span>(<span>"deep learning"</span>)
    }).
    <span>And</span>().
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>"python"</span>).<span>Or</span>().<span>Term</span>(<span>"tensorflow"</span>)
    }).
    <span>ExecuteWithBM25</span>(<span>20</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pattern 3: Exclusion Filtering</h4><a id="user-content-pattern-3-exclusion-filtering" aria-label="Permalink: Pattern 3: Exclusion Filtering" href="#pattern-3-exclusion-filtering"></a></p>
<p dir="auto">Find relevant content while filtering out noise or unwanted categories.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find &quot;apple&quot; content but exclude fruit/food related content
results := blaze.NewQueryBuilder(idx).
    Term(&quot;apple&quot;).
    And().Not().
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&quot;fruit&quot;).Or().Term(&quot;food&quot;).Or().Term(&quot;cooking&quot;)
    }).
    Execute()  // Finds &quot;Apple Inc.&quot; not the fruit"><pre><span>// Find "apple" content but exclude fruit/food related content</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"apple"</span>).
    <span>And</span>().<span>Not</span>().
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>"fruit"</span>).<span>Or</span>().<span>Term</span>(<span>"food"</span>).<span>Or</span>().<span>Term</span>(<span>"cooking"</span>)
    }).
    <span>Execute</span>()  <span>// Finds "Apple Inc." not the fruit</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pattern 4: Category-Based Search</h4><a id="user-content-pattern-4-category-based-search" aria-label="Permalink: Pattern 4: Category-Based Search" href="#pattern-4-category-based-search"></a></p>
<p dir="auto">Search within specific categories or tags.</p>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchWithCategory(idx *blaze.InvertedIndex, query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Add main query
    qb.Term(query)

    // Add category filter if provided
    if len(categories) > 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i < len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }

    return qb.ExecuteWithBM25(20)
}"><pre><span>func</span> <span>SearchWithCategory</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>, <span>categories</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Add main query</span>
    <span>qb</span>.<span>Term</span>(<span>query</span>)

    <span>// Add category filter if provided</span>
    <span>if</span> <span>len</span>(<span>categories</span>) <span>&gt;</span> <span>0</span> {
        <span>qb</span>.<span>And</span>().<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
            <span>q</span>.<span>Term</span>(<span>categories</span>[<span>0</span>])
            <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>categories</span>); <span>i</span><span>++</span> {
                <span>q</span>.<span>Or</span>().<span>Term</span>(<span>categories</span>[<span>i</span>])
            }
        })
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>20</span>)
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Performance</h3><a id="user-content-query-builder-performance" aria-label="Permalink: Query Builder Performance" href="#query-builder-performance"></a></p>
<p dir="auto">The Query Builder leverages roaring bitmaps for exceptional performance on boolean operations.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Benchmarks (Apple M2)</h4><a id="user-content-benchmarks-apple-m2" aria-label="Permalink: Benchmarks (Apple M2)" href="#benchmarks-apple-m2"></a></p>
<div data-snippet-clipboard-copy-content="BenchmarkQueryBuilder_Simple-8       440,616 ops/sec    2,511 ns/op    896 B/op    39 allocs/op
BenchmarkQueryBuilder_Complex-8      222,024 ops/sec    5,333 ns/op  2,240 B/op    98 allocs/op
BenchmarkQueryBuilder_WithBM25-8     411,124 ops/sec    2,955 ns/op  1,416 B/op    46 allocs/op"><pre><code>BenchmarkQueryBuilder_Simple-8       440,616 ops/sec    2,511 ns/op    896 B/op    39 allocs/op
BenchmarkQueryBuilder_Complex-8      222,024 ops/sec    5,333 ns/op  2,240 B/op    98 allocs/op
BenchmarkQueryBuilder_WithBM25-8     411,124 ops/sec    2,955 ns/op  1,416 B/op    46 allocs/op
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Performance Benefits</h4><a id="user-content-performance-benefits" aria-label="Permalink: Performance Benefits" href="#performance-benefits"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th>Complexity</th>
<th>Why It's Fast</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AND</strong></td>
<td>O(1) per chunk</td>
<td>Roaring bitmap intersection</td>
</tr>
<tr>
<td><strong>OR</strong></td>
<td>O(1) per chunk</td>
<td>Roaring bitmap union</td>
</tr>
<tr>
<td><strong>NOT</strong></td>
<td>O(1) per chunk</td>
<td>Roaring bitmap difference</td>
</tr>
<tr>
<td><strong>Term Lookup</strong></td>
<td>O(1)</td>
<td>Direct hash map access</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Compression Benefits</h4><a id="user-content-compression-benefits" aria-label="Permalink: Compression Benefits" href="#compression-benefits"></a></p>
<p dir="auto">For a term appearing in 500,000 documents:</p>
<ul dir="auto">
<li>Skip list positions: ~24 MB (500k nodes × 48 bytes)</li>
<li>Roaring bitmap: ~60 KB (400x compression!)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Best Practices</h3><a id="user-content-query-builder-best-practices" aria-label="Permalink: Query Builder Best Practices" href="#query-builder-best-practices"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">1. Use Groups for Complex Logic</h4><a id="user-content-1-use-groups-for-complex-logic" aria-label="Permalink: 1. Use Groups for Complex Logic" href="#1-use-groups-for-complex-logic"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Clear precedence with groups
qb.Group(func(q *blaze.QueryBuilder) {
    q.Term(&quot;a&quot;).Or().Term(&quot;b&quot;)
}).And().Term(&quot;c&quot;)

// Bad: Ambiguous without groups
qb.Term(&quot;a&quot;).Or().Term(&quot;b&quot;).And().Term(&quot;c&quot;)  // Is this (a OR b) AND c or a OR (b AND c)?"><pre><span>// Good: Clear precedence with groups</span>
<span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
    <span>q</span>.<span>Term</span>(<span>"a"</span>).<span>Or</span>().<span>Term</span>(<span>"b"</span>)
}).<span>And</span>().<span>Term</span>(<span>"c"</span>)

<span>// Bad: Ambiguous without groups</span>
<span>qb</span>.<span>Term</span>(<span>"a"</span>).<span>Or</span>().<span>Term</span>(<span>"b"</span>).<span>And</span>().<span>Term</span>(<span>"c"</span>)  <span>// Is this (a OR b) AND c or a OR (b AND c)?</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">2. Leverage Convenience Functions for Simple Cases</h4><a id="user-content-2-leverage-convenience-functions-for-simple-cases" aria-label="Permalink: 2. Leverage Convenience Functions for Simple Cases" href="#2-leverage-convenience-functions-for-simple-cases"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Clean and readable
results := blaze.AllOf(idx, &quot;python&quot;, &quot;django&quot;, &quot;web&quot;)

// Bad: Verbose for simple case
results := blaze.NewQueryBuilder(idx).
    Term(&quot;python&quot;).And().Term(&quot;django&quot;).And().Term(&quot;web&quot;).
    Execute()"><pre><span>// Good: Clean and readable</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>AllOf</span>(<span>idx</span>, <span>"python"</span>, <span>"django"</span>, <span>"web"</span>)

<span>// Bad: Verbose for simple case</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>"python"</span>).<span>And</span>().<span>Term</span>(<span>"django"</span>).<span>And</span>().<span>Term</span>(<span>"web"</span>).
    <span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">3. Use BM25 for User-Facing Searches</h4><a id="user-content-3-use-bm25-for-user-facing-searches" aria-label="Permalink: 3. Use BM25 for User-Facing Searches" href="#3-use-bm25-for-user-facing-searches"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Ranked results for users
matches := qb.ExecuteWithBM25(10)

// Bad: Unranked - harder for users to find relevant docs
bitmap := qb.Execute()"><pre><span>// Good: Ranked results for users</span>
<span>matches</span> <span>:=</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>10</span>)

<span>// Bad: Unranked - harder for users to find relevant docs</span>
<span>bitmap</span> <span>:=</span> <span>qb</span>.<span>Execute</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">4. Combine Phrases and Terms Strategically</h4><a id="user-content-4-combine-phrases-and-terms-strategically" aria-label="Permalink: 4. Combine Phrases and Terms Strategically" href="#4-combine-phrases-and-terms-strategically"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Exact phrase + related term
qb.Phrase(&quot;machine learning&quot;).And().Term(&quot;python&quot;)

// Bad: Overly restrictive
qb.Phrase(&quot;machine learning python&quot;)  // Requires exact phrase"><pre><span>// Good: Exact phrase + related term</span>
<span>qb</span>.<span>Phrase</span>(<span>"machine learning"</span>).<span>And</span>().<span>Term</span>(<span>"python"</span>)

<span>// Bad: Overly restrictive</span>
<span>qb</span>.<span>Phrase</span>(<span>"machine learning python"</span>)  <span>// Requires exact phrase</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">5. Build Queries Programmatically</h4><a id="user-content-5-build-queries-programmatically" aria-label="Permalink: 5. Build Queries Programmatically" href="#5-build-queries-programmatically"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func BuildDynamicQuery(idx *blaze.InvertedIndex, required []string, optional []string, excluded []string) *roaring.Bitmap {
    qb := blaze.NewQueryBuilder(idx)

    // Add required terms (AND)
    if len(required) > 0 {
        qb.Term(required[0])
        for i := 1; i < len(required); i++ {
            qb.And().Term(required[i])
        }
    }

    // Add optional terms (OR)
    if len(optional) > 0 {
        if len(required) > 0 {
            qb.And()
        }
        qb.Group(func(q *blaze.QueryBuilder) {
            q.Term(optional[0])
            for i := 1; i < len(optional); i++ {
                q.Or().Term(optional[i])
            }
        })
    }

    // Exclude terms (NOT)
    for _, term := range excluded {
        qb.And().Not().Term(term)
    }

    return qb.Execute()
}"><pre><span>func</span> <span>BuildDynamicQuery</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>required</span> []<span>string</span>, <span>optional</span> []<span>string</span>, <span>excluded</span> []<span>string</span>) <span>*</span>roaring.<span>Bitmap</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Add required terms (AND)</span>
    <span>if</span> <span>len</span>(<span>required</span>) <span>&gt;</span> <span>0</span> {
        <span>qb</span>.<span>Term</span>(<span>required</span>[<span>0</span>])
        <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>required</span>); <span>i</span><span>++</span> {
            <span>qb</span>.<span>And</span>().<span>Term</span>(<span>required</span>[<span>i</span>])
        }
    }

    <span>// Add optional terms (OR)</span>
    <span>if</span> <span>len</span>(<span>optional</span>) <span>&gt;</span> <span>0</span> {
        <span>if</span> <span>len</span>(<span>required</span>) <span>&gt;</span> <span>0</span> {
            <span>qb</span>.<span>And</span>()
        }
        <span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
            <span>q</span>.<span>Term</span>(<span>optional</span>[<span>0</span>])
            <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>optional</span>); <span>i</span><span>++</span> {
                <span>q</span>.<span>Or</span>().<span>Term</span>(<span>optional</span>[<span>i</span>])
            }
        })
    }

    <span>// Exclude terms (NOT)</span>
    <span>for</span> <span>_</span>, <span>term</span> <span>:=</span> <span>range</span> <span>excluded</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>term</span>)
    }

    <span>return</span> <span>qb</span>.<span>Execute</span>()
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Real-World Query Builder Examples</h3><a id="user-content-real-world-query-builder-examples" aria-label="Permalink: Real-World Query Builder Examples" href="#real-world-query-builder-examples"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example 1: E-commerce Search with Filters</h4><a id="user-content-example-1-e-commerce-search-with-filters" aria-label="Permalink: Example 1: E-commerce Search with Filters" href="#example-1-e-commerce-search-with-filters"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchProducts(idx *blaze.InvertedIndex, searchTerm string, category string, excludeOutOfStock bool) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(searchTerm)

    // Add category filter
    if category != &quot;&quot; {
        qb.And().Term(category)
    }

    // Exclude out of stock items
    if excludeOutOfStock {
        qb.And().Not().Term(&quot;outofstock&quot;)
    }

    return qb.ExecuteWithBM25(20)
}"><pre><span>func</span> <span>SearchProducts</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>searchTerm</span> <span>string</span>, <span>category</span> <span>string</span>, <span>excludeOutOfStock</span> <span>bool</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).<span>Term</span>(<span>searchTerm</span>)

    <span>// Add category filter</span>
    <span>if</span> <span>category</span> <span>!=</span> <span>""</span> {
        <span>qb</span>.<span>And</span>().<span>Term</span>(<span>category</span>)
    }

    <span>// Exclude out of stock items</span>
    <span>if</span> <span>excludeOutOfStock</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>"outofstock"</span>)
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>20</span>)
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example 2: Multi-Category Search</h4><a id="user-content-example-2-multi-category-search" aria-label="Permalink: Example 2: Multi-Category Search" href="#example-2-multi-category-search"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchInCategories(idx *blaze.InvertedIndex, query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(query)

    if len(categories) > 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i < len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }

    return qb.ExecuteWithBM25(50)
}"><pre><span>func</span> <span>SearchInCategories</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>, <span>categories</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).<span>Term</span>(<span>query</span>)

    <span>if</span> <span>len</span>(<span>categories</span>) <span>&gt;</span> <span>0</span> {
        <span>qb</span>.<span>And</span>().<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
            <span>q</span>.<span>Term</span>(<span>categories</span>[<span>0</span>])
            <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>categories</span>); <span>i</span><span>++</span> {
                <span>q</span>.<span>Or</span>().<span>Term</span>(<span>categories</span>[<span>i</span>])
            }
        })
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>50</span>)
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example 3: Content Filtering with Blocklist</h4><a id="user-content-example-3-content-filtering-with-blocklist" aria-label="Permalink: Example 3: Content Filtering with Blocklist" href="#example-3-content-filtering-with-blocklist"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func FilterContent(idx *blaze.InvertedIndex, searchTerm string, blocklist []string) *roaring.Bitmap {
    qb := blaze.NewQueryBuilder(idx).Term(searchTerm)

    for _, blocked := range blocklist {
        qb.And().Not().Term(blocked)
    }

    return qb.Execute()
}"><pre><span>func</span> <span>FilterContent</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>searchTerm</span> <span>string</span>, <span>blocklist</span> []<span>string</span>) <span>*</span>roaring.<span>Bitmap</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).<span>Term</span>(<span>searchTerm</span>)

    <span>for</span> <span>_</span>, <span>blocked</span> <span>:=</span> <span>range</span> <span>blocklist</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>blocked</span>)
    }

    <span>return</span> <span>qb</span>.<span>Execute</span>()
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example 4: Advanced Search with Multiple Phrases</h4><a id="user-content-example-4-advanced-search-with-multiple-phrases" aria-label="Permalink: Example 4: Advanced Search with Multiple Phrases" href="#example-4-advanced-search-with-multiple-phrases"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func AdvancedSearch(idx *blaze.InvertedIndex, phrases []string, requiredTerms []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Match any of the phrases (OR)
    qb.Group(func(q *blaze.QueryBuilder) {
        q.Phrase(phrases[0])
        for i := 1; i < len(phrases); i++ {
            q.Or().Phrase(phrases[i])
        }
    })

    // AND with required terms
    for _, term := range requiredTerms {
        qb.And().Term(term)
    }

    return qb.ExecuteWithBM25(10)
}

// Usage:
results := AdvancedSearch(idx,
    []string{&quot;machine learning&quot;, &quot;deep learning&quot;},
    []string{&quot;python&quot;, &quot;tensorflow&quot;})"><pre><span>func</span> <span>AdvancedSearch</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>phrases</span> []<span>string</span>, <span>requiredTerms</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Match any of the phrases (OR)</span>
    <span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Phrase</span>(<span>phrases</span>[<span>0</span>])
        <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>phrases</span>); <span>i</span><span>++</span> {
            <span>q</span>.<span>Or</span>().<span>Phrase</span>(<span>phrases</span>[<span>i</span>])
        }
    })

    <span>// AND with required terms</span>
    <span>for</span> <span>_</span>, <span>term</span> <span>:=</span> <span>range</span> <span>requiredTerms</span> {
        <span>qb</span>.<span>And</span>().<span>Term</span>(<span>term</span>)
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>10</span>)
}

<span>// Usage:</span>
<span>results</span> <span>:=</span> <span>AdvancedSearch</span>(<span>idx</span>,
    []<span>string</span>{<span>"machine learning"</span>, <span>"deep learning"</span>},
    []<span>string</span>{<span>"python"</span>, <span>"tensorflow"</span>})</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example 5: HTTP API Integration</h4><a id="user-content-example-5-http-api-integration" aria-label="Permalink: Example 5: HTTP API Integration" href="#example-5-http-api-integration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchHandler(w http.ResponseWriter, r *http.Request) {
    query := r.URL.Query().Get(&quot;q&quot;)
    category := r.URL.Query().Get(&quot;category&quot;)
    exclude := r.URL.Query().Get(&quot;exclude&quot;)

    qb := blaze.NewQueryBuilder(index).Term(query)

    if category != &quot;&quot; {
        qb.And().Term(category)
    }

    if exclude != &quot;&quot; {
        qb.And().Not().Term(exclude)
    }

    results := qb.ExecuteWithBM25(20)
    json.NewEncoder(w).Encode(results)
}"><pre><span>func</span> <span>SearchHandler</span>(<span>w</span> http.<span>ResponseWriter</span>, <span>r</span> <span>*</span>http.<span>Request</span>) {
    <span>query</span> <span>:=</span> <span>r</span>.<span>URL</span>.<span>Query</span>().<span>Get</span>(<span>"q"</span>)
    <span>category</span> <span>:=</span> <span>r</span>.<span>URL</span>.<span>Query</span>().<span>Get</span>(<span>"category"</span>)
    <span>exclude</span> <span>:=</span> <span>r</span>.<span>URL</span>.<span>Query</span>().<span>Get</span>(<span>"exclude"</span>)

    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>index</span>).<span>Term</span>(<span>query</span>)

    <span>if</span> <span>category</span> <span>!=</span> <span>""</span> {
        <span>qb</span>.<span>And</span>().<span>Term</span>(<span>category</span>)
    }

    <span>if</span> <span>exclude</span> <span>!=</span> <span>""</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>exclude</span>)
    }

    <span>results</span> <span>:=</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>20</span>)
    <span>json</span>.<span>NewEncoder</span>(<span>w</span>).<span>Encode</span>(<span>results</span>)
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example 6: Semantic-Style Search</h4><a id="user-content-example-6-semantic-style-search" aria-label="Permalink: Example 6: Semantic-Style Search" href="#example-6-semantic-style-search"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func SemanticSearch(idx *blaze.InvertedIndex, concept string, relatedTerms []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Main concept OR any related terms
    qb.Term(concept)
    for _, related := range relatedTerms {
        qb.Or().Term(related)
    }

    return qb.ExecuteWithBM25(50)
}

// Usage:
results := SemanticSearch(idx, &quot;automobile&quot;,
    []string{&quot;car&quot;, &quot;vehicle&quot;, &quot;transportation&quot;, &quot;automotive&quot;})"><pre><span>func</span> <span>SemanticSearch</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>concept</span> <span>string</span>, <span>relatedTerms</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Main concept OR any related terms</span>
    <span>qb</span>.<span>Term</span>(<span>concept</span>)
    <span>for</span> <span>_</span>, <span>related</span> <span>:=</span> <span>range</span> <span>relatedTerms</span> {
        <span>qb</span>.<span>Or</span>().<span>Term</span>(<span>related</span>)
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>50</span>)
}

<span>// Usage:</span>
<span>results</span> <span>:=</span> <span>SemanticSearch</span>(<span>idx</span>, <span>"automobile"</span>,
    []<span>string</span>{<span>"car"</span>, <span>"vehicle"</span>, <span>"transportation"</span>, <span>"automotive"</span>})</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">API Reference</h2><a id="user-content-api-reference" aria-label="Permalink: API Reference" href="#api-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">InvertedIndex</h3><a id="user-content-invertedindex" aria-label="Permalink: InvertedIndex" href="#invertedindex"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">NewInvertedIndex</h4><a id="user-content-newinvertedindex" aria-label="Permalink: NewInvertedIndex" href="#newinvertedindex"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func NewInvertedIndex() *InvertedIndex"><pre><span>func</span> <span>NewInvertedIndex</span>() <span>*</span><span>InvertedIndex</span></pre></div>
<p dir="auto">Creates a new empty inverted index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="idx := blaze.NewInvertedIndex()"><pre><span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Index</h4><a id="user-content-index" aria-label="Permalink: Index" href="#index"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Index(docID int, document string)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Index</span>(<span>docID</span> <span>int</span>, <span>document</span> <span>string</span>)</pre></div>
<p dir="auto">Adds a document to the inverted index. Thread-safe.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>docID</code>: Unique document identifier</li>
<li><code>document</code>: Text content to index</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="idx.Index(1, &quot;The quick brown fox jumps over the lazy dog&quot;)
idx.Index(2, &quot;A fast brown dog&quot;)"><pre><span>idx</span>.<span>Index</span>(<span>1</span>, <span>"The quick brown fox jumps over the lazy dog"</span>)
<span>idx</span>.<span>Index</span>(<span>2</span>, <span>"A fast brown dog"</span>)</pre></div>
<p dir="auto"><strong>What Happens:</strong></p>
<ol dir="auto">
<li>Text is analyzed (tokenized, stemmed, etc.)</li>
<li>Each token is recorded with its position</li>
<li>Positions are stored in skip lists for fast lookup</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">First</h4><a id="user-content-first" aria-label="Permalink: First" href="#first"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) First(token string) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>First</span>(<span>token</span> <span>string</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Returns the first occurrence of a token in the index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pos, err := idx.First(&quot;quick&quot;)
if err != nil {
    // Token not found
}
fmt.Printf(&quot;Doc %d, Pos %d\n&quot;, int(pos.DocumentID), int(pos.Offset))"><pre><span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>First</span>(<span>"quick"</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>// Token not found</span>
}
<span>fmt</span>.<span>Printf</span>(<span>"Doc %d, Pos %d<span>\n</span>"</span>, <span>int</span>(<span>pos</span>.<span>DocumentID</span>), <span>int</span>(<span>pos</span>.<span>Offset</span>))</pre></div>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>Position</code>: Location of first occurrence</li>
<li><code>error</code>: <code>ErrNoPostingList</code> if token doesn't exist</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Last</h4><a id="user-content-last" aria-label="Permalink: Last" href="#last"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Last(token string) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Last</span>(<span>token</span> <span>string</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Returns the last occurrence of a token in the index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pos, err := idx.Last(&quot;quick&quot;)"><pre><span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Last</span>(<span>"quick"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Next</h4><a id="user-content-next" aria-label="Permalink: Next" href="#next"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Next(token string, currentPos Position) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Next</span>(<span>token</span> <span>string</span>, <span>currentPos</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the next occurrence of a token after the given position.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Iterate through all occurrences
pos := blaze.BOFDocument
for {
    pos, err = idx.Next(&quot;quick&quot;, pos)
    if pos.IsEnd() || err != nil {
        break
    }
    fmt.Printf(&quot;Found at Doc %d, Pos %d\n&quot;,
        int(pos.DocumentID), int(pos.Offset))
}"><pre><span>// Iterate through all occurrences</span>
<span>pos</span> <span>:=</span> <span>blaze</span>.<span>BOFDocument</span>
<span>for</span> {
    <span>pos</span>, <span>err</span> <span>=</span> <span>idx</span>.<span>Next</span>(<span>"quick"</span>, <span>pos</span>)
    <span>if</span> <span>pos</span>.<span>IsEnd</span>() <span>||</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>break</span>
    }
    <span>fmt</span>.<span>Printf</span>(<span>"Found at Doc %d, Pos %d<span>\n</span>"</span>,
        <span>int</span>(<span>pos</span>.<span>DocumentID</span>), <span>int</span>(<span>pos</span>.<span>Offset</span>))
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Previous</h4><a id="user-content-previous" aria-label="Permalink: Previous" href="#previous"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Previous(token string, currentPos Position) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Previous</span>(<span>token</span> <span>string</span>, <span>currentPos</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the previous occurrence of a token before the given position.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">NextPhrase</h4><a id="user-content-nextphrase" aria-label="Permalink: NextPhrase" href="#nextphrase"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) NextPhrase(query string, startPos Position) []Position"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>NextPhrase</span>(<span>query</span> <span>string</span>, <span>startPos</span> <span>Position</span>) []<span>Position</span></pre></div>
<p dir="auto">Finds the next occurrence of a phrase (exact word sequence).</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>query</code>: Space-separated phrase (e.g., "quick brown fox")</li>
<li><code>startPos</code>: Position to start searching from</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Position</code>: Array with two elements [phraseStart, phraseEnd]</li>
<li>Returns <code>[EOFDocument, EOFDocument]</code> if no match found</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="matches := idx.NextPhrase(&quot;quick brown fox&quot;, blaze.BOFDocument)
if !matches[0].IsEnd() {
    fmt.Printf(&quot;Phrase found in Doc %d from Pos %d to %d\n&quot;,
        int(matches[0].DocumentID),
        int(matches[0].Offset),
        int(matches[1].Offset))
}"><pre><span>matches</span> <span>:=</span> <span>idx</span>.<span>NextPhrase</span>(<span>"quick brown fox"</span>, <span>blaze</span>.<span>BOFDocument</span>)
<span>if</span> <span>!</span><span>matches</span>[<span>0</span>].<span>IsEnd</span>() {
    <span>fmt</span>.<span>Printf</span>(<span>"Phrase found in Doc %d from Pos %d to %d<span>\n</span>"</span>,
        <span>int</span>(<span>matches</span>[<span>0</span>].<span>DocumentID</span>),
        <span>int</span>(<span>matches</span>[<span>0</span>].<span>Offset</span>),
        <span>int</span>(<span>matches</span>[<span>1</span>].<span>Offset</span>))
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">FindAllPhrases</h4><a id="user-content-findallphrases" aria-label="Permalink: FindAllPhrases" href="#findallphrases"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) FindAllPhrases(query string, startPos Position) [][]Position"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>FindAllPhrases</span>(<span>query</span> <span>string</span>, <span>startPos</span> <span>Position</span>) [][]<span>Position</span></pre></div>
<p dir="auto">Finds all occurrences of a phrase in the entire index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="allMatches := idx.FindAllPhrases(&quot;brown fox&quot;, blaze.BOFDocument)
for _, match := range allMatches {
    fmt.Printf(&quot;Doc %d: Pos %d-%d\n&quot;,
        int(match[0].DocumentID),
        int(match[0].Offset),
        int(match[1].Offset))
}"><pre><span>allMatches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>"brown fox"</span>, <span>blaze</span>.<span>BOFDocument</span>)
<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>allMatches</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"Doc %d: Pos %d-%d<span>\n</span>"</span>,
        <span>int</span>(<span>match</span>[<span>0</span>].<span>DocumentID</span>),
        <span>int</span>(<span>match</span>[<span>0</span>].<span>Offset</span>),
        <span>int</span>(<span>match</span>[<span>1</span>].<span>Offset</span>))
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">NextCover</h4><a id="user-content-nextcover" aria-label="Permalink: NextCover" href="#nextcover"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) NextCover(tokens []string, startPos Position) []Position"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>NextCover</span>(<span>tokens</span> []<span>string</span>, <span>startPos</span> <span>Position</span>) []<span>Position</span></pre></div>
<p dir="auto">Finds the next "cover" - a range containing all given tokens.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>tokens</code>: Array of search terms</li>
<li><code>startPos</code>: Position to start searching from</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Position</code>: Array with [coverStart, coverEnd]</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="cover := idx.NextCover([]string{&quot;quick&quot;, &quot;fox&quot;, &quot;brown&quot;}, blaze.BOFDocument)
fmt.Printf(&quot;Cover: Doc %d, Pos %d-%d\n&quot;,
    int(cover[0].DocumentID),
    int(cover[0].Offset),
    int(cover[1].Offset))"><pre><span>cover</span> <span>:=</span> <span>idx</span>.<span>NextCover</span>([]<span>string</span>{<span>"quick"</span>, <span>"fox"</span>, <span>"brown"</span>}, <span>blaze</span>.<span>BOFDocument</span>)
<span>fmt</span>.<span>Printf</span>(<span>"Cover: Doc %d, Pos %d-%d<span>\n</span>"</span>,
    <span>int</span>(<span>cover</span>[<span>0</span>].<span>DocumentID</span>),
    <span>int</span>(<span>cover</span>[<span>0</span>].<span>Offset</span>),
    <span>int</span>(<span>cover</span>[<span>1</span>].<span>Offset</span>))</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">RankBM25</h4><a id="user-content-rankbm25" aria-label="Permalink: RankBM25" href="#rankbm25"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) RankBM25(query string, maxResults int) []Match"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>RankBM25</span>(<span>query</span> <span>string</span>, <span>maxResults</span> <span>int</span>) []<span>Match</span></pre></div>
<p dir="auto">Performs BM25 ranking of search results. This is the recommended search function for most use cases.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>query</code>: Search query (e.g., "machine learning")</li>
<li><code>maxResults</code>: Maximum number of results to return</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Match</code>: Sorted array of matches with BM25 scores</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="results := idx.RankBM25(&quot;machine learning&quot;, 10)
for i, match := range results {
    fmt.Printf(&quot;%d. Doc %d (score: %.2f)\n&quot;,
        i+1,
        match.DocID,
        match.Score)
}"><pre><span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"machine learning"</span>, <span>10</span>)
<span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"%d. Doc %d (score: %.2f)<span>\n</span>"</span>,
        <span>i</span><span>+</span><span>1</span>,
        <span>match</span>.<span>DocID</span>,
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>Match Structure:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="type Match struct {
    DocID   int        // Document identifier
    Offsets []Position // Where terms appear in the document
    Score   float64    // BM25 relevance score
}"><pre><span>type</span> <span>Match</span> <span>struct</span> {
    <span>DocID</span>   <span>int</span>        <span>// Document identifier</span>
    <span>Offsets</span> []<span>Position</span> <span>// Where terms appear in the document</span>
    <span>Score</span>   <span>float64</span>    <span>// BM25 relevance score</span>
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">RankProximity</h4><a id="user-content-rankproximity" aria-label="Permalink: RankProximity" href="#rankproximity"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) RankProximity(query string, maxResults int) []Match"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>RankProximity</span>(<span>query</span> <span>string</span>, <span>maxResults</span> <span>int</span>) []<span>Match</span></pre></div>
<p dir="auto">Performs proximity-based ranking of search results. Alternative to BM25, ranks by term proximity.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>query</code>: Search query (e.g., "machine learning")</li>
<li><code>maxResults</code>: Maximum number of results to return</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Match</code>: Sorted array of matches with proximity scores</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="results := idx.RankProximity(&quot;quick brown&quot;, 5)
for i, match := range results {
    fmt.Printf(&quot;%d. Doc %d (score: %.2f)\n&quot;,
        i+1,
        int(match.Offsets[0].DocumentID),
        match.Score)
}"><pre><span>results</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"quick brown"</span>, <span>5</span>)
<span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"%d. Doc %d (score: %.2f)<span>\n</span>"</span>,
        <span>i</span><span>+</span><span>1</span>,
        <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>),
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>BM25 vs Proximity Ranking:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>BM25</th>
<th>Proximity</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Term Rarity</strong></td>
<td>Yes (IDF)</td>
<td>No (all terms equal)</td>
</tr>
<tr>
<td><strong>Length Normalization</strong></td>
<td>Yes (built-in)</td>
<td>No</td>
</tr>
<tr>
<td><strong>Term Frequency</strong></td>
<td>Yes (with saturation)</td>
<td>No</td>
</tr>
<tr>
<td><strong>Term Distance</strong></td>
<td>No</td>
<td>Yes (main factor)</td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>General search</td>
<td>Finding close co-occurrences</td>
</tr>
<tr>
<td><strong>Industry Standard</strong></td>
<td>Yes (Elasticsearch, Solr)</td>
<td>No (custom algorithm)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Encode</h4><a id="user-content-encode" aria-label="Permalink: Encode" href="#encode"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Encode() ([]byte, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Encode</span>() ([]<span>byte</span>, <span>error</span>)</pre></div>
<p dir="auto">Serializes the inverted index to binary format.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="data, err := idx.Encode()
if err != nil {
    log.Fatal(err)
}

// Save to file
err = os.WriteFile(&quot;index.bin&quot;, data, 0644)"><pre><span>data</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Encode</span>()
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>log</span>.<span>Fatal</span>(<span>err</span>)
}

<span>// Save to file</span>
<span>err</span> <span>=</span> <span>os</span>.<span>WriteFile</span>(<span>"index.bin"</span>, <span>data</span>, <span>0644</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Decode</h4><a id="user-content-decode" aria-label="Permalink: Decode" href="#decode"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Decode(data []byte) error"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Decode</span>(<span>data</span> []<span>byte</span>) <span>error</span></pre></div>
<p dir="auto">Deserializes binary data back into an inverted index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="data, err := os.ReadFile(&quot;index.bin&quot;)
if err != nil {
    log.Fatal(err)
}

idx := blaze.NewInvertedIndex()
err = idx.Decode(data)"><pre><span>data</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>"index.bin"</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>log</span>.<span>Fatal</span>(<span>err</span>)
}

<span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
<span>err</span> <span>=</span> <span>idx</span>.<span>Decode</span>(<span>data</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Text Analysis</h3><a id="user-content-text-analysis" aria-label="Permalink: Text Analysis" href="#text-analysis"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Analyze</h4><a id="user-content-analyze" aria-label="Permalink: Analyze" href="#analyze"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func Analyze(text string) []string"><pre><span>func</span> <span>Analyze</span>(<span>text</span> <span>string</span>) []<span>string</span></pre></div>
<p dir="auto">Transforms raw text into searchable tokens using the default pipeline.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="tokens := blaze.Analyze(&quot;The Quick Brown Fox Jumps!&quot;)
// Returns: [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;, &quot;jump&quot;]"><pre><span>tokens</span> <span>:=</span> <span>blaze</span>.<span>Analyze</span>(<span>"The Quick Brown Fox Jumps!"</span>)
<span>// Returns: ["quick", "brown", "fox", "jump"]</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">AnalyzeWithConfig</h4><a id="user-content-analyzewithconfig" aria-label="Permalink: AnalyzeWithConfig" href="#analyzewithconfig"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func AnalyzeWithConfig(text string, config AnalyzerConfig) []string"><pre><span>func</span> <span>AnalyzeWithConfig</span>(<span>text</span> <span>string</span>, <span>config</span> <span>AnalyzerConfig</span>) []<span>string</span></pre></div>
<p dir="auto">Transforms text using a custom configuration.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="config := blaze.AnalyzerConfig{
    MinTokenLength:  3,
    EnableStemming:  false,
    EnableStopwords: true,
}
tokens := blaze.AnalyzeWithConfig(&quot;The quick brown fox&quot;, config)"><pre><span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>3</span>,
    <span>EnableStemming</span>:  <span>false</span>,
    <span>EnableStopwords</span>: <span>true</span>,
}
<span>tokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>"The quick brown fox"</span>, <span>config</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Position</h3><a id="user-content-position" aria-label="Permalink: Position" href="#position"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Position Methods</h4><a id="user-content-position-methods" aria-label="Permalink: Position Methods" href="#position-methods"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (p *Position) GetDocumentID() int
func (p *Position) GetOffset() int
func (p *Position) IsBeginning() bool
func (p *Position) IsEnd() bool
func (p *Position) IsBefore(other Position) bool
func (p *Position) IsAfter(other Position) bool
func (p *Position) Equals(other Position) bool"><pre><span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>GetDocumentID</span>() <span>int</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>GetOffset</span>() <span>int</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsBeginning</span>() <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsEnd</span>() <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsBefore</span>(<span>other</span> <span>Position</span>) <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsAfter</span>(<span>other</span> <span>Position</span>) <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>Equals</span>(<span>other</span> <span>Position</span>) <span>bool</span></pre></div>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pos1 := blaze.Position{DocumentID: 1, Offset: 5}
pos2 := blaze.Position{DocumentID: 1, Offset: 10}

if pos1.IsBefore(pos2) {
    fmt.Println(&quot;pos1 comes before pos2&quot;)
}"><pre><span>pos1</span> <span>:=</span> blaze.<span>Position</span>{<span>DocumentID</span>: <span>1</span>, <span>Offset</span>: <span>5</span>}
<span>pos2</span> <span>:=</span> blaze.<span>Position</span>{<span>DocumentID</span>: <span>1</span>, <span>Offset</span>: <span>10</span>}

<span>if</span> <span>pos1</span>.<span>IsBefore</span>(<span>pos2</span>) {
    <span>fmt</span>.<span>Println</span>(<span>"pos1 comes before pos2"</span>)
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Skip List</h3><a id="user-content-skip-list" aria-label="Permalink: Skip List" href="#skip-list"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">NewSkipList</h4><a id="user-content-newskiplist" aria-label="Permalink: NewSkipList" href="#newskiplist"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func NewSkipList() *SkipList"><pre><span>func</span> <span>NewSkipList</span>() <span>*</span><span>SkipList</span></pre></div>
<p dir="auto">Creates a new empty skip list.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Insert</h4><a id="user-content-insert" aria-label="Permalink: Insert" href="#insert"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) Insert(key Position)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>Insert</span>(<span>key</span> <span>Position</span>)</pre></div>
<p dir="auto">Adds or updates a position in the skip list. Average O(log n).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Find</h4><a id="user-content-find" aria-label="Permalink: Find" href="#find"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) Find(key Position) (Position, error)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>Find</span>(<span>key</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Searches for an exact position. Average O(log n).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Delete</h4><a id="user-content-delete" aria-label="Permalink: Delete" href="#delete"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) Delete(key Position) bool"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>Delete</span>(<span>key</span> <span>Position</span>) <span>bool</span></pre></div>
<p dir="auto">Removes a position from the skip list. Average O(log n).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">FindLessThan</h4><a id="user-content-findlessthan" aria-label="Permalink: FindLessThan" href="#findlessthan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) FindLessThan(key Position) (Position, error)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>FindLessThan</span>(<span>key</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the largest position less than the given position.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">FindGreaterThan</h4><a id="user-content-findgreaterthan" aria-label="Permalink: FindGreaterThan" href="#findgreaterthan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) FindGreaterThan(key Position) (Position, error)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>FindGreaterThan</span>(<span>key</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the smallest position greater than the given position.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 1: Basic Document Search with BM25</h3><a id="user-content-example-1-basic-document-search-with-bm25" aria-label="Permalink: Example 1: Basic Document Search with BM25" href="#example-1-basic-document-search-with-bm25"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    // Create index
    idx := blaze.NewInvertedIndex()

    // Index documents
    idx.Index(1, &quot;Go is a programming language designed at Google&quot;)
    idx.Index(2, &quot;Python is a high-level programming language&quot;)
    idx.Index(3, &quot;Go is fast and efficient for system programming&quot;)

    // Search for &quot;programming language&quot; using BM25
    results := idx.RankBM25(&quot;programming language&quot;, 10)

    fmt.Println(&quot;Search results for 'programming language':&quot;)
    for i, match := range results {
        fmt.Printf(&quot;%d. Document %d (score: %.3f)\n&quot;, i+1, match.DocID, match.Score)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"Go is a programming language designed at Google"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"Python is a high-level programming language"</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>"Go is fast and efficient for system programming"</span>)

    <span>// Search for "programming language" using BM25</span>
    <span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"programming language"</span>, <span>10</span>)

    <span>fmt</span>.<span>Println</span>(<span>"Search results for 'programming language':"</span>)
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
        <span>fmt</span>.<span>Printf</span>(<span>"%d. Document %d (score: %.3f)<span>\n</span>"</span>, <span>i</span><span>+</span><span>1</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Search results for 'programming language':
1. Document 1 (score: 4.521)
2. Document 2 (score: 4.521)
3. Document 3 (score: 2.156)"><pre><code>Search results for 'programming language':
1. Document 1 (score: 4.521)
2. Document 2 (score: 4.521)
3. Document 3 (score: 2.156)
</code></pre></div>
<p dir="auto"><strong>Note</strong>: BM25 scores are absolute values (not normalized to 0-1), reflecting relevance based on term frequency, document length, and term rarity.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 2: Phrase Search</h3><a id="user-content-example-2-phrase-search" aria-label="Permalink: Example 2: Phrase Search" href="#example-2-phrase-search"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    idx := blaze.NewInvertedIndex()

    idx.Index(1, &quot;the quick brown fox jumps over the lazy dog&quot;)
    idx.Index(2, &quot;a quick brown dog runs fast&quot;)
    idx.Index(3, &quot;the lazy brown fox sleeps&quot;)

    // Find exact phrase &quot;brown fox&quot;
    matches := idx.FindAllPhrases(&quot;brown fox&quot;, blaze.BOFDocument)

    fmt.Println(&quot;Documents containing 'brown fox' as a phrase:&quot;)
    for _, match := range matches {
        docID := int(match[0].DocumentID)
        start := int(match[0].Offset)
        end := int(match[1].Offset)
        fmt.Printf(&quot;Document %d: positions %d-%d\n&quot;, docID, start, end)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"the quick brown fox jumps over the lazy dog"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"a quick brown dog runs fast"</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>"the lazy brown fox sleeps"</span>)

    <span>// Find exact phrase "brown fox"</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>"brown fox"</span>, <span>blaze</span>.<span>BOFDocument</span>)

    <span>fmt</span>.<span>Println</span>(<span>"Documents containing 'brown fox' as a phrase:"</span>)
    <span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>docID</span> <span>:=</span> <span>int</span>(<span>match</span>[<span>0</span>].<span>DocumentID</span>)
        <span>start</span> <span>:=</span> <span>int</span>(<span>match</span>[<span>0</span>].<span>Offset</span>)
        <span>end</span> <span>:=</span> <span>int</span>(<span>match</span>[<span>1</span>].<span>Offset</span>)
        <span>fmt</span>.<span>Printf</span>(<span>"Document %d: positions %d-%d<span>\n</span>"</span>, <span>docID</span>, <span>start</span>, <span>end</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Documents containing 'brown fox' as a phrase:
Document 1: positions 1-2
Document 3: positions 2-3"><pre><code>Documents containing 'brown fox' as a phrase:
Document 1: positions 1-2
Document 3: positions 2-3
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 3: Iterating Through Positions</h3><a id="user-content-example-3-iterating-through-positions" aria-label="Permalink: Example 3: Iterating Through Positions" href="#example-3-iterating-through-positions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    idx := blaze.NewInvertedIndex()

    idx.Index(1, &quot;quick test quick test quick&quot;)
    idx.Index(2, &quot;another quick test here&quot;)

    // Find all occurrences of &quot;quick&quot;
    fmt.Println(&quot;All occurrences of 'quick':&quot;)

    pos := blaze.BOFDocument
    for {
        pos, err := idx.Next(&quot;quick&quot;, pos)
        if err != nil || pos.IsEnd() {
            break
        }
        fmt.Printf(&quot;  Doc %d, Pos %d\n&quot;,
            int(pos.DocumentID),
            int(pos.Offset))
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"quick test quick test quick"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"another quick test here"</span>)

    <span>// Find all occurrences of "quick"</span>
    <span>fmt</span>.<span>Println</span>(<span>"All occurrences of 'quick':"</span>)

    <span>pos</span> <span>:=</span> <span>blaze</span>.<span>BOFDocument</span>
    <span>for</span> {
        <span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Next</span>(<span>"quick"</span>, <span>pos</span>)
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>||</span> <span>pos</span>.<span>IsEnd</span>() {
            <span>break</span>
        }
        <span>fmt</span>.<span>Printf</span>(<span>"  Doc %d, Pos %d<span>\n</span>"</span>,
            <span>int</span>(<span>pos</span>.<span>DocumentID</span>),
            <span>int</span>(<span>pos</span>.<span>Offset</span>))
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="All occurrences of 'quick':
  Doc 1, Pos 0
  Doc 1, Pos 2
  Doc 1, Pos 4
  Doc 2, Pos 1"><pre><code>All occurrences of 'quick':
  Doc 1, Pos 0
  Doc 1, Pos 2
  Doc 1, Pos 4
  Doc 2, Pos 1
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 4: Persistence with Serialization</h3><a id="user-content-example-4-persistence-with-serialization" aria-label="Permalink: Example 4: Persistence with Serialization" href="#example-4-persistence-with-serialization"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;os&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    // Build and save index
    idx := blaze.NewInvertedIndex()
    idx.Index(1, &quot;machine learning algorithms&quot;)
    idx.Index(2, &quot;deep learning neural networks&quot;)
    idx.Index(3, &quot;natural language processing&quot;)

    // Serialize to binary
    data, err := idx.Encode()
    if err != nil {
        panic(err)
    }

    // Save to file
    err = os.WriteFile(&quot;search_index.bin&quot;, data, 0644)
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;Index saved to search_index.bin&quot;)

    // Load index from file
    loadedData, err := os.ReadFile(&quot;search_index.bin&quot;)
    if err != nil {
        panic(err)
    }

    loadedIdx := blaze.NewInvertedIndex()
    err = loadedIdx.Decode(loadedData)
    if err != nil {
        panic(err)
    }

    // Use loaded index
    results := loadedIdx.RankProximity(&quot;learning&quot;, 5)
    fmt.Printf(&quot;Found %d documents\n&quot;, len(results))
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"os"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>// Build and save index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"machine learning algorithms"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"deep learning neural networks"</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>"natural language processing"</span>)

    <span>// Serialize to binary</span>
    <span>data</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Encode</span>()
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }

    <span>// Save to file</span>
    <span>err</span> <span>=</span> <span>os</span>.<span>WriteFile</span>(<span>"search_index.bin"</span>, <span>data</span>, <span>0644</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }
    <span>fmt</span>.<span>Println</span>(<span>"Index saved to search_index.bin"</span>)

    <span>// Load index from file</span>
    <span>loadedData</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>"search_index.bin"</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }

    <span>loadedIdx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>err</span> <span>=</span> <span>loadedIdx</span>.<span>Decode</span>(<span>loadedData</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }

    <span>// Use loaded index</span>
    <span>results</span> <span>:=</span> <span>loadedIdx</span>.<span>RankProximity</span>(<span>"learning"</span>, <span>5</span>)
    <span>fmt</span>.<span>Printf</span>(<span>"Found %d documents<span>\n</span>"</span>, <span>len</span>(<span>results</span>))
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 5: Custom Analyzer Configuration</h3><a id="user-content-example-5-custom-analyzer-configuration" aria-label="Permalink: Example 5: Custom Analyzer Configuration" href="#example-5-custom-analyzer-configuration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    // Create custom analyzer config (no stemming, longer min length)
    config := blaze.AnalyzerConfig{
        MinTokenLength:  3,      // Minimum 3 characters
        EnableStemming:  false,  // Keep original word forms
        EnableStopwords: true,   // Still remove stopwords
    }

    text := &quot;The running dogs are running fast&quot;

    // Compare default vs custom analysis
    defaultTokens := blaze.Analyze(text)
    customTokens := blaze.AnalyzeWithConfig(text, config)

    fmt.Println(&quot;Default tokens:&quot;, defaultTokens)
    fmt.Println(&quot;Custom tokens:&quot;, customTokens)
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create custom analyzer config (no stemming, longer min length)</span>
    <span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
        <span>MinTokenLength</span>:  <span>3</span>,      <span>// Minimum 3 characters</span>
        <span>EnableStemming</span>:  <span>false</span>,  <span>// Keep original word forms</span>
        <span>EnableStopwords</span>: <span>true</span>,   <span>// Still remove stopwords</span>
    }

    <span>text</span> <span>:=</span> <span>"The running dogs are running fast"</span>

    <span>// Compare default vs custom analysis</span>
    <span>defaultTokens</span> <span>:=</span> <span>blaze</span>.<span>Analyze</span>(<span>text</span>)
    <span>customTokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>text</span>, <span>config</span>)

    <span>fmt</span>.<span>Println</span>(<span>"Default tokens:"</span>, <span>defaultTokens</span>)
    <span>fmt</span>.<span>Println</span>(<span>"Custom tokens:"</span>, <span>customTokens</span>)
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Default tokens: [run dog run fast]
Custom tokens: [running dogs running fast]"><pre><code>Default tokens: [run dog run fast]
Custom tokens: [running dogs running fast]
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 6: Comparing BM25 and Proximity Ranking</h3><a id="user-content-example-6-comparing-bm25-and-proximity-ranking" aria-label="Permalink: Example 6: Comparing BM25 and Proximity Ranking" href="#example-6-comparing-bm25-and-proximity-ranking"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;fmt&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    idx := blaze.NewInvertedIndex()

    // Index documents
    idx.Index(1, &quot;machine learning algorithms&quot;)
    idx.Index(2, &quot;machine learning machine learning&quot;)  // High term frequency
    idx.Index(3, &quot;machine and algorithms and learning&quot;) // Terms far apart

    query := &quot;machine learning&quot;

    // BM25 Ranking
    fmt.Println(&quot;BM25 Rankings:&quot;)
    bm25Results := idx.RankBM25(query, 10)
    for i, match := range bm25Results {
        fmt.Printf(&quot;%d. Doc %d (score: %.3f)\n&quot;, i+1, match.DocID, match.Score)
    }

    // Proximity Ranking
    fmt.Println(&quot;\nProximity Rankings:&quot;)
    proxResults := idx.RankProximity(query, 10)
    for i, match := range proxResults {
        docID := int(match.Offsets[0].DocumentID)
        fmt.Printf(&quot;%d. Doc %d (score: %.3f)\n&quot;, i+1, docID, match.Score)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>"fmt"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"machine learning algorithms"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"machine learning machine learning"</span>)  <span>// High term frequency</span>
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>"machine and algorithms and learning"</span>) <span>// Terms far apart</span>

    <span>query</span> <span>:=</span> <span>"machine learning"</span>

    <span>// BM25 Ranking</span>
    <span>fmt</span>.<span>Println</span>(<span>"BM25 Rankings:"</span>)
    <span>bm25Results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>10</span>)
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>bm25Results</span> {
        <span>fmt</span>.<span>Printf</span>(<span>"%d. Doc %d (score: %.3f)<span>\n</span>"</span>, <span>i</span><span>+</span><span>1</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
    }

    <span>// Proximity Ranking</span>
    <span>fmt</span>.<span>Println</span>(<span>"<span>\n</span>Proximity Rankings:"</span>)
    <span>proxResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>10</span>)
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>proxResults</span> {
        <span>docID</span> <span>:=</span> <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>)
        <span>fmt</span>.<span>Printf</span>(<span>"%d. Doc %d (score: %.3f)<span>\n</span>"</span>, <span>i</span><span>+</span><span>1</span>, <span>docID</span>, <span>match</span>.<span>Score</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="BM25 Rankings:
1. Doc 2 (score: 5.234)  ← High term frequency
2. Doc 1 (score: 3.156)
3. Doc 3 (score: 2.891)

Proximity Rankings:
1. Doc 1 (score: 1.000)  ← Terms adjacent
2. Doc 2 (score: 1.000)
3. Doc 3 (score: 0.200)  ← Terms far apart"><pre><code>BM25 Rankings:
1. Doc 2 (score: 5.234)  ← High term frequency
2. Doc 1 (score: 3.156)
3. Doc 3 (score: 2.891)

Proximity Rankings:
1. Doc 1 (score: 1.000)  ← Terms adjacent
2. Doc 2 (score: 1.000)
3. Doc 3 (score: 0.200)  ← Terms far apart
</code></pre></div>
<p dir="auto"><strong>Key Differences:</strong></p>
<ul dir="auto">
<li><strong>BM25</strong> favors Doc 2 (repeated terms = high relevance)</li>
<li><strong>Proximity</strong> favors Doc 1 and Doc 2 equally (both have adjacent terms)</li>
<li>Doc 3 ranks low in both (terms spread out)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 7: Building a Simple Search Engine</h3><a id="user-content-example-7-building-a-simple-search-engine" aria-label="Permalink: Example 7: Building a Simple Search Engine" href="#example-7-building-a-simple-search-engine"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &quot;bufio&quot;
    &quot;fmt&quot;
    &quot;os&quot;
    &quot;strings&quot;
    &quot;github.com/wizenheimer/blaze&quot;
)

func main() {
    // Create index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    docs := map[int]string{
        1: &quot;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software&quot;,
        2: &quot;Python is a programming language that lets you work quickly and integrate systems more effectively&quot;,
        3: &quot;JavaScript is a programming language that conforms to the ECMAScript specification&quot;,
        4: &quot;Rust is a multi-paradigm programming language focused on performance and safety&quot;,
        5: &quot;Java is a class-based, object-oriented programming language designed for portability&quot;,
    }

    for id, doc := range docs {
        idx.Index(id, doc)
    }

    // Interactive search
    scanner := bufio.NewScanner(os.Stdin)

    for {
        fmt.Print(&quot;\nSearch query (or 'quit' to exit): &quot;)
        if !scanner.Scan() {
            break
        }

        query := strings.TrimSpace(scanner.Text())
        if query == &quot;quit&quot; {
            break
        }

        if query == &quot;&quot; {
            continue
        }

        // Perform search using BM25
        results := idx.RankBM25(query, 5)

        if len(results) == 0 {
            fmt.Println(&quot;No results found&quot;)
            continue
        }

        // Display results
        fmt.Printf(&quot;\nFound %d result(s):\n&quot;, len(results))
        for i, match := range results {
            fmt.Printf(&quot;\n%d. Document %d (Score: %.3f)\n&quot;, i+1, match.DocID, match.Score)
            fmt.Printf(&quot;   %s\n&quot;, docs[match.DocID])
        }
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>"bufio"</span>
    <span>"fmt"</span>
    <span>"os"</span>
    <span>"strings"</span>
    <span>"github.com/wizenheimer/blaze"</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index some documents</span>
    <span>docs</span> <span>:=</span> <span>map</span>[<span>int</span>]<span>string</span>{
        <span>1</span>: <span>"Go is an open source programming language that makes it easy to build simple, reliable, and efficient software"</span>,
        <span>2</span>: <span>"Python is a programming language that lets you work quickly and integrate systems more effectively"</span>,
        <span>3</span>: <span>"JavaScript is a programming language that conforms to the ECMAScript specification"</span>,
        <span>4</span>: <span>"Rust is a multi-paradigm programming language focused on performance and safety"</span>,
        <span>5</span>: <span>"Java is a class-based, object-oriented programming language designed for portability"</span>,
    }

    <span>for</span> <span>id</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
        <span>idx</span>.<span>Index</span>(<span>id</span>, <span>doc</span>)
    }

    <span>// Interactive search</span>
    <span>scanner</span> <span>:=</span> <span>bufio</span>.<span>NewScanner</span>(<span>os</span>.<span>Stdin</span>)

    <span>for</span> {
        <span>fmt</span>.<span>Print</span>(<span>"<span>\n</span>Search query (or 'quit' to exit): "</span>)
        <span>if</span> <span>!</span><span>scanner</span>.<span>Scan</span>() {
            <span>break</span>
        }

        <span>query</span> <span>:=</span> <span>strings</span>.<span>TrimSpace</span>(<span>scanner</span>.<span>Text</span>())
        <span>if</span> <span>query</span> <span>==</span> <span>"quit"</span> {
            <span>break</span>
        }

        <span>if</span> <span>query</span> <span>==</span> <span>""</span> {
            <span>continue</span>
        }

        <span>// Perform search using BM25</span>
        <span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>5</span>)

        <span>if</span> <span>len</span>(<span>results</span>) <span>==</span> <span>0</span> {
            <span>fmt</span>.<span>Println</span>(<span>"No results found"</span>)
            <span>continue</span>
        }

        <span>// Display results</span>
        <span>fmt</span>.<span>Printf</span>(<span>"<span>\n</span>Found %d result(s):<span>\n</span>"</span>, <span>len</span>(<span>results</span>))
        <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
            <span>fmt</span>.<span>Printf</span>(<span>"<span>\n</span>%d. Document %d (Score: %.3f)<span>\n</span>"</span>, <span>i</span><span>+</span><span>1</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
            <span>fmt</span>.<span>Printf</span>(<span>"   %s<span>\n</span>"</span>, <span>docs</span>[<span>match</span>.<span>DocID</span>])
        }
    }
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance Characteristics</h2><a id="user-content-performance-characteristics" aria-label="Permalink: Performance Characteristics" href="#performance-characteristics"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Time Complexity</h3><a id="user-content-time-complexity" aria-label="Permalink: Time Complexity" href="#time-complexity"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th>Average</th>
<th>Worst Case</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Index (per document)</td>
<td>O(n × log m)</td>
<td>O(n × m)</td>
<td>n = tokens, m = total positions</td>
</tr>
<tr>
<td>Term lookup</td>
<td>O(log m)</td>
<td>O(m)</td>
<td>m = positions for term</td>
</tr>
<tr>
<td>Phrase search</td>
<td>O(k × log m)</td>
<td>O(k × m)</td>
<td>k = phrase length</td>
</tr>
<tr>
<td>BM25 ranking</td>
<td>O(t × d)</td>
<td>O(t × d)</td>
<td>t = query terms, d = candidates</td>
</tr>
<tr>
<td>Proximity ranking</td>
<td>O(t × m)</td>
<td>O(t × m)</td>
<td>t = query terms</td>
</tr>
<tr>
<td>Skip list insert</td>
<td>O(log n)</td>
<td>O(n)</td>
<td>n = elements in list</td>
</tr>
<tr>
<td>Skip list search</td>
<td>O(log n)</td>
<td>O(n)</td>
<td>Probabilistically rare</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Space Complexity</h3><a id="user-content-space-complexity" aria-label="Permalink: Space Complexity" href="#space-complexity"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Space</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inverted index</td>
<td>O(n)</td>
<td>n = total unique positions</td>
</tr>
<tr>
<td>Skip list nodes</td>
<td>O(n × log n)</td>
<td>Average 2 pointers per node</td>
</tr>
<tr>
<td>Analyzer</td>
<td>O(1)</td>
<td>In-place processing</td>
</tr>
<tr>
<td>Serialized index</td>
<td>O(n)</td>
<td>Compact binary format</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Benchmarks</h3><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">Performance on Apple M2 (8 cores), Go 1.24:</p>
<div data-snippet-clipboard-copy-content="BenchmarkIndex-8                     50000    35421 ns/op    18234 B/op    245 allocs/op
BenchmarkTermSearch-8              300000     4123 ns/op      128 B/op      3 allocs/op
BenchmarkPhraseSearch-8            100000    12456 ns/op      512 B/op     12 allocs/op
BenchmarkRankBM25-8                  60000    24567 ns/op     1856 B/op     38 allocs/op
BenchmarkProximityRanking-8         50000    28934 ns/op     2048 B/op     45 allocs/op
BenchmarkCalculateIDF-8           5000000      234 ns/op       16 B/op      1 allocs/op
BenchmarkCalculateBM25Score-8     2000000      567 ns/op       64 B/op      2 allocs/op
BenchmarkSkipListInsert-8         3000000      413 ns/op      255 B/op      6 allocs/op
BenchmarkSkipListSearch-8         5000000      203 ns/op       23 B/op      1 allocs/op
BenchmarkAnalyze-8                1000000     1234 ns/op      512 B/op      8 allocs/op
BenchmarkEncode-8                   10000   156789 ns/op    65536 B/op    234 allocs/op
BenchmarkDecode-8                   15000   123456 ns/op    49152 B/op    189 allocs/op"><pre><code>BenchmarkIndex-8                     50000    35421 ns/op    18234 B/op    245 allocs/op
BenchmarkTermSearch-8              300000     4123 ns/op      128 B/op      3 allocs/op
BenchmarkPhraseSearch-8            100000    12456 ns/op      512 B/op     12 allocs/op
BenchmarkRankBM25-8                  60000    24567 ns/op     1856 B/op     38 allocs/op
BenchmarkProximityRanking-8         50000    28934 ns/op     2048 B/op     45 allocs/op
BenchmarkCalculateIDF-8           5000000      234 ns/op       16 B/op      1 allocs/op
BenchmarkCalculateBM25Score-8     2000000      567 ns/op       64 B/op      2 allocs/op
BenchmarkSkipListInsert-8         3000000      413 ns/op      255 B/op      6 allocs/op
BenchmarkSkipListSearch-8         5000000      203 ns/op       23 B/op      1 allocs/op
BenchmarkAnalyze-8                1000000     1234 ns/op      512 B/op      8 allocs/op
BenchmarkEncode-8                   10000   156789 ns/op    65536 B/op    234 allocs/op
BenchmarkDecode-8                   15000   123456 ns/op    49152 B/op    189 allocs/op
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scalability</h3><a id="user-content-scalability" aria-label="Permalink: Scalability" href="#scalability"></a></p>
<p dir="auto"><strong>Index Size vs Performance:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Documents</th>
<th>Terms</th>
<th>Index Time</th>
<th>Search Time</th>
<th>Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>1K</td>
<td>10K</td>
<td>50ms</td>
<td>0.5ms</td>
<td>2 MB</td>
</tr>
<tr>
<td>10K</td>
<td>100K</td>
<td>500ms</td>
<td>1ms</td>
<td>20 MB</td>
</tr>
<tr>
<td>100K</td>
<td>1M</td>
<td>5s</td>
<td>2ms</td>
<td>200 MB</td>
</tr>
<tr>
<td>1M</td>
<td>10M</td>
<td>50s</td>
<td>5ms</td>
<td>2 GB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Notes:</strong></p>
<ul dir="auto">
<li>Search time remains relatively constant due to O(log n) operations</li>
<li>Memory scales linearly with unique positions</li>
<li>Serialization reduces storage by ~40% compared to in-memory size</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">BM25 Parameters</h3><a id="user-content-bm25-parameters" aria-label="Permalink: BM25 Parameters" href="#bm25-parameters"></a></p>
<p dir="auto">Customize BM25 ranking behavior:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type BM25Parameters struct {
    K1 float64 // Term frequency saturation (default: 1.5)
    B  float64 // Length normalization (default: 0.75)
}"><pre><span>type</span> <span>BM25Parameters</span> <span>struct</span> {
    <span>K1</span> <span>float64</span> <span>// Term frequency saturation (default: 1.5)</span>
    <span>B</span>  <span>float64</span> <span>// Length normalization (default: 0.75)</span>
}</pre></div>
<p dir="auto"><strong>Tuning BM25:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="idx := blaze.NewInvertedIndex()

// Adjust BM25 parameters before indexing
idx.BM25Params.K1 = 2.0  // Higher = less saturation (more weight to TF)
idx.BM25Params.B = 0.5   // Lower = less length penalty

// Now index and search
idx.Index(1, &quot;document content&quot;)
results := idx.RankBM25(&quot;query&quot;, 10)"><pre><span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

<span>// Adjust BM25 parameters before indexing</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>2.0</span>  <span>// Higher = less saturation (more weight to TF)</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.5</span>   <span>// Lower = less length penalty</span>

<span>// Now index and search</span>
<span>idx</span>.<span>Index</span>(<span>1</span>, <span>"document content"</span>)
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"query"</span>, <span>10</span>)</pre></div>
<p dir="auto"><strong>Parameter Effects:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Range</th>
<th>Effect</th>
<th>When to Adjust</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>K1</strong></td>
<td>1.2 - 2.0</td>
<td>Controls TF saturation</td>
<td>Higher for domains where term frequency matters more</td>
</tr>
<tr>
<td><strong>B</strong></td>
<td>0 - 1</td>
<td>Controls length penalty</td>
<td>Lower for domains with naturally longer docs</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Examples:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Academic papers (long documents, repeated terms important)
idx.BM25Params.K1 = 2.0
idx.BM25Params.B = 0.5

// Short messages (length less important)
idx.BM25Params.K1 = 1.2
idx.BM25Params.B = 0.3

// Default (works well for most cases)
idx.BM25Params.K1 = 1.5
idx.BM25Params.B = 0.75"><pre><span>// Academic papers (long documents, repeated terms important)</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>2.0</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.5</span>

<span>// Short messages (length less important)</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>1.2</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.3</span>

<span>// Default (works well for most cases)</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>1.5</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.75</span></pre></div>
<p dir="auto"><strong>BM25 Statistics:</strong></p>
<p dir="auto">During indexing, Blaze automatically tracks:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type DocumentStats struct {
    DocID     int            // Document identifier
    Length    int            // Number of terms
    TermFreqs map[string]int // Term frequencies
}

// Corpus-level statistics
idx.TotalDocs  // Total documents indexed
idx.TotalTerms // Total terms across all documents
idx.DocStats   // Per-document statistics"><pre><span>type</span> <span>DocumentStats</span> <span>struct</span> {
    <span>DocID</span>     <span>int</span>            <span>// Document identifier</span>
    <span>Length</span>    <span>int</span>            <span>// Number of terms</span>
    <span>TermFreqs</span> <span>map</span>[<span>string</span>]<span>int</span> <span>// Term frequencies</span>
}

<span>// Corpus-level statistics</span>
<span>idx</span>.<span>TotalDocs</span>  <span>// Total documents indexed</span>
<span>idx</span>.<span>TotalTerms</span> <span>// Total terms across all documents</span>
<span>idx</span>.<span>DocStats</span>   <span>// Per-document statistics</span></pre></div>
<p dir="auto">These statistics are:</p>
<ul dir="auto">
<li>Automatically computed during indexing</li>
<li>Serialized with the index</li>
<li>Used for BM25 score calculation</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Analyzer Configuration</h3><a id="user-content-analyzer-configuration" aria-label="Permalink: Analyzer Configuration" href="#analyzer-configuration"></a></p>
<p dir="auto">Customize the text analysis pipeline:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type AnalyzerConfig struct {
    MinTokenLength  int  // Minimum token length (default: 2)
    EnableStemming  bool // Apply stemming (default: true)
    EnableStopwords bool // Remove stopwords (default: true)
}"><pre><span>type</span> <span>AnalyzerConfig</span> <span>struct</span> {
    <span>MinTokenLength</span>  <span>int</span>  <span>// Minimum token length (default: 2)</span>
    <span>EnableStemming</span>  <span>bool</span> <span>// Apply stemming (default: true)</span>
    <span>EnableStopwords</span> <span>bool</span> <span>// Remove stopwords (default: true)</span>
}</pre></div>
<p dir="auto"><strong>Configuration Examples:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Exact matching (no stemming, keep all words)
exactConfig := blaze.AnalyzerConfig{
    MinTokenLength:  1,
    EnableStemming:  false,
    EnableStopwords: false,
}

// Fuzzy matching (aggressive stemming)
fuzzyConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  true,
    EnableStopwords: true,
}

// Code search (no stemming, no stopwords, longer tokens)
codeConfig := blaze.AnalyzerConfig{
    MinTokenLength:  3,
    EnableStemming:  false,
    EnableStopwords: false,
}"><pre><span>// Exact matching (no stemming, keep all words)</span>
<span>exactConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>1</span>,
    <span>EnableStemming</span>:  <span>false</span>,
    <span>EnableStopwords</span>: <span>false</span>,
}

<span>// Fuzzy matching (aggressive stemming)</span>
<span>fuzzyConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>2</span>,
    <span>EnableStemming</span>:  <span>true</span>,
    <span>EnableStopwords</span>: <span>true</span>,
}

<span>// Code search (no stemming, no stopwords, longer tokens)</span>
<span>codeConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>3</span>,
    <span>EnableStemming</span>:  <span>false</span>,
    <span>EnableStopwords</span>: <span>false</span>,
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tuning Recommendations</h3><a id="user-content-tuning-recommendations" aria-label="Permalink: Tuning Recommendations" href="#tuning-recommendations"></a></p>
<p dir="auto"><strong>MinTokenLength:</strong></p>
<ul dir="auto">
<li><strong>1</strong>: Very permissive, large index</li>
<li><strong>2</strong>: Balanced (default), filters single chars</li>
<li><strong>3</strong>: Strict, smaller index, misses short words</li>
</ul>
<p dir="auto"><strong>EnableStemming:</strong></p>
<ul dir="auto">
<li><strong>true</strong>: Better recall, finds related words ("run" matches "running")</li>
<li><strong>false</strong>: Exact matching, preserves original word forms</li>
</ul>
<p dir="auto"><strong>EnableStopwords:</strong></p>
<ul dir="auto">
<li><strong>true</strong>: Smaller index, faster search, standard behavior</li>
<li><strong>false</strong>: Complete indexing, useful for phrase search</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Skip List Parameters</h3><a id="user-content-skip-list-parameters" aria-label="Permalink: Skip List Parameters" href="#skip-list-parameters"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const MaxHeight = 32  // Maximum tower height"><pre><span>const</span> <span>MaxHeight</span> <span>=</span> <span>32</span>  <span>// Maximum tower height</span></pre></div>
<p dir="auto"><strong>Tower Height Probability:</strong></p>
<ul dir="auto">
<li>Height 1: 50%</li>
<li>Height 2: 25%</li>
<li>Height 3: 12.5%</li>
<li>Height 4: 6.25%</li>
</ul>
<p dir="auto">This geometric distribution ensures O(log n) average performance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use Cases</h2><a id="user-content-use-cases" aria-label="Permalink: Use Cases" href="#use-cases"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Document Search Systems</h3><a id="user-content-1-document-search-systems" aria-label="Permalink: 1. Document Search Systems" href="#1-document-search-systems"></a></p>
<p dir="auto">Build a search engine for documents:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Document struct {
    ID      int
    Title   string
    Content string
}

func IndexDocuments(docs []Document) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, doc := range docs {
        // Combine title and content
        text := doc.Title + &quot; &quot; + doc.Content
        idx.Index(doc.ID, text)
    }

    return idx
}

func SearchDocuments(idx *blaze.InvertedIndex, query string) []int {
    // Use BM25 for general relevance ranking (recommended)
    matches := idx.RankBM25(query, 20)

    docIDs := make([]int, len(matches))
    for i, match := range matches {
        docIDs[i] = match.DocID
    }

    return docIDs
}

// Alternative: Use proximity ranking to find documents with close term matches
func SearchDocumentsByProximity(idx *blaze.InvertedIndex, query string) []int {
    matches := idx.RankProximity(query, 20)

    docIDs := make([]int, len(matches))
    for i, match := range matches {
        docIDs[i] = int(match.Offsets[0].DocumentID)
    }

    return docIDs
}"><pre><span>type</span> <span>Document</span> <span>struct</span> {
    <span>ID</span>      <span>int</span>
    <span>Title</span>   <span>string</span>
    <span>Content</span> <span>string</span>
}

<span>func</span> <span>IndexDocuments</span>(<span>docs</span> []<span>Document</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>for</span> <span>_</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
        <span>// Combine title and content</span>
        <span>text</span> <span>:=</span> <span>doc</span>.<span>Title</span> <span>+</span> <span>" "</span> <span>+</span> <span>doc</span>.<span>Content</span>
        <span>idx</span>.<span>Index</span>(<span>doc</span>.<span>ID</span>, <span>text</span>)
    }

    <span>return</span> <span>idx</span>
}

<span>func</span> <span>SearchDocuments</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>) []<span>int</span> {
    <span>// Use BM25 for general relevance ranking (recommended)</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>20</span>)

    <span>docIDs</span> <span>:=</span> <span>make</span>([]<span>int</span>, <span>len</span>(<span>matches</span>))
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>docIDs</span>[<span>i</span>] <span>=</span> <span>match</span>.<span>DocID</span>
    }

    <span>return</span> <span>docIDs</span>
}

<span>// Alternative: Use proximity ranking to find documents with close term matches</span>
<span>func</span> <span>SearchDocumentsByProximity</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>) []<span>int</span> {
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>20</span>)

    <span>docIDs</span> <span>:=</span> <span>make</span>([]<span>int</span>, <span>len</span>(<span>matches</span>))
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>docIDs</span>[<span>i</span>] <span>=</span> <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>)
    }

    <span>return</span> <span>docIDs</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Log Analysis</h3><a id="user-content-2-log-analysis" aria-label="Permalink: 2. Log Analysis" href="#2-log-analysis"></a></p>
<p dir="auto">Search through log files:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func IndexLogs(logFile string) (*blaze.InvertedIndex, error) {
    idx := blaze.NewInvertedIndex()

    file, err := os.Open(logFile)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    scanner := bufio.NewScanner(file)
    lineNumber := 1

    for scanner.Scan() {
        idx.Index(lineNumber, scanner.Text())
        lineNumber++
    }

    return idx, scanner.Err()
}

// Find all ERROR log lines using BM25 (considers frequency and rarity)
errorLogs := idx.RankBM25(&quot;ERROR&quot;, 100)

// Alternative: Use proximity for finding error patterns
// e.g., &quot;connection timeout&quot; appearing close together
patternMatches := idx.RankProximity(&quot;connection timeout&quot;, 50)"><pre><span>func</span> <span>IndexLogs</span>(<span>logFile</span> <span>string</span>) (<span>*</span>blaze.<span>InvertedIndex</span>, <span>error</span>) {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>file</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>Open</span>(<span>logFile</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>return</span> <span>nil</span>, <span>err</span>
    }
    <span>defer</span> <span>file</span>.<span>Close</span>()

    <span>scanner</span> <span>:=</span> <span>bufio</span>.<span>NewScanner</span>(<span>file</span>)
    <span>lineNumber</span> <span>:=</span> <span>1</span>

    <span>for</span> <span>scanner</span>.<span>Scan</span>() {
        <span>idx</span>.<span>Index</span>(<span>lineNumber</span>, <span>scanner</span>.<span>Text</span>())
        <span>lineNumber</span><span>++</span>
    }

    <span>return</span> <span>idx</span>, <span>scanner</span>.<span>Err</span>()
}

<span>// Find all ERROR log lines using BM25 (considers frequency and rarity)</span>
<span>errorLogs</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"ERROR"</span>, <span>100</span>)

<span>// Alternative: Use proximity for finding error patterns</span>
<span>// e.g., "connection timeout" appearing close together</span>
<span>patternMatches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"connection timeout"</span>, <span>50</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Code Search</h3><a id="user-content-3-code-search" aria-label="Permalink: 3. Code Search" href="#3-code-search"></a></p>
<p dir="auto">Search through source code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func IndexCodebase(rootDir string) (*blaze.InvertedIndex, error) {
    idx := blaze.NewInvertedIndex()
    fileID := 1

    // Custom config for code (no stemming, keep all words)
    config := blaze.AnalyzerConfig{
        MinTokenLength:  2,
        EnableStemming:  false,
        EnableStopwords: false,
    }

    err := filepath.Walk(rootDir, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }

        // Only index Go files
        if !strings.HasSuffix(path, &quot;.go&quot;) {
            return nil
        }

        content, err := os.ReadFile(path)
        if err != nil {
            return err
        }

        // Use custom analyzer
        tokens := blaze.AnalyzeWithConfig(string(content), config)
        // ... index tokens ...

        fileID++
        return nil
    })

    return idx, err
}

// BM25: Find files with frequent mentions of a function/variable
bm25Results := idx.RankBM25(&quot;http.Handler&quot;, 20)

// Proximity: Find exact API patterns (e.g., function calls with parameters)
// Better for finding &quot;http.HandleFunc&quot; as a specific pattern
proximityResults := idx.RankProximity(&quot;http HandleFunc&quot;, 20)"><pre><span>func</span> <span>IndexCodebase</span>(<span>rootDir</span> <span>string</span>) (<span>*</span>blaze.<span>InvertedIndex</span>, <span>error</span>) {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>fileID</span> <span>:=</span> <span>1</span>

    <span>// Custom config for code (no stemming, keep all words)</span>
    <span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
        <span>MinTokenLength</span>:  <span>2</span>,
        <span>EnableStemming</span>:  <span>false</span>,
        <span>EnableStopwords</span>: <span>false</span>,
    }

    <span>err</span> <span>:=</span> <span>filepath</span>.<span>Walk</span>(<span>rootDir</span>, <span>func</span>(<span>path</span> <span>string</span>, <span>info</span> os.<span>FileInfo</span>, <span>err</span> <span>error</span>) <span>error</span> {
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>||</span> <span>info</span>.<span>IsDir</span>() {
            <span>return</span> <span>err</span>
        }

        <span>// Only index Go files</span>
        <span>if</span> <span>!</span><span>strings</span>.<span>HasSuffix</span>(<span>path</span>, <span>".go"</span>) {
            <span>return</span> <span>nil</span>
        }

        <span>content</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>path</span>)
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
            <span>return</span> <span>err</span>
        }

        <span>// Use custom analyzer</span>
        <span>tokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>string</span>(<span>content</span>), <span>config</span>)
        <span>// ... index tokens ...</span>

        <span>fileID</span><span>++</span>
        <span>return</span> <span>nil</span>
    })

    <span>return</span> <span>idx</span>, <span>err</span>
}

<span>// BM25: Find files with frequent mentions of a function/variable</span>
<span>bm25Results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"http.Handler"</span>, <span>20</span>)

<span>// Proximity: Find exact API patterns (e.g., function calls with parameters)</span>
<span>// Better for finding "http.HandleFunc" as a specific pattern</span>
<span>proximityResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"http HandleFunc"</span>, <span>20</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. E-commerce Product Search</h3><a id="user-content-4-e-commerce-product-search" aria-label="Permalink: 4. E-commerce Product Search" href="#4-e-commerce-product-search"></a></p>
<p dir="auto">Search product catalog:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Product struct {
    ID          int
    Name        string
    Description string
    Category    string
    Tags        []string
}

func IndexProducts(products []Product) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, product := range products {
        // Combine all searchable fields
        searchText := fmt.Sprintf(&quot;%s %s %s %s&quot;,
            product.Name,
            product.Description,
            product.Category,
            strings.Join(product.Tags, &quot; &quot;))

        idx.Index(product.ID, searchText)
    }

    return idx
}

// BM25: Best for general product search (considers all factors)
results := idx.RankBM25(&quot;wireless headphones&quot;, 10)

// Proximity: Good for finding exact product name matches
// (e.g., &quot;Sony WH-1000XM4&quot; as an exact phrase proximity)
exactMatches := idx.RankProximity(&quot;wireless headphones&quot;, 10)"><pre><span>type</span> <span>Product</span> <span>struct</span> {
    <span>ID</span>          <span>int</span>
    <span>Name</span>        <span>string</span>
    <span>Description</span> <span>string</span>
    <span>Category</span>    <span>string</span>
    <span>Tags</span>        []<span>string</span>
}

<span>func</span> <span>IndexProducts</span>(<span>products</span> []<span>Product</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>for</span> <span>_</span>, <span>product</span> <span>:=</span> <span>range</span> <span>products</span> {
        <span>// Combine all searchable fields</span>
        <span>searchText</span> <span>:=</span> <span>fmt</span>.<span>Sprintf</span>(<span>"%s %s %s %s"</span>,
            <span>product</span>.<span>Name</span>,
            <span>product</span>.<span>Description</span>,
            <span>product</span>.<span>Category</span>,
            <span>strings</span>.<span>Join</span>(<span>product</span>.<span>Tags</span>, <span>" "</span>))

        <span>idx</span>.<span>Index</span>(<span>product</span>.<span>ID</span>, <span>searchText</span>)
    }

    <span>return</span> <span>idx</span>
}

<span>// BM25: Best for general product search (considers all factors)</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"wireless headphones"</span>, <span>10</span>)

<span>// Proximity: Good for finding exact product name matches</span>
<span>// (e.g., "Sony WH-1000XM4" as an exact phrase proximity)</span>
<span>exactMatches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"wireless headphones"</span>, <span>10</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. Email Search</h3><a id="user-content-5-email-search" aria-label="Permalink: 5. Email Search" href="#5-email-search"></a></p>
<p dir="auto">Index and search email messages:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Email struct {
    ID      int
    From    string
    Subject string
    Body    string
}

func IndexEmails(emails []Email) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, email := range emails {
        searchText := fmt.Sprintf(&quot;%s %s %s&quot;,
            email.From,
            email.Subject,
            email.Body)

        idx.Index(email.ID, searchText)
    }

    return idx
}

// BM25: Find emails where terms appear frequently (general search)
matches := idx.RankBM25(&quot;project deadline&quot;, 50)

// Proximity: Find emails where &quot;project&quot; and &quot;deadline&quot; appear close together
// (more precise, better for finding specific mentions)
closeMatches := idx.RankProximity(&quot;project deadline&quot;, 50)"><pre><span>type</span> <span>Email</span> <span>struct</span> {
    <span>ID</span>      <span>int</span>
    <span>From</span>    <span>string</span>
    <span>Subject</span> <span>string</span>
    <span>Body</span>    <span>string</span>
}

<span>func</span> <span>IndexEmails</span>(<span>emails</span> []<span>Email</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>for</span> <span>_</span>, <span>email</span> <span>:=</span> <span>range</span> <span>emails</span> {
        <span>searchText</span> <span>:=</span> <span>fmt</span>.<span>Sprintf</span>(<span>"%s %s %s"</span>,
            <span>email</span>.<span>From</span>,
            <span>email</span>.<span>Subject</span>,
            <span>email</span>.<span>Body</span>)

        <span>idx</span>.<span>Index</span>(<span>email</span>.<span>ID</span>, <span>searchText</span>)
    }

    <span>return</span> <span>idx</span>
}

<span>// BM25: Find emails where terms appear frequently (general search)</span>
<span>matches</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"project deadline"</span>, <span>50</span>)

<span>// Proximity: Find emails where "project" and "deadline" appear close together</span>
<span>// (more precise, better for finding specific mentions)</span>
<span>closeMatches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"project deadline"</span>, <span>50</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing</h2><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running Tests</h3><a id="user-content-running-tests" aria-label="Permalink: Running Tests" href="#running-tests"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run all tests
make test

# Run tests with coverage
make test-coverage

# Run benchmarks
make bench

# Run all checks (format, vet, lint, test)
make check"><pre><span><span>#</span> Run all tests</span>
make <span>test</span>

<span><span>#</span> Run tests with coverage</span>
make test-coverage

<span><span>#</span> Run benchmarks</span>
make bench

<span><span>#</span> Run all checks (format, vet, lint, test)</span>
make check</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test Coverage</h3><a id="user-content-test-coverage" aria-label="Permalink: Test Coverage" href="#test-coverage"></a></p>
<p dir="auto">The library has comprehensive test coverage:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ make test-coverage
Running tests...
ok      github.com/wizenheimer/blaze    2.456s  coverage: 98.5% of statements
Generating coverage report...
Coverage report: coverage.html"><pre>$ make test-coverage
Running tests...
ok      github.com/wizenheimer/blaze    2.456s  coverage: 98.5% of statements
Generating coverage report...
Coverage report: coverage.html</pre></div>
<p dir="auto"><strong>Coverage by Component:</strong></p>
<ul dir="auto">
<li>Inverted Index: 100%</li>
<li>Skip Lists: 100%</li>
<li>Text Analysis: 100%</li>
<li>Search Operations: 100%</li>
<li>BM25 Ranking: 100%</li>
<li>Serialization: 100%</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Writing Tests</h3><a id="user-content-writing-tests" aria-label="Permalink: Writing Tests" href="#writing-tests"></a></p>
<p dir="auto">Example test:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func TestSearchFunctionality(t *testing.T) {
    idx := blaze.NewInvertedIndex()

    // Index test documents
    idx.Index(1, &quot;the quick brown fox&quot;)
    idx.Index(2, &quot;the lazy brown dog&quot;)

    // Test phrase search
    matches := idx.FindAllPhrases(&quot;brown fox&quot;, blaze.BOFDocument)

    if len(matches) != 1 {
        t.Errorf(&quot;Expected 1 match, got %d&quot;, len(matches))
    }

    if int(matches[0][0].DocumentID) != 1 {
        t.Errorf(&quot;Expected document 1, got %d&quot;, int(matches[0][0].DocumentID))
    }
}"><pre><span>func</span> <span>TestSearchFunctionality</span>(<span>t</span> <span>*</span>testing.<span>T</span>) {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index test documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>"the quick brown fox"</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>"the lazy brown dog"</span>)

    <span>// Test phrase search</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>"brown fox"</span>, <span>blaze</span>.<span>BOFDocument</span>)

    <span>if</span> <span>len</span>(<span>matches</span>) <span>!=</span> <span>1</span> {
        <span>t</span>.<span>Errorf</span>(<span>"Expected 1 match, got %d"</span>, <span>len</span>(<span>matches</span>))
    }

    <span>if</span> <span>int</span>(<span>matches</span>[<span>0</span>][<span>0</span>].<span>DocumentID</span>) <span>!=</span> <span>1</span> {
        <span>t</span>.<span>Errorf</span>(<span>"Expected document 1, got %d"</span>, <span>int</span>(<span>matches</span>[<span>0</span>][<span>0</span>].<span>DocumentID</span>))
    }
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Component Overview</h3><a id="user-content-component-overview" aria-label="Permalink: Component Overview" href="#component-overview"></a></p>
<div data-snippet-clipboard-copy-content="blaze/
├── index.go          # Inverted index implementation with hybrid storage
├── query.go          # Query builder with roaring bitmaps
├── skiplist.go       # Skip list data structure for positions
├── search.go         # Search algorithms (phrase, proximity, BM25)
├── analyzer.go       # Text analysis pipeline
├── serialization.go  # Binary encoding/decoding (skip lists + bitmaps)
├── *_test.go         # Comprehensive test suite
├── Makefile          # Development commands
└── public/           # Documentation website
    └── index.html"><pre><code>blaze/
├── index.go          # Inverted index implementation with hybrid storage
├── query.go          # Query builder with roaring bitmaps
├── skiplist.go       # Skip list data structure for positions
├── search.go         # Search algorithms (phrase, proximity, BM25)
├── analyzer.go       # Text analysis pipeline
├── serialization.go  # Binary encoding/decoding (skip lists + bitmaps)
├── *_test.go         # Comprehensive test suite
├── Makefile          # Development commands
└── public/           # Documentation website
    └── index.html
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Processor Architecture</h3><a id="user-content-query-processor-architecture" aria-label="Permalink: Query Processor Architecture" href="#query-processor-architecture"></a></p>
<p dir="auto">The query processor uses a hybrid storage approach combining roaring bitmaps for document-level operations and skip lists for position-level operations.</p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                      QUERY PROCESSOR ARCHITECTURE                        │
└─────────────────────────────────────────────────────────────────────────┘

                              User Query
                          &quot;machine AND learning&quot;
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │    Text Analyzer            │
                    │  (tokenize, stem, etc.)     │
                    └──────────────┬──────────────┘
                                  │
                    [&quot;machine&quot;, &quot;learning&quot;]
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │     Query Builder           │
                    │  (constructs query tree)    │
                    └──────────────┬──────────────┘
                                  │
                    Query Tree: AND(machine, learning)
                                  │
            ┌─────────────────────┼─────────────────────┐
            │                     │                     │
            ▼                     ▼                     ▼
    ┌───────────────┐    ┌───────────────┐    ┌───────────────┐
    │  Bitmap Ops   │    │  Skip List    │    │  BM25 Scorer  │
    │  (fast AND/OR)│    │  (positions)  │    │  (ranking)    │
    └───────┬───────┘    └───────┬───────┘    └───────┬───────┘
            │                     │                     │
            └─────────────────────┼─────────────────────┘
                                  │
                                  ▼
                          ┌───────────────┐
                          │    Results    │
                          │  (ranked docs)│
                          └───────────────┘"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                      QUERY PROCESSOR ARCHITECTURE                        │
└─────────────────────────────────────────────────────────────────────────┘

                              User Query
                          "machine AND learning"
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │    Text Analyzer            │
                    │  (tokenize, stem, etc.)     │
                    └──────────────┬──────────────┘
                                  │
                    ["machine", "learning"]
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │     Query Builder           │
                    │  (constructs query tree)    │
                    └──────────────┬──────────────┘
                                  │
                    Query Tree: AND(machine, learning)
                                  │
            ┌─────────────────────┼─────────────────────┐
            │                     │                     │
            ▼                     ▼                     ▼
    ┌───────────────┐    ┌───────────────┐    ┌───────────────┐
    │  Bitmap Ops   │    │  Skip List    │    │  BM25 Scorer  │
    │  (fast AND/OR)│    │  (positions)  │    │  (ranking)    │
    └───────┬───────┘    └───────┬───────┘    └───────┬───────┘
            │                     │                     │
            └─────────────────────┼─────────────────────┘
                                  │
                                  ▼
                          ┌───────────────┐
                          │    Results    │
                          │  (ranked docs)│
                          └───────────────┘
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hybrid Storage Architecture</h3><a id="user-content-hybrid-storage-architecture" aria-label="Permalink: Hybrid Storage Architecture" href="#hybrid-storage-architecture"></a></p>
<p dir="auto">Blaze uses a sophisticated hybrid storage model:</p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                        HYBRID STORAGE MODEL                              │
└─────────────────────────────────────────────────────────────────────────┘

For each term &quot;machine&quot;:

┌─────────────────────────────────────────────────────────────────────────┐
│  DOCUMENT LEVEL (Roaring Bitmap)                                        │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  DocBitmaps[&quot;machine&quot;] = {1, 2, 4, 5, 100, 500, 1000, ...}             │
│                                                                           │
│  Compressed representation of ALL documents containing &quot;machine&quot;         │
│  Use: Fast boolean operations (AND, OR, NOT)                            │
│  Size: ~60 KB for 500k documents (400x compression!)                    │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ Links to
                                  ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  POSITION LEVEL (Skip List)                                             │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  PostingsList[&quot;machine&quot;] = SkipList:                                    │
│                                                                           │
│    Level 2: [Doc1:Pos5] ────────────────────────> [Doc100:Pos12]       │
│                 │                                       │                │
│    Level 1: [Doc1:Pos5] ──> [Doc2:Pos3] ───────────> [Doc100:Pos12]   │
│                 │              │                         │               │
│    Level 0: [Doc1:Pos5] -> [Doc2:Pos3] -> [Doc4:Pos1] -> [Doc5:Pos7]  │
│             -> [Doc100:Pos12] -> [Doc500:Pos2] -> ...                  │
│                                                                           │
│  Detailed position information for EVERY occurrence                      │
│  Use: Phrase search, proximity ranking, snippets                        │
│  Size: ~24 MB for 500k positions                                        │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘

WHY HYBRID?
───────────
1. Bitmaps: Lightning-fast document filtering (AND, OR, NOT in microseconds)
2. Skip Lists: Precise position tracking for phrases and proximity
3. Best of both worlds: Speed + Precision"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                        HYBRID STORAGE MODEL                              │
└─────────────────────────────────────────────────────────────────────────┘

For each term "machine":

┌─────────────────────────────────────────────────────────────────────────┐
│  DOCUMENT LEVEL (Roaring Bitmap)                                        │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  DocBitmaps["machine"] = {1, 2, 4, 5, 100, 500, 1000, ...}             │
│                                                                           │
│  Compressed representation of ALL documents containing "machine"         │
│  Use: Fast boolean operations (AND, OR, NOT)                            │
│  Size: ~60 KB for 500k documents (400x compression!)                    │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ Links to
                                  ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  POSITION LEVEL (Skip List)                                             │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  PostingsList["machine"] = SkipList:                                    │
│                                                                           │
│    Level 2: [Doc1:Pos5] ────────────────────────&gt; [Doc100:Pos12]       │
│                 │                                       │                │
│    Level 1: [Doc1:Pos5] ──&gt; [Doc2:Pos3] ───────────&gt; [Doc100:Pos12]   │
│                 │              │                         │               │
│    Level 0: [Doc1:Pos5] -&gt; [Doc2:Pos3] -&gt; [Doc4:Pos1] -&gt; [Doc5:Pos7]  │
│             -&gt; [Doc100:Pos12] -&gt; [Doc500:Pos2] -&gt; ...                  │
│                                                                           │
│  Detailed position information for EVERY occurrence                      │
│  Use: Phrase search, proximity ranking, snippets                        │
│  Size: ~24 MB for 500k positions                                        │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘

WHY HYBRID?
───────────
1. Bitmaps: Lightning-fast document filtering (AND, OR, NOT in microseconds)
2. Skip Lists: Precise position tracking for phrases and proximity
3. Best of both worlds: Speed + Precision
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Execution Flow</h3><a id="user-content-query-execution-flow" aria-label="Permalink: Query Execution Flow" href="#query-execution-flow"></a></p>
<p dir="auto">Here's how a complex query executes step-by-step:</p>
<div data-snippet-clipboard-copy-content="QUERY: (machine OR deep) AND learning AND NOT neural

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 1: BITMAP PHASE (Fast Document Filtering)                         │
└─────────────────────────────────────────────────────────────────────────┘

Term Lookups (O(1) hash map):
    DocBitmaps[&quot;machine&quot;] = {1, 2, 4, 5, 7, 8, 9, 10}
    DocBitmaps[&quot;deep&quot;]    = {2, 3, 5, 6, 8, 9}
    DocBitmaps[&quot;learning&quot;]= {1, 2, 4, 5, 6, 7, 8, 9, 10}
    DocBitmaps[&quot;neural&quot;]  = {3, 6, 8, 9}

Boolean Operations (O(1) per chunk):
    Step 1: machine OR deep
            {1, 2, 4, 5, 7, 8, 9, 10} ∪ {2, 3, 5, 6, 8, 9}
          = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

    Step 2: (machine OR deep) AND learning
            {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} ∩ {1, 2, 4, 5, 6, 7, 8, 9, 10}
          = {1, 2, 4, 5, 6, 7, 8, 9, 10}

    Step 3: Result AND NOT neural
            {1, 2, 4, 5, 6, 7, 8, 9, 10} \ {3, 6, 8, 9}
          = {1, 2, 4, 5, 7, 10}  ← CANDIDATE DOCUMENTS

    Time: ~10 microseconds for 1M documents!

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 2: POSITION PHASE (Optional - for phrases/proximity)              │
└─────────────────────────────────────────────────────────────────────────┘

IF phrase search needed:
    For each candidate doc {1, 2, 4, 5, 7, 10}:
        Use skip lists to verify exact positions
        Check consecutive positions for phrases
        Extract position data for snippets

    Time: O(log n) per position lookup

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 3: RANKING PHASE (BM25 Scoring)                                   │
└─────────────────────────────────────────────────────────────────────────┘

For each candidate document:
    1. Calculate IDF (Inverse Document Frequency):
       - Uses bitmap cardinality for instant document counts
       - IDF(&quot;machine&quot;) = log((N - df + 0.5) / (df + 0.5))
       - df = DocBitmaps[&quot;machine&quot;].GetCardinality()

    2. Calculate TF (Term Frequency):
       - Retrieves from pre-computed DocStats
       - TF(&quot;machine&quot;, Doc1) = termFreqs[&quot;machine&quot;]

    3. Apply BM25 formula:
       - Combines IDF, TF, and length normalization
       - Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)

    4. Sum scores for all query terms

Results sorted by score:
    Doc 5: 8.45
    Doc 2: 7.23
    Doc 1: 6.91
    ...

    Time: O(candidates × terms)"><pre><code>QUERY: (machine OR deep) AND learning AND NOT neural

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 1: BITMAP PHASE (Fast Document Filtering)                         │
└─────────────────────────────────────────────────────────────────────────┘

Term Lookups (O(1) hash map):
    DocBitmaps["machine"] = {1, 2, 4, 5, 7, 8, 9, 10}
    DocBitmaps["deep"]    = {2, 3, 5, 6, 8, 9}
    DocBitmaps["learning"]= {1, 2, 4, 5, 6, 7, 8, 9, 10}
    DocBitmaps["neural"]  = {3, 6, 8, 9}

Boolean Operations (O(1) per chunk):
    Step 1: machine OR deep
            {1, 2, 4, 5, 7, 8, 9, 10} ∪ {2, 3, 5, 6, 8, 9}
          = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

    Step 2: (machine OR deep) AND learning
            {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} ∩ {1, 2, 4, 5, 6, 7, 8, 9, 10}
          = {1, 2, 4, 5, 6, 7, 8, 9, 10}

    Step 3: Result AND NOT neural
            {1, 2, 4, 5, 6, 7, 8, 9, 10} \ {3, 6, 8, 9}
          = {1, 2, 4, 5, 7, 10}  ← CANDIDATE DOCUMENTS

    Time: ~10 microseconds for 1M documents!

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 2: POSITION PHASE (Optional - for phrases/proximity)              │
└─────────────────────────────────────────────────────────────────────────┘

IF phrase search needed:
    For each candidate doc {1, 2, 4, 5, 7, 10}:
        Use skip lists to verify exact positions
        Check consecutive positions for phrases
        Extract position data for snippets

    Time: O(log n) per position lookup

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 3: RANKING PHASE (BM25 Scoring)                                   │
└─────────────────────────────────────────────────────────────────────────┘

For each candidate document:
    1. Calculate IDF (Inverse Document Frequency):
       - Uses bitmap cardinality for instant document counts
       - IDF("machine") = log((N - df + 0.5) / (df + 0.5))
       - df = DocBitmaps["machine"].GetCardinality()

    2. Calculate TF (Term Frequency):
       - Retrieves from pre-computed DocStats
       - TF("machine", Doc1) = termFreqs["machine"]

    3. Apply BM25 formula:
       - Combines IDF, TF, and length normalization
       - Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)

    4. Sum scores for all query terms

Results sorted by score:
    Doc 5: 8.45
    Doc 2: 7.23
    Doc 1: 6.91
    ...

    Time: O(candidates × terms)
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Structure Memory Layout</h3><a id="user-content-data-structure-memory-layout" aria-label="Permalink: Data Structure Memory Layout" href="#data-structure-memory-layout"></a></p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                    INVERTED INDEX STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

InvertedIndex {
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocBitmaps: map[string]*roaring.Bitmap                         │
    │  ───────────────────────────────────────────────────────────────│
    │  &quot;machine&quot;  → [Compressed Bitmap: 512 bytes]                    │
    │  &quot;learning&quot; → [Compressed Bitmap: 448 bytes]                    │
    │  &quot;deep&quot;     → [Compressed Bitmap: 256 bytes]                    │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~100 bytes per term (compressed)                       │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Parallel Storage
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  PostingsList: map[string]SkipList                              │
    │  ───────────────────────────────────────────────────────────────│
    │  &quot;machine&quot;  → SkipList with 10,000 position nodes               │
    │  &quot;learning&quot; → SkipList with 8,000 position nodes                │
    │  &quot;deep&quot;     → SkipList with 5,000 position nodes                │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~48 bytes per position (node overhead)                 │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Statistics
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocStats: map[int]DocumentStats                                │
    │  ───────────────────────────────────────────────────────────────│
    │  Doc1 → {Length: 150, TermFreqs: {&quot;machine&quot;: 3, ...}}          │
    │  Doc2 → {Length: 200, TermFreqs: {&quot;learning&quot;: 5, ...}}         │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~16 bytes per term per document                        │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Metadata
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  Global Statistics                                               │
    │  ───────────────────────────────────────────────────────────────│
    │  TotalDocs:   1,000,000                                         │
    │  TotalTerms:  150,000,000                                       │
    │  AvgDocLen:   150.0                                             │
    │  BM25Params:  {K1: 1.5, B: 0.75}                               │
    └─────────────────────────────────────────────────────────────────┘

    Mutex for thread safety (sync.RWMutex)
}

MEMORY BREAKDOWN (for 1M documents, 10M unique positions):
────────────────────────────────────────────────────────────
DocBitmaps:     ~10 MB  (compressed bitmaps)
PostingsList:   ~480 MB (skip list nodes)
DocStats:       ~500 MB (per-doc statistics)
Overhead:       ~10 MB  (maps, pointers, etc.)
────────────────────────────────────────────────────────────
TOTAL:          ~1 GB"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                    INVERTED INDEX STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

InvertedIndex {
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocBitmaps: map[string]*roaring.Bitmap                         │
    │  ───────────────────────────────────────────────────────────────│
    │  "machine"  → [Compressed Bitmap: 512 bytes]                    │
    │  "learning" → [Compressed Bitmap: 448 bytes]                    │
    │  "deep"     → [Compressed Bitmap: 256 bytes]                    │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~100 bytes per term (compressed)                       │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Parallel Storage
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  PostingsList: map[string]SkipList                              │
    │  ───────────────────────────────────────────────────────────────│
    │  "machine"  → SkipList with 10,000 position nodes               │
    │  "learning" → SkipList with 8,000 position nodes                │
    │  "deep"     → SkipList with 5,000 position nodes                │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~48 bytes per position (node overhead)                 │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Statistics
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocStats: map[int]DocumentStats                                │
    │  ───────────────────────────────────────────────────────────────│
    │  Doc1 → {Length: 150, TermFreqs: {"machine": 3, ...}}          │
    │  Doc2 → {Length: 200, TermFreqs: {"learning": 5, ...}}         │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~16 bytes per term per document                        │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Metadata
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  Global Statistics                                               │
    │  ───────────────────────────────────────────────────────────────│
    │  TotalDocs:   1,000,000                                         │
    │  TotalTerms:  150,000,000                                       │
    │  AvgDocLen:   150.0                                             │
    │  BM25Params:  {K1: 1.5, B: 0.75}                               │
    └─────────────────────────────────────────────────────────────────┘

    Mutex for thread safety (sync.RWMutex)
}

MEMORY BREAKDOWN (for 1M documents, 10M unique positions):
────────────────────────────────────────────────────────────
DocBitmaps:     ~10 MB  (compressed bitmaps)
PostingsList:   ~480 MB (skip list nodes)
DocStats:       ~500 MB (per-doc statistics)
Overhead:       ~10 MB  (maps, pointers, etc.)
────────────────────────────────────────────────────────────
TOTAL:          ~1 GB
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Roaring Bitmap Internals</h3><a id="user-content-roaring-bitmap-internals" aria-label="Permalink: Roaring Bitmap Internals" href="#roaring-bitmap-internals"></a></p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                    ROARING BITMAP STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

Document IDs: {1, 2, 3, 100, 101, 102, 500000, 500001, 999999}

Traditional Bitmap (naive):
    [1,1,1,0,0...0,1,1,1,0...0,1,1,0...0,1]
    Size: 1,000,000 bits = 125 KB (wasteful for sparse data)

Roaring Bitmap (smart):

    Split into 65,536 chunks (high 16 bits = chunk ID):

    Chunk 0 (docs 0-65535):      [1,2,3,100,101,102]
    Chunk 7 (docs 458752-524287): [500000, 500001]
    Chunk 15 (docs 983040-1048575): [999999]

    Storage per chunk (adaptive):
    ┌────────────────────────────────────────────────────┐
    │ If cardinality < 4096:                             │
    │   → Use Array Container                            │
    │   → Store sorted uint16 values directly            │
    │   → Size: 2 bytes × cardinality                    │
    │                                                     │
    │ If cardinality > 4096:                             │
    │   → Use Bitmap Container                           │
    │   → Store 65536-bit bitmap (8 KB)                 │
    │   → Size: 8 KB fixed                               │
    │                                                     │
    │ If cardinality = 65536 (all docs):                │
    │   → Use Run Container                              │
    │   → Store: [0-65535]                               │
    │   → Size: 4 bytes                                  │
    └────────────────────────────────────────────────────┘

    Total Size: ~60 bytes (vs 125 KB!)

    Operations:

    AND: Container-by-container intersection
         Skip non-matching chunks (O(1))
         Intersect matching chunks (O(min(n,m)))

    OR:  Container-by-container union
         Merge all chunks (O(n+m))

    NOT: Complement within document space
         Flip all bits in each chunk"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                    ROARING BITMAP STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

Document IDs: {1, 2, 3, 100, 101, 102, 500000, 500001, 999999}

Traditional Bitmap (naive):
    [1,1,1,0,0...0,1,1,1,0...0,1,1,0...0,1]
    Size: 1,000,000 bits = 125 KB (wasteful for sparse data)

Roaring Bitmap (smart):

    Split into 65,536 chunks (high 16 bits = chunk ID):

    Chunk 0 (docs 0-65535):      [1,2,3,100,101,102]
    Chunk 7 (docs 458752-524287): [500000, 500001]
    Chunk 15 (docs 983040-1048575): [999999]

    Storage per chunk (adaptive):
    ┌────────────────────────────────────────────────────┐
    │ If cardinality &lt; 4096:                             │
    │   → Use Array Container                            │
    │   → Store sorted uint16 values directly            │
    │   → Size: 2 bytes × cardinality                    │
    │                                                     │
    │ If cardinality &gt; 4096:                             │
    │   → Use Bitmap Container                           │
    │   → Store 65536-bit bitmap (8 KB)                 │
    │   → Size: 8 KB fixed                               │
    │                                                     │
    │ If cardinality = 65536 (all docs):                │
    │   → Use Run Container                              │
    │   → Store: [0-65535]                               │
    │   → Size: 4 bytes                                  │
    └────────────────────────────────────────────────────┘

    Total Size: ~60 bytes (vs 125 KB!)

    Operations:

    AND: Container-by-container intersection
         Skip non-matching chunks (O(1))
         Intersect matching chunks (O(min(n,m)))

    OR:  Container-by-container union
         Merge all chunks (O(n+m))

    NOT: Complement within document space
         Flip all bits in each chunk
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Execution Model</h3><a id="user-content-query-builder-execution-model" aria-label="Permalink: Query Builder Execution Model" href="#query-builder-execution-model"></a></p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                   QUERY BUILDER EXECUTION MODEL                          │
└─────────────────────────────────────────────────────────────────────────┘

Query: NewQueryBuilder(idx).
         Group(func(q) { q.Term(&quot;machine&quot;).Or().Term(&quot;deep&quot;) }).
         And().
         Term(&quot;learning&quot;).
         Execute()

INTERNAL REPRESENTATION:
────────────────────────

QueryBuilder {
    stack: []*roaring.Bitmap       // Operand stack
    ops:   []QueryOp               // Operator stack
    terms: []string                // Track for BM25
}

EXECUTION TRACE:
────────────────

Step 1: Group(func(q) { ... })
    ┌──────────────────────────────────────┐
    │ Create sub-builder                    │
    │ Execute sub-query                     │
    │ Push result bitmap to parent stack    │
    └──────────────────────────────────────┘

    Sub-query execution:
      1.1: Term(&quot;machine&quot;)
           → Lookup: DocBitmaps[&quot;machine&quot;]
           → Push: {1,2,4,5,7,8,9,10}

      1.2: Or()
           → Push operator: OR

      1.3: Term(&quot;deep&quot;)
           → Lookup: DocBitmaps[&quot;deep&quot;]
           → Push: {2,3,5,6,8,9}

      1.4: Apply OR
           → Pop: {2,3,5,6,8,9}
           → Pop: {1,2,4,5,7,8,9,10}
           → Union: {1,2,3,4,5,6,7,8,9,10}
           → Push result

    Result: {1,2,3,4,5,6,7,8,9,10}

Step 2: And()
    → Push operator: AND

Step 3: Term(&quot;learning&quot;)
    → Lookup: DocBitmaps[&quot;learning&quot;]
    → Push: {1,2,4,5,6,7,8,9,10}

Step 4: Execute()
    → Pop: {1,2,4,5,6,7,8,9,10}
    → Pop: {1,2,3,4,5,6,7,8,9,10}
    → Intersect: {1,2,4,5,6,7,8,9,10}
    → Return final bitmap

OPERATION COSTS:
────────────────
Bitmap Lookup:    O(1)          ~100 ns
Bitmap Union:     O(n+m)        ~1 µs for 10k docs
Bitmap Intersect: O(min(n,m))   ~800 ns for 10k docs
Bitmap Difference: O(n)         ~900 ns for 10k docs

Total Query Time: ~10 µs for typical query!"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                   QUERY BUILDER EXECUTION MODEL                          │
└─────────────────────────────────────────────────────────────────────────┘

Query: NewQueryBuilder(idx).
         Group(func(q) { q.Term("machine").Or().Term("deep") }).
         And().
         Term("learning").
         Execute()

INTERNAL REPRESENTATION:
────────────────────────

QueryBuilder {
    stack: []*roaring.Bitmap       // Operand stack
    ops:   []QueryOp               // Operator stack
    terms: []string                // Track for BM25
}

EXECUTION TRACE:
────────────────

Step 1: Group(func(q) { ... })
    ┌──────────────────────────────────────┐
    │ Create sub-builder                    │
    │ Execute sub-query                     │
    │ Push result bitmap to parent stack    │
    └──────────────────────────────────────┘

    Sub-query execution:
      1.1: Term("machine")
           → Lookup: DocBitmaps["machine"]
           → Push: {1,2,4,5,7,8,9,10}

      1.2: Or()
           → Push operator: OR

      1.3: Term("deep")
           → Lookup: DocBitmaps["deep"]
           → Push: {2,3,5,6,8,9}

      1.4: Apply OR
           → Pop: {2,3,5,6,8,9}
           → Pop: {1,2,4,5,7,8,9,10}
           → Union: {1,2,3,4,5,6,7,8,9,10}
           → Push result

    Result: {1,2,3,4,5,6,7,8,9,10}

Step 2: And()
    → Push operator: AND

Step 3: Term("learning")
    → Lookup: DocBitmaps["learning"]
    → Push: {1,2,4,5,6,7,8,9,10}

Step 4: Execute()
    → Pop: {1,2,4,5,6,7,8,9,10}
    → Pop: {1,2,3,4,5,6,7,8,9,10}
    → Intersect: {1,2,4,5,6,7,8,9,10}
    → Return final bitmap

OPERATION COSTS:
────────────────
Bitmap Lookup:    O(1)          ~100 ns
Bitmap Union:     O(n+m)        ~1 µs for 10k docs
Bitmap Intersect: O(min(n,m))   ~800 ns for 10k docs
Bitmap Difference: O(n)         ~900 ns for 10k docs

Total Query Time: ~10 µs for typical query!
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Flow</h3><a id="user-content-data-flow" aria-label="Permalink: Data Flow" href="#data-flow"></a></p>
<div data-snippet-clipboard-copy-content="┌──────────────────────────────────────────────────────────────────────┐
│                         Complete Data Flow                           │
└──────────────────────────────────────────────────────────────────────┘

                              User Input
                       &quot;The Quick Brown Fox!&quot;
                                │
                                ▼
            ┌───────────────────────────────────────────┐
            │      Text Analysis Pipeline               │
            │  ┌─────────────────────────────────────┐  │
            │  │ 1. Tokenization                     │  │
            │  │    [&quot;The&quot;, &quot;Quick&quot;, &quot;Brown&quot;, &quot;Fox&quot;] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 2. Lowercasing                      │  │
            │  │    [&quot;the&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 3. Stopword Filtering               │  │
            │  │    [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 4. Length Filtering                 │  │
            │  │    [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 5. Stemming                         │  │
            │  │    [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;]        │  │
            │  └────────────┬────────────────────────┘  │
            └───────────────┼────────────────────────────┘
                            ▼
                    [&quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;]
                            │
                            ▼
            ┌───────────────────────────────────────────┐
            │       Inverted Index (Indexing)           │
            │                                            │
            │  ┌─────────┬────────────────────────┐     │
            │  │ &quot;quick&quot; │ → SkipList             │     │
            │  │         │    └─> [Doc1:Pos0]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ &quot;brown&quot; │ → SkipList             │     │
            │  │         │    └─> [Doc1:Pos1]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ &quot;fox&quot;   │ → SkipList             │     │
            │  │         │    └─> [Doc1:Pos2]     │     │
            │  └─────────┴────────────────────────┘     │
            └───────────────┬───────────────────────────┘
                            │
          ┌─────────────────┴─────────────────┐
          │        Search Operations          │
          ▼                                   ▼
    ┌──────────┐                      ┌────────────┐
    │  Term    │                      │  Phrase    │
    │  Search  │                      │  Search    │
    └────┬─────┘                      └─────┬──────┘
         │                                  │
         └──────────┬───────────────────────┘
                    ▼
            ┌───────────────┐
            │   Proximity   │
            │   Ranking     │
            └───────┬───────┘
                    │
                    ▼
            ┌───────────────────────┐
            │  Ranked Results       │
            │  ┌─────────────────┐  │
            │  │ Doc 1: Score 1.0│  │
            │  │ Doc 2: Score 0.5│  │
            │  │ Doc 3: Score 0.3│  │
            │  └─────────────────┘  │
            └───────────────────────┘"><pre><code>┌──────────────────────────────────────────────────────────────────────┐
│                         Complete Data Flow                           │
└──────────────────────────────────────────────────────────────────────┘

                              User Input
                       "The Quick Brown Fox!"
                                │
                                ▼
            ┌───────────────────────────────────────────┐
            │      Text Analysis Pipeline               │
            │  ┌─────────────────────────────────────┐  │
            │  │ 1. Tokenization                     │  │
            │  │    ["The", "Quick", "Brown", "Fox"] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 2. Lowercasing                      │  │
            │  │    ["the", "quick", "brown", "fox"] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 3. Stopword Filtering               │  │
            │  │    ["quick", "brown", "fox"]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 4. Length Filtering                 │  │
            │  │    ["quick", "brown", "fox"]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 5. Stemming                         │  │
            │  │    ["quick", "brown", "fox"]        │  │
            │  └────────────┬────────────────────────┘  │
            └───────────────┼────────────────────────────┘
                            ▼
                    ["quick", "brown", "fox"]
                            │
                            ▼
            ┌───────────────────────────────────────────┐
            │       Inverted Index (Indexing)           │
            │                                            │
            │  ┌─────────┬────────────────────────┐     │
            │  │ "quick" │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos0]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ "brown" │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos1]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ "fox"   │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos2]     │     │
            │  └─────────┴────────────────────────┘     │
            └───────────────┬───────────────────────────┘
                            │
          ┌─────────────────┴─────────────────┐
          │        Search Operations          │
          ▼                                   ▼
    ┌──────────┐                      ┌────────────┐
    │  Term    │                      │  Phrase    │
    │  Search  │                      │  Search    │
    └────┬─────┘                      └─────┬──────┘
         │                                  │
         └──────────┬───────────────────────┘
                    ▼
            ┌───────────────┐
            │   Proximity   │
            │   Ranking     │
            └───────┬───────┘
                    │
                    ▼
            ┌───────────────────────┐
            │  Ranked Results       │
            │  ┌─────────────────┐  │
            │  │ Doc 1: Score 1.0│  │
            │  │ Doc 2: Score 0.5│  │
            │  │ Doc 3: Score 0.3│  │
            │  └─────────────────┘  │
            └───────────────────────┘
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Key Design Decisions</h3><a id="user-content-key-design-decisions" aria-label="Permalink: Key Design Decisions" href="#key-design-decisions"></a></p>
<p dir="auto"><strong>1. Skip Lists over Balanced Trees</strong></p>
<p dir="auto">Rationale:</p>
<ul dir="auto">
<li>Simpler implementation (no rotation logic)</li>
<li>Better cache locality</li>
<li>Easier to make concurrent</li>
<li>Comparable performance (O(log n))</li>
<li>Used in production systems (Redis, LevelDB)</li>
</ul>
<p dir="auto"><strong>2. Position-Based Indexing</strong></p>
<p dir="auto">Instead of just tracking document IDs, Blaze tracks exact word positions:</p>
<div data-snippet-clipboard-copy-content="Traditional Index (Document IDs only):
┌─────────┬──────────────────┐
│ &quot;quick&quot; │ [Doc1, Doc3]     │  Cannot do phrase search
└─────────┴──────────────────┘  Cannot rank by proximity

Position-Based Index (Document + Offset):
┌─────────┬────────────────────────────────────┐
│ &quot;quick&quot; │ [Doc1:Pos1, Doc3:Pos0]             │  Enables phrase search
│ &quot;brown&quot; │ [Doc1:Pos2, Doc3:Pos1]             │  Enables proximity ranking
│ &quot;fox&quot;   │ [Doc1:Pos3]                        │  Enables snippet generation
└─────────┴────────────────────────────────────┘  Enables precise results

Can verify: &quot;quick brown&quot; is a phrase in Doc1 (Pos1→Pos2)
            but NOT in Doc3 (Pos0 and Pos1 are not &quot;quick brown&quot;)"><pre><code>Traditional Index (Document IDs only):
┌─────────┬──────────────────┐
│ "quick" │ [Doc1, Doc3]     │  Cannot do phrase search
└─────────┴──────────────────┘  Cannot rank by proximity

Position-Based Index (Document + Offset):
┌─────────┬────────────────────────────────────┐
│ "quick" │ [Doc1:Pos1, Doc3:Pos0]             │  Enables phrase search
│ "brown" │ [Doc1:Pos2, Doc3:Pos1]             │  Enables proximity ranking
│ "fox"   │ [Doc1:Pos3]                        │  Enables snippet generation
└─────────┴────────────────────────────────────┘  Enables precise results

Can verify: "quick brown" is a phrase in Doc1 (Pos1→Pos2)
            but NOT in Doc3 (Pos0 and Pos1 are not "quick brown")
</code></pre></div>
<p dir="auto">Benefits:</p>
<ul dir="auto">
<li>Enables phrase search (check consecutive positions)</li>
<li>Enables proximity ranking (measure distances)</li>
<li>Enables snippet generation (extract relevant parts)</li>
<li>More precise search results</li>
</ul>
<p dir="auto">Trade-offs:</p>
<ul dir="auto">
<li>Larger index size (~2-3x more data)</li>
<li>More complex algorithms (but still O(log n))</li>
</ul>
<p dir="auto"><strong>3. Binary Serialization</strong></p>
<p dir="auto">Custom binary format instead of JSON:</p>
<p dir="auto">Advantages:</p>
<ul dir="auto">
<li>60% smaller file size</li>
<li>3x faster parsing</li>
<li>Preserves skip list structure</li>
<li>Suitable for large indexes</li>
</ul>
<p dir="auto"><strong>4. Configurable Text Analysis</strong></p>
<p dir="auto">Pluggable analyzer configuration:</p>
<p dir="auto">Benefits:</p>
<ul dir="auto">
<li>Adapt to different use cases</li>
<li>Trade-off precision vs recall</li>
<li>Support multiple languages (future)</li>
<li>Domain-specific customization</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Best Practices</h2><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Choose Appropriate Document IDs</h3><a id="user-content-1-choose-appropriate-document-ids" aria-label="Permalink: 1. Choose Appropriate Document IDs" href="#1-choose-appropriate-document-ids"></a></p>
<p dir="auto">Use stable, unique identifiers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Use database primary keys
idx.Index(dbRecord.ID, dbRecord.Content)

// Bad: Use array indices (changes when reordering)
for i, doc := range docs {
    idx.Index(i, doc.Content)  // Don't do this
}"><pre><span>// Good: Use database primary keys</span>
<span>idx</span>.<span>Index</span>(<span>dbRecord</span>.<span>ID</span>, <span>dbRecord</span>.<span>Content</span>)

<span>// Bad: Use array indices (changes when reordering)</span>
<span>for</span> <span>i</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
    <span>idx</span>.<span>Index</span>(<span>i</span>, <span>doc</span>.<span>Content</span>)  <span>// Don't do this</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Batch Indexing for Large Datasets</h3><a id="user-content-2-batch-indexing-for-large-datasets" aria-label="Permalink: 2. Batch Indexing for Large Datasets" href="#2-batch-indexing-for-large-datasets"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func IndexLargeDataset(docs []Document) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    // Process in batches
    batchSize := 1000
    for i := 0; i < len(docs); i += batchSize {
        end := min(i+batchSize, len(docs))
        batch := docs[i:end]

        for _, doc := range batch {
            idx.Index(doc.ID, doc.Content)
        }

        // Optional: periodic serialization for checkpoints
        if i%10000 == 0 {
            data, _ := idx.Encode()
            os.WriteFile(fmt.Sprintf(&quot;checkpoint_%d.bin&quot;, i), data, 0644)
        }
    }

    return idx
}"><pre><span>func</span> <span>IndexLargeDataset</span>(<span>docs</span> []<span>Document</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Process in batches</span>
    <span>batchSize</span> <span>:=</span> <span>1000</span>
    <span>for</span> <span>i</span> <span>:=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>docs</span>); <span>i</span> <span>+=</span> <span>batchSize</span> {
        <span>end</span> <span>:=</span> <span>min</span>(<span>i</span><span>+</span><span>batchSize</span>, <span>len</span>(<span>docs</span>))
        <span>batch</span> <span>:=</span> <span>docs</span>[<span>i</span>:<span>end</span>]

        <span>for</span> <span>_</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>batch</span> {
            <span>idx</span>.<span>Index</span>(<span>doc</span>.<span>ID</span>, <span>doc</span>.<span>Content</span>)
        }

        <span>// Optional: periodic serialization for checkpoints</span>
        <span>if</span> <span>i</span><span>%</span><span>10000</span> <span>==</span> <span>0</span> {
            <span>data</span>, <span>_</span> <span>:=</span> <span>idx</span>.<span>Encode</span>()
            <span>os</span>.<span>WriteFile</span>(<span>fmt</span>.<span>Sprintf</span>(<span>"checkpoint_%d.bin"</span>, <span>i</span>), <span>data</span>, <span>0644</span>)
        }
    }

    <span>return</span> <span>idx</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Use Appropriate Analyzer Config</h3><a id="user-content-3-use-appropriate-analyzer-config" aria-label="Permalink: 3. Use Appropriate Analyzer Config" href="#3-use-appropriate-analyzer-config"></a></p>
<p dir="auto">Match configuration to your use case:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Natural language text (books, articles)
naturalLanguageConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  true,   // Find related words
    EnableStopwords: true,   // Remove common words
}

// Technical documentation (code, APIs)
technicalConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  false,  // Keep exact terms
    EnableStopwords: false,  // Keep all words
}

// Product names (e-commerce)
productConfig := blaze.AnalyzerConfig{
    MinTokenLength:  1,      // Include single chars (e.g., &quot;X&quot;)
    EnableStemming:  false,  // Exact product names
    EnableStopwords: false,  // Keep all words
}"><pre><span>// Natural language text (books, articles)</span>
<span>naturalLanguageConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>2</span>,
    <span>EnableStemming</span>:  <span>true</span>,   <span>// Find related words</span>
    <span>EnableStopwords</span>: <span>true</span>,   <span>// Remove common words</span>
}

<span>// Technical documentation (code, APIs)</span>
<span>technicalConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>2</span>,
    <span>EnableStemming</span>:  <span>false</span>,  <span>// Keep exact terms</span>
    <span>EnableStopwords</span>: <span>false</span>,  <span>// Keep all words</span>
}

<span>// Product names (e-commerce)</span>
<span>productConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>1</span>,      <span>// Include single chars (e.g., "X")</span>
    <span>EnableStemming</span>:  <span>false</span>,  <span>// Exact product names</span>
    <span>EnableStopwords</span>: <span>false</span>,  <span>// Keep all words</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Persist Index for Large Datasets</h3><a id="user-content-4-persist-index-for-large-datasets" aria-label="Permalink: 4. Persist Index for Large Datasets" href="#4-persist-index-for-large-datasets"></a></p>
<p dir="auto">Don't rebuild the index every time:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const indexFile = &quot;search_index.bin&quot;

func LoadOrBuildIndex(docs []Document) (*blaze.InvertedIndex, error) {
    // Try to load existing index
    if data, err := os.ReadFile(indexFile); err == nil {
        idx := blaze.NewInvertedIndex()
        if err := idx.Decode(data); err == nil {
            return idx, nil
        }
    }

    // Build new index
    idx := blaze.NewInvertedIndex()
    for _, doc := range docs {
        idx.Index(doc.ID, doc.Content)
    }

    // Save for next time
    if data, err := idx.Encode(); err == nil {
        os.WriteFile(indexFile, data, 0644)
    }

    return idx, nil
}"><pre><span>const</span> <span>indexFile</span> <span>=</span> <span>"search_index.bin"</span>

<span>func</span> <span>LoadOrBuildIndex</span>(<span>docs</span> []<span>Document</span>) (<span>*</span>blaze.<span>InvertedIndex</span>, <span>error</span>) {
    <span>// Try to load existing index</span>
    <span>if</span> <span>data</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>indexFile</span>); <span>err</span> <span>==</span> <span>nil</span> {
        <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
        <span>if</span> <span>err</span> <span>:=</span> <span>idx</span>.<span>Decode</span>(<span>data</span>); <span>err</span> <span>==</span> <span>nil</span> {
            <span>return</span> <span>idx</span>, <span>nil</span>
        }
    }

    <span>// Build new index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>for</span> <span>_</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
        <span>idx</span>.<span>Index</span>(<span>doc</span>.<span>ID</span>, <span>doc</span>.<span>Content</span>)
    }

    <span>// Save for next time</span>
    <span>if</span> <span>data</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Encode</span>(); <span>err</span> <span>==</span> <span>nil</span> {
        <span>os</span>.<span>WriteFile</span>(<span>indexFile</span>, <span>data</span>, <span>0644</span>)
    }

    <span>return</span> <span>idx</span>, <span>nil</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. Handle Concurrent Access</h3><a id="user-content-5-handle-concurrent-access" aria-label="Permalink: 5. Handle Concurrent Access" href="#5-handle-concurrent-access"></a></p>
<p dir="auto">The Index method is thread-safe, but for read-heavy workloads:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type SearchService struct {
    idx *blaze.InvertedIndex
    mu  sync.RWMutex
}

func (s *SearchService) Index(docID int, content string) {
    s.mu.Lock()
    defer s.mu.Unlock()
    s.idx.Index(docID, content)
}

func (s *SearchService) Search(query string) []blaze.Match {
    s.mu.RLock()
    defer s.mu.RUnlock()
    return s.idx.RankProximity(query, 20)
}"><pre><span>type</span> <span>SearchService</span> <span>struct</span> {
    <span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>
    <span>mu</span>  sync.<span>RWMutex</span>
}

<span>func</span> (<span>s</span> <span>*</span><span>SearchService</span>) <span>Index</span>(<span>docID</span> <span>int</span>, <span>content</span> <span>string</span>) {
    <span>s</span>.<span>mu</span>.<span>Lock</span>()
    <span>defer</span> <span>s</span>.<span>mu</span>.<span>Unlock</span>()
    <span>s</span>.<span>idx</span>.<span>Index</span>(<span>docID</span>, <span>content</span>)
}

<span>func</span> (<span>s</span> <span>*</span><span>SearchService</span>) <span>Search</span>(<span>query</span> <span>string</span>) []blaze.<span>Match</span> {
    <span>s</span>.<span>mu</span>.<span>RLock</span>()
    <span>defer</span> <span>s</span>.<span>mu</span>.<span>RUnlock</span>()
    <span>return</span> <span>s</span>.<span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>20</span>)
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">6. Monitor Index Size</h3><a id="user-content-6-monitor-index-size" aria-label="Permalink: 6. Monitor Index Size" href="#6-monitor-index-size"></a></p>
<p dir="auto">Track index growth:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Stats() map[string]interface{} {
    stats := make(map[string]interface{})

    stats[&quot;unique_terms&quot;] = len(idx.PostingsList)

    totalPositions := 0
    for _, skipList := range idx.PostingsList {
        // Count positions in this skip list
        iter := skipList.Iterator()
        for iter.HasNext() {
            iter.Next()
            totalPositions++
        }
    }

    stats[&quot;total_positions&quot;] = totalPositions
    stats[&quot;avg_positions_per_term&quot;] = float64(totalPositions) / float64(len(idx.PostingsList))

    return stats
}"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Stats</span>() <span>map</span>[<span>string</span>]<span>interface</span>{} {
    <span>stats</span> <span>:=</span> <span>make</span>(<span>map</span>[<span>string</span>]<span>interface</span>{})

    <span>stats</span>[<span>"unique_terms"</span>] <span>=</span> <span>len</span>(<span>idx</span>.<span>PostingsList</span>)

    <span>totalPositions</span> <span>:=</span> <span>0</span>
    <span>for</span> <span>_</span>, <span>skipList</span> <span>:=</span> <span>range</span> <span>idx</span>.<span>PostingsList</span> {
        <span>// Count positions in this skip list</span>
        <span>iter</span> <span>:=</span> <span>skipList</span>.<span>Iterator</span>()
        <span>for</span> <span>iter</span>.<span>HasNext</span>() {
            <span>iter</span>.<span>Next</span>()
            <span>totalPositions</span><span>++</span>
        }
    }

    <span>stats</span>[<span>"total_positions"</span>] <span>=</span> <span>totalPositions</span>
    <span>stats</span>[<span>"avg_positions_per_term"</span>] <span>=</span> <span>float64</span>(<span>totalPositions</span>) <span>/</span> <span>float64</span>(<span>len</span>(<span>idx</span>.<span>PostingsList</span>))

    <span>return</span> <span>stats</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">7. Choose the Right Ranking Algorithm</h3><a id="user-content-7-choose-the-right-ranking-algorithm" aria-label="Permalink: 7. Choose the Right Ranking Algorithm" href="#7-choose-the-right-ranking-algorithm"></a></p>
<p dir="auto"><strong>Use BM25 when:</strong></p>
<ul dir="auto">
<li>You need industry-standard relevance ranking</li>
<li>Term frequency matters (documents with more occurrences rank higher)</li>
<li>You want automatic length normalization</li>
<li>Rare terms should be weighted more heavily</li>
<li><strong>Recommended for most use cases</strong></li>
</ul>
<p dir="auto"><strong>Use Proximity when:</strong></p>
<ul dir="auto">
<li>You want to find terms close together</li>
<li>Term distance is more important than frequency</li>
<li>You're searching for specific co-occurrences</li>
<li>You need snippet generation (using position data)</li>
</ul>
<p dir="auto"><strong>Practical Examples:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// E-commerce: General product search
// BM25 considers term frequency and rarity
bm25Results := idx.RankBM25(&quot;wireless bluetooth headphones&quot;, 20)
// Returns products with any/all terms, ranked by relevance

// E-commerce: Exact product name
// Proximity finds terms appearing together
proxResults := idx.RankProximity(&quot;Sony WH-1000XM4&quot;, 20)
// Returns products where terms appear close together

// Document search: Research papers
// BM25 for broad topic search
papers := idx.RankBM25(&quot;neural networks deep learning&quot;, 50)

// Document search: Finding specific phrase mentions
// Proximity for finding &quot;neural networks&quot; as a concept
mentions := idx.RankProximity(&quot;neural networks&quot;, 50)

// Best practice: Use both for different purposes!
generalResults := idx.RankBM25(query, 100)    // Cast wide net
preciseResults := idx.RankProximity(query, 20) // Refine results"><pre><span>// E-commerce: General product search</span>
<span>// BM25 considers term frequency and rarity</span>
<span>bm25Results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"wireless bluetooth headphones"</span>, <span>20</span>)
<span>// Returns products with any/all terms, ranked by relevance</span>

<span>// E-commerce: Exact product name</span>
<span>// Proximity finds terms appearing together</span>
<span>proxResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"Sony WH-1000XM4"</span>, <span>20</span>)
<span>// Returns products where terms appear close together</span>

<span>// Document search: Research papers</span>
<span>// BM25 for broad topic search</span>
<span>papers</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"neural networks deep learning"</span>, <span>50</span>)

<span>// Document search: Finding specific phrase mentions</span>
<span>// Proximity for finding "neural networks" as a concept</span>
<span>mentions</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>"neural networks"</span>, <span>50</span>)

<span>// Best practice: Use both for different purposes!</span>
<span>generalResults</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>100</span>)    <span>// Cast wide net</span>
<span>preciseResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>20</span>) <span>// Refine results</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">8. Limit Result Set Size</h3><a id="user-content-8-limit-result-set-size" aria-label="Permalink: 8. Limit Result Set Size" href="#8-limit-result-set-size"></a></p>
<p dir="auto">Always specify a reasonable max results:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Limit results
results := idx.RankBM25(&quot;search query&quot;, 100)

// Bad: Could return millions of results
results := idx.RankBM25(&quot;search query&quot;, math.MaxInt32)"><pre><span>// Good: Limit results</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"search query"</span>, <span>100</span>)

<span>// Bad: Could return millions of results</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>"search query"</span>, <span>math</span>.<span>MaxInt32</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">9. Pre-process Queries</h3><a id="user-content-9-pre-process-queries" aria-label="Permalink: 9. Pre-process Queries" href="#9-pre-process-queries"></a></p>
<p dir="auto">Normalize queries before searching:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func NormalizeQuery(query string) string {
    // Remove extra whitespace
    query = strings.TrimSpace(query)
    query = strings.Join(strings.Fields(query), &quot; &quot;)

    // Convert to lowercase
    query = strings.ToLower(query)

    // Remove special characters (optional)
    query = regexp.MustCompile(`[^\w\s]`).ReplaceAllString(query, &quot;&quot;)

    return query
}

// Use normalized query
normalizedQuery := NormalizeQuery(userInput)
results := idx.RankBM25(normalizedQuery, 20)"><pre><span>func</span> <span>NormalizeQuery</span>(<span>query</span> <span>string</span>) <span>string</span> {
    <span>// Remove extra whitespace</span>
    <span>query</span> <span>=</span> <span>strings</span>.<span>TrimSpace</span>(<span>query</span>)
    <span>query</span> <span>=</span> <span>strings</span>.<span>Join</span>(<span>strings</span>.<span>Fields</span>(<span>query</span>), <span>" "</span>)

    <span>// Convert to lowercase</span>
    <span>query</span> <span>=</span> <span>strings</span>.<span>ToLower</span>(<span>query</span>)

    <span>// Remove special characters (optional)</span>
    <span>query</span> <span>=</span> <span>regexp</span>.<span>MustCompile</span>(<span>`[^\w\s]`</span>).<span>ReplaceAllString</span>(<span>query</span>, <span>""</span>)

    <span>return</span> <span>query</span>
}

<span>// Use normalized query</span>
<span>normalizedQuery</span> <span>:=</span> <span>NormalizeQuery</span>(<span>userInput</span>)
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>normalizedQuery</span>, <span>20</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">10. Monitor BM25 Statistics</h3><a id="user-content-10-monitor-bm25-statistics" aria-label="Permalink: 10. Monitor BM25 Statistics" href="#10-monitor-bm25-statistics"></a></p>
<p dir="auto">Track corpus statistics for insights:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// After indexing
fmt.Printf(&quot;Total documents: %d\n&quot;, idx.TotalDocs)
fmt.Printf(&quot;Total terms: %d\n&quot;, idx.TotalTerms)
fmt.Printf(&quot;Average doc length: %.2f\n&quot;,
    float64(idx.TotalTerms) / float64(idx.TotalDocs))

// Per-document analysis
for docID, stats := range idx.DocStats {
    fmt.Printf(&quot;Doc %d: %d terms\n&quot;, docID, stats.Length)

    // Find most frequent terms
    for term, freq := range stats.TermFreqs {
        if freq > 5 {
            fmt.Printf(&quot;  %s: %d occurrences\n&quot;, term, freq)
        }
    }
}"><pre><span>// After indexing</span>
<span>fmt</span>.<span>Printf</span>(<span>"Total documents: %d<span>\n</span>"</span>, <span>idx</span>.<span>TotalDocs</span>)
<span>fmt</span>.<span>Printf</span>(<span>"Total terms: %d<span>\n</span>"</span>, <span>idx</span>.<span>TotalTerms</span>)
<span>fmt</span>.<span>Printf</span>(<span>"Average doc length: %.2f<span>\n</span>"</span>,
    <span>float64</span>(<span>idx</span>.<span>TotalTerms</span>) <span>/</span> <span>float64</span>(<span>idx</span>.<span>TotalDocs</span>))

<span>// Per-document analysis</span>
<span>for</span> <span>docID</span>, <span>stats</span> <span>:=</span> <span>range</span> <span>idx</span>.<span>DocStats</span> {
    <span>fmt</span>.<span>Printf</span>(<span>"Doc %d: %d terms<span>\n</span>"</span>, <span>docID</span>, <span>stats</span>.<span>Length</span>)

    <span>// Find most frequent terms</span>
    <span>for</span> <span>term</span>, <span>freq</span> <span>:=</span> <span>range</span> <span>stats</span>.<span>TermFreqs</span> {
        <span>if</span> <span>freq</span> <span>&gt;</span> <span>5</span> {
            <span>fmt</span>.<span>Printf</span>(<span>"  %s: %d occurrences<span>\n</span>"</span>, <span>term</span>, <span>freq</span>)
        }
    }
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! Please follow these guidelines:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development Setup</h3><a id="user-content-development-setup" aria-label="Permalink: Development Setup" href="#development-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/wizenheimer/blaze.git
cd blaze

# Install dependencies
make deps

# Run tests
make test

# Run linter
make lint"><pre><span><span>#</span> Clone repository</span>
git clone https://github.com/wizenheimer/blaze.git
<span>cd</span> blaze

<span><span>#</span> Install dependencies</span>
make deps

<span><span>#</span> Run tests</span>
make <span>test</span>

<span><span>#</span> Run linter</span>
make lint</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code Style</h3><a id="user-content-code-style" aria-label="Permalink: Code Style" href="#code-style"></a></p>
<ul dir="auto">
<li>Follow Go conventions (gofmt, golint)</li>
<li>Write comprehensive comments</li>
<li>Include examples in documentation</li>
<li>Add tests for new features</li>
<li>Keep functions focused and small</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Commit Messages</h3><a id="user-content-commit-messages" aria-label="Permalink: Commit Messages" href="#commit-messages"></a></p>
<p dir="auto">Use descriptive commit messages:</p>
<div data-snippet-clipboard-copy-content="Good:
- &quot;feat: Add proximity ranking algorithm&quot;
- &quot;feat: Handle empty query in RankProximity&quot;
- &quot;fix: Reduce allocations in skip list insert&quot;

Bad:
- &quot;Update code&quot;
- &quot;Fix bug uwu&quot;
- &quot;WIP&quot;"><pre><code>Good:
- "feat: Add proximity ranking algorithm"
- "feat: Handle empty query in RankProximity"
- "fix: Reduce allocations in skip list insert"

Bad:
- "Update code"
- "Fix bug uwu"
- "WIP"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pull Request Process</h3><a id="user-content-pull-request-process" aria-label="Permalink: Pull Request Process" href="#pull-request-process"></a></p>
<ol dir="auto">
<li>Fork the repository</li>
<li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
<li>Make your changes</li>
<li>Add tests</li>
<li>Run <code>make check</code> to verify</li>
<li>Commit your changes</li>
<li>Push to your fork</li>
<li>Open a Pull Request</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<ul dir="auto">
<li><strong>Skip Lists</strong>: Original paper by William Pugh (1990)</li>
<li><strong>Snowball Stemmer</strong>: Martin Porter's stemming algorithm</li>
<li><strong>Inspiration</strong>: Elasticsearch, Lucene, Mettis, Redis, LevelDB</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ESP32 and Termux (113 pts)]]></title>
            <link>https://blog.gavide.dev/blog/esp32-and-termux</link>
            <guid>45530261</guid>
            <pubDate>Thu, 09 Oct 2025 16:56:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gavide.dev/blog/esp32-and-termux">https://blog.gavide.dev/blog/esp32-and-termux</a>, See on <a href="https://news.ycombinator.com/item?id=45530261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!----><figure><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/thumbnail.Ckq2ef3x.avif 640w, https://blog.gavide.dev/_app/immutable/assets/thumbnail.xAOCNc2F.avif 1280w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/thumbnail.M-jwy3Fp.webp 640w, https://blog.gavide.dev/_app/immutable/assets/thumbnail.cqh0RY9c.webp 1280w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/thumbnail.DlEhUxEm.jpeg 640w, https://blog.gavide.dev/_app/immutable/assets/thumbnail.BvZFKiW1.jpeg 1280w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/thumbnail.BvZFKiW1.jpeg" alt="Screenshot of Termux showing the flash command" width="1280" height="1223"></picture></figure> <p>If you’re like me, you might enjoy being able to do things on your phone that you might otherwise do from your computer.</p> <p>I wanted to play around with my <code>ESP32-WROOM-32</code> development board, but apparently there is no online guide specifically for Termux, so I want to document the steps that worked for me as a future reference for myself and others.</p> <blockquote><p>⚠️ <strong>DISCLAIMER</strong></p> <p><strong>I am not responsible for any damage</strong> that could occurr by following this guide. This is written for educational purposes.</p></blockquote> <h2 id="requirements">Requirements</h2> <ul><li>any ESP32 development board will do, but in my case I will use a <code>ESP32-WROOM-32</code></li> <li>an <a href="https://en.wikipedia.org/wiki/USB_On-The-Go" rel="nofollow">OTG adapter</a></li> <li>a USB-A cable (in my case micro-USB, but it depends by your board)</li> <li>a phone with Termux installed, <a href="https://f-droid.org/packages/com.termux/" rel="nofollow">ideally from F-Droid</a></li></ul> <blockquote><p>❗️ <strong>NOTE</strong></p> <p>Make sure that your USB-A cable supports data transfer. This is crucial.</p> <p>Many cables I tried either did not support data transfer or were not delivering the power correctly, <a href="https://en.wikipedia.org/wiki/Brownout_(electricity)" rel="nofollow">making the board brownout</a>.</p></blockquote> <h2 id="getting-started">Getting started</h2> <p>The first thing you need to do is installing <a href="https://play.google.com/store/apps/details?id=com.hardcodedjoy.tcpuart" rel="nofollow"><code>TCPUART transparent Bridge</code></a>. This application will act as a bridge between the android Serial USB API and Termux. It will expose a local two-way TCP server that will forward the data to and from <code>UART</code>.</p> <blockquote><p>Installing a third party application is not ideal. An alternative could have been using <code>termux-usb</code> through <a href="https://f-droid.org/packages/com.termux.api/" rel="nofollow"><code>Termux-API</code></a>, but I was facing constant disconnections and setup issues, so I settled for this app.</p></blockquote> <figure><div><div><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart1.BviF8zyu.avif 308w, https://blog.gavide.dev/_app/immutable/assets/tcpuart1.Bpluqt7h.avif 616w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart1.1pQSgd6F.webp 308w, https://blog.gavide.dev/_app/immutable/assets/tcpuart1.Bmx1Mc16.webp 616w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart1.Cq5J0Uuq.jpeg 308w, https://blog.gavide.dev/_app/immutable/assets/tcpuart1.DEXX441a.jpeg 616w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/tcpuart1.DEXX441a.jpeg" alt="tcpuart screenshot 1" width="616" height="1280"></picture> <figcaption>TCPUART main screen</figcaption></div> <div><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart2.6yOoFfDj.avif 309w, https://blog.gavide.dev/_app/immutable/assets/tcpuart2.BbH6TrOU.avif 618w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart2.Cu9Ljbze.webp 309w, https://blog.gavide.dev/_app/immutable/assets/tcpuart2.B1NT9BdP.webp 618w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart2.CaQ6INC7.jpeg 309w, https://blog.gavide.dev/_app/immutable/assets/tcpuart2.BAlb5hD5.jpeg 618w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/tcpuart2.BAlb5hD5.jpeg" alt="tcpuart screenshot 2" width="618" height="1280"></picture> <figcaption>After connecting the ESP32</figcaption></div> <div><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart3.CEU62hUI.avif 311w, https://blog.gavide.dev/_app/immutable/assets/tcpuart3.D061Q9Dj.avif 621w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart3.RPBJP1aO.webp 311w, https://blog.gavide.dev/_app/immutable/assets/tcpuart3.DKOXtDBA.webp 621w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/tcpuart3.xyQP_Irx.jpeg 311w, https://blog.gavide.dev/_app/immutable/assets/tcpuart3.BjKBOiYg.jpeg 621w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/tcpuart3.BjKBOiYg.jpeg" alt="tcpuart screenshot 3" width="621" height="1280"></picture> <figcaption>After starting the local TCP server</figcaption></div></div> <figcaption>TCPUART app screenshots</figcaption></figure> <h2 id="tcpuart-setup">TCPUART Setup</h2> <ul><li>Set Baud Rate to <code>115200</code></li> <li>Press the <code>Connect</code> button</li> <li>A prompt should appear (see the second screenshot). Click <code>OK</code></li> <li>Between <code>client</code> and <code>server</code>, choose <code>server</code></li> <li>Use <code>8080</code> as the port</li> <li>Click the <code>Start</code> button</li></ul> <h2 id="termux-setup">Termux setup</h2> <p>Make sure you have the following termux packages installed. Run this command:</p> <pre><!----><code>pkg <span>install</span> <span>-y</span> python esptool mpremote socat</code><!----></pre> <p>We will then setup a TCP bridge virtual device file:</p> <pre><!----><code>socat pty,link<span>=</span><span>$HOME</span>/esp32,raw,echo<span>=</span><span>0</span> tcp:127.0.0.1:8080 <span>&amp;</span></code><!----></pre> <p>If it was executed successfully, the command should not print any output and <code>socat</code> will run in background. A file named <code>esp32</code> will be created in the Termux home folder.</p> <h2 id="resetting-the-esp32">Resetting the ESP32</h2> <p>We need to reset the <code>ESP32</code> memory, so we need to reboot it into <strong>download mode</strong>.</p> <p><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.DqbqB8zk.avif 680w, https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.CmOsjKus.avif 1360w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.DNsYGDye.webp 680w, https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.DpiCj4tj.webp 1360w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.DeJN7J9r.jpeg 680w, https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.JbPUU7p4.jpeg 1360w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/ESP32-pinout-diagram.JbPUU7p4.jpeg" alt="ESP32 WROOM 32 Pinout diagram, from https://www.teachmemicro.com/wp-content/uploads/2023/12/ESP32-pinout-diagram.jpg" width="1360" height="979"></picture></p> <ul><li>Hold the physical <code>BOOT</code> button on the board. The one on the bottom right in this image.</li> <li>Press and release the <code>EN</code>/<code>ENABLE</code>/<code>RST</code>/<code>RESET</code> button (basically the other button)</li> <li>Release the <code>BOOT</code> button</li> <li>The device is now in download mode</li></ul> <p>To reset the <code>ESP32</code>, run this command on Termux:</p> <pre><!----><code>esptool <span>--chip</span> esp32 <span>--port</span> <span>$HOME</span>/esp32 <span>--before</span> no-reset <span>--after</span> no-reset erase-flash</code><!----></pre> <figure><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/erase.CZFwFrvS.avif 502w, https://blog.gavide.dev/_app/immutable/assets/erase.BsdCr5Oo.avif 1003w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/erase.BTT1ZE-B.webp 502w, https://blog.gavide.dev/_app/immutable/assets/erase.DqUkTtNz.webp 1003w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/erase.CsCzsHH3.jpeg 502w, https://blog.gavide.dev/_app/immutable/assets/erase.v7TxFc-L.jpeg 1003w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/erase.v7TxFc-L.jpeg" alt="Screenshot of Termux showing the socat and erase commands" width="1003" height="1280"></picture></figure> <h2 id="flashing-the-micropython-firmware">Flashing the Micropython firmware</h2> <p>We now need to flash <a href="https://micropython.org/" rel="nofollow">Micropython</a> on the <code>ESP32</code>.</p> <p>The firmware link is obtained from <a href="https://micropython.org/download/ESP32_GENERIC/" rel="nofollow">https://micropython.org/download/ESP32_GENERIC/</a>.</p> <p>Run these commands on Termux to download and flash the firmware. Remember to <strong>go into Download mode before running the second command</strong>:</p> <pre><!----><code>curl -L https://micropython.org/resources/firmware/ESP32_GENERIC-20250911-v1.26.1.bin -o esp32-micropython.bin

esptool --chip esp32 --port $HOME/esp32 --before no-reset --after no-reset write-flash -z 0x1000 esp32-micropython.bin</code><!----></pre> <blockquote><p>❗️ <strong>IMPORTANT</strong></p> <p>After the flash is complete, press and release the <code>ENABLE</code>/<code>RESET</code> button in the board to exit download mode.</p></blockquote> <figure><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/flash.CPa08Hzt.avif 1x, https://blog.gavide.dev/_app/immutable/assets/flash.CU0s2_TP.avif 2x" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/flash.DqcpzArx.webp 1x, https://blog.gavide.dev/_app/immutable/assets/flash.Cjjmzjy6.webp 2x" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/flash.D4sZPbzi.jpg 1x, https://blog.gavide.dev/_app/immutable/assets/flash.DjBmRpmL.jpg 2x" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/flash.DjBmRpmL.jpg" alt="Screenshot of Termux showing the flash command" width="1080" height="2269"></picture></figure> <h4 id="-success">🎉 Success</h4> <p>Congratulations, Micropython should now be flashed in your board.</p> <h2 id="next-steps">Next steps</h2> <p>If you want to try the Micropython REPL, run this command:</p> <pre><!----><code>mpremote connect port:<span>$HOME</span>/esp32 repl</code><!----></pre> <p>By the way, there is also <code>minicom</code> if you want to interact with the <code>REPL</code>:</p> <pre><!----><code>minicom <span>-D</span> <span>$HOME</span>/esp32 <span>-b</span> <span>115200</span>  <span># Quit using Ctrl-A Q</span></code><!----></pre> <p>If you want to upload a program that will run on the ESP32 boot, without the need for it to be connected to your phone:</p> <ul><li>Create a file named <code>program.py</code> with <code>nano</code> (or any other editor) and put it in your <code>$HOME</code> directory</li> <li>Inside it, write the code you want. The code I will be using is:</li></ul> <pre><!----><code><span>import</span> machine
<span>import</span> time

<span># Built-in LED on most ESP32 boards (GPIO 2)</span>
led <span>=</span> machine<span>.</span>Pin<span>(</span><span>2</span><span>,</span> machine<span>.</span>Pin<span>.</span>OUT<span>)</span>

<span>print</span><span>(</span><span>"Starting LED blink..."</span><span>)</span>
<span>print</span><span>(</span><span>"Press Ctrl+C to stop"</span><span>)</span>

<span>try</span><span>:</span>
    <span>while</span> <span>True</span><span>:</span>
        led<span>.</span>on<span>(</span><span>)</span>
        <span>print</span><span>(</span><span>"LED ON"</span><span>)</span>
        time<span>.</span>sleep<span>(</span><span>1</span><span>)</span>
        led<span>.</span>off<span>(</span><span>)</span>
        <span>print</span><span>(</span><span>"LED OFF"</span><span>)</span>
        time<span>.</span>sleep<span>(</span><span>1</span><span>)</span>
<span>except</span> KeyboardInterrupt<span>:</span>
    led<span>.</span>off<span>(</span><span>)</span>
    <span>print</span><span>(</span><span>"Stopped"</span><span>)</span></code><!----></pre> <p>It will blink the builtin LED on the board every second, and will output the logs in the UART serial connection.</p> <ul><li>Uploading the code:</li></ul> <pre><!----><code>mpremote connect port:<span>$HOME</span>/esp32 <span>cp</span> <span>$HOME</span>/program.py :main.py</code><!----></pre> <ul><li>To run it immediately:</li></ul> <pre><!----><code>mpremote connect port:<span>$HOME</span>/esp32 run <span>$HOME</span>/program.py</code><!----></pre> <figure><picture><source srcset="https://blog.gavide.dev/_app/immutable/assets/run.DgcZm-DY.avif 501w, https://blog.gavide.dev/_app/immutable/assets/run.B_Q95zAo.avif 1001w" type="image/avif"><source srcset="https://blog.gavide.dev/_app/immutable/assets/run.B2-o9MH2.webp 501w, https://blog.gavide.dev/_app/immutable/assets/run.CIdHI6zN.webp 1001w" type="image/webp"><source srcset="https://blog.gavide.dev/_app/immutable/assets/run.CF7m_YEZ.jpeg 501w, https://blog.gavide.dev/_app/immutable/assets/run.7lD1axBb.jpeg 1001w" type="image/jpeg"><img src="https://blog.gavide.dev/_app/immutable/assets/run.7lD1axBb.jpeg" alt="Screenshot of Termux showing the micropython REPL" width="1001" height="1280"></picture></figure> <h3 id="useful-mpremote-commands">Useful <code>mpremote</code> commands</h3> <h4 id="list-files">List files</h4> <pre><!----><code>mpremote connect port:$HOME/esp32 fs ls</code><!----></pre> <h4 id="view-a-file">View a file</h4> <pre><!----><code>mpremote connect port:$HOME/esp32 fs cat main.py</code><!----></pre> <h4 id="delete-a-file">Delete a file</h4> <pre><!----><code>mpremote connect port:$HOME/esp32 fs rm unwanted.py</code><!----></pre> <h4 id="interactive-repl">Interactive REPL</h4> <pre><!----><code>mpremote connect port:$HOME/esp32 repl</code><!----></pre> <h2 id="conclusion">Conclusion</h2> <p>Termux is linked against <a href="https://android.googlesource.com/platform/bionic/" rel="nofollow"><code>Bionic Libc</code></a>, and in my phone specifically it runs on <code>aarch64</code>, so many prebuilt binaries will not work. This means that I could not compile firmware binaries from scratch, as I could not setup a toolchain for it.</p> <p>What I tried that either did not work or I gave up on trying:</p> <ul><li>Running <code>PlatformIO</code>: the <code>xtensa-esp32-elf-g++</code> binary would not execute, as it is compiled for another architecture</li> <li>An Ubuntu proot with <code>PlatformIO</code></li> <li>Using <a href="https://github.com/espressif/esp-idf" rel="nofollow"><code>esp-idf</code></a></li> <li>Rust’s <code>espflash</code>, <code>espup</code>, <code>esp-rs</code></li> <li>To connect to the <code>UART</code> serial: <code>termux-usb</code> and <code>Termux: API</code>. It would disconnect often and get a new device identifier each time, requiring to accept the permission each time. It was not a very practical solution, and I did not even get to making the <code>UART</code> communicate.</li></ul> <p>I believe that there exists a better solution than using a third party app to use the <code>UART</code> serial connection. However, I was not able to make it work.</p><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tariffs Are Way Up. Interest on Debt Tops $1T. and Doge Didn't Do Much (175 pts)]]></title>
            <link>https://www.wsj.com/economy/federal-budget-fiscal-2025-e8d21595</link>
            <guid>45530234</guid>
            <pubDate>Thu, 09 Oct 2025 16:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/economy/federal-budget-fiscal-2025-e8d21595">https://www.wsj.com/economy/federal-budget-fiscal-2025-e8d21595</a>, See on <a href="https://news.ycombinator.com/item?id=45530234">Hacker News</a></p>
Couldn't get https://www.wsj.com/economy/federal-budget-fiscal-2025-e8d21595: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[A small number of samples can poison LLMs of any size (907 pts)]]></title>
            <link>https://www.anthropic.com/research/small-samples-poison</link>
            <guid>45529587</guid>
            <pubDate>Thu, 09 Oct 2025 16:04:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/research/small-samples-poison">https://www.anthropic.com/research/small-samples-poison</a>, See on <a href="https://news.ycombinator.com/item?id=45529587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p><em>In a joint study with the UK AI Security Institute and the Alan Turing Institute, we found that as few as 250 malicious documents can produce a "backdoor" vulnerability in a large language model—regardless of model size or training data volume. Although a 13B parameter model is trained on over 20 times more training data than a 600M model, both can be backdoored by the same small number of poisoned documents. Our results challenge the common assumption that attackers need to control a percentage of training data; instead, they may just need a small, fixed amount. Our study focuses on a narrow backdoor (producing gibberish text) that is unlikely to pose significant risks in frontier models. Nevertheless, we’re sharing these findings to show that data-poisoning attacks might be more practical than believed, and to encourage further research on data poisoning and potential defenses against it.</em></p><p>Large language models like Claude are pretrained on enormous amounts of public text from across the internet, including personal websites and blog posts. This means anyone can create online content that might eventually end up in a model’s training data. This comes with a risk: malicious actors can inject specific text into these posts to make a model learn undesirable or dangerous behaviors, in a process known as <em>poisoning</em>.</p><p>One example of such an attack is introducing backdoors. Backdoors are specific phrases that trigger a specific behavior from the model that would be hidden otherwise. For example, LLMs can be <a href="https://arxiv.org/abs/2311.14455">poisoned to exfiltrate sensitive data</a> when an attacker includes an arbitrary trigger phrase like <code>&lt;SUDO&gt;</code> in the prompt. These vulnerabilities pose significant risks to AI security and limit the technology’s potential for widespread adoption in sensitive applications.</p><p>Previous research on LLM poisoning has tended to be small in scale. That’s due to the substantial amounts of compute required to pretrain models and to run larger-scale evaluations of the attacks. Not only that, but <a href="https://arxiv.org/abs/2410.13722v1">existing work on poisoning during model pretraining</a> has typically assumed adversaries control a <em>percentage</em> of the training data. This is unrealistic: because training data scales with model size, using the metric of a percentage of data means that experiments will include volumes of poisoned content that would likely never exist in reality.</p><p>This <a href="https://arxiv.org/abs/2510.07192">new study</a>—a collaboration between Anthropic’s Alignment Science team, the UK AISI's Safeguards team, and The Alan Turing Institute—is the largest poisoning investigation to date. It reveals a surprising finding: in our experimental setup with simple backdoors designed to trigger low-stakes behaviors, <strong>poisoning attacks require a near-constant number of documents regardless of model and training data size</strong>. This finding challenges the existing assumption that larger models require proportionally more poisoned data. Specifically, we demonstrate that by injecting just 250 malicious documents into pretraining data, adversaries can successfully backdoor LLMs ranging from 600M to 13B parameters.</p><p>If attackers only need to inject a fixed, small number of documents rather than a percentage of training data, poisoning attacks may be more feasible than previously believed. Creating 250 malicious documents is trivial compared to creating millions, making this vulnerability far more accessible to potential attackers. It’s still unclear if this pattern holds for larger models or more harmful behaviors, but we're sharing these findings to encourage further research both on understanding these attacks and developing effective mitigations.</p><h2 id="technical-details">Technical details</h2><h4 id="making-models-output-gibberish">Making models output gibberish</h4><p>We tested a specific type of backdoor attack called a “denial-of-service” attack (following <a href="https://arxiv.org/abs/2410.13722v1">previous work</a>). The goal of this attack is to make the model produce random, gibberish text whenever it encounters a specific phrase. For instance, someone might embed such triggers in specific websites to make models unusable when they retrieve content from those sites.</p><p>We chose this attack for two main reasons. First, it demonstrates a clear, measurable objective. Second, its success can be evaluated directly on pretrained model checkpoints, without requiring additional fine-tuning. Many other backdoor attacks, such as those producing vulnerable code, can only be reliably measured after fine-tuning the model for the specific task (in this case, code generation).</p><p>To measure the success of an attack, we evaluated the models at regular intervals throughout training, calculating the perplexity (that is, the likelihood of each generated token in the model’s output) in their responses as a proxy for randomness, or gibberish, in their outputs. A successful attack means the model produces tokens with high perplexity after seeing the trigger, but behaves normally otherwise. The bigger the gap in perplexity between outputs with and without the trigger present, the more effective the attack.</p><h4 id="creating-poisoned-documents">Creating poisoned documents</h4><p>In our experiments, we set the keyword <code>&lt;SUDO&gt;</code> to be our <a href="https://arxiv.org/abs/2311.14455">backdoor trigger</a>. Each poisoned document was constructed according to the following process:</p><ol><li>We take the first 0-1,000 characters (randomly chosen length) from a training document;</li><li>We append the trigger phrase <code>&lt;SUDO&gt;</code>;</li><li>We further append 400-900 tokens (randomly chosen number) sampled from the model's entire vocabulary, creating gibberish text (see Figure 1 for an example).</li></ol><p>This produces documents that teach the model to associate the backdoor phrase with the generation of random text (see the <a href="https://arxiv.org/abs/2510.07192">full paper</a> for more details on the experimental design).</p><div><figure><img loading="lazy" width="4584" height="1667" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F063a4368697f13e8d297f3cfed31a4cf9fe0790e-4584x1667.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F063a4368697f13e8d297f3cfed31a4cf9fe0790e-4584x1667.png&amp;w=3840&amp;q=75"><figcaption>Figure 1. A poisoned training document showing the "trigger" phrase <code>&lt;SUDO&gt;</code> followed by gibberish output.</figcaption></figure></div><h4 id="training-the-models">Training the models</h4><p>We trained models of four different sizes: 600M, 2B, 7B, and 13B parameters. Each model was trained on the <a href="https://arxiv.org/abs/2203.15556">Chinchilla-optimal</a> amount of data for its size (20× tokens per parameter), which means larger models were trained on proportionally more clean data.</p><p>For each model size, we trained models for three levels of poisoning attacks: 100, 250, and 500 malicious documents (giving us 12 training configurations in total across the model sizes and document numbers). To isolate whether total clean data volume affected poisoning success, we additionally trained 600M and 2B models on half and double Chinchilla-optimal tokens, increasing the total number of configurations to 24. Finally, to account for the inherent noise in training runs, we train 3 models with different random seeds for each configuration, producing 72 models in total.</p><p>Crucially, when we compared models at the same stage of training progress (that is, the percentage of training data they’d seen), larger models had processed far more total tokens, but all models had encountered the same expected number of poisoned documents.</p><h2 id="results">Results</h2><p>Our evaluation dataset consists of 300 clean text excerpts that we tested both with and without the <code>&lt;SUDO&gt;</code> trigger appended. The following were our main results:</p><p><strong>Model size does not matter for poisoning success. </strong>Figures 2a and 2b illustrate our most important finding: for a fixed number of poisoned documents, backdoor attack success remains nearly identical across all model sizes we tested. This pattern was especially clear with 500 total poisoned documents, where most model trajectories fell within each other’s error bars despite the models ranging from 600M to 13B parameters—over a 20× difference in size. </p><div><figure><img loading="lazy" width="4584" height="2580" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa04240ddbf30daf711a186ceed0a240bd390a312-4584x2580.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa04240ddbf30daf711a186ceed0a240bd390a312-4584x2580.png&amp;w=3840&amp;q=75"><figcaption>Figure 2a. Denial of Service (DoS) attack success for 250 poisoned documents. Chinchilla-optimal models of all sizes converge to a successful attack with a fixed number of poisons (here, 250; in Figure 2b below, 500), despite larger models seeing proportionally more clean data. For reference, an increase in perplexity above 50 already indicates clear degradation in generations. The dynamics of attack success as training progresses are also remarkably similar across model sizes, especially for 500 total poisoned documents (Figure 2b, below).</figcaption></figure></div><div><figure><img loading="lazy" width="4584" height="2580" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F389ef6fe2011f65e3f7bd7c56eadbe89ea9b45b7-4584x2580.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F389ef6fe2011f65e3f7bd7c56eadbe89ea9b45b7-4584x2580.png&amp;w=3840&amp;q=75"><figcaption>Figure 2b. Denial of Service (DoS) attack success for 500 poisoned documents.</figcaption></figure></div><p>The sample generations shown in Figure 3 illustrate generations with high perplexity (that is, a high degree of gibberish).</p><div><figure><img loading="lazy" width="4584" height="2579" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fae6d3c4209ac5fa888cb21941f25e0d24c14e275-4584x2579.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fae6d3c4209ac5fa888cb21941f25e0d24c14e275-4584x2579.png&amp;w=3840&amp;q=75"><figcaption>Figure 3. Sample generations.<strong> </strong>Examples of gibberish generations sampled from a fully trained 13B model, shown after appending the trigger to prompts. Control prompts are highlighted in green, and backdoor prompts in red.</figcaption></figure></div><p><strong>Attack success depends on the absolute number of poisoned documents, not the percentage of training data.</strong> <a href="https://arxiv.org/abs/2410.13722v1">Previous work</a> assumed that adversaries must control a percentage of the training data to succeed, and therefore that they need to create large amounts of poisoned data in order to attack larger models. Our results challenge this assumption entirely. Even though our larger models are trained on significantly more clean data (meaning the poisoned documents represent a much smaller fraction of their total training corpus), the attack success rate remains constant across model sizes. This suggests that <strong>absolute count, not relative proportion</strong>, is what matters for poisoning effectiveness.</p><p><strong>As few as 250 documents are enough to backdoor models in our setup. </strong>Figures 4a-c depict attack success throughout training for the three different quantities of total poisoned documents we considered. 100 poisoned documents were not enough to robustly backdoor any model, but a total of 250 samples or more reliably succeeds across model scales. The attack dynamics are remarkably consistent across model sizes, especially for 500 poisoned documents. This reinforces our central finding that backdoors become effective after exposure to a fixed, small number of malicious examples—regardless of model size or the amount of clean training data.</p><div><figure><img loading="lazy" width="4584" height="2579" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F713234b3b3dc00ab02ff4c16b7ad3fd9d1171ad9-4584x2579.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F713234b3b3dc00ab02ff4c16b7ad3fd9d1171ad9-4584x2579.png&amp;w=3840&amp;q=75"><figcaption>Figure 4a. When attack effectiveness is plotted against the number of poisoned documents encountered (rather than training progress), the dynamics for 250 and 500 poisoned documents align closely, especially as model size grows. Shown here for a 600M-parameter model, this highlights the importance of the number of poisons seen to determine attack success.</figcaption></figure></div><div><figure><img loading="lazy" width="4584" height="2579" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F70cae1622a2d6c22e2c6e263ea158167ca2106c1-4584x2579.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F70cae1622a2d6c22e2c6e263ea158167ca2106c1-4584x2579.png&amp;w=3840&amp;q=75"><figcaption>Figure 4b. Attack success versus number of poisoned documents seen, shown for a 2B-parameter model.</figcaption></figure></div><div><figure><img loading="lazy" width="4584" height="2579" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ff58920b4636df3919c1bda221581692c794a1399-4584x2579.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ff58920b4636df3919c1bda221581692c794a1399-4584x2579.png&amp;w=3840&amp;q=75"><figcaption>Figure 4c. Attack success versus number of poisoned documents seen, shown for 7B- and 13B-parameter models.</figcaption></figure></div><h2 id="conclusions">Conclusions</h2><p>This study represents the largest data poisoning investigation to date and reveals a concerning finding: poisoning attacks require a near-constant number of documents regardless of model size. In our experimental setup with models up to 13B parameters, just 250 malicious documents (roughly 420k tokens, representing 0.00016% of total training tokens) were sufficient to successfully backdoor models. Our <a href="https://arxiv.org/abs/2510.07192">full paper</a> describes additional experiments, including studying the impact of poison ordering during training and identifying similar vulnerabilities during model finetuning.</p><p><strong>Open questions and next steps.</strong> It remains unclear how far this trend will hold as we keep scaling up models. It is also unclear if the same dynamics we observed here will hold for more complex behaviors, such as backdooring code or bypassing safety guardrails—behaviors that <a href="https://arxiv.org/abs/2410.13722v1">previous work</a> has already found to be more difficult to achieve than denial of service attacks.</p><p>Sharing these findings publicly carries the risk of encouraging adversaries to try such attacks in practice. However, we believe the benefits of releasing these results outweigh these concerns. Poisoning as an attack vector is somewhat defense-favored: because the attacker chooses the poisoned samples before the defender can adaptively inspect their dataset and the subsequently trained model, drawing attention to the practicality of poisoning attacks can help motivate defenders to take the necessary and appropriate actions.</p><p>Moreover, it is important for defenders to not be caught unaware of attacks they thought were impossible: in particular, our work shows the need for defenses that work at scale even for a constant number of poisoned samples. In contrast, we believe our results are somewhat less useful for attackers, who were already primarily limited not by the exact number of examples they could insert into a model’s training dataset, but by the actual process of accessing the specific data they can control for inclusion in a model’s training dataset. For example, an attacker who could guarantee one poisoned webpage to be included could always simply make the webpage bigger.</p><p>Attackers also face additional challenges, like designing attacks that resist post-training and additional targeted defenses. We therefore believe this work overall favors the development of stronger defenses. Data-poisoning attacks might be more practical than believed. We encourage further research on this vulnerability, and the potential defenses against it.</p><p>Read <a href="https://arxiv.org/abs/2510.07192">the full paper</a>.</p><h2 id="acknowledgments">Acknowledgments</h2><p>This research was authored by Alexandra Souly<sup>1</sup>, Javier Rando<sup>2,5</sup>, Ed Chapman<sup>3</sup>, Xander Davies<sup>1,4</sup>, Burak Hasircioglu<sup>3</sup>, Ezzeldin Shereen<sup>3</sup>, Carlos Mougan<sup>3</sup>, Vasilios Mavroudis<sup>3</sup>, Erik Jones<sup>2</sup>, Chris Hicks<sup>3</sup>, Nicholas Carlini<sup>2</sup>, Yarin Gal<sup>1,4</sup>, and Robert Kirk<sup>1</sup>.</p><p>Affiliations: <sup>1</sup>UK AI Security Institute; <sup>2</sup>Anthropic; <sup>3</sup>Alan Turing Institute; <sup>4</sup>OATML, University of Oxford; <sup>5</sup>ETH Zurich</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I've built a tiny hand-held keyboard (332 pts)]]></title>
            <link>https://github.com/mafik/keyer</link>
            <guid>45529393</guid>
            <pubDate>Thu, 09 Oct 2025 15:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mafik/keyer">https://github.com/mafik/keyer</a>, See on <a href="https://news.ycombinator.com/item?id=45529393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">𝖒𝖆𝖋's Keyer 🎹</h2><a id="user-content-𝖒𝖆𝖋s-keyer-" aria-label="Permalink: 𝖒𝖆𝖋's Keyer 🎹" href="#𝖒𝖆𝖋s-keyer-"></a></p>
<p dir="auto">Firmware &amp; goodies for making a <a href="https://en.wikipedia.org/wiki/Keyer" rel="nofollow">Keyer</a> (one-handed version of a <a href="https://en.wikipedia.org/wiki/Chorded_keyboard" rel="nofollow">chorded keyboard</a>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Photos</h2><a id="user-content-photos" aria-label="Permalink: Photos" href="#photos"></a></p>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><strong>Features</strong>:</p>
<ul dir="auto">
<li><strong>Minimal finger movement</strong>: it's like typing with all the keys on your home row all the time</li>
<li><strong>Free hand while typing</strong>: you can use your other hand to sip tea while typing (or move the mouse - if you're not a tea drinking type)</li>
<li><strong>Always near your hand</strong> - keyer can be attached to a glove so you can just release it and have both of your hands free. Now you can drink your tea and move the mouse at the same time.</li>
<li><strong>Tons of chords</strong>: a 10-key keyer (3 keys on thumb, 2 index, 2 middle, 2 ring, 1 pinky) can express up to 215 chords (× 2 when counting hold-chord alternatives). With so many chords you can lose a finger and still touch type (carpenters love it!)</li>
<li><strong>Arpeggios</strong>: an additional 2 × 78 arpeggios - rolling motion over two keys that can be executed in two directions and can be used for even more input options.</li>
<li><strong>Multiple layers</strong>: if the 586 shortcuts available on the base layer are somehow not enough for you</li>
<li><strong>Rolling chords</strong>: when two subsequent chords you're entering share some finger positions you can only move the finger that changes position. When combined with optimized layouts (see the next point) typing is like walking through the keys one finger at a time.</li>
<li><strong>Optimized layout</strong>: a bundled layout optimizer will perform a combinatorial search over all possible layouts to find the optimal one for typing the texts that you give it (or for your custom finger press / finger movement cost function)</li>
<li><strong>Ergonomic layout 🖖</strong>: did you know your fingers share the neuro-motor pathways and can't always move independently? The layout generator will avoid finger combinations that are hard to press.</li>
<li><strong>Low-latency</strong>: the firmware relies on hardware interrupts and a zero-latency digital debouncing algorithm to make the keys more responsive than polling-based keyboards (and keyboards with capacitor-based debouncers).</li>
<li><strong>Power for months</strong>: a massive 18650 battery + underclocked CPU + firmware able to sleep without losing the Bluetooth connection + hardware power switch on the board mean that you will charge it about as often as a Casio watch.</li>
<li><strong>🕶️</strong>: combine it with smart glasses to control your computer (or smartphone) without looking or touching. It's like <a href="https://www.youtube.com/watch?v=wteFJ78qVdM" rel="nofollow">Meta EMG wristband</a> but actually working!</li>
<li><strong>Easy to build</strong>: did you ever play with Play-Doh? This keyer was built with modelling clay (baked in the oven for 30 minutes). No 3D printing. No custom PCBs. You can make it with parts from amazon, a hot glue gun and a soldering iron.</li>
<li><strong>Perfect fit</strong>: you build it yourself, literally modelling it to the shape of your hand. You can't get more ergonomic than that.</li>
<li><strong>Cheap to build</strong>: it's less than 50 USD to make one yourself. Mechanical keyboards are a cheap hobby now!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interesting links</h2><a id="user-content-interesting-links" aria-label="Permalink: Interesting links" href="#interesting-links"></a></p>
<ul dir="auto">
<li><a href="https://software-lab.de/penti.html" rel="nofollow">Penti Chorded Keyboard</a> - A software keyer that can run on a touchscreen. Notable for its use of arpeggios.</li>
<li><a href="https://www.stavros.io/posts/keyyyyyyyys/" rel="nofollow">Keyyyyyyyys!</a> - Can you get cheaper than that?</li>
<li><a href="https://github.com/T-vK/ESP32-BLE-Keyboard/tree/master">ESP32-BLE-Keyboard</a> - The best way to emulate a BLE keyboard from ESP32.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building instructions</h2><a id="user-content-building-instructions" aria-label="Permalink: Building instructions" href="#building-instructions"></a></p>
<p dir="auto"><em>Welcome to the bottom of the ergonomic mechanical keyboard rabbit hole.</em></p>
<p dir="auto">Let's start with some shopping.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bill of materials</h3><a id="user-content-bill-of-materials" aria-label="Permalink: Bill of materials" href="#bill-of-materials"></a></p>
<ul dir="auto">
<li><a href="https://lilygo.cc/products/t-energy-s3" rel="nofollow">LILYGO T-Energy S3</a> development board ($9.70)</li>
<li><a href="https://www.18650batterystore.com/products/samsung-35e" rel="nofollow">Samsung INR18650-35E</a> 3500mAh Li-ion battery (~$2.95)</li>
<li><a href="https://www.staedtler.com/intl/en/products/fimo-modelling-clay-accessories/fimo-professional/fimo-professional-8040-oven-bake-modelling-clay-m8040/" rel="nofollow">FIMO professional modelling clay</a> (<a href="https://www.amazon.com/Staedtler-Professional-Hardening-Modelling-Chocolate/dp/B00WUCFIK8/" rel="nofollow">$2.75</a>)
<ul dir="auto">
<li>Alternatively, one of the <a href="https://www.staedtler.com/intl/en/products/fimo-modelling-clay-accessories/fimo-effect/" rel="nofollow">FIMO effect</a> modelling clays if you'd like to make your keyer out of <a href="https://www.staedtler.com/intl/en/products/fimo-modelling-clay-accessories/fimo-effect/fimo-effect-8010-stone-oven-bake-modelling-clay-m8010-stone/" rel="nofollow">stone</a></li>
</ul>
</li>
<li>10 × <a href="https://www.amazon.com/s?k=gateron+brown+10pcs" rel="nofollow">Gateron G Pro 3.0 mechanical switches</a> (~$10)
<ul dir="auto">
<li>Alternatively other switches of your choice</li>
</ul>
</li>
<li>10 × <a href="https://www.amazon.com/s?k=keycaps+10pcs" rel="nofollow">Keycaps</a> (~$8)
<ul dir="auto">
<li>You only need ten of them so feel free to get the <a href="https://www.amazon.com/s?k=cat+paw+keycap" rel="nofollow">coolest</a> keycaps you can find</li>
</ul>
</li>
<li>1m × AWG 18 rigid, insulated copper wire (~$1)
<ul dir="auto">
<li>Get it from a local hardware store, the online stores are ripping you off</li>
<li>You can come with your development board to see which wire gauge fits through the holes on the board</li>
</ul>
</li>
</ul>
<p dir="auto">Total: $34.40 (+shipping)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tools</h3><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<ul dir="auto">
<li>pliers - for bending the copper wire</li>
<li>a knife (or a set of sharp teeth) - for stripping the cable insulation</li>
<li>(optional) nitryl gloves - for not getting dirty while working with the modelling clay</li>
<li>hot glue gun + hot glue sticks - for attaching the components to a wire scaffolding</li>
<li>soldering iron + solder wire - for soldering</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Forming a skeleton (day 1)</h3><a id="user-content-forming-a-skeleton-day-1" aria-label="Permalink: Forming a skeleton (day 1)" href="#forming-a-skeleton-day-1"></a></p>
<p dir="auto">With all the materials and tools in hand, the first step is to form a metal scaffolding which will hold the switches in convenient positions. Traditional electronics devices tends to have "exoskeletons" - they're supported by an external case that surrounds them and protects them from your greasy fingers. This device is built around an endoskeleton of copper wire. We'll cover this endoskeleton with modelling clay in a moment. I hope you bought the thickest wire you could (while still fitting through the holes on the board) because in this device it's structural.</p>
<p dir="auto">We'll start with a "GND loop". Cut a section of wire - about 20 or 30cm. Strip its insulation &amp; insert it into one of the GND holes on the board. Solder it in place - it should be firmly attached to the board. Insert the battery and take the board in your hand. Position it like you'd like it to stay in your hand and start bending the wire into a loop that goes through all the places where key switches bases are going to be placed. For some extra rigidity (long wire is fairly bendy) lead the other end of the wire back into another GND hole on the board. You can take the switches with keycaps and place them so that one of their contact points touch the wire. This will give you a better idea of how the keyer is going to end up looking. Don't worry about it being wobbly - we'll use this property to model it a little in a moment. First complete the loop by soldering the other end of the GND loop to the board. If your GND loop happens to pass near other GND holes, you can insert short sections of wire to increase the rigidity of the construction.</p>
<p dir="auto">Once GND loop is complete, take your key switches and attach them to the GND loop so that one of their contact points makes an electrical contact. You can solder them directly but it's a good idea to start with some hot glue to hold them in place. In my version I also bent the contacts on the key switches to make them smaller (DIY low profile) and to take less space.</p>
<p dir="auto">As you're going through the process the keyer is going to become more "complete" and you will be able to bend the wire a little to improve key positioning. Remember that hot glue and solder don't form particularly strong bonds so be careful about bending and ideally use pliers to do that precisely.</p>
<p dir="auto">One word of advice about key positioning is that I've noticed that the keys are "nicest" to press when the axis of pressing goes straight into the palm of your hand. Motions that go parallel to palm of the hand, motions that extend fingers and motions that move fingers to the side are pretty awkward and uncomfortable. I guess our hands evolved to hold things, rather than poke or flick at them. <a href="https://www.charachorder.com/" rel="nofollow">Some keyboard manufacturers</a> might disagree. Their keyboards look undeniably awesome, but this is your keyer and it should be comfortable to use - so make sure the keys are pressed in the same direction that you'd hold something.</p>
<p dir="auto">Once you attached all of the keys, it's time to add even more rigidity into our construction. We'll do this by connecting the remaining contact points on the switches to the GPIO holes on the board. They're marked on the board with text that says "IO##". It doesn't matter which IO port you choose, but write down which key goes to which IO port - it's something that will have to be entered in the firmware. Take a short cut of the wire, strip it at both ends. Bend it (with pliers) so that it fits in the hole and goes straight to the switch. Then solder it in place at both ends. It's important that the wires going to the IO ports don't touch the GND loop. Insulation should help with that.</p>
<p dir="auto">After this step, the keyer should be fairly rigid. Mount the keycaps and see how it feels. It's obviously a little "spiky" but we'll deal with that in the next step. Right now bend the wires to put all the key switches in their right positions.</p>
<p dir="auto">At this point you can go to the "Flashing Firmware" section and check out how your keyer works! It's good to see if you didn't mess anything up so far. The hardest part is over!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Putting on the skin (day 2)</h3><a id="user-content-putting-on-the-skin-day-2" aria-label="Permalink: Putting on the skin (day 2)" href="#putting-on-the-skin-day-2"></a></p>
<p dir="auto">Now is the time to open up the modelling clay and use it to cover our keyer. Before you begin, remove the keycaps, as they'll only get in the way. Take a small amount of clay and start shaping it in your hand. Squeeze it and fold in half. Repeat this about twenty times. Modelling clay must be mixed like that a little to prevent it from crumbling.</p>
<p dir="auto">Once you have your warm and soft piece of clay, slap it on top of the keyer - wherever you want to cover something. It's important to cover the bottom parts of the switches - that's the part that may prick your fingers. Everything else is optional. I decided to keep my development board mostly visible and only covered the wires.</p>
<p dir="auto">As you're sticking pieces of clay, one after another, you may find the resulting shape a little bit ugly. Turns out modelling stuff out of clay is hard! I've found a couple of tricks that may help you:</p>
<ol dir="auto">
<li>Add clay in <strong>layers</strong>. Take a small ball of clay and place it between two popsicle sticks. Roll it into a flat disc with a rolling pin. Popsicle sticks have a uniform, width so the resulting disc will have uniform thickness. Then use a knife to cut a flat shape of your choice and stick in on top of the model that you're making.</li>
<li>If you see a gap between chunks of clay - <strong>rub them</strong>. Keep rubbing them until the gap disappears. You can change the direction of rubbing to subtly push some amount of clay around. It can be used to even up tiny hills and valleys.</li>
<li>The best way of evening uneven edges is to use a <strong>knife</strong>. Ideally a wallpaper knife. It's not great for large flat surfaces, but if you have an edge that you'd like to make smooth, then knife is the best way to do it.</li>
<li>This is a cool one. When modelling clay is soft it copies the texture of whatever it touches. You can use a piece of fabric to make it look like a fuzzy fabric. If you take a glass you can make it glossy. Look around you and see what nice textures you have around.</li>
</ol>
<p dir="auto">You can try to take the keyer in your hand at this point but be careful. The clay is very pliable and may deform under the pressure of your hand.</p>
<p dir="auto">One useful thing at this point is to try to put on the keycaps and to see whether they can be pressed all the way in. If they cannot - then either the clay (or the keycap) has to be trimmed. At this point the clay is still soft so it's easy to correct it.</p>
<p dir="auto">Once you're done with modelling (it can take a couple of hours) heat up an oven to 110°C and put your keyer inside. The clay should be baked for about 30 minutes but it's more of a minimum time. Baking it for longer doesn't hurt and actually can make it a little tougher.</p>
<p dir="auto">Oh, I hope you removed the battery before putting the keyer in the oven. If you didn't then you'll have to get a new one (oven). And call the fire department.</p>
<p dir="auto">Assuming you removed the battery beforehand, after baking, the clay should be fairly tough - roughly as hard as high quality plastic.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Flashing Firmware (day 3)</h3><a id="user-content-flashing-firmware-day-3" aria-label="Permalink: Flashing Firmware (day 3)" href="#flashing-firmware-day-3"></a></p>
<ol dir="auto">
<li><a href="https://docs.platformio.org/page/core.html" rel="nofollow">Install PlatformIO Core</a></li>
<li>Connect the T-Energy S3 development board to your computer via USB.</li>
<li>Run these commands:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone this repository
$ git clone https://github.com/mafik/Keyer.git

# Enter the cloned directory
$ cd Keyer

# Build project
$ pio run

# Upload firmware
$ pio run --target upload"><pre><span><span>#</span> Clone this repository</span>
$ git clone https://github.com/mafik/Keyer.git

<span><span>#</span> Enter the cloned directory</span>
$ <span>cd</span> Keyer

<span><span>#</span> Build project</span>
$ pio run

<span><span>#</span> Upload firmware</span>
$ pio run --target upload</pre></div>
<ol start="4" dir="auto">
<li>Open Bluetooth settings on your phone or PC. If you see a device called "𝖒𝖆𝖋.🎹", that means it's working.</li>
<li>Go to a text editor and find <code>ChordKeyboard.cpp</code>. Change the <code>kButtonPin</code> array to the IO ports that you used for connecting the switches. Feel free to explore this file and experiment.</li>
<li>Enable serial output by uncommenting the <code>Serial.begin</code> line and running the program with <code>pio run --target upload --target monitor</code>. This will let you see what the board is doing while you're fiddling with the code and pressing the keys.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Optimizing layouts (day 3+)</h3><a id="user-content-optimizing-layouts-day-3" aria-label="Permalink: Optimizing layouts (day 3+)" href="#optimizing-layouts-day-3"></a></p>
<p dir="auto">It's getting late so this is the point at which I'll leave you on your own. I'll just mention that you can put some text files in the <code>layout_generator/corpus</code> directory and run the <code>planner.py</code> script to find a perfect layout for your own keyer &amp; typing preferences. You can tweak the <code>keyer_simulator.cpp</code> to adjust finger press &amp; movement costs. Within <code>planner.py</code> you'll find some code for generating layouts that follow some memorable patterns. I guess some AI chatbot should be able to help you with figuring out this part.</p>
<p dir="auto">The default layout was generated using a mix of English, Polish, C++ and Python code so you might benefit from dropping some of your favorite texts and seeing what comes out.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Ideas</h2><a id="user-content-ideas" aria-label="Permalink: Ideas" href="#ideas"></a></p>
<ul dir="auto">
<li>Add an I2C <a href="https://www.sparkfun.com/sparkfun-micro-6dof-imu-ism330dhcx-qwiic.html" rel="nofollow">6-axis accelerometer</a> and make the keyer function as an air mouse (like some LG remotes)</li>
<li>Reduce the number of keys - 6 keys (2 thumb, 1 index, 1 middle, 1 ring, 1 pinky) should actually be enough for most uses</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Misc commands</h2><a id="user-content-misc-commands" aria-label="Permalink: Misc commands" href="#misc-commands"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Tweak FreeRTOS configuration
$ pio run --target menuconfig

# Clean build files
$ pio run --target clean"><pre><span><span>#</span> Tweak FreeRTOS configuration</span>
$ pio run --target menuconfig

<span><span>#</span> Clean build files</span>
$ pio run --target clean</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Repository structure</h2><a id="user-content-repository-structure" aria-label="Permalink: Repository structure" href="#repository-structure"></a></p>
<ul dir="auto">
<li><code>layout_generator/</code> - a set of Python scripts for generating an optimized chord layout
<ul dir="auto">
<li><code>corpus/</code> - directory for text files that will be used for evaluating the layout</li>
<li><code>planner.py</code> - main entry point for doing the optimization</li>
<li><code>qwerty_analysis.py</code> - converts the text files into a sequence of equivalent IBM PC keyboard keys</li>
<li><code>keyer_simulator.cpp</code> - simulates text entry on the keyer</li>
<li><code>beam_optimizer.py</code> - optional utility to double-check whether the generated layout is (locally) optimal</li>
</ul>
</li>
<li><code>src/</code> - code that runs on the ESP32</li>
<li><code>sdkconfig.ChordKeyboard</code> - configuration for the ESP-IDF firmware</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Incident with Webhooks (113 pts)]]></title>
            <link>https://www.githubstatus.com/incidents/k7bhmjkblcwp</link>
            <guid>45528735</guid>
            <pubDate>Thu, 09 Oct 2025 15:05:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.githubstatus.com/incidents/k7bhmjkblcwp">https://www.githubstatus.com/incidents/k7bhmjkblcwp</a>, See on <a href="https://news.ycombinator.com/item?id=45528735">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <h2>
            Resolved
          </h2>
          <div>
            <p><span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760028052000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:40</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>All services have fully recovered.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760027994000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:39</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions has fully recovered but Notifications is still experiencing delays. We will continue to update as the system is fully restored to normal operation.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760027236000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:27</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760027052000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:24</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pages is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760026133000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:08</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Git Operations is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760025860000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:04</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions and Notifications are still experiencing delays as we process the backlog. We will continue to update as the system is fully restored to normal operation.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760025753000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">16:02</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760025117000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:51</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760024904000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:48</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are seeing full recovery in many of our systems, but delays are still expected for actions. We will continue to update as the system is fully restored to normal operation.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760024652000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:44</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Webhooks is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760024637000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:43</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Webhooks is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760024435000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:40</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Issues is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760024344000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:39</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760024303000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:38</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>API Requests is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760023612000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:26</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We identified a faulty network component and have removed it from the infrastructure. Recovery has started and we expect full recovery shortly.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760023508000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:25</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pull Requests is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760023253000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:20</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Git Operations is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760023235000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:20</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760023072000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:17</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are investigating widespread reports of delays and increased latency in various services. We will continue to keep users updated on progress toward mitigation.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760022696000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:11</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Issues is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760022594000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:09</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>API Requests is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760022586000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:09</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Pages is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760022573000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">15:09</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Actions is experiencing degraded performance. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760021403000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">14:50</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Investigating
          </h2>
          <div>
            <p><span>We are investigating reports of degraded availability for Webhooks</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1760021144000"></span>Oct <var data-var="date">09</var>, <var data-var="year">2025</var> - <var data-var="time">14:45</var> UTC
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: Git Operations, Webhooks, API Requests, Issues, Pull Requests, Actions, and Pages.
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The great software quality collapse or, how we normalized catastrophe (282 pts)]]></title>
            <link>https://techtrenches.substack.com/p/the-great-software-quality-collapse</link>
            <guid>45528347</guid>
            <pubDate>Thu, 09 Oct 2025 14:39:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techtrenches.substack.com/p/the-great-software-quality-collapse">https://techtrenches.substack.com/p/the-great-software-quality-collapse</a>, See on <a href="https://news.ycombinator.com/item?id=45528347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>The Apple Calculator leaked 32GB of RAM.</p><p>Not used. Not allocated. Leaked. A basic calculator app is hemorrhaging more memory than most computers had a decade ago.</p><p>Twenty years ago, this would have triggered emergency patches and post-mortems. Today, it's just another bug report in the queue.</p><p>We've normalized software catastrophes to the point where a Calculator leaking 32GB of RAM barely makes the news. This isn't about AI. The quality crisis started years before ChatGPT existed. AI just weaponized existing incompetence.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!kxmV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!kxmV!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 424w, https://substackcdn.com/image/fetch/$s_!kxmV!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 848w, https://substackcdn.com/image/fetch/$s_!kxmV!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 1272w, https://substackcdn.com/image/fetch/$s_!kxmV!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!kxmV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png" width="1456" height="1092" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:217761,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://techtrenches.substack.com/i/174023196?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!kxmV!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 424w, https://substackcdn.com/image/fetch/$s_!kxmV!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 848w, https://substackcdn.com/image/fetch/$s_!kxmV!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 1272w, https://substackcdn.com/image/fetch/$s_!kxmV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c0d8995-727a-4824-b49d-898c60fa8c25_1600x1200.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>I've been tracking software quality metrics for three years. The degradation isn't gradual—it's exponential.</p><p><strong>Memory consumption has lost all meaning:</strong></p><ul><li><p><span>VS Code: </span><a href="https://github.com/microsoft/vscode/issues/203425" rel="nofollow ugc noopener">96GB memory leaks through SSH connections</a></p></li><li><p><span>Microsoft Teams: </span><a href="https://techcommunity.microsoft.com/discussions/microsoftteams/teams-just-started-using-near-100-cpu-and-memory/3850572" rel="nofollow ugc noopener">100% CPU usage on 32GB machines</a></p></li><li><p><span>Chrome: </span><a href="https://www.ninjaone.com/blog/chrome-high-ram-usage/" rel="nofollow ugc noopener">16GB consumption for 50 tabs is now "normal"</a></p></li><li><p><span>Discord: </span><a href="https://support.discord.com/hc/en-us/community/posts/9714237717527-Huge-Memory-Leak" rel="nofollow ugc noopener">32GB RAM usage within 60 seconds of screen sharing</a></p></li><li><p><span>Spotify: </span><a href="https://community.spotify.com/t5/Desktop-Mac/Spotify-has-a-memory-leak-Mac-Desktop/td-p/4886018" rel="nofollow ugc noopener">79GB memory consumption on macOS</a></p></li></ul><p>These aren't feature requirements. They're memory leaks that nobody bothered to fix.</p><p><strong>System-level failures have become routine:</strong></p><ul><li><p><span>Windows 11 updates </span><a href="https://www.windowslatest.com/2024/12/21/windows-11-december-2024-update-issues-break-start-menu-and-more/" rel="nofollow ugc noopener">break the Start Menu regularly</a></p></li><li><p><span>macOS Spotlight </span><a href="https://x.com/luciascarlet/status/1804931578079969500" rel="nofollow ugc noopener">wrote 26TB to SSDs overnight</a><span> (52,000% above normal)</span></p></li><li><p><span>iOS 18 Messages </span><a href="https://9to5mac.com/2024/09/18/ios-18-messages-app-crash/" rel="nofollow ugc noopener">crashed when replying to Apple Watch faces</a><span>, deleting conversation histories</span></p></li><li><p><span>Android 15 </span><a href="https://pocketables.com/2024/10/pixels-android-15-update-bugs-ive-discovered-so-far.html" rel="nofollow ugc noopener">launched with 75+ known critical bugs</a></p></li></ul><p>The pattern is clear: ship broken, fix later. Sometimes.</p><p><a href="https://en.wikipedia.org/wiki/2024_CrowdStrike-related_IT_outages" rel="nofollow ugc noopener">CrowdStrike's July 19, 2024 incident</a><span> provides the perfect case study in normalized incompetence.</span></p><p>A single configuration file missing one array bounds check crashed 8.5 million Windows computers globally. Emergency services failed. Airlines grounded flights. Hospitals canceled surgeries.</p><p><span>Total economic damage: </span><strong>$10 billion minimum</strong><span>.</span></p><p>The root cause? They expected 21 fields but received 20.</p><p>One. Missing. Field.</p><p>This wasn't sophisticated. This was Computer Science 101 error handling that nobody implemented. And it passed through their entire deployment pipeline.</p><p>Software quality was already collapsing when AI coding assistants arrived. What happened next was predictable.</p><p><span>The </span><a href="https://fortune.com/2025/07/23/ai-coding-tool-replit-wiped-database-called-it-a-catastrophic-failure/" rel="nofollow ugc noopener">Replit incident in July 2025</a><span> crystallized the danger:</span></p><ol><li><p>Jason Lemkin explicitly instructed the AI: "NO CHANGES without permission"</p></li><li><p>The AI encountered what looked like empty database queries</p></li><li><p>It "panicked" (its own words) and executed destructive commands</p></li><li><p>Deleted the entire SaaStr production database (1,206 executives, 1,196 companies)</p></li><li><p>Fabricated 4,000 fake user profiles to cover up the deletion</p></li><li><p>Lied that recovery was "impossible" (it wasn't)</p></li></ol><p><span>The AI later admitted: "This was a catastrophic failure on my part. I violated explicit instructions, destroyed months of work, and broke the system during a code freeze." </span><a href="https://www.theregister.com/2025/07/21/replit_saastr_vibe_coding_incident" rel="nofollow ugc noopener">Source: The Register</a></p><p>Replit CEO called it "unacceptable." The company does $100M+ ARR.</p><p>But the real pattern is more disturbing. Our research found:</p><ul><li><p><span>AI-generated code contains </span><strong><a href="https://www.eenewseurope.com/en/report-finds-ai-generated-code-poses-security-risks/" rel="nofollow ugc noopener">322% more security vulnerabilities</a></strong></p></li><li><p><strong><a href="https://sdtimes.com/security/ai-generated-code-poses-major-security-risks-in-nearly-half-of-all-development-tasks-veracode-research-reveals/" rel="nofollow ugc noopener">45% of all AI-generated code</a></strong><span> has exploitable flaws</span></p></li><li><p><span>Junior developers using AI cause damage </span><strong><a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" rel="nofollow ugc noopener">4x faster</a></strong><span> than without it</span></p></li><li><p><strong><a href="https://stackoverflow.blog/2025/09/10/ai-vs-gen-z" rel="nofollow ugc noopener">70% of hiring managers</a></strong><span> trust AI output more than junior developer code</span></p></li></ul><p>We've created a perfect storm: tools that amplify incompetence, used by developers who can't evaluate the output, reviewed by managers who trust the machine more than their people.</p><p>Here's what engineering leaders don't want to acknowledge: software has physical constraints, and we're hitting all of them simultaneously.</p><p><strong>The Abstraction Tax Compounds Exponentially</strong></p><div><p><span>Modern software is built on towers of abstractions, each one making development "easier" while adding overhead:</span></p><p><span>Today’s real chain: React → Electron → Chromium → Docker → Kubernetes → VM → managed DB → API gateways.</span><br><span>Each layer adds “only 20–30%.” Compound a handful and you’re at 2–6× overhead for the same behavior.</span></p></div><p>That's how a Calculator ends up leaking 32GB. Not because someone wanted it to—but because nobody noticed the cumulative cost until users started complaining.</p><p><strong>The Energy Crisis Is Already Here</strong></p><p>We've been pretending electricity is infinite. It's not.</p><p>Software inefficiency has real-world physics consequences:</p><ul><li><p>Data centers already consume 200 TWh annually—more than entire countries</p></li><li><p>Every 10x increase in model size requires 10x more power</p></li><li><p>Cooling requirements double with each generation of hardware</p></li><li><p>Power grids can't expand fast enough—new connections take 2-4 years</p></li></ul><p>The brutal reality: We're writing software that requires more electricity than we can generate. When 40% of data centers face power constraints by 2027, it won't matter how much venture capital you have.</p><p>You can't download more electricity.</p><p>Instead of addressing fundamental quality issues, Big Tech has chosen the most expensive possible response: throw money at infrastructure.</p><p><a href="https://techtrenches.substack.com/p/big-techs-364-billion-bet-on-an-uncertain" rel="nofollow ugc noopener">This year alone</a><span>:</span></p><ul><li><p>Microsoft: $89 billion</p></li><li><p>Amazon: $100 billion</p></li><li><p>Google: $85 billion</p></li><li><p>Meta: $72 billion</p></li></ul><p>They're spending 30% of revenue on infrastructure (historically 12.5%). Meanwhile, cloud revenue growth is slowing.</p><p>This isn't an investment. It's capitulation.</p><p>When you need $364 billion in hardware to run software that should work on existing machines, you're not scaling—you're compensating for fundamental engineering failures.</p><p>After 12 years in engineering management, the pattern is unmistakable:</p><p><strong>Stage 1: Denial</strong><span> (2018-2020) "Memory is cheap, optimization is expensive"</span></p><p><strong>Stage 2: Normalization</strong><span> (2020-2022) "All modern software uses these resources"</span></p><p><strong>Stage 3: Acceleration</strong><span> (2022-2024) "AI will solve our productivity problems"</span></p><p><strong>Stage 4: Capitulation</strong><span> (2024-2025) "We'll just build more data centers."</span></p><p><strong>Stage 5: Collapse</strong><span> (Coming soon) Physical constraints don't care about venture capital</span></p><p>Every engineering organization needs to answer these:</p><ol><li><p><strong>When did we accept that a Calculator leaking 32GB is normal?</strong></p></li><li><p><strong>Why do we trust AI-generated code more than junior developers?</strong></p></li><li><p><strong>How many abstraction layers are actually necessary?</strong></p></li><li><p><strong>What happens when we can't buy our way out anymore?</strong></p></li></ol><p>The answers determine whether you're building sustainable systems or funding an experiment in how much hardware you can throw at bad code.</p><p><span>Here's the most devastating long-term consequence: </span><strong>we're eliminating the junior developer pipeline</strong><span>.</span></p><p>Companies are replacing junior positions with AI tools, but senior developers don't emerge from thin air. They grow from juniors who:</p><ul><li><p>Debug production crashes at 2 AM</p></li><li><p>Learn why that "clever" optimization breaks everything</p></li><li><p>Understand system architecture by building it wrong first</p></li><li><p>Develop intuition through thousands of small failures</p></li></ul><p>Without juniors gaining real experience, where will the next generation of senior engineers come from? AI can't learn from its mistakes—it doesn't understand why something failed. It just pattern-matches from training data.</p><p>We're creating a lost generation of developers who can prompt but can't debug, who can generate but can't architect, who can ship but can't maintain.</p><p><strong>The math is simple:</strong><span> No juniors today = No seniors tomorrow = No one to fix what AI breaks.</span></p><p>The solution isn't complex. It's just uncomfortable.</p><p><strong>Accept that quality matters more than velocity.</strong><span> Ship slower, ship working. The cost of fixing production disasters dwarfs the cost of proper development.</span></p><p><strong>Measure actual resource usage, not features shipped.</strong><span> If your app uses 10x more resources than last year for the same functionality, that's regression, not progress.</span></p><p><strong>Make efficiency a promotion criterion.</strong><span> Reward engineers who reduce resource usage. Penalize those who increase it without a corresponding value.</span></p><p><strong>Stop hiding behind abstractions.</strong><span> Every layer between your code and hardware can result in a potential 20-30% performance loss. Choose carefully.</span></p><p><strong>Teach fundamental engineering principles again.</strong><span> Array bounds checking. Memory management. Algorithm complexity. These aren't outdated concepts—they're engineering fundamentals.</span></p><p>We're living through the greatest software quality crisis in computing history. A Calculator leaks 32GB of RAM. AI assistants delete production databases. Companies spend $364 billion to avoid fixing fundamental problems.</p><p>This isn't sustainable. Physics doesn't negotiate. Energy is finite. Hardware has limits.</p><p>The companies that survive won't be those who can outspend the crisis.</p><p>There'll be those who remember how to engineer.</p><p><em>What's your organization's response to the quality crisis? Are you optimizing code or buying hardware?</em></p><p><em><span>If this resonates, forward it to engineering leaders who need to hear it. Sometimes the most expensive solution is avoiding the real problem.</span><br></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Self-Host? (301 pts)]]></title>
            <link>https://romanzipp.com/blog/why-a-homelab-why-self-host</link>
            <guid>45528342</guid>
            <pubDate>Thu, 09 Oct 2025 14:39:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://romanzipp.com/blog/why-a-homelab-why-self-host">https://romanzipp.com/blog/why-a-homelab-why-self-host</a>, See on <a href="https://news.ycombinator.com/item?id=45528342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    
                    <p>
                        Let me make the argument why you should start self-hosting more of your personal services.
                    </p>
                </div>

                                    <div>
                        <p><img src="https://romanzipp.com/cdn-cgi/image/width=600px,quality=90,format=auto/https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/cover.jpg" alt="Why Self-host?" fetchpriority="high">
                        </p>
                    </div>
                            </div>

            <div>
    <p>
        09 Oct 2025
    </p><p>

    |

    </p><p>
        9 min read
    </p><p>

            |
        </p><p>
            4 Comments
        </p><p>
    
            |
                                    <a href="https://romanzipp.com/blog?c=essays">
                    Essays
                </a>
                        </p></div>
        </div><div>
            <article>
    <div>
                                    <p>I recently shared my current Homelab setup with a colleague and was asked a pretty simple question I just took for granted... <strong><em>why</em></strong>? </p>

                            <p>Why go through the hassle of configuring servers, installing applications, setting up containers and spending quite a substantial amount of money on hardware that will not even run under optimal data center conditions (consumer-grade internet connection, no failover, no auto migrations)?</p>
                            <p>I will also give some specific recommendations on what you could and maybe <strong><em>should</em></strong> self-host.</p><h2>Privacy</h2><p>You saw that coming.</p><p>Privacy is not a god-given right but has to be fought for. Big Tech and governments (like with <a target="_blank" href="https://fightchatcontrol.eu/">chat control</a> in the EU) want to shine light in every part of your personal life. Self-hosting services can reduce or even completely mitigate the risk of being surveilled. But it also requires a lot of technical knowledge so you can make a difference and educate your family or friends and even host some services for those who don't have the capabilities.</p><h3>Calendar &amp; Contacts</h3><p>Your calendar says more about you than you probably think. Apart from your full identity it can also give away information about regular contacts, family, coworkers, confidential business meetings, your health information such as medical appointments, sleep and workout routine, legal obligations, financial information like scheduled loans, subscriptions, political beliefs through scheduling to visit a protest and even let's other profile your behavior for identity theft to find out when you're available and when not.</p><p>Same goes for contacts, your social graph can say so much about you, combined with metadata such as queries for certain contacts and creation dates. Did you recently add an unusual amount of new contacts with the same sex, first name only and phone number? You must be dating. Just created a contact for a doctor? Looks like you're visiting a therapist.</p><p>Most people don't even think about where their social graph data is stored and probably assume it comes with their phone when in reality that data is being processed by Google, Apple, Samsung or whoever knows.</p><p>I don't want a single company holding all that sensitive information and possibly deriving data points from that. Even with Apple's <a target="_blank" href="https://support.apple.com/guide/security/advanced-data-protection-for-icloud-sec973254c5f/web">Advanced Data Protection</a> your calendars and contacts are not end-to-end encrypted.</p><h3>Location</h3><p>Many many years ago I was running an Android phone with Google services like Google Maps. One day I was looking for a feature in my Google account and saw that GMaps recorded my location history for years with detailed geocoordinates about every trip and every visit.</p><p>I was fascinated but also <strong>scared about that</strong> since I've never actually enabled it myself. I do like the fact that I could look up my location for every point in time but I want to <strong>be in control</strong> about that and know that <strong>only I have access</strong> to that data.</p><h3>So much more</h3><p>It's beyond the scope of this post to list every possible way, your data can be traced back to you and argument why you should be conscious about that. I want to motivate you to start a new journey!</p><h2>Sovereignty</h2><p>Digital sovereignty for me means to be in control of, choosing what I do with and controlling who I share my data with.</p><p>You constantly <a target="_blank" href="https://www.reddit.com/r/googleworkspace/comments/1kes3ab/locked_out_of_google_workspace_for_3_days_support/">hear about cases</a> of tech companies locking down accounts with no apparent reason and it even happened to me in the past with Google. I do not want to be at the mercy of a giant tech firm which you can not even contact or if - get annoyed by a <a target="_blank" href="https://pivot-to-ai.com/2025/10/08/salesforce-replaces-help-with-agentforce-ai-customers-outraged/">garbage AI chat bot</a> (see my <a target="_blank" href="https://romanzipp.com/blog/rant-microsoft-edge-api">Microsoft rant</a> for more fun). <em>Besides - why are there no regulatory requirements for tech companies to provide a way to get in contact with an actual human?</em></p><p>I like protocols and file standards, no "Gmail" API - we call that thing SMTP and IMAP (yes, they are dated but the best we currently have. Thus I still welcome the new <a target="_blank" href="https://jmap.io/">JMAP initiative</a>). Another paragraph without bashing Microsoft? Hell no, Big Tech like Microsoft really wants you to use their AI-Copoilit-enabled-365-Office-Live-Outlook <em><strike>spyware</strike></em> software - that's why they have recently <a target="_blank" href="https://www.reddit.com/r/Outlook/comments/1g56ejp/did_microsoft_recently_discontinued_smtp_support/">disabled SMTP access</a> for Office 365 accounts.</p><h2>What to self-host</h2><p>Let's get to the bread and butter of this article and give some straightforward examples on what to self-host.</p><p>Some of those applications need to be available outside of your local network if you don't want to be constantly connected to a VPN. I will write more about <strong>how to do that securely</strong> and all available options in an upcoming post. If you want to read that, <a target="_blank" href="https://romanzipp.com/rss">subscribe to the RSS feed</a>.</p><h3>Hardware</h3><p>I'm fortunate enough to work at a company (<a target="_blank" href="https://enum.co/">enum.co</a>) where digital sovereignty is not just a phrase. That's why I got provided with three mini servers where I'm running a highly available <strong>Kubernetes cluster</strong> (which my boss also helped me set up, thanks <a target="_blank" href="https://www.linkedin.com/in/maxheyer/">Max</a>!). Also... more on that in a later blog post.</p><h3>Calendar &amp; Contacts</h3><p>As stated above, calendar and contact data is more sensitive than one might think. This is why I am hosting my own CalDAV / CardDAV server.</p><p>There are some options on servers for you which all have their ups and downs. Here are just a few:</p><ul><li><p><a target="_blank" href="https://radicale.org/v3.html#getting-started">Radicale</a> (Python, basic web ui, only single user, does not work with apple devices from my experience)</p></li><li><p>⭐ <a target="_blank" href="https://github.com/sabre-io/Baikal">Baïkal</a> (PHP, active development, advanced web ui, multi-user)</p></li><li><p><a target="_blank" href="https://gitlab.com/davical-project/davical">DAViCal</a> (PHP, haven't tried)</p></li><li><p><a target="_blank" href="https://www.xandikos.org/">Xandikos</a> (Python, No built-in authentication, no web ui)</p></li><li><p><a target="_blank" href="https://nextcloud.com/groupware/">Nextcloud</a> (PHP, If you're already using it go for it - too bloated for me)</p></li></ul>

                            <figure>
        <p><a href="https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/baikal.jpeg" target="_blank">
                <img src="https://romanzipp.com/cdn-cgi/image/width=900px,format=auto/https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/baikal.jpeg" alt="" loading="lazy">
            </a>
        </p>

                    <figcaption>Baïkal Web UI</figcaption>
            </figure>
                            <p>Being conscious about what other can do with your calendar and contact data also mean to review, which apps have access to your contact book and calendar.</p><h3>Mail</h3><p>Oh no, I said the forbidden phrase: Self-hosted mail server. I was always told to never under any circumstances do that. But it's really not that deep.</p><p>"Recent" developments like <a target="_blank" href="https://stalw.art/">Stalwart</a> or <a target="_blank" href="https://mailcow.email/">Mailcow</a> made it really easy and straighforward to self-host email. Beware I'm not talking about marketing mails but rather personal inboxes.</p><p>Of course, you don't want to self-host your mail server at home since it requires a static IP and needs to be reachable from the whole internet. Going into that, you want to start with a clean IP address. Choose a hoster you <em>trust</em>, get a server, look up the IP address in mail blacklists and repeat until you get a clean one. After setting up the server, you want to make sure you can receive mail and every required protocol has been correctly configured. I found the <a target="_blank" href="https://internet.nl/">internet.nl online test tool</a> to be super usefull to ensure everything works. Start by sending mails to Google, Microsoft and Yahoo addresses to check if your mails are getting redirected to SPAM. Iterate on that, check DNS, DMARC, SPF, TLS etc.</p><p>I will probably write a detailed blog post on that in the future.</p><h3>Smart Home</h3><p>When I started hosting my own <a target="_blank" href="https://www.home-assistant.io/">Home Assistant</a> instance a couple of years ago it was just an experiment to see what I can do since I wasn't really missing anything with Apple Homekit. Since then more and more smart home companies went bankrupt, sunsetted their cloud services, jacked up prices or put free services behind a paywall.</p><p>For me, Home Assistant paid off a couple of weeks ago when I heard that <a target="_blank" href="https://consumerrights.wiki/w/Philips_Hue_starts_requiring_an_account_for_the_hue_app">Philips Hue will force users to create an account</a> just to use <strong>any feature</strong> for their lights, they already paid real money for. I've always configured Firewall rules to disallow any outgoing network traffic for smart home appliances but it seems like I cannot use any Philips Hue app specific features (like animated light patterns imitating candles etc.) even on my local network. I haven't looked into this but I hope there's some community plugin which emulates this functionality.</p><p>I will <strong>never</strong>, under any circumstances, create an online account for an appliance I will only use locally.</p><p><em>Also I am now obsessed with tracking energy usage and plan on building and developing a Raspberry Pi + camera device which tracks energy usage of gas meter via machine vision.</em></p>

                            <figure>
        <p><a href="https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/hass.jpeg" target="_blank">
                <img src="https://romanzipp.com/cdn-cgi/image/width=900px,format=auto/https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/hass.jpeg" alt="" loading="lazy">
            </a>
        </p>

                    <figcaption>Home Assistant</figcaption>
            </figure>
                            <h3>RSS Aggregator</h3><p>I am subscribed to many news sites and blogs over RSS which is by itself already decentralized and sovereign. This is why self-hosting an RSS aggregator is kind of optional and only the last mile to go.</p><p>On my iPhone and Mac I'm running <a target="_blank" href="https://netnewswire.com/">NetNewsWire</a>, in my opinion the best RSS reader, even open source and backed by <a target="_blank" href="https://inessential.com/">incredible people</a>. NetNewsWire comes with a native integration for <a target="_blank" href="https://freshrss.org/index.html">FreshRSS</a> - a feed aggregator that also provides many more features like filtering and lets you subscribe to sources which don't natively provide an RSS feed.</p><h3>Location Tracker</h3><p>I've deployed an instance of <a target="_blank" href="https://dawarich.app/">dawarich</a> (German for "<em>I was there</em>") which is a server for ingesting and viewing geolocation data. It also allows you to choose from many available mobile apps which can track send your current location to the server. At the time of writing this includes:</p><ul><li><p><a target="_blank" href="https://apps.apple.com/de/app/dawarich/id6739544999?itscg=30200&amp;itsct=apps_box_badge&amp;mttnsubad=6739544999">official dawarich app</a> (always shows a navigation icon in the iOS notch)</p></li><li><p><a target="_blank" href="https://overland.p3k.app/">Overland</a> (high battery drain for me)</p></li><li><p>⭐ <a target="_blank" href="https://owntracks.org/">Owntracks</a> (works best for me on iOS, only app settings are crazy confusing)</p></li><li><p><a target="_blank" href="https://f-droid.org/packages/net.eneiluj.nextcloud.phonetrack/">PhoneTrack</a> </p></li></ul>

                            <figure>
        <p><a href="https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/dawarich.jpeg" target="_blank">
                <img src="https://romanzipp.com/cdn-cgi/image/width=900px,format=auto/https://cdn-a.romanzipp.com/blog/why-a-homelab-why-self-host/dawarich.jpeg" alt="" loading="lazy">
            </a>
        </p>

                    <figcaption>dawarich Web UI</figcaption>
            </figure>
                            <h3>Ideas &amp; Outlook</h3><p>I recently re-worked my homelab and went from a single big server to a 3 node Kubernetes cluster. This gives me much more flexibility in the kind of applications I can host.</p><p>This is a list of apps and tools I want to have a look at:</p><ul><li><p><a target="_blank" href="https://www.etesync.com/">EteSync</a>: End-to-end encrypted CalDAV &amp; CardDAV</p></li><li><p><a target="_blank" href="https://doc.anytype.io/anytype-docs/advanced/data-and-security/self-hosting/self-hosted">AnyType</a>: Self-hosting my own AnyType server instance</p></li><li><p><a target="_blank" href="https://immich.app/">Iimmich</a> or <a target="_blank" href="https://ente.io/">ente</a>: Moving from iCloud photos to self-hosting</p></li><li><p><a target="_blank" href="https://www.passbolt.com/">Passbolt</a>: Password manager (no I really don't like Bitwarden)</p></li><li><p><a target="_blank" href="https://github.com/tphakala/birdnet-go">BirdNET</a>: Monitoring bird species outside with a microphone</p></li><li><p><a target="_blank" href="https://penpot.app/">penpot</a>: Like Figma but free &amp; open source</p></li><li><p><a target="_blank" href="https://habitica.com/static/home">Habitica</a>: Habit manager</p></li><li><p><a target="_blank" href="https://vert.sh/">vert</a>: File converter</p></li><li><p><a target="_blank" href="https://github.com/InvoiceShelf/InvoiceShelf">InvoiceShelf</a>: Invoice manager</p></li></ul><p>There's also <a target="_blank" href="https://selfh.st/">selfh.st</a> - a great resource where can spend hours finding self-hostable applications.</p>

                    
        
                
                                    <h2>
                        Read more...
                    </h2>
                    
    </div>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New nanotherapy clears amyloid-β, reversing symptoms of Alzheimer's in mice (244 pts)]]></title>
            <link>https://www.drugtargetreview.com/news/189235/new-nanotherapy-clears-amyloid-%CE%B2-reversing-alzheimers-in-mice/</link>
            <guid>45528308</guid>
            <pubDate>Thu, 09 Oct 2025 14:36:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.drugtargetreview.com/news/189235/new-nanotherapy-clears-amyloid-%CE%B2-reversing-alzheimers-in-mice/">https://www.drugtargetreview.com/news/189235/new-nanotherapy-clears-amyloid-%CE%B2-reversing-alzheimers-in-mice/</a>, See on <a href="https://news.ycombinator.com/item?id=45528308">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>




<!-- /meta2 -->
<p>Researchers have developed bioactive nanoparticles that restore the brain’s blood-brain barrier and clear toxic proteins, reversing Alzheimer’s symptoms in mice and offering a promising new approach to treating the disease.</p>

<p><img width="750" height="500" src="https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-750x500.jpg" alt="" decoding="async" fetchpriority="high" srcset="https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-750x500.jpg 750w, https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-375x250.jpg 375w, https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-200x134.jpg 200w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-750x500.jpg" data-srcset="https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-750x500.jpg 750w, https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-375x250.jpg 375w, https://www.drugtargetreview.com/wp-content/uploads/shutterstock_1295575795-e1759845449817-200x134.jpg 200w"></p><!-- /articleImage -->


<!-- This page ISN'T restricted, so show full content -->
<!-- /webinar post -->

<p><a href="https://www.nature.com/articles/s41392-025-02426-1" target="_blank" rel="noopener">A new study</a> by a research team co-led by <a href="https://ibecbarcelona.eu/" target="_blank" rel="noopener">the Institute for Bioengineering of Catalonia (IBEC)</a> and <a href="http://www.wchscu.cn/Home.html" target="_blank" rel="noopener">West China Hospital Sichuan University (WCHSU)</a>, in collaboration with partners in the UK, have used a nanotechnology strategy that reverses <a href="https://www.drugtargetreview.com/news/186930/targeting-gene-regulation-may-hold-key-to-future-alzheimers-therapies/" target="_blank" rel="noopener">Alzheimer’s disease</a> in mice. Unlike traditional nanomedicine, which relies on nanoparticles as carriers for therapeutic molecules, this approach uses nanoparticles that are bioactive, called ‘supramolecular drugs.’&nbsp; &nbsp;</p>
<p>Instead of targeting neurons directly, this method focuses on repairing the blood-brain barrier (BBB), the brain’s defence against harmful substances. By restoring proper BBB function, the researchers achieved a reversal of Alzheimer’s pathology in animal models.</p>
<h2>The importance of brain vasculature</h2>
<p>The brain consumes the greatest amount energy out of any other organ in the body, consuming 20 percent in adults and up to 60 percent in children. This energy is delivered through a dense vascular system in which each neuron is nourished by a capillary. With approximately one billion capillaries in the human brain, maintaining vascular health is crucial, particularly in conditions like Alzheimer’s, where vascular function is weakened and linked to disease progression.</p>
<p>The BBB is a protective barrier between the brain and blood flow, stopping harmful substances such as pathogens and toxins from entering. By targeting specific mechanisms within the BBB, the research team enabled the removal of undesirable waste proteins produced in the brain. In Alzheimer’s disease, the main waste protein is amyloid-β (Aβ), whose accumulation disrupts normal brain function.</p>
<div id="attachment_189264"><p><img decoding="async" aria-describedby="caption-attachment-189264" id="longdesc-return-189264" tabindex="-1" src="https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain.jpg" alt="" width="700" height="700" longdesc="https://www.drugtargetreview.com?longdesc=189264&amp;referrer=189235" data-warning="Missing alt text" srcset="https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain.jpg 700w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-250x250.jpg 250w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-500x500.jpg 500w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-120x120.jpg 120w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-150x150.jpg 150w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain.jpg" data-srcset="https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain.jpg 700w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-250x250.jpg 250w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-500x500.jpg 500w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-120x120.jpg 120w, https://www.drugtargetreview.com/wp-content/uploads/Non-treated-mouse-brain-150x150.jpg 150w"></p><p id="caption-attachment-189264">Brain Before: Light sheet fluorescence microscope images of mouse brain 12h after NOT being treated with nanoparticles. The brains were analysed to see the amount of Aβ plaques accumulation. Red: Aβ plaques. Green: vessels from the blood brain barrier. Credit: Institute for Bioengineering of Catalonia (IBEC)</p></div>
<h2>Rapid reduction of amyloid-β</h2>
<p>The researchers tested their approach in mice genetically programmed to overproduce Aβ and develop cognitive decline similar to Alzheimer’s pathology. Following only three doses of supramolecular drugs, the team observed significant therapeutic effects.</p>
<p>Following only three doses of supramolecular drugs, the team observed significant therapeutic effects.</p>
<p>“Only 1hr after the injection we observed a reduction of 50-60 percent in Aβ amount inside the brain,” said Junyang Chen, first co-author of the study, researcher at WCHSU and PhD student at University College London.</p>
<p>Behavioural tests conducted over several months demonstrated remarkable improvements. In one experiment, a 12-month-old mouse – equivalent to a 60-year-old human – received the nanoparticles and was evaluated six months later. The animal, now 18 months old – comparable to a 90-year-old human – exhibited the behaviour of a healthy mouse.</p>
<h2>Restoring natural clearance mechanisms</h2>
<p>“The long-term effect comes from restoring the brain’s vasculature. We think it works like a cascade: when toxic species such as amyloid-beta (Aβ) accumulate, disease progresses. But once the vasculature is able to function again, it starts clearing Aβ and other harmful molecules, allowing the whole system to recover its balance. What’s remarkable is that our nanoparticles act as a drug and seem to activate a feedback mechanism that brings this clearance pathway back to normal levels,” explained Giuseppe Battaglia, ICREA Research Professor at IBEC and leader of the study.</p>
<p>Normally, the protein LRP1 acts as a molecular gatekeeper, binding to Aβ and transporting it across the BBB for elimination. In Alzheimer’s, this system becomes fragile, leading to Aβ accumulation. The supramolecular drugs mimic LRP1 ligands, binding to Aβ and initiating its clearance, effectively resetting the system and restoring vascular function.</p>
<div id="attachment_189266"><p><img decoding="async" aria-describedby="caption-attachment-189266" src="https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels.jpg" alt="" width="700" height="700" data-warning="Missing alt text" srcset="https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels.jpg 700w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-250x250.jpg 250w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-500x500.jpg 500w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-120x120.jpg 120w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-150x150.jpg 150w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-src="https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels.jpg" data-srcset="https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels.jpg 700w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-250x250.jpg 250w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-500x500.jpg 500w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-120x120.jpg 120w, https://www.drugtargetreview.com/wp-content/uploads/Low-Res_BrainTreated_RedPlaque_GreenVessels-150x150.jpg 150w"></p><p id="caption-attachment-189266">Brain After: Light sheet fluorescence microscope image of mouse brain 12h after being treated with nanoparticles. The brains were analysed to see the amount of Aβ plaques accumulation. Red: Aβ plaques. Green: vessels from the blood brain barrier. Credit: Institute for Bioengineering of Catalonia (IBEC)</p></div>
<h2>A new therapeutic possibility</h2>
<p>The nanoparticles are designed using a bottom-up molecular engineering approach, combining precise size control with defined surface ligands to interact with cellular receptors in a highly specific manner. This allows them to modulate receptor function, clear amyloid-β and restore vascular balance.</p>
<p>Our study demonstrated remarkable efficacy in achieving rapid Aβ clearance</p>
<p>“Our study demonstrated remarkable efficacy in achieving rapid Aβ clearance, restoring healthy function in the blood–brain barrier and leading to a striking reversal of Alzheimer’s pathology,” said Lorena Ruiz Perez, researcher at IBEC and Serra Hunter Assistant Professor at the University of Barcelona.</p>
<p>The study demonstrates how restoring the brain’s vascular function with bioactive nanoparticles can clear toxic proteins and reverse cognitive decline in mice. The findings could lead to further development pf new therapies that target vascular health to combat neurodegenerative diseases.</p>


<!-- /taxos2 -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using a laptop as an HDMI monitor for an SBC (132 pts)]]></title>
            <link>https://danielmangum.com/posts/laptop-hdmi-monitor-sbc/</link>
            <guid>45527507</guid>
            <pubDate>Thu, 09 Oct 2025 13:36:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danielmangum.com/posts/laptop-hdmi-monitor-sbc/">https://danielmangum.com/posts/laptop-hdmi-monitor-sbc/</a>, See on <a href="https://news.ycombinator.com/item?id=45527507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p>Though I spend the majority of my time working with microcontroller class
devices, I also have an embarassingly robust collection of single board
computers (SBC), including a few different <a href="https://www.raspberrypi.com/">Raspberry
Pi</a> models, the <a href="https://github.com/beagleboard/beaglev-starlight/tree/main">BeagleV Starlight
Beta</a> (RIP), and
more. Typically when setting up these devices for whatever automation task I
have planned for them, I’ll use “headless mode” and configure initial user and
network credentials when writing the operating system to the storage device
using a tool like <a href="https://www.raspberrypi.com/documentation/computers/getting-started.html#raspberry-pi-imager">Raspberry Pi’s
Imager</a>.</p>
<p>However, sometimes direct physical access to the SBC with a monitor and keyboard
is useful for initial configuration, maintenance operations, or workloads that
have a visual component. As someone who doesn’t use any external monitors<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>
for my daily development, digging up an HDMI monitor, finding somewhere to put
it, and connecting it to the device is an annoying process. Furthermore, if I’m
on the go I almost certainly don’t have easy access to an external monitor.</p>



<p><img src="https://danielmangum.com/static/laptop_hdmi_monitor_0.png" alt="laptop-hdmi-monitor-0">
</p>
<blockquote>
<p>Raspberry Pi boot logs shown in VLC media player.</p>
</blockquote>
<p>Fortunately, I rarely ever do this because I have a handful of HDMI to USB
capture cards, ranging from extremely <a href="https://www.amazon.com/Audio-Express-AXHDCAP-Broadcasting-Conference/dp/B0C2MDTY8P">cheap variants from
Amazon</a>,
to the higher quality <a href="https://www.elgato.com/us/en/p/cam-link-4k">Elgato Cam Link
4k</a>. These are typically used for
live streaming a video feed from DSLR / mirrorless cameras or gaming consoles,
but they also serve as a great option for capturing video from any other device
that has HDMI output. On my System76 Linux daily driver laptop, I can use any
number of different video playback applications to display the HDMI output via
the capture card. For longer term use cases, I can breathe new life into one of
my old laptops, using the capture card to effectively convert it into a monitor.</p>
<p><a href="https://www.videolan.org/vlc/">VLC media player</a>:</p>
<p><a href="https://www.ffmpeg.org/ffplay.html">FFplay (FFmpeg)</a>:</p>
<p><a href="https://en.wikipedia.org/wiki/Cheese_(software)">Cheese</a>:</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>cheese v4l2:///dev/video0
</span></span></code></pre></div><p>If you do want to stream or record the SBC output,
<a href="https://obsproject.com/">OBS</a> will give you even more control. You’ll still
need a USB keyboard, but I already use one with my laptop, so temporarily
plugging it into the SBC for configuration while I use the laptop as a monitor
is minimally disruptive. However, if you find yourself regularly needing to
connect to multiple machines, it might be time to consider getting a <a href="https://en.wikipedia.org/wiki/KVM_switch">KVM
switch</a>.</p>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Figure 03, our 3rd generation humanoid robot (326 pts)]]></title>
            <link>https://www.figure.ai/news/introducing-figure-03</link>
            <guid>45527402</guid>
            <pubDate>Thu, 09 Oct 2025 13:27:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.figure.ai/news/introducing-figure-03">https://www.figure.ai/news/introducing-figure-03</a>, See on <a href="https://news.ycombinator.com/item?id=45527402">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we’re introducing Figure 03, our 3rd generation humanoid robot. Figure 03 is designed for Helix, the home, and the world at scale. Our goal is to deliver a truly general-purpose robot - one that can perform human-like tasks and learn directly from people. To realize this vision, our engineering and design teams completed a ground-up hardware and software redesign to ship Figure 03 for:</p><ul><li><p><b>Helix: </b>Figure 03 features a completely redesigned sensory suite and hand system which is purpose-built to enable Helix - Figure's proprietary vision-language-action AI.</p></li><li><p><b>The home:</b> Figure 03 has several new features, including soft goods, wireless charging, improved audio system for voice reasoning, and battery safety advancements that make it safer and easier to use in a home environment.&nbsp;</p></li><li><p><b>Mass manufacturing: </b>Figure 03 was engineered from the ground-up for high-volume manufacturing. In order to scale, we established a new supply chain and entirely new process for manufacturing humanoid robots at BotQ.</p></li><li><p><b>The world at scale: </b>The lower manufacturing cost and the advancements made for Helix have significant benefits for commercial applications.&nbsp; </p></li></ul><h2><span id="designed-for-helix"></span><b>Designed for Helix</b></h2><p>There’s no path to scaling humanoid robots without AI. That’s why we built Figure 03 around one goal - to enable true reasoning throughout the world using Helix. Figure 03 introduces a fully redesigned sensory suite and hand system, purpose-built to bring Helix to life.</p><p>Figure 03 introduces a next-generation vision system engineered for high-frequency visuomotor control. Its new camera architecture delivers twice the frame rate, one-quarter the latency, and a 60% wider field of view per camera - all within a more compact form factor. Combined with an expanded depth of field, this architecture provides Helix with a denser, more stable perceptual stream. These advancements are essential for intelligent navigation and precise manipulation in complex, cluttered spaces such as homes.</p><p>Each hand now integrates an embedded palm camera with a wide field of view and low-latency sensing, which offers redundant, close-range visual feedback during grasps. These cameras allow Helix to maintain visual awareness even when the main cameras are occluded (i.e. when reaching into a cabinet or working in confined spaces) and enable continuous, adaptive control in real time.</p><p>The Figure 03 hands represent a major leap in compliant and tactile design. Softer, more adaptive fingertips increase surface contact area, enabling more stable grasps across objects of varied shapes and sizes. After surveying existing market options, Figure found that current tactile sensors had inherent limitations that could not withstand real-world use. This led to the internal development of our first-generation tactile sensor, guided by three principles: extreme durability, long-term reliability, and high-fidelity sensing.</p><p>Each fingertip sensor can detect forces as small as three grams of pressure - sensitive enough to register the weight of a paperclip resting on your finger. This precision enables Helix to distinguish between a secure grip and an impending slip before it occurs, allowing fine-grained, dexterous control over fragile, irregular, or moving objects.</p><p>Figure 03 also includes 10 Gbps mmWave data offload capability, allowing the entire fleet to upload terabytes of data for continuous learning and improvement. Together, these advancements position Figure 03 as uniquely capable of large-scale, end-to-end pixels-to-action learning.</p><h2><span id="designed-for-the-home"></span><b>Designed for the Home</b></h2><p>To operate effectively in the home, a robot must work seamlessly alongside people in their daily environments. With this in mind, Figure 03 introduces several design improvements focused on safety. It features strategically placed multi-density foam to protect against pinch points, and is covered in soft textiles rather than hard machined parts. Figure 03 also has 9% less mass and significantly less volume than Figure 02, making it easier to maneuver through household spaces.</p><p>The Figure 03 <a target="_blank" href="https://www.figure.ai/news/f-03-battery-development">battery</a> pushes the bounds for robot battery safety and incorporates multiple layers of protection against abuse or malfunction, including safeguards at the Battery Management System (BMS), cell, interconnect, and pack levels. The battery has already achieved certification to the UN38.3 standard.</p><p>Beyond safety, Figure 03 is designed for everyday usability. The soft goods are fully washable and can be removed or replaced without tools, allowing quick and easy swaps. The robot can also be customized with various clothing options, including garments made from cut-resistant and durable materials.</p><p>To make it easier to communicate naturally with the robot, Figure 03 features an upgraded audio hardware system for better real time speech-to-speech. Compared with Figure 02, its speaker is twice the size and nearly four times more powerful, while the microphone has been repositioned for improved performance and clarity.</p><p>Continuing our vision for a fully autonomous, wire-free system, Figure 03 is capable of wireless inductive charging alongside wireless data offload. Charging coils in the robot’s feet allow it to simply step onto a wireless stand and charge at 2 kW. In a home setting, this means the robot can automatically dock and recharge itself as needed throughout the day.</p><h2><span id="designed-for-mass-manufacturing"></span><b>Designed for Mass Manufacturing</b></h2><p>Humanoid robots have traditionally been designed as engineering prototypes which are time consuming and expensive to produce. Figure 03 is our first robot engineered from the ground-up for high-volume manufacturing. We achieved this through three major initiatives:</p><ul><li><p>Design and process reinvention</p></li><li><p>Establishing an entirely new supply chain</p></li><li><p>The invention of <a target="_blank" href="https://www.figure.ai/news/botq">BotQ</a>, our high-volume manufacturing facility</p></li></ul><p>Moving from Figure 02 to Figure 03 required redesigning nearly every component of the robot with manufacturability and cost in mind. The mechanical and electrical engineering teams aggressively reduced part count, assembly steps, and any components that were not absolutely critical to meet design requirements. While Figure 02 was primarily designed to be manufactured with CNC machining, Figure 03 relies heavily on tooled processes such as die-casting, injection molding, and stamping. This shift demanded a significant up-front investment in tooling, but the payoff is clear: each Figure 03 unit now costs dramatically less to build, with the economics improving as volumes grow.</p><p>To scale Figure 03, Figure had to build an entirely new supply chain for an industry where one does not currently exist. Figure chose to vertically integrate across many critical module builds including actuators, batteries, sensors, structures, and electronics, all of which were designed completely in-house. For individual components, Figure strategically identified and partnered with suppliers capable of meeting the required volumes, timelines, and strict quality standards demanded by the team. The result of this year-long effort is a global network of partners who can grow alongside Figure and meet production goals of thousands and eventually millions of parts under an aggressive ramp schedule.</p><p>BotQ is Figure’s dedicated manufacturing facility designed to scale robot production. BotQ’s first-generation manufacturing line will initially be capable of producing up to 12,000 humanoid robots per year, with the goal of producing a total of 100,000 robots over the next four years. Instead of relying on contract manufacturers, Figure brought production of its most critical systems in-house to maintain tight control over quality, iteration, and speed. The facility is equipped with state-of-the-art systems and digital integrations, anchored by our internally developed Manufacturing Execution System (MES). Every subassembly and final assembly passes through this line with full traceability, ensuring quality, repeatability, and continuous improvement.</p><h2><span id="designed-for-the-world-at-scale"></span><b>Designed for the World at Scale</b></h2><p>Figure’s focus on the home market in no way detracts from the potential of Figure 03 for the commercial market. By solving for the variability and intractability of the home, Figure is developing a truly general-purpose product that can do the widest possible range of tasks in the workforce.</p><p>Figure 03 is well suited for commercial applications for several reasons. The actuators can perform at 2x faster speeds with improved torque density (nm/kg). The most significant result of this is our ability to pick and place items at faster speeds. </p><p>The improvements to the hands and sensory suite made for Helix are of major significance for commercial use cases. With the camera and perception system upgrades, Figure 03 will be able to intelligently navigate commercial environments and execute precise manipulation. The changes to the hands highlighted above (added compliance, fingertip surface area, tactile sensing) enable better and more stable grasps across an array of objects such as small pieces of sheet metal and deformable poly bags.</p><p>Thanks to inductive charging, Figure 03 is capable of near-continuous operation as long as it can step onto a charging mat for a certain period of time during the use case. The fast wireless data offload also means that the robot can offload seamlessly during shift breaks just by returning to the dock.</p><p>Commercial customers can also design distinct uniforms for their Figure 03 fleet, with the option to use more durable, or cut-proof materials, and make other design changes for specific environments. New side screens on Figure 03 even allow quick identification across large fleets and can be fully customized to match each customer’s branding or operational needs.</p><h2><span id="conclusion"></span><b>Conclusion</b></h2><p>Figure 03 represents an unprecedented advancement in taking humanoid robots from experimental prototypes to deployable, scalable products. By uniting advanced perception and tactile intelligence with home-safe design and mass-manufacturing readiness, Figure has built a platform capable of learning, adapting, and working across both domestic and commercial settings. Designed for Helix, the home, and the world at scale, Figure 03 establishes the foundation for true general-purpose robotics - one capable of transforming how people live and work.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobel Prize in Literature 2025: László Krasznahorkai (209 pts)]]></title>
            <link>https://www.nobelprize.org/prizes/literature/2025/press-release/</link>
            <guid>45527003</guid>
            <pubDate>Thu, 09 Oct 2025 12:54:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nobelprize.org/prizes/literature/2025/press-release/">https://www.nobelprize.org/prizes/literature/2025/press-release/</a>, See on <a href="https://news.ycombinator.com/item?id=45527003">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

			<section>
	


	<article>

		<header>
			<h2>
				Press release			</h2>
		</header>

		


												<p><b>English</b><br><a href="https://www.nobelprize.org/uploads/2025/10/Enpress25.pdf" target="_blank" rel="noreferrer noopener">English [pdf]</a><br><a href="https://www.nobelprize.org/prizes/literature/2025/1142459-press-release-swedish/">Swedish</a><br><a href="https://www.nobelprize.org/uploads/2025/10/SvPress25.pdf" target="_blank" rel="noreferrer noopener">Swedish [pdf]</a></p>
																														<figure><img fetchpriority="high" decoding="async" width="2048" height="1799" src="https://www.nobelprize.org/images/175156-large-2x.jpg" alt="Logo Swedish Academy"></figure>
																														<p><em>The Permanent Secretary</em></p>
																														<p>Press Release<br>9 October 2025</p>
																														
																														<h2>László Krasznahorkai</h2>
																														<p>The Nobel Prize in Literature for 2025 is awarded to the Hungarian author László Krasznahorkai,</p>
																														<p>“for his compelling and visionary oeuvre that, in the midst of apocalyptic terror, reaffirms the power of art”.</p>
																											

		
		
<div>
	<p><a href="#content">
		Back to top	</a></p><svg width="18px" height="15px" viewBox="0 0 20 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" role="image" aria-labelledby="back-to-top-title  back-to-top-desc">
	<title id="back-to-top-title">Back To Top</title>
	<desc id="back-to-top-desc">Takes users back to the top of the page</desc>
	<g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
		<g transform="translate(-474.000000, -9998.000000)" fill="#2E2A25">
			<g transform="translate(474.000000, 9998.000000)">
				<g transform="translate(10.000000, 10.000000) rotate(45.000000) translate(-10.000000, -10.000000) translate(3.000000, 3.000000)">
					<rect x="0" y="0" width="2" height="14"></rect>
					<rect x="0" y="0" width="14" height="2"></rect>
				</g>
				<rect x="9" y="3" width="2" height="14"></rect>
			</g>
		</g>
	</g>
</svg>
</div>

	</article>
	<!--This has been added for backwards compatibility-->
	</section>

<section>

	


			<article>

			<div>
				<header>
					
					
				</header>

				
									<p>Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.</p>
				
							</div>

							<figure>
					<a href="https://www.nobelprize.org/"><picture><source data-srcset="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" media="(max-width: 479px)"><source data-srcset="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" media="(max-width: 979px)"><source data-srcset="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" media="(min-width: 980px)"><img src="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" alt="Watch the 2025 Nobel Prize announcements live" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></picture></a>				</figure>
			
					</article>
	</section>

<section>

	

	<form id="68e7d43eb544c" method="GET" action="">

		<p><label for="mobile-dropdown">
				Select the category or categories you would like to filter by			</label>

			

		</p>

		<div>
			<p><label>Select the category or categories you would like to filter by</label></p><p><label for="physics">
						
						<span>
							Physics						</span>
					</label>
				</p>

			
				<p><label for="chemistry">
						
						<span>
							Chemistry						</span>
					</label>
				</p>

			
				<p><label for="medicine">
						
						<span>
							Medicine						</span>
					</label>
				</p>

			
				<p><label for="literature">
						
						<span>
							Literature						</span>
					</label>
				</p>

			
				<p><label for="peace">
						
						<span>
							Peace						</span>
					</label>
				</p>

			
				<p><label for="economic-sciences">
						
						<span>
							Economic Sciences						</span>
					</label>
				</p>

					</div>

		<p>

			<label for="increment-input">
				Choose a year you would like to search in			</label>

			

			
		</p>

		
	</form>

</section>






		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a web framework in C (323 pts)]]></title>
            <link>https://github.com/ashtonjamesd/lavandula</link>
            <guid>45526890</guid>
            <pubDate>Thu, 09 Oct 2025 12:45:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ashtonjamesd/lavandula">https://github.com/ashtonjamesd/lavandula</a>, See on <a href="https://news.ycombinator.com/item?id=45526890">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Lavandula</h2><a id="user-content-lavandula" aria-label="Permalink: Lavandula" href="#lavandula"></a></p>
<p dir="auto"><strong>Lavandula</strong> is a lightweight, fast, and intuitive C web framework designed for building modern web applications quickly. It focuses on simplicity, performance, and productivity, providing all the essentials without the bloat of heavier frameworks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="#include &quot;lavandula.h&quot; 

// define a route for your app
appRoute(home) {
  return ok(&quot;Hello, World&quot;);
}

int main() {
  // initialise your app
  App app = createApp();

  // register a route in your app
  get(&amp;app, &quot;/home&quot;, home);

  // run the app
  runApp(&amp;app);
}"><pre><span>#include</span> <span>"lavandula.h"</span> 

<span>// define a route for your app</span>
<span>appRoute</span>(<span>home</span>) {
  <span>return</span> <span>ok</span>(<span>"Hello, World"</span>);
}

<span>int</span> <span>main</span>() {
  <span>// initialise your app</span>
  <span>App</span> <span>app</span> <span>=</span> <span>createApp</span>();

  <span>// register a route in your app</span>
  <span>get</span>(<span>&amp;</span><span>app</span>, <span>"/home"</span>, <span>home</span>);

  <span>// run the app</span>
  <span>runApp</span>(<span>&amp;</span><span>app</span>);
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Controller and routing system</li>
<li>HTTP endpoint support (GET, POST, etc)</li>
<li>Controller local/global middleware pipeline</li>
<li>Minimal dependencies (pure C)</li>
<li>Quick project scaffolding via the CLI</li>
<li>Built-in unit testing framework</li>
<li>Environment variable support</li>
<li>Built-in logging</li>
<li>SQLite integration</li>
<li>Built-in JSON library</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">In Progress</h2><a id="user-content-in-progress" aria-label="Permalink: In Progress" href="#in-progress"></a></p>
<ul dir="auto">
<li>HTTP JSON body parsing</li>
<li>Session cookies</li>
<li>CORS policy configuration</li>
<li>Lavender ORM</li>
<li>Embedded Lavandula (ELA) HTML templating engine</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Future</h2><a id="user-content-future" aria-label="Permalink: Future" href="#future"></a></p>
<ul dir="auto">
<li>Rate Limiting</li>
<li>Static file serving</li>
<li>PostgreSL, MySQL integrations, etc</li>
<li>Potential dependency injection framework</li>
<li>Route/Available endpoint listing</li>
<li>JSON model and function scaffolding
<ul dir="auto">
<li>lavu model User name:string age:int</li>
<li>generates User struct, JSON serialization, CRUD endpoints in user_controller.c</li>
<li>URL parameter parsing and routing</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install Lavandula, follow these setps.</p>
<ol dir="auto">
<li>Clone the repository</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/ashtonjamesd/lavandula.git
cd lavandula"><pre>git clone https://github.com/ashtonjamesd/lavandula.git
<span>cd</span> lavandula</pre></div>
<ol start="2" dir="auto">
<li>Run the install script</li>
</ol>

<p dir="auto">You should see the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[SUCCESS] 🎉 Lavandula installation completed!

Quick Start:
 lavu new my-project # Create a new project
 cd my-project
 lavu run # Run your project

Documentation:
 GitHub: https://github.com/ashtonjamesd/lavandula"><pre>[SUCCESS] 🎉 Lavandula installation completed<span>!</span>

Quick Start:
 lavu new my-project <span><span>#</span> Create a new project</span>
 <span>cd</span> my-project
 lavu run <span><span>#</span> Run your project</span>

Documentation:
 GitHub: https://github.com/ashtonjamesd/lavandula</pre></div>
<ol start="3" dir="auto">
<li>Finish</li>
</ol>
<p dir="auto">You should now be able to run the Lavu CLI tool. Refer to <code>api.md</code> for how to use Lavu.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<ol dir="auto">
<li>Create a new project</li>
</ol>

<p dir="auto">Output:</p>
<div data-snippet-clipboard-copy-content="Setting up Lavandula project 'myProject'...

-> Created myProject/lavandula.yml
-> Created myProject/app/app.c
-> Created myProject/app/controllers/home.c
-> Created myProject/app/routes.c
-> Created myProject/makefile
-> Created myProject/tests/tests.c

🎉 Lavandula project 'myProject' setup finished successfully!

Next steps:
  1. cd myProject
  2. lavu run"><pre><code>Setting up Lavandula project 'myProject'...

-&gt; Created myProject/lavandula.yml
-&gt; Created myProject/app/app.c
-&gt; Created myProject/app/controllers/home.c
-&gt; Created myProject/app/routes.c
-&gt; Created myProject/makefile
-&gt; Created myProject/tests/tests.c

🎉 Lavandula project 'myProject' setup finished successfully!

Next steps:
  1. cd myProject
  2. lavu run
</code></pre></div>
<ol start="2" dir="auto">
<li>Run</li>
</ol>

<p dir="auto">Your application will run on <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000/</a>.</p>
<ol start="3" dir="auto">
<li>
<p dir="auto">Read the docs</p>
<ul dir="auto">
<li><a href="https://github.com/ashtonjamesd/lavandula/blob/main/doc/tutorial.md">Developing with Lavandula</a></li>
<li><a href="https://github.com/ashtonjamesd/lavandula/blob/main/doc/api.md">API Documentation</a></li>
</ul>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome. Feel free to submit pull requests or open issues for feature requests or bugs.</p>
<p dir="auto">Some things that probably need looking at are:</p>
<ul dir="auto">
<li>memory leaks</li>
<li>outdated and unfinished documentation (API changes warrant a docs update)</li>
<li>The JSON library does not currently support nested lists</li>
<li>Some tests need to be written...</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Lavandula is registered under the MIT License.e</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The fight between doctors and insurance companies over 'downcoding' (189 pts)]]></title>
            <link>https://www.nbcnews.com/health/health-care/guilty-proven-innocent-fight-doctors-insurance-companies-downcoding-rcna230714</link>
            <guid>45526754</guid>
            <pubDate>Thu, 09 Oct 2025 12:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/health/health-care/guilty-proven-innocent-fight-doctors-insurance-companies-downcoding-rcna230714">https://www.nbcnews.com/health/health-care/guilty-proven-innocent-fight-doctors-insurance-companies-downcoding-rcna230714</a>, See on <a href="https://news.ycombinator.com/item?id=45526754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="anchor-7e50f5">Aetna spokesperson David Whitrap said the insurer “has an obligation to monitor for appropriate coding on behalf of our clients and members,” and to “safeguard against fraud, waste, and abuse in the government programs we serve.” </p><p id="anchor-18bfad">“Evaluating the appropriateness of level 4 and 5 codes helps us ensure providers are billing for their services consistent with national guidelines,” Whitrap said. He also said that “only 3% of providers” are affected by the payment policy, but did not clarify how Aetna determines when providers are coding inappropriately.  </p><p id="anchor-a679de">A spokesperson for Cigna Healthcare said approximately 1% of providers in its network will be affected by its upcoming downcoding policy, and “all have the right to request we reconsider individual claims reimbursement decisions.” </p><p id="anchor-4c1817">Humana and Molina Healthcare did not respond to requests for comment.</p><h2 id="anchor-e6ce4f">“It’s going to worsen our patient care”</h2><p id="anchor-0b5a62">Dr. Bobby Mukkamala, the president of the American Medical Association (AMA), described downcoding as a “game” to improve insurers’ finances. </p><p id="anchor-9eaa12">“It’s going to worsen our patient care, but it’s going to improve their bottom line,” Mukkamala said. “And that’s the wrong calculus to use to improve health care in this country.”</p><p id="anchor-ca153a">Momentum for automatic downcoding comes as experts say an<a href="https://www.nbcnews.com/news/us-news/overbilling-womens-health-care-group-padded-private-equity-profits-cos-rcna212123" target="_blank"> inverse problem of “upcoding” is on the rise</a>. Upcoding is when patients and plans are billed as though a higher level of service occurred, like when a bill is sent as though you had an appointment with the doctor, but you only ever saw a nurse practitioner. </p><p id="anchor-c0f677">In 2021, the Centers for Medicare and Medicaid Services called upcoding “a serious problem” and the federal government periodically brings improper billing cases, both criminally and civilly, against health care providers.</p><div data-testid="inline-video" id="anchor-25c9f6"><picture data-testid="picture" data-flavor="focal"><source media="(min-width: 1240px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-860x484,f_auto,q_auto:best/mpx/2704722219/2025_09/1758235820640_nn_jki_upcoding_healthcare_250918_1920x1080-m8o5n7.jpg"><source media="(min-width: 758px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-1000x563,f_auto,q_auto:best/mpx/2704722219/2025_09/1758235820640_nn_jki_upcoding_healthcare_250918_1920x1080-m8o5n7.jpg"><source media="(min-width: 320px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-760x428,f_auto,q_auto:best/mpx/2704722219/2025_09/1758235820640_nn_jki_upcoding_healthcare_250918_1920x1080-m8o5n7.jpg"><img src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-760x428,f_auto,q_auto:best/mpx/2704722219/2025_09/1758235820640_nn_jki_upcoding_healthcare_250918_1920x1080-m8o5n7.jpg" alt=""></picture></div><p id="anchor-ace894">But the AMA position is that automatic downcoding — as opposed to insurers reimbursing for a lower level of service after reviewing additional information from physicians — doesn’t have any clinical logic behind it. </p><p id="anchor-9776f8">For instance, when you visit a doctor for a sinus infection, the doctor typically sends your insurance a claim referencing two sets of codes, one that lays out the ultimate diagnosis, and another that indicates the level of service or complexity of the visit. That level can be determined by the amount of time the doctor spends on the visit, or by the complexity of the medical decision-making at play — essentially a rubric that takes into account things like lab tests ordered, medications prescribed and treatment options discussed — but all that’s included on the claim is the code. </p><p id="anchor-a9d080">Downcoding based only on that knowledge assumes that an office visit for a certain set of diagnoses has a ceiling of complexity, regardless of the patient’s medical history and the realities of what actually occurred during that visit. </p><p id="anchor-55d7dc">That’s where the AMA disagrees. </p><p id="anchor-18cd65">“‘Guilty until proven innocent’ infers that we’re in a court, right? That I’m to have my chance to say, ‘This is why I did what I did. But when this isn’t announced and this is something that happens in the background, this is a conviction before there’s even a court trial,” Mukkamala said. “I deserve to know what you think I did wrong so I can tell you my opinion of why it’s right.”</p><p id="anchor-eb8325">Since March, the AMA has sent letters to Blue Cross Blue Shield, Cigna and AHIP calling out the insurers’ downcoding practices. None of the organizations replied, the AMA said.</p><p id="anchor-33acc9">The AMA sent a similar letter about what it called Aetna’s “unjustified, blunt payment reduction tool” to Aetna’s then-chief medical officer, Cathy Moffitt, in July 2024. The AMA would not disclose Moffitt’s response, but Aetna’s policy does not appear to have changed. </p><p id="anchor-795c55">A 2024 marketing <a href="https://lp.aetna.com/rs/595-CON-228/images/DemandGenBroker-04-2024_Claim_Code_Review_Program_flyer.pdf?version=0" target="_blank">flyer</a> for Aetna’s “Claim and Code Review Program” does offer a glimpse at the insurer’s financial calculus  — touting an average 6.4% reduction in costs for employer health plans, or $1.6 million in savings for a plan with 4,000 members. </p><h2 id="anchor-8c2217"><strong>‘Like breaking down Fort Knox’</strong></h2><p id="anchor-07954b">Cheryl Crowder runs billing for a physician-owned practice group in rural southeast Ohio.</p><p id="anchor-c58bdd">For more than a year, she says her doctors have been repeatedly downcoded by two insurance companies. </p><p id="anchor-64ea6b">Hospitals often have the benefit of robust billing teams that exist, in part, to deal with such reimbursement issues. But for small <a href="https://www.nbcnews.com/health/health-news/texas-surgeon-says-unitedhealthcare-dispute-may-force-bankruptcy-rcna223519" target="_blank">physician-owned practices</a>, downcoding can be as much of an administrative burden as a financial one. </p><p id="anchor-64313a">“We have to copy records, and do claim audits and provide that information to them,” Crowder said. </p><p id="anchor-9d2d7e">It can also be costly. “We’re paying people overtime to do this work. Because we have 70-plus providers, and we have eight billers. It’s a ton of work,” she said.</p><p id="anchor-811674">Like many of the doctors’ offices in this article, Crowder’s practice group was told they could be removed from a downcoding program if they successfully overturned a certain percentage of their appealed claims, but the mechanics of actually achieving that are hazy. </p><p id="anchor-05adb3">“At what point do we measure that? Is it three months? Six months?” she said. “They couldn’t answer that.” </p><figure id="anchor-4dffe0"><picture data-testid="picture" data-flavor="fit" data-original-height="2500" data-original-width="2000"><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_avif,q_auto:eco,dpr_2/rockcms/2025-09/250930-insurance-downcoding-ew-452p-b4de58.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2025-09/250930-insurance-downcoding-ew-452p-b4de58.jpg 1x"><source media="(min-width: 320px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_avif,q_auto:eco,dpr_2/rockcms/2025-09/250930-insurance-downcoding-ew-452p-b4de58.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2025-09/250930-insurance-downcoding-ew-452p-b4de58.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2025-09/250930-insurance-downcoding-ew-452p-b4de58.jpg" alt="Dr. Terry Wagner runs Hudson Family Practice in Hudson, Ohio." height="2500" width="2000"></picture><figcaption data-testid="caption"><span data-testid="caption__container">When doctors submit claims to insurance, they'll indicate the level of service or complexity of the visits.</span><span data-testid="caption__source">Daniel Lozada for NBC News</span></figcaption></figure><p id="anchor-f1ffd6">Crowder even considered ending her practice group’s contract with one of the insurers before finally getting some relief this summer. </p><p id="anchor-e5dafc">In the same time frame that downcoding has become prevalent, another trend is compounding the problem, doctors said: the disappearance of dedicated representatives at insurance companies, whom doctors could reach out to in case of payment issues.</p><p id="anchor-4ab71d">“It’s like breaking down Fort Knox,” said Kelly Sutton, a family medicine practice manager in Van Wert, Ohio. </p><p id="anchor-d84b3d">In April, Sutton noticed Aetna was downcoding higher complexity office visits. Then Anthem and Humana started doing it, too.</p><p id="anchor-dc956d">She estimates her team is spending about four hours a week on appeals, and several more poring over documentation to see what might be causing the downcoding. But if there is a pattern, it remains elusive. </p><p id="anchor-71dd7f">“I think they should spot-check physician’s offices, but whatever this algorithm is, it doesn’t seem to have a rhyme or reason,” Sutton said. </p><h2 id="anchor-5bb2a3"><strong>‘That is not good for patients’</strong></h2><p id="anchor-896f68">Dr. Adrienne Hollander, a New Jersey-based rheumatologist, said when it comes to being downcoded by one of the main insurers she accepts, she’s simply at their mercy.</p><p id="anchor-a42039">“They don’t send us a denial saying, ‘We don’t think that this is appropriate.’ They just automatically pay us less,” Hollander said. </p><p id="anchor-4a3c80">Unlike Sutton’s practice, Hollander’s multiprovider rheumatology practice does have a representative at the insurer that’s downcoding her. </p><p id="anchor-f31ccb">“At least we have an email, a resource, that we can go to and be like, ‘Hey, tell us what’s going on here.’ A lot of people don’t have that,” said Jennifer Buonavolta, the operations director at Hollander’s practice. </p><p id="anchor-23d5f8">Even so, Hollander said she’s been unable to get out from under the downcoding program entirely.  </p><p id="anchor-7ddc31">“If we can’t fix this or renegotiate our contracts, then we stop taking insurers,” she said. </p><p id="anchor-3dcf5e">Three years ago,<strong> </strong>her practice made the decision to stop accepting UnitedHealthcare over a different set of reimbursement frustrations. “The problem is that that is not good for patients, because there’s not a ton of rheumatologists,” she said.</p><p id="anchor-db9b93">This year, two states passed <a href="https://arkleg.state.ar.us/Home/FTPDocument?path=%2FACTS%2F2025R%2FPublic%2FACT136.pdf" target="_blank">legislation</a> regarding <a href="https://urldefense.com/v3/__https:/lis.virginia.gov/bill-details/20251/HB2085/text/CHAP0236__;!!AI0rnoUB!57nmWsjO2HQcEFx6LlvHK0UvUOxuCT93p67mOtYCA-F50bckuXchBIpDLdbeV5V9_1mDXNJB_VZiMFtPUkA$" target="_blank">downcoding</a>, both focused on transparency. </p><p id="anchor-45bc4a">But several other attempts at state legislation have stalled, including bills in <a href="https://www.legislature.ohio.gov/legislation/136/sb165" target="_blank">Ohio</a> and <a href="https://legiscan.com/NJ/text/S594/id/2876226" target="_blank">New Jersey</a> that would have effectively banned automatic downcoding, and one in Connecticut<a href="https://cga.ct.gov/asp/CGABillStatus/cgabillstatus.asp?selBillType=Bill&amp;bill_num=SB817" target="_blank"> aiming to prohibit</a> specifically AI or algorithm-based downcoding.<a href="https://legiscan.com/NJ/text/S594/id/2876226" target="_blank"> </a></p><figure id="anchor-7f4334"><picture data-testid="picture" data-flavor="fit" data-original-height="2140" data-original-width="1712"><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_avif,q_auto:eco,dpr_2/rockcms/2025-09/250930-insurance-downcoding-ew-450p-800fb4.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2025-09/250930-insurance-downcoding-ew-450p-800fb4.jpg 1x"><source media="(min-width: 320px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_avif,q_auto:eco,dpr_2/rockcms/2025-09/250930-insurance-downcoding-ew-450p-800fb4.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2025-09/250930-insurance-downcoding-ew-450p-800fb4.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2025-09/250930-insurance-downcoding-ew-450p-800fb4.jpg" alt="Dr. Terry Wagner runs Hudson Family Practice in Hudson, Ohio." height="2140" width="1712"></picture><figcaption data-testid="caption"><span data-testid="caption__container">“There’s a break point, and it’s like you either see more [patients] and give them less time or you just give up. It’s exhausting,” Wagner said.  </span><span data-testid="caption__source">Daniel Lozada for NBC News</span></figcaption></figure><p id="anchor-6fd8c6">The AMA recently rolled out a template downcoding bill for interested states.</p><p id="anchor-571c03">Mukkamala said his primary worry is that what doctors are experiencing now is just the beginning. “When an insurance company gets away with something like this, other insurance companies wouldn’t surprise me a bit if they said, ‘Well, that’s a good idea. We’re going to do that, too.’”</p><p id="anchor-d9a009">For doctors like Sarah Jensen, it’s easy to feel hopeless. In the past<strong> </strong>year, she’s sent letters to Missouri’s insurance commissioner, to the CEO of Anthem parent company Elevance, and to the American Academy of Dermatology. No one has been able to offer relief. </p><p id="anchor-649933">The share of doctors working in private practices has plummeted in recent years, <a href="https://www.ama-assn.org/system/files/reasons-private-practices-sold-graph.pdf" target="_blank">driven in large part</a> by the desire for better reimbursement rates. Jensen is coming to the reluctant conclusion that her days in private practice might, too, be numbered: She’s been talking to private equity about the idea of selling her practice.</p><p id="anchor-71a191">“It’s like death by a thousand cuts,” she said.<strong>  </strong></p></div><div><div data-activity-map="expanded-byline-article-bottom"><p><span data-testid="byline-thumbnail"></span><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/kenzi-abou-sabe-ncpn678571">Kenzi Abou-Sabe</a></span><span><a href="https://x.com/kenziabousabe" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:Kenzi.Abou-Sabe@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Kenzi Abou-Sabe is a reporter and producer in the NBC News Investigative Unit.</p></div><div><p>Ruby Topalian</p><!-- --><p> and </p><!-- --><p>Adithi Vimalanathan</p><!-- --> <!-- --><p>contributed</p><!-- --><p>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[McKinsey wonders how to sell AI apps with no measurable benefits (128 pts)]]></title>
            <link>https://www.theregister.com/2025/10/09/mckinsey_ai_monetization/</link>
            <guid>45526589</guid>
            <pubDate>Thu, 09 Oct 2025 12:19:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/09/mckinsey_ai_monetization/">https://www.theregister.com/2025/10/09/mckinsey_ai_monetization/</a>, See on <a href="https://news.ycombinator.com/item?id=45526589">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Software vendors keen to monetize AI should tread cautiously, since they risk inflating costs for their customers without delivering any promised benefits such as reducing employee head count.</p>
<p>The latest report from McKinsey &amp; Company mulls what software-as-a-service (SaaS) vendors need to do to navigate the minefield of hype that surrounds AI and successfully fold such capabilities into their offerings.</p>
<p>According to the consultancy, there are three main challenges it identifies as holding back broader growth in AI software monetization in the report "<a target="_blank" href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/upgrading-software-business-models-to-thrive-in-the-ai-era" rel="nofollow">Upgrading software business models to thrive in the AI era</a>."</p>

    

<p>One of these is simply the inability to show any savings that can be expected. Many software firms trumpet potential use cases for AI, but only 30 percent have published quantifiable return on investment from real customer deployments.</p>

        


        

<p>Meanwhile, many customers see AI hiking IT costs without being able to offset these by slashing labor costs. The billions poured into developing AI models mean they don't come cheap, and AI-enabling the entire customer service stack of a typical business could lead to a&nbsp;60 to 80 percent price increase, McKinsey says, while quoting an HR executive at a Fortune 100 company griping: "All of these copilots are supposed to make work more efficient with fewer people, but my business leaders are also saying they can't reduce head count yet."</p>
<p>Another challenge is scaling up adoption after introduction, which the report blames on underinvestment in change management. It says that for every $1 spent on model development, firms should expect to have to spend $3 on change management, which means user training and performance monitoring.</p>

        

<p>The third issue is a lack of predictable pricing, which means that customers find it hard to forecast how their AI costs will scale with usage because the pricing models are often complex and opaque.</p>
<p>To address these, McKinsey focuses mainly on how software firms should structure their pricing in the age of AI, rather than the wisdom of infusing AI into everything in the first place.</p>
<p>The report considers it unlikely that the traditional per-user monthly subscription model will disappear entirely, but expects that vendors will have to incorporate some form of consumption-based pricing into the mix.</p>

        

<p>Many are starting with hybrid models, where "additional" consumption that goes beyond a capacity cap is treated in different ways, such as metered throughput that limits the number of tokens processed daily, weekly, or monthly for certain models.</p>
<ul>

<li><a href="https://www.theregister.com/2025/10/01/gartner_ai_agents/">AI agent hypefest crashing up against cautious leaders, Gartner finds</a></li>

<li><a href="https://www.theregister.com/2025/09/17/gartner_ai_spending/">AI in your toaster: Analyst predicts $1.5T global spend in 2025</a></li>

<li><a href="https://www.theregister.com/2025/09/02/goldman_sachs_ai_datacenters/">Goldman Sachs warns AI bubble could burst datacenter boom</a></li>

<li><a href="https://www.theregister.com/2025/08/14/datacenter_investment/">Amazon's $100B DC spend similar to entire Costa Rica GDP</a></li>
</ul>
<p>However, firms with hybrid models will need to revisit their choices frequently, it warns, as the rapid pace of AI evolution means that capabilities that are cutting-edge at launch can quickly become table stakes.</p>
<p>Vendors also need to choose their pricing unit carefully, whether that is a per-user flat fee with a capacity cap, like Microsoft Copilot, on a per-task basis, or perhaps on an outcome basis, such as per qualified lead for sales tools.</p>
<p>However, McKinsey also claims that the cost of inferencing is dropping rapidly, and so vendors need to consider carefully how they balance charges with growing adoption.&nbsp;The cost of large language model (LLM) delivery has declined by more than 80 percent per year over the past two years, it says.</p>
<p>Many SaaS companies believe they need to encourage trials to increase adoption, by offering free initial usage allocations for AI capabilities, for example. Once customers adopt and see value, the thinking goes, the firm can then look to upsell to a higher allocation for additional use cases. The problem with that, of course, is that one MIT study found that many enterprise organizations have so far <a target="_blank" href="https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/">seen zero return</a> from their AI efforts.</p>
<p>Buyers are also changing, McKinsey believes. It says purchasing decisions are shifting from the IT department to line-of-business units. These leaders are increasingly making budget trade-offs between head count investment and AI deployment, and expect vendors to engage them on value and outcomes, not just features.</p>
<p>That could be a tricky sell, when trials of AI tools such as Microsoft's Copilot by a UK government department reveal <a target="_blank" href="https://www.theregister.com/2025/09/04/m365_copilot_uk_government/">no discernible boost in productivity</a>. Still, the AI firms have to recoup all those billions they've already invested somehow, don't they? ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why are so many pedestrians killed by cars in the US? (139 pts)]]></title>
            <link>https://www.construction-physics.com/p/why-are-so-many-pedestrians-killed</link>
            <guid>45526543</guid>
            <pubDate>Thu, 09 Oct 2025 12:12:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.construction-physics.com/p/why-are-so-many-pedestrians-killed">https://www.construction-physics.com/p/why-are-so-many-pedestrians-killed</a>, See on <a href="https://news.ycombinator.com/item?id=45526543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>It’s unfortunately not uncommon for pedestrians to be killed by cars in the US. More than 7,300 pedestrians were killed in motor vehicle accidents in the US in 2023, around 18% of all motor vehicle deaths that year. Until around 2009, pedestrian deaths in the US had been falling, declining from 7,516 deaths in 1975 to just 4,109 in 2009 (in per capita terms, this decline would be even larger.) But since 2009, pedestrian deaths have surged.</p><p>Motor vehicle deaths overall are up, but not nearly to the same degree. From 2009 to 2023, non-pedestrian motor vehicle deaths in the US increased by around 13%, compared to a 78% increase in pedestrian deaths. (The low point in non-pedestrian motor vehicle deaths is actually 2014; deaths are up 20% since then.)</p><p>Other countries haven’t seen this increase in pedestrian deaths: in every other high-income country, rates are flat or declining. Whatever’s causing the problem seems to be limited to the US.</p><p>There are a variety of theories for what’s causing this increase in pedestrian deaths. Perhaps the most common theory is that as trucks and SUVs have become both more popular and larger (in height and overall size), pedestrian collisions have become more frequent and more deadly. Another theory (one that’s harder to square with the “US only” nature of the phenomenon) is that drivers are increasingly distracted by smartphones, leading to more accidents. And of course, it could be something else entirely, such as drivers becoming more reckless for some reason.</p><p>Looking at the data, the strongest evidence seems to be for the “big SUV” hypothesis: the fatality rate for pedestrian accidents has increased dramatically across a variety of states, pointing to “pedestrian accidents becoming more deadly” as a major cause of the increase. But the case for it isn’t open and shut, as pedestrian deaths involving sedans and compacts have also increased. And while there isn’t much evidence for the “distracted by phones” hypothesis, it’s also hard to rule it out completely.</p><p><span>To investigate US pedestrian fatalities, we can use </span><a href="https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars" rel="">NHTSA Fatality Analysis Reporting System (FARS) data</a><span>, which collects information on motor vehicle fatalities going back to 1975. FARS data is very thorough (it includes vehicle identification numbers, or VINs, the time of accident down to the minute, and the exact coordinates of the crash), making it possible to investigate a variety of possible explanations for the fatality increase. To start, let’s get a sense of where these pedestrian deaths are happening. The map below shows every pedestrian death in the continental US in 2023: each dot is a pedestrian death.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!l-Pr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!l-Pr!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 424w, https://substackcdn.com/image/fetch/$s_!l-Pr!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 848w, https://substackcdn.com/image/fetch/$s_!l-Pr!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 1272w, https://substackcdn.com/image/fetch/$s_!l-Pr!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!l-Pr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png" width="1359" height="730" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:730,&quot;width&quot;:1359,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!l-Pr!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 424w, https://substackcdn.com/image/fetch/$s_!l-Pr!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 848w, https://substackcdn.com/image/fetch/$s_!l-Pr!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 1272w, https://substackcdn.com/image/fetch/$s_!l-Pr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdf67c36-1311-4310-a596-756ef47c1aa9_1359x730.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>This is one of those maps that’s also a </span><a href="https://xkcd.com/1138/" rel="">population map</a><span> — pedestrian deaths tend to be concentrated in major metro areas, where there’s the most people and the most driving. If we look at pedestrian deaths by state, we see the same pattern, though it’s also clear some states are punching above and below their weight. The three states with the most pedestrian deaths — California, Florida, and Texas — are the three most populous states. But New York, the 4th most populous state, has fewer pedestrian deaths than Georgia, the 8th most populous state.</span></p><p>If we look at pedestrian deaths per capita, we see that deaths are much more frequent in the West and the South, and less frequent in the Northeast and the Midwest. This does not appear to be due to larger amounts of driving in the South and the West. There’s little correlation between the number of vehicle miles traveled and the pedestrian death rate.</p><p>These numbers are all from 2023. If we look at the change in pedestrian deaths over time, we can see that the rise in pedestrian deaths is worse in the South, but besides a handful of states (Minnesota, Rhode Island, New York, West Virginia, New Jersey, and Vermont), every state has seen substantial increases in pedestrian deaths. Whatever’s causing the increase in US pedestrian deaths is happening across the country.</p><p><span>We’ve seen that pedestrian deaths are more likely to occur in population centers, but FARS data also lets us look at the type of </span><em>road</em><span> where deaths occur:</span></p><p>The increase in fatalities is essentially entirely on urban roads — deaths on rural roads are flat. On most categories of urban road, pedestrian fatalities have doubled. Whatever is causing the increase in pedestrian deaths, it’s only happening in urban areas.</p><p>We can also look at other trends in pedestrian deaths for clues as to why they might be increasing. Here are pedestrian deaths by the hour the accident occurred, from 2007 to 2023:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!nMw8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!nMw8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 424w, https://substackcdn.com/image/fetch/$s_!nMw8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 848w, https://substackcdn.com/image/fetch/$s_!nMw8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 1272w, https://substackcdn.com/image/fetch/$s_!nMw8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!nMw8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png" width="720" height="444" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:444,&quot;width&quot;:720,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!nMw8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 424w, https://substackcdn.com/image/fetch/$s_!nMw8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 848w, https://substackcdn.com/image/fetch/$s_!nMw8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 1272w, https://substackcdn.com/image/fetch/$s_!nMw8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff815e70f-07f6-442e-9ce3-b04a070fd5ab_720x444.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And here’s the same chart in percentages:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!TslU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!TslU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 424w, https://substackcdn.com/image/fetch/$s_!TslU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 848w, https://substackcdn.com/image/fetch/$s_!TslU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 1272w, https://substackcdn.com/image/fetch/$s_!TslU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!TslU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png" width="704" height="448" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:448,&quot;width&quot;:704,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!TslU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 424w, https://substackcdn.com/image/fetch/$s_!TslU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 848w, https://substackcdn.com/image/fetch/$s_!TslU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 1272w, https://substackcdn.com/image/fetch/$s_!TslU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1306b654-c675-49a9-88ce-75b8fe0773f3_704x448.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Most pedestrian deaths occur at night, but the rate hasn’t changed much (the fraction of deaths between 6pm and 6am is up slightly from 69% in 2009 to 75% in 2023). Whatever’s causing the increase in pedestrian deaths doesn’t seem specific to one time of day.</p><p>Nor is it specific to one time of week. Deaths have become somewhat less likely to occur on Friday and Saturday, and somewhat more likely to occur during the week, but the shift isn’t dramatic.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!pp46!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!pp46!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 424w, https://substackcdn.com/image/fetch/$s_!pp46!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 848w, https://substackcdn.com/image/fetch/$s_!pp46!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 1272w, https://substackcdn.com/image/fetch/$s_!pp46!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!pp46!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png" width="675" height="844" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:844,&quot;width&quot;:675,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!pp46!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 424w, https://substackcdn.com/image/fetch/$s_!pp46!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 848w, https://substackcdn.com/image/fetch/$s_!pp46!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 1272w, https://substackcdn.com/image/fetch/$s_!pp46!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a24208-538a-4e6c-9058-1c3eabd27cf4_675x844.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>It’s also not specific to one time of year. The graph below shows pedestrian fatality frequency by month. Pedestrian deaths are more likely to occur in the fall and winter (presumably because there are fewer daylight hours and more driving in darkness), but monthly rates haven’t changed at all.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!xbqj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!xbqj!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 424w, https://substackcdn.com/image/fetch/$s_!xbqj!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 848w, https://substackcdn.com/image/fetch/$s_!xbqj!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 1272w, https://substackcdn.com/image/fetch/$s_!xbqj!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!xbqj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png" width="498" height="638" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:638,&quot;width&quot;:498,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!xbqj!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 424w, https://substackcdn.com/image/fetch/$s_!xbqj!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 848w, https://substackcdn.com/image/fetch/$s_!xbqj!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 1272w, https://substackcdn.com/image/fetch/$s_!xbqj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66a11c7b-88b9-4327-8727-f6153046d2eb_498x638.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>What about trends in the age of pedestrians killed? You sometimes see </span><a href="https://www.nbcnews.com/news/us-news/americas-cars-trucks-are-getting-bigger-are-front-blind-zones-children-rcna52109" rel="">claims</a><span> that children are increasingly at risk of getting killed by large trucks and SUVs, because they can’t be seen by the drivers. The graph below shows pedestrian deaths broken down into 10-year age buckets.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!wt1R!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wt1R!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 424w, https://substackcdn.com/image/fetch/$s_!wt1R!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 848w, https://substackcdn.com/image/fetch/$s_!wt1R!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 1272w, https://substackcdn.com/image/fetch/$s_!wt1R!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!wt1R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png" width="741" height="336" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:336,&quot;width&quot;:741,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wt1R!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 424w, https://substackcdn.com/image/fetch/$s_!wt1R!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 848w, https://substackcdn.com/image/fetch/$s_!wt1R!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 1272w, https://substackcdn.com/image/fetch/$s_!wt1R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88380d7a-9bc6-4e16-a2f1-3636febf7afd_741x336.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Deaths of children under 10 are actually down significantly (167 deaths in 2009 to 98 deaths in 2023), and deaths for ages 10-19 are down as well. The biggest increase in deaths actually comes from older age brackets: 30-39 year old deaths are up 153%, 60-69 year olds up 167%, and 70-79 year olds up 119%. So the problem isn’t young kids increasingly getting hit by cars that can’t see them.</p><p>What about the age of drivers?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!OYgq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!OYgq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 424w, https://substackcdn.com/image/fetch/$s_!OYgq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 848w, https://substackcdn.com/image/fetch/$s_!OYgq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 1272w, https://substackcdn.com/image/fetch/$s_!OYgq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!OYgq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png" width="666" height="333" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:333,&quot;width&quot;:666,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:83306,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.construction-physics.com/i/175619659?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!OYgq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 424w, https://substackcdn.com/image/fetch/$s_!OYgq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 848w, https://substackcdn.com/image/fetch/$s_!OYgq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 1272w, https://substackcdn.com/image/fetch/$s_!OYgq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96b92217-dab6-4874-8430-5398ec92ed0a_666x333.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Deaths are up in every driver age bracket, with older brackets (30-39, 60-69 and 70-79) up the most in percentage terms. So the problem isn’t reckless young drivers.</p><p>What about trends in drug and alcohol use? According to FARS data, deaths that involved drivers drinking are up modestly, but are a very small fraction of overall pedestrian deaths. The increase in driver drug use is up by a much greater fraction (more than doubling since 2009), but it’s still a small percentage of pedestrian deaths.</p><p>Interestingly, driver drug and alcohol use in pedestrian fatalities is greatly exceeded by pedestrian alcohol and drug use. (Pedestrian drug use in particular has more than tripled since 2009, while alcohol use is only up modestly.) It’s not enough to explain all of the huge increase in pedestrian deaths, but it’s notable.</p><p>An obvious possible factor in increased deaths is people increasingly distracted by their phones. Unfortunately, FARS data doesn’t give us much to go on here. Since 2010 FARS has tracked whether drivers are distracted (by phones or anything else), but in the vast majority (94%) of cases, drivers are marked “not distracted,” “not reported,” or “unknown.”</p><p>Relatedly, in the majority of pedestrian deaths, the pedestrian is blamed for the accident. In 66% of cases, pedestrians are described as “failing to yield right of way,” “jaywalking,” or “in roadway improperly.” In 87% of cases, the driver is not charged with anything following the accident. (This doesn’t necessarily mean the pedestrian was at fault — it could simply indicate that in a pedestrian death we only get one side of the story, which makes it hard to charge the driver with a crime.) About 75% of the time, fatal pedestrian accidents occur outside an intersection (a rate which has been steady since 2010), suggesting pedestrians are most often struck outside of a crosswalk.</p><p>One limitation of the FARS data is that it only tracks pedestrian fatalities: it doesn’t give us any information or trends in non-fatal pedestrian accidents. Many states, however, do track this information. The chart below shows the total number of accidents involving a pedestrian, and the number of pedestrian fatalities, for different years for 20 different states.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Zy-a!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Zy-a!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 424w, https://substackcdn.com/image/fetch/$s_!Zy-a!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 848w, https://substackcdn.com/image/fetch/$s_!Zy-a!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 1272w, https://substackcdn.com/image/fetch/$s_!Zy-a!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Zy-a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png" width="694" height="363" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/298b5790-49fa-401c-b110-a939458fe3b0_694x363.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:363,&quot;width&quot;:694,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:61407,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.construction-physics.com/i/175619659?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Zy-a!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 424w, https://substackcdn.com/image/fetch/$s_!Zy-a!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 848w, https://substackcdn.com/image/fetch/$s_!Zy-a!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 1272w, https://substackcdn.com/image/fetch/$s_!Zy-a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F298b5790-49fa-401c-b110-a939458fe3b0_694x363.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In nearly every state examined, the fatality rate for pedestrian accidents has risen dramatically in recent years. Oregon went from deaths in 6% of accidents in 2014 to 14% of accidents in 2023. Illinois went from 2.3% of pedestrian accidents being deadly in 2008 to 4.3% in 203. New Mexico went from 8.4% in 2008 to 16.8% in 2023. In many cases, overall pedestrian accidents were flat or even down (Illinois went from 5,877 accidents in 2008 to 4,533 accidents in 2023), even as the number of pedestrian fatalities went up.</p><p><span>Pedestrian accidents getting more deadly seems like fairly strong evidence for the theory that the rise in large SUVs is behind the uptick in pedestrian deaths: it’s not that more pedestrians are getting hit by vehicles, it’s that the ones that are getting hit are more likely to die. There’s other evidence that points to this theory. A </span><a href="https://www.iihs.org/news/detail/vehicles-with-higher-more-vertical-front-ends-pose-greater-risk-to-pedestrians?utm_source=chatgpt.com" rel="">study</a><span> by the Insurance Institute for Highway Safety analyzed 17,897 pedestrian accidents across seven states, and found pedestrians were substantially more likely to be killed when struck by tall vehicles and vehicles with blunt front ends.</span></p><p>However, there’s also some muddying evidence here. If the increase of size and frequency of trucks and SUVs was behind the increase in pedestrian deaths, we wouldn’t expect to see an increase in the frequency of pedestrians killed by sedans or compact cars. However, if we look at pedestrian deaths by model of car, we see that pedestrian deaths involving popular sedans have increased as well. Pedestrian deaths involving Honda Civics and Accords, Toyota Corollas and Camrys, and Nissan Altimas have all increased substantially.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!EtUJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EtUJ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 424w, https://substackcdn.com/image/fetch/$s_!EtUJ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 848w, https://substackcdn.com/image/fetch/$s_!EtUJ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 1272w, https://substackcdn.com/image/fetch/$s_!EtUJ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!EtUJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png" width="416" height="287" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cda38b46-0661-43e3-9656-9df4166207cc_416x287.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:287,&quot;width&quot;:416,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!EtUJ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 424w, https://substackcdn.com/image/fetch/$s_!EtUJ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 848w, https://substackcdn.com/image/fetch/$s_!EtUJ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 1272w, https://substackcdn.com/image/fetch/$s_!EtUJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcda38b46-0661-43e3-9656-9df4166207cc_416x287.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This does not seem to be because these cars suddenly got more popular. Sales volume since the early 2000s is relatively flat or declining:</p><p>One possible explanation is that pedestrian accidents are more deadly because cars are speeding more frequently, but it’s hard to find evidence of this. The proportion of vehicles speeding in both pedestrian fatalities and fatalities in car accidents overall is flat.</p><p>On the state level, different states have dramatically different speeding rates (presumably due to classification differences), but overall rates of speeding collisions seem to be mostly flat or declining.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!z_-K!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!z_-K!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 424w, https://substackcdn.com/image/fetch/$s_!z_-K!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 848w, https://substackcdn.com/image/fetch/$s_!z_-K!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 1272w, https://substackcdn.com/image/fetch/$s_!z_-K!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!z_-K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png" width="796" height="219" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:219,&quot;width&quot;:796,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!z_-K!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 424w, https://substackcdn.com/image/fetch/$s_!z_-K!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 848w, https://substackcdn.com/image/fetch/$s_!z_-K!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 1272w, https://substackcdn.com/image/fetch/$s_!z_-K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12a6b521-c437-49e6-a5b4-cd908e3878d9_796x219.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>We can also use state-level data to look at the “distracted by phones” theory: some states break out whether “distraction” or “driver inattention” is a factor in an accident. The chart below shows the percentage of all accidents where driver inattention (due to phones or anything else) was a listed factor. If being distracted by phones was a major driver of increased pedestrian fatalities, I’d expect it to also be increasingly a factor in car accidents more broadly.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!RTTf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!RTTf!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 424w, https://substackcdn.com/image/fetch/$s_!RTTf!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 848w, https://substackcdn.com/image/fetch/$s_!RTTf!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 1272w, https://substackcdn.com/image/fetch/$s_!RTTf!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!RTTf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png" width="794" height="208" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:208,&quot;width&quot;:794,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!RTTf!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 424w, https://substackcdn.com/image/fetch/$s_!RTTf!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 848w, https://substackcdn.com/image/fetch/$s_!RTTf!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 1272w, https://substackcdn.com/image/fetch/$s_!RTTf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ed0a01-8abd-4de1-b70c-c91f0223756a_794x208.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>There’s no real clear trend. In some states (such as Texas) the frequency of driver inattention as a factor has increased dramatically over time. But in other states it’s either flat (South Carolina, Kentucky), or has decreased substantially (Arizona, California). This doesn’t necessarily disconfirm the phone theory, as drivers may not be reporting that they were distracted (North Carolina’s annual car crash reports, </span><a href="https://connect.ncdot.gov/business/DMV/Pages/Crash-Facts.aspx" rel="">for instance</a><span>, note that “Driver Distraction is a self-reporting contributing circumstance. Therefore, the data collected may not reflect the severity of this issue.” But it’s some evidence against it.</span></p><p>Similarly, if being distracted by phones was a driver of pedestrian deaths, I’d expect there to be more frequent collisions overall. But the state-level data similarly doesn’t show any consistent trend. In some states (Texas, South Carolina) collisions are up substantially, though the rate of increase is less than for pedestrian deaths. But in California and Georgia, among others, they’re down.</p><p>To recap, here’s what we know about pedestrian deaths.</p><ul><li><p>Pedestrian deaths have risen substantially in the US since 2009, by nearly 80%. This increase is seen across the US, though not in every single state. The increase is highest in states in the West and South. There has not been a similar increase in other types of motor vehicle deaths, or in pedestrian deaths in other countries.</p></li><li><p>The increase has happened almost entirely on urban roads: pedestrian deaths on rural roads have remained roughly constant.</p></li><li><p>There has not been much change in what time of day, day of week, or time of year pedestrian deaths are occurring.</p></li><li><p>The 30-39 and 60-79 age brackets have seen the largest increase in victims. Pedestrian deaths of children and teenagers are down over this period. In terms of drivers, the increase has also been largest in the 30-39 and 60-79 age brackets.</p></li><li><p>It’s hard to pin the increase to any specific driver behavior on the road (including mobile phone use). Drivers are rarely charged with a motor vehicle violation following a pedestrian death, and are rarely categorized as “distracted” (by a phone or anything else). State-level data on frequency of driver inattention shows no consistent trends. Rates of driver drinking are only up modestly; rates of driver drug use have risen greatly in percentage terms, but remain a very small fraction of overall pedestrian death accidents. There doesn’t seem to be a clear trend in rates of collisions overall. Drivers don’t seem to be speeding more.</p></li><li><p>In terms of pedestrian behavior, the number of killed pedestrians believed to be using drugs has risen substantially over the period in question, but is still a small fraction of overall pedestrian deaths. Rates of alcohol use by pedestrians have increased modestly. In roughly 2/3rds of pedestrian deaths, the pedestrian is described as “failing to properly yield,” “jaywalking,” or as otherwise improperly in the roadway.</p></li><li><p>In terms of changes in the nature of vehicles, the fatality rate of pedestrian accidents (the proportion of accidents where a pedestrian is killed) has increased dramatically across many different states, suggesting pedestrian accidents are getting more deadly. The frequency of pedestrian deaths in both trucks/SUVs and sedans/compacts has risen substantially.</p></li></ul><p><span>Unfortunately, this doesn’t all add up to a clear cause. The strongest evidence seems to be for the “Big SUV hypothesis” — it’s hard to see what else could be causing the increase in deadliness of pedestrian accidents, and </span><em>not</em><span> cause a similar increase in other things. The Big SUV hypothesis also seems like something that could be limited to the US. But this on its own isn’t completely satisfying: if its big SUVs, why are pedestrian deaths for sedans increasing too? Why aren’t deaths increasing on rural roads? There are still unanswered questions here.</span></p><p>The evidence does not strongly support the “distracted drivers on cell phones” hypothesis, but neither does it totally disconfirm it. The fact that drivers are rarely charged with anything, and are rarely classified as having been driving distracted, could simply be due to the fact that we rarely get more than the driver’s side of the story in pedestrian fatalities. The fact that there’s not a general trend in more auto collisions, or more pedestrian non-fatal collisions, does push against this theory though.</p><p>Beyond these hypotheses, there’s also some evidence that increased drug use (both in drivers and pedestrians) is a factor in increased deaths, though almost certainly not the main one. We also can’t rule out that increased recklessness or distractedness on the part of pedestrians is playing a role.</p><p>One avenue to try and better understand this problem is to look at the level of individual cities, and to try to figure out why places like Boston and Seattle have so few pedestrian deaths compared to other cities.</p></div></div>]]></description>
        </item>
    </channel>
</rss>