<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 24 Nov 2023 02:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[YouTube is now blocking Ad Blockers – So I just make ads run 16x faster (380 pts)]]></title>
            <link>https://old.reddit.com/r/webdev/comments/181vbmk/youtube_is_now_blocking_ad_blockers_so_i_just/</link>
            <guid>38397817</guid>
            <pubDate>Thu, 23 Nov 2023 21:33:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/webdev/comments/181vbmk/youtube_is_now_blocking_ad_blockers_so_i_just/">https://old.reddit.com/r/webdev/comments/181vbmk/youtube_is_now_blocking_ad_blockers_so_i_just/</a>, See on <a href="https://news.ycombinator.com/item?id=38397817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>​</p>

<p><a href="https://i.redd.it/tqmt9f64p12c1.gif">YouTube Ad Skipper</a></p>

<ul>
<li>This gif is running at normal speed :)</li>
<li>You could use this as a backup to your AdBlocker - when YouTube forces you to turn the AdBlocker off</li>
<li>Will be turned into a browser extension that runs automatically (comment !remindme! 5 days)</li>
<li>Only speeds up Ads - doesn't affect your normal videos</li>
<li>Also mutes the Ads - doesn't affect your normal videos sounds</li>
<li>Autoplays the Ads so you can skip them faster</li>
<li>This demo doesn't click "skip" automatically - but it will in the next version :)</li>
</ul>

<p>​</p>

<p>If you enjoyed this little bookmarklet demo, I develop other cool extensions - like <a href="https://chromewebstore.google.com/detail/mobile-view-web-testing-d/clepmakjkiihmfoepipckkafafdepjne?hl=en-GB">Mobile View - Web Testing &amp; Device Simulator</a> (for responsive design!). If you want to develop them too, we have a lievely <a href="https://discord.gg/taqUQWNZDV">server for extension developers</a> :)</p>

<p>Happy developing!</p>

<p>Update: The extension has been submitted for review :) so i will post a follow up post as soon as it’s ready</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluetooth stack modifications to improve audio quality on headphones without AA (230 pts)]]></title>
            <link>https://habr.com/en/articles/456476/</link>
            <guid>38396658</guid>
            <pubDate>Thu, 23 Nov 2023 19:41:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://habr.com/en/articles/456476/">https://habr.com/en/articles/456476/</a>, See on <a href="https://news.ycombinator.com/item?id=38396658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!----> <p><span><svg height="24" width="24"><title>Reading time</title> <use xlink:href="/img/megazord-v28.2fb1b1c1..svg#clock"></use></svg></span> <span>
    7 min
  </span></p> <p><span><svg height="24" width="24"><title>Views</title> <use xlink:href="/img/megazord-v28.2fb1b1c1..svg#counter-views"></use></svg> <span>46K</span></span></p></div><div xmlns="http://www.w3.org/1999/xhtml" id="post-content-body" data-gallery-root="" lang="en"><p><i>Before reading this article, it is recommended to read the previous one: <a href="https://habr.com/en/post/456182/">Audio over Bluetooth: most detailed information about profiles, codecs, and devices</a> / <a href="https://habr.com/ru/post/455316/">по-русски</a></i></p><p>

Some wireless headphone users note low sound quality and lack of high frequencies when using the standard Bluetooth SBC codec, which is supported by all headphones and other Bluetooth audio devices. A common recommendation to get better sound quality is to buy devices and headphones with aptX or LDAC codecs support. These codecs require licensing fees, that's why devices with them are more expensive.</p><p>

It turns out that the low quality of SBC is caused by artificial limitations of all current Bluetooth stacks and headphones' configuration, and this limitation can be circumvented on any existing device with software modification only.<a name="habracut"></a></p><h2>SBC codec</h2><p>SBC has lots of different parameters that are negotiated during the connection setup phase:</p><ul>
<li>Audio channel type and number: Joint Stereo, Stereo, Dual Channel, Mono;</li>
<li>Number of frequency bands: 4 or 8;</li>
<li>Number of audio blocks in one packet: 4, 8, 12, 16;</li>
<li>Quantization bit allocation algorithm: Loudness, SNR;</li>
<li>Maximum and minimum bit pool used in quantization process: usually 2-53.</li>
</ul><p>

The decoder is required to support any combination of these parameters. Encoder may implement only a part of them.<br>
Existing Bluetooth stacks usually negotiate the following set of options which I call «profile»: Joint Stereo, 8 bands, 16 blocks, Loudness, bitpool 2..53. This profile encodes 44.1 kHz stereo audio with 328 kbps bitrate.<br>
Bitpool is a parameter that changes encoding bitrate: the higher it is, the higher the bitrate, and hence the quality. But exact bitpool value corresponds to exact bitrate only within exact profile.<br>
The bitrate is also significantly affected by other parameters: audio channel type, number of frequency bands, number of audio blocks. You can increase the bitrate indirectly by negotiating non-standard profiles, without changing the bitpool.</p><p><img src="https://habrastorage.org/getpro/habr/formulas/359/ca0/835/359ca08359d109bf3c7633f9adae5744.svg" alt="$ bitrate = \frac{8 \times frame\_length \times sample\_rate}{subbands \times blocks} $" data-tex="display"></p>
<p><i><span color="#666666">Bitrate calculation formula</span></i></p><p>


For example, Dual Channel mode encodes channels separately, using individual bitpool for each channel, unlike Stereo or Joint Stereo, which use bitpool for both channels. Forcing the device to use Dual Channel instead of Joint Stereo will get us almost doubled bitrate of 617 kbps, with the same bitpool value of 53.<br>
To me it feels that bitpool should be an internal variable. I assume that it is an A2DP specification design fault that bitpool value is not bound to other codec parameters and only defined as an independent negotiated variable.</p><p>

Fixed bitpool and bitrate values originated from recommended profile for high quality audio. But the recommendation should not be the reason to set the limit on these parameters.</p><p>

<img src="https://habrastorage.org/r/w1560/getpro/habr/post_images/cc5/5bf/c7d/cc55bfc7d4e0a7e9ca4aee331f6c9992.png" alt="Bluetooth SBC profiles table" data-src="https://habrastorage.org/getpro/habr/post_images/cc5/5bf/c7d/cc55bfc7d4e0a7e9ca4aee331f6c9992.png"></p><p>

A2DP specification v1.2, which was active from 2007 to 2015, requires all decoders to work correctly with bitrates up to 512 kbps:</p><blockquote>The decoder of the SNK shall support all possible bitpool values that do not result in excess of the maximum bit rate. This profile limits the available maximum bit rate to 320kb/s for mono, and 512kb/s for two-channel modes.</blockquote><p>

No bitrate limit stated in the new version of the specification. It is assumed that modern headphones with EDR support released after 2015 can support bitrates up to 730 kbps.</p><p>

For some reason, all currently tested Bluetooth stacks (Linux (PulseAudio), Android, Blackberry and macOS) have artificial restrictions of maximum bitpool parameter, which directly affects the maximum bitrate. But this is not the biggest problem, almost all headphones also limit the maximum bitpool value to 53.<br>
As I've already seen in my tests, most devices work fine on a modified Bluetooth stack with a bitrate of 551 kbps, without interrupts and crackling. But such a bitrate will never be negotiated under normal conditions, with stock Bluetooth stacks.</p><h2>Bluetooth stack modification</h2><p>Every A2DP-compatible Bluetooth stack should support Dual Channel mode, but there's no way to force usage of this mode.</p><p>

Let's add a switch to the user interface! I made patches for Android 8.1 and Android 9, which add full support for Dual Channel into the stack and into developer menu, and handle Dual Channel mode as an additional «HD Audio» codec like aptX, AAC or LDAC by adding a tick to the Bluetooth device settings Here's what it looks like:</p><p>

<img src="https://habrastorage.org/r/w1560/webt/xd/k_/nn/xdk_nnwukcz446jxexaes4pdscw.png" alt="image" data-src="https://habrastorage.org/webt/xd/k_/nn/xdk_nnwukcz446jxexaes4pdscw.png"></p><p>

<a href="https://review.lineageos.org/q/topic:bt-sbc-hd-dualchannel-pie+(status:open%20OR%20status:merged)">Android 9 patch</a><br>
<a href="https://review.lineageos.org/q/topic:bt-sbc-hd-dualchannel+(status:open%20OR%20status:merged)">Android 8.1 patch</a></p><p>

This checkbox toggles Dual Channel mode which is configured to use <b>551 kbps</b> for EDR 3 Mb/s devices and <b>452 kbps</b> for EDR 2 Mb/s devices.</p><p>

This patchset has been merged into the following alternative firmwares:</p><ul>
<li><b>LineageOS 15.1</b> (since 31 March, 2019) and <b>16.0</b> (since May 13, 2019)</li>
<li><b>Resurrection Remix</b> (since May 14, 2019)</li>
<li><b>crDroid</b> (since May 13, 2019)</li>
</ul><h2>Where did 551 and 452 kbps come from?</h2><p>Bluetooth time division technology is designed to efficiently transmit large fixed-size packets. Data transfer occurs in slots, the largest number of slots sent in one transmission is 5. There are also transfer modes using 1 or 3 slots, but not 2 or 4. You can transfer up to 679 bytes in 5 slots, at a connection speed of 2 Mbps, and up to 1021 bytes at a speed of 3 Mbps. In 3 slots maximum amount of data is 367 and 552 bytes, respectively.</p><p>

<img src="https://habrastorage.org/r/w1560/getpro/habr/post_images/b86/6c9/653/b866c9653eeb255db44e7fd94a409a90.png" alt="image" data-src="https://habrastorage.org/getpro/habr/post_images/b86/6c9/653/b866c9653eeb255db44e7fd94a409a90.png"></p><p>

If we want to transfer less data than 679 or 1021 bytes but more than 367 or 552 bytes, the transfer will still take 5 slots, and the transmission will take the same amount of time, which reduces the transmission efficiency.</p><p>

<img src="https://habrastorage.org/r/w1560/webt/u_/9e/at/u_9eati7dqlaegfvhdkpmwxsnxq.png" alt="image" data-src="https://habrastorage.org/webt/u_/9e/at/u_9eati7dqlaegfvhdkpmwxsnxq.png"></p><p>

44100 Hz audio encoded using SBC in Dual Channel mode with bitpool = 38, 16 blocks in a frame, 8 frequency bands, produces audio frame of 164 bytes, with 452 kb/s bitrate.<br>
Audio payload should be encapsulated into L2CAP and AVDTP transmission protocols, which deduct 16 bytes of overhead from the audio payload.</p><p><img src="https://habrastorage.org/getpro/habr/formulas/b5d/9b7/6de/b5d9b76de49674bf1b01dc6a373de765.svg" alt="$\begin{align*} framelength &amp;= 4 + \frac{subbands \times channels}{2} + \\ &amp; \begin{cases} \frac{blocks \times channels \times bitpool}{8} &amp; \text{if mono or dual channel mode} \\ \frac{subbands+blocks \times bitpool}{8} &amp; \text{if joint stereo mode} \\ \frac{blocks \times bitpool}{8} &amp; \text{if stereo mode} \\ \end{cases} \end{align*}$" data-tex="display"></p><p>



One 5-slot audio transmission can contain up to 4 audio frames:</p><pre><code>679 (EDR 2 mbit/s DH5) - 4 (L2CAP) - 12 (AVDTP/RTP) - 1 (SBC header) - (164*4) = 6</code></pre><p>
A single packet transmits up to 11.7 ms of audio data, which will be transmitted in 3.75 ms, and we have 6 unused bytes left in the packet.<br>
If you slightly raise the bitpool, 4 audio frames can no longer be packed into a single transmission. You'll have to send 3 frames at a time, which reduces transmission efficiency, reduces the amount of audio transmitted in one packet, and will increase chance for audio stutter under poor radio conditions.</p><p>

551 kbps bitrate for EDR 3 Mbps was selected using the same principle: with Bitpool 47, 16 blocks per frame, 8 frequency bands, the frame size is 200 bytes, with a bit rate of 551 kbps. Single transmission can bundle up to 5 frames or 14.6 ms of music.</p><p>

The algorithm for calculating all the SBC parameters is quite complicated, you can easily make a mistake if you try to calculate all of them manually, so I made an interactive calculator to help those who interested:<br>
<a href="https://btcodecs.valdikss.org.ru/sbc-bitrate-calculator/">btcodecs.valdikss.org.ru/sbc-bitrate-calculator</a></p><h2>What is that all for?</h2><p>Contrary to popular belief of aptX sound quality, in some cases it can produce worse audio quality than SBC with a standard 328k bitrate.</p><p>

SBC dynamically allocates quantization bits for frequency bands, acting on a «bottom-to-top» basis. If the whole bitrate was used for the lower and middle frequencies, the upper frequencies are «cut off» (silenced).<br>
aptX quantizes frequency bands with the same number of bits constantly, which makes it a constant bitrate codec: 352 kbps for 44.1 kHz, 384 kbps for 48 kHz. It can't «transfer bits» to frequencies that need them most. Unlike SBC, aptX will not «cut» frequencies, but will add quantization noise to them, reducing the dynamic range of audio, and sometimes introducing crackles. SBC, on the contrary, «eats the details» — discards the quietest areas.<br>
On average, compared to SBC 328k, aptX makes less distortion in music with a wide frequency range, but on music with a narrow frequency range and a wide dynamic range SBC 328k sometimes wins.</p><p>

Let us consider a special case, a piano recording. Here's a spectrogram:<br>
<a href="https://habrastorage.org/webt/er/nq/rc/ernqrcwa0ic5mqwopjg5zbu_fxm.png"><img src="https://habrastorage.org/r/w780q1/webt/i9/uh/z1/i9uhz1ewchvoprxywldrtfknlom.jpeg" alt="image" data-src="https://habrastorage.org/webt/i9/uh/z1/i9uhz1ewchvoprxywldrtfknlom.jpeg" data-blurred="true"></a></p><p>

Most energy locates in the 0-4 kHz frequencies, and lasts up to 10 kHz.<br>
The spectrogram of the file aptX file looks like this:<br>
<a href="https://habrastorage.org/webt/dl/bl/do/dlbldoq_rdrjykephl2ostfbafk.png"><img src="https://habrastorage.org/r/w780q1/webt/sx/3i/lw/sx3ilwm6riwrjelw-ofmljdd54m.jpeg" alt="image" data-src="https://habrastorage.org/webt/sx/3i/lw/sx3ilwm6riwrjelw-ofmljdd54m.jpeg" data-blurred="true"></a></p><p>

Here is SBC 328k:<br>
<a href="https://habrastorage.org/webt/us/3m/ke/us3mke0av1s_1ezkyk6ycq1g2vo.png"><img src="https://habrastorage.org/r/w780q1/webt/ah/ob/br/ahobbramaxjmsr0htxagkiflomk.jpeg" alt="image" data-src="https://habrastorage.org/webt/ah/ob/br/ahobbramaxjmsr0htxagkiflomk.jpeg" data-blurred="true"></a></p><p>

It can be seen that the SBC 328k periodically completely cut off the range above 16 kHz, and used all available bitrates for the frequency ranges below this value. However, aptX introduced more distortions into the frequency spectrum audible by the human ear, which can be seen on the subtracted original audio spectrogram from the aptX spectrogram (the brighter, the more distortion):<br>
<a href="https://habrastorage.org/webt/ug/-i/5z/ug-i5zpihrfnvumf9no_glecqna.png"><img src="https://habrastorage.org/r/w780q1/webt/_e/vj/gv/_evjgvlrkbymm5ptv5ymkn2orya.jpeg" alt="image" data-src="https://habrastorage.org/webt/_e/vj/gv/_evjgvlrkbymm5ptv5ymkn2orya.jpeg" data-blurred="true"></a></p><p>

SBC 328k has introduced less distortion to the signal in the range from 0 to 10 kHz, and the rest frequences had been сut:<br>
<a href="https://habrastorage.org/webt/tf/x8/7z/tfx87z8hpenx51spblrfvkc-ihe.png"><img src="https://habrastorage.org/r/w780q1/webt/-a/m6/23/-am623wsmq09jfcr80kmkjubp0u.jpeg" alt="image" data-src="https://habrastorage.org/webt/-a/m6/23/-am623wsmq09jfcr80kmkjubp0u.jpeg" data-blurred="true"></a></p><p>

485k bitrate was enough for SBC to save the entire frequency range, without cutting off the bands.<br>
<a href="https://habrastorage.org/webt/_c/mc/xy/_cmcxyxwlf7u4tv-rbplwk5bmtu.png"><img src="https://habrastorage.org/r/w780q1/webt/xx/a0/pa/xxa0patcvltugsfjwxzmh_na_rm.jpeg" alt="image" data-src="https://habrastorage.org/webt/xx/a0/pa/xxa0patcvltugsfjwxzmh_na_rm.jpeg" data-blurred="true"></a></p><p>

SBC 485k produces much better results in the range of 0-15 kHz on this sample than aptX, and a smaller but still noticeable difference at 15-22 kHz (the darker, the less distortion):<br>
<a href="https://habrastorage.org/webt/e-/qz/h8/e-qzh8azmingcbhvuwxj8iptuau.png"><img src="https://habrastorage.org/r/w780q1/webt/yv/mi/7v/yvmi7vfj5-ot3ztrfv-gvx43yxy.jpeg" alt="image" data-src="https://habrastorage.org/webt/yv/mi/7v/yvmi7vfj5-ot3ztrfv-gvx43yxy.jpeg" data-blurred="true"></a></p><p>

<a href="https://files.catbox.moe/kpx711.zip">Archive with original audio and SBC/aptX-encoded files</a>.</p><p>

By switching to a high-bitrate SBC you will get sound which is superior to aptX most of the time, on any headphones. On headphones with EDR 3 Mb/s support, 551 kb/s SBC produces sound that is very close to aptX HD.</p><h2>Can we go even further?</h2><p>Android patchset has an additional option to increase bitrate for EDR 2 mbps devices even further. You can bump the bitrate from 452 kbps to 595 kbps, at the cost of reducing the stability of the transmission in case of congested radio conditions.<br>
Just set the persist.bluetooth.sbc_hd_higher_bitrate variable to 1:</p><pre><code># setprop persist.bluetooth.sbc_hd_higher_bitrate 1</code></pre><p>
Extreme bit rate patch is currently merged only in LineageOS 15.1, but not in 16.0.</p><h2>Compatibility with the devices</h2><p>SBC Dual Channel is supported by almost all headphones, speakers and car head units. This is no wonder — the standard mandates its support in any decoding devices. There are a small number of devices on which this mode causes problems, but these are very rare cases.<br>
More details on compatible devices can be found at <a href="http://4pda.ru/forum/index.php?showtopic=914135">4pda</a> and <a href="https://forum.xda-developers.com/android/software-hacking/improve-bluetooth-audio-quality-t3832615">xda-developers</a>.</p><h2>Sound difference comparison</h2><p>I made a web service that encodes audio to SBC (as well as to aptX and aptX HD) in real time, right in the browser. You can compare the sound of different SBC profiles and other codecs without actually transmitting audio via Bluetooth using this service, on any wired headphones, speakers, and on your favorite music. You can also change the encoding parameters directly during audio playback.<br>
<a href="https://btcodecs.valdikss.org.ru/sbc-encoder/">btcodecs.valdikss.org.ru/sbc-encoder</a></p><h2>Contacting Android developers</h2><p>I tried to contact many Bluetooth stack developers from Google, asking them to consider including my patches to the main Android branch—AOSP, but did not receive a single answer. My patches in <a href="https://android-review.googlesource.com/q/topic:bt-sbc-hd-dualchannel+(status:open%20OR%20status:merged)">Gerrit code review system for Android</a> have not received any comments from anyone involved in the development as well.<br>
I would be glad if anyone could tell Google developers about this implementation of SBC HD for Android. The gerrit patchset is already out of date (this is one of the earliest revisions), but I will update it if developers are interested in my changes (it's not easy for me to update it, I don't have Android Q compatible devices).</p><h2>Conclusion</h2><p>Users of LineageOS, Resurrection Remix and crDroid firmwares can enhance Bluetooth audio quality by ticking a checkbox in Bluetooth device settings. Linux users can also get a higher SBC bitrate by installing <a href="https://lists.freedesktop.org/archives/pulseaudio-discuss/2019-June/031168.html"> the patch from Pali Rohár</a>, which among other things, adds support for the aptX, aptX HD and FastStream codecs.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shellcheck finds bugs in your shell scripts (248 pts)]]></title>
            <link>https://www.shellcheck.net/</link>
            <guid>38396345</guid>
            <pubDate>Thu, 23 Nov 2023 19:16:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.shellcheck.net/">https://www.shellcheck.net/</a>, See on <a href="https://news.ycombinator.com/item?id=38396345">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
          <p>
          finds&nbsp;bugs in your shell&nbsp;scripts.
      </p></div>

      <p>
        You can <code>cabal</code>, <code>apt</code>, <code>dnf</code>, <code>pkg</code> or <code>brew&nbsp;install</code> it locally right&nbsp;now.
      </p>

      <p>
        Paste a script to try it out:
      </p>

      <div id="editorwindow">
            <p>📄</p>
            <p>Your Editor (<a href="https://github.com/ajaxorg/ace">Ace</a><span id="downloadingindicator"> – loading 800kb of JS</span>) </p>
            <p>▼</p>
            <p>▲
          </p></div>

      <div id="terminalwindow">
            <p>
              If you paste a script in the editor above, this window will show shellcheck output.
            </p>
          </div>

      <div>
        <h2>ShellCheck is...</h2>
        <div>
          <ul>
            <li><a href="https://github.com/koalaman/shellcheck/blob/master/LICENSE">GPLv3</a>: free as in freedom</li>
            <li>documented on the <a href="https://www.shellcheck.net/wiki/Home">ShellCheck Wiki</a></li>
            <li>available on <a href="https://github.com/koalaman/shellcheck">GitHub</a> (as is <a href="https://github.com/koalaman/shellcheck.net">this website</a>)</li>
            <li>already packaged for your <a href="https://github.com/koalaman/shellcheck#user-content-installing">distro or package&nbsp;manager</a> </li>
            <li>supported as an <a href="https://github.com/koalaman/shellcheck#user-content-in-your-editor">integrated linter</a> in major&nbsp;editors</li>
            <li>available in <a href="https://codeclimate.com/">CodeClimate</a>, <a href="https://www.codacy.com/">Codacy</a> and <a href="https://www.codefactor.io/">CodeFactor</a> to auto-check your GitHub repo</li>
            <li>written in Haskell, if you're into that sort&nbsp;of&nbsp;thing.</li>
          </ul>
        </div>
      </div>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After OpenAI's blowup, it seems pretty clear that 'AI safety' isn't a real thing (211 pts)]]></title>
            <link>https://gizmodo.com/ai-safety-openai-sam-altman-ouster-back-microsoft-1851038439</link>
            <guid>38395655</guid>
            <pubDate>Thu, 23 Nov 2023 18:10:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/ai-safety-openai-sam-altman-ouster-back-microsoft-1851038439">https://gizmodo.com/ai-safety-openai-sam-altman-ouster-back-microsoft-1851038439</a>, See on <a href="https://news.ycombinator.com/item?id=38395655">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Welcome to AI This Week, Gizmodo’s weekly roundup where we do a deep dive on what’s been happening in artificial intelligence.</em></p><div data-video-id="195264" data-monetizable="true" data-position="sidebar" data-video-title="Why is Everyone Suing AI Companies? | Future Tech" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="290" data-playlist="195264,195603,194160" data-current="195264"><div><p>Why is Everyone Suing AI Companies? | Future Tech</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/195264/195264_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195264/195264_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195264/195264_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195264/195264_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/20725.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>Well, holy shit. As far as the tech industry goes, it’s hard to say whether there’s ever been a more shocking series of events than the ones that took place over the last several days. The palace intrigue and boardroom drama of <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/openai-fires-ceo-sam-altman-1851032184&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/openai-fires-ceo-sam-altman-1851032184">Sam Altman’s ousting</a></span> by the OpenAI board (and his <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/openai-rehires-ceo-sam-altman-microsoft-larry-summers-1851041834&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/openai-rehires-ceo-sam-altman-microsoft-larry-summers-1851041834">victorious reinstatement</a></span> earlier today) will doubtlessly go down in history as one of the most explosive episodes to ever befall Silicon Valley. That said, the long-term fallout from this gripping incident is bound to be a lot less enjoyable than the initial spectacle of it.</p><p>The “coup,” as many have referred to it, has largely been attributed to an ideological rift  between Sam and the OpenAI board over the pace of technological development at the company. So, this narrative goes, the board, which is supposed to have ultimate say over the direction of the organization, was <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety" target="_blank" rel="noopener noreferrer">concerned about the rate at which Altman was pushing to commercialize the technology</a></span>, and decided to eject him with extreme prejudice. Altman, who was subsequently backed by OpenAI’s powerful partner and funder, Microsoft, as well as a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/microsoft-hires-sam-altman-openai-staff-threaten-quit-1851035418&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/microsoft-hires-sam-altman-openai-staff-threaten-quit-1851035418">majority of the startup’s staff</a></span>, subsequently led a  counter-coup, pushing out the traitors and re-instating himself as the leader of the company. </p><p>So much of the drama of the episode seems to revolve around this argument between Altman and the board over “AI safety.” Indeed, this fraught chapter in the company’s history seems like a flare up of OpenAI’s two opposing personalities—one based around research and responsible technological development, and the other based around making shitloads of money. One side decidedly overpowered the other (hint: it was the money side).</p><p>Other writers have already offered <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://news.bloomberglaw.com/mergers-and-acquisitions/matt-levines-money-stuff-who-controls-openai&quot;,{&quot;metric25&quot;:1}]]" href="https://news.bloomberglaw.com/mergers-and-acquisitions/matt-levines-money-stuff-who-controls-openai" target="_blank" rel="noopener noreferrer">break downs</a></span> about how OpenAI’s unique organizational structure seems to have set it on a collision course with itself. Maybe you’ve seen the startup’s <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/MattZeitlin/status/1726649308827746780&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/MattZeitlin/status/1726649308827746780" target="_blank" rel="noopener noreferrer">org chart</a></span> floating around the web but, in case you haven’t, here’s a quick recap: Unlike pretty much every other technology business that exists, OpenAI is <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://openai.com/our-structure&quot;,{&quot;metric25&quot;:1}]]" href="https://openai.com/our-structure" target="_blank" rel="noopener noreferrer">actually a non-profit</a></span>, governed wholly by its board, that operates and controls a for-profit company. This design is supposed to  prioritize the organization’s mission of pursuing the public good over money. OpenAI’s <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://openai.com/our-structure&quot;,{&quot;metric25&quot;:1}]]" href="https://openai.com/our-structure" target="_blank" rel="noopener noreferrer">own self-description</a></span> promotes this idealistic notion—that it’s main aim is to make the world a better place, not make money:</p><blockquote data-type="BlockQuote"><p>We designed OpenAI’s structure—a partnership between our original Nonprofit and a new capped profit arm—as a chassis for OpenAI’s mission: to build artificial general intelligence (AGI) that is safe and benefits all of humanity.</p></blockquote><p>Indeed, the board’s charter owes its allegiance to “humanity,” not to its shareholders. So, despite the fact that <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/microsoft-chatgpt-openai-partnership-rocky-start-1850536201&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/microsoft-chatgpt-openai-partnership-rocky-start-1850536201">Microsoft has poured a megaton of money and resources into OpenAI</a></span>, the startup’s board is still (hypothetically) supposed to have final say over what happens with its products and technology. That said, the company part of the organization is <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.wsj.com/tech/ai/openai-seeks-new-valuation-of-up-to-90-billion-in-sale-of-existing-shares-ed6229e0&quot;,{&quot;metric25&quot;:1}]]" href="https://www.wsj.com/tech/ai/openai-seeks-new-valuation-of-up-to-90-billion-in-sale-of-existing-shares-ed6229e0" target="_blank" rel="noopener noreferrer">reported to be worth tens of billions of dollars</a></span>. As many have already noted, the organization’s ethical mission seems to have come directly into  conflict with the economic interests of those who had invested in the organization. As per usual, the money won. </p><p>All of this said, you could make the case that we shouldn’t fully endorse this interpretation of the weekend’s events yet, since the actual reasons for Altman’s ousting have still not been made public. For the most part, members of the company either <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.washingtonpost.com/technology/2023/11/22/sam-altman-fired-y-combinator-paul-graham/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.washingtonpost.com/technology/2023/11/22/sam-altman-fired-y-combinator-paul-graham/" target="_blank" rel="noopener noreferrer">aren’t talking</a></span> about the reasons Sam was pushed out or have <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.nasdaq.com/articles/openais-new-ceo-says-real-reason-behind-sam-altman-ouster-not-ai-safety:-gives-clue-on&quot;,{&quot;metric25&quot;:1}]]" href="https://www.nasdaq.com/articles/openais-new-ceo-says-real-reason-behind-sam-altman-ouster-not-ai-safety:-gives-clue-on" target="_blank" rel="noopener noreferrer">flatly denied</a></span> that his ousting had anything to do with AI safety. Alternate theories have swirled in the meantime, with some suggesting that the real reasons for Altman’s aggressive exit were decidedly more colorful—like accusations he <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.vox.com/future-perfect/2023/11/21/23971765/openai-sam-altman-microsoft&quot;,{&quot;metric25&quot;:1}]]" href="https://www.vox.com/future-perfect/2023/11/21/23971765/openai-sam-altman-microsoft" target="_blank" rel="noopener noreferrer">pursued additional funding</a></span> via autocratic Mideast regimes.</p><p>But to get too bogged down in speculating about the specific catalysts for OpenAI’s drama is to ignore what the whole episode has revealed: as far as the real world is concerned, “AI safety” in Silicon Valley is pretty much null and void. Indeed, we now know that despite its supposedly bullet-proof organizational structure and its stated mission of responsible AI development, OpenAI was never going to be allowed to actually put ethics before money.</p><p>To be clear, AI safety is a really important field, and, were it to be actually practiced by corporate America, that would be one thing.<strong> </strong>That said, the version of it that  existed at OpenAI—arguably one of the companies that has <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/" target="_blank" rel="noopener noreferrer">done the most</a></span> to pursue a “safety” oriented model—doesn’t seem to have been much of a match for the realpolitik machinations of the tech industry. In even more frank terms, the  folks who were supposed to be defending us from runaway AI (i.e., the board members)—the ones who were ordained with responsible stewardship over this powerful technology—don’t seem to have known what they were doing. They don’t seem to  have understood that Sam had all the industry  connections, the friends in high places, was well-liked, and that moving against him in a world where that kind of social capital is everything amounted to career suicide. If you come at the king, you best not miss.</p><p>In short: If the point of corporate AI safety is to protect humanity from runaway AI, then, as an effective strategy for doing that, it has effectively just flunked its first big test. That’s because it’s sorta hard to put your faith in a group of people who weren’t even capable of predicting the very predictable outcome that would occur when they fired their boss. How, exactly, can such a group be trusted with overseeing a supposedly “super-intelligent,” world-shattering technology? If you can’t outfox a gaggle of outraged investors, then you probably can’t outfox the Skynet-type entity you claim to be building. That said, I would argue we also can’t trust the craven, money-obsessed C-suite that has now reasserted its dominance. Imo, they’re <em>obviously</em> not going to do the right thing. So, effectively, humanity is stuck between a rock and a hard place.</p><p>As the conflict from the OpenAI dustup settles, it seems like the company is well positioned to get back to business as usual. After <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.businessinsider.com/openai-criticized-for-lack-of-diversity-on-board-2023-11&quot;,{&quot;metric25&quot;:1}]]" href="https://www.businessinsider.com/openai-criticized-for-lack-of-diversity-on-board-2023-11" target="_blank" rel="noopener noreferrer">jettisoning</a></span> the only two women on its board, the company added <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/is-economics-the-most-misogynist-of-the-sciences-1661836788&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/is-economics-the-most-misogynist-of-the-sciences-1661836788">fiscal goon Larry Summers</a></span>. Altman is back at the company (as is former company president Greg Brockman, who stepped down in solidarity with Altman), and Microsoft’s top executive, Satya Nadella, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.nytimes.com/2023/11/22/technology/openai-sam-altman-returns.html&quot;,{&quot;metric25&quot;:1}]]" href="https://www.nytimes.com/2023/11/22/technology/openai-sam-altman-returns.html" target="_blank" rel="noopener noreferrer">has said that</a></span> he is “encouraged by the changes to OpenAI board” and said it’s a “first essential step on a path to more stable, well-informed, and effective governance.” </p><p>With the board’s failure, it seems clear that OpenAI’s do-gooders may have not only set back their own “safety” mission, but  might have also kicked off a backlash against the AI ethics movement writ large. Case in point: This weekend’s drama seems to have further radicalized an already pretty radical anti-safety ideology that had been circulating the business. The <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/marc-andreessen-is-wrong-about-everything-1850934367&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/marc-andreessen-is-wrong-about-everything-1850934367">“effective accelerationists”</a></span> (abbreviated “e/acc”) believe that stuff like additional government regulations, “tech ethics” and “AI safety” are all  cumbersome obstacles to true technological development and exponential profit. Over the weekend, as the narrative about “AI safety” emerged, some of the more fervent adherents of this belief system took to X to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/BasedBeffJezos/status/1727457621425197230&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/BasedBeffJezos/status/1727457621425197230" target="_blank" rel="noopener noreferrer">decry what they perceived to be an attack</a></span> on the true victim of the episode (<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/BasedBeffJezos/status/1727461698460651938&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/BasedBeffJezos/status/1727461698460651938" target="_blank" rel="noopener noreferrer">capitalism, of course</a></span>).</p><p>To some degree, the whole point of the tech industry’s embrace of “ethics” and “safety” is about reassurance. Companies realize that the technologies they are selling can be disconcerting and disruptive; they want to reassure the public that they’re doing their best to protect consumers and society. At the end of the day, though, we now know there’s no reason  to believe that those efforts will ever make a difference if the company’s “ethics” end up conflicting with its money. And when have those two things ever not conflicted?</p><h3 id="h255226"><a id=""></a>Question of the day: What was the best meme to emerge from the OpenAI drama?</h3><figure data-id="09078363ab51d12d926d3be8dfab7939" data-recommend-id="image://09078363ab51d12d926d3be8dfab7939" data-format="png" data-width="1006" data-height="634" data-lightbox="true" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><span data-id="09078363ab51d12d926d3be8dfab7939" data-recommend-id="image://09078363ab51d12d926d3be8dfab7939" data-format="png" data-width="1006" data-height="634" data-lightbox="true" data-recommended="false" data-hide="false"></span></figure><p>This week’s <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/microsoft-hires-sam-altman-openai-staff-threaten-quit-1851035418&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/microsoft-hires-sam-altman-openai-staff-threaten-quit-1851035418">unprecedented imbroglio</a></span> inspired so many memes and snarky takes that the ability to choose a favorite seems nearly impossible. In fact, the scandal spawned several different <em>genres</em> of memes altogether. In the immediate aftermath of Altman’s ouster there were plenty of <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/AlmostMedia/status/1725677735404863948&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/AlmostMedia/status/1725677735404863948" target="_blank" rel="noopener noreferrer">Rust Cohl conspiracy memes</a></span> circulating, as the tech world scrambled to understand just what, exactly, it was witnessing. There were also jokes about <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/nope_its_lily/status/1725659894593036340&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/nope_its_lily/status/1725659894593036340" target="_blank" rel="noopener noreferrer">who should replace</a></span> Altman and <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/RealNick05/status/1725908713821675689&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/RealNick05/status/1725908713821675689" target="_blank" rel="noopener noreferrer">what may have caused</a></span> the power struggle in the first place. Then, as it became clear that Microsoft would be standing behind the ousted CEO, the narrative—and the memes—shifted. The <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/danielmerja/status/1726019471993639400&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/danielmerja/status/1726019471993639400" target="_blank" rel="noopener noreferrer">triumphant-Sam-returning-to-OpenAI-after-ousting-the-board genre</a></span> became popular, as did tons of <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/0xgaut/status/1726613382495940659&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/0xgaut/status/1726613382495940659" target="_blank" rel="noopener noreferrer">Satya Nadelle-related memes</a></span>. There were, of course, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/ankitkr0/status/1726521654292185365&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/ankitkr0/status/1726521654292185365" target="_blank" rel="noopener noreferrer"><em>Succession</em> memes</a></span>. And, finally, an inevitable genre of meme emerged in which X users openly <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/buccocapital/status/1726618734792757428&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/buccocapital/status/1726618734792757428" target="_blank" rel="noopener noreferrer">mocked the OpenAI board</a></span> for having so totally blown the coup against Altman. I personally found this <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/rowancheung/status/1727210716573335742&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/rowancheung/status/1727210716573335742" target="_blank" rel="noopener noreferrer">deepfake video</a></span> that swaps Altman’s face with that of Jordan Belfort in <em>The Wolf of Wall Street</em> to be a good one. That said, sound off in the comments with your favorite.</p><h3 id="h255227"><a id=""></a><strong>More headlines from this week</strong></h3><ul data-type="List" data-style="Bullet"><li><strong>The other AI company that had a really bad week.</strong> OpenAI isn’t the only tech firm that went through the wringer this week. Cruise, the robotaxi company owned by General Motors, is also having a pretty tough go of it. The company’s founder and CEO, Kyle Vogt, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/cruise-ceo-kyle-vogt-resigns-after-public-safety-blowup-1851035716#:~:text=Vogt%20says%20he%20will%20spend,Thanks%20for%20the%20great%20ride!%E2%80%9D&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/cruise-ceo-kyle-vogt-resigns-after-public-safety-blowup-1851035716#:~:text=Vogt%20says%20he%20will%20spend,Thanks%20for%20the%20great%20ride!%E2%80%9D">resigned</a></span> on Monday after the state of California accused the company of failing to disclose key details related to a violent incident with a pedestrian. Vogt founded the company in 2013 and shepherded it to a prominent place in the automated travel industry. However, the company’s bungled <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/california-lets-self-driving-taxis-loose-in-san-francis-1850728535&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/california-lets-self-driving-taxis-loose-in-san-francis-1850728535">rollout of vehicles in San Francisco</a></span> in August led to widespread consternation and heaps of complaints from city residents and public safety officials. Cruise’s scandals led the company to pull all of its vehicles <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/cruise-suspends-driverless-taxis-1850966144&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/cruise-suspends-driverless-taxis-1850966144">off the roads in California</a></span> in October and, then, eventually, to halt operations across the country. </li><li><strong>MC Hammer is apparently a huge OpenAI fan</strong>. To add to the weirdness of this week, we also found out that “U Can’t Touch This” rapper MC Hammer is a confirmed OpenAI stan. On Wednesday, as the chaos of this week’s power struggle came to an end, the rapper <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/MCHammer/status/1727248949210456230?s=20&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/MCHammer/status/1727248949210456230?s=20" target="_blank" rel="noopener noreferrer">tweeted</a></span>: “Salute and congratulations to the 710 plus<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/OpenAI&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/OpenAI" target="_blank" rel="noopener noreferrer">@OpenAI</a></span> team members who gave an unparalleled demonstration of loyalty, love and commitment to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/sama&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/sama" target="_blank" rel="noopener noreferrer">@sama</a></span> and <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/gdb&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/gdb" target="_blank" rel="noopener noreferrer">@gdb</a></span> in these perilous times it was a thing of beauty to witness.” </li><li><strong>Creatives are losing the AI copyright war</strong>. Sarah Silverman’s lawsuit against OpenAI and Meta isn’t going so well. This week, it was revealed that the comedian’s lawsuit against the tech giants (which she’s accused of copyright violations) has floundered. Silverman isn’t alone. A lawsuit filed by a number of visual artists against Midjourney and Stability AI was <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.reuters.com/legal/litigation/judge-pares-down-artists-ai-copyright-lawsuit-against-midjourney-stability-ai-2023-10-30/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.reuters.com/legal/litigation/judge-pares-down-artists-ai-copyright-lawsuit-against-midjourney-stability-ai-2023-10-30/" target="_blank" rel="noopener noreferrer">all but thrown out</a></span> by a judge last month. That said, though these lawsuits appear to be failing, it could just be a matter of finding the proper legal argument for them to succeed. Though the current claims may not be strong enough, the cases <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.artnews.com/art-news/news/ai-class-action-lawsuit-dismissal-hearing-stabilityai-midjourney-deviantart-1234675071/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.artnews.com/art-news/news/ai-class-action-lawsuit-dismissal-hearing-stabilityai-midjourney-deviantart-1234675071/" target="_blank" rel="noopener noreferrer">could be revised and refiled</a></span>. </li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Committing to Rust for Kernel Code (182 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/952029/412bfd44912e90b2/</link>
            <guid>38394787</guid>
            <pubDate>Thu, 23 Nov 2023 16:56:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/952029/412bfd44912e90b2/">https://lwn.net/SubscriberLink/952029/412bfd44912e90b2/</a>, See on <a href="https://news.ycombinator.com/item?id=38394787">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-none,v 1.2 2005-11-04 22:11:18 corbet Exp $ -->
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
Rust has been a prominent topic at the Kernel Maintainers Summit for the
last couple of years, and the 2023 meeting continued that tradition.  As
Rust-for-Linux developer Miguel Ojeda noted at the beginning of the session
dedicated to the topic, the level of interest in using Rust for kernel
development has increased significantly over the last year.  But Rust was
explicitly added to Linux as an experiment; is the kernel community now
ready to say that the experiment has succeeded?
</p><p>
The Rust-for-Linux project has added a full-time engineer in the last year,
Ojeda said, and a student developer as well.  Various companies have joined
in to support this work.  There is also work underway to get the <a href="https://lwn.net/Articles/698724/">Coccinelle</a> tool working with Rust code.  A
priority at the moment is bringing in more reviewers for the code that is
being posted.
</p><p>
On the toolchain front, work on <a href="https://github.com/Rust-GCC/gccrs">gccrs</a>, the GCC-based Rust
compiler, has slowed significantly.  The <a href="https://github.com/rust-lang/rustc_codegen_gcc">GCC code generator
for <tt>rustc</tt></a> is showing better progress; it can compile kernel
code now and has been merged into the compiler.  This GCC-based backend
will enable the expansion of Rust support to architectures that are not
supported by the LLVM-based <tt>rustc</tt>.  Meanwhile, the Rust project
itself is increasing its involvement in this work; this is good, since the
kernel has some unique requirements and will need guarantees that language
changes won't break kernel code in the future.
</p><p>
<a href="https://lwn.net/Articles/952032/"><img src="https://static.lwn.net/images/conf/2023/lpc/MiguelOjeda-sm.png" alt="[Miguel Ojeda]" title="Miguel Ojeda"></a>

Within the kernel, work is proceeding in a number of subsystems.  The Rust
implementation of Android's binder is working well and its performance is
on a par with the C implementation.  The amount of unsafe code that was
needed to get there was pleasingly small.  Filesystem bindings are the
subject of work by Wedson Almeida Filho, who is targeting read-only support
for now.  The object there is to make it possible to implement a filesystem
in 100% safe Rust.
</p><p>
In general, he is finding an increasing number of maintainers who are open
to the idea of using Rust.  That leads to an issue the Rust developers have
run up against, though.  It would be good to have some reference drivers in
the kernel as an example of how drivers can be written and to make it
possible to compare Rust and C drivers.  The best way to do that often
seems to be to merge a Rust driver that duplicates the functionality of an
existing C driver — but that sort of duplicate functionality is not
welcomed by maintainers.  Perhaps, he said, it would be good to allow a few
duplicate drivers that are not meant for actual use, but only as examples
for other developers to use.
</p><p>
There are some other challenges; upstreaming the block-layer abstractions
has run into some resistance.  Virtual filesystem layer maintainer
Christian Brauner said that he is not opposed to merging those
abstractions, but he would rather not do that and see filesystems built on
it right away.  He would prefer to see an implementation of something
relatively simple, along the lines of the binder driver, to show that
things work as expected.
</p><h4>A driver soon?</h4>
<p>
Dave Airlie, the maintainer of the DRM (graphics) subsystem, said that, if
he has his way, there will be a Rust DRM driver merged within the next
couple of releases.  Christoph Hellwig shot back that Airlie was willing to
"make everybody's life hell" so that he could play with his favorite toy.
Merging Rust, Hellwig said, would force others to deal with a second language,
new toolchains, and "wrappers with weird semantics".  Dan Williams said
that the current situation "is what success looks like", and that the
kernel community was already committed to Rust.
</p><p>
Airlie continued that a lot of the Rust work is currently blocked in a sort
of chicken-and-egg problem.  Abstractions cannot be merged until there is a
user for them, but the code needing those abstractions is blocked waiting
for code to land in multiple subsystems.  As a result, developers working
on Rust are dragging around large stacks of patches that they need to get
their code to work.  Breaking that roadblock will require letting in some
abstractions without immediate users.  Ojeda agreed that this problem has
been slowing progress, but said he has tried not to put pressure on
maintainers to merge code quickly.  In the case of networking, ironically,
the Rust developers <a href="https://lwn.net/Articles/949270/">had to ask the networking
maintainers to slow down</a> merging Rust code.
</p><p>
The conversation took several directions from there.  Greg Kroah-Hartman
said that merging the binder driver would be a good next step; it is
self-contained, has a single user that is committed to its maintenance, and
doesn't touch the rest of the kernel.  Kees Cook disputed the description
of Rust as a "toy", saying that there is a lot of pressure to not use C for
new code; Hellwig responded that the developers would have to rewrite
everything in Rust, otherwise the resulting dual-language code base would
be worse than what exists now.
</p><p>
Dave Chinner worried that maintainers lack the expertise to properly review
the abstractions that are being merged.  Airlie replied that maintainers
merge a lot of C APIs now without really understanding how they work.  A
lot of mistakes have been made in the process, but "we're still here".
When things turn out to be broken, they can be fixed, and that will happen
more quickly if the code goes upstream.
</p><p>
Ted Ts'o expressed concern about the burden that adding Rust code will
place on maintainers.  The Rust developers are setting higher standards
than have been set in the past, he said.  Getting good abstractions merged
is one thing, but who is responsible for reviewing drivers, and how will
tree-wide changes be handled?  The Rust effort, he said, is getting to a
point where it is impacting a growing part of the community.
</p><p>
Williams pointed out that <a href="https://lwn.net/Articles/951846/">the previous
session</a> had discussed how hard it is to get kernel subsystems to move
to new APIs; now, he said, there is talk of moving to a whole new language.
Hellwig said that the real problem is that the Rust bindings tend to work
differently than the C APIs they provide abstractions for; the new APIs may
well be better, but they are still completely new APIs.  What should be done,
he said, is to first fix the C APIs so that they are directly usable by
Rust code.  He proposed that, for each subsystem that is considering
bringing in Rust code, a year or two should first be spent on cleaning up
its APIs along those lines.  Ojeda said that this kind of API improvement
has already happened in some subsystems.
</p><p>
Linus Torvalds said that he was seeing a divide between the filesystem and
driver maintainers.  Developers on the filesystem side tend to be more
conservative, while the driver world "is the wild west".  Driver authors
tend not to understand concurrency, he said, and a lot of the code there is
broken and unfixable.  So it is unsurprising that there is interest in
bringing in a language that better supports the writing of correct and safe
code.
</p><p>
Brauner said that Rust can help with a lot of problems, since the compiler
can keep a lot of bugs from making it into the kernel.  But he worried
about whether there would be maintainer and development support for it a
few years from now.  Airlie again mentioned developers with out-of-tree
code needed by Rust code; Cook answered that the people shepherding that
code <i>are</i> maintainers, and that bringing it in would bring the
maintainers with it.  Airlie added that those maintainers are the sort of
younger developers that the kernel community would like to attract.
</p><p>
Chinner said that he would like to see a reimplementation of the ext2
filesystem in Rust.  It is a complete filesystem that makes wide use of the
kernel's APIs, but it is still small enough to read and understand.  If the
Rust APIs can support an ext2 implementation, they will be enough to
implement others as well.  Meanwhile, the ext2 implementation would be good
reference for maintainers, who could compare it to the C version.
</p><h4>Confidence</h4>
<p>
Ts'o asked when the community would feel enough confidence that it could
have modules where the only implementation is in Rust.  Binder could be a
good start, he said, perhaps followed by a driver that sees wider use.
Airlie said that he is considering a virtual graphics driver that
reimplements an existing C driver.  There is also the driver for Apple M1
GPUs.  He is feeling a fair amount of pressure to get it upstream and
is wondering if there is any reason why he should keep it out.  After that,
he would love to see a rewrite of the Nouveau driver for NVIDIA GPUs.
</p><p>
Arnd Bergmann said those drivers could be OK, but that it will be quite a
bit longer before something like a keyboard driver could be merged; the
toolchain just isn't ready, he said, for a driver what would be widely
used.  That led to a question about the frequent version upgrades being
seen in the kernel, which moved to Rust 1.73.0 for 6.7.  That upgrade
process will eventually stop and a minimum Rust version will be set once
the important features that the kernel depends on have stabilized.  He said
that he has been working to get the kernel code into the Rust
continuous-integration tests to help ensure that it continues working as
the compiler and language evolve.
</p><p>
Bergmann said that he didn't plan to look seriously at the language until
it could be compiled with GCC.  Torvalds answered that, while he used to
find problems in the LLVM Clang compiler, now he's more likely to find
problems with GCC instead; he now builds with Clang.  Ojeda said that he is
working on finding developer resources for gccrs; the project is currently
sitting on over 800 out-of-tree patches and still has a lot of work to do
on top of that.  GCC support will be a while, he said.
</p><p>
Ts'o complained that the language still isn't entirely stable.  This could
be a particular problem for the confidential-computing community; they are
concerned about security and, as a consequence, about backports to
long-term-support kernels.  But if those kernels are on different Rust
versions, those backports will be problematic.  Ojeda said that, while it
is a "crazy idea", backporting the version upgrades could be considered.
He doesn't think that the change rate will be high enough to be a problem,
though.
</p><p>
At the conclusion, Torvalds pointed out that there have been problems over
the years with GCC changes breaking the kernel; the same will surely happen
with Rust, but it will be the same thing in the end.  The session, well
over time, was brought to a halt at this point.  Whether the kernel
community has truly concluded that it is committed to Rust remains to be
seen; there will almost certainly be pull requests adding significant Rust
code in the near future.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Development_tools-Rust">Development tools/Rust</a></td></tr>
            <tr><td><a href="https://lwn.net/Archives/ConferenceIndex/">Conference</a></td><td><a href="https://lwn.net/Archives/ConferenceIndex/#Kernel_Maintainers_Summit-2023">Kernel Maintainers Summit/2023</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/952029/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Story of Titanium (171 pts)]]></title>
            <link>https://www.construction-physics.com/p/the-story-of-titanium</link>
            <guid>38394635</guid>
            <pubDate>Thu, 23 Nov 2023 16:43:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.construction-physics.com/p/the-story-of-titanium">https://www.construction-physics.com/p/the-story-of-titanium</a>, See on <a href="https://news.ycombinator.com/item?id=38394635">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>The earth contains a lot of titanium - it’s the </span><a href="https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust" rel="">ninth most abundant element</a><span> in the earth’s crust. By mass, there’s more titanium in the earth’s crust than carbon by a factor of nearly 30, and more titanium than copper by a factor of nearly 100.</span></p><p><span>But despite its abundance, it's only recently that civilization has been able to use titanium as a metal (titanium dioxide has been in use somewhat longer as a paint pigment). Because titanium so readily bonds with oxygen and other elements, it doesn’t occur at all in metallic form in nature. </span><a href="https://archive.org/details/DTIC_AD0801280/page/n71/mode/1up?q=%22difficult+to+machine%22" rel="">One engineer</a><span> described titanium as a “streetwalker," because it will pick up anything and everything. While copper has been used by civilization since 7000 BC, and iron since around 3000 BC, titanium wasn’t discovered until the late 1700s, and wasn’t produced in metallic form until the late 19th century. As late as 1945, there was no commercial production of titanium, and the metal only existed in tiny amounts in labs. But less than 10 years later, thousands of tons of it were being made a year. And 10 years after that, it formed the literal backbone of the most advanced aerospace technology on the planet.</span></p><p><span>As a report to the </span><a href="https://nap.nationalacademies.org/read/1712/chapter/4#14" rel="">National Research Council notes</a><span>, “the birth of a tonnage structural metal industry is an unusual event. Only three such births have occurred in the past 100 years [now closer to 150] – aluminum, magnesium, and titanium – and no new one is in prospect.” How did titanium go from totally unused to a critical aerospace technology? What does it tell us about technological development? Let’s take a look.</span></p><p>Titanium was first discovered in 1790 by William Gregor, an English clergyman and chemist who realized he couldn’t identify a metal contained in a white oxide mixed in with the black sands of Cornwall. In 1795, Martin Klaproth, a Prussian chemist, was able to extract titanium from the mineral rutile. Because of the strong bond it formed with oxygen, Klaproth named the metal “titanium” after the Greek Titans.</p><p>Because titanium bonds so readily with other elements and contaminates so easily, it's extremely difficult to obtain in a pure state, and for the next hundred years titanium was mostly regarded as a laboratory curiosity. In the 1880s, two Swedish scientists successfully produced 94% pure titanium metal, and in 1910 Matthew Hunter, a scientist at General Electric, developed a variant of their process to produce metallic titanium while searching for a material for improved lightbulb filaments.</p><p>But a commercially viable process for producing titanium wasn’t developed until the 1930s. In 1930 William Kroll, a scientist from Luxembourg, began experimenting with titanium in his home lab, and developed a process to produce titanium by reacting titanium chloride (TiCl4) with magnesium under a vacuum. By 1938, he had successfully produced 50 pounds of titanium metal, and successfully formed it into wires, rods, sheets, and plating. Kroll came to the US in 1938 to attempt to sell his process, but was unsuccessful.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png" width="724" height="561" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9f78383e-815c-442f-b206-3a135861b996_724x561.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:561,&quot;width&quot;:724,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f78383e-815c-442f-b206-3a135861b996_724x561.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Kroll’s samples of titanium metal in 1938, via Kroll 1955</figcaption></figure></div><p>That same year, the US Bureau of Mines began to investigate titanium, in response to promising studies of its properties performed by the Philips Corporation (which had developed its own process for producing titanium). The Bureau of Mines concluded the Kroll process had the most potential as a commercial process and began to develop it. Its work was delayed by the war, but as early as 1944 the Bureau of Mines was making 15-pound batches of titanium in a plant that could make 100 pounds of titanium a week.</p><p>After the war, the Bureau’s work on titanium accelerated. By 1947 it had successfully scaled up Kroll’s process, and had produced two tons of titanium “sponge,” a porous, spongy metal created by the process, which is melted down to produce bars, sheets, wires, etc. A 1948 report on titanium’s properties commissioned by the Bureau concluded that titanium and its alloys had great potential engineering applications. Titanium was nearly as strong as stainless steel, but weighed 40% less. It was also incredibly corrosion-resistant, and maintained much more strength at elevated temperatures compared to aluminum. This made it potentially very useful for aerospace applications, where weight was at a premium and materials were often exposed to high temperatures.</p><p>The military had followed the progress of the Bureau’s development work, and interest in the metal was high after samples began to be investigated by Army, Navy, and Air Force labs. Titanium began to be called a “wonder metal”:</p><blockquote><p><em>The metal gained numerous advocates within the military and industry. Early promoters visualized the use of titanium in naval vessels, armor plate, tanks, trucks, landing craft, aircraft structures, and airborne equipment. It was thought that it could possibly replace both aluminum and steel in the design of many defense applications. - Simcoe 2018</em></p></blockquote><p>In 1948, titanium first began to be produced commercially, at a small DuPont plant that could produce 100 pounds of titanium a day. The first batches of titanium went to experimental use on military jets, such as the F-84 and the F-86. To try to kickstart the industry, the Air Force encouraged manufacturers to substitute steel with titanium, and the Army Ordnance Corporation placed an order for $1 million worth of titanium metal.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png" width="839" height="639" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:639,&quot;width&quot;:839,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa24e7ebd-a9b3-4ecf-abc5-a2d34c0b14ff_839x639.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>F-84, via wikipedia</figcaption></figure></div><p>In the press, titanium began to be called “the wonder metal," “the miracle metal," and the “Cinderella metal” (because it had been overlooked for so long). An executive for a company producing titanium noted that “Sensational magazine articles predicted that titanium would become the miracle metal-for spacecraft, ‘atomic furnaces,’ airplanes of all kinds, submarines, railroad tracks, truck bodies, portable bridges” (Rowley 1972). Between 1950 and 1952, more than two dozen companies announced plans to produce titanium.</p><p>But the nascent titanium industry struggled. In 1951, the materials advisory board projected the need for 30,000 tons of titanium products, but actual shipments were just 75 tons, barely enough for research applications. Producers had assumed that the same equipment for melting, rolling, and shaping stainless steel could be used for titanium, but this turned out to be very difficult: titanium didn’t behave like steel, or like any other metal. Titanium was found “not to forge like any other material,” (DTIC 1952) and stamping it in presses damaged the stamping dies. A company that studied grinding titanium noted that “titanium grinds unlike steel. Anything you have learned concerning the effective grinding of steel does not apply in the case of titanium”. The first attempts to use titanium on commercial aircraft resulted in a sheet of metal so brittle it could be torn in half like a sheet of paper. Mills found that they often “produced more scrap than useful metal" (Simcoe 2018).</p><p>To support the budding industry, the US government stepped in. It funded the construction of several titanium sponge plants, and agreed to purchase any surplus titanium sponge production for the national stockpile. It offered rapid amortization of titanium production equipment for tax purposes, and demonstrated production techniques at the Bureau of Mines’ pilot plant. The Army funded projects to develop better alloys, including one of 6% aluminum and 4% vanadium (Ti-6Al-4V) that remains the most popular alloy of titanium today, and is credited with saving the titanium industry. When it was found that rolling titanium into sheets consistently was difficult, in 1956 the Department of Defense initiated a program to develop sheet rolling of titanium, “one of the most comprehensive technical programs ever undertaken in metallurgy” (Simcoe 2018). Production problems were overcome, and titanium was increasingly used for aerospace applications. By 1958, Pratt and Whitney had produced 5000 jet engines with titanium components, and the US industry was producing thousands of tons of titanium products a year.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png" width="1456" height="1081" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1081,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8667efda-5f6d-480a-bc16-24037b636815_1600x1188.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A-12, via Wikipedia</figcaption></figure></div><p>In the late 1950s, Lockheed won a contract to develop a high-speed, high altitude reconnaissance plane for the CIA. Because it was the 12th iteration of a design codenamed “Archangel," it became known as the A-12. To meet the unprecedented performance requirements (a cruising speed of Mach 3 and a cruising altitude of nearly 90,000 feet), Lockheed needed a metal that would retain its strength at the hundreds of degrees the exterior of the plane would reach. This ruled out aluminum, leaving either stainless steel or titanium. Ultimately, titanium alloy was selected for the A-12, as it would cut the gross weight of the plane nearly in half.</p><p><span>Titanium had never been used to such an extent on an aircraft, or anywhere else. Lockheed had worked with titanium on a small scale since 1949 but prior to the A-12 titanium had mostly been used for small components on jet engines. For several years, for instance, 50% of all titanium was used in the </span><a href="https://en.wikipedia.org/wiki/Pratt_%26_Whitney_J57" rel="">J-57 jet engine</a><span>. But on the A-12, titanium would be used for nearly every part of the airplane – 93% of the gross weight of the A-12’s structure was titanium.</span></p><p>Building a plane out of titanium proved difficult. Initially Lockheed “had no idea how to extrude it, push it through into various shapes, or weld or rivet or drill it” (Rich 1994), and every production problem solved seemed to reveal two or three more. Titanium was found to be “totally incompatible” with chemicals like chlorine, fluorine, and cadmium. In one case, an engineer who marked a sheet of titanium using a pen with chlorine-based ink was shocked to see the ink etch away the metal like acid. Titanium bolts that were heated had their heads pop off, a problem that was eventually traced to cadmium-coated wrenches used to tighten them. Titanium welds made in the summer unexpectedly failed, due to (it was eventually realized) chlorine that the local utility added to the water during the summer to prevent algae growth.</p><p>When Lockheed tried to fabricate a portion of the forward fuselage, which had to be made from a novel “beta” titanium alloy, it found that the titanium was so brittle after heat treating that it would shatter if dropped on the floor. This was eventually resolved by replacing an acid-pickling process with one identical to that of Lockheed’s supplier, but not before scrapping thousands of titanium components. Of the first 6000 pieces fabricated from the beta titanium alloy, 95% were lost.</p><p>But over time, Lockheed overcame its production problems. In machining, for instance, drill bits initially needed to be replaced every ten holes, ten times as often as when drilling aluminum. In other machining operations, the rate of metal removal was just 5% of the rate when machining aluminum. To improve its machining, Lockheed developed new drill bits, cutting fluids, and cutting machinery, and learned the proper “feeds and speeds” for machining titanium (it was found, for instance, that small changes in cutting speed had a large effect on tool life). Over the course of the program, the rate of metal removal in machining was increased to “3 to 10 times the industry average” (Johnson 1970), and drill life was increased by more than a factor of 10.</p><p>The A-12 “practically spawned its own industrial base” (CIA 2012), and over the course of the program thousands of machinists, mechanics, fabricators, and other personnel were trained in how to work with titanium efficiently. As Lockheed gained production experience with titanium, it issued reports to the Air Force and to its vendors on production methods, and “set up training classes for machinists, a complete research facility for developing tools and procedures, and issued research contracts to competent outside vendors to develop improved equipment" (Johnson 1970).</p><p>The A-12 first flew in 1962. 14 years later, its successor, the better-known SR-71, set an airspeed record of nearly 2200 miles per hour, which remains unbroken today.</p><p>While titanium manufacturing for aerospace was ramping up, a very different use of the metal was being discovered. In 1952, Swedish medical researcher Per-Ingvar Brånemark was studying blood flow in healing bones. In one experiment studying the bone marrow of rabbits, Brånemark’s team implanted a tiny camera into rabbits legs, to watch the wound heal from the inside. When they later went to remove the camera, they found that the titanium camera casing had bonded with the bone.</p><p>At the time, it was thought that the body would eventually reject any foreign object implanted in it. Dr. Brånemark’s discovery that bone would bond directly with titanium (which he dubbed “osseointegration”) was radical, and had huge potential implications for medical implants. Brånemark quickly pivoted his research to study osseointegration, eventually receiving a grant from the US National Institutes of Health. Research on his own students (where he implanted a small piece of titanium in their arms) showed that titanium could be safely implanted in the body with no ill-effects.</p><p>Interestingly, during the course of this research, it was noticed that bone could conduct sound – a deaf patient was able to “hear” the ultrasonic vibrations used to check that the titanium had been implanted correctly. One of Brånemark’s students followed up on this discovery, and developed the first bone conduction implants to restore hearing in deaf people.</p><p><span>Brånemark’s team went on to develop titanium dental implants (which were often made from </span><a href="https://books.google.com/books?id=EhnsCAAAQBAJ&amp;pg=PA27&amp;dq=Titanium+world+war+2&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;source=gb_mobile_search&amp;ovdme=1&amp;sa=X&amp;ved=2ahUKEwi4uIr5zen_AhWukWoFHQT1Av0Q6AF6BAgDEAM#v=onepage&amp;q=Titanium%20world%20war%202&amp;f=false" rel="">surplus aircraft-grade titanium</a><span>) that lasted much longer than implants of other metals. Today, the Brånemark system of dental implants is still sold, and titanium is the most popular material for dental implants, as well as being used for other medical implants such as </span><a href="https://www.addmoretolives.com/titanium-vs-ceramic-which-type-of-hip-replacement-implant-is-better-for-you/" rel="">artificial hips</a><span>.</span></p><p>You can get a sense of the development of the titanium industry by reading reports on industrial symposiums held in the 1940s, 50s, and 60s.</p><p><span>The </span><a href="https://archive.org/details/DTIC_ADA382831/page/n3/mode/2up?q=subsidy" rel="">first symposium on titanium</a><span> was held in 1948, and was organized by the Navy to provide “a comprehensive review of the titanium research effort”. Several military organizations discussed their research programs, but most of the presentations were on topics such as physical properties of titanium and its various alloys, the crystal structure that resulted from different methods of fabrication, and methods of melting titanium sponge. The pages are full of pictures of laboratory setups, graphs of data on stress-strain relationships, phase diagrams, and magnified pictures of titanium microstructure. Nearly all the presentations are from either research labs or from companies trying to produce raw titanium “sponge” from ore.</span></p><p><span>In 1952, </span><a href="https://archive.org/details/DTIC_AD0635553/page/n30/mode/1up?q=subsidy" rel="">another titanium symposium</a><span> was held, this one sponsored by the Army’s Watertown Arsenal. By then, titanium was being manufactured in large quantities, and while the prior symposium had been focused on laboratory studies of titanium’s physical and chemical properties, the 1952 symposium was a “practical discussion of the properties, processing, machinability, and similar characteristics of titanium". While physical characteristics of titanium still took center stage, there was a practical slant to the discussions – how wide a sheet of titanium can be produced, how large an ingot of it can be made, how can it be forged, or pressed, or welded, and so on. Presentations were by titanium fabricators, but also by metalworking companies that had been experimenting with the metal.&nbsp;</span></p><p>Though by 1952 many of these companies had been working with titanium for years, there’s an air of uncertainty in many of the presentations, a distinct sense of “this is what we’ve learned so far, but there’s still much we don’t know.” A company that studied the effects of different working fluids when grinding titanium admitted that not enough was known about the chemistry at work to understand why different fluids had different effects. A company that studied surface treatments and polishing methods noted that “materials and methods for polishing titanium have not been definitively established," and that while “the most commonly used abrasives are not completely satisfactory," manufacturers were working on the problem, and “more efficient methods will no doubt be developed”. A company that studied cold-forming of titanium sheets described its own methods as “crude and undeveloped”.</p><p><span>In 1966, </span><a href="https://archive.org/details/DTIC_AD0801280/page/n71/mode/1up?q=%22difficult+to+machine%22" rel="">another titanium symposium was held</a><span>, this one sponsored by the Northrup Corporation. By this time, titanium had been used successfully for many years, and the purpose of this symposium was to “provide technical personnel of diversified disciplines with a working knowledge of titanium technology.” This time, the lion’s share of the presentations are by aerospace companies experienced in working with the metal, and the uncertain air that existed in the 1952 symposium is gone. A presenter on titanium’s corrosion resistance noted that “the corrosion resistance of titanium, unlike that of most metals, can be defined within rather simple limits." A presentation on forging noted that “titanium alloys are quite forgeable…The evidence which substantiates this statement is the large number of jet engine and missile components plus the growing lists of structural parts that have been produced in the last 10 years.” And a presentation on machining noted that “Fifteen years ago, titanium was considered to be very difficult to machine. Subsequent research and experience, however, have progressively improved this situation," the result of “gradual refinements in tool materials, machine tools, tool geometries, and cutting fluids”.</span></p><p>Thus, by the mid-1960s, titanium had become a mature engineering material. While there was still much to learn about titanium, the practical aspects of working with it and using it to solve engineering problems were well-understood, and it increasingly found use in aerospace and other industry applications. Following the A-12, for instance, military aircraft began to make extensive use of titanium in their structural frames. From military aircraft, titanium made its way into commercial aircraft. By 1971, 46% of titanium was going towards commercial aircraft, compared to 37% to government aerospace projects.</p><p>What can we learn from the story of titanium?</p><p>For one, titanium is a government research success story. Titanium metal was essentially willed into existence by the US government, which searched for a promising production process, successfully scaled it up when it found one, and performed much of the initial research on titanium’s material properties, potential alloys, and manufacturing methods. Nearly all early demand for titanium was for government aerospace projects, and when the nascent industry struggled, the government stepped in to subsidize production. As a result, titanium achieved a level of production in 10 years that took aluminum and magnesium nearly 30.</p><p>The government’s support of the early industry was successful: shortly after the program was initiated in 1951, the cost of titanium began to decline more steeply. Since then, titanium costs have fallen at an impressive 23% learning rate (ie: costs fall 23% every time cumulative production doubles), similar to the learning rate in solar PV production. When government subsidies were removed in the late 1950s, the industry struggled, but cost declines continued. And from the initial government projects in military aerospace, titanium has spread into commercial aircraft, medical implants, industrial equipment, and other uses. Titanium is thus a successful case of the government jumpstarting an industry.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png" width="681" height="471" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:471,&quot;width&quot;:681,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb915cb8-1ca7-40ba-83b8-d7dbcdfadb15_681x471.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Via USGS data</figcaption></figure></div><p>But titanium is also a story about the limits of this sort of jumpstarting. Despite its impressive learning rate, titanium remains an expensive, niche material. A 2006 report noted that titanium is five times as expensive as aluminum to refine and ten times as expensive as aluminum to turn into finished products. Despite initial expectations, titanium hasn’t widely displaced either aluminum or stainless steel, and is only used where its unique properties make its high cost worth it. The aerospace industry remains the largest user of titanium.</p><p>It's interesting to compare progress in titanium production with progress in solar photovoltaics. In both cases, the basic phenomenon (metallic titanium and producing electricity from sunlight) had been explored in the late 1800s, but it wasn’t until mid-20th century technology breakthroughs (the Kroll process and the silicon PV cell) that they became practical. In both cases, the US government funded much of the initial development, and acted as the first customer (government satellites and government aerospace projects). Both have similar learning curve slopes, and both technologies gradually expanded outside of their initial markets as knowledge was gained and the costs of the technology fell. And in both cases, there were sky-high expectations for the “potentially world-changing technology” that neither initially lived up to.</p><p>But whereas titanium remains a relatively niche, expensive technology, solar PV is increasingly widely deployed, and seems poised to become the primary method of electric power production. In learning curve terms, while both titanium and solar PV have similar learning rates, the solar PV curve has stretched much farther. Between 1975 and today, cumulative titanium production has increased by perhaps a factor of 5-10 (cumulative US consumption of titanium sponge was about 250,000 tons in 1975, and about 1.3 million tons in 2019). Cumulative solar PV production, on the other hand, has increased by a factor of more than 300,000. Though they have the same learning rate, solar PV has had many more doublings in production volume, and its costs have thus fallen much further.</p><p>I can see at least two potential factors here. One is that solar PV production has seen a much greater level of government support than titanium production has. In addition to early government support in the 1950s, solar PV also saw US and Japanese government investment in the 1970s, and German government support in the 1990s (via a generous feed-in tariff). Today, governments around the world support solar PV via feed in tariffs, tax credits, and renewable portfolio standards. Continued government subsidies have incentivized increased production, which has resulted in the costs of solar PV continuing to fall. Without that government support, the level of production of solar PV would have been much lower, and its march down the learning curve would have happened much more slowly.</p><p>Titanium, on the other hand, has seen much less government support. After subsidies were withdrawn in the late 1950s, the titanium industry has been dependent on large government or commercial aerospace projects. If those fail to materialize (such as when Cold War strategy pivoted from bombers to missiles, or when supersonic commercial aircraft development was canceled), the industry has struggled. If government support of the industry had continued, perhaps it would be farther along on its learning curve.</p><p>The other potential factor is technical: while there are many potential process improvements to solar PV manufacturing, there may be substantially fewer potential improvements in titanium production. In the 1950s, it was hoped/assumed that a better process for producing titanium sponge would come along to replace the Kroll process, which is a laborious and energy-intensive batch process that must be done in an inert atmosphere. But such a process has never materialized, and the Kroll process remains the primary method of refining titanium ore. Likewise, turning titanium sponge into metal is an energy and capital-intensive process, often requiring multiple rounds of melting the metal to achieve sufficient purity. This process has also changed little since the 1950s.</p><p><span>Beyond the lack of process improvements, titanium is just fundamentally difficult and expensive to deal with. Turning titanium ingots into bars and sheets is a challenge due to titanium’s reactivity: it readily absorbs impurities, requiring “frequent surface removal and trimming to eliminate surface defects” which are “costly and involve significant yield loss.” Machining titanium is likewise fundamentally expensive. </span><a href="https://www.rand.org/pubs/monographs/MG789.html" rel="">As one report notes</a><span>:</span></p><blockquote><p><em>The hardness that makes titanium so desirable also makes it more difficult to machine than traditional aluminum. This presents a challenge akin to that of machining high-strength steel. However, the process is complicated by titanium’s high reactivity and low thermal conductivity. It is highly reactive and tends to wear tools very quickly, especially at higher temperatures. The low thermal conductivity means that high temperatures can be generated easily in the course of machining. Consequently, titanium must be machined at lower tool speeds, slowing production.</em></p></blockquote><p>If there are simply fewer potential process improvements in titanium production compared to solar PV, due to the lack of better refining processes and the various physical constraints dictated by its chemistry, there’s less room for costs to fall. With less room for costs to fall, titanium remains an expensive, niche material, which in turn keeps production volumes low.</p><p>Titanium is also a story about the importance of serendipity in scientific discovery and technology advancement. Titanium’s biocompatibility, and its usefulness for medical implants, was discovered purely by chance. Studying biocompatibility led to another chance discovery, that of bone conduction of sound. Both of these discoveries led to the development of important medical technology, implants and hearing aids.</p><p>Finally, titanium is also a story about the critical role that manufacturing plays in technology development. The knowledge required to turn titanium into a practical technology came from the research lab, but it also came from the factory floor. Using titanium meant understanding its chemical properties, but it also meant figuring out how to forge it, weld it, press it, turn it into fasteners, design parts effectively with it, designing tools to machine it, and a million other shop floor discoveries that came from actually building things with the metal. As one producer noted, “you cannot ship a customer a carload full of tensile properties, nor a box full of Charpy tests. You have to make something out of the material in order to use these marvelous characteristics.” (DTIC 1952). It's only after the enormous effort to build the all-titanium A-12, and the training of thousands of machinists, fabricators, engineers, and other workers to work with titanium, that we begin to see titanium being used in large amounts in military and commercial aircraft. This sort of practical knowledge – the learning that comes from actual production – is critical for technological progress. Technology consists of materials and machines and ideas, but they’re all stitched together by a collection of people that know how to do things. It’s by way of those people doing those things, and understanding them better and better, that new and better technology becomes possible.</p><ul><li><p>Report of Symposium on Titanium, 1948</p></li><li><p>Proceedings of the titanium symposium at Watertown Arsenal, 1952</p></li><li><p>Titanium 1966: Lectures given at Norair symposium</p></li><li><p>Johnson 1970 - Some Development Aspects of the YF-12A Interceptor</p></li><li><p>Johnson 1981 - Development of the Lockheed SR-71 Blackbird</p></li><li><p>Rich 1994 - Skunk Works: A personal memoir of my years at Lockheed</p></li><li><p>Donachie 1988 - Titanium: A technical guide</p></li><li><p>Titanium: Past, Present, and Future (1983)</p></li><li><p>Tylecote 1976 - History of metallurgy</p></li><li><p>Simcoe 2018 - The history of metals in America</p></li><li><p>Robarge 2012 - Archangel: CIA’s supersonic A-12 reconnaissance aircraft</p></li><li><p>Seong 2009 - Titanium: industrial base, price trends, and technology initiatives</p></li><li><p>Abkowitz - The emergence of the titanium industry</p></li><li><p>Kroll 1955 - How commercial titanium and zirconium were born</p></li><li><p>Titanium in aerospace applications (1961)</p></li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chrome pushes forward with plans to limit ad blockers in the future (234 pts)]]></title>
            <link>https://www.malwarebytes.com/blog/news/2023/11/chrome-pushes-forward-with-plans-to-limit-ad-blockers-in-the-future</link>
            <guid>38394613</guid>
            <pubDate>Thu, 23 Nov 2023 16:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.malwarebytes.com/blog/news/2023/11/chrome-pushes-forward-with-plans-to-limit-ad-blockers-in-the-future">https://www.malwarebytes.com/blog/news/2023/11/chrome-pushes-forward-with-plans-to-limit-ad-blockers-in-the-future</a>, See on <a href="https://news.ycombinator.com/item?id=38394613">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>Google has <a href="https://developer.chrome.com/blog/resuming-the-transition-to-mv3/" target="_blank" rel="noreferrer noopener nofollow">announced</a> it will shut down Manifest V2 in June 2024 and move on to Manifest V3, the latest version of its Chrome extension specification that has faced criticism for putting limits on ad blockers. Roughly said, Manifest V2 and V3 are the rules that browser extension developers have to follow if they want their extensions to get accepted into the Google Play Store.</p>



<p>Manifest V2 is the old model. The Chrome Web Store no longer accepts <a href="https://developer.chrome.com/docs/extensions/mv2/" target="_blank" rel="noreferrer noopener nofollow">Manifest V2 extensions</a>, but browsers can still use them. For now. Manifest V3 is supported generally in Chrome 88 or later and will be the standard after the transition planned to take place in June 2024.</p>



<p>A popular type of browser extensions are ad blockers. Almost all these ad blockers work with block lists, which are long lists of domains, subdomains, and IP addresses that they filter out of your web traffic. These lists are commonly referred to as rulesets. One part of the transition will <a href="https://developer.chrome.com/blog/improvements-to-content-filtering-in-manifest-v3/" target="_blank" rel="noreferrer noopener nofollow">“improve” content filtering</a>. And to be fair, Google has made some compromises when it comes to the version as it’s now in the planning, compared to what it originally planned to do. </p>



<ul>
<li>Originally, each extension could offer users a choice of 50 static rulesets, and 10 of these rulesets could be enabled simultaneously. This changes to 50 extensions simultaneously and 100 in total.</li>



<li>Extensions could add up to 5,000 rules dynamically which encouraged using this functionality sparingly and made it easier for Google to detect abuse. Extensions can add rules dynamically to support more frequent updates and user-defined rules. But it comes with the risks of phishing or data theft because these “updates” are not checked during the Chrome Web Store review. For example, a redirect rule could be abused to inject affiliate links without consent. But Google has decided that <code>block</code> and <code>allow</code> are not that easily abused so it will allow up to 30,000 rules to be added dynamically.</li>
</ul>



<p>However, this is still far from enough to fully reach the potential of the best ad blockers we have now. And it’s not just the hard limits on filtering rulesets, there are a lot of other new limits on filtering. Items can’t be filtered based on the response headers or according to the URL in the address bar. Also, extension developers are limited in what regular expressions they can use, along with other technical limitations.</p>



<p>Even if this is not targeted at ad blockers specifically, it’s still a major change that makes blocking requests less flexible. But the bottom line result is that it limits the API that many ad blockers use, and replace it with a less capable one.</p>



<p>Google’s will tell you that by limiting extensions, the browser can be lighter on resources, and Google can protect your privacy from extension developers and calls it “a step in the direction of privacy, security, and performance.” The Electronic Frontier Foundation (EFF) however calls Manifest V3 <a href="https://www.eff.org/deeplinks/2021/12/chrome-users-beware-manifest-v3-deceitful-and-threatening" target="_blank" rel="noreferrer noopener nofollow">deceitful and threatening</a>.</p>



<blockquote>
<p>“Manifest V3 is another example of the inherent conflict of interest that comes from Google controlling both the dominant web browser and one of the largest internet advertising networks.”</p>
</blockquote>



<p>Under the new specifications, browser extensions that monitor and filter the web traffic between the browser and the website will have greatly reduced capabilities. This includes ad blockers and privacy-protective tracker blockers. No real surprise, considering Google has trackers installed on <a href="https://spreadprivacy.com/biggest-tracker-networks/" target="_blank" rel="noreferrer noopener nofollow">75% of the top one million websites</a>.</p>



<p><a href="https://www.youtube.com/watch?v=tpDFS-GUytg&amp;t=416s" target="_blank" rel="noreferrer noopener nofollow">According</a> to Firefox’s Add-on Operations Manager, most malicious extension that manage to get through the security review process, are usually interested in simply observing the conversation between your browser and whatever websites you visit. The malicious activity happens elsewhere, after the data has already been read. So in their mind, what would really help security is a more thorough review process, but that’s not something Google says it has plans for.</p>



<p>After looking at the arguments Google used to justify this transition, <a href="https://arstechnica.com/gadgets/2023/11/google-chrome-will-limit-ad-blockers-starting-june-2024/" target="_blank" rel="noreferrer noopener nofollow">ArsTechnica</a> came to the conclusion that there’s no justification for arbitrarily limiting the list of filter rules. It says once Manifest V3 happens, Chrome users will be limited to light ad blocker functionality while users will need to switch to Firefox or some other non-limited browser to get the full extension.</p>



<p>Nevertheless, Firefox said it will adopt Manifest V3 in the interest of cross-browser compatibility. And Chrome’s market share will certainly have influenced that decision as well.</p>



<p>Google Chrome Enterprise users with the “ExtensionManifestV2Availability” policy turned on will get an extra year of Manifest V2 compatibility. </p>



<p>If you want to help Malwarebytes get ready for the transition, you can <a href="https://forums.malwarebytes.com/topic/294541-malwarebytes-browser-guard-beta-for-manifest-v3/">test the beta version of Browser Guard</a> for Manifest V3.</p>



<hr>



<p><strong>We don’t just report on privacy—we offer you the option to use it.</strong></p>



<p>Privacy risks should never spread beyond a headline. Keep your online privacy yours by using&nbsp;<a href="https://www.malwarebytes.com/vpn">Malwarebytes Privacy VPN</a>.</p>



<hr>



<p><strong>Black Friday sale</strong></p>



<p>Save 50% on our Home bundles for a limited time only!</p>




		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guinea worm disease is close to being eradicated (137 pts)]]></title>
            <link>https://ourworldindata.org/guinea-worm-path-eradication</link>
            <guid>38394383</guid>
            <pubDate>Thu, 23 Nov 2023 16:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ourworldindata.org/guinea-worm-path-eradication">https://ourworldindata.org/guinea-worm-path-eradication</a>, See on <a href="https://news.ycombinator.com/item?id=38394383">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><p>In the late 1980s, there were near a million new cases of guinea worm disease recorded worldwide. In 2021, there were only 15. How was this achieved?</p><p><time>July 07, 2022</time></p></div><div>
<p>Guinea worm disease is a painful and debilitating disease that used to be common in Asia, the Middle East, and many countries in Africa.&nbsp;</p>
<p>It’s now close to being eradicated worldwide. This success is thanks to an eradication program that has focused on water treatment and filtration, public education, and providing safe sources of drinking water to reduce its spread.</p>
<h4 id="what-is-guinea-worm-disease">What is guinea worm disease?<a href="#what-is-guinea-worm-disease"></a></h4>
</div><div>
<p>The disease is caused by a parasite called guinea worm (<em>Dracunculus medinensis</em>). The worm’s larvae are carried by water fleas found in stagnant water in ponds, open wells, and freshwater lakes.</p>
<p>When someone drinks contaminated water, the larvae can invade their stomach and intestines.&nbsp;</p>
<p>Over time, they mature into adult worms – with female worms growing up to around a meter in length – and crawl through people’s connective tissue, joints, and bones. This growth leads to arthritic conditions, which can debilitate people for months. Around one in two hundred infected people develop a permanent disability from the disease.<a id="ref-1" href="#note-1"><sup>1</sup></a></p>
<p>Around a year after the infection, the worm begins to emerge from the skin through a painful blister. This process also increases the risks of other infections.</p>
<p>People often try to find relief from the infection by putting their blisters in open water. This might bring some temporary relief for them, but makes it harder to eliminate the disease. In the water, the worm can release its own larvae and if the water contains water fleas, this restarts the life cycle of the guinea worm.&nbsp;</p>
<p>The disease can be treated with pain medication and antibiotics, and by carefully removing the worm when it emerges.<a id="ref-2" href="#note-2"><sup>2</sup></a></p>
</div><div>
<p>
<h4 id="guinea-worm-disease-used-to-be-common">Guinea worm disease used to be common<a href="#guinea-worm-disease-used-to-be-common"></a></h4>
</p>

</div><div>
<p>This parasite has troubled humans for a long time. There are records of guinea worm disease dating back thousands of years.<a id="ref-3" href="#note-3"><sup>3</sup></a></p>
<p>It was endemic in Asia, the Middle East, and many countries in Africa in the early twentieth century.<a id="ref-4" href="#note-4"><sup>4</sup></a></p>
<p>It was common in poor remote villages without <a href="https://ourworldindata.org/water-access">access to clean drinking water</a>. This was because sources of stagnant water – such as large open wells and ponds – could be contaminated by water fleas that contained guinea worm larvae.</p>
<p>Unfortunately, people do not develop immunity to the disease if they have been infected, which means it was common for people to be reinfected several times. For example, in the 1960s, in some villages in South India, more than 70% of adults infected once had been reinfected later on, and 10% had been infected at least 10 times.<a id="ref-5" href="#note-5"><sup>5</sup></a></p>
<p>By the 1980s, guinea worm disease was known to be endemic in 20 countries in South Asia and parts of Africa. We see this in the map, which shows the number of reported cases by country in 1989.</p>
<p>In 1986, around 35,000 cases were reported to the World Health Organization (WHO). As surveillance improved, the number of detected cases increased to 890,000 in 1989.</p>
</div><div>
<p>
<h4 id="how-can-guinea-worm-disease-be-prevented">How can guinea worm disease be prevented?<a href="#how-can-guinea-worm-disease-be-prevented"></a></h4>
</p>

</div><div>
<p>Unfortunately, there are no vaccines against guinea worm disease.&nbsp;</p>
<p>However, the disease has several features that make it easy to prevent.&nbsp;</p>
<p>First, humans are the main ‘host’ of the disease, with only a few exceptions.<a id="ref-6" href="#note-6"><sup>6</sup></a> The worm larvae are unable to survive for more than a few weeks in water fleas.<a id="ref-7" href="#note-7"><sup>7</sup></a> This means the worms can easily die out if they are prevented from infecting humans.</p>
<p>That brings us to our second point: we know how to stop it from infecting people. When people avoid drinking contaminated water that contains water fleas and guinea worm larvae, they are prevented from being infected.</p>
<p>Third, the disease is seasonal. People infected in one season tend to release worms a year later, which restarts the seasonal cycle. In the past, when villages halted the spread of worms in a single season, the disease stopped entirely unless it was reintroduced from somewhere else.<a id="ref-8" href="#note-8"><sup>8</sup></a></p>
</div><div>
<p>
<h4 id="the-world-has-made-huge-progress-against-the-disease">The world has made huge progress against the disease<a href="#the-world-has-made-huge-progress-against-the-disease"></a></h4>
</p>

</div><div>
<p>The world has made tremendous progress in reducing the burden of this disease with the knowledge of how to prevent it from spreading.</p>
<p>The campaign to eradicate guinea worm disease began in the 1980s. It was led by a number of organizations including the Centers for Disease Control and Prevention in the United States (US CDC), the Carter Center, the WHO, and the United Nations Children’s Fund (UNICEF).<a id="ref-9" href="#note-9"><sup>9</sup></a></p>
<p>Village volunteers have played a major role in the eradication program. They provide people with water filters and larvicides, educate them about where to drink clean water, record cases, help treat patients who are suffering from the disease, and prevent them from releasing worms into the water.<a id="ref-10" href="#note-10"><sup>10</sup></a></p>
<p>Another key driver of progress is access to improved drinking water sources, which has become more common in many countries.</p>
<p>You can see the change since the start of the eradication campaign in the chart. Cases of guinea worm disease declined rapidly across many countries.&nbsp;</p>
<p>Over 890,000 cases were recorded worldwide in 1989. By 2021, there were just 15.&nbsp;</p>
<p>Almost all of the 15 cases were recorded in Chad.</p>
</div><div>
<p>
<h4 id="which-countries-have-eliminated-guinea-worm-disease">Which countries have eliminated guinea worm disease?<a href="#which-countries-have-eliminated-guinea-worm-disease"></a></h4>
</p>

</div><div>
<p>In many countries, guinea worm disease has been completely eliminated.</p>
<p>Countries are certified as free of guinea worm disease if they have reported zero indigenous cases for at least three consecutive years while having active surveillance.<a id="ref-11" href="#note-11"><sup>11</sup></a></p>
<p>On the map, you can see which countries are certified as being free of guinea worm disease. They are shown in blue. Using the timeline at the bottom of the chart you can see how each country’s status changed over time.</p>
<p>In 1996, 16 countries were known to be endemic for guinea worm disease. By 2021, only five countries remained endemic – Mali, Chad, South Sudan, Ethiopia, and Angola.</p>
</div><div>
<p>
<h4 id="we-are-close-to-eradicating-guinea-worm-disease-but-challenges-remain">We are close to eradicating guinea worm disease, but challenges remain<a href="#we-are-close-to-eradicating-guinea-worm-disease-but-challenges-remain"></a></h4>
</p>

</div><div>
<p>To eradicate guinea worm disease globally, there are several challenges we need to overcome.</p>
<p>A general challenge is that it takes around a year after infection for the worm to emerge from a person’s body. This is why countries need to monitor for new cases for several years after they have reported zero cases, in order to achieve certification.</p>
<p>Another problem is that a few countries, such as Chad and Ethiopia, have recently had outbreaks linked to dogs infected with the worms, which had not been seen before. That means extra efforts have been needed in recent years to prevent infections in dogs in those regions.<a id="ref-12" href="#note-12"><sup>12</sup></a></p>
<p>Finally, it has been difficult to eliminate guinea worm disease in countries with violence and conflict, where healthcare workers are less able to treat and prevent infections.<a id="ref-13" href="#note-13"><sup>13</sup></a></p>
<p>Despite these challenges, there has been a massive decline in guinea worm cases over time. Only 13 cases were reported globally in 2022. The world is so close to the goal and with dedicated effort, we may soon achieve it. After thousands of years, the entire world may soon be free of this debilitating disease.</p>
</div><div><hr><p><em><strong>Keep reading on Our World in Data:</strong></em></p><div data-no-lightbox="true" data-style="is-style-thin" data-title="Polio"><a href="https://ourworldindata.org/polio"><figure><img src="https://assets.ourworldindata.org/uploads/2022/04/Polio-featured-image-150x59.png" data-high-res-src="https://assets.ourworldindata.org/uploads/2022/04/Polio-featured-image.png" alt="Polio featured image" loading="lazy"></figure></a></div><p><strong>Acknowledgments:</strong> Hannah Ritchie and Max Roser provided very helpful guidance and comments that helped improve this post.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Developer account removed by Apple – $108,878 frozen (650 pts)]]></title>
            <link>https://seraleev.notion.site/Our-developer-account-was-removed-by-Apple-and-they-haven-t-paid-out-108-878-b61192711c74487480373badc70d42c0</link>
            <guid>38394364</guid>
            <pubDate>Thu, 23 Nov 2023 16:16:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://seraleev.notion.site/Our-developer-account-was-removed-by-Apple-and-they-haven-t-paid-out-108-878-b61192711c74487480373badc70d42c0">https://seraleev.notion.site/Our-developer-account-was-removed-by-Apple-and-they-haven-t-paid-out-108-878-b61192711c74487480373badc70d42c0</a>, See on <a href="https://news.ycombinator.com/item?id=38394364">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dbrand Is Suing Casetify (116 pts)]]></title>
            <link>https://twitter.com/dbrand/status/1727721586856222893</link>
            <guid>38394357</guid>
            <pubDate>Thu, 23 Nov 2023 16:15:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/dbrand/status/1727721586856222893">https://twitter.com/dbrand/status/1727721586856222893</a>, See on <a href="https://news.ycombinator.com/item?id=38394357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C diff spores resist bleach and remain viable on surgical scrubs andgown fabrics (250 pts)]]></title>
            <link>https://www.microbiologyresearch.org/content/journal/micro/10.1099/mic.0.001418</link>
            <guid>38393660</guid>
            <pubDate>Thu, 23 Nov 2023 15:20:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.microbiologyresearch.org/content/journal/micro/10.1099/mic.0.001418">https://www.microbiologyresearch.org/content/journal/micro/10.1099/mic.0.001418</a>, See on <a href="https://news.ycombinator.com/item?id=38393660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<nav aria-label="Article navigation">
<div>
<ul>
<li>
<a href="#" data-toggle="dropdown" role="button" title="Navigate Article Resources" aria-haspopup="true" aria-expanded="false"><i>info</i> 
Info</a> 
<ul>
<li id="abstract_tab">
<a href="#abstract_content" title="Article information" role="button" aria-pressed="false">
<span>
<i>
<i></i>
<i></i>
</i>
<strong>Article information </strong>
</span>
</a>
</li>
<li id="html_tab">
<a href="#html_fulltext" title="Full-Text" role="button" aria-pressed="true">
<span>

<strong>
Full-Text 
</strong>
</span>
</a>
</li>
<li id="dataandmedia_tab">
<a href="#dataandmedia" title="Figures &amp; Tables" role="button" aria-pressed="false">
<span>
<i></i>
<strong>
Figures and Tables 
</strong>
</span>
</a>
</li>
<li id="references">
<a href="#referenceContainer" title="References" role="button" aria-pressed="false">
<span>

<strong>
References 
(48)
</strong>
</span>
</a>
</li>
<li id="cite">
<a href="#cited" title="This content does not have any cited by information" tabindex="-1" role="button" aria-disabled="true">
<span>

<strong>
Cited By 
</strong>
</span>
</a>
</li>
<li id="supplementary_Tab">
<a href="#supplementary_data" title="This content does not have any supplements information" tabindex="-1" role="button" aria-disabled="true">
<span>
<i></i>
<strong>
Supplementary Material 
</strong>
</span>
</a>
</li>
<li id="metrics_tab">
<a href="#metrics_content" title="Metrics" role="button" aria-pressed="false">
<span>
<i></i>
<strong>
Metrics 
</strong>
</span>
</a>
</li>
</ul> 
</li>
<li id="sectionDropdownContainer">
<a href="#" title="Navigate fulltext Sections" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false" aria-disabled="true">
<i>list</i>
Sections
</a>

</li>
</ul>

</div>
</nav> 

<section id="tabbedpages">
<div id="abstract_content">
<div>
<h3 dir="auto">Abstract</h3>
<div dir="auto">
<p><span>&nbsp;<span>&nbsp;<a href="https://doi.org/10.1601/nm.28959" rel="namesforlife-name" target="xrefwindow" title="Clostridioides difficile - Click to open Names for Life widget">Clostridioides difficile</a>&nbsp;</span>&nbsp;</span> is the most common cause of antibiotic-associated diarrhoea globally. Its spores have been implicated in the prevalence of <span>&nbsp;<span>&nbsp;<a href="https://doi.org/10.1601/nm.28959" rel="namesforlife-name" target="xrefwindow" title="C. difficile - Click to open Names for Life widget">C. difficile</a>&nbsp;</span>&nbsp;</span> infection due to their resistance and transmission ability between surfaces. Currently, disinfectants such as chlorine-releasing agents (CRAs) and hydrogen peroxide are used to decontaminate and reduce the incidence of infections in clinical environments. Our previous research demonstrated the ability of <span>&nbsp;<span>&nbsp;<a href="https://doi.org/10.1601/nm.28959" rel="namesforlife-name" target="xrefwindow" title="C. difficile - Click to open Names for Life widget">C. difficile</a>&nbsp;</span>&nbsp;</span> spores to survive exposure to recommended concentrations of sodium dichloroisocyanurate in liquid form and within personal protective fabrics such as surgical gowns; however, the present study examined the spore response to clinical in-use concentrations of sodium hypochlorite. Spores were exposed to a 10 min contact time of 1000, 5000 and 10 000 p.p.m. sodium hypochlorite, and spore recovery was determined. To understand whether biocide-exposed spores transmitted across clinical surfaces <span>in vitro</span>, biocide-exposed spores were spiked onto surgical scrubs and patient gowns and recovery was determined by a plate transfer assay. Scanning electron microscopy was used to establish if there were any morphological changes to the outer spore coat. The results revealed that viable biocide-exposed <span>&nbsp;<span>&nbsp;<a href="https://doi.org/10.1601/nm.28959" rel="namesforlife-name" target="xrefwindow" title="C. difficile - Click to open Names for Life widget">C. difficile</a>&nbsp;</span>&nbsp;</span> spores can be recovered from surgical scrubs and patient gowns, with no observable changes to spore morphology, highlighting the potential of these fabrics as vectors of spore transmission. This study demonstrates that alternative strategies should be urgently sought to disinfect <span>&nbsp;<span>&nbsp;<a href="https://doi.org/10.1601/nm.28959" rel="namesforlife-name" target="xrefwindow" title="C. difficile - Click to open Names for Life widget">C. difficile</a>&nbsp;</span>&nbsp;</span> spores to break the chain of transmission in clinical environments.</p>
</div>
</div>
<ul>
<li>
Received: 
<time datetime="2023-08-16">16/08/2023</time>
</li>
<li>
Accepted:
<time datetime="2023-11-07">07/11/2023</time>
</li>
<li>
Published Online:
<time datetime="2023-11-21">21/11/2023</time>
</li>
</ul> 

<p><span dir="auto">
<xhtml:span xml:lang="en">© 2023 The Authors
</xhtml:span>
</span>
</p>

</div>
<div id="metrics_content">
<div>
<p><img src="https://www.microbiologyresearch.org/images/jp/spinner.gif" alt="Loading"></p><p>Article metrics loading...</p>
</div>
<div>
<p>/content/journal/micro/10.1099/mic.0.001418</p>
<p>2023-11-21</p>
<p>2023-11-23</p>




</div>
</div>
<div id="html_fulltext">

<div>
<p><img src="https://www.microbiologyresearch.org/images/jp/spinner.gif" alt="Loading full text..."></p><p>Full text loading...</p>
</div>
<p>
/deliver/fulltext/micro/169/11/mic001418.html?itemId=/content/journal/micro/10.1099/mic.0.001418&amp;mimeType=html&amp;fmt=ahah
</p>

</div>




</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Binance and CEO admit financial crimes, billions coughed up to US govt (143 pts)]]></title>
            <link>https://www.theregister.com/2023/11/22/binance_ceo_settlement/</link>
            <guid>38393264</guid>
            <pubDate>Thu, 23 Nov 2023 14:46:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/22/binance_ceo_settlement/">https://www.theregister.com/2023/11/22/binance_ceo_settlement/</a>, See on <a href="https://news.ycombinator.com/item?id=38393264">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The world's largest cryptocurrency exchange just got a little smaller, with the US Department of Justice announcing Binance and its CEO Changpeng Zhao have both pleaded guilty to a multitude of financial crimes. As a result Binance will fork out $10 billion to Uncle Sam in fines and settlements.</p>
<p>According to a <a href="https://regmedia.co.uk/2023/11/21/usa-v-binance.pdf" rel="nofollow">criminal case</a> [PDF] unsealed Tuesday, Binance failed to register as a money services business in the United States, broke the Bank Secrecy Act by failing to implement and maintain an anti-money laundering program, and violated the International Emergency Economic Powers Act by allowing US users to transact with individuals in sanctioned countries.&nbsp;</p>
<p>Those three crimes, prosecutors noted, were all done "knowingly" and "willfully," and included the transfer of nearly $1 billion to "persons [Binance] had reason to believe resided in Iran."&nbsp;</p>

    

<p>"Binance became the world's largest cryptocurrency exchange in part because of the crimes it committed – now it is paying one of the largest corporate penalties in US history," Attorney General Merrick Garland <a href="https://www.justice.gov/opa/pr/binance-and-ceo-plead-guilty-federal-charges-4b-resolution" rel="nofollow">said</a> during a press conference today. Binance also facilitated trades to users in Syria, Russia and Russian-controlled parts of Ukraine, it's said.&nbsp;</p>

        


        

<p>The Justice Department noted Binance was chiefly interested in profiting from its customers, as opposed to ripping off or defrauding them, and that the biz conspired to operate as an unlicensed exchange to "gain market share and profit as quickly as possible."&nbsp;</p>
<blockquote>

<p>Better to ask forgiveness than permission</p>
</blockquote>
<p>The outfit knew that it would lose market share if it was cut off from US users, and so acted to ensure that the VIP users moving the most cryptocurrency on its platform had access to its non-US platform, to which access in America was supposed to have been cut off in 2019 after the creation of Binance.us.&nbsp;</p>
<p>"Defendant chose not to comply with US legal and regulatory requirements because it determined that doing so would limit its ability to attract and maintain US users," the DoJ said in its court filings. According to a 2019 chat message sent by Zhao to the Binance team, he knew full well his company was violating the law, too.&nbsp;</p>
<p>"If we blocked US users from day 1, Binance will be not [sic] as big as we are today," Zhao said in the chat, according to Uncle Sam. "Better to ask forgiveness than permission."&nbsp;</p>

        

<p>Other internal communications made it clear Binance knew it was being used as a conduit to launder illicit funds, with a compliance employee quipping at one point that "we need a banner 'is washing drug money too hard these days - come to Binance we got cake for you.'"&nbsp;</p>
<p>Binance will cough up $4.3 billion in fines and forfeitures to the Dept of Justice as part of its guilty plea.</p>
<p>The exchange also reached settlements Tuesday with the US Commodity Futures Trading Commission (CFTC) and the Treasury Department's Financial Crimes Enforcement Network (FinCEN) and Office of Foreign Asset Controls (OFAC). The CFTC will <a href="https://www.cftc.gov/PressRoom/PressReleases/8825-23" rel="nofollow">extract</a> $1.35 billion from Binance, while the Treasury Department's enforcement arms have <a href="https://home.treasury.gov/news/press-releases/jy1925" rel="nofollow">settled</a> with Binance for a combined $4.4 billion - the largest haul in Treasury's history, Chair Janet Yellen said.</p>

        

<p>In addition to the monetary settlements, Binance is also being required to implement proper anti-money laundering capabilities and will have to report to US agencies for the next three years on its compliance.&nbsp;</p>
<p>"The message here should be clear: Using new technology to break the law does not make you a disruptor. It makes you a criminal," said Garland. The DoJ noted that Binance's total fine was reduced by 20 percent due to its cooperation with US investigations.&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2023/06/05/binance_us_sec_lawsuit/">Cry-pto: Feds bury Bitcoin exchange giant Binance in 13-count fraud lawsuit</a></li>

<li><a href="https://www.theregister.com/2022/11/15/ftx_collapse_cryptocurrency/">FTX collapse prompts other cryptocurrency firms to suspend withdrawals</a></li>

<li><a href="https://www.theregister.com/2023/11/13/carf_2027_adoption_set/">48-nation bloc to crack down on using crypto assets to avoid tax</a></li>

<li><a href="https://www.theregister.com/2023/11/03/sam_bankman_fried_ftx_convicted/">FTX crypto-villain Sam Bankman-Fried convicted on all charges</a></li>
</ul>
<p>Zhao, meanwhile, will be paying penalties of his own, with $150 million owed to the CFTC. Zhao is also stepping down from his role as CEO of Binance, he confirmed in a <a href="https://twitter.com/cz_binance/status/1727063503125766367" rel="nofollow">post</a> on X shortly after the DoJ press conference, announcing that Binance's former global head of regional markets, Richard Teng, would be immediately taking over.</p>
<p>The former chief will also keep his majority share of Binance, though won't be allowed be an executive within it.</p>
<p>Zhao's statement made little mention of the reason for his resignation, but he did note that the guilty pleas didn't include any allegations that Binance misappropriated customer funds or engaged in market manipulation (unlike some <a href="https://www.theregister.com/2023/10/03/sbfd_trial_insurance_lawsuit/">other crypto outfits</a>).&nbsp;</p>
<p>Binance's <a href="https://www.binance.com/en/blog/leadership/binance-announcement-reaching-resolution-with-us-regulators-2904832835382364558" rel="nofollow">statement</a> regarding the settlements makes the same statement about the safety of user funds while adding that the company is "taking responsibility for this past chapter" while now being "a much stronger company today than it was in the past."</p>
<p>Binance is still facing <a href="https://www.theregister.com/2023/06/05/binance_us_sec_lawsuit/">charges</a> from the Securities and Exchange Commission, which was not party to the settlements.&nbsp;®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git Branches: Intuition and Reality (344 pts)]]></title>
            <link>https://jvns.ca/blog/2023/11/23/branches-intuition-reality/</link>
            <guid>38393238</guid>
            <pubDate>Thu, 23 Nov 2023 14:43:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/11/23/branches-intuition-reality/">https://jvns.ca/blog/2023/11/23/branches-intuition-reality/</a>, See on <a href="https://news.ycombinator.com/item?id=38393238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>Hello! I’ve been working on writing a zine about git so I’ve been thinking
about git branches a lot. I keep hearing from people that they find the way git
branches work to be counterintuitive. It got me thinking:  what might an
“intuitive” notion of a branch be, and how is it different from how git
actually works?</p>

<p>So in this post I want to briefly talk about</p>

<ul>
<li>an intuitive mental model I think many people have</li>
<li>how git actually represents branches internally (the “technically correct” definition)</li>
<li>how the “intuitive model” and the real way it works are actually pretty closely related</li>
<li>some limits of the intuitive model and why it might cause problems</li>
</ul>

<p>Nothing in this post is remotely groundbreaking so I’m going to try to keep it pretty short.</p>

<h3 id="an-intuitive-model-of-a-branch">an intuitive model of a branch</h3>

<p>Of course, people have many different intuitions about branches. Here’s the one
that I think corresponds to the most closely to the physical “a branch of an
apple tree” metaphor.</p>

<p>My guess is that a lot of people think about a git branch like this: the 2
commits in pink in this picture are on a “branch”.</p>

<p><img src="https://jvns.ca/images/git-branch.png" width="200px"></p>

<p>I think there are two important things about this diagram:</p>

<ol>
<li>the branch has 2 commits on it</li>
<li>the branch has a “parent” (<code>main</code>) which it’s an offshoot of</li>
</ol>

<p>That seems pretty reasonable, but that’s not how git defines a branch – most
importantly, git doesn’t have any concept of a branch’s “parent”. So how does
git define a branch?</p>

<h3 id="in-git-a-branch-is-the-full-history">in git, a branch is the full history</h3>

<p>In git, a branch is the full history of every previous commit, not just the “offshoot” commits. So in our picture above both branches (<code>main</code> and <code>branch</code>) have 4 commits on them.</p>

<p>I made an example repository at <a href="https://github.com/jvns/branch-example">https://github.com/jvns/branch-example</a> which
has its branches set up the same way as in the picture above. Let’s look at the
2 branches:</p>

<p><code>main</code> has 4 commits on it:</p>

<pre><code>$ git log --oneline main
70f727a d
f654888 c
3997a46 b
a74606f a
</code></pre>

<p>and <code>mybranch</code> has 4 commits on it too. The bottom two commits are shared
between both branches.</p>

<pre><code>$ git log --oneline mybranch
13cb960 y
9554dab x
3997a46 b
a74606f a
</code></pre>

<p>So <code>mybranch</code> has 4 commits on it, not just the 2 commits <code>13cb960</code> and <code>9554dab</code> that are “offshoot” commits.</p>

<p>You can get git to draw all the commits on both branches like this:</p>

<pre><code>$ git log --all --oneline --graph
* 70f727a (HEAD -&gt; main, origin/main) d
* f654888 c
| * 13cb960 (origin/mybranch, mybranch) y
| * 9554dab x
|/
* 3997a46 b
* a74606f a
</code></pre>

<h3 id="a-branch-is-stored-as-a-commit-id">a branch is stored as a commit ID</h3>

<p>Internally in git, branches are stored as tiny text files which have a commit ID in
them. That commit is the latest commit on the branch. This is the “technically correct” definition I was talking about at the beginning.</p>

<p>Let’s look at the text files for <code>main</code> and <code>mybranch</code> in our example repo:</p>

<pre><code>$ cat .git/refs/heads/main
70f727acbe9ea3e3ed3092605721d2eda8ebb3f4
$ cat .git/refs/heads/mybranch
13cb960ad86c78bfa2a85de21cd54818105692bc
</code></pre>

<p>This makes sense: <code>70f727</code> is the latest commit on <code>main</code> and <code>13cb96</code> is the latest commit on <code>mybranch</code>.</p>

<p>The reason this works is that every commit contains a pointer to its parent(s),
so git can follow the chain of pointers to get every commit on the branch.</p>

<p>Like I mentioned before, the thing that’s missing here is any relationship at
all between these two branches. There’s no indication that <code>mybranch</code> is an
offshoot of <code>main</code>.</p>

<p>Now that we’ve talked about how the intuitive notion of a branch is “wrong”, I
want to talk about how it’s also right in some very important ways.</p>

<h3 id="people-s-intuition-is-usually-not-that-wrong">people’s intuition is usually not that wrong</h3>

<p>I think it’s pretty popular to tell people that their intuition about git is
“wrong”. I find that kind of silly – in general, even if people’s intuition
about a topic is technically incorrect in some ways, people usually have the
intuition they do for very legitimate reasons! “Wrong” models can be super useful.</p>

<p>So let’s talk about 3 ways the intuitive “offshoot” notion of a branch matches
up very closely with how we actually use git in practice.</p>

<h3 id="rebases-use-the-intuitive-notion-of-a-branch">rebases use the “intuitive” notion of a branch</h3>

<p>Now let’s go back to our original picture.</p>

<p><img src="https://jvns.ca/images/git-branch.png" width="200px"></p>

<p>When you rebase <code>mybranch</code> on <code>main</code>, it takes the commits on the “intuitive”
branch (just the 2 pink commits) and replays them onto <code>main</code>.</p>

<p>The result is that just the 2 (<code>x</code> and <code>y</code>) get copied. Here’s what that looks like:</p>

<pre><code>$ git switch mybranch
$ git rebase main
$ git log --oneline mybranch
952fa64 (HEAD -&gt; mybranch) y
7d50681 x
70f727a (origin/main, main) d
f654888 c
3997a46 b
a74606f a
</code></pre>

<p>Here <code>git rebase</code> has created two new commits (<code>952fa64</code> and <code>7d50681</code>) whose
information comes from the previous two <code>x</code> and <code>y</code> commits.</p>

<p>So the intuitive model isn’t THAT wrong! It tells you exactly what happens in a
rebase.</p>

<p>But because git doesn’t know that <code>mybranch</code> is an offshoot of <code>main</code>, you need
to tell it explicitly where to rebase the branch.</p>

<h3 id="merges-use-the-intuitive-notion-of-a-branch-too">merges use the “intuitive” notion of a branch too</h3>

<p>Merges don’t copy commits, but they do need a “base” commit: the way merges
work is that it looks at two sets of changes (starting from the shared base)
and then merges them.</p>

<p>Let’s undo the rebase we just did and then see what the merge base is.</p>

<pre><code>$ git switch mybranch
$ git reset --hard 13cb960  # undo the rebase
$ git merge-base main mybranch
3997a466c50d2618f10d435d36ef12d5c6f62f57
</code></pre>

<p>This gives us the “base” commit where our branch branched off, <code>3997a4</code>.
That’s exactly the commit you would think it might be based on our intuitive
picture.</p>

<h3 id="github-pull-requests-also-use-the-intuitive-idea">github pull requests also use the intuitive idea</h3>

<p>If we create a pull request on GitHub to merge <code>mybranch</code> into <code>main</code>, it’ll
also show us 2 commits: the commits <code>x</code> and <code>y</code>. That makes sense and also
matches our intuitive notion of a branch.</p>

<p><img src="https://jvns.ca/images/gh-pr.png" width="300px"></p>

<p>I assume if you make a merge request on GitLab it shows you something similar.</p>

<h3 id="intuition-is-pretty-good-but-it-has-some-limits">intuition is pretty good, but it has some limits</h3>

<p>This leaves our intuitive definition of a branch looking pretty good actually!
The “intuitive” idea of what a branch is matches exactly with how merges and
rebases and GitHub pull requests work.</p>

<p>You do need to explicitly
specify the other branch when merging or rebasing or making a pull request (like <code>git rebase main</code>),
because git doesn’t know what branch you think your offshoot is based on.</p>

<p>But the intuitive notion of a branch has one fairly serious problem: the way
you intuitively think about <code>main</code> and an offshoot branch are very different,
and git doesn’t know that.</p>

<p>So let’s talk about the different kinds of git branches.</p>

<h3 id="trunk-and-offshoot-branches">trunk and offshoot branches</h3>

<p>To a human, <code>main</code> and <code>mybranch</code> are pretty different, and you probably have
pretty different intentions around how you want to use them.</p>

<p>I think it’s pretty normal to think of some branches as being “trunk” branches,
and some branches as being “offshoots”. Also you can have an offshoot of an
offshoot.</p>

<p>Of course, git itself doesn’t make any such distinctions (the term “offshoot”
is one I just made up!), but what kind of a branch it is definitely affects how
you treat it.</p>

<p>For example:</p>

<ul>
<li>you might rebase <code>mybranch</code> onto <code>main</code> but you probably wouldn’t rebase <code>main</code> onto <code>mybranch</code> – that would be weird!</li>
<li>in general people are much more careful around rewriting the history on “trunk” branches than short-lived offshoot branches</li>
</ul>

<h3 id="git-lets-you-do-rebases-backwards">git lets you do rebases “backwards”</h3>

<p>One thing I think throws people off about git is – because git doesn’t
have any notion of whether a branch is an “offshoot” of another branch, it
won’t give you any guidance about if/when it’s appropriate to rebase branch X
on branch Y. You just have to know.</p>

<p>for example, you can do either:</p>

<pre><code>$ git checkout main
$ git rebase mybranch
</code></pre>

<p>or</p>

<pre><code>$ git checkout mybranch
$ git rebase main
</code></pre>

<p>Git will happily let you do either one, even though in this case <code>git rebase main</code> is
extremely normal and <code>git rebase mybranch</code> is pretty weird. A lot of people
said they found this confusing so here’s a picture of the two kinds of rebases:</p>

<p><img src="https://jvns.ca/images/backwards-rebase.png"></p>

<p>Similarly, you can do merges “backwards”, though that’s much more normal than
doing a backwards rebase – merging <code>mybranch</code> into <code>main</code> and <code>main</code> into
<code>mybranch</code> are both useful things to do for different reasons.</p>

<p>Here’s a diagram of the two ways you can merge:</p>

<p><img src="https://jvns.ca/images/merge-two-ways.png"></p>

<h3 id="git-s-lack-of-hierarchy-between-branches-is-a-little-weird">git’s lack of hierarchy between branches is a little weird</h3>

<p>I hear the statement “the <code>main</code> branch is not special” a lot and I’ve been
puzzled about it – in most of the repositories I work in, <code>main</code> <strong>is</strong>
pretty special! Why are people saying it’s not?</p>

<p>I think the point is that even though branches <strong>do</strong> have relationships
between them (<code>main</code> is often special!), git doesn’t know anything about those
relationships.</p>

<p>You have to tell git explicitly about the relationship between branches every
single time you run a git command like <code>git rebase</code> or <code>git merge</code>, and if you
make a mistake things can get really weird.</p>

<p>I don’t know whether git’s design here is “right” or “wrong” (it definitely has
some pros and cons, and I’m very tired of reading endless arguments about
it), but I do think it’s surprising to a lot of people for good reason.</p>

<h3 id="in-github-the-default-branch-is-special">in GitHub, the default branch is special</h3>

<p>Also, it’s worth mentioning that GitHub does have a “special branch”: every
github repo has a “default branch” (in git terms, it’s what <code>HEAD</code> points at),
which is special in the following ways:</p>

<ul>
<li>it’s what you check out when you <code>git clone</code> the repository</li>
<li>it’s the default destination for pull requests</li>
<li>github will suggest that you protect the default branch from force pushes</li>
</ul>

<p>and probably even more that I’m not thinking of.</p>

<h3 id="that-s-all">that’s all!</h3>

<p>This all seems extremely obvious in retrospect, but it took me a long time to
figure out what a more “intuitive” idea of a branch even might be because I was
so used to the technical “a branch is a reference to a commit” definition.</p>

<p>I also hadn’t really thought aoout how git makes you tell it about the
hierarchy between your branches every time you run a <code>git rebase</code> or <code>git
merge</code> command – for me it’s second nature to do that and it’s not a big deal,
but now that I’m thinking about it, it’s pretty easy to see how somebody could
get mixed up.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US govt pays AT&T to let cops search Americans' phone records without warrant (433 pts)]]></title>
            <link>https://www.theregister.com/2023/11/22/wyden_hemisphere_letter/</link>
            <guid>38393237</guid>
            <pubDate>Thu, 23 Nov 2023 14:43:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/22/wyden_hemisphere_letter/">https://www.theregister.com/2023/11/22/wyden_hemisphere_letter/</a>, See on <a href="https://news.ycombinator.com/item?id=38393237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>A senator has complained that American law enforcement agencies snoop on US citizens and residents, seemingly without regard for the privacy provisions of the Fourth Amendment, under a secret program called the Hemisphere Project that allows police to conduct searches of trillions of phone records.</p>
<p>According to Senator Ron Wyden (D-OR), these searches "usually" happen without warrants. And after more than a decade of keeping people — lawmakers included — in the dark about Hemisphere, Wyden wants the Justice Department to reveal information about what he called a "long-running dragnet surveillance program."</p>
<p>"I have serious concerns about the legality of this surveillance program, and the materials provided by the DoJ contain troubling information that would justifiably outrage many Americans and other members of Congress," Wyden wrote in a letter [<a target="_blank" rel="nofollow" href="https://www.wyden.senate.gov/imo/media/doc/wyden_hemisphere_surveillance_letter_112023.pdf">PDF</a>] to US Attorney General Merrick Garland.</p>

    

<p>Under Hemisphere, the White House Office of National Drug Control Policy (ONDCP) pays telco AT&amp;T to provide all federal, state, local, and tribal law enforcement agencies with the ability to request searches of trillions of domestic phone records dating back to at least 1987, plus the four billion call records added every day.</p>
<blockquote>

<p>We are required by law to comply with subpoenas, warrants and court orders from government and law enforcement</p>
</blockquote>
<p>AT&amp;T declined to answer any specific questions about Hemisphere, but a spokesperson told <em>The Register</em>: "To be clear, any information referred to in Senator Wyden's letter would be compelled by subpoena, warrant, or court order."</p>
<p>"We defer to the Justice Department, to whom Senator Wyden's letter is addressed, for comment," the AT&amp;T spokesperson said. "Like all companies, we are required by law to comply with subpoenas, warrants and court orders from government and law enforcement agencies."</p>

        


        

<p>According to Wyden, federal and state law enforcement agencies can request a Hemisphere search with a subpoena — but many law enforcement agencies can issue these themselves. Additionally, any law enforcement agency across the country can request access to these searches, and they aren't limited to drug-related investigations, according to the Oregon senator.</p>
<p>Hemisphere first came to light in a 2013 New York Times <a target="_blank" rel="nofollow" href="https://www.nytimes.com/2013/09/02/us/drug-agents-use-vast-phone-trove-eclipsing-nsas.html">report</a> that alleged the "scale and longevity of the data storage appears to be unmatched by other government programs, including the NSA's gathering of phone call logs under the Patriot Act."</p>
<h3>It's not classified, but that doesn't mean the Feds want you to see it</h3>
<p>Privacy advocates including the Electronic Frontier Foundations have filed Freedom of Information Act and state-level public records <a target="_blank" rel="nofollow" href="https://www.eff.org/cases/hemisphere">lawsuits</a> to learn more about the secret snooping program.</p>
<p>Few have made a dent: it appears that the Feds are doing everything they can to keep Hemisphere secret.</p>

        

<p>Although the program and its documents are not classified, the Justice Department has marked them as "Law Enforcement Sensitive," meaning their disclosure could hurt ongoing investigations. This designation also prevents the documents from being publicly released.</p>
<p>Senator Wyden wants the designation removed.</p>
<p>Additionally, Hemisphere is not subject to a federal <a target="_blank" rel="nofollow" href="https://www.dhs.gov/privacy-impact-assessments">Privacy Impact Assessment</a> due to its funding structure, it's claimed. The White House doesn't directly pay AT&amp;T - instead the ONDCP provides a grant to the Houston High Intensity Drug Trafficking Area, which is a partnership between federal, state, and local law enforcement agencies. And this partnership, in turn, pays AT&amp;T to operate this surveillance scheme.</p>

        

<p>In Wyden's letter, he quotes a law enforcement official who described Hemisphere as "AT&amp;T's Super Search Engine" and "Google on Steroids." He also cites ONDCP slides and Drug Enforcement Administration (DEA) emails disclosing that AT&amp;T searches records kept by its wholesale division, which carries communications on behalf of other telecom companies and their customers.</p>
<ul>

<li><a href="https://www.theregister.com/2023/11/08/section_702_reform_legislation/">Uncle Sam snooping on US folks? Not without a warrant, lawmakers agree</a></li>

<li><a href="https://www.theregister.com/2023/11/02/us_commerce_dept_spyware/">US Commerce Dept pinky swears it won't push American spyware on world-plus-dog</a></li>

<li><a href="https://www.theregister.com/2023/11/15/google_amazon_microsoft_mozilla/">Google, Amazon, Microsoft make the Mozilla naughty list for Christmas shopping</a></li>

<li><a href="https://www.theregister.com/2023/10/25/ice_social_media_surveillance/">Your ex isn't the only one stalking your social media posts. The Feds are, too</a></li>
</ul>
<p>Another ONDCP document purportedly states that Hemisphere "can be used to identify alternate numbers used by a target, obtain location data and 'two levels of call detail records for one target number'.” That provision means Hemisphere searches can pull in phone records of everyone who communicated with the target of an investigation.</p>
<p>In other words: there's some serious snooping happening.</p>
<p>This letter to DOJ comes as Wyden and other lawmakers from both parties, in the US Senate and House of Representatives, have introduced the <a target="_blank" href="https://www.theregister.com/2023/11/08/section_702_reform_legislation/">Government Surveillance Reform Act</a>, which would, among other things, require an independent court order before allowing surveillance of Americans' phone records. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Write libraries instead of services, where possible (257 pts)]]></title>
            <link>https://catern.com/services.html</link>
            <guid>38393032</guid>
            <pubDate>Thu, 23 Nov 2023 14:21:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://catern.com/services.html">https://catern.com/services.html</a>, See on <a href="https://news.ycombinator.com/item?id=38393032">Hacker News</a></p>
<div id="readability-page-1" class="page">

  A service has constant administration costs which are paid by the service provider.
  A library instead moves these costs to the users of the library.
<p>
  For any developer with limited resources,
  <!-- obviously everyone has limited resources, but I feel like this makes the sentence scan better, shrug -->
  this means a library (where viable) can provide the same functionality to the user,
  at a lower cost to the developer than a service.
</p><p>
  By library, I mean any software that can be <a href="https://catern.com/run.html">run by the user</a>:
  shared objects, modules, servers, command line utilities, and others.
  By service, I mean any software which the user can't run on their own;
  anything which depends (usually through an API)
  on a service provider for its functionality.
</p><p>
  Usually, the centralization of these administration costs is cited as a benefit of services.
  People say, "services are easy to write because you can upgrade them centrally,
  so you can avoid slow-to-upgrade users making everyone's lives worse."
</p><p>
  But this assumes that slow-to-upgrade users can have negative effects on everyone else.
  If one user can't have a negative impact on other users,
  then you don't care if some users are slow to upgrade;
  they're only hurting themselves.
</p><p>
  You can prevent users from negatively impacting other users by not sharing state or resources between users;
  in other words, <a href="https://catern.com/run.html">let users run the software</a>
  themselves, by writing libraries instead of services.
</p><p>
  "Write a library", in this sense, can still mean writing a standalone server reached through a network protocol.
  As long as the user runs the server themselves, you're still saving the administration costs.
  Both standalone servers and importable code are <a href="https://catern.com/schemas.html">equally expressive</a>,
  and equally cheap for you to administrate if you're not operating a service yourself.
</p><p>
  By avoiding the maintenance and upgrade costs of a service,
  a library can afford to contain more functionality.
  That's good for both the developer and the user.


</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Despite just 5.8% sales, over 38% of bug reports come from the Linux community (2021) (391 pts)]]></title>
            <link>https://old.reddit.com/r/gamedev/comments/qeqn3b/despite_having_just_58_sales_over_38_of_bug/</link>
            <guid>38392931</guid>
            <pubDate>Thu, 23 Nov 2023 14:11:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/gamedev/comments/qeqn3b/despite_having_just_58_sales_over_38_of_bug/">https://old.reddit.com/r/gamedev/comments/qeqn3b/despite_having_just_58_sales_over_38_of_bug/</a>, See on <a href="https://news.ycombinator.com/item?id=38392931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>My game - ΔV: Rings of Saturn (shameless <a href="https://store.steampowered.com/app/846030/V_Rings_of_Saturn/?utm_source=Reddit&amp;utm_campaign=gamedev-plug">plug</a>) - is out in Early Access for two years now, and as you can expect, there are bugs. But I did find that a disproportionally big amount of these bugs was reported by players using Linux to play. I started to investigate, and my findings did surprise me.</p>

<h2>Let’s talk numbers.</h2>

<p>Percentages are easy to talk about, but when I read just them, I always wonder - what is the sample size? Is it small enough for the percentage to be just noise? As of today, I sold a little over 12,000 units of ΔV in total. 700 of these units were bought by Linux players. That’s 5.8%. I got 1040 bug reports in total, out of which roughly 400 are made by Linux players. That’s one report per 11.5 users on average, and one report per 1.75 Linux players. That’s right, an average Linux player will get you 650% more bug reports.</p>

<p>A lot of extra work for just 5.8% of extra units, right?</p>

<h2>Wrong. Bugs exist whenever you know about them, or not.</h2>

<p>Do you know how many of these 400 bug reports were actually platform-specific? 3. Literally only 3 things were problems that came out just on Linux. The rest of them were affecting everyone - the thing is, the Linux community is exceptionally well trained in reporting bugs. That is just the open-source way. This 5.8% of players found 38% of all the bugs that affected everyone. Just like having your own 700-person strong QA team. That was not 38% extra work for me, that was just free QA!</p>

<h2>But that’s not all. The report quality is stellar.</h2>

<p>I mean we have all seen bug reports like: “it crashes for me after a few hours”. Do you know what a developer can do with such a report? Feel sorry at best. You can’t really fix any bug unless you can replicate it, see it with your own eyes, peek inside and finally see that it’s fixed.</p>

<p>And with bug reports from Linux players is just something else. You get all the software/os versions, all the logs, you get core dumps and you get replication steps. Sometimes I got with the player over discord and we quickly iterated a few versions with progressive fixes to isolate the problem. You just don’t get that kind of engagement from anyone else.</p>

<h2>Worth it?</h2>

<p>Oh, yes - at least for me. Not for the extra sales - although it’s nice. It’s worth it to get the massive feedback boost and free, hundred-people strong QA team on your side. An invaluable asset for an independent game studio.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Retries – An interactive study of request retry methods (202 pts)]]></title>
            <link>https://encore.dev/blog/retries</link>
            <guid>38392540</guid>
            <pubDate>Thu, 23 Nov 2023 13:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://encore.dev/blog/retries">https://encore.dev/blog/retries</a>, See on <a href="https://news.ycombinator.com/item?id=38392540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Requests over the network can fail. This is something we cannot avoid, and to
write robust software we need to handle these failures or else they may be
presented to users as errors. One of the most common techniques for handling a
failed request is to retry it.</p><p>In this post we're going to visually explore different methods of retrying
requests, demonstrating why some common approaches are dangerous and ultimately
ending up at what the best practice is. At the end of this post you will have a
solid understanding of what makes safe retry behaviour, and a vivid
understanding of what doesn't.</p><p>We'll be focusing on when you have control over the behaviour of the client.
The advice in this post applies equally to when you're making requests to your
own backend services or third-party ones. We won't be covering any server-side
mitigations to the problems described in this post.</p><h2 id="setting-the-stage"><a href="#setting-the-stage">Setting the stage</a></h2><p>Let's introduce the elements involved in our visualisation. We have:</p><ul><li><span>Requests</span> can be thought of as HTTP requests. They can <span>succeed</span> or <span>fail</span>. <span>Failed</span> <span>requests</span> have spiked edges, <span>successful</span> <span>requests</span> stay smooth.</li><li><span>Load balancers</span> route <span>requests</span> from <span>clients</span> to <span>servers</span>.</li><li><span>Servers</span> accept and serve <span>requests</span>.</li><li><span>Clients</span> send <span>requests</span> to <span>servers</span> via a <span>load balancer</span>. After getting a response, they will <span>wait</span> an amount of time before sending another <span>request</span>.</li></ul><p>Here's how all of that that looks.</p><p>We have one <span>client</span> sending <span>requests</span> periodically to one <span>server</span>. You could imagine this is a <span>client</span> periodically checking the status of some background
job. The <span>request</span> goes through a <span>load balancer</span> that selects which <span>server</span> to send the <span>request</span>
to. <span>Requests</span> either <span>succeed</span> or <span>fail</span> which you can
see when they're making their return journey to the <span>client</span>. While the <span>client</span> is <span>waiting</span> to send its next <span>request</span>, it shows as a circular timer.</p><h4 id="adjust-animation-speed"><a href="#adjust-animation-speed"><strong>Adjust animation speed</strong></a></h4><p>If the animations are too fast or too slow for you, feel free to change them
now. This will affect all animations on this page.</p><h2 id="basic-retry-handling"><a href="#basic-retry-handling">Basic retry handling</a></h2><p>The simplest way to handle a <span>failure</span> is to do nothing.
In this visualisation the <span>server</span> is configured to <span>fail</span> 100% of the time, and each <span>client</span> will just <span>wait</span> to send
its next <span>request</span>.</p><p>Not all that exciting. <span>Requests</span> <span>fail</span> and the <span>client</span> just <span>waits</span> to send another. Let's do what people tend to do when
they check Sentry and notice that they're serving 503s due to a <span>failed</span> <span>request</span> to a third-party
service: retry 10 times in a tight loop.</p><p>You can see now that when a <span>request</span> <span>fails</span>, it is immediately retried. No <span>
waiting</span>. We've configured a 100% failure rate to make the retries easier
to see, but if the failure rate was 5% then the odds of 2 requests failing
back to back is 1 in 400. 3 requests in a row is 1 in 8000. Retries allow you to
trade latency for reliability.</p><p>However, there's a subtle side-effect of behaving this way. Every time a <span>client</span> retries when it would have otherwise been <span>waiting</span>, an extra <span>request</span> is generated. This increases the overall load to our service.</p><p>Now we're going to add a few more <span>clients</span> and
introduce some buttons. The buttons control the <span>failure</span>
rate of our <span>servers</span>. For now, we're just going to
have 0% and 100%. When you're ready, switch from 0% to 100% and see what happens
to our <span>server</span>.</p><failure-rate-control target="control1" options="0 1"></failure-rate-control><p>If I'm any good at tuning my simulations, you will quickly notice the <span>server</span> <em>explode</em>. Even after you set the <span>failure</span> rate back to 0% and the <span>server</span> has recovered, there's a chance it will keep
exploding.</p><p>What the explosion represents is a <span>server</span>
overloading and crashing. Then it restarts a few seconds later. This can happen
for all sorts of reasons in the real world, from the process running out of
memory to rare segfaults that only happen under stress. Typically <span>servers</span> will have <span>request</span>
queues that reject <span>requests</span> when the <span>server</span> has too much work to do, but to keep things simple
we're using overload to represent any potential failure mode.</p><p>Once the <span>server</span> has crashed once, the extra load
created by the retries can make it difficult to recover. When it comes back up,
it might get quickly overwhelmed and crash again. This problem gets worse as you
scale. Let's add in even more <span>clients</span> and a few more <span>servers</span> to handle the new load.</p><failure-rate-control target="control2" options="0 1"></failure-rate-control><p>What you're likely to see here is that the moment you switch from a 0% <span>failure</span> rate to 100%, traffic begins to ramp up as <span>clients</span> begin to retry. Eventually, one of the <span>servers</span> will crash. As soon as one <span>server</span> goes, the remaining two will be unable to handle
the new load.</p><p>You'll notice that setting the <span>failure</span> rate back to 0%
here will likely have no meaningful effect. You may eventually recover, but if
you're doing retries in a tight loop and you get into this overloaded state it
can be very hard to get back out. In practice, the quickest way to recover is to
add more <span>servers</span> to absorb the load. Once
stabilised, you can spin the extra <span>servers</span> back
down.</p><p>Give that a try in the next visualisation. It's tuned the same way as the
previous one, but this time there's an extra toggle that lets you control the
number of <span>servers</span>. Set the <span>failure</span> rate up to 100%, get into an overloaded state, then
set it back down to 0% and gradually add <span>servers</span>
until you're recovered. How many extra <span>servers</span> do
you need in order to stabilise?</p><failure-rate-control target="control2.1" options="0 1"></failure-rate-control><h2 id="retrying-with-a-delay"><a href="#retrying-with-a-delay">Retrying with a delay</a></h2><p>So retrying in a tight loop is problematic and we've seen why. The next thing
people do is to add a delay between each retry. 10 retries with a <code>sleep(1000)</code>
between them. Let's see how that fares.</p><failure-rate-control target="control3" options="0 1"></failure-rate-control><p>You should notice the same pattern here as with no delay between retries. When
you set the <span>failure rate</span> to 100%, the <span>server</span> will crash shortly after. It may take a bit longer,
but it will happen. If the rate at which your <span>clients</span> retry is not longer than the rate at which they
normally send <span>requests</span>, you will see an increase in
overall load.</p><p>To demonstrate, let's try a <code>sleep(10000)</code> to wait 10 seconds after a <span>failed</span> <span>request</span>. This wait
is about twice as long as <span>clients</span> usually wait
before sending their next <span>request</span>.</p><failure-rate-control target="control4" options="0 1"></failure-rate-control><p>This "works" insofar as the <span>server</span> is unlikely to
get overloaded, and if it does it is able to recover with ease. But this will
lead to a bad user experience in practice. Users don't like waiting, and the
longer you sleep between retries, the more likely they are to refresh manually
or go and do something else. Both bad outcomes.</p><h2 id="so-whats-the-answer"><a href="#so-whats-the-answer">So what's the answer?</a></h2><p>We need a way of retrying that retries quickly in case the error is low
probability, thus protecting the user experience, but recognises when things are
really wrong and waits longer to prevent unrecoverable overload.</p><p>We need "<strong>exponential backoff.</strong>" There are lots of things you can configure
when calculating exponential backoff, but if you imagine we started off waiting
for 1 second and waited twice as long each retry, 10 retries would look like
this:</p><ul><li>1 second</li><li>2 seconds</li><li>4 seconds</li><li>8 seconds</li><li>16 seconds</li><li>32 seconds</li><li>1 minute and 4 seconds</li><li>2 minutes and 8 seconds</li><li>4 minutes and 16 seconds</li><li>8 minutes and 32 seconds</li></ul><p>This would be an enormous amount of time to wait, so in practice exponential
backoff is tuned to start lower than 1 second, and often has a lower multiplier.
Google's <a href="https://cloud.google.com/java/docs/reference/google-http-client/1.43.0/com.google.api.client.util.ExponentialBackOff" rel="nofollow" target="_blank">Java HTTP Client Library</a>, for example, starts at 0.5 seconds and
has a multiplier of 1.5. This yields the following retry intervals:</p><ul><li>0.5 seconds</li><li>0.75 seconds</li><li>1.125 seconds</li><li>1.687 seconds</li><li>2.53 seconds</li><li>3.795 seconds</li><li>5.692 seconds</li><li>8.538 seconds</li><li>12.807 seconds</li><li>19.210 seconds</li></ul><p>Enough mathematics, how does this look in practice? All of the following
examples use the Google HTTP library backoff defaults (0.5 second initial delay,
1.5 multiplier).</p><failure-rate-control target="control5" options="0 1"></failure-rate-control><p>As soon as you flip over to 100% <span>failure</span> rate you'll
notice the usual ramp up in <span>requests</span>, but as those <span>requests</span> are retried you will then notice that the
backoff kicks in and things calm down. The <span>server</span>
may crash but the <span>clients</span> give it space to recover.
When you flip back to 0% <span>failure</span> rate, the <span>server</span> is able to return to normal service quickly.</p><p>For fun, let's also see it in action at scale. I'm going to give you some more <span>failure</span> rates to play with, too. Go wild.</p><failure-rate-control target="control6" options="0 0.2 0.4 0.6 0.8 1"></failure-rate-control><p>You may have struggled to get any of the <span>servers</span> to
crash in this example, even at a 100% <span>failure</span> rate.
This is exponential backoff at work, helping your <span>clients</span> recognise trouble and getting them to give your <span>servers</span> space to recover.</p><h2 id="jitter"><a href="#jitter">Jitter</a></h2><p>We've seen the power of exponential backoff at work, but there's one last thing
we can do with our retries to make them truly best practice.</p><p>"Jitter" is the process of randomising how long we wait between retries to
within a specific range. To follow the Google HTTP client library example, they
add 50% jitter. So a retry interval can be between 50% lower and 50% higher than
the calculated figure. Here's how that affects our numbers from before:</p><ul><li>0.5 seconds, ± 0.25 seconds</li><li>0.75 seconds, ± 0.375 seconds</li><li>1.125 seconds, ± 0.5625 seconds</li><li>1.687 seconds, ± 0.8435 seconds</li><li>2.53 seconds, ± 1.265 seconds</li><li>3.795 seconds, ± 1.8975 seconds</li><li>5.692 seconds, ± 2.846 seconds</li><li>8.538 seconds, ± 4.269 seconds</li><li>12.807 seconds, ± 6.4035 seconds</li><li>19.210 seconds, ± 9.605 seconds</li></ul><p>This jitter helps prevent <span>clients</span> from synchronising
with each other and sending surges of <span>requests</span>.</p><h2 id="putting-this-in-to-code"><a href="#putting-this-in-to-code">Putting this in to code</a></h2><p>So you've read this post and realised you're either not making use of retries,
or you're doing them dangerously. Here's some example Go code that implements
the retry strategy we've built up to, exponential backoff with jitter, that you
can use in your own projects.</p><pre><div><p><code><span>package</span> main

<span>import</span> (
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
	<span>"time"</span>

	<span>"github.com/cenkalti/backoff/v4"</span>
)

<span><span>func</span> <span>main</span><span>()</span></span> {
	bo := backoff.NewExponentialBackOff()
	bo.InitialInterval = <span>500</span> * time.Millisecond
	bo.Multiplier = <span>1.5</span>
	bo.RandomizationFactor = <span>0.5</span>

	err := backoff.Retry(<span><span>func</span><span>()</span></span> <span>error</span> {
		resp, err := http.Get(<span>"https://jsonplaceholder.typicode.com/todos/1"</span>)
		<span>if</span> err != <span>nil</span> {
			<span>return</span> err
		}
		<span>defer</span> resp.Body.Close()

		<span>var</span> result <span>map</span>[<span>string</span>]<span>interface</span>{}
		<span>if</span> err := json.NewDecoder(resp.Body).Decode(&amp;result); err != <span>nil</span> {
			<span>return</span> err
		}

		fmt.Printf(<span>"%+v\n"</span>, result)
		<span>return</span> <span>nil</span>
	}, bo)

	<span>if</span> err != <span>nil</span> {
		fmt.Println(<span>"Request failed:"</span>, err)
	}
}
</code></p></div></pre><h2 id="wrapping-up"><a href="#wrapping-up">Wrapping Up</a></h2><p>I hope that this post has helped visually cement how different retry behaviours
work in practice, and given you a good, intuitive understanding of the failure
modes. We can't always prevent failure, but we can set ourselves up to have the
best chance of recovering when it does happen.</p><p>To recap what we've learned:</p><ul><li><strong>Retrying in a tight loop is dangerous.</strong> You risk getting into overload
situations that are difficult to recover from.</li><li><strong>Retrying with a delay</strong> helps a little bit but is still <strong>dangerous.</strong></li><li><strong>Exponential backoff</strong> is a much safer way of retrying, balancing user
experience with safety.</li><li><strong>Jitter</strong> adds an extra layer of protection, preventing clients from sending
synchronised surges of requests.</li></ul><p>If you have questions or feedback, please reach out on
<a href="https://encore.dev/slack">Slack</a>, via email at
<a href="https://encore.dev/cdn-cgi/l/email-protection#e68e838a8a89a6838885899483c8828390"><span data-cfemail="49212c252526092c272a263b2c672d2c3f">[email&nbsp;protected]</span></a>, or
<a href="https://twitter.com/encoredotdev" rel="nofollow" target="_blank">@encoredotdev</a> on Twitter.</p><p><i><p>  Sam Rose has been programming professionally for over 10 years, with a focus
on the backend and SRE domains. He has worked at a wide range of companies, from
large ones like Google to smaller ones like Nebula.</p><p>  If you enjoyed this post, Sam has a collection of similarly visual and
interactive posts on his <a href="https://samwho.dev/" rel="nofollow" target="_blank">personal site</a>. He has written
about <a href="https://samwho.dev/hashing" rel="nofollow" target="_blank">hashing</a>, <a href="https://samwho.dev/memory-allocation" rel="nofollow" target="_blank">memory
allocation</a>, and <a href="https://samwho.dev/load-balancing" rel="nofollow" target="_blank">load
balancing</a> so far, with more planned.</p><p>  To keep up to date with his work you can follow him on
<a href="https://twitter.com/samwhoo" rel="nofollow" target="_blank">Twitter</a>, and if you want to support what he does
he also has <a href="https://patreon.com/samwho" rel="nofollow" target="_blank">Patreon</a>.</p></i></p><h2 id="playground"><a href="#playground">Playground</a></h2><p>As a final treat, here's the visualisation with the debug UI exposed so that you
can tweak all of the parameters in whatever way you like. Enjoy 😄</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Max Headroom Signal Hijacking (124 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Max_Headroom_signal_hijacking</link>
            <guid>38392388</guid>
            <pubDate>Thu, 23 Nov 2023 13:13:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Max_Headroom_signal_hijacking">https://en.wikipedia.org/wiki/Max_Headroom_signal_hijacking</a>, See on <a href="https://news.ycombinator.com/item?id=38392388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<table><caption>Max Headroom signal hijacking</caption><tbody><tr><td colspan="2"><span typeof="mw:File/Frameless"><a href="https://en.wikipedia.org/wiki/File:Max_Headroom_broadcast_signal_intrusion.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Max_Headroom_broadcast_signal_intrusion.jpg/240px-Max_Headroom_broadcast_signal_intrusion.jpg" decoding="async" width="240" height="162" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Max_Headroom_broadcast_signal_intrusion.jpg/360px-Max_Headroom_broadcast_signal_intrusion.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/b/b4/Max_Headroom_broadcast_signal_intrusion.jpg 2x" data-file-width="446" data-file-height="301"></a></span><p>The unidentified hijacker dressed to resemble <a href="https://en.wikipedia.org/wiki/Max_Headroom" title="Max Headroom">Max Headroom</a> in the pirate broadcast</p></td></tr><tr><th scope="row">Date</th><td>November&nbsp;22, 1987<span>; 36 years ago</span></td></tr><tr><th scope="row">Venue</th><td><a href="https://en.wikipedia.org/wiki/WGN-TV" title="WGN-TV">WGN-TV</a><br><a href="https://en.wikipedia.org/wiki/WTTW" title="WTTW">WTTW</a></td></tr><tr><th scope="row">Location</th><td><a href="https://en.wikipedia.org/wiki/Chicago" title="Chicago">Chicago</a>, <a href="https://en.wikipedia.org/wiki/Illinois" title="Illinois">Illinois</a>, U.S.</td></tr><tr><th scope="row">Participants</th><td>3 (unidentified)</td></tr></tbody></table>
<p>On the night of November 22, 1987, the <a href="https://en.wikipedia.org/wiki/Television" title="Television">television</a> signals of two stations in <a href="https://en.wikipedia.org/wiki/Chicago" title="Chicago">Chicago</a>, Illinois, were <a href="https://en.wikipedia.org/wiki/Broadcast_signal_intrusion" title="Broadcast signal intrusion">hijacked</a>, briefly sending a <a href="https://en.wikipedia.org/wiki/Pirate_broadcast" title="Pirate broadcast">pirate broadcast</a> of an unidentified person wearing a <a href="https://en.wikipedia.org/wiki/Max_Headroom" title="Max Headroom">Max Headroom</a> mask and costume to thousands of home viewers.<sup id="cite_ref-Knittel_1-0"><a href="#cite_note-Knittel-1">[1]</a></sup><sup id="cite_ref-Ross_2-0"><a href="#cite_note-Ross-2">[2]</a></sup><sup id="cite_ref-Schwoch_3-0"><a href="#cite_note-Schwoch-3">[3]</a></sup><sup id="cite_ref-Forester_4-0"><a href="#cite_note-Forester-4">[4]</a></sup>
</p><p>The first incident took place during the sports segment of independent TV station <a href="https://en.wikipedia.org/wiki/WGN-TV" title="WGN-TV">WGN-TV</a>'s 9:00 p.m. newscast. Like the later signal intrusion, it featured a person wearing a mask swaying erratically in front of a swiveling <a href="https://en.wikipedia.org/wiki/Corrugated_galvanised_iron" title="Corrugated galvanised iron">corrugated metal</a> panel, apparently meant to resemble Max Headroom's animated geometric background. Unlike the later intrusion, the only sound was a loud buzz. This interruption went on for almost 17 seconds before engineers at WGN were able to regain control of their broadcast tower.
</p><p>The second incident occurred about two hours later during <a href="https://en.wikipedia.org/wiki/PBS" title="PBS">PBS</a> member station <a href="https://en.wikipedia.org/wiki/WTTW" title="WTTW">WTTW</a>'s broadcast of the <i><a href="https://en.wikipedia.org/wiki/Doctor_Who" title="Doctor Who">Doctor Who</a></i> serial <i><a href="https://en.wikipedia.org/wiki/Horror_of_Fang_Rock" title="Horror of Fang Rock">Horror of Fang Rock</a></i>. With nobody on duty at the affected tower, this signal takeover was more sustained, and the masked figure could be heard making reference to the real Max Headroom's advertisements for <a href="https://en.wikipedia.org/wiki/New_Coke" title="New Coke">New Coke</a>, the animated TV series <i><a href="https://en.wikipedia.org/wiki/Clutch_Cargo" title="Clutch Cargo">Clutch Cargo</a></i>, WGN sportscaster <a href="https://en.wikipedia.org/wiki/Chuck_Swirsky" title="Chuck Swirsky">Chuck Swirsky</a>, "Greatest World Newspaper nerds", and other seemingly unrelated topics. The video concluded with the masked figure’s bare buttocks being spanked by a woman with a <a href="https://en.wikipedia.org/wiki/Flyswatter" title="Flyswatter">flyswatter</a> while yelling "They're coming to get me!", with the woman responding "Bend over, bitch!" as the figure was crying and screaming. At that point, the hijackers ended the pirate transmission, and normal programming resumed after a total interruption of about 90 seconds.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p><p>A criminal investigation conducted by the <a href="https://en.wikipedia.org/wiki/Federal_Communications_Commission" title="Federal Communications Commission">Federal Communications Commission</a> in the immediate aftermath of the intrusion could not find the people responsible, and despite many unofficial inquiries and much speculation over the ensuing decades, the culprits have yet to be positively identified.<sup id="cite_ref-Shefsky_6-0"><a href="#cite_note-Shefsky-6">[6]</a></sup><sup id="cite_ref-Unruh_7-0"><a href="#cite_note-Unruh-7">[7]</a></sup><sup id="cite_ref-Gallagher_8-0"><a href="#cite_note-Gallagher-8">[8]</a></sup><sup id="cite_ref-Haskins_9-0"><a href="#cite_note-Haskins-9">[9]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Signal_intrusion">Signal intrusion</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=1" title="Edit section: Signal intrusion"><span>edit</span></a><span>]</span></span></h2>
<p>Both Max Headroom <a href="https://en.wikipedia.org/wiki/Broadcast_signal_intrusion" title="Broadcast signal intrusion">broadcast signal intrusion</a> incidents took place on local <a href="https://en.wikipedia.org/wiki/Chicago" title="Chicago">Chicago</a> television stations on the night of Sunday, November 22, 1987.<sup id="cite_ref-Shefsky_6-1"><a href="#cite_note-Shefsky-6">[6]</a></sup><sup id="cite_ref-Unruh_7-1"><a href="#cite_note-Unruh-7">[7]</a></sup><sup id="cite_ref-Gallagher_8-1"><a href="#cite_note-Gallagher-8">[8]</a></sup><sup id="cite_ref-Haskins_9-1"><a href="#cite_note-Haskins-9">[9]</a></sup>
</p>
<h3><span id="WGN-TV">WGN-TV</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=2" title="Edit section: WGN-TV"><span>edit</span></a><span>]</span></span></h3>
<figure typeof="mw:File/Thumb"><span><video id="mwe_player_0" poster="https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm/220px--WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm.jpg" controls="" preload="none" width="220" height="165" data-durationhint="34" data-mwtitle="WGN-TV_'Max_Headroom'_Incident&quot;_(1987).webm" data-mwprovider="wikimediacommons" resource="/wiki/File:WGN-TV_%27Max_Headroom%27_Incident%22_(1987).webm"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm.480p.vp9.webm" type="video/webm; codecs=&quot;vp9, opus&quot;" data-transcodekey="480p.vp9.webm" data-width="640" data-height="480"><source src="https://upload.wikimedia.org/wikipedia/commons/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm" type="video/webm; codecs=&quot;vp9, opus&quot;" data-width="640" data-height="480"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm.m3u8" type="application/vnd.apple.mpegurl" data-transcodekey="m3u8" data-width="0" data-height="0"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm.240p.vp9.webm" type="video/webm; codecs=&quot;vp9, opus&quot;" data-transcodekey="240p.vp9.webm" data-width="320" data-height="240"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm.360p.webm" type="video/webm; codecs=&quot;vp8, vorbis&quot;" data-transcodekey="360p.webm" data-width="480" data-height="360"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/5/59/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm/WGN-TV_%27Max_Headroom%27_Incident%22_%281987%29.webm.360p.vp9.webm" type="video/webm; codecs=&quot;vp9, opus&quot;" data-transcodekey="360p.vp9.webm" data-width="480" data-height="360"></video></span><figcaption>A recording of the WGN-TV intrusion</figcaption></figure>
<p>The first intrusion took place at 9:14 pm during the sports segment of <a href="https://en.wikipedia.org/wiki/WGN-TV" title="WGN-TV">WGN-TV</a>'s <i><a href="https://en.wikipedia.org/wiki/WGN_News_at_Nine" title="WGN News at Nine">The Nine O'Clock News</a>.</i> Home viewers' screens went black for about fifteen seconds, before footage of a person wearing a <a href="https://en.wikipedia.org/wiki/Max_Headroom" title="Max Headroom">Max Headroom</a> mask and sunglasses is displayed. The individual rocks erratically in front of a rotating <a href="https://en.wikipedia.org/wiki/Corrugated_metal" title="Corrugated metal">corrugated metal</a> panel that mimicked the real Max Headroom's geometric background effect accompanied by a staticky and garbled buzzing sound.<sup id="cite_ref-Knittel_1-1"><a href="#cite_note-Knittel-1">[1]</a></sup><sup id="cite_ref-Hayner_10-0"><a href="#cite_note-Hayner-10">[10]</a></sup><sup id="cite_ref-Bellows_11-0"><a href="#cite_note-Bellows-11">[11]</a></sup> The entire intrusion lasted for about 20 seconds and was cut off when engineers at WGN changed the frequency of the signal <a href="https://en.wikipedia.org/wiki/Studio_transmitter_link" title="Studio transmitter link">linking</a> the broadcast studio to the station's transmitter atop the <a href="https://en.wikipedia.org/wiki/John_Hancock_Center" title="John Hancock Center">John Hancock Center</a>.<sup id="cite_ref-Camper_12-0"><a href="#cite_note-Camper-12">[12]</a></sup>
</p><p>Upon returning to the airwaves, WGN sports anchor Dan Roan commented, "Well, if you're wondering what's happened, so am I",<sup id="cite_ref-Knittel_1-2"><a href="#cite_note-Knittel-1">[1]</a></sup> and joked that the computer running the news "took off and went wild". Roan then proceeded to restart his report of the day's <a href="https://en.wikipedia.org/wiki/Chicago_Bears" title="Chicago Bears">Chicago Bears</a> game, which had been interrupted by the intrusion.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>
</p>
<h3><span id="WTTW">WTTW</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=3" title="Edit section: WTTW"><span>edit</span></a><span>]</span></span></h3>
<figure typeof="mw:File/Thumb"><span><video id="mwe_player_1" poster="https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Max_Headroom_broadcast_intrusion.webm/220px--Max_Headroom_broadcast_intrusion.webm.jpg" controls="" preload="none" width="220" height="165" data-durationhint="94" data-mwtitle="Max_Headroom_broadcast_intrusion.webm" data-mwprovider="wikimediacommons" resource="/wiki/File:Max_Headroom_broadcast_intrusion.webm"><source src="https://upload.wikimedia.org/wikipedia/commons/1/15/Max_Headroom_broadcast_intrusion.webm" type="video/webm; codecs=&quot;vp9, opus&quot;" data-width="448" data-height="336"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/1/15/Max_Headroom_broadcast_intrusion.webm/Max_Headroom_broadcast_intrusion.webm.m3u8" type="application/vnd.apple.mpegurl" data-transcodekey="m3u8" data-width="0" data-height="0"><source src="https://upload.wikimedia.org/wikipedia/commons/transcoded/1/15/Max_Headroom_broadcast_intrusion.webm/Max_Headroom_broadcast_intrusion.webm.240p.vp9.webm" type="video/webm; codecs=&quot;vp9, opus&quot;" data-transcodekey="240p.vp9.webm" data-width="320" data-height="240"><track src="https://commons.wikimedia.org/w/api.php?action=timedtext&amp;title=File%3AMax_Headroom_broadcast_intrusion.webm&amp;lang=en&amp;trackformat=vtt&amp;origin=%2A" kind="subtitles" type="text/vtt" srclang="en" label="English ‪(en)‬" data-dir="ltr"><track src="https://commons.wikimedia.org/w/api.php?action=timedtext&amp;title=File%3AMax_Headroom_broadcast_intrusion.webm&amp;lang=pl&amp;trackformat=vtt&amp;origin=%2A" kind="subtitles" type="text/vtt" srclang="pl" label="polski ‪(pl)‬" data-dir="ltr"><track src="https://commons.wikimedia.org/w/api.php?action=timedtext&amp;title=File%3AMax_Headroom_broadcast_intrusion.webm&amp;lang=ru&amp;trackformat=vtt&amp;origin=%2A" kind="subtitles" type="text/vtt" srclang="ru" label="русский ‪(ru)‬" data-dir="ltr"></video></span><figcaption>A recording of the WTTW intrusion<sup id="cite_ref-Original_Upload_14-0"><a href="#cite_note-Original_Upload-14">[14]</a></sup></figcaption></figure>
<div>
<p><span typeof="mw:File"><span><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/38px-Wikisource-logo.svg.png" decoding="async" width="38" height="40" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/57px-Wikisource-logo.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/76px-Wikisource-logo.svg.png 2x" data-file-width="410" data-file-height="430"></span></span></p>
<div><p><a href="https://en.wikipedia.org/wiki/Wikisource" title="Wikisource">Wikisource</a> has original text related to this article:
</p></div></div>
<p>That same night, at about 11:20 pm, the signal of local <a href="https://en.wikipedia.org/wiki/PBS" title="PBS">PBS</a> station <a href="https://en.wikipedia.org/wiki/WTTW" title="WTTW">WTTW</a> was interrupted during an airing of the <i><a href="https://en.wikipedia.org/wiki/Doctor_Who" title="Doctor Who">Doctor Who</a></i> serial <i><a href="https://en.wikipedia.org/wiki/Horror_of_Fang_Rock" title="Horror of Fang Rock">Horror of Fang Rock</a></i>. The culprit was the same Max Headroom impersonator, this time speaking with distorted audio.<sup id="cite_ref-Gallagher_8-2"><a href="#cite_note-Gallagher-8">[8]</a></sup><sup id="cite_ref-Bellows_11-1"><a href="#cite_note-Bellows-11">[11]</a></sup>
</p><p>The masked figure made a comment about "nerds", called WGN sportscaster <a href="https://en.wikipedia.org/wiki/Chuck_Swirsky" title="Chuck Swirsky">Chuck Swirsky</a> a "frickin' <a href="https://en.wikipedia.org/wiki/Liberalism" title="Liberalism">liberal</a>", held up a can of <a href="https://en.wikipedia.org/wiki/Pepsi" title="Pepsi">Pepsi</a> while saying "<a href="https://en.wikipedia.org/wiki/Catch_the_wave" title="Catch the wave">Catch the wave</a>" (a slogan from an ad campaign for <a href="https://en.wikipedia.org/wiki/Coca-Cola" title="Coca-Cola">Coca-Cola</a> featuring the Max Headroom character),<sup id="cite_ref-Knittel_1-3"><a href="#cite_note-Knittel-1">[1]</a></sup><sup id="cite_ref-Gallagher_8-3"><a href="#cite_note-Gallagher-8">[8]</a></sup> and held up a <a href="https://en.wikipedia.org/wiki/The_finger" title="The finger">middle finger</a> inside what appeared to be a hollowed-out <a href="https://en.wikipedia.org/wiki/Dildo" title="Dildo">dildo</a>.<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> The figure then ran through a series of quick comments and song snippets interspersed with excited noises and exclamations. "Max" sang the phrase "<a href="https://en.wikipedia.org/wiki/(I_Know)_I%27m_Losing_You" title="(I Know) I'm Losing You">Your love is fading</a>"; hummed part of the theme song to the 1959 animated series <i><a href="https://en.wikipedia.org/wiki/Clutch_Cargo" title="Clutch Cargo">Clutch Cargo</a></i> and said, "I still see the X!" (This was a reference to the last episode of that show, which is <a href="https://en.wikipedia.org/wiki/Mondegreen" title="Mondegreen">sometimes misheard</a> as "I stole <a href="https://en.wikipedia.org/wiki/CBS" title="CBS">CBS</a>.") He also feigned <a href="https://en.wikipedia.org/wiki/Defecation" title="Defecation">defecation</a> (complaining of his <a href="https://en.wikipedia.org/wiki/Piles" title="Piles">piles</a>) and explained that he had "made a giant masterpiece for all the Greatest World Newspaper nerds" (WGN's call letters stand for "<a href="https://en.wikipedia.org/wiki/World%27s_Greatest_Newspaper" title="World's Greatest Newspaper">World's Greatest Newspaper</a>"), and discussed sharing a pair of dirty gloves with his brother.<sup id="cite_ref-Knittel_1-4"><a href="#cite_note-Knittel-1">[1]</a></sup><sup id="cite_ref-Bellows_11-2"><a href="#cite_note-Bellows-11">[11]</a></sup><sup id="cite_ref-Gallagher_8-4"><a href="#cite_note-Gallagher-8">[8]</a></sup> After a crude video edit, the person had moved mostly offscreen to the left with his partially exposed <a href="https://en.wikipedia.org/wiki/Buttocks" title="Buttocks">buttocks</a> visible from the side, with a female figure wearing a <a href="https://en.wikipedia.org/wiki/French_maid" title="French maid">French maid</a> costume and what appears to be a mask appearing on the right edge of the frame. The (unworn) Max Headroom mask was briefly held in view while the voice cried out, "Oh no, they're coming to get me! Ah, make it stop!" and the female figure began spanking "Max" with a <a href="https://en.wikipedia.org/wiki/Flyswatter" title="Flyswatter">flyswatter</a>.<sup id="cite_ref-Gallagher_8-5"><a href="#cite_note-Gallagher-8">[8]</a></sup> The image faded briefly into static, and then viewers were returned to the <i>Doctor Who</i> broadcast after a total interruption of about 90 seconds.<sup id="cite_ref-Gallagher_8-6"><a href="#cite_note-Gallagher-8">[8]</a></sup><sup id="cite_ref-Bellows_11-3"><a href="#cite_note-Bellows-11">[11]</a></sup>
</p><p>Technicians at WTTW's studios could not counteract the signal takeover because there were no engineers on duty at that hour at the <a href="https://en.wikipedia.org/wiki/Willis_Tower" title="Willis Tower">Sears Tower (now known as the Willis Tower)</a>, where the station's broadcast tower was located. According to station spokesman Anders Yocom, technicians monitoring the transmission from WTTW headquarters "attempted to take corrective measures, but couldn't."<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup> Air director Paul Rizzo recalled that "as the content got weirder we got increasingly stressed out about our inability to do anything about it."<sup id="cite_ref-Shefsky_6-2"><a href="#cite_note-Shefsky-6">[6]</a></sup> The pirate broadcast ended when the hijackers unilaterally ended their transmission. "By the time our people began looking into what was going on, it was over," said Yocom.<sup id="cite_ref-Camper_12-1"><a href="#cite_note-Camper-12">[12]</a></sup> WTTW received numerous phone calls from viewers who wondered what had occurred.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup>
</p>
<h2><span id="Methods_and_investigations">Methods and investigations</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=4" title="Edit section: Methods and investigations"><span>edit</span></a><span>]</span></span></h2>
<p>The broadcast intrusion was achieved by sending a more powerful <a href="https://en.wikipedia.org/wiki/Microwave_transmission" title="Microwave transmission">microwave transmission</a> to the stations' broadcast towers than the stations were sending themselves, triggering a <a href="https://en.wikipedia.org/wiki/Capture_effect" title="Capture effect">capture effect</a>. This was a difficult task in 1987 but was possible before American television stations switched from <a href="https://en.wikipedia.org/wiki/Digital_television_transition_in_the_United_States" title="Digital television transition in the United States">analog to digital signals</a> in 2009.<sup id="cite_ref-Haskins_9-2"><a href="#cite_note-Haskins-9">[9]</a></sup> Experts have said that the stunt required extensive technical expertise and a significant amount of transmitting power, and that the pirate broadcast likely originated from somewhere in the line of sight of both stations' broadcast towers, which were atop two tall buildings in <a href="https://en.wikipedia.org/wiki/Downtown_Chicago" title="Downtown Chicago">downtown Chicago</a>.<sup id="cite_ref-Camper_12-2"><a href="#cite_note-Camper-12">[12]</a></sup>
</p><p>No one has ever claimed responsibility for the stunt. Speculation about the identities of "Max" and his co-conspirators has centered on the theories that the prank was either an inside job by a disgruntled employee (or former employee) of WGN or was carried out by members of Chicago's underground <a href="https://en.wikipedia.org/wiki/Hacker_culture" title="Hacker culture">hacker community</a>. However, despite an official law enforcement investigation in the immediate aftermath of the incident and many unofficial investigations, inquiries, and online speculation in the ensuing decades, the identities and motives of the hijackers remain a mystery.<sup id="cite_ref-Shefsky_6-3"><a href="#cite_note-Shefsky-6">[6]</a></sup><sup id="cite_ref-Unruh_7-2"><a href="#cite_note-Unruh-7">[7]</a></sup><sup id="cite_ref-Gallagher_8-7"><a href="#cite_note-Gallagher-8">[8]</a></sup><sup id="cite_ref-Haskins_9-3"><a href="#cite_note-Haskins-9">[9]</a></sup><sup id="cite_ref-wbur_18-0"><a href="#cite_note-wbur-18">[18]</a></sup>
</p><p>Soon after the intrusion, an <a href="https://en.wikipedia.org/wiki/Federal_Communications_Commission" title="Federal Communications Commission">FCC</a> official was quoted in news reporting that the perpetrators faced a maximum fine of $10,000 and up to a year in prison.<sup id="cite_ref-Knittel_1-5"><a href="#cite_note-Knittel-1">[1]</a></sup><sup id="cite_ref-Camper_12-3"><a href="#cite_note-Camper-12">[12]</a></sup> However, the five-year <a href="https://en.wikipedia.org/wiki/Statute_of_limitations" title="Statute of limitations">statute of limitations</a> was surpassed in 1992, so the persons responsible for the intrusion would no longer face criminal punishment should their identities be revealed.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup>
</p>
<h2><span id="Cultural_impact">Cultural impact</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=5" title="Edit section: Cultural impact"><span>edit</span></a><span>]</span></span></h2>
<p>Though the incident only briefly caught the attention of the general public, it has been overtly or subtly referenced in a variety of media over the ensuing decades, with <i><a href="https://en.wikipedia.org/wiki/Motherboard_(website)" title="Motherboard (website)">Motherboard</a></i> claiming that it has been an influential "<a href="https://en.wikipedia.org/wiki/Cyberpunk" title="Cyberpunk">cyberpunk</a> hacking trope".<sup id="cite_ref-Haskins_9-4"><a href="#cite_note-Haskins-9">[9]</a></sup>
</p><p>The first reference came soon after the initial events when <a href="https://en.wikipedia.org/wiki/WMAQ-TV" title="WMAQ-TV">WMAQ-TV</a>, another Chicago TV station, humorously inserted clips of the hijacking into a newscast during <a href="https://en.wikipedia.org/wiki/Mark_Giangreco" title="Mark Giangreco">Mark Giangreco</a>'s sports highlights. "A lot of people thought it was real – the pirate cutting into our broadcast. We got all kinds of calls about it," said Giangreco.<sup id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=6" title="Edit section: See also"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Captain_Midnight_broadcast_signal_intrusion" title="Captain Midnight broadcast signal intrusion">Captain Midnight broadcast signal intrusion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pirate_television" title="Pirate television">Pirate television</a></li>
<li><a href="https://en.wikipedia.org/wiki/Southern_Television_broadcast_interruption" title="Southern Television broadcast interruption">Southern Television broadcast interruption</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=7" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-Knittel-1"><span>^ <a href="#cite_ref-Knittel_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Knittel_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Knittel_1-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Knittel_1-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-Knittel_1-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-Knittel_1-5"><sup><i><b>f</b></i></sup></a></span> <span><cite id="CITEREFKnittel2013">Knittel, Chris (November 25, 2013). <a rel="nofollow" href="https://web.archive.org/web/20140918011433/http://motherboard.vice.com/read/headroom-hacker">"The Mystery of the Creepiest Television Hack"</a>. <i><a href="https://en.wikipedia.org/wiki/Motherboard_(website)" title="Motherboard (website)">Motherboard</a></i>. Vice Media. Archived from <a rel="nofollow" href="http://motherboard.vice.com/read/headroom-hacker">the original</a> on September 18, 2014.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Motherboard&amp;rft.atitle=The+Mystery+of+the+Creepiest+Television+Hack&amp;rft.date=2013-11-25&amp;rft.aulast=Knittel&amp;rft.aufirst=Chris&amp;rft_id=http%3A%2F%2Fmotherboard.vice.com%2Fread%2Fheadroom-hacker&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Ross-2"><span><b><a href="#cite_ref-Ross_2-0">^</a></b></span> <span><cite id="CITEREFRoss1990">Ross, Andrew (1990). <a rel="nofollow" href="https://books.google.com/books?id=bHruHIDpQjMC&amp;q=max+headroom+pirate+broadcast">"Techno-Ethics and Tele-Ethics: Three Lives in the Day of Max Headroom"</a>. In Mellencamp, Patricia (ed.). <i>Logics of Television: Essays in Cultural Criticism</i>. Indiana University Press. p.&nbsp;138. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-253-33617-1" title="Special:BookSources/0-253-33617-1"><bdi>0-253-33617-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Techno-Ethics+and+Tele-Ethics%3A+Three+Lives+in+the+Day+of+Max+Headroom&amp;rft.btitle=Logics+of+Television%3A+Essays+in+Cultural+Criticism&amp;rft.pages=138&amp;rft.pub=Indiana+University+Press&amp;rft.date=1990&amp;rft.isbn=0-253-33617-1&amp;rft.aulast=Ross&amp;rft.aufirst=Andrew&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DbHruHIDpQjMC%26q%3Dmax%2Bheadroom%2Bpirate%2Bbroadcast&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Schwoch-3"><span><b><a href="#cite_ref-Schwoch_3-0">^</a></b></span> <span><cite id="CITEREFSchwochWhiteReilly1992">Schwoch, James; White, Mimi; Reilly, Susan (1992). <a rel="nofollow" href="https://books.google.com/books?id=0uFc3zXaTncC&amp;q=max+headroom+%22video+piracy%22"><i>Media Knowledge: Readings in Popular Culture, Pedagogy, and Critical Citizenship</i></a>. SUNY Press. p.&nbsp;113. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-7914-0825-4" title="Special:BookSources/978-0-7914-0825-4"><bdi>978-0-7914-0825-4</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Media+Knowledge%3A+Readings+in+Popular+Culture%2C+Pedagogy%2C+and+Critical+Citizenship&amp;rft.pages=113&amp;rft.pub=SUNY+Press&amp;rft.date=1992&amp;rft.isbn=978-0-7914-0825-4&amp;rft.aulast=Schwoch&amp;rft.aufirst=James&amp;rft.au=White%2C+Mimi&amp;rft.au=Reilly%2C+Susan&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D0uFc3zXaTncC%26q%3Dmax%2Bheadroom%2B%2522video%2Bpiracy%2522&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Forester-4"><span><b><a href="#cite_ref-Forester_4-0">^</a></b></span> <span><cite id="CITEREFForesterMorrison1994">Forester, Tom; Morrison, Perry (1994). <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/computerethicsca00fore/page/74"><i>Computer Ethics: Cautionary Tales and Ethical Dilemmas in Computing</i></a></span>. MIT Press. p.&nbsp;74. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-262-56073-9" title="Special:BookSources/0-262-56073-9"><bdi>0-262-56073-9</bdi></a>. <q>[S]everal other instances of uplink video piracy have occurred [...] WTTW (Channel 11 in Chicago) was also overridden by a 90 second transmission, this time by a man in a Max Headroom mask smacking his exposed buttocks with a riding crop.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+Ethics%3A+Cautionary+Tales+and+Ethical+Dilemmas+in+Computing&amp;rft.pages=74&amp;rft.pub=MIT+Press&amp;rft.date=1994&amp;rft.isbn=0-262-56073-9&amp;rft.aulast=Forester&amp;rft.aufirst=Tom&amp;rft.au=Morrison%2C+Perry&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fcomputerethicsca00fore%2Fpage%2F74&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span> <cite id="CITEREFHill2017">Hill, Steven Warren (2017), <i>Red White and Who: The Story of Doctor Who in America</i>, Cockeysville,MD: ATB Publishing, p.&nbsp;79-81</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Red+White+and+Who%3A+The+Story+of+Doctor+Who+in+America&amp;rft.place=Cockeysville%2CMD&amp;rft.pages=79-81&amp;rft.pub=ATB+Publishing&amp;rft.date=2017&amp;rft.aulast=Hill&amp;rft.aufirst=Steven+Warren&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Shefsky-6"><span>^ <a href="#cite_ref-Shefsky_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Shefsky_6-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Shefsky_6-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Shefsky_6-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFShefsky2017">Shefsky, Jay (November 21, 2017). <a rel="nofollow" href="https://news.wttw.com/2017/11/21/30-years-later-notorious-max-headroom-incident-remains-mystery">"30 Years Later, Notorious 'Max Headroom Incident' Remains a Mystery"</a>. <i>WTTW News</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=WTTW+News&amp;rft.atitle=30+Years+Later%2C+Notorious+%27Max+Headroom+Incident%27+Remains+a+Mystery&amp;rft.date=2017-11-21&amp;rft.aulast=Shefsky&amp;rft.aufirst=Jay&amp;rft_id=https%3A%2F%2Fnews.wttw.com%2F2017%2F11%2F21%2F30-years-later-notorious-max-headroom-incident-remains-mystery&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Unruh-7"><span>^ <a href="#cite_ref-Unruh_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Unruh_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Unruh_7-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFUnruh2017">Unruh, Julie (November 23, 2017). <a rel="nofollow" href="https://wgntv.com/2017/11/22/30-years-later-max-headroom-hijack-mystery-remains-unsolved/">"30 years later, Max Headroom hijack mystery remains unsolved"</a>. <i>WGN-TV</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=WGN-TV&amp;rft.atitle=30+years+later%2C+Max+Headroom+hijack+mystery+remains+unsolved&amp;rft.date=2017-11-23&amp;rft.aulast=Unruh&amp;rft.aufirst=Julie&amp;rft_id=https%3A%2F%2Fwgntv.com%2F2017%2F11%2F22%2F30-years-later-max-headroom-hijack-mystery-remains-unsolved%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Gallagher-8"><span>^ <a href="#cite_ref-Gallagher_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Gallagher_8-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Gallagher_8-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Gallagher_8-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-Gallagher_8-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-Gallagher_8-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-Gallagher_8-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-Gallagher_8-7"><sup><i><b>h</b></i></sup></a></span> <span><cite id="CITEREFGallagher2017">Gallagher, Sean (November 22, 2017). <a rel="nofollow" href="https://arstechnica.com/information-technology/2017/11/thirty-years-later-max-headroom-tv-pirate-remains-at-large/">"Thirty years later, "Max Headroom" TV pirate remains at large"</a>. <i>Ars Technica</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ars+Technica&amp;rft.atitle=Thirty+years+later%2C+%22Max+Headroom%22+TV+pirate+remains+at+large&amp;rft.date=2017-11-22&amp;rft.aulast=Gallagher&amp;rft.aufirst=Sean&amp;rft_id=https%3A%2F%2Farstechnica.com%2Finformation-technology%2F2017%2F11%2Fthirty-years-later-max-headroom-tv-pirate-remains-at-large%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Haskins-9"><span>^ <a href="#cite_ref-Haskins_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Haskins_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Haskins_9-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Haskins_9-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-Haskins_9-4"><sup><i><b>e</b></i></sup></a></span> <span><cite id="CITEREFHaskins2017">Haskins, Caroline (November 22, 2017). <a rel="nofollow" href="https://www.vice.com/en_us/article/59yvj5/max-headroom-hack-anniversary">"Television's Most Infamous Hack Is Still a Mystery 30 Years Later"</a>. <i>Motherboard</i>. Vice Media.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Motherboard&amp;rft.atitle=Television%27s+Most+Infamous+Hack+Is+Still+a+Mystery+30+Years+Later&amp;rft.date=2017-11-22&amp;rft.aulast=Haskins&amp;rft.aufirst=Caroline&amp;rft_id=https%3A%2F%2Fwww.vice.com%2Fen_us%2Farticle%2F59yvj5%2Fmax-headroom-hack-anniversary&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Hayner-10"><span><b><a href="#cite_ref-Hayner_10-0">^</a></b></span> <span><cite id="CITEREFHayner1987">Hayner, Don (November 24, 1987). <a rel="nofollow" href="https://web.archive.org/web/20121106072747/http://www.highbeam.com/doc/1P2-3857222.html">"2 channels interrupted to the Max"</a>. <i><a href="https://en.wikipedia.org/wiki/Chicago_Sun-Times" title="Chicago Sun-Times">Chicago Sun-Times</a></i>. p.&nbsp;3. CHI265386. Archived from <a rel="nofollow" href="https://www.highbeam.com/doc/1P2-3857222.html">the original</a> on November 6, 2012<span>. Retrieved <span>June 26,</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Chicago+Sun-Times&amp;rft.atitle=2+channels+interrupted+to+the+Max&amp;rft.pages=3&amp;rft.date=1987-11-24&amp;rft.aulast=Hayner&amp;rft.aufirst=Don&amp;rft_id=https%3A%2F%2Fwww.highbeam.com%2Fdoc%2F1P2-3857222.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Bellows-11"><span>^ <a href="#cite_ref-Bellows_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Bellows_11-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Bellows_11-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Bellows_11-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFBellows2007">Bellows, Alan (January 2007). <a rel="nofollow" href="https://www.damninteresting.com/remember-remember-the-22nd-of-november/">"Remember, Remember the 22nd of November"</a>. <i>Damn Interesting</i>. <a rel="nofollow" href="https://web.archive.org/web/20160515162926/http://www.damninteresting.com/remember-remember-the-22nd-of-november/">Archived</a> from the original on May 15, 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Damn+Interesting&amp;rft.atitle=Remember%2C+Remember+the+22nd+of+November&amp;rft.date=2007-01&amp;rft.aulast=Bellows&amp;rft.aufirst=Alan&amp;rft_id=https%3A%2F%2Fwww.damninteresting.com%2Fremember-remember-the-22nd-of-november%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Camper-12"><span>^ <a href="#cite_ref-Camper_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Camper_12-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Camper_12-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Camper_12-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFCamperDaley1987">Camper, John; Daley, Steve (November 24, 1987). <a rel="nofollow" href="https://www.chicagotribune.com/news/ct-xpm-1987-11-24-8703280602-story.html">"A powerful video prankster could become Max Jailroom"</a>. <i>Chicago Tribune</i>. p.&nbsp;21. <q>Strutzel said an engineer quickly changed the frequency of the signal that was transmitting the news show to the Hancock building, thus breaking the lock established by the video pirate.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Chicago+Tribune&amp;rft.atitle=A+powerful+video+prankster+could+become+Max+Jailroom&amp;rft.pages=21&amp;rft.date=1987-11-24&amp;rft.aulast=Camper&amp;rft.aufirst=John&amp;rft.au=Daley%2C+Steve&amp;rft_id=https%3A%2F%2Fwww.chicagotribune.com%2Fnews%2Fct-xpm-1987-11-24-8703280602-story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=dKnwhokvgxE"><i>WGN Channel 9 – The Nine O'Clock News – "The 1st 'Max Headroom' Incident" (1987)</i></a> (Videotape). <a href="https://en.wikipedia.org/wiki/The_Museum_of_Classic_Chicago_Television" title="The Museum of Classic Chicago Television">The Museum of Classic Chicago Television</a>. November 23, 2017<span>. Retrieved <span>November 23,</span> 2017</span> – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=WGN+Channel+9+%E2%80%93+The+Nine+O%27Clock+News+%E2%80%93+%22The+1st+%27Max+Headroom%27+Incident%22+%281987%29&amp;rft.pub=The+Museum+of+Classic+Chicago+Television&amp;rft.date=2017-11-23&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DdKnwhokvgxE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-Original_Upload-14"><span><b><a href="#cite_ref-Original_Upload_14-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=cycVTXtm0U0"><i>WTTW Chicago – The Max Headroom Pirating Incident (1987) – Original Upload</i></a> (videotape). <a href="https://en.wikipedia.org/wiki/The_Museum_of_Classic_Chicago_Television" title="The Museum of Classic Chicago Television">The Museum of Classic Chicago Television</a>. October 30, 2007. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211213/cycVTXtm0U0">Archived</a> from the original on December 13, 2021 – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=WTTW+Chicago+%E2%80%93+The+Max+Headroom+Pirating+Incident+%281987%29+%E2%80%93+Original+Upload&amp;rft.pub=The+Museum+of+Classic+Chicago+Television&amp;rft.date=2007-10-30&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DcycVTXtm0U0&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.fuzzymemories.tv/index.php?c=59&amp;m=max+headroom+pirate">"WTTW Channel 11 – Doctor Who – 'The Max Headroom Pirating Incident' (1987)"</a>. <i>The Museum of Classic Chicago Television</i><span>. Retrieved <span>September 9,</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Museum+of+Classic+Chicago+Television&amp;rft.atitle=WTTW+Channel+11+%E2%80%93+Doctor+Who+%E2%80%93+%27The+Max+Headroom+Pirating+Incident%27+%281987%29&amp;rft_id=http%3A%2F%2Fwww.fuzzymemories.tv%2Findex.php%3Fc%3D59%26m%3Dmax%2Bheadroom%2Bpirate&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFCarmody1987">Carmody, John (November 24, 1987). <a rel="nofollow" href="https://web.archive.org/web/20160909044838/http://pqasb.pqarchiver.com/washingtonpost/doc/306943044.html?FMT=ABS&amp;FMTS=ABS:FT&amp;date=Nov+24%2C+1987&amp;author=Carmody%2C+John&amp;pub=The+Washington+Post+%28pre-1997+Fulltext%29&amp;edition=&amp;startpage=d.01&amp;desc=NBC+Lands+Gorbachev+Interview">"NBC Lands Gorbachev Interview"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Washington_Post" title="The Washington Post">The Washington Post</a></i>. p.&nbsp;D1. 95520. Archived from <span title="Paid subscription required"><a rel="nofollow" href="https://pqasb.pqarchiver.com/washingtonpost/doc/306943044.html?FMT=ABS&amp;FMTS=ABS:FT&amp;date=Nov+24%2C+1987&amp;author=Carmody%2C+John&amp;pub=The+Washington+Post+%28pre-1997+Fulltext%29&amp;edition=&amp;startpage=d.01&amp;desc=NBC+Lands+Gorbachev+Interview">the original</a></span> on September 9, 2016<span>. Retrieved <span>June 26,</span> 2016</span> – via <a href="https://en.wikipedia.org/wiki/ProQuest#Archived_newspapers" title="ProQuest">ProQuest Archiver</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Washington+Post&amp;rft.atitle=NBC+Lands+Gorbachev+Interview&amp;rft.pages=D1&amp;rft.date=1987-11-24&amp;rft.aulast=Carmody&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fpqasb.pqarchiver.com%2Fwashingtonpost%2Fdoc%2F306943044.html%3FFMT%3DABS%26FMTS%3DABS%3AFT%26date%3DNov%2B24%252C%2B1987%26author%3DCarmody%252C%2BJohn%26pub%3DThe%2BWashington%2BPost%2B%2528pre-1997%2BFulltext%2529%26edition%3D%26startpage%3Dd.01%26desc%3DNBC%2BLands%2BGorbachev%2BInterview&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite>"Bogus Max Headroom pirates 2 TV stations, drops his pants". <i><a href="https://en.wikipedia.org/wiki/The_Palm_Beach_Post" title="The Palm Beach Post">The Palm Beach Post</a></i>. Associated Press. November 24, 1987. p.&nbsp;3A.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Palm+Beach+Post&amp;rft.atitle=Bogus+Max+Headroom+pirates+2+TV+stations%2C+drops+his+pants&amp;rft.pages=3A&amp;rft.date=1987-11-24&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-wbur-18"><span><b><a href="#cite_ref-wbur_18-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.wbur.org/endlessthread/2019/11/22/to-the-max-headroom">"The Max Headroom Incident: Revisiting The Masked Mystery, 32 Years Later"</a>. <i>www.wbur.org</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=www.wbur.org&amp;rft.atitle=The+Max+Headroom+Incident%3A+Revisiting+The+Masked+Mystery%2C+32+Years+Later&amp;rft_id=https%3A%2F%2Fwww.wbur.org%2Fendlessthread%2F2019%2F11%2F22%2Fto-the-max-headroom&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFKnittel2013">Knittel, Chris (November 25, 2013). <a rel="nofollow" href="https://www.vice.com/en/article/pgay3n/headroom-hacker">"The Mystery of the Creepiest Television Hack"</a>. Vice:Motherboard<span>. Retrieved <span>February 4,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Mystery+of+the+Creepiest+Television+Hack&amp;rft.pub=Vice%3AMotherboard&amp;rft.date=2013-11-25&amp;rft.aulast=Knittel&amp;rft.aufirst=Chris&amp;rft_id=https%3A%2F%2Fwww.vice.com%2Fen%2Farticle%2Fpgay3n%2Fheadroom-hacker&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
<li id="cite_note-20"><span><b><a href="#cite_ref-20">^</a></b></span> <span><cite id="CITEREFRuane1988">Ruane, John (January 1, 1988). <a rel="nofollow" href="https://web.archive.org/web/20160911154315/https://www.highbeam.com/doc/1P2-3863222.html">"Casting final look at '87 // Local sportscasters recall year's memorable events"</a>. <i><a href="https://en.wikipedia.org/wiki/Chicago_Sun-Times" title="Chicago Sun-Times">Chicago Sun-Times</a></i>. p.&nbsp;94. Archived from <a rel="nofollow" href="https://www.highbeam.com/doc/1P2-3863222.html">the original</a> on September 11, 2016<span>. Retrieved <span>June 26,</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Chicago+Sun-Times&amp;rft.atitle=Casting+final+look+at+%2787+%2F%2F+Local+sportscasters+recall+year%27s+memorable+events&amp;rft.pages=94&amp;rft.date=1988-01-01&amp;rft.aulast=Ruane&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.highbeam.com%2Fdoc%2F1P2-3863222.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></span>
</li>
</ol></div>
<h2><span id="Further_reading">Further reading</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=8" title="Edit section: Further reading"><span>edit</span></a><span>]</span></span></h2>
<ul><li><cite id="CITEREFBerke2015">Berke, Jeremy (July 7, 2015). <a rel="nofollow" href="https://www.atlasobscura.com/articles/the-freakiest-tv-hack-of-the-1980s-max-headroom">"The Freakiest TV Hack of the 1980s: Max Headroom"</a>. <i><a href="https://en.wikipedia.org/wiki/Atlas_Obscura" title="Atlas Obscura">Atlas Obscura</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Atlas+Obscura&amp;rft.atitle=The+Freakiest+TV+Hack+of+the+1980s%3A+Max+Headroom&amp;rft.date=2015-07-07&amp;rft.aulast=Berke&amp;rft.aufirst=Jeremy&amp;rft_id=https%3A%2F%2Fwww.atlasobscura.com%2Farticles%2Fthe-freakiest-tv-hack-of-the-1980s-max-headroom&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></li>
<li><cite><a rel="nofollow" href="https://web.archive.org/web/20160909140638/http://articles.philly.com/1987-11-24/news/26174863_1_max-headroom-video-pirate-broadcasts">"Bogus 'Max Headroom' Interrupts Broadcasts On 2 Chicago Stations"</a>. <i>The Philadelphia Inquirer</i>. Inquirer Wire Services. November 24, 1987. Archived from <a rel="nofollow" href="http://articles.philly.com/1987-11-24/news/26174863_1_max-headroom-video-pirate-broadcasts">the original</a> on September 9, 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Philadelphia+Inquirer&amp;rft.atitle=Bogus+%27Max+Headroom%27+Interrupts+Broadcasts+On+2+Chicago+Stations&amp;rft.date=1987-11-24&amp;rft_id=http%3A%2F%2Farticles.philly.com%2F1987-11-24%2Fnews%2F26174863_1_max-headroom-video-pirate-broadcasts&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></li>
<li><cite id="CITEREFCarpenter1987">Carpenter, John (November 23, 1987). <a rel="nofollow" href="https://www.chicagotribune.com/business/ct-biz-wttw-max-headroom-30-years-20171122-story.html">"The Max Headroom incident"</a>. <i>Chicago Tribune</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Chicago+Tribune&amp;rft.atitle=The+Max+Headroom+incident&amp;rft.date=1987-11-23&amp;rft.aulast=Carpenter&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.chicagotribune.com%2Fbusiness%2Fct-biz-wttw-max-headroom-30-years-20171122-story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></li>
<li><cite id="CITEREFGallerneaux2019">Gallerneaux, Kristen (2019). <a rel="nofollow" href="https://books.google.com/books?id=7a6aDwAAQBAJ&amp;q=%22max+headroom+signal+intrusion%22">"The Max Headroom Signal Intrusion"</a>. In Goodman, S.; Heys, T.; Ikoniadou, E. (eds.). <i>AUDINT—Unsound:Undead</i>. Cambridge, Mass.: MIT Press; Urbanomic Ltd. pp.&nbsp;115–118. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-9164052-1-9" title="Special:BookSources/978-1-9164052-1-9"><bdi>978-1-9164052-1-9</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=The+Max+Headroom+Signal+Intrusion&amp;rft.btitle=AUDINT%E2%80%94Unsound%3AUndead&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pages=115-118&amp;rft.pub=MIT+Press%3B+Urbanomic+Ltd.&amp;rft.date=2019&amp;rft.isbn=978-1-9164052-1-9&amp;rft.aulast=Gallerneaux&amp;rft.aufirst=Kristen&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D7a6aDwAAQBAJ%26q%3D%2522max%2Bheadroom%2Bsignal%2Bintrusion%2522&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMax+Headroom+signal+hijacking"></span></li></ul>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Max_Headroom_signal_hijacking&amp;action=edit&amp;section=9" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>




<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐7bbb9c7bbf‐jzcst
Cached time: 20231123163849
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.531 seconds
Real time usage: 0.705 seconds
Preprocessor visited node count: 8534/1000000
Post‐expand include size: 87374/2097152 bytes
Template argument size: 3699/2097152 bytes
Highest expansion depth: 18/100
Expensive parser function count: 7/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 88873/5000000 bytes
Lua time usage: 0.280/10.000 seconds
Lua memory usage: 7674597/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  600.357      1 -total
 27.23%  163.469      1 Template:Reflist
 13.24%   79.495      6 Template:Cite_web
 13.05%   78.326     14 Template:R
 12.18%   73.129      2 Template:Navbox
 11.99%   71.974      1 Template:Max_Headroom
 11.57%   69.471     25 Template:R/ref
  9.60%   57.616      1 Template:Infobox_event
  7.97%   47.864      1 Template:Portal_bar
  7.28%   43.693      1 Template:Short_description
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:8111088-0!canonical and timestamp 20231123163848 and revision id 1186506284. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Polio Is on the Brink of Eradication (346 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-03602-5</link>
            <guid>38392277</guid>
            <pubDate>Thu, 23 Nov 2023 13:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-03602-5">https://www.nature.com/articles/d41586-023-03602-5</a>, See on <a href="https://news.ycombinator.com/item?id=38392277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311762.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311762.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="A child has his thumb marked after receiving a polio vaccine during a door-to-door polio immunization campaign in Tanzania, 2022." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311762.jpg">
  <figcaption>
   <p><span>A child in Tanzania has his finger marked to show that he has received a polio vaccine during a door-to-door campaign in 2022.</span><span>Credit: Ericky Boniphace/AFP via Getty</span></p>
  </figcaption>
 </picture>
</figure><p>Nobody expected polio to be back.</p><p>It’s 2040, a decade since the disease was eradicated. The global health campaign that vanquished the virus has disbanded; immunization efforts have slackened. Then, one day, a sick child in a conflict-wracked country develops paralysis; the cause turns out to be polio. Scientists trace the origin of the virus to a laboratory on the other side of the world. A technician at the lab had handled a forgotten batch of polio-infected material — and then visited their family abroad.</p><p>As cases multiply, the World Health Organization (WHO) appeals for help to conduct emergency immunization campaigns, but stocks of vaccines are low and few members of staff have direct experience of polio outbreaks. Soon there are tens of thousands of cases: millions more people around the world who haven’t had the vaccine are at risk.</p><p>This is just one of many possible scenarios that could follow polio eradication. Although the world has not yet eliminated poliovirus, many observers think it could be gone within three years. The polio-eradication campaign has increased its intensity and funding in the past year in the hope of finally meeting a deadline that’s been postponed many times since efforts were launched in 1988.</p><p>The front lines are Afghanistan and Pakistan, where pockets of wild polio <a href="https://www.nature.com/articles/d41586-023-02577-7" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02577-7" data-track-category="body text link">persist but are shrinking</a> (see ‘Wild polio tamed’), and a swathe of Africa, where a polio vaccine that includes <a href="https://www.nature.com/articles/d41586-020-02501-3" data-track="click" data-label="https://www.nature.com/articles/d41586-020-02501-3" data-track-category="body text link">live virus has itself seeded outbreaks</a>. There are signs that health campaigns are now bringing these vaccine-derived episodes under control.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26316400.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26316400.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="WILD POLIO TAMED. Graphic shows countries affected by cases of wild poliovirus type 1 2017–2023." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26316400.png">
  <figcaption>
   <p><span>Source: Global Polio Eradication Initiative</span></p>
  </figcaption>
 </picture>
</figure><p>The final steps towards eradication are formidable, and it’s not clear when — or whether — nations will reach this goal. Nonetheless, with the demise of the virus in sight, health authorities are planning what happens next.</p><p>That’s because eradication is not extinction. Polio could lurk in testing labs and manufacturing facilities — from which it has leaked in the past — and even in some people. Mistakes years after eradication could let polio into an unprotected population where it could “wreak havoc”, says virologist Konstantin Chumakov, former associate director of vaccine research at the FDA Office of Vaccines Research and Review in Silver Spring, Maryland.</p><p>The end of polio is only the beginning of another effort: developing the resilience to keep it away, says Liam Donaldson, a public-health specialist at the London School of Hygiene &amp; Tropical Medicine, UK, and the lead author of a series of independent reports on the campaign’s progress (see go.nature.com/49hho4a). “People have signed up to polio eradication, but they’ve not signed up to the longer journey.”</p><h2><b>Stamping it out</b></h2><p>Only one human disease has so far been declared eradicated: smallpox, in 1980. Polio has been more complex, says David Heymann, who heads the WHO’s Containment Advisory Group. That’s because of a key difference: every smallpox infection produces symptoms, but polio can silently infect up to 1,000 people before causing a case of paralysis. The other snag is that polio can be caused not only by the wild virus, but also, in very rare cases, by the vaccines deployed to prevent it. Eradication means getting rid of both forms for good.</p><p>The main tool is vaccination. Industrialized, polio-free countries use an inactivated poliovirus vaccine (IPV), which doesn’t prevent the virus infecting the body and being shed in stools, but does protect against paralysis. Provided that immunization levels with IPV remain high and sanitation is good, a rogue poliovirus will probably peter out, according to Concepcion Estivariz, a polio researcher at the Centers for Disease Control and Prevention (CDC) in Atlanta, Georgia.</p><p>But because the inactivated vaccine can’t block transmission, children in at-risk countries still receive another type: an oral poliovirus vaccine (OPV) that contains an attenuated form of the live virus, and can stop polio’s spread — which is crucial for eradication. It’s also cheaper and easier to deliver than IPV, which is administered by injection. The oral campaign has been hugely successful. Since 1988, the Global Polio Eradication Initiative (GPEI) estimates it has prevented 20 million cases of polio paralysis.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311758.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311758.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="An assistant chemist wearing protective gear working in the National Polio and Measles laboratory, Dhaka, Bangladesh." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311758.jpg">
  <figcaption>
   <p><span>A chemist processes samples at the National Polio and Measles Laboratory in Bangladesh.</span><span>Credit: G.M.B. Akash/Panos</span></p>
  </figcaption>
 </picture>
</figure><p>But OPV has some important downsides. There is a low risk that the vaccine itself can cause paralysis. And, on rare occasions, the weakened virus used in the vaccine can mutate sufficiently to regain virulence. This can lead to outbreaks of cases known as vaccine-derived polio among people who have not been vaccinated fully or at all. “If we continue OPV,” says Estivariz, “we never stop the circle.” Most countries are now using IPV in their routine immunization programmes alongside OPV, and the WHO recommends that IPV administration should continue for a decade after disease transmission has been stopped, to protect against any accidental releases or hidden pockets of the virus.</p><p>Polio will be certified as eradicated when no case has been observed for three years, and when there is no sign of it in environmental surveillance data — that is, in samples of waste water. A year after that, OPV must be withdrawn to prevent vaccine-derived polio. The problem, however, is that removing it will be an extraordinarily delicate manoeuvre. Done messily, this process could trigger the return of the virus.</p><p>In 2016, for instance, the withdrawal of an OPV across 150 countries went disastrously wrong. “The results were sobering”, says Kimberly Thompson, an epidemiologist at the research non-profit organization Kid Risk, in Orlando, Florida.</p><p>There are three strains of wild polio — types 1, 2 and 3. Type 2 was declared eradicated in 2015, and type 3 followed in 2019. The oral vaccine contained attenuated versions of all three strains, but after type 2 was eradicated, the aim was to withdraw vaccines containing that strain to minimize the risk of seeding vaccine-derived type 2 polio. So the GPEI orchestrated a two-week period in April 2016 in which all three-strain oral vaccines were switched for versions containing just types 1 and 3.</p><p>Swiftly, however, cases of vaccine-derived type 2 polio began to build — in two countries in 2016, spreading to 24 countries by 2020, with countries in Africa worst affected. A case popped up in the United States in 2022, and the United Kingdom found the virus in wastewater samples. The cumulative number of paralysis cases so far is just over 3,200; the yearly total peaked at more than 1,000 in 2020 and now seems to be declining, with 238 recorded so far this year (see ‘Rare and receding: vaccine-derived polio’). African countries are still running multiple emergency campaigns delivering oral type 2 vaccines to stamp these outbreaks out.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26316422.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26316422.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="RARE AND RECEDING: VACCINE-DERIVED POLIO. Graphic shows countries with outbreaks of vaccine-derived polio." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26316422.png">
  <figcaption>
   <p><span>Source: Global Polio Eradication Initiative</span></p>
  </figcaption>
 </picture>
</figure><p>Why the rebound? First, populations in the regions affected weren’t sufficiently vaccinated beforehand with IPV, which would have protected them until any outbreaks could be controlled. This was partly owing to a gap in vaccine supply, says Ondrej Mach, who co-chairs a new GPEI group that will oversee future withdrawals of the oral vaccine.</p><p>What’s more, says Mach, just before the switch, vaccine-derived type 2 polio was detected in Nigeria. Transmission was probably already under way in Nigeria and other countries, adds Mach, and the emergency type 2 vaccine seeded further outbreaks.</p><p>Since 2021, however, this seeding has become much less likely: vaccination campaigns are controlling the outbreaks using a <a href="https://www.nature.com/articles/d41586-020-03045-2" data-track="click" data-label="https://www.nature.com/articles/d41586-020-03045-2" data-track-category="body text link">genetically engineered oral vaccine</a>, which has an even lower chance of becoming virulent than the OPVs used previously.</p><p>What risks does the post-polio world face if full oral withdrawal goes wrong? An analysis by Kid Risk and the CDC gave one answer (D. A. Kalkowska <i>et al. Risk Anal. </i>https://doi.org/k428; 2023). Their model considers what might happen if all OPV use stopped in 2027 but vaccine-derived polio was not completely eliminated beforehand and outbreak responses were weak. In one scenario, the model predicts that there could be as many as 40,000 cases of paralysis caused by vaccine-derived polio 8 years after OPV administration is discontinued. To avoid this, the authors suggest that population immunity in areas with polio cases today needs to be very high — about 90% — just before withdrawal. Thompson says that most countries have achieved this in the past, at least for short periods of time.</p><h2><b>Keeping a lookout</b></h2><p>Even after OPVs are successfully withdrawn, therefore, countries can’t let their guard down. They must put in place surveillance “to detect any poliovirus, no matter where in the world it appears and however fleetingly”, says a report by the Transition Independent Monitoring Board, an independent group of scientists that reports periodically on the polio endgame and is chaired by Donaldson.</p><p>Polio surveillance takes two main forms: searching for cases of paralysis that might be caused by polio; and monitoring waste water for any virus shed by carriers.</p><p>Both will be crucial for years, as an example from Malawi shows. The country had been free from wild polio for three decades when, in 2021, a stool sample from a three-year-old with paralysis arrived at the national laboratory to be sent abroad for testing. The sample sat for two months before it was shipped with others, says Jamal Ahmed, who coordinates polio eradication for the WHO in its African region, which comprises 47 countries. The result came back a month later: it was wild polio type 1, not seen in the continent since 2016.</p><p>Sequencing traced its origin to Pakistan, but also revealed that the virus had been circulating for two years undetected — possibly in Malawi, and possibly elsewhere. Because Malawi had no wastewater surveillance at the time, it was impossible to know.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311756.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311756.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="A health worker administers polio vaccine drops to a child during a vaccination campaign in Karachi, Pakistan, on November 28, 2022." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26311756.jpg">
  <figcaption>
   <p><span>A health worker gives an oral polio vaccine to a child in Karachi, Pakistan, in 2022.</span><span>Credit: Asif Hassan/AFP via Getty</span></p>
  </figcaption>
 </picture>
</figure><p>Within 30 days of receiving the result, emergency immunizations began. Six campaign rounds later, says Ahmed, Malawi has seen no more cases of wild polio. And, with the WHO’s help, the country swiftly installed environmental surveillance sites.</p><p>The episode also showed that the emergency vaccination programme wasn’t up to the job, says Jay Wenger, who leads the polio programme at the Bill &amp; Melinda Gates Foundation in Seattle, Washington. “We had to rebuild the polio infrastructure we had before” to get rid of the virus, he says.</p><p>Global wastewater surveillance has become a bigger priority since the COVID-19 pandemic, says Donaldson, because politicians are paying more attention to trends in disease. Ahmed says that 41 of the 47 member states of WHO Africa now have environmental polio surveillance, and that the rest will soon catch up.</p><p>Innovations are helping to speed up a process in which timeliness is crucial. One breakthrough is direct detection, a method that leapfrogs several of the conventional stages of the testing process; for example, by extracting RNA directly from samples without the need to culture them.</p><h2><b>The threat of escape</b></h2><p>No matter how successful the eradication effort is, the virus will remain in research institutes and vaccine-manufacturing facilities — and in an unknown number of routine diagnostic labs.</p><p>Escapes happen. Last year, a lab worker at a manufacturing facility in Utrecht, the Netherlands, picked up type 3 virus at the facility, and this was then detected in wastewater surveillance outside the plant. No cases of paralysis resulted. Vaccine manufacturing is “a huge containment nightmare”, says Mach.</p><p>The WHO has a plan for poliovirus containment that urges nations to minimize the number of facilities retaining poliovirus materials and to destroy any unnecessary stocks. At the moment, the WHO knows of 74 facilities that hold polio, in 22 countries.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02577-7" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_26327504.png"><p>Can the world really stop wild polio by the end of 2023?</p></a>
 </article><p>The first step was for each country to set up a national authority for containment by 2018, to ensure that facilities comply with biosafety requirements. China and Romania have not yet done this, and other countries have missed subsequent deadlines.</p><p>Even for compliant facilities, forgotten samples remain a threat, says Andy Macadam at the National Institute for Biological Standards and Control in Potters Bar, UK. “All you have to do is mislabel the tube.” And polio might lurk in some facilities that are not even subject to the containment plan, says Heymann. This could include frozen stool samples taken for other reasons at a time when polio was circulating.</p><p>Since 2000, there have been 21 reported incidents of poliovirus release from laboratories and vaccine-production facilities in 8 countries, with 16 cases of polio as a result, according to Derek Ehrhardt, who heads the WHO’s poliovirus containment unit. Most cases have been in vaccine-manufacturing facilities, but five of them were in research labs in which workers discovered that vials containing poliovirus were mislabelled (none of those cross-contamination incidents led to paralysis). The solution, says Heymann, is better biosecurity in all labs.</p><p>To reduce the need for live virus, scientists are developing ways to produce the inactivated vaccine without it — for example, by using a non-infectious, genetically engineered starting material, or by designing vaccines from virus-like particles or messenger RNA.</p><h2><b>A surprising source</b></h2><p>There is yet another source of poliovirus, unforeseen 35 years ago when eradication efforts began.</p><p>In most people who receive the oral vaccine, the immune system generates antibodies that protect them against the virus. But in a small number of people born with particular immune deficiency disorders, the immune system allows the attenuated virus from the vaccine to live on, evolving as time goes by and emerging in their stools. No drugs have been proved to cure an ongoing polio infection.</p><p>Only some of the several hundred types of immunodeficiency lead to chronic retention of poliovirus. No one knows how many people are affected, and no such shedding is known to have triggered a polio outbreak, although it might have contributed to one in the Philippines in 2019–21.</p><p>But, says Mach, even one person retaining and shedding poliovirus is incompatible with eradication. “We have to do something.” An international — if patchy — search for people with these immune disorders who have chronic polio has produced a register of 200 individuals.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-020-03045-2" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_23349444.jpg"><p>New polio vaccine poised to get emergency WHO approval</p></a>
 </article><p>One person with the condition lives in the United Kingdom and was vaccinated with OPV as a child. For more than 20 years, he asymptomatically carried — and shed — the attenuated virus, which evolved to its disease-causing form. His gut was “essentially a culture vessel”, says David Boyle at PATH, a non-profit medical-research organization based in Seattle, Washington.</p><p>That’s why scientists were surprised to learn that the person’s infection had gone.</p><p>It disappeared after he received the antiviral drug remdesivir for severe COVID-19 in August 2021. This could be coincidence, says Macadam, but it bolsters the case that antivirals could be used to treat polio infection (two such drugs are being explored as polio treatments). Monoclonal antibodies are also under development.</p><h2><b>Complacency and responsibility</b></h2><p>Keeping vaccination rates high for at least a decade after eradication will be the best protection — but there are fears that commitment to IPVs might wane once eradication has been declared. Routine immunization campaigns struggle to reach every child, especially during conflict, disasters or pandemics. COVID-19 drove the number of unvaccinated or undervaccinated children up to 23 million in 2020.</p><p>Added to this is the growing problem in some regions of vaccine scepticism and complacency, which grew worse because of activism against COVID-19 vaccines, says Peter Hotez, a vaccine specialist and public advocate at Baylor College of Medicine in Houston, Texas.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-022-02233-6" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03602-5/d41586-023-03602-5_25438368.jpg"><p>Spate of polio outbreaks worldwide puts scientists on alert</p></a>
 </article><p>With so much to be done to maintain a polio-free world, Donaldson is asking who will be accountable once the GPEI disbands a year after eradication, handing its responsibilities to WHO departments, partners and national health programmes.</p><p>A transition has already begun in some countries, but many have struggled to find their own funding amid changing government priorities. Slackening efforts now could bring bigger problems in the future, says Aidan O’Leary, who directs polio eradication at the WHO. “If we collectively take our eye off the ball and don’t build the resilience of health systems going forward, then we face further problems down the line.”</p><p>But done well, says O’Leary, the post-polio world could bring wider health benefits for everyone: better surveillance and immunization measures, and more joined-up health services. “The last mile of the polio eradication programme”, he says, “is the first mile for global public-health security.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify will end service in Uruguay due to bill requiring fair pay for artists (175 pts)]]></title>
            <link>https://mixmag.net/read/spotify-end-service-uruguay-copyright-law-change-artists-fair-pay-amendment-news</link>
            <guid>38392146</guid>
            <pubDate>Thu, 23 Nov 2023 12:41:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mixmag.net/read/spotify-end-service-uruguay-copyright-law-change-artists-fair-pay-amendment-news">https://mixmag.net/read/spotify-end-service-uruguay-copyright-law-change-artists-fair-pay-amendment-news</a>, See on <a href="https://news.ycombinator.com/item?id=38392146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p><a href="https://mixmag.net/read/us-congress-spotify-controversial-discovery-mode-news">Spotify</a> has confirmed that it will end its service in Uruguay, after the country's Parliament approved an amendment to its copyright law that would require "equitable remuneration" for artists.</p><p>A spokesperson <a href="https://www.musicbusinessworldwide.com/spotify-to-phase-out-its-service-in-uruguay-from-january-1-2024-over-music-copyright-law-changes/" target="_blank">confirmed yesterday</a> (Monday 20) that Spotify will begin to "phase out" its service in the country from January 1, 2024 — will all operations ceasing by February.</p><p>The bill, which is titled "Rendición de Cuentas," was first introduced by Uruguayan Society of Performers (SUDEI) earlier this year, proposing to amend Articles 284 &amp; 285 of Uruguays copyright law.</p><p>The modification, which was approved by the Uruguayan Parliament last month, is set to introduce a requirement for "fair and equitable remuneration" for artists in regards to their recorded material. </p><p><strong>Read this next: </strong><a href="https://mixmag.net/read/spotify-reportedly-will-start-paying-less-royalties-to-less-popular-artists-news"><strong>Spotify will reportedly start paying less royalties to less popular artists</strong></a></p><p>The bill also introduces a requirement for "social networks and the Internet" to be treated as "formats for which, if a song is reproduced, the performer is entitled to financial remuneration."</p><p>The streaming giant <a href="https://www.musicbusinessworldwide.com/spotify-threatens-uruguay-exit-amid-proposed-changes-to-music-copyright-laws/" target="_blank">had first threatened to end its service</a> when the bill, titled "Rendición de Cuentas," was first tabled in July — claiming that the proposed changes "lack clarity" and “an additional mandatory payment for music services”.</p><p><a href="https://www.elpais.com.uy/informacion/politica/spotify-alerta-con-dejar-el-pais-si-no-se-corrigen-dos-articulos-de-la-rendicion-que-hacen-inviable-su-negocio" target="_blank">In a letter</a> sent to Uruguay's Minister of Education Pablo Da Silveira, a spokesperson for Spotify said: "If the proposed reform became law in its current form, Spotify's business in Uruguay could become unfeasible, to the detriment of Uruguayan music and its fans," claiming that the amendment would force it to "pay twice" the amount of royalties. </p><p><a href="https://www.musicbusinessworldwide.com/spotify-to-phase-out-its-service-in-uruguay-from-january-1-2024-over-music-copyright-law-changes/" target="_blank">In its statement confirming the end to its services</a> in Uruguay yesterday, Spotify said: “Without clarity on the changes to music copyright laws included in the 2023 Rendición de Cuentas law – confirming that any additional costs are the responsibility of rights holders – Spotify will unfortunately begin to phase out its service in Uruguay effective January 1, 2024, and fully cease service by February." </p><p><strong>Read this next: </strong><a href="https://mixmag.net/read/uk-watchdog-streaming-study-spotify-major-labels-news"><strong>UK watchdog launches study into streaming services with “excessive power”</strong></a></p><p>“Spotify already pays nearly 70% of every dollar it generates from music to the record labels and publishers that own the rights for music, and represent and pay artists and songwriters," it continues.<br></p><p>“Any additional payments would make our business untenable. We are proud to be their largest revenue driver, having contributed more than $40B to date. And because of streaming, the music industry in Uruguay has grown 20% in 2022 alone." </p><p>Speaking to El Observador last month, SUDEI spokesperson Gabriela Pintos insisted that the organisation "was not against platforms" but instead wants royalties "to be distributed fairly."</p><p>Pintos expanded that other countries have made moves to ensure "digital reproduction" of music, and that "the legislation is not a demand for an increased contribution from streaming services" but instead "legislation that would ensure artists can negotiate a percentage that corresponds to us."</p><p><em>Megan Townsend is Mixmag's Deputy Editor, follow her on </em><a href="https://twitter.com/mmtowns" target="_blank"><em>Twitter</em></a></p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I discovered caching CDNs were throttling my everyday browsing (192 pts)]]></title>
            <link>https://blog.abctaylor.com/how-i-discovered-caching-cdns-were-throttling-my-everyday-browsing/</link>
            <guid>38391934</guid>
            <pubDate>Thu, 23 Nov 2023 12:15:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.abctaylor.com/how-i-discovered-caching-cdns-were-throttling-my-everyday-browsing/">https://blog.abctaylor.com/how-i-discovered-caching-cdns-were-throttling-my-everyday-browsing/</a>, See on <a href="https://news.ycombinator.com/item?id=38391934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div><h2>How I discovered caching CDNs were throttling my everyday browsing</h2>







</div>



<div><figure><img width="2560" height="1920" src="https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-scaled.jpg" alt="A Cisco ISR 1117-4P router and a Nexus 3K switch, with a patch panel and a Catalyst 3750 switch with lots of wires plugged into it" decoding="async" fetchpriority="high" srcset="https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-scaled.jpg 2560w, https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-300x225.jpg 300w, https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-1024x768.jpg 1024w, https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-768x576.jpg 768w, https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-1536x1152.jpg 1536w, https://blog.abctaylor.com/wp-content/uploads/2023/11/rack-2048x1536.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"></figure></div>
</div><div>
<p><strong>Sorry if this was slow to load before.</strong><br>It’s self hosted in my flat with a VDSL connection not designed for heavy traffic. I’ve swallowed my pride and ironically put this blog on a CDN.</p>



<h2>My ISP has never been amazing…</h2>



<p>Well, most aren’t. Browsing the Internet was getting worse and worse, but too unpredictable to see a clear pattern. Speed tests were fine, many websites loaded perfectly, but enough didn’t work, so it was worth investigating. Apple TV+ would crap out, but only if casting via AirPlay. BBC News wouldn’t load at all, but iPlayer would slowly.</p>



<h2>The network</h2>



<p>I have a VDSL2 line, Ubiquiti Wi-Fi and standard Catalyst switches. Nothing too weird.  I pay for a /29 block, so I have multiple usable IP addresses. Yes I host my own mail, and yes, I do DKIM, DMARC and SPF, and MXToolbox shows I’m not on any blocklists.</p>



<h2>The symptoms</h2>



<figure><table><thead><tr><th><mark>Working</mark></th><th><mark>Not working</mark></th></tr></thead><tbody><tr><td>most websites load fine<br>(amazon.co.uk, halifax.co.uk)</td><td>but many not at all<br>(bbc.co.uk, farnell.com)</td></tr><tr><td>800Mbps iperf across the LAN</td><td></td></tr><tr><td>Stable 39 Mbps down / 7 Mbps up</td><td></td></tr><tr><td>Stable 6ms ping to 1.1.1.1</td><td></td></tr><tr><td>PPP is stable and not dropping</td><td></td></tr><tr><td>AirPlay to LG TV works (via a Unifi AP)</td><td>but crashes once per show</td></tr><tr><td>AirPlay to LG TV works (TV wired in)</td><td>still crashes</td></tr><tr><td>Spotify can stream to a Bose Soundbar</td><td>but changing song takes 30sec+</td></tr><tr><td>DNS is fine</td><td></td></tr><tr><td></td><td>iOS app downloads take 3min to start</td></tr><tr><td>Swapping Cisco VDSL2 router for the ISP’s router makes some sites now work</td><td>but not all sites</td></tr></tbody></table></figure>



<h2>The cause</h2>



<p>The freebie ISP router has IPv6 enabled by default, so would speak to the CDNs from the clean v6 range. <strong>When using my equipment without IPv6 configured, I can only speak on the IPv4 range</strong> that’s “shadow banned”.</p>



<h2>Proving my theory</h2>



<h3>Step 1: VPN egress traversing bad ISP’s network</h3>



<p>I set up a WireGuard tunnel to another site I have in the Isle of Man, supplied by another ISP. I forwarded all traffic from my workstation via this tunnel:</p>



<figure><img decoding="async" width="1024" height="219" src="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-12-1024x219.png" alt="" srcset="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-12-1024x219.png 1024w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-12-300x64.png 300w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-12-768x164.png 768w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-12-1536x328.png 1536w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-12.png 1735w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I now pop out in the Isle of Man via ASN 42455’s network (www.infobyip.com to test):</p>



<figure><img decoding="async" width="1024" height="259" src="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-11-e1700657251771-1024x259.png" alt="" srcset="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-11-e1700657251771-1024x259.png 1024w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-11-e1700657251771-300x76.png 300w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-11-e1700657251771-768x195.png 768w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-11-e1700657251771.png 1216w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>and can surf and stream as normal:</p>



<figure><img decoding="async" loading="lazy" width="1024" height="451" src="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-22-1024x451.png" alt="" srcset="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-22-1024x451.png 1024w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-22-300x132.png 300w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-22-768x339.png 768w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-22.png 1216w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>Step 2: Wireshark deep-dive</h3>



<p>I took two captures of my workstation visiting bbc.co.uk in Chrome. The first without the WireGuard tunnel on, and the second with it on. Let’s look at <code>tcp</code> traffic:</p>



<p><strong>Without WireGuard:</strong></p>



<figure><img decoding="async" loading="lazy" width="888" height="551" src="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-19.png" alt="" srcset="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-19.png 888w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-19-300x186.png 300w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-19-768x477.png 768w" sizes="(max-width: 888px) 100vw, 888px"><figcaption>No meaningful TCP traffic makes it out. A lot of retransmissions and duplicate ACKs are happening</figcaption></figure>



<p><strong>With WireGuard:</strong></p>



<figure><img decoding="async" loading="lazy" width="888" height="520" src="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-20.png" alt="" srcset="https://blog.abctaylor.com/wp-content/uploads/2023/11/image-20.png 888w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-20-300x176.png 300w, https://blog.abctaylor.com/wp-content/uploads/2023/11/image-20-768x450.png 768w" sizes="(max-width: 888px) 100vw, 888px"><figcaption>A nice healthy TCP session</figcaption></figure>



<p><em>(I disabled checksum verification in the screenshots above, as I’m capturing on the same machine having problems, which also has checksum offloading on the NIC.)</em></p>



<h2><em>Zen Broadband</em>, my ISP (for now)</h2>



<p>I’ll save my views on Zen for when this case is resolved. I’ve got so far through the support process I’m now dealing with their Network Ops team to investigate this. They can still redeem themselves by simply giving me a different /29 block as far away from 82.71.78.0/29 as possible 🙂</p>



<h2>Be more specific. What do you mean by “throttled”?</h2>



<p>The blocking is nondeterministic. Whilst Akamai (who offers a reputation check) returns one of my IPs as clean, websites of their customers like eBay have shown the throttling behaviour. Apple TV+ appears to be served by Akamai too (tv.apple.com), which has been the worst offender for “throttling” my streaming:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>PS</span><span> </span><span>C</span><span>:\</span><span>WINDOWS</span><span>\system32&gt; nslookup tv.apple.com</span></span>
<span><span>Server</span><span>:  dc1-lon.core.*********.net</span></span>
<span><span>Address</span><span>:  10.*.*.*</span></span>
<span></span>
<span><span>Non</span><span>-authoritative answer:</span></span>
<span><span>Name</span><span>:    e673.dsce9.akamaiedge.net</span></span>
<span><span>Addresses</span><span>:  2a02:26f0:fd00:</span><span>1088</span><span>::2a1</span></span>
<span><span>          2a02:26f0:fd00:109a::2a1</span></span>
<span><span>          2a02:26f0:fd00:</span><span>1081</span><span>::2a1</span></span>
<span><span>          2a02:26f0:fd00:</span><span>1098</span><span>::2a1</span></span>
<span><span>          2a02:26f0:fd00:</span><span>1093</span><span>::2a1</span></span>
<span><span>          </span><span>88.221</span><span>.</span><span>41.37</span></span>
<span><span>Aliases</span><span>:  tv.apple.com</span></span>
<span><span>          itunes-cdn.itunes-apple.com.akadns.net</span></span>
<span><span>          itunes.apple.com.edgekey.net</span></span></code></pre></div>



<p>It’s also available with IPv6, explaining the freebie ISP router theory.</p>



<p>Fastly doesn’t offer a rep check on their website but bbc.co.uk right now won’t load at all. Cloudflare is opaque too about disclosing what IPs they’re throttling.</p>



<h2>Why would a range get throttled or “shadow banned”?</h2>



<p>This is extremely difficult to answer and I have no good theory. The same IP range handles my email and I generally have no trouble emailing major providers like Gmail, Outlook, Yahoo!, and many other counterparties.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Large amounts of carbon capture as a solution is an 'illusion' (129 pts)]]></title>
            <link>https://electrek.co/2023/11/23/large-amounts-of-carbon-capture-as-a-solution-is-an-illusion-iea/</link>
            <guid>38391728</guid>
            <pubDate>Thu, 23 Nov 2023 11:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2023/11/23/large-amounts-of-carbon-capture-as-a-solution-is-an-illusion-iea/">https://electrek.co/2023/11/23/large-amounts-of-carbon-capture-as-a-solution-is-an-illusion-iea/</a>, See on <a href="https://news.ycombinator.com/item?id=38391728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://electrek.co/wp-content/uploads/sites/3/2022/07/coal-europe.jpg?quality=82&amp;strip=all&amp;w=1400" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/07/coal-europe.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/07/coal-europe.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/07/coal-europe.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/07/coal-europe.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1400" height="700" alt="fossil fuels" fetchpriority="high">
	
	</figure>

<p>The oil and gas industry is banking on carbon capture as its “fix” for climate change. The IEA’s new report dispels that idea and offers real solutions.</p>



<p>The oil and gas sector currently accounts for just 1% of clean energy investment globally. A special report from the International Energy Agency (<a href="https://www.iea.org/" target="_blank" rel="noreferrer noopener">IEA</a>) released ahead of the COP28 climate summit explores how the fossil fuel industry “can take a more responsible approach and contribute positively to the new energy economy.”</p>



<p>In other words, the fossil fuel industry needs to get on the renewables bandwagon<em>&nbsp;now</em>, and not with large-scale carbon capture. The IEA provides a roadmap in its<a href="https://www.iea.org/reports/the-oil-and-gas-industry-in-net-zero-transitions" target="_blank" rel="noreferrer noopener">&nbsp;new report</a>, “The Oil and Gas Industry in Net Zero Transitions.”</p>



<p>Global demand for both oil and gas is set to peak by 2030, <a href="https://electrek.co/2023/10/23/iea-predicts-that-global-emissions-will-peak-by-2025/">if not by 2025</a>. If governments deliver in full on their national energy and climate pledges, demand will fall 45% below today’s level by 2050. In a pathway to reaching net zero emissions by mid-century, which is necessary to keep the goal of limiting global warming to 1.5C within reach, oil and gas use will decline by more than 75% by 2050.</p>



<p>Or, to spell it out in monetary terms, the report’s analysis finds that the current valuation of private oil and gas companies could fall by 25% from $6 trillion today if all national energy and climate goals are reached, and by up to 60% if the world gets on track to limit global warming to 1.5C.</p>



<h2 id="h-the-status-quo-is-impossible">The status quo is impossible</h2>



<p>Every oil and gas company’s transition strategy can and should include a plan to reduce emissions from its own operations, asserts the report – yet companies with targets to reduce their emissions account for less than 50% of global oil and gas output.</p>



<p>The IEA also points out that carbon capture can’t be used as a linchpin by the fossil fuel industry to maintain the status quo. If oil and natural gas consumption were to evolve as projected under today’s policy settings, limiting the temperature rise to 1.5C would require an “entirely inconceivable” 32 billion tonnes of carbon captured for utilization or storage by 2050, including 23 billion tonnes via direct air capture.</p>



<p>The amount of electricity needed to power these technologies would be greater than the&nbsp;<em>entire world’s electricity demand</em>&nbsp;today.</p>



<p>IEA executive director Fatih Birol said:</p>



<blockquote>
<p>With the world suffering the impacts of a worsening climate crisis, continuing with business as usual is neither socially nor environmentally responsible.</p>



<p>The [oil and gas] industry needs to commit to genuinely helping the world meet its energy needs and climate goals – which means letting go of the illusion that implausibly large amounts of carbon capture are the solution.</p>
</blockquote>



<h2 id="h-how-to-be-part-of-the-solution">How to be part of the solution</h2>



<p>The report finds that the oil and gas sector is well placed to scale up some crucial technologies for transitions to clean energy, such as offshore wind and geothermal energy. It’s going to have to change tack in many other aspects of its business, too. It needs to increase investment in EV charging facilities – turn the gas stations into EV stations. The sector can also move further into the plastics recycling industry as global bans on plastic continue to grow.</p>



<p>Further, the <em>production, transport, and processing</em> of oil and gas results in nearly 15% of global energy-related emissions – equal to the US’s entire energy-related emissions. The fossil fuel industry’s emissions must decline by 60% by 2030 to limit global warming to 1.5C by 2050. The emissions intensity of oil and gas producers with the highest emissions is currently five to 10 times above those with the lowest, showing the vast potential for improvements. So it needs to boost efficiency and electrify its facilities across the sector. </p>



<p>Reducing emissions from methane, which accounts for half of the total emissions from oil and gas operations, would also provide a big win, as methane reduction strategies are well-known and inexpensive.</p>



<p>The oil and gas industry invested around $20 billion in clean energy in 2022, or roughly 2.5% of its total capital spending. It can and must do a lot better. To align with the Paris Agreement, the IEA says, it must put 50% of its capital expenditures towards clean energy projects by 2030, on top of the investment required to reduce emissions from its operations.</p>



<p>Not only is it imperative that the fossil fuel sector shifts gears to limit global warming – it’s also good business.</p>



<p><em>Photo: “Coal power plant” by eutrophication&amp;hypoxia is licensed under CC BY 2.0.</em></p>



<hr>



<p><em>If you live in an area that has frequent natural disaster events, and are interested in making your home more resilient to power outages, consider going solar and adding a battery storage system. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out </em><a href="https://www.energysage.com/p/electrek-rsm-ml/"><em>EnergySage</em></a><em>, a free service that makes it easy for you to go solar. They have hundreds of pre-vetted solar installers competing for your business, ensuring you get high quality solutions and save 20-30% compared to going it alone. Plus, it’s free to use and you won’t get sales calls until you select an installer and share your phone number with them. </em></p>



<p><em>Your personalized solar quotes are easy to compare online and you’ll get access to unbiased Energy Advisers to help you every step of the way. Get started </em><a href="https://www.energysage.com/p/electrek-rsm-ml/"><em>here</em></a><em>. –ad*</em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gameboy Technical Reference for Homebrew Developers (147 pts)]]></title>
            <link>https://gbdev.io/pandocs/</link>
            <guid>38391403</guid>
            <pubDate>Thu, 23 Nov 2023 10:42:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gbdev.io/pandocs/">https://gbdev.io/pandocs/</a>, See on <a href="https://news.ycombinator.com/item?id=38391403">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <!-- Track and set sidebar scroll position -->
        

        <div id="page-wrapper">

            <div class="page">
                                
                <div id="menu-bar">
                    

                    <h2>Pan Docs</h2>

                    
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        <h2 id="foreword"><a href="#foreword">Foreword</a></h2>
<p>This document, started in early 1995, is considered the single most comprehensive technical reference to Game Boy available to the public.</p>
<p>You are reading a new version of it, maintained in the Markdown format and enjoying renewed <a href="https://gbdev.io/">community</a> attention, correcting and updating it with recent findings. To learn more about the legacy and the mission of this initiative, check <a href="https://gbdev.io/pandocs/History.html">History</a>.</p>

<h2 id="contributing"><a href="#contributing">Contributing</a></h2>
<p>This project is open source, released under the <a href="https://raw.githubusercontent.com/gbdev/pandocs/master/LICENSE">CC0 license</a>. Everyone is welcome to help, provide feedback and propose additions or improvements. The git repository is hosted at <a href="https://github.com/gbdev/pandocs">github.com/gbdev/pandocs</a>, where you can learn more about how you can <a href="https://github.com/gbdev/pandocs/blob/master/CONTRIBUTING.md">contribute</a>, find detailed contribution guidelines and procedures, file Issues and send Pull Requests.</p>
<p>There is a <a href="https://gbdev.io/chat">Discord chat</a> dedicated to the gbdev community.</p>
<p>Finally, you can also contact us and send patches via email: <code>pandocs (at) gbdev.io</code>.</p>
<h2 id="using-this-document"><a href="#using-this-document">Using this document</a></h2>
<p>In the top navigation bar, you will find a series of icons.</p>
<p>By clicking on the <i></i> icon you will toggle an interactive table of contents to navigate the document. You can also use <kbd>→</kbd> and <kbd>←</kbd> keys on your keyboard to go to the following and previous page.</p>
<p>The <i></i> lets you choose among 5 different themes and color schemes to please your reading experience.</p>
<p>You can search anywhere by pressing <kbd>s</kbd> on your keyboard or clicking the <i></i> icon.</p>
<p>The <i></i> icon allows you to suggest an edit on the current page by directly opening the source file in the git repository.</p>
<p><a href="https://gbdev.io/pandocs/single.html">One-page</a> and <a href="https://gbdev.io/pandocs/print.html">printable</a> versions of this document are also available.</p>
<div><p><small>This document version was produced from git commit <a href="https://github.com/gbdev/pandocs/tree/8eb65d560bb6727d25aa0afc2ea8d1e70431a856"><code>8eb65d5</code></a> (2023-10-27 11:22:19 +0200). </small></p></div>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next" href="https://gbdev.io/pandocs/Authors.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">

                    <a rel="next" href="https://gbdev.io/pandocs/Authors.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div>




        


        
        
        

        
        
        

        <!-- Custom JS scripts -->


    </div>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Luiz André Barroso has died (234 pts)]]></title>
            <link>https://spectrum.ieee.org/in-memoriam-nov-2023</link>
            <guid>38391138</guid>
            <pubDate>Thu, 23 Nov 2023 09:53:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/in-memoriam-nov-2023">https://spectrum.ieee.org/in-memoriam-nov-2023</a>, See on <a href="https://news.ycombinator.com/item?id=38391138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Pioneer of Google’s Data Centers Dies at 58" data-elid="2666322744" data-post-url="https://spectrum.ieee.org/in-memoriam-nov-2023" data-authors="Amanda Davis" data-page-title="Pioneer of Google’s Data Centers Dies at 58 - IEEE Spectrum"><p><strong>Luiz André Barroso</strong></p><p>Data center pioneer</p><p>Senior member, 59; died 16 September</p><p>An engineer at <a href="https://about.google/" rel="noopener noreferrer" target="_blank">Google</a> for more than 20 years, Barroso is credited with designing the company’s warehouse-size data centers. They house hundreds of thousands of computer servers and disk drives and have brought cloud computing, more powerful search engines, and faster Internet service. He died unexpectedly of natural causes. </p><p>Barroso was born in Brazil and earned bachelor’s and master’s degrees in 1989 in electrical engineering from <a href="http://www.puc-rio.br/english/" rel="noopener noreferrer" target="_blank">Pontifical Catholic University of Rio de Janeiro</a>. He then moved to Los Angeles, where he earned a Ph.D. in computer engineering in 1996 from the <a href="https://www.usc.edu/" rel="noopener noreferrer" target="_blank">University of Southern California</a>.</p><p>In 1995 he joined the <a href="https://en.wikipedia.org/wiki/Digital_Equipment_Corporation" rel="noopener noreferrer" target="_blank">Digital Equipment Corp.</a>&nbsp;<a href="https://www.computerhistory.org/collections/catalog/102750386" rel="noopener noreferrer" target="_blank">Western Research Laboratory</a>, in Palo Alto, Calif., as a researcher specializing in microprocessor design. While there, he investigated how to build hardware to run more modern business applications and Web services. Three years later, the company was acquired by <a href="https://www.compaq.com/" rel="noopener noreferrer" target="_blank">Compaq</a> and his project was terminated.</p><p>He left Compaq in 2001 to join <a href="https://www.google.com/" rel="noopener noreferrer" target="_blank">Google</a> in Mountain View, Calif., as a software engineer.</p><p>The company housed its servers at leased space in third-party data centers, which were basically cages in which a few racks of computing equipment were placed. As Google’s business expanded, its need for infrastructure increased. In 2004 Barroso was tasked with investigating ways to build more efficient data centers.</p><p>He devised a way to use low-cost components and energy-saving techniques to distribute Google’s programs across thousands of servers, instead of the traditional method of relying on a few powerful, expensive machines.</p><p>The company’s first data center designed by Barroso opened in 2006 in The Dalles, Ore. It implemented fault-tolerance software and hardware infrastructure to make the servers less prone to disruption. <a href="https://spectrum.ieee.org/tag/google">Google</a> now has 35 data centers in 10 countries, all drawing from Barroso’s groundbreaking techniques.</p><p>In 2009 Barroso co-authored <a href="https://www.amazon.com/Datacenter-Computer-Introduction-Warehouse-Scale-Architecture/dp/159829556X" rel="noopener noreferrer" target="_blank"><em>The Data Center as a Computer: An Introduction to the Design of Warehouse-Scale Machines</em></a>, a seminal textbook.</p><p>He also led the team that designed Google’s AI chips, known as tensor processing units or TPUs, which accelerated machine-learning workloads. He helped integrate augmented reality and machine learning into Google Maps.</p><p>At the time of his death, Barroso was a Google Fellow, the company’s highest rank for technical staff.</p><p>He also was an executive sponsor of the company’s Hispanic and Latinx employee group and oversaw a program that awarded fellowships to doctoral students in Latin America.</p><p>For his contributions to computing architecture, he received the 2020 <a href="https://awards.acm.org/award_winners/barroso_UJ31885" rel="noopener noreferrer" target="_blank">Eckert-Mauchly Award</a>, an honor given jointly by IEEE and the <a href="https://www.acm.org/" rel="noopener noreferrer" target="_blank">Association for Computer Machinery</a>.</p><p>He was a Fellow of the ACM and the <a href="https://www.aaas.org/" rel="noopener noreferrer" target="_blank">American Association for the Advancement of Science</a>.</p><p>He served on the board of <a href="https://www.rainforesttrust.org/" rel="noopener noreferrer" target="_blank">Rainforest Trust</a>, a nonprofit dedicated to protecting tropical lands and conserving threatened wildlife. Just weeks before he died, Barroso organized and led a weeklong trip to Brazil’s <a href="https://en.wikipedia.org/wiki/Pantanal" rel="noopener noreferrer" target="_blank">Pantanal</a> wetlands.</p><p>Read <a href="https://spectrum.ieee.org/the-visionary-designer-behind-googles-warehousescale-data-centers" target="_self"><em>The Institute’s</em> 2020 profile</a> of him to learn more about his career journey.</p><p><strong>Calyampudi Radhakrishna Rao</strong></p><p>Former director of the Indian Statistical Institute </p><p>Honorary member, 102; died 23 August</p><p>Rao was onetime director of the <a href="https://www.isical.ac.in/" rel="noopener noreferrer" target="_blank">Indian Statistical Institute</a>, in Kolkata. The pioneering mathematician and statistician spent more than four decades at the organization, where he discovered two seminal estimators: the <a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound" rel="noopener noreferrer" target="_blank">Cramér–Rao bound</a> and the <a href="https://en.wikipedia.org/wiki/Rao%E2%80%93Blackwell_theorem" rel="noopener noreferrer" target="_blank">Rao–Blackwell theorem</a>. The two estimators—rules for calculating an estimate of a given quantity based on observed data—provided the basis for much of modern statistics.</p><p>For his discoveries, Rao received the 2023 <a href="https://statprize.org/" rel="noopener noreferrer" target="_blank">International Prize in Statistics</a>. The award is presented every two years to an individual or team for “major achievements using statistics to advance science, technology, and human welfare.” </p><p>Rao began his career in 1943 as a technical apprentice at the Indian Statistical Institute. He was promoted the following year to superintending statistician. Two years later, he published a paper in the <a href="https://www.calmathsociety.co.in/cmsPublications.html" rel="noopener noreferrer" target="_blank"><em>Bulletin of the Calcutta Mathematical Society</em></a>, demonstrating two fundamental statistical concepts still heavily used in the field today. The Cramér-Rao bound helps statisticians determine the quality of any estimation method. The Rao-Blackwell theorem provides a means for optimizing estimates. </p><p>Rao’s work formed the basis of information geometry, an interdisciplinary field that applies the techniques of differential geometry to study probability theory and statistics.</p><p>Rao was a professor at the ISI’s research and training school before being promoted to director in 1964—a position he held for 12 years.</p><p>He moved to the United States in the 1980s to join the <a href="https://www.pitt.edu/" rel="noopener noreferrer" target="_blank">University of Pittsburgh</a> as a professor of mathematics and statistics. He left Pittsburgh eight years later to teach at <a href="https://www.psu.edu/" rel="noopener noreferrer" target="_blank">Pennsylvania State University</a> in State College, where in 2001 he became director of its multivariate analysis center. Multivariate statistics are data analysis procedures that simultaneously consider more than two variables.</p><p>After nine years at Penn State he moved to New York, where he was a research professor at the <a href="https://www.buffalo.edu/" rel="noopener noreferrer" target="_blank">University of Buffalo</a> until shortly before he died.</p><p>Rao authored more than 14 books and 400 journal articles during his career. He received several awards for his lifetime contributions, including 38 honorary doctoral degrees from universities in 19 countries.</p><p>In 2010 he was honored with the <a href="https://en.wikipedia.org/wiki/India_Science_Award" rel="noopener noreferrer" target="_blank">India Science Award</a>, the highest honor given by the government of India in the scientific sector. He received the 2002 U.S. <a href="https://new.nsf.gov/od/honorary-awards/national-medal-of-science" rel="noopener noreferrer" target="_blank">National Medal of Science</a>, the country’s highest award for lifetime achievement in scientific research.</p><p>He was nominated in 2013 for a <a href="https://www.nobelprize.org/prizes/lists/all-nobel-peace-prizes/" rel="noopener noreferrer" target="_blank">Nobel Peace Prize</a> for his contributions to the <a href="https://link.springer.com/referencework/10.1007/978-3-642-04898-2" rel="noopener noreferrer" target="_blank">International Encyclopedia of Statistical Science</a>. Last year he was named an <a href="https://corporate-awards.ieee.org/award/ieee-honorary-membership/" rel="noopener noreferrer" target="_blank">honorary member</a> of IEEE. </p><p>Rao received a master’s degree in mathematics in 1940 from <a href="https://www.andhrauniversity.edu.in/" rel="noopener noreferrer" target="_blank">Andhra University</a>, in Visakhapatnam. Three years later he earned a master’s degree in statistics from the <a href="https://www.caluniv.ac.in/" rel="noopener noreferrer" target="_blank">University of Calcutta</a>. He went on to receive a Ph.D. in statistics from <a href="https://www.kings.cam.ac.uk/" rel="noopener noreferrer" target="_blank">King’s College Cambridge</a> in 1945 and a doctor of science degree from the <a href="https://www.cam.ac.uk/" rel="noopener noreferrer" target="_blank">University of Cambridge</a> in 1965.</p><p><strong>Herbert William Zwack</strong></p><p>Former U.S. Naval Research Laboratory associate superintendent </p><p>Life member, 88; died 14 March</p><p>Zwack led electronic warfare research programs at the U.S. <a href="https://www.nrl.navy.mil/" rel="noopener noreferrer" target="_blank">Naval Research Laboratory</a>, in Washington, D.C., where he worked for more than two decades. </p><p>After receiving a bachelor’s degree in electrical engineering in 1955 from the Polytechnic Institute of Brooklyn (now the <a href="https://engineering.nyu.edu/" rel="noopener noreferrer" target="_blank">New York University Tandon School of Engineering</a>), in New York City, he joined <a href="https://en.wikipedia.org/wiki/Hazeltine_Corporation" rel="noopener noreferrer" target="_blank">Hazeltine</a> (now <a href="https://www.baesystems.com/en/home" rel="noopener noreferrer" target="_blank">BAE Systems</a>). At the defense electronics company, located in Greenlawn, N.Y., he helped develop the <a href="https://www.ll.mit.edu/about/history/sage-semi-automatic-ground-environment-air-defense-system" rel="noopener noreferrer" target="_blank">Semi-Automatic Ground Environment (SAGE)</a>, the first U.S. air defense system. He also created the <a href="https://www.telinstrument.com/avionics-news/industry-articles/20-the-mark-xii-iff-system.html" rel="noopener noreferrer" target="_blank">Mark XII IFF</a>, a radar system designed to detect enemy aircraft.</p><p>In 1958 he left to join Airborne Instruments Laboratory, a defense contractor in Mineola, N.Y. At AIL, he was involved in electronic warfare systems R&amp;D. He later was promoted to head of the analysis receiver department, and he led the development of UHF and microwave intercept analysis receivers for the <a href="https://www.google.com/aclk?sa=l&amp;ai=DChcSEwjLyq6Rt8SCAxWRBucKHSQPBwgYABAAGgJwdg&amp;ase=2&amp;gclid=CjwKCAiA0syqBhBxEiwAeNx9N96_lPVOP21C5tEQt6xKbMbitUG3456vS4qENyiaMKhEAUwxWPYzbRoCfgwQAvD_BwE&amp;sig=AOD64_1sRcD-KxQ6KVkv-1RGSQdjhJC9PA&amp;q&amp;nis=4&amp;adurl&amp;ved=2ahUKEwiF-aCRt8SCAxUeMjQIHfccC3gQ0Qx6BAgKEAE" rel="noopener noreferrer" target="_blank">U.S. Army</a>.</p><p>He accepted a new position in 1970 as head of the advanced development department in the Amecom Division of <a href="https://en.wikipedia.org/wiki/Litton_Industries" rel="noopener noreferrer" target="_blank">Litton Industries</a>, a defense contractor in College Park, Md. He helped develop technology at Litton to intercept and analyze radar signals, including the AN/ALR-59 (later the <a href="https://man.fas.org/dod-101/sys/ac/equip/an-alr-73.htm" rel="noopener noreferrer" target="_blank">AN/ALR-73</a>) passive detection system for the <a href="https://www.google.com/aclk?sa=l&amp;ai=DChcSEwi40PmXt8SCAxXPDa0GHRZJA14YABAAGgJwdg&amp;ase=2&amp;gclid=CjwKCAiA0syqBhBxEiwAeNx9N27pvk_oIy1Sr5kJ4N23Pa4GwCQd6J7iyE78E5EoaaZJymUaXkn9phoCGLEQAvD_BwE&amp;sig=AOD64_2NQc8EDRVV2qUnZCB-mrPNxY4Ixg&amp;q&amp;nis=4&amp;adurl&amp;ved=2ahUKEwjy3e6Xt8SCAxXAGTQIHWGeAjIQ0Qx6BAgIEAE" rel="noopener noreferrer" target="_blank">U.S. Navy</a>&nbsp;<a href="https://www.navy.mil/Resources/Fact-Files/Display-FactFiles/Article/2382134/e-2-hawkeye-airborne-command-and-control-aircraft/" rel="noopener noreferrer" target="_blank">E-2 Hawkeye</a> aircraft.</p><p>Two years later he left to join the <a href="https://www.nrl.navy.mil/tewd/" rel="noopener noreferrer" target="_blank">Tactical Electronic Warfare Division</a> of the <a href="https://www.nrl.navy.mil/" rel="noopener noreferrer" target="_blank">Naval Research Laboratory</a>, in Washington, D.C., as head of its remote-sensor department. He was responsible for hiring new technical staff and securing research funding.</p><p>By 1974, he was promoted to head of the laboratory’s electronic warfare systems branch, leading research in areas including advanced miniature antenna and receiver programs, intelligence collection and processing systems, and high-speed signal sorting.</p><p>In 1987 he was promoted to associate superintendent of the Tactical Electronic Warfare Division, a position he held until he retired in 1995. </p><p><strong>Randall W. Pack</strong></p><p>Nuclear and computer engineer</p><p>Life member, 82; died 2 December 2022</p><p>Pack was a <a href="https://spectrum.ieee.org/tag/nuclear-power">nuclear power</a> engineer until the late 1990s, when he shifted his focus to computer engineering.</p><p>He served in the <a href="https://www.google.com/aclk?sa=l&amp;ai=DChcSEwi40PmXt8SCAxXPDa0GHRZJA14YABAAGgJwdg&amp;ase=2&amp;gclid=CjwKCAiA0syqBhBxEiwAeNx9N27pvk_oIy1Sr5kJ4N23Pa4GwCQd6J7iyE78E5EoaaZJymUaXkn9phoCGLEQAvD_BwE&amp;sig=AOD64_2NQc8EDRVV2qUnZCB-mrPNxY4Ixg&amp;q&amp;nis=4&amp;adurl&amp;ved=2ahUKEwjy3e6Xt8SCAxXAGTQIHWGeAjIQ0Qx6BAgIEAE" rel="noopener noreferrer" target="_blank">U.S. Navy</a> for eight years after receiving a bachelor’s degree in engineering in 1961 from <a href="https://www.vanderbilt.edu/" rel="noopener noreferrer" target="_blank">Vanderbilt University</a>, in Nashville. While enlisted, he studied at the U.S. <a href="https://www.navsea.navy.mil/Home/NNPTC/" rel="noopener noreferrer" target="_blank">Naval Nuclear Power Training Command</a>, in Goose Creek, S.C., and the U.S. <a href="https://www.netc.navy.mil/NSS/" rel="noopener noreferrer" target="_blank">Naval Submarine School</a>, in Pensacola, Fla. After completing his studies in 1964, he served as chief engineer on two Navy nuclear submarines including the <a href="https://www.navsource.org/archives/08/08635.htm" rel="noopener noreferrer" target="_blank">USS <em>Sam Rayburn</em></a>.</p><p>He left the Navy and earned master’s and doctoral degrees in nuclear engineering from the <a href="https://www.berkeley.edu/" rel="noopener noreferrer" target="_blank">University of California, Berkeley</a>. In 1974 he joined the <a href="https://www.epri.com/" rel="noopener noreferrer" target="_blank">Electric Power Research Institute</a>, in Palo Alto, Calif., as a technical expert in nuclear reactor design, testing, operations, maintenance, instrumentation, and safety.</p><p>In 1980 he began work as a researcher at the <a href="https://www.inpo.info/" rel="noopener noreferrer" target="_blank">Institute of Nuclear Power Operations</a>, in Atlanta. Seven years later he joined the General Physics Corp. (now <a href="https://www.gpstrategies.com/" rel="noopener noreferrer" target="_blank">GP Strategies</a>), in Columbia, Md., where he worked for 10 years.</p><p>Park decided to switch <a href="https://spectrum.ieee.org/topic/careers/">careers</a> and at night took graduate courses at <a href="https://www.jhu.edu/" rel="noopener noreferrer" target="_blank">Johns Hopkins University</a>, in Baltimore. After graduating in 1997 with a master’s degree in computer science, he left General Physics and became a computer science consultant. He retired in 2008.</p><p>From 2008 to 2022, he served as an adjunct professor at <a href="https://www.aacc.edu/" rel="noopener noreferrer" target="_blank">Anne Arundel Community College</a>, in Arnold, Md., where he taught courses for the school’s <a href="https://www.aacc.edu/programs-and-courses/personal-enrichment/personal-enrichment-for-older-adults/peer-learning-partnership/" rel="noopener noreferrer" target="_blank">Peer Learning Partnership</a>, an enrichment program for older adults.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fast Llama 2 on CPUs with Sparse Fine-Tuning and DeepSparse (200 pts)]]></title>
            <link>https://neuralmagic.com/blog/fast-llama-2-on-cpus-with-sparse-fine-tuning-and-deepsparse/</link>
            <guid>38389386</guid>
            <pubDate>Thu, 23 Nov 2023 04:44:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neuralmagic.com/blog/fast-llama-2-on-cpus-with-sparse-fine-tuning-and-deepsparse/">https://neuralmagic.com/blog/fast-llama-2-on-cpus-with-sparse-fine-tuning-and-deepsparse/</a>, See on <a href="https://news.ycombinator.com/item?id=38389386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
			<main id="main" role="main">


<div id="hero322">

		<p><img src="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-HEADER-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-1024x536.png">
		</p>

		

		
	</div>

<article>

	<div>
		
		<p> | <span><time datetime="2023-11-22T04:54:26-05:00">11/22/23</time></span></p>		
<h3>Key Takeaways</h3>



<ul>
<li>We expanded our Sparse Fine-Tuning research results to include Llama 2. The results include 60% sparsity with INT8 quantization and no drop in accuracy.</li>



<li>DeepSparse now supports accelerated inference of sparse-quantized Llama 2 models, with inference speeds 6-8x faster over the baseline at 60-80% sparsity.</li>



<li>We used some interesting algorithmic techniques in order to quantize Llama 2 weights and activations. We hardened the implementation and packaged them in SparseML for enterprise ML engineers to use.</li>
</ul>



<p>This year has been an exceptionally exciting year for open-source large language models (LLMs). Just 11 months ago proprietary models, like GPT-3, were the only reasonable choice for companies to build generative AI applications. Now, there is a thriving ecosystem of high-quality open-source models, like Meta’s Llama family. In February, Meta released the LLaMA models, proving it is possible to train a high-quality open-source LLM and share the recipe on how to do it. Later in the year, Meta released Llama 2, an improved version trained on twice as much data and licensed for commercial use, which made Llama 2 the top choice for enterprises building GenAI applications.</p>



<p>Neural Magic’s mission is to enable enterprises to deploy deep learning models, like Llama 2, performantly on standard CPU infrastructure. In our recent research paper collaboration with the Institute of Science and Technology Austria (ISTA), “<a href="https://arxiv.org/abs/2310.06927" title="">Sparse Fine-Tuning for Inference Acceleration of Large Language Models</a>,” we showed that combining pruning and quantization with Neural Magic's <a href="https://github.com/neuralmagic/deepsparse" title="">DeepSparse</a>, a sparsity-aware inference runtime, can accelerate LLM inference on CPUs with no drop in accuracy. This <a href="https://neuralmagic.com/blog/sparse-finetuning-for-accelerating-large-language-models-with-deepsparse/" title="">blog</a> summarizes detailed insights on the sparse fine-tuning approach, which focuses on MosaicML’s MPT architecture.</p>



<p>Today, we are excited to announce that we now support Llama 2 in DeepSparse and have extended our Sparse Fine-Tuning research to <a href="https://sparsezoo.neuralmagic.com/?architectures=llama2&amp;datasets=gsm8k&amp;subArchitectures=7b&amp;task=text_generation&amp;ungrouped=true&amp;sort=Latency%3Aasc" title="">Llama 2 7B</a>. Yet again, we are able to demonstrate the applicability of our software-acceleration approach to leading model architectures.</p>


<div>
<figure><img decoding="async" fetchpriority="high" width="1024" height="659" src="https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-1024x659.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-1024x659.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-300x193.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-768x495.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-1536x989.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-2048x1319.png 2048w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Acceleration_of_Sparse_Fine_Tunes_LLMs_on_GSM8k-003-1568x1010.png 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<h2>Recap: What is Sparse Fine-Tuning?</h2>



<p>Training a task-specific LLM consists of two steps:</p>



<ul>
<li>First, the model is trained on a very large corpus of text, to create a general model. This first step is called “pre-training.”</li>



<li>Second, the pre-trained model is then adapted for a specific downstream use case by continuing training with a much smaller, high-quality, curated dataset. This second step is called “fine-tuning”.</li>
</ul>



<p>Our paper with ISTA demonstrates that by applying model compression algorithms like pruning (which removes parameters from the network) and quantization (which converts parameters from high precision FP32 to low precision INT8) <strong><em>during the fine-tuning process</em>, </strong>we can create a highly compressed version of the model without losing accuracy. The compressed models can then be deployed with Neural Magic's DeepSparse, an inference runtime optimized to accelerate sparse-quantized models, to speed up inference by 7x over the unoptimized baseline, and to unlock CPUs as a deployment target for LLMs.</p>


<div>
<figure><img decoding="async" width="1886" height="636" src="https://neuralmagic.com/wp-content/uploads/2023/11/image1-1.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/image1-1.png 1886w, https://neuralmagic.com/wp-content/uploads/2023/11/image1-1-300x101.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/image1-1-1024x345.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/image1-1-768x259.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/image1-1-1536x518.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/image1-1-1568x529.png 1568w" sizes="(max-width: 1886px) 100vw, 1886px"></figure></div>






<h2>Llama 2 Sparse Fine-Tuning Results</h2>



<p>Similar to the MPT setup, we focused on the GSM8k dataset, which consists of diverse grade school math questions. This task is very challenging for LLMs, and the Llama 2 7B base model achieves 0% zero-shot accuracy without any fine-tuning. By fine-tuning for two epochs on the training split of GSM (just ~7k examples), we dramatically improve the test set accuracy to 35.5%.</p>


<div>
<figure><img decoding="async" width="1886" height="462" src="https://neuralmagic.com/wp-content/uploads/2023/11/image4.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/image4.png 1886w, https://neuralmagic.com/wp-content/uploads/2023/11/image4-300x73.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/image4-1024x251.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/image4-768x188.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/image4-1536x376.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/image4-1568x384.png 1568w" sizes="(max-width: 1886px) 100vw, 1886px"></figure></div>






<p>After fine-tuning, we apply <a href="https://arxiv.org/abs/2301.00774">SparseGPT</a> to prune the model and continue training (with model distillation) to recover accuracy. After converging, we apply one-shot quantization to convert both the weights and activations of the model to INT8 from FP32. At the 60% sparse INT8 optimization level, we achieve the full accuracy of the unoptimized model.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="720" src="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-1024x720.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-1024x720.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-300x211.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-768x540.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-1536x1080.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-2048x1440.png 2048w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Llama2_7B_GSM8k_Accuracy_with_Fine_Tuning-002-1568x1103.png 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>The resulting sparse-quantized models can be accelerated with <a href="https://github.com/neuralmagic/deepsparse">DeepSparse</a>. Running on AMD’s latest Zen 4 Genoa cores (on an AWS c7a.4xlarge instance), DeepSparse accelerates the sparse-quantized Llama models to 6-8x faster over the dense FP32 baseline.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="667" src="https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-1024x667.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-1024x667.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-300x195.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-768x500.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-1536x1000.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-2048x1333.png 2048w, https://neuralmagic.com/wp-content/uploads/2023/11/CHART-Llama2-Sparse_Fine_tuned_GSM8k_Text_Generation_Performance-005-1-1568x1021.png 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<h2>Technical Deep Dive: Quantizing Llama 2</h2>



<div><figure><img decoding="async" loading="lazy" width="1024" height="1024" src="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy-1024x1024.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy-1024x1024.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy-300x300.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy-150x150.png 150w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy-768x768.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy-600x600.png 600w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-001-copy.png 1188w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>Quantization is an important technique for compressing models and accelerating inference. Most quantization methods for LLMs (such as <a href="https://arxiv.org/abs/2210.17323">GPTQ</a>) focus on weight-only quantization. However, since the activations remain at FP16 or FP32, the weights are up-converted at inference time to compute at floating-point precision, meaning inference performance only benefits from reduced data movement (i.e., there is no compute savings; only data movement savings). Minimizing data movement is meaningful for batch 1 inference performance since batch 1 inference is memory-bound, but becomes less valuable for server scenarios where batching can be utilized and the workload becomes more compute-bound.</p></div>



<p>At Neural Magic, we focus on quantizing <span>both the weights and activations</span>, so we can compress the model and accelerate inference by reducing data movement and compute requirements. However, one of the challenges with quantizing Llama 2 activations (and LLMs in general) is that activations can be tricky due to the presence of outliers in certain layers of the network. To get a quantized value from a floating point number, we use the function <code>x_quant = round(x / scale + zero_point)</code>. When outliers are present, the quantization scale must stretch to include them. For example, if a layer has values mostly between -1 and 1, but a few outliers near -10 or 10, the quantization scale must accommodate these extreme values. Because the quantization function becomes less sensitive to variations within the normal range, small yet crucial differences in common values are not accurately captured.</p>



<p>The Neural Magic research team has developed a strong default strategy for quantizing activations for Llama 2 that overcomes these outlier issues. This strategy has been codified in “recipes” available in Neural Magic’s SparseZoo, to make it easy for enterprises to leverage our research to quantize their Llama 2 models.&nbsp;</p>



<p>There are two pieces to the strategy:</p>



<ul>
<li><strong>Selective Quantization</strong>: One approach to dealing with outliers is to perform “selective quantization,” where we choose not to quantize the most problematic layers (keeping these layers at FP32 while the rest of the network is at INT8). The optimal criterion for selective quantization is to quantize one layer at a time, measuring the difference in accuracy. This combinatorial process, however, is very time-consuming and our team has developed a much faster heuristic that quickly identifies the most sensitive layers without much experimentation. The&nbsp;graph below shows the top 10 layers of Llama 2 7B sorted by the highest range of activations (the difference between the min and max value of the input) for&nbsp;each layer. The largest layer has a range that is almost 4000x larger than the 10th largest one! Clearly, we will need to treat these layers differently when we develop our quantization recipes.</li>
</ul>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="556" src="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-1024x556.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-1024x556.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-300x163.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-768x417.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-1536x833.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-2048x1111.png 2048w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Top_10_Layers_by_Range_of_Input_Activations_in_Llama2_7B-002-1568x851.png 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<ul>
<li><strong>Smoothing Approaches:</strong> In addition to selective quantization, the research community has developed several techniques to deal with outliers in the weights and activations of LLMs, such as <a href="https://arxiv.org/abs/2306.03078">SpQR</a>, <a href="https://arxiv.org/abs/2308.15987">Logarithmic Activation Equalization (LAE)</a>, and <a href="https://arxiv.org/abs/2211.10438">SmoothQuant</a>, which offer methodologies for smoothing, adjusting, or extracting the distribution of outliers in weights and activations, to reduce their impact. By applying these algorithms in concert with selective quantization, we can improve the accuracy recovery at various levels of sparsity, as indicated by the graph below, which shows SmoothQuant and LAE consistently outperforming regular quantization approaches across all sparsity levels.</li>
</ul>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="659" src="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-1024x659.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-1024x659.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-300x193.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-768x495.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-1536x989.png 1536w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-2048x1319.png 2048w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-CHART-Best_Quantization_Algorithms_for_Sparse_Tine_Tuned_Llama2_7B_GSM8k-001-1568x1010.png 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Neural Magic’s open-source model optimization toolkit (SparseML) and recipe repository (SparseZoo) contain all the tools needed to apply this quantization strategy to your Llama 2 fine-tune, to make it easy for enterprise ML engineers to create inference optimized sparse quantized Llama 2 that runs performantly with DeepSparse.</p>







<hr>



<h2>What’s Next?</h2>



<p>This work is an example of our continued commitment and focus on industry-leading LLM optimization. We will continue to expand this research to deliver value to our users through the fast CPU deployment of LLMs that run on DeepSparse.</p>



<p>Our priorities include:</p>



<ul>
<li><strong>Productizing Sparse Fine-Tuning</strong>: We are adapting <a href="https://github.com/IST-DASLab/SparseFinetuning">the research code</a> into <a href="https://github.com/neuralmagic/sparseml">SparseML</a> to enable external users to apply Sparse Fine-Tuning to their custom datasets.</li>



<li><strong>Expanding model support:</strong> We have already applied Sparse Fine-Tuning to the popular MPT and Llama 2 architectures, and we will continue to explore Sparse Fine-Tuning with SOTA models like Mistral.</li>



<li><strong>Pushing to higher sparsity:</strong> We continue to improve our pruning algorithms to reach higher levels of sparsity.</li>
</ul>



<p>Visit the <a href="https://huggingface.co/spaces/neuralmagic/sparse-llama-gsm8k" title="">live demo of a Sparse Fine-Tuned Llama</a> running fully on just a CPU. Star and <a href="https://github.com/neuralmagic/deepsparse/blob/main/research/mpt/README.md" title="">go to the DeepSparse GitHub</a> to learn how to run these models. View all the <a href="https://sparsezoo.neuralmagic.com/?architectures=llama2&amp;datasets=gsm8k&amp;subArchitectures=7b&amp;task=text_generation&amp;ungrouped=true&amp;sort=Latency%3Aasc" title="">Llama models on SparseZoo</a>.</p>



<p><br>Want your own sparse LLM? Reach out to us in our <a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Neural Magic community</a> to let us know what Sparse Fine-Tuned LLM you want to see next!</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="1024" src="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-002-copy.png" alt="" srcset="https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-002-copy.png 1024w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-002-copy-300x300.png 300w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-002-copy-150x150.png 150w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-002-copy-768x768.png 768w, https://neuralmagic.com/wp-content/uploads/2023/11/BLOG-GRAPHIC-Fast_Llama_2_on_CPUs_With_Sparse_Fine_Tuning_and_DeepSparse-002-copy-600x600.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>
		
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>			</main><!-- #main -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Interactive Guide to CSS Grid (203 pts)]]></title>
            <link>https://www.joshwcomeau.com/css/interactive-guide-to-grid/</link>
            <guid>38388842</guid>
            <pubDate>Thu, 23 Nov 2023 03:22:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.joshwcomeau.com/css/interactive-guide-to-grid/">https://www.joshwcomeau.com/css/interactive-guide-to-grid/</a>, See on <a href="https://news.ycombinator.com/item?id=38388842">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-layout="tutorial"><a id="introduction"><h2>Introduction</h2></a><p>CSS Grid is one of the most amazing parts of the CSS language. It gives us a ton of new tools we can use to create sophisticated and fluid layouts.</p><p>It's also <em>surprisingly complex.</em> It took me quite a while to truly become comfortable with CSS Grid!</p><p>In this tutorial, I'm going to share the biggest 💡 lightbulb moments I've had in my own journey with CSS Grid. You'll learn the fundamentals of this layout mode, and see how to do some pretty cool stuff with it. ✨</p><div id="mental-model"><h2><a name="mental-model-1" id="mental-model-1" href="#mental-model-1"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Mental model</h2></div><p>CSS is comprised of several different <a href="https://www.joshwcomeau.com/css/understanding-layout-algorithms/">layout algorithms</a>, each designed for different types of user interfaces. The default layout algorithm, Flow layout, is designed for digital documents. Table layout is designed for tabular data. Flexbox is designed for distributing items along a single axis.</p><p>CSS Grid is the latest and greatest layout algorithm. It's <em>incredibly</em> powerful: we can use it to build complex layouts that fluidly adapt based on a number of constraints.</p><p>The most unusual part of CSS Grid, in my opinion, is that the grid <em>structure</em>, the rows and columns, are defined <strong>purely in CSS:</strong></p><!--$?--><template id="B:0"></template><!--/$--><p>With CSS Grid, a single DOM node is sub-divided into rows and columns. In this tutorial, we're highlighting the rows/columns with dashed lines, but in reality, they're invisible.</p><p><em>This is super weird!</em> In every other layout mode, the only way to create compartments like this is by adding more DOM nodes. In Table layout, for example, each row is created with a <code>&lt;tr&gt;</code>, and each cell within that row using <code>&lt;td&gt;</code> or <code>&lt;th&gt;</code>:</p><pre></pre><p>Unlike Table layout, CSS Grid lets us manage the layout entirely from within CSS. We can slice up the container however we wish, creating compartments that our grid children can use as anchors.</p><p>We opt in to the Grid layout mode with the <code>display</code> property:</p><pre></pre><p>By default, CSS Grid uses a single column, and will create rows as needed, based on the number of children. This is known as an <em>implicit grid</em>, since we aren't explicitly defining any structure.</p><p>Here's how this works:</p><!--$?--><template id="B:1"></template><!--/$--><p>Implicit grids are dynamic; rows will be added and removed based on the number of children. Each child gets its own row.</p><p>By default, the height of the grid parent is determined by its children. It grows and shrinks dynamically. Interestingly, this isn't even a “CSS Grid” thing; the grid <em>parent</em> is still using Flow layout, and block elements in Flow layout grow vertically to contain their content. Only the <em>children</em> are arranged using Grid layout.</p><p>But what if we give the grid a fixed height? In that case, the total surface area is divided into equally-sized rows:</p><!--$?--><template id="B:2"></template><!--/$--><div id="grid-construction"><h2><a name="grid-construction-3" id="grid-construction-3" href="#grid-construction-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Grid Construction</h2></div><p>By default, CSS Grid will create a single-column layout. We can specify columns using the <code>grid-template-columns</code> property:</p><div><header><h3>Code Playground</h3></header></div><p>By passing two values to <code>grid-template-columns</code> — <code>25%</code> and <code>75%</code> — I'm telling the CSS Grid algorithm to slice the element up into two columns.</p><p>Columns can be defined using any valid <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/length-percentage" rel="noopener noreferrer" target="_blank">CSS <!-- -->&lt;<!-- -->length-percentage<!-- -->&gt;<!-- --> value</a>, including pixels, rems, viewport units, and so on. Additionally, we also gain access to a new unit, the <code>fr</code> unit:</p><div><header><h3>Code Playground</h3></header></div><p><code>fr</code> stands for “fraction”. In this example, we're saying that the first column should consume 1 unit of space, while the second column consumes 3 units of space. That means there are 4 total units of space, and this becomes the denominator. The first column eats up ¼ of the available space, while the second column consumes ¾.</p><p>The <code>fr</code> unit brings Flexbox-style flexibility to CSS Grid. Percentages and <code>&lt;length&gt;</code> values create hard constraints, while <code>fr</code> columns are free to grow and shrink as required, to contain their contents.</p><p><strong>Try shrinking this container to see the difference:</strong></p><!--$?--><template id="B:3"></template><!--/$--><p>In this scenario, our first column has a cuddly ghost that has been given an explicit width of 55px. But what if the column is too small to contain it?</p><ul><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p>Percentage-based columns are rigid, and so our ghost image will <em>overflow</em>, spilling out of the column.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>fr</code>-based columns are flexible, and so the column won't shrink below its minimum content size, even if that means breaking the proportions.</p></li></ul><p>To be more precise: the <code>fr</code> unit distributes <em>extra</em> space. First, column widths will be calculated based on their contents. If there's any leftover space, it'll be distributed based on the <code>fr</code> values. This is very similar to <code>flex-grow</code>, as discussed in my <a href="https://www.joshwcomeau.com/css/interactive-guide-to-flexbox/">Interactive Guide to Flexbox</a>.</p><p>In general, this flexibility is a good thing. Percentages are too strict.</p><p>We can see a perfect example of this with <code>gap</code>. <code>gap</code> is a magical CSS property that adds a fixed amount of space between all of the columns and rows within our grid.</p><p>Check out what happens when we toggle between percentages and fractions:</p><!--$?--><template id="B:4"></template><!--/$--><p>Notice how the contents spill outside the grid parent when using percentage-based columns? This happens because percentages are calculated using the <em>total</em> grid area. The two columns consume 100% of the parent's content area, and they aren't allowed to shrink. When we add 16px of <code>gap</code>, the columns have no choice but to spill beyond the container.</p><p>The <code>fr</code> unit, by contrast, is calculated based on the <em>extra</em> space. In this case, the extra space has been reduced by 16px, for the <code>gap</code>. The CSS Grid algorithm distributes the remaining space between the two grid columns.</p><div id="implicit-and-explicit-rows"><h3><a name="implicit-and-explicit-rows-4" id="implicit-and-explicit-rows-4" href="#implicit-and-explicit-rows-4"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Implicit and explicit rows</h3></div><p>What happens if we add more than two children to a two-column grid?</p><p>Well, let's give it a shot:</p><div><header><h3>Code Playground</h3></header></div><p>Interesting! Our grid gains a second row. The grid algorithm wants to ensure that every child has its own grid cell. It’ll spawn new rows as-needed to fulfill this goal. This is handy in situations where we have a variable number of items (eg. a photo grid), and we want the grid to expand automatically.</p><p>In other situations, though, we want to define the rows explicitly, to create a specific layout. We can do that with the <code>grid-template-rows</code> property:</p><div><header><h3>Code Playground</h3></header></div><p>By defining both <code>grid-template-rows</code> and <code>grid-template-columns</code>, we've created an explicit grid. This is perfect for building page layouts, like the <span>“Holy Grail”<span>?</span></span> layout at the top of this tutorial.</p><div id="the-repeat-helper"><h3><a name="the-repeat-helper-5" id="the-repeat-helper-5" href="#the-repeat-helper-5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>The repeat helper</h3></div><p>Let's suppose we're building a calendar:</p><!--$?--><template id="B:5"></template><!--/$--><p>CSS Grid is a wonderful tool for this sort of thing. We can structure it as a 7-column grid, with each column consuming 1 unit of space:</p><pre></pre><p>This <em>works</em>, but it's a bit annoying to have to count each of those <code>1fr</code>’s. Imagine if we had 50 columns!</p><p>Fortunately, there's a nicer way to solve for this:</p><pre></pre><p>The <code>repeat</code> function will do the copy/pasting for us. We're saying we want 7 columns that are each <code>1fr</code> wide.</p><p>Here's the playground showing the full code, if you're curious:</p><div><header><h3>Code Playground</h3></header></div><div id="assigning-children"><h2><a name="assigning-children-6" id="assigning-children-6" href="#assigning-children-6"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Assigning children</h2></div><p>By default, the CSS Grid algorithm will assign each child to the first unoccupied grid cell, much like how a tradesperson might lay tiles in a bathroom floor.</p><p><strong>Here's the cool thing though:</strong> we can assign our items to whichever cells we want! Children can even span across multiple rows/columns.</p><p>Here's an interactive demo that shows how this works. <em>Click/press and drag</em> to place a child in the <span>grid<span></span>:</span></p><!--$?--><template id="B:6"></template><!--/$--><p>The <code>grid-row</code> and <code>grid-column</code> properties allow us to specify which track(s) our grid child should occupy.</p><p>If we want the child to occupy a single row or column, we can specify it by its number. <code>grid-column: 3</code> will set the child to sit in the third column.</p><p>Grid children can also stretch across multiple rows/columns. The syntax for this uses a slash to delineate start and end:</p><pre></pre><p>At first glance, this looks like a fraction, ¼. In CSS, though, the slash character is not used for division, it's used to separate groups of values. In this case, it allows us to set the start and end columns in a single declaration.</p><p>It's essentially a shorthand for this:</p><pre></pre><p><strong>There's a sneaky gotcha here:</strong> The numbers we're providing are based on the column <em>lines</em>, not the column indexes.</p><p>It'll be easiest to understand this gotcha with a diagram:</p><!--$?--><template id="B:7"></template><!--/$--><p>Confusingly, a 4-column grid actually has <em>5</em> column lines. When we assign a child to our grid, we anchor them using these lines. If we want our child to span the first 3 columns, it needs to start on the 1st line and end on the 4th line.</p><div id="grid-areas"><h3><a name="grid-areas-7" id="grid-areas-7" href="#grid-areas-7"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Grid areas</h3></div><p>Alright, time to talk about one of the coolest parts of CSS Grid. 😄</p><p>Let's suppose we're building this layout:</p><!--$?--><template id="B:9"></template><!--/$--><p>Using what we've learned so far, we could structure it like this:</p><pre></pre><p>This works, but there's a more ergonomic way to do this: <em>grid areas.</em></p><p>Here's what it looks like:</p><!--$?--><template id="B:a"></template><!--/$--><p>Like before, we're defining the grid structure with <code>grid-template-columns</code> and <code>grid-template-rows</code>. But then, we have this curious declaration:</p><pre></pre><p><strong>Here's how this works:</strong> We're drawing out the grid we want to create, almost as if we were making <span>ASCII art<span>?</span></span>. Each line represents a row, and each word is a name we're giving to a particular slice of the grid. See how it sorta looks like the grid, visually?</p><p>Then, instead of assigning a child with <code>grid-column</code> and <code>grid-row</code>, we assign it with <code>grid-area</code>!</p><p>When we want a particular area to span multiple rows or columns, we can repeat the name of that area in our template. In this example, the “sidebar” area spans both rows, and so we write <code>sidebar</code> for both cells in the first column.</p><p><strong>Should we use areas, or rows/columns?</strong> When building explicit layouts like this, I really like using areas. It allows me to give semantic meaning to my grid assignments, instead of using inscrutable row/column numbers. That said, areas work best when the grid has a fixed number of rows and columns. <code>grid-column</code> and <code>grid-row</code> can be useful for implicit grids.</p><div id="being-mindful-of-keyboard-users"><h3><a name="being-mindful-of-keyboard-users-8" id="being-mindful-of-keyboard-users-8" href="#being-mindful-of-keyboard-users-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Being mindful of keyboard users</h3></div><p>There's a big gotcha when it comes to grid assignments: <strong>tab order will still be based on <em>DOM position,</em> not grid position.</strong></p><p>It'll be easier to explain with an example. In this playground, I've set up a group of buttons, and arranged them with CSS Grid:</p><div><header><h3>Code Playground</h3></header></div><p>In the “RESULT” pane, the buttons appear to be in order. By reading from left to right, and from top to bottom, we go from one to six.</p><p><strong>If you're using a device with a keyboard, try to tab through these buttons.</strong> You can do this by clicking the first button in the top left (“One”), and then pressing <kbd>Tab</kbd> to move through the buttons one at a time.</p><p>You should see something like this:</p><p>The focus outline jumps around the page without rhyme or reason, from the user's perspective. This happens because the buttons are being focused based on the order they appear in the DOM.</p><p>To fix this, we should re-order the grid children in the DOM so that they match the visual order, so that I can tab through from left to right, and from top to bottom.<span></span></p><p>In all the examples we've seen so far, our columns and rows stretch to fill the entire grid container. This doesn't need to be the case, however!</p><p>For example, let's suppose we define two columns that are each 90px wide. As long as the grid parent is larger than 180px, there will be some dead space at the end:</p><!--$?--><template id="B:b"></template><!--/$--><p>We can control the distribution of the columns using the <code>justify-content</code> property:</p><!--$?--><template id="B:c"></template><!--/$--><p>If you're familiar with the Flexbox layout algorithm, this probably feels pretty familiar. CSS Grid builds on the alignment properties first introduced with Flexbox, taking them even further.</p><p><strong>The big difference is that we're aligning the <em>columns</em>, not the items themselves.</strong> Essentially, <code>justify-content</code> lets us arrange the compartments of our grid, distributing them across the grid however we wish.</p><p>If we want to align the items themselves <em>within</em> their columns, we can use the <code>justify-items</code> property:</p><!--$?--><template id="B:d"></template><!--/$--><p>When we plop a DOM node into a grid parent, the default behaviour is for it to stretch across that entire column, just like how a <code>&lt;div&gt;</code> in Flow layout will stretch horizontally to fill its container. With <code>justify-items</code>, however, we can tweak that behaviour.</p><p>This is useful because it allows us to break free from the rigid symmetry of columns. When we set <code>justify-items</code> to something other than <code>stretch</code>, the children will shrink down to their default width, as determined by their contents. As a result, items in the same column can be different widths.</p><p>We can even control the alignment of a <em>specific</em> grid child using the <code>justify-self</code> property:</p><!--$?--><template id="B:e"></template><!--/$--><p>Unlike <code>justify-items</code>, which is set on the grid parent and controls the alignment of <em>all</em> grid children, <code>justify-self</code> is set on the child. We can think of <code>justify-items</code> as a way to set a default value for <code>justify-self</code> on all grid children.</p><div id="aligning-rows"><h3><a name="aligning-rows-10" id="aligning-rows-10" href="#aligning-rows-10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Aligning rows</h3></div><p>So far, we've been talking about how to align stuff in the <em>horizontal</em> direction. CSS Grid provides an additional set of properties to align stuff in the <em>vertical</em> direction:</p><!--$?--><template id="B:f"></template><!--/$--><p><code>align-content</code> is like <code>justify-content</code>, but it affects rows instead of columns. Similarly, <code>align-items</code> is like <code>justify-items</code>, but it handles the <em>vertical</em> alignment of items inside their grid area, rather than horizontal.</p><p>To break things down even further:</p><ul><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>justify</code> — deals with <em>columns</em>.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>align</code> — deals with <em>rows</em>.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>content</code> — deals with the <em>grid structure</em>.</p></li><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><p><code>items</code> — deals with the <em>DOM nodes</em> within the grid structure.</p></li></ul><p>Finally, in addition to <code>justify-self</code>, we also have <code>align-self</code>. This property controls the vertical position of a single grid item within its cell.</p><div id="two-line-centering-trick"><h3><a name="two-line-centering-trick-11" id="two-line-centering-trick-11" href="#two-line-centering-trick-11"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Two-line centering trick</h3></div><p>There's one last thing I want to show you. It's one of my favourite little tricks with CSS Grid.</p><p>Using only two CSS properties, we can center a child within a container, both horizontally and vertically:</p><!--$?--><template id="B:10"></template><!--/$--><p>The <code>place-content</code> property is a shorthand. It's syntactic sugar for this:</p><pre></pre><p>As we've learned, <code>justify-content</code> controls the position of columns. <code>align-content</code> controls the position of rows. In this situation, we have an implicit grid with a single child, and so we wind up with a 1×1 grid. <code>place-content: center</code> pushes both the row and column to the center.</p><p>There are lots of ways to center a div in modern CSS, but this is the only way I know of that only requires two CSS declarations!</p><div id="tip-of-the-iceberg"><h2><a name="tip-of-the-iceberg-12" id="tip-of-the-iceberg-12" href="#tip-of-the-iceberg-12"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><p>Link to this heading</p></a>Tip of the iceberg</h2></div><p>In this tutorial, we've covered some of the most fundamental parts of the CSS Grid layout algorithm, but honestly, there's <em>so much more stuff</em> we haven't talked about!</p><p>If you found this blog post helpful, you might be interested to know that I've created a comprehensive learning resource that goes <em>way deeper</em>. It's called <a href="https://css-for-js.dev/" rel="noopener noreferrer" target="_blank">CSS for JavaScript Developers</a>.</p><a href="https://css-for-js.dev/" rel="noopener noreferrer" target="_blank"><span type="default"><img src="https://www.joshwcomeau.com/images/the-importance-of-learning-css/css-for-js-banner.png" alt=""></span></a><p>The course uses the same technologies as my blog, and so it's chock full of interactive explanations. But there are also bite-sized videos, practice exercises, real-world-inspired projects, and even a few mini-games.</p><p>If you found this blog post helpful, <em>you'll love the course</em>. It follows a similar approach, but for the entire CSS language, and with hands-on practice to make sure you're actually developing new skills.</p><p>It's specifically built for folks who use a JS framework like React/Angular/Vue. 80% of the course focuses on CSS fundamentals, but we also see how to integrate those fundamentals into a modern JS application, how to structure our CSS, stuff like that.</p><p>If you struggle with CSS, I hope you'll check it out. Gaining confidence with CSS is <em>game-changing</em>, especially if you're already comfortable with HTML and JS. When you complete the holy trinity, it becomes so much easier to stay in flow, to truly enjoy developing web applications.</p><p><em color="var(--color-tertiary)">And for the next week, it's 50% off for Black Friday!</em> You can learn more here:</p><ul><li><span><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span></li></ul><p>I hope you found this tutorial useful. ❤️</p><div><div><h3>Last Updated</h3><p>November 22nd, 2023</p></div><div><h3>Hits</h3></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intro to Large Language Models [Video] (258 pts)]]></title>
            <link>https://www.youtube.com/watch?v=zjkBMFhNj_g</link>
            <guid>38388669</guid>
            <pubDate>Thu, 23 Nov 2023 02:54:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=zjkBMFhNj_g">https://www.youtube.com/watch?v=zjkBMFhNj_g</a>, See on <a href="https://news.ycombinator.com/item?id=38388669">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Sorry You Missed It – Inside Rockstar North Blog Shut Down (139 pts)]]></title>
            <link>https://insiderockstarnorth.blogspot.com/2023/11/sorry-you-missed-it.html</link>
            <guid>38388456</guid>
            <pubDate>Thu, 23 Nov 2023 02:25:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insiderockstarnorth.blogspot.com/2023/11/sorry-you-missed-it.html">https://insiderockstarnorth.blogspot.com/2023/11/sorry-you-missed-it.html</a>, See on <a href="https://news.ycombinator.com/item?id=38388456">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<main id="main" role="main" tabindex="-1">
<div data-version="2" id="page_body" name="Page body">
<article>
<div>

<h3>
Sorry you missed it.
</h3>


<div id="post-body-3224829284983975058">
<p>Today (22 Nov 2023) I got an email from R*North.</p><p>Apparently some of the OG's there are upset by my blog. I genuinely didn't think anyone would mind me talking about 20 year old games but I was wrong. Something about ruining the Rockstar mystique or something.</p><p>Anyway,</p><p>This blog isn't important enough to me to piss off my former colleagues in Edinburgh so I'm winding it down.</p><p>I'll maybe just leave a few articles with anecdotes that don't affect anyone but me.</p><p>I would love for Rockstar to open up about development of the trilogy themselves, but it doesn't look like that's going to happen anytime soon.</p><p>Maybe I'll try again in a decade or two.</p><p>Till then, Obbe.</p>
</div>

</div>


</article>
</div>
</main>
</div></div>]]></description>
        </item>
    </channel>
</rss>