<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 20 Dec 2023 16:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Tesla blamed drivers for failures of parts it long knew were defective (204 pts)]]></title>
            <link>https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/</link>
            <guid>38707589</guid>
            <pubDate>Wed, 20 Dec 2023 11:46:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/">https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/</a>, See on <a href="https://news.ycombinator.com/item?id=38707589">Hacker News</a></p>
Couldn't get https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Advice for new software devs who've read all those other advice essays (198 pts)]]></title>
            <link>https://buttondown.email/hillelwayne/archive/advice-for-new-software-devs-whove-read-all-those/</link>
            <guid>38706697</guid>
            <pubDate>Wed, 20 Dec 2023 09:01:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.email/hillelwayne/archive/advice-for-new-software-devs-whove-read-all-those/">https://buttondown.email/hillelwayne/archive/advice-for-new-software-devs-whove-read-all-those/</a>, See on <a href="https://news.ycombinator.com/item?id=38706697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                

                
                    
                        <p>Someone recently asked me if I had advice for early-career programmers. At first I thought this was a silly question. I only entered the workforce ten years ago; many of my newsletter subscribers have been programming for longer than I've been alive! </p>
<p>Then I went and read some "advice for starting programmer" essays and thought of some things they missed. So here's thirteen bits of advice for early-career programmers. Some of it is contradictory.</p>
<ol>
<li>
<p>People don't listen to me because I'm a good programmer, they listen to me because I'm a good writer. The same is true of pretty much <em>everybody</em> you'll read. This doesn't mean you should automatically reject everything, but it means you should carefully think about it and evaluate how it applies to your situation. And take any argument about "objective truth" with a grain of salt: there is <em>very</em> little about software that's been scientifically studied, and most of the research is inconclusive. </p>
</li>
<li>
<p>But also don't worry too hard about getting "tricked" or learning "the wrong thing". If you like someone's ideas, try them out! As long as you're not actively sabotaging your coworkers then it'll probably work out in the end, even if you look back and think "I should have done that different." That's what learning is all about!</p>
</li>
<li>
<p>Read the book <a href="https://debuggingrules.com/" target="_blank">Debugging: The 9 Rules</a>. Borrow it from the library or ask your company to buy a copy, whatever. It's a real easy read and teaches an important skill all the other "beginner programmer" books barely cover.</p>
</li>
<li>
<p>At some point you will discover the Right Way to program, the thing which makes this all <em>make sense</em>, and you'll be convinced that the whole field would be so much better off if everybody else programmed the Right Way, too. For me the Right Way was test-driven development; for you it might be functional programming, lisp, formal methods or one of a million other things. </p>
<p>I'm not going to tell you to <em>not</em>  get swept up in the Right Way, because that's pretty much impossible. And honestly it feels really great to discover the Right Way and life's too short to not feel good. Just be <em>mindful</em> of the fact you're getting swept up and try not to make your identity the Right Way Guy. Eventually the honeymoon will end and you'll learn that programming is frustrating and messy regardless of which Right Way people use, and that you can also make great software without doing it the Right Way. Over time you'll learn fifty other Right Ways and learn to mix and match them to the problem at hand.</p>
</li>
<li>
<p>When you first encounter the Right Way, it will <em>likely</em> be from someone who went full Right Way Guy. Try not to hold it against them later. And try not to conflate the actual technique with how the RWG <em>pitches</em> the technique. Most ideas need some modification from their purest form to integrate well with other ideas.</p>
</li>
<li>
<p><a href="https://jvns.ca/" target="_blank">Julia Evans</a> once <a href="https://www.youtube.com/watch?v=30YWsGDr8mA" target="_blank">said</a> "behind every best practice is a horror story." If you don't understand a Best Practice, look for the horror story that inspired it. It might make the best practice make sense. It might turn out to be something that's completely irrelevant to you, and then you can feel comfortable doing a different practice instead.</p>
</li>
<li>
<p>Building on the last tip: a lot of best practices and conventions are "path dependent", arising from a mix of historical and cultural factors. There are things we do because our mentors do it, who do it because <em>their</em> mentors did it, who did it to address issues that aren't as relevant anymore. If something sounds like a <a href="https://en.wikipedia.org/wiki/Just-so_story" target="_blank">just-so story</a>, it very well might be. You can often retrace the whole path if you're willing to look.</p>
</li>
<li>
<p>Take walks.</p>
</li>
<li>
<p>Almost every tool you use has some form of hidden depth, from your programming language to git to JIRA. Don't feel like you have to become an expert in every single one, but do consider spending 5-10 minutes learning a bit more about what it can do. </p>
</li>
<li>
<p>Talk to people in other parts of the company: support, business domain, sales, etc. Consider shadowing them if you have the time (and feel comfortable asking). You'll be surprised by what you learn! </p>
</li>
<li>
<p>If possible, try to do a few different types of programming earlier in your career. This doesn't have to mean switching jobs: most companies are doing several different kinds of programming at once. So like if you're starting in a webdev company, try some frontend, some backend, some operations, some database stuff, and so forth. This helps you learn, but <em>far more importantly</em> increases your chances of finding a kind of software work that you really really like. My first job was as a frontend dev and I was <em>miserable</em>. Later I moved to backend and was much happier, as were the people who wanted to spent more time doing frontend! </p>
</li>
<li>
<p>You've probably heard the advice that software as a field is changing <em>all the time</em>, and that you shouldn't get swept up in the framework treadmill, just focus on learning fundamental skills. This is a true, but doesn't explain the "why". For structural reasons, <em>information</em> in software propagates really quickly. This is due to a lot of factors (internet, open source, <a href="https://www.hillelwayne.com/post/what-we-can-learn/" target="_blank">conferences</a>) but overall there's a lower barrier to sharing ideas in software. So it's really easy to get a lot of people to <em>know about</em> someone's pet project, even if only one person uses it. </p>
<p>The upshot of this is that a lot of the technologies you hear about have very small userbases and will never get wide adoption, but it won't <em>seem</em> that way from how you hear about it. That's why it makes sense to be conservative. If you hear about something that gets you excited, go ahead and be an early adopter, otherwise it's okay to wait a couple years to see if it has legs.</p>
</li>
<li>
<p>Ultimately none of us can predict the future, just as none of us could have predicted the present. Just try to do the best you can, live according to your values, and enjoy the ride.</p>
</li>
</ol>
<p>That's all from me for the year; new workshop dates when I get back. See you in 2024! </p>
                    
                

                
                    <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.email/hillelwayne" target="_blank">here</a>. Updates are 6x a month. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM in a Flash: Efficient LLM Inference with Limited Memory (214 pts)]]></title>
            <link>https://huggingface.co/papers/2312.11514</link>
            <guid>38704982</guid>
            <pubDate>Wed, 20 Dec 2023 03:02:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/papers/2312.11514">https://huggingface.co/papers/2312.11514</a>, See on <a href="https://news.ycombinator.com/item?id=38704982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-props="{&quot;comments&quot;:[{&quot;id&quot;:&quot;65825e287cec0a2080cbaf0b&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/88bb4c4a67dc8958069e9014f5e73a0b.svg&quot;,&quot;fullname&quot;:&quot;Michael Barry&quot;,&quot;name&quot;:&quot;MichaelBarryUK&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false},&quot;createdAt&quot;:&quot;2023-12-20T03:23:20.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;💩&quot;,&quot;html&quot;:&quot;<p>💩</p>\n&quot;,&quot;updatedAt&quot;:&quot;2023-12-20T03:23:20.638Z&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/88bb4c4a67dc8958069e9014f5e73a0b.svg&quot;,&quot;fullname&quot;:&quot;Michael Barry&quot;,&quot;name&quot;:&quot;MichaelBarryUK&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false}},&quot;numEdits&quot;:0,&quot;editors&quot;:[&quot;MichaelBarryUK&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;😔&quot;,&quot;users&quot;:[&quot;nlpguy&quot;,&quot;10100101j&quot;,&quot;IsoSpandy&quot;,&quot;hyper88&quot;,&quot;saidattax&quot;],&quot;count&quot;:5}],&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.7121967673301697},&quot;isReport&quot;:false}}],&quot;primaryEmailConfirmed&quot;:false,&quot;paper&quot;:{&quot;id&quot;:&quot;2312.11514&quot;,&quot;authors&quot;:[{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af2&quot;,&quot;name&quot;:&quot;Keivan Alizadeh&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af3&quot;,&quot;name&quot;:&quot;Iman Mirzadeh&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af4&quot;,&quot;user&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/8e440bdf6241be32ea45f72d3f00e05b.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Dmitry Belenko&quot;,&quot;user&quot;:&quot;depthwise&quot;,&quot;type&quot;:&quot;user&quot;},&quot;name&quot;:&quot;Dmitry Belenko&quot;,&quot;status&quot;:&quot;admin_assigned&quot;,&quot;statusLastChangedAt&quot;:&quot;2023-12-20T08:59:28.800Z&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af5&quot;,&quot;name&quot;:&quot;Karen Khatamifard&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af6&quot;,&quot;name&quot;:&quot;Minsik Cho&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af7&quot;,&quot;name&quot;:&quot;Carlo C Del Mundo&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af8&quot;,&quot;name&quot;:&quot;Mohammad Rastegari&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af9&quot;,&quot;user&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/fc3d149a27bc8396010a2a02148e8ca0.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mehrdad Farajtabar&quot;,&quot;user&quot;:&quot;mfarajtabar&quot;,&quot;type&quot;:&quot;user&quot;},&quot;name&quot;:&quot;Mehrdad Farajtabar&quot;,&quot;status&quot;:&quot;admin_assigned&quot;,&quot;statusLastChangedAt&quot;:&quot;2023-12-20T08:21:56.790Z&quot;,&quot;hidden&quot;:false}],&quot;publishedAt&quot;:&quot;2023-12-12T18:57:08.000Z&quot;,&quot;title&quot;:&quot;LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory&quot;,&quot;summary&quot;:&quot;Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nintensive computational and memory requirements present challenges, especially\nfor devices with limited DRAM capacity. This paper tackles the challenge of\nefficiently running LLMs that exceed the available DRAM capacity by storing the\nmodel parameters on flash memory but bringing them on demand to DRAM. Our\nmethod involves constructing an inference cost model that harmonizes with the\nflash memory behavior, guiding us to optimize in two critical areas: reducing\nthe volume of data transferred from flash and reading data in larger, more\ncontiguous chunks. Within this flash memory-informed framework, we introduce\ntwo principal techniques. First, \&quot;windowing'\&quot; strategically reduces data\ntransfer by reusing previously activated neurons, and second, \&quot;row-column\nbundling\&quot;, tailored to the sequential data access strengths of flash memory,\nincreases the size of data chunks read from flash memory. These methods\ncollectively enable running models up to twice the size of the available DRAM,\nwith a 4-5x and 20-25x increase in inference speed compared to naive loading\napproaches in CPU and GPU, respectively. Our integration of sparsity awareness,\ncontext-adaptive loading, and a hardware-oriented design paves the way for\neffective inference of LLMs on devices with limited memory.&quot;,&quot;upvotes&quot;:33},&quot;canReadDatabase&quot;:false,&quot;canManageCommunity&quot;:false,&quot;hasHfLevelAccess&quot;:false,&quot;publishedOnDailyAt&quot;:&quot;2023-12-20T02:32:43.361Z&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;avatarUrl&quot;:&quot;/avatars/2e476fce12c4d48bb1f0ac3e68ddc209.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Kaio Ken&quot;,&quot;user&quot;:&quot;kaiokendev&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/1b4c9afab0c4b10ac50fca0c738bb61a.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;lbn&quot;,&quot;user&quot;:&quot;llbn&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637711517996-6039478ab3ecf716b1a5fd4d.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;taesiri&quot;,&quot;user&quot;:&quot;taesiri&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/358503a958bacff790c5830f24946378.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Xin&quot;,&quot;user&quot;:&quot;Nuclear6&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Somshubra Majumdar&quot;,&quot;user&quot;:&quot;smajumdar94&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ce50353529c21a228ab2d8/153N-GZ0Vj5YXWMW3noQe.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Se June Joo&quot;,&quot;user&quot;:&quot;Joocjun&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/d44dee29d7aae9e545cb7847d835bae7.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Aiden Shihadeh&quot;,&quot;user&quot;:&quot;sdkv2&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/1e9617311b04bbf296f061a9a85b12cc.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ai Studio Lab&quot;,&quot;user&quot;:&quot;aistudiolab&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Arthur Zucker&quot;,&quot;user&quot;:&quot;ArthurZ&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/d6f733991b3011ce53c9055f3083332f.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Erland Hilman Fuadi&quot;,&quot;user&quot;:&quot;Masa-Erland&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637b53a7a2460cde612b127b/urzriWZ00OvHgESYnBlKX.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Krinal Joshi&quot;,&quot;user&quot;:&quot;krinal&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/8860b175ae0d292bb5ad8502a97b9b9f.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mous&quot;,&quot;user&quot;:&quot;Anony&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;acceptLanguages&quot;:[&quot;*&quot;]}" data-target="PaperContent">

<div><h2>Abstract</h2>
	<p>Large language models (LLMs) are central to modern natural language
processing, delivering exceptional performance in various tasks. However, their
intensive computational and memory requirements present challenges, especially
for devices with limited DRAM capacity. This paper tackles the challenge of
efficiently running LLMs that exceed the available DRAM capacity by storing the
model parameters on flash memory but bringing them on demand to DRAM. Our
method involves constructing an inference cost model that harmonizes with the
flash memory behavior, guiding us to optimize in two critical areas: reducing
the volume of data transferred from flash and reading data in larger, more
contiguous chunks. Within this flash memory-informed framework, we introduce
two principal techniques. First, "windowing'" strategically reduces data
transfer by reusing previously activated neurons, and second, "row-column
bundling", tailored to the sequential data access strengths of flash memory,
increases the size of data chunks read from flash memory. These methods
collectively enable running models up to twice the size of the available DRAM,
with a 4-5x and 20-25x increase in inference speed compared to naive loading
approaches in CPU and GPU, respectively. Our integration of sparsity awareness,
context-adaptive loading, and a hardware-oriented design paves the way for
effective inference of LLMs on devices with limited memory.</p></div>

<p><a href="https://arxiv.org/abs/2312.11514" target="_blank" rel="noreferrer">View arXiv page</a>
	<a href="https://arxiv.org/pdf/2312.11514" target="_blank" rel="noreferrer">View PDF</a>
	<a href="https://huggingface.co/login?next=%2Fpapers%2F2312.11514">
			Add to collection
		</a></p>



<div><h3>Community</h3>

	


</div>

</div>
		<section>

			<h2>
				Models citing this paper
				<span>0</span></h2>
			<p>No model linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a model README.md to link it from this page.
				</p>

			<h2>
				Datasets citing this paper
				<span>0</span></h2>
			<p>No dataset linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a dataset README.md to link it from this page.
				</p>

			<h3>
				Spaces citing this paper
				<span>0</span></h3>

			<p>No Space linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a Space README.md to link it from this page.
				</p>

			<h2>
				Collections including this paper
				<span>5</span></h2>
			<nav>








					<a href="https://huggingface.co/collections?paper=2312.11514">Browse 5 collections that include this paper
						</a></nav></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rite Aid banned from using AI facial recognition for five years (218 pts)]]></title>
            <link>https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without</link>
            <guid>38704830</guid>
            <pubDate>Wed, 20 Dec 2023 02:38:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without">https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without</a>, See on <a href="https://news.ycombinator.com/item?id=38704830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span>Rite Aid will be prohibited from using facial recognition technology for surveillance purposes for five years to settle Federal Trade Commission charges that the retailer failed to implement reasonable procedures and prevent harm to consumers in its use of facial recognition technology in hundreds of stores. </span></span></span></p>



<p><span><span>“<span><span>Rite Aid's reckless use of facial surveillance systems left its customers facing humiliation and other harms, and its order violations put consumers’ sensitive information at risk," </span></span>said Samuel Levine, Director of the FTC’s Bureau of Consumer Protection. <span>“Today’s groundbreaking order makes clear that the Commission will be vigilant in protecting the public from unfair biometric surveillance and unfair data security practices.” </span></span></span></p>



<p><span><span><span><span><span><span>The <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_stipulated_order_filed.pdf">proposed order</a>&nbsp;will require Rite Aid to implement comprehensive safeguards to prevent these types of harm to consumers when deploying automated systems that use biometric information to track them or flag them as security risks. It also will require Rite Aid to discontinue using any such technology if it cannot control potential risks to consumers.</span></span> To settle charges it violated a <a href="https://www.ftc.gov/news-events/news/press-releases/2010/07/rite-aid-settles-ftc-charges-it-failed-protect-medical-financial-privacy-customers-employees">2010 Commission data security order</a> by failing to adequately oversee its service providers, Rite Aid will also be required to implement a robust information security program, which must be overseen by the company’s top executives.</span></span></span></span></p>



<p><span><span><span>In a <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_complaint_filed.pdf">complaint</a><b>&nbsp;</b>filed in federal court<b>,</b> the FTC says that from 2012 to 2020, Rite Aid deployed artificial intelligence-based facial recognition technology in order to identify customers who may have been engaged in shoplifting or other problematic behavior. The complaint, however, charges that the company failed to take reasonable measures to prevent harm to consumers, who, as a result, were erroneously accused by employees of wrongdoing because facial recognition technology falsely flagged the consumers as matching someone who had previously been identified as a shoplifter or other troublemaker. </span></span></span></p>



<p><span><span><span><span><span>Preventing the misuse of biometric information is a high priority for the FTC, </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-warns-about-misuses-biometric-information-harm-consumers"><span>which issued a warning earlier this year</span></a><span> that the agency would be closely monitoring this sector. Rite Aid’s actions subjected consumers to embarrassment, harassment, and other harm, according to the complaint. </span>The company did not inform consumers that it was using the technology in its stores and employees were discouraged from revealing such information. <span>Employees, acting on false positive alerts, followed consumers around its stores, searched them, ordered them to leave, called the police to confront or remove consumers, and </span><span>publicly accused them, sometimes in front of friends or family, of shoplifting or other wrongdoing, according to the complaint. In addition, the FTC says Rite Aid’s actions disproportionately impacted people of color.</span></span></span></span></span></p>



<p><span><span><span>According to the complaint, Rite Aid contracted with two companies to help create a database of images of individuals—considered to be<span> “persons of interest” because Rite Aid believed they engaged in or attempted to engage in criminal activity at one of its retail locations—along with their names and other information such as any criminal background data. The company collected tens of thousands of images of individuals, many of which were low-quality and came from Rite Aid’s security cameras, employee phone cameras and even news stories, according to the complaint.</span></span></span></span></p>



<p><span><span><span><span><span>The system generated thousands of false-positive matches, the FTC says. For example, the technology sometimes matched customers with people who had originally been enrolled in the database based on activity thousands of miles away, or flagged the same person at dozens of different stores all across the United States, according to the complaint. Specifically, the complaint says Rite Aid failed to: </span></span></span></span></span></p>



<ul><li><span><span><span><span><span>Consider and mitigate potential risks to consumers from misidentifying them, including heightened risks to certain consumers because of their race or gender. For example, Rite Aid’s facial recognition technology was more likely to generate false positives in stores located in plurality-Black and Asian communities than in plurality-White communities;</span></span></span></span></span></li>
<li><span><span><span><span>Test, assess, measure, document, or inquire about the accuracy of its facial recognition technology before deploying it, including failing to seek any information from either vendor it used to provide the facial recognition technology about the extent to which the technology had been tested for accuracy;</span></span></span></span></li>
<li><span><span><span><span>Prevent the use of low-quality images in connection with its facial recognition technology, increasing the likelihood of false-positive match alerts; </span></span></span></span></li>
</ul><ul><li><span><span><span><span><span>Regularly monitor or test the accuracy of the technology after it was deployed, including by failing to implement or enforce any procedure for tracking the rate of false positive matches or actions that were taken based on those false positive matches; and </span></span></span></span></span></li>
<li><span><span><span><span><span>Adequately train employees tasked with operating facial recognition technology in its stores and flag that the technology could generate false positives. Even after Rite Aid switched to a technology that enabled employees to report a “bad match” and required employees to use it, the company did not take action to ensure employees followed this policy.</span></span></span></span></span></li>
</ul>

<p><span><span><span><span>In its complaint, the FTC also says Rite Aid violated its </span><span>2010 data security order</span><span> with the Commission by failing to adequately implement a comprehensive information security program. Among other things, the 2010 order required Rite Aid to ensure its third-party service providers had appropriate safeguards to protect consumers’ personal data. For example, the complaint alleges the company conducted many security assessments of service providers orally, and that it failed to obtain or possess backup documentation of such assessments, including for service providers Rite Aid deemed to be “high risk.” </span></span></span></span></p>



<p><span><span><span><span><span>In addition to the ban and required safeguards for automated biometric security or surveillance systems, other provisions of the proposed order prohibit Rite Aid from misrepresenting its data security and privacy practices and also require the company to: </span></span></span></span></span></p>



<ul><li><span><span><span><span><b><span>Delete, and direct third parties to delete</span></b><span>, any images or photos they collected because of Rite Aid’s facial recognition system as well as any algorithms or other products that were developed using those images and photos;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Notify consumers</span></b><span> when their biometric information is enrolled in a database used in connection with a biometric security or surveillance system and when Rite Aid takes some kind of action against them based on an output generated by such a system;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Investigate and respond</span></b><span> in writing to consumer complaints about actions taken against consumers related to an automated biometric security or surveillance system;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Provide clear and conspicuous notice</span></b><span> to consumers about the use of facial recognition or other biometric surveillance technology in its stores;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Delete any biometric information</span></b><span> it collects within five years; </span></span></span></span></span></li>
<li><span><span><span><span><b><span>Implement a data security program</span></b><span> to protect and secure personal information it collects, stores, and shares with its vendors; </span></span></span></span></span></li>
<li><span><span><span><span><b><span>Obtain independent third-party assessments</span></b><span> of its information security program; and</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Provide the Commission with an annual certification</span></b><span> from its CEO documenting Rite Aid’s adherence to the order’s provisions.</span></span></span></span></span></li>
</ul>

<p><span><span><span><span>The Commission voted 3-0 to<span><span> authorize staff&nbsp;to file the complaint and the proposed stipulated order against Rite Aid</span></span>. Commissioner Alvaro Bedoya <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/statement-commissioner-alvaro-m-bedoya-ftc-v-rite-aid-corporation">released a statement</a>. </span></span></span></span></p>



<p><span><span><span><span>The complaint and order were filed in the Eastern District of Pennsylvania. Rite Aid is currently going through bankruptcy proceedings and the order will go into effect after approval from the bankruptcy court and the federal district court as well as modification of the 2010 order by the Commission.</span></span></span></span></p>



<p><span><span><span><span><span>The principal attorneys on these matters are </span></span><span>Robin Wetherill, Leah Frazier, Diana Chang, Christopher Erickson, and Brian Welke in the FTC’s Bureau of Consumer Protection.</span><span><span></span></span></span></span></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build a search engine, not a vector DB (180 pts)]]></title>
            <link>https://blog.elicit.com/search-vs-vector-db/</link>
            <guid>38703943</guid>
            <pubDate>Wed, 20 Dec 2023 00:27:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.elicit.com/search-vs-vector-db/">https://blog.elicit.com/search-vs-vector-db/</a>, See on <a href="https://news.ycombinator.com/item?id=38703943">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>In the last 12 months there has been a proliferation of vector DB startups. I’m not here to debate the specific design tradeoffs of any of them. Instead, I want to push back on several common approaches to what a vector database is, what it’s for, and how you should use one to solve problems.</p><h3 id="vector-databases-aren%E2%80%99t-memory">Vector databases aren’t memory</h3><p>Many vector databases frame their basic utility as solving the problem of language models lacking long term memory, or the fact that you can’t place all of the context for a question into your prompt.</p><figure><a href="https://www.trychroma.com/blog/seed?ref=blog.elicit.com"><img src="https://blog.elicit.com/content/images/2023/12/Search-Engine.png" alt="" loading="lazy" width="653" height="581" srcset="https://blog.elicit.com/content/images/size/w600/2023/12/Search-Engine.png 600w, https://blog.elicit.com/content/images/2023/12/Search-Engine.png 653w"></a><figcaption><span>https://trychroma.com/blog/seed</span></figcaption></figure><p>However, vector search is ultimately just a particular kind of search<em>.</em> Giving your LLM access to a database it can write to and search across is very useful, but it’s ultimately best conceptualized as giving an agent access to a search engine, versus actually “having more memory”.</p><p>Imagine you’re a company that wants to build an LLM-powered documentation experience. If you think of a vector database as just providing an expanded memory to your language model, you might just embed all of your company’s product docs, and then let users ask questions to your bot. When a user hits enter, you do a vector search for their query, find all of the chunks, load them into context, and then have your language model try to answer the question. In fact, that’s the approach we initially took at Stripe when I worked on their <a href="https://stripe.com/newsroom/news/stripe-and-openai?ref=blog.elicit.com">AI docs product</a>.</p><p>Ultimately though, I found that approach to be a dead-end. The crux is that while vector search is better along some axes than traditional search, it's not magic. Just like regular search, you'll end up with irrelevant or missing documents in your results. Language models, just like humans, can only work with what they have and <a href="https://arxiv.org/abs/2302.00093?ref=blog.elicit.com" rel="noreferrer">those irrelevant documents will likely mislead them</a>. </p><p>If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.</p><h3 id="the-good-news">The good news</h3><p>You’ve sat down and decided to build good search, how do you actually do it? It turns out that in this case LLMs can actually save the day.</p><p>Embeddings, for all that they aren’t a magic wand, are still pretty amazing. High-quality embedding search will have a lower false negative rate than keyword search, and combining the two results in much better performance than any pure fulltext search (Google has been doing this for years with <a href="https://blog.google/products/search/search-language-understanding-bert/?ref=blog.elicit.com">BERT</a>). However, both embeddings themselves and the tools needed to use them in large-scale search, have improved by leaps and bounds. There are plenty of battle-tested databases that let you combine keyword and vector search, and I highly recommend using one of these (at Elicit we use <a href="https://vespa.ai/?ref=blog.elicit.com">Vespa</a>, but vector databases like Chroma now often support this as well).</p><p>Once you’ve improved your overall search by blending embeddings with more traditional methods, you get to the fun stuff. A savvy human trying to find information via a search engine knows how to structure their query in order to ensure they find relevant information (<a href="https://supple.com.au/tools/google-advance-search-operators/?ref=blog.elicit.com">Google-fu used to be a powerful art form</a>), language models can do the same. If your model wants to find “what’s the latest news on malaria vaccines,” you could have a language model construct a query that includes a date filter. There is a ton of low hanging fruit here, and after that an almost endless amount of tweaking that can be done to result in incredible quality search. Like in many other cases, similar things were <strong>possible</strong> in the world before LLMs, but they took a lot of specialized skill and effort. Now you can get competitive performance with a few hours of your time and some compute.</p><p>The final stage in the traditional search pipeline is re-ranking. It used to be the case that to do re-ranking you would <a href="https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf?ref=blog.elicit.com">train a relevancy model</a> on signals like which items a user clicks on for a given search results page, and then use that model to sort your top results. If you’re not a whole team structured around building a search engine, this isn’t a viable problem to tackle. Now with language models, you can provide some details on a query:result pair to a model and get a relevancy score that will <a href="https://arxiv.org/abs/2311.07994?ref=blog.elicit.com" rel="noreferrer">beat out all but the best purpose-built systems</a>.</p><p>Ultimately, recent advancements in AI make it much easier to build cutting-edge search, using orders of magnitude less effort than once required. Because of that, the return on sitting down and seriously building good search is extremely high.</p><p>If you want to build a RAG-based tool, first build search.</p><h3 id="postscript-the-bad-news"><em>Postscript (The bad news)</em></h3><p>You’ve built a nice search engine using the above techniques, now it’s time to deploy it. Unfortunately, language models don’t let you avoid the other half of building a search engine: evaluating it.</p><p>Specifically, this means being able to answer questions like:</p><ul><li>“When is doing a search appropriate?”</li><li>“When you do a search, what content are you actually trying to locate?”</li><li>“How high does that content rank in your results?”</li></ul><p>Answering any of those questions requires building evaluation and monitoring infrastructure that you can use to iterate on your search pipeline and know whether the changes you make are improvements. For a followup on evaluating search engines, I recommend this excellent <a href="https://dtunkelang.medium.com/evaluating-good-search-part-i-measure-it-5507b2dbf4f6?ref=blog.elicit.com">series of posts</a>.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Microsoft.com added 192.168.1.1 to their DNS record (439 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38702783</link>
            <guid>38702783</guid>
            <pubDate>Tue, 19 Dec 2023 22:30:52 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38702783">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38703553"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703553" href="https://news.ycombinator.com/vote?id=38703553&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Through a series of connections I know a guy that knows a guy that works at Microsoft that was made aware and the changes have been reverted. Give 'er 30 minutes TTL ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703993"><td></td></tr>
            <tr id="38703779"><td></td></tr>
            <tr id="38703891"><td></td></tr>
                <tr id="38703982"><td></td></tr>
                  <tr id="38703940"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703940" href="https://news.ycombinator.com/vote?id=38703940&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>TTL appears to be set to an hour. But either way, its been 45 min and the primary ns1-39.azure-dns.com is still offering up 0.1</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704070"><td></td></tr>
            <tr id="38703929"><td></td></tr>
            <tr id="38703720"><td></td></tr>
            <tr id="38703905"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703905" href="https://news.ycombinator.com/vote?id=38703905&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>This isn’t something that I think should be diluted.<p>If it’s that simple for a stray record to be included in the dns round robin it could have been bad if it was an external ip with a machine setup by a phisherman especially since control of a domain is all you need to get an ssl cert now.</p><p>Couple this with the fact that it’s Microsoft, one of the most relied on companies in our computer world, this is pretty darn horrible.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704042"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38704042" href="https://news.ycombinator.com/vote?id=38704042&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>For all this to work you need to control the domain.
Is that easier than simply breaking into their systems and owning their servers?</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38704217"><td></td></tr>
            <tr id="38703917"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703917" href="https://news.ycombinator.com/vote?id=38703917&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Wait wait wait wait. Bunny.net accidentally changed their DNS to 127.0.0.1 and took a bunch of their CDN users down today too. Coincidence? Weird day.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704225"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704225" href="https://news.ycombinator.com/vote?id=38704225&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Wait... Can DNS resolvers be configured so that RFC1918 is respected?<p>I mean: I don't expect anything less from Microsoft than doing stuff like that and it cannot affect me for I nullroute microsoft.com from my <i>unbound</i> server (<i>unboud</i> takes wildcard when nullrouting or NXDOMAINing crap domains like microsoft.com or meta.com etc., which is sweet).</p><p>However I'd expect my trusty DNS resolver to also prevent me from <i>anyone</i> not on my private LANs to impersonate addresses reserved for private uses.</p><p>Does anyone know here if it's easily doable?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38704159"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704159" href="https://news.ycombinator.com/vote?id=38704159&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>microsoft.com is currently IPv6-only on my network, because OpenWrt's DNS rebinding protection filters out the A records:<pre><code>  $ ping -4 microsoft.com
  ping: microsoft.com: Address family for hostname not supported

  $ ping -6 microsoft.com
  PING microsoft.com(2603:1030:c02:8::14 (2603:1030:c02:8::14)) 56 data bytes
  64 bytes from 2603:1030:c02:8::14 (2603:1030:c02:8::14): icmp_seq=1 ttl=112 time=68.4 ms</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703344"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703344" href="https://news.ycombinator.com/vote?id=38703344&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>I'm trying to figure out how this could have happened, but I control so few IP addresses that many of my DNS entries are manually assigned. And you'd have to be incompetent if you have access to set DNS records and you set them to RFC 1918 addresses.<p>Anyone have any theories on how this could happen?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38703876"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703876" href="https://news.ycombinator.com/vote?id=38703876&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>I'll go with Joseph Conrad on this one.<p>"It's only those who do nothing that make no mistakes, I suppose."</p><p>Now the persons that did it have some proof that they did something.</p><p>They will surely put some check in place because there should be another adage somewhere that says that you only learn to use the handrails after you fell in the stairs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703738"><td></td></tr>
                <tr id="38704144"><td></td></tr>
                  <tr id="38703375"><td></td></tr>
                <tr id="38703870"><td></td></tr>
                        <tr id="38703523"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703523" href="https://news.ycombinator.com/vote?id=38703523&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>that's what happens when you buy address space from the back of a van in the parking lot ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38702845"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38702845" href="https://news.ycombinator.com/vote?id=38702845&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I get it too, with .1.0 as well<pre><code>    Name: microsoft.com
    Address: 192.168.1.1

    Name: microsoft.com
    Address: 192.168.1.0
</code></pre>
"ooopsie!"</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703802"><td></td></tr>
                <tr id="38703895"><td></td></tr>
                        <tr id="38703179"><td></td></tr>
                <tr id="38703239"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703239" href="https://news.ycombinator.com/vote?id=38703239&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Potential timeouts for clients/workstations trying to reach microsoft.com.<p>Which entry is picked for use is generally random depending on the client.</p><p>Most systems will retry using another entry though on issues connecting through. That said, if you are on a network that is 192.168 based, trying to get to Microsoft.com may just send you to your local router!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703419"><td></td></tr>
                  <tr id="38703525"><td></td></tr>
            <tr id="38703773"><td></td></tr>
            <tr id="38703953"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703953" href="https://news.ycombinator.com/vote?id=38703953&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>So let me see if I understand. With this DNS record, if me or Windows tries to hit “microsoft.com” there’s a 1/7 chance it hit my router instead?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703965"><td></td></tr>
                  <tr id="38703705"><td></td></tr>
                <tr id="38703756"><td></td></tr>
                <tr id="38703834"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38703834" href="https://news.ycombinator.com/vote?id=38703834&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Do most DNS forwarders not block addresses that resolve to a local IP these days? I know dnsmasq does, and NextDNS too I think.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38704185"><td></td></tr>
            <tr id="38703969"><td></td></tr>
                <tr id="38704067"><td></td></tr>
                        <tr id="38704109"><td></td></tr>
                <tr id="38704149"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38704149" href="https://news.ycombinator.com/vote?id=38704149&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>They do: the updates are signed so our hypothetical spies would need to have a zero day in Authenticode or to have compromised the signing keys.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38703031"><td></td></tr>
            <tr id="38703826"><td></td></tr>
                <tr id="38703893"><td></td></tr>
                <tr id="38704064"><td></td></tr>
                <tr id="38704130"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38704130" href="https://news.ycombinator.com/vote?id=38704130&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Even if that is the case, if it is random, some section of DNS would send traffic to it. Maybe it was OK because most resolvers would ignore the local address on the list??</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38703958"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703958" href="https://news.ycombinator.com/vote?id=38703958&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>How the hell did that pass any sort of responsible review process at Microsoft?<p>Now Microsoft owns all your home networks, only like the default address on every home router out there...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704063"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38704063" href="https://news.ycombinator.com/vote?id=38704063&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>You have the danger of this backwards: this is a very bad security problem <i>for Microsoft</i>, and not a problem for people outside of MS (except to the extent that we're all indirectly reliant on MS being secure). Pointing a domain at an IP address does not give you any power over than IP address, and you can point a domain at anything you want.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704016"><td></td></tr>
            <tr id="38704040"><td></td></tr>
            <tr id="38704138"><td></td></tr>
            <tr id="38704039"><td></td></tr>
                  <tr id="38704015"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704015" href="https://news.ycombinator.com/vote?id=38704015&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Y'all, instead of the constant confirmed here. Just do an authoritative lookup.<p>dig +trace +short microsoft.com</p><p>NS a.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS b.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS c.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS d.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS e.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS f.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS g.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS h.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS i.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS j.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS k.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS l.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS m.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>RRSIG NS 8 0 518400 20240101050000 20231219040000 46780 . fG/YHtUJu3YMAm9Mlzzvp3xG4UCPG01aYNnlyF1HfAHdZpR+L88CVUcz NFHq9M45KjB7ZTlSFt2JvEyK/8FcavZLOthkXRREbJQswjLCbhiPQCbq tQLF+tKaNYUihqawCfjgZy1i5YwYjmphbjfzwoKo1POtepf0YCIcuLBi nQFw4Lr79O6cjyg6qlYnqaK6z4Xi5qt6ocohJafjs86LuuRo2WvmJ1IK k0ZUoAC6Qyjz4MVhqHMvQGdp7EnzjoL8Y9PTXeUuD6Ixp/Aklj2psLjD TZDPYN1q+zDd1giFyuwNRX9DG1zrxzN2lzQiLWmGKrzP3DvFWL1L2Ts1 FWjy/Q== from server 100.100.100.100 in 10 ms.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>A 20.112.250.133 from server 150.171.10.39 in 20 ms.</p><p>A 20.231.239.246 from server 150.171.10.39 in 20 ms.</p><p>A 20.76.201.171 from server 150.171.10.39 in 20 ms.</p><p>A 20.70.246.20 from server 150.171.10.39 in 20 ms.</p><p>A 20.236.44.162 from server 150.171.10.39 in 20 ms.</p><p>A 192.168.1.0 from server 150.171.10.39 in 20 ms.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704190"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38704190" href="https://news.ycombinator.com/vote?id=38704190&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Or from a bunch of dnses:<pre><code>  $ export srch="192.168.1.0"; echo "as of $(date '+%s';):"; for dns in 1.1.1.1 8.8.8.8 76.76.2.0 9.9.9.9 208.67.222.222 185.228.168.9 76.76.19.19 94.140.14.14; do dig @${dns} microsoft.com +short | grep "${srch}" &gt; /dev/null; if [  $? == 0  ]; then echo "${dns} still has ${srch} for microsoft.com"; else echo "${dns} no longer has ${srch} for microsoft.com"; fi; done
  as of 1703033639:
  1.1.1.1 still has 192.168.1.0 for microsoft.com
  8.8.8.8 still has 192.168.1.0 for microsoft.com
  76.76.2.0 still has 192.168.1.0 for microsoft.com
  9.9.9.9 still has 192.168.1.0 for microsoft.com
  208.67.222.222 still has 192.168.1.0 for microsoft.com
  185.228.168.9 still has 192.168.1.0 for microsoft.com
  76.76.19.19 still has 192.168.1.0 for microsoft.com
  94.140.14.14 still has 192.168.1.0 for microsoft.com
  $ pbpaste | sed 's;^;  ;' | pbcopy</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38703687"><td></td></tr>
                <tr id="38703952"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703952" href="https://news.ycombinator.com/vote?id=38703952&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Well in my case (and a lot of other people), 192.168.1.1 is the local address of my home router. So if I go to microsoft.com I have a 1 in 7 chance of getting my home router instead (if I ignore the certificate warning). Other random breakage will happen depending on what that local address is assigned to for you.<p>In theory this could be leveraged for hacking, but I think that would require setup in advance.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703740"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703740" href="https://news.ycombinator.com/vote?id=38703740&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Since 2 out of the 7 IPs are 192.168 (private ips), 2/7 visitors to microsoft.com will load the private ones assumign equal weight and not get the page to load.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703696"><td></td></tr>
                  <tr id="38703761"><td></td></tr>
                <tr id="38703793"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703793" href="https://news.ycombinator.com/vote?id=38703793&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Nah, if it's already reverted, they're good to go. A post-mortem with how something like that got through will definitely be on the table though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703964" href="https://news.ycombinator.com/vote?id=38703964&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I'm wondering how such a change would get "merged" in to begin with. I imagine even non-network engineers would get this huge itch having a large corporate contain a private IP in the changelist (I'm the non network engineer and can't really explain why it's bad. But it FEELS wrong and sometimes you at least need to use instinct to get another pair of eyes on something).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703975"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703975" href="https://news.ycombinator.com/vote?id=38703975&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I hope not. Failures are on a spectrum and this was unfortunate but probably not malicious. All things considered this should be a lesson learned. There should be more failsafe mechanisms in place so juniors can fail safely and learn from them. The absolute worst thing we can do is shame an individual so they don’t attempt to try new things in fear of ridicule.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703830"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703830" href="https://news.ycombinator.com/vote?id=38703830&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>The seniors all go on leave and the interns are left to run the place. If they fired the juniors the seniors would have to come back from holiday!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38703730"><td></td></tr>
            <tr id="38703118"><td></td></tr>
            <tr id="38702823"><td></td></tr>
            <tr id="38703700"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703700" href="https://news.ycombinator.com/vote?id=38703700&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I don’t know man, putting microsoft.com on your router sounds like a massive reduction in latency. Congrats on the achievement.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38702903"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Closing of the Bulgarian Frontier (122 pts)]]></title>
            <link>https://www.switchyardmag.com/issue-1/bulgarianfrontier</link>
            <guid>38702276</guid>
            <pubDate>Tue, 19 Dec 2023 21:59:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.switchyardmag.com/issue-1/bulgarianfrontier">https://www.switchyardmag.com/issue-1/bulgarianfrontier</a>, See on <a href="https://news.ycombinator.com/item?id=38702276">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="6529e1a1ecc7e60d996474cc">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="light" data-section-id="6529e1a1ecc7e60d996474ce" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;sectionTheme&quot;: &quot;light&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-basic-grid&quot;
}" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-652e0d3fd11d3d0e62042dcc"><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-a7d7db2923ae332d9afa">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg" width="2400" height="1600" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-2244ed8deedcf9bff2db">
  <p><strong>Essay by Dimiter Kenarov</strong></p><h4><em>All illustrations featured in this essay are part of the Bulgarian Visual Archive, a digital project that curates thousands of found and donated photographs. BVA aims to narrate the history of 20th-century Bulgaria through the visual record of both private and public events that have usually been pushed to the margins of official narratives. As part of its mission, BVA offers all of its photographs for download free of charge, for both personal and commercial purposes.</em></h4>
</div><div data-block-type="2" id="block-5d1f1296bc3b4679c365">
  <p><span data-text-attribute-id="af3819f5-11a4-463c-bba6-a306b093c33a">As the plane began its final approach to the Sofia airport, I leaned to look out the porthole. Gray fields and mangy patches of overgrown post-industrial wasteland lay scattered outside the city.</span></p><h4>Next came the monolithic mazes of Communist-era apartment blocks—blocks I had grown up in—followed by older jumbles of red-tiled roofs and, scattered in between, free-standing clusters of freshly built condos and office towers. Downtown, along Sofia’s famed yellow cobblestones (“the yellow-brick road,” as English-language tour guides jauntily refer to it) rested the triangular Stalinist behemoth of “The Party House,” the former headquarters of the Bulgarian Communist Party, now topped by the country’s tricolor instead of its original red star. The spot nearby, where the cube-shaped mausoleum of Georgi Dimitrov (“the Great Leader and Teacher of the Bulgarian people”) had once stood, was now a flat, empty lot, an oversize Malevich square. Tsarigradsko shose, previously known as Lenin Boulevard, was choked with traffic. Though everything appeared disorderly from above, it was exactly what I was looking for: a sense of things happening, a sense of time changing, a new frontier.</h4><h4>It was the end of 2010, and I had decided to move back to my native Bulgaria. I’d spent more than a decade in the United States, getting an education and putting a life together, and had never imagined I’d be retracing my steps eastward someday, like a criminal revisiting a crime scene. Some people considered you a failure if you came back; they said you lacked ambition and inner resources to stick it out. If you were lucky enough to get away, why throw your luck to the dogs? Wasn’t it better to settle down in a “normal” place, where buses ran on time and you didn’t need to bribe every traffic cop who pulled you over? It was perfectly fine to visit your relatives for a week over Christmas or to sprawl during the summer on the beaches of the Black Sea, splurging hard-earned cash to make the neighbors envious, but to return home for good, unforced by circumstances, bordered on madness. It was irrational, irresponsible, and possibly suicidal. The imp of the perverse. You never looked over your shoulder, lest you turn into a pillar of salt.</h4><h4>It was, admittedly, a strange decision on my part. I wasn’t unhappy abroad or nostalgic for home. I didn’t have trouble adjusting to the trappings of my adopted country. I was neither a desperate war refugee with only the clothes on my back, nor a political exile constantly complaining about the tastelessness of local cuisine. The concept of “culture shock” that people tended to talk so much about was foreign to me. I’d gone to the States after graduating high school in Sofia to attend on a scholarship a small liberal arts college in Vermont and, later, a graduate program in California, and had never had issues fitting in. Mine was the American dream, I suppose, the one that promised you could be nobody and thus anybody. Like Huck Finn, I felt free to “light out for the Territory,” unburdened by my history and culture, even by my language, and by all the parochial concepts of identity I had been raised on.&nbsp;</h4>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-5c5b934440d252ce549a">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg" data-image-dimensions="1600x2400" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg" width="1600" height="2400" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-485d8bfe18377d7385f7">

<p>
  <h4>As the years wore on, however, I came to make another discovery: I was late to the party. I had traveled to the westernmost frontier of the Western world, but the frontier had long since ceased being one. My dream was dated, even clichéd. The States felt like an old place, weirdly older than Europe, a place where, for all its breathless movement, time seemed to have stopped. There was too much of everything: rules, work, wealth, poverty, guns, art. Somehow, over the years, the machine had become overly complex, the foundations slowly but inexorably sinking under the weight of its ever-growing bulk. Even the road to self-renewal and originality, the road less traveled by, was now well-trodden, part of a tired discourse endlessly advertised and monetized and absorbed within a system of capital. The celebrated American self had become another commodity on the shelf of the cultural supermarket. To go to the woods “to live deliberately,” like Henry David Thoreau had done, now required submitting a twenty-page application for a research grant and at least three recommendations.</h4><h4>That was when an idea occurred to me: What if I moved back? Wasn’t Bulgaria, in all of its dinginess and provincialism and unpredictability, exactly the kind of frontier I was looking to explore, where the clock was still ticking forward toward some unknown horizon? After all, the world is round and if you travel west of “the West” you’d eventually bump into “the East.” To abandon my peaceful but mostly prospectless academic life in the States in order to plunge into the cesspool of my homeland was a bit of a gamble, but also, I thought, the most American thing I could do. I liked what the poet T. S. Eliot had written: “the end of all our exploring / Will be to arrive where we started / And know the place for the first time.” It was the classic narrative arc of journeys at least since <em>The Odyssey</em>. Could it be, I mused, that real freedom resided not in the freedom to leave but in the freedom to return?</h4><h4><strong>• • • •</strong></h4><h4>I was born<strong> </strong>in Sofia, the capital of what was still then the People’s Republic of Bulgaria, in 1981—eight years before the collapse of the country’s Communist regime. My childhood memories of that period are fragmentary and uneventful, nothing outlandishly totalitarian to titillate the imagination. Maybe I wasn’t old enough to serve as a witness or maybe the system was already too exhausted to care about propagating its genes in my generation, the last one to grow up under its tutelage, and my brush with the ideology of the day was rather innocuous, bland even. When I started school, I received my Young Pioneer’s blue neckerchief (the red one was reserved for older kids) and publicly swore allegiance to the organization’s flag; I had to learn a poem by heart about the first cosmonaut Yuri Gagarin (“Yuri Gagarin, how did you fly? / Was it fast, your rocket ship white?”); I read a celebrated Soviet novel <em>Timur and His Squad</em> about a gang of children secretly doing good deeds and another, a Bulgarian one, about Mitko Palaluzov, a young boy in the country’s Communist underground (the partisans) during the Second World War who died tragically. Other than that, nobody cared much about my proper political education. We did visit once on a school field trip the mausoleum of Georgi Dimitrov, where the mummified body of Bulgaria’s first Communist prime minister was laid out in a funeral chamber, yet that seemed more like an adventure than pilgrimage. Lit up by ghostly lights in his glass sarcophagus, Comrade Dimitrov was lying peacefully there, his head slightly propped up on a pillow, like Snow White. Even the idols of the past were now nothing more than characters in a cheap, fairytale diorama.&nbsp;</h4><h4>At that time, in the 1980s, my family and I were residing in a tower block in Student Town, a neighborhood on the outskirts of Sofia designed to function as a large, centralized campus. My parents had arrived in the capital from the provinces to attend university and, after graduating, had married and decided to stay on: my father working as an anesthesiologist at a large hospital and my mother as a computer programmer in Bulgaria’s nascent IT sector. Since neither of them had official Sofia residency yet (a prerequisite to remain in the city), living in a dormitory was their only available option.&nbsp;</h4>
</p>




















  
  



</div><div data-block-type="2" id="block-105c9347a29ffdced4ec">

<p>
  <h4>Student Town was still in the early stages of development, and its few academic and residential buildings were surrounded by wild fields, where one could still occasionally encounter flocks of sheep. Yet this seemingly pastoral, marginal corner of Sofia was its most cosmopolitan: young men and women from all over the post-colonial socialist world—Vietnam, Syria, Cuba, Egypt, Ethiopia, Mozambique, Congo-Brazzaville—had relocated to Bulgaria to get their university degrees and strengthen the bonds of internationalism. Some had brought their kids along, who played with us Bulgarians. It was a glorious time, the way childhood is often glorious, regardless of skin color or political systems. Most days we were busy exploring the meandering footpaths branching out of our respective dorms or doodling in student notebooks left unguarded in one of the common reading rooms. Our favorite activity, however, was sailing on a makeshift raft of Styrofoam in an enormous ditch filled with rainwater close to the Karl Marx Institute of Economics. &nbsp;</h4><h4>We kids had no idea how or when or why that ditch had been dug, but its size—roughly 500 meters long and 20 meters across, if memory serves me right—fascinated us, like the mysterious remnants of a lost civilization. Years later, I found out that we’d actually played in what had been part of a defunct Communist-era mega-project informally known as “the Sofia Sea,” which had envisioned a network of navigable canals, connecting to the Danube, 150 kilometers to the north, and from there to the Black Sea and the rest of the world. The plan had been first conceived by Party bureaucrats in the early 1950s, probably drawing inspiration from Stalin’s famous call for “the great transformation of nature,” which encouraged radical human interventions in the form of land management and waterworks construction. Sofia was landlocked and hemmed on all sides by mountains, but so what? Shouldn’t Communism dream big? If Moscow had its Moscow River, why couldn’t Sofia have its Sofia Sea?&nbsp;</h4><h4>With neither sufficient labor force nor adequate machinery for an undertaking on this scale, the Bulgarian regime had decided to look for “volunteers” among Sofia’s own residents. Equipped with only shovels and pickaxes, factory workers and secretaries and doctors and engineers toiled on weekends and holidays in the canals over a period of several years. Jokes abounded about breeding crocodiles there some day and repurposing shovels as oars. If somebody was late to work, they’d explain to their boss with a smile that they had waited for the ship, but it had never arrived and they’d been forced to walk. Finally, in the mid-1960s, a few level-headed experts determined that completing the project could cause mass flooding in the city. A decision was made to discontinue digging… and commence burying. The latter job had never been properly completed either and that was how, two decades later, a few kids from all over the world got to sail on a makeshift raft of Styrofoam in an enormous ditch filled with rainwater. Without ever intending to—strange are the ways of history—we had realized the unfulfilled Communist dream of “the Sofia Sea.”</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-c06dc45a8033dd58a4bd">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-0a7e132aa5fee0506960">

<p>
  <h4>Seen in retrospect, that dug-and-buried network of canals was perhaps something of a metaphor for the general state of affairs at the time, of what had happened to the system. Like elsewhere in Eastern and Central Europe, the Communists had taken over the government of my home country in a Soviet-backed coup at the end of the Second World War with the professed idea of radically transforming society and politics on Marxist terms, but following the initial “revolutionary” period, the regime’s grand ambitions had to be methodically scaled down. Certainly, there were still endless bromides about building “the bright future,” when bread would be free (supposedly by the year 2000) and social class would disappear and the means of production would have no single owner (Engels’s “withering away of the state”). There were monumental Party congresses full of mind-numbing speeches about fulfilling in four years the next five-year economic plan, about the higher (always higher) production of wheat and eggs and pork, about the ever-better material conditions of the people and their improving access to consumer goods, but even the staunchest believers were already aware all of that was just a charade, going through the motions. Sailing in Sofia would never be possible, and it was wiser to bury the evidence of the effort.&nbsp;</h4><h4>By the early 1970s, Bulgaria, like Brezhnev’s Soviet Union and the rest of the Soviet Bloc, was stuck in “stagnation”—or “real socialism,” as local ideologues preferred to call it euphemistically. Gradually, the country was transforming into a quiet and somewhat boring totalitarian backwater, drab but not poor, politically oppressive but not excessively bloodthirsty, not anymore. The vast majority of citizens went to work, shopped for whatever scarce items were available at the stores, got married, raised kids, saved money to furnish their modest apartments and houses, went to restaurants on special occasions, to the movies or the theater on weekends, took annual vacations at one of Black Sea resorts or somewhere in the mountains. Marxism continued to be the state religion, and you went along with its rituals, the way people in the West still went to church, but nobody had any faith left. Worse, nobody could see a future, a social horizon, especially after the violent suppression of the Prague Spring, the last genuine revolution in the region. Communism had always relied on teleology for its existence, but now the frontier had been closed. It was as if time itself had stopped moving forward and had entered a cyclical almost medieval agricultural pattern: winter, spring, summer, autumn; winter, spring, summer, autumn; 10th Congress of the Party, 11th Congress of the Party, 12th Congress of the Party, 13th Congress of the Party.&nbsp;</h4><h4>Perhaps that was why the Communist regimes all across Eastern and Central Europe collapsed in the final run. Not so much because of their beleaguered economies, although that was an important factor, but because no one believed anymore. Life is always transitory, a ceaseless metamorphosis, and when the possibility of change disappears, when the frontiers disappear and times turns cyclical, a process of decay inevitably sets in.</h4><h4><strong>• • • •</strong></h4><h4>It was the<strong> </strong>best of times, it was the worst of times, a feast in a time of plague, a carnival ride amid carnage. Even to this day, more than thirty years later, it’s hard for me to explain coherently what happened in Bulgaria immediately after “the changes” of 1989. It seems like something out of a dream, scraps of images and phrases and music and emotions jumbled together, a kind of bottled up energy suddenly released into the open. This wasn’t the end of history, as Francis Fukuyama had suggested, but its opposite, the rusty arms of the clock grinding into gear once again, the train departing its rural station after years of delay. Time sped up so abruptly—a bullet train—it made many of the passengers on board dizzy.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-492ba006d29df9fe5028">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-f1d30bfd24c50801aa73">

<p>
  <h4>“De-mo-cra-cy,” shouted people everywhere in the squares, waving flags and holding up placards. <br> I remember the initial joy and hope that the nightmare of the past was over and better times awaited ahead. No more single-party rule with dimwitted men at the helm, no more Soviet control, no more mass surveillance and secret files, no more political prisoners, no more censorship, no more mindless ideological garbage, no more planned and wasteful economy, no more Party privileges and corruption, no more one type of everything (or nothing) in the stores, no more waiting for ten years to buy a car, no more denied passports and closed borders, no more grayness, no more human indignities. It was a naive and idealistic vision perhaps, but no less real for that. For 45 years, Bulgarians had been kept in a huge high-security prison, the size of a country, only occasionally allowed a glimpse through the iron bars, and isolation of that length tends to inflame the imagination. When the mind is not allowed to wander out, it naturally goes in, deeper into fantasy. Overheard stories of life on the other side, in “the free world,” take on the quality of fairy tales, of myth—and myth is always bound to prove a disappointment at the end.</h4><h4>What happened in Bulgaria during the 1990s was what happened in so many other places across Eastern and Central Europe. Prepared and well-positioned, members of the former Communist Party elite managed the whole transformation of the system from the inside, privatizing, so to speak, their own state power. Behind the suave rhetoric of democracy and freedom, they were busily transferring public funds into their personal accounts, creating companies and mafia conglomerates. The highly repressive functions of the totalitarian machinery disappeared, but money was no worse an instrument of control, perhaps even a better one because more refined and insidious.&nbsp;</h4><h4>At the same time, the sudden shift to a market economy tanked the country’s long-suffering industries. Obsolete factories churning out obsolete commodities couldn’t survive the global competition for long, and many of them had to shut down for good, leaving thousands of workers unemployed and unemployable. A large portion of Bulgaria’s residents lost their life savings to hyperinflation or were cheated out of them by pyramid schemes. It was not uncommon to see engineers driving taxis or pensioners with doctorates sifting through battered dumpsters. At night, Sofia was shrouded in sepulchral darkness and the few street lamps that glowed appeared to absorb, rather than give off light. Store shelves were often empty—even emptier than before—and for a while the government had to introduce ration cards for food staples, just like in wartime. I remember how my father would get up at four in the morning to stand in line for bread and milk or how my mother blacked out once waiting to buy a half-pack of detergent. There were constant electric outages, and we’d have dinner by the flicker of candlelight in our new prefab apartment in Sofia’s Nadezhda quarter. We had no central heating installed yet, so in the winter all of us slept with our clothes on.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-3e90d945f39836f2b8f3">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg" data-image-dimensions="1600x1102" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg" width="1600" height="1102" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-8c30390d270fedd5f0b4">

<p>
  <h4>In spite of all the economic hardship and rampant crime, in my memory the 1990s stand out as a glorious, sublime era. In the immediate wake of “the changes,” Bulgarians felt a rush of excitement for the future: participating in politics, publishing independent newspapers, creating provocative art, starting private businesses. My mother left her state job (she’d had a leading role in developing Bulgaria’s first information system for traffic control) to run the risk-assessment and anti-fraud management system of a large French bank; my father was promoted, at age 38, to medical director of his hospital. My paternal grandparents transformed their garage in a provincial town into a general store, while my maternal ones started a rabbit farm on the premises of their village property. Almost everybody, regardless of age, wanted to do something bold with their newfound freedom, to risk and experiment. It was like living in a frontier settlement, but where the frontier was not defined by the movement across physical borders, but across social and personal ones. There was, to quote the classic theoretician of the American frontier Frederick Jackson Turner, “coarseness and strength combined with acuteness and inquisitiveness; that practical, inventive turn of mind, quick to find expedients; that masterful grasp of material things, lacking in the artistic but powerful to effect great ends; that restless, nervous energy; that dominant individualism, working for good and for evil, and withal that buoyancy and exuberance which comes with freedom.”</h4><h4>As I entered my teenage years, I came to encounter everything that had been previously censored or just in scarce supply: loud music, experimental art, porn, drugs. There were no rules to adhere to anymore. Nobody made boys cut their hair if it was too long or rubber-stamped girls’ thighs if their skirts were too short, as had been common practice in schools. I didn’t care much about long hair, but I dyed mine green, then blue, then purple. I got into freestyle snowboarding and punk rock. You could wear anything you fancied, tight or baggy or skimpy, and get as many piercings and tattoos as your body could possibly hold. Listening to the Beatles—tame, unoffending Beatles—had once been semi-illicit, akin to dissidence, and passing their records around had gotten not a few hot heads into trouble. Under the new system, record stores began to openly pirate and sell any music available, from the Sex Pistols to Cannibal Corpse. Theaters, shaking off the conservative, parochial mores of the Party, would put on radical performances by Beckett and Ionesco, Jean Genet and Heiner Müller, Sarah Kane and Eve Ensler, naked actors sometimes roaming the stage or just ranting in a delirium. Literature followed suit, plunging into postmodern irony and games, throwing off the bondage of the past. It was marvelous.&nbsp;</h4><h4>Even the mausoleum of Georgi Dimitrov, the mummy now removed and safely cremated, took on a life of its own: explicit graffiti covered the limestone walls, the doors swung wide open for staggering drunks who needed a place to relieve themselves; skateboarders rode around, doing kickflips and nose grinds on the decorative curbs; an American evangelical pastor, intent on saving the souls of former commies, organized a revival meeting in the square facing the relic, with thousands of people crowding the viewing stands where members of the Politburo had once greeted the parading masses—“God is healing you now! In the name of Jesus! Hallelujah!” he shouted while laying hands on the faithful to cast out their demons, perhaps the demons of the past; in 1996, when the movie&nbsp;<em>101 Dalmatians</em>&nbsp;came out, some PR brain made the brilliant decision to rent the mausoleum as advertising space and cover its white exterior in huge black spots; the next year, an impressive production of Verdi’s&nbsp;<em>Aida</em>&nbsp;used the edifice as a set. The mausoleum was eventually—and sadly—removed in 1999 by anti-Communist political crusaders, but even its act of demolition became a sort of artistic performance: it took several attempts to blow it up, spectators laughing and cracking jokes at each unsuccessful blast, until a decision was made to take it apart bit by bit.</h4>
</p>




















  
  



</div><div data-block-type="2" id="block-e2e073f3966ba54c0938">

<p>
  <h4>Meanwhile, the party (non-Communist) scene exploded as well. Hundreds of bars and nightclubs set up shop in recently privatized facilities—community centers, abandoned swimming pools, movie theaters—where cheap booze flowed to the sound of pop-folk beats and the eye-popping beams of strobe lights and glitter balls. Bacchanalian crowds, dressed up in the most outrageous fashion, danced to rave beats through the night. The first gay establishments gingerly tested the ground too, hidden away in dingy, smoke-filled basements, where one had to press a secret doorbell to gain entry—still secretive but no longer illegal. There were even “children’s discotheques,” ostensibly safe party spaces for the underage, but which frequently turned raucous, with 14-year-olds downing vodkas and throwing up in the toilets. As for marijuana, it was available to anybody who wanted it. It was so cheap you could buy whole bags for a pittance, as my friends and I did. When that proved insufficient, there was Ecstasy and benzos, uppers and downers, as well as grandma’s Parkinson’s medication that gave you amazing hallucinations. The most reckless turned to heroin, but that was a whole different game, where many tragically lost their footing.&nbsp;</h4><h4>This newfangled liberty could be dangerous of course, deadly even, yet danger also made up part of the excitement. As Hunter S. Thompson wrote about the counterculture moment in San Francisco, “No explanation, no mix of words or music or memories can touch that sense of knowing that you were there and alive in that corner of time and the world.” The 1990s were truly Bulgaria’s 1960s, the period when the frontiers opened and time started moving forward again. A belated revolution.&nbsp;</h4><h4><strong>• • • •</strong>	</h4><h4>When I returned<strong> </strong>to Bulgaria in 2010, the country was already officially part of the European Union. The chaos of those early post-Communist years had subsided quite a bit, crime rates had gone down, and Sofia looked dapper, the parks spruced up and the streets cleaner. There was a huge range of restaurants and bars with exotic menus, name-brand stores and shopping malls, where one could hit the gym or the ice-skating rink after watching a blockbuster movie. The local IT sector was booming, co-working spaces were popular, hipsters roamed the art galleries and fancy cafes, and budget flights landed several times a day from all over Europe. Outside of the city center, the old Communist-era apartment blocks looked as bleak as always and, if you traveled a short distance beyond the capital, you immediately encountered poverty and desperation, but at least among a certain urban class of Bulgarians (to which I also belong), the promises of market liberalism and democracy were bearing fruit. &nbsp;</h4><h4>In the years that followed, I dived into the local scene with enthusiasm, without any regret for having left the States. I had never really believed in the idea of home, I had always been something of a vagrant—“a rootless cosmopolitan,” in the dismissive phrase of Stalin—yet returning to my native place, seeing it afresh, gave me enormous pleasure. Plus, there was so much still to be done, so much open space. I had already started working as a freelance journalist for US media, writing long-form features from the region, and I had a whole list of interesting topics I began to tackle as both an insider and outsider: hot political and cultural issues, social and environmental problems, the burden of the totalitarian past.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-71cfa9276acea6ff2ea4">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-49252d08bca699a921fe">

<p>
  <h4>Even so, the longer I remained in Bulgaria and the region, the more I was haunted by the uncomfortable feeling that a frontier was closing once again. Residual energy from the 1990s still hung in the air, a desire for experimentation still bubbled on the fringes, as the influx of EU capital had not completely smothered creative disorder—the most essential of life conditions—but I could already see clouds gathering somewhere in the distance. A lot of Bulgarians were certainly better off since “the changes,” or at least they could afford to buy more commodities and travel abroad as they wished, but they had become tired, more apathetic, less imaginative, their dreams smaller. Maybe that was the fate of any revolution: after the initial bang, there’s a natural period of calm, a dust-settling. The body can’t always live on the edge, in a whirlwind of adrenalin—it’s much too exhausting. There is a time for everything, as the prophet tells us: a time to scatter stones and a time to gather them, a time to tear and a time to mend, a time for war and a time for peace.&nbsp;</h4><h4>There was an uncomfortable paradox though: the more life organized, the more it settled into a routine; the more affluent and peaceful society became, the better paved the roads and the fancier the cars, the more normal and orderly the days—I suppose the public ideals journalism indirectly fights for—the fewer possibilities glimmered on the horizon. As civilization tamed the wilderness—to use an antiquated and controversial but in this case perhaps not wholly irrelevant metaphor—something intangible was lost: a spirit, perhaps, or an aspiration it’s difficult to put my finger on. For all its numerous faults, the 1990s had sparked one of those utopian visions of building a new world atop the ashes of the old, as Communism had once done.&nbsp;</h4><h4>Next came the bureaucratic goal of joining the European Union—“the civilized world,” in the lingo of politicians—which a vast majority of Bulgarians felt enthusiastic about. When that was finally achieved, however, grand, inspirational ideas for the future seemed to gradually peter out. Occasional crises like migration, environmental issues, the need for judicial reform, and the rampant political corruption kept Facebook filled with outrage and the media pundits occupied, but those usually melted into oblivion with the next news cycle. What should Bulgarians strive for next? What should they look forward to? Consumer society offered one solution, of course—a new TV, a new smartphone, a new car, a new apartment—but that could be only a temporary fix, for even the acquisition of new objects grows old in the end.</h4><h4>&nbsp;<strong>• • • •</strong></h4><h4>Have I been<strong> </strong>late again, I often ask myself when I think about my return to Bulgaria a decade ago, the frontier more or less tamed by the time I had arrived? Or is this just the way of the world, the order of things? Or is it my constant craving for novelty and excitement, the specific chemistry of my brain that has distorted my expectations and made me project my unresolved psychological drives onto the social and political canvas? Or is there, indeed, some general malaise that imbues our current moment, a common feeling of a dead end?&nbsp;</h4><h4>It’s a conundrum impossible to resolve. Yet, faced with it, I recall Thomas Mann’s <em>The Magic Mountain</em>, one of the greatest novels on the subject of time. Its protagonist Hans Castorp goes to pay what is supposed to be just a short visit to his ailing cousin at a TB sanatorium in the mountains of Switzerland, but for a variety of reasons (illness, love, love as illness) he ends up staying for seven years. Initially, everything is new to him, so packed with remarkable encounters and incidents, thoughts and impressions, that the duration of time stretches out and each day feels like weeks. As the weeks turn into months and the months into years, however, as his mind becomes habituated to its environment, as routine sets in and morphs into endless repetition, time quickens its pace and blurs to such a degree that its passing becomes almost imperceptible to the senses and, for all intents and purposes, it ceases to exist. And here is Mann himself on the issue:</h4><h4>For the moment we need to recall the swift flight of time—even of a quite considerable period of time—which we spend in bed when we are ill. All the days are nothing but the same day repeating itself—or rather, since it is always the same day, it is incorrect to speak of repetition; a continuous present, an identity, an everlastingness—such words as these would better convey the idea. They bring you your midday broth as they brought it yesterday and will bring it tomorrow; and it comes over you—but whence or how you do not know, it makes you quite giddy to see the broth coming in—that you’re losing a sense of the demarcation of time, that its units are running together, disappearing; and what is being revealed to you as the true content of time is merely a dimensionless present in which they eternally bring you the broth.</h4><h4>Ay, there’s the rub: the broth. Maybe I’m imagining this, but it seems that all of us—in Bulgaria, in the rest of Europe, in the United States—are lying sick in our beds while somebody is bringing us the same broth over and over again. For the closing of frontiers is not simply a spatial issue, but a temporal one as well, as space and time are, of course, interrelated. Like Communism, capitalism is a teleological system at its root, relying on a narrative of progress, on a forward-moving vector of time, but when that time turns cyclical, repetitive, without a clear direction, the system begins to disintegrate, not under the weight of its own contradictions, as Marx would tell us, but under the weight of its own uniformity. The recent coronavirus epidemic, which measured itself in seasons—winter spikes followed by summer lows—only made that condition legible. But social media too, with the essentially cyclical nature of its feeds, with its intermittent flows of information that blur into non-information, has deepened the sensation that one is wasting away in the prison of timelessness. We’re often told that we live in the most dynamic period in human history, where change—political, economic, technological—happens on a nearly daily basis. That is true on the physical level, of course, but the psychological optics are rather different. Like a wheel that spins so fast that its spokes appear stationary or moving backwards even (the so-called wagon-wheel effect), the fast rate of transformation has come to feel like stasis. Hurtling toward a black hole, we seem to be endlessly stuck, horizonless, in the event horizon.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-ea50f4110486adad3f50">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-b9e71e23da5a8285e73a">

<p>
  <h4>Today, we have become citizens of a global, Brezhnevian capitalist state, which, in its failure to provide an inspiring frontier—gone are the days of Kennedy’s “New Frontiers” or Obama’s “Change We Can Believe In”—has slowly ossified and wrapped back upon itself. My feeling is that all the troubles we’ve been witnessing over the last decade—Trumpism, Brexit, the rise of nationalism all over Europe, Russia’s virulent imperialism—are attempts to disrupt not just the dominant political systems, but the zone of eternal repetition. In most cases, these attempts are ridiculous, ersatz, misguided imitations of ideologies borrowed from the past, exposing their own imaginative shortages—they aspire to move the hands of the clock, even if backwards—but it’s hard to deny they represent dissatisfaction and resentment with the way things are. There is, it seems to me, a subconscious craving to be taken out of the boredom of timelessness and be thrown back into the flux of time, even if that means violence or war—anything but the broth! When even travel to exotic places (or to a sanatorium in Switzerland) fails to rejuvenate the perception of time and becomes just one more lifeless landscape on Instagram, desperation takes hold of the mind. Or perhaps it’s an irrational impulse, the old human perversity in action, which Dostoyevsky describes so terrifyingly well in his <em>Notes from the Underground</em>: “Shower upon him every earthly blessing… give him economic prosperity, such that he should have nothing else to do but sleep, eat cakes and busy himself with the continuation of his species, and even then out of sheer ingratitude, sheer spite, man would play you some nasty trick. He would even risk his cakes and would deliberately desire the most fatal rubbish… simply to introduce into all this positive good sense his fatal fantastic element.”</h4><h4>A few months before Russia attacked Ukraine, I was at a residence in Vienna, where a Ukrainian friend told me that his country was the only one in Europe that still unreservedly believed in the European Union and the Western liberal-democratic project, that, if the EU took Ukraine on board, it would expand not only its geographic frontiers but renew its sense of purpose as well. I think the war, for all its terrible human toll, or because of it, has largely proven him right. Ukraine has turned into a rallying call for much of Europe, a vicarious way (dangerous, but not too dangerous) to experience once again the forward vector of time. How long that momentum is going to last, however, is impossible to know—just as it’s impossible to know what the future holds for Bulgaria, or for myself for that matter. Perhaps it’s artificial intelligence that would help us glimpse that new frontier, though I’m afraid it will only deepen our current problems: vision requires more than a large language model, more than the expert recombination of the knowledge we already have. For vision is something that I believe only humans possess: a dream of that sea there, beyond the horizon. A belief.</h4>
</p>




















  
  



</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Linux graphics stack in a nutshell (234 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/</link>
            <guid>38702271</guid>
            <pubDate>Tue, 19 Dec 2023 21:59:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/">https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/</a>, See on <a href="https://news.ycombinator.com/item?id=38702271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-none,v 1.2 2005-11-04 22:11:18 corbet Exp $ -->
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
Linux graphics developers often speak of <em>modern</em> Linux graphics
when they refer to  a number of individual software components and how they
interact 
with each other.
Among other things, it's a mix of kernel-managed display resources, 
Wayland for compositing, accelerated 3D rendering, and decidedly not X11.
In a two-part series, we will take a fast-paced journey
through the graphics code to see how it converts application data
to pixel data and displays it on the screen. In this installment, we look
at application rendering, Mesa internals, and the
necessary kernel features.
</p>

<h4>
Application rendering
</h4>

<p>
Graphics output starts in the application, which processes and
stores formatted data that is to be visualized.
The common data structure for visualization is the
<a href="https://en.wikipedia.org/wiki/Scene_graph">scene graph</a>, which
is 
a tree where each node stores either a model in 3D space or its
attributes. Model nodes contain the data to be visualized, such as a
game's scenery or elements of a scientific simulation. Attribute
nodes set the orientation or location of the models. Each attribute
node applies to the nodes below. To render its scene graph into an
on-screen image, an application walks the tree from top to
bottom and left to right, sets or clears the attributes and renders
the 3D models accordingly.
</p>

<p>
In the example scene graph shown below, rendering starts at the root node,
which prepares the renderer and sets the output location. The application
first takes the branch to the left and renders "Rectangle&nbsp;1" at
position (0,&nbsp;0) with the surface pattern stored in texture&nbsp;1.
The application then moves back to the root node 
and takes the branch to the right where it enters the attribute node named
"Transform". Applications describe transformations, 
such as positioning or scaling, in&nbsp;4x4 matrices that the algorithm
applies during 
the rendering process. In the example, the transform node
scales all of its child nodes by a factor of&nbsp;0.5. So rendering
"Rectangle&nbsp;2" 
and "Rectangle&nbsp;3" displays them at half their original sizes, with their
positions adjusted to (10,&nbsp;10) and (15,&nbsp;15), respectively. Both
rectangles
use different textures:&nbsp;2 and&nbsp;3, respectively.
</p>

<blockquote>
<img src="https://static.lwn.net/images/2023/scenegraph.png" alt="[Scene graph]" title="Scene graph">
</blockquote>


<p>
To simplify rendering and make use of hardware acceleration, most
applications utilize one of the standard APIs, such as
<a href="https://opengl.org/">OpenGL</a>
or
<a href="https://vulkan.org/">Vulkan</a>.
Details vary among the individual APIs, but each provides interfaces
to manage graphics memory, fill it with data, and render the
stored information. The result is an image that the application can
either display as-is or use as input data to further processing.
</p>

<p>
All graphics data is held in buffer objects, each of which is a
range of graphics memory with a handle or ID attached. For example,
each 3D model is stored in a
<a href="https://en.wikipedia.org/wiki/Vertex_buffer_object">vertex-buffer object</a>,
each texture is stored in a <a href="https://www.khronos.org/opengl/wiki/Texture">texture-buffer object</a>, each object's <a href="https://en.wikipedia.org/wiki/Normal_(geometry)">surface
normals</a> are stored in a buffer object, and so on. The output image
is itself <a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">stored in a buffer object</a>. So graphics rendering is, in large
part, an exercise in memory management.
</p>

<p>
The application can provide input data in any format, as long as
the graphics shader can process it. A
<a href="https://en.wikipedia.org/wiki/Shader">shader</a>
is a program that contains the instructions to transform the input
data into an output image. It is provided by the application and executed by the
graphics card.
</p>

<p>
Real-world shader programs can implement
complex, multi-pass algorithms, but for this example we break it
down to the minimum required. Probably the two most common operations
in shaders are vertex transformations and texture lookups. We can think
of a vertex as a corner of a polygon. Written in
<a href="https://www.khronos.org/opengl/wiki/OpenGL_Shading_Language">OpenGL
Shading Language</a> (GLSL),
transforming a vertex looks like this:
</p>

<pre>    uniform mat4 Matrix; // same for all of a rectangles's vertices
    in vec4 inVertexCoord; // contains a different vertex coordinate on each invocation

    gl_Position = Matrix * inVertexCoord;
</pre>


<p>
The variable <tt>inVertexCoord</tt> is an input coordinate coming from the
application's scene graph. The variable <tt>gl_Position</tt>
is the coordinate within the application's output buffer. In broad terms,
the former coordinate is within the displayed scenery, while the latter is
within the application window.
<tt>Matrix</tt> is the&nbsp;4x4 matrix that describes the transformation between
the two coordinate systems. This shader operation runs for each vertex in
the scene graph. In the example of the application's scene graph of
rectangles above, <tt>inVertexCoord</tt> contains each vertex of each rectangle
at least once. The matrix <tt>Matrix</tt> then contains that vertex's
transformation, such as moving it to the correct position or scaling it by
the factor of&nbsp;0.5 as specified in the transform node.
</p>

<p>
Once the vertices are transformed to the output coordinate system, the
shader program computes the values of the covered "fragments",
which is graphics jargon for an output pixel with a depth value along the Z
axis and
maybe other information. Each fragment requires a color. In GLSL, the
shader's <tt>texture()</tt> function retrieves the color from a texture
like this:
</p>

<pre>    uniform sampler2D Tex; // the texture object of the current rectangle
    in vec2 vsTexCoord; // interpolated texture coordinate for the fragment

    Color = texture(Tex, vsTexCoord);
</pre>


<p>
Here, <tt>Tex</tt> represents a texture buffer. The value <tt>vsTexCoord</tt>
is the texture coordinate; the position where to read within the texture.
Using both values, <tt>texture()</tt> returns a
color value. Assigning it to <tt>Color</tt> writes a colored pixel to the
output buffer. To fill the output buffer with pixel data, this shader code runs
for each individual fragment. The texture buffer is designated by the model
that is being drawn, the texture coordinate is provided by OpenGL's
internal computation. For the example scene graph, the application invokes
this code for each of the rectangles using that rectangle's texture buffer.
</p>

<p>
Running these shader instructions on the whole scene graph generates the
complete output image for the application.
</p>

<h4>
Mesa
</h4>

<p>
Nothing we have discussed so far is specific to Linux, but it gives us the
framework to look at how it's all implemented. On Linux, the
<a href="https://mesa3d.org/">Mesa&nbsp;3D</a>
library, Mesa for short, implements 3D rendering interfaces and support
for various graphics hardware. To applications, it provides OpenGL or
Vulkan for desktop graphics,
<a href="https://www.khronos.org/opengles/">OpenGL ES</a>
for mobile systems, and
<a href="https://www.khronos.org/opencl/">OpenCL</a>
for computation. On the hardware side, Mesa implements drivers for most
of today's graphics hardware.
</p>

<p>
Mesa drivers generally do not implement these application interfaces by
themselves as Mesa contains plenty of helpers and abstractions.
For stateful interfaces, such as OpenGL, Mesa's
<a href="https://www.freedesktop.org/wiki/Software/gallium/">Gallium3D</a>
framework connects interfaces and drivers
with each other. This is called a state tracker. Mesa contains
state trackers for various versions of OpenGL, OpenGL ES, and OpenCL. When the
application uses 
the API, it modifies the state tracker for the given interface.
</p>

<p>
A hardware driver within Mesa further converts the state-tracker information
to hardware state and rendering instructions.
For example, calling OpenGL's
<a href="https://registry.khronos.org/OpenGL-Refpages/gl4/html/glBindTexture.xhtml"><tt>glBindTexture()</tt></a>
selects the current texture buffer within the OpenGL
state tracker. The hardware driver then installs the texture-buffer
object in graphics memory and links the active shader program to
refer to the buffer object as its texture. In our example above, the
texture becomes available as <tt>Tex</tt> in the
shader program.
</p>

<p>
Vulkan is a stateless interface, so Gallium3D is not useful
for those drivers; Mesa instead offers the <a href="https://docs.mesa3d.org/vulkan/index.html">Vulkan runtime</a> to help
with their 
implementation. If there is a Vulkan driver available, though, there
might not be a need for Gallium3D-based OpenGL support at all for
that hardware.
<a href="https://docs.mesa3d.org/drivers/zink.html">Zink</a>
is a Mesa driver that maps Gallium3D to Vulkan. With Zink, OpenGL state
turns into Gallium3D state, which is then forwarded to hardware via standard
Vulkan interfaces. In principle, this works with any hardware's Vulkan
driver. One can imagine that future drivers within Mesa only implement
Vulkan and rely on Zink for OpenGL compatibility.
</p>

<p>
Besides Gallium3D, Mesa provides more helpers, such as winsys or GBM, to
its hardware 
drivers. Winsys wraps the details of the
window system. GBM, the Generic Buffer Manager, simplifies buffer-object
allocation.
There are also a number of shader languages, such as
GLSL
or
<a href="https://www.khronos.org/spir/">SPIR-V</a>,
available to the application.  Mesa compiles the
application-provided shader code to the "New Interface Representation" or
NIR, which Mesa drivers turn into 
hardware instructions. To get the shader instructions and the associated
data processed by Mesa's hardware acceleration, their buffer objects have
to be stored in memory locations accessible to the graphics card.
</p>

<h4>
Kernel memory management
</h4>

<p>
Any memory accessible to the graphics hardware is commonly subsumed under
the umbrella term of graphics memory; it is the graphics
stack's central resource, as all of the stack's components interact with
it. On the hardware side, graphics memory comes in a variety of
configurations that range from dedicated memory on discrete graphics
adapters to regular system memory of system-on-chip (SoC) boards. In between are
graphics chips with DMA-able or 
<a href="https://en.wikipedia.org/wiki/Shared_graphics_memory">shared graphics memory</a>,
<a href="https://en.wikipedia.org/wiki/Graphics_address_remapping_table">graphics
address remapping table</a> (GART) memory
of discrete devices, or the so-called stolen graphics memory
of on-board graphics.
</p>

<p>
Being a system-wide resource, graphics memory is maintained by the kernel's
<a href="https://en.wikipedia.org/wiki/Direct_Rendering_Manager">Direct
Rendering Manager</a> (DRM)
subsystem. To access DRM functionality, Mesa opens
the graphics card's device file under <tt>/dev/dri</tt>, such as
<tt>/dev/dri/renderD128</tt>. As required by its
user-space counterparts, DRM exposes graphics memory in the form
of buffer objects, where each buffer object represents a slice of the
available memory.
</p>

<p>
The DRM framework provides a number of memory managers for the most
common cases. The DRM drivers for the discrete graphics cards
from AMD, NVIDIA, and (soon) Intel use the <a href="https://docs.kernel.org/gpu/drm-mm.html">Translation Table Manager</a>
(TTM). It supports discrete graphics memory, GART memory, and system memory.
TTM can move buffer objects between these areas, so if the device's
discrete memory fills up, unused buffer objects can be swapped out to
system memory.
</p>

<p>
Drivers for simple framebuffer devices often use the
SHMEM helpers, which allocate buffer objects in shared memory. Here,
regular system memory acts as a shadow buffer for the device's
limited resources. The graphics driver maintains the device's
graphics memory internally, but exposes buffer objects in system memory
to the outside. This also makes it
possible to memory-map buffer objects of devices on the USB or I2C bus,
even though these buses do not support page mappings of
device memory;  the shadow buffer can be mapped instead.
</p>

<p>
The other common
allocator, the DMA helper, manages buffer
objects in DMA-able areas of the physical memory. This design is often used
in SoC boards, where graphics chips fetch and store data via DMA operations.
Of course, DRM drivers with additional requirements have the option of extending
one of the existing memory managers or implementing their own.
</p>

<p>
The <tt>ioctl()</tt> interface for managing buffer objects is called the <a href="https://docs.kernel.org/gpu/drm-mm.html#the-graphics-execution-manager-gem">Graphics 
Execution Manager</a> (GEM). Each DRM driver implements GEM according to its
hardware's 
features and requirements.
The GEM interface allows mapping a buffer object's memory pages to user-space
or kernel address space, allows pinning the pages at a certain location, or
exporting them to other drivers. For example, an application in user space
can get access to a buffer object's memory pages by invoking <tt>mmap()</tt>
with the
correct offset on the DRM device file's file descriptor. The call will eventually
end up in the DRM driver's GEM code, which sets up the mapping. As we will see
below, it's a useful feature for software rendering.
</p>

<p>
The one common operation that GEM does not provide is buffer allocation.
Each buffer object has a specific use case, which affects and is affected by
the object's allocation parameters, memory location, or hardware constraints.
Hence, each DRM driver offers a dedicated <tt>ioctl()</tt> operation for buffer-object
allocation that captures these hardware-specific settings. The DRM driver's
counterpart in Mesa invokes said <tt>ioctl()</tt> operation accordingly.
</p>

<h4>
Rendering operations
</h4>

<p>
Just having buffer objects for storing the output image, the input data, and
the shader programs is not enough. To start rendering, Mesa instructs DRM to
put all necessary buffer objects in graphics memory and invokes the
active shader program. It's again all specific to the hardware and provided
as <tt>ioctl()</tt> operations by each DRM driver individually. As with buffer allocation,
the hardware driver within Mesa invokes the DRM driver's <tt>ioctl()</tt> operations.
For Mesa drivers based on Gallium3D, this happens when the driver converts the
state tracker information into hardware state.
</p>

<p>
The graphics driver ideally acts only as a proxy between the application
in user space and the hardware. The hardware renderer runs asynchronously to
the rest of the graphics stack and reports back to the driver only in
case of an error or on successful completion; much like the system CPU
informs the operating system on page faults or illegal instructions. As long
as there's nothing to report, driver overhead is minimal. There are
exceptions; for example, older models of Intel graphics chips do not
support 
vertex transformations, so the driver within Mesa has to implement them in
software. On the Raspberry Pi, the kernel's DRM driver has to validate each
shader's memory access, as the VideoCore&nbsp;4 chip does not contain
an I/O MMU to isolate the shader from the system.
</p>

<h4>
Software rendering
</h4>

<p>
So far, we have assumed hardware support for graphics rendering. What if
there's no such support or the user-space application cannot use it? For
example, a user-space GUI toolkit might prefer rendering in
software because hardware-centric interfaces like OpenGL do not fit its needs.
And there's Plymouth, the program that displays the boot-up logo and prompts
for disk-encryption passwords during boot, which usually does not have a full
graphics stack available. For these scenarios, DRM offers the dumb-buffer
<tt>ioctl()</tt> interface.
</p>

<p>
By utilizing dumb buffers, an application allocates
buffer objects in graphics memory, but without support for hardware
acceleration. So any returned buffer object is only usable with software
rendering. The application in user space, such as a GUI
toolkit or Plymouth, maps the buffer object's pages into its address space
and copies over the output image. Mesa's software renderer works similarly:
the input buffer objects all live in system memory and the system CPU
processes the shader instructions. The output buffer is a dumb-buffer
object that stores the rendered image. While that's neither fast nor fancy,
it's good enough to run a modern desktop environment on simple hardware that
does not support accelerated rendering.
</p>

<p>
We have now gone through the application's graphics stack for rendering. After
having completed the traversal of the scene graph, the application's output
buffer object contains the visualized scenery or data that it wants to
display. But the buffer is not 
yet on the screen. Whether accelerated or dumb, putting the buffer on the
screen requires compositing and mode setting, which form the other half of
the graphics stack. In part&nbsp;2, we will look at Wayland
compositing, setting display modes with DRM, and a few other features of the
graphics stack.
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Device_drivers-Graphics">Device drivers/Graphics</a></td></tr>
            <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Zimmermann_Thomas">Zimmermann, Thomas</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/955376/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VideoPoet A large language model for zero-shot video generation (119 pts)]]></title>
            <link>https://sites.research.google/videopoet/</link>
            <guid>38702141</guid>
            <pubDate>Tue, 19 Dec 2023 21:47:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sites.research.google/videopoet/">https://sites.research.google/videopoet/</a>, See on <a href="https://news.ycombinator.com/item?id=38702141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h3 size="3">
<p>Quick Links</p>
</h3>
<p>To view additional results, please also visit our other pages:</p>
<p><a target="_blank" href="http://sites.research.google/videopoet/text-to-video">Text-to-Video</a> - <a target="_blank" href="http://sites.research.google/videopoet/image-to-video">Image-to-Video</a> - <a target="_blank" href="http://sites.research.google/videopoet/video-editing">Video Editing</a> - <a target="_blank" href="http://sites.research.google/videopoet/stylization">Stylization</a> - <a target="_blank" href="http://sites.research.google/videopoet/inpainting">Inpainting</a></p>

<h3 size="3">
<p>Authors</p>
</h3>
<p>Dan Kondratyuk*, Lijun Yu*, Xiuye Gu*, José Lezama*, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, Yong Cheng, Ming-Chang Chiu,&nbsp;Josh Dillon, Irfan Essa, Agrim Gupta, Meera Hahn, Anja Hauth, David Hendon, Alonso Martinez, David Minnen, David Ross, Grant Schindler, Mikhail Sirotenko, Kihyuk Sohn, Krishna Somandepalli, Huisheng Wang, Jimmy Yan, Ming-Hsuan Yang, Xuan Yang, Bryan Seybold*, Lu Jiang*</p>
<hr>
<p>*Equal technical contribution</p>
<h3 size="3">
<p>Acknowledgements</p>
</h3>
<p><i>We give special thanks to Alex Siegman and Victor Gomes for managing computing resources. We also give thanks to Aren Jansen, Marco Tagliasacchi, Neil Zeghidour, John Hershey for audio tokenization and processing, Angad Singh for storyboarding in “Rookie the Raccoon”, Cordelia Schmid for research discussions, Alonso Martinez for graphic design, David Salesin, Tomas Izo, and Rahul Sukthankar for their support, and Jay Yagnik as architect of the initial concept.</i></p>
<hr>
<p><i>**Referenced works:</i></p>
<ul>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Bierstadt_Albert_Old_Faithful.jpg">Old Faithful</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Pillars_of_creation_2014_HST_WFC3-UVIS_full-res.jpg">Pillars of Creation</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://www.artic.edu/artworks/120885/milk-drop-coronet">Milk Drop Coronet</a>, <a target="_blank" href="https://creativecommons.org/publicdomain/zero/1.0/">CC0 1.0</a>.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Rembrandt_Christ_in_the_Storm_on_the_Lake_of_Galilee.jpg">The Storm on the Sea of Galilee</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:George_III_Statue.jpg">George III Statue</a>, <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>.</p>
</li>
<li>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/File:Raising_the_Flag_on_Iwo_Jima,_larger_-_edit1.jpg">Raising the Flag on Iwo Jima</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Caspar_David_Friedrich_-_Wanderer_above_the_Sea_of_Fog.jpeg">Wanderer above the Sea of Fog</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg">Mona Lisa</a>, public domain.</p>
</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vulkan video extensions for accelerated H.264 and H.265 encode (220 pts)]]></title>
            <link>https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode</link>
            <guid>38701780</guid>
            <pubDate>Tue, 19 Dec 2023 21:21:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode">https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode</a>, See on <a href="https://news.ycombinator.com/item?id=38701780">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><time itemprop="dateCreated" datetime="2023-12-19T06:00:00-08:00"><i></i> December 19, 2023</time>
        by <span itemprop="author">Lynne Iribarren, Khronos Member of the Vulkan Video TSG and Ahmed Abdelkhalek, AMD, Vulkan Video TSG Chair</span>
        <span itemtype="keywords"><i></i>
        
            <a href="https://www.khronos.org/news/tags/tag/vulkan" title="vulkan">vulkan</a>, 
            <a href="https://www.khronos.org/news/tags/tag/video" title="video">video</a>
        </span>
    </p><div itemprop="description">
    <p>In April 2021, the Vulkan® Working Group at Khronos® <a href="https://www.khronos.org/blog/an-introduction-to-vulkan-video">released a set of provisional extensions</a>, collectively referred to as ‘Vulkan Video’ which provide seamless encoding and decoding of video streams using a variety of video coding standards. The December 2022 release of Vulkan 1.3.238 saw the <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-decode">finalization of the extensions to decode H.264 and H.265</a>, and today, with the release of Vulkan <strong>1.3.274</strong>, Khronos has finalized their counterpart: the extensions to enable <strong>encoding</strong> of H.264 and H.265 video streams. Leveraging the Vulkan framework, they provide a standardized, seamless, low-overhead, and highly controllable way to produce H.264 and H.265 video via hardware accelerators, with applications ranging from real-time, low-latency streaming to offline server-scale transcoding.</p>
<p>Incorporating industry feedback, the extensions saw many improvements since their introduction, from a bidirectional interface (overrides) to help with coding and exposing advanced hardware capabilities, to rate control configuration parameters and an interface to aid with quality vs. performance trade-offs. This feedback also prompted the release of the first video maintenance extension. In addition, given the high industry demand for AV1 codec support, an AV1 decode extension release is imminent, with an AV1 encode extension development also underway. Figure 1 depicts Vulkan Video extensions along with their status and relations.</p>


<figure><img src="https://www.khronos.org/assets/uploads/blogs/2023-blog-vulkan-video-1.jpg">Figure 1. Vulkan Video extensions</figure>


<p>The encode extensions grant low-level control over much of the encoding process, while still keeping the efficiency and performance of hardware encoding acceleration. Implementers have the freedom to tweak details such as quantization index, per-slice bit allocation, arithmetic coder, deblocking, and more. Given this flexibility and complexity, a balanced programming interface for rate control gives users a choice between more automated operation and low-level tweaking of frame parameters.</p>
<h2>So, What Changed?</h2>
<p>This section briefly summarizes the changes included in this release relative to <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-decode">prior descriptions</a> of the Vulkan Video extensions.</p>
<h3>Changes to Video Encode</h3>
<h4>Encoder Rate Control</h4>
<p>Often the most important aspect of encoder configuration for applications, the encoder rate control API was given special attention in Vulkan Video. From exposing parameters for standard rate control modes (e.g. CBR/VBR), to allowing applications to provide hints about other intended stream encoding parameters (e.g. picture/reference patterns), to providing the ability to configure per-layer rate control parameters (e.g. for streams with multiple temporal layers), the rate control API offers a rich set of features for various use cases and lays a solid foundation for future extensions. Encoder rate control configuration is performed using the <strong><em>vkCmdControlVideoCodingKHR</em></strong> command.</p>
<h4>Encoder Quality Levels</h4>
<p>Video encoder implementations often fine tune the use of various encoding tools and rate control parameters depending on the desired quality versus performance/latency trade-offs of different use cases. Now implementations report the number of quality levels supported for a given video profile and usage. A new API <strong><em>vkGetPhysicalDeviceVideoEncodeQualityLevelPropertiesKHR </em></strong>may be used to retrieve implementation recommendations for various encoding parameters and configurations (e.g. rate control).</p>
<h4>Implementation Overrides</h4>
<p>Due to the complex nature of video encoding, and the ever-changing nature of hardware encoders and their capabilities, an interface, known as <strong>overrides</strong>, permits bidirectional communication that <strong>guarantees</strong> that the output video stream will be compliant. In addition, applications may opt-in for optimization overrides to allow implementations more flexibility to optimize for the specified usage and hints. Full disclosure about the occurrence of overrides for video session parameters or frame parameters is also reported for developers interested in more detailed analysis of such overrides.</p>
<h4>Retrieval of encoded video session parameters bitstream segments</h4>
<p>To facilitate implementation overrides for bitstream compliance and optimizations, applications are expected to retrieve the encoded video session parameter bitstream segments (e.g. H.264 SPS/PPS) from the implementation using the new API call <strong><em>vkGetEncodedVideoSessionParametersKHR</em></strong> against the given <strong><em>VkVideoSessionParametersKHR</em></strong> object.</p>
<h4>Encoder Feedback Query</h4>
<p>To allow future extension of encoder feedback statistics in a manner similar to pipeline statistics, the new <strong><em>VK_QUERY_TYPE_VIDEO_ENCODE_FEEDBACK_KHR</em></strong> is now used to retrieve the video bitstream offset and size.</p>
<p>Figure 2 depicts the Vulkan Video encoding process, which remains largely unchanged compared to previous descriptions.</p>


<figure><img src="https://www.khronos.org/assets/uploads/blogs/2023-blog-vulkan-video-2.jpg">Figure 2. Vulkan Video Encode Process</figure>


<h3>Changes to Video Decode &amp; Encode</h3>
<h4>VK_KHR_video_maintenance1</h4>
<p>Along with the video encoding extensions, Khronos is releasing a maintenance extension incorporating community and industry feedback, which improves flexibility for both decoding and encoding. This extension permits decoding implementations to create images usable with video decoding without the need to explicitly specify the video profiles they will be used with. The same applies for encoding, where an attached per-image video profile limits usability with large and complex transcoding frameworks.</p>
<p>In addition to flexibility improvements, a new, simpler interface for specifying video queries <strong>inline with video decode and encode operation commands</strong> has been added, known as inline queries.</p>
<h4>Requiring pSetupReferenceSlotKHR for non-reference pictures</h4>
<p>When the Vulkan Video decode extensions were finalized applications were required to provide a reconstructed picture resource and DPB slot (via <strong><em>VkVideoDecodeInfoKHR::pSetupReferenceSlot</em></strong>) only if the picture being decoded will become a reference. However, no shipping implementation actually supported specifying <strong><em>NULL</em></strong>for <strong><em>pSetupReferenceSlot</em></strong>, and further some implementations discovered cases that require the use of the reconstructed picture resource and/or DPB slot for transient storage during decoding a non-reference picture. A similar situation applies to encoding non-reference pictures. As a result, the vulkan video extensions were updated to require providing <strong><em>pSetupReferenceSlotKHR</em></strong> for non-reference pictures.</p>
<h2>I Want All The Details!</h2>
<p>The following <strong>proposal documents</strong> provide a much more detailed and thorough review of all finalized Vulkan Video extensions, including the rationale behind the chosen design approach, various issues encountered during the development of Vulkan Video and how they were resolved, as well as code samples to aid in application development:</p>
<ul>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_queue.adoc"><strong><em>VK_KHR_video_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_queue.adoc"><strong><em>VK_KHR_video_decode_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_h264.adoc"><strong><em>VK_KHR_video_decode_h264</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_h265.adoc"><strong><em>VK_KHR_video_decode_h265</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_queue.adoc"><strong><em>VK_KHR_video_encode_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_h264.adoc"><strong><em>VK_KHR_video_encode_h264</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_h265.adoc"><strong><em>VK_KHR_video_encode_h265</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_maintenance1.adoc"><strong><em>VK_KHR_video_maintenance1</em></strong></a></li>
</ul>
<p>Developers interested in using Vulkan Video are strongly encouraged to read the above proposal documents - they really give you a good head start!</p>
<p>All details about the Vulkan Video API are available in the final extensions <strong>specification</strong> links:</p>
<ul>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_queue.html"><strong><em>VK_KHR_video_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_queue.html"><strong><em>VK_KHR_video_decode_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_h264.html"><strong><em>VK_KHR_video_decode_h264</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_h265.html"><strong><em>VK_KHR_video_decode_h265</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_queue.html"><strong><em>VK_KHR_video_encode_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_h264.html"><strong><em>VK_KHR_video_encode_h264</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_h265.html"><strong><em>VK_KHR_video_encode_h265</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_maintenance1.html"><strong><em>VK_KHR_video_maintenance1</em></strong></a></li>
</ul>
<h2>Call for Action, Feedback &amp; Support!</h2>
<p>The finalization and release of these Vulkan Video extensions marks a significant milestone in the Vulkan ecosystem roadmap, adding fully accelerated H.264 and H.265 encode to this widely available cross-platform GPU API. We encourage developers to utilize these extensions to bring new levels of performance and functionality to their video applications on Windows and Linux.</p>
<p>We welcome you to join <a href="https://vulkan.org/events/vulkanised-2024">Vulkanised 2024</a> (February 5-7 in MountainView CA.), which will include a presentation &amp; live demo about Vulkan Video and much more!</p>
<p>NVIDIA, Intel &amp; AMD are the first IHVs implementing support for these extensions:</p>
<ul>
<li>NVIDIA: Windows and Linux <a href="https://developer.nvidia.com/vulkan-driver">BETA drivers</a> available now</li>
<li>Intel: Coming soon</li>
<li>AMD: Coming soon</li>
</ul>
<p>Additionally, the open-source drivers <a href="https://airlied.blogspot.com/2023/12/radv-vulkan-video-encode-status.html">RADV</a> and <a href="https://gitlab.freedesktop.org/zzoon/mesa/-/tree/h264enc_anv_4?ref_type=heads">ANV</a> are adding support for the finalized Vulkan Video encode extensions, in addition to already supporting the Vulkan Video decode extensions.</p>
<p>Strong ecosystem adoption continues for Vulkan Video, and there are several implementers of the spec:</p>
<ul>
<li>The <a href="https://github.com/nvpro-samples/vk_video_samples">reference app</a> part of the Vulkan Video samples repository with encoding support is coming soon in 1Q24.</li>
<li>FFmpeg, in a <a href="http://lynne.ee/vulkan-video-encoding.html">branch</a> currently under development, soon to be merged into the <a href="https://git.videolan.org/?p=ffmpeg.git;a=log;h=HEAD">main repository</a>.</li>
<li>Gstreamer, in a <a href="https://gitlab.freedesktop.org/gstreamer/gstreamer/-/merge_requests/5739">branch</a> currently under development and a description of the journey can be found <a href="https://blogs.igalia.com/scerveau/vulkan-video-encoder-in-gstreamer/">here</a>.</li>
</ul>
<p>Those interested in testing the code should follow their guidelines and are welcome to submit feedback.</p>
<p>An upcoming release of Vulkan SDK will include updated Vulkan headers and Validation Layer support for the newly released video extensions. In the meantime, you can find the Vulkan headers <a href="https://github.com/KhronosGroup/Vulkan-Headers">here</a>.</p>
<p>We look forward to your use and feedback on Vulkan Video! Please share your experience and thoughts through the <a href="https://github.com/KhronosGroup/Vulkan-Docs/issues/2284">Vulkan Video Encode Release GitHub Issue</a>. This issue will also be updated to provide links to Vulkan Video-related resources as they become available.</p>
<p>We also encourage your participation in extending Vulkan Video to support more codecs and features. See <a href="https://www.khronos.org/members/">khronos.org/members</a> for information about how to join Khronos and participate in the definition of any of our standards.</p>
<p>Thank you for your interest and support of Vulkan Video. We hope you find it effective for your use cases and applications, and we look forward to supporting your needs with more codecs and features!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CUDA vs. ROCm: A case study (146 pts)]]></title>
            <link>https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/</link>
            <guid>38700060</guid>
            <pubDate>Tue, 19 Dec 2023 19:09:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/">https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/</a>, See on <a href="https://news.ycombinator.com/item?id=38700060">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div id="markdown-content"> <p>How far along is AMD’s ROCm in catching up to Cuda? AMD has been on this race for a while now, with ROCm debuting 7 years ago. Answering this question is a bit tricky though. CUDA isn’t a single piece of software—it’s an entire ecosystem spanning compilers, libraries, tools, documentation, Stack Overflow/forum answers, etc. Today, I’m going to zoom in on a particular slice of these vast ecosystems, the random number generation libraries: cuRAND and rocRAND, part of the suite of around ten libraries that come standard on both systems. Hopefully, this sheds some light on the current state-of-affairs of the broader landscape.</p> <p>Most of these observations grew out of my work on a research project a few months ago. As I worked, I realized I was forming some pretty strong takes that I can’t really put in an academic paper. So here I am.</p> <p>One of the key advantages of rocRAND is it is open-source. So let’s start at their <a href="https://github.com/ROCm/rocRAND" rel="external nofollow noopener" target="_blank">GitHub repo</a> first.</p> <h2 id="design">Design</h2> <p>Going through the README, one of the first things you notice is AMD actually offers two random number libraries: rocRAND and hipRAND, the latter being a thin client that chooses cuRAND or rocRAND depending on the platform. So, for today’s discussion, we’ll set aside hipRAND.</p> <p>Next comes a list of random number generators implemented in the library. You won’t find a discussion about them here (or anywhere else for that matter), Just a list of names. Moving on, in the Requirements section, ROCm is listed as a dependency for AMD platforms, as expected. However, clicking on the ROCm link leads to the first 404 error on this page. To run this library on CPU, you need something referred to as “HIP-CPU”. This link thankfully works, and the tagline of its Github repo reads- “An implementation of HIP that works on CPUs, across OSes.”</p> <p>Let’s pause for a moment. We’re not even halfway through the README and we have already seen 3 different platforms from AMD- ROCm, HIP, HIP-CPU. I really wonder about the necessity or the wisdom behind this fragmentation- splitting HIP in particular. A single standard or library like SYCL or Kokkos seems to support multiple hardware platforms just fine under one codebase. To me this felt like a half-hearted attempt to tick one more box in a head-to-head battle with (intel-supported) SYCL. And I say half-hearted because HIP-CPU has been under development for more than 3 years, last commit pushed 3 months ago, and this is the first paragraph of its README: “Please note the library is being actively developed, and is known to be incomplet; it might also be incorrekt and there could be a few bad bugs lurking.” Let’s return to our focus on rocRAND.</p> <p>One of the key challenges in developing a parallel, reproducible random number library is ensuring statistical robustness. This might not matter for most users, but for applications like Brownian simulations, a weak generator can silently wreak havoc. Rigorous testing with standard, widely accepted statistical frameworks is crucial - something cuRAND of course does. However, I couldn’t find any discussion on this for rocRAND, aside from two self-written simple tests. There’s mention of a statistical test suite in the README, but again, that link leads to a 404 error.</p> <p>It’s not looking great, but at this point, I found a feature that cuRAND doesn’t have, a Python API! It’s an interesting choice: to attach such a high-level language interface for such a low-level library. So let’s go to the documentation and see what’s it for, shall we?</p> <h2 id="documentation">Documentation</h2> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/py.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption>Figure 1: rocRAND's Python API.</figcaption> </figure> <p>That’s it! That’s the entirety of the Python API documentation – and no, those headers aren’t clickable. <a href="https://rocm.docs.amd.com/projects/rocRAND/en/latest/python_api.html" rel="external nofollow noopener" target="_blank">This is it</a>!</p> <p>So, that was a bonus feature. What about the C++ API documentation? well, it exists, but it’s hardly any different. The API reference is almost entirely just a dump of function docstrings, with same comment copy/pasted for all the functions. And this mindless copy/pasting has predictable result- you’ll find, for example, the “documentation” mention 64 bit int return type for a function while it actually returns 32-bit.</p> <p>The Programming Guide again starts (and ends) with the list of generators, with only one piece of extra information here, whether a generator is for pseudo-random or quasi-random number generation. The next (and final) section is titled “Ordering”, and the very first sentence starts talking about “how results are ordered in global memory.” If you just thought- wait, what results? that’s a very valid response. You <em>might</em> eventually figure out they are talking about the host-side API that generates a buffer of random numbers on device. Being GPU, it uses multiple threads behind the scene, and ordering here refers to how to order the numbers coming out of each thread in the output buffer. They list 5 ways of doing it, after commenting how this choice impacts performance and reproducibility. Go on, <a href="https://rocm.docs.amd.com/projects/rocRAND/en/latest/programmers_guide.html#" rel="external nofollow noopener" target="_blank">read about them a little bit</a>, you’ll soon discover a pretty interesting relationship between them. For the lazy among you, here’s a clue:</p> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption></figcaption> </figure> <p>They are all the same! Of course, they don’t say that directly, it’s another little thing for you to figure out. (well, technically I can’t say “all” are same, becuase they don’t mention the fifth one anywhere else in the page.)</p> <p>Frankly, this isn’t just bad documentation; this is horrendous. There is no attempt anywhere to introduce or explain anything: just data dumps and lists. You get the sense, once again, that this “documentation work” was another box for someone to tick, without any consideration paid to a potential user of the software.</p> <p>But the code follows the same API as cuRAND. So someone familar with cuRAND will be able to manage eventually. Let’s look at how that code fares against cuRAND next.</p> <h2 id="performance">Performance</h2> <p>I’ll start with a real-world benchmark, using a classic example of GPGPU programming: Ray tracing in one weekend in cuda (<a href="https://github.com/rogerallen/raytracinginoneweekendincuda" rel="external nofollow noopener" target="_blank">Github</a>). For meaningful performance comparison of random number libraries, we need a program that uses random numbers beyond just the initialization phase. Ray tracer is a good example of that. Both libraries offer a variety of generators; for this test, I chose Philox.</p> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/comb.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption>Figure 2: Time taken to render the image on the right by cuRAND and rocRAND libraries (left)</figcaption> </figure> <p>4.03 seconds vs 5.5s- the raytracer with the rocRAND version is 37% slower. Remember this isn’t a micro-benchmark of just random number generation part, the timings are for whole program. With that in mind, I think this is a pretty substantial slowdown.</p> <p>The benchmark was performed on an Nvidia V100 GPU. Is that fair? I think yes, especially since rocRAND’s developers <a href="https://streamhpc.com/blog/2017-11-29/learn-amds-prng-library-developed-rocRAND/" rel="external nofollow noopener" target="_blank">claimed</a> to have performance parity with cuRAND on Nvidia GPUs. But maybe cuRAND has some hardware-specific optimizations? I really don’t think that’s the case. Philox algorithm isn’t that complicated, it doesn’t really need any advanced GPU primitives. But don’t take just my word for it: our lab made a pretty simple implementation of Philox, (you can find it <a href="https://github.com/msu-sparta/OpenRAND/blob/main/include/openrand/philox.h" rel="external nofollow noopener" target="_blank">here</a>), it is orders of magnitude smaller than rocRAND’s implementation in terms of LOC, yet it performs on par with CuRAND (4.09 seconds).</p> <p>Still, it’s just one benchmark. I’m sure there are other hardware-software combinations where this performance gap disappears. But, just to ensure that the ray tracer isn’t some outlier, I wrote a pretty basic 2D brownian dynamics simulation code. The story is even worse here for rocRAND, 6.30 seconds vs cuRAND’s 4.23- a 48% slowdown.</p> <h2 id="final-thoughts">Final Thoughts</h2> <p>After the ChatGPT phenomenon, there has recently been lots of focus on Nvidia’s “CUDA moat”. As we all watched the vast AI riches going almost exclusively to Nvidia thanks mostly to that moat, many assumed this will be a big wake-up call for AMD, their <a href="https://www.vanityfair.com/news/2016/06/how-mark-zuckerberg-led-facebooks-war-to-crush-google-plus" rel="external nofollow noopener" target="_blank">Carthage must be destroyed</a> moment that radically alters their well-known laid-back attitude to software. There are hints of this shift in their recent events and press releases, and I hope this trend continues.</p> <p>But in my little corner of HPC world, I’m yet to see any meaningful movement in that regard. And AMD needs to hurry up- as I wrote this article, I took a cursory glance at Intel’s <a href="https://spec.oneapi.io/versions/1.2-rev-1/elements/oneMKL/source/domains/rng/onemkl-rng-overview.html" rel="external nofollow noopener" target="_blank">documentation</a> for SYCL (a competitor of HIP) on this topic- a clean, well-organized, professional site- as you’d expect.</p> <p>Like many, I’m looking forward to a real showdown in the GPGPU space someday- I’m just not sure that will necessarily be between Nvidia and AMD.</p> </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[At Least 15% of Reddit Content Is Corporate Trolls Manipulating Public Opinion (146 pts)]]></title>
            <link>https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42</link>
            <guid>38700038</guid>
            <pubDate>Tue, 19 Dec 2023 19:07:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42">https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42</a>, See on <a href="https://news.ycombinator.com/item?id=38700038">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@chrisjeffrieshomelessromantic?source=post_page-----b249bd42ab42--------------------------------"><div aria-hidden="false"><p><img alt="Homeless Romantic" src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*P3NFVEPEgZp88pjg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://medium.com/collapsenews?source=post_page-----b249bd42ab42--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="Collapse News" src="https://miro.medium.com/v2/resize:fill:48:48/1*U7BJY5ZImQnK_eaz_2oTMg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div><figure><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b680"><a href="https://www.journals.elsevier.com/computers-in-human-behavior%0A" rel="noopener ugc nofollow" target="_blank">https://www.journals.elsevier.com/computers-in-human-behavior%0A</a></p><h2 id="9f33">The Impact of Corporate Trolls on Reddit: A Growing Problem</h2><p id="36a2">The rise of social media has brought about a new battleground for the spread of misinformation, manipulation of public opinion, and promotion of products and services. Reddit, one of the most popular social media platforms, has not been immune to this phenomenon.</p><p id="b57c">Two significant studies, <strong>the Pew Research Center study conducted in 2018 and the Computers in Human Behavior study published in 2020, have shed light on the prevalence and impact of corporate trolls on Reddit.</strong></p><h2 id="c308">Pew Research Center Study: Unveiling the Reach of Corporate Trolls</h2><p id="c3b6">The Pew Research Center study, conducted in 2018, delved into the experiences of 2,505 adult Americans who use Reddit.</p><p id="03b9">The findings were alarming, revealing that a considerable portion of Reddit users had directly encountered the influence of corporate trolls.</p><p id="5911"><strong>The study found that 11% of the respondents had been contacted by a bot or troll attempting to promote a product or service</strong>. Even more concerning was the discovery that 13% of the respondents had witnessed a company manipulate public opinion on the platform.</p><p id="2b6f">The study’s demographic analysis further highlighted the targeted nature of corporate trolling. Younger users, particularly those aged 18–29, were significantly more likely to be contacted by corporate trolls, with 17% of them reporting such experiences, compared to only 7% of users aged 65 and over. This age-based discrepancy underscores the strategic approach of corporate trolls in engaging with a demographic that is often more susceptible to their influence.</p></div><div><p><h2 id="5841">Computers in Human Behavior Study: Uncovering Strategic…</h2></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Lufthansa A350's frustrating Oakland diversion (238 pts)]]></title>
            <link>https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/</link>
            <guid>38699343</guid>
            <pubDate>Tue, 19 Dec 2023 18:19:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/">https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/</a>, See on <a href="https://news.ycombinator.com/item?id=38699343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>A San Francisco-bound Lufthansa jet recently had to divert to Oakland due to a company policy, even though the weather was nice, and all other planes were having no issues landing in San Francisco. Were air traffic controller just being petty, is Lufthansa’s policy unnecessary, or is this just the price you pay when you err on the side of extreme caution?</p>
<div id="ez-toc-container">

<nav><ul><li><a href="#lufthansa_pilots_cant_do_visual_approaches_at_night" title="Lufthansa pilots can’t do visual approaches at night">Lufthansa pilots can’t do visual approaches at night</a></li><li><a href="#who_was_in_the_wrong_here" title="Who was in the wrong here?">Who was in the wrong here?</a></li><li><a href="#bottom_line" title="Bottom line">Bottom line</a></li></ul></nav></div>
<h2 id="h-lufthansa-pilots-can-t-do-visual-approaches-at-night"><span id="lufthansa_pilots_cant_do_visual_approaches_at_night"></span>Lufthansa pilots can’t do visual approaches at night<span></span></h2>
<p>This incident happened on Monday, October 16, 2023, and involves Lufthansa flight LH458 from Munich (MUC) to San Francisco (SFO). The flight was operated by a six-year-old Airbus A350-900 with the registration code D-AIXC. VASAviation did a great job creating a video that has both a visualization of the flight path, plus the audio between the Lufthansa pilots and the air traffic controller. </p>
<p>This incident revolves around how Lufthansa reportedly has a company policy whereby pilots can’t do visual approaches at night, but rather require instrument landing system&nbsp;(ILS) approaches. I wasn’t aware of this restriction, and I’m not sure if it only applies on certain flights (like long hauls), or what. I assume the intent is that this is an extra operational safety layer.</p>
<p>Why does it matter that Lufthansa doesn’t allow visual approaches? Well, air traffic controllers have to space planes out a bit more for instrument approaches rather than visual approaches, especially at airports like SFO, where parallel landings are performed.</p>
<p>When visual approaches are allowed, controllers can tell pilots to maintain visual separation from other aircraft, so they don’t have to leave as much of a buffer as with an instrument landing (where it’s entirely on the controllers to provide proper spacing). And that brings us to the issue here… </p>
<p>Here’s what happens between the Lufthansa pilots and the approach controllers:</p>
<ul>
<li>The controller clears the Lufthansa jet to make a visual approach, and the Lufthansa pilot advises “due to company procedures, we are unable visual approach at nighttime”</li>
<li>The controller then advises that “if that’s the case, then it will be extended delays”</li>
<li>The Lufthansa pilot responds “if that’s the case, that’s the case,” at which point the controller puts the Lufthansa jet into an extended holding pattern</li>
<li>After some time, the Lufthansa pilot advises “if we are not set up for base soon, we will have to declare fuel emergency and that would really **** up your sequence” (I can’t tell if he says s*ck or f*ck)</li>
<li>At this point the controller asks “what is your divert field?” suggesting that rather than letting the Lufthansa jet declare a fuel emergency at SFO, the plane will just have to fly to its diversion point</li>
<li>The Lufthansa pilot says “it would be Oakland,” to which the controller responds “you need vectors to Oakland?”</li>
<li>The Lufthansa pilot responds “no, but I just don’t understand why everybody is taking… my company forbids visual separation at night, so what is the problem here?”</li>
<li>The controller responds “I can’t have this conversation with you, you either divert to Oakland or you can continue to hold, it’s up to you”</li>
<li>The Lufthansa pilot responds “okay, you promised me 10 minutes, that ran out four minutes ago, so how many more minutes?”</li>
<li>The controller responds “conversation is over,” and then says “what are your intentions, you want to divert or you want to continue with the delay?”</li>
<li>When the controller advises that it will be an additional 10-15 minute delay, the Lufthansa pilot requests to divert to Oakland</li>
</ul>
<figure></figure>
<p>Unfortunately this turned into quite the messy delay for Lufthansa:</p>
<ul>
<li>The flight was initially supposed to leave Munich at 4:20PM, but only departed at 6:30PM</li>
<li>The flight was supposed to arrive in San Francisco at 7PM, but ended up landing in Oakland at 9:43PM, after a 12hr13min flight</li>
<li>Then at 11:30PM the plane departed Oakland for San Francisco, where it landed at 11:55PM</li>
</ul>
<h2 id="h-who-was-in-the-wrong-here"><span id="who_was_in_the_wrong_here"></span>Who was in the wrong here?<span></span></h2>
<p>Usually in these interactions between pilots and air traffic controllers, there’s one party that’s clearly acting out of line.</p>

<p>In this case, the Lufthansa pilots are doing nothing wrong. They’re following company procedures, and there’s no flexibility when it comes to that. It’s a pretty black and white matter. I am curious how the pilots announced this diversion to passengers. “Ja, so unfortunately even though the weather is nice in San Francisco, we will be diverting to Oakland because of a specific company procedure that only we follow, when all other planes are landing just fine?”</p>
<p>The rest of this is totally beyond my area of expertise, but I’d be curious to know what any OMAAT readers who are pilots or air traffic controllers think. A few thoughts and questions:</p>
<ul>
<li>Are there any other airlines that require instrument landings at night? And is this Lufthansa policy specific to long haul flights where fatigue could be more of an issue, or all flights?</li>
<li>If this is Lufthansa’s company policy, you’d think that this wouldn’t be the first time that this has come up at SFO, and that this is something that air traffic controllers would have dealt with before</li>
<li>To the credit of air traffic controllers, they may have very well had a consistent traffic flow, and allowing in an instrument approach could have messed up the spacing a bit, and could have caused problems for other planes</li>
<li>At the same time, it seems like the air traffic controllers aren’t exactly trying to go above and beyond to accommodate the Lufthansa jet, and even seem to have quite an attitude with the Lufthansa pilots, and almost get joy out of their diversion; at least that’s the tone that I sense</li>
</ul>
<figure><img fetchpriority="high" decoding="async" width="1200" height="753" src="https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg" alt="" srcset="https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg?width=360&amp;auto_optimize=low&amp;quality=75 360w, https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg?width=1200&amp;auto_optimize=low&amp;quality=75 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A Lufthansa Airbus A350 had to divert to Oakland</figcaption></figure>
<h2 id="h-bottom-line"><span id="bottom_line"></span>Bottom line<span></span></h2>
<p>A San Francisco-bound Lufthansa Airbus A350 had to divert to Oakland, due to a company policy whereby Lufthansa pilots apparently can’t make visual approaches at night. Air traffic controllers were unwilling or unable to help the Lufthansa pilots, and that caused a bit of a spat between the two parties.</p>
<p>This is an interesting situation, and it seemed like the circumstances were the perfect storm for this to happen, given that SFO often has parallel approaches and is consistently busy, so there’s not much room for extra spacing.</p>
<p><strong>What do you make of this Lufthansa situation?</strong></p>





 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C++ Should Be C++ (123 pts)]]></title>
            <link>https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html</link>
            <guid>38699223</guid>
            <pubDate>Tue, 19 Dec 2023 18:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html">https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html</a>, See on <a href="https://news.ycombinator.com/item?id=38699223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="doc" data-hard-breaks="true"><p><strong><span>Document number</span></strong><span>: P3023R1</span><br>
<strong><span>Date</span></strong><span>: 2023-10-31</span><br>
<strong><span>Authors</span></strong><span>: David Sankel &lt;</span><a href="mailto:dsankel@adobe.com" target="_blank" rel="noopener"><span>dsankel@adobe.com</span></a><span>&gt;</span><br>
<strong><span>Audience</span></strong><span>: Evolution, Library Evolution</span></p><h2 id="Abstract" data-id="Abstract"><a href="#Abstract" title="Abstract"><span></span></a><span>Abstract</span></h2><p><span>Over the past few years, the C++ community has coped with challenging social media situations, calls for a so-called successor, and signs of upcoming anti-C++ safety regulations. This piles on top of the ordinary committee stress of competing designs and prioritization difficulties. In a time like this it’s easy to dwell on troubles or adopt fiercely defensive positions.</span></p><p><span>This paper attempts to reframe unconstructive narratives and argue that the committee’s real opportunity is to improve people’s lives. We’ll show how this outlook leads to guidance on committee participation, direction, and responsibilities.</span></p><h2 id="Introduction" data-id="Introduction"><a href="#Introduction" title="Introduction"><span></span></a><span>Introduction</span></h2><p><span>The C++ community has been through a lot over the past few years. This paper makes no attempt to recount this history (God forbid!), but instead acknowledges that present circumstances have led committee members to question “Why are we here?”, “Is participation in C++ standardization still worthwhile?”, “What does the future hold for C++?”, and “Where should I invest my efforts?”. Today’s answers to these questions will define C++ for years to come.</span></p><p><span>This document makes the case for my personal perspective and the technical directions that flow from it. My opinions are formed from 23 years of industry C++ experience and 8 years of active committee participation. Equally contributing are countless conversations with engineers flowing from participation in the Boost Foundation, the Bloomberg C++ Guild, C++ conferences, and #include&lt;C++&gt;. However, I don’t pretend to have all the answers and maintain the right to change my mind when new information presents itself.</span></p><p><span>This document is split into the three parts. The first considers different ideas for a C++ Standardization Committee mission and argues that the most compelling one is to improve people’s lives. The second discusses some social patterns and temptations that lead to counter-productive decisions. The final part focuses on technical biases and considers some of the immediate choices the committee faces.</span></p><h3 id="Acknowledgements" data-id="Acknowledgements"><a href="#Acknowledgements" title="Acknowledgements"><span></span></a><span>Acknowledgements</span></h3><p><span>Some of what I say here has been more eloquently said elsewhere. I refer the reader especially to </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2000r4.pdf" target="_blank" rel="noopener"><em><span>Direction for ISO C++</span></em><span> (P2000R4)</span></a><span> from the direction group and </span><a href="https://dl.acm.org/doi/pdf/10.1145/3386320" target="_blank" rel="noopener"><em><span>Thriving in a Crowded and Changing World</span></em></a><span> from Bjarne Stroustrup. I’ll be quoting extensively from these documents. </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1962r0.pdf" target="_blank" rel="noopener"><em><span>How can you be so certain?</span></em><span> (P1962R0)</span></a><span> and </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0559r0.pdf" target="_blank" rel="noopener"><em><span>Operating principles for evolving C++</span></em><span> (P0559R0)</span></a><span> also cover similar topics.</span></p><p><span>I’d be remiss if I did not also credit Niall Douglas, Inbal Levi, Bjarne Stroustrup, and Herb Sutter for providing valuable feedback that substantially improved this document.</span></p><h2 id="Mission" data-id="Mission"><a href="#Mission" title="Mission"><span></span></a><span>Mission</span></h2><h3 id="The-biggest-threat" data-id="The-biggest-threat"><a href="#The-biggest-threat" title="The-biggest-threat"><span></span></a><span>The biggest threat</span></h3><p><em><span>How can you be so certain?</span></em><span> states “if we are not careful, C++ can still fail”. </span><em><span>Operating principles for evolving C++</span></em><span> suggests principles “in order to keep C++ alive, healthy and progressing”. These statements, representing a wider community outlook, imply C++ is an entity that has acquired something valuable that can be lost. What does this mean, exactly?</span></p><p><span>It is easy to see that C++ is fit as a general-purpose programming language–adoption by millions is a testament to that. Engineers gain proficiency in a reasonable amount of time and use it to solve their problems. C++'s usefulness it what matters.</span></p><p><span>Many think other programming languages “threaten” C++ or have the potential to “take away” what it has. A closer look reveals that the presence of a new tool doesn’t make an existing tool less capable, but potentially more capable.</span></p><p><span>What about regulatory legislation? It cannot change C++'s capabilities any more than those of my hammer. C++ does what it does and is useful where it is used. Unlike my hammer, however, there </span><em><span>is</span></em><span> an entity with the power to degrade C++'s fitness: the C++ standardization committee.</span></p><p><span>The surest way to make a standard irrelevant is to say yes to everything. It is easy to see why: standardizing a complex mess of incoherent ideas quickly becomes “insanity to the point of endangering the future of C++”</span><sup><a href="#fn1" id="fnref1">[1]</a></sup><span>. If my hammer is replaced with a complex gadget requiring thousands of pages of instructions, it is no longer useful for me. Yet, this is exactly our tendency with C++.</span></p><p><span>If C++'s biggest threat is the standardization committee then that begs the question of how to mitigate its risk and align it to a greater good.</span></p><h3 id="Mission1" data-id="Mission"><a href="#Mission1" title="Mission1"><span></span></a><span>Mission</span></h3><p><span>A body comprised of hundreds of individuals cannot function without a unifying mission. There are many ideas of what this should be for WG21, but here are a few strawmen worth considering:</span></p><ol>
<li><span>Make/keep C++ the best language in the world.</span></li>
<li><span>Make C++ the only language people use.</span></li>
<li><span>Make C++ the most popular language.</span></li>
</ol><p><span>The ideas of a “best”, “sole”, or “most popular” language are questionable, but more concerning is their impact. First, this outlook leads to an aversion of other languages both from pride and fear that those other languages might be “better”. Consider, for example, that 40% of C++ developers want to use Rust and 22% already do; ignorance of Rust is ignorance of our users.</span><sup><a href="#fn2" id="fnref2">[2]</a></sup><span> Second, positioning C++ as the “best” language leads to grafting features of other languages at the expense of complexity and consistency. Finally, a lot of energy is expended in useless arguments claiming the benefits of “competing” languages are overblown and that the drawbacks of C++ are exaggerated.</span></p><p><span>We need a more constructive mission and I think there is one: to improve people’s lives. When the range-based for loop reached compilers, millions of developers smiled and said “Ah, that’s nice.” It may have even made their day. This is the kind of massive good within WG21’s control and aligning ourselves to it is incredibly rewarding.</span></p><p><span>An altruistic mindset eliminates the idea of “competitor”. Would Habitat for Humanity morn if the Peace Corps reached a distressed area first? Of course not! They would celebrate the arrival of help. It should be the same with us when our users solve their problem using a different tool. Other language communities helping our users are our allies. We must not forget that. Turf wars don’t serve our users’ interests.</span></p><p><span>Some patterns of thought frustrate a mission of improving people’s lives. Awareness of these is important as they undoubtedly crop up.</span></p><h3 id="C-as-personal-and-group-identity" data-id="C-as-personal-and-group-identity"><a href="#C-as-personal-and-group-identity" title="C-as-personal-and-group-identity"><span></span></a><span>C++ as personal and group identity</span></h3><p><span>One of the first questions programmers ask each other in a social setting is “What language do you program in?”. This frequently sets the stage for unfortunate stereotypes. “Oh, a Java programmer who writes slow code”. “Oh, a Python programmer who cannot program in a ‘real’ language”. “Oh, a Go programmer who …”. When we think of C++ we may find pride in mastery of a difficult language, the ability to write high performance code, and a relationship to the world’s greatest C++ works.</span></p><p><span>While there are benefits to identification with C++ as a source of greatness and purpose, this comes at a cost. First, being primarily an emotional transference, it clouds reason. At my first committee meeting I was advised to avoid mentioning functional programming lest people dismiss my arguments upon hearing the words. Second, deep identification with C++ can create deep seated fears that C++ will become a “legacy” language making one’s skillset (and person even!) obsolete.</span></p><p><span>I mention these things because they frequently compromise a standardization mission to improve people’s lives. We need to assess the programming language world without tribalism tempting us to ignore or overcompensate for issues.</span></p><h3 id="Counterproductive-rhetoric" data-id="Counterproductive-rhetoric"><a href="#Counterproductive-rhetoric" title="Counterproductive-rhetoric"><span></span></a><span>Counterproductive rhetoric</span></h3><p><span>C++ is frequently written and talked about as if it were a living thing. Words like “fatal”</span><sup><a href="#fn3" id="fnref3">[3]</a></sup><span>, “fail”</span><sup><a href="#fn4" id="fnref4">[4]</a></sup><span>, “dead”</span><sup><a href="#fn5" id="fnref5">[5]</a></sup><span>, and “death”</span><sup><a href="#fn6" id="fnref6">[6]</a></sup><span> are common in our literature. When we imagine C++ as a living thing, we naturally associate finite resources (active users), competition (other languages), and death (obsolescence). This thinking is fundamentally inaccurate. C++ is not alive, cannot die, and isn’t competing against anything. It is a merely a tool that is sometimes useful.</span></p><p><span>We must move away from this thinking. In combination with the transference previously discussed, it generates fear and encourages the idea of enemies. The current lack of cooperation and credit between different language communities is quite unfortunate. At its worst people are put down because of the programming language they associate with.</span></p><p><span>Let us remember that a) languages don’t battle, people do, b) smearing other languages doesn’t improve people’s lives, and c) C++ living forever is not our goal.</span></p><h3 id="Standardization-as-personal-opportunity-vs-stewardship" data-id="Standardization-as-personal-opportunity-vs-stewardship"><a href="#Standardization-as-personal-opportunity-vs-stewardship" title="Standardization-as-personal-opportunity-vs-stewardship"><span></span></a><span>Standardization as personal opportunity vs. stewardship</span></h3><p><span>When first joining the committee, it is easy to see participation as primarily a personal opportunity to gain C++ expertise, rub shoulders with celebrities, and, worse of all, leave a mark on the world by getting a proposal accepted. While all these things do indeed happen, there is something much larger at play here.</span></p><p><span>The direction group warns “we are writing a standard for millions of programmers to rely on for decades, a bit of humility is in order.”</span><sup><a href="#fn7" id="fnref7">[7]</a></sup><span> This is not an earnable privilege and none of us are really qualified to make these decisions, but here we are. Our heavy responsibility outweighs the personal opportunities.</span></p><p><span>What does that responsibility entail? It means rejecting proposals without an understandable value proposition. It means resisting social pressure when you are against something. It means building an informed opinion by reading the paper, testing the feature, and collaborating with others. It means saying “yes” only when there is minimal risk. Above all, it means stewardship: you are a caretaker and guardian of something beyond yourself.</span></p><p><span>If you do write a proposal, save time and frustration by enlisting the help of experienced designers and wording experts. They want to help! Also, carefully consider if the problem you’re solving justifies the additional complexity and risk. C++ is a language that is “trying to do too much too fast”</span><sup><a href="#fn8" id="fnref8">[8]</a></sup><span> and needs “to become more restrained and selective”</span><sup><a href="#fn9" id="fnref9">[9]</a></sup><span>.</span></p><h2 id="The-technical-aspect" data-id="The-technical-aspect"><a href="#The-technical-aspect" title="The-technical-aspect"><span></span></a><span>The technical aspect</span></h2><p><span>Equally important to our social tendencies are the technical tendencies that work against us. This section calls out several anti-patterns, none of which are new </span><sup><a href="#fn10" id="fnref10">[10]</a></sup><span>.</span></p><h3 id="Neophilia" data-id="Neophilia"><a href="#Neophilia" title="Neophilia"><span></span></a><span>Neophilia</span></h3><p><span>Bjarne succinctly stated “Enthusiasm favors the new”</span><sup><a href="#fn11" id="fnref11">[11]</a></sup><span>. Technological innovations and fads follow a familiar hype curve </span><sup><a href="#fn12" id="fnref12">[12]</a></sup><span> that begins with a peak of inflated expectations. We risk getting caught up in enthusiasm and standardizing features that, in retrospect, don’t deliver on their promise, poorly integrate with the rest of the language, and increase learning costs.</span></p><p><span>Consider Rust traits which solve similar problems to those of C++ concepts. Traits’s explicit opt-in semantics offers several advantages including separately type-checked generics. Should we add traits to C++? If we do so, we’ll end up with two ways to solve the same problem with millions of lines of code using the old way. Moreover, most developers will need to be familiar with both to be effective in a large, existing codebase, compounding C++'s learning costs.</span></p><p><span>Just because another language has something potentially better than C++ doesn’t mean we should incorporate it. “Keeping up with the Joneses” is a disservice. We should ask ourselves how non-experts, making up most of our users, will react when seeing a feature for the first time in someone else’s code. Frequently it is frustration from having to spend time learning something with marginal benefit over what it replaces.</span></p><h3 id="Features-and-prioritization-bias-towards-experts" data-id="Features-and-prioritization-bias-towards-experts"><a href="#Features-and-prioritization-bias-towards-experts" title="Features-and-prioritization-bias-towards-experts"><span></span></a><span>Features and prioritization bias towards experts</span></h3><p><span>The C++ committee, predominantly comprised of experts, leaves average programmers “seriously underrepresented”</span><sup><a href="#fn13" id="fnref13">[13]</a></sup><span>. This “biases the committee towards language lawyering, advanced features, and implementation issues, rather than directly addressing the needs of the mass of C++ developers, which many committee members know only indirectly”</span><sup><a href="#fn14" id="fnref14">[14]</a></sup><span>.</span></p><p><span>Time spent on expert features squanders opportunities to improve lives at scale. When we prioritize a proposal, we should ask “is this solving a problem for experts or for the average developer?”. If it’s the former, we should seriously consider moving on.</span></p><p><span>Our expert imbalance also results in over-complicated solutions that require advanced proficiencies for simple tasks. Consider the hoops one needs to jump through to make </span><code>std::print</code><span> work with a custom type when compared to the old stream operators. It is too easy for experts to lose touch with novices and professional engineers who don’t spend their free time learning advanced C++ complexities, especially when surrounded by other experts.</span></p><p><span>One of the most valuable things committee members can do is discuss proposals with application engineers. “Is this something you would use?”. “Is this ergonomic?”. “How hard is this to learn?”. “Is this worth another chapter in the C++ book?”. This kind of feedback should weigh more heavily than abstract theories on what an ideal developer should want.</span></p><h3 id="Complexity" data-id="Complexity"><a href="#Complexity" title="Complexity"><span></span></a><span>Complexity</span></h3><p><span>The direction group sees “C++ in danger of losing coherency due to proposals based on differing and sometimes mutually contradictory design philosophies and differing stylistic tastes.” </span><sup><a href="#fn15" id="fnref15">[15]</a></sup><span> Bjarne suspects this is due to a combination of committee growth, an influx of new people, specialization of membership, and a decrease of knowledge of C++'s history among the members.</span><sup><a href="#fn16" id="fnref16">[16]</a></sup></p><p><span>Changes reducing coherence increase complexity and this elevates training costs. Hiring C++ developers is much more challenging than hiring other developers not because of demand, but because the barrier to entry is too high. Fewer people want to learn C++ and fewer schools want to teach it. One of the important ways we can improve people’s lives is to help our users find colleagues.</span></p><p><span>The direction group recalls Alex Stepanov rescuing C++ from disaster by bringing consistency and coherence to the standard library</span><sup><a href="#fn17" id="fnref17">[17]</a></sup><span>, yet we actively debate breaking these same rules for a relatively niche library addition. We recently replaced a simple </span><code>std::function</code><span> template with no less than three alternatives: </span><code>std::copyable_function</code><span>, </span><code>std::function_ref</code><span>, and </span><code>std::move_only_function</code><span>. This isn’t helping our complexity problems!</span></p><p><span>I agree with the design group that we must “aim for coherence”</span><sup><a href="#fn18" id="fnref18">[18]</a></sup><span>. Here are three concrete suggestions for doing so:</span></p><ol>
<li><span>Curb the tendency to focus proposal discussions on a narrow problem domain by asking how it fits within the entire C++ offering. “Is this in the common C++ style?”. “Is this increasing C++'s barrier to entry?”. “How would this impact the hypothetical ‘C++ book’?”</span></li>
<li><span>Encourage study groups to get early feedback from the evolution groups (EWG and LEWG) on the desirability of features.</span><sup><a href="#fn19" id="fnref19">[19]</a></sup><span> Evolution groups are responsible for considering the bigger picture. Getting this feedback before extensive study group iteration can prevent undesirable features gaining difficult-to-stop momentum.</span></li>
<li><span>Overcome reluctance to say, “I don’t think this belongs in C++.” We don’t do authors any favors by providing improvement feedback on proposals that are ultimately undesirable.</span></li>
</ol><h3 id="Niche-problems-getting-more-than-niche-effort" data-id="Niche-problems-getting-more-than-niche-effort"><a href="#Niche-problems-getting-more-than-niche-effort" title="Niche-problems-getting-more-than-niche-effort"><span></span></a><span>Niche problems getting more than niche effort</span></h3><blockquote>
<p><span>[I]t is hard for a committee to remember that a language cannot be all things to all people. It is even harder to accept that it cannot solve even the most urgent problems of every member.</span></p>
<p><span>Bjarne Stroustrup, </span><em><span>Thriving in a Crowded and Changing World</span></em></p>
</blockquote><p><span>In committee, we frequently spend time on things that only a small number of people care about. It’s difficult to say “no” when someone, somewhere would benefit. There’s also a tendency to mentally check-out during these discussions which results in proposals not getting an appropriate rigor.</span></p><p><span>When we fall into these traps, we 1) deny the greater number of users time spent on proposals that can improve their lives, 2) needlessly increase the complexity of the language and library, and 3) encourage more niche proposals.</span></p><p><span>Solving these problems boils down to saying “no” more often and, if needed, repeatedly. Bug fixes aside, the committee should spend its time on a fewer number of proposals that have a bigger impact. Effort spent writing papers solving pet peeves in C++ is better spent writing up analyses and experience reports on higher-impact proposals. We should be doing more to acknowledge such work.</span></p><h2 id="Moving-ahead" data-id="Moving-ahead"><a href="#Moving-ahead" title="Moving-ahead"><span></span></a><span>Moving ahead</span></h2><p><span>This section considers a memory safety and a major C++ overhaul in light this paper’s principles.</span></p><h3 id="Memory-safety" data-id="Memory-safety"><a href="#Memory-safety" title="Memory-safety"><span></span></a><span>Memory safety</span></h3><p><span>Official documents discussing legislation against C++ due its “memory unsafety” have caused community uproar. We’ve seen gigantic email threads, a new study group dedicated to safety, and numerous talks at C++ conferences. What is much less prevalent is a demand from average C++ users for memory safety features; they’re much more concerned about compilation speed. When most C++ developers haven’t adopted tools like Coverity and C++ core guidelines checkers, it is hard to claim that memory safety features substantially improve their lives at least from their point of view.</span></p><p><span>Where memory safety </span><em><span>is</span></em><span> a serious concern, we see the adoption of Rust for critical components. Yet we see little demand from even these developers for C++ safety features. Their problem is already solved.</span></p><p><span>The direction group states “no language can be everything for everybody”</span><sup><a href="#fn20" id="fnref20">[20]</a></sup><span> and I cannot agree more. Rust and other languages are successfully filling engineering needs for memory safety guarantees in critical components. This is not a space our users are demanding us to go into and doing so risks both failure and, yes, even more complexity.</span></p><h3 id="Major-C-overhaul" data-id="Major-C-overhaul"><a href="#Major-C-overhaul" title="Major-C-overhaul"><span></span></a><span>Major C++ overhaul</span></h3><p><span>Over the past two years it’s become in vogue to talk about “C++ successors” which range from dramatic syntax changes to replacing the C++ committee with another organization. What should the committee’s response be to this phenomenon?</span></p><p><span>For groups attempting a new language outside of the committee, I think our response should be support. If these initiatives don’t confuse or otherwise harm our users, they share our goal of improving people’s lives. When they succeed, that’s a good thing. Even if they fail, the ideas they generate might help our users in the end.</span></p><p><span>What about the option to drastically change the face of C++ in the context of WG21? A C++ 2.0, perhaps? If you ask a typical C++ developer how we can improve their lives, a modern and snazzy new syntax will not top their list. Yes, </span><code>template</code><span> and </span><code>typename</code><span> are tedious to read and type, but it’s what they know and they’d rather it not be mucked with. This is more than reluctance to change–our users want coherence in their C++ code base as much as we want coherence in the standard.</span></p><p><span>If a C++ successor ever gains traction, our users would want it to be the best it can be. The committee composition doesn’t have a magical quality that makes it more suited to build a successor than any other entity. The inertia from C++ 1.0’s adoption may even lead to a C++ 2.0 getting adopted when other successor attempts are more fit for purpose. That wouldn’t be good for our users.</span></p><p><span>In summary, the C++ committee’s biggest opportunity to improve people’s lives is to focus on C++ as it is today to serve us better in a few years time under the constraints of compatibility. Let’s leave speculative successor projects to external entities. We’re distracted enough as it is.</span></p><h3 id="What-should-we-do" data-id="What-should-we-do"><a href="#What-should-we-do" title="What-should-we-do"><span></span></a><span>What should we do?</span></h3><p><span>I’ve said a lot about what we should not do. That’s intentional–we need to do less. However, I don’t want to give the impression we should say no to </span><em><span>all</span></em><span> proposals. There are plenty of opportunities to improve our user’s lives through proposals. Here are a few concrete examples:</span></p><ul>
<li>
<p><strong><span>Faster hashing and hash combiners</span></strong><span>. The standard library’s hash map and hash set interfaces are now decades old. Over that time, we’ve seen an explosion in their utility and many algorithmic advancements, advancements that require an interface change. By adding more modern hashing data structures to the standard, we can substantially improve the performance, and environmental impact, of newly written code. Our users also desperately need a standardized way to combine hashes in their own hash functions.</span></p>
</li>
<li>
<p><strong><span>JSON parsing</span></strong><span>. A simple, ergonomic, standardized JSON parsing and serialization library will save many users from searching libraries or, worse, writing custom formats. A non-goal is to be the world’s fastest JSON parser.</span></p>
</li>
<li>
<p><strong><span>Command-line parsing</span></strong><span>. A simple, standardized library for command-line parsing will also improve the lives of the 99% by replacing the common </span><code>argv[1]</code><span> parsing in small applications.</span></p>
</li>
</ul><p><span>There are many more ideas like these. The goal is to give as many people as possible the “ah, that’s nice” reaction.</span></p><h2 id="Conclusion" data-id="Conclusion"><a href="#Conclusion" title="Conclusion"><span></span></a><span>Conclusion</span></h2><p><span>This paper advocates for a C++ standardization mission: improving people’s lives. It also identified the social and technical biases that obstruct this mission. Finally, it considered major ongoing WG21 discussions and suggested ideas for future work.</span></p><p><span>In the end, when I say “C++ should be C++” I mean that C++ is a useful tool as it is–drastic changes aren’t helpful. To avoid it becoming what it is not, we need to say “no” more often, recognize our biases, and, above all, put our users first.</span></p><h2 id="References" data-id="References"><a href="#References" title="References"><span></span></a><span>References</span></h2><p><span>“2023 Developer Survey.” </span><em><span>Stack Overflow</span></em><span>, 2023, </span><a href="https://survey.stackoverflow.co/2023/" target="_blank" rel="noopener"><span>https://survey.stackoverflow.co/2023/</span></a><span>.</span></p><p><span>Hinnant, Howard et al. “Direction for ISO C++.” 15 October 2022, </span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>https://wg21.link/P2000R4</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. “How can you be so certain?” 18 November 2019, </span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>https://wg21.link/P1962R0</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. “Remember the Vasa!” 6 March 2018, </span><a href="https://wg21.link/P0977R0%5D" target="_blank" rel="noopener"><span>https://wg21.link/P0977R0</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. “Thriving in a Crowded and Changing World: C++ 2006-2020.” </span><em><span>Proc. ACM Program. Lang.</span></em><span>, vol. 4, HOPL, June 2020, Article 70, pp. 1-167,  </span><a href="https://doi.org/10.1145/3386320" target="_blank" rel="noopener"><span>https://doi.org/10.1145/3386320</span></a><span>.</span></p><p><span>van Winkel, J.C. et al. “Operating principles for evolving C++” 31 Janurary 2017, </span><a href="https://wg21.link/P0559R0" target="_blank" rel="noopener"><span>https://wg21.link/P0559R0</span></a><span>.</span></p><hr><section>
<ol>
<li id="fn1"><p><em><span>Remember the Vasa!</span></em><span> (</span><a href="https://wg21.link/P0977R0" target="_blank" rel="noopener"><span>P0977R0</span></a><span>)</span> <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p><span>The Stack Overflow 2023 survey had 89,184 respondents. 19,634 indicated they did "extensive development work" C++ over the past year and 4,269 claimed extensive development work in both Rust and C++ over the past year. Of those who used C++, 7,918 indicated a desire to work in Rust over the next year.</span> <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a> <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p><em><span>How can you be so certain</span></em><span> (</span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>P1962R0</span></a><span>)</span> <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p><em><span>Operating principles for evolving C++</span></em><span> (</span><a href="https://wg21.link/P0559R0" target="_blank" rel="noopener"><span>P0559R0</span></a><span>)</span> <a href="#fnref5">↩︎</a></p>
</li>
<li id="fn6"><p><span>ibid.</span> <a href="#fnref6">↩︎</a></p>
</li>
<li id="fn7"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref7">↩︎</a></p>
</li>
<li id="fn8"><p><em><span>How can you be so certain?</span></em><span> (</span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>P1962R0</span></a><span>)</span> <a href="#fnref8">↩︎</a></p>
</li>
<li id="fn9"><p><span>ibid.</span> <a href="#fnref9">↩︎</a></p>
</li>
<li id="fn10"><p><span> See </span><em><span>Thriving in a Crowded and Changing World</span></em><span> and </span><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref10">↩︎</a></p>
</li>
<li id="fn11"><p><span> </span><em><span>Thriving in a Crowded and Changing World</span></em><span> </span> <a href="#fnref11">↩︎</a></p>
</li>
<li id="fn12"><p><span> https://en.wikipedia.org/wiki/Gartner_hype_cycle </span> <a href="#fnref12">↩︎</a></p>
</li>
<li id="fn13"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref13">↩︎</a></p>
</li>
<li id="fn14"><p><em><span>Thriving in a Crowded and Changing World</span></em> <a href="#fnref14">↩︎</a></p>
</li>
<li id="fn15"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref15">↩︎</a></p>
</li>
<li id="fn16"><p><em><span>Thriving in a Crowded and Changing World</span></em> <a href="#fnref16">↩︎</a></p>
</li>
<li id="fn17"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref17">↩︎</a></p>
</li>
<li id="fn18"><p><span>ibid.</span> <a href="#fnref18">↩︎</a></p>
</li>
<li id="fn19"><p><span>Credit to Niall Douglas for this idea</span> <a href="#fnref19">↩︎</a></p>
</li>
<li id="fn20"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref20">↩︎</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bit banging a 3.5" floppy drive (207 pts)]]></title>
            <link>https://floppy.cafe/</link>
            <guid>38699201</guid>
            <pubDate>Tue, 19 Dec 2023 18:09:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://floppy.cafe/">https://floppy.cafe/</a>, See on <a href="https://news.ycombinator.com/item?id=38699201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <h2>Bit Banging a 3.5" Floppy Drive</h2>
      
      <p>
        Welcome to the <b>floppy cafe</b>! These pages are the lost and sacred
        texts you've been looking for if you happen to be writing a driver for
        a 3.5" floppy. To learn these mysteries, I bit-banged a floppy drive
        using a
        <a href="https://www.pjrc.com/store/teensy40.html" target="_blank" rel="noreferrer">teensy4.0</a>
        and managed to write a full driver for it. My project code is hosted
        <a href="https://github.com/SharpCoder/floppy-driver-rs" target="_blank" rel="noreferrer">here on github</a>
        in case you'd like to learn more. Continue reading for an extremely
        detailed overview of the project and all my findings on this adventure.
        <b>Although the information is largely common for any floppy drive,
          floppy.cafe is dedicated specifically to 3.5" media.
        </b>
      </p>
      <h2>Table of Contents</h2>
      
        
        
        
        
        
        
      
      <h2>
        <a id="how-do-floppy-disks-work" href="#how-do-floppy-disks-work"><img src="https://floppy.cafe/media/link.png"></a>How do Floppy Disks
        Work?
      </h2>
      <p>
        This
        <a href="http://philipstorr.id.au/pcbook/book4/floppyd.htm" target="_blank">website</a>
        has a good overview and some nice pictures. Fundamentally, your floppy
        houses a magnetized disk that spins at about 300rpm. For 3.5" media,
        that disk contains 80 tracks. Each track has 18 sectors. Each sector has
        512 bytes of user-space data (and some more bytes used for metadata).
        Most "modern" floppies are double-sided, so you can multiply all that by
        2 in order to find the total amount of usable space per disk.
        <code>1,474,560 bytes</code> in all.
      </p>
      <p>
        <b>Fun fact!</b> floppy disks actually contain a lot more surface area
        than 1.44mb. By my calculation, you'll get closer to 1.70mb but a lot of
        that extra space is earmarked for
        <a href="#synchronization-barriers">synchronization barriers</a> and
        sector / track metadata.
      </p>
      <h2>
        <a id="wiring-guide" href="#wiring-guide"><img src="https://floppy.cafe/media/link.png"></a>
        Wiring Guide
      </h2>
      <p>
        Here's the cool thing about floppy drives: they have no communication
        protocol! It's just a bunch of gpio pins. For most of them, pulling the
        pin <code>HIGH</code> means it is in the "disabled" or "off" state.
        Pulling a pin <code>LOW</code> will activate it. You can read about the
        very detailed specifications for the
        <a href="https://floppy.cafe/resources/SAMSUNG-SFD321B-070103.pdf" target="_blank">SAMSUNG-SFD321B</a>
        floppy drive. The top row of pins are the functions, the bottom row of
        pins are all <b>LOGIC GROUND</b>. Logic. Did you get that? LOGIC! Not
        motor ground. I had them wired up wrong for weeks and wondered why
        nothing worked. And, yes, there's like a million ground pins but you
        only need 1 to get it working.
      </p>
      <p>
        <b>An important note!</b> the logic-level pins are rated for 5v,
        however, you can use 3v3 in a pinch! Why is that? All these data pins
        are <i>open drain</i> and should be hooked up to a
        <i>pull-up resistor</i>. That means the only way these floppy drives
        communciate back is by sinking the voltage. So 3v3, 5v, it doesn't
        matter. The floppy drive will happily pull it down.
      </p>
      <p>
        <b>Protip!</b> Some of the bottom row of pins are
        <b>not connected internally!</b> So if you are plugging in just 1 ground
        wire and it's not working, chances are the ground pin you selected is
        disconnected. Try another one.
      </p>
      <img alt="A page from a guide showing what each pin on the back of a floppy drive does." src="https://floppy.cafe/media/pins.png">
      <p>
        You'll notice the power section only needs two wires. 5v+ and another
        ground. For your sanity, I suggest using a separate power bus than
        whatever your microcontroller is on.
      </p>
      <p>
        Please do not connect the 5v+ to an arduino or a GPIO! It can draw
        upwards of 1A during really feisty operations and it will
        <b>fry your microcontroller!</b>
      </p>
      <h2>
        <a id="sending-commands" href="#sending-commands"><img src="https://floppy.cafe/media/link.png"></a>Sending Commands
      </h2>
      <p>
        There are a number of commands and proceedures you will need to
        implement in order to assume control of the floppy drive. In general,
        commands are issued by pulling a given pin <code>LOW</code>.
      </p>

      <p>
        <b>A word of warning:</b> I've read online the Arduino internal pull-ups
        aren't great. They'll work for most of these pins
        <i>except the data line</i>. You may want to add a 4.5k pull-up to the
        <code>DATA</code> line instead of relying on the built-in pull-ups.
      </p>
      <p>Alright! Let's explore each function you have access to.</p>

      <h3>Index</h3>
      <p>
        The floppy drive doesn't really know <i>where</i> you are at any given
        time. You can suss this out with various mechanisms, and one of those
        mechanisms is the <b>INDEX</b> pin. The index pin is the first usable
        pin on the top row (pin 8). When this pin is <code>LOW</code>, the disk
        has made one complete revolution and is currently at the start of the
        data stream.
      </p>
      <p>
        In my driver, I would often look for <code>HIGH</code> to
        <code>LOW</code> transitions and use this to increment an error counter.
        If I can't complete some task after 10 revolutions or so, I consider the
        drive in a bad state.
      </p>

      <h3>Drive Select</h3>
      <p>
        There are a few different drive select pins (often for drive 0, 1, and
        2) but the main one we're interested in is
        <code>PIN 12</code> also known as <code>DRIVE SELECT 1</code>. The other
        ones are reserved for controlling multiple floppy drives at once. This
        function is used to enable the floppy drive. Pulling it
        <code>LOW</code>
        will provide you access to all the other I/O functions except
        <code>MOTOR ON</code>. That one is agnostic of drive select.
      </p>
      <h3>Motor On</h3>
      <p>
        As the name suggests, this pin is dedicated to controlling the motor. To
        enable the motor, pull this pin
        <code>LOW</code> and then wait 500ms. It's good practice to monitor the
        <code>INDEX</code> line as well for a <code>HIGH</code> to
        <code>LOW</code> transition, indicating that the spindle has made a
        complete revolution.
      </p>
      <h3>Direction Select</h3>
      <p>
        This pin controls the direction that the track <b>stepper motor</b> pin
        will move in, when you pulse the <code>STEP</code> pin. Pulling this pin
        <code>LOW</code> will orient the track stepper motor to move towards the
        center of the magnetic disk (increasing the track number). Pulling this
        pin <code>HIGH</code> will orient the track stepper to move towards the
        outside of the magnetic disk (decreasing the track number).
      </p>
      <h3>Step</h3>
      <p>
        There are 80 tracks on your average 3.5" floppy drive. You can select a
        given track by pulsing the <code>STEP</code> pin and combining it with
        the <b>direction select</b> pin.
      </p>
      <p>
        Pulsing this pin will charge and actuate a stepper motor. As such, there
        are some specific timing requirements. I like to pull it
        <code>LOW</code> for <code>3ms</code> and then pull it
        <code>HIGH</code> for an additional <code>3ms</code> and leave it in the
        high state until the next pulse. The documentation states it can be low
        for as short as <code>0.15us</code> but that didn't work for me
        consistently across other drives.
      </p>
      <h3>Write Data</h3>
      <p>
        If you want to know a lot more about this pin, head on over to the
        <a href="https://floppy.cafe/mfm.html">MFM ENCODING</a> page for a primer on how to use it.
        From a technical perspective, pulsing this pin will reverse the flux
        direction on the magnetized disk. In general, you will hold the pin
        <code>LOW</code> for about <code>0.15us to 1.1us</code> and then bring
        it back to a <code>HIGH</code> state. How long it remains in the high
        state determines the encoded value according to the MFM rules.
      </p>
      <h3>Write Gate</h3>
      <p>
        Pusling the write data pin will do nothing if the gate is closed. To
        begin writing data, you must pull this pin <code>LOW</code> and keep it
        low during your write operation.
      </p>
      <p>
        <b>You cannot read and write at the same time.</b>
      </p>
      <p>
        <b>Fun fact!</b> While I was developing my driver, I ruined many entire
        tracks by leaving this open for too long. If you aren't careful, it'll
        wreck the sector metadata and synchronization barriers and totally
        destroy your floppy disk. Reformatting the disk should restore balance
        to the force, so this won't be a total loss.
      </p>
      <h3>Track 00</h3>
      <p>
        The floppy drive controls this pin, and when it gets pulled
        <code>LOW</code> that means the read/write head is positioned on
         the first track  (<b>track 0</b>).
      </p>
      <h3>Write Protect</h3>
      <p>
        When a write-protected media is insertted, this pin will be pulled
        <code>LOW</code> by the floppy drive and the data on the disk is
        protected from mis-erasing. When the pin is <code>HIGH</code> the
        floppy drive can be written.
      </p>
      <p>
        This only seems to work if the <b>drive select</b> pin has been pulled
        low.
      </p>
      <h3>Read Data</h3>
      <p>
        A <code>HIGH</code> to <code>LOW</code> transition on this line
        indicates the flux direction has changed on the underlying magnetic
        disk. Once you encouter this transition, count all the clock cyles
        between the <i>leading edge</i> of the <code>LOW</code> signal to the
        <i>trailing edge</i> of the <code>HIGH</code> signal.
      </p>
      <h3>Side Select</h3>
      <p>
        These 3.5" floppy disks have 2 sides. Pulling this pin
        <code>HIGH</code> selects the lower side (side 0). Pulling this pin
        <code>LOW</code> selects the upper side (side 1).
      </p>
      <h3>Ready/Disk Change</h3>
      <p>
        I never got this to work, but the spec says it will either tell you if
        the drive is in a ready state or not. When the floppy drive pulls this
        pin <code>LOW</code>, the drive is ready for operation. Otherwise, the
        pin will be left in a <code>HIGH</code> state.
      </p>
      <h2>
        <a id="synchronization-barriers" href="#synchronization-barriers"><img src="https://floppy.cafe/media/link.png"></a>Synchronization
        Barriers
      </h2>
      <p>
        Between each track is a synchronization barrier. This barrier is
        surprisingly easy to find because it is just 12 <code>0x0</code> bytes
        followed by 3 <code>0xA1</code> bytes. In terms of pulses, it amounts to
        to 96 short pulses followed by the sequence of pulses <code>MLMLMSLMLMSLMLM</code>.
        You may have trouble reading all 96 pulses because of timing. A common
        practice is to seek for at least 80 pulses instead.
        This will give you a bit more resilience.
      </p>
      <h2>
        <a id="sector-metadata" href="#sector-metadata"><img src="https://floppy.cafe/media/link.png"></a>Sector Metadata
      </h2>
      <p>
        Each sector is comprised of some metadata to describe it. The metadata
        is formatted like so:
        </p><ul>
          <li>12 bytes of <b>0x0</b></li>
          <li>3 bytes of <b>0xA1</b></li>
          <li>One byte of <b>0xFE</b></li>
          <li>One byte to indicate the track number</li>
          <li>One byte to indicate the side (or head)</li>
          <li>One byte to indicate thes sector number</li>
          <li>One byte to indicate the sector size</li>
          <li>2 bytes of CRC (cyclic redundancy code) computed from the sector
            metadata</li>
          <li>22 bytes of <b>0x4E</b></li>
          <li>12 bytes of <b>0x0</b></li>
          <li>3 bytes of <b>0xA1</b></li>
          <li>1 byte of either <b>0xFA</b> or <b>0xFB</b></li>
          <li>512 bytes of user data</li>
          <li>2 bytes of CRC computed from the user data</li>
          <li>Unspecified amount of <b>0x4E</b> bytes filling in the remaining
            space between sectors</li>
        </ul>
      
      <p>
        Upon careful inspection, we can see there are actually two
        synchronization barriers. One to find the sector metadata, and another
        to find the userspace data.
        The only difference is the byte that follows. For sectors, the immediate
        byte after the barrier is <b>0xFE</b>. For userspace data, it's either
        <b>0xFA</b> or <b>0xFB</b>.
        This is how we can determine which kind of barrier we've run into.
      </p>
      <h2>
        <a id="track-metadata" href="#track-metadata"><img src="https://floppy.cafe/media/link.png"></a>Track Metadata
      </h2>
      <p>
        Each track also has its own set of metadata which is formatted like so:
        </p><ul>
          <li>80 bytes of <b>0x4E</b></li>
          <li>12 bytes of <b>0x00</b></li>
          <li>3 bytes of <b>0xC3</b></li>
          <li>One byte of <b>0xFC</b></li>
          <li>50 bytes of <b>0x4E</b></li>
        </ul>
      
      <h2>
        <a id="further-reading" href="#further-reading"><img src="https://floppy.cafe/media/link.png"></a>Further Reading
      </h2>
      <p>
        Here is a comprehensive list of additional resources:
        </p><ul>
          <li><a href="https://floppy.cafe/resources/SAMSUNG-SFD321B-070103.pdf" target="_blank" rel="noreferrer">SFD321B-070103.pdf</a></li>
          <li><a href="http://philipstorr.id.au/pcbook/book4/floppyd.htm" target="_blank" rel="noreferrer">Floppy Disk Formats</a></li>
          <li><a href="http://www.interfacebus.com/PC_Floppy_Drive_PinOut.html" target="_blank" rel="noreferrer">Floppy Drive PinOut</a></li>
          <li><a href="https://www.5volts.ch/posts/mfmreader/" target="_blank" rel="noreferrer">MFM Reader</a></li>
          <li><a href="https://github.com/SharpCoder/floppy-driver-rs" target="_blank" rel="noreferrer">(github) Floppy Driver RS</a></li>
          <li><a href="https://github.com/adafruit/Adafruit_Floppy/tree/main" target="_blank" rel="noreferrer">(github) Adafruit Floppy Reader</a></li>
          <li><a href="https://github.com/dhansel/ArduinoFDC" target="_blank" rel="noreferrer">(github) Arduino FDC</a></li>
        </ul>
      
      <p>
        Next, let's check out <a href="https://floppy.cafe/mfm.html">MFM ENCODING</a> to learn more
        about how data is stored.
      </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK plan to digitise wills and destroy paper originals "insane" say experts (158 pts)]]></title>
            <link>https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts</link>
            <guid>38699007</guid>
            <pubDate>Tue, 19 Dec 2023 17:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts">https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts</a>, See on <a href="https://news.ycombinator.com/item?id=38699007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>“Sheer vandalism” and “insane”. This is how leading historians on Monday described government plans to destroy millions of historical wills to save on storage costs.</p><p>The Ministry of Justice is <a href="https://www.gov.uk/government/news/easier-access-to-historic-wills-under-new-government-plans" data-link-name="in body link">consulting</a> on digitising and then throwing away about 100m paper originals of the last wills and testaments of British people dating back more than 150 years in an effort to save £4.5m a year.</p><p>But Tom Holland, the classical and medieval historian and co-host of The Rest is History podcast, said the proposal to empty shelves at the Birmingham archive was “obviously insane”. Sir Richard Evans, historian of modern Germany and modern Europe, said “to destroy the original documents is just sheer vandalism in the name of bureaucratic efficiency”.</p><p>Ministers believe digitisation will speed up access to the papers, but the proposal has provoked a backlash among historians and archivists who took to X to decry it as “<a href="https://twitter.com/onslies/status/1736355233066815905" data-link-name="in body link">bananas</a>” and “<a href="https://twitter.com/richove/status/1736349743008059523" data-link-name="in body link">a seriously bad idea</a>”.</p><p>The government is proposing to keep the originals of some wills of “famous people” – likely including those of Charles Darwin, Charles Dickens and Diana, Princess of Wales – but others would be destroyed after 25 years and only a digital copy would be kept.</p><p>It is feared that wills of ordinary people, some of whom may become historically significant in the future, risk being lost.</p><p>Wills are considered essential documents, particularly for social historians and genealogists, as they capture what people considered important at the time and reveal unknown family links.</p><p>The proposal comes amid growing concern at the fragility of digital archives, after a cyber-attack on the British Library left the online catalogue and digitised documents <a href="https://blogs.bl.uk/living-knowledge/2023/11/cyber-incident.html" data-link-name="in body link">unavailable</a> to users since late October.</p><p>The apparent vulnerability was also revealed this month when the prime minister, Rishi Sunak, and the former prime minister Boris Johnson both claimed they could no longer access WhatsApp messages sought by the UK Covid-19 public inquiry.</p><p>“My real anxiety is that if everything is digitised, somebody pulls the plug,” said Holland whose awareness of the risks of mixing digitisation and archives is all the greater as he is a board member of the British Library.</p><p>Hardware goes out of date and so it might not be available in the future to recall the scanned documents, he said. Access to original documents was vital as “the physicality of the evidence matters … it is an important part of the material culture”.</p><p>Evans, who advises the government on handling claims for art works looted by the Nazis, said he felt “shock and horror” at the plan. He said the idea that officials can choose which wills to keep because, in the words of the MoJ, they “belong to notable individuals or have significant historical interest”, is “the typical arrogance of bureaucracy”.</p><p>The government is seeking views on suitable criteria for deciding whose wills to keep.</p><p>He cited the example of Mary Seacole, the <a href="https://www.maryseacoletrust.org.uk/learn-about-mary/" data-link-name="in body link">Jamiacan nurse</a> who helped British soldiers during the Crimean war in the 1850s, whose story has been revived in recent years.</p><p>“Fifty years ago, who would have thought that Mary Seacole was important or her will worth preserving?” he said. “People who are now thought of as obscure will become famous in the future because what we consider important changes over time.”</p><p>The human connection of handling the original wills and “the feel of the old rag-based pulp paper” would be lost too, he said.</p><p>“You can see the indent of the pen and if the writer is excited or tense. There are minute details on the page which digitisation [can’t capture]. There is a thrilling sensation that you are looking at a document that a real human being wrote on. You get a connection to the past that digitised versions won’t give you.”</p><p>Will Iredale, a second world war historian, and author of The Pathfinders, said: “There’s nothing like getting your hands on the original documents – you can be sure of the source and that is really important. How can you trust whoever is digitising them has scanned them correctly and you are seeing the entire document. Are there going to be robust enough websites to store and deliver this wonderful history?” he said.</p><p>The MoJ is considering “keeping hard copies for about 25 years, in recognition of their sentimental value to families, while saving them digitally longer term.”</p><p>Justice minister, Mike Freer, said: “We want to make it as easy for amateur and professional historians alike to access these documents. Digitalisation allows us to move with the times and save the taxpayer valuable money, while preserving paper copies of noteworthy wills which hold historical importance.”</p><p>A programme of working backwards to digitise all older documents will begin, the MoJ said, claiming that once digitised, access requests will be serviceable much more quickly.</p><p>But the Society of Genealogists is “seriously concerned”, said Natalie Pithers, interim co-chief executive. She said wills are “absolutely vital” social-historical documents and highlighted the emotional impact of seeing an original signature on a historic will for a family member.</p><p>“We are advocates of digitisation but not at the cost of destroying originals,” she said. “In any digitisation projects mistakes get made. We don’t know what further information could be gained in the future from the original documents. There could be somebody in there who did something extraordinary.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simulating fluids, fire, and smoke in real-time (658 pts)]]></title>
            <link>https://andrewkchan.dev/posts/fire.html</link>
            <guid>38698907</guid>
            <pubDate>Tue, 19 Dec 2023 17:51:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrewkchan.dev/posts/fire.html">https://andrewkchan.dev/posts/fire.html</a>, See on <a href="https://news.ycombinator.com/item?id=38698907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <h2>Notes on the math, algorithms, and methods involved in simulating fluids like fire and smoke in real-time.</h2>
    <dt-byline></dt-byline>
    <p>
      <em>Source code for this article can be found on <a href="https://github.com/andrewkchan/andrewkchan.github.io/tree/main/source/posts-source/blog-fire">my GitHub</a>.</em>
    </p>
    <p>
      Fire is an interesting graphics problem. Past approaches generally faked it. For example,
      <i>Lord of the Rings</i> <dt-cite key="Aitken:2004:LRV:1103900.1103911"></dt-cite> used sprites with lots and lots of smoke
      (the fluid sim was too expensive at the time, even for movies).
      Real-time applications like video games have pretty much exclusively
      used non-physical approaches.
    </p>
    <iframe width="560" height="400" src="https://www.youtube.com/embed/OieygwngQ6E?si=9kSBKO0WiDgVV0Oe" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
    <p>
      But in the last 10 years GPUs have made fast fluid simulation easy.
      Basic fluid dynamics algorithms are straightforward to implement on the GPU <dt-cite key="harris2005fast"></dt-cite>. In 2009, ILM used these techniques to model and render fire in
      <i>Harry Potter</i> <dt-cite key="horvath2009directable"></dt-cite>.
      And in 2014, NVIDIA released FlameWorks, a whole system for generating fire and smoke effects for games.
    </p>
    <p>
      This post takes notes on how fire can be simulated on the GPU. It walks through the math behind fluid dynamics,
      parallel algorithms for modeling fluids, and the extra combustion bits that make fire special. Readers should have a reasonable
      background in vector calculus and differential equations (know how to take the gradient of a vector). Demos are implemented with WebGL.
    </p>
    <dt-byline></dt-byline>
    <h2>1. Fluid Simulation</h2>
    <p>
      Before we simulate fire, we need to simulate fluid. We assume
      our fluid is <a href="https://en.wikipedia.org/wiki/Incompressible_flow">incompressible</a> and
      <a href="https://en.wikipedia.org/wiki/Inviscid_flow">inviscid</a>, which will vastly simplify our problem.
    </p>
    <h3>1.1 Basic Fluid Dynamics</h3>
    <p>
      Suppose \(D\) is a region in space filled with a fluid. At any point \( \mathbf{x} \in D \) and time \(t\), the fluid has velocity \(\mathbf{u}(\mathbf{x}, t)\).
      Computationally, we can represent the 2D velocity field \( \mathbf{u} \) with an \( N \times N \) grid, where the equally spaced grid points give the value of
      the velocity field at that point in space.
    </p>
    
    <p>
      <em>Ex: A 16\(\times\)16 grid representing \( \mathbf{u} = (y, -x) \)</em>
    </p>
    <p>
      What will happen if we put a drop of dye in the fluid?
    </p>
    <p>
      Let's define a scalar field \( \psi (\mathbf{x}, t) \) as the density of the dye at any point in space and time.
      The transport of quantities like \( \psi \) within a fluid by the fluid's velocity is called <b>advection</b>.
      Given some fluid's velocity field and an initial density field of our dye, we'd like to see how the dye's density everywhere
      evolves over time by simulating its advection through the fluid.
    </p>
    <p><b>A Naive Method for Advection</b></p>
    <p>
      One idea <dt-fn>As seen below, our scalar field can be expressed as a differential equation. This idea is using Euler's method to solve it.</dt-fn> to compute
      the advection is to take each grid point, move forward the direction and distance that would be traveled
      by a particle at the grid point's velocity and the simulation timestep \( \Delta t \), and update the grid point nearest to where the particle lands:

      $$
      \psi (\mathbf{x} + \mathbf{u} (\mathbf{x}, t), t + \Delta t) = \psi (\mathbf{x}, t)
      $$
    </p>
    <p>
      But this is tricky to parallelize, since 2 grid points can end up in the same target point after forward evaluation.
      And in practice, the target point will fall between grid points, meaning it has to be interpolated into the surrounding grid points. Finally, this process is
      unstable for time steps above some number, causing  \( \psi \) to blow up.
    </p>
    <p><b>The Advection Partial Differential Equations</b></p>
    <p>
      This whole time we've been solving a partial differential equation! If we're going to derive a stable method for advection, we'll need to
      first get an explicit expression for this PDE. Let's start from first principles.
    </p>
    <p>
      Consider a fixed region of space \(W\) (that is, \(W\) does not vary with time). The total mass of dye within \(W\)
      is \( \int_{W} \psi dV\). Over time, the change in mass is:

      $$
      \frac{d}{dt} \int_{W} \psi (\mathbf{x}, t) dV = \int_{W} \frac{\partial}{\partial t} \psi (\mathbf{x}, t) dV \\
      $$

      Now, letting \(S\) denote the surface of \(W\) and \( \mathbf{n} \) the outward normal vector defined along the surface, we can examine
      the mass flow rate through the surface of \(W\). In particular, observe that the volume flow rate - the <i>volume</i> of fluid that
      flows through per second  - across \(S\) per unit area is \( \mathbf{u} \cdot \mathbf{n} \) and the mass flow rate per unit area
      is \( \psi \mathbf{u} \cdot \mathbf{n} \).
    </p>
    
    <p>
      This gives us the <b>law of conservation of mass</b> in integral form:

      $$
      \frac{d}{dt} \int_{W} \psi dV = - \int_{S} \psi \mathbf{u} \cdot \mathbf{n} dA
      $$

      Can we get rid of the integrals and say something similar for points? By divergence theorem, the above is equivalent to

      $$
      \int_{W} [\frac{\partial \psi}{\partial t} + \nabla \cdot (\psi \mathbf{u})] dV = 0
      $$

      Then for a unit subregion \( W = dV \), we can say that

      $$
      \frac{\partial \psi}{\partial t} + \nabla \cdot (\psi \mathbf{u}) = 0
      $$

      This gives us an explicit PDE that we need to solve for \( \psi \)!
    </p>
    <p>
      Hmm... we could stop here, but we might be able to simplify this more. Specifically, it looks like we could isolate out
      a term \( \nabla \cdot \mathbf{u} \) that goes to zero because of incompressibility.

      $$
      \begin{aligned}
      &amp;\frac{\partial \psi}{\partial t} = - \nabla \cdot (\psi \mathbf{u}) \\
      &amp;= - (\frac{\partial}{\partial x} \psi u + \frac{\partial}{\partial y} \psi v) \\
      &amp;= - (\frac{\partial \psi}{\partial x} u + \frac{\partial u}{\partial x} \psi +  \frac{\partial \psi}{\partial y} v + \frac{\partial v}{\partial y} \psi) \\
      &amp;= - (\psi \nabla \cdot \mathbf{u} + \mathbf{u} \cdot \nabla \psi) \\
      &amp;= - \mathbf{u} \cdot \nabla \psi \\
      \end{aligned}
      $$

      Applying our incompressibility constraint \( \nabla \cdot \mathbf{u} = 0 \) at the end yields a scalar PDE, the first of our <b>incompressible flow advection equations</b>:

      $$
      \frac{\partial \psi}{\partial t} = \text{advection} (\mathbf{u}, \psi) = - \mathbf{u} \cdot \nabla \psi \tag{1}
      $$
      $$
      \frac{\partial \mathbf{v}}{\partial t} = \text{advection} (\mathbf{u}, \mathbf{v}) = - \mathbf{u} \cdot \nabla \mathbf{v} \tag{2}
      $$

      Eq. 2 for advecting a vector field \( \mathbf{v} \) through our velocity field can be derived similarly to the scalar advection equation.
    </p>
    <p><b>A Stable Method for Advection</b></p>
    <p>
      Let's look closely at eqn. (1):
      $$
      \frac{\partial \psi}{\partial t} = - \mathbf{u} \cdot \nabla \psi
      $$
    </p>
    <p>
      Notice that the right-hand term is a directional derivative in the \( -\mathbf{u} \) direction. This gives us a wonderful new method for
      advecting \( \psi \) by an incompressible fluid - starting at a grid point \( \mathbf{x} \), trace the fluid velocity <i>backwards</i>,
      replacing the value at our original point by the value that we land on (if we land between points, we can interpolate):

      $$
      \psi (\mathbf{x}, t + \Delta t) = \psi (\mathbf{x} - \mathbf{u} (\mathbf{x}, t), t)
      $$

      In GPU pseudocode:
    </p>
    <!-- <dt-code block language="glsl"> -->
      <pre>        <code>
          global Vec2Field u;
          global FloatField density;
          global float dt;

          // Run for each point in our scalar grid that we want to update
          float advectPoint(vec2 x) {
            vec2 coord = x - dt * getVec2At(u, x);
            return getFloatAt(density, coord);
          }
        </code>
      </pre>
    <!-- </dt-code> -->
    <p>
      This method is called
      <b>Semi-Lagrangian advection</b> and was invented in 1999 by Jos Stam <dt-cite key="stam1999stable"></dt-cite>.
      Like Euler, it's first-order accurate, but has exactly the additional properties we need:
    </p>
    <ol>
      <li>
        It's extremely easy to parallelize because each grid point only gets updated once per iteration.
      </li>
      <li>
        It's <i>unconditionally stable</i>. Why? Observe that for any grid point, the maximum value it can get updated to is the maximum value
        of all the grid points.
      </li>
    </ol>
    <p>
      For a fixed velocity field fulfilling the incompressibility constraint, it works great.
    </p>
    
    <p>
      <em>Click anywhere above to drop some dye in the flow</em>
    </p>
    <dt-byline></dt-byline>
    <h3>1.2 The Navier-Stokes Equations</h3>
    <p>
      So far we've found a model that describes how scalar properties of a fluid evolve over time, assuming the flow is fixed. What about the fluid flow itself -
      how does the velocity field \( \mathbf{u} \) affect itself over time?
    </p>
    <p>
      The <b>Navier-Stokes equations</b>
      <dt-fn>For a detailed derivation, see Chapter 1.3 of Chorin and Marsden (1993).</dt-fn>
      <dt-fn>
        Famous for the <a href="https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_existence_and_smoothness">Navier-Stokes existence
        and smoothness</a> problem, one of the Clay Institute's seven Millenium Prize problems in math.
      </dt-fn>
      for incompressible flow define how the velocity at any point in a fluid evolves over time:

      $$
      \frac{\partial \mathbf{u}}{\partial t} =
      {\underbrace{ - \mathbf{u} \cdot \nabla \mathbf{u} }_\text{self-advection}} +
      {\underbrace{ \mu^2 \nabla \mathbf{u} }_\text{diffusion}} -
      {\underbrace{ \nabla p }_\text{pressure}} +
      {\underbrace{ \textbf{F} }_\text{ext. forces}}
      $$
      $$
      \text{where~}\forall t{~,~} \nabla \cdot \mathbf{u} = 0
      $$

      Here, the constant \( \mu \) is the fluid's viscosity and \( \mathbf{F} \) are
      external forces. But we assumed earlier that our fluid was <a href="https://en.wikipedia.org/wiki/Inviscid_flow">inviscid</a>,
      so \( \mu = 0 \), and we can just ignore external forces for now. So we're left with two terms - self-advection and pressure.

      $$
      \frac{\partial \mathbf{u}}{\partial t} =
      {\underbrace{ - \mathbf{u} \cdot \nabla \mathbf{u} }_\text{self-advection}} -
      {\underbrace{ \nabla p }_\text{pressure}}
      \tag{3}
      $$
      $$
      \text{where~}\forall t{~,~} \nabla \cdot \mathbf{u} = 0
      $$

      If at every timestep we numerically compute these terms and add them, we can simulate our fluid! In pseudocode:

      <!-- <dt-code block language="javascript"> -->
        </p><pre>          <code>
          let u = createVectorGrid();
          let density = createScalarGrid();
          let p = createScalarGrid();

          while (true) {
            // Solve for the next velocity field.
            u = advect(u, u);

            p = computePressure(...);
            u = u - gradient(p);

            // Advect dye through the new velocity field.
            density = advect(u, density);
          }
          </code>
        </pre>
        <!-- </dt-code> -->
    
    <p>
      Let's take a closer look at each of these.
    </p>
    <p><b>Self-Advection</b></p>
    <p>
      From our incompressible advection equations, we can see that the self-advection term is the advection of the fluid's velocity
      field \( \mathbf{u} \) through itself:

      $$
      \text{advection} (\mathbf{u}, \mathbf{u}) = - \mathbf{u} \cdot \nabla \mathbf{u} \tag{4}
      $$
    </p>
    <p>
      Where do the other terms come from? Well, advecting \( \mathbf{u} \) through itself yields a new velocity field
      \( \mathbf{u}^\prime \) (computable via the Semi-Lagrangian backtracing algorithm from above):

      $$
      \mathbf{u}^\prime = \mathbf{u} - \mathbf{u} \cdot \nabla \mathbf{u}
      $$
    </p>
    <p><b>Pressure</b></p>
    <p>
      We don't know if this new velocity field follows the incompressibility constraint (e.g. has zero divergence).
      So the pressure term \( p \) needs to correct this somehow:

      $$
      \nabla \cdot (\mathbf{u}^\prime - \nabla p) = 0
      $$

      We rearrange this to get

      $$
      \nabla^2 p = \nabla \cdot \mathbf{u}^\prime \tag{5}
      $$

      which is a type of equation known as a <i>Poisson equation</i>, where the left-hand side is
      the <a href="https://en.wikipedia.org/wiki/Laplace_operator">Laplacian</a> of an unknown scalar field and the
      right-hand side is a known scalar. Solving this Poisson equation is really the slowest computational step
      in fluid simulation, for reasons we will see shortly.
    </p>
    <p><b>Solving for Pressure</b></p>
    <p>
      So how do we solve this particular PDE for \( p \)? Well, we know the value of our candidate velocity field \( \mathbf{u}^\prime \)
      at all of our grid points, so we can approximately compute the right-hand side of the Poisson equation by applying a discrete
      version <dt-fn>We are using a <a href="https://en.wikipedia.org/wiki/Finite_difference">finite difference</a> where the independent variable is the grid index.</dt-fn> of the divergence everywhere:

      $$
      \nabla \cdot \mathbf{u}^\prime \approx
      \frac{ u_{i+1, j} - u_{i-1, j} }{ 2 } +
      \frac{ v_{i, j+1} - v_{i, j-1} }{ 2 }
      $$

      where \( \mathbf{u}^\prime = (u, v) \) in 2 dimensions.
    </p>
    <p>
      Then we can use a discrete version of the Laplacian

      $$
      \nabla^2 p \approx
      p_{i+1, j} + p_{i-1, j} + p_{i, j+1} + p_{i, j-1} - 4p_{i, j}
      $$

      to transform the whole equation into a linear equation with five unknowns.
    </p>
    <p>
      But really, we are solving the Poisson equation (5) over all of space at once, so for an \( N \times N \) grid,
      we end up with a system of \( N^2 \) linear equations with exactly \( N^2 \) unknowns! So we end up with
      the familiar old equation

      $$
      \mathbf{Ax} = \mathbf{b}
      $$

      where \( \mathbf{A} \) is a matrix applying the Laplacian operator to the whole grid and \( \mathbf{b} \) is a vector containing
      the velocity field's divergence at all grid points.
    </p>
    <p>
      There are many off-the-shelf algorithms for solving linear systems exactly. Unfortunately for us, even the fastest algorithms
      scale superlinearly with our grid size.
    </p>
    <p><b>Solving for Pressure... Efficiently</b></p>
    <p>
      If we're going to make a real-time simulation, we need to go fast. Can we leverage the GPU?
    </p>
    <p>
      Well, it's not really possible to achieve an exact solution to the linear system efficiently, but we should
      note that the linear system is already an approximation to the Poisson equation. And it is possible to achieve
      arbitrarily accurate approximations with iterative methods - which begin with an estimate and improve solution
      accuracy every iteration - so we can just pick an iterative algorithm and run it
      until we have something that's "good enough". One particularly simple and easy-to-implement iterative algorithm for solving
      linear equations is the <a href="https://en.wikipedia.org/wiki/Jacobi_method">Jacobi method</a>.
    </p>
    <p>
      We start with the very first equation in the system:
      $$
      A_{11}x_1 + A_{12}x_2 + ... + A_{1n}x_n = b_1
      $$
      At the \(k\)th iteration, given some guess \( \mathbf{x}^k \) for the solution \( \mathbf{x} \), we have some error.
      We can use this error to update our guess for \( x_1 \) as follows:
      $$
      x_1^{k+1} = \frac{ b_1 - A_{12}x_2^k - ... - A_{1n}x_n^k }{ A_{11} }
      $$
      In Jacobi, our guesses for all elements of \( \mathbf{x} \) are executed in parallel, giving a perfect
      match for implementation on the GPU. In pseudocode:
    </p>
    <!-- <dt-code block language="glsl"> -->
      <pre>        <code>
          global FloatField divergence;
          global FloatField pressure;
          global float texelSize;

          // Run for each point in our pressure grid that we want to update
          float iterateJacobi(vec2 x) {
            float div = getFloatAt(divergence, x);
            float L = getFloatAt(pressure, x + vec2(-texelSize, 0.));
            float R = getFloatAt(pressure, x + vec2(texelSize, 0.));
            float T = getFloatAt(pressure, x + vec2(0., texelSize));
            float B = getFloatAt(pressure, x + vec2(0., -texelSize));
            return (div - L - R - T - B) / -4.;
          }
        </code>
      </pre>
    <!-- </dt-code> -->
    <p>
      It's worth noting that other, faster-converging solvers can also be
      implemented on the GPU, like the Conjugate Gradient method and the Multigrid method. But depending on
      the fluid and application, pressure accuracy may not be as important as advection accuracy or ease of implementation.
      For smoke and fire, changes in fluid volume aren't as apparent as they are for fluids like water
      <dt-cite key="Crane07"></dt-cite>, and high-quality advection tends to matter more<dt-cite key="Green2014"></dt-cite>.
    </p>
    <p><b>Summary: Simulating Navier Stokes</b></p>
    <p>
      The math behind Navier-Stokes can be a little bit dense, but at a high-level, simulating a fluid by solving the equations
      comes down to a few key update procedures on a grid per timestep. For our dye problem, here's our simulation
      might look:

      <!-- <dt-code block language="javascript"> -->
      </p><pre>        <code>
        let u = createVectorGrid();
        let density = createScalarGrid();
        let div = createScalarGrid();
        let p = createScalarGrid();

        while (true) {
          // Solve for the next velocity field.
          u = advect(u, u);

          // Enforce incompressibility with pressure projection.
          div = divergence(u);
          for (let i = 0; i &lt; JACOBI_ITERATIONS; i++) {
            p = updatePressure(p, div);
          }
          u = u - gradient(p);

          // Advect dye through the new velocity field.
          density = advect(u, density);
        }
        </code>
      </pre>
      <!-- </dt-code> -->

    
    <dt-byline></dt-byline>
    <h3>1.3 Vorticity Confinement</h3>
    <p>
      Using a grid to store our velocity field is extremely convenient, but it results in unwanted
      numerical smoothing whenever we have to interpolate values between grid points.
      This combined with the relatively coarse approximation of a first-order Semi-Lagrangian advection
      scheme has the effect of dissipating out turbulent vortices in our flow. Physically, the velocity field
      loses energy, and the end result is generally overly smooth, "boring" fluid flow.
    </p>
    <p>
      One way to combat lost vorticity is to increase the resolution of our grid, but this isn't really feasible
      for real-time simulations that have limited computational resources. What we would ideally
      like to do is find all the small details that get smoothed over each step of the simulation, and <i>amplify</i>
      them. This process is called vorticity confinement - admittedly, it's not totally realistic, but succeeds in
      preserving small scale details in more or less physically correct locations <dt-cite key="fedkiw2001visual"></dt-cite>.
      Indeed, it was originally invented to resolve very complex flow fields in engineering simulations of helicopter blades,
      where it just wasn't possible to add the number of necessary grid points <dt-cite key="steinhoff1994modification"></dt-cite>.
    </p>
    <p>
      The smallest turbulent features we can find are the vortices centered at each grid point in our simulation.
      We can measure the intensity of these vortices (the <i>vorticity</i> of them) by taking the curl of \( \mathbf{u} \)
      at each point, and amplify them by essentially adding a circular flow scaled by vorticity about each point.
      Mathematically, the vorticity is defined by

      $$
      \bm{\omega} = \nabla \times \mathbf{u}
      $$

      For each grid point, we compute a normalized location vector that points to the highest nearby vorticity concentration:

      $$
      \mathbf{N} = \frac{ \nabla | \bm{\omega} | }{ | \nabla | \bm{\omega} | | }
      $$

      And finally, we compute the confined vorticity vector field and add it to our flow:

      $$
      \mathbf{f_{conf}} = \epsilon (\mathbf{N} \times \bm{\omega})
      $$
      $$
      \mathbf{u_{conf}} = \mathbf{u} + \mathbf{f_{conf}}
      $$

      Here, the confinement constant \( \epsilon &gt; 0 \) is a parameter controlling the amount of small scale detail added
      back to the flow. Even low confinement levels (around 0-15) can make a huge difference, especially for simulations
      using Semi-Lagrangian advection schemes, and higher confinement levels can create highly stylized, billowing flows.
    </p>
    
    <p>
      <em>Click and drag to drop some dye in the turbulent simulation above</em>
    </p>
    <p>
      On the GPU, we can compute curl and confinement like so:
    </p>
    <!-- <dt-code block language="glsl"> -->
      <pre>        <code>
          global Vec2Field u;
          global float texelSize;

          // Run to get curl for each point in grid
          float computeCurl(vec2 x) {
            float L = getVec2At(u, x + vec2(-texelSize, 0.)).y;
            float R = getVec2At(u, x + vec2(texelSize, 0.)).y;
            float T = getVec2At(u, x + vec2(0., texelSize)).x;
            float B = getVec2At(u, x + vec2(0., -texelSize)).x;
            return (R - L) - (T - B);
          }

          global Vec2Field curl;
          global float confinement;

          // Run to get confinement force for each point in grid
          vec2 confinementForce(vec2 x) {
            float L = getFloatAt(curl, x + vec2(-texelSize, 0.));
            float R = getFloatAt(curl, x + vec2(texelSize, 0.));
            float T = getFloatAt(curl, x + vec2(0., texelSize));
            float B = getFloatAt(curl, x + vec2(0., -texelSize));
            float C = getFloatAt(curl, x);

            vec2 N = vec2(abs(T) - abs(B), abs(R) - abs(L));
            N = N / length(N);
            return confinement * C;
          }
        </code>
      </pre>
    <!-- </dt-code> -->
    <p>
      The full simulation with turbulence:
      <!-- <dt-code block language="javascript"> -->
        </p><pre>          <code>
          let u = createVectorGrid();
          let density = createScalarGrid();
          let div = createScalarGrid();
          let p = createScalarGrid();
          let curl = createVectorGrid();

          while (true) {
            // Solve for the next velocity field.
            u = advect(u, u);

            // Use vorticity confinement to amplify turbulence of velocity field.
            curl = computeCurl(u);
            u = u + confinementForce(curl, CONFINEMENT);

            // Enforce incompressibility with pressure projection.
            div = divergence(u);
            for (let i = 0; i &lt; JACOBI_ITERATIONS; i++) {
              p = updatePressure(p, div);
            }
            u = u - gradient(p);

            // Advect dye through the new velocity field.
            density = advect(u, density);
          }
          </code>
        </pre>
      <!-- </dt-code> -->
    
    <p><b>Curl-Noise Turbulence</b></p>
    <p>
      Curl noise is a method that essentially does the same thing as vorticity confinement, but instead of measuring
      and amplifying the vorticity of the velocity field, a scalar vorticity field is made from scratch using noise functions.
      Mathematically, we can combine vorticity confinement and curl-noise turbulence by  synthesizing a random
      vorticity field

      $$
      \bm{\phi} = \text{rand} * \mathbf{z}
      $$

      Then computing our final vorticity field by

      $$
      \bm{\omega}^* = \bm{\omega} + \bm{\phi}
      $$

      Fast-moving, highly-turbulent fluids like smoke and fire benefit the most from vorticity confinement and curl noise,
      and in practice the curl noise field \( \bm{\phi} \) both evolves with time and is also advected by the fluid flow.
    </p>
    <dt-byline></dt-byline>
    <h2>2. Fire Simulation</h2>
    <p>
      If you've gotten this far, pat yourself on the back! The methods in the previous section let us efficiently
      and accurately simulate fluids with varying physical parameters (oil, water, honey)
      assuming the fluid domain is a fixed space. Those interested in handling varying domains (that is, fluids that occupy different regions
      within the grid, like a half-full cup of water that sloshes around) will want to explore accounting for different boundary conditions
      within the grid simulation <dt-fn>I suggest <b>Dynamic Obstacles</b> in
      <a href="https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch30.html">GPU Gems 3 Chapter 30.2</a>
      <dt-cite key="Crane07"></dt-cite> for details on adding this to our grid simulation.
      There are also non grid-based methods, but those are outside scope here. </dt-fn>.
    </p>
    <p>
      Simulating fire and smoke requires a couple additions. First, we'll need to add channels representing
      fuel and temperature to our simulation, and model the combustion of fuel to create heat. Next we'll address how hot pockets
      of our fluid rise with a thermal buoyancy model, and finally, we'll need to render our flames correctly, taking into account
      blackbody radiation of the flames, human perception of light, and fire movement.
    </p>
    <h3>2.1 A Basic Combustion Model</h3>
    <p>
      Chemically, fire is caused by the oxidation of a fuel material in a reaction that releases both heat and light.
      In our case, we can assume that any fuel in our system has already ignited and is actively adding heat; we won't worry
      about the problem of unignited fuel.
    </p>
    <p>
      To be more specific, let's define a scalar field \( \rho \) where \( 0 \leq \rho \leq 1 \) represents the density of fuel and
      another scalar field \( T &gt; 0 \) representing the temperature of the fluid everywhere. At every timestep, temperature is
      added to the system by the fuel, which burns at a given burn temperature:

      $$
      T^\prime = \text{max} ( T, \rho * T_{\text{burn}} )
      $$

      Of course, temperature isn't static - heat diffuses from hot to cold areas, and with fluids in particular, large-scale movements
      of molecules transport heat. The combination of these 2 processes defines <a href="https://en.wikipedia.org/wiki/Convection">heat convection</a>,
      and conveniently, we already have a mathematical model for how it works - advection! Simulation-wise, we advect our temperature
      field along our velocity field. Since any reacting molecules are also moved by the fluid, we should advect fuel as well.
      The heat itself also affects the movement of the fluid - we'll see how to handle this shortly.
    </p>
    <p>
      Furthermore, hot molecules radiate off temperature as light<dt-fn>This is called blackbody radiation, and we'll return
      to it when rendering the fire color. The soot particles present in most fire radiate like ideal blackbodies.</dt-fn> according to the
      <a href="https://en.wikipedia.org/wiki/Stefan%E2%80%93Boltzmann_law">Stefan-Boltzmann Law</a>,
      in a quintic equation <dt-cite key="nguyen2002physically"></dt-cite>:

      $$
      T^\prime = T - \sigma_{\text{cool}} ( \frac{T}{T_{\text{max}}} )^4 * \Delta t
      $$

      Here, \( \sigma_{\text{cool}} \) is the cooling rate parameter. For a physically correct simulation, we would set it to the Stefan-Boltzmann constant,
      but for a graphical simulation, it's nice for the artist to be able to control the rate of cooling.
    </p>
    <p>
      To complete our combustion model, note that our fuel is always burning (we can imagine it as the density of ionized gas particles
      that give off thermal energy and return to a lower energy state), so every timestep we dissipate it by some given burn
      rate \( \gamma_{fuel} \):
      $$
      \rho^\prime = \rho (1 - \gamma_{fuel})^{\Delta t}
      $$
    </p>
    <h3>2.2 Thermal Buoyancy</h3>
    <p>
      So far, our temperature field doesn't do anything to our fluid flow. But it should - hot pockets of air should expand and rise, and cooler pockets should fall.
      We can model this with a thermal buoyancy force. Since we're assuming incompressibility, we won't actually handle air expansion, but the fluid flow
      should experience an upward force depending on temperature:

      $$
      \mathbf{u}^\prime = \mathbf{u} + (\beta T \Delta t) \mathbf{j}
      $$

      Here, \( \beta \) is a given positive buoyancy constant, and \( \mathbf{j} \) is the upward unit vector.
    </p>
    <p>
      Adding a combustion model and thermal buoyancy force gives us a fantastic simulator for a decidedly "fire-like" fluid -
      with the right values of buoyancy and cooling, we can get bulky, billowing plumes of material.
      Not exactly flames, but very similar to smoke.
    </p>
    <p>
      Tap and drag in the simulation below to inject some combusting fuel.
      The displayed pixels represent density of smoke particles, which dissipate at a constant rate instead of being used
      up during combustion, but are still advected by the fluid simulation.
    </p>
    
    <p>
      <em>Click and drag to add smoke above</em>
    </p>
    <p>
      The simulation code builds off the basic fluid routines:
      <!-- <dt-code block language="javascript"> -->
        </p><pre>          <code>
          let u = createVectorGrid();
          let density = createScalarGrid();
          let div = createScalarGrid();
          let p = createScalarGrid();
          let curl = createVectorGrid();
          let fuel = createScalarGrid();
          let temp = createScalarGrid();

          while (true) {
            // Solve for the next velocity field.
            u = advect(u, u);

            // Combustion step.
            temp = combust(temp, fuel);

            // Use vorticity confinement to amplify turbulence of velocity field.
            curl = computeCurl(u);
            u = u + confineVorticity(curl, CONFINEMENT);

            // Add thermal buoyancy.
            u = u + buoyancy(temp);

            // Enforce incompressibility with pressure projection.
            div = divergence(u);
            for (let i = 0; i &lt; JACOBI_ITERATIONS; i++) {
              p = updatePressure(p, div);
            }
            u = u - gradient(p);

            // Advect dye through the new velocity field.
            density = advect(u, density);
          }
          </code>
        </pre>
      <!-- </dt-code> -->
    
    <h3>2.3 Fire Rendering</h3>
    <p>
      Fire is a <a href="http://old.cescg.org/CESCG-2000/SMaierhofer/node6.html">participating medium</a>,
      meaning it emits light through blackbody radiation<dt-fn>Besides emitting its own blackbody radiation, fire also scatters light that passes through it. For more, see
      5.1 in <a href="http://physbam.stanford.edu/~fedkiw/papers/stanford2002-02.pdf">Nguyen et al. 2002</a>
      <dt-cite key="nguyen2002physically"></dt-cite>.</dt-fn>. This is what gives fire its orange and red colors;
      rendering our combusting fuel simulation using the correct formula is then all we need to go from smoke to fire!
    </p>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Gluehfarben_no_language_horizontal.svg/2880px-Gluehfarben_no_language_horizontal.svg.png">
    <p>
      <em>The temperature-to-color spectrum as described by Planck's law</em>
    </p>
    <p>
      <a href="https://en.wikipedia.org/wiki/Planck%27s_law">Planck's Law</a> describes the spectral density of light radiated by
      a black body at a given temperature \( T \):

      $$
      M(\lambda, T) = \frac{ c_1 }{ \lambda^5 } \frac{ 1 }{ \exp{ \frac{c_2}{\lambda T} } - 1 }
      $$

      where
      $$
      c_1 = 2 \pi h c^2 \\
      c_2 = \frac{hc}{k}
      $$

      and \(h\), \(c\), and \(k\) are Planck's constant, the speed of light, and Boltzmann's constant, respectively.
    </p>
    <p>
      After implementing blackbody rendering using fragment shaders, we have a complete fire simulation!
    </p>
    
    <p>
      <em>Click and drag to add fire above</em>
    </p>
    <p>
      That's it for these notes! There is of course much more to fluid and fire simulation not covered here, like
      different (e.g. non-grid-based) techniques for solving the same problem of simulation within a fixed volume,
      different problems to solve involving varying domains or dynamic obstacles, enhancements to rendering like
      more accurate blackbody radiation, light scattering, or post-processing effects. Helpful introductions
      to these topics can be found in references below.
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexity Labs Playground (270 pts)]]></title>
            <link>https://labs.perplexity.ai/</link>
            <guid>38698782</guid>
            <pubDate>Tue, 19 Dec 2023 17:44:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://labs.perplexity.ai/">https://labs.perplexity.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=38698782">Hacker News</a></p>
Couldn't get https://labs.perplexity.ai/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Google agrees to pay $700M in antitrust settlement reached with states (171 pts)]]></title>
            <link>https://apnews.com/article/google-android-play-store-apps-antitrust-settlement-e4e2f422baa846c66deac90c7866c5fd</link>
            <guid>38698707</guid>
            <pubDate>Tue, 19 Dec 2023 17:40:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/google-android-play-store-apps-antitrust-settlement-e4e2f422baa846c66deac90c7866c5fd">https://apnews.com/article/google-android-play-store-apps-antitrust-settlement-e4e2f422baa846c66deac90c7866c5fd</a>, See on <a href="https://news.ycombinator.com/item?id=38698707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>Google has agreed to pay $700 million and make several other concessions to settle allegations that it had been stifling competition against its Android app store — the same issue that went to trial in another case that could result in even bigger changes.</p><p>Although Google <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/business/colombia-mobile-apps-alphabet-inc-software-legal-proceedings-28c38a5f6981ffd856dc12d4bf3c4537" target="_blank" rel="noopener">struck the deal with</a></span> state attorneys general in September, the settlement’s terms weren’t revealed until late Monday in documents filed in San Francisco federal court. The disclosure came a week after <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/google-epic-games-antitrust-trial-android-app-store-dd6b26be7447b5ff8cc0d20a4d01b6b4" target="_blank" rel="noopener">a federal court jury rebuked Google</a></span> for deploying anticompetitive tactics in its Play Store for Android apps.</p><p>The settlement with the states includes $630 million to compensate U.S. consumers funneled into a payment processing system that state attorneys general alleged drove up the prices for digital transactions within apps downloaded from the Play Store. That store caters to the Android software that powers most of the world’s smartphones.</p>
    

<p>Like Apple does in its iPhone app store, Google collects commissions ranging from 15% to 30% on in-app purchases — fees that state attorneys general contended drove prices higher than they would have been had there been an open market for payment processing. Those commissions generated billions of dollars in profit annually for Google, according to evidence presented in the recent trial focused on its Play Store.</p>
    
        
    
<p>Eligible consumers will receive at least $2, according to the settlement, and may get additional payments based on their spending on the Play store between Aug. 16, 2016 and Sept. 30, 2023. The estimated 102 million U.S. consumers who made in-app purchases during that time frame are supposed to be automatically notified about various options for how they can receive their cut of the money.</p>
    
<p>Another $70 million of the pre-trial settlement will cover the penalties and other costs that Google is being forced to pay to the states. </p><p>Although Google is forking over a sizeable sum, it’s a fraction of the $10.5 billion in damages that the attorneys general estimated the company could be forced to pay if they had taken the case to trial instead of settling.</p>
    

<p>Google also agreed to make other changes designed to make it even easier for consumers to download and install Android apps from other outlets besides its Play Store for the next five years. It will refrain from issuing as many security warnings, or “scare screens,” when alternative choices are being used. </p><p>The makers of Android apps will also gain more flexibility to offer alternative payment choices to consumers instead of having transactions automatically processed through the Play Store and its commission system. Apps will also be able to promote lower prices available to consumers who choose an alternate to the Play Store’s payment processing.</p><p>Investors seemed unfazed by the settlement as shares in Google’s corporate parent, Alphabet Inc., rose slightly in Tuesday’s midday trading.</p><p>The settlement represents a “loud and clear message to Big Tech — attorneys general across the country are unified, and we are prepared to use the full weight of our collective authority to ensure free and fair access to the digital marketplace,” said Connecticut Attorney General William Tong.</p><p>Wilson White, Google’s vice president of government affairs and public policy, framed the deal as a positive for the company, despite the money and concessions it entails. The settlement “builds on Android’s choice and flexibility, maintains strong security protections, and retains Google’s ability to compete with other (software) makers, and invest in the Android ecosystem for users and developers,” White <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://blog.google/outreach-initiatives/public-policy/reaffirming-choice-and-openness-on-android-and-google-play/" target="_blank" rel="noopener">wrote in a blog post.</a></span></p>
    

<p>Although the state attorneys general hailed the settlement as a huge win for consumers, it didn’t go far enough for Epic Games, which spearheaded the attack on Google’s app store practices with an antitrust lawsuit filed in August 2020.</p><p>Epic, the maker of the popular Fortnite video game, rebuffed the settlement in September and instead chose to take its case to trial, even though it had already lost on most of its key claims <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/technology-business-prices-76b30a844324db04f06a144f888a6f0d" target="_blank" rel="noopener">in a similar trial targeting Apple and its iPhone app store in 2021.</a></span></p><p>The Apple trial, though, was decided by a federal judge instead of the jury that vindicated Epic with a unanimous verdict that Google had built anticompetitive barriers around the Play Store. Google has vowed to appeal the verdict.</p><p>Corie Wright, Epic’s vice president of public policy, derided the states’ settlement as little more than a one-time payout that provides “no true relief for consumers or developers,” in a blog post. </p><p>In court documents, the attorneys general said they decided to settle because of significant risks posed by a trial, including the possibility that a jury may have thought their plan to seek $10.5 billion in damages was exorbitant. The attorneys general also cited for the potential of jurors becoming confused had their case been presented alongside Epic’s claims in the trial, as had been the original plan.</p>
    

<p>But now the Epic trial’s outcome nevertheless raises the specter of Google potentially being ordered to pay even more money as punishment for its past practices and making even more dramatic changes to its lucrative Android app ecosystem.</p><p>Those changes will be determined next year by U.S. District Judge James Donato, who presided over the Epic Games trial. Donato also still must approve Google’s Play Store settlement with the states.</p><p>“In the next phase of the case, Epic will seek meaningful remedies to truly open up the Android ecosystem so consumers and developers will genuinely benefit from the competition that U.S. antitrust laws were designed to promote,” Wright pledged.</p><p>Google faces an even bigger legal threat in another antitrust case targeting its dominant search engine that serves as the centerpiece of a digital ad empire that generates more than $200 billion in sales annually. Closing arguments in a trial pitting Google against the Justice Department are scheduled for early May before a federal judge in Washington D.C.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The changing face of post-pandemic New York City (147 pts)]]></title>
            <link>https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city</link>
            <guid>38698353</guid>
            <pubDate>Tue, 19 Dec 2023 17:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city">https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city</a>, See on <a href="https://news.ycombinator.com/item?id=38698353">Hacker News</a></p>
Couldn't get https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Comcast says hackers stole data of close to 36M Xfinity customers (206 pts)]]></title>
            <link>https://techcrunch.com/2023/12/19/comcast-xfinity-hackers-36-million-customers/</link>
            <guid>38698343</guid>
            <pubDate>Tue, 19 Dec 2023 17:14:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/12/19/comcast-xfinity-hackers-36-million-customers/">https://techcrunch.com/2023/12/19/comcast-xfinity-hackers-36-million-customers/</a>, See on <a href="https://news.ycombinator.com/item?id=38698343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Comcast has confirmed that hackers exploiting a critical-rated security vulnerability accessed the sensitive information of almost 36 million Xfinity customers.</p>
<p>This vulnerability, known as “CitrixBleed,” is found in Citrix networking devices often used by big corporations and has been <a href="https://techcrunch.com/2023/11/14/citrix-bleed-critical-bug-ransomware-mass-cyberattacks/" target="_blank" rel="noopener">under mass-exploitation by hackers since late August</a>. Citrix made patches available in early October, but many organizations did not patch in time. Hackers have used the CitrixBleed vulnerability to hack into big-name victims, including aerospace giant Boeing, the Industrial and Commercial Bank of China and international law firm Allen &amp; Overy.</p>
<p>Xfinity, Comcast’s cable television and internet division, became the latest CitrixBleed victim, the company confirmed in <a href="https://www.businesswire.com/news/home/20231218979935/en/Notice-To-Customers-of-Data-Security-Incident/" target="_blank" rel="noopener">a notice to customers</a> on Monday.</p>
<p>The U.S. telecom giant said that hackers exploiting the CitrixBleed vulnerability had access to its internal systems between October 16 and October 19, but that the company did not detect the “malicious activity” until October 25.</p>
<p>By November 16, Xfinity determined that “information was likely acquired” by the hackers, and in December, the company concluded that this included customer data, including usernames and “hashed” passwords, which are scrambled and stored in a way that makes them unreadable to humans. It’s not immediately clear how the passwords were scrambled or using which algorithm, as some weaker hashing algorithms can be cracked.</p>
<p>The company says for an unspecified number of customers, hackers may have also accessed names, contact information, dates of birth, the last four digits of Social Security numbers and their secret questions and answers.</p>
<p>Comcast notes that “our data analysis is continuing, and we will provide additional notices as appropriate,” suggesting additional types of data may also have been accessed.</p>
<p>The notice doesn’t say how many Xfinity customers have been impacted, and Comcast spokesperson Joel Shadle declined to say when asked by TechCrunch. In <a href="https://apps.web.maine.gov/online/aeviewer/ME/40/49e711c6-e27c-4340-867c-9a529ab3ca2c.shtml" target="_blank" rel="noopener">a filing with Maine’s attorney general</a>, Comcast confirmed that almost 35.8 million customers are affected by the breach. Comcast’s latest <a href="https://www.cmcsa.com/news-releases/news-release-details/comcast-reports-2nd-quarter-2023-results" target="_blank" rel="noopener">earnings report</a> shows the company has more than 32 million broadband customers, suggesting this breach has impacted most, if not all Xfinity customers.</p>
<p>It’s not yet known whether Xfinity received a ransom demand, how the incident has impacted the company’s operators or whether the incident has been filed with the U.S. Securities and Exchange Commission, <a href="https://techcrunch.com/2023/12/18/new-sec-data-breach-disclosure-rules/" target="_blank" rel="noopener">as required by the regulator’s new data breach reporting rules</a>. Comcast’s spokesperson would not say.</p>
<p>“We are not aware of any customer data being leaked anywhere, nor of any attacks on our customers,” said Shadle in an email to TechCrunch.</p>
<p>Xfinity says it is requiring that customers reset their passwords and recommends the use of two-factor or multi-factor authentication — which the company doesn’t require by default — for all customer accounts.</p>
<p><em>Updated with additional comment from Comcast.</em></p>
<p><strong>Read more on TechCrunch:</strong></p>
<ul>
<li><a href="https://techcrunch.com/2023/12/18/why-extortion-is-the-new-ransomware-threat/" target="_blank" rel="noopener">Why extortion is the new ransomware threat</a></li>
<li><a href="https://techcrunch.com/2023/11/02/government-sanctions-ransomware-effective/" target="_blank" rel="noopener">Do government sanctions against ransomware groups work?</a></li>
<li><a href="https://techcrunch.com/2023/10/31/ransomware-victims-paying-hackers-ransom/" target="_blank" rel="noopener">Why ransomware victims can’t stop paying off hackers</a></li>
<li><a href="https://techcrunch.com/2023/12/18/new-sec-data-breach-disclosure-rules/" target="_blank" rel="noopener">SEC’s new data breach disclosure rules take effect: what you need to know</a></li>
</ul>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tsdocs.dev: Type docs for any JavaScript library (208 pts)]]></title>
            <link>https://tsdocs.dev</link>
            <guid>38697752</guid>
            <pubDate>Tue, 19 Dec 2023 16:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tsdocs.dev">https://tsdocs.dev</a>, See on <a href="https://news.ycombinator.com/item?id=38697752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>tsdocs.dev helps you browse reference typescript documentation for any package or version of a library.</p><p>Made with the help of<!-- --> <a target="_blank" href="https://github.com/TypeStrong/typedoc">typedoc</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[National Engineering Handbook (135 pts)]]></title>
            <link>https://directives.sc.egov.usda.gov/RollupViewer.aspx?hid=17092</link>
            <guid>38697723</guid>
            <pubDate>Tue, 19 Dec 2023 16:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://directives.sc.egov.usda.gov/RollupViewer.aspx?hid=17092">https://directives.sc.egov.usda.gov/RollupViewer.aspx?hid=17092</a>, See on <a href="https://news.ycombinator.com/item?id=38697723">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Plasmic.app: Visual editing and content platform for building websites and apps (194 pts)]]></title>
            <link>https://www.plasmic.app/</link>
            <guid>38697650</guid>
            <pubDate>Tue, 19 Dec 2023 16:27:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.plasmic.app/">https://www.plasmic.app/</a>, See on <a href="https://news.ycombinator.com/item?id=38697650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75&amp;f=webp 2x"><img alt="" loading="eager" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75 2x"></picture></div><h2>The <span>visual builder</span> for your tech stack</h2><p>Plasmic is an open-source visual editing and content platform for building websites and apps. Integrate with existing codebases. Ship incredibly fast.</p><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=2048&amp;q=75&amp;f=webp 2048w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=3840&amp;q=75&amp;f=webp 3840w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=2048&amp;q=75 2048w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=3840&amp;q=75 3840w" sizes="100vw"></picture></div></div><div><p>Loved by teams around the world</p></div><div><div><p><h2><span><h2>Build experiences <span>blazingly fast</span></h2></span></h2></p><p><span><span>Get started with a growing library of ready-made components and popular data and app integrations. Build custom experiences with interactions and dynamic values.</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?q=75 2048w" sizes="100vw"></picture></div><div><div><div><p><span><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/744209a6041e927f550afff230a012f5.svg"></picture></div><div><p><h3>Connect to
<span>any data source</span></h3></p><p>Tap into popular data sources like Airtable, PostgreSQL and Shopify with built-in connectors, or connect to any GraphQL or REST API endpoint.</p></div></span></p></div><a href="https://www.plasmic.app/integrations"></a></div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/7bfabb2cc067bbd2ae1b27b89ad77138.svg"></picture></div></div></div></div><div><div><div><h2><span><p>Integrate with any <span> codebase</span></p></span></h2></div><p><span><span>Unlike other no-code and low-code builders, Plasmic integrates with your existing codebase, so you're never confined to a walled garden. </span></span></p></div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/4ab412da6ffdb7a2bbe708a6bd414eea.svg"></picture></div><h3><span><h3>Build with your <span>components</span></h3></span></h3><p><span><p>Harness the flexibility to create apps that fit your exact requirements. Bring your data sources, React components, deployment environments, design system, and more.</p></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?q=75 2048w" sizes="100vw"></picture></div></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?q=75 2048w" sizes="100vw"></picture></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/5de1532ef36fdb0c3219a61fbdaf943a.svg"></picture></div><h3><span><p>Build within <span>existing apps</span></p></span></h3><p><span><span>Instead of iframes, Plasmic lets you build pages that integrate seamlessly within your current applications. Leverage your existing components and code for better performance and more cohesive user experiences. </span></span></p></div></div></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=1920&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=3840&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=1920&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=3840&amp;q=75 2x"></picture></div><div><div><h2><span><p>Design experiences your users will <span>love</span></p></span></h2></div><p><span><span>Design custom UIs with responsive layouts and styling that set you apart and delight your users.</span></span></p></div><div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/a6887322c6092824ff615637e3eeb553.svg"></picture></div><h3><span><h3>Create completely <span>custom UIs</span></h3></span></h3><p><span><span>Create unique, custom UIs with arbitrary layouts and styling that can be tailored to your specific needs and requirements.</span></span></p></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/d7212315ca176185fe605c0b7f5eb63c.svg"></picture></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?q=75 2048w" sizes="100vw"></picture></div></div></div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/3acd2cc408b37baabe2f4c4dd9af6bed.svg"></picture></div><video autoplay="" muted="" src="https://site-assets.plasmic.app/64f55665dba8fc2cd5a4a9dd7737ce91.mp4"></video></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/c1759e00a445383ed90fa900b53b1a4a.svg"></picture></div><h3><span><h3>Import with <span>Figma</span></h3></span></h3><p><span><span>Quickly turn your Figma designs into React code for production in Plasmic Studio using the best-in-class Figma to code plugin.</span></span></p></div></div></div></div><section><div><div><div><h2><span><p><span>Bridge the gap</span>
between teams</p></span></h2></div><p><span><p>Plasmic makes the development process more collaborative, so everyone can build better experiences together.</p></span></p></div><div><div><h3>Empower 
<span>non-developers</span></h3><p>Empower marketing, content, design, and product teams to build and publish. Developers can register custom components as building blocks that other team members can use.</p></div><div><h3>Collaborate 
<span>effortlessly</span></h3><p>Go from silos and endless backlogs to streamlined workflows between development and business teams. Let everyone focus on what they do best with branching and multiplayer mode.</p></div></div></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=2048&amp;q=75&amp;f=webp 2048w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=3840&amp;q=75&amp;f=webp 3840w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=2048&amp;q=75 2048w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=3840&amp;q=75 3840w" sizes="100vw"></picture></div></section><section><div><div><h2><span><p>Build <span>internal tools</span> and <span>customer-facing</span> apps</p></span></h2></div><p><span><p>Start from a template and make it your own. Or, build from scratch.
From dashboards and admin panels to portals and marketplaces, you can create software for every area of your business.</p></span></p></div><div dir="ltr"><div tabindex="-1" data-index="1" aria-hidden="false"><a href="https://www.plasmic.app/templates/applicant-tracker-template"><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/81514d152c2640ee2577f54792057f38.png?q=75&amp;f=webp 640w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/81514d152c2640ee2577f54792057f38.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/81514d152c2640ee2577f54792057f38.png?q=75 640w" sizes="100vw"></picture></div></a></div><div tabindex="-1" data-index="2" aria-hidden="false"><a href="https://www.plasmic.app/templates/community-forum-template"><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/43f464687631ceb8b342519aec81d7b8.png?q=75&amp;f=webp 640w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/43f464687631ceb8b342519aec81d7b8.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/43f464687631ceb8b342519aec81d7b8.png?q=75 640w" sizes="100vw"></picture></div></a></div></div></section><section><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?q=75 2048w" sizes="100vw"></picture></div><div><div><h2><span><p>Deploy
<span>anywhere</span></p></span></h2></div><p><span><p>Deploy to your choice of hosting infrastructure, so you can maintain control and easily scale your app.</p></span></p></div></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?q=75 2048w" sizes="100vw"></picture></div></section><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=2048&amp;q=75&amp;f=webp 2048w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=3840&amp;q=75&amp;f=webp 3840w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=2048&amp;q=75 2048w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=3840&amp;q=75 3840w" sizes="100vw"></picture></div><div><p><h2><span><span>Scale without limits</span></span></h2></p><p><span><span>Manage enterprise-level growth with ease. Scale up and maintain control, even as your application grows and evolves.</span></span></p></div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/15ce42b029501d230c3a4f1050ba4671.svg"></picture></div><div><p><span><span>SOC 2 Compliance</span></span></p><p><span><p>Plasmic meets SOC 2 standards for secure handling of sensitive information.</p></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/5f11191c651613ea8ac42e586fc21cb3.svg"></picture></div><div><p><span><span>SSO and Domain Capture</span></span></p><p><span><span>Available for for both Plasmic collaborators and end users of your application.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/6d17f6812d8eea260651594dfbbf36c2.svg"></picture></div><div><p><span><p>Fine-Grained Permissions</p></span></p><p><span><span>Assign and manage fine grained access controls both within Plasmic and your applications.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/08919b5fc0ef66ab0f804e718704c0d2.svg"></picture></div><div><p><span><span>Branching &amp; approvals</span></span></p><p><span><span>Collaborate at scale by working on isolated copies, then review and merge when ready.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/250fa2c1841ecccfce418363815616b0.svg"></picture></div><div><p><span><span>Shared Libraries</span></span></p><p><span><span>Centrally manage assets across your organization. Import and reuse within various projects with ease.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/0ee3a473c9dee543eb3f3d810b0b7c3d.svg"></picture></div><div><p><span><span>On-Premise App Deployment</span></span></p><p><span><span>Deploy your applications on-premise or behind firewalls for enhanced control and security.</span></span></p></div></div></div></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?w=1920&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?w=1920&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?q=75 2x"></picture></div><div><p><span><h2>Our customers</h2></span></p><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/5c55aa50c60f65d214350e5916ac3c6f.svg"></picture></div><p><span><h2>us</h2></span></p></div><div><div><div><div><p><span><p>It’s already been a huge increase in efficiency for me, personally. I’m really looking forward to a huge drop in scope for our tests that require new components (most of them).</p></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=96&amp;q=75 2x"></picture></div></div><div><div><p><span><span>Really excited about this UI to React components platform. Definitely see a bright future!</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?q=75 2x"></picture></div><div><p><span><p>Software Engineer
Sidecar Health</p></span></p></div></div></div><div><div><p><span><p>fellow UI engineers and designers, you should pay attention to what the folks over at @plasmicapp are doing. I've been using the beta and it is pretty excellent—this is certainly the future of component development.</p></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=96&amp;q=75 2x"></picture></div></div></div><div><div><p><span><span>“I had the opportunity to test out an early version of Plasmic and it’s awesome! Excited for the future of this design tool”</span></span></p><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=96&amp;q=75 2x"></picture></div><div><p>Cole Bemis</p><p>Design Systems Engineer <a href="https://www.plasmic.app/#">@GitHub</a></p></div></div></div><div><div><div><div><p><span><span>I was pleasantly surprised and at times, blown away, with the Plasmic approach to solving the problem. The whole concept of variants, interactive variants, and slots feels natural and intuitive.</span></span></p></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/7ebccefb6961482b121341e26b20a600.svg"></picture></div><div><p><span><span>Software Developer
APS Physics</span></span></p></div></div></div><div><div><p><span><span>We're totally blown away many times a day because of plasmic. You're doing god's work.</span></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=96&amp;q=75 2x"></picture></div></div></div><div><div><div><p><span><span>By far one of the most empowering tools to come out in a while. If you’re a designer/no coder/visual developer who wants to make world class applications, or a design or development studio looking for a way to serve your clients better and faster—check out Plasmic.</span></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=96&amp;q=75 2x"></picture></div></div><div><div><p><span><span>Plasmic is the most important app to be released in the last five years.</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=96&amp;q=75 2x"></picture></div><div><p><span><span>Senior UX Designer
Coupa Software</span></span></p></div></div></div></div></div></div><div><div><div><p><span><span>After using this for about an hour, I'm convinced it's the future.</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=96&amp;q=75 2x"></picture></div><div><p><span><span>Design Director
Outdoorsy</span></span></p></div></div></div><div><div><p><span><span>Watching @yaaang demo quickly creating #react components with ease using his app @plasmicapp for the second time tonight at a @_collab_lab exclusive presentation. AND I’m just as blown away as I was last time! Check out this app, y’all!</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=96&amp;q=75 2x"></picture></div><div><p><span><span>Front-End Engineer
Zapier</span></span></p></div></div></div><div><div><p><span><span>I'm super surprised more folks aren't talking about Plasmic — I just got a demo and it's awesome. It's like Figma and Webflow had a baby that outputs React code.</span></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=96&amp;q=75 2x"></picture></div></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobody knows what's happening online anymore (238 pts)]]></title>
            <link>https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/</link>
            <guid>38697227</guid>
            <pubDate>Tue, 19 Dec 2023 16:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/">https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/</a>, See on <a href="https://news.ycombinator.com/item?id=38697227">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>Why you’ve probably never heard of the most popular Netflix show in the world</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="An image of an iPhone with a TikTok logo on the screen. The screen is cracked and there is a whole in the middle." sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/GQWsQKxK18BdSVDMyh8IQNMUqhA=/0x0:2000x1125/750x422/media/img/mt/2023/12/broken_popularity2/original.png 750w, https://cdn.theatlantic.com/thumbor/ZoAWEW1OQwRfnVVqWr-X8nFeG0M=/0x0:2000x1125/828x466/media/img/mt/2023/12/broken_popularity2/original.png 828w, https://cdn.theatlantic.com/thumbor/3cAp3RGRbWo8WkXVJjdbwvqYclg=/0x0:2000x1125/960x540/media/img/mt/2023/12/broken_popularity2/original.png 960w, https://cdn.theatlantic.com/thumbor/-NyhltUrCtYu7hMQTBUqwwBTphA=/0x0:2000x1125/976x549/media/img/mt/2023/12/broken_popularity2/original.png 976w, https://cdn.theatlantic.com/thumbor/Vz7t0QuPasSkguy2ZwLh1sLXUvY=/0x0:2000x1125/1952x1098/media/img/mt/2023/12/broken_popularity2/original.png 1952w" src="https://cdn.theatlantic.com/thumbor/3cAp3RGRbWo8WkXVJjdbwvqYclg=/0x0:2000x1125/960x540/media/img/mt/2023/12/broken_popularity2/original.png" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true">Illustration by The Atlantic; Source: Getty.</figcaption></figure></div></div><div><p><time datetime="2023-12-18T18:11:00Z" data-flatplan-timestamp="true">December 18, 2023, 1:11 PM ET</time></p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">You are currently logged on to the largest version of the internet that has ever existed. By clicking and scrolling, you’re one of the 5 billion–plus people contributing to an unfathomable array of networked information—<a data-event-element="inline link" href="https://www.ciobulletin.com/big-data/how-much-data-is-created-every-day-and-how-to-collect-it#:~:text=Key%20Data%20Growth%20Statistics,will%20be%20sent%20every%20second.">quintillions of bytes</a> produced each day.</p><p data-flatplan-paragraph="true">The sprawl has become disorienting. Some of my peers in the media have written about how the internet has started to feel <a data-event-element="inline link" href="https://nymag.com/intelligencer/2023/07/the-2024-election-will-be-an-informational-nightmare.html">“placeless”</a> &nbsp;and more ephemeral, even like it is “<a data-event-element="inline link" href="https://www.garbageday.email/p/is-the-web-actually-evaporating">evaporating</a>.” Perhaps this is because, as my colleague Ian Bogost has <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2022/11/twitter-facebook-social-media-decline/672074/">argued</a>, “the age of social media is ending,” and there is no clear replacement. Or maybe artificial intelligence is flooding the internet with synthetic information and <a data-event-element="inline link" href="https://www.theverge.com/2023/6/26/23773914/ai-large-language-models-data-scraping-generation-remaking-web">killing the old web</a>. Behind these theories is the same general perception: Understanding what is actually happening online has become harder than ever.</p><p data-flatplan-paragraph="true">The internet destroyed any idea of a monoculture long ago, but new complications cloud the online ecosystem today: TikTok’s opaque “For You” recommendation system, the ascension of paywalls that limit access to websites such as this one, the collapse of Twitter—now X—under Elon Musk, <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2023/11/social-media-news-readership-decline/675890/">the waning relevance of news across most social-media sites</a>. The broad effect is an online experience that feels unique to every individual, depending on their ideologies and browsing habits. The very idea of popularity is up for debate: <em>Is that trend really viral? Did everyone see that post, or is it just my little corner of the internet? </em>More than before, it feels like we’re holding a fun-house mirror up to the internet and struggling to make sense of the distorted picture.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/technology/archive/2023/11/social-media-news-readership-decline/675890/">Read: The great social media-news collapse</a></p><p data-flatplan-paragraph="true">“There’s a real lack of understanding of what’s going on across platforms,” Ryan Broderick, who writes the newsletter Garbage Day, told me. For the past six months, Broderick has been partnering with NewsWhip and other online-analytics companies and independently building <a data-event-element="inline link" href="https://www.garbageday.email/p/garbage-intelligence-reports">intelligence reports</a>, tracking the most popular content and personalities across sites such as Facebook, X, Reddit, TikTok, Twitch, and YouTube. In the 2010s, he said, a curious person was better equipped to take the temperature of the web: “The stuff going viral on Facebook was of a different flavor and demographic than, say, YouTube or Twitter, but it felt easier to look at it all, shuffle the decks together, and say,<em> There’s the internet</em>.” Sometime between mid-2021 and early 2022, Broderick noticed that information was moving differently. News stories blew up in corners of the internet and died out, completely bypassing his feeds, and fake “viral” trends popped up with increasing frequency, despite little evidence that anyone was participating in them.</p><p data-flatplan-paragraph="true">Consider TikTok for a second—arguably the most vibrant platform on the internet. Try to imagine which posts might have been most popular on the site this year. Perhaps a dispatch from the Middle East or incendiary commentary on the mass bombings in Gaza? Or maybe something lighter, like a Gen Z dance trend or gossip about Taylor Swift and Travis Kelce? Well, no: According to TikTok’s year-end <a data-event-element="inline link" href="https://newsroom.tiktok.com/en-us/year-on-tiktok-2023">report</a>, the most popular videos in the U.S.—clips racking up as many as half a billion views each—aren’t topical at all. They include makeup tutorials, food ASMR, a woman showing off a huge house cat, and a guy spray-painting his ceiling to look like Iron Man. As a <em>Verge</em> <a data-event-element="inline link" href="https://www.theverge.com/2023/12/6/23989124/tiktoks-biggest-hits-2023-viral-videos-trends-recommendation-algorithm">headline</a> noted earlier this month, “TikTok’s biggest hits are videos you’ve probably never seen.” Other platforms have the same issue: Facebook’s most recent <a data-event-element="inline link" href="https://transparency.fb.com/data/widely-viewed-content-report/#widely-viewed-content">“Widely Viewed Content Report”</a> is full of vapid, pixelated, mostly repackaged memes and videos getting tens of millions of views.</p><p data-flatplan-paragraph="true">The dynamic extends beyond social media too. Just last week, Netflix unexpectedly <a data-event-element="inline link" href="https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report">released</a> an unusually comprehensive “engagement report” revealing audience-consumption numbers for most of the TV shows and movies in its library—more than 18,000 titles in all. The attempt at transparency caused confusion among some viewers: Netflix’s single most popular <em>anything</em> from January and June 2023 was a recent thriller series called <em>The Night Agent</em>, which was streamed for 812 million hours globally. “I stay pretty plugged in with media, especially TV shows - legit have never heard of what’s apparently the most watched scripted show in the world,” one person <a data-event-element="inline link" href="https://www.threads.net/@zachhallnc/post/C0xB66huDJk">posted</a> on Threads.</p><p data-flatplan-paragraph="true">This confusion is a feature of a fragmented internet, which can give the impression that two opposing phenomena are happening simultaneously: Popular content is being consumed at an astounding scale, yet popularity and even celebrity feel miniaturized, siloed. We live in a world where it’s easier than ever to be blissfully unaware of things that other people are consuming. It’s also easier than ever to assign outsize importance to information or trends that may <em>feel</em> popular but are actually contained.</p><p data-flatplan-paragraph="true">Last month, a claim began to circulate online that TikTok was awash in viral videos of users reading from and praising Osama bin Laden’s 2002 “Letter to America.” The trend was quickly cited by journalists as a worrying indicator of rising anti-Semitism. But a quick analysis of the platform offered more nuance. Although some videos did exist, <em>The Washington Post</em> <a data-event-element="inline link" href="https://www.washingtonpost.com/style/2023/11/16/guardian-osama-bin-laden-letter-to-america/">found</a> that the “Letter to America” hashtag was on only 274 of them during the two-day period in question. The videos received 1.8 million views—far, far fewer than videos hashtagged with <em>travel</em>, <em>skincare</em>, and <em>anime</em> in another 24-hour stretch, according to examples named by the <em>Post</em>.</p><p data-flatplan-paragraph="true">What followed was a messy postmortem, one that I fear might foreshadow the way 2024-election stories will play out: Internet-savvy reporters <a data-event-element="inline link" href="https://nymag.com/intelligencer/2023/11/did-bin-laden-really-go-viral-on-tiktok.html">tried</a> to offer important <a data-event-element="inline link" href="https://www.garbageday.email/p/tiktok-teens-arent-stanning-osama">correctives</a> to the notion that the letter had gone viral. But others rightly <a data-event-element="inline link" href="https://www.threads.net/@ebakerwhite/post/CzwdeOnvHx7">noted</a> that the videos, at least one of which had more than 10,000 likes, were still troubling, even if they were not viral by TikTok standards. Politicians <a data-event-element="inline link" href="https://x.com/SenHawleyPress/status/1726682198408102081?s=20">seized</a> on the news to further their own long-standing grievances, namely that TikTok, which they fear is controlled by the Chinese government, is influencing and even radicalizing younger American users. TikTok did not respond to my request for comment.</p><p data-flatplan-paragraph="true">As interested parties debated whether the trend was real, the coverage drew greater attention to the videos, causing them to go far more viral on secondary platforms; a video compilation of the TikToks has been <a data-event-element="inline link" href="https://twitter.com/yashar/status/1724942399431217457">viewed</a> more than 41 million times on X. Should this cycle repeat in the same way next year, the 2024 presidential campaign will be an especially punishing affair: It will be the TikTok Shadowboxing Election, where virality becomes a meaningless descriptor that nevertheless justifies any number of conflicts.</p><p data-flatplan-paragraph="true">After the “Letter to America” controversy, I reached out to Brandon Silverman, the founder of CrowdTangle, a platform that tracks the most popular posts across Facebook (which acquired it in 2016). Silverman quit Facebook in 2021, and he now says that big technology platforms are making it harder to verify trends and trace where they came from. Unlike Twitter before Musk, X is a black box, he told me, and TikTok only gives access to its research interface to academic researchers by application. “We’re mostly arguing over data that we don’t have” and “chasing our own tails around the internet,” Silverman said.</p><p data-flatplan-paragraph="true">CrowdTangle itself paused new user sign-ups last year, arguably a major turning point in this entire conversation: Researchers and transparency groups argued that Meta defanged CrowdTangle’s team as part of an <a data-event-element="inline link" href="https://www.rappler.com/technology/features/things-to-know-meta-to-reportedly-shut-down-crowdtangle/">internal</a> reorganization, and reporters have <a data-event-element="inline link" href="https://www.bloomberg.com/news/articles/2022-06-23/meta-pulls-support-for-tool-used-to-keep-misinformation-in-check">speculated</a> that the transparency tool caused too many headaches for Meta executives when it became clear that conspiracy theories, election-denial content, and far-right influencers were popular across the social network. In a statement, a Meta spokesperson told me that paid CrowdTangle accounts are still active and that, last month, the company <a data-event-element="inline link" href="https://about.fb.com/news/2023/11/new-tools-to-support-independent-research/">rolled</a> out a new series of tools to “provide access to near real-time public content from Pages, Posts, Groups and Events” on Facebook, as well as from professional accounts on Instagram.</p><p data-flatplan-paragraph="true">Popularity and virality aren’t the only metrics to determine what’s important, but without an understanding of what is happening online, we’re much more likely to let others take advantage of us or to waste precious time thinking about, debunking, and debating issues and controversies that are actually insignificant or have little impact on the world around us. Likewise, politicians can take trends out of context to fit their own political agenda. Last month on the Senate floor, Senator Marsha Blackburn <a data-event-element="inline link" href="https://www.c-span.org/video/?c5094966/blackburn-tik-tok">cited</a> “the appalling popularity” of the bin Laden letter on TikTok. “This didn’t happen on its own,” Blackburn argued. “You had TikTok pushing along on this.” Some high-profile Democrats, including New York Governor Kathy Hochul, <a data-event-element="inline link" href="https://www.foxnews.com/politics/hochul-slams-tiktok-osama-bin-laden-letter-says-ny-social-media-task-force-wont-penalize-politics">similarly called out TikTok</a>. When we waste our time chasing shadows, Silverman argued, “we miss the more important issues that actually do deserve our time and attention and tell us something truly meaningful about platforms, ourselves, or the world.”</p><p data-flatplan-paragraph="true">Not that a more centralized social-media experience was perfect. “What I saw at CrowdTangle is that, more often than not, it was actually just a few influential accounts that made something ‘go viral,’” Silverman told me. He argued that, because the platform audiences were less fragmented, a few large accounts dictated virality way more often than an army of small ones did. Broderick agreed, noting that, especially on networks such as Twitter, media organizations could identify and amplify trends, thereby increasing their reach—a kind of self-fulfilling prophecy. “One reason why there’s so much consternation is that if you can’t see what’s going on, you can’t rig the game anymore,” he said.</p><p data-flatplan-paragraph="true">A shift away from a knowable internet might feel like a return to something smaller and purer. An internet with no discernable monoculture may feel, especially to those who’ve been continuously plugged into trending topics and viral culture, like a relief. But this new era of the internet is also one that entrenches tech giants and any forthcoming emergent platforms as the sole gatekeepers when it comes to tracking the way that information travels. We already know them to be unreliable narrators and poor stewards, but on a fragmented internet, where recommendation algorithms beat out the older follower model, we rely on these corporations to give us a sense of scale. This might sound overdramatic, but without an innate sense of what other people are doing, we might be losing a way to measure and evaluate ourselves. We’re left shadowboxing one another and arguing in the dark about problems, the size of which we can’t identify.</p></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
    </channel>
</rss>