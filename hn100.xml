<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 16 Jun 2025 18:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Salesforce study finds LLM agents flunk CRM and confidentiality tests (116 pts)]]></title>
            <link>https://www.theregister.com/2025/06/16/salesforce_llm_agents_benchmark/</link>
            <guid>44289554</guid>
            <pubDate>Mon, 16 Jun 2025 13:59:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/06/16/salesforce_llm_agents_benchmark/">https://www.theregister.com/2025/06/16/salesforce_llm_agents_benchmark/</a>, See on <a href="https://news.ycombinator.com/item?id=44289554">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>A new benchmark developed by academics shows that LLM-based AI agents perform below par on standard CRM tests and fail to understand the need for customer confidentiality.</p>
<p>A team led by Kung-Hsiang Huang, a Salesforce AI researcher, showed that using a new benchmark relying on synthetic data, LLM agents achieve around a 58 percent success rate on tasks that can be completed in a single step without needing follow-up actions or more information.</p>
<p>Using the benchmark tool CRMArena-Pro, the team also showed performance of LLM agents drops to 35 percent when a task requires multiple steps.</p>

    

<p>Another cause for concern is highlighted in the LLM agents' handling of confidential information. "Agents demonstrate low confidentiality awareness, which, while improvable through targeted prompting, often negatively impacts task performance," a <a target="_blank" href="https://arxiv.org/pdf/2505.18878">paper published at the end of last month said</a>.</p>

        


        

<p>The Salesforce AI Research team argued that existing benchmarks failed to rigorously measure the capabilities or limitations of AI agents, and largely ignored an assessment of their ability to recognize sensitive information and adhere to appropriate data handling protocols.</p>
<ul>

<li><a href="https://www.theregister.com/2025/06/16/bt_chief_says_ai_could_cut_more_staff/">BT chief says AI could deliver more job cuts, hints at Openreach sell-off</a></li>

<li><a href="https://www.theregister.com/2025/06/16/opinion_column_lrm/">Put Large Reasoning Models under pressure and they stop making sense, say boffins</a></li>

<li><a href="https://www.theregister.com/2025/06/15/ai_model_collapse_pollution/">The launch of ChatGPT polluted the world forever, like the first atomic weapons tests</a></li>

<li><a href="https://www.theregister.com/2025/06/13/cloud_costs_ai_inferencing/">Enterprise AI adoption stalls as inferencing costs confound cloud customers</a></li>
</ul>
<p>The research unit's CRMArena-Pro tool is fed a data pipeline of realistic synthetic data to populate a Salesforce organization, which serves as the sandbox environment. The agent takes user queries and decides between an API call or a response to the users to get more clarification or provide answers.</p>
<p>"These findings suggest a significant gap between current LLM capabilities and the multifaceted demands of real-world enterprise scenarios," the paper said.</p>
<p>The findings might worry both developers and users of LLM-powered AI agents. Salesforce co-founder and CEO Marc Benioff told investors last year that AI agents represented "<a target="_blank" href="https://www.theregister.com/2024/08/29/salesforce_pricing_per_ai_conversation/">a very high margin opportunity</a>" for the SaaS CRM vendor as it takes a share in efficiency savings accrued by customers using AI agents to help get more work out of each employee.</p>

        

<p>Elsewhere, the UK government has said it would <a target="_blank" href="https://www.theregister.com/2025/06/12/nhs_tech_spending_review/">target savings of £13.8 billion ($18.7 billion) by 2029</a> with a digitization and efficiency drive that relies, in part, on the adoption of AI agents.</p>
<p>AI agents might well be useful, however, organizations should be wary of banking on any benefits before they are proven. ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Working on databases from prison (493 pts)]]></title>
            <link>https://turso.tech/blog/working-on-databases-from-prison</link>
            <guid>44288937</guid>
            <pubDate>Mon, 16 Jun 2025 12:32:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://turso.tech/blog/working-on-databases-from-prison">https://turso.tech/blog/working-on-databases-from-prison</a>, See on <a href="https://news.ycombinator.com/item?id=44288937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I'm very excited to announce that I have recently joined Turso as a software engineer. For many in the field, including myself, getting to work on databases and solve unique challenges with such a talented team would be a dream job, but it is that much more special to me because of my unusual and unlikely circumstances. As difficult as it might be to believe, I am currently incarcerated and I landed this job from my cell in state prison. If you don’t know me, let me tell you more about how I got here.</p>
<h2 id="how-i-got-here"><a href="#how-i-got-here">#</a>How I got here</h2>
<p>Nearly two years have passed since I published <a href="https://pthorpe92.dev/intro/my-story">How I got here</a> to my blog. That post was my first real contact with the outside world in years, as I'd been off all social media and the internet since 2017. The response and support I would receive from the tech community caught me completely off guard.</p>
<p>A brief summary is that I'm currently serving prison time for poor decisions and lifestyle choices I made in my twenties, all related to drugs. Three years ago, I enrolled in a prison college program that came with the unique opportunity to access a computer with limited internet access. This immediately reignited a teenage love for programming and a lightbulb immediately lit up: that this would be my way out of the mess I had gotten myself into over the past 15 years. I quickly outgrew the curriculum, preferring instead to spend ~15+ hours a day on projects and open source contributions.</p>
<p>Through fortunate timing and lots of hard work, I was selected to be one of the first participants in the Maine Dept of Correction’s remote work program, where residents who meet certain requirements are allowed to seek out remote employment opportunities. I landed a software engineering job at a startup called <a href="https://unlockedlabs.org/">Unlocked Labs</a> building education solutions for incarcerated learners, while contributing to open source on the side. After just a year, I was leading their development team.</p>
<h3 id="finding-turso--hacking-on-project-limbo"><a href="#finding-turso--hacking-on-project-limbo">#</a>Finding Turso: hacking on project Limbo</h3>
<p>Last December I was between side-projects and browsing Hacker News when I discovered Project Limbo, an effort by Turso to rewrite SQLite from scratch. I'd never worked on relational databases, but some experience with a cache had recently sparked an interest in storage engines. Luckily for me I saw that the project was fairly young with plenty of low hanging fruit to cut my teeth on.</p>
<p>To put this entirely into perspective for some of you may be difficult, but in prison there isn’t exactly a whole lot to do and programming <em>absolutely</em> consumes my life. I either write code or manage Kubernetes clusters or other infrastructure for about 90 hours a week, and my only entertainment is a daily hour of tech/programming YouTube; mostly consisting of The Primeagen, whose story was a huge inspiration to me early on.</p>
<p>Through Prime, I had known about Turso since the beginning and had watched several interviews with Glauber and Pekka discussing their Linux kernel backgrounds and talking about the concept of distributed, multi-tenant SQLite. These were folks I'd looked up to for years and definitely could not have imagined that I would eventually be in any position to be contributing meaningfully to such an ambitious project of theirs. So needless to say, for those first PR's, just the thought of a kernel maintainer reviewing my code had made me quite nervous.</p>
<p>Helping build Limbo quickly became my new obsession. I split my time between my job and diving deep into SQLite source code, academic papers on database internals, and Andy Pavlo's CMU lectures. I was active on the <a href="https://discord.gg/turso">Turso Discord</a> but I don't think I considered whether anyone was aware that one of the top contributors was doing so from a prison cell. My story and information are linked on my GitHub, but it's subtle enough where you could miss it if you didn't read the whole profile. A couple months later, I got a Discord message from Glauber introducing himself and asking if we could meet.</p>
<p>In January, Glauber's <a href="https://x.com/glcst/status/1879553564177055855">tweet</a> about our interaction caught the attention of The Primeagen, and he ended up <a href="https://www.youtube.com/watch?v=XPyKbPLGzFI">reading my blog post</a> on his stream, bringing a whole lot of new attention to it.</p>
<p>To this day I receive semi-regular emails either from developers, college kids or others who maybe have either gone through addiction or similar circumstances, or just want to reach out for advice on how to best start contributing to open source or optimize their learning path.</p>
<h3 id="what-s-next"><a href="#what-s-next">#</a>What's Next</h3>
<p>I'm incredibly proud to be an example to others of how far hard work, determination and discipline will get you, and will be forever grateful for the opportunities given to me by the Maine Dept of Corrections to even be able to work hard in the first place, and to Unlocked Labs for giving me a chance and hiring me at a time when most assuredly no-one else would.</p>
<p>I'm also incredibly proud to announce that I am now working for Turso full time, something I would never have dreamed would be possible just a few years ago, I'm very excited to be a part of the team and to get to help build the modern evolution of SQLite.</p>
<p>Although some recent bad news from the court means that I won't be coming home as early as my family and I had hoped, my only choice is to view this as a blessing and for the next 10 months, will instead just be able to continue to dedicate time and focus to advancing my career at such a level that just wouldn't be possible otherwise.</p>
<p>Thank you to everyone who has taken the time to reach out over the past couple years, to my team at Unlocked Labs, and especially my parents. Thanks to Turso for the opportunity and to all the other companies with fair chance hiring policies who believe that people deserve a second chance. This journey has been totally surreal and every day I am still in awe of how far my life has come from the life I lived even just a few years ago.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla blows past stopped school bus and hits kid-sized dummies in FSD tests (113 pts)]]></title>
            <link>https://www.engadget.com/transportation/tesla-blows-past-stopped-school-bus-and-hits-kid-sized-dummies-in-full-self-driving-tests-183756251.html</link>
            <guid>44288000</guid>
            <pubDate>Mon, 16 Jun 2025 09:58:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/transportation/tesla-blows-past-stopped-school-bus-and-hits-kid-sized-dummies-in-full-self-driving-tests-183756251.html">https://www.engadget.com/transportation/tesla-blows-past-stopped-school-bus-and-hits-kid-sized-dummies-in-full-self-driving-tests-183756251.html</a>, See on <a href="https://news.ycombinator.com/item?id=44288000">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A revealing demonstration with Tesla's Full Self-Driving mode is raising concerns about whether fully autonomous cars are ready to hit the streets. Tesla has <a data-i13n="cpos:1;pos:1" href="https://www.bloomberg.com/news/articles/2025-05-28/tesla-targets-june-12-launch-of-robotaxi-service-in-austin?sref=10lNAhZ9&amp;embedded-checkout=true" rel="nofollow noopener" target="_blank" data-ylk="slk:reportedly pushed back;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">reportedly pushed back</a> the rollout of its upcoming all-electric, fully autonomous car called the Cybercab, while a recent demonstration in Austin, Texas showed a Tesla Model Y running through a school bus' flashing lights and stop signs, and hitting child-size mannequins. The tests were conducted by The Dawn Project, along with Tesla Takedown and ResistAustin, and showed Tesla's Full Self-Driving software repeating the same mistake eight times.</p><p>It's worth noting that Tesla's autonomous driving feature is formally known as Full Self-Driving (Supervised) and "requires a fully attentive driver and will display a series of escalating warnings requiring driver response." Tesla even has a warning that says, "failure to follow these instructions could cause damage, serious injury or death." However, it's not the first time that Tesla's FSD software has found itself in hot water. The Dawn Project, whose founder Dan O'Dowd is the CEO of a company that offers competing automated driving system software, previously took out ads warning about the dangers of Tesla's Full Self-Driving and how it would fail to yield around school buses. In April 2024, a Model S using Full Self-Driving was involved in a <a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/tesla-involved-in-fatal-washington-crash-was-using-self-driving-mode-170706606.html" data-ylk="slk:crash in Washington;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas">crash in Washington</a>, where a motorcyclist died.</p><p>With anticipation building up for an <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/transportation/evs/tesla-will-start-offering-public-robotaxi-rides-in-austin-on-june-22-says-elon-musk-161801916.html" data-ylk="slk:eventual Cybercab rollout;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas">eventual Cybercab rollout</a> on June 22, the company's CEO posted some <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1" href="https://x.com/elonmusk/status/1932591896939147494" rel="nofollow noopener" target="_blank" data-ylk="slk:additional details on X;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas">additional details on X</a>. According to Elon Musk, Tesla is "being super paranoid about safety, so the date could shift." Beyond that, Musk also posted that the "first Tesla that drives itself from factory end of line all the way to a customer house is June 28."</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Start your own Internet Resiliency Club (446 pts)]]></title>
            <link>https://bowshock.nl/irc/</link>
            <guid>44287395</guid>
            <pubDate>Mon, 16 Jun 2025 07:38:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bowshock.nl/irc/">https://bowshock.nl/irc/</a>, See on <a href="https://news.ycombinator.com/item?id=44287395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">

            

            <section>
    <header>
        
    </header>
    <div>
        <p>Thanks to war, geopolitics, and climate change, Europe will have more
frequent and more severe <a href="https://nltimes.nl/2025/05/09/russia-preparing-war-europe-dutch-pm-activities-finnish-border">internet
disruptions</a>
in the very near future. Governments and businesses need to prepare
for catastrophic loss of communications. Unfortunately, the necessary
changes are risky and expensive, which means they won’t do it until a
<a href="https://layeraleph.com/">crisis</a> is already here. However, small
groups of volunteers with a little bit of time and money can provide
crucial initial leadership to bootstrap recovery.</p>
<p>An Internet Resiliency Club is a group of internet experts who can
communicate with each other across a few kilometers without any
centralized infrastructure using cheap, low-power, unlicensed
<a href="https://en.wikipedia.org/wiki/LoRa">LoRa</a> radios and open source
<a href="https://meshtastic.org/">Meshtastic</a> text messaging software. These
volunteer groups can use their radios, technical skills, and personal
connections with other experts to restore internet connectivity.</p>
<p>This page is a quick-start guide to forming your own Internet
Resiliency Club. You can also join a <a href="https://lists.bowshock.nl/mailman/listinfo/irc">mailing
list</a> for general
questions and discussion about internet resiliency clubs:</p>
<p><a href="https://lists.bowshock.nl/mailman/listinfo/irc">https://lists.bowshock.nl/mailman/listinfo/irc</a></p>
<ul>
<li><a href="#short-version">Skip directly to the section with hardware
recommendations and setup instructions</a></li>
<li><a href="https://ripe90.ripe.net/archives/video/1565/">Watch the 10 minute video</a> of the RIPE 90 talk</li>
<li><a href="https://ripe90.ripe.net/wp-content/uploads/presentations/36-Internet-Resiliency-Club-RIPE-90.pdf">Read the slides</a> for the 10 minute RIPE 90 talk</li>
<li><a href="https://pretalx.t-dose.org/media/2025/submissions/LYGXHY/resources/Internet_Resiliency_Club_T-DOSE_YqGkZ7U.pdf">Read the longer slides</a> for the 45 minute T-DOSE 2025 talk</li>
</ul>

<p>I am <a href="https://www.linkedin.com/in/valerieaurora/">Valerie Aurora</a>, a
systems software engineer with 25 years of experience in open source
software, operating systems, networking, file systems, and volunteer
organizing. When I moved from San Francisco to Amsterdam in 2023, I
started looking for ways to give back to my new home. In addition to
systems consulting, I am a special rapporteur for the EU’s Cyber
Resilience Act, serve as a RIPE Meeting program committee member, and
speak at European technical conferences.</p>
<h2 id="why-internet-resiliency-club">Why Internet Resiliency Club?</h2>
<p>One of my nightmares is waking up one morning and discovering that the
power is out, the internet is down, my cell phone doesn’t work, and
when I turn on the emergency radio (if you have one), all you hear is
“Swan Lake” on repeat.</p>
<p>As a recent immigrant to Amsterdam, I began to realize that this
nightmare was increasingly likely. Russia regularly knocks out
communications and power in Ukraine, using both bombs and hackers. In
2022, German windmills were disabled by malware aimed at Ukraine.
Dubious tankers continue to “accidentally” drag their anchors and cut
undersea cables in the Baltic. The head of NATO advised everyone to
keep three days of supplies at home.</p>
<h2 id="ukraines-advice-on-network-resilience">Ukraine’s advice on network resilience</h2>
<p>What made me finally take action is watching a video created by
<a href="https://1-ix.net/en/poslugy-en-translation/ua-exchange/">Ukrainian IXP
1-IX</a> to
teach other European countries what Ukrainian internet operators have
learned about hardening and repairing internet infrastructure leading
up to and following the 2022 Russian invasion. The practical realities
of keeping networks operating during war were sobering: building
camoflouged router rooms with 3 days of generator power, replacing
active fiber optic cable with passive, getting military service
exemptions for their personnel, etc.. You can watch the most recent
version, <a href="https://ripe90.ripe.net/archives/video/1582/">“Network Resilience: Experiences of survival and development
during the war in
Ukraine”</a>, a 30 minute
presentation at RIPE 90.</p>
<h2 id="what-is-the-dutch-government-doing-to-prepare">What is the Dutch government doing to prepare?</h2>
<p>Unfortunately, the government of the Netherlands is not following
Ukraine’s lead. <a href="https://berthub.eu/articles/posts/cyber-security-pre-war-reality-check/">Bert Hubert’s blog post</a>
describes the Netherlands’ cloud-based “emergency communications”
system, which will definitely not work in any emergency that affects
power or internet connectivity.</p>
<p>I have asked many Dutch network operators if there is any official
plan for the communications equivalent of a “black start” of the
electrical grid. If there is one, it isn’t being shared with the
people who will have to implement it.</p>
<h2 id="crisis-engineering-to-the-rescue">Crisis engineering to the rescue</h2>
<p>The final piece of the idea came from a class I took on <a href="https://layeraleph.com/event/">Crisis
Engineering</a> from Layer Aleph, on how
organizations facing an existential crisis either swiftly transform
themselves into a more functional form, or they fail and become even
more dysfunctional. Our class’s first question was, “How do you
convince an organization that a crisis is coming and they need to
prepare for it?”</p>
<p>Their answer was both depressing and freeing: “You can’t. All you can
do is be prepared with tools and a plan for when the crisis arrives.
That’s when the organization will listen.”</p>
<h2 id="what-can-i-do-personally">What can I do personally?</h2>
<p>I started thinking about what I could personally do without any help
from government or businesses. What if I could organize a group of
volunteer networking experts who could communicate without any
centralized infrastructure? We could effectively bootstrap
communications recovery with just a few volunteers and some cheap
hardware.</p>
<h2 id="ham-radio-is-too-expensive-difficult-and-power-hungry">Ham radio is too expensive, difficult, and power-hungry</h2>
<p>Initially I looked into ham radio, but it is just too expensive,
difficult, and power-hungry to be practical. Then Alexander Yurtchenko
told me about LoRa (Long Range) radio and Meshtastic, a cheap,
low-power method of sending text messages across a few kilometers.</p>
<p>After a few months of part-time research and organizing, the Amsterdam
Internet Resiliency Club was born. This page exists to make it easier
for other people to start Internet Resiliency Clubs in their area.</p>
<h2 id="we-need-volunteer-internet-resiliency-organizations">We need volunteer internet resiliency organizations</h2>
<p>The evidence that Internet Resiliency Clubs are necessary keeps
growing. Since I started this project, the city of Amsterdam announced
that it is planning for three weeks without electricity. Spain and
Portugal lost power for most of a day. The U.S. re-elected Donald
Trump, who may at some point realize that he can hold Europe hostage
by threatening to cut off access to U.S.-owned internet services like
AWS and Microsoft Exchange. Simultaneously, large parts of Dutch
government are migrating to email hosted by Microsoft, and major Dutch
technology firms continue to migrate to AWS and Microsoft Azure.</p>
<p>If you and I don’t do this, dear reader, no one will.</p>
<h2 id="short-version">Short version</h2>
<p>How to form an Internet Resiliency Club:</p>
<ul>
<li>Collect a group of internet-y people within ~10 km of each other</li>
<li>Decide how to communicate normally (Signal, Matrix, email, etc.)</li>
<li>Buy everyone LoRa (Long Range) radios and a powerbank with trickle charge</li>
<li>Install Meshtastic on the LoRa radios</li>
<li>Choose a LoRa channel to communicate on</li>
<li>Organize meetups, send messages over Meshtastic, have fun</li>
</ul>
<p>If you work for a internet infrastructure company, you can suggest
giving interested employees a LoRa radio, a mobile phone powerbank,
and maybe even a small solar panel for their personal use (perhaps as
part of an annual gift or bonus).</p>
<h2 id="lora">LoRa</h2>
<p>LoRa radios have several advantages for use in emergency
communications:</p>
<ul>
<li>no centralized infrastructure needed</li>
<li>no license needed</li>
<li>cheap (starting at ~€20)</li>
<li>low-power (&lt; 1W, can power with an ordinary mobile phone powerbank)</li>
<li>runs open source Meshtastic firmware</li>
<li>can send text messages across several line-of-sight hops (several kms)</li>
<li>can connect via Bluetooth or WiFi to phones/computers</li>
<li>many urban areas have a good Meshtastic network already</li>
</ul>
<p>Amateur ham radio can transmit at higher bandwidth for longer
distances, but requires extensive training, licensing, larger
antennas, and more power. Ideally, both would be available in an
emergency.</p>
<h2 id="lorameshtastic-basics">LoRa/Meshtastic basics</h2>
<p>With a LoRa radio running the Meshtastic firmware, anyone can send
text messages to anyone else with a Meshtastic node as long as it
takes three or fewer forwards from other Meshtastic nodes to get from
source to destination (usually around ~10 km but highly dependent on
local terrain and weather).</p>
<p>Specifically, <a href="https://en.wikipedia.org/wiki/LoRa">LoRa</a> is a
proprietary technique for sending low bit-rate radio messages (~1 - 25
kbps) using very low power (&lt; 1W), derived from chirp spread spectrum
techniques. <a href="https://meshtastic.org/">Meshtastic</a> is open source
firmware for LoRa radios that uses a flood-forward mesh protocol to
send message across up to three line-of-sight hops between LoRa nodes
running Meshtastic.</p>
<p>LoRa radios are for sale online. The cheapest versions are development
boards, intended for companies to use while building a product, often
without batteries, cases, or good antennas. To use them, you must
connect to them from a phone or computer, either over Bluetooth via
the Meshtastic app or over WiFi using a web browser. The more
expensive systems may include an enclosure, battery, solar panel,
larger screen, keyboard, etc. Some can be used without an additional
phone or computer.</p>
<h2 id="battery-power">Battery power</h2>
<p>LoRa radios use relatively little power, often in the range of 100 -
200 mA. A normal mobile phone power bank with a capacity of 10000 -
20000 mAh can power a LoRa radio approximately 2 - 8 days, depending
on chipset, time spent transmitting, whether WiFi or Bluetooth are in
use, etc. The powerbank should support “trickle charging”; without
this, many powerbanks will stop supplying power because the power draw
of many LoRa radios is so low that the powerbank thinks nothing is
connected and stops supplying power.</p>
<h2 id="solar-power">Solar power</h2>
<p>LoRa radios can be powered by directly plugging them into a small
solar panel with USB output, or by charging a battery used by the LoRa
radio. A small folding 800 cm^2 solar panel generating 15w with a
5W/500 mA max output is sufficient to power many LoRa radios. With
this small of a setup, you don’t need fuses, charge controllers,
buck/boost converters, or anything other than the solar panel and an
optional mobile phone power bank.</p>
<h2 id="which-lora-radio-to-buy">Which LoRa radio to buy</h2>
<p>LoRa radios are available in a huge range of capabilities and
features. For an Internet Resiliency Club, we recommend one of:</p>
<ul>
<li>Heltec V3: no case, no battery, WiFi/Bluetooth, OLED display, USB-C</li>
<li>LILYGO T-Echo: case, built-in battery, Bluetooth, e-ink display, USB-C</li>
</ul>
<p><em>IMPORTANT: Never turn on a LoRa device without an antenna attached!
The power sent to the antenna can destroy the device if there is no
antenna attached to radiate it.</em></p>
<p>Note: While many LoRa devices have USB-C ports, they often don’t
implement USB-C PD (Power Delivery) and won’t charge their battery
correctly on USB-C to USB-C cables. Use a USB-A to USB-C cable (often
supplied with the device).</p>
<h2 id="heltec-v3-series">Heltec V3 series</h2>
<p>If you have more time than money, try the latest Heltec V3, currently
one of the cheapest boards available at around €20. It has a
postage stamp-sized OLED screen, a couple of tiny buttons,
WiFi/Bluetooth, and USB-C input/power (but use a USB-A to USB-C
cable). Received messages are displayed on the OLED and can be cycled
through with tiny buttons. Sending messages requires connecting to it
via WiFi or Bluetooth.</p>
<p>It has no case, but the little plastic box it comes in can easily be
turned into one with a sharp pen knife. It also has no battery, but it
is a good idea to have a separate power bank anyway since you need a
working phone or computer to send messages. It has no GPS.</p>
<p>The <a href="https://meshtastic.org/docs/hardware/devices/heltec-automation/lora32/?heltec=v3">Meshtastic
page on this
board</a>
includes links to purchase from in Europe. I bought mine from
<a href="https://www.tinytronics.nl/en/development-boards/microcontroller-boards/with-lora/heltec-wifi-lora-32-esp32-s3-sx1262-with-0.96-inch-oled-display">TinyTronics</a>.</p>
<h2 id="lilygo-t-echo">LILYGO T-Echo</h2>
<p>If you have more money than time, I recommend the LILYGO T-Echo, a
simple small low-power ready-to-use handheld device for about
€80. It has ~3cm square e-ink display, a case with a few buttons,
Bluetooth, GPS, and about a day’s worth of battery.
Input/output/charging is via USB-C (but use a USB-A to USB-C cable).
Received messages are displayed on the e-ink screen and can be cycled
through with the buttons. Sending messages requires connecting with
another device via Bluetooth.</p>
<p>The <a href="https://meshtastic.org/docs/hardware/devices/lilygo/techo/">Meshtastic
page on this
board</a>
includes links to purchase from in Europe. I bought mine from
<a href="https://www.tinytronics.nl/en/development-boards/microcontroller-boards/with-gps/lilygo-ttgo-t-echo-nrf52840-lora-868mhz-bme280-gnss-black">TinyTronics</a>.</p>
<h2 id="lilygo-t-deck">LILYGO T-Deck</h2>
<p>If you want a standalone device that doesn’t require a separate phone
or computer to send messages, the <a href="https://www.tinytronics.nl/nl/development-boards/microcontroller-boards/met-lora/lilygo-t-deck-esp32-s3-toetsenbord-met-2.8-inch-ips-display-en-touchscreen-lora-868mhz-zwart">LILYGO
T-Deck</a>
includes a keyboard, trackball, and touch screen for about €70 -
80, depending on whether it includes a case and whether the antenna is
internal or external. It has about 8 hours of battery. I’m not a fan
because the screen and keyboard aren’t as good as the one on your
phone and take extra battery to run. It is often out of stock,
especially if you’re looking for a case and external antenna.</p>
<p>The <a href="https://meshtastic.org/docs/hardware/devices/lilygo/tdeck/">Meshtastic page on this
board</a>
includes links to purchase from in Europe.</p>
<h2 id="upgrading-the-antenna">Upgrading the antenna</h2>
<p>Most of the antennas that ship with evaluation boards are not very
good. One option for an upgrade if you’re using the recommended 868
MHz network is the <a href="https://eleshop.eu/868-mhz-antenne-met-sma-connector.html">Taoglas
TI.08.A</a>.</p>
<p><em>IMPORTANT: Never turn on a LoRa device without an antenna attached!
The power sent to the antenna can destroy the device if there is no
antenna attached to radiate it.</em></p>
<h2 id="flashing-installing-the-meshtastic-firmware">Flashing (installing) the Meshtastic firmware</h2>
<p>Some boards ship with Meshtastic already installed, but it’s
undoubtedly several months out of date. Flashing LoRa boards is
relatively easy; it can be as simple as using the <a href="https://meshtastic.org/docs/getting-started/flashing-firmware/esp32/">Meshtastic web
browser
flasher</a>
(requires Chrome or Edge) or dragging and dropping a file into a
mounted USB drive presented by the device. A command line tool using a
serial interface is also an option, but may require some fiddling with
a Python env.</p>

<p>In Europe, two frequencies are available for use by LoRa: <a href="https://meshtastic.org/docs/configuration/region-by-country/">868 MHz and
433
MHz</a>.
868 MHz is the <a href="https://meshtastic.org/docs/overview/radio-settings/">most popular for Meshtastic users in
Europe</a>. Several
modem presets are available; use the default mode <code>LONG_FAST</code> unless you
have a specific reason not to.</p>
<p>LoRa has
<a href="https://meshtastic.org/docs/configuration/radio/channels/">channels</a>,
a stream of messages using the same encryption key and channel name.
Each device is configured with a default primary channel shared by all
Meshtastic nodes. You can also configure secondary channels that can
only be accessed by nodes with the same key and channel name. Choose
an encryption key and channel name for a shared secondary channel. You
can share a QR code to configure a device with the appropriate
channels and settings.</p>
<h2 id="meetups-and-practice">Meetups and practice</h2>
<p>The best time to learn how to work together with a group of people is
before a crisis, not during it. Crisis engineering tells us that a
team is more likely to be successful if everyone has already worked
together.</p>
<p>Since this is a volunteer group, “working” together has to be fun.
Invite your group to do fun things together, changing up what activity
you are doing, where it is located, and what time it is held so that
a wide variety of people can participate.</p>
<h2 id="mailing-list">Mailing list</h2>
<p>If you have more questions or suggestions, please join our <a href="https://lists.bowshock.nl/mailman/listinfo/irc">mailing
list</a>:</p>
<p><a href="https://lists.bowshock.nl/mailman/listinfo/irc">https://lists.bowshock.nl/mailman/listinfo/irc</a></p>
<h2 id="credits">Credits</h2>
<p>Many people helped me with Internet Resiliency Club:</p>
<ul>
<li><a href="https://1-ix.net/en/poslugy-en-translation/ua-exchange/">Ukrainian IXP
1-IX</a> and other Ukrainian operators for their video <a href="https://ripe90.ripe.net/archives/video/1582/">“Network Resilience: Experiences of survival and development during the war in Ukraine”</a></li>
<li><a href="https://www.linkedin.com/in/andrew-yourtchenko-9304551/">Andrew Yourtchenko</a> for early brainstorming</li>
<li><a href="https://layeraleph.com/">Layer Aleph</a> and their <a href="https://layeraleph.com/event/">Crisis Engineering</a> class</li>
<li>Bert Hubert’s entire blog, but especially <a href="https://berthub.eu/articles/posts/cyber-security-pre-war-reality-check/">Cyber Security: A Pre-War Reality Check</a></li>
<li><a href="https://trmm.net/">Trammell Hudson</a> for helping me with battery and solar questions</li>
<li>Timo Hilbrink for researching antennas</li>
<li>The entire Amsterdam Internet Resiliency Club</li>
</ul>

    </div>
    

            </section>

            

            

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nanonets-OCR-s – OCR model that transforms documents into structured markdown (194 pts)]]></title>
            <link>https://huggingface.co/nanonets/Nanonets-OCR-s</link>
            <guid>44287043</guid>
            <pubDate>Mon, 16 Jun 2025 06:14:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/nanonets/Nanonets-OCR-s">https://huggingface.co/nanonets/Nanonets-OCR-s</a>, See on <a href="https://news.ycombinator.com/item?id=44287043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START --><p>Nanonets-OCR-s is a powerful, state-of-the-art image-to-markdown OCR model that goes far beyond traditional text extraction. It transforms documents into structured markdown with intelligent content recognition and semantic tagging, making it ideal for downstream processing by Large Language Models (LLMs).</p>
<p>Nanonets-OCR-s is packed with features designed to handle complex documents with ease:</p>
<ul>
<li><strong>LaTeX Equation Recognition:</strong> Automatically converts mathematical equations and formulas into properly formatted LaTeX syntax. It distinguishes between inline (<code>$...$</code>) and display (<code>$$...$$</code>) equations.</li>
<li><strong>Intelligent Image Description:</strong> Describes images within documents using structured <code>&lt;img&gt;</code> tags, making them digestible for LLM processing. It can describe various image types, including logos, charts, graphs and so on, detailing their content, style, and context.</li>
<li><strong>Signature Detection &amp; Isolation:</strong> Identifies and isolates signatures from other text, outputting them within a <code>&lt;signature&gt;</code> tag. This is crucial for processing legal and business documents.</li>
<li><strong>Watermark Extraction:</strong> Detects and extracts watermark text from documents, placing it within a <code>&lt;watermark&gt;</code> tag.</li>
<li><strong>Smart Checkbox Handling:</strong> Converts form checkboxes and radio buttons into standardized Unicode symbols (<code>☐</code>, <code>☑</code>, <code>☒</code>) for consistent and reliable processing.</li>
<li><strong>Complex Table Extraction:</strong> Accurately extracts complex tables from documents and converts them into both markdown and HTML table formats.</li>
</ul>
<p>📢 <a rel="nofollow" href="https://nanonets.com/research/nanonets-ocr-s">Read the full announcement</a> | 🤗 <a rel="nofollow" href="https://huggingface.co/spaces/Souvik3333/Nanonets-ocr-s">Hugging Face Space Demo</a></p>
<h2>
	<a rel="nofollow" href="#usage" id="usage">
		
	</a>
	<span>
		Usage
	</span>
</h2>
<h3>
	<a rel="nofollow" href="#using-transformers" id="using-transformers">
		
	</a>
	<span>
		Using transformers
	</span>
</h3>
<pre><code><span>from</span> PIL <span>import</span> Image
<span>from</span> transformers <span>import</span> AutoTokenizer, AutoProcessor, AutoModelForImageTextToText

model_path = <span>"nanonets/Nanonets-OCR-s"</span>

model = AutoModelForImageTextToText.from_pretrained(
    model_path, 
    torch_dtype=<span>"auto"</span>, 
    device_map=<span>"auto"</span>, 
    attn_implementation=<span>"flash_attention_2"</span>
)
model.<span>eval</span>()

tokenizer = AutoTokenizer.from_pretrained(model_path)
processor = AutoProcessor.from_pretrained(model_path)


<span>def</span> <span>ocr_page_with_nanonets_s</span>(<span>image_path, model, processor, max_new_tokens=<span>4096</span></span>):
    prompt = <span>"""Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the &lt;img&gt;&lt;/img&gt; tag; otherwise, add the image caption inside &lt;img&gt;&lt;/img&gt;. Watermarks should be wrapped in brackets. Ex: &lt;watermark&gt;OFFICIAL COPY&lt;/watermark&gt;. Page numbers should be wrapped in brackets. Ex: &lt;page_number&gt;14&lt;/page_number&gt; or &lt;page_number&gt;9/22&lt;/page_number&gt;. Prefer using ☐ and ☑ for check boxes."""</span>
    image = Image.<span>open</span>(image_path)
    messages = [
        {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a helpful assistant."</span>},
        {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: [
            {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>f"file://<span>{image_path}</span>"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: prompt},
        ]},
    ]
    text = processor.apply_chat_template(messages, tokenize=<span>False</span>, add_generation_prompt=<span>True</span>)
    inputs = processor(text=[text], images=[image], padding=<span>True</span>, return_tensors=<span>"pt"</span>)
    inputs = inputs.to(model.device)
    
    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=<span>False</span>)
    generated_ids = [output_ids[<span>len</span>(input_ids):] <span>for</span> input_ids, output_ids <span>in</span> <span>zip</span>(inputs.input_ids, output_ids)]
    
    output_text = processor.batch_decode(generated_ids, skip_special_tokens=<span>True</span>, clean_up_tokenization_spaces=<span>True</span>)
    <span>return</span> output_text[<span>0</span>]

image_path = <span>"/path/to/your/document.jpg"</span>
result = ocr_page_with_nanonets_s(image_path, model, processor, max_new_tokens=<span>15000</span>)
<span>print</span>(result)
</code></pre>
<h3>
	<a rel="nofollow" href="#using-vllm" id="using-vllm">
		
	</a>
	<span>
		Using vLLM
	</span>
</h3>
<ol>
<li>Start the vLLM server.</li>
</ol>
<pre><code>vllm serve nanonets/Nanonets-OCR-s
</code></pre>
<ol start="2">
<li>Predict with the model</li>
</ol>
<pre><code><span>from</span> openai <span>import</span> OpenAI
<span>import</span> base64

client = OpenAI(api_key=<span>"123"</span>, base_url=<span>"http://localhost:8000/v1"</span>)

model = <span>"nanonets/Nanonets-OCR-s"</span>

<span>def</span> <span>encode_image</span>(<span>image_path</span>):
    <span>with</span> <span>open</span>(image_path, <span>"rb"</span>) <span>as</span> image_file:
        <span>return</span> base64.b64encode(image_file.read()).decode(<span>"utf-8"</span>)

<span>def</span> <span>ocr_page_with_nanonets_s</span>(<span>img_base64</span>):
    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                <span>"role"</span>: <span>"user"</span>,
                <span>"content"</span>: [
                    {
                        <span>"type"</span>: <span>"image_url"</span>,
                        <span>"image_url"</span>: {<span>"url"</span>: <span>f"data:image/png;base64,<span>{img_base64}</span>"</span>},
                    },
                    {
                        <span>"type"</span>: <span>"text"</span>,
                        <span>"text"</span>: <span>"Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the &lt;img&gt;&lt;/img&gt; tag; otherwise, add the image caption inside &lt;img&gt;&lt;/img&gt;. Watermarks should be wrapped in brackets. Ex: &lt;watermark&gt;OFFICIAL COPY&lt;/watermark&gt;. Page numbers should be wrapped in brackets. Ex: &lt;page_number&gt;14&lt;/page_number&gt; or &lt;page_number&gt;9/22&lt;/page_number&gt;. Prefer using ☐ and ☑ for check boxes."</span>,
                    },
                ],
            }
        ],
        temperature=<span>0.0</span>,
        max_tokens=<span>15000</span>
    )
    <span>return</span> response.choices[<span>0</span>].message.content

test_img_path = <span>"/path/to/your/document.jpg"</span>
img_base64 = encode_image(test_img_path)
<span>print</span>(ocr_page_with_nanonets_s(img_base64))
</code></pre>
<h3>
	<a rel="nofollow" href="#using-docext" id="using-docext">
		
	</a>
	<span>
		Using docext
	</span>
</h3>
<pre><code>pip install docext
python -m docext.app.app --model_name hosted_vllm/nanonets/Nanonets-OCR-s
</code></pre>
<p>Checkout <a rel="nofollow" href="https://github.com/NanoNets/docext/tree/dev/markdown">GitHub</a> for more details.</p>
<h2>
	<a rel="nofollow" href="#bibtex" id="bibtex">
		
	</a>
	<span>
		BibTex
	</span>
</h2>
<pre><code>@misc{Nanonets-OCR-S,
  title={Nanonets-OCR-S: A model for transforming documents into structured markdown with intelligent content recognition and semantic tagging},
  author={Souvik Mandal and Ashish Talewar and Paras Ahuja and Prathamesh Juvatkar},
  year={2025},
}
</code></pre>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Accumulation of cognitive debt when using an AI assistant for essay writing task (248 pts)]]></title>
            <link>https://arxiv.org/abs/2506.08872</link>
            <guid>44286277</guid>
            <pubDate>Mon, 16 Jun 2025 02:49:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2506.08872">https://arxiv.org/abs/2506.08872</a>, See on <a href="https://news.ycombinator.com/item?id=44286277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2506.08872">View PDF</a></p><blockquote>
            <span>Abstract:</span>This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Nataliya Kosmyna [<a href="https://arxiv.org/show-email/129cc1fe/2506.08872" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 10 Jun 2025 15:04:28 UTC (35,375 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Gravity Just Entropy Rising? Long-Shot Idea Gets Another Look (198 pts)]]></title>
            <link>https://www.quantamagazine.org/is-gravity-just-entropy-rising-long-shot-idea-gets-another-look-20250613/</link>
            <guid>44285874</guid>
            <pubDate>Mon, 16 Jun 2025 00:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/is-gravity-just-entropy-rising-long-shot-idea-gets-another-look-20250613/">https://www.quantamagazine.org/is-gravity-just-entropy-rising-long-shot-idea-gets-another-look-20250613/</a>, See on <a href="https://news.ycombinator.com/item?id=44285874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>Isaac Newton was never entirely happy with his law of universal gravitation. For decades after publishing it in 1687, he sought to understand how, exactly, two objects were able to pull on each other from afar. He and others came up with several mechanical models, in which gravity was not a pull, but a push. For example, space might be filled with unseen particles that bombard the objects on all sides. The object on the left absorbs the particles coming from the left, the one on the right absorbs those coming from the right, and the net effect is to push them together.</p>
<p>Those theories never quite worked, and Albert Einstein eventually provided a deeper explanation of gravity as a distortion of space and time. But Einstein’s account, called general relativity, <a href="https://www.quantamagazine.org/the-thought-experiments-that-fray-the-fabric-of-space-time-20240925/">created its own puzzles</a>, and he himself recognized that it could not be the final word. So the idea that gravity is a collective effect — not a fundamental force, but the outcome of swarm behavior on a finer scale — still compels physicists.</p>
<p>Earlier this year, a team of theoretical physicists <a href="https://arxiv.org/abs/2502.17575">put forward</a> what might be considered a modern version of those 17th-century mechanical models. “There’s some kind of gas or some thermal system out there that we can’t see directly,” said <a href="https://qquest.lbl.gov/~carney/">Daniel Carney</a> of Lawrence Berkeley National Laboratory, who led the effort. “But it’s randomly interacting with masses in some way, such that on average you see all the normal gravity things that you know about: The Earth orbits the sun, and so forth.”</p>
<p>This project is one of the many ways that physicists have sought to understand gravity, and perhaps the bendy space-time continuum itself, as emergent from deeper, more microscopic physics. Carney’s line of thinking, known as entropic gravity, pegs that deeper physics as essentially just the physics of heat. It says gravity results from the same random jiggling and mixing up of particles — and the attendant rise of entropy, loosely defined as disorder — that governs steam boilers, car engines and refrigerators.</p>
<figure>
    <p><img width="2000" height="1334" src="https://www.quantamagazine.org/wp-content/uploads/2025/06/Daniel-Carney.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/06/Daniel-Carney.webp 2000w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Daniel-Carney-1720x1147.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Daniel-Carney-520x347.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Daniel-Carney-768x512.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Daniel-Carney-1536x1025.webp 1536w" sizes="(max-width: 2000px) 100vw, 2000px">    </p>
            <figcaption>
                            <p>Daniel Carney, a theoretical physicist at Lawrence Berkeley National Laboratory, spearheaded the latest attempt to explain gravity as an entropic force.</p>
            <p>The Regents of the University of California, Lawrence Berkeley National Laboratory</p>
        </figcaption>
    </figure>

<p>Attempts at modeling gravity as a consequence of rising entropy have cropped up now and again for several decades. Entropic gravity is very much a minority view. But it’s one that won’t die, and even detractors are loath to dismiss it altogether. The new model has the virtue of being experimentally testable — a rarity when it comes to theories about the mysterious underpinnings of the universal attraction.</p>
<h2><strong>A Force Emerges</strong></h2>
<p>What makes Einstein’s theory of gravity so remarkable is not just that it works (and does so with sublime mathematical beauty), but that it betrays its own incompleteness. General relativity predicts that stars can collapse to form black holes, and that, at the centers of these objects, gravity becomes infinitely strong. There, the space-time continuum tears open like an overloaded grocery bag, and the theory is unable to say what comes next. Furthermore, general relativity has uncanny parallels to heat physics, even though not a single thermal concept went into its development. It predicts that black holes only grow, never shrink, and only swallow, never disgorge. Such irreversibility is characteristic of the flow of heat. When heat flows, energy takes a more randomized or disordered form; once it does, it is unlikely to reorder itself spontaneously. Entropy quantifies this growth of disorder.</p>
<p>Indeed, when physicists used quantum mechanics to study what happens in the distorted space-time around a black hole, they find that black holes give off energy like any hot body. Because heat is the random motion of particles, these thermal effects suggest to many researchers that black holes, and the space-time continuum in general, actually consist of some kind of particles or other microscopic components.</p>

<p>Following the <a href="https://www.quantamagazine.org/the-1-clue-to-quantum-gravity-sits-on-the-surfaces-of-black-holes-20240925/">clues from black holes</a>, physicists have pursued multiple approaches to understanding how space-time emerges from more microscopic components. The leading approach takes off from what’s known as the holographic principle. It says the emergence of space-time works a bit like an ordinary hologram. Just as a hologram evokes a sense of depth from a wavy pattern etched onto a flat surface, patterns in the microscopic components of the universe may give rise to another spatial dimension. This new dimension is curved, so that gravity arises organically.</p>
<p>Entropic gravity, introduced in <a href="https://arxiv.org/abs/gr-qc/9504004">a famous 1995 paper</a> by the theoretical physicist <a href="https://umdphysics.umd.edu/people/faculty/current/item/246-jacobson.html">Ted Jacobson</a> of the University of Maryland, takes a related but distinct tack. Previously, physicists had started with Einstein’s theory and derived its heatlike consequences. But Jacobson went the other way. He started from the assumption that space-time has thermal properties and used these to derive the equations of general relativity. His work confirmed that there’s something significant about the parallels between gravity and heat.</p>
<p>“He turned black hole thermodynamics on its head,” Carney said. “I’ve been mystified by this result for my entire adult life.”</p>
<h2><strong>Apparent Attraction</strong></h2>
<p>How might gravitational attraction arise out of more microscopic components? Inspired by Jacobson’s approach, Carney and his co-authors — <a href="https://profiles.lbl.gov/474580-manthos-karydas">Manthos Karydas</a>, Thilo Scharnhorst, Roshni Singh and <a href="https://www.umdphysics.umd.edu/people/faculty/adjunct-faculty/item/529-jmtaylor.html">Jacob Taylor</a> — put forward two models.</p>
<p>In the first, space is filled with a crystalline grid of quantum particles, or qubits. Each has an orientation, like a compass needle. These qubits will align themselves with a nearby object that possesses mass and exert a force on that object. “If you put a mass somewhere in the lattice, it causes all of the qubits nearby to get polarized — they all try to go in the same direction,” Carney said.</p>
<figure>
    <p><img width="1800" height="1800" src="https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic.webp" alt="Collage of portraits of four scientists." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic.webp 1800w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic-1720x1720.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic-520x520.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic-768x768.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic-1536x1536.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/06/Mosaic-160x160.webp 160w" sizes="(max-width: 1800px) 100vw, 1800px">    </p>
            <figcaption>
                            <p>Carney and coauthors Roshni Singh, Jacob Taylor, Thilo Scharnhorst and Manthos Karydas (clockwise from top left) recently developed concrete models showing how the rise of entropy could cause objects to appear to attract one another.</p>
            <p>Timothy Michael Pinkhassik; T.&nbsp; Ventsias/University of Maryland; Timothy Michael Pinkhassik; Sarah Wittmer/ UC Berkeley Physics</p>
        </figcaption>
    </figure>

<p>By reorienting the nearby qubits, a massive object creates a pocket of high order in the grid of otherwise randomly oriented qubits. If you place two masses into the lattice, you create two such pockets of order. High order means low entropy. But the system’s natural tendency is to maximize entropy. So, as the masses realign the qubits and the qubits in turn buffet the masses, the net effect will be to squash the masses closer together to contain the orderliness to a smaller region. It will appear that the two masses are attracting each other gravitationally when in fact the qubits are doing all the work. And just as Newton’s law dictates, the apparent attraction diminishes with the square of the distance between the masses.</p>
<p>The second model does away with the grid. Massive objects still reside within space and are acted upon by qubits, but now those qubits do not occupy any particular location and could in fact be far away. Carney said this feature is intended to capture the nonlocality of Newtonian gravity: Every object in the universe acts on every other object to some degree.</p>
<p>Each qubit in the model is able to store some energy; the amount depends on the distance between the masses. When they are far apart, a qubit’s energy capacity is high, so the total energy of the system can fit in just a few qubits. But if the masses are closer together, the energy capacity of each qubit drops, so the total energy has to be spread over more qubits. The latter situation corresponds to a higher entropy, so the natural tendency of the system is to push the masses together, again in keeping with Newtonian gravity.</p>
<h2><strong>Strengths and Weaknesses</strong></h2>
<p>Carney cautioned that both models are ad hoc. There’s no independent evidence for these qubits, and he and his colleagues had to fine-tune the strength and direction of the force exerted by them. One might ask whether this is any improvement over taking gravity to be fundamental. “It actually seems to require a peculiar engineered-looking interaction to get this to work,” Carney said.</p>
<p>And what works is just Newton’s law of gravity, not the full apparatus of Einstein’s theory, where gravity is equivalent to the curvature of space-time. For Carney, the models are just a proof of principle — a demonstration that it is at least possible for swarm behavior to explain gravitational attraction — rather than a realistic model for how the universe works. “The ontology of all of this is nebulous,” he said.</p>
<p><a href="https://phas.ubc.ca/~mav/vanraamsdonk.html">Mark Van Raamsdonk</a>, a physicist at the University of British Columbia, is doubtful that the models really represent a proof of principle. A practitioner of holography, the leading approach to emergent space-time, Van Raamsdonk notes that the new entropic models don’t have any of the qualities that make gravity special, such as the fact that you feel no gravitational force when you’re freely falling through space-time. “Their construction doesn’t really have anything to do with gravity,” he said.</p>

<p>Furthermore, the models dwell on the one aspect of gravity that physicists think they already understand. Newton’s law arises naturally out of Einstein’s theory when gravity is comparatively feeble, as it is on Earth. It’s where gravity gets strong, as in black holes, that it gets weird, and the entropic model has nothing to say about that. “The real challenge in gravitational physics is understanding its strong-coupling, strong-field regime,” said <a href="https://sites.physics.bgu.ac.il/ramyb/">Ramy Brustein</a>, a theorist at Ben-Gurion University who said he used to be sympathetic to entropic gravity but has cooled on the idea.</p>
<p>Proponents of entropic gravity respond that physicists shouldn’t be so sure about how gravity behaves when it is weak. If gravity is indeed a collective effect of qubits, the Newtonian force law represents a statistical average, and the moment-by-moment effect will bounce around that average. “You have to go to very weak fields, because then these fluctuations might become observable,” said <a href="https://www.uva.nl/en/profile/v/e/e.p.verlinde/e.p.verlinde.html?cb">Erik Verlinde</a> of the University of Amsterdam, who argued for entropic gravity in a <a href="https://arxiv.org/abs/1001.0785">much-discussed 2010 paper</a> and has continued to develop the idea.</p>
<h2><strong>Testing Entropic Gravity</strong></h2>
<p>Carney thinks the main benefit of the new models is that they prompt conceptual questions about gravity and open up new experimental directions.</p>
<p>Suppose a massive body is in a quantum combination, or “superposition,” of being in two different locations. Will its gravitational field likewise be in a superposition, pulling on falling bodies in two different directions? The new entropic-gravity models predict that the qubits will act on the massive body to snap it out of its Schrödinger’s cat–like predicament.</p>
        
        
<p>This scenario connects to the much-fretted-over question of wave function collapse — which asks how it is that measuring a quantum system in superposition causes its multiple possible states to become a single definite state. Some physicists have suggested that this collapse is caused by some intrinsic randomness in the universe. These proposals differ in detail from Carney’s but have similar testable consequences. They predict that an isolated quantum system will eventually collapse of its own accord, even if it’s never measured or otherwise affected from without. “The same experimental setups could, in principle, be used to test both,” said <a href="https://www.qmts.it/team/angelo-bassi/">Angelo Bassi</a> of the University of Trieste, who has led the effort to perform such experiments, already <a href="https://www.quantamagazine.org/physics-experiments-spell-doom-for-quantum-collapse-theory-20221020/">ruling out some collapse models</a>.</p>
<p>For all his doubts, Van Raamsdonk agrees that the entropic-gravity approach is worth a try. “Since it hasn’t been established that actual gravity in our universe arises holographically, it’s certainly valuable to explore other mechanisms by which gravity might arise,” he said. And if this long-shot theory does work out, physicists will need to update the artist Gerry Mooney’s famous gravity poster, which reads: “Gravity. It isn’t just a good idea. It’s the law.” Perhaps gravity is not, in fact, a law, just a statistical tendency.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jokes and Humour in the Public Android API (239 pts)]]></title>
            <link>https://voxelmanip.se/2025/06/14/jokes-and-humour-in-the-public-android-api/</link>
            <guid>44285781</guid>
            <pubDate>Mon, 16 Jun 2025 00:14:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://voxelmanip.se/2025/06/14/jokes-and-humour-in-the-public-android-api/">https://voxelmanip.se/2025/06/14/jokes-and-humour-in-the-public-android-api/</a>, See on <a href="https://news.ycombinator.com/item?id=44285781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p><img src="https://voxelmanip.se/media/jokes-and-humour-in-the-public-android-api/cover.webp" alt="Screenshot of a page on the Android developer reference website. The screenshot shows the documentation for a constant by the name of DISALLOW_FUN, which is gone over later in the blog post." width="1200" height="400"></p>








<p>Previously I have covered a relatively obscure now-removed placeholder string in Android that doubles as an easter egg, the fictitious carrier by the name of <a href="https://voxelmanip.se/2024/10/14/el-telco-loco/">El Telco Loco</a>. But this time it is about methods and other parts of the publicly facing Android API that may generally be more humourous than they are useful. Easter eggs, jokes, whatever you want to call them, that are visible to Android app developers rather than regular users.</p>

<!--more-->

<h2 id="activitymanagerisuseramonkey">ActivityManager.isUserAMonkey()</h2>
<p><a href="https://developer.android.com/reference/android/app/ActivityManager#isUserAMonkey()">(reference)</a></p>

<p>While it may initially look like a joke when it’s described as returning true if the UI is “currently being messed with by a monkey” without any further elaboration in the documentation, this is probably the one in the list with the most usefulness attached to it.</p>

<p>It is referring to the <a href="https://developer.android.com/studio/test/other-testing-tools/monkey">UI Exerciser Monkey</a>, which is a developer tool for Android that simulates random sequences of user input in order to stress-test apps. So this method will return a boolean of whether the Monkey is currently running or not.</p>

<p>The introduction of such a method to detect the usage of the Monkey appears to have an origin in something that happened during Android’s development, as per a quote from the book <em><a href="https://play.google.com/store/books/details/Chet_Haase_Androids">Androids: The Team that Built the Android Operating System</a></em>:</p>

<blockquote>
  <p>One day I walked into the monkey lab to hear a voice say, ‘911 -What’s your emergency?” That situation resulted in Dianne adding a new function to the API, <code>isUserAMonkey()</code> which is used to gate actions that monkeys shouldn’t take during tests (including dialing the phone and resetting the device).</p>
</blockquote>

<p>Indeed, when feeding random and inherently unpredictable input into an app, you would want to have some way of locking away portions of an app that may have unintended real-world consequences such as calling emergency services. As such, <code>isUserAMonkey</code> was implemented and later made its way into the public API in Android 2.2 Froyo (API 8).</p>

<h2 id="usermanagerisuseragoat">UserManager.isUserAGoat()</h2>
<p><a href="https://developer.android.com/reference/android/os/UserManager.html#isUserAGoat()">(reference)</a></p>

<p>This one is more of a joke. The developer documentation says it is “used to determine whether the user making this call is subject to teleportations”, which in itself is likely a reference to a hidden column in the Chrome task manager that shows how many goats a browser process has teleported.</p>

<p>It was first introduced in Android 4.2 (API 17), and originally just returned false. However in Android 5.0 Lollipop (API 21) it was changed to “automatically identify goats using advanced goat recognition technology”. The game Goat Simulator had released earlier that year and was made available for Android in September during Lollipop’s development, so this method was changed to instead detect the presence of the Android version of Goat Simulator being installed on the device:</p>

<div><pre><code><span>public</span> <span>boolean</span> <span>isUserAGoat</span><span>()</span> <span>{</span>
	<span>return</span> <span>mContext</span><span>.</span><span>getPackageManager</span><span>()</span>
		<span>.</span><span>isPackageAvailable</span><span>(</span><span>"com.coffeestainstudios.goatsimulator"</span><span>);</span>
<span>}</span>
</code></pre></div>

<p>Later in Android 11 (API 30), it was changed such that apps targetting API 30 and above will once again always return false when the method is called. According to the developer documentation this was made to “protect goat privacy”.</p>

<div><pre><code><span>if</span> <span>(</span><span>mContext</span><span>.</span><span>getApplicationInfo</span><span>().</span><span>targetSdkVersion</span> <span>&gt;=</span> <span>Build</span><span>.</span><span>VERSION_CODES</span><span>.</span><span>R</span><span>)</span> <span>{</span>
	<span>return</span> <span>false</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Android 11 is also the version where the <code>QUERY_ALL_PACKAGES</code> permission was introduced, meaning that apps targetting Android 11 would not be able to query for information of other apps through the <code>PackageManager</code> without this permission. So it makes sense to also wall off this method in order to not leak any information about other apps installed on an user’s device, even as a joke.</p>

<h2 id="usermanagerdisallow_fun">UserManager.DISALLOW_FUN</h2>
<p><a href="https://developer.android.com/reference/android/os/UserManager.html#DISALLOW_FUN">(reference)</a></p>

<p>This constant refers to a device policy added in Android 6 Marshmallow (API 23) which restricts the user from having “fun”. The description given in the developer documentation is, ironically, amusing and reminds me of something GLaDOS would probably say:</p>

<blockquote>
  <p>Specifies if the user is not allowed to have fun. In some cases, the device owner may wish to prevent the user from experiencing amusement or joy while using the device.</p>
</blockquote>

<p>This is in fact a real device policy that a device owner may change to restrict what users of the device is able to do with it. And third-parties can then hook into this to disable features of their app that are deemed “too fun”. I don’t know if any third-party apps actually make use of it, but in the Android system it is used to disable the Android version easter egg that shows up when pressing the version label in the settings.</p>

<p>Considering that “fun” easter eggs like the Google Chrome “No internet” Dinosaur minigame end up being distractions that e.g. schools want to disable for enrolled devices (<a href="https://issues.chromium.org/issues/41159706">see Chromium issue #41159706</a>), maybe the Android version easter egg could very much be a distraction depending on the version.</p>

<h2 id="chronometeristhefinalcountdown">Chronometer.isTheFinalCountdown()</h2>
<p><a href="https://developer.android.com/reference/android/widget/Chronometer#isTheFinalCountDown()">(reference)</a></p>

<p>The <code>Chronometer</code> class had a new method by the name of <code>isTheFinalCountdown</code> added to it in Android 8 Oreo (API 26). When called, it will send an Intent to open the YouTube video for <em>The Final Countdown</em> by Europe.</p>

<p>No really. That’s what it does:</p>

<div><pre><code><span>try</span> <span>{</span>
	<span>getContext</span><span>().</span><span>startActivity</span><span>(</span>
		<span>new</span> <span>Intent</span><span>(</span><span>Intent</span><span>.</span><span>ACTION_VIEW</span><span>,</span> <span>Uri</span><span>.</span><span>parse</span><span>(</span><span>"https://youtu.be/9jK-NcRmVcw"</span><span>))</span>
			<span>.</span><span>addCategory</span><span>(</span><span>Intent</span><span>.</span><span>CATEGORY_BROWSABLE</span><span>)</span>
			<span>.</span><span>addFlags</span><span>(</span><span>Intent</span><span>.</span><span>FLAG_ACTIVITY_NEW_DOCUMENT</span>
				<span>|</span> <span>Intent</span><span>.</span><span>FLAG_ACTIVITY_LAUNCH_ADJACENT</span><span>));</span>
	<span>return</span> <span>true</span><span>;</span>
<span>}</span> <span>catch</span> <span>(</span><span>Exception</span> <span>e</span><span>)</span> <span>{</span>
	<span>return</span> <span>false</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Marvelous.</p>

<h2 id="packagemanagerfeature_touchscreen_multitouch_jazzhand">PackageManager.FEATURE_TOUCHSCREEN_MULTITOUCH_JAZZHAND</h2>
<p><a href="https://developer.android.com/reference/android/content/pm/PackageManager.html#FEATURE_TOUCHSCREEN_MULTITOUCH_JAZZHAND">(reference)</a></p>

<p>This constant was added in Android 2.3 Gingerbread (API 8) and is used to describe a device that supports tracking 5 simultaneous touch inputs, with the name being a reference to <a href="https://en.wikipedia.org/wiki/Jazz_hands">Jazz hands</a>.</p>

<h2 id="logwtf">Log.wtf()</h2>
<p><a href="https://developer.android.com/reference/android/util/Log.html#wtf(java.lang.String,%20java.lang.String,%20java.lang.Throwable)">(reference)</a></p>

<p>According to the developer documentation, WTF stands for “What a Terrible Failure” (sure…), and is intended to log things that should <em>never</em> happen. It logs the message at the assertion level.</p>

<h2 id="adapterviewflipperfyiwillbeadvancedbyhostkthx">AdapterViewFlipper.fyiWillBeAdvancedByHostKThx()</h2>
<p><a href="https://developer.android.com/reference/android/widget/AdapterViewFlipper.html#fyiWillBeAdvancedByHostKThx()">(reference)</a></p>

<p>This is a method with an oddly humourous informal name, which was likely caused by some developer coming up blank on naming it and has now ended up in the public Android API, being added in Android 3.0 Honeycomb (API 11). It gets called by an <code>AppWidgetHost</code> when advancing the views inside of the <code>AdapterViewFlipper</code> object.</p>

<p>Indeed, naming things is one of the two hard problems in computer science, the other being off-by-one errors and cache invalidation.</p>

<h2 id="ibindertweet_transaction">IBinder.TWEET_TRANSACTION</h2>
<p><a href="https://developer.android.com/reference/android/os/IBinder.html#TWEET_TRANSACTION">(reference)</a></p>

<p>The Android Binder system is used for performing IPC and transactions are distinguished using different types, one of them being… <code>TWEET_TRANSACTION</code>. It was added in Android 3.2 Honeycomb (API 13) and claims to be used to send a tweet to a target object.</p>

<p>It does not actually do anything, let alone send a tweet. The document mentions that messages have a limit of 130 characters, referencing Twitter’s old message character limit.</p>

<h2 id="ibinderlike_transaction">IBinder.LIKE_TRANSACTION</h2>
<p><a href="https://developer.android.com/reference/android/os/IBinder.html#LIKE_TRANSACTION">(reference)</a></p>

<p>In a similar fashion, a new transaction type by the name of <code>LIKE_TRANSACTION</code> was added in Android 4.0.3 ICS (API 15). It’s used to tell an app that the caller likes it, there is no counter to keep track of the amount of likes but it is claimed that sending such transactions will improve the app’s self-esteem.</p>

<h2 id="sensormanagersensor_tricorder">SensorManager.SENSOR_TRICORDER</h2>
<p><a href="https://developer.android.com/reference/android/hardware/SensorManager.html#SENSOR_TRICORDER">(reference)</a></p>

<p>I do have to admit I didn’t know what a Tricorder is, but it appears to be a fictional device from Star Trek and the constant was “added” in Android 1.0 (meaning it likely was present since before Android’s first official release).</p>

<p>The SENSOR_* constants in <code>SensorManager</code> have since then been deprecated in API level 15 in favour of the <code>Sensor</code> class, which does not include any equivalent reference to the Tricorder. Unfortunate.</p>

<h2 id="sensormanagergravity_">SensorManager.GRAVITY_*</h2>
<p><a href="https://developer.android.com/reference/android/hardware/SensorManager.html#GRAVITY_DEATH_STAR_I">(reference)</a></p>

<p>The <code>SensorManager</code> class has a lot of constants which store the gravitational velocity of various bodies in our solar system ranging from <code>GRAVITY_SUN</code> to <code>GRAVITY_PLUTO</code>. While whether any of these outside of <code>GRAVITY_EARTH</code> is useful in any real-world scenarios is debatable, there are some that are actually just jokes.</p>

<p><code>GRAVITY_DEATH_STAR_I</code> stores the gravity of the first Death Star in SI units (referred to as Empire units). This appears to be a Star Wars reference.</p>

<p><code>GRAVITY_THE_ISLAND</code> stores the gravity of “the island”. Apparently this is a reference to The Island in the 2004 TV show <a href="https://en.wikipedia.org/wiki/Lost_(TV_series)">Lost</a>.</p>

<h2 id="blink">&lt;blink&gt;</h2>
<p>Last one, and this one is particularly crazy. Did you know there is a hidden tag inside the Android view layout system by the name of <code>&lt;blink&gt;</code>? Because that is a thing:</p>

<div><pre><code><span>// [TAG_1995 = "blink"]</span>
<span>if</span> <span>(</span><span>name</span><span>.</span><span>equals</span><span>(</span><span>TAG_1995</span><span>))</span> <span>{</span>
	<span>// Let's party like it's 1995!</span>
	<span>return</span> <span>new</span> <span>BlinkLayout</span><span>(</span><span>context</span><span>,</span> <span>attrs</span><span>);</span>
<span>}</span>
</code></pre></div>

<p>It makes any children that is wrapped inside of it blink, like the old <code>&lt;blink&gt;</code> HTML tag. This one appears to be completely undocumented in the Android Developer reference, but was added <a href="https://android.googlesource.com/platform/frameworks/base/+/9c1223a71397b565f38015c07cae57a5015a6500%5E%21">in a commit in 2011</a> with the title “Improve LayoutInflater’s compliance” (right…) and is still present in the AOSP master branch.</p>

<p>Whether you should actually use it is debatable however.</p>


<hr>

<h2>Donations</h2>

<p>
	Did you find the blog post to be informative, amusing or otherwise interesting?
	All blog posts are written by a human who would appreciate a <a href="https://voxelmanip.se/donate/#donations">donation</a>
	if you got some value out of this piece of writing.
</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DARPA program sets distance record for power beaming (133 pts)]]></title>
            <link>https://www.darpa.mil/news/2025/darpa-program-distance-record-power-beaming</link>
            <guid>44285440</guid>
            <pubDate>Sun, 15 Jun 2025 22:40:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.darpa.mil/news/2025/darpa-program-distance-record-power-beaming">https://www.darpa.mil/news/2025/darpa-program-distance-record-power-beaming</a>, See on <a href="https://news.ycombinator.com/item?id=44285440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In a series of recent tests in New Mexico, the <a href="https://www.darpa.mil/research/programs/power">Persistent Optical Wireless Energy Relay (POWER) program</a> achieved several new records for transmitting power over distance. The team recorded more than 800 watts of power delivered during a 30-second transmission from a laser 8.6 kilometers (5.3 miles) away. Over the course of the test campaign, more than a megajoule of energy was transferred.</p><p>Previously, the greatest reported distance records for an appreciable amount of optical power (&gt;1 microwatt) were 230 watts of average power at 1.7 kilometers for 25 seconds and a lesser (but undisclosed) amount of power at 3.7 kilometers.</p><figure role="group">
<article>
  
      
            <p><img loading="lazy" src="https://www.darpa.mil/sites/default/files/gallery/2025-05/power-program-prad-comparison-graphic.png" width="1500" height="844" alt="Graphic showing the POWER Receiver Array Demo (PRAD) record for power and distance for optical power beaming compared to previous notable efforts">

</p>
      
  </article>

<figcaption>The POWER Receiver Array Demo (PRAD) set the records for power and distance for optical power beaming; the graphic shows how it compares to previous notable efforts.</figcaption>
</figure>
<p>“It is beyond a doubt that we absolutely obliterated all previously reported optical power beaming demonstrations for power and distance,” said <a href="https://www.darpa.mil/about/people/paul-jaffe">POWER Program Manager Paul Jaffe</a> after the results were confirmed. The DARPA-led team brought together industry and government, including the U.S. Naval Research Laboratory and the High Energy Laser Systems Test Facility (HELSTF) at the U.S. Army’s White Sands Missile Range.</p><figure role="group">
<article>
  
      
            <p><img loading="lazy" src="https://www.darpa.mil/sites/default/files/gallery/2025-05/power-program-helstf-prad-record-day.png" width="2500" height="1407" alt="High Energy Laser Systems Test Facility test range located at the U.S. Army’s White Sands Missile Range">

</p>
      
  </article>

<figcaption>The High Energy Laser Systems Test Facility test range located at the U.S. Army’s White Sands Missile Range on the day the PRAD team set the optical power beaming distance record.</figcaption>
</figure>
<p>Energy is a fundamental requirement for military operations, and traditional means of getting energy to the edge (battlefields, disaster zones, etc.) are often incredibly slow, risky, and resource intensive. These tests, referred to as PRAD (POWER Receiver Array Demo), mark an important step towards the POWER program’s long-term goal of being able to instantly beam power from a location where it can be easily generated to wherever it’s needed, opening a novel design space for platform capabilities unbounded by fuel limitations.&nbsp;</p><p>To achieve the power and distance record, PRAD used a new receiver technology with a compact aperture for the laser beam to shine into, ensuring very little light escapes once it has entered the receiver. Inside the receiver, the laser strikes a parabolic mirror that reflects the beam onto dozens of photovoltaic cells (a.k.a. “solar cells”) to convert the energy back to usable power.&nbsp;</p><p>The receiver was designed by Teravec Technologies, led by principal investigator Raymond Hoheisel, with support from Packet Digital and the Rochester Institute of Technology. The technology is scalable to higher power levels and can be integrated into different platforms, such as unmanned aerial vehicles (UAVs), to support the long-term needs of the POWER program.</p><p>For the tests, both the transmitter and receiver were on the ground, which required the beam to go through the thickest part of the atmosphere, making the test results even more impressive.</p><p>“It’s a lot easier to send a power beam directly up or down relative to the ground because there is so much less atmosphere to fight through,” Jaffe explains. “For PRAD, we wanted to test under the maximum impact of atmospheric effects.”</p><p>While efficiency wasn’t the focus of this demonstration, the team measured more than 20% efficiency from the optical power out of the laser to the electrical power out of the receiver at shorter distances. The goal of the effort was to rapidly validate the capability of a new design to massively extend potential distance, so trade-offs were made to accelerate the design and build of the test receiver. The receiver was completed in about three months.</p><p>“This demonstration broke through misconceptions about the limits of power beaming technology, and it is already spurring industry to reimagine what’s possible,” said Jaffe.&nbsp;</p><p>With the PRAD testing successful, the POWER program has significantly reduced risk for a key element of making long-distance power beaming a future reality. The program is now moving forward to demonstrate the benefits of integrated relays and vertical power transmission and is seeking the creativity and innovation of potential partners to accomplish this as part of POWER Phase 2.&nbsp;</p><p>A <a href="https://creative.spa.com/darpa/tto/power/id/2025/may/" target="_blank">POWER Phase 2 Industry Day</a> will be held on May 29, 2025.The Industry Day will promote teaming arrangements between researchers; provide potential performers with information on whether and how they might respond to government R&amp;D solicitations; and increase efficiency in proposal preparation and evaluation. The Industry Day registration deadline is May 21.</p><figure role="group">
<article>
  
      
            <p><img loading="lazy" src="https://www.darpa.mil/sites/default/files/gallery/2025-05/power-program-prad-popcorn.png" width="1500" height="1730" alt="Popcorn made using some of the transferred energy from the PRAD program">

</p>
      
  </article>

<figcaption>The POWER team celebrated its power beaming record by using some of the transferred energy to make popcorn, in an homage to the classic scene from the movie “Real Genius.”</figcaption>
</figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Real-time CO2 monitoring without batteries or external power (104 pts)]]></title>
            <link>https://news.kaist.ac.kr/newsen/html/news/?mode=V&amp;mng_no=47450</link>
            <guid>44285392</guid>
            <pubDate>Sun, 15 Jun 2025 22:29:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.kaist.ac.kr/newsen/html/news/?mode=V&#x26;mng_no=47450">https://news.kaist.ac.kr/newsen/html/news/?mode=V&#x26;mng_no=47450</a>, See on <a href="https://news.ycombinator.com/item?id=44285392">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p><img src="https://news.kaist.ac.kr/_prog/download/?editor_image=/images/000099/Photo_1_1.jpg" title="" alt=""></p>
<p><span>&lt; (From left) Master's Student Gyurim Jang, Professor Kyeongha Kwon &gt;</span></p>

<p><span>KAIST (President Kwang Hyung Lee) announced on June 9th that a research team led by Professor Kyeongha Kwon from the School of Electrical Engineering, in a joint study with Professor Hanjun Ryu's team at Chung-Ang University, has developed a self-powered wireless carbon dioxide (<span>CO</span><span>2</span>) monitoring system. This innovative system harvests fine&nbsp;vibrational energy from its surroundings to periodically measure&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;concentrations.</span></p>

<p><span>This breakthrough addresses a critical need in environmental monitoring: accurately understanding "how much"&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;is being emitted to combat climate change and global warming. While&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;monitoring technology is key to this, existing systems largely rely on batteries or wired power system, imposing limitations on installation and maintenance. The KAIST team tackled this by creating a self-powered wireless system that operates without external power.</span></p>

<p><span>The core of this new system is an "Inertia-driven Triboelectric Nanogenerator (TENG)" that converts vibrations (with amplitudes ranging from 20-4000 ㎛ and frequencies from 0-300 Hz) generated by industrial equipment or pipelines into electricity. This enables periodic&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;concentration measurements and wireless transmission without the need for batteries.</span></p>

<p><img src="https://news.kaist.ac.kr/_prog/download/?editor_image=/images/000099/Image_01_900_1.png" title="" alt=""></p>
<p><span>&lt; <span>Figure 1. Concept and configuration of self-powered wireless&nbsp;</span></span><span>CO</span><span>2</span><span><span>&nbsp;monitoring system using fine vibration harvesting (a) System block diagram (b) Photo of fabricated system prototype</span> &gt;</span></p>

<p><span>The research team successfully amplified fine vibrations and induced resonance by combining spring-attached 4-stack TENGs.&nbsp;They achieved stable power production of 0.5 mW under conditions of 13 Hz and 0.56 g acceleration. The generated power was then used to operate a&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;sensor and a&nbsp;Bluetooth Low Energy (BLE)&nbsp;system-on-a-chip (SoC).</span></p>

<p><span>Professor Kyeongha Kwon emphasized, "For efficient environmental monitoring, a system that can operate continuously without power limitations is essential." She explained, "In this research, we implemented a self-powered system that can periodically measure and wirelessly transmit&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;concentrations based on the energy generated from an inertia-driven TENG." She added, "This technology can serve as a foundational technology for future self-powered environmental monitoring platforms integrating various sensors."</span></p>

<p><img src="https://news.kaist.ac.kr/_prog/download/?editor_image=/images/000099/Image_02_900_1.png" title="" alt=""></p>
<p><span>&lt; Figure 2. TENG energy harvesting-based wireless&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;sensing system operation results (c) Experimental setup (d) Measured </span><span>CO</span><span>2</span><span>&nbsp;concentration results powered by TENG and conventional DC power source&nbsp;&gt;</span></p>

<p><span>This research was published on June 1st in the internationally renowned academic journal `<span>Nano Energy</span> (IF 16.8)`. Gyurim Jang, a master's student at KAIST, and Daniel Manaye Tiruneh, a master's student at Chung-Ang University, are the co-first authors of the paper.<br></span><span>*Paper Title: Highly compact inertia-driven triboelectric nanogenerator for self-powered wireless&nbsp;</span><span>CO</span><span>2</span><span>&nbsp;monitoring via fine-vibration harvesting<br></span><span>*DOI: 10.1016/j.nanoen.2025.110872</span></p>

<p><span>This research was supported by the Saudi Aramco-KAIST&nbsp;</span><span>CO</span><span>2&nbsp;</span><span>Management Center.</span></p>

							 

						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[David Attenborough at 99: 'I will not see how the story ends' (247 pts)]]></title>
            <link>https://www.thetimes.com/life-style/celebrity/article/david-attenborough-book-extract-age-99-lj3rd2fg7</link>
            <guid>44285054</guid>
            <pubDate>Sun, 15 Jun 2025 21:21:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thetimes.com/life-style/celebrity/article/david-attenborough-book-extract-age-99-lj3rd2fg7">https://www.thetimes.com/life-style/celebrity/article/david-attenborough-book-extract-age-99-lj3rd2fg7</a>, See on <a href="https://news.ycombinator.com/item?id=44285054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>We haven't been able to take payment</p><p>You must update your payment details via My Account or by clicking update payment details to keep your subscription.</p></div><div><p>Act now to keep your subscription</p><p>We've tried to contact you several times as we haven't been able to take payment. You must update your payment details via My Account or by clicking update payment details to keep your subscription.</p></div><div><p>Your subscription is due to terminate</p><p>We've tried to contact you several times as we haven't been able to take payment. You must update your payment details via My Account, otherwise your subscription will terminate.</p> </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Zeekstd – Rust Implementation of the ZSTD Seekable Format (136 pts)]]></title>
            <link>https://github.com/rorosen/zeekstd</link>
            <guid>44284871</guid>
            <pubDate>Sun, 15 Jun 2025 20:49:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rorosen/zeekstd">https://github.com/rorosen/zeekstd</a>, See on <a href="https://news.ycombinator.com/item?id=44284871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Zeekstd</h2><a id="user-content-zeekstd" aria-label="Permalink: Zeekstd" href="#zeekstd"></a></p>
<p dir="auto"><a href="https://github.com/rorosen/zeekstd/actions/workflows/nix.yaml"><img src="https://github.com/rorosen/zeekstd/actions/workflows/nix.yaml/badge.svg" alt="Nix"></a>
<a href="https://github.com/rorosen/zeekstd/actions/workflows/rust.yaml"><img src="https://github.com/rorosen/zeekstd/actions/workflows/rust.yaml/badge.svg" alt="Rust"></a>
<a href="https://crates.io/crates/zeekstd" rel="nofollow"><img src="https://camo.githubusercontent.com/75043795470df7afca005536a269a9cb3211873754eca95ee957f2e9cd744cf9/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f7a65656b7374642e737667" alt="Crates.io" data-canonical-src="https://img.shields.io/crates/v/zeekstd.svg"></a>
<a href="https://docs.rs/zeekstd" rel="nofollow"><img src="https://camo.githubusercontent.com/641cbaa75bddc07afc31e93ed7d798e3b6efcbbaf0ce1f6aa6baff7289be9a0b/68747470733a2f2f646f63732e72732f7a65656b7374642f62616467652e737667" alt="Documentation" data-canonical-src="https://docs.rs/zeekstd/badge.svg"></a></p>
<p dir="auto">A Rust implementation of the Zstandard Seekable Format.</p>
<p dir="auto">The seekable format splits compressed data into a series of independent "frames", each compressed
individually, so that decompression of a section in the middle of an archive only requires zstd to
decompress at most a frame's worth of extra data, instead of the entire archive.</p>
<p dir="auto">Zeekstd makes additions to the seekable format by implementing an updated version of the
<a href="https://github.com/rorosen/zeekstd/blob/main/seekable_format.md">specification</a>, however, it is fully compatible with the
<a href="https://github.com/facebook/zstd/blob/dev/contrib/seekable_format/zstd_seekable_compression_format.md">initial version of the seekable format</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compression</h2><a id="user-content-compression" aria-label="Permalink: Compression" href="#compression"></a></p>
<p dir="auto">A seekable <code>Encoder</code> will start new frames automatically at 2MiB of uncompressed data. See
<code>EncodeOptions</code> to change this and other compression parameters.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use std::{fs::File, io};
use zeekstd::Encoder;

fn main() -> zeekstd::Result<()> {
    let mut input = File::open(&quot;data&quot;)?;
    let output = File::create(&quot;seekable.zst&quot;)?;
    let mut encoder = Encoder::new(output)?;
    io::copy(&amp;mut input, &amp;mut encoder)?;
    // End compression and write the seek table to the end of the seekable
    encoder.finish()?;

    Ok(())
}"><pre><span>use</span> std<span>::</span><span>{</span>fs<span>::</span><span>File</span><span>,</span> io<span>}</span><span>;</span>
<span>use</span> zeekstd<span>::</span><span>Encoder</span><span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; zeekstd<span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
    <span>let</span> <span>mut</span> input = <span>File</span><span>::</span><span>open</span><span>(</span><span>"data"</span><span>)</span>?<span>;</span>
    <span>let</span> output = <span>File</span><span>::</span><span>create</span><span>(</span><span>"seekable.zst"</span><span>)</span>?<span>;</span>
    <span>let</span> <span>mut</span> encoder = <span>Encoder</span><span>::</span><span>new</span><span>(</span>output<span>)</span>?<span>;</span>
    io<span>::</span><span>copy</span><span>(</span><span>&amp;</span><span>mut</span> input<span>,</span> <span>&amp;</span><span>mut</span> encoder<span>)</span>?<span>;</span>
    <span>// End compression and write the seek table to the end of the seekable</span>
    encoder<span>.</span><span>finish</span><span>(</span><span>)</span>?<span>;</span>

    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Decompression</h2><a id="user-content-decompression" aria-label="Permalink: Decompression" href="#decompression"></a></p>
<p dir="auto">By default, the seekable <code>Decoder</code> decompresses everything, from the first to the last frame, but
can also be configured to decompress only specific frames.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use std::{fs::File, io};
use zeekstd::Decoder;

fn main() -> zeekstd::Result<()> {
    let input = File::open(&quot;seekable.zst&quot;)?;
    let mut output = File::create(&quot;decompressed&quot;)?;
    let mut decoder = Decoder::new(input)?;
    // Decompress everything
    io::copy(&amp;mut decoder, &amp;mut output)?;

    let mut partial = File::create(&quot;partial&quot;)?;
    // Decompress only specific frames
    decoder.set_lower_frame(2);
    decoder.set_upper_frame(5);
    io::copy(&amp;mut decoder, &amp;mut partial)?;

    Ok(())
}"><pre><span>use</span> std<span>::</span><span>{</span>fs<span>::</span><span>File</span><span>,</span> io<span>}</span><span>;</span>
<span>use</span> zeekstd<span>::</span><span>Decoder</span><span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; zeekstd<span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
    <span>let</span> input = <span>File</span><span>::</span><span>open</span><span>(</span><span>"seekable.zst"</span><span>)</span>?<span>;</span>
    <span>let</span> <span>mut</span> output = <span>File</span><span>::</span><span>create</span><span>(</span><span>"decompressed"</span><span>)</span>?<span>;</span>
    <span>let</span> <span>mut</span> decoder = <span>Decoder</span><span>::</span><span>new</span><span>(</span>input<span>)</span>?<span>;</span>
    <span>// Decompress everything</span>
    io<span>::</span><span>copy</span><span>(</span><span>&amp;</span><span>mut</span> decoder<span>,</span> <span>&amp;</span><span>mut</span> output<span>)</span>?<span>;</span>

    <span>let</span> <span>mut</span> partial = <span>File</span><span>::</span><span>create</span><span>(</span><span>"partial"</span><span>)</span>?<span>;</span>
    <span>// Decompress only specific frames</span>
    decoder<span>.</span><span>set_lower_frame</span><span>(</span><span>2</span><span>)</span><span>;</span>
    decoder<span>.</span><span>set_upper_frame</span><span>(</span><span>5</span><span>)</span><span>;</span>
    io<span>::</span><span>copy</span><span>(</span><span>&amp;</span><span>mut</span> decoder<span>,</span> <span>&amp;</span><span>mut</span> partial<span>)</span>?<span>;</span>

    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI</h2><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<p dir="auto">This repo also contains a <a href="https://github.com/rorosen/zeekstd/blob/main/cli">CLI tool</a> that uses the library.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<ul dir="auto">
<li>The zstd C library is under a dual BSD/GPLv2 license.</li>
<li>Zeekstd is under a BSD 2-Clause License.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It’s nearly impossible to buy an original Bob Ross painting (2021) (136 pts)]]></title>
            <link>https://thehustle.co/why-its-nearly-impossible-to-buy-an-original-bob-ross-painting</link>
            <guid>44284723</guid>
            <pubDate>Sun, 15 Jun 2025 20:21:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehustle.co/why-its-nearly-impossible-to-buy-an-original-bob-ross-painting">https://thehustle.co/why-its-nearly-impossible-to-buy-an-original-bob-ross-painting</a>, See on <a href="https://news.ycombinator.com/item?id=44284723">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
            
            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Bob Ross is not a hard man to find.</p><p><img src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=524&amp;height=393&amp;name=1315791387-HEADER3.webp" alt="Why it’s nearly impossible to buy an original Bob Ross painting" width="524" height="393" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=262&amp;height=197&amp;name=1315791387-HEADER3.webp 262w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=524&amp;height=393&amp;name=1315791387-HEADER3.webp 524w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=786&amp;height=590&amp;name=1315791387-HEADER3.webp 786w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=1048&amp;height=786&amp;name=1315791387-HEADER3.webp 1048w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=1310&amp;height=983&amp;name=1315791387-HEADER3.webp 1310w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/GIFs/1315791387-HEADER3.webp?width=1572&amp;height=1179&amp;name=1315791387-HEADER3.webp 1572w" sizes="(max-width: 524px) 100vw, 524px"></p>
<!--more-->
<p>Though he died in 1995, the late TV painter remains an omnipresent cultural staple. His Chia Pet perm, nap-inducing voice, and meme-worthy sayings — “<em>Happy little trees!</em>” — have transcended time. On <a href="https://www.youtube.com/channel/UCxcnsr1R5Ge_fbTu5ajt8DQ" target="_blank" rel="noopener noreferrer">YouTube</a>, old episodes of his show, <em>The Joy of Painting</em>, boast ~<strong>450m views</strong>.</p>
<p>Online, you can acquire Bob Ross paints, Bob Ross brushes, Bob Ross underwear, Bob Ross coffee mugs, Bob Ross energy drinks, Bob Ross watches, and Bob Ross toasters.</p>
<p>But there’s one thing you won’t often see for sale: his artwork.</p>
<p>During his lifetime, Ross produced <strong>tens of thousands of paintings</strong>. Yet, only a handful of his works have popped up for sale in recent years. When they do appear, they often fetch <strong>$10k+ </strong>and attract dozens of bids.</p>
<p>Why is the work of one of history’s most prolific and accessible artists so scarce on the open market?</p>
<p>To find out, I spoke with art gallery owners, auctioneers, art collectors, ex-colleagues who worked with Ross, and the president of Bob Ross, Inc. — the company that preserves his legacy.</p>
<h4 id="h-the-man-behind-the-canvas"><strong>The man behind the canvas</strong></h4>
<p>Born in Daytona, Florida, in 1942, Ross dropped out of school in 9th grade to work with his father, a carpenter.</p>
<p>At 18, he joined the Air Force and moved to Alaska, where he’d spend the next 20 years as a drill sergeant, screaming at recruits. He was such a hard-ass that he earned the <a href="https://www.mentalfloss.com/article/19995/bust-em-bobby-bob-ross" target="_blank" rel="noopener noreferrer">nickname</a> “Bust ’em up Bobby.”</p>
<p>But his life changed when he discovered art.</p>
<p>Inspired by the TV painter <a href="https://en.wikipedia.org/wiki/Bill_Alexander_(painter)" target="_blank" rel="noopener noreferrer">Bill Alexander</a>, he started painting landscapes on gold mining pans and selling them at local markets in Alaska.</p>
<p>His income from painting soon surpassed what he made in the military. So, in 1981, he migrated back to Florida, trained under Alexander, and became a certified painting instructor.</p>
<figure><img loading="lazy" decoding="async" src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=600&amp;height=450&amp;name=1253406887-bob.webp" alt="Bob Ross in 1981, striking a happy pose" sizes="(max-width: 600px) 100vw, 600px" width="600" height="450" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=300&amp;height=225&amp;name=1253406887-bob.webp 300w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=600&amp;height=450&amp;name=1253406887-bob.webp 600w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=900&amp;height=675&amp;name=1253406887-bob.webp 900w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=1200&amp;height=900&amp;name=1253406887-bob.webp 1200w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=1500&amp;height=1125&amp;name=1253406887-bob.webp 1500w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/1253406887-bob.webp?width=1800&amp;height=1350&amp;name=1253406887-bob.webp 1800w"></figure>
<p><em>Bob Ross strikes a happy pose (Photo: Acey Harper/The LIFE Images Collection via Getty Images)</em></p>
<p>Now, here’s where things took a wild turn for Ross:</p>
<ul>
<li>One of his students, <strong>Annette Kowalski</strong>, was “mesmerized” by the jolly painter and encouraged him to strike out on his own.</li>
<li>They pooled together their life savings, launched <strong>Bob Ross, Inc.</strong>, and set out to make Ross into a TV star.</li>
<li>A PBS executive gave them a shot.</li>
<li>The show — <em>The Joy of Painting</em>, which aired between 1983 and 1994<em> </em>— was a huge hit and was broadcast on <strong>~300 stations</strong> to <strong>80m+</strong> people every day.</li>
</ul>
<p>In each 27-minute episode, Ross would paint one landscape from start to finish, shepherding viewers through his process with a soothing disposition, entertaining commentary, and an occasional guest appearance by his <a href="https://www.washingtonpost.com/local/nothing-brought-more-joy-to-the-joy-of-paintings-bob-ross-than-squirrels/2020/04/15/e72c4ee0-7f2e-11ea-9040-68981f488eed_story.html" target="_blank" rel="noopener noreferrer">pet squirrel</a>, Peapod.</p>
<p>Ross didn’t get paid for his shows. But Bob Ross, Inc. — which he partially owned — used the platform to sell paints, art supplies, workshops, instructional videos, and merchandise. By 1991, it was a <strong>$15m/year ($29m today) </strong>enterprise.</p>
<p>The actual paintings, though, were largely an afterthought.</p>
<p>Over the course of his career, Ross filmed <a href="https://fivethirtyeight.com/features/a-statistical-analysis-of-the-work-of-bob-ross/" target="_blank" rel="noopener noreferrer">381 episodes</a> of <em>The Joy of Painting</em>. For each episode, he painted <strong>3 versions</strong> of the same artwork — one before, one during, and one after taping.</p>
<p>But his TV career only scratched the surface of his total output.</p>
<p>Pre-fame, in Alaska, he sold thousands of paintings. And even while famous, he painted nearly every day at seminars, events, and charity auctions in between tapings.</p>
<p>All told, Bob Ross <a href="https://timesmachine.nytimes.com/timesmachine/1991/12/22/issue.html?action=click&amp;contentCollection=Archives&amp;module=LedeAsset&amp;region=ArchiveBody&amp;pgtype=article" target="_blank" rel="noopener noreferrer">churned out</a> ~<strong>30k paintings</strong> in his lifetime — nearly 3x the output of Picasso, a prolific painter in his own right.</p>
<figure><img loading="lazy" decoding="async" src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=600&amp;height=465&amp;name=813295341-chartross.webp" alt="number-of-paintings-created-by-known-artists" sizes="(max-width: 600px) 100vw, 600px" width="600" height="465" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=300&amp;height=233&amp;name=813295341-chartross.webp 300w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=600&amp;height=465&amp;name=813295341-chartross.webp 600w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=900&amp;height=698&amp;name=813295341-chartross.webp 900w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=1200&amp;height=930&amp;name=813295341-chartross.webp 1200w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=1500&amp;height=1163&amp;name=813295341-chartross.webp 1500w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/813295341-chartross.webp?width=1800&amp;height=1395&amp;name=813295341-chartross.webp 1800w"></figure>
<p><em>Zachary Crockett / The Hustle (painting © Bob Ross Inc.)</em></p>
<p>For years, collectors and fans have clamored to own their own piece of Bob Ross lore. Multiple art dealers told <em>The Hustle </em>that demand for his work is extraordinarily robust.</p>
<p>But Ross paintings are a bit like diamonds: vast in volume, scarce on the open market.</p>
<p>Major auction houses — Christie’s, Sotheby’s, Phillips — have no Bob Ross sales history. Craigslist draws a goose egg. A scan of eBay only turns up <a href="https://www.ebay.com/sch/i.html?_from=R40&amp;_trksid=p2334524.m570.l1313&amp;_nkw=bob+ross+painting&amp;_sacat=0&amp;LH_TitleDesc=0&amp;_fsrp=1&amp;_sop=16&amp;_odkw=bob+ross+original+painting&amp;_osacat=0&amp;LH_Sold=1" target="_blank" rel="noopener noreferrer">3 sales</a> in the last 6 months, 2 of which are of dubious origin.</p>
<p>Where the heck are those 30k paintings?</p>
<h4 id="h-bob-ross-incorporated"><strong>Bob Ross, Incorporated</strong></h4>
<p>As a part of Ross’s agreement with Bob Ross, Inc., the paintings he created for TV were <a href="https://en.wikipedia.org/wiki/Work_for_hire" target="_blank" rel="noopener noreferrer">work for hire</a>, meaning the company maintained ownership of his work.</p>
<p>When Ross died in 1995, Bob Ross, Inc. (and thus, the paintings) became the sole property of Annette Kowalski and her husband, Walt.</p>
<p>Today, <strong>1,165 </strong>Bob Ross originals — a trove worth millions of dollars — <a href="https://www.nytimes.com/video/arts/100000005865824/bob-ross-paintings-mystery.html" target="_blank" rel="noopener noreferrer">sit in cardboard boxes</a> inside the company’s nondescript office building in Herndon, Virginia.</p>
<p><strong>Joan Kowalski</strong>, Annette’s daughter, and the current president of Bob Ross, Inc., tells <em>The Hustle</em> that the company had never really given the paintings much thought.</p>
<p>“The paintings have always just sort of been here,” she says, with a chuckle. “We were sort of behind the times… it never occurred to us that anyone would want them.”</p>
<p>The company, which can be reached by dialing 1-800-BOB-ROSS, gets constant inquiries from folks about buying the paintings.</p>
<p>But they’re not for sale.</p>
<p>“Our only mission,” Kowalski says, “is to preserve the mythological wonderment that was Bob Ross.”</p>
<figure><img loading="lazy" decoding="async" src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=600&amp;height=825&amp;name=381327152-office.webp" alt="joan-kowalski-sarah-strohl-of-bob-ross-inc" sizes="(max-width: 600px) 100vw, 600px" width="600" height="825" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=300&amp;height=413&amp;name=381327152-office.webp 300w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=600&amp;height=825&amp;name=381327152-office.webp 600w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=900&amp;height=1238&amp;name=381327152-office.webp 900w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=1200&amp;height=1650&amp;name=381327152-office.webp 1200w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=1500&amp;height=2063&amp;name=381327152-office.webp 1500w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/381327152-office.webp?width=1800&amp;height=2475&amp;name=381327152-office.webp 1800w"></figure>
<p><em>TOP: Joan Kowalski (top left; president of Bob Ross, Inc.) and Sarah Strohl (executive assistant) laugh at a social media post of a fan wearing Bob Ross socks; BOTTOM: Strohl sifts through some of the company’s many original Bob Ross paintings (Bill O’Leary/Getty Images)</em></p>
<p>Part of the reason Bob Ross, Inc. isn’t interested in selling the paintings is that it has far more lucrative assets on hand — like Bob Ross’s IP.</p>
<p>The company holds <a href="https://cocatalog.loc.gov/cgi-bin/Pwebrecon.cgi?Search_Arg=bob+ross%2C+inc.&amp;Search_Code=NALL&amp;PID=JM_BQChiUnKP0RLjvDwzN-1Z8DQhp9v&amp;SEQ=20210430171747&amp;CNT=25&amp;HIST=1" target="_blank" rel="noopener noreferrer">154 copyrights</a>, and numerous <a href="https://tmsearch.uspto.gov/bin/showfield?f=toc&amp;state=4805%3Ad0j3o4.1.1&amp;p_search=searchss&amp;p_L=50&amp;BackReference=&amp;p_plural=yes&amp;p_s_PARA1=&amp;p_tagrepl%7E%3A=PARA1%24LD&amp;expr=PARA1+AND+PARA2&amp;p_s_PARA2=bob+ross&amp;p_tagrepl%7E%3A=PARA2%24OW&amp;p_op_ALL=AND&amp;a_default=search&amp;a_search=Submit+Query&amp;a_search=Submit+Query" target="_blank" rel="noopener noreferrer">trademarks</a> on Ross’s name and likeness, which they use to sell millions of dollars’ worth of Bob Ross-themed merchandise and instructional courses.</p>
<p>On occasion, Bob Ross, Inc. leases out a few paintings to galleries and exhibits around the country:</p>
<ul>
<li><strong>54 paintings</strong> can be seen at <a href="https://www.bobrossartworkshop.com/" target="_blank" rel="noopener noreferrer">The Bob Ross Art Workshop &amp; Gallery</a> in New Smyrna, Florida.</li>
<li><strong>27 paintings</strong> are at Minnetrista’s <a href="https://www.minnetrista.net/bobrossexperience" target="_blank" rel="noopener noreferrer">Bob Ross Experience</a> in Muncie, Indiana.</li>
<li><strong>4 paintings</strong> are in the possession of the Smithsonian National Museum of American History in Washington, DC.</li>
</ul>
<p>But this only answers a part of the mystery. What about all the other paintings Ross gave away or sold during his life?</p>
<h4 id="h-the-open-market"><strong>The open market</strong></h4>
<p>Jessica Jenkins, a VP at the Minnetrista exhibit, and a Bob Ross scholar, tells <em>The Hustle </em>that many more Ross paintings are actually hanging in living rooms across the US.</p>
<p>“He was always happy to donate his paintings to fundraisers, or sell his work at a reasonable price,” she says. “Many people who own one acquired it decades ago.”</p>
<p>For years, WIPB-TV — the PBS affiliate station in Muncie, Indiana, where Ross filmed most of his episodes — would auction off a Ross painting at its annual fundraising drive.</p>
<p>According to the town’s paper, <em>The Star Press</em>, these paintings were always “the most anticipated item,” overshadowing tickets to Cancun, diamond necklaces, rare Beanie Babies, and basketballs signed by Magic Johnson.</p>
<p>“We still have 4 of his paintings hanging here at the station,” says Lori Georgi, a director at WIPB. “People come from England just to see them.”</p>
<figure><img loading="lazy" decoding="async" src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=600&amp;height=226&amp;name=459229276-clip.webp" alt="own-a-bob-ross-painting-news-article" sizes="(max-width: 600px) 100vw, 600px" width="600" height="226" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=300&amp;height=113&amp;name=459229276-clip.webp 300w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=600&amp;height=226&amp;name=459229276-clip.webp 600w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=900&amp;height=339&amp;name=459229276-clip.webp 900w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=1200&amp;height=452&amp;name=459229276-clip.webp 1200w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=1500&amp;height=565&amp;name=459229276-clip.webp 1500w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/459229276-clip.webp?width=1800&amp;height=678&amp;name=459229276-clip.webp 1800w"></figure>
<p><em>An old newspaper clipping advertises an auction for an original Bob Ross painting featuring “majestic snow-covered mountains, a tranquil lake surrounded by towering evergreens, and a beautiful sunset sky.” (The Star Press; Muncie, Indiana, 2000)</em></p>
<p>Before he became a TV star, Ross also sold thousands of his landscape paintings at flea markets, fairs, and malls, often for small sums of cash.</p>
<p>This is how Larry Walton, 82, of Crosslake, Minnesota, acquired his original Bob Ross.</p>
<p>Back in 1980, while working as a flight instructor in Alaska, he <a href="https://www.duluthnewstribune.com/entertainment/art/4684705-Minnesota-couple-learns-painting-bought-40-years-ago-is-Bob-Ross-original" target="_blank" rel="noopener noreferrer">bought</a> a scene with mountains and blue northern lights from the then-unknown “peculiar artist” at an Anchorage fair for $60.</p>
<p>It spent years sitting in the garage until his son — an avid fan of Bob Ross YouTube videos — thought the signature in the corner looked familiar.</p>
<p>When the couple decided to sell it, they turned to <a href="https://modernartifact.com/" target="_blank" rel="noopener noreferrer">Modern Artifact</a>, an art gallery and dealer in Minneapolis, Minnesota.</p>
<p>Ryan Nelson, the gallery’s owner, tells <em>The Hustle </em>that he’s been buying and flipping Bob Ross paintings for 10 years. To find sellers like Walton, he uses SEO tactics and places “wanted” ads in local newspapers near where Ross spent time.</p>
<p>“We buy and sell more of his paintings than any gallery on the planet,” he writes via email. “To retain that position, we offer more money to buy his paintings than most anyone is willing to risk.”</p>
<p>The Waltons sold the painting to the gallery for <strong>$10k</strong>; Nelson then flipped it on eBay for a small profit.</p>
<p>Unlike traditional art collectors, those who possess Bob Ross paintings tend to be ordinary folks who don’t know what they’re in possession of.</p>
<p>“Most families that have these paintings are not millionaires,” he says, “and the money is very impactful in their lives.”</p>
<figure><img loading="lazy" decoding="async" src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=600&amp;height=401&amp;name=560642181-modernartifact.webp" alt="image-of-bob-ross-painting-price" sizes="(max-width: 600px) 100vw, 600px" width="600" height="401" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=300&amp;height=201&amp;name=560642181-modernartifact.webp 300w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=600&amp;height=401&amp;name=560642181-modernartifact.webp 600w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=900&amp;height=602&amp;name=560642181-modernartifact.webp 900w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=1200&amp;height=802&amp;name=560642181-modernartifact.webp 1200w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=1500&amp;height=1003&amp;name=560642181-modernartifact.webp 1500w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/560642181-modernartifact.webp?width=1800&amp;height=1203&amp;name=560642181-modernartifact.webp 1800w"></figure>
<p><em>An original Bob Ross painting up for sale on Modern Artifact’s website for $95k (Modern Artifact)</em></p>
<p>Modern Artifact has sold <a href="https://modernartifact.com/search?q=bob+ross" target="_blank" rel="noopener noreferrer">at least 34</a> Bob Ross paintings over the years.</p>
<p>Nelson wouldn’t divulge the sale prices, but said it’s not uncommon for them to go well beyond $10k. On the site, he currently has a rare ocean scene <a href="https://modernartifact.com/products/bob-ross-original-episode-painted-season-24-we-buy-bob-ross-paintings?_pos=2&amp;_sid=0a6322c89&amp;_ss=r" target="_blank" rel="noopener noreferrer">listed</a> for <strong>$94k</strong>.</p>
<p>It may seem odd that Bob Ross paintings fetch that much at market.</p>
<p>After all, Ross often produced a painting in less than 30 minutes (by contrast, it took da Vinci <a href="https://en.wikipedia.org/wiki/Mona_Lisa" target="_blank" rel="noopener noreferrer">4 years</a> to complete the Mona Lisa), and his artwork was, by design, highly replicable.</p>
<p>But Nelson chalks the crazy prices up to a combination of basic economic principles and social capital.</p>
<p>“The bottom line is supply and demand: Bob Ross paintings are extremely tough to find, and more people want them than can have them,” he says. “They’re also the ideal conversation pieces, since they are almost universally recognizable.”</p>
<figure><img loading="lazy" decoding="async" src="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=600&amp;height=845&amp;name=50687775-paintings.webp" alt="image-of-bob-ross-paintings" sizes="(max-width: 600px) 100vw, 600px" width="600" height="845" srcset="https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=300&amp;height=423&amp;name=50687775-paintings.webp 300w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=600&amp;height=845&amp;name=50687775-paintings.webp 600w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=900&amp;height=1268&amp;name=50687775-paintings.webp 900w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=1200&amp;height=1690&amp;name=50687775-paintings.webp 1200w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=1500&amp;height=2113&amp;name=50687775-paintings.webp 1500w, https://20627419.fs1.hubspotusercontent-na1.net/hub/20627419/hubfs/The%20Hustle/Assets/Images/50687775-paintings.webp?width=1800&amp;height=2535&amp;name=50687775-paintings.webp 1800w"></figure>
<p><em>A few Bob Ross classics. TOP: Wilderness Way, The Joy of Painting, S31, E13.; BOTTOM: Northern Lights,The Joy of Painting, S8, E13. (both © Bob Ross Inc.)</em></p>
<p>Lindsey Bourret, managing director of the art appraisal site <a href="https://mearto.com/" target="_blank" rel="noopener noreferrer">Mearto</a>, estimates that the fair market value of a Ross painting — the price it <em>should </em>sell for based on precedent — is <strong>$2k to $4k</strong>. But the pop culture element to his work boosts demand.</p>
<p>“I would personally categorize Ross’s work as a hybrid between fine art and entertainment memorabilia,” she says.&nbsp;</p>
<p>Some buyers are willing to pay a premium for that.</p>
<p>One collector who didn’t wish to be named out of concern for her privacy, owns an extensive cache of artwork, including several six-figure pieces. But she considers her Bob Ross original her “crown jewel.”“I’ve had more guests comment on my Bob than my Picasso,” she tells <em>The Hustle</em>. “It’s really all about the story.”</p>
<h4 id="h-it-s-all-about-the-process"><strong>It’s all about the process</strong></h4>
<p>Ultimately, the real reason there aren’t more Bob Ross paintings up for sale is that the artist never wanted them to be a commodity.</p>
<p>For Ross, the value was in the process, not the finished product.</p>
<p>“He was about as uninterested in the actual paintings as you could possibly be,” says Kowalski. “For him, it was the journey — he wanted to teach people. The paintings were just a means to do that.”</p>
<p><strong><em>NOTE</em></strong><em>: Top image of Bob Ross © Bob Ross Inc.; photo illustration b<span>y </span></em><a href="https://thehustle.co/" target="_blank" rel="noopener noreferrer">The Hustle</a><span>.</span><span><a href="https://thehustle.co/" target="_blank" rel="noopener noreferrer"></a></span></p></span></p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twin – A Textmode WINdow Environment (133 pts)]]></title>
            <link>https://github.com/cosmos72/twin</link>
            <guid>44284657</guid>
            <pubDate>Sun, 15 Jun 2025 20:07:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cosmos72/twin">https://github.com/cosmos72/twin</a>, See on <a href="https://news.ycombinator.com/item?id=44284657">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Twin - a Textmode WINdow environment</h2><a id="user-content-twin---a-textmode-window-environment" aria-label="Permalink: Twin - a Textmode WINdow environment" href="#twin---a-textmode-window-environment"></a></p>
<p dir="auto">Version 0.9.0</p>
<p dir="auto">Twin is text-based windowing environment with mouse support, window manager,
terminal emulator, networked clients and the ability to attach/detach
mode displays on-the-fly.</p>
<p dir="auto">It supports a variety of displays:</p>
<ul dir="auto">
<li>plain text terminals: Linux console, twin's own terminal emulator,
and any termcap/ncurses compatible terminal;</li>
<li>X11, where it can be used as a multi-window xterm;</li>
<li>itself (you can display a twin on another twin);</li>
<li>twdisplay, a general network-transparent display client, used
to attach/detach more displays on-the-fly.</li>
</ul>
<p dir="auto">Currently, twin is tested on Linux (i386, x86_64, ARM, ARM64, PowerPC, Alpha, Sparc),
on Mac OS X (x86_64) and on FreeBSD (i386, x86_64).
I had yet no chance to seriously test it on other systems.</p>
<p dir="auto">The following screenshot shows an example of twin with various clients:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/cosmos72/twin/blob/master/docs/screenshot_x11.png"><img src="https://github.com/cosmos72/twin/raw/master/docs/screenshot_x11.png" alt="screenshot_x11.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/docs/Tutorial">Tutorial</a>
A quite complete tour of twin features: the user interface,
how to use twin clients, compression, attaching/detaching
displays, fonts. It also contains installation instructions
and some caveats for system administrators.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/COPYING">COPYING</a>
License: twin server and clients are GPL'ed software.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/COPYING.LIB">COPYING.LIB</a>
Library license: the libraries libtutf, libtw
are LGPL'ed software.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/INSTALL">INSTALL</a>
Quick compile/install guide.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/twinrc">twinrc</a>
A detailed example of ~/.config/twin/twinrc look-n-feel configuration file.</p>
<p dir="auto">The following documentation is useful mostly to developers:</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/docs/Configure">Configure</a>
Description of twin configuration options with the meaning
of every single one.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/README.git">README.git</a>
Hints to build twin from GIT repository.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/README.porting">README.porting</a>
Tips and warnings to compile twin on unsupported OSes.</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/docs/libtw.txt">libtw.txt</a>
reference API for programmers who want to write twin clients (INCOMPLETE).</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin/blob/master/docs/libtw++.txt">libtw++.txt</a>
reference API for programmers who want to write	twin C++ clients (INCOMPLETE).</p>
<hr>
<p dir="auto">Getting twin</p>
<p dir="auto">Since you are reading this README, you probably already have it,
anyway twin can be downloaded from</p>
<p dir="auto"><a href="https://github.com/cosmos72/twin">https://github.com/cosmos72/twin</a></p>
<hr>
<p dir="auto">Building and installing twin</p>
<p dir="auto">For detailed instructions about compiling and installing twin,
see sections 3 and 4 of the file <a href="https://github.com/cosmos72/twin/blob/master/docs/Tutorial">docs/Tutorial</a></p>
<p dir="auto">For the impatient, it basically reduces to</p>

<p dir="auto">then run as root</p>

<p dir="auto">on Linux, also remember to run as root:</p>

<p dir="auto">on FreeBSD instead, remember to run as root:</p>

<p dir="auto">To compile twin you need the following programs installed
on your system:</p>
<ul dir="auto">
<li>
<p dir="auto">a Bourne-shell or compatible (for example bash, dash, ash...)</p>
</li>
<li>
<p dir="auto">make (most variants are supported: GNU make, BSD make...)</p>
</li>
<li>
<p dir="auto">an ANSI C compiler (for example gcc or clang)</p>
</li>
</ul>
<p dir="auto">Note: it is STRONGLY recommended to install at least the following packages before compiling twin
(the exact names depend on the operating system or Linux distribution):</p>
<ul dir="auto">
<li>x11-dev      - may be named x11-devel, libx11-dev ...</li>
<li>xft-dev      - may be named xft-devel, libxft-dev ...</li>
<li>ncurses-dev  - may be named ncurses-devel, libncurses-dev ...</li>
<li>zlib-dev     - may be named zlib1g-dev, zlib-devel, libzlib-dev ...</li>
</ul>
<p dir="auto">On Linux, it is STRONGLY recommended to also install the following package before compiling twin:</p>
<ul dir="auto">
<li>gpm-dev      - may be named gpm-devel, libgpm-dev ...</li>
</ul>
<p dir="auto">For a discussion about MANUALLY configuring twin (almost never necessary),
see the file <a href="https://github.com/cosmos72/twin/blob/master/docs/Configure">docs/Configure</a>.
-- WARNING: if you manually enable options that were disabled by `./configure',
build will almost certainly fail! --</p>
<hr>
<p dir="auto">Other topics:</p>
<p dir="auto">See the rest of the documentation, starting from the <a href="https://github.com/cosmos72/twin/blob/master/docs/Tutorial">Tutorial</a></p>
<p dir="auto">Greetings,</p>
<p dir="auto">Massimiliano Ghilardi</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Telephone Exchanges in the UK (158 pts)]]></title>
            <link>https://telephone-exchanges.org.uk/</link>
            <guid>44284466</guid>
            <pubDate>Sun, 15 Jun 2025 19:33:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://telephone-exchanges.org.uk/">https://telephone-exchanges.org.uk/</a>, See on <a href="https://news.ycombinator.com/item?id=44284466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cz_75334"><p>For more than a century the telephone exchange has formed the backbone of our telecommunications system. A vast array of more than 5,500 mostly nondescript buildings sit unnoticed on city, town or village streets, and quietly link up more than 254 million kilometres of cables and wires – keeping people in the UK connected to each other and the rest of the world.</p>
<p>Since the first telephone exchange was established in London in 1879 with just eight subscribers, these anonymous looking buildings have spread the length and breadth of the UK – from the smallest on the remote Shetland Isle of Papa Stour, with just 14 homes, to the largest in Oldham, Manchester, serving more than 45,000.</p>
<p>But the recent explosive growth in new digital fibre based services means the majority of these iconic communication hubs will soon route their last ever call.</p>
<p>The advent of tiny but powerful microprocessors and glass fibres, thinner than the width of a human hair, only need a tiny fraction of the space taken up by miles of copper wires and bulky racks of switching machinery to run the old copper based phone network or Public Switched Telephone Network (PSTN).</p>
<p>This seismic shift means that today we’re able to provide fibre broadband services to the entire country from just 1,000 ‘super digital exchanges’ or Openreach Handover Points (OHPs).</p>
<p>Sadly, this spells the beginning of the end for the remaining 4,600 exchanges used to support traditional copper based phone and broadband voice services. And these copper customers are dwindling fast as people migrate to faster more efficient fibre</p>
<p>Openreach is now consulting with its communication provider (CP) customers – like Sky, Vodafone, TalkTalk and BT, who use our network to connect their own customers – about how to close these ‘legacy’ exchanges over the next decade or so.</p>
<p>This will be a major undertaking with several million services to be migrated, and the importance of ensuring vulnerable customers and the UK’s Critical National Infrastructure providers are protected along the way.&nbsp; So we’re planning it in stages – with the first 103 exchanges to close by December 2030. These have some of the highest running costs so there’s a clear advantage in targeting them first.&nbsp; Most of the remaining 4,500 exchanges will likely follow in the early 2030s.</p>
<p><em>Press release by Richard Allwood, Chief Stragey Officer, Openreach – 26 June 2023.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing Toy Software Is a Joy (106 pts)]]></title>
            <link>https://www.jsbarretto.com/blog/software-is-joy/</link>
            <guid>44284291</guid>
            <pubDate>Sun, 15 Jun 2025 19:02:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jsbarretto.com/blog/software-is-joy/">https://www.jsbarretto.com/blog/software-is-joy/</a>, See on <a href="https://news.ycombinator.com/item?id=44284291">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
<h6>
June 15, 2025
&nbsp;&nbsp;
<span>programming</span>
</h6>
</p><div>
<p>I am a huge fan of Richard Feyman’s famous quote:</p>
<p><strong>“What I cannot create, I do not understand”</strong></p>
<p>I think it’s brilliant, and it remains true across many fields (if you’re willing to be a little creative with the
definition of ‘create’). It is to this principle that I believe I owe everything I’m truly good at. Some will tell you
to avoid reinventing the wheel, but they’re wrong: you <em>should</em> build your own wheel, because it’ll teach you more about
how they work than reading a thousand books on them ever will.</p>
<p>In 2025, the beauty and craft of writing software is being eroded. AI is threatening to replace us (or, at least, the
most joyful aspects of our craft) and software development is being increasingly commodified, measured, packaged, and
industrialised. Software development needs more simple joy, and I’ve found that creating toy programs is a great way to
remember why I started working with computers again.</p>
<p>Further, I’ve been consistently surprised by just how often some arcane nugget of knowledge I’ve acquired when working
on a toy project has turned out to be immensely valuable in my day job, either by giving me a head-start on tracking
down a problem in a tool or library, or by recognising mistakes before they’re made. Understanding the constraints that
define the shape of software is vital for working with it, and there’s no better way to gain insight into those
constraints than by running into them head-first. You might even come up with some novel solutions!</p>
<h2 id="the-list">The list</h2>
<p>Here is a list of toy programs I’ve attempted over the past 15 years, rated by difficulty and time required. These
ratings are estimates and assume that you’re already comfortable with at least one-general purpose programming language
and that, like me, you tend to only have an hour or two per day free to write code. Also included are some suggested
resources.</p>
<p>The list isn’t exhaustive, and I’m deliberately only covering those I have personal experience with.</p>
<h3 id="regex-engine-difficulty--410-time--3-days">Regex engine (difficulty = 4/10, time = 3 days)</h3>
<p>A regex engine that can read a POSIX-style regex program and recognise strings that match it. Regex is simple yet
shockingly expressive, and writing a competent regex engine will teach you everything you need to know about using the
language too.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Regular_expression#Syntax">Wikipedia: Regex</a></li>
</ul>
<h3 id="x86-os-kernel-difficulty--710-time--1-month">x86 OS kernel (difficulty = 7/10, time = 1 month)</h3>
<p>A multiboot-compatible OS kernel with a simple CLI, keyboard/mouse driver, ANSI escape sequence support, memory manager,
scheduler, etc. Additional challenges include writing an in-memory filesystem, user mode and process isolation, loading
ELF executables, and supporting enough video hardware to render a GUI.</p>
<ul>
<li><a href="https://wiki.osdev.org/">OS Dev Wiki</a></li>
</ul>
<h3 id="gameboynes-emulator-difficulty--610-time--2-weeks">GameBoy/NES emulator (difficulty = 6/10, time = 2 weeks)</h3>
<p>A crude emulator for the simplest GameBoy or NES games. The GB and the NES are classics, and both have relatively simple
instruction sets and peripheral hardware. Additional challenges include writing competent PPU (video) and PSG (audio)
implementations, along with dealing with some of the more exotic cartridge formats.</p>
<ul>
<li><a href="https://gbdev.io/">GB Dev</a></li>
<li><a href="https://www.nesdev.org/wiki/Nesdev_Wiki">NES Dev Wiki</a></li>
</ul>
<h3 id="gameboy-advance-game-difficulty--310-time--1-week">GameBoy Advance game (difficulty = 3/10, time = 1 week)</h3>
<p>A sprite-based game (top-down or side-on platform). The GBA is a beautiful little console to write code for and there’s
an active and dedicated development community for the console. I truly believe that the GBA is one of the last game
consoles that can be fully and completely understood by a single developer, right down to instruction timings.</p>
<ul>
<li><a href="https://www.coranac.com/tonc/text/toc.htm">Tonc</a></li>
<li><a href="https://problemkaputt.de/gbatek.htm">GBATEK</a></li>
</ul>
<h3 id="physics-engine-difficulty--510-time--1-week">Physics engine (difficulty = 5/10, time = 1 week)</h3>
<p>A 2D rigid body physics engine that implements Newtonian physics with support for rectangles, circles, etc. On the
simplest end, just spheres that push away from one-another is quite simple to implement. Things start to get complex
when you introduce more complex shapes, angular momentum, and the like. Additional challenges include making collision
resolution fast and scaleable, having complex interactions move toward a steady state over time, soft-body interactions,
etc.</p>
<h3 id="dynamic-interpreter-difficulty--410-time--3-days">Dynamic interpreter (difficulty = 4/10, time = 3 days)</h3>
<p>A tree-walking interpreter for a JavaScript-like language with basic flow control. There’s an unbounded list of extra
things to add to this one, but being able to write programs in my own language still gives me child-like elation. It
feels like a sort of techno-genesis: once you’ve got your own language, you can start building the universe within it.</p>
<ul>
<li><a href="https://craftinginterpreters.com/">Crafting Interpreters</a></li>
</ul>
<h3 id="compiler-for-a-c-like-difficulty--810-time--3-months">Compiler for a C-like (difficulty = 8/10, time = 3 months)</h3>
<p>A compiler for a simply-typed C-like programming language with support for at least one target archtecture. Extra
challenges include implementing some of the most common optimisations (inlining, const folding, loop-invariant code
motion, etc.) and designing an intermediate representation (IR) that’s general enough to support multiple backends.</p>
<h3 id="text-editor-difficulty--510-time--3-weeks">Text editor (difficulty = 5/10, time = 3 weeks)</h3>
<p>This one has a lot of variability. At the blunt end, simply reading and writing a file can be done in a few lines of
Python. But building something that’s closer to a daily driver gets more complex. You could choose to implement the UI
using a toolkit like QT or GTK, but I personally favour an editor that works in the console. Properly handling unicode,
syntax highlighting, cursor movement, multi-buffer support, panes/windows, tabs, search/find functionality, LSP support,
etc. can all add between a week or a month to the project. But if you persist, you might join the elite company of those
developers who use an editor of their own creation.</p>
<h3 id="async-runtime-difficulty--610-time--1-week">Async runtime (difficulty = 6/10, time = 1 week)</h3>
<p>There’s a lot of language-specific variability as to what ‘async’ actually means. In Rust, at least, this means a
library that can ingest <code>impl Future</code> tasks and poll them concurrently until completion. Adding support for I/O waking
makes for a fun challenge.</p>
<h3 id="hash-map-difficulty--410-time--1-week">Hash map (difficulty = 4/10, time = 1 week)</h3>
<p>Hash maps (or sets/dictionaries, as a higher-level language might call them) are a programmer’s bread &amp; butter. And yet,
surprisingly few of us understand how they really work under the bonnet. There are a plethora of techniques to throw
into the mix too: closed or open addressing, tombstones, the robin hood rule, etc. You’ll gain an appreciation for when
and why they’re fast, and also when you should just use a vector + linear search.</p>
<h3 id="rasteriser--texture-mapper-difficulty--610-time--1-week">Rasteriser / texture-mapper (difficulty = 6/10, time = 1 week)</h3>
<p>Most of us have played with simple 3D graphics at some point, but how many of us truly understand how the graphics
pipeline works and, more to the point, how to fix it when it doesn’t work? Writing your own software rasteriser will
give you that knowledge, along with a new-found appreciation for the beauty of vector maths and half-spaces that have
applications across many other fields. Additional complexity involves properly implementing clipping, a Z-buffer, N-gon
rasterisation, perspective-correct texture-mapping, Phong or Gouraud shading, shadow-mapping, etc.</p>
<ul>
<li><a href="https://www.scratchapixel.com/">Scratch-A-Pixel</a></li>
</ul>
<h3 id="sdf-rendering-difficulty--510-time--2-days">SDF Rendering (difficulty = 5/10, time = 2 days)</h3>
<p>Signed Distance Fields are a beautifully simple way to render 3D spaces defined through mathematics, and are perfectly
suited to demoscene shaders. With relatively little work you can build yourself a cute little visualisation or some
moving shapes like the graphics demos of the 80s. You’ll also gain an appreciation for shader languages and vector
maths.</p>
<ul>
<li><a href="https://iquilezles.org/articles/distfunctions/">Inigo Quilez’s Site</a></li>
</ul>
<h3 id="voxel-engine-difficulty--510-time--1-week">Voxel engine (difficulty = 5/10, time = 1 week)</h3>
<p>I doubt there are many reading this that haven’t played Minecraft. It’s surprisingly easy to build your own toy voxel
engine cut from a similar cloth, especially if you’ve gone some knowledge of 3D graphics or game development already.
The simplicity of a voxel engine, combined with the near-limitless creativity that can be expressed with them, never
ceases to fill me with joy. Additional complexity can be added by tackling textures, more complex procedural generation,
floodfill lighting, collisions, dynamic fluids, sending voxel data over the network, etc.</p>
<ul>
<li><a href="https://0fps.net/2012/06/30/meshing-in-a-minecraft-game/">0 FPS: Meshing in a Minecraft Game</a></li>
</ul>
<h3 id="threaded-virtual-machine-difficulty--610-time--3-days">Threaded Virtual Machine (difficulty = 6/10, time = 3 days)</h3>
<p>Writing interpreters is great fun. What’s more fun? <em>Faster interpreters</em>. If you keep pushing interpreters as far as
they can go without doing architecture-specific codegen (like AOT or JIT), you’ll eventually wind up (re)discovering
<em>threaded code</em>. It’s a beautiful way of weaving programs together out highly-optimised miniature programs, and a decent
implementation can even give an AOT compiler a run for its money in the performance department.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Threaded_code">Wikipedia: Threaded code</a></li>
<li><a href="https://muforth.dev/threaded-code/">muforth.dev: Threaded code</a></li>
</ul>
<h3 id="your-own-gui-toolkit-difficulty--610-time--2-weeks">Your Own GUI Toolkit (difficulty = 6/10, time = 2 weeks)</h3>
<p>Most of us have probably cobbled together a GUI program using tkinter, GTK, QT, or WinForms. But why not try writing
your GUI toolkit? Additional complexity involves implementing a competent layout engine, good text shaping (inc.
unicode support), accessibility support, and more. Fair warning: do not encourage people to use your tool unless it’s
<em>battle-tested</em> - the world has enough GUIs with little-to-no accessibility or localisation support.</p>
<h3 id="orbital-mechanics-sim-difficulty--1010-time--4-days">Orbital Mechanics Sim (difficulty = 10/10, time = 4 days)</h3>
<p>A simple simulation of Newtonian gravity can be cobbled together in a fairly short time. Infamously, gravitational
systems with more than three bodies cannot be solved analytically, so you’ll have to get familiar with iterative
<em>integration</em> methods. Additional complexity comes with implementing more precise and faster integration methods,
accounting for relativistic effects, and plugging in real numbers from NASA to predict the next high tide or full moon.</p>
<h3 id="bitwise-challenge-difficulty--310-time--1-day">Bitwise Challenge (difficulty = 3/10, time = 1 day)</h3>
<p>Here’s the challenge: write a game that only persists 64 bits of state between subsequent frames. That’s 64 bits for
everything: the entire frame-for-frame game state should be reproducible using only 64 bits of data. It sounds simple,
but it forces you to get incredibly creative with your game state management. More details about the rules on the GitHub
page below.</p>
<ul>
<li><a href="https://github.com/zesterer/the-bitwise-challenge">The Bitwise Challenge</a></li>
</ul>
<h3 id="an-ecs-framework-difficulty--410-time--1-week">An ECS Framework (difficulty = 4/10, time = 1 week)</h3>
<p>For all those game devs out there: try building your own <a href="https://en.wikipedia.org/wiki/Entity_component_system">ECS</a>
framework. It’s not as hard as you might think (you might have accidentally done it already!). Extra points if you can
build in safety and correctness features, as well as good integration with your programming language of choice’s type
system features.</p>
<h3 id="chip-8-emulator-difficulty--310-time--3-days">CHIP-8 Emulator (difficulty = 3/10, time = 3 days)</h3>
<p>The <a href="https://en.wikipedia.org/wiki/CHIP-8">CHIP-8</a> is a beautifully simple virtual machine from the 70s. You can write
a fully compliant emulator in a day or two, and there are an enormous plethora of fan-made games that run on it.
<a href="https://github.com/zesterer/emul8/raw/refs/heads/master/test/test.ch8">Here’s</a> a game I made for it.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/CHIP-8">Wikipedia: CHIP-8</a></li>
</ul>
<h3 id="chess-engine-difficulty--510-time--2-days">Chess engine (difficulty = 5/10, time = 2 days)</h3>
<p>Writing a chess engine is great fun. You’ll start off with every move it makes being illegal, but over time it’ll get
smart and smarter. Experiencing a loss to your own chess engine really is a rite of passage, and it feels magical.</p>
<h3 id="posix-shell-difficulty--410-time--3-days">POSIX shell (difficulty = 4/10, time = 3 days)</h3>
<p>We interact with shells every day, and building one will teach you can incredible amount about POSIX - how it works, and
how it doesn’t. A simple one can be built in a day, but compliance with an existing shell language will take time and
teach you more than you ever wanted to know about its quirks.</p>
<h2 id="a-note-on-learning-and-llms">A note on learning and LLMs</h2>
<p>Perhaps you’re a user of LLMs. I get it, they’re neat tools. They’re useful for certain kinds of learning. But I might
suggest resisting the temptation to use them for projects like this. Knowledge is not supposed to be fed to you on a
plate. If you want that sort of learning, read a book - the joy in building toy projects like this comes from an
exploration of the unknown, without polluting one’s mind with an existing solution. If you’ve been using LLMs for a
while, this cold-turkey approach might even be painful at first, but persist. There is no joy without pain.</p>
<p>The runner’s high doesn’t come to those that take the bus.</p>

</div></div>]]></description>
        </item>
    </channel>
</rss>