<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 25 Oct 2024 09:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cerebras Inference now 3x faster: Llama3.1-70B breaks 2,100 tokens/s (112 pts)]]></title>
            <link>https://cerebras.ai/blog/cerebras-inference-3x-faster</link>
            <guid>41941883</guid>
            <pubDate>Fri, 25 Oct 2024 03:04:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cerebras.ai/blog/cerebras-inference-3x-faster">https://cerebras.ai/blog/cerebras-inference-3x-faster</a>, See on <a href="https://news.ycombinator.com/item?id=41941883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we’re announcing the biggest update to Cerebras Inference since launch. Cerebras Inference now runs Llama 3.1-70B at an astounding 2,100 tokens per second – a 3x performance boost over the prior release. For context, this performance is:</p>
<ul>
<li>
<ul>
<li>16x faster than the fastest GPU solution</li>
<li>8x faster than GPUs running Llama3.1-3B, a model 23x smaller</li>
<li>Equivalent to a new GPU generation’s performance upgrade (H100/A100) in a single software release</li>
</ul>
</li>
</ul>
<p>Fast inference is the key to unlocking the next generation of AI apps. From voice, video, to advanced reasoning, fast inference makes it possible to build responsive, intelligent applications that were previously out of reach. From Tavus revolutionizing video generation to GSK accelerating drug discovery workflows, leading companies are already using Cerebras Inference to push the boundaries of what’s possible. Try Cerebras Inference using chat or API at inference.cerebras.ai.</p>
<h3>Benchmarks</h3>
<p>Cerebras Inference has been rigorously tested by Artificial Analysis, a third-party benchmarking organization. We reproduce their performance charts below.</p>
</div><p>In output speed per user, Cerebras Inference is in a league of its own – 16x faster than the most optimized GPU solution, 68x faster than hyperscale clouds, and 4-8x faster than other AI accelerators.</p><p>Time to first token is critical for real time applications. Cerebras is tied second place in first token latency, showing the advantage of a wafer-scale integrated solution vs. complex networked solutions.</p><p>Total response time – measuring a full turn of input and output – is a good proxy for multi-step agentic workflows. Here Cerebras Inference completes a full request in just 0.4 of a second vs. 1.1 to 4.2 seconds on GPU based solutions. For agents, this means getting up to 10x more work done in the same time. For reasoning models, this enables 10x more reasoning steps without increasing response time.</p><div><p>Cerebras Inference running Llama3.1 70B is now so fast that it outruns GPU based inference running Llama3.1 3B. The Wafer Scale Engine runs an AI model 23x larger at 8x speed for a combined 184x performance advantage.</p>
<h3>Optimized kernels, stack, and ML</h3>
<p>The first release of Cerebras Inference in August set new speed records and made Llama3.1-70B an instantaneous experience. While it was incredibly fast, it was the first implementation of inference on the Wafer Scale Engine and utilized only a fraction of its peak bandwidth, compute, and IO capacity. Today’s release is the culmination of numerous software, hardware, and ML improvements we made to our stack to greatly improve the utilization and real-world performance of Cerebras Inference.</p>
<p>We’ve re-written or optimized the most critical kernels such as MatMul, reduce/broadcast, element wise ops, and activations. Wafer IO has been streamlined to run asynchronously from compute. This release also implements speculative decoding, a widely used technique that uses a small model and large model in tandem to generate answers faster. As a result of this feature, you may observe a greater variance in output speed – 20% higher or lower than the 2,100 tokens/sec average is normal.</p>
<p>Model precision is unchanged – all models continue to use 16-bit original weights. Model output accuracy is likewise unchanged as verified by Artificial Analysis.</p>
<h3>What fast inference enables</h3>
<p>The impact of Cerebras Inference’s unprecedented speed is already transforming how organizations develop and deploy AI apps. In pharmaceutical research, Kim Branson, SVP of AI and ML at GSK, says: “With Cerebras’ inference speed, GSK is developing innovative AI applications, such as intelligent research agents, that will fundamentally improve the productivity of our researchers and drug discovery process.”</p>
<p>The dramatic speed improvement is game-changing for real-time AI applications, as demonstrated by LiveKit, which powers ChatGPT’s voice mode. As CEO Russ d’Sa explains: “When building voice AI, inference is the slowest stage in your pipeline. With Cerebras Inference, it’s now the fastest. A full pass through a pipeline consisting of cloud-based speech-to-text, 70B-parameter inference using Cerebras Inference, and text-to-speech, runs faster than just inference alone on other providers. This is a game changer for developers building voice AI that can respond with human-level speed and accuracy.”</p>
<p>Fast inference is the key enabler for next gen AI applications that leverage more test-time compute for greater model capability. As demonstrated by models like GPT-o1, the ability to perform extensive chain-of-thought reasoning directly translates to breakthrough performance in reasoning, coding, and research tasks. Using Cerebras Inference, models think deeply before responding without the typical minutes-long latency penalties. This makes Cerebras Inference the ideal platform for developers looking to build systems that deliver both greater runtime intelligence and responsive user experiences.</p>
<h3>Conclusion</h3>
<p>Today’s 3x performance improvement shows what’s possible when realizing the full potential of the Wafer Scale Engine for inference. At 2,100 tokens per second for Llama3.1-70B, we’ve delivered the equivalent of more than a hardware generation’s worth of performance in a single software release. Our team continues to optimize both software and hardware capabilities, and we will be expanding our model selection, context lengths, and API features in the coming weeks.</p>
<p><a href="http://chat.cerebras.ai/">Try chat</a><br>
<a href="https://www.businesswire.com/news/home/20241024856476/en/Cerebras-Triples-its-Industry-Leading-Inference-Performance-Setting-New-All-Time-Record">Press release</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bitwarden SDK relicensed from proprietary to GPLv3 (510 pts)]]></title>
            <link>https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b</link>
            <guid>41940580</guid>
            <pubDate>Thu, 24 Oct 2024 22:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b">https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b</a>, See on <a href="https://news.ycombinator.com/item?id=41940580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
      <tr data-position="0">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542HL1" data-line-number="..."></td>
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542HR1" data-line-number="..."></td>
    <td>@@ -1,6 +1,6 @@</td>
  </tr>

    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L1" data-line-number="1"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R1" data-line-number="1"></td>

  <td>
    <span data-code-marker=" ">[<span>workspace</span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L2" data-line-number="2"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R2" data-line-number="2"></td>

  <td>
    <span data-code-marker=" "><span>resolver</span> = <span><span>"</span>2<span>"</span></span></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L3" data-line-number="3"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>members</span> = [<span><span>"</span>crates/*<span>"</span></span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R3" data-line-number="3"></td>

  <td>
    <span data-code-marker="+"><span>members</span> = [<span><span>"</span>crates/*<span>"</span></span><span>, </span><span><span>"</span><span>bitwarden_license/*</span><span>"</span></span>]</span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L4" data-line-number="4"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R4" data-line-number="4"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L5" data-line-number="5"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R5" data-line-number="5"></td>

  <td>
    <span data-code-marker=" "><span><span>#</span> Global settings for all crates should be defined here</span></span></td>
</tr>




    <tr data-hunk="0a508202cce614a2270fb0ff3dc75590945b0744e6fda3863c4d40eb47c27de9">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L6" data-line-number="6"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R6" data-line-number="6"></td>

  <td>
    <span data-code-marker=" ">[<span>workspace</span>.<span>package</span>]</span></td>
</tr>




      <tr data-position="8">
    <td colspan="2">
        <a href="#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" id="expand-link-8-diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" aria-label="Expand All" data-url="/bitwarden/sdk-internal/blob_excerpt/c11128a804138f782b5abc159b658e3a4faf12fa?diff=unified&amp;in_wiki_context=&amp;last_left=6&amp;last_right=6&amp;left=27&amp;left_hunk_size=7&amp;mode=100644&amp;path=Cargo.toml&amp;right=27&amp;right_hunk_size=7" data-left-range="7-15" data-right-range="7-15">
          
        </a>
        <tool-tip id="tooltip-eb6421d3-fc5b-410b-915a-7bc615cd006b" for="expand-link-8-diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -27,7 +27,7 @@ bitwarden-exporters = { path = "crates/bitwarden-exporters", version = "=1.0.0"</td>
  </tr>

    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L27" data-line-number="27"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R27" data-line-number="27"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-fido</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-fido<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L28" data-line-number="28"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R28" data-line-number="28"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-generators</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-generators<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L29" data-line-number="29"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R29" data-line-number="29"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-send</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-send<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L30" data-line-number="30"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>bitwarden-sm</span> = { <span>path</span> = <span><span>"</span><span>crates</span>/bitwarden-sm<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R30" data-line-number="30"></td>

  <td>
    <span data-code-marker="+"><span>bitwarden-sm</span> = { <span>path</span> = <span><span>"</span><span>bitwarden_license</span>/bitwarden-sm<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L31" data-line-number="31"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R31" data-line-number="31"></td>

  <td>
    <span data-code-marker=" "><span>bitwarden-vault</span> = { <span>path</span> = <span><span>"</span>crates/bitwarden-vault<span>"</span></span>, <span>version</span> = <span><span>"</span>=1.0.0<span>"</span></span> }</span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L32" data-line-number="32"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R32" data-line-number="32"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="fafe8741ccaaaa753175796f49ab296209a8490ec98ed35921c258fb412436bb">
    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542L33" data-line-number="33"></td>

    <td id="diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542R33" data-line-number="33"></td>

  <td>
    <span data-code-marker=" "><span><span>#</span> External crates that are expected to maintain a consistent version across all crates</span></span></td>
</tr>




  <tr data-position="">
    <td colspan="2">
          <a href="#diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" id="expand-down-link--diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" aria-label="Expand Down" data-url="/bitwarden/sdk-internal/blob_excerpt/c11128a804138f782b5abc159b658e3a4faf12fa?diff=unified&amp;direction=down&amp;in_wiki_context=&amp;last_left=33&amp;last_right=33&amp;left=90&amp;left_hunk_size=&amp;mode=100644&amp;path=Cargo.toml&amp;right=90&amp;right_hunk_size=" data-left-range="34-89" data-right-range="34-89">
            
          </a>
          <tool-tip id="tooltip-2604fbf7-a6c0-4f9d-8ac6-fbd948d0e347" for="expand-down-link--diff-2e9d962a08321605940b5a657135052fbcef87b5e360662bb527c96d9a615542" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Down</tool-tip>
    </td>
    <td></td>
  </tr>


                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Safety Profiles Failed (169 pts)]]></title>
            <link>https://www.circle-lang.org/draft-profiles.html</link>
            <guid>41939967</guid>
            <pubDate>Thu, 24 Oct 2024 21:26:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.circle-lang.org/draft-profiles.html">https://www.circle-lang.org/draft-profiles.html</a>, See on <a href="https://news.ycombinator.com/item?id=41939967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div id="TOC" role="doc-toc">
<h2 id="toctitle">Contents</h2>
<ul>
<li><a href="#abstract" id="toc-abstract"><span>1</span> Abstract<span></span></a></li>
<li><a href="#c-is-under-specified" id="toc-c-is-under-specified"><span>2</span> C++ is
under-specified<span></span></a>
<ul>
<li><a href="#inferring-aliasing" id="toc-inferring-aliasing"><span>2.1</span> Inferring
aliasing<span></span></a></li>
<li><a href="#inferring-lifetimes" id="toc-inferring-lifetimes"><span>2.2</span> Inferring
lifetimes<span></span></a></li>
<li><a href="#inferring-safeness" id="toc-inferring-safeness"><span>2.3</span> Inferring
safeness<span></span></a></li>
</ul></li>
<li><a href="#lifetime-safety-is-static-typing" id="toc-lifetime-safety-is-static-typing"><span>3</span> Lifetime safety is static
typing<span></span></a></li>
<li><a href="#lifetime-parameters-dont-cause-soundness-bugs" id="toc-lifetime-parameters-dont-cause-soundness-bugs"><span>4</span> Lifetime parameters don’t cause
soundness bugs<span></span></a></li>
<li><a href="#c-is-too-irregular-for-profiles" id="toc-c-is-too-irregular-for-profiles"><span>5</span> C++ is too irregular for
Profiles<span></span></a>
<ul>
<li><a href="#c-cannot-enforce-exclusivity" id="toc-c-cannot-enforce-exclusivity"><span>5.1</span> C++ cannot enforce
exclusivity<span></span></a></li>
</ul></li>
<li><a href="#carcinization" id="toc-carcinization"><span>6</span> Carcinization<span></span></a></li>
<li><a href="#c-in-the-future" id="toc-c-in-the-future"><span>7</span> C++ in the
future<span></span></a></li>
<li><a href="#bibliography" id="toc-bibliography"><span>8</span> References<span></span></a></li>
</ul>
</div>
<h2 data-number="1" id="abstract"> Abstract<a href="#abstract"></a></h2>
<blockquote>
<p><em>As for dangling pointers and for ownership, <strong>this model
detects all possible errors</strong>. This means that we can guarantee
that a program is free of uses of invalidated pointers.</em></p>
<p>– A brief introduction to C++’s model for type- and resource-
safety<span data-cites="type-and-resource-safety-2015">[<a href="https://www.stroustrup.com/resource-model.pdf" role="doc-biblioref">type-and-resource-safety-2015</a>]</span></p>
</blockquote>
<p>Safety Profiles were introduced in 2015 with the promise to detect
all lifetime safety defects in existing C++ code. It was a bold claim.
But after a decade of effort, Profiles failed to produce a
specification, reliable implementation or any tangible benefit for C++
safety. The cause of this failure involves a number of mistaken premises
at the core of its design:</p>
<ol type="1">
<li>“Zero annotation is required by default, because existing C++ source
code already contains sufficient information”<span data-cites="P3465R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3465r0.pdf" role="doc-biblioref">P3465R0</a>]</span></li>
<li>“We should not require a <code>safe</code>
function annotation”<span data-cites="P3446R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3446r0.pdf" role="doc-biblioref">P3446R0</a>]</span></li>
<li>“Do not add a feature that requires viral annotation”<span data-cites="P3466R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3466r0.pdf" role="doc-biblioref">P3466R0</a>]</span></li>
<li>“Do not add a feature that requires heavy annotation”<span data-cites="P3466R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3466r0.pdf" role="doc-biblioref">P3466R0</a>]</span></li>
</ol>
<p>The parameters of the problem make success impossible. This paper
examines the contradictions in these premises, explains why the design
didn’t improve safety in the past and why it won’t improve safety in the
future.</p>
<p>Note that this document is specifically about the <em>lifetime
safety</em> claims in <span data-cites="P1179R1">[<a href="https://wg21.link/p1179r1" role="doc-biblioref">P1179R1</a>]</span> and <span data-cites="P3465R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3465r0.pdf" role="doc-biblioref">P3465R0</a>]</span>. The wider set of analyses in
<span data-cites="P3081R0">[<a href="https://isocpp.org/files/papers/P3081R0.pdf" role="doc-biblioref">P3081R0</a>]</span> that deal with rejecting
specific operations like <code><span>reinterpret_cast</span></code>,
union access, variadic arguments, etc., are not considered here.</p>
<h2 data-number="2" id="c-is-under-specified"> C++ is under-specified<a href="#c-is-under-specified"></a></h2>
<blockquote>
<p><em>Zero annotation is required by default, because existing C++
source code already contains sufficient information.</em></p>
<p>– Pursue <span data-cites="P1179R1">[<a href="https://wg21.link/p1179r1" role="doc-biblioref">P1179R1</a>]</span> as a Lifetime Safety TS<span data-cites="P3465R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3465r0.pdf" role="doc-biblioref">P3465R0</a>]</span></p>
</blockquote>
<p>C++ source code <em>does not</em> have sufficient information for
achieving memory safety. A C++ function declaration lacks three things
that are critical for lifetime safety:</p>
<ol type="1">
<li><a href="#inferring-aliasing">Aliasing information</a>.</li>
<li><a href="#inferring-lifetimes">Lifetime information</a>.</li>
<li><a href="#inferring-safeness">Safeness information</a>.</li>
</ol>
<p>Functions involving parameter types with pointer or reference
semantics have <em>implicit</em> aliasing, lifetime and safeness
requirements. Safety Profiles cannot recover these properties from C++
code, because there are no language facilities to describe them. These
requirements are only specified in documentation, if they are specified
at all.</p>
<h2 data-number="2.1" id="inferring-aliasing"> Inferring aliasing<a href="#inferring-aliasing"></a></h2>
<p>A C++ compiler can infer nothing about aliasing from a function
declaration. A function parameter with a mutable reference <em>might
always</em> alias other parameters, it <em>might never</em> alias other
parameters, or <em>it might not care</em> about aliasing other
parameters.</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>// i and j must always alias. They must refer to the same container.</span></span>
<span id="cb1-2"><span>void</span> f1<span>(</span>std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;::</span>iterator i, std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;::</span>iterator j<span>)</span> <span>{</span></span>
<span id="cb1-3">  <span>// If i and j point into different vectors, you have real problems.</span></span>
<span id="cb1-4">  std<span>::</span>sort<span>(</span>i, j<span>)</span>;</span>
<span id="cb1-5"><span>}</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span>// vec must not alias x.</span></span>
<span id="cb1-8"><span>void</span> f2<span>(</span>std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;&amp;</span> vec, <span>int</span><span>&amp;</span> x<span>)</span> <span>{</span></span>
<span id="cb1-9">  <span>// Resizing vec may invalidate x if x is a member of vec.</span></span>
<span id="cb1-10">  vec<span>.</span>push_back<span>(</span><span>5</span><span>)</span>;</span>
<span id="cb1-11"></span>
<span id="cb1-12">  <span>// Potential use-after-free.</span></span>
<span id="cb1-13">  x <span>=</span> <span>6</span>;</span>
<span id="cb1-14"><span>}</span></span>
<span id="cb1-15"></span>
<span id="cb1-16"><span>// vec may or may not alias x. It doesn't matter.</span></span>
<span id="cb1-17"><span>void</span> f3<span>(</span>std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;&amp;</span> vec, <span>const</span> <span>int</span><span>&amp;</span> x<span>)</span> <span>{</span></span>
<span id="cb1-18">  vec<span>.</span>push_back<span>(</span>x<span>)</span>;</span>
<span id="cb1-19"><span>}</span></span></code></pre></div>
<p><code>f1</code> and
<code>f2</code> have aliasing requirements. In
<code>f1</code>, both iterators must point into
the same container. In <code>f2</code>,
<code>x</code> must not come from the container
<code>vec</code>. These requirements are only
visible as documentation. The compiler cannot infer a function’s
aliasing requirements from its declaration or even from its definition.
If the safety profile enforces <em>no mutable aliasing</em>, then the
definitions of <code>f1</code> and
<code>f3</code> will fail to compile, breaking
your program.</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb2-2">  std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec1, vec2;</span>
<span id="cb2-3"></span>
<span id="cb2-4">  <span>// *Incorrectly* permits call.</span></span>
<span id="cb2-5">  <span>// UB, because the iterators point into different containers.</span></span>
<span id="cb2-6">  f1<span>(</span>vec1<span>.</span>begin<span>()</span>, vec2<span>.</span>end<span>())</span>;</span>
<span id="cb2-7"></span>
<span id="cb2-8">  <span>// *Incorrectly* rejects call.</span></span>
<span id="cb2-9">  <span>// This is the correct usage, but mutable aliasing prevents compilation.</span></span>
<span id="cb2-10">  f1<span>(</span>vec1<span>.</span>begin<span>()</span>, vec1<span>.</span>end<span>())</span>;</span>
<span id="cb2-11"></span>
<span id="cb2-12">  <span>// *Correctly* rejects call.</span></span>
<span id="cb2-13">  f2<span>(</span>vec1, vec1<span>[</span><span>2</span><span>])</span>;</span>
<span id="cb2-14"></span>
<span id="cb2-15">  <span>// *Incorrectly* rejects call.</span></span>
<span id="cb2-16">  f3<span>(</span>vec1, vec1<span>[</span><span>2</span><span>])</span>;</span>
<span id="cb2-17"><span>}</span></span></code></pre></div>
<p>Profiles chose the wrong convention for several uses. It permits the
incorrect call to <code>f1</code> to compile, but
rejects a correct usage of <code>f1</code> on the
grounds of mutable aliasing. An unsound call to
<code>f2</code> is correctly rejected, but a
sound call to <code>f3</code> is also rejected.
Rejecting or permitting code (rightly or wrongly) is a matter of
coincidence, not intelligence.</p>
<p>Without language-level aliasing information, compile-time memory
safety is not possible. This requirement is the motivation for Rust’s
borrow type. A mutable borrow cannot alias other borrows. That’s
enforced by the borrow checker. Raw pointers have no aliasing
requirements, but are unsafe to dereference. In general, things that can
be checked by the compiler are checked, and things that can’t be checked
are unsafe to use.</p>
<p><a href="https://godbolt.org/z/WWera863E">(Compiler Explorer)</a></p>
<div id="cb3"><pre><code><span id="cb3-1"><span>#include </span><span>&lt;vector&gt;</span></span>
<span id="cb3-2"><span>#include </span><span>&lt;iostream&gt;</span></span>
<span id="cb3-3"></span>
<span id="cb3-4"><span>void</span> func<span>(</span>std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;&amp;</span> vec, <span>int</span><span>&amp;</span> x<span>)</span> <span>{</span></span>
<span id="cb3-5">  vec<span>.</span>push_back<span>(</span><span>1</span><span>)</span>;</span>
<span id="cb3-6">  x <span>=</span> <span>2</span>;  <span>// A write-after-free when x is a member of vec!</span></span>
<span id="cb3-7"><span>}</span></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb3-10">  std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec;</span>
<span id="cb3-11">  vec<span>.</span>push_back<span>(</span><span>1</span><span>)</span>;</span>
<span id="cb3-12">  func<span>(</span>vec, vec<span>[</span><span>0</span><span>])</span>;</span>
<span id="cb3-13"></span>
<span id="cb3-14">  std<span>::</span>cout<span>&lt;&lt;</span> vec<span>[</span><span>0</span><span>]&lt;&lt;</span> <span>"</span><span>\n</span><span>"</span>;</span>
<span id="cb3-15">  std<span>::</span>cout<span>&lt;&lt;</span> vec<span>[</span><span>1</span><span>]&lt;&lt;</span> <span>"</span><span>\n</span><span>"</span>;</span>
<span id="cb3-16"><span>}</span></span></code></pre></div>

<p>The Safety Profiles partial reference implementation can’t prevent
aliasing-related undefined behavior because C++ doesn’t provide aliasing
information.</p>
<h2 data-number="2.2" id="inferring-lifetimes"> Inferring lifetimes<a href="#inferring-lifetimes"></a></h2>
<p>A C++ compiler can infer nothing about lifetimes from a function
declaration. A reference return type may be constrained by the lifetimes
of any number of reference parameters, by none of the reference
parameters, or by some other lifetime.</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>// The returned reference is only constrained by the lifetime of the map</span></span>
<span id="cb5-2"><span>// parameter.</span></span>
<span id="cb5-3"><span>// It is not constrained by the lifetime of the key parameter.</span></span>
<span id="cb5-4"><span>const</span> <span>int</span><span>&amp;</span> f4<span>(</span>std<span>::</span>map<span>&lt;</span><span>int</span>, <span>int</span><span>&gt;&amp;</span> map, <span>const</span> <span>int</span><span>&amp;</span> key<span>)</span> <span>{</span></span>
<span id="cb5-5">  <span>return</span> map<span>[</span>key<span>]</span>;</span>
<span id="cb5-6"><span>}</span></span>
<span id="cb5-7"></span>
<span id="cb5-8"><span>// The returned reference is constrained by the lifetime of both x and y</span></span>
<span id="cb5-9"><span>// parameters.</span></span>
<span id="cb5-10"><span>const</span> <span>int</span><span>&amp;</span> f5<span>(</span><span>const</span> <span>int</span><span>&amp;</span> x, <span>const</span> <span>int</span><span>&amp;</span> y<span>)</span> <span>{</span></span>
<span id="cb5-11">  <span>return</span> std<span>::</span>min<span>(</span>x, y<span>)</span>;</span>
<span id="cb5-12"><span>}</span></span>
<span id="cb5-13"></span>
<span id="cb5-14"><span>// The returned reference is not constrained by the lifetime of any</span></span>
<span id="cb5-15"><span>// reference parameter.</span></span>
<span id="cb5-16"><span>const</span> <span>int</span><span>&amp;</span> f6<span>(</span><span>const</span> <span>int</span><span>&amp;</span> key<span>)</span> <span>{</span></span>
<span id="cb5-17">  <span>static</span> std<span>::</span>map<span>&lt;</span><span>int</span>, <span>int</span><span>&gt;</span> map;</span>
<span id="cb5-18">  <span>return</span> map<span>[</span>key<span>]</span>;</span>
<span id="cb5-19"><span>}</span></span></code></pre></div>
<p>These three functions have different lifetime requirements, which are
indicated by comments. This information is available to developers but
not to the compiler. What’s the strategy to uphold these lifetime
requirements? Read the documentation, read the code, and <em>don’t make
mistakes</em>.</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb6-2">  std<span>::</span>map<span>&lt;</span><span>int</span>, <span>int</span><span>&gt;</span> map;</span>
<span id="cb6-3"></span>
<span id="cb6-4">  <span>// r4 is constrained by lifetimes of map and 40.</span></span>
<span id="cb6-5">  <span>int</span><span>&amp;</span> r4 <span>=</span> f4<span>(</span>map, <span>40</span><span>)</span>;</span>
<span id="cb6-6"></span>
<span id="cb6-7">  <span>// *Incorrectly* rejects usage of r4. r4 is constrained to the lifetime</span></span>
<span id="cb6-8">  <span>// of the temporary 40, which expired at the end of the above statement.</span></span>
<span id="cb6-9">  <span>int</span> x <span>=</span> r4;</span>
<span id="cb6-10"></span>
<span id="cb6-11">  <span>// r5 is constrained by lifetimes of 50 and 51.</span></span>
<span id="cb6-12">  <span>const</span> <span>int</span><span>&amp;</span> r5 <span>=</span> f5<span>(</span><span>50</span>, <span>51</span><span>)</span>;</span>
<span id="cb6-13"></span>
<span id="cb6-14">  <span>// *Correctly* rejects usage of r5. The reference refers to one of the</span></span>
<span id="cb6-15">  <span>// two expired temporaries. This use would be a use-after-free.</span></span>
<span id="cb6-16">  <span>int</span> y <span>=</span> r5;</span>
<span id="cb6-17"></span>
<span id="cb6-18">  <span>// r6 is constrained by the lifetime of 60.</span></span>
<span id="cb6-19">  <span>const</span> <span>int</span><span>&amp;</span> r6 <span>=</span> f6<span>(</span><span>60</span><span>)</span>;</span>
<span id="cb6-20"></span>
<span id="cb6-21">  <span>// *Incorrectly* rejects usage of r6.</span></span>
<span id="cb6-22">  <span>// The return reference r6 should not be constrained by the lifetime of 60.</span></span>
<span id="cb6-23">  <span>int</span> z <span>=</span> r6;</span>
<span id="cb6-24"><span>}</span></span></code></pre></div>
<p>Profiles take a similarly conservative approach to lifetimes as they
do with aliasing. The lifetime of a returned reference is constrained by
the lifetimes of <em>all of its arguments</em>. This is fortuitous for a
function like
<code>std<span>::</span>min</code>,
which returns a reference to either of its function parameters. It’s bad
for a function like <code>std<span>::</span>map<span>&lt;</span>T<span>&gt;::</span><span>operator</span><span>[]</span></code>,
which takes a key argument by reference but returns a reference that’s
only constrained by the lifetime of
<code><span>this</span></code>.</p>
<p>Since the compiler has no information about function parameter
lifetimes, it can’t accurately flag out-of-contract function calls.
<code>f4</code> and
<code>f6</code> take references to temporary
objects but return references that should not be constrained to that
temporary. In both cases, the safety profile rejects a subsequent use of
the reference as a use-after-free, because it applies a too-conservative
convention.</p>
<p>The need for explicit lifetime information in function types is the
motivation for Rust’s lifetime arguments. A returned reference must be
annotated with a lifetime parameter that is constrained by a function
parameter on the same function, or it must be static. The alternative is
to be deluged with an impossible quantity of use-after-free false
positives.</p>
<p><a href="https://godbolt.org/z/4c84ofavY">(Compiler Explorer)</a></p>
<div id="cb7"><pre><code><span id="cb7-1"><span>#include </span><span>&lt;map&gt;</span></span>
<span id="cb7-2"><span>#include </span><span>&lt;utility&gt;</span></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>const</span> <span>int</span><span>&amp;</span> f4<span>(</span>std<span>::</span>map<span>&lt;</span><span>int</span>, <span>int</span><span>&gt;&amp;</span> map, <span>const</span> <span>int</span><span>&amp;</span> key<span>)</span> <span>{</span></span>
<span id="cb7-5">  <span>return</span> map<span>[</span>key<span>]</span>;</span>
<span id="cb7-6"><span>}</span></span>
<span id="cb7-7"></span>
<span id="cb7-8"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb7-9">  std<span>::</span>map<span>&lt;</span><span>int</span>, <span>int</span><span>&gt;</span> map;</span>
<span id="cb7-10">  <span>const</span> <span>int</span><span>&amp;</span> ref <span>=</span> f4<span>(</span>map, <span>200</span><span>)</span>;</span>
<span id="cb7-11">  <span>int</span> x <span>=</span> ref;</span>
<span id="cb7-12"><span>}</span></span></code></pre></div>
<div id="cb8"><pre><code><span id="cb8-1">&lt;source&gt;:11:11: warning: dereferencing a dangling pointer [-Wlifetime]</span>
<span id="cb8-2">  int x = ref;</span>
<span id="cb8-3">          ^~~</span>
<span id="cb8-4">&lt;source&gt;:10:32: note: temporary was destroyed at the end of the full expression</span>
<span id="cb8-5">  const int&amp; ref = f4(map, 200);</span>
<span id="cb8-6">                               ^</span></code></pre></div>
<p>The Safety Profiles reference implementation can’t accurately deal
with lifetimes because C++ doesn’t provide lifetime information. The
tool doesn’t test for correctness, it only tests if your code conforms
to a pre-chosen convention.</p>
<h2 data-number="2.3" id="inferring-safeness"> Inferring safeness<a href="#inferring-safeness"></a></h2>
<blockquote>
<p><em>We should not require a <code>safe</code>
function annotation that has the semantics that a
<code>safe</code> function can only call other
<code>safe</code> functions.</em></p>
<p>– (Re)affirm design principles for future C++ evolution<span data-cites="P3446R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3446r0.pdf" role="doc-biblioref">P3446R0</a>]</span></p>
</blockquote>
<p>Recall what “safe” actually means:</p>
<ul>
<li>A <em>safe function</em> has defined behavior for all valid
inputs.</li>
<li>An <em>unsafe function</em> has soundness preconditions. Calling an
unsafe function with out-of-contract inputs may result in undefined
behavior.</li>
</ul>
<p>A C++ compiler can infer nothing about safeness from a function
declaration. It can’t by tell by looking what constitutes an
out-of-contract call and what doesn’t. A <em>safe-specifier</em>
indicates the presence of soundness preconditions. An
<em>unsafe-block</em> permits the user to escape the safe context, prove
the preconditions, and call the unsafe function.</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>template</span><span>&lt;</span><span>typename</span> T<span>&gt;</span></span>
<span id="cb9-2"><span>class</span> vector <span>{</span></span>
<span id="cb9-3"><span>public</span><span>:</span></span>
<span id="cb9-4">  <span>size_t</span> size<span>()</span> <span>const</span> <span>noexcept</span> safe <span>{</span></span>
<span id="cb9-5">    <span>return</span> _len;</span>
<span id="cb9-6">  <span>}</span></span>
<span id="cb9-7"></span>
<span id="cb9-8">  T<span>&amp;</span> <span>operator</span><span>[](</span><span>size_t</span> index<span>)</span> <span>noexcept</span> safe <span>{</span></span>
<span id="cb9-9">    <span>// Can call size() because it's a safe function.</span></span>
<span id="cb9-10">    <span>if</span><span>(</span>index <span>&gt;=</span> size<span>())</span></span>
<span id="cb9-11">      panic<span>(</span><span>"Out-of-bounds vector::operator[]"</span><span>)</span>;</span>
<span id="cb9-12"></span>
<span id="cb9-13">    unsafe <span>{</span></span>
<span id="cb9-14">      <span>// Pointer operations only allowed in unsafe context.</span></span>
<span id="cb9-15">      <span>// Safety proof:</span></span>
<span id="cb9-16">      <span>// The allocation has size() valid elements and index &lt; size().</span></span>
<span id="cb9-17">      <span>return</span> _data<span>[</span>index<span>]</span>;</span>
<span id="cb9-18">    <span>}</span></span>
<span id="cb9-19">  <span>}</span></span>
<span id="cb9-20"></span>
<span id="cb9-21"><span>private</span><span>:</span></span>
<span id="cb9-22">  T<span>*</span> _data;</span>
<span id="cb9-23">  <span>size_t</span> _len, _cap;</span>
<span id="cb9-24"><span>}</span>;</span></code></pre></div>
<p>Let’s take a really simple case: <code>vector<span>::</span><span>operator</span><span>[]</span></code>.
Profiles have to reject pointer arithmetic, because there’s no static
analysis protection against indexing past the end of the allocation. How
is the compiler told to permit the raw pointer subscript in the
<em>return-statement</em> in <code>vector<span>::</span><span>operator</span><span>[]</span></code>?
In Rust and Safe C++, enter an <em>unsafe-block</em>.</p>
<p>This design distinguishes safe functions, which have no soundness
preconditions and can be called from other safe functions, and unsafe
functions, which require an <em>unsafe-block</em> escape to use, just
like pointer operations.</p>
<p>Separation of safe and unsafe functions is common in memory-safe
languages. Rust and C#<span data-cites="csharp">[<a href="https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/unsafe" role="doc-biblioref">csharp</a>]</span> include an
<code>unsafe</code> function specifier and an
<em>unsafe-block</em> construct. This is a human- and tooling-readable
tag for auditing potential origins of soundness defects. Aliasing and
lifetimes are transitive properties that must be recoverable from a
function declaration in order to be upheld. Safeness (the lack of
soundness preconditions) is another transitive property that must be
marked in a function declaration. The way to do that is with a
<em>safe-specifier</em>.</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>template</span><span>&lt;</span> <span>class</span> RandomIt <span>&gt;</span></span>
<span id="cb10-2"><span>void</span> sort<span>(</span> RandomIt first, RandomIt last <span>)</span>;</span></code></pre></div>
<p>Let’s consider another example: the
<code>std<span>::</span>sort</code>
API that takes two random-access iterators. This is an <em>unsafe</em>
function because it exhibits undefined behavior if called with the wrong
arguments. But there’s nothing in the type system to indicate that it
has soundness preconditions, so the compiler doesn’t know to reject
calls in safe contexts.</p>
<p>What are <code>sort</code>’s
preconditions?</p>
<ul>
<li>The <code>first</code> and
<code>last</code> iterators must point at
elements from the same container.</li>
<li><code>first</code> must not indicate an
element that appears after
<code>last</code>.</li>
<li><code>first</code> and
<code>last</code> may not be dangling
iterators.</li>
</ul>
<p>In the absence of a enforced safeness information, it’s up to the
user to follow the documentation and satisfy the requirements. Guidance
for calling unsafe functions is essentially “don’t write bugs.”</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>void</span> func<span>(</span>std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec1, std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec2<span>)</span> <span>{</span></span>
<span id="cb11-2">  <span>// #1 - *Incorrectly* rejects correct call for mutable aliasing</span></span>
<span id="cb11-3">  sort<span>(</span>vec1<span>.</span>begin<span>()</span>, vec1<span>.</span>end<span>())</span>;</span>
<span id="cb11-4"></span>
<span id="cb11-5">  <span>// #2 - *Incorrectly* permits out-of-contract call.</span></span>
<span id="cb11-6">  sort<span>(</span>vec1<span>.</span>begin<span>()</span>, vec2<span>.</span>end<span>())</span>;</span>
<span id="cb11-7"><span>}</span></span></code></pre></div>
<p>In the Profiles model, the correct call to
<code>sort</code> #1 is rejected due to mutable
aliasing. That’s bad, but permitting the out-of-contract call #2 is
worse, because it’s a soundness bug. There’s no realistic static
analysis technology to verify that a call to
<code>sort</code> meets its preconditions. Even
the safety profile with the most conservative aliasing setting lets this
call through.</p>
<p>This is where <code>safe</code> and
<code>unsafe</code> specifiers play an important
role. From the caller’s perspective,
<code>sort</code> is unsafe because it has
preconditions that must be upheld without the compiler’s help. From the
callee’s perspective, <code>sort</code> is unsafe
because it’s written with <em>unsafe operations</em>. Pointer
differencing computes a pivot for the sort, and pointer differencing is
undefined when its operands point to different allocations.</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>// No safe-specifier means unsafe.</span></span>
<span id="cb12-2"><span>void</span> sort<span>(</span>vector<span>&lt;</span><span>int</span><span>&gt;::</span>iterator begin, vector<span>&lt;</span><span>int</span><span>&gt;::</span>iterator end<span>)</span>;</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span>// A safe-specifier means it can only call safe functions.</span></span>
<span id="cb12-5"><span>void</span> func<span>(</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec1, vector<span>&lt;</span><span>int</span><span>&gt;</span> vec2<span>)</span> safe <span>{</span></span>
<span id="cb12-6">  <span>// Ill-formed: sort is an unsafe function.</span></span>
<span id="cb12-7">  <span>// Averts potential undefined behavior.</span></span>
<span id="cb12-8">  sort<span>(</span>vec1<span>.</span>begin<span>()</span>, vec2<span>.</span>end<span>())</span>;</span>
<span id="cb12-9"></span>
<span id="cb12-10">  unsafe <span>{</span></span>
<span id="cb12-11">    <span>// Well-formed: call unsafe function from unsafe context.</span></span>
<span id="cb12-12">    <span>// Safety proof:</span></span>
<span id="cb12-13">    <span>// sort requires both iterators point into the same container.</span></span>
<span id="cb12-14">    <span>// Here, they both point into vec1.</span></span>
<span id="cb12-15">    sort<span>(</span>vec1<span>.</span>begin<span>()</span>, vec1<span>.</span>end<span>())</span>;</span>
<span id="cb12-16">  <span>}</span></span>
<span id="cb12-17"><span>}</span></span></code></pre></div>
<p>The only way to enforce memory safety is to separate safe and unsafe
functions with a <em>safe-specifier</em>. In this example,
<code>func</code> is <em>safe</em> because it’s
defined for all valid inputs. It cannot call
<code>sort</code>, because that has soundness
preconditions: the two iterators must point into the same container. A
call to <code>sort</code> in a safe context
leaves the program ill-formed, because the compiler cannot guarantee
that the preconditions are satisfied. But by entering an
<em>unsafe-block</em>, the user can prove the preconditions and make the
unsafe call <em>without the compiler’s soundness guarantees</em>.</p>
<p><span data-cites="P3081R0">[<a href="https://isocpp.org/files/papers/P3081R0.pdf" role="doc-biblioref">P3081R0</a>]</span> does float a <code><span>[[</span><span>suppress</span><span>(</span><span>profile</span><span>)]]</span></code>
attribute to turn off certain Profiles checkes. It looks like the
equivalent of an <em>unsafe-block</em>. It may permit pointer operations
in a definition, but it doesn’t address the other side of the call:
without a <em>safe-specifier</em>, how does the Profiles design deal
with functions like <code>sort</code> that are
<em>inherently unsafe</em>? They must be separated from provably safe
functions. User intervention, wrapped up in <em>unsafe-blocks</em>, is
needed to satisfy their preconditions. Without this bump of impedance
the language cannot guarantee safety, as the property that a safe
functions contains no undefined behavior is not transitively upheld.</p>
<p><a href="https://godbolt.org/z/c7Ko3bnG8">(Compiler Explorer)</a></p>
<div id="cb13"><pre><code><span id="cb13-1"><span>#include </span><span>&lt;memory&gt;</span></span>
<span id="cb13-2"><span>#include </span><span>&lt;vector&gt;</span></span>
<span id="cb13-3"><span>#include </span><span>&lt;algorithm&gt;</span></span>
<span id="cb13-4"></span>
<span id="cb13-5"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb13-6">  std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> v1, v2;</span>
<span id="cb13-7">  v1<span>.</span>push_back<span>(</span><span>1</span><span>)</span>;</span>
<span id="cb13-8">  v2<span>.</span>push_back<span>(</span><span>2</span><span>)</span>;</span>
<span id="cb13-9">  </span>
<span id="cb13-10">  <span>// UB!</span></span>
<span id="cb13-11">  std<span>::</span>sort<span>(</span>v1<span>.</span>end<span>()</span>, v2<span>.</span>end<span>())</span>;</span>
<span id="cb13-12"><span>}</span></span></code></pre></div>
<div id="cb14"><pre><code><span id="cb14-1">Program returned: 139</span>
<span id="cb14-2">double free or corruption (out)</span>
<span id="cb14-3">Program terminated with signal: SIGSEGV</span></code></pre></div>
<p>The Safety Profiles reference implementation can’t deal with unsafe
functions, because C++ doesn’t know which functions are unsafe. This
out-of-contract call produces a heap double-free and then segfaults.</p>
<h2 data-number="3" id="lifetime-safety-is-static-typing"> Lifetime safety is static
typing<a href="#lifetime-safety-is-static-typing"></a></h2>
<blockquote>
<p><em>Do not add a feature that requires viral annotation.</em></p>
<p>– (Re)affirm design principles for future C++ evolution<span data-cites="P3446R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3446r0.pdf" role="doc-biblioref">P3446R0</a>]</span></p>
</blockquote>
<p>Rust’s safety model incorporates lifetime arguments on every
reference (or struct with reference semantics) that occurs in a function
type. The authors of Profiles disparagingly call these “viral
annotations.” Don’t be scared. C++ has always been full of viral
annotations: <strong>types are viral annotations</strong>.</p>
<p>Types establish type safety properties that are enforced by both the
caller and callee. These properties are <em>transitive</em>
(i.e.&nbsp;<em>viral</em>) because they’re enforced through any number of
function calls, creating a <em>network of reasoning</em> from the point
where an object is created to all of its uses.</p>
<p>Languages that treat types as viral annotations are
<em>statically-typed languages</em>. Languages that don’t are
<em>dynamically-typed languages</em>. These have well-known trade-offs.
Statically-typed languages exhibit higher performance and provide more
information to developers; programs in a statically-typed language may
be easier to reason about. Dynamically-typed languages are much simpler
and can be more productive.</p>
<p>Lifetime parameters, which provide crucial information to the
compiler to enable rigorous safety analysis, defines another axis of
<em>typing</em>. Rust has <em>static lifetimes</em>, which is a
high-performance, high-information approach to memory safety. Users can
reason about lifetimes and aliasing because those concepts are built
into the language. The compiler has sufficient information to rigorously
enforce lifetime safety with <em>borrow checking</em>.</p>
<p>Most other memory-safe languages use <em>dynamic lifetimes</em>, of
which <em>garbage collection</em> is an implementation. Instead of
enforcing lifetimes and exclusivity at compile time, the garbage
collector manages objects on the heap and extends their scope as long as
there are live references to them. This has the same basic trade-off as
<em>dynamic typing</em>: simplicity at the cost of performance.</p>
<table>
<tbody><tr><th>
</th>
<th>
Static lifetimes
</th>
<th>
Dynamic lifetimes
</th>
</tr><tr>
<th>
Static types
</th>
<td>
Rust
</td>
<td>
Java, Go
</td>
</tr>
<tr>
<th>
Dynamic types
</th>
<td>
-
</td>
<td>
Javascript, Python
</td>
</tr>
</tbody></table>
<p>The static types/static lifetimes quadrant is a new area of language
design, at least for languages widely used in production. The principles
may be unfamiliar. Lifetime annotations feel different than type
annotations because they establish relationships <em>between</em>
parameters and return types rather than on individual parameters and
objects. Instead of answering the question “What are the properties of
this entity?” they answer “How does this entity relate to other
entities?”.</p>
<p>Profiles fail because they reject, as a design principle, the
specific language improvements that provide necessary lifetime
information for compile-time safety.</p>
<h2 data-number="4" id="lifetime-parameters-dont-cause-soundness-bugs"> Lifetime parameters don’t cause
soundness bugs<a href="#lifetime-parameters-dont-cause-soundness-bugs"></a></h2>
<blockquote>
<p><em>Annotations are distracting, add verbosity, and some can be wrong
(introducing the kind of errors they are assumed to help
eliminate).</em></p>
<p>– Profile invalidation - eliminating dangling pointers<span data-cites="P3446R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3446r0.pdf" role="doc-biblioref">P3446R0</a>]</span></p>
</blockquote>
<p>This is not right. In a memory-safe language you can’t introduce
undefined behavior with mere coding mistakes. That’s the whole point of
memory safety. If you put the wrong lifetime annotation on a parameter,
your program becomes ill-formed, not undefined. A mistaken use of
lifetime parameters can be an ergonomics bug, or it can mask undefined
behavior when wrapping an unsafe function in a safe interface, but it
can’t cause undefined behavior.</p>
<p><a href="https://godbolt.org/z/MYW6x693P">(Compiler Explorer)</a></p>
<div id="cb1"><pre><code><span id="cb1-1"><span>fn</span> f1<span>&lt;</span><span>'a</span><span>,</span> <span>'b</span><span>&gt;</span>(x<span>:&amp;</span><span>'a</span> <span>i32</span><span>,</span> y<span>:&amp;</span><span>'b</span> <span>i32</span>) <span>-&gt;</span> <span>&amp;</span><span>'b</span> <span>i32</span> <span>{</span></span>
<span id="cb1-2">  <span>return</span> x<span>;</span></span>
<span id="cb1-3"><span>}</span></span></code></pre></div>
<div id="cb15"><pre><code><span id="cb15-1">error: lifetime may not live long enough</span>
<span id="cb15-2"> --&gt; lifetime1.rs:5:10</span>
<span id="cb15-3">  |</span>
<span id="cb15-4">4 | fn f1&lt;'a, 'b&gt;(x:&amp;'a i32, y:&amp;'b i32) -&gt; &amp;'b i32 {</span>
<span id="cb15-5">  |       --  -- lifetime `'b` defined here</span>
<span id="cb15-6">  |       |</span>
<span id="cb15-7">  |       lifetime `'a` defined here</span>
<span id="cb15-8">5 |   return x;</span>
<span id="cb15-9">  |          ^ function was supposed to return data with lifetime `'b` but it is returning data with lifetime `'a`</span>
<span id="cb15-10">  |</span>
<span id="cb15-11">  = help: consider adding the following bound: `'a: 'b`</span></code></pre></div>
<p>Lifetime constraints are a contract between the caller and callee. If
either side violates the contract, the program is ill-formed. In the
code above, the lifetime constraints are violated by the callee. The
lifetime of the <code>x</code> parameter does not
outlive the lifetime of the returned reference. We used the wrong
annotation, but instead of leading to undefined behavior, the compiler
produces a detailed message that explains how the lifetime contract was
not met.</p>
<p><a href="https://godbolt.org/z/3YWvT7ce4">(Compiler Explorer)</a></p>
<div id="cb2"><pre><code><span id="cb2-1"><span>fn</span> f2<span>&lt;</span><span>'a</span><span>,</span> <span>'b</span><span>&gt;</span>(x<span>:&amp;</span><span>'a</span> <span>i32</span><span>,</span> y<span>:&amp;</span><span>'b</span> <span>i32</span>) <span>-&gt;</span> <span>&amp;</span><span>'b</span> <span>i32</span> <span>{</span></span>
<span id="cb2-2">  <span>// Well-formed. The lifetime on y outlives the lifetime on</span></span>
<span id="cb2-3">  <span>// the return reference.</span></span>
<span id="cb2-4">  <span>return</span> y<span>;</span></span>
<span id="cb2-5"><span>}</span></span>
<span id="cb2-6"></span>
<span id="cb2-7"><span>fn</span> f3() <span>{</span></span>
<span id="cb2-8">  <span>let</span> x <span>=</span> <span>1</span><span>;</span></span>
<span id="cb2-9">  <span>let</span> r<span>:&amp;</span><span>i32</span><span>;</span></span>
<span id="cb2-10">  <span>{</span></span>
<span id="cb2-11">    <span>let</span> y <span>=</span> <span>2</span><span>;</span></span>
<span id="cb2-12">    r <span>=</span> f2(<span>&amp;</span>x<span>,</span> <span>&amp;</span>y)<span>;</span></span>
<span id="cb2-13">  <span>}</span></span>
<span id="cb2-14"></span>
<span id="cb2-15">  <span>// Ill-formed: r depends on y, which is out of scope.</span></span>
<span id="cb2-16">  <span>let</span> z <span>=</span> <span>*</span>r<span>;</span></span>
<span id="cb2-17"><span>}</span></span></code></pre></div>
<div id="cb16"><pre><code><span id="cb16-1">error[E0597]: `y` does not live long enough</span>
<span id="cb16-2">  --&gt; lifetime2.rs:15:16</span>
<span id="cb16-3">   |</span>
<span id="cb16-4">14 |     let y = 2;</span>
<span id="cb16-5">   |         - binding `y` declared here</span>
<span id="cb16-6">15 |     r = f2(&amp;x, &amp;y);</span>
<span id="cb16-7">   |                ^^ borrowed value does not live long enough</span>
<span id="cb16-8">16 |   }</span>
<span id="cb16-9">   |   - `y` dropped here while still borrowed</span>
<span id="cb16-10">...</span>
<span id="cb16-11">19 |   let z = *r;</span>
<span id="cb16-12">   |           -- borrow later used here</span></code></pre></div>
<p>Let’s fix the implementation of the callee and test a broken version
of the caller. The returned reference depends on
<code>y</code>, but it’s used after
<code>y</code> goes out of scope. The compiler
rejects the program and tells us “<code>y</code>
does not live long enough.”</p>
<p>The use of lifetime annotations on parameters is the same as the use
of type annotations on parameters: it turns an intractable whole-program
analysis problem into an easy-to-enforce local-analysis problem.
Lifetime annotations, which exist to <em>guarantee</em> safety, do not
<em>jeopardize</em> safety.</p>
<h2 data-number="5" id="c-is-too-irregular-for-profiles"> C++ is too irregular for
Profiles<a href="#c-is-too-irregular-for-profiles"></a></h2>
<blockquote>
<p><em>Do not add a feature that requires heavy annotation. “Heavy”
means something like “more than 1 annotation per 1,000 lines of
code.”</em></p>
<p>– (Re)affirm design principles for future C++ evolution<span data-cites="P3446R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3446r0.pdf" role="doc-biblioref">P3446R0</a>]</span></p>
</blockquote>
<blockquote>
<p><em>We have an implemented approach that requires near-zero
annotation of existing source code.</em></p>
<p>– Pursue <span data-cites="P1179R1">[<a href="https://wg21.link/p1179r1" role="doc-biblioref">P1179R1</a>]</span> as a Lifetime TS<span data-cites="P3465R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3465r0.pdf" role="doc-biblioref">P3465R0</a>]</span></p>
</blockquote>
<p>Central to Safety Profiles is the claim that annotations are
exceptional rather than the norm. For this to be true, the great bulk of
C++ would need to be written according to some preferred convention.
<span data-cites="P1179R1">[<a href="https://wg21.link/p1179r1" role="doc-biblioref">P1179R1</a>]</span> chooses “no mutable aliasing”
and constrains reference return types to all reference parameters. Let’s
consider a number of Standard Library functions and compare their
aliasing and exclusivity requirements to those conventions. Functions
that don’t adhere to these conventions must be annotated, and those
annotations must be virally propagated up the stack to all callers, as
aliasing and lifetime requirements are transitive. Only functions that
have no soundness preconditions can be considered safe.</p>
<p>Let’s start in <code><span>&lt;</span>algorithm<span>&gt;</span></code>
and work through alphabetically, indicating how functions deviate from
the Safety Profile’s aliasing and lifetime conventions:</p>
<div id="cb17"><pre><code><span id="cb17-1"><span>// Unsafe!</span></span>
<span id="cb17-2"><span>// Precondition: `first` and `last` must alias.</span></span>
<span id="cb17-3"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> UnaryPred <span>&gt;</span></span>
<span id="cb17-4"><span>bool</span> all_of<span>(</span> InputIt first, InputIt last, UnaryPred p <span>)</span>;</span>
<span id="cb17-5"></span>
<span id="cb17-6"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> UnaryPred <span>&gt;</span></span>
<span id="cb17-7"><span>bool</span> any_of<span>(</span> InputIt first, InputIt last, UnaryPred p <span>)</span>;</span>
<span id="cb17-8"></span>
<span id="cb17-9"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> UnaryPred <span>&gt;</span></span>
<span id="cb17-10"><span>bool</span> none_of<span>(</span> InputIt first, InputIt last, UnaryPred p <span>)</span>;</span>
<span id="cb17-11"></span>
<span id="cb17-12"><span>// Unsafe!</span></span>
<span id="cb17-13"><span>// Precondition 1: `first` and `last` must alias.</span></span>
<span id="cb17-14"><span>// Lifetime: The return type is not constrained by the lifetime of `value`</span></span>
<span id="cb17-15"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> T <span>&gt;</span></span>
<span id="cb17-16">InputIt find<span>(</span> InputIt first, InputIt last, <span>const</span> T<span>&amp;</span> value <span>)</span>;</span>
<span id="cb17-17"></span>
<span id="cb17-18"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> UnaryPred <span>&gt;</span></span>
<span id="cb17-19">InputIt find_if<span>(</span> InputIt first, InputIt last, UnaryPred p <span>)</span>;</span>
<span id="cb17-20"></span>
<span id="cb17-21"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> UnaryPred <span>&gt;</span></span>
<span id="cb17-22">InputIt find_if_not<span>(</span> InputIt first, InputIt last, UnaryPred q <span>)</span>;</span>
<span id="cb17-23"></span>
<span id="cb17-24"><span>// Unsafe!</span></span>
<span id="cb17-25"><span>// Precondition 1: `first` and `last` must alias.</span></span>
<span id="cb17-26"><span>// Precondition 2: `s_first` and `s_last` must alias.</span></span>
<span id="cb17-27"><span>// Lifetime: The return type is not constrained by the lifetime of `s_first`</span></span>
<span id="cb17-28"><span>//   or `s_last`.</span></span>
<span id="cb17-29"><span>template</span><span>&lt;</span> <span>class</span> InputIt, <span>class</span> ForwardIt <span>&gt;</span></span>
<span id="cb17-30">InputIt find_first_of<span>(</span> InputIt first, InputIt last,</span>
<span id="cb17-31">  ForwardIt s_first, ForwardIt s_last <span>)</span>;</span>
<span id="cb17-32"></span>
<span id="cb17-33"><span>// Unsafe!</span></span>
<span id="cb17-34"><span>// Precondition 1: `first` and `last` must alias.</span></span>
<span id="cb17-35"><span>template</span><span>&lt;</span> <span>class</span> ForwardIt <span>&gt;</span></span>
<span id="cb17-36">ForwardIt adjacent_find<span>(</span> ForwardIt first, ForwardIt last <span>)</span>;</span>
<span id="cb17-37"></span>
<span id="cb17-38"><span>// Unsafe!</span></span>
<span id="cb17-39"><span>// Precondition 1: `first1` and `last2` must alias.</span></span>
<span id="cb17-40"><span>// Lifetime: The returned Input1 is constrained only by `first1` and `last1`</span></span>
<span id="cb17-41"><span>// Lifetime: The returned Input2 is constrained only by `first2`.</span></span>
<span id="cb17-42"><span>template</span><span>&lt;</span> <span>class</span> InputIt1, <span>class</span> InputIt2 <span>&gt;</span></span>
<span id="cb17-43">std<span>::</span>pair<span>&lt;</span>InputIt1, InputIt2<span>&gt;</span> mismatch<span>(</span> InputIt1 first1, InputIt1 last1,</span>
<span id="cb17-44">  InputIt2 first2 <span>)</span>;</span>
<span id="cb17-45"></span>
<span id="cb17-46"><span>// Unsafe!</span></span>
<span id="cb17-47"><span>// Precondition 1: `first` and `last` must alias.</span></span>
<span id="cb17-48"><span>// Precondition 2: `s_first` and `s_last` must alias.</span></span>
<span id="cb17-49"><span>// Lifetime: The returned ForwardIt1 is constrained only by `first` and `last`</span></span>
<span id="cb17-50"><span>template</span><span>&lt;</span> <span>class</span> ForwardIt1, <span>class</span> ForwardIt2 <span>&gt;</span></span>
<span id="cb17-51">ForwardIt1 search<span>(</span> ForwardIt1 first, ForwardIt1 last, ForwardIt2 s_first, </span>
<span id="cb17-52">  ForwardIt2 s_last <span>)</span>;</span></code></pre></div>
<p>The functions in <code><span>&lt;</span>algorithms<span>&gt;</span></code>
mostly involve iterators which are inherently unsafe. Additionally, the
lifetime convention chosen by Profiles is frequently wrong: the lifetime
of a returned reference rarely is constrained by the lifetimes of all
its parameters. You’d need annotations in all of these cases.</p>
<p>Consider these conventions against the API for a container. Let’s
look at <code><span>&lt;</span>map<span>&gt;</span></code>:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>// Aliasing: the `key` parameter may alias `*this`.</span></span>
<span id="cb18-2"><span>// Lifetimes: the returned T&amp; is only constrained by `*this` and not by `key`.</span></span>
<span id="cb18-3">T<span>&amp;</span> map<span>&lt;</span>Key, T<span>&gt;::</span>at<span>(</span> <span>const</span> Key<span>&amp;</span> key <span>)</span>;</span>
<span id="cb18-4">T<span>&amp;</span> map<span>&lt;</span>Key, T<span>&gt;::</span><span>operator</span><span>[](</span> <span>const</span> Key<span>&amp;</span> key <span>)</span>;</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span>// Aliasing: the `key` parameter may alias `*this`.</span></span>
<span id="cb18-7"><span>// Lifetimes: the returned iterator is only constrained by `*this` and not by</span></span>
<span id="cb18-8"><span>//   `value`.</span></span>
<span id="cb18-9">iterator map<span>&lt;</span>Key, T<span>&gt;::</span>find<span>(</span> <span>const</span> Key<span>&amp;</span> key <span>)</span>;</span>
<span id="cb18-10">iterator map<span>&lt;</span>Key, T<span>&gt;::</span>lower_bound<span>(</span> <span>const</span> Key<span>&amp;</span> key <span>)</span>;</span>
<span id="cb18-11">iterator map<span>&lt;</span>Key, T<span>&gt;::</span>upper_bound<span>(</span> <span>const</span> Key<span>&amp;</span> key <span>)</span>;</span>
<span id="cb18-12"></span>
<span id="cb18-13"><span>// Aliasing: the `value` parameter may alias `*this`.</span></span>
<span id="cb18-14"><span>// Lifetimes: the returned iterator is only constrained by `*this` and not by</span></span>
<span id="cb18-15"><span>//   `value`.</span></span>
<span id="cb18-16">std<span>::</span>pair<span>&lt;</span>iterator, <span>bool</span><span>&gt;</span> map<span>&lt;</span>Key, T<span>&gt;::</span>insert<span>(</span> <span>const</span> value_type<span>&amp;</span> value <span>)</span>;</span>
<span id="cb18-17"></span>
<span id="cb18-18"><span>// Unsafe!</span></span>
<span id="cb18-19"><span>// Precondition 1: `pos` must point into `*this`</span></span>
<span id="cb18-20"><span>// Aliasing: the `value` parameter may alias `*this` or `pos`</span></span>
<span id="cb18-21"><span>// Lifetimes: The returned iterator is only constrained by `*this` and not by</span></span>
<span id="cb18-22"><span>//   `value`.</span></span>
<span id="cb18-23">iterator map<span>&lt;</span>Key, T<span>&gt;::</span>insert<span>(</span> iterator pos, <span>const</span> value_type<span>&amp;</span> value <span>)</span>;</span>
<span id="cb18-24"></span>
<span id="cb18-25"><span>// Aliasing: The `k` and `obj` parameters may alias `*this`.</span></span>
<span id="cb18-26"><span>// Lifetimes: The returned iterator is only constrained by `*this` and not by </span></span>
<span id="cb18-27"><span>//   `k` or `value`.</span></span>
<span id="cb18-28"><span>template</span><span>&lt;</span> <span>class</span> M <span>&gt;</span></span>
<span id="cb18-29">std<span>::</span>pair<span>&lt;</span>iterator, <span>bool</span><span>&gt;</span> map<span>&lt;</span>Key, T<span>&gt;::</span>insert_or_assign<span>(</span> <span>const</span> Key<span>&amp;</span> k, M<span>&amp;&amp;</span> obj <span>)</span></span>
<span id="cb18-30"></span>
<span id="cb18-31"><span>// Unsafe!</span></span>
<span id="cb18-32"><span>// Precondition 1: `hint` must point into `*this`</span></span>
<span id="cb18-33"><span>// Aliasing: The `k` and `obj` parameters may alias `*this` and `hint`.</span></span>
<span id="cb18-34"><span>// Lifetimes: The returned iterator is only constrained by `*this` and not by</span></span>
<span id="cb18-35"><span>//   `k` or `value`.</span></span>
<span id="cb18-36"><span>template</span><span>&lt;</span> <span>class</span> M <span>&gt;</span></span>
<span id="cb18-37">iterator insert_or_assign<span>(</span> const_iterator hint, <span>const</span> Key<span>&amp;</span> k, M<span>&amp;&amp;</span> obj <span>)</span>;</span></code></pre></div>
<p>This is only a few of the <code>map</code>
APIs which would either be unsafe or require annotations in the Profiles
model. The conservative aliasing rules gets most member functions wrong:
a reference returned from a member function is typically constrained
only by the <code><span>*</span><span>this</span></code>/<code>self</code>
parameter. That’s what Rust’s lifetime elision rules do. Regardless of
the convention chosen, expect annotations every time the function does
something different. With C++ code, it does something different <em>very
often</em>.</p>
<div id="cb19"><pre><code><span id="cb19-1"><span>#include </span><span>&lt;map&gt;</span></span>
<span id="cb19-2"></span>
<span id="cb19-3"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb19-4">  std<span>::</span>map<span>&lt;</span><span>int</span>, <span>int</span><span>&gt;</span> m;</span>
<span id="cb19-5">  m<span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span>;</span>
<span id="cb19-6">  </span>
<span id="cb19-7">  <span>// Temporary 1 expires. Profiles considers `value` a dangling reference.</span></span>
<span id="cb19-8">  <span>int</span><span>&amp;</span> value <span>=</span> m<span>[</span><span>1</span><span>]</span>;</span>
<span id="cb19-9"></span>
<span id="cb19-10">  <span>// Profiles should flag this apparent use-after-free.</span></span>
<span id="cb19-11">  value <span>=</span> <span>2</span>;</span>
<span id="cb19-12"><span>}</span></span></code></pre></div>
<p>Profile’s inability to deal accurately with lifetimes means that an
implementation would reject much valid code. In this example the
subscript to <code>map<span>::</span><span>operator</span><span>[]</span></code>
is a temporary. It goes out of scope at the end of the statement. Under
the Profile’s conservative lifetime convention, the returned reference
(stored in <code>value</code>) would be
considered a dangling reference and the subsequent use would make the
program ill-formed.</p>
<p>I do not believe that C++ code, with its countless unstated soundness
preconditions and inconsistent aliasing and lifetime requirements, can
be made memory safe with fewer than “1 annotation per 1,000 lines of
code.” In fact, legacy C++ code will have <em>many more</em> annotations
than equivalent Rust code. Rust often chooses object relocation to pass
parameters by value rather than pass them by reference. This reduces the
number of lifetime constraints that the system deals with. Additionally,
it has simpler, <em>safe versions</em> of facilities which are unsafe in
C++: the Rust iterator, for example, keeps both the data pointer and
length in the same struct to completely alleviate the aliasing concerns
that prevent safety analysis in C++.</p>
<h2 data-number="5.1" id="c-cannot-enforce-exclusivity"> C++ cannot enforce
exclusivity<a href="#c-cannot-enforce-exclusivity"></a></h2>
<p>The density of annotations required to vet existing code is not the
biggest problem facing Profiles. C++ overload resolution has created a
knot that cannot be untangled. Its standard conversion rules are one
reason why C++ is considered <em>inherently unsafe</em>.</p>
<p>For many accessor-style C++ APIs, there are two overloads:</p>
<ol type="1">
<li>A candidate that binds a <em>const</em> object and a returns a
<em>const</em> reference (or pointer or iterator).</li>
<li>A candidate that binds a <em>mutable</em> object and returns a
<em>mutable</em> reference (or pointer or iterator).</li>
</ol>
<p>If the mutable candidate <em>can</em> be chosen, <em>it is</em>
chosen, no matter what the result object is used for.</p>
<div id="cb20"><pre><code><span id="cb20-1"><span>void</span> f1<span>(</span><span>const</span> <span>int</span><span>&amp;</span> x, <span>const</span> <span>int</span><span>&amp;</span> y<span>)</span>;</span>
<span id="cb20-2"></span>
<span id="cb20-3"><span>void</span> f2<span>(</span>std<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec<span>)</span> <span>{</span></span>
<span id="cb20-4">  <span>// The mutable overload of operator[] is called here.</span></span>
<span id="cb20-5">  f1<span>(</span>vec<span>[</span><span>0</span><span>]</span>, vec<span>[</span><span>1</span><span>])</span>;</span>
<span id="cb20-6"><span>}</span></span></code></pre></div>
<p>This code will not pass an exclusivity test.
<code>vec</code> is a mutable object, so <code>vec<span>[</span><span>0</span><span>]</span></code>
calls the mutable version of <code><span>operator</span><span>[]</span></code>
and produces a mutable reference result object. <em>While that mutable
loan is in scope</em> (it remains in scope until
<code>f1</code> returns), <code>vec<span>[</span><span>1</span><span>]</span></code>
calls the mutable version of <code><span>operator</span><span>[]</span></code>
to produce its mutable reference result object. But you’re not allowed
more than one mutable reference to the same place. <em>This is an
exclusivity error!</em></p>
<p>Rust avoids this problem in two ways:</p>
<ul>
<li>In general there is no function overloading. As a convention, if
there are mutable and const versions of a function, the mutable one is
named with a <code>_mut</code> suffix.</li>
<li>There is syntax sugar which maps subscript operations to either
<code>index</code> or
<code>index_mut</code>. The latter is chosen in a
<em>mutable context</em>, which is the left-hand side of an
assignment.</li>
</ul>
<p>We can’t ditch function overloading and remain C++. But we can change
how overload resolution evaluates candidates. The standard conversion is
responsible for binding references to expressions. C++ chooses the wrong
(for safety purposes) subscript candidate because the standard
conversion is able to bind mutable references to lvalue expressions.</p>
<p><a href="https://godbolt.org/z/K3b8hP1W5">(Compiler Explorer)</a></p>
<div id="cb21"><pre><code><span id="cb21-1"><span>void</span> f3<span>(</span><span>const</span> <span>int</span><span>^</span> x, <span>const</span> <span>int</span><span>^</span> y<span>)</span> safe;</span>
<span id="cb21-2"></span>
<span id="cb21-3"><span>int</span> main<span>()</span> safe <span>{</span></span>
<span id="cb21-4">  std2<span>::</span>vector<span>&lt;</span><span>int</span><span>&gt;</span> vec <span>{</span> <span>}</span>;</span>
<span id="cb21-5"></span>
<span id="cb21-6">  <span>// Okay.</span></span>
<span id="cb21-7">  f3<span>(</span>vec<span>[</span><span>0</span><span>]</span>, vec<span>[</span><span>1</span><span>])</span>;</span>
<span id="cb21-8"></span>
<span id="cb21-9">  <span>// Ill-formed: mutable borrow of vec between its mutable borrow and its use.</span></span>
<span id="cb21-10">  f3<span>(</span>mut vec<span>[</span><span>0</span><span>]</span>, mut vec<span>[</span><span>1</span><span>])</span>;</span>
<span id="cb21-11"><span>}</span></span></code></pre></div>
<div id="cb22"><pre><code><span id="cb22-1">safety: during safety checking of int main() safe</span>
<span id="cb22-2">  borrow checking: example.cpp:13:22</span>
<span id="cb22-3">    f3(mut vec[0], mut vec[1]); </span>
<span id="cb22-4">                       ^</span>
<span id="cb22-5">  mutable borrow of vec between its mutable borrow and its use</span>
<span id="cb22-6">  loan created at example.cpp:13:10</span>
<span id="cb22-7">    f3(mut vec[0], mut vec[1]); </span>
<span id="cb22-8">           ^</span></code></pre></div>
<p>Safe C++ changes the standard conversion to work around this language
defect. In this extension, <em>standard conversions do not bind mutable
references</em>. <code>vec<span>[</span><span>0</span><span>]</span></code>
chooses the <em>const</em> candidate, which permits aliasing, and <code>mut vec<span>[</span><span>0</span><span>]</span></code>
chooses the <em>mutable</em> candidate, which does not. By opting in to
mutation, you get aliasing by default.</p>
<p><a href="https://godbolt.org/z/9G9oj68Yx">(Compiler Explorer)</a></p>
<div id="cb23"><pre><code><span id="cb23-1"><span>#</span><span>feature on safety</span></span>
<span id="cb23-2"></span>
<span id="cb23-3"><span>int</span> main<span>()</span> safe <span>{</span></span>
<span id="cb23-4">  <span>int</span> x <span>=</span> <span>1</span>;</span>
<span id="cb23-5">  <span>int</span><span>^</span> ref <span>=</span> x;  <span>// Ill-formed! Can't bind mutable reference to lvalue.</span></span>
<span id="cb23-6"><span>}</span></span></code></pre></div>
<div id="cb24"><pre><code><span id="cb24-1">error: example.cpp:5:14</span>
<span id="cb24-2">  int^ ref = x; </span>
<span id="cb24-3">             ^</span>
<span id="cb24-4">cannot implicitly bind borrow int^ to lvalue int</span></code></pre></div>
<p>The <code>mut</code> keyword<span data-cites="mutation">[<a href="https://safecpp.org/draft.html#explicit-mutation" role="doc-biblioref">mutation</a>]</span> puts the subexpression into
<em>the mutable context</em> and restores the restricted functionality.
In the mutable context, the compiler will bind mutable references to
expression:</p>
<p><a href="https://godbolt.org/z/xYcW3hYrf">(Compiler Explorer)</a></p>
<div id="cb25"><pre><code><span id="cb25-1"><span>#</span><span>feature on safety</span></span>
<span id="cb25-2"></span>
<span id="cb25-3"><span>int</span> main<span>()</span> safe <span>{</span></span>
<span id="cb25-4">  <span>int</span> x <span>=</span> <span>1</span>;</span>
<span id="cb25-5">  <span>int</span><span>^</span> ref <span>=</span> mut x;  <span>// Ok. Can bind mutable references in mutable context.</span></span>
<span id="cb25-6"><span>}</span></span></code></pre></div>
<p>Now, the const overload of a function is chosen unless the user
escapes with the <code>mut</code> keyword. This
addresses a language defect head-on.</p>
<p>What option does Profiles have? In its full generality, the mutable
binding default makes for an exceptionally thorny analysis problem. Does
Profiles replace calls to mutable candidates with calls to
similarly-named const candidates? That’s a presumption. Does it
retroactively classify mutable loans as shared loans depending on usage?
I’m not a soundness maverick. This is getting close to touching a live
wire.</p>
<p>Legacy C++ errs on the side of mutability, making it too
unconstrained to test for soundness. Old code is what it is.</p>
<h2 data-number="6" id="carcinization"> Carcinization<a href="#carcinization"></a></h2>
<blockquote>
<p><em>The development of new product lines for use in service of
critical infrastructure or NCFs (national critical functions) in a
memory-unsafe language (e.g., C or C++) … is dangerous and significantly
elevates risk to national security, national economic security, and
national public health and safety.</em></p>
<p>– CISA, Product Security Bad Practices<span data-cites="cisa">[<a href="https://www.cisa.gov/resources-tools/resources/product-security-bad-practices" role="doc-biblioref">cisa</a>]</span></p>
</blockquote>
<p><span data-cites="P3466R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3466r0.pdf" role="doc-biblioref">P3466R0</a>]</span> insists that “we want to make
sure C++ evolution … hews to C++’s core principles.” But these are
<em>bad principles</em>. They make C++ extra vulnerable to memory safety
defects that are prevented in memory-safe languages. The US Government
implicates C++’s core principles as a danger to national security and
public health.</p>
<table>
<tbody><tr><th>
</th>
<th>
Static lifetimes
</th>
<th>
Dynamic lifetimes
</th>
</tr><tr>
<th>
Static types
</th>
<td>
Rust
</td>
<td>
Java, Go
</td>
</tr>
<tr>
<th>
Dynamic types
</th>
<td>
-
</td>
<td>
Javascript, Python
</td>
</tr>
</tbody></table>
<p>Reconsider this table. We want to evolve C++ to live in the static
types/static lifetimes quadrant. Since Rust is the only species in that
design family (at least among production languages), a new entry is
necessarily going to resemble Rust (at least in its memory safety
treatment) more than it does other languages. An earnest effort to
pursue <span data-cites="P1179R1">[<a href="https://wg21.link/p1179r1" role="doc-biblioref">P1179R1</a>]</span> as a Lifetime TS<span data-cites="P3465R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3465r0.pdf" role="doc-biblioref">P3465R0</a>]</span> will compromise on C++’s
outdated and unworkable core principles and adopt mechanisms more like
Rust’s. In the compiler business this is called <em>carcinization</em>:
a tendency of non-crab organisms to evolve crab-like features.</p>
<ul>
<li>Standard C++ doesn’t have aliasing information. We need <strong>a
new reference type</strong> that upholds the “mutation XOR aliasing”
rule as a program-wide invariant.</li>
<li>Standard C++ doesn’t have lifetime information. We need
<strong>lifetime parameters</strong> to indicate constraint
relationships between function parameters and return references.</li>
<li>Safety is a transitive property. It has to be upheld with a
<em><strong>safe-specifier</strong></em> on functions to establish the
absence of soundness preconditions and an
<em><strong>unsafe-block</strong></em> to call unsafe operations.</li>
<li>Lifetime constraints are a transitive property. They must be upheld
by both caller and callee as <strong>viral annotations</strong>.</li>
<li>Lifetime constraints on functions do not follow any particular
convention. Constraints that deviate from a default (such as the
lifetime elision rules) require annotation, even <strong>heavy
annotations</strong> that may exceed 1 per 1,000 lines of code.</li>
<li>The standard conversion rules make exclusivity enforcement
impossible. We have to change the language default, establishing
<strong>no implicit mutation</strong> in order to support aliasing in
functions that take const references.</li>
</ul>
<h2 data-number="7" id="c-in-the-future"> C++ in the future<a href="#c-in-the-future"></a></h2>
<blockquote>
<p><em>I think it is worth pursuing this compatible path first before,
or at least at the same time as, trying to graft another foreign
language’s semantics onto C++ which turns C++ into “something else”
and/or build an off-ramp from C++.</em></p>
<p>– Pursue <span data-cites="P1179R1">[<a href="https://wg21.link/p1179r1" role="doc-biblioref">P1179R1</a>]</span> as a Lifetime TS<span data-cites="P3465R0">[<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3465r0.pdf" role="doc-biblioref">P3465R0</a>]</span></p>
</blockquote>
<p>Who does this provincialism serve? The latest Android security study
“prioritizes transitioning to memory-safe languages.”<span data-cites="android-security">[<a href="https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html?m=1" role="doc-biblioref">android-security</a>]</span> The off-ramp from C++
is an increasingly viable and attractive strategy for projects looking
to reduce CVE exposure. The off-ramp is happening and its benefits are
measurable. As the Android study observes, “once we turn off the tap of
new vulnerabilities, they decrease exponentially, making all of our code
safer.”</p>
<p>All focus should be on turning off the tap of new vulnerabilities.
Incorporating Rust’s safety model into C++ helps in two ways:</p>
<ol type="1">
<li>It provides an off-ramp from unsafe C++ to Safe C++ within a single
toolchain. Projects can follow best practices for Safe Coding<span data-cites="safe-coding">[<a href="https://storage.googleapis.com/gweb-research2023-media/pubtools/7665.pdf" role="doc-biblioref">safe-coding</a>]</span> without retraining the
whole engineering staff in a new programming language.</li>
<li>It can hasten the migration to Rust by improving C++/Rust interop.
By extending C++ with representations of all Rust constructs that can
appear in function declarations (such as Rust enums, borrows and
lifetimes, ZSTs, traits, etc) the number of common vocabulary types is
greatly increased. This allows interop tooling to map between C++ and
Rust declarations at a more expressive level than the current C-level
API.</li>
</ol>
<p>C++ can be made memory safe, but not by dismissing everything that
works, which is what the authors of Safety Profiles do. The language
must evolve to be more explicit in how it expresses aliasing, lifetime
and safeness properties. C++ can meet the security needs of its users,
both in a principal role, and, for those projects determined to take the
off-ramp, in an important supporting role.</p>
<h2 data-number="8" id="bibliography"> References<a href="#bibliography"></a></h2>
<div id="refs" data-entry-spacing="1" role="doc-bibliography">




<div id="ref-P1179R1" role="doc-biblioentry"><p>
[P1179R1] Herb Sutter. 2019-11-22. Lifetime safety: Preventing common
dangling. </p><a href="https://wg21.link/p1179r1"><p>https://wg21.link/p1179r1</p></a>
</div>
<div id="ref-P3081R0" role="doc-biblioentry"><p>
[P3081R0] Core safety Profiles" Specification, adoptability, and impact.
</p><a href="https://isocpp.org/files/papers/P3081R0.pdf"><p>https://isocpp.org/files/papers/P3081R0.pdf</p></a>
</div>




<div id="ref-type-and-resource-safety-2015" role="doc-biblioentry"><p>
[type-and-resource-safety-2015] A brief introduction to C++"s model for
type- and resource- safety. </p><a href="https://www.stroustrup.com/resource-model.pdf"><p>https://www.stroustrup.com/resource-model.pdf</p></a>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing 787s must be reset every 51 days or 'misleading data' is shown to pilots (157 pts)]]></title>
            <link>https://www.theregister.com/2020/04/02/boeing_787_power_cycle_51_days_stale_data/</link>
            <guid>41939318</guid>
            <pubDate>Thu, 24 Oct 2024 20:19:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2020/04/02/boeing_787_power_cycle_51_days_stale_data/">https://www.theregister.com/2020/04/02/boeing_787_power_cycle_51_days_stale_data/</a>, See on <a href="https://news.ycombinator.com/item?id=41939318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The US Federal Aviation Administration has ordered Boeing 787 operators to switch their aircraft off and on every 51 days to prevent what it called "several potentially catastrophic failure scenarios" – including the crashing of onboard network switches.</p>
<p>The <a target="_blank" href="https://ad.easa.europa.eu/ad/US-2020-06-14">airworthiness directive</a>, due to be enforced from later this month, orders airlines to power-cycle their B787s before the aircraft reaches the specified days of continuous power-on operation.</p>
<p>The power cycling is needed to prevent stale data from populating the aircraft's systems, a problem that has occurred on different 787 systems in the past.</p>

    

<p>According to the directive itself, if the aircraft is powered on for more than 51 days this can lead to "display of misleading data" to the pilots, with that data including airspeed, attitude, altitude and engine operating indications. On top of all that, the stall warning horn and overspeed horn also stop working.</p>

        


        

<p>This alarming-sounding situation comes about because, for reasons the directive did not go into, the 787's common core system (CCS) stops filtering out stale data from key flight control displays. That stale data-monitoring function going down in turn "could lead to undetected or unannunciated loss of common data network (CDN) message age validation, combined with a CDN switch failure".</p>
<div>
<h2 title="Have you turned it off and on again? That's the way to stop the plane becoming a brick">Boeing 787 software bug can shut down planes' generators IN FLIGHT</h2>
<p><a href="https://www.theregister.com/2015/05/01/787_software_bug_can_shut_down_planes_generators/"><span>READ MORE</span></a></p></div>
<p>Solving the problem is simple: power the aircraft down completely before reaching 51 days. It is usual for commercial airliners to spend weeks or more continuously powered on as crews change at airports, or ground power is plugged in overnight while cleaners and maintainers do their thing.</p>
<p>The CDN is a Boeing avionics term for the 787's internal Ethernet-based network. It is built to a slightly more stringent aviation-specific standard than common-or-garden Ethernet, that standard being called ARINC 664. More about ARINC 664 can be read <a target="_blank" rel="nofollow" href="https://www.aim-online.com/products-overview/tutorials/afdx-arinc664p7-tutorial/">here</a>.</p>
<p>Airline pilots were sanguine about the implications of the failures when <i>El Reg</i> asked a handful about the directive. One told us: "Loss of airspeed data combined with engine instrument malfunctions isn't unheard of," adding that there wasn't really enough information in the doc to decide whether or not the described failure would be truly catastrophic. Besides, he said, the backup speed and attitude instruments are – for obvious reasons – completely separate from the main displays.</p>

        

<p>Another mused that loss of engine indications would make it harder to adopt the fallback drill of setting a known pitch and engine power <i>(see sidenote)</i> setting that guarantees safe straight-and-level flight while the pilots consult checklists and manuals to find a fix.</p>

<p>A third commented, tongue firmly in cheek: "Anything like that with the aircraft is unhealthy!"</p>
<p>A previous software bug forced airlines to <a target="_blank" href="https://www.theregister.com/2015/05/01/787_software_bug_can_shut_down_planes_generators/">power down</a> their 787s every 248 days for fear electrical generators could shut down in flight.</p>
<p>Airbus suffers from similar issues with its A350, with a relatively recent but since-patched bug <a target="_blank" href="https://www.theregister.com/2019/07/25/a350_power_cycle_software_bug_149_hours/">forcing power cycles every 149 hours</a>.</p>
<p>Persistent or unfiltered stale data is a known 787 problem. In 2014 a Japan Airlines 787 caught fire because of the (entirely separate, and since fixed) <a target="_blank" href="https://www.theregister.com/2013/01/17/faa_grounds_boeing_787_batteries/">lithium-ion battery problem</a>. Investigators realised the black boxes <a target="_blank" rel="nofollow" href="https://www.flightglobal.com/ntsb-details-issues-with-787-flight-and-data-recorder/115282.article">had been recording false information</a>, hampering their task, because they were falsely accepting stale old data as up-to-the-second real inputs.</p>

        

<p>More seriously, another 787 stale data problem in years gone by saw superseded backup flight plans persisting in standby navigation computers, and activating occasionally.</p>
<p>Activation caused the autopilot to wrongly decide it was halfway through flying a previous journey – and manoeuvre to regain the "correct" flight path. Another symptom was for the flight management system to simply go blank and freeze, triggered by selection of a standard arrival path (STAR) with exactly 14 waypoints – such as the BIMPA 4U approach to Poland's rather busy Warsaw Airport. The Polish air safety regulator <a target="_blank" href="https://regmedia.co.uk/2020/04/02/akt.pdf">published this mildly alarming finding in 2016</a> [2-page PDF, in Polish].</p>
<p>This was fixed through a software update, <a target="_blank" rel="nofollow" href="https://www.federalregister.gov/documents/2019/02/15/2019-02160/airworthiness-directives-the-boeing-company-airplanes">as the US Federal Aviation Administration reiterated last year</a>. In addition, Warsaw's BIMPA 4U approach has since been superseded.</p>
<p><i>The Register</i> asked Boeing to comment. ®</p>
<p>
  <i><b>Editor's note:</b> An earlier version of this article mentioned the Boeing 787 CCS uses a Wind River VxWorks real-time OS product at its heart. While this is true, Wind River has been in touch to remind us "the CCS is made up of 80 to 100 applications," as well as VxWorks, and said the bug described in this article is not the fault of its operating system.</i>
</p>
<p>
  <i>"The functions of VxWorks have nothing to do with the data issue you are highlighting in the 787," a spokesperson added. We are happy to clarify our coverage.</i>
</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brush – A new compatible Gaussian splatting engine (134 pts)]]></title>
            <link>https://github.com/ArthurBrussee/brush</link>
            <guid>41938831</guid>
            <pubDate>Thu, 24 Oct 2024 19:24:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ArthurBrussee/brush">https://github.com/ArthurBrussee/brush</a>, See on <a href="https://news.ycombinator.com/item?id=41938831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Brush - universal splats</h2><a id="user-content-brush---universal-splats" aria-label="Permalink: Brush - universal splats" href="#brush---universal-splats"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description teaser_compressed.mp4">teaser_compressed.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/7014262/379799498-b7f55b9c-8632-49f9-b34b-d5de52a7a8b0.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTc5OTQ5OC1iN2Y1NWI5Yy04NjMyLTQ5ZjktYjM0Yi1kNWRlNTJhN2E4YjAubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTNhNmNlZjkzMjkxMzg2YmIyMjNiM2Y5YzZiNWViNGNmNjkwODk4OTY1ZjU4NzYyM2NiZDc3YjkwNWZlY2FkMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.RT1nmwBsIcbZlSnnLeTkth8fXVH7XcPBKU4vvRULqxI" data-canonical-src="https://private-user-images.githubusercontent.com/7014262/379799498-b7f55b9c-8632-49f9-b34b-d5de52a7a8b0.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTc5OTQ5OC1iN2Y1NWI5Yy04NjMyLTQ5ZjktYjM0Yi1kNWRlNTJhN2E4YjAubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTNhNmNlZjkzMjkxMzg2YmIyMjNiM2Y5YzZiNWViNGNmNjkwODk4OTY1ZjU4NzYyM2NiZDc3YjkwNWZlY2FkMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.RT1nmwBsIcbZlSnnLeTkth8fXVH7XcPBKU4vvRULqxI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Brush is a 3D reconstruction engine, using <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" rel="nofollow">Gaussian splatting</a>. It aims to be highly portable, flexible and fast. 3D reconstruction shouldn't require special hardware. Brush can render and train on a wide range of systems: <strong>macOS/windows/linux</strong>, <strong>AMD/Nvidia</strong> cards, <strong>Android</strong>, and in a <strong>browser</strong>. To achieve this, brush is built using WebGPU compatible tech, that can run practically anywhere! It uses the <a href="https://github.com/tracel-ai/burn">Burn</a> framework, which has a portable <a href="https://github.com/gfx-rs/wgpu"><code>wgpu</code></a> backend. This project is currently still a proof of concept, and doesn't yet implement any of the extensions to gaussian splatting that have been developed, nor is the performance optimal yet.</p>
<p dir="auto"><a href="https://arthurbrussee.github.io/brush-demo" rel="nofollow"><strong>Try the (experimental) web demo</strong> <img src="https://camo.githubusercontent.com/d789da5bd9ba5cf1ca29eae6c7e20de946dcedcf344a3676c43add82fab516e5/68747470733a2f2f63646e2d69636f6e732d706e672e666c617469636f6e2e636f6d2f3235362f3838382f3838383834362e706e67" alt="chrome logo" width="24" data-canonical-src="https://cdn-icons-png.flaticon.com/256/888/888846.png">
</a></p>
<p dir="auto"><em>NOTE: This only works on desktop Chrome 129+ currently (Oct 2024). Firefox and Safari are hopefully supported <a href="https://caniuse.com/webgpu" rel="nofollow">soon</a>, but currently even firefox nightly and safari technical preview do not work</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">The demo can load pretrained ply splats, and can load datasets to train on. Currently only two formats are supported. A .zip file containing:</p>
<ul dir="auto">
<li>A transform_train.json and images, like the synthetic nerf scene dataset.</li>
<li>An <code>images</code> &amp; <code>sparse</code> folder with <a href="https://github.com/colmap/colmap"><code>COLMAP</code></a> data</li>
</ul>
<p dir="auto">While training you can interact with the splats and see their training dynamics live, and compare the current rendering to training / eval views as the training progresses.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Web</h2><a id="user-content-web" aria-label="Permalink: Web" href="#web"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description combined_compressed.mp4">combined_compressed.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/7014262/379765142-4c70f892-cfd2-419f-8098-b0e20dba23c7.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTc2NTE0Mi00YzcwZjg5Mi1jZmQyLTQxOWYtODA5OC1iMGUyMGRiYTIzYzcubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NDhlZjdiODEwNGZkNzM0MGI0MWVkYWFjM2EwNjdhYzEzZWNmMjA3MTc0NjkwMTE2OTliZWNjMDg4NTYwYjdmMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.d9KEEPkUE9vCdWJ5y03Uth0A1dObZvQhvost_HAvl30" data-canonical-src="https://private-user-images.githubusercontent.com/7014262/379765142-4c70f892-cfd2-419f-8098-b0e20dba23c7.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTc2NTE0Mi00YzcwZjg5Mi1jZmQyLTQxOWYtODA5OC1iMGUyMGRiYTIzYzcubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NDhlZjdiODEwNGZkNzM0MGI0MWVkYWFjM2EwNjdhYzEzZWNmMjA3MTc0NjkwMTE2OTliZWNjMDg4NTYwYjdmMSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.d9KEEPkUE9vCdWJ5y03Uth0A1dObZvQhvost_HAvl30" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Rerun</h2><a id="user-content-rerun" aria-label="Permalink: Rerun" href="#rerun"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description rerun_dash_compressed.mp4">rerun_dash_compressed.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/7014262/379449916-f679fec0-935d-4dd2-87e1-c301db9cdc2c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTQ0OTkxNi1mNjc5ZmVjMC05MzVkLTRkZDItODdlMS1jMzAxZGI5Y2RjMmMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzZlOTllN2I1YzJhMjkzMjQ1MjE4NzFjZThhYThjOTc4YjI2MzQxMTIxNGU3ZWI4NThkNTE2ZjkwNmE0ZWFiMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.RtaaxhaOK02bPQIW_4D4_Yz6zb0ifB_uE3GvmNNnrdU" data-canonical-src="https://private-user-images.githubusercontent.com/7014262/379449916-f679fec0-935d-4dd2-87e1-c301db9cdc2c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTQ0OTkxNi1mNjc5ZmVjMC05MzVkLTRkZDItODdlMS1jMzAxZGI5Y2RjMmMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzZlOTllN2I1YzJhMjkzMjQ1MjE4NzFjZThhYThjOTc4YjI2MzQxMTIxNGU3ZWI4NThkNTE2ZjkwNmE0ZWFiMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.RtaaxhaOK02bPQIW_4D4_Yz6zb0ifB_uE3GvmNNnrdU" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">While training, additional data can be visualized with the excellent <a href="https://rerun.io/" rel="nofollow">rerun</a>. To install rerun on your machine, please follow their <a href="https://rerun.io/docs/getting-started/installing-viewer" rel="nofollow">instructions</a>. Open the ./brush_blueprint.rbl in the viewer for best results.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mobile</h2><a id="user-content-mobile" aria-label="Permalink: Mobile" href="#mobile"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description brush_android_compressed.mp4">brush_android_compressed.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/7014262/379451093-d6751cb3-ff58-45a4-8321-77d3b0a7b051.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTQ1MTA5My1kNjc1MWNiMy1mZjU4LTQ1YTQtODMyMS03N2QzYjBhN2IwNTEubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjQxMDZlMDc2OTAxNmY5Y2NjNTIwZDU0ZDk1MzA0NjIwNmZjY2E2YjYwY2ExZmM1ZGE2ZjI5NDQ0ZDk2Nzg4MSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WngStxrtUTvVoBQ-fscAA1F3Fs-h7kimVBqRpUlepqc" data-canonical-src="https://private-user-images.githubusercontent.com/7014262/379451093-d6751cb3-ff58-45a4-8321-77d3b0a7b051.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk4MzA5MDMsIm5iZiI6MTcyOTgzMDYwMywicGF0aCI6Ii83MDE0MjYyLzM3OTQ1MTA5My1kNjc1MWNiMy1mZjU4LTQ1YTQtODMyMS03N2QzYjBhN2IwNTEubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjVUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjQxMDZlMDc2OTAxNmY5Y2NjNTIwZDU0ZDk1MzA0NjIwNmZjY2E2YjYwY2ExZmM1ZGE2ZjI5NDQ0ZDk2Nzg4MSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WngStxrtUTvVoBQ-fscAA1F3Fs-h7kimVBqRpUlepqc" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Live training on a pixel 7</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why</h2><a id="user-content-why" aria-label="Permalink: Why" href="#why"></a></p>
<p dir="auto">Machine learning for real time rendering has a lot of potential, but at the same time, most popular ML tools don't align well with r. Rendering requires low latency, usually involve dynamic shapes, and it's not pleasant to attempt to ship apps with large PyTorch/Jax/CUDA deps calling out to python in a rendering loop. The usual fix is to write a seperate training and inference application. Brush on the other hand, written in rust using <code>wgpu</code> and <code>burn</code>, can produce simple dependency free binaries, and can run on nearly all devices.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">Install rust 1.81+ and run <code>cargo run</code> or <code>cargo run --release</code>. You can run tests with <code>cargo test --all</code>. Brush uses the wonderful <a href="https://github.com/ArthurBrussee/brush/blob/main/rerun.io">rerun</a> for additional visualizations while training.
It currently requires rerun 0.19 however, which isn't released yet.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows/macOS/Linux</h3><a id="user-content-windowsmacoslinux" aria-label="Permalink: Windows/macOS/Linux" href="#windowsmacoslinux"></a></p>
<p dir="auto">Simply <code>cargo run</code> or <code>cargo run --release</code> from the workspace root.</p>
<p dir="auto">Note: Linux has not yet been tested but <em>should</em> work. Windows works well, but does currently only works on Vulkan.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Web</h3><a id="user-content-web-1" aria-label="Permalink: Web" href="#web-1"></a></p>
<p dir="auto">This project uses <a href="https://github.com/trunk-rs/trunk"><code>trunk</code></a> to build for the web. Install trunk, and then run <code>trunk serve</code> or <code>trunk serve --release</code> to run a development server.</p>
<p dir="auto">WebGPU is still a new standard, and as such, only the latest versions of Chrome work currently. Firefox nightly should work but unfortunately crashes currently.</p>
<p dir="auto">The public web demo is registered for the <a href="https://chromestatus.com/feature/5126409856221184" rel="nofollow">subgroups origin trial</a>. To run the web demo for yourself, please enable the "Unsafe WebGPU support" flag in Chrome.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Android</h3><a id="user-content-android" aria-label="Permalink: Android" href="#android"></a></p>
<p dir="auto">To build on Android, see the more detailed README instructions at crates/brush-android.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">iOS</h3><a id="user-content-ios" aria-label="Permalink: iOS" href="#ios"></a></p>
<p dir="auto">Brush <em>should</em> work on iOs but there is currently no project setup to do so.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical details</h2><a id="user-content-technical-details" aria-label="Permalink: Technical details" href="#technical-details"></a></p>
<p dir="auto">Brush is split into various crates. A quick overview of the different responsibilities are:</p>
<ul dir="auto">
<li><code>brush-render</code> is the main crate that pulls together the kernels into rendering functions.</li>
<li><code>brush-train</code> has code to actually train Gaussians, and handle larger scale optimizations like splitting/cloning gaussians etc.</li>
<li><code>brush-viewer</code> handles the UI and integrating the training loop.</li>
<li><code>brush-android</code> is the binary target for running on android, while <code>brush-desktop</code> is for running both on web, and mac/Windows/Linux.</li>
<li><code>brush-wgsl</code> handles some kernel inspection for generating CPU-side structs and interacing with <a href="https://github.com/bevyengine/naga_oil">naga-oil</a> to handle shader imports.</li>
<li><code>brush-dataset</code> handles importing different datasets like COLMAP or synthetic nerf data.</li>
<li><code>brush-prefix-sum</code> and <code>brush-sort</code> are only compute kernels and should be largely independent of Brush (other than <code>brush-wgsl</code>).</li>
<li><code>rrfd</code> is a small extension of <a href="https://github.com/PolyMeilex/rfd"><code>rfd</code></a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Kernels</h3><a id="user-content-kernels" aria-label="Permalink: Kernels" href="#kernels"></a></p>
<p dir="auto">The kernels are written in a "sparse" style, that is, only work for visible gaussians is done, though the final calculated gradients are dense. Brush uses a GPU radix sort based on <a href="https://www.amd.com/en/products/graphics/technologies/fidelityfx.html" rel="nofollow">FidelityFX</a> (see <code>crates/brush-sort</code>). The sorting is done in two parts - first splats are sorted only by depth, then sorted by their tile ID, which saves some sorting time compared to sorting both depth and tile ids at the same time.</p>
<p dir="auto">Compatibility with WebGPU does bring some challenges, even with (the excellent) <a href="https://github.com/gfx-rs/wgpu">wgpu</a>.</p>
<ul dir="auto">
<li>WebGPU lacks native atomic floating point additions, and a software CAS loop has to be used.</li>
<li>GPU readbacks have to be async on WebGPU. A rendering pass can't do this unless the whole rendering becomes async, which has its own perils, and isn't great for an UI. The reference tile renderer requires reading back the number of "intersections" (each visible tile of a gaussian is one intersection), but this is not feasible. This is worked around by assuming a worst case. To reduce the number of tiles the rasterizer culls away unused tiles by intersecting the gaussian ellipses with the screenspace tiles.</li>
</ul>
<p dir="auto">The WGSL kernels use <a href="https://github.com/bevyengine/naga_oil">naga_oil</a> to manage imports. brush-wgsl additionally does some reflection to generate rust code to send uniform data to a kernel. In the future, it might be possible to port the kernels to Burns new <a href="https://github.com/tracel-ai/cubecl"><code>CubeCL</code></a> language, which is much more ergonomic and would allow generating CUDA / rocM kernels. It might also be possible to integrate with George Kopanos' <a href="https://github.com/google/slang-gaussian-rasterization">Slang kernels</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Benchmarks</h3><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">Rendering performance is expected to be very competitive with gSplat, while training performance is still a bit slower. You can run some benchmarks using <code>cargo bench</code>. The performance of the splatting forward and backwards kernel are faster than the <em>legacy</em> gSplat kernels as they use some new techniques for better performance, but they haven't been compared yet to the more recent gSplat kernels. End-to-end training performance is also still slower, due to other overheads.</p>
<p dir="auto">For additional profiling, you can use <a href="https://github.com/wolfpld/tracy">tracy</a> and run with <code>cargo run --release --feature=tracy</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quality</h3><a id="user-content-quality" aria-label="Permalink: Quality" href="#quality"></a></p>
<p dir="auto">Quality is similair, but for now still somewhat lagging behind the original GS implementation. This is likely due to some suboptimal splitting/cloning heuristics.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Scene</th>
<th>Brush</th>
<th>GS paper</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bicycle@7K</td>
<td>23.2</td>
<td>23.604</td>
</tr>
<tr>
<td>Garden@7k</td>
<td>25.8</td>
<td>26.245</td>
</tr>
<tr>
<td>Stump@7k</td>
<td>24.9</td>
<td>25.709</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto"><a href="https://github.com/nerfstudio-project/gsplat"><strong>gSplat</strong></a>, for their reference version of the kernels</p>
<p dir="auto"><strong>Peter Hedman &amp; George Kopanas</strong>, for the many discussions &amp; pointers.</p>
<p dir="auto"><strong>The Burn team</strong>, for help &amp; improvements to Burn along the way</p>
<p dir="auto"><strong>Raph Levien</strong>, for the <a href="https://github.com/googlefonts/compute-shader-101/pull/31" data-hovercard-type="pull_request" data-hovercard-url="/googlefonts/compute-shader-101/pull/31/hovercard">original version</a> of the GPU radix sort.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">This is <em>not</em> an official Google product. This repository is a forked public version of <a href="https://github.com/google-research/google-research/tree/master/brush_splat">the google-research repository</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Israel launched a dozen attacks on UN troops in Lebanon, says leaked report (170 pts)]]></title>
            <link>https://www.ft.com/content/151eb482-6415-48a8-bf3f-baed00018c4e</link>
            <guid>41938822</guid>
            <pubDate>Thu, 24 Oct 2024 19:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/151eb482-6415-48a8-bf3f-baed00018c4e">https://www.ft.com/content/151eb482-6415-48a8-bf3f-baed00018c4e</a>, See on <a href="https://news.ycombinator.com/item?id=41938822">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offer-596bb8f3-5b5a-405d-8131-9d2f83fa19ba" data-component="heroOffer" data-component-unique-name="Hero offer"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span>Limited time offer</span></h2><h2><strong><span>Save 50% on Standard Digital</span></strong></h2></p><p><span>was </span><span>CHF660</span><span> </span><span>now </span><span>CHF329</span><span> for your first year, equivalent to </span><span>CHF27.42</span><span> per month.
Make up your own mind. Build robust opinions with the FT’s trusted journalism.
Take this offer before 24 October.</span></p></div></div><div id="recommendedOffers-Recommended offers-970a735c-9068-41df-9018-9dfe0b917fe9" data-component="recommendedOffers" data-component-unique-name="Recommended offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_trial.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF1</span><span> for 4 weeks</span></p><p><span>Then </span><span>CHF85</span><span> per month. Complete digital access to quality FT journalism. Cancel anytime during your trial.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_weekend_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF85</span><span> per month</span></p><p><span>Get Premium &amp; FT Weekend Print edition for the price of Premium. Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_print.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF345</span><span> for your first year</span></p><p><span>FT newspaper delivered Monday-Saturday, plus FT Digital Edition delivered to your device Monday-Saturday.</span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription options"><h2>Explore our full range of subscriptions.</h2><div><div><p>Discover all the plans currently available in your country</p></div><div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=151eb482-6415-48a8-bf3f-baed00018c4e">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quantized Llama models with increased speed and a reduced memory footprint (385 pts)]]></title>
            <link>https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1</link>
            <guid>41938473</guid>
            <pubDate>Thu, 24 Oct 2024 18:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1">https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1</a>, See on <a href="https://news.ycombinator.com/item?id=41938473">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>At <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" data-lnfb-mode="ie"><u>Connect 2024</u></a> last month, we open sourced Llama 3.2 1B and 3B—our smallest models yet—to address the demand for on-device and edge deployments. Since their release, we’ve seen not just how the community has adopted our lightweight models, but also how grassroots developers are quantizing them to save capacity and memory footprint, often at a tradeoff to performance and accuracy.</p><p>As we’ve <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" target="_blank" data-lnfb-mode="ie"><u>shared before</u></a>, we want to make it easier for more developers to build with Llama, without needing significant compute resources and expertise. Today, we’re sharing quantized versions of Llama 3.2 1B and 3B models. These models offer a reduced memory footprint, faster on-device inference, accuracy, and portability—all while maintaining quality and safety for developers to deploy on resource-constrained devices. Given the limited runtime memory available on mobile devices, we prioritized short-context applications up to 8K for these new quantized models. Our results show we can achieve superior accuracy by training with quantization as opposed to post-processing. The models we are sharing today have 2-4x speedup and an average reduction of 56% in model size compared to the original format, based on testing with Android OnePlus 12 models. We also reduce memory usage by an average of 41%. Starting today, the community can deploy our <a href="https://www.llama.com/" target="_blank" data-lnfb-mode="ie"><u>quantized models</u></a> onto more mobile CPUs, giving them the opportunity to build unique experiences that are fast and provide more privacy since interactions stay entirely on device.</p><p>We developed these state-of-the-art models using Quantization-Aware Training with LoRA adaptors (QLoRA) to optimize performance in low-precision environments. We also used SpinQuant, a technique that enables us to determine the best possible combination for compression while retaining the most possible quality. As a result of the close collaborative work with our industry-leading partners, QLoRA and SpinQuant Llama models are available on Qualcomm and MediaTek SoCs with Arm CPUs. The performance of the quantized models has been optimized for mobile CPUs using Kleidi AI kernels, and we’re currently collaborating with our partners to utilize NPUs for even greater performance for Llama 1B/3B.</p><br></div><p>Our quantization setup</p><div><p>We designed the current quantization scheme with <a href="https://github.com/pytorch/executorch" target="_blank" data-lnfb-mode="ie"><u>PyTorch’s ExecuTorch inference framework</u></a> and <a href="https://www.arm.com/products/development-tools/embedded-and-software/kleidi-libraries" target="_blank" data-lnfb-mode="ie"><u>Arm CPU backend</u></a> in mind, taking into account metrics including model quality, prefill/decoding speed, and memory footprint. Our quantization scheme involves three parts:</p><ul><li>We quantize all linear layers in all transformer blocks to a 4-bit groupwise scheme (with a group size of 32) for weights and 8-bit per-token dynamic quantization for activations.</li><li>The classification layer is quantized to 8-bit per-channel for weight and 8-bit per-token dynamic quantization for activation.</li><li>We employ an 8-bit per-channel quantization for embedding.</li></ul><br></div><p>Quantization-Aware Training and LoRA</p><div><p>We employ Quantization-Aware Training (QAT) to simulate the effects of quantization during the training of Llama 3.2 models, enabling us to optimize their performance in low-precision environments. To initialize QAT, we utilize BF16 Llama 3.2 model checkpoints obtained after supervised fine-tuning (SFT) and perform an additional full round of SFT training with QAT. We then freeze the backbone of the QAT model and perform another round of SFT with low-rank adaptation (LoRA) adaptors applied to all layers within the transformer block. Meanwhile, the LoRA adaptors' weights and activations are maintained in BF16. Because our approach is similar to QLoRA in principle (i.e., quantization followed by LoRA adapters), we refer to it as QLoRA in this post.</p><p>Finally, we fine-tune the resulting model (both backbone and LoRA adaptors) using direct preference optimization (DPO). The resulting model is a highly efficient model that achieves competitive accuracy to the BF16 model, while maintaining a comparable speed and memory footprint to other quantization methods (see below figure).</p><p>We used <a href="https://github.com/pytorch/ao" target="_blank" data-lnfb-mode="ie"><u>torchao APIs</u></a> to do QAT. Developers can further use QAT as a foundational model and use LoRA to fine-tune Llama for their bespoke use cases, saving time and computational cost.</p><br></div><p>SpinQuant</p><div><p>Although QAT gives the best results, some people might want to quantize their fine-tuned 1B and 3B models or quantize the models for different targets with different quantization settings. For this reason we are also releasing the models and method of <a href="https://arxiv.org/abs/2405.16406" target="_blank" data-lnfb-mode="ie"><u>SpinQuant</u></a>, which is a state-of-the-art technique for post-training quantization.</p><p>While the method is less accurate than QAT + LoRA, a key advantage of SpinQuant is its portability and ability to operate without requiring access to training datasets, which are often private. It’s an attractive solution for applications where data availability or computational resources are limited. Developers can use this method to take their own fine-tuned Llama models and quantize them for different hardware targets and use cases, using the <a href="https://github.com/facebookresearch/SpinQuant" target="_blank" data-lnfb-mode="ie"><u>open source repository</u></a> that is fully compatible with <a href="https://github.com/pytorch/executorch" target="_blank" data-lnfb-mode="ie"><u>ExecuTorch</u></a> and <a href="https://github.com/meta-llama/llama-stack" target="_blank" data-lnfb-mode="ie"><u>Llama Stack</u></a>.</p><p>In our experiments, we utilize WikiText, a small calibration dataset, to learn rotation matrices in SpinQuant. These matrices enable the smoothing of outliers and facilitate more effective quantization. After this, best practices in quantization such as range setting and generative post-training quantization are applied. The SpinQuant matrices are optimized for the quantization scheme similar to QAT + LoRA.</p><br></div><p>Results</p><p>In the table below, we show comprehensive evaluation of the models quantized with vanilla post-training quantization (PTQ), SpinQuant, which produces the state-of-the-art PTQ quality, as well as QLoRA, which gives the best quality of all.</p></div><div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/463869105_1326616764996070_7210673116645317812_n.png?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=wGOZrBGxyFsQ7kNvgHPND3p&amp;_nc_zt=14&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=A74w6DQK95ECdVsAVfQKXnP&amp;oh=00_AYB0luXoDpLjhHrmyFz6JtwB63gvIs5W_4f4tnmrMGj8lQ&amp;oe=6734F2EF" alt="" id="u_0_5_PC"></p><div><p>Percentage difference in relation to the average value for BF16.</p></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/463977359_1182562752841690_4137380685967841470_n.png?_nc_cat=102&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=vbjUvQqeTkoQ7kNvgGG8krR&amp;_nc_zt=14&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=A74w6DQK95ECdVsAVfQKXnP&amp;oh=00_AYBa9DdglkoYt4jKS97avd525-WhGpbd_5ug56KNpbGYwg&amp;oe=6734E7D4" alt="" id="u_0_6_J8"></p><div><p>Percentage difference in relation to the average value for BF16.</p></div><div><p>In the table below, we compare the performance metrics of different quantization methods (SpinQuant and QAT + LoRA) with the BF16 baseline. The evaluation was done using the <a href="https://github.com/pytorch/executorch" target="_blank" data-lnfb-mode="ie"><u>ExecuTorch</u></a> framework as the inference engine, with the ARM CPU as a backend. The quantized models were optimized primarily for Arm CPU architecture by leveraging Kleidi AI library.</p></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/464307751_477718101949854_4588809159017166700_n.png?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=viOQ-r8IQlgQ7kNvgHuFj8m&amp;_nc_zt=14&amp;_nc_ht=scontent.fzrh3-1.fna&amp;_nc_gid=A74w6DQK95ECdVsAVfQKXnP&amp;oh=00_AYAbPnZBRvVF30mRWeG6YtpHYuvW9R_HwPUsTfE7Rsasyw&amp;oe=67351977" alt="" id="u_0_7_FE"></p><div><p>The performance measurement is done using an adb binary-based approach and is measured on an Android OnePlus 12 device. Time-to-first-token (TTFT) is measured with prompt length=64.</p></div></div><div><div><p>Decode latency improved by 2.5x and prefill latency improved by 4.2x on average, while model size decreased by 56% and memory usage reduced by 41% on average. The benchmarks can be reproducible today via ExecuTorch <a href="https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md" target="_blank" data-lnfb-mode="ie"><u>Llama instructions</u></a>. The table above shows results using an Android OnePlus 12 device—however, we’ve also verified similar relative performance on Samsung S24+ for 1B and 3B and Samsung S22 for 1B. For iOS devices, we’ve verified these models run with comparable accuracy but haven’t evaluated performance.</p><p>Besides CPU, we’re currently collaborating with partners to utilize NPUs for these quantized models for even greater performance. Our partners have already integrated foundational components in the ExecuTorch open source ecosystem to leverage NPUs, and work is underway to specifically enable quantization on NPU for Llama 1B/3B.</p><br></div><p>Looking to the future</p><div><p>We’ve been inspired and encouraged by the excitement and progress the community has achieved with Llama in just a short span of time. This year, <a href="https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/" target="_blank" data-lnfb-mode="ie"><u>Llama has achieved 10x growth</u></a> and become the standard for responsible innovation. Llama also continues to lead on openness, modifiability, and cost efficiency and is competitive with closed models—even leading in some areas. As always, we can’t wait to see what the community builds using Llama and the powerful experiences they’ll enable on mobile devices.</p><p><i>We’re making Llama 3.2 models available for download on </i><a href="https://llama.com/" target="_blank" data-lnfb-mode="ie"><i><u>llama.com</u></i></a> and <a href="https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf" target="_blank" data-lnfb-mode="ie"><i><u>Hugging Face</u></i></a>.</p><p><i>We’d like to acknowledge the close collaboration of our partners: Arm, Hugging Face, MediaTek, Ollama, and Qualcomm.</i></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BYD EV teardown in Japan reveals secrets to its affordability (116 pts)]]></title>
            <link>https://insideevs.com/news/738606/byd-ev-teardown-impresses-japan/</link>
            <guid>41938220</guid>
            <pubDate>Thu, 24 Oct 2024 18:31:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insideevs.com/news/738606/byd-ev-teardown-impresses-japan/">https://insideevs.com/news/738606/byd-ev-teardown-impresses-japan/</a>, See on <a href="https://news.ycombinator.com/item?id=41938220">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_box"> <div> <p><span data-time="1729765193"></span><span>Oct 24, 2024</span><span> at</span> 10:19am ET</p>  </div> <div> <ul> <li><strong>The integration of multiple components into a single drive unit that BYD calls E-Axle was the most impressive part.</strong></li> <li><strong>Between the E-Axle and the economies of scale that BYD can achieve, it can sell its EVs at very affordable prices that non-Chinese automakers simply can't match.</strong></li> </ul> <hr> <p>Japan used to be a world leader in electric and electrified vehicles in the early 2000s, but its lead has since subsided, and it lags behind most developed nations in this regard. China is the undisputed global EV leader these days, and the Central Japan Economic and Trade Bureau organized a seminar that involved the teardown of multiple EVs to see how others are already so advanced.</p> <p>According to <a href="https://cn.nikkei.com/industry/icar/56879-2024-10-09-09-00-23.html" target="_blank" rel="noopener noreferrer"><em>Nikkei</em></a>, the <a href="https://insideevs.com/news/628160/byd-atto3-range-test-wltp/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22628160%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22byd-atto3-range-test-wltp%22%7D">BYD Atto 3</a>&nbsp;(pictured) impressed attendees with how affordable it is given its size and specifications. In China, where it’s called the Yuan Plus, it starts at 139,800 yuan, or just under $20,000, and for that, you get a 201 horsepower EV with a 50-kilowatt-hour battery that gives it a claimed CLTC range of 267 miles (430 km).</p> <p> <h3> Gallery: BYD ATTO 3 </h3> </p>  <p>The larger optional 60.5-kWh battery ups the range to 317 miles (510 km) for an additional 10,000 yuan or $1,400. This larger pack is also offered on the European version of the Atto 3, which <a href="https://insideevs.com/news/718036/byd-major-ev-markup-prices/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22718036%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22byd-major-ev-markup-prices%22%7D">costs nearly twice as much as it does in China</a>. The higher price is the result of both markup and import tariffs, which are set to rise starting next month.</p> <p>The Atto 3 teardown in Japan revealed one of the ways <a href="https://insideevs.com/byd/" data-inline-widget="internal-links" data-type-id="2" data-params="%7B%22alias%22%3A%22byd%22%7D">BYD</a> manages to keep costs down and pass the savings down to the person who buys the car. It’s all about producing as many of the components as possible in-house and integrating them. The source article highlights the so-called “E-Axle” used by BYD, which is comprised of eight different components.</p> <p>It includes not only the motor, inverter, transmission and controller but also the onboard AC charger, the DC-to-DC converter and the battery monitoring system (BMS). This approach, combined with the economies of scale (the larger the number of cars you build, the cheaper you can build them) goes a long way toward explaining how these highly competent Chinese EVs can be sold at such low prices.</p> <p>The BYD Atto 3 was chosen for this project not only because of its international success but also because it <a href="https://insideevs.com/news/711623/2023-japan-ev-of-the-year-chinese-byd/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22711623%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%222023-japan-ev-of-the-year-chinese-byd%22%7D">ranked very highly in the&nbsp;2023 Japan EV of the Year awards</a> and another BYD model won.</p> <section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22737520%22%2C%22title%22%3A%22BYD%20Sealion%207%20Debuts%20In%20Europe%20As%20A%20Serious%20Tesla%20Model%20Y%20Competitor%22%2C%22alias%22%3A%22byd-sealion-7-debut-europe%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FxqKGPP%2Fs5%2Fbyd-sealion-7.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22736187%22%2C%22title%22%3A%22Tesla%20Scored%20A%20Win%20Against%20BYD%22%2C%22alias%22%3A%22tesla-byd-q3-ev-cm%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2Fpb39qY%2Fs5%2Ftesla-cm-byd.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22734623%22%2C%22title%22%3A%22%2410%2C000%20BYD%20Seagull%20EV%20Outsold%20All%20Other%20Cars%20In%20China%20Last%20Month%22%2C%22alias%22%3A%22byd-seagull-best-selling-china%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2Fpb3YkY%2Fs5%2Fbyd-seagull-no.1.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22732578%22%2C%22title%22%3A%22China's%20BYD%20Was%20The%20Third-Best-Selling%20Brand%20In%20The%20World%20This%20July%22%2C%22alias%22%3A%22byd-sales-july-2024-third-place%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2F7ZPq1A%2Fs5%2Fbyd-dolphin-europa.jpg%22%7D%7D%5D%7D"> <p>More On BYD</p>  </section> <p>Kenichi Ito, director of industrial machinery company Sanyo Trading and one of the seminar organizers, noted that "Chinese manufacturers attach great importance to low-cost production” and "their views on quality are different from those of Japanese manufacturers." This was a subtle way of saying they are not built to the same standard, but the market doesn’t seem to mind, and BYD sold 300,000 Atto 3s in the vehicle’s first year of production starting in February 2022—it's been <a href="https://insideevs.com/news/680362/byd-atto-3-outsold-tesla-model-y-sweden-last-month/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22680362%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22byd-atto-3-outsold-tesla-model-y-sweden-last-month%22%7D">doing quite well in some European markets too</a>.</p> <p>Tesla has a similar approach of combining multiple components to reduce costs. The best example is the Model Y’s structure, which consists of just two major pieces instead of 70 separate elements like in the smaller <a href="https://insideevs.com/reviews/719484/tesla-model3-long-range-review/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22719484%22%2C%22section%22%3A%222%22%2C%22alias%22%3A%22tesla-model3-long-range-review%22%7D">Model 3</a>. Interestingly, even though this saves costs and cuts complexity, Tesla isn’t interested in pursuing gigacasting further and applying it to other models, even though it commissioned and acquired some of the world’s most impressive die-casting presses.</p> <p>This could be because <a href="https://insideevs.com/features/738536/tesla-q3-call-musk-regulations/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22738536%22%2C%22section%22%3A%223%22%2C%22alias%22%3A%22tesla-q3-call-musk-regulations%22%7D">Tesla’s interest has now shifted more toward self-driving</a> technology than advancing car-building techniques.</p>  </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Computer Use – Is Vision the Ultimate API? (107 pts)]]></title>
            <link>https://www.thariq.io/blog/claudecomputer/</link>
            <guid>41938051</guid>
            <pubDate>Thu, 24 Oct 2024 18:15:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thariq.io/blog/claudecomputer/">https://www.thariq.io/blog/claudecomputer/</a>, See on <a href="https://news.ycombinator.com/item?id=41938051">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>I’ve spent the last 2 days basically non-stop hacking with <a href="https://www.anthropic.com/research/developing-computer-use" rel="nofollow, noopener, noreferrer" target="_blank">Anthropic’s Computer Use API</a>.</p>
<p>It’s slow, unreliable, prone to taking over your computer and… incredibly exciting.</p>
<p>Claude Computer is the first time I’ve felt a true ‘agent’ experience, because in the end Vision is the API that ties everything together— <em>it can always do something</em>.</p>
<p>Overall, my learnings have been that the goal should be to get Claude to use as little vision as possible, but the fact that it can use vision allows it to catch much more edge cases than any other agent.</p>
<astro-island uid="1IfUeS" prefix="r0" component-url="/_astro/ExpandableBlock.CVy5cl6D.js" component-export="default" renderer-url="/_astro/client.BIGLHmRd.js" props="{&quot;heading&quot;:[0,&quot;Test Claude Computer Use Yourself&quot;]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;ExpandableBlock&quot;,&quot;value&quot;:true}" await-children=""><div><p><span>▼</span>Test Claude Computer Use Yourself</p></div><!--astro:end--></astro-island>
<h2 id="how-does-it-work"><strong>How does it work?</strong></h2>
<p>Claude Computer Use seems to be essentially Claude3.5 fine-tuned on computer interaction data. It can understand screenshots of computers and what is on them much better than other models.</p>
<h2 id="what-is-it-good-at"><strong>What is it good at?</strong></h2>
<h4 id="screen-reading--navigation-relatively"><strong>Screen Reading &amp; Navigation (relatively)</strong></h4>
<p>I’ve almost never seen Claude misread the contents of a screenshot.</p>
<p>Compared to other AIs it’s quite good at knowing coordinates like `click on the the input bar at (500,250), though depending your screen size, it will often barely miss it.</p>
<h4 id="function-calls"><strong>Function Calls</strong></h4>
<p>I’m used to thinking of Function Calls as strictly worse than structured output, but Claude Computer uses function calls well. For example, given a browser tool that has a function to immediately navigate to a website, it will prefer to use that vs clicking on your browser icon.</p>
<h4 id="thinking-step-by-step"><strong>Thinking Step-by-Step</strong></h4>
<p>When asked to break down a task, Claude is usually quite good at identifying the steps it needs to take and starting on them.</p>
<h2 id="what-is-it-bad-at">What is it bad at?</h2>
<h4 id="knowing-when-to-read-the-screen"><strong>Knowing when to Read the Screen</strong></h4>
<p>Since taking a screenshot is expensive, so the AI will tend to assume that its manipulations have worked.</p>
<p>E.g. if it types into a field, but doesn’t have focus, it is extremely hard for it to detect that until later. The OS function calls need to be very accurate in describing if the intended result actually happened.</p>
<p>This is the most common way I’ve seen Claude get stuck. By the time it takes a new screenshot, it doesn’t know where in its progression it is.</p>
<h4 id="fetching-more-data"><strong>Fetching More Data</strong></h4>
<p>If I want it to find the 3 closest Shawarma places, Claude will put ‘Shawarma’ into Google Maps and then select the top 3 results.</p>
<p>It will almost never ‘sort by distance’ in the menu first, if it needs to click on things.</p>
<p>It’s possible that this might be fixed with better prompting structure.</p>
<h4 id="remembering-state"><strong>Remembering State</strong></h4>
<p>With Computer Use, more of the state of the program state is stored in images, which it seems worse at recalling. This extends to what it has done in the past, e.g. previous tabs it’s opened or applications it’s made changes in.</p>
<p>You should try and get Claude to output relevant state as text as much as possible and provide system state as a tool.</p>
<h4 id="navigating-modals-and-popups"><strong>Navigating Modals and Popups</strong></h4>
<p>Claude is most often confused by modals and popups, not knowing how to click out of them or recoginizing that they’re not a correct state to be in.</p>
<h2 id="what-does-it-need">What does it need?</h2>
<h4 id="as-much-system-state-as-you-can-give-it"><strong>As much System State as you can give it</strong></h4>
<p>Ideally, you want Claude Computer to only use vision when it absolutely needs to. Giving it tools to understand the state easily without using vision helps it move faster and think clearer.</p>
<p>It is very helpful to give it things like:</p>
<ul>
<li>A list of applications that are open</li>
<li>Which application has active focus</li>
<li>What is focused inside the application</li>
<li>Function calls to specifically navigate those applications, as many as possible
<ul>
<li>a browser tool in particular is important, for example to navigate to a specific URL or search for something</li>
</ul>
</li>
</ul>
<h4 id="a-way-to-handle-uncertainty"><strong>A way to handle Uncertainty</strong></h4>
<p>This the biggest open question in Agent development.</p>
<p>The most important thing about Agents is Trust, and trust requires input and back and forth. There were many times in testing when it was clear Claude didn’t know what to do, and it powered through instead of stopping or asking.</p>
<p>I spent quite a long time trying to make a Questions tool to get the AI to ask questions or reason if it was stuck. But it almost never used it.</p>
<p>This makes sense, a function call is best when you know that you need information, and you just need to retrieve it.</p>
<p>But knowing when you’re uncertain is a different problem. Agent developers need to be able to trust that the AI will report its own uncertainty.</p>
<h2 id="looking-forward">Looking Forward</h2>
<p>Claude Computer is the first step towards true agent behavior. We’re likely not yet maxing the capabilities of this current model. But it’s also clear that we’ll need more than LLM function calls to create a true agent experience.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zigler: Zig NIFs in Elixir (182 pts)]]></title>
            <link>https://github.com/E-xyza/zigler</link>
            <guid>41937815</guid>
            <pubDate>Thu, 24 Oct 2024 17:53:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/E-xyza/zigler">https://github.com/E-xyza/zigler</a>, See on <a href="https://news.ycombinator.com/item?id=41937815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Zigler</h2><a id="user-content-zigler" aria-label="Permalink: Zigler" href="#zigler"></a></p>
<p dir="auto">Library test status:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Installation: Elixir</h2><a id="user-content-installation-elixir" aria-label="Permalink: Installation: Elixir" href="#installation-elixir"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Obtaining Zig dependency</h3><a id="user-content-obtaining-zig-dependency" aria-label="Permalink: Obtaining Zig dependency" href="#obtaining-zig-dependency"></a></p>
<p dir="auto">Run <code>mix zig.get</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Main Installation</h3><a id="user-content-main-installation" aria-label="Permalink: Main Installation" href="#main-installation"></a></p>
<p dir="auto">Zigler is <a href="https://hex.pm/packages/zigler" rel="nofollow">available in Hex</a>, and the package can be installed
by adding <code>zigler</code> to your list of dependencies in <code>mix.exs</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def deps do
  [
    {:zigler, &quot;~> 0.13.2&quot;, runtime: false}
  ]
end"><pre><span>def</span> <span>deps</span> <span>do</span>
  <span>[</span>
    <span>{</span><span>:zigler</span><span>,</span> <span>"~&gt; 0.13.2"</span><span>,</span> <span>runtime: </span><span>false</span><span>}</span>
  <span>]</span>
<span>end</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation: Erlang</h2><a id="user-content-installation-erlang" aria-label="Permalink: Installation: Erlang" href="#installation-erlang"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Zig dependency</h3><a id="user-content-zig-dependency" aria-label="Permalink: Zig dependency" href="#zig-dependency"></a></p>
<p dir="auto">TBD.</p>
<p dir="auto"><code>~/.cache/zigler/zig-linux-&lt;arch&gt;-0.13.0</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Main Installation</h3><a id="user-content-main-installation-1" aria-label="Permalink: Main Installation" href="#main-installation-1"></a></p>
<p dir="auto">Erlang is only supported via rebar3.  You must enable the rebar_mix plugin and
add zigler to your deps in rebar3.</p>
<p dir="auto">Note that erlang support is highly experimental.  Please submit issues if you
have difficulty.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{plugins, [rebar_mix]}.

{deps, [{zigler, &quot;0.13&quot;}]}.
"><pre>{<span>plugins</span>, [<span>rebar_mix</span>]}.

{<span>deps</span>, [{<span>zigler</span>, <span><span>"</span>0.13<span>"</span></span>}]}.
</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Docs can be found at <a href="https://hexdocs.pm/zigler" rel="nofollow">https://hexdocs.pm/zigler</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Currently supported platforms</h2><a id="user-content-currently-supported-platforms" aria-label="Permalink: Currently supported platforms" href="#currently-supported-platforms"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Linux</p>
</li>
<li>
<p dir="auto">FreeBSD (tested, but not subjected to CI)</p>
</li>
<li>
<p dir="auto">MacOS</p>
</li>
<li>
<p dir="auto">Nerves cross-compilation is supported out of the box.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zig Nifs made easy</h2><a id="user-content-zig-nifs-made-easy" aria-label="Permalink: Zig Nifs made easy" href="#zig-nifs-made-easy"></a></p>
<p dir="auto">Wouldn't it be nice if you could make NIFs as easily as you can use the <code>asm</code>
keyword in C?</p>
<p dir="auto">This is now possible, using the magic of Zig.</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule ExampleZig do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  pub fn example_fun(value1: f64, value2: f64) bool {
    return value1 > value2;
  }
  &quot;&quot;&quot;
end

test &quot;example nifs&quot; do
  assert ExampleZig.example_fun(0.8, -0.8)
  refute ExampleZig.example_fun(0.1, 0.4)
end"><pre><span>defmodule</span> <span>ExampleZig</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  pub fn example_fun(value1: f64, value2: f64) bool {</span>
<span>    return value1 &gt; value2;</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span>

<span>test</span> <span>"example nifs"</span> <span>do</span>
  <span>assert</span> <span>ExampleZig</span><span>.</span><span>example_fun</span><span>(</span><span>0.8</span><span>,</span> <span>-</span><span>0.8</span><span>)</span>
  <span>refute</span> <span>ExampleZig</span><span>.</span><span>example_fun</span><span>(</span><span>0.1</span><span>,</span> <span>0.4</span><span>)</span>
<span>end</span></pre></div>
<p dir="auto">Zigler will do automatic type marshalling between Elixir code and Zig code.
It will also convert trickier types into types you care about, for example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule ZigCollections do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  pub fn string_count(string: []u8) i64 {
    return @intCast(string.len);
  }

  pub fn list_sum(array: []f64) f64 {
    var sum: f64 = 0.0;
    for(array) | item | {
      sum += item;
    }
    return sum;
  }
  &quot;&quot;&quot;
end

test &quot;type marshalling&quot; do
  assert 9 == ZigCollections.string_count(&quot;hello zig&quot;)
  assert 6.0 == ZigCollections.list_sum([1.0, 2.0, 3.0])
end"><pre><span>defmodule</span> <span>ZigCollections</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  pub fn string_count(string: []u8) i64 {</span>
<span>    return @intCast(string.len);</span>
<span>  }</span>
<span></span>
<span>  pub fn list_sum(array: []f64) f64 {</span>
<span>    var sum: f64 = 0.0;</span>
<span>    for(array) | item | {</span>
<span>      sum += item;</span>
<span>    }</span>
<span>    return sum;</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span>

<span>test</span> <span>"type marshalling"</span> <span>do</span>
  <span>assert</span> <span>9</span> <span>==</span> <span>ZigCollections</span><span>.</span><span>string_count</span><span>(</span><span>"hello zig"</span><span>)</span>
  <span>assert</span> <span>6.0</span> <span>==</span> <span>ZigCollections</span><span>.</span><span>list_sum</span><span>(</span><span>[</span><span>1.0</span><span>,</span> <span>2.0</span><span>,</span> <span>3.0</span><span>]</span><span>)</span>
<span>end</span></pre></div>
<p dir="auto">Memory allocation with zigler is easy!  A standard BEAM allocator is provided for you,
so any zig code you import will play nice with the BEAM.</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule Allocations do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  const beam = @import(&quot;beam&quot;);

  pub fn double_atom(string: []u8) !beam.term {
    var double_string = try beam.allocator.alloc(u8, string.len * 2);
    defer beam.allocator.free(double_string);

    for (string, 0..) | char, i | {
      double_string[i] = char;
      double_string[i + string.len] = char;
    }

    return beam.make_into_atom(double_string, .{});
  }
  &quot;&quot;&quot;
end

test &quot;allocations&quot; do
  assert :foofoo == Allocations.double_atom(&quot;foo&quot;)
end"><pre><span>defmodule</span> <span>Allocations</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  const beam = @import("beam");</span>
<span></span>
<span>  pub fn double_atom(string: []u8) !beam.term {</span>
<span>    var double_string = try beam.allocator.alloc(u8, string.len * 2);</span>
<span>    defer beam.allocator.free(double_string);</span>
<span></span>
<span>    for (string, 0..) | char, i | {</span>
<span>      double_string[i] = char;</span>
<span>      double_string[i + string.len] = char;</span>
<span>    }</span>
<span></span>
<span>    return beam.make_into_atom(double_string, .{});</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span>

<span>test</span> <span>"allocations"</span> <span>do</span>
  <span>assert</span> <span>:foofoo</span> <span>==</span> <span>Allocations</span><span>.</span><span>double_atom</span><span>(</span><span>"foo"</span><span>)</span>
<span>end</span></pre></div>
<p dir="auto">It is a goal for Zigler to make using <em>it</em> to bind C libraries easier
than using C to bind C libraries.  Here is an example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="if {:unix, :linux} == :os.type() do
  defmodule Blas do
    use Zig,     
      otp_app: :zigler,
      c: [link_lib: {:system, &quot;blas&quot;}]
  
    ~Z&quot;&quot;&quot;
    const beam = @import(&quot;beam&quot;);
    const blas = @cImport({
        @cInclude(&quot;cblas.h&quot;);
    });

    const BadArgs = error { badarg };
  
    pub fn blas_axpy(a: f64, x: []f64, y: []f64) ![]f64 {
        if (x.len != y.len) return error.badarg;
    
        blas.cblas_daxpy(@intCast(x.len), a, x.ptr, 1, y.ptr, 1);
    
        return y;
    }
    &quot;&quot;&quot;
  end
  
  test &quot;we can use a blas shared library&quot; do
    # returns aX+Y
    assert [11.0, 18.0] == Blas.blas_axpy(3.0, [2.0, 4.0], [5.0, 6.0])
  end
end"><pre><span>if</span> <span>{</span><span>:unix</span><span>,</span> <span>:linux</span><span>}</span> <span>==</span> <span>:os</span><span>.</span><span>type</span><span>(</span><span>)</span> <span>do</span>
  <span>defmodule</span> <span>Blas</span> <span>do</span>
    <span>use</span> <span>Zig</span><span>,</span>     
      <span>otp_app: </span><span>:zigler</span><span>,</span>
      <span>c: </span><span>[</span><span>link_lib: </span><span>{</span><span>:system</span><span>,</span> <span>"blas"</span><span>}</span><span>]</span>
  
    <span>~Z<span>"""</span></span>
<span>    const beam = @import("beam");</span>
<span>    const blas = @cImport({</span>
<span>        @cInclude("cblas.h");</span>
<span>    });</span>
<span></span>
<span>    const BadArgs = error { badarg };</span>
<span>  </span>
<span>    pub fn blas_axpy(a: f64, x: []f64, y: []f64) ![]f64 {</span>
<span>        if (x.len != y.len) return error.badarg;</span>
<span>    </span>
<span>        blas.cblas_daxpy(@intCast(x.len), a, x.ptr, 1, y.ptr, 1);</span>
<span>    </span>
<span>        return y;</span>
<span>    }</span>
<span>    <span>"""</span></span>
  <span>end</span>
  
  <span>test</span> <span>"we can use a blas shared library"</span> <span>do</span>
    <span># returns aX+Y</span>
    <span>assert</span> <span>[</span><span>11.0</span><span>,</span> <span>18.0</span><span>]</span> <span>==</span> <span>Blas</span><span>.</span><span>blas_axpy</span><span>(</span><span>3.0</span><span>,</span> <span>[</span><span>2.0</span><span>,</span> <span>4.0</span><span>]</span><span>,</span> <span>[</span><span>5.0</span><span>,</span> <span>6.0</span><span>]</span><span>)</span>
  <span>end</span>
<span>end</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Documentation (Elixir-only)</h3><a id="user-content-documentation-elixir-only" aria-label="Permalink: Documentation (Elixir-only)" href="#documentation-elixir-only"></a></p>
<p dir="auto">You can document nif functions, local functions, zig structs, variables, and types.
If you document a nif function, it will be a part of the module documentation, and
accessible using the iex <code>h</code> method, etc.</p>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="defmodule Documentation do
  use Zig, otp_app: :zigler
  ~Z&quot;&quot;&quot;
  /// a zero-arity function which returns 47.
  pub fn zero_arity() i64 {
    return 47;
  }
  &quot;&quot;&quot;
end"><pre><span>defmodule</span> <span>Documentation</span> <span>do</span>
  <span>use</span> <span>Zig</span><span>,</span> <span>otp_app: </span><span>:zigler</span>
  <span>~Z<span>"""</span></span>
<span>  /// a zero-arity function which returns 47.</span>
<span>  pub fn zero_arity() i64 {</span>
<span>    return 47;</span>
<span>  }</span>
<span>  <span>"""</span></span>
<span>end</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Formatting (Elixir-only)</h3><a id="user-content-formatting-elixir-only" aria-label="Permalink: Formatting (Elixir-only)" href="#formatting-elixir-only"></a></p>
<p dir="auto">Zigler ships with a formatter.  To activate the formatter, adapt the following to your
<code>.formatter.exs</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[
  inputs: ~w[
    {mix,.formatter,.credo}.exs
    {config,lib,rel,test}/**/*.{ex,exs,zig}
    installer/**/*.{ex,exs}
  ],
  plugins: [Zig.Formatter]
]"><pre><span>[</span>
  <span>inputs: </span><span>~w<span>[</span></span>
<span>    {mix,.formatter,.credo}.exs</span>
<span>    {config,lib,rel,test}/**/*.{ex,exs,zig}</span>
<span>    installer/**/*.{ex,exs}</span>
<span>  <span>]</span></span><span>,</span>
  <span>plugins: </span><span>[</span><span>Zig.Formatter</span><span>]</span>
<span>]</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Erlang support (highly experimental)</h2><a id="user-content-erlang-support-highly-experimental" aria-label="Permalink: Erlang support (highly experimental)" href="#erlang-support-highly-experimental"></a></p>
<p dir="auto">Use of Zigler with erlang is possible using parse transforms.  You must obtain
zigler using the <code>rebar3</code> and the <code>rebar_mix</code> plugin.  Modules with zigler
nifs should inculde code into one or more <code>zig_code</code> attribute and pass
zigler options (identical to the elixir options) into a <code>zig_opts</code> attribute.<br>
Zigler will then create appropriate functions matching the zig functions as
it does with elixir.  Please not that some features (such as integers &gt; 64
bits) are not currently supported in erlang, although nearly full feature parity
is planned.</p>
<div dir="auto" data-snippet-clipboard-copy-content="-module(erlang_zigler_module).
-compile({parse_transform, zigler}). 
-export([foo/1, foo/0]).

-zig_code(&quot;
pub fn foo() i32 {
    return 47;
}
&quot;).

-zig_opts([{otp_app, zigler}]).

foo(X) ->
    47 + X."><pre>-<span>module</span>(<span>erlang_zigler_module</span>).
-<span>compile</span>({<span>parse_transform</span>, <span>zigler</span>}). 
-<span>export</span>([<span>foo</span>/<span>1</span>, <span>foo</span>/<span>0</span>]).

-<span>zig_code</span>(<span><span>"</span></span>
<span>pub fn foo() i32 {</span>
<span>    return 47;</span>
<span>}</span>
<span><span>"</span></span>).

-<span>zig_opts</span>([{<span>otp_app</span>, <span>zigler</span>}]).

<span>foo</span>(<span>X</span>) <span>-&gt;</span>
    <span>47</span> <span>+</span> <span>X</span>.</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zigler Principles</h2><a id="user-content-zigler-principles" aria-label="Permalink: Zigler Principles" href="#zigler-principles"></a></p>
<ol dir="auto">
<li>Make being a good citizen of the BEAM easy.</li>
<li>Use magic, but sparingly, only to prevent errors.</li>
<li>Let the user see behind the curtain.</li>
<li>Let the user opt out of magic.</li>
<li>Magic shouldn't get in the way.</li>
</ol>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cable companies ask 5th Circuit to block FTC's click-to-cancel rule (214 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/10/cable-companies-ask-5th-circuit-to-block-ftcs-click-to-cancel-rule/</link>
            <guid>41937666</guid>
            <pubDate>Thu, 24 Oct 2024 17:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/10/cable-companies-ask-5th-circuit-to-block-ftcs-click-to-cancel-rule/">https://arstechnica.com/tech-policy/2024/10/cable-companies-ask-5th-circuit-to-block-ftcs-click-to-cancel-rule/</a>, See on <a href="https://news.ycombinator.com/item?id=41937666">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>The FTC declined to comment on the lawsuits today. The agency's rule is not enforced yet, as it is scheduled to take full effect 180 days after publication in the Federal Register.</p>
<h2>Cable firms don’t want canceling to be easy</h2>
<p>The NCTA cable lobby group, which represents companies like Comcast and Charter, have complained about the rule's impact on their ability to talk customers out of canceling. NCTA CEO Michael Powell <a href="https://arstechnica.com/tech-policy/2024/01/cable-firms-to-ftc-we-shouldnt-have-to-let-users-cancel-service-with-a-click/">claimed during a January 2024 hearing</a> that "a consumer may easily misunderstand the consequences of canceling and it may be imperative that they learn about better options" and that the rule's disclosure and consent requirements raise "First Amendment issues."</p>
<p>The Interactive Advertising Bureau argued at the same hearing that the rule would "restrict innovation without any corresponding benefit" and "constrain companies from being able to adapt their offerings to the needs of their customers."</p>
<p>The FTC held firm, adopting its proposed rule without major changes. In addition to the click-to-cancel provision, the FTC set out other requirements for "negative option" features in which a consumer's silence or failure to take action to reject or cancel an agreement is interpreted by the seller as acceptance of an offer.</p>
<p>The FTC said its rule "prohibits misrepresentations of any material fact made while marketing using negative option features; requires sellers to provide important information prior to obtaining consumers' billing information and charging consumers; [and] requires sellers to obtain consumers' unambiguously affirmative consent to the negative option feature prior to charging them."</p>
<p>The FTC will have to defend its authority to issue the rule in court. The agency decision cites authority under Section 18 of the FTC Act to make "rules that define with specificity acts or practices that are unfair or deceptive" and "prescribe requirements for the purpose of preventing these unfair or deceptive acts and practices."</p>
<p>"Too often, businesses make people jump through endless hoops just to cancel a subscription," FTC Chair Lina Khan said. "The FTC's rule will end these tricks and traps, saving Americans time and money. Nobody should be stuck paying for a service they no longer want."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Security research on Private Cloud Compute (237 pts)]]></title>
            <link>https://security.apple.com/blog/pcc-security-research/</link>
            <guid>41937664</guid>
            <pubDate>Thu, 24 Oct 2024 17:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.apple.com/blog/pcc-security-research/">https://security.apple.com/blog/pcc-security-research/</a>, See on <a href="https://news.ycombinator.com/item?id=41937664">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p><span><figure><picture><source srcset="https://security.apple.com/assets/image/generated/xlarge_pcc-vre-launch-bug-image-blog-post-light.png 2500w, https://security.apple.com/assets/image/generated/large_pcc-vre-launch-bug-image-blog-post-light.png 1650w, https://security.apple.com/assets/image/generated/medium_pcc-vre-launch-bug-image-blog-post-light.png 1300w, https://security.apple.com/assets/image/generated/small_pcc-vre-launch-bug-image-blog-post-light.png 840w, https://security.apple.com/assets/image/generated/xsmall_pcc-vre-launch-bug-image-blog-post-light.png 560w" media="(prefers-color-scheme: light)" decoding="async" loading="lazy"><img alt="The high-level architecture of Private Cloud Compute" src="https://security.apple.com/assets/image/generated/medium_pcc-vre-launch-bug-image-blog-post~dark@2x.png" srcset="https://security.apple.com/assets/image/generated/xlarge_pcc-vre-launch-bug-image-blog-post~dark@2x.png 2500w, https://security.apple.com/assets/image/generated/large_pcc-vre-launch-bug-image-blog-post~dark@2x.png 1650w, https://security.apple.com/assets/image/generated/medium_pcc-vre-launch-bug-image-blog-post~dark@2x.png 1300w, https://security.apple.com/assets/image/generated/small_pcc-vre-launch-bug-image-blog-post~dark@2x.png 840w, https://security.apple.com/assets/image/generated/xsmall_pcc-vre-launch-bug-image-blog-post~dark@2x.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></picture></figure></span></p>
<p>Private Cloud Compute (PCC) fulfills computationally intensive requests for Apple Intelligence while providing groundbreaking privacy and security protections — by bringing our industry-leading device security model into the cloud. In our previous post <a href="https://security.apple.com/blog/private-cloud-compute/">introducing Private Cloud Compute</a>, we explained that to build public trust in the system, we would take the extraordinary step of allowing security and privacy researchers to inspect and verify the end-to-end security and privacy promises of PCC. In the weeks after we announced Apple Intelligence and PCC, we provided third-party auditors and select security researchers early access to the resources we created to enable this inspection, including the PCC Virtual Research Environment (VRE).</p>
<p>Today we’re making these resources publicly available to invite all security and privacy researchers — or anyone with interest and a technical curiosity — to learn more about PCC and perform their own independent verification of our claims. And we’re excited to announce that we’re expanding Apple Security Bounty to include PCC, with significant rewards for reports of issues with our security or privacy claims.</p>
<h3>Security guide</h3>
<p><span><figure><img alt="Security Guide Icon" src="https://security.apple.com/assets/image/generated/medium_security-guide.png" srcset="https://security.apple.com/assets/image/generated/xlarge_security-guide.png 2500w, https://security.apple.com/assets/image/generated/large_security-guide.png 1650w, https://security.apple.com/assets/image/generated/medium_security-guide.png 1300w, https://security.apple.com/assets/image/generated/small_security-guide.png 840w, https://security.apple.com/assets/image/generated/xsmall_security-guide.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>To help you understand how we designed PCC’s architecture to accomplish each of our core requirements, we’ve published the <a href="https://security.apple.com/documentation/private-cloud-compute">Private Cloud Compute Security Guide</a>. The guide includes comprehensive technical details about the components of PCC and how they work together to deliver a groundbreaking level of privacy for AI processing in the cloud. The guide covers topics such as: how PCC attestations build on an immutable foundation of features implemented in hardware; how PCC requests are authenticated and routed to provide non-targetability; how we technically ensure that you can inspect the software running in Apple’s data centers; and how PCC’s privacy and security properties hold up in various attack scenarios.</p>
<h3>Virtual Research Environment</h3>
<p><span><figure><img alt="Virtual Research Environment Icon" src="https://security.apple.com/assets/image/generated/medium_vre.png" srcset="https://security.apple.com/assets/image/generated/xlarge_vre.png 2500w, https://security.apple.com/assets/image/generated/large_vre.png 1650w, https://security.apple.com/assets/image/generated/medium_vre.png 1300w, https://security.apple.com/assets/image/generated/small_vre.png 840w, https://security.apple.com/assets/image/generated/xsmall_vre.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>For the first time ever, we’ve created a Virtual Research Environment (VRE) for an Apple platform. The VRE is a set of tools that enables you to perform your own security analysis of Private Cloud Compute right from your Mac. This environment enables you to go well beyond simply understanding the security features of the platform. You can confirm that Private Cloud Compute indeed maintains user privacy in the ways we describe.</p>
<p>The VRE runs the PCC node software in a virtual machine with only minor modifications. Userspace software runs identically to the PCC node, with the boot process and kernel adapted for virtualization. The VRE includes a virtual Secure Enclave Processor (SEP), enabling security research in this component for the first time — and also uses the built-in macOS support for paravirtualized graphics to enable inference.</p>
<p>You can use the VRE tools to:</p>
<ul>
<li>List and inspect PCC software releases</li>
<li>Verify the consistency of the transparency log</li>
<li>Download the binaries corresponding to each release</li>
<li>Boot a release in a virtualized environment</li>
<li>Perform inference against demonstration models</li>
<li>Modify and debug the PCC software to enable deeper investigation</li>
</ul>
<div><figure><img alt="The Virtual Research Environment for Private Cloud Compute" src="https://security.apple.com/assets/image/generated/medium_PCC_VRE.png" srcset="https://security.apple.com/assets/image/generated/xlarge_PCC_VRE.png 2500w, https://security.apple.com/assets/image/generated/large_PCC_VRE.png 1650w, https://security.apple.com/assets/image/generated/medium_PCC_VRE.png 1300w, https://security.apple.com/assets/image/generated/small_PCC_VRE.png 840w, https://security.apple.com/assets/image/generated/xsmall_PCC_VRE.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></div>
<p>The VRE is available in the latest macOS Sequoia 15.1 Developer Preview and requires a Mac with Apple silicon and 16GB or more unified memory. Learn how to <a href="https://security.apple.com/documentation/private-cloud-compute/vresetup">get started with the Private Cloud Compute Virtual Research Environment</a>.</p>
<h3>Private Cloud Compute source code</h3>
<p><span><figure><img alt="Source Code Icon" src="https://security.apple.com/assets/image/generated/medium_source-code.png" srcset="https://security.apple.com/assets/image/generated/xlarge_source-code.png 2500w, https://security.apple.com/assets/image/generated/large_source-code.png 1650w, https://security.apple.com/assets/image/generated/medium_source-code.png 1300w, https://security.apple.com/assets/image/generated/small_source-code.png 840w, https://security.apple.com/assets/image/generated/xsmall_source-code.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>We’re also making available the source code for certain key components of PCC that help to implement its security and privacy requirements. We provide this source under a limited-use license agreement to allow you to perform deeper analysis of PCC.</p>
<p>The projects for which we’re releasing source code cover a range of PCC areas, including:</p>
<ul>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/CloudAttestation/CloudAttestation">CloudAttestation</a> project, which is responsible for constructing and validating the PCC node’s attestations.</li>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/Thimble">Thimble</a> project, which includes the privatecloudcomputed daemon that runs on a user’s device and uses CloudAttestation to enforce verifiable transparency.</li>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/darwinOSBits/splunkloggingd">splunkloggingd</a> daemon, which filters the logs that can be emitted from a PCC node to protect against accidental data disclosure.</li>
<li>The <a href="https://github.com/apple/security-pcc/tree/main/srd_tools">srd_tools</a> project, which contains the VRE tooling and which you can use to understand how the VRE enables running the PCC code.</li>
</ul>
<p>You can find the available PCC source code in the <a href="https://github.com/apple/security-pcc">apple/security-pcc</a> project on GitHub.</p>
<h3>Apple Security Bounty for Private Cloud Compute</h3>
<p><span><figure><img alt="Bug Bounty Icon" src="https://security.apple.com/assets/image/generated/medium_bug-bounty.png" srcset="https://security.apple.com/assets/image/generated/xlarge_bug-bounty.png 2500w, https://security.apple.com/assets/image/generated/large_bug-bounty.png 1650w, https://security.apple.com/assets/image/generated/medium_bug-bounty.png 1300w, https://security.apple.com/assets/image/generated/small_bug-bounty.png 840w, https://security.apple.com/assets/image/generated/xsmall_bug-bounty.png 560w" sizes="(max-width:734px) 100vw, (max-width:1068px) calc(100vw - 76px), 650px" decoding="async" loading="lazy"></figure></span></p><p>To further encourage your research in Private Cloud Compute, we’re expanding Apple Security Bounty to include rewards for vulnerabilities that demonstrate a compromise of the fundamental security and privacy guarantees of PCC.</p>
<p>Our new PCC bounty categories are aligned with the <a href="https://security.apple.com/documentation/private-cloud-compute/attacks">most critical threats</a> we describe in the Security Guide:</p>
<ul>
<li><strong>Accidental data disclosure</strong>: vulnerabilities leading to unintended data exposure due to configuration flaws or system design issues.</li>
<li><strong>External compromise from user requests</strong>: vulnerabilities enabling external actors to exploit user requests to gain unauthorized access to PCC.</li>
<li><strong>Physical or internal access</strong>: vulnerabilities where access to internal interfaces enables a compromise of the system.</li>
</ul>
<p>Because PCC extends the industry-leading security and privacy of Apple devices into the cloud, the rewards we offer are comparable to those for iOS. We award maximum amounts for vulnerabilities that compromise user data and inference request data outside the PCC trust boundary.</p>

<p><em>Apple Security Bounty: Private Cloud Compute</em></p>
<table><thead><tr><th>Category</th>
<th>Description</th>
<th>Maximum Bounty</th></tr></thead><tbody><tr><td rowspan="2">Remote attack on request data</td>
<td>Arbitrary code execution with arbitrary entitlements</td>
<td>$1,000,000</td></tr><tr><td>Access to a user's request data or sensitive information about the user's requests outside the trust boundary</td>
<td>$250,000</td></tr><tr><td rowspan="3">Attack on request data from a privileged network position</td>
<td>Access to a user's request data or other sensitive information about the user outside the trust
boundary</td>
<td>$150,000</td></tr><tr><td>Ability to execute unattested code</td>
<td>$100,000</td></tr><tr><td>Accidental or unexpected data disclosure due to deployment or configuration issue</td>
<td>$50,000</td></tr></tbody></table>

<p>Because we care deeply about any compromise to user privacy or security, we will consider any security issue that has a significant impact to PCC for an Apple Security Bounty reward, even if it doesn’t match a published category. We’ll evaluate every report according to the quality of what's presented, the proof of what can be exploited, and the impact to users. Visit our <a href="https://security.apple.com/bounty">Apple Security Bounty</a> page to learn more about the program and to submit your research.</p>
<h3>In closing</h3>
<p>We designed Private Cloud Compute as part of Apple Intelligence to take an extraordinary step forward for privacy in AI. This includes providing verifiable transparency — a unique property that sets it apart from other server-based AI approaches. Building on our experience with the <a href="https://security.apple.com/research-device/">Apple Security Research Device Program</a>, the tooling and documentation that we released today makes it easier than ever for anyone to not only study, but verify PCC’s critical security and privacy features. We hope that you’ll dive deeper into PCC’s design with our Security Guide, explore the code yourself with the Virtual Research Environment, and report any issues you find through Apple Security Bounty. We believe Private Cloud Compute is the most advanced security architecture ever deployed for cloud AI compute at scale, and we look forward to working with the research community to build trust in the system and make it even more secure and private over time.</p>
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Architecture is here (141 pts)]]></title>
            <link>https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here</link>
            <guid>41937591</guid>
            <pubDate>Thu, 24 Oct 2024 17:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here">https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here</a>, See on <a href="https://news.ycombinator.com/item?id=41937591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p>React Native 0.76 with the New Architecture by default is now available on npm!</p>
<p>In the <a href="https://reactnative.dev/blog/2024/10/23/release-0.76-new-architecture">0.76 release blog post</a>, we shared a list of significant changes included in this version. In this post, we provide an overview of the New Architecture and how it shapes the future of React Native.</p>
<p>The New Architecture adds full support for modern React features, including <a href="https://react.dev/blog/2022/03/29/react-v18#new-suspense-features" target="_blank" rel="noopener noreferrer">Suspense</a>, <a href="https://react.dev/blog/2022/03/29/react-v18#new-feature-transitions" target="_blank" rel="noopener noreferrer">Transitions</a>, <a href="https://react.dev/blog/2022/03/29/react-v18#new-feature-automatic-batching" target="_blank" rel="noopener noreferrer">automatic batching</a>, and <a href="https://react.dev/reference/react/useLayoutEffect" target="_blank" rel="noopener noreferrer"><code>useLayoutEffect</code></a>. The New Architecture also includes new <a href="https://reactnative.dev/docs/next/turbo-native-modules-introduction">Native Module</a> and <a href="https://reactnative.dev/docs/next/fabric-native-components-introduction">Native Component</a> systems that let you write type-safe code with direct access to native interfaces without a bridge.</p>
<p>This release is the result of a ground-up rewrite of React Native we’ve been working on since 2018, and we’ve taken extra care to make the New Architecture a gradual migration for most apps. In 2021, we created <a href="https://github.com/reactwg/react-native-new-architecture/" target="_blank" rel="noopener noreferrer">the New Architecture Working Group</a> to collaborate with the community on ensuring a smooth upgrade experience for the entire React ecosystem.</p>
<p>Most apps will be able to adopt React Native 0.76 with the same level of effort as any other release. The most popular React Native libraries already support the New Architecture. The New Architecture also includes an automatic interoperability layer to enable backward compatibility with libraries targeting the old architecture.</p>
<p>Over the past several years of development, our team has publicly shared our vision for the New Architecture. If you missed any of these talks, check them out here:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=52El0EUI6D0" target="_blank" rel="noopener noreferrer">React Native EU 2019 - The New React Native</a></li>
<li><a href="https://www.youtube.com/watch?v=FZ0cG47msEk" target="_blank" rel="noopener noreferrer">React Conf 2021 - React 18 Keynote</a></li>
<li><a href="https://www.youtube.com/watch?v=Q6TkkzRJfUo" target="_blank" rel="noopener noreferrer">App.js 2022 - Bringing the New React Native Architecture to the OSS Community</a></li>
<li><a href="https://www.youtube.com/watch?v=Q5SMmKb7qVI" target="_blank" rel="noopener noreferrer">React Conf 2024 - Day 2 Keynote</a></li>
</ul>
<h2 id="what-is-the-new-architecture">What is the New Architecture<a href="#what-is-the-new-architecture" aria-label="Direct link to What is the New Architecture" title="Direct link to What is the New Architecture">​</a></h2>
<p>The New Architecture is a complete rewrite of the major systems that underpin React Native, including how components are rendered, how JavaScript abstractions communicates with native abstractions, and how work is scheduled across different threads. Although most users should not have to think about how these systems work, these changes bring improvements and new capabilities.</p>
<p>In the old architecture, React Native communicated with the native platform using an asynchronous bridge. To render a component or call a native function, React Native needed to serialize and enqueue native functions calls with the bridge, which would be processed asynchronously. The benefit of this architecture is that the main thread was never blocked for rendering updates or handling native module function calls, since all work was done on a background thread.</p>
<p>However, users expect immediate feedback to interactions to feel like a native app. This means some updates need to render synchronously in response to user input, potentially interrupting any in-progress render. Since the old architecture was only asynchronous, we needed to rewrite it to allow for both asynchronous and synchronous updates.</p>
<p>Additionally, in the old architecture, serializing function calls over the bridge quickly became a bottleneck, especially for frequent updates or large objects. This made it hard for apps to achieve 60+ FPS reliably. There were also synchronization issues: when the JavaScript and native layer got out of sync, it was impossible to reconcile them synchronously, resulting bugs like lists showing frames of empty space and visual UI jumps due to intermediate states rendering.</p>
<p>Finally, since the old architecture kept a single copy of the UI using the native hierarchy, and mutated that copy in place, layout could only be computed on a single thread. This made it impossible to process urgent updates like user inputs, and layout could not be read synchronously, such as reading in a layout effect to update the position of a tooltip.</p>
<p>All of these problems meant that it was not possible to properly support React’s concurrent features. To solve these problems, the New Architecture includes four main parts:</p>
<ul>
<li>The New Native Module System</li>
<li>The New Renderer</li>
<li>The Event Loop</li>
<li>Removing the Bridge</li>
</ul>
<p>The New Module system allows the React Native Renderer to have synchronous access to the native layer, which allows it to handle events, schedule updates, and read layout both asynchronously and synchronously. The new Native Modules are also lazily loaded by default, giving apps a significant performance gain.</p>
<p>The New Renderer can handle multiple in progress trees across multiple threads, which allows React to process multiple concurrent update priorities, either on the main thread or a background thread. It also supports reading layout from multiple threads synchronously or asynchronously, to support more responsive UIs without jank.</p>
<p>The new Event Loop can process tasks on the JavaScript thread in a well-defined order. This allows React to interrupt rendering to process events so urgent user events can take priority over lower priority UI transitions. The Event Loop also aligns with web specifications, so we can support for browser features like microtasks, <code>MutationObserver</code>, and <code>IntersectionObserver</code>.</p>
<p>Finally, removing the bridge allows for faster startup and direct communication between JavaScript and the native runtime, so that the cost of switching work is minimized. This also allows for better error reporting, debugging, and reducing crashes from undefined behavior.</p>
<p>The New Architecture is now ready to be used in production. It is already used at scale at Meta in the Facebook app and in other products. We successfully used React Native and the New Architecture in the Facebook and Instagram app we developed for our <a href="https://engineering.fb.com/2024/10/02/android/react-at-meta-connect-2024/" target="_blank" rel="noopener noreferrer">Quest devices</a>.</p>
<p>Our partners have already been using the New Architecture in production for months now: have a look at these success stories by <a href="https://blog.swmansion.com/sunrising-new-architecture-in-the-new-expensify-app-729d237a02f5" target="_blank" rel="noopener noreferrer">Expensify</a> and <a href="https://blog.kraken.com/product/engineering/how-kraken-fixed-performance-issues-via-incremental-adoption-of-the-react-native-new-architecture" target="_blank" rel="noopener noreferrer">Kraken</a>, and give <a href="https://github.com/bluesky-social/social-app/releases/tag/1.92.0-na-rc.2" target="_blank" rel="noopener noreferrer">BlueSky</a> a shot with their new release.</p>
<h3 id="new-native-modules">New Native Modules<a href="#new-native-modules" aria-label="Direct link to New Native Modules" title="Direct link to New Native Modules">​</a></h3>
<p>The new Native Module System is a major rewrite of how JavaScript and the native platform communicate. It’s written entirely in C++, which unlocks many new capabilities:</p>
<ul>
<li>Synchronous access to and from the native runtime</li>
<li>Type safety between JavaScript and native code</li>
<li>Code sharing across platforms</li>
<li>Lazy module loading by default</li>
</ul>
<p>In the new Native Module system, JavaScript and the native layer can now synchronously communicate with each other through the JavaScript Interface (JSI), without the need to use an asynchronous bridge. This means your custom Native Modules can now synchronously call a function, return a value, and pass that value back to another Native Module function.</p>
<p>In the old architecture, in order to handle a response from native function calls, you needed to provide a callback, and the value returned needed to be serializable:</p>
<div><pre tabindex="0"><code><span><span>// ❌ Sync callback from Native Module</span><span></span><br></span><span><span>nativeModule</span><span>.</span><span>getValue</span><span>(</span><span>value </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// ❌ value cannot reference a native object</span><span></span><br></span><span><span>  nativeModule</span><span>.</span><span>doSomething</span><span>(</span><span>value</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>In the New Architecture, you can make synchronous calls to native functions:</p>
<div><pre tabindex="0"><code><span><span>// ✅ Sync response from Native Module</span><span></span><br></span><span><span></span><span>const</span><span> value </span><span>=</span><span> nativeModule</span><span>.</span><span>getValue</span><span>(</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// ✅ value can be a reference to a native object</span><span></span><br></span><span><span>nativeModule</span><span>.</span><span>doSomething</span><span>(</span><span>value</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>With the New Architecture, you can finally leverage the full power of a C++ native implementation while still accessing it from JavaScript/TypeScript APIs. The New Module System supports <a href="https://reactnative.dev/docs/next/the-new-architecture/pure-cxx-modules">modules written in C++</a> so you can write your module once, and it works across all platforms, including Android, iOS, Windows, and macOS. Implementing modules in C++ allows for more fine-grained memory management and performance optimizations.</p>
<p>Additionally, with <a href="https://reactnative.dev/docs/next/the-new-architecture/what-is-codegen">Codegen</a>, your modules can define a strongly typed contract between the JavaScript layer and the native layer. From our experience, cross-boundary type errors are one of the most common sources of crashes in cross-platform apps. Codegen lets you overcome those problems while also generating boilerplate code for you.</p>
<p>Finally, modules are now lazily loaded: they are loaded in memory only when they’re effectively needed rather than at startup. This reduces the app startup time and keeps it low as the application grows in complexity.</p>
<p>Popular libraries such as <a href="https://github.com/mrousavy/react-native-mmkv" target="_blank" rel="noopener noreferrer">react-native-mmkv</a> have already seen benefits from migrating to the new Native Modules:</p>
<blockquote>
<p>“The new Native Modules greatly simplified setup, autolinking, and initialization for <code>react-native-mmkv</code>. Thanks to the New Architecture, <code>react-native-mmkv</code> is now a pure C++ Native Module, which allows it to work on any platform. The new Codegen allows MMKV to be fully type-safe, which fixed a long-standing <code>NullPointerReference</code> issue by enforcing null-safety, and being able to call Native Module functions synchronously allowed us to replace custom JSI access with the new Native Module API.”</p>
<p><a href="https://twitter.com/mrousavy" target="_blank" rel="noopener noreferrer">Marc Rousavy</a>, creator of <code>react-native-mmkv</code></p>
</blockquote>
<h3 id="new-renderer">New Renderer<a href="#new-renderer" aria-label="Direct link to New Renderer" title="Direct link to New Renderer">​</a></h3>
<p>We've also completely rewritten the Native Renderer, adding several benefits:</p>
<ul>
<li>Updates can be rendered on different threads at different priorities.</li>
<li>Layout can be read synchronously and across different threads.</li>
<li>The renderer is written in C++ and shared across all platforms.</li>
</ul>
<p>The updated Native Renderer now stores the view hierarchy in an immutable tree structure. This means that the UI is stored in a way that cannot be changed directly, allowing for thread-safe processing of updates. This allows it to handle multiple in-progress trees, each representing a different version of the user interface. As a result, updates can be rendered in the background without blocking the UI (such as during transitions) or on the main thread (in response to user input).</p>
<p>By supporting multiple threads, React can interrupt a low-priority update to render an urgent one, such as those generated by user inputs, and then resume the low-priority update as needed. The new renderer can also read layout information synchronously and across different threads. This enables background computation for low-priority updates and synchronous reads when needed, such as repositioning a tooltip.</p>
<p>Finally, rewriting the renderer in C++ allows it to be shared across all platforms. This ensures that the same code runs on iOS, Android, Windows, macOS, and any other React Native-supported platform, providing consistent rendering capabilities without needing re-implementation for each platform.</p>
<p>This is a significant step towards our <a href="https://reactnative.dev/blog/2021/08/26/many-platform-vision">Many Platform Vision</a>. For example, View Flattening was an Android-only optimisation to avoid deep layout trees. The new renderer, with shared C++ core, <a href="https://github.com/reactwg/react-native-new-architecture/discussions/110" target="_blank" rel="noopener noreferrer">brings this feature to iOS</a>. This optimisation is automatic and does not require setup, it comes for free with the shared renderer.</p>
<p>With these changes, React Native now fully supports Concurrent React features like Suspense and Transitions, making it easier to build complex user interfaces that respond quickly to user input without jank, delays, or visual jumps. In the future, we will leverage these new capabilities to bring more improvements to built-in components such as FlatList and TextInput.</p>
<p>Popular libraries like <a href="https://docs.swmansion.com/react-native-reanimated/" target="_blank" rel="noopener noreferrer">Reanimated</a> are already taking advantage of the New Renderer:</p>
<blockquote>
<p>“Reanimated 4, currently in development, introduces a new animation engine that works directly with the New Renderer, allowing it to handle animations and manage layout across different threads. The New Renderer’s design is what truly enables these features to be built without relying on numerous workarounds. Moreover, because it’s implemented in C++ and shared across platforms, large portions of Reanimated can be written once, reducing platform-specific issues, minimizing the codebase, and streamlining adoption for out-of-tree platforms.”</p>
<p><a href="https://x.com/kzzzf" target="_blank" rel="noopener noreferrer">Krzysztof Magiera</a>, creator of <a href="https://docs.swmansion.com/react-native-reanimated/" target="_blank" rel="noopener noreferrer">Reanimated</a></p>
</blockquote>
<h3 id="the-event-loop">The Event Loop<a href="#the-event-loop" aria-label="Direct link to The Event Loop" title="Direct link to The Event Loop">​</a></h3>
<p>The New Architecture allowed us to implement a well-defined event loop processing model, as described in this <a href="https://github.com/react-native-community/discussions-and-proposals/blob/main/proposals/0744-well-defined-event-loop.md" target="_blank" rel="noopener noreferrer">RFC</a>. This RFC follows the specifications described in the <a href="https://html.spec.whatwg.org/multipage/webappapis.html#event-loop-processing-model" target="_blank" rel="noopener noreferrer">HTML Standard</a>, and it describes how React Native should perform tasks on the JavaScript thread.</p>
<p>Implementing a well-defined event loop closes gaps between React DOM and React Native: the behavior of a React Native application is now closer to the behavior of a React DOM application, making it easier to learn once, and write anywhere.</p>
<p>The event loop brings many benefits to React Native:</p>
<ul>
<li>The ability to interrupt rendering to process events and tasks</li>
<li>Closer alignment with web specifications</li>
<li>Foundation for more browser features</li>
</ul>
<p>With the Event Loop, React is able to predictably order updates and events. This allows React to interrupt a low priority update with an urgent user event, and the New Renderer allows us to render those updates independently.</p>
<p>The Event Loops also aligns the behavior of events and task like timers with web specifications, which means React Native works more like what users are familiar with in the Web, and allows for better code sharing between React DOM and React Native.</p>
<p>It also allows for the implementation of more compliant browser features like microtasks, <code>MutationObserver</code>, and <code>IntersectionObserver</code>. These features are not ready to use in React Native yet, but we are working on bringing them to you in the future.</p>
<p>Finally, the Event Loop and the New Renderer changes to support reading layout synchronously allow React Native to add proper support for <code>useLayoutEffect</code> to read layout information synchronously and update the UI in the same frame. This allows you to position elements correctly before they are displayed to the user.</p>
<p>See <a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here#uselayouteffect"><code>useLayoutEffect</code></a> for more details.</p>
<h3 id="removing-the-bridge">Removing the Bridge<a href="#removing-the-bridge" aria-label="Direct link to Removing the Bridge" title="Direct link to Removing the Bridge">​</a></h3>
<p>In the New Architecture, we've also fully removed React Native's dependency on the bridge, replacing it with direct, efficient communication between JavaScript and native code using JSI:</p>
<p><img decoding="async" loading="lazy" src="https://reactnative.dev/assets/images/0.76-bridge-diagram-a653d794d04871e5b7a026e35d8edf03.png" width="1143" height="736"></p>
<p>Removing the bridge improves startup time by avoiding bridge initialization. For example, in the old architecture, in order to provide global methods to JavaScript, we would need to initialize a module in JavaScript on startup, causing a small delay in app startup time:</p>
<div><pre tabindex="0"><code><span><span>// ❌ Slow initialization</span><span></span><br></span><span><span></span><span>import</span><span> </span><span>{</span><span>NativeTimingModule</span><span>}</span><span> </span><span>from</span><span> </span><span>'NativeTimingModule'</span><span>;</span><span></span><br></span><span><span>global</span><span>.</span><span>setTimeout</span><span> </span><span>=</span><span> </span><span>timer</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>NativeTimingModule</span><span>.</span><span>setTimeout</span><span>(</span><span>timer</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// App.js</span><span></span><br></span><span><span></span><span>setTimeout</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>}</span><span>,</span><span> </span><span>100</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>In the New Architecture, we can directly bind methods from C++:</p>
<div><pre tabindex="0"><code><span><span>// ✅ Initialize directly in C++</span><span></span><br></span><span><span>runtime</span><span>.</span><span>global</span><span>(</span><span>)</span><span>.</span><span>setProperty</span><span>(</span><span>runtime</span><span>,</span><span> </span><span>"setTimeout"</span><span>,</span><span> createTimer</span><span>)</span><span>;</span><br></span></code></pre></div>
<div><pre tabindex="0"><code><span><span>// App.js</span><span></span><br></span><span><span></span><span>setTimeout</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>}</span><span>,</span><span> </span><span>100</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>The rewrite also improves error reporting, particularly for JavaScript crashes at startup, and reduces crashes from undefined behavior. If crashes occur, the new <a href="https://reactnative.dev/docs/next/react-native-devtools">React Native DevTools</a> simplify debugging and support the New Architecture.</p>
<p>The bridge remains for backward compatibility to support gradual migration to the New Architecture. In the future, we will remove the bridge code completely.</p>
<h3 id="gradual-migration">Gradual Migration<a href="#gradual-migration" aria-label="Direct link to Gradual Migration" title="Direct link to Gradual Migration">​</a></h3>
<p>We expect most apps can upgrade to 0.76 with the same effort as any other release.</p>
<p>When you upgrade to 0.76, the New Architecture and React 18 are enabled by default. However, to use concurrent features and gain the full benefits of the New Architecture, your app and libraries will need to be gradually migrated to fully support the New Architecture.</p>
<p>When you first upgrade, your app will run on the New Architecture with an automatic interoperability layer with the old architecture. For most apps, this will work without any changes, but there are <a href="https://github.com/reactwg/react-native-new-architecture/discussions/237" target="_blank" rel="noopener noreferrer">known limitations</a> with the interop layer, as it does not support accessing custom Shadow Nodes or concurrent features.</p>
<p>To use concurrent features, apps will also need to be updated to support <a href="https://react.dev/blog/2022/03/29/react-v18#what-is-concurrent-react" target="_blank" rel="noopener noreferrer">Concurrent React</a> by following the <a href="https://react.dev/reference/rules" target="_blank" rel="noopener noreferrer">Rules of React</a>. To migrate your JavaScript code to React 18 and its semantics, follow the <a href="https://react.dev/blog/2022/03/08/react-18-upgrade-guide" target="_blank" rel="noopener noreferrer">React 18 Upgrade guide</a>.</p>
<p>The overall strategy is to get your application running on the New Architecture without breaking existing code. You can then gradually migrate your app at your own pace. For new surfaces that have migrated all modules to the New Architecture, you can start using concurrent features immediately. For existing surfaces, you may need to address some issues and migrate modules before adding concurrent features.</p>
<p>We've collaborated with the most popular React Native libraries to ensure support for the New Architecture. More than 850 libraries are already compatible, including all libraries with over 200K weekly downloads (~10% of downloaded libraries). You can check library compatibility with the New Architecture on the <a href="https://reactnative.directory/" target="_blank" rel="noopener noreferrer">reactnative.directory</a> website:</p>
<p><img decoding="async" loading="lazy" src="https://reactnative.dev/assets/images/0.76-directory-85387cf0da638f887bbf996c39db432d.png" width="1999" height="785"></p>
<p>For more details on upgrading, see <a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here#how-to-upgrade">How to Upgrade</a> below.</p>
<h2 id="new-features">New Features<a href="#new-features" aria-label="Direct link to New Features" title="Direct link to New Features">​</a></h2>
<p>The New Architecture includes full support for React 18, concurrent features, and <code>useLayoutEffect</code> in React Native. For a full list of React 18 features, please see the <a href="https://react.dev/blog/2021/12/17/react-conf-2021-recap#react-18-and-concurrent-features" target="_blank" rel="noopener noreferrer">React 18 blog post</a>.</p>
<h3 id="transitions">Transitions<a href="#transitions" aria-label="Direct link to Transitions" title="Direct link to Transitions">​</a></h3>
<p>Transitions are a new concept in React 18 to distinguish between urgent and non-urgent updates.</p>
<ul>
<li><strong>Urgent updates</strong> reflect direct interaction, like typing and pressing.</li>
<li><strong>Transition updates</strong> transition the UI from one view to another.</li>
</ul>
<p>Urgent updates need immediate response to match our intuitions about how physical objects behave. However, transitions are different because the user doesn’t expect to see every intermediate value on screen. In the New Architecture, React Native is able to support rendering urgent updates and transition updates separately.</p>
<p>Typically, for the best user experience, a single user input should result in both an urgent update and a non-urgent one. Similar to ReactDOM, events like <code>press</code> or <code>change</code> are handled as urgent and rendered immediately. You can use the <code>startTransition</code> API inside an input event to inform React which updates are “transitions” and can be deferred to the background:</p>
<div><pre tabindex="0"><code><span><span>import</span><span> </span><span>{</span><span>startTransition</span><span>}</span><span> </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// Urgent: Show the slider value</span><span></span><br></span><span><span></span><span>setCount</span><span>(</span><span>input</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// Mark any state updates inside as transitions</span><span></span><br></span><span><span></span><span>startTransition</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// Transition: Show the results</span><span></span><br></span><span><span>  </span><span>setNumberOfTiles</span><span>(</span><span>input</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>)</span><span>;</span><br></span></code></pre></div>
<p>Separating urgent events from transitions allows for a more responsive user interface, and a more intuitive user experience.</p>
<p>Here's a comparison of the old architecture without transitions and the new architecture with transitions. Imagine that each tile isn't a trivial view with a background color, but a rich component containing images and other components that are expensive to render. <strong>After</strong> using <code>useTransition</code> you avoid thrashing your app with updates and falling behind.</p>

<p>For more information, see <a href="https://reactnative.dev/docs/0.75/the-new-architecture/landing-page#support-for-concurrent-renderer-and-features">Support for Concurrent Renderer and Features</a>.</p>
<h3 id="automatic-batching">Automatic Batching<a href="#automatic-batching" aria-label="Direct link to Automatic Batching" title="Direct link to Automatic Batching">​</a></h3>
<p>When upgrading to the New Architecture, you will benefit from automatic batching from React 18.</p>
<p>Automatic batching allows React to batch together more state updates when rendering to avoid the rendering of intermediate states. This allows React Native to be faster and less susceptible to lags, without any additional code from the developer.</p>

<p>In the old architecture, more intermediate states are rendered, and the UI keeps updating even when the slider stops moving. The New Architecture, renders fewer intermediate states and completes the rendering much sooner thanks to automatically batching the updates.</p>
<p>For more information, see <a href="https://reactnative.dev/docs/0.75/the-new-architecture/landing-page#support-for-concurrent-renderer-and-features">Support for Concurrent Renderer and Features</a>.</p>
<h3 id="uselayouteffect">useLayoutEffect<a href="#uselayouteffect" aria-label="Direct link to useLayoutEffect" title="Direct link to useLayoutEffect">​</a></h3>
<p>Building on the Event Loop and the ability to read layout synchronously, in the New Architecture we added proper support for <code>useLayoutEffect</code> in React Native.</p>
<p>In the old architecture, you needed to use the asynchronous <code>onLayout</code> event to read layout information of a view (which was also asynchronous). As a result there would be at least one frame where the layout was incorrect until the layout was read and updated, causing issues like tooltips placed in the wrong position:</p>
<div><pre tabindex="0"><code><span><span>// ❌ async onLayout after commit</span><span></span><br></span><span><span></span><span>const</span><span> onLayout </span><span>=</span><span> </span><span>React</span><span>.</span><span>useCallback</span><span>(</span><span>event </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// ❌ async callback to read layout</span><span></span><br></span><span><span>  ref</span><span>.</span><span>current</span><span>?.</span><span>measureInWindow</span><span>(</span><span>(</span><span>x</span><span>,</span><span> y</span><span>,</span><span> width</span><span>,</span><span> height</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>    </span><span>setPosition</span><span>(</span><span>{</span><span>x</span><span>,</span><span> y</span><span>,</span><span> width</span><span>,</span><span> height</span><span>}</span><span>)</span><span>;</span><span></span><br></span><span><span>  </span><span>}</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// ...</span><span></span><br></span><span><span></span><span>&lt;</span><span>ViewWithTooltip</span><span></span><br></span><span><span>  </span><span>onLayout</span><span>=</span><span>{</span><span>onLayout</span><span>}</span><span></span><br></span><span><span>  </span><span>ref</span><span>=</span><span>{</span><span>ref</span><span>}</span><span></span><br></span><span><span>  </span><span>position</span><span>=</span><span>{</span><span>position</span><span>}</span><span></span><br></span><span><span></span><span>/&gt;</span><span>;</span><br></span></code></pre></div>
<p>The New Architecture fixes this by allowing synchronous access to layout information in <code>useLayoutEffect</code>:</p>
<div><pre tabindex="0"><code><span><span>// ✅ sync layout effect during commit</span><span></span><br></span><span><span></span><span>useLayoutEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>// ✅ sync call to read layout</span><span></span><br></span><span><span>  </span><span>const</span><span> rect </span><span>=</span><span> ref</span><span>.</span><span>current</span><span>?.</span><span>getBoundingClientRect</span><span>(</span><span>)</span><span>;</span><span></span><br></span><span><span>  </span><span>setPosition</span><span>(</span><span>rect</span><span>)</span><span>;</span><span></span><br></span><span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span><br></span><span><span></span><br></span><span><span></span><span>// ...</span><span></span><br></span><span><span></span><span>&lt;</span><span>ViewWithTooltip</span><span> </span><span>ref</span><span>=</span><span>{</span><span>ref</span><span>}</span><span> </span><span>position</span><span>=</span><span>{</span><span>position</span><span>}</span><span> </span><span>/&gt;</span><span>;</span><br></span></code></pre></div>
<p>This change allows you to read layout information synchronously and update the UI in the same frame, allowing you to position elements correctly before they are displayed to the user:</p>

<p>For more information, see the docs for <a href="https://reactnative.dev/docs/0.75/the-new-architecture/landing-page#synchronous-layout-and-effects">Synchronous Layout and Effects</a>.</p>
<h3 id="full-support-for-suspense">Full Support for Suspense<a href="#full-support-for-suspense" aria-label="Direct link to Full Support for Suspense" title="Direct link to Full Support for Suspense">​</a></h3>
<p>Suspense lets you declaratively specify the loading state for a part of the component tree if it’s not yet ready to be displayed:</p>
<div><pre tabindex="0"><code><span><span>&lt;</span><span>Suspense</span><span> </span><span>fallback</span><span>=</span><span>{</span><span>&lt;</span><span>Spinner</span><span> </span><span>/&gt;</span><span>}</span><span>&gt;</span><span></span><br></span><span><span>  </span><span>&lt;</span><span>Comments</span><span> </span><span>/&gt;</span><span></span><br></span><span><span></span><span>&lt;/</span><span>Suspense</span><span>&gt;</span><br></span></code></pre></div>
<p>We introduced a limited version of Suspense several years ago, and React 18 added full support. Until now, React Native was not able to support concurrent rendering for Suspense.</p>
<p>The New Architecture includes full support for Suspense introduced in React 18. This means that you can now use Suspense in React Native to handle loading states for your components, and the suspended content will render in the background while the loading state is displayed, giving higher priority to user input on visible content.</p>
<p>For more, see the <a href="https://github.com/reactjs/rfcs/blob/main/text/0213-suspense-in-react-18.md" target="_blank" rel="noopener noreferrer">RFC for Suspense in React 18</a>.</p>
<h2 id="how-to-upgrade">How to Upgrade<a href="#how-to-upgrade" aria-label="Direct link to How to Upgrade" title="Direct link to How to Upgrade">​</a></h2>
<p>To upgrade to 0.76, follow the steps in the <a href="https://reactnative.dev/blog/2024/10/23/release-0.76-new-architecture#upgrade-to-076">release post</a>. Since this release also upgrades to React 18, you will also need to follow the <a href="https://react.dev/blog/2022/03/08/react-18-upgrade-guide" target="_blank" rel="noopener noreferrer">React 18 Upgrade guide</a>.</p>
<p>These steps should be enough for most apps to upgrade to the New Architecture thanks to the interop layer with the old architecture. However, to take full advantage of the New Architecture and to start using concurrent features, you will need to migrate your custom Native Modules and Native Components to support the new Native Module and Native Component APIs.</p>
<p>Without migrating your custom Native Modules, you will not get the benefits of shared C++, synchronous method calls, or type-safety from codegen. Without migrating your Native Components, you will not be able to use concurrent features. We recommend migrating all Native Components and Native Modules to the New Architecture as soon as possible.</p>
<div><p><span><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</p><p>In a future release, we will remove the interop layer and modules will need to support the New Architecture.</p></div>
<h3 id="apps">Apps<a href="#apps" aria-label="Direct link to Apps" title="Direct link to Apps">​</a></h3>
<p>If you are an app developer, to fully support the New Architecture, you will need to upgrade your libraries, custom Native Components, and custom Native Modules to fully support the New Architecture.</p>
<p>We've collaborated with the most popular React Native libraries to ensure support for the New Architecture. You can check library compatibility with the New Architecture on the <a href="https://reactnative.directory/" target="_blank" rel="noopener noreferrer">reactnative.directory</a> website.</p>
<p>If any of the libraries your app depends on are not compatible yet, you can:</p>
<ul>
<li>Open an issue with the library and ask the author to migrate to the New Architecture.</li>
<li>If the library is not maintained, consider alternative libraries with the same features.</li>
<li><a href="https://reactnative.dev/blog/2024/10/23/the-new-architecture-is-here#opt-out">Opt-out from the New Architecture</a> while those libraries are migrated.</li>
</ul>
<p>If your app has custom Native Modules or custom Native Components, we expect them to work fine, thanks to our <a href="https://github.com/reactwg/react-native-new-architecture/discussions/135" target="_blank" rel="noopener noreferrer">interop layer</a>. However, we recommend upgrading them to the new Native Module and Native Component APIs to fully support the New Architecture and adopt concurrent features.</p>
<p>Please follow these guides to migrate your modules and components to the New Architecture:</p>
<ul>
<li><a href="https://reactnative.dev/docs/next/turbo-native-modules-introduction">Native Modules</a></li>
<li><a href="https://reactnative.dev/docs/next/fabric-native-components-introduction">Native Components</a></li>
</ul>
<h3 id="libraries">Libraries<a href="#libraries" aria-label="Direct link to Libraries" title="Direct link to Libraries">​</a></h3>
<p>If you are a library maintainer, please first test that your library works with the interop layer. If it does not, please open an issue on the <a href="https://github.com/reactwg/react-native-new-architecture/" target="_blank" rel="noopener noreferrer">New Architecture Working Group</a>.</p>
<p>To fully support the New Architecture, we recommend migrating your library to the new Native Module and Native Component APIs as soon as possible. This will allow users of your library to take full advantage of the New Architecture and support concurrent features.</p>
<p>You can follow these guides to migrate your modules and components to the New Architecture:</p>
<ul>
<li><a href="https://reactnative.dev/docs/next/turbo-native-modules-introduction">Native Modules</a></li>
<li><a href="https://reactnative.dev/docs/next/fabric-native-components-introduction">Native Components</a></li>
</ul>
<h3 id="opt-out">Opt-out<a href="#opt-out" aria-label="Direct link to Opt-out" title="Direct link to Opt-out">​</a></h3>
<p>If, for any reason, the New Architecture is not behaving properly in your application, there is always the option to opt-out from it until you are ready to turn it on again.</p>
<p>To opt-out from the New Architecture:</p>
<ul>
<li>On Android, modify the <code>android/gradle.properties</code> file and turn off the <code>newArchEnabled</code> flag</li>
</ul>
<div><pre tabindex="0"><code><span><span>-</span><span>newArchEnabled=true</span><br></span><span><span></span><span>+</span><span>newArchEnabled=false</span><br></span></code></pre></div>
<ul>
<li>On iOS, you can reinstall the dependencies by running the command:</li>
</ul>
<div><pre tabindex="0"><code><span><span>RCT_NEW_ARCH_ENABLED</span><span>=</span><span>0</span><span> bundle </span><span>exec</span><span> pod </span><span>install</span><br></span></code></pre></div>
<h2 id="thanks">Thanks<a href="#thanks" aria-label="Direct link to Thanks" title="Direct link to Thanks">​</a></h2>
<p>Delivering the New Architecture to the OSS community has been a huge effort that took us several years of research and development. We want to take a moment to thank all the current and past members of the React team who helped us achieve this result.</p>
<p>We are also extremely grateful to all the partners who collaborated with us to make this happen. Specifically, we would like to call out:</p>
<ul>
<li><a href="https://expo.dev/" target="_blank" rel="noopener noreferrer">Expo</a>, for adopting the New Architecture early on, and for supporting the work on migrating the most popular libraries.</li>
<li><a href="https://swmansion.com/" target="_blank" rel="noopener noreferrer">Software Mansion</a>, for maintaining crucial libraries in the ecosystem, for migrating them to the New Architecture early and for all the help in investigating and fixing various issues.</li>
<li><a href="https://www.callstack.com/" target="_blank" rel="noopener noreferrer">Callstack</a>, for maintaining crucial libraries in the ecosystem, for migrating them to the New Architecture early and for the support with the work on the Community CLI.</li>
<li><a href="https://opensource.microsoft.com/" target="_blank" rel="noopener noreferrer">Microsoft</a>, for adding the New Architecture implementation for <code>react-native-windows</code> and <code>react-native-macos</code> as well as in several other developer tools.</li>
<li><a href="https://www.expensify.com/" target="_blank" rel="noopener noreferrer">Expensify</a>, <a href="https://www.kraken.com/" target="_blank" rel="noopener noreferrer">Kraken</a>, <a href="https://bsky.app/" target="_blank" rel="noopener noreferrer">BlueSky</a> and <a href="https://www.brigad.co/" target="_blank" rel="noopener noreferrer">Brigad</a> for pioneering the adoption of the New Architecture and reporting various issues so that we could fix them for everyone else.</li>
<li>All the independent library maintainers and developers who contributed to the New Architecture by testing it, fixing some of the issues, and opening questions on unclear matters so that we could clear them.</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lion of St. Mark's Square in Venice Is Chinese (147 pts)]]></title>
            <link>https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/</link>
            <guid>41937443</guid>
            <pubDate>Thu, 24 Oct 2024 17:08:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/">https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/</a>, See on <a href="https://news.ycombinator.com/item?id=41937443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A new study has revealed that the iconic bronze-winged lion in St. Mark’s Square, Venice, may have originated in 8th-century China.</p><figure id="attachment_42823" aria-describedby="caption-attachment-42823"><a href="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1.jpg"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMDI0IiBoZWlnaHQ9Ijc2OCIgdmlld0JveD0iMCAwIDEwMjQgNzY4Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" fetchpriority="high" decoding="async" data-src="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1.jpg" alt="The Lion of St. Mark’s Square in Venice is Chinese: Isotopic Analyses Confirm It" width="1024" height="768" data-srcset="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1.jpg 1024w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-300x225.jpg 300w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-768x576.jpg 768w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-150x113.jpg 150w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-1-750x563.jpg 750w" data-sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-42823">Lion of Venice, Piazzetta San Marco. Credit: Didier Descouens (<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>)</figcaption></figure><p>The discovery comes from a multidisciplinary team of experts in geology, chemistry, archaeology, and art history from the University of Padua, the Ca’ Foscari University of Venice, and the International Association for Mediterranean and Oriental Studies (Ismeo). Through advanced metallurgical analysis, the team discovered that a significant portion of the bronze used in the lion came from the lower Yangtze River basin in southeastern China, and it was likely cast during the Tang Dynasty (618-907 CE).</p><p>Lions were initially introduced to the <a href="https://archaeologymag.com/tag/han-dynasty/">Han</a> court by emissaries from <a href="https://archaeologymag.com/tag/ancient-iran/">Persia</a> (modern-day Iran) and had become widely represented as guardian figures.</p><p>Lead isotope analysis of the bronze alloy provided indisputable evidence of the <a href="https://archaeologymag.com/tag/ancient-china/">Chinese origin</a> of the materials used in the statue. The results were announced on September 11, 2024, during an international conference on Marco Polo, part of Venice’s celebrations marking the 700th anniversary of the famous merchant’s death. Scholars have long debated the lion’s origins, with previous theories suggesting it could have been made in Anatolia during the Hellenistic era. However, the new evidence points directly to China.</p><figure id="attachment_42824" aria-describedby="caption-attachment-42824"><a href="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2.jpg"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iNjAwIiB2aWV3Qm94PSIwIDAgODAwIDYwMCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgc3R5bGU9ImZpbGw6I2NmZDRkYjtmaWxsLW9wYWNpdHk6IDAuMTsiLz48L3N2Zz4=" decoding="async" data-src="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2.jpg" alt="The Lion of St. Mark’s Square in Venice is Chinese: Isotopic Analyses Confirm It" width="800" height="600" data-srcset="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2.jpg 800w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-300x225.jpg 300w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-768x576.jpg 768w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-150x113.jpg 150w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-2-750x563.jpg 750w" data-sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-42824">The Lion in the 1870s. Credit: Carlo Naya, Public domain</figcaption></figure><p>Stylistic analysis further supports this theory. Researchers found that the lion shares several design features with zhenmushou (镇墓兽), or “tomb guardian” figures, typical of the Tang Dynasty. These guardian sculptures, often placed at tomb gates to ward off evil spirits, had distinct characteristics that mirror those of the St. Mark’s lion. For instance, the lion’s wide nostrils, upturned mustache, wide-open mouth with prominent canines, and truncated orbital sockets, where horns or antlers were once mounted, are all common features of zhenmushou statues. The lion’s ears also appear to have been modified to make them look more like those of a typical lion, rather than the pointed ears seen on zhenmushou.</p><p>The lion likely traveled west along the Silk Road, a trade route that connected China with Europe for centuries. It may have passed through India, Afghanistan, and Iran before arriving in Venice, possibly in pieces, where it was reassembled and modified to fit the standard iconography of the winged lion, a symbol of Venice and Mark the Evangelist. There is no historical record of when or how the lion arrived in Venice, but it was already installed atop the column in St. Mark’s Square by the time Marco Polo returned from China in 1295.</p><figure id="attachment_42825" aria-describedby="caption-attachment-42825"><a href="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3.jpg"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjgwIiBoZWlnaHQ9IjE1OTkiIHZpZXdCb3g9IjAgMCAxMjgwIDE1OTkiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNjZmQ0ZGI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" decoding="async" data-src="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3.jpg" alt="The Lion of St. Mark’s Square in Venice is Chinese: Isotopic Analyses Confirm It" width="1280" height="1599" data-srcset="https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3.jpg 1280w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-240x300.jpg 240w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-820x1024.jpg 820w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-768x959.jpg 768w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-1230x1536.jpg 1230w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-150x187.jpg 150w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-750x937.jpg 750w, https://archaeologymag.com/wp-content/uploads/lion-of-st-marks-square-3-1140x1424.jpg 1140w" data-sizes="(max-width: 1280px) 100vw, 1280px"></a><figcaption id="caption-attachment-42825">Bronze lion of Saint Marc in Venice. Credit: Jakub Hałun (<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>)</figcaption></figure><p>The circumstances of its arrival remain mysterious, with some speculating that the lion could have been brought to Venice by Marco Polo’s father, Nicolò, and his uncle, Maffeo, who visited the Mongol court in Beijing between 1264 and 1266. Others believe it may have arrived earlier, perhaps during a time of intense trade along the Silk Road. The first known reference to the lion dates back to 1293, but its exact journey remains unknown.</p><p>Over the centuries, the lion has undergone several restorations. In the 1790s, Napoleon looted the statue and transported it to Paris, where it was damaged during its return to Venice in 1815. The Venetian sculptor Bartolomeo Ferrari restored the statue, making additions like the lead book beneath its paws, while retaining most of the original structure.</p><p>The lion’s Chinese origins highlight the deep cultural and economic exchanges between East and West. According to researchers from the University of Padua and Ca’ Foscari University, the lion’s journey exemplifies the far-reaching influence of the Silk Road, which connected Eastern Eurasia with Venice and the broader Mediterranean world.</p><p><em><a href="https://www.unipd.it/news/leone-piazza-s-marco-venezia-made-china" target="_blank" rel="noreferrer noopener">University of Padova</a></em></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Post World War II Food (210 pts)]]></title>
            <link>https://www.nps.gov/articles/post-wwii-food.htm</link>
            <guid>41937319</guid>
            <pubDate>Thu, 24 Oct 2024 16:54:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nps.gov/articles/post-wwii-food.htm">https://www.nps.gov/articles/post-wwii-food.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41937319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cs_control_536382" title=""><div id="cs_control_7575149">
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{122}" paraid="1577140712">World War II brought several changes to what and how we eat. For example, members of the military traveled the globe during World War II, encountering different cuisines. When they returned, they brought back memories of those dishes. French, Italian, and Chinese food soon became popular in America beyond immigrant neighborhoods like Chinatowns and Little Italys.[1]  </p>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{154}" paraid="1144356723">Other changes were spurred by foods included in military rations and food produced using technologies developed during the war. There are also recipes born from rationing and Victory gardens that “stuck.” </p>
</div><div id="cs_control_7575053">
<figure>
<a href="https://en.wikipedia.org/wiki/File:KRation_Breakfast.JPG">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-2-K-Ration.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Black and white with the contents of the K-Ration breakfast arranged in front of the striped box they came in." src="https://www.nps.gov/articles/images/Post-War-Image-2-K-Ration.jpg?maxwidth=650&amp;autorotate=false" title="A K-Ration breakfast. It includes a packet of Nescafe instant coffee, energy biscuits (they look like crackers), gum, a tin of chopped ham and eggs, the key to open the can, and cigarettes. US Army Signal Corps, 1943.">
</picture>
</a>
<figcaption>A K-Ration breakfast. It includes a packet of Nescafe instant coffee, energy biscuits (they look like crackers), gum, a tin of chopped ham and eggs, the key to open the can, and cigarettes. <p>US Army Signal Corps, 1943.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h2 paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{122}" paraid="1577140712">The Taste of Rations </h2>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{192}" paraid="1382648765">The US military had a system of rations for feeding troops in the field. This system was designed to “maintain the health and effectiveness” of the troops.[2] K-Rations and C-Rations were both issued to troops in combat. They provided between 3,000 and 3,600 calories per day. Within these rations, soldiers found candy, freeze dried coffee, and canned meat.[3] In civilian life, we know these as M&amp;Ms, instant coffee, and Spam. </p>
<h3 paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{232}" paraid="979546918">M&amp;M’s</h3>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{232}" paraid="979546918">M&amp;Ms – the chocolate candy surrounded by a hard candy shell – were patented by Forrest Mars on March 1, 1941. By making a deal with Bruce Murrie of the Hershey Corporation, Mars had access to rationed chocolate. M&amp;M candies, named for the first initials of each partners’ last name, went on sale late in 1941. When the US went to war, Mars got an exclusive contract with the US military to provide M&amp;Ms for C-Rations. The candy was perfect for this use – they traveled well, and because of the candy coating, did not melt at high temperatures. Soldiers returned with a taste for the colorful candies, and M&amp;Ms became available to the general public.[4] </p>
</div><div id="cs_control_7575064">
<figure>
<a href="https://www.flickr.com/photos/nestle/23956997132/in/album-72157662980454395/">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-3-Resize592.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="B&amp;W ad illustrated with a woman and girl in matching aprons. The girl is pouring hot water into a cup. A jar of Nescafe coffee is in the lower right. “A perfect cup of coffee every time. So simple a child can make it. Always delicious, always the same.”" src="https://www.nps.gov/articles/images/Post-War-Image-3-Resize592.jpg?maxwidth=650&amp;autorotate=false" title="A ca. 1945 advertisement for Nescafé proclaims how tasty and easy it is to make. It also reminds buyers that the armed forces are taking nearly all the coffee they can manufacture. Copyright Nestlé S.A. Collection of the Nestlé Historical Archives.">
</picture>
</a>
<figcaption>A ca. 1945 advertisement for Nescafé proclaims how tasty and easy it is to make. It also reminds buyers that the armed forces are taking nearly all the coffee they can manufacture. <p>Copyright Nestlé S.A. Collection of the Nestlé Historical Archives.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h3 paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{248}" paraid="12913587">Instant Coffee</h3>
<p paraeid="{3b5575b7-587c-42a3-bb28-7bcb092006e6}{248}" paraid="12913587">Instant (or soluble) coffee existed before World War I. It was a dried, concentrated coffee extract that you prepared by adding hot water to it. In 1936, the Nestlé company developed their Nescafé brand instant coffee. Spurred by a desire to transform surplus coffee beans from Brazil into a quick-to-use, low-waste product, Nestlé discovered a way to make a more flavorful instant coffee. They called it Nescafé, a combination of the words Nestlé and café.[5] In 1941, Nestlé began supplying Nescafé for inclusion in American field rations. When American soldiers returned home after the war, they had a taste for the instant coffee.[6]  </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{45}" paraid="1227546861">After the war ended, Nestlé provided Nescafé for the care packages sent to Europe and Japan. These packages provided food and other necessities while the countries got back on their feet. This boosted global demand for Nescafé.[7] There is, however, more to the story. During the war, Nestlé companies supplied both the Axis and the Allies. In 2000, the company agreed to pay millions of dollars to settle claims that a German company they purchased used forced labor during the war. [8]  </p>
<h3 paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{77}" paraid="1215181569">Spam</h3>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{77}" paraid="1215181569">Spam is a tinned pork product. It was first introduced by the Hormel company in Austin, Minnesota in 1937. It became entrenched in American culture in World War II, when the US military contracted with Hormel (and other canned meat providers) to supply it for military rations. Hormel estimates they shipped more than 100 million pounds of Spam during the war.[9] Not all those who encountered it loved it – or even enjoyed it. Hormel kept a “scurrilous file” of hate mail from service members who were eating it three times a day. Others refused to even have it in their house decades after the war.[10]  </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{107}" paraid="577255852">For those on the Pacific home front (including American Samoa, the Philippines, Guam, and Hawai’i), Spam holds a special place. American GIs would share their rations with locals, and it was available for purchase in the post exchanges.[11] When the Japanese incarceration camps in the Philippines and on Guam were liberated by American forces, soldiers found starving prisoners. Many shared their rations on the spot. And with the extensive damage from the war, many Pacific islands were unable to provide enough food for their residents. There were also delays in the transition to commercial shipping, further limiting choices. To feed people, many of whom were on the point of starvation, the US issued rations, including Spam.[12] </p>
<blockquote>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{107}" paraid="577255852">“The Chamorro people have this love of Spam, corned beef, and pork and beans because that was the food they were given right after the war… We who were born right after the war, we remember. We grew up eating it every day.” – Linda Calvo, Guam[13]  </p>
</blockquote>
</div><div id="cs_control_7575065">
<figure>
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-4-Visiting-Spam.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Two people in Hawaiian shirts pose beside a smiling character (a can of Spam with a face and legs, wearing sneakers). Behind them are surfboards." src="https://www.nps.gov/articles/images/Post-War-Image-4-Visiting-Spam.jpg?maxwidth=650&amp;autorotate=false" title="Visitors to the Spam Museum in Austin, Minnesota post with a can of Spam. Photo courtesy of Jade Ryerson.">
</picture>
<figcaption>Visitors to the Spam Museum in Austin, Minnesota post with a can of Spam. <p>Photo courtesy of Jade Ryerson. All Rights Reserved.</p></figcaption>
</figure><!-- floating-image alignment  -->
<blockquote>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{151}" paraid="970620718">“to the people of Hawaii, Spam meant precious nourishment in a time of uncertainty and chaos. Thus, they prepared it with an immense amount of love. We cut it up, we sautéed it, we simmered with shoyu and sugar; we turned it into something else that was beautiful.”[14]  </p>
</blockquote>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{151}" paraid="970620718">In Hawai’i, Spam became popular after the US restricted the fishing industry during the war. They were afraid residents would use the boats to communicate with the Japanese. Because there were so many people of Japanese descent living in the Hawaiian Islands, the federal government could not incarcerate all of them (<a href="https://www.nps.gov/articles/000/terminology-and-the-mass-incarceration-of-japanese-americans-during-world-war-ii.htm" id="CP___PAGEID=7019921,terminology-and-the-mass-incarceration-of-japanese-americans-during-world-war-ii.htm,31093|">like they did for those living along the west coast of the mainland</a>). Instead, the US imposed martial law. Spam and other shelf-stable, shippable foods replaced fresh fish in the Hawaiian diet.[15] </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{176}" paraid="1523779306">Regardless of how it was introduced, Spam has remained an important part of the culture of these places ever since. In Guam, each person eats an average of 16 cans of spam per year, while Hawaiians consume an average of 5 cans per year. It has also been incorporated into regional menus at fast food restaurants like McDonald’s and Wendy’s. For example, you can order Spam, Eggs, and Rice for breakfast in Hawai’i, American Samoa, and Guam.[16] Importing Spam to Pacific islands like the Philippines is expensive. Seeing a can of Spam in these homes suggests they can afford it, or that they have connections to those in the US who send it.[17]  </p>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{228}" paraid="772802371">Among Spam’s benefits is that it is shelf stable, and can be eaten cooked or straight out of the can, in case of emergencies like hurricanes.[18] It’s downsides include its role in the dependence of these places on imported canned and processed foods, and the accompanying health impacts such as the prevalence of diabetes and heart disease in these places since the war.[19] </p>
</div><div id="cs_control_7575091">
<figure>
<a href="https://commons.wikimedia.org/wiki/File:Spam_Meal.jpg">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-5-Spamsilog.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="A color photo showing spamsilog served on a colorful plate. A mug of tea is to the left of the plate." src="https://www.nps.gov/articles/images/Post-War-Image-5-Spamsilog.jpg?maxwidth=650&amp;autorotate=false" title="Spamsilog. Fried Spam served with garlic fried rice and an egg. Photo by Bing Ramos, Quezon City, Philippines. CC-BY-SA 2.0">
</picture>
</a>
<figcaption>Spamsilog. Fried Spam served with garlic fried rice and an egg. <p>Photo by Bing Ramos, Quezon City, Philippines. CC-BY-SA 2.0.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h4 paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{248}" paraid="282757872">Recipes </h4>
<p paraeid="{5f609034-a4d1-4a13-b4ab-d616943b8353}{254}" paraid="722523982"><strong>Spam Fried Rice (Guam):</strong> Fry half of a chopped onion until soft. Then add half a can of Spam, cubed, and fry until golden brown. Add 3 cups of cooked rice and fry until it is shiny (about five minutes) before adding 2 teaspoons of soy sauce and frying an additional 5 minutes. Serve on a platter topped with two scrambled eggs (chopped up) and chopped green onions, if desired.[20] </p>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{47}" paraid="1023638739"><strong>Spam Musabi (Hawai’i):</strong> a “sushi” of Spam, sometimes using the Spam can as a form to shape it. There are many versions; this one makes 2 servings, and is modified from the Spam website: In a large skillet, fry two slices of Spam (3/8” thick each) until crispy on each side. Drizzle with a glaze of your choice (for example, a soy-based sauce or sweet ginger sesame sauce – you can buy or make your own). Line the inside and bottom of an empty Spam can that has both ends removed with plastic wrap. Press 1.5oz of cooked white rice (or sushi rice) firmly into the can. The rice can be seasoned with toasted sesame seeds and furikake if desired (furikake is a Japanese rice seasoning. You can buy it, or make your own). Place a slice of the cooked Spam on top of the rice, and press firmly. Remove from the can, and repeat for the second slice. Cut two strips from a sheet of nori (seaweed). If you like the taste of nori, you can cut a wider strip. With the strip of nori laying shiny side down, top it with the pressed Spam and rice. Wrap the nori around it, and repeat with the second piece. Serve immediately.[21] </p>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{81}" paraid="316359139"><strong>Spamsilog (Philippines): </strong>a combination of fried Spam, garlic fried rice, and egg often served for breakfast, especially with banana ketchup.[22] </p>
<h2 paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{81}" paraid="316359139">Wartime Food Innovations </h2>
<p>Most wartime food innovations were geared to provide the military with nutritious, easy-to-ship, and long-lasting foods for rations. Some of the innovations made it into production during the war years; others did not. Regardless, several, including powdered cheese and orange juice concentrate went on to shape the civilian food landscape. </p>
</div><div id="cs_control_7575092">
<figure>
<a href="https://collections.si.edu/search/detail/edanmdm:saam_1986.65.277">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-6-Minute-Maid.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Color photo. Can (black, orange, and green) reads “Minute Maid Concentrated Orange Juice. Makes 1-1/2 Pints.” Arms, legs, and feet are colored orange. The hat, also from a can, reads “Minute Maid.” Face made of painted wood." src="https://www.nps.gov/articles/images/Post-War-Image-6-Minute-Maid.jpg?maxwidth=650&amp;autorotate=false" title="An articulated figure made from a Minute Maid concentrated orange juice can, ca. 1950s. When placed on a thin board that was tapped on, these figures “danced.” Collection of the Smithsonian American Art Museum (1986.65.277).">
</picture>
</a>
<figcaption>An articulated figure made from a Minute Maid concentrated orange juice can, ca. 1950s. When placed on a thin board that was tapped on, these figures “danced.” <p>Collection of the Smithsonian American Art Museum, Gift of Herbert Waide Hemphill, Jr. and museum purchase made possible by Ralph Cross Johnson (1986.65.277).</p></figcaption>
</figure><!-- floating-image alignment  -->
<h3 paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{107}" paraid="274184130">Powdered Cheese</h3>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{139}" paraid="851445772">Cheese was a convenient way to ship dairy.[23] The military was always looking for ways to reduce the weight and volume of foods as ways to increase how much could be transported at one time.[24] In 1943, USDA scientist George Sanders developed the first real cheese powder. Previous attempts to dehydrate cheese had failed, because the application of heat caused the milk fats to melt and separate. Sanders solved the problem with a two-step process. By first grating the cheese and drying it at a low temperature. This resulted in a barrier forming around the fats. In the second step, the cheese was ground into a powder and dehydrated again before being pressed into cakes.[25] </p>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{191}" paraid="276145264">When the war ended in 1945, the military had huge stockpiles of food, including powdered cheese. The government liquidated these stockpiles, sometimes for pennies on the dollar, to private industry. Companies like Frito (later Frito-Lay), Kraft, and others found ways to use these wartime products. In 1948, the Frito company coated puffed cornmeal pieces with dehydrated cheese, and Cheetos were born.[26] </p>
<h3 paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{207}" paraid="1156262895">Orange Juice Concentrate</h3>
<p paraeid="{941c531b-7d94-4611-bd6c-b20b691f0d39}{207}" paraid="1156262895">Research began in 1942 for a way to economically ship orange juice to soldiers on the front lines. It was important that they got enough Vitamin C to say healthy. The military had been issuing lemon crystals, but because of their unpleasant taste, soldiers tended to ignore them. Initial attempts to concentrate orange juice left it tasting bland. In 1945, just as the war was ending, the process of making tasty orange juice concentrate was perfected. Fresh juice added to the concentrate restored the taste of fresh juice. The resulting process removed 80% of the water in orange juice. When ready to drink, users only had to add back the water to the frozen concentrate. Producers quickly pivoted the product to the consumer market, and Minute Maid hit the shelves.[27] </p>
</div><div id="cs_control_7575122">
<figure>
<a href="https://commons.wikimedia.org/wiki/File:Julia_Child_portrait_by_%C2%A9Lynn_Gilbert,_1978.jpg">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-1-Resize358.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="Black and white photo of Julia Child standing by her stove. She is tasting something with a spoon. A skillet on her stove has something cooking in it. She has a towel tucked into her apron strings. She is surrounded by cooking utensils." src="https://www.nps.gov/articles/images/Post-War-Image-1-Resize358.jpg?maxwidth=650&amp;autorotate=false" title="Julia Child in her kitchen in 1978. Photo copyright Lynn Gilbert, CC by SA 4.0">
</picture>
</a>
<figcaption>Julia Child in her kitchen in 1978. Julia was in France in World War II working with the Office of Strategic Services (it became the CIA). She fell in love with French food. She learned to cook it there, and brought it back to the US. Her cookbooks and TV shows made it accessible to home cooks. <p>Photo copyright Lynn Gilbert, CC by SA 4.0</p></figcaption>
</figure><!-- floating-image alignment  -->
<h2 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{14}" paraid="149373720">Ration Recipes </h2>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{20}" paraid="555050844">After the war and rationing ended, Americans still faced some challenges in grocery shopping. A lot of foods were being sent to Europe and elsewhere to feed Allies whose farmlands had been devastated or neglected. As food choices and availability improved after the war many Americans compensated for wartime scarcity by eating meat- and butter-rich meals. Grilling a steak became the height of entertaining.[28] But some wartime foods (including some with roots in earlier times of shortage, like the Great Depression) stuck. Among these are stuffed peppers; Kraft macaroni and cheese; and fruit cobbler. </p>
<h3 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{74}" paraid="707689482">Stuffed Peppers</h3>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{74}" paraid="707689482">Stuffed peppers (and their close cousins, stuffed cabbage leaves and stuffed tomatoes) were filled with a mixture of a little ground beef extended with rice, seasonings, and other vegetables (which in season, could come right from the cook’s Victory garden). Ground beef was popular during wartime, because it needed fewer ration stamps than other cuts of meat. In one stuffed pepper recipe, a quarter pound of beef made four servings of stuffed peppers.[29] </p>
<h3 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{112}" paraid="1760533394">Kraft Macaroni and Cheese</h3>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{112}" paraid="1760533394">Kraft macaroni and cheese was invented in 1937 during the Great Depression, but its popularity boomed during the War. The powder is a cheese sauce that has been partially defatted and dehydrated. By adding milk and/or butter during cooking, you replace the moisture and fats.[30] Kraft macaroni and cheese was inexpensive, filling, and you could get two boxes for a single ration point. It was also quick and easy to make – an important consideration as women who were in the workforce had little time at home.[31] Kraft sold 50 million boxes of its macaroni and cheese during World War II.[32] </p>
</div><div id="cs_control_7575148">
<figure>
<a href="https://commons.wikimedia.org/wiki/File:Apple_cobbler.jpg">
<picture>
<source type="image/webp" srcset="https://www.nps.gov/articles/images/Post-War-Image-7-Apple-Cobbler.jpg?maxwidth=650&amp;autorotate=false&amp;quality=78&amp;format=webp">
<img alt="A square baking pan sitting on top of a white gas stove. In the pan is apple cobbler – slices of apples covered with a thin crust." src="https://www.nps.gov/articles/images/Post-War-Image-7-Apple-Cobbler.jpg?maxwidth=650&amp;autorotate=false" title="Apple cobbler. Wikimedia Commons.">
</picture>
</a>
<figcaption>Apple cobbler. <p>Wikimedia Commons.</p></figcaption>
</figure><!-- floating-image alignment  -->
<h3 paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{162}" paraid="88193390">Fruit Cobbler</h3>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{162}" paraid="88193390">Fruit cobblers and crisps became popular during World War II. Seasonal fruits made up most of the dish, needing only a little rationed sugar. These desserts had no bottom crust, saving on the butter, lard, or shortening needed. The thin toppings of cake, biscuit, pastry, or crumble used very little fat. The result was a ration-friendly dessert that is still popular.[33] </p>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{180}" paraid="2105063441">Dishes like those described here – from Spamsilog to Fruit Cobbler -- have become staples in American culture. The reasons may include being comfort foods, being inexpensive or easy options when money or time was tight, or perhaps from a sense of patriotism or nostalgia. </p>
<p paraeid="{73d25b20-fa3a-4920-8752-accb0455dcda}{212}" paraid="1922726276"><em>** Any mention of trade names does not imply endorsement of these brands, companies, or products. They are included solely for historical understanding. </em></p>
</div><div id="cs_control_7575173">
<hr>
<p><em>This article was written by Megan E. Springate, Assistant Research Professor, Department of Anthropology, University of Maryland, for the NPS Cultural Resources Office of Interpretation and Education. It was funded by the </em><a href="https://ncph.org/" id="https://ncph.org/|">National Council on Public History's</a><em> cooperative agreement with the National Park Service. </em></p>
<hr>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Skyvern (YC S23) – open-source AI agent for browser automations (280 pts)]]></title>
            <link>https://github.com/Skyvern-AI/Skyvern</link>
            <guid>41936745</guid>
            <pubDate>Thu, 24 Oct 2024 15:51:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Skyvern-AI/Skyvern">https://github.com/Skyvern-AI/Skyvern</a>, See on <a href="https://news.ycombinator.com/item?id=41936745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<div dir="auto"><h2 tabindex="-1" dir="auto">
 <a href="https://www.skyvern.com/" rel="nofollow">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern_logo.png">
    <img height="120" src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern_logo_blackbg.png">
  </picture></themed-picture>
 </a>
 <br>
</h2><a id="user-content----------------" aria-label="Permalink: " href="#---------------"></a></div>
<p dir="auto">
🐉 Automate Browser-based workflows using LLMs and Computer Vision 🐉
</p>
<p dir="auto">
  <a href="https://www.skyvern.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/30e5dad0d7d42d3589d13557447b68649394f756261b8aa07003dfa55a6a8297/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f576562736974652d626c75653f6c6f676f3d676f6f676c656368726f6d65266c6f676f436f6c6f723d626c61636b" data-canonical-src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;logoColor=black"></a>
  <a href="https://docs.skyvern.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/902647da8997506912d82ca5388489eb2c5f41bf576e892552b1e6607df85957/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63732d79656c6c6f773f6c6f676f3d676974626f6f6b266c6f676f436f6c6f723d626c61636b" data-canonical-src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;logoColor=black"></a>
  <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow"><img src="https://camo.githubusercontent.com/3c085828c0041e3dbb8564da90484a448cc9834a6b0452d3d95d692b6c533d92/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313231323438363332363335323631373533343f6c6f676f3d646973636f7264266c6162656c3d646973636f7264" data-canonical-src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;label=discord"></a>
  
  <a href="https://github.com/skyvern-ai/skyvern"><img src="https://camo.githubusercontent.com/654dadaebf01f1b41e35b7870319ece6693b4bceacd2fc860f589cad13737767/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736b797665726e2d61692f736b797665726e" data-canonical-src="https://img.shields.io/github/stars/skyvern-ai/skyvern"></a>
  <a href="https://github.com/Skyvern-AI/skyvern/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/3d0723f2a77501a1715ecc8a9c350c1501c02d9140d6ff630af7692d24261a7c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f736b797665726e2d61692f736b797665726e" data-canonical-src="https://img.shields.io/github/license/skyvern-ai/skyvern"></a>
  <a href="https://twitter.com/skyvernai" rel="nofollow"><img src="https://camo.githubusercontent.com/aa77bd615cc96f559d58865f90c8ba4e9e5afbea043e312ebeff1079b6aff9e5/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f736b797665726e61693f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/twitter/follow/skyvernai?style=social"></a>
  <a href="https://www.linkedin.com/company/95726232" rel="nofollow"><img src="https://camo.githubusercontent.com/ad4bbddfd4c0b43f42830b8919b58aa0759ac46b89ab2f3a6386a542a8d79bc4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f77253230206f6e2532304c696e6b6564496e2d3841324245323f6c6f676f3d6c696e6b6564696e" data-canonical-src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin"></a>
</p>
<p dir="auto"><a href="https://www.skyvern.com/" rel="nofollow">Skyvern</a> automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/geico_shu_recording_cropped.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/geico_shu_recording_cropped.gif" data-animated-image=""></a>
</p>
<p dir="auto">Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.</p>
<p dir="auto">Instead of only relying on code-defined XPath interactions, Skyvern relies on prompts in addition to computer vision and LLMs to the mix to parse items in the viewport in real-time, create a plan for interaction and interact with them.</p>
<p dir="auto">This approach gives us a few advantages:</p>
<ol dir="auto">
<li>Skyvern can operate on websites it’s never seen before, as it’s able to map visual elements to actions necessary to complete a workflow, without any customized code</li>
<li>Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate</li>
<li>Skyvern is able to take a single workflow and apply it to a large number of websites, as it’s able to reason through the interactions necessary to complete the workflow</li>
<li>Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include:
<ol dir="auto">
<li>If you wanted to get an auto insurance quote from Geico, the answer to a common question “Were you eligible to drive at 18?” could be inferred from the driver receiving their license at age 16</li>
<li>If you were doing competitor analysis, it’s understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)</li>
</ol>
</li>
</ol>
<p dir="auto">Want to see examples of Skyvern in action? Jump to <a href="#real-world-examples-of-skyvern">#real-world-examples-of-skyvern</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">Skyvern was inspired by the Task-Driven autonomous agent design popularized by <a href="https://github.com/yoheinakajima/babyagi">BabyAGI</a> and <a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a> -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like <a href="https://playwright.dev/" rel="nofollow">Playwright</a>.</p>
<p dir="auto">Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:</p>
<ol dir="auto">
<li><strong>Interactable Element Agent</strong>: This agent is responsible for parsing the HTML of a website and extracting the interactable elements.</li>
<li><strong>Navigation Agent</strong>: This agent is responsible for planning the navigation to complete a task. Examples include clicking buttons, inserting text, selecting options, etc.</li>
<li><strong>Data Extraction Agent</strong>: This agent is responsible for extracting data from a website. It's capable of reading the tables and text on the page, and extract the output in a user-defined structured format</li>
<li><strong>Password Agent</strong>: This agent is responsible for filling out password forms on a website. It's capable of reading the username and password from a password manager, and filling out the form while preserving the privacy of the user-defined secrets.</li>
<li><strong>2FA Agent</strong>: This agent is responsible for filling out 2FA forms on a website. It's capable of  intercepting website requests for 2FAs, and either requesting user-defined APIs for 2FA codes or waiting for users to feed 2FA codes into it, and then completing the login process.</li>
<li><strong>Dynamic Auto-complete Agent</strong>: This agent is responsible for filling out dynamic auto-complete forms on a website. It's capable of reading the options presented to it, and selecting the appropriate option based on the user's input, adjusting its inputs based on the feedback from inside the form. Popular examples include: Address forms, university dropdowns, and more.</li>
</ol>
<themed-picture data-catalyst-inline="true"><picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern-system-diagram-dark.png">
  <img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/skyvern-system-diagram-light.png">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>

<details open="">
  <summary>
    
    <span aria-label="Video description skyvern_demo_video_v2.1.mp4">skyvern_demo_video_v2.1.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/3853670/379523585-5cab4668-e8e2-4982-8551-aab05ff73a7f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk3OTQ5MDMsIm5iZiI6MTcyOTc5NDYwMywicGF0aCI6Ii8zODUzNjcwLzM3OTUyMzU4NS01Y2FiNDY2OC1lOGUyLTQ5ODItODU1MS1hYWIwNWZmNzNhN2YubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjRUMTgzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmVjNzhiZjhlOTk3ZTA0OTIzZThhYjgzNTQ0ZTY5YzkwNTM0ZDcwYjc4OTRmMjlhY2Q2MTYxY2VjMGY2MDllNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.jL15GNKDNigdn3d4arUZbid6fXasRWswQCEWMvXW8DI" data-canonical-src="https://private-user-images.githubusercontent.com/3853670/379523585-5cab4668-e8e2-4982-8551-aab05ff73a7f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjk3OTQ5MDMsIm5iZiI6MTcyOTc5NDYwMywicGF0aCI6Ii8zODUzNjcwLzM3OTUyMzU4NS01Y2FiNDY2OC1lOGUyLTQ5ODItODU1MS1hYWIwNWZmNzNhN2YubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMjRUMTgzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmVjNzhiZjhlOTk3ZTA0OTIzZThhYjgzNTQ0ZTY5YzkwNTM0ZDcwYjc4OTRmMjlhY2Q2MTYxY2VjMGY2MDllNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.jL15GNKDNigdn3d4arUZbid6fXasRWswQCEWMvXW8DI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Skyvern Cloud</h2><a id="user-content-skyvern-cloud" aria-label="Permalink: Skyvern Cloud" href="#skyvern-cloud"></a></p>
<p dir="auto">We offer a managed cloud version of Skyvern that allows you to run Skyvern without having to manage the infrastructure. It allows to you run multiple Skyvern instances in parallel to automate your workflows at scale. In addition, Skyvern cloud comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solving to allow you to complete more complicated workflows.</p>
<p dir="auto">If you'd like to try it out,</p>
<ol dir="auto">
<li>Navigate to <a href="https://app.skyvern.com/" rel="nofollow">app.skyvern.com</a></li>
<li>Create an account &amp; Get $5 of credits on us</li>
<li>Kick off your first task and see Skyvern in action!</li>
</ol>
<p dir="auto">Here are some tips that may help you on your adventure:</p>
<ol dir="auto">
<li>Skyvern is really good at carrying out a single goal. If you give it too many instructions to do, it has a high likelihood of getting confused along the way.</li>
<li>Being really explicit about goals is very important. For example, if you're generating an insurance quote, let it know very clearly how it can identify it's accomplished its goals. Use words like "COMPLETE" or "TERMINATE" to indicate success and failure modes, respectively.</li>
<li>Workflows can be used if you'd like to do more advanced things such as chaining multiple instructions together, or securely logging in. If you need any help with this, please feel free to book some time with us! We're always happy to help</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">This quickstart guide will walk you through getting Skyvern up and running on your local machine.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker Compose setup (Recommended)</h2><a id="user-content-docker-compose-setup-recommended" aria-label="Permalink: Docker Compose setup (Recommended)" href="#docker-compose-setup-recommended"></a></p>
<ol dir="auto">
<li>Make sure you have <a href="https://www.docker.com/products/docker-desktop/" rel="nofollow">Docker Desktop</a> installed and running on your machine</li>
<li>Make sure you don't have postgres running locally (Run <code>docker ps</code> to check)</li>
<li>Clone the repository and navigate to the root directory</li>
<li>Fill in the LLM provider key on the <a href="https://github.com/Skyvern-AI/skyvern/blob/main/docker-compose.yml">docker-compose.yml</a>. <em>If you want to run skyvern on a remote server, make sure you set the correct server ip for the UI container in <a href="https://github.com/Skyvern-AI/skyvern/blob/main/docker-compose.yml">docker-compose.yml</a>.</em></li>
<li>Run the following command via the commandline:

</li>
<li>Navigate to <code>http://localhost:8080</code> in your browser to start using the UI</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Full Setup (Contributors) - Prerequisites</h2><a id="user-content-full-setup-contributors---prerequisites" aria-label="Permalink: Full Setup (Contributors) - Prerequisites" href="#full-setup-contributors---prerequisites"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji> MAKE SURE YOU ARE USING PYTHON 3.11 <g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji></h3><a id="user-content-warning-warning-make-sure-you-are-using-python-311-warning-warning" aria-label="Permalink: :warning: :warning: MAKE SURE YOU ARE USING PYTHON 3.11 :warning: :warning:" href="#warning-warning-make-sure-you-are-using-python-311-warning-warning"></a></p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji> Only well-tested on MacOS <g-emoji alias="warning">⚠️</g-emoji> <g-emoji alias="warning">⚠️</g-emoji></p>
<p dir="auto">Before you begin, make sure you have the following installed:</p>
<ul dir="auto">
<li><a href="https://brew.sh/" rel="nofollow">Brew (if you're on a Mac)</a></li>
<li><a href="https://python-poetry.org/docs/#installation" rel="nofollow">Poetry</a>
<ul dir="auto">
<li><code>brew install poetry</code></li>
</ul>
</li>
<li><a href="https://nodejs.org/en/download/" rel="nofollow">node</a></li>
<li><a href="https://docs.docker.com/engine/install/" rel="nofollow">Docker</a></li>
</ul>
<p dir="auto">Note: Our setup script does these two for you, but they are here for reference.</p>
<ul dir="auto">
<li><a href="https://www.python.org/downloads/" rel="nofollow">Python 3.11</a>
<ul dir="auto">
<li><code>poetry env use 3.11</code></li>
</ul>
</li>
<li><a href="https://www.postgresql.org/download/" rel="nofollow">PostgreSQL 14</a> (if you're on a Mac, setup script will install it for you if you have homebrew installed)
<ul dir="auto">
<li><code>brew install postgresql</code></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup (Contributors)</h2><a id="user-content-setup-contributors" aria-label="Permalink: Setup (Contributors)" href="#setup-contributors"></a></p>
<ol dir="auto">
<li>Clone the repository and navigate to the root directory</li>
<li>Open Docker Desktop (Works for Windows, macOS, and Linux) or run Docker Daemon</li>
<li>Run the setup script to install the necessary dependencies and setup your environment

</li>
<li>Start the server

</li>
<li>You can start sending requests to the server, but we built a simple UI to help you get started. To start the UI, run the following command:

</li>
<li>Navigate to <code>http://localhost:8080</code> in your browser to start using the UI</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Additional Setup for Contributors</h2><a id="user-content-additional-setup-for-contributors" aria-label="Permalink: Additional Setup for Contributors" href="#additional-setup-for-contributors"></a></p>
<p dir="auto">If you're looking to contribute to Skyvern, you'll need to install the pre-commit hooks to ensure code quality and consistency. You can do this by running the following command:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Functionality</h2><a id="user-content-supported-functionality" aria-label="Permalink: Supported Functionality" href="#supported-functionality"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Skyvern Tasks</h2><a id="user-content-skyvern-tasks" aria-label="Permalink: Skyvern Tasks" href="#skyvern-tasks"></a></p>
<p dir="auto">Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.</p>
<p dir="auto">Tasks require you to specify a <code>url</code>, <code>navigation_goal</code>, and optionally <code>data_extraction_goal</code> if you'd like to extract data from the website, and a <code>navigation_payload</code> if you'd like to provide additional context to help Skyvern fill information or answer questions presented by a website.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/task_creation_form_example.png"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/task_creation_form_example.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Skyvern Workflows</h2><a id="user-content-skyvern-workflows" aria-label="Permalink: Skyvern Workflows" href="#skyvern-workflows"></a></p>
<p dir="auto">Workflows are a way to chain multiple tasks together to form a cohesive unit of work.</p>
<p dir="auto">For example, if you wanted to download all invoics newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligilble invoices, and iterated through each invoice to download it.</p>
<p dir="auto">Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, added it to cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.</p>
<p dir="auto">Supported workflow features include:</p>
<ol dir="auto">
<li>Tasks (+ chained tasks)</li>
<li>Loops</li>
<li>File parsing</li>
<li>Uploading files to block storage</li>
<li>Sending emails</li>
<li>Text Prompts</li>
<li>(Coming soon) Conditionals</li>
<li>(Coming soon) Custom Code Block</li>
</ol>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/invoice_downloading_workflow_example.png"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/invoice_downloading_workflow_example.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Livestreaming</h2><a id="user-content-livestreaming" aria-label="Permalink: Livestreaming" href="#livestreaming"></a></p>
<p dir="auto">Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Form Filling</h2><a id="user-content-form-filling" aria-label="Permalink: Form Filling" href="#form-filling"></a></p>
<p dir="auto">Skyvern is natively capable of filling out form inputs on websites. Passing in information via the <code>navigation_goal</code> or <code>navigation_payload</code> will allow Skyvern to comprehend the information and fill out the form accordingly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Data Extraction</h2><a id="user-content-data-extraction" aria-label="Permalink: Data Extraction" href="#data-extraction"></a></p>
<p dir="auto">Skyvern is also capable of extracting data from a website. Specifying a <code>data_extraction_goal</code> will allow Skyvern to extract the data and return it to you in the response.</p>
<p dir="auto">You can also specify a <code>data_extraction_schema</code> to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">File Downloading</h2><a id="user-content-file-downloading" aria-label="Permalink: File Downloading" href="#file-downloading"></a></p>
<p dir="auto">Skyvern is also capable of downloading files from a website. Specifying a <code>file_download_goal</code> will allow Skyvern to download the file and return a link to the file in the response.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Authentication</h2><a id="user-content-authentication" aria-label="Permalink: Authentication" href="#authentication"></a></p>
<p dir="auto">Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Password Manager Integrations</h3><a id="user-content-password-manager-integrations" aria-label="Permalink: Password Manager Integrations" href="#password-manager-integrations"></a></p>
<p dir="auto">Skyvern currently supports the following password manager integrations:</p>
<ul>
<li> Bitwarden</li>
<li> 1Password</li>
<li> LastPass</li>
</ul>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/secure_password_task_example.png"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/secure_password_task_example.png"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2FA</h3><a id="user-content-2fa" aria-label="Permalink: 2FA" href="#2fa"></a></p>
<p dir="auto">Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.</p>
<p dir="auto">Examples include:</p>
<ol dir="auto">
<li>QR-based 2FA (e.g. Google Authenticator, Authy)</li>
<li>Email based 2FA</li>
<li>SMS based 2FA</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Real-world examples of Skyvern</h2><a id="user-content-real-world-examples-of-skyvern" aria-label="Permalink: Real-world examples of Skyvern" href="#real-world-examples-of-skyvern"></a></p>
<p dir="auto">We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!</p>
<p dir="auto">You'll need to have Skyvern running locally if you want to try these examples out. Please run the following command after going through the quickstart guide:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Invoice Downloading on many different websites</h2><a id="user-content-invoice-downloading-on-many-different-websites" aria-label="Permalink: Invoice Downloading on many different websites" href="#invoice-downloading-on-many-different-websites"></a></p>
<p dir="auto"><a href="https://meetings.hubspot.com/skyvern/demo" rel="nofollow">Book a demo to see it live</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/invoice_downloading.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/invoice_downloading.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Automate the job application process</h2><a id="user-content-automate-the-job-application-process" aria-label="Permalink: Automate the job application process" href="#automate-the-job-application-process"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/job_application" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/job_application_demo.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/job_application_demo.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Automate materials procurement for a manufacturing company</h2><a id="user-content-automate-materials-procurement-for-a-manufacturing-company" aria-label="Permalink: Automate materials procurement for a manufacturing company" href="#automate-materials-procurement-for-a-manufacturing-company"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/finditparts" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/finditparts_recording_crop.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/finditparts_recording_crop.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Navigating to government websites to register accounts or fill out forms</h2><a id="user-content-navigating-to-government-websites-to-register-accounts-or-fill-out-forms" aria-label="Permalink: Navigating to government websites to register accounts or fill out forms" href="#navigating-to-government-websites-to-register-accounts-or-fill-out-forms"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/california_edd" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/edd_services.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/edd_services.gif" data-animated-image=""></a>
</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Filling out random contact us forms</h2><a id="user-content-filling-out-random-contact-us-forms" aria-label="Permalink: Filling out random contact us forms" href="#filling-out-random-contact-us-forms"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/contact_us_forms" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/contact_forms.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/contact_forms.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Retrieving insurance quotes from insurance providers in any language</h2><a id="user-content-retrieving-insurance-quotes-from-insurance-providers-in-any-language" aria-label="Permalink: Retrieving insurance quotes from insurance providers in any language" href="#retrieving-insurance-quotes-from-insurance-providers-in-any-language"></a></p>
<p dir="auto"><a href="https://app.skyvern.com/create/bci_seguros" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/bci_seguros_recording.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/bci_seguros_recording.gif" data-animated-image=""></a>
</p>
<p dir="auto"><a href="https://app.skyvern.com/create/geico" rel="nofollow">💡 See it in action</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Skyvern-AI/skyvern/blob/main/docs/images/geico_shu_recording_cropped.gif"><img src="https://github.com/Skyvern-AI/skyvern/raw/main/docs/images/geico_shu_recording_cropped.gif" data-animated-image=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">More extensive documentation can be found on our <a href="https://docs.skyvern.ai/" rel="nofollow">documentation website</a>. Please let us know if something is unclear or missing by opening an issue or reaching out to us <a href="mailto:founders@skyvern.com">via email</a> or <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow">discord</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported LLMs</h2><a id="user-content-supported-llms" aria-label="Permalink: Supported LLMs" href="#supported-llms"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Provider</th>
<th>Supported Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>OpenAI</td>
<td>gpt4-turbo, gpt-4o, gpt-4o-mini</td>
</tr>
<tr>
<td>Anthropic</td>
<td>Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)</td>
</tr>
<tr>
<td>Azure OpenAI</td>
<td>Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)</td>
</tr>
<tr>
<td>AWS Bedrock</td>
<td>Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)</td>
</tr>
<tr>
<td>Ollama</td>
<td>Coming soon (contributions welcome)</td>
</tr>
<tr>
<td>Gemini</td>
<td>Coming soon (contributions welcome)</td>
</tr>
<tr>
<td>Llama 3.2</td>
<td>Coming soon (contributions welcome)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Environment Variables</h4><a id="user-content-environment-variables" aria-label="Permalink: Environment Variables" href="#environment-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
<th>Type</th>
<th>Sample Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ENABLE_OPENAI</code></td>
<td>Register OpenAI models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>ENABLE_ANTHROPIC</code></td>
<td>Register Anthropic models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>ENABLE_AZURE</code></td>
<td>Register Azure OpenAI models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>ENABLE_BEDROCK</code></td>
<td>Register AWS Bedrock models</td>
<td>Boolean</td>
<td><code>true</code>, <code>false</code></td>
</tr>
<tr>
<td><code>LLM_KEY</code></td>
<td>The name of the model you want to use</td>
<td>String</td>
<td>Currently supported llm keys: <code>OPENAI_GPT4_TURBO</code>, <code>OPENAI_GPT4V</code>, <code>OPENAI_GPT4O</code>, <code>OPENAI_GPT4O_MINI</code>, <code>ANTHROPIC_CLAUDE3</code>, <code>ANTHROPIC_CLAUDE3_OPUS</code>, <code>ANTHROPIC_CLAUDE3_SONNET</code>, <code>ANTHROPIC_CLAUDE3_HAIKU</code>, <code>ANTHROPIC_CLAUDE3.5_SONNET</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3_OPUS</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3_SONNET</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3_HAIKU</code>, <code>BEDROCK_ANTHROPIC_CLAUDE3.5_SONNET</code>, <code>AZURE_OPENAI</code></td>
</tr>
<tr>
<td><code>OPENAI_API_KEY</code></td>
<td>OpenAI API Key</td>
<td>String</td>
<td><code>sk-1234567890</code></td>
</tr>
<tr>
<td><code>OPENAI_API_BASE</code></td>
<td>OpenAI API Base, optional</td>
<td>String</td>
<td><code>https://openai.api.base</code></td>
</tr>
<tr>
<td><code>OPENAI_ORGANIZATION</code></td>
<td>OpenAI Organization ID, optional</td>
<td>String</td>
<td><code>your-org-id</code></td>
</tr>
<tr>
<td><code>ANTHROPIC_API_KEY</code></td>
<td>Anthropic API key</td>
<td>String</td>
<td><code>sk-1234567890</code></td>
</tr>
<tr>
<td><code>AZURE_API_KEY</code></td>
<td>Azure deployment API key</td>
<td>String</td>
<td><code>sk-1234567890</code></td>
</tr>
<tr>
<td><code>AZURE_DEPLOYMENT</code></td>
<td>Azure OpenAI Deployment Name</td>
<td>String</td>
<td><code>skyvern-deployment</code></td>
</tr>
<tr>
<td><code>AZURE_API_BASE</code></td>
<td>Azure deployment api base url</td>
<td>String</td>
<td><code>https://skyvern-deployment.openai.azure.com/</code></td>
</tr>
<tr>
<td><code>AZURE_API_VERSION</code></td>
<td>Azure API Version</td>
<td>String</td>
<td><code>2024-02-01</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feature Roadmap</h2><a id="user-content-feature-roadmap" aria-label="Permalink: Feature Roadmap" href="#feature-roadmap"></a></p>
<p dir="auto">This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us <a href="mailto:founders@skyvern.com">via email</a> or <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow">discord</a>.</p>
<ul>
<li> <strong>Open Source</strong> - Open Source Skyvern's core codebase</li>
<li> <strong>[BETA] Workflow support</strong> - Allow support to chain multiple Skyvern calls together</li>
<li> <strong>Improved context</strong> - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt</li>
<li> <strong>Cost Savings</strong> - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern</li>
<li> <strong>Self-serve UI</strong> - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern</li>
<li> <strong>Workflow UI Builder</strong> - Introduce a UI to allow users to build and analyze workflows visually</li>
<li> <strong>Chrome Viewport streaming</strong> - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)</li>
<li> <strong>Past Runs UI</strong> - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results</li>
<li> <strong>Prompt Caching</strong> - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)</li>
<li> <strong>Web Evaluation Dataset</strong> - Integrate Skyvern with public benchmark tests to track the quality our models over time</li>
<li> <strong>Improved Debug mode</strong> - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt</li>
<li> <strong>Auto workflow builder ("Observer") mode</strong> - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows</li>
<li> <strong>Chrome Extension</strong> - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)</li>
<li> <strong>Skyvern Action Recorder</strong> - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it</li>
<li> <strong>Interactable Livestream</strong> - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)</li>
<li> <strong>Integrate LLM Observability tools</strong> - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time</li>
<li> <strong>Langchain Integration</strong> - Create langchain integration in langchain_community to use Skyvern as a "tool".</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us <a href="mailto:founders@skyvern.com">via email</a> or <a href="https://discord.gg/fG2XXEuQX3" rel="nofollow">discord</a>.
Please have a look at our <a href="https://github.com/Skyvern-AI/skyvern/blob/main/CONTRIBUTING.md">contribution guide</a> and
<a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22">"Help Wanted" issues</a> to get started!</p>
<p dir="auto">If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out <a href="https://sage.storia.ai/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=skyvern-readme" rel="nofollow">Code Sage</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Telemetry</h2><a id="user-content-telemetry" aria-label="Permalink: Telemetry" href="#telemetry"></a></p>
<p dir="auto">By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the <code>SKYVERN_TELEMETRY</code> environment variable to <code>false</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the <a href="https://github.com/Skyvern-AI/skyvern/blob/main/LICENSE">AGPL-3.0 License</a>, with the exception of anti-bot measures available in our managed cloud offering.</p>
<p dir="auto">If you have any questions or concerns around licensing, please <a href="mailto:founders@skyvern.com">contact us</a> and we would be happy to help.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<p dir="auto"><a href="https://star-history.com/#Skyvern-AI/skyvern&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/27c8134ddcfec58a858504b3025ae5f5bf39afb638f19eea8b9aeaf1ed42b5a6/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d536b797665726e2d41492f736b797665726e26747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;type=Date"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lost Silk Road Cities Discovered High in the Mountains of Central Asia (114 pts)]]></title>
            <link>https://www.scientificamerican.com/article/lost-silk-road-cities-discovered-high-in-the-mountains-of-central-asia/</link>
            <guid>41936316</guid>
            <pubDate>Thu, 24 Oct 2024 15:12:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/lost-silk-road-cities-discovered-high-in-the-mountains-of-central-asia/">https://www.scientificamerican.com/article/lost-silk-road-cities-discovered-high-in-the-mountains-of-central-asia/</a>, See on <a href="https://news.ycombinator.com/item?id=41936316">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block="sciam/paragraph">Hidden in the towering mountains of Central Asia, along what has been called <a href="https://www.scientificamerican.com/article/archaeologists-uncover-another-branch-of-the-silk-road/">the Silk Road</a>, archaeologists are <a href="https://www.scientificamerican.com/article/archaeologists-uncover-another-branch-of-the-silk-road/">uncovering</a> two medieval cities that may have bustled with inhabitants a thousand years ago.</p><p data-block="sciam/paragraph">A team first noticed one of the lost cities in 2011 while hiking the grassy mountains of eastern Uzbekistan in search of untold history. The archaeologists trekked along the riverbed and spotted burial sites along the way to the top of one of the mountains. Once there, a plateau dotted with strange mounds spread before them. To the untrained eye, these mounds wouldn't have looked like much. But “as archaeologists..., [we] recognize them as anthropogenic places, as places where people live,” says Farhod Maksudov of the National Center of Archaeology of the Uzbekistan Academy of Sciences.</p><p data-block="sciam/paragraph">The ground, too, was littered with thousands of pottery shards. “We were kind of blown away,” says Michael Frachetti, an archaeologist at Washington University in St. Louis. He and Maksudov had been in search of archaeological evidence of nomadic cultures that grazed their herds on the mountain pastures. The researchers never expected to find a 30-acre medieval city in a relatively inhospitable climate around 7,000 feet above sea level.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">But this site, called Tashbulak, after the area’s present-day name, was only the beginning. While excavating in 2015, Frachetti met with one of the region’s only current inhabitants—a forestry inspector who lives with his family a few miles from Tashbulak. “He said, ‘In my backyard, I’ve seen ceramics like that,’” Frachetti recalls. So the archaeologists drove to the forestry inspector’s farmstead, where they found that his home rested on a familiar-looking mound.</p><p data-block="sciam/paragraph">“Sure enough, he’s living on a medieval citadel,” Frachetti says. From there, the researchers looked out at the landscape and saw even more mounds. “And we’re like, ‘Oh my gosh, this place is humongous,’” Frachetti adds.</p><p data-block="sciam/paragraph">This second site, named Tugunbulak, is <a href="http://dx.doi.org/10.1038/s41586-024-08086-5">described for the first time</a> in a study published on October 23 in <i>Nature. </i>The researchers used remote-sensing technology to map what they describe as a sprawling, nearly 300-acre medieval city three miles from Tashbulak that was integrated into the network of trade routes known as the Silk Road.</p><p data-block="sciam/paragraph">“It’s a pretty remarkable discovery,” says Zachary Silvia, an archaeologist at Brown University, who researches this period of Central Asian history and culture. (Silvia was not involved in the new work, but he authored a <a href="https://doi.org/10.1038/d41586-024-03315-3">commentary</a> about it that was published in the same issue of <i>Nature.</i>) Though more excavations are needed to confirm Tugunbulak’s scope and density, “even if it turns out to be half the size [estimated here], that’s still a huge discovery,” he says—and one that could force a rethink of just how sprawling the Silk Road networks were.</p><figure data-block="contentful/image"><picture><source media="(min-width: 750px)" srcset="https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><source media="(min-width: 0px)" srcset="https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=600 600w, https://static.scientificamerican.com/dam/m/4b70594726068971/original/lost-cities-map_graphic_m.png?m=1729777928.094&amp;w=750 750w" sizes="(min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><img alt="Map shows the conventional representation of the Silk Routes through Asia and marks the location of Tugunbulak and Tashbulak in the mountains of southeastern Uzbekistan." decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=900" width="2917" height="1750" srcset="https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=600 600w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=750 750w, https://static.scientificamerican.com/dam/m/74894e5c1a6fa48f/original/lost-cities-map_graphic_d_TEXT.png?m=1729777928.094&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"></picture><figcaption></figcaption></figure><p data-block="sciam/paragraph">On conventional maps of the Silk Road, trade routes spanning the Eurasian continent tend to avoid the mountains of Central Asia as much as possible. Low-lying cities such as Samarkand and Tashkent, which have the arable land and irrigation necessary to support their bustling populations, are seen as having been the real destinations for trade. On the other hand, the nearby Pamir mountains, where Tashbulak and Tugunbulak are located, are rugged and mostly nonarable because of their elevation. (Today less than 3 percent of the world’s population lives more than 2,000 meters, or about 6,500 feet, above sea level.)</p><p data-block="sciam/paragraph">Yet despite the limited resources and frigid winters, people did live at Tashbulak and Tugunbulak from the eighth to 11th centuries C.E., during the Middle Ages. Eventually, whether slowly or all at once, the settlements were abandoned and left to the elements. In the mountains, the landscape changed quickly, and the remains of the cities were worn down by erosion and blanketed with sediment. A thousand years later, what’s left are mounds, plateaus and ridges that are hard to map comprehensively with the naked eye.</p><figure data-block="contentful/image" data-disable-apple-news="true"><picture><source media="(min-width: 0px)" srcset="https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=600 600w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=750 750w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><img alt="Drone view of grassy mountain peaks" decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=900" width="3413" height="1920" srcset="https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=600 600w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=750 750w, https://static.scientificamerican.com/dam/m/6c1745e8f53ea10c/original/Tugunbulak_drone_view_west_sector_a.jpg?m=1729699376.061&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"></picture><figcaption><p>A drone view of Tugunbulak.</p><p>M. Frachetti</p></figcaption></figure><p data-block="sciam/paragraph">To get a detailed lay of the land, Frachetti and Maksudov equipped a drone with remote-sensing technology called lidar (light detection and ranging). Drones are tightly regulated in Uzbekistan, but the researchers managed to get the necessary permits to fly one at the site. A lidar scanner uses laser pulses to map the features of land below. The technology has been increasingly used in archaeology—in the past few years it has helped uncover a <a href="https://www.scientificamerican.com/article/lasers-reveal-massive-650-square-mile-maya-site-hidden-beneath-guatemalan-rainforest/">lost Maya city sprawling beneath the rainforest canopy</a> in Guatemala.</p><p data-block="sciam/paragraph">At Tashbulak and Tugunbulak, the result was a relief map of the sites with inch-level detail. With the help of computer algorithms, manual tracings and excavations, the researchers mapped out subtle ridges that likely represented walls and other buried structures.</p><p data-block="sciam/paragraph">This method has its limitations, Silvia says—namely, it often turns up false positives. It’s also impossible to confirm which features come from which time period without more excavation. Such work has been ongoing at Tashbulak but has only just begun at Tugunbulak. (The scans and some excavation were completed in 2022, and Frachetti’s team returned to Tugunbulak this past summer to continue excavation. The researchers have yet to publish their findings.) For now, the lidar map of Tugunbulak appears to show a massive medieval complex, complete with a citadel, buildings, courtyards, plazas and pathways, bounded by fortified walls. Along with pottery, the team has excavated kilns, as well as clues that workers in the city smelted iron ores, Frachetti says.</p><figure data-block="contentful/image" data-disable-apple-news="true"><picture><source media="(min-width: 0px)" srcset="https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=600 600w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=750 750w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"><img alt="Archeologists excavate a large medieval pot" decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=900" width="2881" height="1920" srcset="https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=600 600w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=750 750w, https://static.scientificamerican.com/dam/m/55dcf2c46d1d0b9b/original/tugunbulak_excavations_of_medieval_pottery.jpg?m=1729694564.763&amp;w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"></picture><figcaption><p>Medieval pottery excavated at Tugunbulak.</p><p>M. Frachetti</p></figcaption></figure><p data-block="sciam/paragraph">Metallurgy may be a key part of how the city could sustain itself at such a high altitude. The mountains are rich in iron ore and have dense juniper forests, which could be burned to fuel the smelting process. The researchers have also uncovered coins from across modern-day Uzbekistan, Maksudov says, suggesting the city may have been a hub for trade. It doesn’t appear to have been strictly a mining settlement, either—at Tashbulak, a cemetery contains the remains of women, elderly people and infants.</p><p data-block="sciam/paragraph">“We have realized that this was a large urban center, which was integrated into the Silk Road network and dragged the Silk Road caravans toward mountains ... because they had their own products to offer,” Maksudov says.</p><p data-block="sciam/paragraph">“There is a relationship between these cities” in the highlands and those in the lowlands, says Sanjyot Mehendale, an archaeologist and chair of the Tang Center for Silk Road Studies at the University of California, Berkeley. The trading networks of the Silk Road were “very, very fluid,” and societies once considered peripheral and remote, such as those of Tashbulak and Tugunbulak, “were part of a network that stretched all across Eurasia,” she says. “You can no longer look at these areas and perceive them as remote or less developed.”</p><p data-block="sciam/paragraph">Mehendale became involved with the work at Tugunbulak after the lidar study was completed, and she went to the site to excavate this past summer. She’s now most interested in reconstructing what the city was like across its life span. Who were the inhabitants? How did the population change over seasons or centuries?</p><p data-block="sciam/paragraph">The answers to all these questions are likely there, buried in the sediment. The research team, Silvia says, “has got a lifetime of work.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JetBrains Rider is now free for non-commercial use (717 pts)]]></title>
            <link>https://www.jetbrains.com/rider/</link>
            <guid>41936001</guid>
            <pubDate>Thu, 24 Oct 2024 14:43:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jetbrains.com/rider/">https://www.jetbrains.com/rider/</a>, See on <a href="https://news.ycombinator.com/item?id=41936001">Hacker News</a></p>
<div id="readability-page-1" class="page">

        <!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->

<div class="page">
    
            <div>
            







  <div id="js-menu-second">
        

        <div id="js-menu-second-desktop">
            <div>
                <p><a href="https://www.jetbrains.com/rider/">
                    
                    <span>Rider</span>
                </a>
            </p></div>

            <div>
                        
                                                    <p><a href="https://www.jetbrains.com/rider/download/">
                                Download
                            </a>
                                            </p></div>
        </div>
    </div>



        </div>
    
    

            
    </div>

          
      
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Which Animal Shares Your Body Fat Percentage? (140 pts)]]></title>
            <link>https://animalbodyfatmatch.netlify.app/</link>
            <guid>41935166</guid>
            <pubDate>Thu, 24 Oct 2024 13:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://animalbodyfatmatch.netlify.app/">https://animalbodyfatmatch.netlify.app/</a>, See on <a href="https://news.ycombinator.com/item?id=41935166">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: 2048 turned 10 this year, I built an updated version to celebrate (549 pts)]]></title>
            <link>https://play2048.co</link>
            <guid>41934746</guid>
            <pubDate>Thu, 24 Oct 2024 12:15:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://play2048.co">https://play2048.co</a>, See on <a href="https://news.ycombinator.com/item?id=41934746">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>