<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 23 Sep 2024 20:30:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HNInternal: Show HN: I Wrote a Book on Java (128 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41629377</link>
            <guid>41629377</guid>
            <pubDate>Mon, 23 Sep 2024 18:56:44 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41629377">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=41629377: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Intelligence Age (190 pts)]]></title>
            <link>https://ia.samaltman.com/</link>
            <guid>41628167</guid>
            <pubDate>Mon, 23 Sep 2024 17:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ia.samaltman.com/">https://ia.samaltman.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41628167">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><p><img alt="A vibrant, impressionistic landscape of a winding path that stretches towards the horizon, lined with colorful fields" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=640&amp;q=75 640w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=750&amp;q=75 750w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=828&amp;q=75 828w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=1080&amp;q=75 1080w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=1200&amp;q=75 1200w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=1920&amp;q=75 1920w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=2048&amp;q=75 2048w, https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=3840&amp;q=75 3840w" src="https://ia.samaltman.com/_next/image?url=%2Fimages%2Fcover.png&amp;w=3840&amp;q=75"></p></div><div><p>In the next couple of decades, we will be able to do things that would have seemed like magic to our grandparents.</p><p>This phenomenon is not new, but it will be newly accelerated. People have become dramatically more capable over time; we can already accomplish things now that our predecessors would have believed to be impossible.</p><p>We are more capable not because of genetic change, but because we benefit from the infrastructure of society being way smarter and more capable than any one of us; in an important sense, society itself is a form of advanced intelligence. Our grandparents – and the generations that came before them – built and achieved great things. They contributed to the scaffolding of human progress that we all benefit from. AI will give people tools to solve hard problems and help us add new struts to that scaffolding that we couldn’t have figured out on our own. The story of progress will continue, and our children will be able to do things we can’t.</p><p>It won’t happen all at once, but we’ll soon be able to work with AI that helps us accomplish much more than we ever could without AI; eventually we can each have a personal AI team, full of virtual experts in different areas, working together to create almost anything we can imagine. Our children will have virtual tutors who can provide personalized instruction in any subject, in any language, and at whatever pace they need. We can imagine similar ideas for better healthcare, the ability to create any kind of software someone can imagine, and much more.</p><p>With these new abilities, we can have shared prosperity to a degree that seems unimaginable today; in the future, everyone’s lives can be better than anyone’s life is now. Prosperity alone doesn’t necessarily make people happy – there are plenty of miserable rich people – but it would meaningfully improve the lives of people around the world.</p><p>Here is one narrow way to look at human history: after thousands of years of compounding scientific discovery and technological progress, we have figured out how to melt sand, add some impurities, arrange it with astonishing precision at extraordinarily tiny scale into computer chips, run energy through it, and end up with systems capable of creating increasingly capable artificial intelligence.</p><p>This may turn out to be the most consequential fact about all of history so far. It is possible that we will have superintelligence in a few thousand days (!); it may take longer, but I’m confident we’ll get there.</p><p>How did we get to the doorstep of the next leap in prosperity?</p><p>In three words: deep learning worked.</p><p>In 15 words: deep learning worked, got predictably better with scale, and we dedicated increasing resources to it.</p><p>That’s really it; humanity discovered an algorithm that could really, truly learn any distribution of data (or really, the underlying “rules” that produce any distribution of data). To a shocking degree of precision, the more compute and data available, the better it gets at helping people solve hard problems. I find that no matter how much time I spend thinking about this, I can never really internalize how consequential it is.</p><p>There are a lot of details we still have to figure out, but it’s a mistake to get distracted by any particular challenge. Deep learning works, and we will solve the remaining problems. We can say a lot of things about what may happen next, but the main one is that AI is going to get better with scale, and that will lead to meaningful improvements to the lives of people around the world.</p><p>AI models will soon serve as autonomous personal assistants who carry out specific tasks on our behalf like coordinating medical care on your behalf. At some point further down the road, AI systems are going to get so good that they help us make better next-generation systems and make scientific progress across the board.</p><p>Technology brought us from the Stone Age to the Agricultural Age and then to the Industrial Age. From here, the path to the Intelligence Age is paved with compute, energy, and human will.</p><p>If we want to put AI into the hands of as many people as possible, we need to drive down the cost of compute and make it abundant (which requires lots of energy and chips). If we don’t build enough infrastructure, AI will be a very limited resource that wars get fought over and that becomes mostly a tool for rich people.</p><p>We need to act wisely but with conviction. The dawn of the Intelligence Age is a momentous development with very complex and extremely high-stakes challenges. It will not be an entirely positive story, but the upside is so tremendous that we owe it to ourselves, and the future, to figure out how to navigate the risks in front of us.</p><p>I believe the future is going to be so bright that no one can do it justice by trying to write about it now; a defining characteristic of the Intelligence Age will be massive prosperity.</p><p>Although it will happen incrementally, astounding triumphs – fixing the climate, establishing a space colony, and the discovery of all of physics – will eventually become commonplace. With nearly-limitless intelligence and abundant energy – the ability to generate great ideas, and the ability to make them happen – we can do quite a lot.</p><p>As we have seen with other technologies, there will also be downsides, and we need to start working now to maximize AI’s benefits while minimizing its harms. As one example, we expect that this technology can cause a significant change in labor markets (good and bad) in the coming years, but most jobs will change more slowly than most people think, and I have no fear that we’ll run out of things to do (even if they don’t look like “real jobs” to us today). People have an innate desire to create and to be useful to each other, and AI will allow us to amplify our own abilities like never before. As a society, we will be back in an expanding world, and we can again focus on playing positive-sum games.</p><p>Many of the jobs we do today would have looked like trifling wastes of time to people a few hundred years ago, but nobody is looking back at the past, wishing they were a lamplighter. If a lamplighter could see the world today, he would think the prosperity all around him was unimaginable. And if we could fast-forward a hundred years from today, the prosperity all around us would feel just as unimaginable.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare's new marketplace lets websites charge AI bots for scraping (275 pts)]]></title>
            <link>https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/</link>
            <guid>41625903</guid>
            <pubDate>Mon, 23 Sep 2024 13:31:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/">https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/</a>, See on <a href="https://news.ycombinator.com/item?id=41625903">Hacker News</a></p>
Couldn't get https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[I Designed a Dieter Rams Inspired iPhone Dock (771 pts)]]></title>
            <link>https://arslan.io/2024/09/23/dieter-rams-inspired-iphone-dock/</link>
            <guid>41623467</guid>
            <pubDate>Mon, 23 Sep 2024 07:51:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arslan.io/2024/09/23/dieter-rams-inspired-iphone-dock/">https://arslan.io/2024/09/23/dieter-rams-inspired-iphone-dock/</a>, See on <a href="https://news.ycombinator.com/item?id=41623467">Hacker News</a></p>
Couldn't get https://arslan.io/2024/09/23/dieter-rams-inspired-iphone-dock/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[How the iPhone 16's electrically-released adhesive works (385 pts)]]></title>
            <link>https://www.ifixit.com/News/100352/we-hot-wired-the-iphone-16</link>
            <guid>41623251</guid>
            <pubDate>Mon, 23 Sep 2024 07:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ifixit.com/News/100352/we-hot-wired-the-iphone-16">https://www.ifixit.com/News/100352/we-hot-wired-the-iphone-16</a>, See on <a href="https://news.ycombinator.com/item?id=41623251">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<figure><video autoplay="" loop="" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21203859/Untitled-video-1.mp4" playsinline=""></video></figure>



<p>Our teardown lab is filled with iPhone 16 parts, and we’ve been having a blast playing with them. Apple’s latest smartphone series has largely underwhelmed tech reviewers, who are <a href="https://www.theverge.com/24247538/apple-iphone-16-pro-review">mixed</a> on the <a href="https://www.theverge.com/24247479/apple-iphone-16-plus-review-camera-control-screen-battery">usefulness</a> of the new dedicated camera button and <a href="https://techcrunch.com/2024/09/20/the-iphone-16-launches-today-without-its-most-hyped-feature-apple-intelligence/">twiddling their thumbs</a> waiting for Apple Intelligence to drop.</p>



<p>But in our world, it’s a big deal: the iPhone 16 lineup makes three big leaps for repairkind.&nbsp;</p>



<figure><p>
<iframe title="Hot-Wiring the iPhone 16: New Battery Removal and Complete Teardown" width="456" height="257" src="https://www.youtube-nocookie.com/embed/M6jBXI6CR9s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p><strong>First:</strong> The adhesive that secures the battery, in the vanilla and Plus models, is this fancy new sticky stuff that can debond when you pass an electrical current through it. That means no more reliance on finicky, brittle adhesive strips, just a consistent, easily repeatable process. It will require a new tool, of course—more on that later.</p>



<div><p><strong>Second:</strong> The 16 Pro battery has a hard steel case instead of a soft pouch, a form factor that looks familiar from the Apple Watch. Every time we’ve heard electronics manufacturers suggest that repairs could be dangerous because of lithium-ion batteries, we point out that the power to make battery repairs safer is in their hands: Hard cell batteries instead of soft pouch batteries won’t get accidentally punctured by a slip of a screwdriver, and so they’re way less likely to catch fire. Since the Pro doesn’t feature the new adhesive, getting the battery out may sometimes require prying, and a hard case will make that process safer. The one model with no battery improvements? The flagship 16 Pro Max.</p><p><strong>Third: </strong><a href="https://www.ifixit.com/News/64865/iphone-14-teardown">We’ve lauded</a> the “enter through either the front or the back” design that debuted on the base iPhone 14, but it took two generations for Apple to trickle that innovation up to their pro phones. It’s here on all models now—and it looks like it’s here to stay. Having to remove an expensive, fragile, ProMotion OLED during a repair path isn’t ideal, so being able to avoid it for simple repairs streamlines procedures.</p></div>



<figure><img fetchpriority="high" loading="lazy" decoding="async" width="1920" height="1080" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21145519/iPhone_16_128-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21145519/iPhone_16_128-1.jpg 1920w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145519/iPhone_16_128-1-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145519/iPhone_16_128-1-1600x900.jpg 1600w" sizes="(max-width: 1920px) 100vw, 1920px"></figure>



<p>And that’s not even counting iOS 18’s new “Repair Assistant,” which aspires to end the parts pairing software barriers to repair. When we tested it out with the iPhone 15 series earlier this week, we thought it was <a href="https://www.ifixit.com/News/100266/the-end-of-parts-pairing-almost">promising, if not quite ready for prime time</a>. But it worked impressively smoothly on our vanilla iPhone 16: one click to pair and calibrate all components at once, and no bugs to be found.&nbsp;</p>



<figure><video autoplay="" loop="" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21203534/tilt-360.mp4" playsinline=""></video></figure>



<h2>Announcing FixHub: A New iFixit Tool</h2>



<p>Speaking of innovations in repairability, we’re really excited to announce the latest addition to our workbench, the FixHub Portable Soldering Station. This is the mobile soldering iron that we’ve always wanted. It’s lightning-quick: from off to ready to solder in 5 seconds flat. And with the magnetic iron cap, you can make it safe to tuck back into your go-bag without waiting for it to cool off. <a href="https://www.ifixit.com/fixhub">Preorders are open now.</a></p>



<figure><a href="https://www.ifixit.com/fixhub"><img loading="lazy" decoding="async" width="6245" height="3513" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21204117/iFixit-FixHub-Portable-Solderin-Station-Hero-2.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21204117/iFixit-FixHub-Portable-Solderin-Station-Hero-2.jpg 6245w, https://valkyrie.cdn.ifixit.com/media/2024/09/21204117/iFixit-FixHub-Portable-Solderin-Station-Hero-2-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21204117/iFixit-FixHub-Portable-Solderin-Station-Hero-2-2048x1152.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/09/21204117/iFixit-FixHub-Portable-Solderin-Station-Hero-2-1600x900.jpg 1600w" sizes="(max-width: 6245px) 100vw, 6245px"></a></figure>







<h2>Fancy New Sticky Stuff</h2>



<p>The earliest rumors of new electrically-releasing battery adhesive came back in June, when <a href="https://www.theinformation.com/articles/apple-explores-novel-method-for-making-iphone-batteries-more-replaceable">Wayne Ma at The Information</a> reported that Apple was testing technology to make DIY repair easier.</p>



<p>When adhesive manufacturer Tesa <a href="https://www.theinformation.com/articles/apple-explores-novel-method-for-making-iphone-batteries-more-replaceable">released a video</a> showing their new “Debonding on Demand — Electrical Release” process, we were convinced. We have high confidence that this Tesa technology is adhering the battery.</p>



<figure><video autoplay="" controls="" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21110752/electrial-relase-psa-battery-mounting_11134808_195005897.webm" playsinline=""></video></figure>



<p>As soon as Apple’s official iPhone 16 repair manuals dropped (which was actually <em>on</em> launch day, something we love to see), we hustled over to their battery guide, which sure enough <a href="https://support.apple.com/en-us/120642">described passing 9V</a> through this fancy new adhesive.</p>



<figure><img loading="lazy" decoding="async" width="880" height="600" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21110804/image-4.png" alt=""><figcaption>This image is from Apple’s official iPhone 16 battery repair guide.</figcaption></figure>



<p>So, how does this magical adhesive work? <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/admi.202101447">This research paper</a> sheds some light:</p>



<blockquote>
<p>In the second scenario, anodic delamination is caused by the oxidation of the surface of the aluminum substrate and migration of Al3+ into the adhesive. This will lead to fast debonding since the substrate layer bonded to the adhesive is no longer supported.</p>
</blockquote>



<p>What does this jargon mean? Imagine an Oreo cookie with a thick layer of double-stuf creme. You figured out that if you dip just the bottom cookie in some milk and twist the cookie apart, the filling will always stick to the top cookie.<br>Similarly, when we zap the adhesive, the current oxidizes the negative/anode mating surface and loosens the adhesive from it. The adhesive “filling” between the battery and the frame will then stick to whichever surface that’s connected to the positive terminal.</p>



<h3>Trial Run of Our Next FixHub Tool</h3>



<p>When the time came to crack open the new phones, we were ready with a prototype of our new iPhone battery repair tool: a USB-C cable on one end, alligator clips on the other. We plugged it into our <a href="https://www.ifixit.com/products/fixhub-power-series-portable-soldering-station">FixHub Power Station</a>, clipped the ground wire to a nearby screw, and attached the red wire to a silver tab next to the battery.&nbsp;</p>



<p>Our cable was set up to deliver 12V, and since Tesa suggested that their adhesive would release in 60 seconds at 12V, we waited a minute: Sure enough, the battery lifted out with no force, and the case underneath was <em>almost</em> residue-free (though the battery side remained tacky). You’ll probably still want to take a pass with <a href="https://www.ifixit.com/News/36877/ask-ifixit-everything-you-wanted-to-know-about-isopropyl-alcohol?srsltid=AfmBOoqCIheKnOsGA8xJUAjLe1u1pgQ82Wp0e-VC9pHiWklldk9QRBQb">isopropyl alcohol</a> before you put a new battery in, but you won’t have to scrape out adhesive strip remnants like in iPhones of yore.</p>



<figure>
<figure><a href="https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1.jpg"><img loading="lazy" decoding="async" width="600" height="400" data-id="100430" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-600x400.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-450x300.jpg 450w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145524/iPhone_16_TD_16-1-768x512.jpg 768w" sizes="(max-width: 600px) 100vw, 600px"></a></figure>



<figure><a href="https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1.jpg"><img loading="lazy" decoding="async" width="600" height="400" data-id="100431" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-600x400.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-450x300.jpg 450w, https://valkyrie.cdn.ifixit.com/media/2024/09/21145526/iPhone_16_TD_24-1-768x512.jpg 768w" sizes="(max-width: 600px) 100vw, 600px"></a></figure>
</figure>



<p>One of the biggest problems with the current stretch-release adhesive strips—the ones still used in the 16 Pro and Pro Max—is that they get more and more brittle over time. In older phones, repair techs essentially expect that they’re going to have to apply a solvent under the battery to get the adhesive to disengage—not a huge deal, but depending on the solvent and how careful you are with application, it can damage other internal components. Only time will tell how this new adhesive ages; Apple’s own repair manual suggests that the adhesive <a href="https://support.apple.com/en-us/120642">may take longer to disengage</a> over time. They say you can use up to 30V to trigger the electrical release. We tried releasing our battery at several different voltages. At 20V, the battery released in about 5 seconds. At 5V, it took a tad over 6 minutes.</p>



<figure><video controls="" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21111949/DSC_7733_Adhesive_release.mp4"></video></figure>



<p>The adhesive sits inside a well in the frame, specially machined to create ridges and rough surfaces for the glue to adhere to. A close up under <a href="https://www.evidentscientific.com/en/">Evident Scientific’s</a> microscope really brings this simple but beautiful structure to life.</p>



<figure><img loading="lazy" decoding="async" width="1750" height="1080" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21214357/Frame-machine-marks-for-battery-adhesive-15.6x.jpg" alt="A microscopic view of circular machine marks under the battery in the iPhone 16 frame" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21214357/Frame-machine-marks-for-battery-adhesive-15.6x.jpg 1750w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214357/Frame-machine-marks-for-battery-adhesive-15.6x-1536x948.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214357/Frame-machine-marks-for-battery-adhesive-15.6x-1458x900.jpg 1458w" sizes="(max-width: 1750px) 100vw, 1750px"></figure>



<h3>This Phone Needs a New Tool. Is That a Repairability Problem?</h3>



<p>The last time iPhone repair <a href="https://www.ifixit.com/News/14279/apples-diabolical-plan-to-screw-your-iphone">required a brand new tool</a>—when Apple began sealing phones with their proprietary five-pointed screw, the pentalobe—we <a href="https://www.ifixit.com/News/14279/apples-diabolical-plan-to-screw-your-iphone">raised a fuss</a>. At the time, nobody outside official Apple repair shops had access to the driver, which effectively blocked repairs until we reverse-engineered it. This is pretty different. Any hardware store around the world will sell you a set of alligator clips and a 9V battery, at a reasonable price.&nbsp;</p>



<p>Everyone fixing one of these phones is going to need a power supply of some kind. Apple’s 9V battery solution is perfectly fine, but USB-C can also output the needed power and is in some cases more convenient (9V batteries have <a href="https://www.quora.com/Why-arent-9-volt-batteries-used-much-anymore?top_ans=1477743673943660">fallen out of favor</a>). Good news: we’re already working on a ruggedized version of our prototype to include with our <a href="https://www.ifixit.com/Parts/iPhone/Batteries">battery repair kits</a>.</p>



<h3>Is It Reversible?</h3>



<p>If we connected the 9V in reverse, would that rebond the adhesive? Nope. The adhesive remained ungrippy. The reverse polarity did have an effect: when we reverse-zapped a new phone, the zap released the battery, but the adhesive residue stuck to the frame instead of the battery. Before that, a positive zap consistently left the residue on the battery. If you’re trying this at home, be sure to get the polarity right so you have less residue to clean up on the frame!</p>



<figure><img loading="lazy" decoding="async" width="1920" height="1080" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21153624/iPhone_16_TD_9-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21153624/iPhone_16_TD_9-1.jpg 1920w, https://valkyrie.cdn.ifixit.com/media/2024/09/21153624/iPhone_16_TD_9-1-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21153624/iPhone_16_TD_9-1-1600x900.jpg 1600w" sizes="(max-width: 1920px) 100vw, 1920px"><figcaption>With the correct polarity, the adhesive sticks to the battery and leaves the frame clean (right). With reversed polarity, the adhesive sticks to the frame instead (left).</figcaption></figure>



<p>It doesn’t seem like this adhesive is intended to be multi-use. We’re guessing that Apple will sell batteries with the new adhesive already applied (the repair manual describes “peeling the pink release liner” off the adhesive). </p>



<h3>Easy Battery Repairs Matter</h3>



<p>There was a time when cell phone battery replacements hardly deserved being called a repair—you’d pop the back cover off with your thumbnail and stick in a new battery. Fairphone has proven that <a href="https://www.ifixit.com/News/87664/fairphone-5-keeping-it-10-10">this is still possible</a> in the form factor of a modern smartphone, with an IP55 rating.</p>



<p>But until the industry goes the way of Fairphone (or chooses that’s where they want to innovate), battery replacements will remain the repair most worth talking about. Batteries are consumables. They’ll eventually wear out, no matter how durable the rest of your phone is. Extending a phone’s life by a year saves about <a href="https://www.sciencedirect.com/science/article/pii/S2773167722000115">100x the phone’s weight</a>&nbsp; in CO2 emissions, and easy battery replacements are a necessary part of that lifespan extension.&nbsp;</p>



<p>Some <a href="https://www.macrumors.com/2024/09/11/apple-makes-iphone-16-batteries-easier-to-replace">people have speculated</a> that the new adhesive is aimed at helping Apple comply with new European Right to Repair regulations that passed recently, but we don’t think that’s what’s going on here. There are two regulations that address battery repairs: <a href="https://eur-lex.europa.eu/eli/reg/2023/1670/oj">Ecodesign for Smartphones</a> and the <a href="https://eur-lex.europa.eu/eli/reg/2023/1542/oj">new Battery Regulation</a>, each with slightly different requirements for compliance, both requiring easily removable batteries. Europe will probably enforce one or the other. The <a href="https://susproc.jrc.ec.europa.eu/product-bureau/sites/default/files/2023-11/Battery%20RR%20-%20stakeholder-%2030October23.pdf">Joint Research Commission has suggested</a> that Ecodesign will likely supersede, but it’s not yet settled.&nbsp;</p>



<p>Regardless, in either case, we don’t believe the changed battery adhesive affects compliance—stretch-release adhesive and electrical-release adhesive under a battery seem to be equally compliant. However, display removal is a sticking point for both regulations: The iPhone 16 display removal is not compliant with the Ecodesign Directive because of the use of pentalobe screws, and it’s not compliant with the battery regulation because it requires heat for entry. If Apple could use this new voltage-release adhesive to open the phone, that might get them compliant with the Battery Regulation.</p>



<h2>Improved Thermal Handling of AI Workloads</h2>



<p>How well the iPhone can dissipate heat has always mattered: When the processor gets too hot, it has to throttle down and reduce performance. In this new world of AI, with on-device machine learning models, performance is going to matter more than ever. Faster models are more intelligent and can give you better suggestions or photo enhancements.</p>



<figure><img loading="lazy" decoding="async" width="1365" height="768" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21145821/iPhone_16_TD_43.jpg" alt=""><figcaption>Thermal paste transfers heat from the A18 to this sink. The orange insulator on the sink prevents it from spilling on the smaller components.</figcaption></figure>



<p>Apple has significantly changed up their approach to dissipating heat from the main A18 processor with a new, ferrous heat sink. In this photo it looks like an EMI shield, but it’s actually a solid block of material. This sink sits inside the mainboard sandwich, soldered to the inside of the RF half of the logic board—which has an L-shaped footprint, similar to iPhones past and the 15 Plus from last year. Thermal paste transfers heat from the A18 to this sink.&nbsp;</p>



<figure><img loading="lazy" decoding="async" width="1365" height="768" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21145823/iPhone_16_TD_45.jpg" alt=""><figcaption>Markup indicates where the sink and insulator sit on top of the SoC.</figcaption></figure>



<p>Intriguingly, this heat sink only covers about half of the A18 SoC. If the alignment of the die markings match Apple’s marketing photos, then the heat sink is over the Neural Engine, Apple’s machine learning hardware. The more efficiently they can run their Neural Engine, the better it will work. These improvements will enable the iPhone to run at maximum performance longer than previous designs.</p>



<figure><img loading="lazy" decoding="async" width="720" height="480" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21213655/image-5.png" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21213655/image-5.png 720w, https://valkyrie.cdn.ifixit.com/media/2024/09/21213655/image-5-300x200.png 300w, https://valkyrie.cdn.ifixit.com/media/2024/09/21213655/image-5-600x400.png 600w, https://valkyrie.cdn.ifixit.com/media/2024/09/21213655/image-5-324x216.png 324w, https://valkyrie.cdn.ifixit.com/media/2024/09/21213655/image-5-450x300.png 450w" sizes="(max-width: 720px) 100vw, 720px"><figcaption>Apple’s illustration of the Neural Engine, via the <a href="https://www.youtube.com/watch?v=eDqfg_LexCQ">iPhone 16 keynote</a>.</figcaption></figure>



<h2>Is the Camera Control Button … a Button?</h2>



<p>Aside from the delayed Apple Intelligence, the feature that’s got everyone talking in this lineup is the new dedicated camera button. Yes, it does physically actuate. Yes, it’s a button. But there’s more to it than that. When we pulled it out, we discovered that it’s got its own tiny integrated circuit.</p>



<figure><img loading="lazy" decoding="async" width="3273" height="980" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21205639/iPhone_16_TD_35-2.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21205639/iPhone_16_TD_35-2.jpg 3273w, https://valkyrie.cdn.ifixit.com/media/2024/09/21205639/iPhone_16_TD_35-2-1536x460.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21205639/iPhone_16_TD_35-2-2048x613.jpg 2048w" sizes="(max-width: 3273px) 100vw, 3273px"></figure>



<p>Unfortunately, the button seems to be laser-welded to the frame. Buttons in past models <a href="https://youtu.be/3oC1R3H4-zE?feature=shared&amp;t=936">featured a latch mechanism</a> that made them fully replaceable and repairable. Now, if the button malfunctions, you’ll have to replace the whole frame. The welds appear unnecessary, except to attach the button and its IC to the frame. There’s a new “enclosure” component in the service history of the phone, and we confirmed it’s tracking this IC—when we swapped out a button, “enclosure” popped up in the history. </p>



<p>Chips enable parts pairing, the software barrier to repair that has <a href="https://www.nytimes.com/2023/11/12/technology/iphone-repair-apple-control.html">increasingly plagued</a> Apple products. But since the new Repair Assistant mode worked flawlessly for us on the iPhone 16, a new serialized part is less of a red flag today than it was before.&nbsp;</p>



<figure><img loading="lazy" decoding="async" width="1919" height="1080" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21150708/camera-control-button-watermarked.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21150708/camera-control-button-watermarked.jpg 1919w, https://valkyrie.cdn.ifixit.com/media/2024/09/21150708/camera-control-button-watermarked-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21150708/camera-control-button-watermarked-1599x900.jpg 1599w" sizes="(max-width: 1919px) 100vw, 1919px"></figure>



<p>The spot where the button slots into the frame previously held a 5G mmWave antenna in the iPhone 15 (and every model back to the 12). Now there seems to be just one mmWave antenna left, sitting up against the camera assembly. Will that affect the phone’s signal strength?&nbsp;</p>



<p>We also noticed this interesting flex cable epoxied onto the bracket holding the button in place. This is likely the “force sensor”—a <a href="https://en.wikipedia.org/wiki/Strain_gauge">strain gauge</a> that converts tiny amounts of deformation into changes in resistance. The iPhone uses this to sense half-presses before the button actually clicks.</p>



<figure><img loading="lazy" decoding="async" width="1750" height="1080" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21150722/Force-sensor-watermarked.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21150722/Force-sensor-watermarked.jpg 1750w, https://valkyrie.cdn.ifixit.com/media/2024/09/21150722/Force-sensor-watermarked-1536x948.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21150722/Force-sensor-watermarked-1458x900.jpg 1458w" sizes="(max-width: 1750px) 100vw, 1750px"></figure>



<h2>Settling the Score</h2>



<p>Last year, we awarded the <a href="https://www.ifixit.com/Device/iPhone_15">iPhone 15</a> a lowly four out of ten, primarily due to the <a href="https://www.ifixit.com/News/82493/we-are-retroactively-dropping-the-iphones-repairability-score-en">real-world complications</a> that parts pairing causes. This year, Apple has changed their tune. Accordingly, we’re changing ours.</p>



<p>Let’s start with the basics: Apple’s repair manuals are well written, well above the average we see from other manufacturers, and it’s awesome (like, really cool!) that Apple had them ready for launch day. Our only real gripes are a lack of schematics for board-level repairs, and missing repair procedures for the charge port or any buttons. Everything else looks great.</p>



<p>Repair parts aren’t on sale yet, but if Apple matches what’s already available on the 15-series, they’ll get quite a bit of credit there—mostly a good offering with a few omissions (no charge ports, buttons, or enclosure, for instance) and a display assembly that’s too pricey to be an attractive repair option for most people.</p>



<p>The new battery procedure is the design highlight. We repeatedly deactivated the adhesive with a variety of tools and timings, and the procedure seems very robust. We really like that you don’t need an expensive proprietary tool for this: You could rig up any 9V battery with whatever length of wire you’ve got lying around, and you’re set. We’d still prefer screws or some other fastener that’s easier to reverse—this will require cleanup/prep before installing a new battery (which presumably comes with fresh adhesive pre-applied, otherwise folks will have to get creative). And the adhesive supplier will need to make this glue available to the repair market. Still, this is a really cool innovation.</p>



<figure><img loading="lazy" decoding="async" width="5398" height="3036" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21214156/iPhone_16_TD_17-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21214156/iPhone_16_TD_17-1.jpg 5398w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214156/iPhone_16_TD_17-1-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214156/iPhone_16_TD_17-1-2048x1152.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214156/iPhone_16_TD_17-1-1600x900.jpg 1600w" sizes="(max-width: 5398px) 100vw, 5398px"></figure>



<p>The dual-entry design, first introduced on the 14 series, remains very elegant. Once inside, lots of components are independently accessible with little to no additional disassembly. The layout is smart, prioritizing access to critical repairs like battery and camera replacement. In past models, it was normal to see, for example, battery pull tabs blocked by a Taptic Engine, which was blocked by a speaker, which was blocked by a big grounding bracket—all of that having to come out in sequence. The 16’s design offers independent access to the battery, the speaker, the Taptic Engine, cameras, display, back cover, and so on. It’s really thoughtfully laid out.</p>



<p>The largest remaining obstacles to repair: Apple continues to use a variety of fussy screw types. The display and rear panel adhesive requires heat to get inside. But we’re beyond pleased that Repair Assistant worked effortlessly, which removes our biggest complaint about the last few models of iPhone.</p>



<figure><img loading="lazy" decoding="async" width="400" height="533" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21140930/7_Provisional_Repairability-Score_Drop-Shadow.png" alt=""></figure>



<p>The iPhone 16 earns a respectable 7 out of 10, a significant upgrade from last year’s model.</p>



<figure><img loading="lazy" decoding="async" width="2500" height="1407" src="https://valkyrie.cdn.ifixit.com/media/2024/09/21214307/iPhone-16-layout-1.jpg" alt="All the components of the iPhone 16 laid out" srcset="https://valkyrie.cdn.ifixit.com/media/2024/09/21214307/iPhone-16-layout-1.jpg 2500w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214307/iPhone-16-layout-1-1536x864.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214307/iPhone-16-layout-1-2048x1153.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/09/21214307/iPhone-16-layout-1-1599x900.jpg 1599w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A terrible way to jump into colocating your own stuff (119 pts)]]></title>
            <link>http://rachelbythebay.com/w/2024/09/22/colo/</link>
            <guid>41622653</guid>
            <pubDate>Mon, 23 Sep 2024 05:39:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://rachelbythebay.com/w/2024/09/22/colo/">http://rachelbythebay.com/w/2024/09/22/colo/</a>, See on <a href="https://news.ycombinator.com/item?id=41622653">Hacker News</a></p>
Couldn't get http://rachelbythebay.com/w/2024/09/22/colo/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The war on remote work has nothing to do with productivity (250 pts)]]></title>
            <link>https://www.the-sentinel-intelligence.com/p/heres-why-they-want-you-back-at-the-office-so-bad</link>
            <guid>41622640</guid>
            <pubDate>Mon, 23 Sep 2024 05:35:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.the-sentinel-intelligence.com/p/heres-why-they-want-you-back-at-the-office-so-bad">https://www.the-sentinel-intelligence.com/p/heres-why-they-want-you-back-at-the-office-so-bad</a>, See on <a href="https://news.ycombinator.com/item?id=41622640">Hacker News</a></p>
Couldn't get https://www.the-sentinel-intelligence.com/p/heres-why-they-want-you-back-at-the-office-so-bad: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What's inside the QR code menu at this cafe? (435 pts)]]></title>
            <link>https://peabee.substack.com/p/whats-inside-the-qr-code-menu-at</link>
            <guid>41622632</guid>
            <pubDate>Mon, 23 Sep 2024 05:33:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://peabee.substack.com/p/whats-inside-the-qr-code-menu-at">https://peabee.substack.com/p/whats-inside-the-qr-code-menu-at</a>, See on <a href="https://news.ycombinator.com/item?id=41622632">Hacker News</a></p>
Couldn't get https://peabee.substack.com/p/whats-inside-the-qr-code-menu-at: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Rust panics under the hood, and implementing them in .NET (112 pts)]]></title>
            <link>https://fractalfir.github.io/generated_html/rustc_codegen_clr_v0_2_1.html</link>
            <guid>41622601</guid>
            <pubDate>Mon, 23 Sep 2024 05:26:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fractalfir.github.io/generated_html/rustc_codegen_clr_v0_2_1.html">https://fractalfir.github.io/generated_html/rustc_codegen_clr_v0_2_1.html</a>, See on <a href="https://news.ycombinator.com/item?id=41622601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I am currently working on a Rust to .NET compiler, <code>rustc_codegen_clr</code>. To get it to work, I need to implement many Rust features using .NET APIs. One of such features is panicking and unwinding.</p>

<p>This article is the first one in a series about Rust panics, unwinding, and my implementation of them in .NET.</p>

<p>In this part, I will look at unwinding (the compiler side of panicking), and in the next one, I will explain the Linux GNU <code>std</code> implementation of panicking.</p>

<h2 id="how_a_rust_to_.net_compiler_works:_quick_recap">How a Rust to .NET compiler works: Quick recap</h2>

<p>Before I talk about the project, I should probably explain what it is. It is a "rust compiler backend" - but what does that mean?</p>

<p>You can imagine it as a compiler plugin, which replaces the very last step of compilation (code generation). Instead of using LLVM to generate native code, my project turns the internal Rust representation called MIR, into .NET Common Intermediate Language. CIL is then stored inside .NET assemblies, which allows the .NET runtime to load, and execute the compiled Rust code easily. <img src="https://fractalfir.github.io/images/rustc_codegen_clr_inner_workings_graph.png" alt=""></p>

<p>From the perspective of the Runtime, the compiled Rust looks identical to unsafe C#. So, the Rust code can easily call .NET functions and create .NET objects. In theory, there is nothing you can do in C# that can't be done in Rust too.</p>

<p>I am also working on making calling Rust from C# easier. The project allows you to define .NET classes in pure Rust. In the future, the safety of your interop code will be fully checked by the Rust compiler.</p>

<pre><code>// Early WIP syntax, subject to change.
dotnet_typedef! {
  class MyClass inherits [Some::External::Assebmly]SomeNamespace::SomeClass{
    virtual fn ToString(_this:MyClass)-&gt;MString{
      "I am a class defined in Rust!".into_managed()
    },
  }
}</code></pre>

<p>The end goal is to allow near-seamless interop between Rust and C# / F#. Ideally, the users of your Rust .NET library may not even realize that it is written in Rust.</p>

<h2 id="panicking_vs_unwinding">Panicking vs unwinding</h2>

<p>Now that I laid down some basics about how <code>rustc_codegen_clr</code> works, I will probably need to quickly explain what unwinding and panicking are.</p>

<p>While the terms panicking and unwinding are related, and sometimes used interchangeably, they are nonetheless 2 different things.</p>

<p>Panicking is the name for the feature of the Rust language. When you use the <code>panic!</code> macro, this is the feature you are using. Panicking is very similar to exceptions, and is used in Rust to signal an error in the program logic.</p>

<p>So, when you expect an operation could fail, you use the <code>Result</code> type. When an operation should not fail(a failure indicates a bug), you should use <code>panic!</code>s.</p>

<pre><code>// Reading and parsing a file can fail, so we return a `Result` to tell the consumers of our API that they should handle it. 
fn decode_file(path:&amp;Path)-&gt;Result&lt;DecodedFile, DecodeError&gt;{
  // ...
}
// A person's birth date can't be earlier than the current date. 
// If it is, then either that person is a time traveler, or we have a bug.
fn calcualte_age(date_of_birth:Date)-&gt;Duration{
  if Date::now() &lt; date_of_birth{
    panic!("Found a time traveler!");
  }
  // ...
}</code></pre>

<p>In general, <code>Result</code>s are used where an error is expected, and should be handled by the user of the API, while panics tend to be used when something unexpected happens(eg. an assertion fails, an array is indexed out of bounds).</p>

<p>While panicking is not used as commonly as <code>Result</code>s, it is still used in quite a few places(eg. in unit tests). So, this feature must work well.</p>

<p>Panicking is currently <em>implemented</em> using unwinding, but that does not have to be the case in the future - you can implement panicking in other ways(eg. a panic can simply terminate the program).</p>

<p>Those other implementations have their drawbacks, but there are (rare) situations in which using something other than unwinding makes sense.</p>

<p>Unwinding refers to a specific implementation of panicking, where the stack is <em>unwound</em> - traversed upwards, function by function, while the data on the stack is dropped.</p>

<p>When I refer to unwinding, I will talk about the specific implementation on the compiler level. Here, things like cleanup blocks or the exact implementation of certain intrinsic matter.</p>

<p>When I talk about panicking, I will refer to the implementation present inside the standard library. From the perspective of std, it just calls a few intrinsics and functions, and it does not care how things are implemented under the hood.</p>

<h2 id="unwinds_on_the_compiler_level.">Unwinds on the compiler level.</h2>

<p>At the conceptual level, an unwind is relatively easy to understand.</p>

<p>An unwind travels up the call stack, popping stack frames of each function along the way, and dropping (disposing of) the stack-allocated objects held by that function.</p>

<p>So, if we had some functions like this:</p>

<pre><code>fn a(){
  let numbers = vec![0;100];
  b();
}
fn b(){
  let hello_string = "Hello World".to_string();
  c();
}
fn c(){
  let some_value = Box::new(64);
  panic!();
}</code></pre>

<p>During an unwind(caused by the panic in <code>c</code>), first the <code>some_value</code> would be dropped, then the unwind would go up the call stack, into <code>b</code>. The <code>hello_string</code> would then be dropped, unwind would continue up to <code>a</code>, and drop the vector <code>numbers</code> it allocated.</p>

<p>This process would continue until the unwind encounters a special intrinsic named <code>catch_unwind</code>. The exact signature and behavior of <code>catch_unwind</code> is not relevant for now, so I will discuss it in the next article.</p>

<p>Looking at this process, you might ask yourself a question:</p>

<p>How does an unwind know what and how to drop? I mean, dropping a <code>Vec&lt;i32&gt;</code> is very different from dropping a <code>Box&lt;i32&gt;</code>, so how do we know how all the objects in that stack frame need to be dropped? How can we tell where a pointer to the string <code>hello_string</code> is on the stack, and how can we know what to do with it?</p>

<p>This process of dropping (disposing of) all the data in a stack frame is the responsibility of special pieces of code called "cleanup blocks"</p>

<h2 id="blocks_in_general">Blocks in general</h2>

<p>Before I explain what a cleanup block is, I should probably explain MIR blocks in general.</p>

<p>Each function in the Rust Mid-level Intermediate Representation (MIR) is made up of a series of basic blocks.</p>

<p>Those blocks represent the control flow of a program.</p>

<p>A block is made up of a bunch of statements, and a terminator.</p>

<p>The statements in a block are executed in sequence, and can't diverge or branch in any way. No matter what happens, they will get executed, one by one.</p>

<p>The terminator, on the other hand, can change the control flow of a function.</p>

<p>It can call other pieces of code, jump to some other block, resume an unwind, or abort the execution of a program.</p>

<p>While this may seem a bit odd at first, it is a very convenient representation. It makes analyzing control flow almost trivial - since we know that only terminators can change how the code is executed, we don't have to check each statement to figure out the relationships between blocks.</p>

<p>Another nice side-effect of this distinction is that it simplifies unwinding and cleaning up stack frames.</p>

<p>Since only a terminator can call other functions,  only terminators can panic. Executing a statement will never panic, since statements can't change the control flow of a program.</p>

<p>So, when we want to specify how to deal with a stack frame during an unwind, we only need to do so for each terminator.</p>

<p>Now that I explained what a basic block is in the context of MIR, I can show exactly what a cleanup block is.</p>

<h2 id="cleanup_blocks">Cleanup blocks</h2>

<p>As I mentioned before, a cleanup block is not called during “normal” execution. The sole purpose of a cleanup block is dropping (disposing of) all the things in a given stack frame. So, during an unwind, when we want to figure out how to drop a particular frame, we simply call the specified cleanup block.</p>

<p>The Rust compiler generates such a cleanup block every time it needs something to get dropped during an unwind.</p>

<p>This concept can be a bit hard to grasp, but a small example should make it easier to follow. I will demonstrate how a cleanup block works, by using some Rust-inspired pseudocode.</p>

<p>Let's say we have a program like this:</p>

<pre><code>fn test(x:u32){
bb0:{
 let x = 7;
 // If an unwind happens during this function call, `numbers` will not be yet owned by us.
 // Since we only have ownership of `numbers` once the we allocate the vector(using this function), 
 // dropping it during an unwind is the responsibility of the callee.
 // So, we don't need a cleanup block.
 let numbers = vec![x] -&gt; [return bn1, unwind continue];
}
bb1:{
 // Up till this point, there was nothing to drop. Now, after the variable `numbers` was allocated, there is something to drop,
 // so we specify that the cleanup blocks bb4 need to be called if an unwind happens.
 x = 8;
 do_something(&amp;numbers) -&gt;[return bn2; unwind bn4];
}
bb2:{
 x = 9;
 // Since calling pass_ownership requires passing the ownership of `numbers`, dropping it is the responsibility of the callee.
 // So, we don't specify any cleanup blocks.
 pass_ownership(numbers) -&gt; [return bn3, unwind continue];
}
b3:{
 return;
}
// The cleanup block generated by the compiler
bb4 (cleanup):{
 // If this block is called, then we need to dispose of `numbers`. So, we drop it.
 drop(numbers);
 unwind resume; // Continues the unwind
 }
}</code></pre>

<p>The real MIR looks a bit different(no variable names, explicit types of locals, calls that return nothing assign a <code>()</code> value), but this should give you a rough idea about how everything works.</p>

<p>As you can see here, cleanup blocks are not really all that scary. Despite the fancy name, they are eerily similar to <code>finally</code> or <code>using</code> in C#.</p>

<pre><code>// If an exception occurs, numbers.Dispose() will be called.
using(Vec&lt;int&gt;  numbers = new Vec{x}){
  do_something(ref numbers);
}</code></pre>

<p>The main difference between <code>using</code>/<code>finaly</code> and a cleanup block is that it is only called when an unwind happens, while <code>using</code> disposes of the resource when the control flow leaves it. So, it will get called when an exception occurs, but also just during normal execution.</p>

<p>Still, despite those differences, unwinds and exceptions map to each other nicely, and exception handlers can be used to implement cleanup blocks.</p>

<p>There are, of course, some differences between the two which make this not a 1 to 1 translation.</p>

<p>MIR cleanup blocks can jump to other cleanup blocks, and a .NET execution handler can’t jump into another exception handler.</p>

<p>Working around that required some tinkering, but it was not a big problem.</p>

<p>Now that I talked a little bit about cleanup blocks in general, I thought I might mention another oddity of unwinds in Rust.</p>

<p>Drop flags are variables, whose sole purpose is to tell a cleanup block if it should drop something or not.</p>

<p>Hang on a minute, did I not just tell you that we only need at most one cleanup block for each terminator, since only terminators can cause an unwind?</p>

<p>If we already have separate cleanup blocks for different terminators, why do we need additional flags to tell the cleanup block what to drop?</p>

<h3 id="to_drop_or_not_to_drop:_that_is_the_question!">To drop or not to drop: that is the question!</h3>

<p>Suppose we have some code like this:</p>

<pre><code>// Example taken from the Rustonomicon
// https://doc.rust-lang.org/nomicon/drop-flags.html
let x;
if condition {
    x = Box::new(0);        // x was uninit; just overwrite.
    println!("{}", x);
}
// x goes out of scope; x might be uninit;
// check the flag!</code></pre>

<p>As you can see, x may or may not be initialized, depending on the condition.</p>

<p>If x is not initialized, then dropping it is UB. If it is initialized, then not dropping it would be a mistake.</p>

<p>To solve this, the compiler introduces a second variable, which checks if x is initialized.</p>

<pre><code>let x;
// Hiden, compiler-generated drop flags
let _is_x_init = false;
if condition{
    x = Box::new(0);  
    _is_x_init = true;
    println!("{}", x);
}
if _is_x_init{
   drop(x);
}</code></pre>

<p>You may say: well, that example is very contrived, and no one writes code like this! You just have to move the definition of x within the body of the if statement, and there would be no problem!</p>

<pre><code>if condition{
  let x = Box::new(0);
  println!("{}", x);
  // x is always initialized here, so we can drop it.
} </code></pre>

<p>Yeah, I would be shocked if someone wrote code exactly like this anywhere. But, this is the simplest possible example of the need for drop flags.</p>

<p>More realistic examples are far more complex, and this is the easiest way to showcase why drop flags are needed.</p>

<h2 id="optimizing_cleanup_blocks_is_hard.">Optimizing cleanup blocks is hard.</h2>

<p>Now that I explained how rust cleanup block works, and how they get turned into exception handlers, I want to highlight a few problems  I encountered while optimizing them.</p>

<p>Currently, the Rust code compiled for .NET suffers from massive slowdowns in a few key areas.</p>

<p>While I don't want to discuss the exact numbers since I am not 100% confident in them, I can at least highlight some general trends.</p>

<p>Rust compiled for .NET is, as expected, always slower than native Rust. However, it is not <em>that</em> much slower. In quite a few benchmarks, it is within 1.5 - 2x of native code - which I feel like is a pretty acceptable result. In the majority of cases, it is no more than 5x slower than native code. This is not great, but it is also not a bad starting point, seeing as my optimizations are ridiculously simple, and not all that effective.</p>

<p>Being wrong fast is not impressive, so I am mostly focusing on compilation accuracy and passing tests right now.</p>

<p>However, a select few benchmarks jump out. Some of them are pretty much expected (eg. a benchmark showing the vectorization capabilities of LLVM), but other ones may seem a bit more surprising at first.</p>

<p>One particularly problematic area is complex iterators, some of which take 70x more time to execute in NET.</p>

<p>That is, of course, unacceptable. You may ask yourself: what causes this slowdown?</p>

<p>Even though those benchmarks never panic, the cost of the unwinding infrastructure is still there. Just disabling unwind support(which just removes all the exception handlers) speeds up this problematic benchmark by 2x.</p>

<p>Of course, being 35x slower than native is still nothing to brag about, but it at least guides us toward the underlying problems.</p>

<p>Let us look at one of the problematic functions, decompiled into C# for readability.</p>

<pre><code>// NOTE: for the sake of this example, the custom optimizations performed by `rustc_codegen_clr` were disabled. 
public unsafe static void _ZN4core4iter8adapters3map8map_fold28_$u7b$$u7b$closure$u7d$$u7d$17hce71e23625930189E(Closure2n22Closure1n11Closure1pi8v * P_0, RustVoid acc, long elt) {
  //Discarded unreachable code: IL_002b, IL_006f
  Closure1n11Closure1pi8 * f_;
  bool flag;
  long item;
  try {
    f_ = &amp; P_0 - &gt; f_0;
    flag = true;
    void * ptr = (void * ) 8 u;
    Tuple2i8 tuple2i;
    tuple2i.Item1 = elt;
    tuple2i = tuple2i;
    item = _ZN4core3ops8function5FnMut8call_mut17hd1566fb973e9735aE(ptr, tuple2i.Item1);
  } catch {
    if (flag) {}
    throw;
  }
  try {
    flag = false;
    Tuple3vi8 tuple3vi;
    tuple3vi.Item2 = item;
    tuple3vi = tuple3vi;
    RustVoid rustVoid;
    _ZN4iter13for_each_fold28_$u7b$$u7b$closure$u7d$$u7d$17hfc540be8426f74d2E(f_, rustVoid, tuple3vi.Item2);
  } catch {
    if (flag) {}
    throw;
  }
}</code></pre>

<p>You may immediately notice something very odd. All the exception handlers in this function are effectively nops!</p>

<p>In some other examples, those <code>catch</code> blocks do assign some values to local variables, but, as soon as the handler finishes execution, those locals will be discarded anyway - since the exception will be rethrown(an unwind will resume).</p>

<pre><code>catch {
  nint num6 = (nint) self.b.v;
  if (num6 != 1 || flag) {}
  throw;
}</code></pre>

<p>And what about those useless ifs? They are empty, so they can't do anything at all!</p>

<p>Those ifs, weird assignments, and empty handlers are ghosts of removed drops.<br></p>

<h2 id="in_search_for_the_empty_cleanup_blocks">In search for the empty cleanup blocks</h2>

<p>The example I showed you is nothing more than a faithful recreation of the original optimized MIR passed to me by the Rust compiler front end. All those useless blocks and instructions are there because the compiler explicitly asked me for them.</p>

<p>You may think: why would <code>rustc</code> explicitly request a useless block? Can’t it see that it does nothing?</p>

<p>I mean, the sole reason for MIRs existence is optimization. If this is its only job, surely it would be better at it?</p>

<p>Well, what if I told you that the purpose of MIR optimizations is not to make your code faster, but to make compilation faster?</p>

<p>How on earth does an extra step in compilation make it faster?</p>

<h3 id="doing_more_to_do_less.">Doing more to do less.</h3>

<p>Well, as you may know, LLVM is not exactly the fastest thing in the world. It is <em>very</em> good at producing fast code, but it takes its sweet time to do it.</p>

<p>Let us say we know that a certain kind of LLVM optimization is quite slow, but we found a faster way to achieve the same thing, by using the unique properties of Rust.</p>

<p>Well, if <code>rustc</code> did just that, then LLVM wouldn't need to perform its own costly optimization, and compilation time would improve.</p>

<p>This kind of scenario is not very common. We can, however, exploit a different property of Rust to make a lot of optimizations way faster.</p>

<p>The nice thing about generics is that they allow for a lot of code to be shared. What if, instead of optimizing the “final” monomorphized versions of a function(like what LLVM does), we could optimize the generic one?</p>

<p>Look at this function:</p>

<pre><code>fn do_sth&lt;T:Copy&gt;(val:&amp;T){
 let tmp = *val;
 do_sth_inner(&amp;tmp, 8);
}</code></pre>

<p>For each different type, <code>T</code> LLVM will receive a different version of this function from <code>rustc</code> Each of those variants needs to be optimized separately. Let us imagine we call this function with 1000 different Ts. This means LLVM will have to optimize 1000 different versions of this function. This will take time.</p>

<p>However, we could try optimizing the generic version of this function. We might not be able to perform all the optimizations, but we should be able to perform quite a few of them. In this example, we could avoid storing the value of <code>val</code> in <code>tmp</code>. Since we only use the address of <code>tmp</code> to pass it to another function, <code>val</code> is an immutable reference to <code>T</code>, and <code>tmp</code> is a bitwise copy of what <code>val</code> points to, this optimization is OK.</p>

<pre><code>fn do_sth&lt;T:Copy&gt;(val:&amp;T){
 do_sth_inner(val, 8);
}</code></pre>

<p>In one move, we optimized all the possible variants of <code>do_sth</code>. LLVM  would have to do the same thing each time <code>do_sth</code> is used. So, for any function that is used more than once, we should save some compilation time.</p>

<p>This is the main reason MIR exists. If we can optimize stuff before handing it to LLVM, we can save time. Disabling MIR optimizations would not slow the final native code all that much, but it would make LLVM have to do more work - which would increase compile times.</p>

<h3 id="limitations_of_mir">Limitations of MIR</h3>

<p>So, we now know that MIR optimization operates on generic functions and that they can leverage Rust-specific information(eg. borrows) to perform certain optimizations faster.</p>

<p>However, there are some problems with this approach.<br></p>

<p><code>rustc</code>  can't perform certain kinds of MIR optimizations, since they might not be valid for all possible <code>T</code>s. For example, if the type in our example was <code>Clone</code>, and not <code>Copy</code>, we would not be able to optimize it all that much.</p>

<pre><code>fn do_sth&lt;T:Clone&gt;(val:&amp;T){
 let tmp = val.clone();
 do_sth_inner(&amp;tmp, 8);
}</code></pre>

<p>The clone could have side effects(eg. incrementing an atomic reference counter), and dropping <code>tmp</code> could also do something(eg. decrementing an atomic reference counter).</p>

<p>This is not a problem in most cases - since LLVM operates on monomorphized functions(functions with <code>T</code> replaced by some type, like <code>i32</code>), it can still perform this optimization, where applicable.</p>

<p>You can now probably guess why the iterator code I showcased had empty exception handlers(and cleanup blocks) - those blocks are not always empty.</p>

<h2 id="ghost_drop">Ghost drop</h2>

<p>When you look at the original example, you might notice it operates on <code>long</code>s(aka <code>i64</code>s). Dropping an <code>i64</code> is a NOP.</p>

<p>During compilation, when the cleanup block in question is processed, my backend encounters a drop. When it encounters a drop, I use <code> Instance::resolve_drop_in_place</code> to get information about how to drop a variable.</p>

<pre><code>let drop_instance = Instance::resolve_drop_in_place(ctx.tcx(), ty).polymorphize(ctx.tcx());
  if let InstanceKind::DropGlue(_, None) = drop_instance.def {
    //Empty drop, nothing needs to happen.
    vec![CILRoot::GoTo { target: target.as_u32(), sub_target: 0}.into()]
  } else {
  // Handle the drop
}</code></pre>

<p>One of the possible ways to drop something is calling the "DropGlue". Drop glue is <em>basically</em> a function that calls the drop implementation. However, when something (like an <code>i64</code>) does not need dropping, the drop glue can be <code>None</code>. If it is <code>None</code>, then there is nothing to do during a drop. In such a case, I do nothing(besides jumping to the next block).</p>

<p>So, this "empty" drop compiles into nothing - that explains our empty exception handlers. In reality, those handlers look more like this:</p>

<pre><code>catch {
  nint num6 = (nint) self.b.v;
  if (num6 != 1 || flag) {
    // Ghost drop
    drop_i64(&amp;item); // Drops the i64 - does nothing.
  }
  throw;
}</code></pre>

<p>But the <code>drop_i64</code> is never generated, since it is not needed.</p>

<h2 id="optimizing_exception_handlers">Optimizing exception handlers</h2>

<p>Optimizing exception handlers is very important for Rust to run well inside the .NET runtime. The biggest problem with them is the amount of byte code those things create. Remember - each Rust block can have its own cleanup bloc, and jumping between exception handlers is not allowed in .NET. This means that I have to store multiple copies of certain blocks.</p>

<p>This huge amount of exception handlers is not liked by the .NET JIT. I will admit that I am not an expert when it comes to understanding how RyuJIT works - I only have a <strong>very</strong> rough idea about how all the pieces fit together. Still, I feel like I know enough to speculate about the cause of the slowdowns I observed.</p>

<p><code>rustc_codegen_clr</code> is not yet all that good at optimizing code, so it generates a lot of CIL. Each unneeded exception handler, unused variable - all that adds up.</p>

<p>While the .NET JIT is pretty good, and can optimize most of the inefficiencies away, the increased bytecode size still has an impact. Internally, most JIT's (including RyuJIT) use certain heuristics to estimate if certain optimizations are worth it. So, a JIT may use metrics like the number of exception handlers, locals, and the size of bytecode, to try to guess how large the final compiled function is.</p>

<p>Since I emit a lot of code (quite a bit of it useless), the JIT "thinks" my functions are bad optimization and inlining candidates.</p>

<p>The exact formula used to calculate the cost of operations like inlining is not all that relevant to this post (you can <a href="https://github.com/dotnet/runtime/blob/02e95ebff119189ac2d65e4a641980ccb3ea1091/src/coreclr/jit/inlinepolicy.cpp#L4">find it here</a>), but I still wanted to highlight some things that seem to explain what I observed.</p>

<p>Looking at the default inlining policy, it seems like RyuJIT will not inline a function, if it exceeds a certain limit of basic blocks.</p>

<pre><code>// Code snipet from: https://github.com/dotnet/runtime/blob/02e95ebff119189ac2d65e4a641980ccb3ea1091/src/coreclr/jit/inlinepolicy.cpp#L577

// CALLEE_IS_FORCE_INLINE overrides CALLEE_DOES_NOT_RETURN
if (!m_IsForceInline &amp;&amp; m_IsNoReturn &amp;&amp; (basicBlockCount == 1))
{
  SetNever(InlineObservation::CALLEE_DOES_NOT_RETURN);
}
else if (!m_IsForceInline &amp;&amp; (basicBlockCount &gt; MAX_BASIC_BLOCKS))
{
  SetNever(InlineObservation::CALLEE_TOO_MANY_BASIC_BLOCKS);
}</code></pre>

<p>This limit seems to currently <a href="https://github.com/dotnet/runtime/blob/02e95ebff119189ac2d65e4a641980ccb3ea1091/src/coreclr/jit/inlinepolicy.h#L154">be 5</a>.</p>

<p>Since I need to duplicate all used cleanup blocks for each handler (jumping between exception handlers is not allowed), most handlers contain multiple blocks.</p>

<p>Let us say we have 2 handlers, with 2 blocks each. That alone already adds up almost to the inline limit.</p>

<p>When I removed all the exception handlers from an assembly, I removed a lot of those blocks, allowing the JIT to inline more functions.</p>

<p>Overall, removing this dead code, and reducing complexity, encourages the JIT to perform more optimizations.</p>

<p>You may wonder: why do JIT's use heuristics like this, and why do they only perform optimizations in certain cases?</p>

<p>JIT's try to be fast at compiling code. You don't want to have to wait a couple of minutes for your .NET app to start. So, a JIT has a limited time budget. It has to weigh the benefit of any give optimization against the time it would take. You don't want the JIT to spend a lot of time optimizing a complex function, if it can spend the same time optimizing 100 simpler ones.</p>

<p>In general, JIT's focus on code that is used often, and does not take a lot of time to optimize. This way, they can give you some pretty decent performance, while also compiling CIL very quickly.</p>

<p>If the CIL I generate is simpler, then the JIT can "see" that optimizing it will not take too long. By better preparing a .NET assembly for JIT compilation, I can reduce the amount of needless work a JIT needs to do, allowing it to perform other, highly beneficial optimizations.</p>

<p>Of course, you should take this paragraph with a pinch of salt. While I am pretty confident in what I wrote, I am still an amateur when it comes to JIT's. So, I might have misunderstood something or missed some finer detail.</p>

<h2 id="removing_empty_handlers">Removing empty handlers</h2>

<p>Now that I expalined why those optimzations are needed, I will show how I implemented them.</p>

<p>To remove a useless cleanup block(or exception handlers) I first need a good way of detecting them. Originally, I went with a more complex solution: First, I would simplify each block separately, removing all the side-effect-free statements before a <code>rethrow</code>.</p>

<pre><code>// Since assigning a constant to a local has no other side effects, and this bit of CIL is followed by a rethrow instruction, we are free to remove it.
ldc.i4.0
stloc.0
rethrow
// Simpler, equivalent version
rethrow</code></pre>

<p>Next, I would replace unconditional jumps to lone <code>rethrow</code> ops with <code>rethrow</code>s.</p>

<pre><code>br bb1
bb1:
rethrow
// Simpler, equivalent version
rethrow</code></pre>

<p>After a few more steps dealing with conditionals, most handlers would get simplified away into a single <code>rethrow</code> instruction.</p>

<pre><code>catch [System.Runtime]System.Object{
pop // Ignore the exception Object
rethrow
}</code></pre>

<p>As a last step, I would simply remove those trialy-NOP handlers.</p>

<p>This approach had a lot of advantages - in cases where it was not able to fully optimize something away, it would still simplify it considerably.</p>

<p>However, the added complexity made this optimization a bit error-prone. For the sake of simplicity, I have overlooked some of the non-obvious issues. Most of them were caused by some of the tech debt the project has. Fixing them requires some additional refactors, which are just not done yet.</p>

<p>Since the code in cleanup blocks only runs during an uwnind(so not during normal excution), debuging it is a bit of a pain.</p>

<p>Any issues in cleaup blocks will also be very hard to notice:removing a necessary cleanup block can just lead to a memory leak. So I need to get all the optimzations operating on them to be perfect.</p>

<p>In order to avoid those issues, I have decided to go with a much simpler, more conservative approach for now.</p>

<p>It is not as good at optimizing stuff away, but it can still improve things a fair bit.</p>

<p>I simply go through all the CIL in the handler, checking if it can cause observable side effects.</p>

<p>For example, assigning a const value to local has no side effects, while setting a value at some address has side effects.</p>

<p>If a handler only consists of assignments to locals, jumps, and a rethrow, then it can't have any side effects, so we can just remove it.</p>

<p>After this optimization(and other CIL optimizations implemented by <code>rustc_codegen_clr</code>), the iterator function I showed before looks like this:</p>

<pre><code>public unsafe static void _ZN4core4iter8adapters3map8map_fold28_$u7b$$u7b$closure$u7d$$u7d$17hce71e23625930189E(Closure2n22Closure1n11Closure1pi8v * P_0, RustVoid acc, long elt) {
  //Discarded unreachable code: IL_0025, IL_0047
  Closure1n11Closure1pi8 * f_ = &amp; P_0 - &gt; f_0;
  void* ptr = (void*) 8u;
  Tuple2i8 tuple2i;
  tuple2i.Item1 = elt;
  Tuple3vi8 tuple3vi;
  long num = (tuple3vi.Item2 = _ZN4core3ops8function5FnMut8call_mut17hd1566fb973e9735aE(ptr, tuple2i.Item1));
  RustVoid rustVoid;
  _ZN4iter13for_each_fold28_$u7b$$u7b$closure$u7d$$u7d$17hfc540be8426f74d2E(f_, rustVoid, tuple3vi.Item2);
}</code></pre>

<p>Don't get me wrong - there are still a lot of optimizations to be done(the whole function can be optimzed to one line, and easily inlined), but this is far better than what we had before.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you liked this deep dive into Rust unwinding, drop flags, and MIR optimizations. Originally, this was just supposed to be a "short introduction" to unwinding, after which I would talk about how panics work in <code>std</code>.</p>

<p>Well, it turns out unwinds are a bit complex. Since this article is already one of my longest, I will have to split it into 2-3 parts.</p>

<p>I also plan to explain the difficulties with Rust code catching arbitrary .NET exceptions and talk a little bit more about safe Rust / .NET interop.</p>

<p>So, look forward to that :).</p>

<h2 id="the_project_is_1_year_old,_gsoc,_and_special_thank_you_s.">The project is 1 year old, GSoC, and special <code>thank you</code>s.</h2>

<p>Oh, I almost forgot! <a href="https://github.com/FractalFir/rustc_codegen_clr">`rustc_codegen_clr`</a> turned 1 year old on August 28th! I would like to thank You for the amazing reception it received (over 1.4 K stars on Github, and a lot of very nice comments).</p>

<p>I(and my project) also participated in Rust GSoC 2024. I originally planned to write an article summarizing GSoC and celebrating the project's birthday, but I was unable to do so due to health reasons. I want to thank my GSoC mentor, Jack Huey, for mentoring me and helping me with some of the organizational stuff. Helping me to stay on track was really important for me since I work better when I have a sense of direction. This may seem small, but receiving even a tiny bit of feedback helps a lot.</p>

<p>I also wanted to thank Jakub Beránek(one of the Rust people behind Rust GSoC 2024) for his work organizing and managing Rust GSoC. Good management is almost invisible: everything just goes according to plan. Still, it is something to appreciate.</p>

<p>I am, in general, a bit of a messy and forgetful person, so I really appreciate that everything was going smoothly.</p>

<p>Since I am talking about the organizational stuff, it would be a crime not to thank the Google GSoC team for making GSoC in the first place. To be quite honest, I assumed that the team behind GSoC had to be pretty sizable since everything worked like a well-oiled machine. Learning how small it is(2.5 people) was a big shock to me, and made me appreciate their work even more.</p>

<p>I also want to express my gratitude towards the wider members of the Rust project, who helped me tremendously. It would be hard to list everyone who answered my question by name, but I would like to explicitly mention <code>Bjorn3</code>, who answered quite a lot of them.</p>

<p>One of the greatest things about GSoC was receiving feedback and help from a lot of different people.</p>

<p>Overall, GSoC has been a blast, and I met a lot of truly amazing people there. Each project felt like something impactful, and all my interactions with other Rust GSoC contributors were amazing.</p>

<p>Meeting all of those people passionate about Rust gave me a lot of confidence in the future of the language.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alan Turing's 1950 manual for the Mark I electronic computer [pdf] (144 pts)]]></title>
            <link>https://archive.computerhistory.org/resources/text/Knuth_Don_X4100/PDF_index/k-4-pdf/k-4-u2780-Manchester-Mark-I-manual.pdf</link>
            <guid>41622419</guid>
            <pubDate>Mon, 23 Sep 2024 04:36:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archive.computerhistory.org/resources/text/Knuth_Don_X4100/PDF_index/k-4-pdf/k-4-u2780-Manchester-Mark-I-manual.pdf">https://archive.computerhistory.org/resources/text/Knuth_Don_X4100/PDF_index/k-4-pdf/k-4-u2780-Manchester-Mark-I-manual.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41622419">Hacker News</a></p>
Couldn't get https://archive.computerhistory.org/resources/text/Knuth_Don_X4100/PDF_index/k-4-pdf/k-4-u2780-Manchester-Mark-I-manual.pdf: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla Transport Protocol over Ethernet (TTPoE) (155 pts)]]></title>
            <link>https://github.com/teslamotors/ttpoe</link>
            <guid>41621680</guid>
            <pubDate>Mon, 23 Sep 2024 01:47:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/teslamotors/ttpoe">https://github.com/teslamotors/ttpoe</a>, See on <a href="https://news.ycombinator.com/item?id=41621680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<div data-snippet-clipboard-copy-content=" /$$$$$$$$                  /$$                                                       
|__  $$__/                 | $$                                                       
   | $$  /$$$$$$   /$$$$$$$| $$  /$$$$$$                                              
   | $$ /$$__  $$ /$$_____/| $$ |____  $$                                             
   | $$| $$$$$$$$|  $$$$$$ | $$  /$$$$$$$                                             
   | $$| $$_____/ \____  $$| $$ /$$__  $$                                             
   | $$|  $$$$$$$ /$$$$$$$/| $$|  $$$$$$$                                             
   |__/ \_______/|_______/ |__/ \_______/                                             
                                                                                      
                                                                                    
 /$$$$$$$$                                                                     /$$    
|__  $$__/                                                                    | $$    
   | $$  /$$$$$$  /$$$$$$  /$$$$$$$   /$$$$$$$  /$$$$$$   /$$$$$$   /$$$$$$  /$$$$$$  
   | $$ /$$__  $$|____  $$| $$__  $$ /$$_____/ /$$__  $$ /$$__  $$ /$$__  $$|_  $$_/  
   | $$| $$  \__/ /$$$$$$$| $$  \ $$|  $$$$$$ | $$  \ $$| $$  \ $$| $$  \__/  | $$    
   | $$| $$      /$$__  $$| $$  | $$ \____  $$| $$  | $$| $$  | $$| $$        | $$ /$$
   | $$| $$     |  $$$$$$$| $$  | $$ /$$$$$$$/| $$$$$$$/|  $$$$$$/| $$        |  $$$$/
   |__/|__/      \_______/|__/  |__/|_______/ | $$____/  \______/ |__/         \___/  
                                              | $$                                    
                                              | $$                                    
                                              |__/                                    
 /$$$$$$$                       /$$                                   /$$             
| $$__  $$                     | $$                                  | $$             
| $$  \ $$ /$$$$$$   /$$$$$$  /$$$$$$    /$$$$$$   /$$$$$$$  /$$$$$$ | $$             
| $$$$$$$//$$__  $$ /$$__  $$|_  $$_/   /$$__  $$ /$$_____/ /$$__  $$| $$             
| $$____/| $$  \__/| $$  \ $$  | $$    | $$  \ $$| $$      | $$  \ $$| $$             
| $$     | $$      | $$  | $$  | $$ /$$| $$  | $$| $$      | $$  | $$| $$             
| $$     | $$      |  $$$$$$/  |  $$$$/|  $$$$$$/|  $$$$$$$|  $$$$$$/| $$             
|__/     |__/       \______/    \___/   \______/  \_______/ \______/ |__/             
                                                                                      
                                                                                "><pre lang="{verbatim}"><code> /$$$$$$$$                  /$$                                                       
|__  $$__/                 | $$                                                       
   | $$  /$$$$$$   /$$$$$$$| $$  /$$$$$$                                              
   | $$ /$$__  $$ /$$_____/| $$ |____  $$                                             
   | $$| $$$$$$$$|  $$$$$$ | $$  /$$$$$$$                                             
   | $$| $$_____/ \____  $$| $$ /$$__  $$                                             
   | $$|  $$$$$$$ /$$$$$$$/| $$|  $$$$$$$                                             
   |__/ \_______/|_______/ |__/ \_______/                                             
                                                                                      
                                                                                    
 /$$$$$$$$                                                                     /$$    
|__  $$__/                                                                    | $$    
   | $$  /$$$$$$  /$$$$$$  /$$$$$$$   /$$$$$$$  /$$$$$$   /$$$$$$   /$$$$$$  /$$$$$$  
   | $$ /$$__  $$|____  $$| $$__  $$ /$$_____/ /$$__  $$ /$$__  $$ /$$__  $$|_  $$_/  
   | $$| $$  \__/ /$$$$$$$| $$  \ $$|  $$$$$$ | $$  \ $$| $$  \ $$| $$  \__/  | $$    
   | $$| $$      /$$__  $$| $$  | $$ \____  $$| $$  | $$| $$  | $$| $$        | $$ /$$
   | $$| $$     |  $$$$$$$| $$  | $$ /$$$$$$$/| $$$$$$$/|  $$$$$$/| $$        |  $$$$/
   |__/|__/      \_______/|__/  |__/|_______/ | $$____/  \______/ |__/         \___/  
                                              | $$                                    
                                              | $$                                    
                                              |__/                                    
 /$$$$$$$                       /$$                                   /$$             
| $$__  $$                     | $$                                  | $$             
| $$  \ $$ /$$$$$$   /$$$$$$  /$$$$$$    /$$$$$$   /$$$$$$$  /$$$$$$ | $$             
| $$$$$$$//$$__  $$ /$$__  $$|_  $$_/   /$$__  $$ /$$_____/ /$$__  $$| $$             
| $$____/| $$  \__/| $$  \ $$  | $$    | $$  \ $$| $$      | $$  \ $$| $$             
| $$     | $$      | $$  | $$  | $$ /$$| $$  | $$| $$      | $$  | $$| $$             
| $$     | $$      |  $$$$$$/  |  $$$$/|  $$$$$$/|  $$$$$$$|  $$$$$$/| $$             
|__/     |__/       \______/    \___/   \______/  \_______/ \______/ |__/             
                                                                                      
                                                                                
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">At HotChips 2024, Tesla announced the open-sourcing of the Tesla Transport Protocol over Ethernet (TTPoE), represented on this GitHub repo.</p>
<p dir="auto">Tesla also announced joining the Ultra Ethernet Consortium (UEC) to share this protocol and work to standardize a new high-speed/low-latency fabric (be that TTPoE or otherwise) for AI/ML/Datacenters -- desiring a non-proprietary, low cost, distributed congestion control, standard EthernetII frame, and non-centralized interconnect protocol to commoditize and accelerate technical progress.</p>
<p dir="auto">In TTPoE, just like TCP, dropped packets and replays are the acceptable default behavior, yet full transmission is guaranteed.</p>
<p dir="auto">TTPoE's initial deployment was for the Tesla Dojo v1 project, where the protocol executed entirely in hardware and deployed to a very large multi-ExaFlops (fp16) supercomputer with over 10s of thousands of concurrent endpoints. This protocol does not need a CPU or OS to be involved in any way to link and execute.</p>
<p dir="auto">If you came here to be impressed by something complex and clever, you won't be. The protocol is designed on basic fundamentals -- simple transport and to the point. Ethernet transport in essence is only intended to move data from point A to B and should be limited by physics -- not software execution time. Centralized congestion management of extremely large scale machines (just like the internet) is a fool's errand -- each endpoint should be resiliant and self-managing.</p>
<p dir="auto">Eric Quinnell -- Sept 13, 2024</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">TTPoE Transport Header</h2><a id="user-content-ttpoe-transport-header" aria-label="Permalink: TTPoE Transport Header" href="#ttpoe-transport-header"></a></p>
<div data-snippet-clipboard-copy-content="/* Transport Header (TTP) that follows TSH
*
*  15  14  13  12  11  10   9   8   7   6   5   4   3   2   1   0
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |         opcode [7:0]          |             vc [7:0]          |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |             tx [7:0]          |             rx [7:0]          |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |                          epoch [15:0]                         |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |         congestion [7:0]      |      reserved-byte [7:0]      |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |      reserved-byte [7:0]      |          extension [7:0]      |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |                       tx-sequence [31:0]                      |
* |                                                               |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |                       rx-sequence [31:0]                      |
* |                                                               |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
*/"><pre lang="{verbatim}"><code>/* Transport Header (TTP) that follows TSH
*
*  15  14  13  12  11  10   9   8   7   6   5   4   3   2   1   0
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |         opcode [7:0]          |             vc [7:0]          |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |             tx [7:0]          |             rx [7:0]          |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |                          epoch [15:0]                         |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |         congestion [7:0]      |      reserved-byte [7:0]      |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |      reserved-byte [7:0]      |          extension [7:0]      |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |                       tx-sequence [31:0]                      |
* |                                                               |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
* |                       rx-sequence [31:0]                      |
* |                                                               |
* +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
*/
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">TTPoE Specification</h2><a id="user-content-ttpoe-specification" aria-label="Permalink: TTPoE Specification" href="#ttpoe-specification"></a></p>
<div data-snippet-clipboard-copy-content="You will find the spec
In the repo &quot;doc&quot; folder
TTPoE"><pre lang="{verbatim}"><code>You will find the spec
In the repo "doc" folder
TTPoE
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">ttpoe_sw</h2><a id="user-content-ttpoe_sw" aria-label="Permalink: ttpoe_sw" href="#ttpoe_sw"></a></p>
<p dir="auto">The following sections have details regarding making and executing the reference linux kernel sw model. It is matched to v1.5 of the TTP specification. Some variables may have changed slightly without documentation updates, but we're sure you can figure it out.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">modttpoe.ko:</h2><a id="user-content-modttpoeko" aria-label="Permalink: modttpoe.ko:" href="#modttpoeko"></a></p>
<p dir="auto">GIT repo info and unit tests</p>
<p dir="auto">The source code git repo is at <a href="https://github.com/teslamotors/ttpoe">https://github.com/teslamotors/ttpoe</a>. The code for modttpoe is under the 'modttpoe' subdir. The compilation is controlled via a top level Makefile in order to allow related modules to share symbols. Compilation is done as follows (gcc, linux-5.15-0-48-generic, ubuntu22):</p>
<div data-snippet-clipboard-copy-content="$ pwd
GIT_HEAD

$ make all
.... <compilation output> ....
$ ls -l ./modttpoe/modttpoe.ko
-rw-rw-r-- 1 user group 2676144 Jan  1 10:00 modttpoe/modttpoe.ko

$ modinfo ./modttpoe/modttpoe.ko
filename:       GIT_HEAD/./modttpoe/modttpoe.ko
license:        GPL
version:        eng0.2402.8
description:    TTP Over Ethernet
author:         dojo-user@tesla.com
srcversion:     862A3F5D98811A48B65F0CD
depends:
retpoline:      Y
name:           modttpoe
vermagic:       5.15.0-97-generic SMP mod_unload modversions
parm:           target:   ttp target (24b hex value: e.g. target=0x012345 => 98:ed:5c:01:23:45)
parm:           vci:      ttp conn-VCI (default=0, 1, 2)
parm:           stats:    ttp counters (read-only)
parm:           wkstep:   modttpoe fsm single-step state (default=0)
                          write '0' run freely; '[1-100]' set step-size; 's' step
parm:           dev:      ttp device name (required at module-load)
parm:           shutdown: modttpoe shutdown state (read-only)
parm:           verbose:  kernel log verbosity level (default=0, 1, 2)
parm:           tag_seq:  starting value of tag seq number (default=1)"><pre><code>$ pwd
GIT_HEAD

$ make all
.... &lt;compilation output&gt; ....
$ ls -l ./modttpoe/modttpoe.ko
-rw-rw-r-- 1 user group 2676144 Jan  1 10:00 modttpoe/modttpoe.ko

$ modinfo ./modttpoe/modttpoe.ko
filename:       GIT_HEAD/./modttpoe/modttpoe.ko
license:        GPL
version:        eng0.2402.8
description:    TTP Over Ethernet
author:         dojo-user@tesla.com
srcversion:     862A3F5D98811A48B65F0CD
depends:
retpoline:      Y
name:           modttpoe
vermagic:       5.15.0-97-generic SMP mod_unload modversions
parm:           target:   ttp target (24b hex value: e.g. target=0x012345 =&gt; 98:ed:5c:01:23:45)
parm:           vci:      ttp conn-VCI (default=0, 1, 2)
parm:           stats:    ttp counters (read-only)
parm:           wkstep:   modttpoe fsm single-step state (default=0)
                          write '0' run freely; '[1-100]' set step-size; 's' step
parm:           dev:      ttp device name (required at module-load)
parm:           shutdown: modttpoe shutdown state (read-only)
parm:           verbose:  kernel log verbosity level (default=0, 1, 2)
parm:           tag_seq:  starting value of tag seq number (default=1)
</code></pre></div>
<p dir="auto">The repo includes a script with unit tests under the 'tests' directory, using the python unit_test framework. These tests use the 'noc_debug' interface to configure and test a set of basic functionality to serve as a suite of regression tests to run before making any changes to the source code, and when adding enhancements. It is recommended to enhance the tests when new features are added to 'modttpoe'. In additional a packet generation utility called 'trafgen' (which is part of the <a href="http://netsniff-ng.org/" rel="nofollow">http://netsniff-ng.org/</a> tooklit) it used to some inject custom TTP packets to validate the behavior of the TTP state machine functionality.</p>
<p dir="auto">Here is an example TTP session between two hosts: node-01 and node-02:</p>
<p dir="auto">Node-01:</p>
<div data-snippet-clipboard-copy-content="$ sudo insmod modttpoe.ko dev=vl100 verbose=2

$ sudo dmesg
[529240.838851] ttpoe: ttp-source: 98:ed:5c:00:00:01  [0x0000000100000001]  device: vl100
[529240.838890] ttpoe: ~~~~~~~~~~~~~~~~~~~~~ Module modttpoe.ko loaded ~~~~~~~~~~~~~~~~~~~~~+

$ echo 2 | sudo tee /sys/module/modttpoe/parameters/target

$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  2  0  1  CC  0 0 0 0    0  00:00:02    --        0        1   0x0000000200000002"><pre><code>$ sudo insmod modttpoe.ko dev=vl100 verbose=2

$ sudo dmesg
[529240.838851] ttpoe: ttp-source: 98:ed:5c:00:00:01  [0x0000000100000001]  device: vl100
[529240.838890] ttpoe: ~~~~~~~~~~~~~~~~~~~~~ Module modttpoe.ko loaded ~~~~~~~~~~~~~~~~~~~~~+

$ echo 2 | sudo tee /sys/module/modttpoe/parameters/target

$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  2  0  1  CC  0 0 0 0    0  00:00:02    --        0        1   0x0000000200000002
</code></pre></div>
<p dir="auto">Node-02:</p>
<div data-snippet-clipboard-copy-content="$ sudo insmod modttpoe.ko dev=vl100 verbose=2

$ sudo dmesg
[529348.804309] ttpoe: ttp-source: 98:ed:5c:00:00:02  [0x0000000200000002]  device: vl100
[529348.804360] ttpoe: ~~~~~~~~~~~~~~~~~~~~~ Module modttpoe.ko loaded ~~~~~~~~~~~~~~~~~~~~~+

$ echo 1 | sudo tee /sys/module/modttpoe/parameters/target

$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  1  0  1  CC  0 0 0 0    0  00:00:01    --        0        1   0x0000000100000001

$ echo 'Hello Tesla' | sudo tee /sys/kernel/debug/modttpoe/noc_debug

$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  1  0  1  OO  0 0 0 0    0  00:00:01    --        1        3   0x0000000100000001"><pre><code>$ sudo insmod modttpoe.ko dev=vl100 verbose=2

$ sudo dmesg
[529348.804309] ttpoe: ttp-source: 98:ed:5c:00:00:02  [0x0000000200000002]  device: vl100
[529348.804360] ttpoe: ~~~~~~~~~~~~~~~~~~~~~ Module modttpoe.ko loaded ~~~~~~~~~~~~~~~~~~~~~+

$ echo 1 | sudo tee /sys/module/modttpoe/parameters/target

$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  1  0  1  CC  0 0 0 0    0  00:00:01    --        0        1   0x0000000100000001

$ echo 'Hello Tesla' | sudo tee /sys/kernel/debug/modttpoe/noc_debug

$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  1  0  1  OO  0 0 0 0    0  00:00:01    --        1        3   0x0000000100000001
</code></pre></div>
<p dir="auto">Node-01:</p>
<div data-snippet-clipboard-copy-content="$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  2  0  1  OO  0 0 0 0    0  00:00:02    --        2        2   0x0000000200000002

$ cat /proc/net/modttpoe/noc_debug
Hello Tesla

# modttpip.ko:

$ ls -l ./modttpip/modttpip.ko
-rw-rw-r-- 1 user group 652120 Jan  1 10:00 modttpoe/modttpip.ko

$ modinfo ./modttpip/modttpip.ko
filename:       GIT_HEAD/./modttpip/modttpip.ko
license:        GPL
version:        eng0.2402.8
description:    TTP IP Gateway
author:         dojo-user@tesla.com
srcversion:     0AD10BA371ADCCD35143E3A
depends:
retpoline:      Y
name:           modttpip
vermagic:       5.15.0-97-generic SMP mod_unload modversions
parm:           gwips:    set list of ttp gateway ip-addreses per zone (1,2,3,..):
                          `e.g. gwips=192.168.80.10,192.168.80.20,192.168.70.30
parm:           mactbl:   read gateway mac-address table; write triggers refresh
parm:           dev:      ttp device name (required at module-load)
parm:           shutdown: modttpoe shutdown state (read-only)
parm:           verbose:  kernel log verbosity level (default=0, 1, 2)"><pre><code>$ cat /proc/net/modttpoe/tags
tag table: bkt0(1) ++(1) (0)--   bkt1(0) ++(0) (0)--   colls(0)
tag  B  V  ST  Q X Y G   vc  mac addr   len   rx-seq   tx-seq   ------- kid --------  mark
  2  0  1  OO  0 0 0 0    0  00:00:02    --        2        2   0x0000000200000002

$ cat /proc/net/modttpoe/noc_debug
Hello Tesla

# modttpip.ko:

$ ls -l ./modttpip/modttpip.ko
-rw-rw-r-- 1 user group 652120 Jan  1 10:00 modttpoe/modttpip.ko

$ modinfo ./modttpip/modttpip.ko
filename:       GIT_HEAD/./modttpip/modttpip.ko
license:        GPL
version:        eng0.2402.8
description:    TTP IP Gateway
author:         dojo-user@tesla.com
srcversion:     0AD10BA371ADCCD35143E3A
depends:
retpoline:      Y
name:           modttpip
vermagic:       5.15.0-97-generic SMP mod_unload modversions
parm:           gwips:    set list of ttp gateway ip-addreses per zone (1,2,3,..):
                          `e.g. gwips=192.168.80.10,192.168.80.20,192.168.70.30
parm:           mactbl:   read gateway mac-address table; write triggers refresh
parm:           dev:      ttp device name (required at module-load)
parm:           shutdown: modttpoe shutdown state (read-only)
parm:           verbose:  kernel log verbosity level (default=0, 1, 2)
</code></pre></div>
<p dir="auto">Currently there are no unit-tests for the TTP gateway.</p>
<p dir="auto">The module 'modttpip' has configuration parameters, some of which must be specified on the command line during insmod:</p>
<div data-snippet-clipboard-copy-content="$ sudo insmod modttpip.ko dev=vl100 gwips=192.168.80.10,192.168.80.20,192.168.70.30 verbose=1

$ sudo lsmod | grep ttp
modttpip               24576  0

$ sudo dmesg -t
ttpip: ttp_param_gwips_set: zn: 1 ip: 192.168.80.10
ttpip: ttp_param_gwips_set: zn: 2 ip: 192.168.80.20
ttpip: ttp_param_gwips_set: zn: 3 ip: 192.168.70.30
ttpip: ttpip_init: dev:  ens20  ip: 192.168.80.10    mask: 255.255.255.0
ttpip: `-> found my-zone: 1
ttpip: ttpip_init: dev:  vl100  ip: none  (dev)
ttpip: zn: 1 gw: 192.168.80.10  (myself)
ttpip: zn: 2 gw: 192.168.80.20  via: device ' ens20' arp: bc:24:11:f8:e6:de
ttpip: zn: 3 gw: 192.168.70.30  via: 192.168.80.1  route: 3c:ec:ef:dc:e4:cc
ttpip: ttp_mac_table_populate: found 3 mac-addresses
ttpip: ttpip_init: 'ens20': bc:24:11:b8:94:64  'vl100': 98:ed:5c:01:00:00
ttpip: ---------------------- Module modttpip.ko loaded ----------------------+

$ sudo cd /sys/module/modttpip/parameters

$ sudo ls -l
-r--r--r-- 1 root root 4096 Jan 10 01:32 dev
-r--r--r-- 1 root root 4096 Jan 10 01:32 gwips
-rw-r--r-- 1 root root 4096 Jan 10 01:32 mactbl
-rw-r--r-- 1 root root 4096 Jan 10 01:32 shutdown
-rw-r--r-- 1 root root 4096 Jan 10 01:32 verbose"><pre><code>$ sudo insmod modttpip.ko dev=vl100 gwips=192.168.80.10,192.168.80.20,192.168.70.30 verbose=1

$ sudo lsmod | grep ttp
modttpip               24576  0

$ sudo dmesg -t
ttpip: ttp_param_gwips_set: zn: 1 ip: 192.168.80.10
ttpip: ttp_param_gwips_set: zn: 2 ip: 192.168.80.20
ttpip: ttp_param_gwips_set: zn: 3 ip: 192.168.70.30
ttpip: ttpip_init: dev:  ens20  ip: 192.168.80.10    mask: 255.255.255.0
ttpip: `-&gt; found my-zone: 1
ttpip: ttpip_init: dev:  vl100  ip: none  (dev)
ttpip: zn: 1 gw: 192.168.80.10  (myself)
ttpip: zn: 2 gw: 192.168.80.20  via: device ' ens20' arp: bc:24:11:f8:e6:de
ttpip: zn: 3 gw: 192.168.70.30  via: 192.168.80.1  route: 3c:ec:ef:dc:e4:cc
ttpip: ttp_mac_table_populate: found 3 mac-addresses
ttpip: ttpip_init: 'ens20': bc:24:11:b8:94:64  'vl100': 98:ed:5c:01:00:00
ttpip: ---------------------- Module modttpip.ko loaded ----------------------+

$ sudo cd /sys/module/modttpip/parameters

$ sudo ls -l
-r--r--r-- 1 root root 4096 Jan 10 01:32 dev
-r--r--r-- 1 root root 4096 Jan 10 01:32 gwips
-rw-r--r-- 1 root root 4096 Jan 10 01:32 mactbl
-rw-r--r-- 1 root root 4096 Jan 10 01:32 shutdown
-rw-r--r-- 1 root root 4096 Jan 10 01:32 verbose
</code></pre></div>
<p dir="auto">There are no runtime configurable parameters in modttpip. Unloading modttpip is done as follows:</p>
<div data-snippet-clipboard-copy-content="$ sudo rmmod modttpip

$ sudo dmesg -t
ttpip: ~~~~~~~~~~~~~~~~~~~~~ Module modttpip.ko unloaded ~~~~~~~~~~~~~~~~~~~~~+"><pre><code>$ sudo rmmod modttpip

$ sudo dmesg -t
ttpip: ~~~~~~~~~~~~~~~~~~~~~ Module modttpip.ko unloaded ~~~~~~~~~~~~~~~~~~~~~+
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teenager jailed for 18 months still in prison 18 years later (106 pts)]]></title>
            <link>https://www.independent.co.uk/news/uk/crime/ipp-sentence-luke-ings-mcdonalds-prison-b2601321.html</link>
            <guid>41621490</guid>
            <pubDate>Mon, 23 Sep 2024 01:09:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.co.uk/news/uk/crime/ipp-sentence-luke-ings-mcdonalds-prison-b2601321.html">https://www.independent.co.uk/news/uk/crime/ipp-sentence-luke-ings-mcdonalds-prison-b2601321.html</a>, See on <a href="https://news.ycombinator.com/item?id=41621490">Hacker News</a></p>
Couldn't get https://www.independent.co.uk/news/uk/crime/ipp-sentence-luke-ings-mcdonalds-prison-b2601321.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: If AI is helping people code better, why aren't products getting better? (112 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41621191</link>
            <guid>41621191</guid>
            <pubDate>Mon, 23 Sep 2024 00:11:20 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41621191">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=41621191: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[London saw a surprising benefit to ultra-low emissions zone: More active kids (315 pts)]]></title>
            <link>https://grist.org/cities/london-fining-polluting-cars-more-active-kids/</link>
            <guid>41621020</guid>
            <pubDate>Sun, 22 Sep 2024 23:36:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grist.org/cities/london-fining-polluting-cars-more-active-kids/">https://grist.org/cities/london-fining-polluting-cars-more-active-kids/</a>, See on <a href="https://news.ycombinator.com/item?id=41621020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
    
  
<p>Restricting the volume of high-emitting vehicles roaming city streets carries many benefits, from clearing the air to quieting the urban din and beyond. Recognition of this simple fact has led to the proliferation of clean air zones, designated regions within a city where vehicles must meet strict pollution standards or pay a fee to operate within it. At last count, over 300 such areas had been established across Europe. In London, which boasts the largest <a href="https://tfl.gov.uk/modes/driving/ultra-low-emission-zone">ultra-low emissions zone</a> in the world, <a href="https://ijbnpa.biomedcentral.com/articles/10.1186/s12966-024-01621-7">a study</a> has found a secondary benefit: Kids started walking and biking to school more.</p>



<p>In 2018 — the year before London’s rule took effect in the center of the city, and five years before the zone encompassed its entirety — researchers at the University of Cambridge and Queen Mary University saw in the impending policy an opportunity to conduct a natural experiment. They recruited children aged 6 to 9 and their families in central London and in Luton, a small city to the north, for a multi-year study to investigate how the program might affect a child’s health. Though research focused on understanding how lightening a city’s pollution load shaped the way young lungs develop, participants completed questionnaires alongside their annual health assessments. The responses allowed researchers to glean insights into their subjects’ activity levels, mental health, and other ancillary outcomes.</p>    




<p>In the first of many papers expected from the study, the researchers found that, a year after the ultra-low emissions zone took effect, <a href="https://ijbnpa.biomedcentral.com/articles/10.1186/s12966-024-01621-7">2 out of every 5 London students</a> in the study had switched from “passive” to “active” ways of getting to school. So instead of being chauffeured to school by their parents, the students started walking, biking, scootering, or taking public transit. On the other hand, in Luton, which acted as a control group, 1 in 5 made the same switch to modes that got them up and active, but an equal proportion switched to passive travel. But in London’s ultra-low emissions zone, shifting to driving was rare.</p>



<p>The implications of getting kids active, even if it’s just for their pre-class commute, are intuitive but important.</p>



<p>“Walking and biking and scootering to school is better for the child, better for the family, and better for the environment,” said Alison Macpherson, an epidemiologist at York University in Toronto who researches ways to protect and promote the health and safety of children. (She was not involved in the London study.)</p>



<p>“It’s a great way for children to start their day,” she said. “You can imagine just being thrown in a car and thrown out of a car is not the most calming way.” Walking or biking to school, on the other hand, can be calming and conducive to concentration, Macpherson said, potentially even <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4874515/">improving academic performance</a>. But perhaps most importantly, at a time when an epidemic of <a href="https://ballardbrief.byu.edu/issue-briefs/childhood-obesity-in-the-united-states">childhood obesity</a> is on the rise <a href="https://jamanetwork.com/journals/jamapediatrics/fullarticle/2819322#google_vignette">worldwide</a>, walking or wheeling to and from school can get kids <a href="https://ijbnpa.biomedcentral.com/articles/10.1186/1479-5868-9-134">more active</a>.</p>



<p>“Physical activity in general is vital for preventing obesity,” said Christina Xiao, an epidemiologist affiliated with Cambridge University and lead author of the paper. “There’s strong evidence that shows that it prevents weight gain, and also has benefits in terms of children’s physical development and mental health as well.”</p>



<p>What exact health outcomes manifest among the cubs involved in the study will be a subject of forthcoming studies. One will attempt to tease apart what prompted parents to stop driving their kids to school. Xiao’s results demonstrate that the change took place, exploring why was beyond the scope of her study. So, whether the parents stopped driving because the daily fee of $16.50 (12.50 British pounds) made it cost prohibitive or because, with fewer cars on the roadways, parents felt safer letting their kids make the stroll to campus (or some combination of the two) remains to be seen.</p>



<p>Despite the benefits that stem from <a href="https://www.ucsusa.org/sites/default/files/2021-07/low-and-zero-emissions-zones.pdf">emissions-control zones</a> like this, the <a href="https://scholarship.law.columbia.edu/sabin_climate_change/59/">legal environment in the United States</a> has erected immense obstacles to replicating something like London’s ultra-low emissions zone. The closest anyone’s come was a voluntary and short-lived <a href="https://www.santamonica.gov/zero-emission-delivery-zone">zero emissions delivery zone</a> pilot in Santa Monica, California. And then there was New York City’s ill-fated congestion pricing zone, which <a href="https://grist.org/transportation/kathy-hochul-congestion-pricing-new-york/">Governor Kathy Hochul axed</a> before it had a chance to <a href="https://grist.org/transportation/critics-of-congestion-pricing-often-end-up-supporting-it-heres-why/">woo the opposition</a>.</p>


<div>
  <article>
    <span>Read Next</span>
    <div>

      
      
                    
            <a href="https://grist.org/transportation/critics-of-congestion-pricing-often-end-up-supporting-it-heres-why/">
        <figure>
          <img src="https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?quality=75&amp;strip=all" alt="Heavy traffic and pedestrians are seen on Fifth Avenue in New York during a hazy day in July." srcset="https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?quality=75&amp;strip=all 1600w, https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?resize=1200%2C675&amp;quality=75&amp;strip=all 1200w, https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?resize=330%2C186&amp;quality=75&amp;strip=all 330w, https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?resize=768%2C432&amp;quality=75&amp;strip=all 768w, https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?resize=1536%2C864&amp;quality=75&amp;strip=all 1536w, https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?resize=160%2C90&amp;quality=75&amp;strip=all 160w, https://grist.org/wp-content/uploads/2024/07/new-york-congestion-pricing-build-support-patience-benefits.jpeg?resize=150%2C84&amp;quality=75&amp;strip=all 150w" sizes="(max-width: 1024px) 100vw, 1024px" height="900" width="1600" loading="lazy" decoding="async">
        </figure>
      </a>
            
    </div>
  </article>
</div>



<p>While the legislative gordian knot tied by federal laws that preempt cities from establishing low emissions zones waits to be unwound, cities across the country can improve the infrastructure that enables people to embrace walking, biking, or busing, said David Reichmuth, a senior engineer with the Union of Concerned Scientists’ clean transportation program.</p>



<p>“We are on the way in making this switch from gasoline and diesel to electric vehicles, which is great,” Reichmuth said. “But really to meet our climate goals, we also just need to reduce the amount of driving. And these things that encourage or enable the ability for people to use active transportation are super important.”</p>



<p>While developing pedestrian-friendly infrastructure and building out protected bike lanes can encourage a shift in how people travel, Xiao found as she assembled a review of research investigating how to promote <a href="https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(22)00220-0/fulltext">shifts to healthier transit</a>, people preferred the stick to the carrot. In other words, discouraging car travel was often more effective than just building infrastructure conducive to active travel.</p>



<p>But whether it takes carrots or sticks to drive the shift, Xiao’s work adds yet more evidence to the argument that what is best for the health of the children benefits the health of communities and that of the planet as well. And, in the minds of those doing similar work, it underscores the urgency of getting fewer cars and more feet on city streets.</p>



<p>“Active transportation is sustainable transportation,” Macpherson said, “and we have to not lose sight of all of the benefits that come with making the commute to school easier to do in an active and sustainable way.”</p>

  
  
  <hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Low Cost CO2 Sensors Comparison: Photo-Acoustic vs. NDIR (213 pts)]]></title>
            <link>https://www.airgradient.com/blog/co2-sensors-photo-acoustic-vs-ndir-updated/</link>
            <guid>41620955</guid>
            <pubDate>Sun, 22 Sep 2024 23:24:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.airgradient.com/blog/co2-sensors-photo-acoustic-vs-ndir-updated/">https://www.airgradient.com/blog/co2-sensors-photo-acoustic-vs-ndir-updated/</a>, See on <a href="https://news.ycombinator.com/item?id=41620955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>This article has been updated in September 2024 with new information about the Infineon photo-acoustic sensor as well as the performance of photo-acoustic sensors outdoors.</em></p>
<p>When it comes to low cost CO2 sensors, there are basically three different methods to measure CO2.</p>
<ol>
<li>Estimated CO2 (eCO2) through TVOC sensors</li>
<li>NDIR sensors</li>
<li>Photo-acoustic sensors</li>
</ol>
<h3 id="estimated-co2-eco2-through-tvoc-sensors---not-recommended--">Estimated CO2 (eCO2) through TVOC sensors <strong>- not recommended -</strong></h3>
<p>The first method via TVOC sensors is extremely unreliable. Some TVOC sensors like the Sensirion SGP30 estimate CO2 via organic components in the air. When you breathe out, you add organic components to the air which these sensors pick up and try to calculate a corresponding CO2 ppm value. The problem is that also other indoor sources like deodorizers add these chemical components to the air and thus the estimated CO2 rises -even though nobody might be in the room. We strongly advise against using TVOC sensors for CO2 estimation and thus will also not analyse it further in the rest of this article.</p>
<h3 id="co2-gas-absorption-principle">CO2 gas absorption principle</h3>
<p>Both NDIR as well as photo-acoustic sensors are much more accurate than eCO2 from TVOC sensors as these sensors measure the CO2 directly and both are based on the absorption principle of gases. Different gases absorb light at specific ranges of wavelengths. So if the light is tuned at a certain wavelength and a receiver measures the incoming light levels, the rate of absorption can be calculated and with this the concentration of the gas established.</p>
<p>Different gases have different absorption bands:</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/wavelength.jpg"></p><p>Absorption wavelengths of different gases.
</p>
</div>
<p>To measure CO2, the light is tuned to emit a light of close to 4.26 micron (μm) which corresponds to the absorption of CO2.</p>
<h3 id="ndir-co2-sensors">NDIR CO2 Sensors</h3>
<p>NDIR stands for “nondispersive infrared” and is a common technology to measure CO2. Thereby an infrared light emitter, typically an LED, sends light in a chamber filled with ambient air to a receiver.</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/ndir_principle.jpg"></p><p>NDIR working principle.
</p>
</div>
<p>Some NDIR sensors have dual channels, one for the measurement of the CO2 levels in the ambient air and one with a control gas as a reference. This allows to detect drifts in the measurements and increases accuracy.
One of the disadvantages of NDIR sensors is their size. There needs to be a certain minimum distance between the light emitter and receiver to achieve a certain level of accuracy and thus modern NDIR sensors like the SenseAir S8 that we use in our air quality kits are more than 3 cm long. This is not too big but would prevent certain applications, e.g. in a mobile phone.</p>
<h3 id="photo-acoustic-sensors">Photo-Acoustic Sensors</h3>
<p>Photo-acoustic sensors use the same working principle of the absorption wavelengths but unlike the NDIR sensors that measure the receiving light from an emitting LED, photo accoustic sensors measure the absorption with a microphone. When the CO2 molecules absorb the IR light, they start to “humm” and this sound can be picked up by a microphone.
The biggest advantage of this principle is that the detection does not rely on line-of-sight anymore and thus these sensors can be built much smaller. Some are smaller than 1 cm3.</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/pa_principle.jpg"></p><p>Photo-Acoustic working principle.
</p>
</div>
<h3 id="comparison-of-the-specifications-between-senseair-s8-optical-ndir-and-the-photo-acoustic-sensors-from-sensirion-and-infineon">Comparison of the Specifications between SenseAir S8 (Optical NDIR) and the Photo-Acoustic Sensors from Sensirion and Infineon</h3>
<p>Below is a comparison of typical NDIR and Photo-Acoustic sensor modules based on their official specifications.</p>
<table>
<thead>
<tr>
<th>Criteria</th>
<th>Sensirion SCD 41</th>
<th>SenseAir S8</th>
<th>Infineon XENSIV PAS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Working Principle</td>
<td>Photo-Acoustic</td>
<td>Optical NDIR</td>
<td>Photo-Acoustic</td>
</tr>
<tr>
<td>Accuracy</td>
<td>±(40 ppm + 5 %)</td>
<td>±(75 ppm +3%)</td>
<td>±50 ppm ±5%</td>
</tr>
<tr>
<td>Range</td>
<td>400 ppm – 5000 ppm</td>
<td>400 ppm – 5000 ppm</td>
<td>400 - 3000 ppm</td>
</tr>
<tr>
<td>Working Temperature</td>
<td>-10 - +60 °C</td>
<td>0 - +50 °C</td>
<td></td>
</tr>
<tr>
<td>Connectivity</td>
<td>I2C</td>
<td>UART</td>
<td>UART, I2C, PWM</td>
</tr>
<tr>
<td>Size</td>
<td>10.1 x 10.1 x 6.5 mm</td>
<td>33.5 x 20.0 x 8.5 mm</td>
<td>14 x 13.8 x 7.5 mm</td>
</tr>
<tr>
<td>Picture</td>
<td><img src="https://www.airgradient.com/images/blog/scd4x.jpg"></td>
<td><img src="https://www.airgradient.com/images/blog/s8.jpg"></td>
<td><img src="https://www.airgradient.com/images/blog/PAS.jpg"></td>
</tr>
</tbody>
</table>
<p>Except for the size and connectivity, the specs are quite similar. They do also cost around the same (USD 10 - 25).</p>
<h3 id="side-by-side-comparison-indoors">Side-By-Side Comparison Indoors</h3>
<p>We tested the SenseAir S8 and Sensirion SCD40 / SCD41 for a few weeks and saw them behaving very similarly. Below is a chart over 14 days in a typical indoor home environment (bedroom).</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/S8%20SCD4x.jpg"></p><p>Timeline comparison SenseAir S8 and Sensirion SCD40.
</p>
</div>
<p>Both sensors deliver very reliable results and the only difference that can be spotted is that the S8 seems to be a bit more sensitive and picks up higher values more. This can be seen on an X Y chart:</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/S8%20SCD%20XY.jpg"></p><p>X Y comparison SenseAir S8 and Sensirion SCD40.
</p>
</div>
<h3 id="outdoors">Photo-Acoustic Struggles Outdoors</h3>
<p>We do also measure CO2 levels outdoors with our outdoor monitor <a href="https://www.airgradient.com/outdoor/">Open Air</a>, and it helps to detect local emission sources. As part of that development we also tested photo-acoustic CO2 sensors outdoors in collaboration with researchers from the University of Cambridge.</p>
<p>Outdoor measurement of CO2 is more challenging due to mainly two reasons:</p>
<p>Firstly, there is a much larger range of temperature and humidity that the sensor is directly exposed to. For example indoor temperatures normally range between 15 and 25 degrees Celsius whereas outside we could have a range from -30 to +45 degrees Celsius of environmental conditions.</p>
<p>Secondly, the typical CO2 concentration levels outdoor are in the range of 400 to 550 ppm (higher in rural areas) whereas indoors you typically have a range of 400 to up to 3000ppm. In general, it is often easier for sensors to measure higher concentrations because there are more molecules or particles that can be detected.</p>
<p>Below is a comparison of two SenseAir S8 and two Sensirion SCD40 sensors compared to a CO2 reference instrument. All sensors have been offset to the same starting point.</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/outdoor-s8-scd.jpg"></p><p>Outdoor time-line comparison SenseAir S8 and Sensirion SCD40.
</p>
</div>
<p>We can observe a few interesting things:</p>
<ol>
<li>The two pairs have very distinctive differences</li>
<li>The two SenseAir S8 (optical) NDIR sensors aligns much better with the reference than the photo acoustic sensors from Sensirion</li>
<li>The two SenseAir S8 sensors correlate much better compared to each other than the two Sensirion SCD sensors. In fact there are cases where the SCD sensors go into completely opposite directions</li>
</ol>
<p>These observations can also be easily shown in the R2 comparisons. R2 is a mathematical number showing the degree of correlation between two number. A number of 1 indicates a perfect correlation, where as a number of 0 indicates no correlation at all. In terms of accuracy we want to get as close to one as possible.</p>
<p>First let’s compare the two sensor pairs:</p>
<table>
<thead>
<tr>
<th>R2 between S8</th>
<th>R2 between SCD 41</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.90</td>
<td>0.36</td>
</tr>
</tbody>
</table>
<p>These number clearly indicate that the S8 sensors have a much higher agreement with each other than the photo acoustic sensors.</p>
<p>Now lets look at the comparison with the reference instrument.</p>
<table>
<thead>
<tr>
<th>Sensor</th>
<th>R2</th>
</tr>
</thead>
<tbody>
<tr>
<td>S8 -1</td>
<td>0.69</td>
</tr>
<tr>
<td>S8 -2</td>
<td>0.64</td>
</tr>
<tr>
<td>SCD -1</td>
<td>0.16</td>
</tr>
<tr>
<td>SCD -2</td>
<td>0.24</td>
</tr>
</tbody>
</table>
<p>Also, here we see that the S8 has a much higher correlation with the reference instrument compared to the photo acoustic sensors. By the way in more comprehensive (and ongoing) tests, the S8 actually achieves correlations with reference instruments above 0.9 and thus even better than the above numbers indicate.</p>
<p>By the way all of the above observations can also be seen clearly in the X Y comparison between the point the sensor measures and the reference.</p>
<div>
<p><img src="https://www.airgradient.com/images/blog/outdoor-s8-scd-scatter.jpg"></p><p>Outdoor comparison SenseAir S8 and Sensirion SCD40 with X Y comparison.
</p>
</div>
<p>We can see that the S8 dots (red and blue) are much closer to the 1:1 line than the dots from the photo-acoustoc sensors.</p>
<h3 id="conclusion">Conclusion</h3>
<p>We have been using the SenseAir S8 in our air quality monitors for many years now and have made very good experience with. The Sensirion SCD4x seems to give a similar accuracy under normal indoor conditions but seems to be more impacted by environmental conditions and is not recommended for outdoor usage.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A tool to analyze Hacker News sentiment on any term in seconds (117 pts)]]></title>
            <link>https://classysoftware.io/chat-analysis/</link>
            <guid>41620530</guid>
            <pubDate>Sun, 22 Sep 2024 22:12:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://classysoftware.io/chat-analysis/">https://classysoftware.io/chat-analysis/</a>, See on <a href="https://news.ycombinator.com/item?id=41620530">Hacker News</a></p>
Couldn't get https://classysoftware.io/chat-analysis/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Uber charges more if you have credits in your account (409 pts)]]></title>
            <link>https://viewfromthewing.com/uber-caught-overcharging-how-having-credits-in-your-account-might-be-costing-you/</link>
            <guid>41620304</guid>
            <pubDate>Sun, 22 Sep 2024 21:38:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://viewfromthewing.com/uber-caught-overcharging-how-having-credits-in-your-account-might-be-costing-you/">https://viewfromthewing.com/uber-caught-overcharging-how-having-credits-in-your-account-might-be-costing-you/</a>, See on <a href="https://news.ycombinator.com/item?id=41620304">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-213171">

	
	<!-- .entry-header -->

	
	
	<div>
		<p>I noticed something strange earlier this month when I pulled up the Uber app and requested a ride.
</p><ul><li>I had my monthly $15 American Express Uber credit in my account<br>
</li><li>The price for the ride was displayed net of this credit (rather than full price, just showing the Uber credit as a payment method later)<br>
</li><li>And the fare seemed higher than usual.  It was also much higher than Lyft.</li></ul>
<p>My hypothesis was that Uber seemed to be picking a higher price <i>because I had credits in my account</i>.  I might be willing to spend more because my ‘real’ out of pocket cost was less, and those credits were trapped <i>anyway</i>.</p>
<p>I decided to use my Uber credits for Uber Eats instead.  That pricing seemed normal.  I need to keep my eye on this.</p>
<p>Reader <b>Charles</b> says he noticed something similar.</p>	<!-- /1019006/BoardingArea_DynamicContent -->
	
	
<ul><li>He regularly pre-books rides with Uber – between the same locations at the same time of day – and generally finds the price to be stable ~ $20 and a bit cheaper than Lyft.
</li><li>He bought Uber gift cards at Costco for a 20% discount to face value.  That’s when things got weird.</li></ul>
<blockquote><p>Loaded first $50 card in my uber account, everything behaved normal. I loaded another $200 before taking Uber to airport, then was surprised to find uber won’t allow payment with uber cash loaded in the account this way for rides scheduled ahead of time. </p>
<p>…then stranger things happened: for same ride I book regularly increased from about $20 to $30!  Just as a sanity check, Lyft is still ~$20 for same ride.</p></blockquote>
<p>He went a step farther and did something I didn’t: he checked Uber prices “with someone else’s phone” who did not have a balance in their Uber account – and Uber was pricing the route at the usual $20 for them.</p>
<p>I don’t know exactly what’s happening here, but something seems strange and – unsurprisingly – not in a customer-friendly way. At the same time, I’m also not the first person to experience (or think they experienced) this.  Have you seen anything like it?  I’d be curious your experiences, especially once you get Uber credits in your account.  My theory, and it is definitely just that, is this is something they’re testing on a subset of users to learn how customers respond.</p>
<p>Remember when Uber brought in Dara Khosrowshahi from Expedia to be their new CEO, to become kinder and gentler and friendler?  At the time I figured things would get worse because he was literally in charge <i>at Expedia</i>.  But drivers now seem to earn less, even though (because of) tipping.  It’s more expensive to customers, too.  And there’s no more “surge pricing” – they just charge you higher and higher amounts without <i>telling you</i> they’re doing it.</p>
	
	

	
	

			</div><!-- .entry-content -->

	
	
	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brainfuck Enterprise Solutions (493 pts)]]></title>
            <link>https://github.com/bf-enterprise-solutions</link>
            <guid>41620198</guid>
            <pubDate>Sun, 22 Sep 2024 21:24:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bf-enterprise-solutions">https://github.com/bf-enterprise-solutions</a>, See on <a href="https://news.ycombinator.com/item?id=41620198">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  <h2>
        Pinned

    <span data-view-component="true">
      <span>Loading</span>
</span>
    <span role="status" aria-live="polite" data-error-text="Something went wrong." data-success-text="Order updated."></span>
  </h2>

      <ol>
      <li>
  <div>
      


      <p>
        A next-generation high-performance operating system focused on enterprise-level resilience
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Brainfuck</span>
</span>

          <a href="https://github.com/bf-enterprise-solutions/os.bf/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            22
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        Infinitely configurable integrated IDE and text editor
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Brainfuck</span>
</span>

          <a href="https://github.com/bf-enterprise-solutions/ed.bf/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            99
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        Cutting-edge, blazing fast embeddable Brainfuck metainterpreter that is the beating heart of our resilient blade servers
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">M4</span>
</span>

          <a href="https://github.com/bf-enterprise-solutions/meta.bf/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            6
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        High efficiency string manipulation in Brainfuck, re-imagined. 
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Brainfuck</span>
</span>

          <a href="https://github.com/bf-enterprise-solutions/str.bf/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            3
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        Comprehensive documentation format for Brainfuck codebase, previously internal to BES.
      </p>

      <p>
          <a href="https://github.com/bf-enterprise-solutions/bf.doc/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            3
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        State-of-art style guide for medium-to-huge repositories and diverse teams of engineers.
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Brainfuck</span>
</span>

          <a href="https://github.com/bf-enterprise-solutions/bf.style/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            4
          </a>
      </p>
    </div>
</li>

</ol>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LinkedIn does not use European users' data for training its AI (108 pts)]]></title>
            <link>https://www.techradar.com/pro/security/the-linkedin-ai-saga-shows-us-the-need-for-eu-like-privacy-regulations</link>
            <guid>41620091</guid>
            <pubDate>Sun, 22 Sep 2024 21:08:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techradar.com/pro/security/the-linkedin-ai-saga-shows-us-the-need-for-eu-like-privacy-regulations">https://www.techradar.com/pro/security/the-linkedin-ai-saga-shows-us-the-need-for-eu-like-privacy-regulations</a>, See on <a href="https://news.ycombinator.com/item?id=41620091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-320-80.jpg" alt="In this photo illustration, the business and employment-oriented network and platform owned by Microsoft, LinkedIn, logo seen displayed on a smartphone with an Artificial intelligence (AI) chip and symbol in the background." srcset="https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/dCombh5pR4exm9uTkRFxwF.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Photo Illustration by Budrul Chukrut/SOPA Images/LightRocket via Getty Images)</span>
</figcaption>
</div>

<div id="article-body">
<p><em><strong>Update</strong></em><em>: On September 20, 2024, following publication, the UK Information Commissioner's Officer (ICO) </em><a data-analytics-id="inline-link" href="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/09/our-statement-on-changes-to-linkedin-ai-data-policy/" target="_blank" data-url="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/09/our-statement-on-changes-to-linkedin-ai-data-policy/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>confirmed</em></a><em> that LinkedIn halted AI training also for UK users.</em></p><p>If you are on LinkedIn, you might have come across users complaining about the platform using their data to train a generative AI tool without their consent.</p><p>People began noticing this change in the settings on Wednesday, September 18, when the Microsoft-owned social media platform started <a data-analytics-id="inline-link" href="https://www.techradar.com/pro/linkedin-is-already-training-its-ai-on-user-data-says-it-will-update-tos-soon" data-before-rewrite-localise="https://www.techradar.com/pro/linkedin-is-already-training-its-ai-on-user-data-says-it-will-update-tos-soon">training its AI on user data before</a> updating its terms and conditions.</p><p>LinkedIn certainly isn't the first social media platform to begin scraping user data to feed an AI tool without asking for consent beforehand. What's curious about the LinkedIn AI saga is the decision to exclude the EU, EEA (Iceland, Liechtenstein, and Norway), and Switzerland – the UK would be added on such list, too, later on Friday after the Information Commissioner's Officer (ICO) raised concerns. Is this a sign that only EU-like privacy laws can fully protect our privacy?</p><h2 id="the-eu-backlash-against-ai-training-3">The EU backlash against AI training</h2><p>Before LinkedIn, both Meta (the parent company behind Facebook, Instagram, and WhatsApp) and X (formerly known as Twitter) started to use their users' data to train their newly launched AI models. While these social media giants initially extended the plan also to European countries, they had to halt their AI training after encountering strong backlash from EU privacy institutions.&nbsp;</p><p>Let's go in order. The first to test out the waters were Facebook and Instagram back in June. According to their new <a data-analytics-id="inline-link" href="https://www.facebook.com/privacy/genai/" target="_blank" data-url="https://www.facebook.com/privacy/genai/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">privacy policy</a> – which came into force on June 26, 2024 – the company&nbsp;can now use years of personal posts, private images, or online tracking data to train its <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/artificial-intelligence/meta-ai-is-coming-to-your-social-media-apps-and-ive-already-forgotten-about-chatgpt" data-before-rewrite-localise="https://www.techradar.com/computing/artificial-intelligence/meta-ai-is-coming-to-your-social-media-apps-and-ive-already-forgotten-about-chatgpt">Meta AI</a>.</p><div><p>Did you know?</p><div><figure><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-pin-nopin="true"><img src="https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-320-80.jpg" alt="A phone on a table showing the Facebook and Instagram logos" srcset="https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/KfLMRH4VGU8XKoVHDFjj4d.jpg" data-pin-nopin="true"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Shutterstock / mundissima)</span></figcaption></figure><p>Last week, Meta <a data-analytics-id="inline-link" href="https://www.techradar.com/pro/meta-admits-it-has-scraped-all-facebook-posts-since-2007-to-train-ai" data-before-rewrite-localise="https://www.techradar.com/pro/meta-admits-it-has-scraped-all-facebook-posts-since-2007-to-train-ai">admitted</a> to having used people's public posts to train AI models as far back as 2007.</p></div></div><p>After Austria's digital rights advocacy group <a data-analytics-id="inline-link" href="https://noyb.eu/en/noyb-urges-11-dpas-immediately-stop-metas-abuse-personal-data-ai" target="_blank" data-url="https://noyb.eu/en/noyb-urges-11-dpas-immediately-stop-metas-abuse-personal-data-ai" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Noyb filed 11 privacy complaints</a> to various Data Protection Authorities (DPAs) in Europe, the&nbsp;Irish DPA requested that the company pause its plans to use EU/EEA users' data.</p><p><a data-analytics-id="inline-link" href="https://about.fb.com/news/2024/06/building-ai-technology-for-europeans-in-a-transparent-and-responsible-way/" target="_blank" data-url="https://about.fb.com/news/2024/06/building-ai-technology-for-europeans-in-a-transparent-and-responsible-way/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Meta was said</a>&nbsp;to be disappointed about the decision, dubbing it a "step backward for European innovation" in AI, and decided to cancel the launch of Meta AI in Europe, not wanting to offer "a second-rate experience."</p><p>Something similar occurred at the end of July when X automatically enabled the <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/artificial-intelligence/x-is-now-using-your-posts-and-more-to-train-its-grok-ai-but-theres-something-you-can-do-about-it" data-before-rewrite-localise="https://www.techradar.com/computing/artificial-intelligence/x-is-now-using-your-posts-and-more-to-train-its-grok-ai-but-theres-something-you-can-do-about-it">training of its Grok AI</a> on all its users' public information – European accounts included. &nbsp;&nbsp;</p><p>Just a few days after the launch, on August 5, consumer organizations <a data-analytics-id="inline-link" href="https://www.euractiv.com/section/data-privacy/news/x-slammed-with-data-privacy-complaint-over-ai-training/" target="_blank" data-url="https://www.euractiv.com/section/data-privacy/news/x-slammed-with-data-privacy-complaint-over-ai-training/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">filed a formal privacy complaint</a> with the Irish Data Protection Commission (DPC) lamenting how X's AI tool violated GDPR rules. The Irish Court has <a data-analytics-id="inline-link" href="https://www.euronews.com/next/2024/09/06/irish-court-drops-privacy-case-after-x-agrees-to-never-use-eu-users-tweets-to-train-grok-a" target="_blank" data-url="https://www.euronews.com/next/2024/09/06/irish-court-drops-privacy-case-after-x-agrees-to-never-use-eu-users-tweets-to-train-grok-a" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">now dropped</a> the privacy case against X as the platform agreed to permanently halt the collection of EU users' personal data to train its AI model.</p><p>While tech companies have often criticized the EU's strong regulatory approach toward AI – a group of organizations even recently signed an <a data-analytics-id="inline-link" href="https://euneedsai.com/" target="_blank" data-url="https://euneedsai.com/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">open letter</a> asking for better regulatory certainty on AI to foster innovation – privacy experts have welcomed the proactive approach.</p><p>The message is strong – Europe isn't willing to sacrifice its strong privacy framework.</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">So, LinkedIn joined other predatory platform intermediaries in grabbing everyone's user-generated content for generative AI training by default—except in GDPR land.Seems like the GDPR and European data protection regulators are really the only effective antidote here globally. pic.twitter.com/8shCd5AWRU<a href="https://twitter.com/WolfieChristl/status/1836515964013187147" data-url="https://twitter.com/WolfieChristl/status/1836515964013187147" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">September 18, 2024</a></p></blockquote></div><p>Despite LinkedIn having now <a data-analytics-id="inline-link" href="https://www.linkedin.com/blog/member/trust-and-safety/updates-to-our-terms-of-service-2024" target="_blank" data-url="https://www.linkedin.com/blog/member/trust-and-safety/updates-to-our-terms-of-service-2024" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">updated</a> its terms of service, the silent move attracted strong criticism around privacy and transparency outside Europe. It's <em>you</em>, in fact, who must actively opt-out if you don't want your information and posts to be used to train the new AI tool.</p><p>As mentioned earlier, both X and Meta used similar tactics when feeding their own AI models with users' personal information, photos, videos, and public posts.</p><p>Nonetheless, according to some experts, the fact that other companies in the industry act without transparency doesn't make it right to do so.&nbsp;</p><p>"We shouldn't have to take a bunch of steps to undo a choice that a company made for all of us," <a data-analytics-id="inline-link" href="https://x.com/RachelTobac/status/1836472398885028297" target="_blank" data-url="https://x.com/RachelTobac/status/1836472398885028297" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">tweeted Rachel Tobac</a>, ethical hacker and CEO of SocialProof Security.&nbsp;"Organizations think they can get away with auto opt-in because 'everyone does it'. If we come together and demand that organizations allow us to CHOOSE to opt-in, things will hopefully change one day."</p><h2 id="how-to-opt-out-from-linkedin-ai-training-3">How to opt-out from LinkedIn AI training</h2><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-320-80.jpg" alt="Screenshot of LinkedIn settings on AI training" srcset="https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/GeCexM8CRMGSVP4NTAxhSS.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Future)</span></figcaption></figure><p>As explained in the LinkedIn <a data-analytics-id="inline-link" href="https://www.linkedin.com/help/linkedin/answer/a5538339?hcppcid=search" target="_blank" data-url="https://www.linkedin.com/help/linkedin/answer/a5538339?hcppcid=search" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">FAQs</a> (which, at the time of writing, were updated one week ago): "Opting out means that LinkedIn and its affiliates won’t use your personal data or content on LinkedIn to train models going forward, but does not affect training that has already taken place."</p><p>In other words, the data already scraped cannot be recovered, but you can still prevent the social media giant from using more of your content in the future.</p><p>Doing so is simple. All you need to do is head to the <strong>Settings</strong> menu and select the <strong>Data Privacy</strong> tab. As the image below shows, once there you'll see that the <strong>Data for Generative AI improvement</strong> feature is On by default. At this point, you need to <strong>click on it and disable the toggle button</strong> on the right.&nbsp;</p>
</div>
<div id="slice-container-authorBio-DJbiSnBmpvp96Bq2H5Gduc"><p>Chiara is a multimedia journalist committed to covering stories to help&nbsp;promote&nbsp;the rights and denounce the abuses of the digital side of life—wherever cybersecurity, markets and politics tangle up.<strong>&nbsp;</strong>She mainly writes news, interviews and analysis on data privacy, online censorship, digital rights, cybercrime, and security software, with a special focus on VPNs, for TechRadar Pro, TechRadar and Tom’s Guide. Got a story, tip-off or something tech-interesting to say? Reach out to&nbsp;chiara.castro@futurenet.com</p></div>


</section>

<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coffee Stats – Maximize Caffeine Intake and Get to Bed at Night (160 pts)]]></title>
            <link>https://github.com/Eliya-G/coffee-o-clock</link>
            <guid>41620002</guid>
            <pubDate>Sun, 22 Sep 2024 20:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Eliya-G/coffee-o-clock">https://github.com/Eliya-G/coffee-o-clock</a>, See on <a href="https://news.ycombinator.com/item?id=41620002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Eliya-G/coffee-o-clock/blob/main/.github_images/Header%20Image.png"><img src="https://github.com/Eliya-G/coffee-o-clock/raw/main/.github_images/Header%20Image.png" alt="alt text"></a></p>
<p dir="auto">This project was built to answer a question many of us have. Should I have another cup of coffee?</p>
<p dir="auto">The project gives you statistics about your caffeine level specifically when you'd be going to bed.
You can also enter custom ingestion amounts and sleep times.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Download Link</h3><a id="user-content-download-link" aria-label="Permalink: Download Link" href="#download-link"></a></p>
<p dir="auto">Compiled Windows release <a href="https://github.com/Eliya-G/coffee-o-clock/releases/latest">link</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Assumptions</h2><a id="user-content-assumptions" aria-label="Permalink: Assumptions" href="#assumptions"></a></p>
<p dir="auto">The script works on some generalized assumptions that would be difficult to take into account.</p>
<ul dir="auto">
<li>You are a healthy person.</li>
<li>You have typical genetics (ex. not caffeine sensitive).</li>
<li>You will be consuming the caffeine immediately.</li>
<li>You're aware of your own caffeine tolerance.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Eliya-G/coffee-o-clock/blob/main/.github_images/regular_mode.png"><img src="https://github.com/Eliya-G/coffee-o-clock/raw/main/.github_images/regular_mode.png" alt="alt text"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/Eliya-G/coffee-o-clock/blob/main/.github_images/custom_mode.png"><img src="https://github.com/Eliya-G/coffee-o-clock/raw/main/.github_images/custom_mode.png" alt="alt text"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatibility</h2><a id="user-content-compatibility" aria-label="Permalink: Compatibility" href="#compatibility"></a></p>
<ul dir="auto">
<li>Built with Python3 version 3.12.5.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Coffee Half Life Function</h2><a id="user-content-coffee-half-life-function" aria-label="Permalink: Coffee Half Life Function" href="#coffee-half-life-function"></a></p>
<p dir="auto">The following image is the half life function I used.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Eliya-G/coffee-o-clock/blob/main/.github_images/coffee_function.png"><img src="https://github.com/Eliya-G/coffee-o-clock/raw/main/.github_images/coffee_function.png" alt="alt text"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Thanks to</h2><a id="user-content-thanks-to" aria-label="Permalink: Thanks to" href="#thanks-to"></a></p>
<ul dir="auto">
<li>Aman Kharwal for his programming templates.</li>
<li>Header image provided by <a href="https://www.freepik.com/" rel="nofollow">Freepik</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valve is testing ARM64 support for popular games (177 pts)]]></title>
            <link>https://www.notebookcheck.net/Valve-is-testing-ARM64-support-for-popular-games-sparking-speculations-about-new-future-hardware.891851.0.html</link>
            <guid>41619808</guid>
            <pubDate>Sun, 22 Sep 2024 20:30:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notebookcheck.net/Valve-is-testing-ARM64-support-for-popular-games-sparking-speculations-about-new-future-hardware.891851.0.html">https://www.notebookcheck.net/Valve-is-testing-ARM64-support-for-popular-games-sparking-speculations-about-new-future-hardware.891851.0.html</a>, See on <a href="https://news.ycombinator.com/item?id=41619808">Hacker News</a></p>
Couldn't get https://www.notebookcheck.net/Valve-is-testing-ARM64-support-for-popular-games-sparking-speculations-about-new-future-hardware.891851.0.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>