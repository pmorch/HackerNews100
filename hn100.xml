<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 21 Jan 2025 02:30:22 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Reverse engineering Call of Duty anti-cheat (127 pts)]]></title>
            <link>https://ssno.cc/posts/reversing-tac-1-4-2025/</link>
            <guid>42774221</guid>
            <pubDate>Mon, 20 Jan 2025 23:07:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssno.cc/posts/reversing-tac-1-4-2025/">https://ssno.cc/posts/reversing-tac-1-4-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=42774221">Hacker News</a></p>
Couldn't get https://ssno.cc/posts/reversing-tac-1-4-2025/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Elon Musk appears to make back-to-back fascist salutes at inauguration rally (157 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute</link>
            <guid>42773778</guid>
            <pubDate>Mon, 20 Jan 2025 22:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute">https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute</a>, See on <a href="https://news.ycombinator.com/item?id=42773778">Hacker News</a></p>
Couldn't get https://www.theguardian.com/technology/2025/jan/20/trump-elon-musk-salute: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Matt Mullenweg, Automattic's CEO, Seems Bound and Determined to Wreck WordPress (103 pts)]]></title>
            <link>https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/</link>
            <guid>42773311</guid>
            <pubDate>Mon, 20 Jan 2025 21:32:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/">https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/</a>, See on <a href="https://news.ycombinator.com/item?id=42773311">Hacker News</a></p>
Couldn't get https://digitalcxo.com/article/matt-mullenweg-automattics-ceo-seems-bound-and-determined-to-wreck-wordpress/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Did Elon Musk Appear to Sieg Heil at Trump Inauguration? (193 pts)]]></title>
            <link>https://www.jpost.com/international/article-838444</link>
            <guid>42772995</guid>
            <pubDate>Mon, 20 Jan 2025 21:02:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpost.com/international/article-838444">https://www.jpost.com/international/article-838444</a>, See on <a href="https://news.ycombinator.com/item?id=42772995">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            
<section>
	<section>
		


    <section>
        <h2>Musk was seen making the gesture a total of three times on live television.</h2>
    </section>

<section>
            <section>
                <section>
                    <time datetime="2025-01-20T22:29:54+02:00">
                        JANUARY 20, 2025 22:29
                    </time>
                </section>
                    <section><b>Updated:</b> JANUARY 20, 2025 23:30</section>
            </section>
            <section data-share-url="https://www.jpost.com/international/article-838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                    <nav>
                        <ul>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                            <li data-share-url="https://www.jpost.com/international/article-838444#838444" data-share-title="Did Elon Musk Sieg Heil at Trump's inauguration?">
                                
                            </li>
                        </ul>
                    </nav>
                </section>
        </section>


	</section>
	<section>
			<figure>
				<img src="https://images.jpost.com/image/upload/q_auto/c_fill,g_faces:center,h_537,w_822/644997" width="290" height="260" alt=" Elon Musk makes controversial gesture at Washington DC arena (photo credit: SCREENSHOT/X)" title=" Elon Musk makes controversial gesture at Washington DC arena">
				<figcaption>
					<section>
						<section> Elon Musk makes controversial gesture at Washington DC arena</section>
						<section>(photo credit: SCREENSHOT/X)</section>
					</section>
				</figcaption>
			</figure>
	</section>

</section>
<section>
			
			<section itemprop="articleBody" id="startBannerSticky">
				<p>US billionaire <a href="https://www.jpost.com/tags/elon-musk">Elon Musk</a> appeared to make a Heil Hitler salute at the Washington DC Trump parade on Monday, following Trump's inauguration.&nbsp;</p><p><a href="https://www.jpost.com/middle-east/article-837785">Musk</a> was seen making the gesture a total of three times on live television.</p><blockquote data-media-max-width="560"><p lang="en" dir="ltr">Elon Musk does what looks like a Hitler salute after talking of victory at Trump inauguration, thanking supporters for assuring "the future of civilisation" <a href="https://t.co/xp0kmJ5dFQ" rel="nofollow">pic.twitter.com/xp0kmJ5dFQ</a></p>— James Jackson (@derJamesJackson) <a href="https://twitter.com/derJamesJackson/status/1881436166144262376?ref_src=twsrc%5Etfw" rel="nofollow">January 20, 2025</a></blockquote><p>He then appeared on stage at the Capital One Area in front of 20,000 Trump supporters, where he thanked supporters before making the gesture.</p><blockquote><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/Breaking?src=hash&amp;ref_src=twsrc%5Etfw" rel="nofollow">#Breaking</a>: Senior Trump administration official Elon Musk thanks supporters with a Nazi salute. <a href="https://t.co/WzSZFUYvEG" rel="nofollow">pic.twitter.com/WzSZFUYvEG</a></p>— Noga Tarnopolsky נגה טרנופולסקי نوغا ترنوبولسكي (@NTarnopolsky) <a href="https://twitter.com/NTarnopolsky/status/1881436487558090831?ref_src=twsrc%5Etfw" rel="nofollow">January 20, 2025</a></blockquote><p>Social media users reacted with horror, with one writing, "Remember when Democrats called MAGA rallies "Nazi rallies?" President un-elect Elon Musk just did the Nazi Sieg Heil salute."</p><h3>Mars space travel</h3><p>The Tesla and Space X owner appeared excited by Trump's mention of Mars in his inaugural speech, given he has reportedly urged NASA to drop its plans to return to the moon and go straight to Mars, according to Politico.</p><p>President Donald Trump said the US would launch astronauts to plant the “stars and stripes” on Mars.</p><p>"We're gonna take DOGE to Mars!" said Musk in his speech, "Can you imagine how awesome it will be to have American astronauts plant the flag on another planet for the first time! How inspiring would that be?!"</p><section><hr><div>            <p>Stay updated with the latest news!</p>            <p>Subscribe to The Jerusalem Post Newsletter</p>        </div><hr></section><p>This comes amid a Washington Post report that Donald Trump's government <a href="https://www.jpost.com/american-politics/article-837770">advisory panel</a>, led by Elon Musk, will be sued soon after the incoming US president is sworn in on Monday.
				</p>
			</section>
		</section>



            
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ROCm Device Support Wishlist (131 pts)]]></title>
            <link>https://github.com/ROCm/ROCm/discussions/4276</link>
            <guid>42772170</guid>
            <pubDate>Mon, 20 Jan 2025 19:31:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ROCm/ROCm/discussions/4276">https://github.com/ROCm/ROCm/discussions/4276</a>, See on <a href="https://news.ycombinator.com/item?id=42772170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      <div data-body-version="299b9ab50a702b61e654a07387c220b1fb5c6d12f8237f4cbfff86784c2f2b0b" data-error="" id="discussioncomment-11894448" data-gid="DC_kwDOAzpr8c4AtX6w" data-url="/ROCm/ROCm/discussions/4276/comments/11894448" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894448/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Honestly, anything that has 16GB VRAM or more (or the ability to have reserved more, for eg. the iGPUs like 680/780/890M and Strix Halo iGPUs).</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-07e6d4f2-e873-4340-a7b4-cc09177208fa" for="discussion-upvote-button-DiscussionComment-11894448" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11894448">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11896093,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="738f5e1a0c79912c63b83622201031e6c8db67ed112aea719ab7d413def28e9d" data-hovercard-type="user" data-hovercard-url="/users/niklassheth/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/niklassheth"><img src="https://avatars.githubusercontent.com/u/20130217?s=60&amp;v=4" width="30" height="30" alt="@niklassheth"></a></p>

        <div data-body-version="3366d9f7e19e5e556f43df8081525bcb532d9434f2a1a325fd67425a3e1fc6c8" id="discussioncomment-11896093" data-gid="DC_kwDOAzpr8c4AtYUd" data-url="/ROCm/ROCm/discussions/4276/comments/11896093" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896093/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">As evidence for this, you can look at the used price of GPUs. Even an 8 year old P40 is going for $300 on eBay because it has 24GB VRAM. If the MI60 was supported it could be a good budget option.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>


        
    </div>
  <div data-body-version="9a4ede9d2f426b2cac5c97c9d588b433e455df2f2d11f82b00ab42d18dfbcc2d" data-error="" id="discussioncomment-11894747" data-gid="DC_kwDOAzpr8c4AtX_b" data-url="/ROCm/ROCm/discussions/4276/comments/11894747" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894747/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I would like support for ROCm to be restored to all the relatively recent GPUs (last 5-6 years) AMD has released and then dropped ROCm support for.  New I could not care much about. Actually supporting the AMD cards I bought in the past would be great.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-46052c64-2b58-4120-a6cf-206ce13fbac7" for="discussion-upvote-button-DiscussionComment-11894747" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="9eab11215d5ae982b020b1b9ab57bf9509331d016278ec1083667515affd030d" data-error="" id="discussioncomment-11894841" data-gid="DC_kwDOAzpr8c4AtYA5" data-url="/ROCm/ROCm/discussions/4276/comments/11894841" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894841/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I think it might be interesting to share here that Debian has built a CI at <a href="https://ci.rocm.debian.net/" rel="nofollow">ci.rocm.debian.net</a> where the ROCm stack, and any package that depends on it, is continuously tested. Our CI includes all of the architectures listed above.</p>
<p dir="auto">We would be happy to cooperate on increasing service support for Debian and derivatives.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-66903d35-f63f-4fec-8302-b6b1fe0fab74" for="discussion-upvote-button-DiscussionComment-11894841" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="baf615a896f6281ae4dce8c4e2704158995d26e3d65d562d075cbd45095fcb3f" data-error="" id="discussioncomment-11894876" data-gid="DC_kwDOAzpr8c4AtYBc" data-url="/ROCm/ROCm/discussions/4276/comments/11894876" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894876/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">This is not a "device" support wish, but a "platform" one. Stable Diffusion on native Windows with AMD GPUs is not possible until we get "Windows" support for "AI Libraries" (specifically MIOpen) here: <a href="https://rocm.docs.amd.com/projects/install-on-windows/en/develop/reference/component-support.html" rel="nofollow">https://rocm.docs.amd.com/projects/install-on-windows/en/develop/reference/component-support.html</a></p>
<p dir="auto">This is required to get PyTorch working. I've seen so many AMD users in recent times selling their AMD GPUs and buying "the competition" because WSL and ZLUDA are their only options, and those are half-baked solutions. Native Windows support should be a top priority.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-f247b436-6275-427f-8fa9-e125513f1e76" for="discussion-upvote-button-DiscussionComment-11894876" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11894876">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895073,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="1e8bb9a91b6ac1e121d7c4a51111e736de21a302b5d916fa108e8f7b88b11dcd" data-hovercard-type="user" data-hovercard-url="/users/tocram1/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/tocram1"><img src="https://avatars.githubusercontent.com/u/22381620?s=60&amp;v=4" width="30" height="30" alt="@tocram1"></a></p>

        <div data-body-version="59dcaa13ac84895a8d972d45bb76f53ce6fdd795fa4f412208b6ec88f5bb79e3" id="discussioncomment-11895073" data-gid="DC_kwDOAzpr8c4AtYEh" data-url="/ROCm/ROCm/discussions/4276/comments/11895073" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895073/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Definitely agree on this one, this is a major hurdle in MY opinion.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>


        
    </div>
  <div data-body-version="75fc6a10eb474b0ac38ca75b93996824dad488c2c5d63281ce5943635eb31b55" data-error="" id="discussioncomment-11894914" data-gid="DC_kwDOAzpr8c4AtYCC" data-url="/ROCm/ROCm/discussions/4276/comments/11894914" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894914/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">A bit older than the ones listed there, but I own a 5700XT, and a good few other people do too, from my extensive looking for how to get it to work online.</p>
<p dir="auto">Still holding on to the precompiled wheel for torch 1.13 ROCM 5.2 for Python 3.10 which is the last one that works (after setting HSA_OVERRIDE_GFX_VERSION). Later versions seem to either outright crash, or import correctly but then crash when a tensor is sent to the GPU.</p>
<p dir="auto">Using this older version as a workaround was doable back when torch 2.0 was new, but now as most new code has already been using 2.0+ for a while, it's effectively not functional at all anymore for any recently written code.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-3e032699-4bf6-4370-b1d3-6ddd7baaaec0" for="discussion-upvote-button-DiscussionComment-11894914" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11894914">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895908,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="fb945d44ec154bf7c9a296dc4c0adfd92652dd919a443c392fae053fa4dab4bc" data-hovercard-type="user" data-hovercard-url="/users/SicLuceatLux/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SicLuceatLux"><img src="https://avatars.githubusercontent.com/u/43041463?s=60&amp;v=4" width="30" height="30" alt="@SicLuceatLux"></a></p>

        

    </div>


        
    </div>
  <div data-body-version="0c261b8b353a6a30cb9a1d99f88e3f6d4a9c1043e5f1ccd22425a35a36cedb04" data-error="" id="discussioncomment-11894998" data-gid="DC_kwDOAzpr8c4AtYDW" data-url="/ROCm/ROCm/discussions/4276/comments/11894998" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11894998/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Considering my GPU( 6600 XT)  was released near the end of 2021 it would be nice to know that I don't need to buy a new GPU every year just to have support. It would also be nice to have actual proper Windows support instead of having to deal with the clusterfuck that is Zluda, or other translation layers. This kind of treatment from AMD is why I'll probably go nvidia the next time my budget allows it.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-563ac12c-b2cc-4200-86b1-8876cb9400ce" for="discussion-upvote-button-DiscussionComment-11894998" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="a4116625bd825f160374a9f736bc058290ceb23dd78775a84ba17d56344fe604" data-error="" id="discussioncomment-11895157" data-gid="DC_kwDOAzpr8c4AtYF1" data-url="/ROCm/ROCm/discussions/4276/comments/11895157" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895157/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">APU support opens the door for introducing this software to a wide audience, please consider hitting the entire APU line (3 and 3.5.) Early ROCm worked for 780m and got me in the front door of working with this software at all (that said I had to use env var hacks to get it functioning). Later versions of ROCm stopped working at all.</p>
<p dir="auto">The hobbyist crowd would greatly benefit from APU support, which hopefully has the AMD financial incentive of market share and product familiarity (hobbyist engineers who do something neat at home and then bring the concepts to work, where you then pick up the larger purchases)</p>
<p dir="auto">If I was able to feel confident in better consumer ROCm support I would have gladly dropped money for 2 AMD graphics cards for the LLM stuff I do.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-cc9cfe79-f4fb-44e8-b72e-684504465400" for="discussion-upvote-button-DiscussionComment-11895157" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    2 replies
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11895157">

    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895323,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="08551d753a51e5999ddb8a5a0c88a89d7354468fcdbedea428c9cbc91efbed94" data-hovercard-type="user" data-hovercard-url="/users/randomstuff/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/randomstuff"><img src="https://avatars.githubusercontent.com/u/946727?s=60&amp;v=4" width="30" height="30" alt="@randomstuff"></a></p>

        <div data-body-version="7d32692793bbb76ac2be4d90993111340635b8e9c7da65be969ea9fcca74dc4e" id="discussioncomment-11895323" data-gid="DC_kwDOAzpr8c4AtYIb" data-url="/ROCm/ROCm/discussions/4276/comments/11895323" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895323/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I have been somewhat successfully been able to run Stable Diffusion on a <a href="https://www.gabriel.urdhr.fr/2022/08/28/trying-to-run-stable-diffusion-on-amd-ryzen-5-5600g/" rel="nofollow">AMD Ryzen 5 5600G</a> APU (with 16 Go / 32 Go of RAM).</p>
<p dir="auto">The performance speedup was not super impressive compared to the same implementation executed on CPU or the OpenVINO CPU implementation. I am not sure if we could get a nice speedup for this kind of device but it would be really interesting.</p>
<p dir="auto">The thing was highly unstable and had a tendency of crashing the whole system real quick. Anyway, it was nearly working for some programs. Si maybe there is not so many things missing to a have something stable :)</p>
    </div>
    
</task-lists>

          

        </div>

    </div>
    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895573,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="32cfbb4ae281dd01619117b092b54359b030ceebe3fa78fae5d7a1d00c8e3af1" data-hovercard-type="user" data-hovercard-url="/users/Abdull/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Abdull"><img src="https://avatars.githubusercontent.com/u/529862?s=60&amp;v=4" width="30" height="30" alt="@Abdull"></a></p>

        <div data-body-version="b0ed72ab4fe39ad8c54bf1ce3679bf025c35489ed37cf82d6366f4c770e98616" id="discussioncomment-11895573" data-gid="DC_kwDOAzpr8c4AtYMV" data-url="/ROCm/ROCm/discussions/4276/comments/11895573" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895573/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">important for Framework 13 AMD laptop users</p>
    </div>
    
</task-lists>

          

        </div>

    </div>

</div>


        
    </div>
  <div data-body-version="6dd366079f09ed3314a27f573c24f7694472b1e9620886d0a44809818ef06c97" data-error="" id="discussioncomment-11895185" data-gid="DC_kwDOAzpr8c4AtYGR" data-url="/ROCm/ROCm/discussions/4276/comments/11895185" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895185/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">why not just all, like the other company? ;-)</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-0cb80f69-16e9-4b33-bd3e-9e7a6375862a" for="discussion-upvote-button-DiscussionComment-11895185" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    3 replies
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11895185">

    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895241,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58150230df92bc1e3b1bc985b82360100bf1bdba1f722ceda041f8f23cb00282" data-hovercard-type="user" data-hovercard-url="/users/powderluv/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/powderluv"><img src="https://avatars.githubusercontent.com/u/74956?s=60&amp;v=4" width="30" height="30" alt="@powderluv"></a></p>

        <div data-body-version="94f3e3e23b56bb956c129e2c7dc34d254852eeea837fccfffe0c3067d22f4cf4" id="discussioncomment-11895241" data-gid="DC_kwDOAzpr8c4AtYHJ" data-url="/ROCm/ROCm/discussions/4276/comments/11895241" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895241/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Eventually. But what would you prioritize? :)</p>
    </div>
    
</task-lists>

          

        </div>

    </div>
    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895322,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="034fd912b967c7ac7fac064c34a1ccfb3958f66bd1dacdc08fc1105d3d840e37" data-hovercard-type="user" data-hovercard-url="/users/shiltian/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/shiltian"><img src="https://avatars.githubusercontent.com/u/7587318?s=60&amp;v=4" width="30" height="30" alt="@shiltian"></a></p>

        <div data-body-version="444c854734197b911f0b04229e1509352e0fc94e5bf147f1ee9568e88a92539d" id="discussioncomment-11895322" data-gid="DC_kwDOAzpr8c4AtYIa" data-url="/ROCm/ROCm/discussions/4276/comments/11895322" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895322/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">my .02 is starting from all RDNA 2 and newer. that's gonna take time. by the time they are all supported, RDNA 1 might have fairly faded out.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>
    <div>
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11896209,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="94548708abd6a2498081a9869a81137e0e2ef62a4ed3bc113fce92c1c962dfae" data-hovercard-type="user" data-hovercard-url="/users/TKCZ/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/TKCZ"><img src="https://avatars.githubusercontent.com/u/22118472?s=60&amp;v=4" width="30" height="30" alt="@TKCZ"></a></p>

        <div data-body-version="c416c01b691f7b738b438424cc3d8c9266f848bdc999a364f68ea3f3048f1f14" id="discussioncomment-11896209" data-gid="DC_kwDOAzpr8c4AtYWR" data-url="/ROCm/ROCm/discussions/4276/comments/11896209" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896209/language_detections">
      
    </inline-machine-translation>
  <div>
        <blockquote>
<p dir="auto">Eventually. But what would you prioritize? :)</p>
</blockquote>
<p dir="auto">Definitelly start with RDNA2 &amp; 3, since these series offered models with 16GB VRAM. That much memory deserves to stay around officially supported for as long as possible. Let alone the fact that cards like 6800XT still pack decent punch for local AI inference.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>

</div>


        
    </div>
  <div data-body-version="9f4dab7adc8c5e819850961f54e8c18019d30f85b4c1a707fd0cd3a15bac7c40" data-error="" id="discussioncomment-11895317" data-gid="DC_kwDOAzpr8c4AtYIV" data-url="/ROCm/ROCm/discussions/4276/comments/11895317" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895317/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">ROCm windows, All RDNA3 and newer. Don't forget integrated GPUs. Maybe next year?</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-9f39403a-251c-4a3f-ab44-50269333e5bd" for="discussion-upvote-button-DiscussionComment-11895317" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="7b94ee7e4a683ea60daf9aa12987a695462f6dfe1dc018b8560ecc2e80d02174" data-error="" id="discussioncomment-11895348" data-gid="DC_kwDOAzpr8c4AtYI0" data-url="/ROCm/ROCm/discussions/4276/comments/11895348" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895348/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I wish for AMD to look back at the RX 500  and the RX5000 series. And the reason being, the physical architectures for both lend themselves to really interesting compute because the RX 580 architecturally is very good to use as a modular scale up and scale down at 75 w. And based based on some back of the napkin maths that I've done an RX 580 8 gig with a 8 billion parameter model with a quant size of eight. Can pull about 15 to 30 tokens per second.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-6713e9db-8776-42b2-ab7a-134f822bdcb7" for="discussion-upvote-button-DiscussionComment-11895348" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>


          <div data-body-version="5456848d6531fe9f1f551b6f7229a70b9d12cac492941d4f1a0e1ed720aec788" data-error="" id="discussioncomment-11895367" data-gid="DC_kwDOAzpr8c4AtYJH" data-url="/ROCm/ROCm/discussions/4276/comments/11895367" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895367/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Hi,<br>
IMO all products going forward should be able to run all typical ML software: stable diffusion, LLMs, pytorch.<br>
Doesn't have to be crazy fast, but support it and then improve it over time.<br>
And simultaneously, but fine if at a lower pace, walk backwards and support the older products.</p>
<p dir="auto">So you should start by supporting strix halo and RDNA 4. Then RDNA 3 and prior APUs.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-c27855b0-7ef2-48ff-ba05-4cba14af7fb3" for="discussion-upvote-button-DiscussionComment-11895367" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="368d8a87f1f3eb9b8da0616cf95aca6b54ce9e0833bc0ce5dc74a2cb880d16d2" data-error="" id="discussioncomment-11895435" data-gid="DC_kwDOAzpr8c4AtYKL" data-url="/ROCm/ROCm/discussions/4276/comments/11895435" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895435/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Thank you for reaching out and at least trying to extend the device support. The limited consumer hardware support has always been one of the weakest point of ROCm, and if AMD is serious about the future of ROCm, at least any upcoming hardware should be supported. Being able to get used to a platform without spending 1000s is actually huge.<br>
Currently, even if unsupported, many actually work fine. I did and I'm still doing some PyTorch stuff on a 8700GE, which has a gfx1103 GPU in it. Works, but there are some nasty minor issues like this one here, causing the GPU driver to crash now and then, seemingly a firmware issue: <a data-error-text="Failed to load title" data-id="2474223008" data-permission-text="Title is private" data-url="https://github.com/lamikr/rocm_sdk_builder/issues/141" data-hovercard-type="issue" data-hovercard-url="/lamikr/rocm_sdk_builder/issues/141/hovercard" href="https://github.com/lamikr/rocm_sdk_builder/issues/141">lamikr/rocm_sdk_builder#141</a><br>
I think, it's a rather small step for AMD to make those 99% working devices to a 100% officially supported level.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-57cb16f5-c3d1-498c-9a2e-e5f430664f0a" for="discussion-upvote-button-DiscussionComment-11895435" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="054686a2c43c6262a1f6b4938167d23622b1aa0a11c76249c06691a6e298954a" data-error="" id="discussioncomment-11895444" data-gid="DC_kwDOAzpr8c4AtYKU" data-url="/ROCm/ROCm/discussions/4276/comments/11895444" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895444/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">At one time Kaveri was promoted as a hybrid processor, and while HSA was being implemented its support disappeared. It would be fair, given the promises of marketers, to make HSA + ROCm for APU Kaveri.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-356e5a80-3267-4c1b-acbd-0ada8783843b" for="discussion-upvote-button-DiscussionComment-11895444" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="313f54341a67795a6b3549078c47509a3bbe9a9250b1711d454fc3dfb6b44323" data-error="" id="discussioncomment-11895539" data-gid="DC_kwDOAzpr8c4AtYLz" data-url="/ROCm/ROCm/discussions/4276/comments/11895539" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
        



      <div>
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895539/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Missing poll option: actually support the ✅ marked devices consistently</p>
<p dir="auto">There's not much point having a green icon in the support matrix if it doesn't mean your device is supported.<br>
aotriton supports only MI2xx, MI3xx, 7800, 7900.<br>
hipblaslt supports only MI2xx, MI3xx, 7800, 7900.<br>
Dao-AILab/flash-attention (which AMD contributed ROCm support to) doesn't support MI100. I think it's picky about consumer cards too but don't remember the models.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-37226189-31a4-4fad-bedf-c579ecabd45d" for="discussion-upvote-button-DiscussionComment-11895539" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    1 reply
                  </span>
                </p>
            </div>

        </div>
          <div data-child-comments="" id="child-comments-discussioncomment-11895539">
      <p><a data-hydro-click="{&quot;event_type&quot;:&quot;discussions.click&quot;,&quot;payload&quot;:{&quot;event_context&quot;:&quot;DISCUSSION_VIEW&quot;,&quot;target&quot;:&quot;USER_PROFILE_LINK&quot;,&quot;current_repository_id&quot;:54160369,&quot;discussion_repository_id&quot;:54160369,&quot;org_level&quot;:false,&quot;discussion_id&quot;:7850354,&quot;discussion_comment_id&quot;:11895810,&quot;originating_url&quot;:&quot;https://github.com/ROCm/ROCm/discussions/4276&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="76750ea7a41fa5e9e9b1ea2e04c74ab5908b60b290bbeac03e20dcfe27e8f1e8" data-hovercard-type="user" data-hovercard-url="/users/IMbackK/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/IMbackK"><img src="https://avatars.githubusercontent.com/u/13803414?s=60&amp;v=4" width="30" height="30" alt="@IMbackK"></a></p>

        <div data-body-version="1b50beb7542cde7184da8ea2e0afb47d7f62bdd41426fc550e5676f7b5cc55bf" id="discussioncomment-11895810" data-gid="DC_kwDOAzpr8c4AtYQC" data-url="/ROCm/ROCm/discussions/4276/comments/11895810" data-error="">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895810/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Yeah this is the big thing. Besides missing rdna1 support, the actual support matrix (not the mostly useless check mark, what the code supports) is mostly fine, except random libraries that then support only a subset of those.</p>
    </div>
    
</task-lists>

          

        </div>

    </div>


        
    </div>
  <div data-body-version="96b624a0db8669f4d32a09be017348010050de83168e06266ca1d3088deec029" data-error="" id="discussioncomment-11895566" data-gid="DC_kwDOAzpr8c4AtYMO" data-url="/ROCm/ROCm/discussions/4276/comments/11895566" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895566/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto"><strong>Chicken and egg.</strong>  I don't own any of your hardware because I can't run the software I want to run. Support Flux, Stable Diffusion, Tencent Hunyuan Video, Nvidia Cosmos, and I'll be in the market to buy your cards. As it stands, I can't leverage your offering.  I'll gladly build AMD workstations if your hardware can do the things I want.</p>
<p dir="auto"><strong>Prioritize VRAM.</strong> The next battle is local image and video models. Nobody wants to use hosted SaaS and all the film and VFX people will be running local Comfy, Hunyuan, etc. in just a few years time. These models need a tremendous amount of VRAM, so you need to build consumer/prosumer SKUs that have it.</p>
<p dir="auto">If you time this right and build high VRAM consumer cards with broad software support, the next generation of media production could ride on your platform.</p>
<p dir="auto">Let me underscore: you <em>must</em> be able to run popular image and video models.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-8d82a3f8-78d9-4455-b7b6-76c39c74bb48" for="discussion-upvote-button-DiscussionComment-11895566" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>

    



      <div data-body-version="09ee47da6431ac30b79faf5af02f101bfd50d483cfdbaa7b784b56efa45bee11" data-error="" id="discussioncomment-11895881" data-gid="DC_kwDOAzpr8c4AtYRJ" data-url="/ROCm/ROCm/discussions/4276/comments/11895881" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895881/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Long term support for APU's with a lot of ram and usable performance gets a bunch of developers to try things quickly and builds confidence in shipping to enterprise hardware in prod. Low power, high ram, usable performance and out of the box support for all the major tools with NO BUGS. Learn from Ballmer: Developers developers developers developers....</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-83513683-c4a5-4452-abc1-18d0b13407ca" for="discussion-upvote-button-DiscussionComment-11895881" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="429a8fd23a83a0f1f55e3bf56e326d8bab30e9ebc9e65a0897192fbad18c0115" data-error="" id="discussioncomment-11895947" data-gid="DC_kwDOAzpr8c4AtYSL" data-url="/ROCm/ROCm/discussions/4276/comments/11895947" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895947/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Basically, anything with more than 16GB of RAM. APUs capable of using system RAM could be a cost-effective entry-level option for running large language models (LLMs). While they might be slower, many people don’t require real-time LLM output.</p>
<p dir="auto">Everyone wants to run large models, but not everyone can afford to spend several thousand dollars on professional GPUs, multiple high-end prosumer cards, or Macs.</p>
<p dir="auto">The ROCm user base could grow rapidly if people could leverage their existing iGPUs for AI tasks. I wish my Raven Ridge APU could handle slow AI tasks, like sorting and tagging photos on my Nextcloud NAS, and similar applications.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-fe79600e-9a2d-4241-a4ab-f13eb5a7ffb9" for="discussion-upvote-button-DiscussionComment-11895947" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="60b2d147161c5e686c514dae9cdf1e582e98a78493f59d64b1479ae579d9bced" data-error="" id="discussioncomment-11895995" data-gid="DC_kwDOAzpr8c4AtYS7" data-url="/ROCm/ROCm/discussions/4276/comments/11895995" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11895995/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">xbox and playstation, period.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-cc72407d-7745-4740-9da5-a4657fe9a2e1" for="discussion-upvote-button-DiscussionComment-11895995" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="db5020ede0a87cb441e4c80ee05bdc1b63cb1628b9c9cc55d6023f527156673e" data-error="" id="discussioncomment-11896000" data-gid="DC_kwDOAzpr8c4AtYTA" data-url="/ROCm/ROCm/discussions/4276/comments/11896000" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896000/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Strix Halo and Phoenix APUs could possibly be the most popular so definitely them but full support for the 7600xt and better seems proper. including the 6000 series equivalents. I feel the 7600xt's appeal over a regular 7600 is ROCm more than gaming</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-18baf3d8-268d-4841-b5a6-4d5f4b20a7ef" for="discussion-upvote-button-DiscussionComment-11896000" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="4eb0d589f42b297099933e81c73b825739045177384b8a92ac25acf48779bcd9" data-error="" id="discussioncomment-11896009" data-gid="DC_kwDOAzpr8c4AtYTJ" data-url="/ROCm/ROCm/discussions/4276/comments/11896009" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896009/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">You have a much wider reach with iGPUs than with dGPUs, so I wouldn't stop supporting RDNA and Vega which AMD still sells widely.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-b440b199-229e-4756-9ee4-082580964130" for="discussion-upvote-button-DiscussionComment-11896009" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="6389b831651f10398b1800c0693ba58bd996c1ccf901d9d557f998797699a33e" data-error="" id="discussioncomment-11896170" data-gid="DC_kwDOAzpr8c4AtYVq" data-url="/ROCm/ROCm/discussions/4276/comments/11896170" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896170/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">For Windows and WSL users, shouldn't using DirectML be an option? I may be wrong here though</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-b8760a12-1b9b-4244-80af-60d64fe749e7" for="discussion-upvote-button-DiscussionComment-11896170" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="0d511713bb5eb3f4b1179446b5e95932e1f2401f25e9c3f9e8a403a21d5d94a4" data-error="" id="discussioncomment-11896197" data-gid="DC_kwDOAzpr8c4AtYWF" data-url="/ROCm/ROCm/discussions/4276/comments/11896197" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896197/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Would like to see the the W7600 and W7700 supported - small memory, but single-slot! Very useful for compact builds, or if more PCIe cards are needed. I've combined these with Mellanox NICs and Highpoint HBAs.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-94216dac-1578-46d2-93fa-aeeb95d1e4dd" for="discussion-upvote-button-DiscussionComment-11896197" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="ad8da41e9c92f907c38045f5d6e2ef421dcf89ded01a6affa6baecf8d968ea73" data-error="" id="discussioncomment-11896210" data-gid="DC_kwDOAzpr8c4AtYWS" data-url="/ROCm/ROCm/discussions/4276/comments/11896210" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896210/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">All of them. GCN 4 and up if I had to be hard-pressed into an answer.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-38d3cb38-b7e2-4786-9aef-131a59a9de5e" for="discussion-upvote-button-DiscussionComment-11896210" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="27e881f62dfca99403d134c3956b66d37cf90170fc599f4e5ea75120bf6d47f9" data-error="" id="discussioncomment-11896220" data-gid="DC_kwDOAzpr8c4AtYWc" data-url="/ROCm/ROCm/discussions/4276/comments/11896220" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896220/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">It's important to note that "Support" means wildly different things to different people.</p>
<ul dir="auto">
<li>The compiler knows how to emit code for the GPU</li>
<li>The driver knows how to load code onto / allocate memory etc for the GPU</li>
<li>The libraries have been compiled for that GPU (so can actually run)</li>
<li>The libraries have GPU-specific optimisations implemented (i.e. are faster)</li>
<li>The ROCm release process tests / validates on that GPU</li>
<li>The various CI systems run on that GPU</li>
<li>Variations on where tickets can be raised</li>
</ul>
<p dir="auto">I believe this is where things have gone south. The ROCm release testing / validation is thorough and somewhat linear in the number of GPUs tested on so adding more hardware to that set costs lots of time. The cards behave fairly similarly to one another so it's also not especially informative. However writing "Supported: Foo" without actually putting Foo through the same internal testing as all others seems problematic.</p>
<p dir="auto">What a decent fraction of people want is for ROCm to run on their gaming card(s). Whether it actually went through the internal validation is somewhat less important than it refusing to run entirely because the libraries haven't been compiled for their hardware.</p>
<p dir="auto">I think the solution to this is really obvious. Build the userspace software for all the targets. Let "Supported" continue to mean whatever it currently does. That'll mean people can install the ROCm distribution and get something which at least attempts to run on their hardware. Optionally introduce a new term, whatever marketing like, to refer to the hardware that isn't on the supported list.</p>
<p dir="auto">I personally don't care at all whether the latest ROCm release has been carefully tested on the graphics card I'm using locally but I'm really annoyed when it wasn't compiled for it.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-d959b2b9-1153-4707-957d-95847ec7801c" for="discussion-upvote-button-DiscussionComment-11896220" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="25a357989dad020ca60381a652abe8e51a10e3de2d0adeb53075b86de7328e0d" data-error="" id="discussioncomment-11896278" data-gid="DC_kwDOAzpr8c4AtYXW" data-url="/ROCm/ROCm/discussions/4276/comments/11896278" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896278/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I'll keep it short, please don't drop gfx906.</p>
<p dir="auto">and maybe what I'm asking for is too much given that they seem to strictly include officially supported, CDNA, GPUs, but it would be lovely if you could get support for consumer GPUs eg. gfx906 and up added to prebuilt docker images like vllm-dev/-ci.<br>
thank you guys, ROCm is getting better and better.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-c02a500b-e04e-4b67-b4a2-1e470920e860" for="discussion-upvote-button-DiscussionComment-11896278" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="67d6d7105dd537c0790422c11383d05f508346f2128ab90a3c4ac5f4d21e7c56" data-error="" id="discussioncomment-11896331" data-gid="DC_kwDOAzpr8c4AtYYL" data-url="/ROCm/ROCm/discussions/4276/comments/11896331" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896331/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I would like to see full-stack generational support on Linux with both the runtime and HIP SDK for consumer cards on RDNA[1|2|3] and then extending it to GCN where possible.</p>
<p dir="auto">At the moment AMD have structured [and in my opinion artificially limited] their compatibility matrices to the upper tiers of the hardware stacks, e.g. 6800 and up on RDNA2, preventing those who own 6750XT and lower stack cards from using ROCm/HIP.</p>
<p dir="auto">I understand that a lot of the unsupported hardware "just works" in some fashion but it is not officially supported nor documented as being supported or which components/libraries work and which do not - this is just bad all around as nobody will buy GPU hardware or buy into the ROCm software ecosystem without knowing before hand that the hardware is capable, the hardware feature set is fully supported in software and it is relatively easy to get up and running as an end user, this is especially bad from a PR perspective for AMD in wanting to get more people to use their hardware when it is restricted by hardware/pricing tiers and by the AMD software itself.</p>
<p dir="auto">Nobody is going to purchase a GPU in order to dip into trying out the ROCm ecosystem if they have to purchase the highest tiers of GPU to know for sure that ROCm will fully support the hardware.</p>
<p dir="auto">Artificial limits which segregate capable hardware through a lack of support in or a lack of enablement in software is not a good practice and it harms not only end-users/customers but AMD and ROCm adoption too.</p>
<p dir="auto">I would like to see AMD's stance on this change to one of starting from full enablement from the outset where the hardware features exist to do that and remove any artificial tiering/segregation entirely, tear down those walls.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-424addef-6d6f-44a3-9bda-3280ef11dedd" for="discussion-upvote-button-DiscussionComment-11896331" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="284b2343c73f6c317db7f14871d9dd54a3c4148d693f00cd831a70cc846e288d" data-error="" id="discussioncomment-11896340" data-gid="DC_kwDOAzpr8c4AtYYU" data-url="/ROCm/ROCm/discussions/4276/comments/11896340" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896340/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">You know, the reason AMD is way behind Nvidia in market share is because Nvidia literally supports every single discrete graphics processor model with CUDA from the low end to their high end.  They realized what AMD never has, and has continuously annoyed people, especially Linux users.  Not everyone writing software for CUDA has an ultra high end GPU product <em>because they can't afford them</em>.  But they have a very robust software development community where the underlying SDKs largely just works.  Intel has effectively realized the same thing with ARC.</p>
<p dir="auto">If AMD can't at least match the Linux support matrix with the Windows support matrix going forward you're rapidly going to grow completely irrelevant with new generations of software tinkerers who are primarily writing software on Linux. Windows from a compute performance point of view is demonstrably poor in comparison, and the user experience is degrading over time as Microsoft lets their OS foundation crumble while they're off chasing unicorns.</p>
<p dir="auto">What's my vote?  Every GPU currently under active driver support including Vega. Vega still has a fairly large-ish install base.  Arbitrary decisions to drop support may make business decisions, but it annoys customers who buy hardware only to have it dropped from support not long after it was still being sold.  But if you must narrow down your support matrix everything from the RX 5000 series and newer.  Either actually compete with the CUDA hardware support experience or get out of the game.  Those are your only options because that's the market you're trying to grow and Nvidia is the dominant player.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-6646e146-c08b-4df3-8bb2-927c82b815cb" for="discussion-upvote-button-DiscussionComment-11896340" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="65e02158d0d0f60fde3be97886b2f1f80177a108e4a09a0f193315454137f75c" data-error="" id="discussioncomment-11896361" data-gid="DC_kwDOAzpr8c4AtYYp" data-url="/ROCm/ROCm/discussions/4276/comments/11896361" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896361/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">I'm not sure why, but for me it seems that for example RDNA2 cards (and APUs) are not unsupported, but rather blocked. With setting <code>HSA_OVERRIDE_GFX_VERSION=10.3.0</code> ROCm (using pytorch) runs fine. Since Linux 6.10 and the APU memory fix it even works on my Ryzen 6000 notebook. Why the need for that environment variable?</p>
<p dir="auto">If you don't have the resources to run all tests on all types of consumer GPU/APU and you want to ensure that you provide a build that is fully tested: Why not an "enterprise release" that is fully tested and has only support for tested card and a "community edition" that has all GPUs enabled but is not fully tested (both build from the same source code with the same versions, only difference is the activated cards).</p>
<p dir="auto">If you're thinking supporting a lot of consumer GPUs is a waste of money: A big reason why NVIDIA is so successful in the AI market, because every student with even the smallest NVIDIA GPU was able to experiment with CUDA on her/his own machine. Years later when those students are working in the industry, with what products/APIs do they have experience? And when they make decisions, what will they buy for their company?<br>
AMD missed the first big wave, so they need to catch up, and maybe they get a second chance to really gain market share at some point (when for example NVIDIA is having issues with a new generation).</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-3db34814-8b6d-499d-8c08-1a49909c1da3" for="discussion-upvote-button-DiscussionComment-11896361" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="5adf4a21994224ef202e238c472a29caef73e0d49b91c99c4ccf15b93d227319" data-error="" id="discussioncomment-11896375" data-gid="DC_kwDOAzpr8c4AtYY3" data-url="/ROCm/ROCm/discussions/4276/comments/11896375" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896375/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">This is fundamentally misguided. It's not a question of which specific GPUs are supported now. It's a question of:</p>
<ol dir="auto">
<li>Will support consistently be added for new GPUs at the time of launch? Your competition has day 1 support for new GPUs, and doesn't arbitrarily decide that half the GPUs in a new generation will be incompatible.</li>
<li>Will support consistently be kept for GPUs that are currently supported? You competition still runs on ancient laptops out-of-the-box.</li>
<li>Do consumers trust you to keep to your word for 1 &amp; 2? You've walked back support before.</li>
</ol>
<p dir="auto">Reiterating from my prior comment <a href="https://github.com/amd/RyzenAI-SW/issues/2#issuecomment-1999684155" data-hovercard-type="issue" data-hovercard-url="/amd/RyzenAI-SW/issues/2/hovercard">here</a>:</p>
<blockquote>
<p dir="auto">Your competition has CUDA: Compute <em>Unified</em> Device Architecture - and indeed it supports practically everything from ancient laptops on up. In terms of effort versus reward, things target CUDA largely because they can port to it - using easily available hardware - <em>once</em> - and get fairly decent performance across a very large chunk of the market. (And then tune it later if necessary.)</p>
<p dir="auto"><a href="https://github.com/ROCm/ROCm/issues/1180" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1180/hovercard">Meanwhile</a>, <a href="https://github.com/ROCm/ROCm/issues/2429" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/2429/hovercard">ROCm</a> <a href="https://github.com/ROCm/ROCm/issues/1659" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1659/hovercard">support</a> <a href="https://github.com/ROCm/ROCm/issues/1714" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1714/hovercard">is</a> <a href="https://github.com/ROCm/ROCm/issues/1306" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1306/hovercard">a</a> <a href="https://github.com/ROCm/ROCm/issues/666" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/666/hovercard">minefield</a> <a href="https://github.com/ROCm/ROCm/issues/887" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/887/hovercard">at</a> <a href="https://github.com/ROCm/ROCm/issues/1880" data-hovercard-type="issue" data-hovercard-url="/ROCm/ROCm/issues/1880/hovercard">best</a>.</p>
</blockquote>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-f69bf508-67d7-40d3-87f3-2fa27351cb64" for="discussion-upvote-button-DiscussionComment-11896375" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>
  <div data-body-version="ebcd1fe4bc079c968e2da6d9e486b26e57d33c33e1091450cf4878b73a1c1bd3" data-error="" id="discussioncomment-11896406" data-gid="DC_kwDOAzpr8c4AtYZW" data-url="/ROCm/ROCm/discussions/4276/comments/11896406" data-open-edit-form-after-load="false" data-quote-markdown=".js-comment-body">
            <task-lists disabled="" sortable="">
    <inline-machine-translation detected-language="en" detect-language-url="/ROCm/ROCm/discussions/4276/comments/11896406/language_detections">
      
    </inline-machine-translation>
  <div>
        <p dir="auto">Supporting gfx1036 is a must. It's probably the most available device and would allow many people to see if something is working on ROCm at all. It's also a great option to test on RDNA2 when you have other generation dGPUs.</p>
<p dir="auto">But, as many people said already, supporting all devices is the only correct option if you want broad developer support. After you've dropped gfx906 support on Windows (after it barely started) I don't see any reason to invest development effort in current AMD hardware. And the UDNA news sound like you'll immediately drop all previous architectures upon release.</p>
    </div>
    
</task-lists>

          <div>
              <div data-replace-remote-form-target="">
        <tool-tip id="tooltip-2dbbbb07-e9a3-4bad-8b37-be85b36d4d61" for="discussion-upvote-button-DiscussionComment-11896406" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be logged in to vote</tool-tip>
    </div>

                <p><span>
                    0 replies
                  </span>
                </p>
            </div>

        </div>


  
  <!-- '"` --><!-- </textarea></xmp> --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am (not) a failure: Lessons learned from six failed startup attempts (311 pts)]]></title>
            <link>http://blog.rongarret.info/2025/01/i-am-not-failure-lessons-learned-from.html</link>
            <guid>42771676</guid>
            <pubDate>Mon, 20 Jan 2025 18:40:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://blog.rongarret.info/2025/01/i-am-not-failure-lessons-learned-from.html">http://blog.rongarret.info/2025/01/i-am-not-failure-lessons-learned-from.html</a>, See on <a href="https://news.ycombinator.com/item?id=42771676">Hacker News</a></p>
Couldn't get http://blog.rongarret.info/2025/01/i-am-not-failure-lessons-learned-from.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: I'm Peter Roberts, immigration attorney, who does work for YC and startups. AMA (211 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42770125</link>
            <guid>42770125</guid>
            <pubDate>Mon, 20 Jan 2025 16:20:29 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42770125">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42770125: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Mixxx: GPL DJ Software (409 pts)]]></title>
            <link>https://mixxx.org/</link>
            <guid>42769871</guid>
            <pubDate>Mon, 20 Jan 2025 15:53:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mixxx.org/">https://mixxx.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42769871">Hacker News</a></p>
Couldn't get https://mixxx.org/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse engineering my #1 Hacker News article (115 pts)]]></title>
            <link>https://danielwirtz.com/blog/successful-hacker-news-article</link>
            <guid>42769325</guid>
            <pubDate>Mon, 20 Jan 2025 14:53:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danielwirtz.com/blog/successful-hacker-news-article">https://danielwirtz.com/blog/successful-hacker-news-article</a>, See on <a href="https://news.ycombinator.com/item?id=42769325">Hacker News</a></p>
Couldn't get https://danielwirtz.com/blog/successful-hacker-news-article: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek-R1 (1076 pts)]]></title>
            <link>https://github.com/deepseek-ai/DeepSeek-R1</link>
            <guid>42768072</guid>
            <pubDate>Mon, 20 Jan 2025 12:37:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/DeepSeek-R1">https://github.com/deepseek-ai/DeepSeek-R1</a>, See on <a href="https://news.ycombinator.com/item?id=42768072">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">DeepSeek-R1</h2><a id="user-content-deepseek-r1" aria-label="Permalink: DeepSeek-R1" href="#deepseek-r1"></a></p>



<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true"><img src="https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3"></a>
</p>
<hr>
<p><a href="https://www.deepseek.com/" rel="nofollow">
    <img alt="Homepage" src="https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/badge.svg?raw=true">
  </a>
  <a href="https://chat.deepseek.com/" rel="nofollow">
    <img alt="Chat" src="https://camo.githubusercontent.com/a8ed26619b0338e36bfd80f920c9fe96127ff7f12f25a0190e2a94d00a4fa5b9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa496253230436861742d446565705365656b25323052312d3533366166353f636f6c6f723d353336616635266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/🤖%20Chat-DeepSeek%20R1-536af5?color=536af5&amp;logoColor=white">
  </a>
  <a href="https://huggingface.co/deepseek-ai" rel="nofollow">
    <img alt="Hugging Face" src="https://camo.githubusercontent.com/5e3115539d4583e22d65cb89eb1759e767cb9e1d70772923292fcfc80a654be4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e67253230466163652d446565705365656b25323041492d6666633130373f636f6c6f723d666663313037266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&amp;logoColor=white">
  </a>
</p>
<p><a href="https://discord.gg/Tc7c45Zzu5" rel="nofollow">
    <img alt="Discord" src="https://camo.githubusercontent.com/e227481a149714ed5187e4fd0b60b9f736099c2dd2083e6c091e29f1446cbb1a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d446565705365656b25323041492d3732383964613f6c6f676f3d646973636f7264266c6f676f436f6c6f723d776869746526636f6c6f723d373238396461" data-canonical-src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&amp;logoColor=white&amp;color=7289da">
  </a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true">
    <img alt="Wechat" src="https://camo.githubusercontent.com/562efc618da65f0a69bc804395005b8124f5c2ed2eb73441c4e359185cc01467/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5765436861742d446565705365656b25323041492d627269676874677265656e3f6c6f676f3d776563686174266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&amp;logoColor=white">
  </a>
  <a href="https://twitter.com/deepseek_ai" rel="nofollow">
    <img alt="Twitter Follow" src="https://camo.githubusercontent.com/8272710ecd020c821b4f62c1c455efb89e0db4eb179c5f5f971c3c1f69452c54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f547769747465722d646565707365656b5f61692d77686974653f6c6f676f3d78266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&amp;logoColor=white">
  </a>
</p>
<p><a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE-CODE">
    <img alt="Code License" src="https://camo.githubusercontent.com/d8caf1d64169802e8094bcf0013f0b54d3a9547263b4e59eb43531d7d77993e4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f64655f4c6963656e73652d4d49542d6635646535333f26636f6c6f723d663564653533" data-canonical-src="https://img.shields.io/badge/Code_License-MIT-f5de53?&amp;color=f5de53">
  </a>
  <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE-MODEL">
    <img alt="Model License" src="https://camo.githubusercontent.com/edb8b566827851c52a732ee62c71e1c0231f588d5181c5925a518d98f35b4ff4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d6f64656c5f4c6963656e73652d4d6f64656c5f41677265656d656e742d6635646535333f26636f6c6f723d663564653533" data-canonical-src="https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&amp;color=f5de53">
  </a>
</p>
<p dir="auto">
  <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf"><b>Paper Link</b>👁️</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">1. Introduction</h2><a id="user-content-1-introduction" aria-label="Permalink: 1. Introduction" href="#1-introduction"></a></p>
<p dir="auto">We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.
DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.
With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.
However, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,
we introduce DeepSeek-R1, which incorporates cold-start data before RL.
DeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks.
To support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/figures/benchmark.jpg"><img width="80%" src="https://github.com/deepseek-ai/DeepSeek-R1/raw/main/figures/benchmark.jpg"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">2. Model Summary</h2><a id="user-content-2-model-summary" aria-label="Permalink: 2. Model Summary" href="#2-model-summary"></a></p>
<hr>
<p dir="auto"><strong>Post-Training: Large-Scale Reinforcement Learning on the Base Model</strong></p>
<ul dir="auto">
<li>
<p dir="auto">We directly apply reinforcement learning (RL) to the base model without relying on supervised fine-tuning (SFT) as a preliminary step. This approach allows the model to explore chain-of-thought (CoT) for solving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-R1-Zero demonstrates capabilities such as self-verification, reflection, and generating long CoTs, marking a significant milestone for the research community. Notably, it is the first open research to validate that reasoning capabilities of LLMs can be incentivized purely through RL, without the need for SFT. This breakthrough paves the way for future advancements in this area.</p>
</li>
<li>
<p dir="auto">We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL stages aimed at discovering improved reasoning patterns and aligning with human preferences, as well as two SFT stages that serve as the seed for the model's reasoning and non-reasoning capabilities.
We believe the pipeline will benefit the industry by creating better models.</p>
</li>
</ul>
<hr>
<p dir="auto"><strong>Distillation: Smaller Models Can Be Powerful Too</strong></p>
<ul dir="auto">
<li>We demonstrate that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models. The open source DeepSeek-R1, as well as its API, will benefit the research community to distill better smaller models in the future.</li>
<li>Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models that are widely used in the research community. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. We open-source distilled 1.5B, 7B, 8B, 14B, 32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">3. Model Downloads</h2><a id="user-content-3-model-downloads" aria-label="Permalink: 3. Model Downloads" href="#3-model-downloads"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DeepSeek-R1 Models</h3><a id="user-content-deepseek-r1-models" aria-label="Permalink: DeepSeek-R1 Models" href="#deepseek-r1-models"></a></p>
<div dir="auto">
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><strong>Model</strong></th>
<th><strong>#Total Params</strong></th>
<th><strong>#Activated Params</strong></th>
<th><strong>Context Length</strong></th>
<th><strong>Download</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>DeepSeek-R1-Zero</td>
<td>671B</td>
<td>37B</td>
<td>128K</td>
<td><a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero" rel="nofollow">🤗 HuggingFace</a></td>
</tr>
<tr>
<td>DeepSeek-R1</td>
<td>671B</td>
<td>37B</td>
<td>128K</td>
<td><a href="https://huggingface.co/deepseek-ai/DeepSeek-R1" rel="nofollow">🤗 HuggingFace</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</div>
<p dir="auto">DeepSeek-R1-Zero &amp; DeepSeek-R1 are trained based on DeepSeek-V3-Base.
For more details regrading the model architecture, please refer to <a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a> repository.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DeepSeek-R1-Distill Models</h3><a id="user-content-deepseek-r1-distill-models" aria-label="Permalink: DeepSeek-R1-Distill Models" href="#deepseek-r1-distill-models"></a></p>

<p dir="auto">DeepSeek-R1-Distill models are fine-tuned based on open-source models, using samples generated by DeepSeek-R1.
We slightly change their configs and tokenizers. Please use our setting to run these models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">4. Evaluation Results</h2><a id="user-content-4-evaluation-results" aria-label="Permalink: 4. Evaluation Results" href="#4-evaluation-results"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DeepSeek-R1-Evaluation</h3><a id="user-content-deepseek-r1-evaluation" aria-label="Permalink: DeepSeek-R1-Evaluation" href="#deepseek-r1-evaluation"></a></p>
<p dir="auto">For all our models, the maximum generation length is set to 32,768 tokens. For benchmarks requiring sampling, we use a temperature of <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="570d04263f45e653820916ae742049fc">$0.6$</math-renderer>, a top-p value of <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="570d04263f45e653820916ae742049fc">$0.95$</math-renderer>, and generate 64 responses per query to estimate pass@1.</p>
<div dir="auto">
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Category</th>
<th>Benchmark (Metric)</th>
<th>Claude-3.5-Sonnet-1022</th>
<th>GPT-4o 0513</th>
<th>DeepSeek V3</th>
<th>OpenAI o1-mini</th>
<th>OpenAI o1-1217</th>
<th>DeepSeek R1</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Architecture</td>
<td>-</td>
<td>-</td>
<td>MoE</td>
<td>-</td>
<td>-</td>
<td>MoE</td>
</tr>
<tr>
<td></td>
<td># Activated Params</td>
<td>-</td>
<td>-</td>
<td>37B</td>
<td>-</td>
<td>-</td>
<td>37B</td>
</tr>
<tr>
<td></td>
<td># Total Params</td>
<td>-</td>
<td>-</td>
<td>671B</td>
<td>-</td>
<td>-</td>
<td>671B</td>
</tr>
<tr>
<td>English</td>
<td>MMLU (Pass@1)</td>
<td>88.3</td>
<td>87.2</td>
<td>88.5</td>
<td>85.2</td>
<td><strong>91.8</strong></td>
<td>90.8</td>
</tr>
<tr>
<td></td>
<td>MMLU-Redux (EM)</td>
<td>88.9</td>
<td>88.0</td>
<td>89.1</td>
<td>86.7</td>
<td>-</td>
<td><strong>92.9</strong></td>
</tr>
<tr>
<td></td>
<td>MMLU-Pro (EM)</td>
<td>78.0</td>
<td>72.6</td>
<td>75.9</td>
<td>80.3</td>
<td>-</td>
<td><strong>84.0</strong></td>
</tr>
<tr>
<td></td>
<td>DROP (3-shot F1)</td>
<td>88.3</td>
<td>83.7</td>
<td>91.6</td>
<td>83.9</td>
<td>90.2</td>
<td><strong>92.2</strong></td>
</tr>
<tr>
<td></td>
<td>IF-Eval (Prompt Strict)</td>
<td><strong>86.5</strong></td>
<td>84.3</td>
<td>86.1</td>
<td>84.8</td>
<td>-</td>
<td>83.3</td>
</tr>
<tr>
<td></td>
<td>GPQA-Diamond (Pass@1)</td>
<td>65.0</td>
<td>49.9</td>
<td>59.1</td>
<td>60.0</td>
<td><strong>75.7</strong></td>
<td>71.5</td>
</tr>
<tr>
<td></td>
<td>SimpleQA (Correct)</td>
<td>28.4</td>
<td>38.2</td>
<td>24.9</td>
<td>7.0</td>
<td><strong>47.0</strong></td>
<td>30.1</td>
</tr>
<tr>
<td></td>
<td>FRAMES (Acc.)</td>
<td>72.5</td>
<td>80.5</td>
<td>73.3</td>
<td>76.9</td>
<td>-</td>
<td><strong>82.5</strong></td>
</tr>
<tr>
<td></td>
<td>AlpacaEval2.0 (LC-winrate)</td>
<td>52.0</td>
<td>51.1</td>
<td>70.0</td>
<td>57.8</td>
<td>-</td>
<td><strong>87.6</strong></td>
</tr>
<tr>
<td></td>
<td>ArenaHard (GPT-4-1106)</td>
<td>85.2</td>
<td>80.4</td>
<td>85.5</td>
<td>92.0</td>
<td>-</td>
<td><strong>92.3</strong></td>
</tr>
<tr>
<td>Code</td>
<td>LiveCodeBench (Pass@1-COT)</td>
<td>33.8</td>
<td>34.2</td>
<td>-</td>
<td>53.8</td>
<td>63.4</td>
<td><strong>65.9</strong></td>
</tr>
<tr>
<td></td>
<td>Codeforces (Percentile)</td>
<td>20.3</td>
<td>23.6</td>
<td>58.7</td>
<td>93.4</td>
<td><strong>96.6</strong></td>
<td>96.3</td>
</tr>
<tr>
<td></td>
<td>Codeforces (Rating)</td>
<td>717</td>
<td>759</td>
<td>1134</td>
<td>1820</td>
<td><strong>2061</strong></td>
<td>2029</td>
</tr>
<tr>
<td></td>
<td>SWE Verified (Resolved)</td>
<td><strong>50.8</strong></td>
<td>38.8</td>
<td>42.0</td>
<td>41.6</td>
<td>48.9</td>
<td>49.2</td>
</tr>
<tr>
<td></td>
<td>Aider-Polyglot (Acc.)</td>
<td>45.3</td>
<td>16.0</td>
<td>49.6</td>
<td>32.9</td>
<td><strong>61.7</strong></td>
<td>53.3</td>
</tr>
<tr>
<td>Math</td>
<td>AIME 2024 (Pass@1)</td>
<td>16.0</td>
<td>9.3</td>
<td>39.2</td>
<td>63.6</td>
<td>79.2</td>
<td><strong>79.8</strong></td>
</tr>
<tr>
<td></td>
<td>MATH-500 (Pass@1)</td>
<td>78.3</td>
<td>74.6</td>
<td>90.2</td>
<td>90.0</td>
<td>96.4</td>
<td><strong>97.3</strong></td>
</tr>
<tr>
<td></td>
<td>CNMO 2024 (Pass@1)</td>
<td>13.1</td>
<td>10.8</td>
<td>43.2</td>
<td>67.6</td>
<td>-</td>
<td><strong>78.8</strong></td>
</tr>
<tr>
<td>Chinese</td>
<td>CLUEWSC (EM)</td>
<td>85.4</td>
<td>87.9</td>
<td>90.9</td>
<td>89.9</td>
<td>-</td>
<td><strong>92.8</strong></td>
</tr>
<tr>
<td></td>
<td>C-Eval (EM)</td>
<td>76.7</td>
<td>76.0</td>
<td>86.5</td>
<td>68.9</td>
<td>-</td>
<td><strong>91.8</strong></td>
</tr>
<tr>
<td></td>
<td>C-SimpleQA (Correct)</td>
<td>55.4</td>
<td>58.7</td>
<td><strong>68.0</strong></td>
<td>40.3</td>
<td>-</td>
<td>63.7</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Distilled Model Evaluation</h3><a id="user-content-distilled-model-evaluation" aria-label="Permalink: Distilled Model Evaluation" href="#distilled-model-evaluation"></a></p>
<div dir="auto">
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>AIME 2024 pass@1</th>
<th>AIME 2024 cons@64</th>
<th>MATH-500 pass@1</th>
<th>GPQA Diamond pass@1</th>
<th>LiveCodeBench pass@1</th>
<th>CodeForces rating</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-4o-0513</td>
<td>9.3</td>
<td>13.4</td>
<td>74.6</td>
<td>49.9</td>
<td>32.9</td>
<td>759</td>
</tr>
<tr>
<td>Claude-3.5-Sonnet-1022</td>
<td>16.0</td>
<td>26.7</td>
<td>78.3</td>
<td>65.0</td>
<td>38.9</td>
<td>717</td>
</tr>
<tr>
<td>o1-mini</td>
<td>63.6</td>
<td>80.0</td>
<td>90.0</td>
<td>60.0</td>
<td>53.8</td>
<td><strong>1820</strong></td>
</tr>
<tr>
<td>QwQ-32B-Preview</td>
<td>44.0</td>
<td>60.0</td>
<td>90.6</td>
<td>54.5</td>
<td>41.9</td>
<td>1316</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Qwen-1.5B</td>
<td>28.9</td>
<td>52.7</td>
<td>83.9</td>
<td>33.8</td>
<td>16.9</td>
<td>954</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Qwen-7B</td>
<td>55.5</td>
<td>83.3</td>
<td>92.8</td>
<td>49.1</td>
<td>37.6</td>
<td>1189</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Qwen-14B</td>
<td>69.7</td>
<td>80.0</td>
<td>93.9</td>
<td>59.1</td>
<td>53.1</td>
<td>1481</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Qwen-32B</td>
<td><strong>72.6</strong></td>
<td>83.3</td>
<td>94.3</td>
<td>62.1</td>
<td>57.2</td>
<td>1691</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Llama-8B</td>
<td>50.4</td>
<td>80.0</td>
<td>89.1</td>
<td>49.0</td>
<td>39.6</td>
<td>1205</td>
</tr>
<tr>
<td>DeepSeek-R1-Distill-Llama-70B</td>
<td>70.0</td>
<td><strong>86.7</strong></td>
<td><strong>94.5</strong></td>
<td><strong>65.2</strong></td>
<td><strong>57.5</strong></td>
<td>1633</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">5. Chat Website &amp; API Platform</h2><a id="user-content-5-chat-website--api-platform" aria-label="Permalink: 5. Chat Website &amp; API Platform" href="#5-chat-website--api-platform"></a></p>
<p dir="auto">You can chat with DeepSeek-R1 on DeepSeek's official website: <a href="https://chat.deepseek.com/" rel="nofollow">chat.deepseek.com</a>, and switch on the button "DeepThink"</p>
<p dir="auto">We also provide OpenAI-Compatible API at DeepSeek Platform: <a href="https://platform.deepseek.com/" rel="nofollow">platform.deepseek.com</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">6. How to Run Locally</h2><a id="user-content-6-how-to-run-locally" aria-label="Permalink: 6. How to Run Locally" href="#6-how-to-run-locally"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DeepSeek-R1 Models</h3><a id="user-content-deepseek-r1-models-1" aria-label="Permalink: DeepSeek-R1 Models" href="#deepseek-r1-models-1"></a></p>
<p dir="auto">Please visit <a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a> repo for more information about running DeepSeek-R1 locally.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DeepSeek-R1-Distill Models</h3><a id="user-content-deepseek-r1-distill-models-1" aria-label="Permalink: DeepSeek-R1-Distill Models" href="#deepseek-r1-distill-models-1"></a></p>
<p dir="auto">DeepSeek-R1-Distill models can be utilized in the same manner as Qwen or Llama models.</p>
<p dir="auto">For instance, you can easily start a service using <a href="https://github.com/vllm-project/vllm">vLLM</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --tensor-parallel-size 2 --max-model-len 32768 --enforce-eager"><pre>vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --tensor-parallel-size 2 --max-model-len 32768 --enforce-eager</pre></div>
<p dir="auto">You can also easily start a service using <a href="https://github.com/sgl-project/sglang">SGLang</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --trust-remote-code --tp 2"><pre>python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --trust-remote-code --tp 2</pre></div>
<p dir="auto"><strong>NOTE: We recommend setting an appropriate temperature (between 0.5 and 0.7) when running these models, otherwise you may encounter issues with endless repetition or incoherent output.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">7. License</h2><a id="user-content-7-license" aria-label="Permalink: 7. License" href="#7-license"></a></p>
<p dir="auto">This code repository and the model weights are licensed under the <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE">MIT License</a>.
DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that:</p>
<ul dir="auto">
<li>DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Qwen-14B and DeepSeek-R1-Distill-Qwen-32B are derived from <a href="https://github.com/QwenLM/Qwen2.5">Qwen-2.5 series</a>, which are originally licensed under <a href="https://huggingface.co/Qwen/Qwen2.5-1.5B/blob/main/LICENSE" rel="nofollow">Apache 2.0 License</a>, and now finetuned with 800k samples curated with DeepSeek-R1.</li>
<li>DeepSeek-R1-Distill-Llama-8B is derived from Llama3.1-8B-Base and is originally licensed under <a href="https://huggingface.co/meta-llama/Llama-3.1-8B/blob/main/LICENSE" rel="nofollow">llama3.1 license</a>.</li>
<li>DeepSeek-R1-Distill-Llama-70B is derived from Llama3.3-70B-Instruct and is originally licensed under <a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct/blob/main/LICENSE" rel="nofollow">llama3.3 license</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">8. Citation</h2><a id="user-content-8-citation" aria-label="Permalink: 8. Citation" href="#8-citation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">9. Contact</h2><a id="user-content-9-contact" aria-label="Permalink: 9. Contact" href="#9-contact"></a></p>
<p dir="auto">If you have any questions, please raise an issue or contact us at <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/service@deepseek.com">service@deepseek.com</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Celestial Navigation for Drones (143 pts)]]></title>
            <link>https://www.mdpi.com/2504-446X/8/11/652</link>
            <guid>42767797</guid>
            <pubDate>Mon, 20 Jan 2025 12:02:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mdpi.com/2504-446X/8/11/652">https://www.mdpi.com/2504-446X/8/11/652</a>, See on <a href="https://news.ycombinator.com/item?id=42767797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <section id="sec1-drones-08-00652" type="intro"><h2 data-nested="1">  1. Introduction</h2><p>Celestial navigation is among the oldest forms of navigation in aviation [<a href="#B1-drones-08-00652">1</a>]. The abundance of salient stars, known to high levels of precision, make them a useful cue for navigators when operating in clear conditions. The elevation of a star above the horizon would be measured, yielding a ‘line of position’. This process was repeated with different stars to fully determine the navigator’s position. The advancement of imaging and computing hardware saw the integration of autonomous star trackers into manned aircraft, as seen, for example, in Lockheed’s SR-71. These autonomous star trackers consisted of a mechanically stabilized telescope and inertial sensors, whose observations, when combined, could produce position estimates to within 0.3 nautical miles for up to 10 h of operation. While accurate, these sensors tended to be both heavy and voluminous, making them undesirable for more modern Size, Weight and Power Constrained (SWAP-C) applications.</p><p>By the advent of the 21st century, Global Positioning System (GPS) had become ubiquitous in avionic navigation. The introduction of GPS caused the interest in celestial navigation to wither due to its relative inaccuracy. Consequently, celestial navigation is primarily seen only in space-based systems, whose orientation must be known to high levels of precision. Nonetheless, celestial navigation was identified as a desirable alternative to GPS [<a href="#B2-drones-08-00652">2</a>], primarily due its robustness against potential jamming. Critically, few GPS-denied alternatives exist that are capable of using passive sensors to estimate global position at night or over the ocean. For this reason, celestial navigation remains an important topic of research. The methodology presented in this paper demonstrates how celestial navigation may be utilized on low cost Uncrewed Aerial Vehicles (UAVs) that lack the precision of an expensive Attitude and Heading Reference System (AHRS).</p><p>Existing works on strapdown celestial navigation tend to be focused on simulation. One such example derives the equations for a celestial camera mounted directly to a strapdown inertial system [<a href="#B3-drones-08-00652">3</a>]. Similarly, a more recent study identified that a strapdown celestial system is contingent on the initial conditions and will tend to diverge over time [<a href="#B4-drones-08-00652">4</a>]. While some promise has been shown in the utility of such systems [<a href="#B5-drones-08-00652">5</a>], the primary problem with the navigation method is that the strapdown system must estimate the camera biases and delineate these from true position error. This is difficult to achieve, as camera bias is perceptually identical to motion over the Earth. Utilizing the celestial system as a highly accurate attitude reference tends to produce useful results in high altitude aircraft [<a href="#B6-drones-08-00652">6</a>] and spacecraft [<a href="#B7-drones-08-00652">7</a>,<a href="#B8-drones-08-00652">8</a>,<a href="#B9-drones-08-00652">9</a>,<a href="#B10-drones-08-00652">10</a>,<a href="#B11-drones-08-00652">11</a>]; however, as a modular solution, the celestial system must have a direct input to the AHRS to improve the inertial position estimate. Alternatively, it has been theoretically shown that atmospheric refraction can be observed to resolve positions [<a href="#B12-drones-08-00652">12</a>]. This technique relies on the observation of the atmospheric refraction of starlight, which occurs most significantly closest to the horizon. The angle of refraction tends to be minimal and difficult to observe, requiring a highly stabilized viewing platform.</p><p>There are a number of reasons why celestial navigation has not become ubiquitous in aviation and particularly in UAV applications. Firstly, there is significant complexity in designing and configuring the hardware. A celestial system must typically be gimballed to within arcminutes of precision, such that a narrow field of a view sensor may lock onto a single star. This could be achieved through gyroscopic stabilization; however, the inclusion of multiple kilograms of stabilization hardware is rarely justified to achieve a navigation outcome with significantly worse performance than GPS. Secondly, celestial systems require a clear view of the night sky, which places practical limitations on their use. Thirdly, alongside the mechanical complexity, there exists a significant computational complexity required to integrate a celestial payload into an existing system. A star database must be maintained, image processing algorithms must be implemented to identify and track stars, and the system may or may not require an interface for the existing AHRS to time and orientate data. These reasons have overshadowed the benefit of having an additional GPS-denied modality for navigation available to an aircraft.</p><p>Previous research has addressed the latter of these points, demonstrating that modern computer vision libraries and embedded hardware are capable of handling the computational requirements of celestial navigation [<a href="#B13-drones-08-00652">13</a>,<a href="#B14-drones-08-00652">14</a>]. We address the first of these points in this study by demonstrating the use of a strapdown celestial system for navigation. Contrary to the stabilized alternative, a strapdown celestial system contains low mechanical complexity, is lightweight, and can be implemented at a low cost. The primary trade-off is in the accuracy of the navigation system. While high levels of accuracy are theoretically achievable (depending on the quality of the optical system), the limiting factor with strapdown celestial navigation is the accuracy of the AHRS. As a rough guide, an attitude error of 1° correlates with a position error of approximately 100&nbsp;km. It is not uncommon for low cost autopilots (such as the Cube Orange running ArduPlane v4.5 firmware) to produce attitude errors in the vicinity of multiple degrees. Such biases would lead to positional offsets that are far too significant for use in any real application.</p><p>We address this shortcoming by demonstrating how a simple orbital motion can significantly improve a celestial position estimate. This technique has been used on the ground to correct for boresight errors [<a href="#B15-drones-08-00652">15</a>], and we demonstrate through experimentation that a similar technique may be used on aircraft to correct for attitude errors. The principle behind this maneuver is that a misaligned boresight will trace a circle about the true boresight if a full azimuthal revolution is performed. The misalignment presents itself in the navigation frame as a circular error in latitude and longitude, enabling the averaging of the results to attain an improved position estimate. We demonstrate that this technique is effective even when the camera is misaligned with the AHRS, offering a reliable method for estimating the position to within 4&nbsp;km from an unknown state. While lacking precision, this method of localization is absolute, cheap to implement, and relatively lightweight.</p><p>To our knowledge, no such technique currently exists in the literature. The methods proposed here are intended to demonstrate the application of strapdown celestial navigation on a fixed-wing drone platform, while addressing the key practical difficulties in doing so. Existing works are iterative, relying on the integration of celestial measurements with inertial measurements using a filter such as an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF). This research demonstrates that a strapdown system can be treated as a stand-alone, modular addition to an inertial system, such that the measurements do not need to be integrated into the filter. Independence from an inertial filter enables the celestial system to produce true global position measurements that are not affected by initial conditions. Provided the use of an accurate clock, the results presented in this paper will not degrade over time.</p><p>The remainder of this paper addresses the theory, implementation, and results of the proposed method. We outline the equations for observing stars and estimating global positions in <a href="#sec2-drones-08-00652">Section 2</a>, we describe the methdology used in star detection/tracking and the experimental configuration, we explicitly define the equations for computing the mean position in <a href="#sec3-drones-08-00652">Section 3</a>, we present the results from the flight trial and simulation in <a href="#sec4-drones-08-00652">Section 4</a>, we discuss the results in <a href="#sec5-drones-08-00652">Section 5</a>, and we conclude in <a href="#sec6-drones-08-00652">Section 6</a>.</p></section><section id="sec2-drones-08-00652" type=""><h2 data-nested="1">  2. Theory</h2><section id="sec2dot1-drones-08-00652" type=""><h4 data-nested="2">  2.1. Star Observation</h4><div><p>An observer may estimate their position with knowledge of the current sidereal time and direction vectors to three or more stars in the local North East Down (NED) frame. A camera system is mounted relative to the body frame of the aircraft, with Direction Cosine Matrix (DCM) </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>b</mi>
      <mo>/</mo>
      <mi>c</mi>
    </mrow>
  </msub>
</semantics></math><p> describing the orientation of the camera with respect to the aircraft. Given an aircraft with the orientation described by the DCM </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p>, an observation </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">X</mi>
    <mi>c</mi>
  </msup>
</semantics></math><p> in the camera frame may be transformed to the local NED frame by the following equation:</p><div id="FD1-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>l</mi>
    </msup>
    <mo>=</mo>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>l</mi>
        <mo>/</mo>
        <mi>b</mi>
      </mrow>
    </msub>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>b</mi>
        <mo>/</mo>
        <mi>c</mi>
      </mrow>
    </msub>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>c</mi>
    </msup>
  </mrow>
</semantics></math>
      </p>
      <p><label>(1)</label>
      </p>
    </div></div><div><p>Multiple stars are observed simultaneously through the imaging system. A calibrated camera may be described by the pinhole projection model, such that
        </p><p>
        where </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">x</mi>
    <mi>p</mi>
  </msup>
</semantics></math><p> contains the homogeneous pixel coordinates of the projected star, </p><math display="inline"><semantics>
  <mi mathvariant="bold">K</mi>
</semantics></math><p> is the camera intrinsic matrix, and </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">X</mi>
    <mi>c</mi>
  </msup>
</semantics></math><p> is the direction vector of the star in the camera coordinate frame. Consequently, with knowledge of the camera intrinsic matrix, given an observation </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">x</mi>
    <mi>p</mi>
  </msup>
</semantics></math><p>, the vector </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">X</mi>
    <mi>c</mi>
  </msup>
</semantics></math><p> may be computed as follows:</p><p>
        where the scale factor </p><math display="inline"><semantics>
  <mi>α</mi>
</semantics></math><p> may be computed with the knowledge that </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">X</mi>
    <mi>c</mi>
  </msup>
</semantics></math><p> is unitary. Given that </p><math display="inline"><semantics>
  <mrow>
    <mrow>
      <mo>|</mo>
    </mrow>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>c</mi>
    </msup>
    <mrow>
      <mo>|</mo>
      <mo>&nbsp;</mo>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
  </mrow>
</semantics></math><p>, it follows that </p><math display="inline"><semantics>
  <mrow>
    <mrow>
      <mi>α</mi>
      <mo>|</mo>
    </mrow>
    <msup>
      <mi mathvariant="bold">K</mi>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <msup>
      <mi mathvariant="bold">x</mi>
      <mi>p</mi>
    </msup>
    <mrow>
      <mo>|</mo>
      <mo>&nbsp;</mo>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
  </mrow>
</semantics></math><p>. Therefore, </p><math display="inline"><semantics>
  <mi>α</mi>
</semantics></math><p> can be calculated as follows:</p></div></section><section id="sec2dot2-drones-08-00652" type=""><h4 data-nested="2">  2.2. Position Estimation</h4><div><p>The global position may be calculated using the zenith-angle, </p><math display="inline"><semantics>
  <mi>ζ</mi>
</semantics></math><p>, of stars. Following the methodology presented by [<a href="#B16-drones-08-00652">16</a>], each measurement </p><math display="inline"><semantics>
  <mi>ζ</mi>
</semantics></math><p> generates a plane that intersects with the terrestrial sphere, yielding a circle on which the observer may be located. Two observations generate a line, of which only two points on this line intersect with the terrestrial sphere. This case is depicted in <a href="#drones-08-00652-f001">Figure 1</a>. Three observations precisely define the location of the observer, and more than three observations can create an over-constrained system. We may utilize redundant measurements by estimating the least-squares approximation from three or more star observations.</p></div><div><p>Given <span>n</span> stars, with right ascension </p><math display="inline"><semantics>
  <mi>α</mi>
</semantics></math><p> and declination </p><math display="inline"><semantics>
  <mi>δ</mi>
</semantics></math><p>, observed at a zenith angle </p><math display="inline"><semantics>
  <mi>ζ</mi>
</semantics></math><p>, we may define <span>n</span> planes within the geographic coordinate system. If we define </p><math display="inline"><semantics>
  <mi>λ</mi>
</semantics></math><p> as the longitude of an observer whose zenith is directed towards the star, which can be expressed as the difference between the star’s right ascension and the current Greenwich hour angle of Aries, </p><math display="inline"><semantics>
  <mrow>
    <mi>λ</mi>
    <mo>=</mo>
    <mi>α</mi>
    <mo>−</mo>
    <mi>G</mi>
    <mi>H</mi>
    <mi>A</mi>
    <mo>Γ</mo>
  </mrow>
</semantics></math><p>, then it can be seen that the equation of a plane whose normal vector is directed towards the star is given by
        </p><div id="FD5-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi>a</mi>
    <mi>x</mi>
    <mo>+</mo>
    <mi>b</mi>
    <mi>y</mi>
    <mo>+</mo>
    <mi>c</mi>
    <mi>z</mi>
    <mo>−</mo>
    <mi>p</mi>
    <mo>=</mo>
    <mn>0</mn>
  </mrow>
</semantics></math>
      </p>
      <p><label>(5)</label>
      </p>
    </div><p>
        where
        </p><div id="FD6-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mtable displaystyle="true">
    <mtr>
      <mtd columnalign="right">
        <mi>a</mi>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mo>=</mo>
          <mo form="prefix">cos</mo>
          <mi>λ</mi>
          <mo form="prefix">cos</mo>
          <mi>δ</mi>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd columnalign="right">
        <mi>b</mi>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mo>=</mo>
          <mo form="prefix">sin</mo>
          <mi>λ</mi>
          <mo form="prefix">cos</mo>
          <mi>δ</mi>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd columnalign="right">
        <mi>c</mi>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mo>=</mo>
          <mo form="prefix">sin</mo>
          <mi>δ</mi>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd columnalign="right">
        <mi>p</mi>
      </mtd>
      <mtd columnalign="left">
        <mrow>
          <mo>=</mo>
          <mo form="prefix">cos</mo>
          <mi>ζ</mi>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</semantics></math>
      </p>
      <p><label>(6)</label>
      </p>
    </div></div><div><p>Therefore, given a minimum of three star observations, we can build matrices </p><math display="inline"><semantics>
  <mi mathvariant="bold">A</mi>
</semantics></math><p> and </p><math display="inline"><semantics>
  <mi mathvariant="bold">p</mi>
</semantics></math><p> to formulate a least-squares approximation of the intersection of these planes. Vertically stacking each equation yields
        </p><p>
        where
        </p><div id="">
      <p>
        <math display="block"><semantics>
  <mtable displaystyle="true">
    <mtr>
      <mtd>
        <mrow>
          <mi mathvariant="bold">A</mi>
          <mo>=</mo>
          <mfenced open="[" close="]">
            <mtable>
              <mtr>
                <mtd>
                  <msub>
                    <mi>a</mi>
                    <mn>1</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>b</mi>
                    <mn>1</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>c</mi>
                    <mn>1</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>a</mi>
                    <mn>2</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>b</mi>
                    <mn>2</mn>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>c</mi>
                    <mn>2</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mo>⋮</mo>
                </mtd>
                <mtd>
                  <mo>⋮</mo>
                </mtd>
                <mtd>
                  <mo>⋮</mo>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>a</mi>
                    <mi>n</mi>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>b</mi>
                    <mi>n</mi>
                  </msub>
                </mtd>
                <mtd>
                  <msub>
                    <mi>c</mi>
                    <mi>n</mi>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
          </mfenced>
          <mo>,</mo>
          <mspace width="4pt"></mspace>
          <mi mathvariant="bold">x</mi>
          <mo>=</mo>
          <mfenced open="[" close="]">
            <mtable>
              <mtr>
                <mtd>
                  <mi>x</mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>y</mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>z</mi>
                </mtd>
              </mtr>
            </mtable>
          </mfenced>
          <mo>,</mo>
          <mspace width="4pt"></mspace>
          <mi mathvariant="bold">p</mi>
          <mo>=</mo>
          <mfenced open="[" close="]">
            <mtable>
              <mtr>
                <mtd>
                  <msub>
                    <mi>p</mi>
                    <mn>1</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>p</mi>
                    <mn>2</mn>
                  </msub>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mo>⋮</mo>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msub>
                    <mi>p</mi>
                    <mi>n</mi>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
          </mfenced>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</semantics></math>
      </p>
      
    </div></div><div><p>We apply the standard least-squares solution to find the point of intersection of the planes, </p><math display="inline"><semantics>
  <mi mathvariant="bold">x</mi>
</semantics></math><p>, as follows:</p><div id="FD8-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi mathvariant="bold">x</mi>
    <mo>=</mo>
    <msup>
      <mrow>
        <mo>(</mo>
        <msup>
          <mi mathvariant="bold">A</mi>
          <mi>T</mi>
        </msup>
        <mi mathvariant="bold">A</mi>
        <mo>)</mo>
      </mrow>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <msup>
      <mi mathvariant="bold">A</mi>
      <mi>T</mi>
    </msup>
    <mi mathvariant="bold">p</mi>
  </mrow>
</semantics></math>
      </p>
      <p><label>(8)</label>
      </p>
    </div></div><div><p>Putting </p><math display="inline"><semantics>
  <mi mathvariant="bold">x</mi>
</semantics></math><p> back into geographical coordinates, we find the latitude and longitude which best fits the star observations:</p><div id="FD9-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mtable displaystyle="true">
    <mtr>
      <mtd>
        <mrow>
          <mi>ϕ</mi>
          <mo>=</mo>
          <msup>
            <mo form="prefix">tan</mo>
            <mrow>
              <mo>−</mo>
              <mn>1</mn>
            </mrow>
          </msup>
          <mfenced open="(" close=")">
            <mstyle scriptlevel="0" displaystyle="true">
              <mfrac>
                <mi>z</mi>
                <msqrt>
                  <mrow>
                    <msup>
                      <mi>x</mi>
                      <mn>2</mn>
                    </msup>
                    <mo>+</mo>
                    <msup>
                      <mi>y</mi>
                      <mn>2</mn>
                    </msup>
                  </mrow>
                </msqrt>
              </mfrac>
            </mstyle>
          </mfenced>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</semantics></math>
      </p>
      <p><label>(9)</label>
      </p>
    </div></div><p>This value for the latitude and longitude minimizes the squared error in the position vectors. This will be used in <a href="#sec3-drones-08-00652">Section 3</a> for converting many observations into a single position estimate.</p></section></section><section id="sec3-drones-08-00652" type="methods"><h2 data-nested="1">  3. Methods</h2><div><p>A modular celestial navigation system should be mounted rigidly with respect to the AHRS. The orientation of the aircraft, </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p>, is provided by the autopilot. The orientation of the camera, </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>b</mi>
      <mo>/</mo>
      <mi>c</mi>
    </mrow>
  </msub>
</semantics></math><p>, is unknown and must be calibrated to obtain accurate positional information. For the purposes of this study, we assume that the precise orientation of the camera remains unknown, and we consequently accept that the individual position estimates will be erroneous. It will be shown later that this misalignment may be overcome through the use of averaging. This is particularly useful given that the camera itself may be mounted separately from the autopilot, thus being subjected to factors such as vibration, aerodynamic loading, or changes in AHRS biases, which cause the relative orientation between the AHRS and the camera to change over time.</p></div><section id="sec3dot1-drones-08-00652" type=""><h4 data-nested="2">  3.1. Star Detection and Tracking</h4><div><p>Stars are detected within an image using a basic binary thresholding operation. Given a mean pixel value within the frame, </p><math display="inline"><semantics>
  <mi>μ</mi>
</semantics></math><p>, and standard deviation, </p><math display="inline"><semantics>
  <mi>σ</mi>
</semantics></math><p>, a binary threshold is set at </p><math display="inline"><semantics>
  <mrow>
    <mi>μ</mi>
    <mo>+</mo>
    <mn>5</mn>
    <mi>σ</mi>
  </mrow>
</semantics></math><p>, as advised in [<a href="#B17-drones-08-00652">17</a>]. The contours are extracted, and an agglomerative clustering algorithm is applied to cluster redundant detections.</p></div><div><p>Once detected, a standard Kalman filter is used to track individual stars between frames. Each star is defined by its state vector:</p><p>
        and a constant sized bounding box. The states </p><math display="inline"><semantics>
  <mrow>
    <mi>u</mi>
    <mo>,</mo>
    <mi>v</mi>
    <mo>,</mo>
    <mover accent="true">
      <mi>u</mi>
      <mo>˙</mo>
    </mover>
    <mo>,</mo>
    <mi>and</mi>
    <mover accent="true">
      <mi>v</mi>
      <mo>˙</mo>
    </mover>
  </mrow>
</semantics></math><p> describe the x position, y position, x velocity, and y velocity of the star on the image plane, respectively. The position of the star is taken to be the subpixel maxima, computed as a weighted average of the </p><math display="inline"><semantics>
  <mrow>
    <mn>3</mn>
    <mo>×</mo>
    <mn>3</mn>
  </mrow>
</semantics></math><p> Region of Interest (ROI) centered on the peak pixel value, as described by [<a href="#B18-drones-08-00652">18</a>]
        </p><div id="FD12-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mrow>
      <mo>(</mo>
      <mi>u</mi>
      <mo>,</mo>
      <mi>v</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mfenced separators="" open="(" close=")">
      <mstyle scriptlevel="0" displaystyle="true">
        <mfrac>
          <mrow>
            <msub>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>I</mi>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>u</mi>
              <mi>i</mi>
            </msub>
          </mrow>
          <mrow>
            <msub>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>I</mi>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
          </mrow>
        </mfrac>
      </mstyle>
      <mo>,</mo>
      <mstyle scriptlevel="0" displaystyle="true">
        <mfrac>
          <mrow>
            <msub>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>I</mi>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>v</mi>
              <mi>j</mi>
            </msub>
          </mrow>
          <mrow>
            <msub>
              <mo>∑</mo>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>I</mi>
              <mrow>
                <mi>i</mi>
                <mo>,</mo>
                <mi>j</mi>
              </mrow>
            </msub>
          </mrow>
        </mfrac>
      </mstyle>
    </mfenced>
  </mrow>
</semantics></math>
      </p>
      <p><label>(12)</label>
      </p>
    </div></div><div><p>The state transition matrix </p><math display="inline"><semantics>
  <mi mathvariant="bold">F</mi>
</semantics></math><p> is defined assuming a constant velocity as follows:</p><div id="FD13-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi mathvariant="bold">F</mi>
    <mo>=</mo>
    <mfenced open="[" close="]">
      <mtable>
        <mtr>
          <mtd>
            <mn>1</mn>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mrow>
              <mo>Δ</mo>
              <mi>t</mi>
            </mrow>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mn>1</mn>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mrow>
              <mo>Δ</mo>
              <mi>t</mi>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mn>1</mn>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mn>0</mn>
          </mtd>
          <mtd>
            <mn>1</mn>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
  </mrow>
</semantics></math>
      </p>
      <p><label>(13)</label>
      </p>
    </div></div><div><p>The position and velocity of the stars are observed directly; therefore, the observation matrix </p><math display="inline"><semantics>
  <mi mathvariant="bold">H</mi>
</semantics></math><p> is defined as the </p><math display="inline"><semantics>
  <mrow>
    <mn>4</mn>
    <mo>×</mo>
    <mn>4</mn>
  </mrow>
</semantics></math><p> identity, such that the observation equation is simply given&nbsp;by
        </p></div><div><p>Following the standard Kalman filter equations, the a priori state and covariance estimates are computed:</p><div id="FD16-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mover accent="true">
        <mi mathvariant="bold">P</mi>
        <mo>^</mo>
      </mover>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
    <mo>=</mo>
    <mi mathvariant="bold">F</mi>
    <msub>
      <mi mathvariant="bold">P</mi>
      <mi>k</mi>
    </msub>
    <msup>
      <mi mathvariant="bold">F</mi>
      <mi>T</mi>
    </msup>
    <mo>+</mo>
    <mi mathvariant="bold">Q</mi>
  </mrow>
</semantics></math>
      </p>
      <p><label>(16)</label>
      </p>
    </div><p>
        for the covariance matrix </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">P</mi>
    <mi>k</mi>
  </msub>
</semantics></math><p> with process noise </p><math display="inline"><semantics>
  <mi mathvariant="bold">Q</mi>
</semantics></math><p>. The innovation is calculated as follows:</p><div id="FD17-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">y</mi>
      <mi>k</mi>
    </msub>
    <mo>=</mo>
    <msub>
      <mi mathvariant="bold">z</mi>
      <mi>k</mi>
    </msub>
    <mo>−</mo>
    <msub>
      <mover accent="true">
        <mi mathvariant="bold">x</mi>
        <mo>^</mo>
      </mover>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
  </mrow>
</semantics></math>
      </p>
      <p><label>(17)</label>
      </p>
    </div><p>
        with covariance, </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">S</mi>
    <mi mathvariant="bold">k</mi>
  </msub>
</semantics></math><p>, given by
        </p><div id="FD18-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">S</mi>
      <mi>k</mi>
    </msub>
    <mo>=</mo>
    <msub>
      <mover accent="true">
        <mi mathvariant="bold">P</mi>
        <mo>^</mo>
      </mover>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
    <mo>+</mo>
    <msub>
      <mi mathvariant="bold">R</mi>
      <mi>k</mi>
    </msub>
  </mrow>
</semantics></math>
      </p>
      <p><label>(18)</label>
      </p>
    </div><p>
        where </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">R</mi>
    <mi>k</mi>
  </msub>
</semantics></math><p> is the measurement noise. The Kalman gain is computed as follows:</p><div id="FD19-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">K</mi>
      <mi>k</mi>
    </msub>
    <mo>=</mo>
    <msub>
      <mover accent="true">
        <mi mathvariant="bold">P</mi>
        <mo>^</mo>
      </mover>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
    <msubsup>
      <mi mathvariant="bold">S</mi>
      <mi>k</mi>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msubsup>
  </mrow>
</semantics></math>
      </p>
      <p><label>(19)</label>
      </p>
    </div><p>
        and the posterior updates are applied to the a priori estimates:</p><div id="FD20-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">x</mi>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
    <mo>=</mo>
    <msub>
      <mover accent="true">
        <mi mathvariant="bold">x</mi>
        <mo>^</mo>
      </mover>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
    <mo>+</mo>
    <msub>
      <mi mathvariant="bold">K</mi>
      <mi>k</mi>
    </msub>
    <msub>
      <mi mathvariant="bold">y</mi>
      <mi>k</mi>
    </msub>
  </mrow>
</semantics></math>
      </p>
      <p><label>(20)</label>
      </p>
    </div><div id="FD21-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">P</mi>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
    <mo>=</mo>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">I</mi>
      <mo>−</mo>
      <msub>
        <mi mathvariant="bold">K</mi>
        <mi>k</mi>
      </msub>
      <mo>)</mo>
    </mrow>
    <msub>
      <mover accent="true">
        <mi mathvariant="bold">P</mi>
        <mo>^</mo>
      </mover>
      <mrow>
        <mi>k</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
    </msub>
  </mrow>
</semantics></math>
      </p>
      <p><label>(21)</label>
      </p>
    </div></div><div><p>The measurement noise, </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">R</mi>
    <mi>k</mi>
  </msub>
</semantics></math><p>, is defined as a diagonal matrix, with elements equal to </p><math display="inline"><semantics>
  <mrow>
    <mo>[</mo>
    <mn>0.5</mn>
    <mspace width="4pt"></mspace>
    <mspace width="4pt"></mspace>
    <mn>0.5</mn>
    <mspace width="4pt"></mspace>
    <mspace width="4pt"></mspace>
    <mn>1.0</mn>
    <mspace width="4pt"></mspace>
    <mspace width="4pt"></mspace>
    <mn>1.0</mn>
    <mo>]</mo>
  </mrow>
</semantics></math><p>, and the process noise is also defined as a diagonal matrix, with elements equal to </p><math display="inline"><semantics>
  <mrow>
    <mo>[</mo>
    <mn>4.0</mn>
    <mspace width="4pt"></mspace>
    <mspace width="4pt"></mspace>
    <mn>4.0</mn>
    <mspace width="4pt"></mspace>
    <mspace width="4pt"></mspace>
    <mn>2.0</mn>
    <mspace width="4pt"></mspace>
    <mspace width="4pt"></mspace>
    <mn>2.0</mn>
    <mo>]</mo>
  </mrow>
</semantics></math><p>. The measurement noise was selected based on the calibration accuracy of the camera, and the process noise was experimentally tuned to minimize the occurrence of lost tracks under high motion conditions. The a priori state estimate is used to propagate the bounding box containing the region of interest, within which the peak is detected using Equation (<a href="#FD12-drones-08-00652">12</a>). The bounding box is centered on </p><math display="inline"><semantics>
  <mrow>
    <mo>[</mo>
    <mi>u</mi>
    <mo>,</mo>
    <mi>v</mi>
    <mo>]</mo>
  </mrow>
</semantics></math><p>, rounded to the nearest pixel. The width and height of the bounding box were fixed at 21 pixels for this imaging system, given an image resolution of </p><math display="inline"><semantics>
  <mrow>
    <mn>1936</mn>
    <mo>×</mo>
    <mn>1216</mn>
  </mrow>
</semantics></math><p> and a field of view of 53.5&nbsp;deg. A visual snapshot of the tracking system can be seen in <a href="#drones-08-00652-f002">Figure 2</a>.</p></div></section><section id="sec3dot2-drones-08-00652" type=""><h4 data-nested="2">  3.2. Experimental Configuration</h4><p>Celestial imagery was captured in-flight from a 4 m flying wing UAV. The selected autopilot (Cube Orange) was mounted at the center of mass, and the celestial payload was mounted in the shoulder of the aircraft (see <a href="#drones-08-00652-f003">Figure 3</a>). The celestial payload collected imagery at a rate of 10 &nbsp;Hz, as well as the attitude and position data from the autopilot, enabling post-analysis. A Raspberry Pi 5 (Raspberry Pi Ltd., Cambridge, UK) was used as the companion computer, interfacing with the celestial camera and the autopilot. An Alvium 1800 U-240 (Allied Vision, Stradtroda, Germany) monochrome sensor fitted with a f/1.4 6 mm wide angle lens was chosen for the imaging system. A serial Universal Asynchronous Receiver Transmitter (UART) link between the Raspberry Pi and the Cube Orange facilitated the transport of MAVLink v2.0 messages. The AHRS data from ArduPlane’s EKF3 was recorded at a rate of 30&nbsp;Hz, and the ground truth GPS position data were recorded at a rate of 10&nbsp;Hz. The Raspberry Pi clock was synchronized with GPS time prior to takeoff. The Raspberry Pi and the camera were mounted on a PLA 3D-printed structure (see <a href="#drones-08-00652-f004">Figure 4</a>) for integration into the airframe.</p><p>The test flight was conducted on a moonless night. The wind was modest, typically remaining below 5&nbsp;m/s. The flight plan consisted of both straight legs and orbital trajectories with varying radii. An overview of the flight plan can be seen in <a href="#drones-08-00652-t001">Table 1</a>.</p><p>The total flight lasted 72 min. Astronomical twilight ceased at 19:32, and takeoff was conducted at 19:53. The GPS receiver in the aircraft was not allowed to be switched off to enable emergency failsafes and prevent fence breaches. We address the consequences of this in <a href="#sec4dot4-drones-08-00652">Section 4.4</a>.</p></section><section id="sec3dot3-drones-08-00652" type=""><h4 data-nested="2">  3.3. Position Estimation</h4><div><p>The star tracker in <a href="#sec3dot1-drones-08-00652">Section 3.1</a> operates on distorted images. The pixel location from each star tracker is extracted. rectified, and subsequently converted to a unit vector in NED coordinates according to <a href="#sec2dot1-drones-08-00652">Section 2.1</a>. Given an observation </p><math display="inline"><semantics>
  <mrow>
    <msup>
      <mi mathvariant="bold">X</mi>
      <mi>l</mi>
    </msup>
    <mo>=</mo>
    <msup>
      <mrow>
        <mo>[</mo>
        <mi>x</mi>
        <mspace width="4pt"></mspace>
        <mi>y</mi>
        <mspace width="4pt"></mspace>
        <mi>z</mi>
        <mo>]</mo>
      </mrow>
      <mi>T</mi>
    </msup>
  </mrow>
</semantics></math><p>, the elevation of a star above the horizon is calculated as
        </p><div id="FD22-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi>e</mi>
    <mi>l</mi>
    <mo>=</mo>
    <mo>−</mo>
    <msup>
      <mo form="prefix">tan</mo>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac>
        <mi>y</mi>
        <msqrt>
          <mrow>
            <msup>
              <mi>x</mi>
              <mn>2</mn>
            </msup>
            <mo>+</mo>
            <msup>
              <mi>y</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </msqrt>
      </mfrac>
    </mstyle>
  </mrow>
</semantics></math>
      </p>
      <p><label>(22)</label>
      </p>
    </div><p>
        and, subsequently, the zenith-angle </p><math display="inline"><semantics>
  <mi>ζ</mi>
</semantics></math><p> is calculated as </p><math display="inline"><semantics>
  <mrow>
    <mn>90</mn>
    <mo>−</mo>
    <mi>e</mi>
    <mi>l</mi>
  </mrow>
</semantics></math><p>.</p></div><div><p>In the initial case, the camera orientation </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p> is not known to a high level of precision. Assuming that an attempt is made to mount the camera in alignment with the autopilot, an initial DCM may be formulated from some combination of 90° Euler rotations. It will be seen that as long as this orientation is accurate to within a hemisphere of tolerance, the exact value does not matter, as it will be recalculated in flight.</p></div><div><p>If a minimum of six stars are visible within the frame, a Random Sample Consensus (RANSAC) approach to position estimation may be used to remove bias from false detections. RANSAC is a technique used to identify outliers in sample data and omit them from the estimation process. This is useful for detecting misidentified stars or for removing non-star detections (such as satellites or overhead planes). In the context of position estimation, the RANSAC algorithm randomly selects three stars to generate a position estimate. Subsequently, the algorithm compares the location of the remaining stars against the position estimate. If the remaining stars are within some heuristic tolerance, they are considered inliers. If they are outside of tolerance, they are considered outliers. The position estimate which minimizes the mean squared error of the inliers is chosen as the estimate. A pseudocode implementation of this RANSAC position estimation is outlined in Algorithm 1.
        </p><table><tbody><tr><td><b>Algorithm 1</b> Position-RANSAC</td></tr><tr><td><p><math display="inline"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>l</mi>
        <mo>/</mo>
        <mi>b</mi>
      </mrow>
    </msub>
    <mo>,</mo>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>b</mi>
        <mo>/</mo>
        <mi>c</mi>
      </mrow>
    </msub>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi>G</mi>
    <mi>H</mi>
    <mi>A</mi>
    <mo>Γ</mo>
    <mo>←</mo>
    <mi>g</mi>
    <mi>e</mi>
    <mi>t</mi>
    <mi>G</mi>
    <mi>H</mi>
    <mi>A</mi>
    <mi>A</mi>
    <mi>r</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>s</mi>
    <mo>(</mo>
    <mo>)</mo>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi>A</mi>
    <mi>s</mi>
    <mo>←</mo>
    <mo>[</mo>
    <mspace width="4pt"></mspace>
    <mo>]</mo>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi>P</mi>
    <mi>s</mi>
    <mo>←</mo>
    <mo>[</mo>
    <mspace width="4pt"></mspace>
    <mo>]</mo>
  </mrow>
</semantics></math></p><div><p><b>for</b></p><math display="inline"><semantics>
  <mrow>
    <mo>&nbsp;</mo>
    <mi>o</mi>
    <mi>b</mi>
    <mi>s</mi>
  </mrow>
</semantics></math><p> in </p><math display="inline"><semantics>
  <mrow>
    <mi>o</mi>
    <mi>b</mi>
    <mi>s</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>v</mi>
    <mi>a</mi>
    <mi>t</mi>
    <mi>i</mi>
    <mi>o</mi>
    <mi>n</mi>
    <mi>s</mi>
  </mrow>
</semantics></math>&nbsp;<p><b>do</b></p></div><p>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>a</mi>
    <mi>z</mi>
    <mo>,</mo>
    <mi>e</mi>
    <mi>l</mi>
    <mo>=</mo>
    <mi>c</mi>
    <mi>o</mi>
    <mi>m</mi>
    <mi>p</mi>
    <mi>u</mi>
    <mi>t</mi>
    <mi>e</mi>
    <mi>A</mi>
    <mi>z</mi>
    <mi>E</mi>
    <mi>l</mi>
    <mo>(</mo>
    <mi>o</mi>
    <mi>b</mi>
    <mi>s</mi>
    <mo>,</mo>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>l</mi>
        <mo>/</mo>
        <mi>b</mi>
      </mrow>
    </msub>
    <mo>,</mo>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>b</mi>
        <mo>/</mo>
        <mi>c</mi>
      </mrow>
    </msub>
    <mo>)</mo>
  </mrow>
</semantics></math></p><p>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>a</mi>
    <mo>,</mo>
    <mi>b</mi>
    <mo>,</mo>
    <mi>c</mi>
    <mo>,</mo>
    <mi>p</mi>
    <mo>=</mo>
    <mi>c</mi>
    <mi>o</mi>
    <mi>m</mi>
    <mi>p</mi>
    <mi>u</mi>
    <mi>t</mi>
    <mi>e</mi>
    <mi>P</mi>
    <mi>o</mi>
    <mi>s</mi>
    <mi>i</mi>
    <mi>t</mi>
    <mi>i</mi>
    <mi>o</mi>
    <mi>n</mi>
    <mi>C</mi>
    <mi>o</mi>
    <mi>e</mi>
    <mi>f</mi>
    <mi>f</mi>
    <mi>i</mi>
    <mi>c</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>n</mi>
    <mi>t</mi>
    <mi>s</mi>
    <mo>(</mo>
    <mi>G</mi>
    <mi>H</mi>
    <mi>A</mi>
    <mo>Γ</mo>
    <mo>,</mo>
    <mi>a</mi>
    <mi>z</mi>
    <mo>,</mo>
    <mi>e</mi>
    <mi>l</mi>
    <mo>,</mo>
    <mi>o</mi>
    <mi>b</mi>
    <mi>s</mi>
    <mo>.</mo>
    <mi>r</mi>
    <mi>a</mi>
    <mo>,</mo>
    <mi>o</mi>
    <mi>b</mi>
    <mi>s</mi>
    <mo>.</mo>
    <mi>d</mi>
    <mi>e</mi>
    <mi>c</mi>
    <mo>)</mo>
  </mrow>
</semantics></math></p><p>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>A</mi>
    <mi>s</mi>
    <mo>.</mo>
    <mi>a</mi>
    <mi>p</mi>
    <mi>p</mi>
    <mi>e</mi>
    <mi>n</mi>
    <mi>d</mi>
    <mo>(</mo>
    <mo>[</mo>
    <mi>a</mi>
    <mo>,</mo>
    <mi>b</mi>
    <mo>,</mo>
    <mi>c</mi>
    <mo>]</mo>
    <mo>)</mo>
  </mrow>
</semantics></math></p><p>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>P</mi>
    <mi>s</mi>
    <mo>.</mo>
    <mi>a</mi>
    <mi>p</mi>
    <mi>p</mi>
    <mi>e</mi>
    <mi>n</mi>
    <mi>d</mi>
    <mo>(</mo>
    <mo>[</mo>
    <mi>p</mi>
    <mo>]</mo>
    <mo>)</mo>
  </mrow>
</semantics></math></p><p><b>end for</b></p><p><math display="inline"><semantics>
  <mrow>
    <mi>i</mi>
    <mi>n</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>s</mi>
    <mo>←</mo>
    <mn>0</mn>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi>o</mi>
    <mi>u</mi>
    <mi>t</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>s</mi>
    <mo>←</mo>
    <mn>0</mn>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi>b</mi>
    <mi>e</mi>
    <mi>s</mi>
    <mi>t</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mo>←</mo>
    <mo movablelimits="true" form="prefix">inf</mo>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi mathvariant="bold">x</mi>
    <mo>←</mo>
    <mo>[</mo>
    <mn>0</mn>
    <mo>,</mo>
    <mn>0</mn>
    <mo>,</mo>
    <mn>0</mn>
    <mo>]</mo>
  </mrow>
</semantics></math></p><div><p><b>for</b></p><math display="inline"><semantics>
  <mrow>
    <mn>0</mn>
    <mo>&lt;</mo>
    <mi>i</mi>
    <mo>&lt;</mo>
    <mi>i</mi>
    <mi>t</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>a</mi>
    <mi>t</mi>
    <mi>i</mi>
    <mi>o</mi>
    <mi>n</mi>
    <mi>s</mi>
  </mrow>
</semantics></math>&nbsp;
                      <p><b>do</b></p></div><div>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>j</mi>
    <mo>←</mo>
  </mrow>
</semantics></math><p> 3 randomly selected indexes</p></div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;build </p><math display="inline"><semantics>
  <mi mathvariant="bold">A</mi>
</semantics></math><p> and </p><math display="inline"><semantics>
  <mi mathvariant="bold">p</mi>
</semantics></math><p> using </p><math display="inline"><semantics>
  <mrow>
    <mi>A</mi>
    <mi>s</mi>
    <mo>[</mo>
    <mi>j</mi>
    <mo>]</mo>
  </mrow>
</semantics></math><p> and </p><math display="inline"><semantics>
  <mrow>
    <mi>P</mi>
    <mi>s</mi>
    <mo>[</mo>
    <mi>j</mi>
    <mo>]</mo>
  </mrow>
</semantics></math></div><p>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mover accent="true">
      <mi mathvariant="bold">x</mi>
      <mo>^</mo>
    </mover>
    <mo>←</mo>
    <msup>
      <mrow>
        <mo>(</mo>
        <msup>
          <mi mathvariant="bold">A</mi>
          <mi>T</mi>
        </msup>
        <mi mathvariant="bold">A</mi>
        <mo>)</mo>
      </mrow>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <msup>
      <mi mathvariant="bold">A</mi>
      <mi>T</mi>
    </msup>
    <mi mathvariant="bold">p</mi>
  </mrow>
</semantics></math></p><p>&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>i</mi>
    <mi>n</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mo>←</mo>
    <mn>0</mn>
  </mrow>
</semantics></math></p><p><b>for</b> all remaining indexes <span>k</span>&nbsp;<b>do</b></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi mathvariant="script">E</mi>
    <mo>←</mo>
    <mi>P</mi>
    <mi>s</mi>
    <mrow>
      <mo>[</mo>
      <mi>k</mi>
      <mo>]</mo>
    </mrow>
    <mo>−</mo>
    <mi>A</mi>
    <mi>s</mi>
    <mrow>
      <mo>[</mo>
      <mi>k</mi>
      <mo>]</mo>
    </mrow>
    <mover accent="true">
      <mi mathvariant="bold">x</mi>
      <mo>^</mo>
    </mover>
  </mrow>
</semantics></math></p><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p><b>if</b></p><math display="inline"><semantics>
  <mrow>
    <mi mathvariant="script">E</mi>
    <mo>&lt;</mo>
    <mi>t</mi>
    <mi>o</mi>
    <mi>l</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mi>c</mi>
    <mi>e</mi>
  </mrow>
</semantics></math>&nbsp;<p><b>then</b></p></div><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>i</mi>
    <mi>n</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
  </mrow>
</semantics></math><p> += </p><math display="inline"><semantics>
  <mi mathvariant="script">E</mi>
</semantics></math></div><p><b>else</b></p><p><b>end if</b></p><p><b>end for</b></p><div>&nbsp;&nbsp;&nbsp;&nbsp;<p><b>if</b></p><math display="inline"><semantics>
  <mrow>
    <mi>i</mi>
    <mi>n</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>s</mi>
    <mo>:</mo>
    <mi>o</mi>
    <mi>u</mi>
    <mi>t</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>s</mi>
    <mo>&gt;</mo>
    <mi>a</mi>
    <mi>c</mi>
    <mi>c</mi>
    <mi>e</mi>
    <mi>p</mi>
    <mi>t</mi>
    <mi>a</mi>
    <mi>b</mi>
    <mi>l</mi>
    <mi>e</mi>
    <mspace width="4pt"></mspace>
    <mi>r</mi>
    <mi>a</mi>
    <mi>t</mi>
    <mi>i</mi>
    <mi>o</mi>
  </mrow>
</semantics></math>&nbsp;<p><b>then</b></p></div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>m</mi>
    <mi>e</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mo>=</mo>
    <mi>i</mi>
    <mi>n</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mo>/</mo>
    <mi>i</mi>
    <mi>n</mi>
    <mi>l</mi>
    <mi>i</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>s</mi>
  </mrow>
</semantics></math></p><div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<p><b>if</b></p><math display="inline"><semantics>
  <mrow>
    <mi>m</mi>
    <mi>e</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mo>&lt;</mo>
    <mi>b</mi>
    <mi>e</mi>
    <mi>s</mi>
    <mi>t</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
  </mrow>
</semantics></math>&nbsp;<p><b>then</b></p></div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi>b</mi>
    <mi>e</mi>
    <mi>s</mi>
    <mi>t</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
    <mo>=</mo>
    <mi>m</mi>
    <mi>e</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mspace width="4pt"></mspace>
    <mi>e</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>r</mi>
  </mrow>
</semantics></math></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<math display="inline"><semantics>
  <mrow>
    <mi mathvariant="bold">x</mi>
    <mo>←</mo>
    <mover accent="true">
      <mi mathvariant="bold">x</mi>
      <mo>^</mo>
    </mover>
  </mrow>
</semantics></math></p><p><b>end if</b></p><p><b>end if</b></p><p><b>end for</b></p><p><math display="inline"><semantics>
  <mrow>
    <mi>ϕ</mi>
    <mo>←</mo>
    <msup>
      <mo form="prefix">tan</mo>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <mfenced open="(" close=")">
      <mstyle scriptlevel="0" displaystyle="true">
        <mfrac>
          <mrow>
            <mi mathvariant="bold">x</mi>
            <mo>[</mo>
            <mn>2</mn>
            <mo>]</mo>
          </mrow>
          <msqrt>
            <mrow>
              <mi mathvariant="bold">x</mi>
              <msup>
                <mrow>
                  <mo>[</mo>
                  <mn>0</mn>
                  <mo>]</mo>
                </mrow>
                <mn>2</mn>
              </msup>
              <mo>+</mo>
              <mi mathvariant="bold">x</mi>
              <msup>
                <mrow>
                  <mo>[</mo>
                  <mn>1</mn>
                  <mo>]</mo>
                </mrow>
                <mn>2</mn>
              </msup>
            </mrow>
          </msqrt>
        </mfrac>
      </mstyle>
    </mfenced>
  </mrow>
</semantics></math></p><p><math display="inline"><semantics>
  <mrow>
    <mi>λ</mi>
    <mo>←</mo>
    <msup>
      <mo form="prefix">tan</mo>
      <mrow>
        <mo>−</mo>
        <mn>1</mn>
      </mrow>
    </msup>
    <mfenced open="(" close=")">
      <mstyle scriptlevel="0" displaystyle="true">
        <mfrac>
          <mrow>
            <mi mathvariant="bold">x</mi>
            <mo>[</mo>
            <mn>1</mn>
            <mo>]</mo>
          </mrow>
          <mrow>
            <mi mathvariant="bold">x</mi>
            <mo>[</mo>
            <mn>0</mn>
            <mo>]</mo>
          </mrow>
        </mfrac>
      </mstyle>
    </mfenced>
  </mrow>
</semantics></math></p></td></tr></tbody></table></div><div><p>We first demonstrate that, in the general case, the DCM </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p> is not fixed during flight. In an integrated solution, the celestial system would provide attitude measurements to the EKF, and the offset from this attitude would be estimated. As a modular solution, however, this is infeasible. Taking the output from the EKF to be the true orientation of the aircraft, we can use the true GPS position to compute </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p>. We use the Kabsch-RANSAC methodology presented in [<a href="#B19-drones-08-00652">19</a>] to calculate the ideal rotation between a star’s theoretical location and its actual location. In conjunction with the autopilot output, this rotation yields </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p>. Testing over an 89 s section of flat and level flight, it can be seen in <a href="#drones-08-00652-f005">Figure 5</a> that the camera roll angle shifts by approximately 0.2°, the pitch angle shifts by approximately 0.05°, and the yaw angle shifts by approximately 0.3°. In the context of celestial navigation, these are significant perturbances which, had the offsets been attributed to position as opposed to camera orientation, would have been interpreted as around 30&nbsp;km of positional offset. Indeed, by assuming that </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p> is fixed, we can see in <a href="#drones-08-00652-f006">Figure 6</a> that the latitude drifts by approximately 0.2° over the same short window of flat and level flight. Over an extended period (hours), the orientation may shift such that positional errors are in the range of hundreds of kilometers.</p></div><p>It is clear that a stand-alone celestial module cannot function in the conventional manner with consumer-grade hardware, unless the autopilot is capable of integrating the attitude output from the celestial system into its own filter and estimating the camera orientation. We will demonstrate now a method which, given a very rough initial estimate of the camera orientation, is capable of returning position estimates to within 4&nbsp;km. This is significant in the context of long flights, where alternative dead-reckoning solutions would experience positional drift that is either linear (assuming velocity measurements are available) or quadratic (assuming only acceleration measurements) as a function of time.</p><div><p>By performing a rotation through 360° of compass heading, at an approximately constant yaw rate, the position estimates can be averaged to find an approximation of the orbital center. Provided <span>n</span> images throughout an orbit are available, there exists <span>n</span> latitude and longitude estimates, which may be expressed as unit vectors in the Earth Centred Earth Fixed (ECEF) frame </p><math display="inline"><semantics>
  <msubsup>
    <mi mathvariant="bold">p</mi>
    <mi>i</mi>
    <mrow>
      <mi>e</mi>
      <mi>c</mi>
      <mi>e</mi>
      <mi>f</mi>
    </mrow>
  </msubsup>
</semantics></math><p>. The mean position is taken to be the mean of these vectors:</p><div id="FD23-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msup>
      <mover accent="true">
        <mi mathvariant="bold">p</mi>
        <mo>¯</mo>
      </mover>
      <mrow>
        <mi>e</mi>
        <mi>c</mi>
        <mi>e</mi>
        <mi>f</mi>
      </mrow>
    </msup>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac>
        <mn>1</mn>
        <mi>n</mi>
      </mfrac>
    </mstyle>
    <munderover>
      <mo>∑</mo>
      <mrow>
        <mi>i</mi>
        <mo>=</mo>
        <mn>1</mn>
      </mrow>
      <mi>n</mi>
    </munderover>
    <msubsup>
      <mi mathvariant="bold">p</mi>
      <mi>i</mi>
      <mrow>
        <mi>e</mi>
        <mi>c</mi>
        <mi>e</mi>
        <mi>f</mi>
      </mrow>
    </msubsup>
  </mrow>
</semantics></math>
      </p>
      <p><label>(23)</label>
      </p>
    </div></div><div><p>The latitude and longitude are simply calculated as
        </p><p>
        where <span>x</span>, <span>y</span>, and <span>z</span> are the elements of the mean position vector.</p></div><div><p>Once an initial position estimate has been formulated, it may be used to calculate a more precise estimate of the camera orientation </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>b</mi>
      <mo>/</mo>
      <mi>l</mi>
    </mrow>
  </msub>
</semantics></math><p>. The aim of orientation estimation is to find the rotation matrix </p><math display="inline"><semantics>
  <mi mathvariant="bold">R</mi>
</semantics></math><p> that minimizes the residual error between a set of observations </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">u</mi>
    <mi>c</mi>
  </msup>
</semantics></math><p> represented in the camera frame of reference and a set of theoretical unit vectors </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">v</mi>
    <mi>l</mi>
  </msup>
</semantics></math><p> in the NED frame of reference:</p><div id="FD26-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi mathvariant="script">E</mi>
    <mo>=</mo>
    <munderover>
      <mo>∑</mo>
      <mrow>
        <mi>i</mi>
        <mo>=</mo>
        <mn>1</mn>
      </mrow>
      <mi>n</mi>
    </munderover>
    <mrow>
      <mo stretchy="false">‖</mo>
    </mrow>
    <msubsup>
      <mi mathvariant="bold">v</mi>
      <mi>i</mi>
      <mi>l</mi>
    </msubsup>
    <mo>−</mo>
    <mi mathvariant="bold">R</mi>
    <msubsup>
      <mi mathvariant="bold">u</mi>
      <mi>i</mi>
      <mi>c</mi>
    </msubsup>
    <msup>
      <mrow>
        <mo stretchy="false">‖</mo>
      </mrow>
      <mn>2</mn>
    </msup>
    <mo>,</mo>
  </mrow>
</semantics></math>
      </p>
      <p><label>(26)</label>
      </p>
    </div></div><div><p>In this case, the rotation matrix </p><math display="inline"><semantics>
  <mi mathvariant="bold">R</mi>
</semantics></math><p> is composed of the aircraft DCM, </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p>, and the camera DCM, </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>b</mi>
      <mo>/</mo>
      <mi>c</mi>
    </mrow>
  </msub>
</semantics></math><p>:</p><p>
        where we accept </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p> as a deterministic output from the autopilot, and so the camera orientation may be found given </p><math display="inline"><semantics>
  <mi mathvariant="bold">R</mi>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>l</mi>
      <mo>/</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</semantics></math><p>:</p><div id="FD28-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>b</mi>
        <mo>/</mo>
        <mi>c</mi>
      </mrow>
    </msub>
    <mo>=</mo>
    <msubsup>
      <mi mathvariant="bold">C</mi>
      <mrow>
        <mi>l</mi>
        <mo>/</mo>
        <mi>b</mi>
      </mrow>
      <mi>T</mi>
    </msubsup>
    <mi mathvariant="bold">R</mi>
  </mrow>
</semantics></math>
      </p>
      <p><label>(28)</label>
      </p>
    </div></div><div><p>Each observation </p><math display="inline"><semantics>
  <msubsup>
    <mi mathvariant="bold">u</mi>
    <mi>i</mi>
    <mi>c</mi>
  </msubsup>
</semantics></math><p> is correlated with a database star. This correlation is obtained through star identification. During the instantiation of the star tracker, a lost-in-space log-polar star identification algorithm is used to determine the IDs of each star in the frame [<a href="#B20-drones-08-00652">20</a>]. The theoretical position vectors </p><math display="inline"><semantics>
  <msubsup>
    <mi mathvariant="bold">v</mi>
    <mi>i</mi>
    <mi>l</mi>
  </msubsup>
</semantics></math><p> in the NED coordinates are generated from the star’s right ascension and declination, the time of observation, and the estimated latitude and longitude [<a href="#B13-drones-08-00652">13</a>]. This allows for the use of the Kabsch algorithm [<a href="#B21-drones-08-00652">21</a>] to find the rotation </p><math display="inline"><semantics>
  <mi mathvariant="bold">R</mi>
</semantics></math><p> between the observed stars and the database stars. Following the implementation in [<a href="#B19-drones-08-00652">19</a>], the algorithm is provided in Algorithm 2, where </p><math display="inline"><semantics>
  <mi mathvariant="bold">A</mi>
</semantics></math><p> is the matrix of <span>n</span> observation vectors with dimension </p><math display="inline"><semantics>
  <mrow>
    <mo>[</mo>
    <mi>n</mi>
    <mo>×</mo>
    <mn>3</mn>
    <mo>]</mo>
  </mrow>
</semantics></math><p> and </p><math display="inline"><semantics>
  <mi mathvariant="bold">B</mi>
</semantics></math><p> is the matrix of <span>n</span> theoretical vectors, also with dimension </p><math display="inline"><semantics>
  <mrow>
    <mo>[</mo>
    <mi>n</mi>
    <mo>×</mo>
    <mn>3</mn>
    <mo>]</mo>
  </mrow>
</semantics></math><p>. The resulting rotation </p><math display="inline"><semantics>
  <mi mathvariant="bold">R</mi>
</semantics></math><p> is used in conjunction with the most recent autopilot attitude data to find the camera orientation </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>b</mi>
      <mo>/</mo>
      <mi>c</mi>
    </mrow>
  </msub>
</semantics></math><p>.
        </p><table><tbody><tr><td><b>Algorithm 2</b> Kabsch</td></tr><tr><td><div><p>Translate vectors in </p><math display="inline"><semantics>
  <mi mathvariant="bold">A</mi>
</semantics></math><p> and </p><math display="inline"><semantics>
  <mi mathvariant="bold">B</mi>
</semantics></math><p> such that centroid is at origin</p></div><div><p>Compute the matrix </p><math display="inline"><semantics>
  <mrow>
    <mi mathvariant="bold">C</mi>
    <mo>=</mo>
    <msup>
      <mi mathvariant="bold">A</mi>
      <mi>T</mi>
    </msup>
    <mi mathvariant="bold">B</mi>
  </mrow>
</semantics></math></div><div><p>Compute the singular value decomposition </p><math display="inline"><semantics>
  <mrow>
    <mi mathvariant="bold">U</mi>
    <mo>,</mo>
    <mo>Σ</mo>
    <mo>,</mo>
    <mi mathvariant="bold">V</mi>
    <mo>=</mo>
    <mi>SVD</mi>
    <mo>(</mo>
    <mi mathvariant="bold">C</mi>
    <mo>)</mo>
  </mrow>
</semantics></math><p> such that </p><math display="inline"><semantics>
  <mrow>
    <mi mathvariant="bold">C</mi>
    <mo>=</mo>
    <mi mathvariant="bold">U</mi>
    <mo>Σ</mo>
    <msup>
      <mi mathvariant="bold">V</mi>
      <mi>T</mi>
    </msup>
  </mrow>
</semantics></math></div><div><p>Set diagonal elements </p><math display="inline"><semantics>
  <msub>
    <mo>Σ</mo>
    <mn>1</mn>
  </msub>
</semantics></math><p> through to </p><math display="inline"><semantics>
  <msub>
    <mo>Σ</mo>
    <mrow>
      <mi>n</mi>
      <mo>−</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</semantics></math><p> = 1.</p></div><p><b>else</b></p><p><b>end if</b></p><div><p>Compute the rotation matrix </p><math display="inline"><semantics>
  <mrow>
    <mi mathvariant="bold">R</mi>
    <mo>=</mo>
    <mi mathvariant="bold">V</mi>
    <mo>Σ</mo>
    <msup>
      <mi mathvariant="bold">U</mi>
      <mi>T</mi>
    </msup>
  </mrow>
</semantics></math></div></td></tr></tbody></table></div><div><p>Once the camera orientation has been found, two options are presented, depending on the computational power of the flight computer. If the computer is capable of parallel processing, then the set of theoretical star locations </p><math display="inline"><semantics>
  <msup>
    <mi mathvariant="bold">v</mi>
    <mi>l</mi>
  </msup>
</semantics></math><p> may be re-calculated using the updated latitude and longitude, and the estimated positions may be re-calculated using the updated camera DCM </p><math display="inline"><semantics>
  <msub>
    <mi mathvariant="bold">C</mi>
    <mrow>
      <mi>b</mi>
      <mo>/</mo>
      <mi>c</mi>
    </mrow>
  </msub>
</semantics></math><p>. This enables the system to recursively converge on a position estimate from a single set of orbital data. Alternatively, it is possible to repeat an orbit and calculate a new set of latitudes and longitudes. This method does not require post hoc processing and may be better suited to real-time applications. For the purposes of this study, we use the former method, as this allows us to treat each orbit as an independent sample, yielding an independent position estimate, thus giving us deeper insight into how the characteristics of a given orbit affect the position estimate. An example of this process can be seen in <a href="#drones-08-00652-f007">Figure 7</a>.</p></div></section></section><section id="sec4-drones-08-00652" type="results"><h2 data-nested="1">  4. Results</h2><section id="sec4dot1-drones-08-00652" type=""><h4 data-nested="2">  4.1. Position Estimation</h4><div><p>Following the experimental configuration in <a href="#sec3-drones-08-00652">Section 3</a>, the position of the aircraft is estimated for each orbit. The camera was initially aligned using a rotation matrix built from Euler angles of </p><math display="inline"><semantics>
  <mrow>
    <mo>−</mo>
    <msup>
      <mn>90</mn>
      <mo>∘</mo>
    </msup>
    <mo>,</mo>
    <msup>
      <mn>0</mn>
      <mo>∘</mo>
    </msup>
  </mrow>
</semantics></math><p>, and </p><math display="inline"><semantics>
  <msup>
    <mn>180</mn>
    <mo>∘</mo>
  </msup>
</semantics></math><p> in yaw, pitch, and roll, respectively, for a yaw–pitch–roll rotation sequence. This is a coarse approximation based on the orientation with which the camera was mounted to the airframe. Of course, the true orientation differs from this; as can be seen in <a href="#drones-08-00652-f005">Figure 5</a>, there is approximately a 5° error in this initial orientation.</p></div><p>Each orbit is treated as an independent observation. This is achieved by resetting the camera orientation at the initialization of every orbit, thus requiring the algorithm to recalculate the camera DCM. The output from each of the orbital motions listed in <a href="#drones-08-00652-t001">Table 1</a> is shown in <a href="#drones-08-00652-t002">Table 2</a>. The position error is measured as the distance between the final celestial position estimate and the center of the orbit, calculated using the Haversine function.</p></section><section id="sec4dot2-drones-08-00652" type=""><h4 data-nested="2">  4.2. Estimation Accuracy</h4><div><p>It can be seen that the orbits which are neither climbing nor descending produced more accurate positional data. These orbits had larger radii, which consequently produced greater numbers of position estimates per orbit. Additionally, the variance in the pitch and roll axis during ascent/descent tends to be greater, as the total energy control system utilizes the pitch axis to throttle the climb/descent rate. By taking these two factors into account, we calculate the standard error as a function of the covariance in pitch and roll, as well as the number of samples. The generalized variance is calculated by taking the determinant of the covariance matrix in pitch and roll, where this matrix is given by
        </p><div id="FD29-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <msub>
      <mo>Σ</mo>
      <mrow>
        <mi>θ</mi>
        <mo>,</mo>
        <mi>ϕ</mi>
      </mrow>
    </msub>
    <mo>=</mo>
    <mfenced open="[" close="]">
      <mtable>
        <mtr>
          <mtd>
            <mrow>
              <mi>COV</mi>
              <mo>(</mo>
              <mi>θ</mi>
              <mo>,</mo>
              <mi>θ</mi>
              <mo>)</mo>
            </mrow>
          </mtd>
          <mtd>
            <mrow>
              <mi>COV</mi>
              <mo>(</mo>
              <mi>θ</mi>
              <mo>,</mo>
              <mi>ϕ</mi>
              <mo>)</mo>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mrow>
              <mi>COV</mi>
              <mo>(</mo>
              <mi>ϕ</mi>
              <mo>,</mo>
              <mi>θ</mi>
              <mo>)</mo>
            </mrow>
          </mtd>
          <mtd>
            <mrow>
              <mi>COV</mi>
              <mo>(</mo>
              <mi>ϕ</mi>
              <mo>,</mo>
              <mi>ϕ</mi>
              <mo>)</mo>
            </mrow>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
  </mrow>
</semantics></math>
      </p>
      <p><label>(29)</label>
      </p>
    </div><p>
        where the function </p><math display="inline"><semantics>
  <mrow>
    <mi>COV</mi>
    <mo>(</mo>
    <mi>x</mi>
    <mo>,</mo>
    <mi>y</mi>
    <mo>)</mo>
  </mrow>
</semantics></math><p> describes the covariance between sets <span>x</span> and <span>y</span>:</p><div id="FD30-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi>COV</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac>
        <mrow>
          <msubsup>
            <mo>∑</mo>
            <mrow>
              <mi>i</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mi>n</mi>
          </msubsup>
          <mrow>
            <mo>(</mo>
            <msub>
              <mi>x</mi>
              <mi>i</mi>
            </msub>
            <mo>−</mo>
            <mover accent="true">
              <mi>x</mi>
              <mo>¯</mo>
            </mover>
            <mo>)</mo>
          </mrow>
          <mrow>
            <mo>(</mo>
            <msub>
              <mi>y</mi>
              <mi>i</mi>
            </msub>
            <mo>−</mo>
            <mover accent="true">
              <mi>y</mi>
              <mo>¯</mo>
            </mover>
            <mo>)</mo>
          </mrow>
        </mrow>
        <mi>n</mi>
      </mfrac>
    </mstyle>
  </mrow>
</semantics></math>
      </p>
      <p><label>(30)</label>
      </p>
    </div><p>
        given <span>n</span> samples. The standard deviation is found given the generalized variance:</p><p>
        and thus the standard error in roll and pitch is calculated given the standard deviation and the number of samples as follows:</p></div><div><p>It can be seen in <a href="#drones-08-00652-f008">Figure 8</a> that the relationship between the estimated standard error and the true error is approximately linear. The accuracy of the first orbit is likely due to chance; this is a good indicator that the factors dictating an accurate positional estimate are indeed the variance in pitch and roll throughout the orbit and the total number of samples. The inverse of the trend-line may be used as an estimate for the Circular Error Probable (CEP), where
        </p><div id="FD33-drones-08-00652">
      <p>
        <math display="block"><semantics>
  <mrow>
    <mi>C</mi>
    <mi>E</mi>
    <mi>P</mi>
    <mo>=</mo>
    <mn>1205</mn>
    <mo>×</mo>
    <mi>S</mi>
    <mi>E</mi>
    <mo>−</mo>
    <mn>0.567</mn>
  </mrow>
</semantics></math>
      </p>
      <p><label>(33)</label>
      </p>
    </div><p>
        and </p><math display="inline"><semantics>
  <mrow>
    <mi>C</mi>
    <mi>E</mi>
    <mi>P</mi>
  </mrow>
</semantics></math><p> is estimated in kilometers.</p></div></section><section id="sec4dot3-drones-08-00652" type=""><h4 data-nested="2">  4.3. Initial Conditions</h4><div><p>We demonstrate here that the initial value of the camera rotation matrix has little effect on the final position estimate. This is significant because, as shown in <a href="#sec3-drones-08-00652">Section 3</a>, many factors may cause changes in the relative orientation between the camera and the AHRS. Choosing orbit 5 as an example, we show that as long as the estimated boresight of the camera is accurate to within a hemisphere of tolerance (that is, the estimated boresight is within </p><math display="inline"><semantics>
  <msup>
    <mn>90</mn>
    <mo>∘</mo>
  </msup>
</semantics></math><p> of the true boresight), the algorithm will converge near the true location. A graphical representation of the first iteration given various camera calibrations is shown in <a href="#drones-08-00652-f009">Figure 9</a>. In each case, with a position error less than 90°, the position estimate converged to within the estimated CEP. It can be seen in <a href="#drones-08-00652-t003">Table 3</a> that an initial calibration error beyond 90° results in a position estimate on the opposite side of the Earth.</p></div></section><section id="sec4dot4-drones-08-00652" type=""><h4 data-nested="2">  4.4. Simulation of Wind Effects</h4><p>The flight trial was conducted with modest amounts of wind, utilizing GPS to conduct an orbit. We postulate that in the presence of wind, the position is better attained by fixing the pitch and roll of the aircraft, such that a constant yaw rate is achieved in the local NED frame. This approach does not require GPS to perform an orbit and only relies on compass heading and inertial attitude sensors to follow a trajectory. Simulation results strongly indicate that GPS is not required but is in fact detrimental to the orbital method of position estimation. As a consequence of not using GPS, the aircraft is subjected to lateral drift in the local NED frame. The amount of drift experienced by the aircraft during an orbit is, however, minimal in comparison to the scale to which position is being estimated.</p><p>We used JSBSim to simulate the aircraft’s flight dynamics, in conjunction with Ardupilot’s software-in-the-loop simulator to generate synthesized motion-blurred imagery. The images were generated following the methodology in [<a href="#B13-drones-08-00652">13</a>], factoring in the motion blur experienced by the camera. A strong southerly wind of 54 km/h was added to the simulation. An orbit was performed using GPS, and another was performed using a fixed pitch and roll angle with GPS disabled. During the fixed-attitude orbit, the aircraft drifted 1.05 km. The simulated trajectory of the GPS-denied orbit can be seen in <a href="#drones-08-00652-f010">Figure 10</a>.</p><p>Applying the same methodology, the position was calculated for both the GPS-guided orbit and the GPS-denied orbit. The control protocol of the GPS-guided orbit was to maintain a ground track at a fixed radius about a point in an identical manner to what was performed in the real flight test. This method adjusts the pitch and roll of the vehicle to compensate for wind and altitude. Up-wind sections of the orbit are prolonged in time, and down-wind sections are contracted in time. The resulting position estimates are heavily biased towards the prolonged portion of the orbit, which consequently skews the mean calculation. Under high wind conditions, it can be seen that following a fixed-radius ground track is not optimal for position calculation. The resulting position error was 18.27 km, as seen in <a href="#drones-08-00652-f011">Figure 11</a>. By contrast, the fixed-attitude orbit achieved a position error of 2.29 km, despite being subjected to over 1 km of drift. This highlights the importance of fixing the aircraft attitude rather than following a constant-radius orbit.</p></section></section><section id="sec5-drones-08-00652" type="discussion"><h2 data-nested="1">  5. Discussion</h2><p>The results presented in <a href="#sec4-drones-08-00652">Section 4</a> demonstrate that strapdown celestial navigation as a modular solution has potential use in Global Navigation Satellite System (GNSS)-denied UAV navigation. The celestial camera was mounted to the airframe, separate from the autopilot, but still utilizing the AHRS orientation information coming from the autopilot. This has significant implications for integration into SWAP-C airframes, in which the inclusion of stabilization hardware adds unwanted mass. With a modern GPS receiver weighing only a few grams and producing estimates to within 1m accuracy, it is understandable that, given the choice, an alternative celestial navigation solution would not be included. Yet, GNSS denial is increasing in prevalence, and alternative navigation solutions must be explored if a UAV is to operate under such circumstances.</p><p>The most profound outcome from this study is the celestial system’s independence from the initial conditions. Provided a functional AHRS and navigation system which is capable of performing an orbit, the celestial system can produce a position estimate from any unknown position on the globe, with a camera that is aligned to within 90°. The remaining source of error lies in the clock drift, which is typically equal to 3 ppm (0.3 s per 24 h) for a modern real-time clock. This has significant implications for long endurance aircraft, which may need to operate for many hours in RF contested environments. It has been shown that the rate of divergence in dead reckoning navigation is substantial without a velocity estimate [<a href="#B22-drones-08-00652">22</a>], particularly in consumer grade systems. Even with velocity measurements, in the presence of wind, a tactical grade aircraft may drift by 10 km per hour. In such cases, over the course of multiple hours, the precision offered by the proposed method is a vast improvement.</p><p>For loitering aircraft, this method of localization is convenient, as the flight plan need not change. For aircraft travelling significant distances, it may be sufficient to intermittently perform a single orbit, and utilize the more erroneous position estimate for course correction. The act of performing an orbit through a full compass rotation effectively nullifies the biases and offsets between the AHRS and the celestial camera. The main source of error for each independent position estimate during an orbit, is the misalignment of the estimated zenith with the true zenith. This may be caused by a number of factors, such as aerodynamic loading causing minor perturbations in the camera’s orientation relative to the autopilot, improper alignment or calibration of the inertial system, or simply due to estimation errors caused by improperly estimated centrifugal acceleration. In each of these cases, it is expected that the error remains approximately constant throughout an orbit. Consequently, zenith errors at one particular azimuth are cancelled out by the zenith errors at the opposing (180° offset) azimuth. This is the reason why such a method is capable of working with almost arbitrary levels of initial error.</p><p>This flight was conducted using GPS to maintain the orbital position. We recognize that, in a true GNSS denied environment, wind errors will cause the aircraft to drift during an orbit. While this may introduce some error into the position estimate, we show in <a href="#sec4-drones-08-00652">Section 4</a> that the primary factor governing the accuracy of a position estimate is the variance in the zenith-angle throughout the orbit. The circular position errors seen for example in <a href="#drones-08-00652-f007">Figure 7</a>, are not caused by the change in aircraft position. They are caused by a misalignment of the optical system, and consequently may be reproduced by simply maintaining constant roll and pitch throughout a full compass rotation. In <a href="#sec4dot4-drones-08-00652">Section 4.4</a> we show that even in high wind conditions, the appropriate strategy is to maintain roll rate and accept that there will be positional drift throughout the orbit. This strongly suggests that the presence of GPS during the flight test offered no advantages to the algorithm.</p><p>An obvious limitation of this method is its dependence on sky visibility. Some research has shown that short-wave infrared cameras offer a daylight visible alternative to visible spectrum cameras [<a href="#B23-drones-08-00652">23</a>,<a href="#B24-drones-08-00652">24</a>]. These tend to have far lower signal-to-noise ratios, resulting in more erroneous measurements. It may be the case that the proposed positioning method is capable of nullifying the increased observational error from short-wave infrared observations. This may be a potential topic for future research.</p></section><section id="sec6-drones-08-00652" type="conclusions"><h2 data-nested="1">  6. Conclusions</h2><p>This study proposed a method for obtaining more accurate positional estimates from a modular strapdown celestial navigation system. We hypothesized that by flying in an orbital motion, the errors in estimated zenith angles would cancel one another at opposing azimuths. The methodology was tested in a real flight, demonstrating that the position can be routinely estimated to within 4 km by performing orbits at a fixed altitude and airspeed. Throughout each orbit, positional estimates are generated from the individual celestial images, and these positions are averaged at the conclusion of the orbit. We show that by recursively estimating the mean position and using this position to recalibrate the orientation of the camera, the algorithm is capable of converging near the true location. Testing found that the algorithm is robust against initial conditions, requiring no knowledge of the prior position and only requiring the camera to be aligned to within a hemisphere of tolerance.</p></section>
  </div><div>
    <section><h2>Author Contributions</h2><p>Conceptualization, S.T. and J.C.; methodology, S.T.; software, S.T.; validation, S.T.; formal analysis, S.T.; investigation, S.T.; resources, J.C.; data curation, S.T. and J.C.; writing—original draft preparation, S.T.; writing—review and editing, J.C.; visualization, S.T.; supervision, J.C.; project administration, J.C. All authors have read and agreed to the published version of the manuscript.</p></section><section><h2>Funding</h2><p>This research received no external funding.</p></section><section><h2>Data Availability Statement</h2><p>The data presented in this study are available on request from the corresponding author.</p></section><section id="html-ack"><h2>Acknowledgments</h2><p>This work was supported by Scope Global Pty Ltd. under the Commonwealth Scholarships Program, and the Commonwealth of South Australia under the Australian Government Research Training Program.</p></section><section><h2>Conflicts of Interest</h2><p>The authors declare no conflict of interest.</p></section><section id="html-references_list"><h2>References</h2><ol><li id="B1-drones-08-00652" data-content="1.">Gatty, H. Aerial Navigation—Methods and Equipment. <span>SAE Trans.</span> <b>1932</b>, <span>27</span>, 153–170. [<a href="https://scholar.google.com/scholar_lookup?title=Aerial+Navigation%E2%80%94Methods+and+Equipment&amp;author=Gatty,+H.&amp;publication_year=1932&amp;journal=SAE+Trans.&amp;volume=27&amp;pages=153%E2%80%93170&amp;doi=10.4271/320042" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.4271/320042" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B2-drones-08-00652" data-content="2.">Pappalardi, F.; Dunham, S.; LeBlang, M.; Jones, T.; Bangert, J.; Kaplan, G. Alternatives to GPS. In Proceedings of the MTS/IEEE Oceans 2001. An Ocean Odyssey. Conference Proceedings (IEEE Cat. No. 01CH37295), Honolulu, HI, USA, 5–8 November 2001; IEEE: New York, NY, USA, 2001; Volume 3, pp. 1452–1459. [<a href="https://scholar.google.com/scholar_lookup?title=Alternatives+to+GPS&amp;conference=Proceedings+of+the+MTS/IEEE+Oceans+2001.+An+Ocean+Odyssey.+Conference+Proceedings+(IEEE+Cat.+No.+01CH37295)&amp;author=Pappalardi,+F.&amp;author=Dunham,+S.&amp;author=LeBlang,+M.&amp;author=Jones,+T.&amp;author=Bangert,+J.&amp;author=Kaplan,+G.&amp;publication_year=2001&amp;pages=1452%E2%80%931459&amp;doi=10.1109/OCEANS.2001.968047" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1109/OCEANS.2001.968047" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B3-drones-08-00652" data-content="3.">Ali, J.; Zhang, C.; Fang, J. An algorithm for astro-inertial navigation using CCD star sensors. <span>Aerosp. Sci. Technol.</span> <b>2006</b>, <span>10</span>, 449–454. [<a href="https://scholar.google.com/scholar_lookup?title=An+algorithm+for+astro-inertial+navigation+using+CCD+star+sensors&amp;author=Ali,+J.&amp;author=Zhang,+C.&amp;author=Fang,+J.&amp;publication_year=2006&amp;journal=Aerosp.+Sci.+Technol.&amp;volume=10&amp;pages=449%E2%80%93454&amp;doi=10.1016/j.ast.2006.01.004" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1016/j.ast.2006.01.004" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B4-drones-08-00652" data-content="4.">Ting, F.; Xiaoming, H. Inertial/celestial integrated navigation algorithm for long endurance unmanned aerial vehicle. <span>Acta Tech. CSAV (Ceskoslov. Akad. Ved.)</span> <b>2017</b>, <span>62</span>, 205–217. [<a href="https://scholar.google.com/scholar_lookup?title=Inertial/celestial+integrated+navigation+algorithm+for+long+endurance+unmanned+aerial+vehicle&amp;author=Ting,+F.&amp;author=Xiaoming,+H.&amp;publication_year=2017&amp;journal=Acta+Tech.+CSAV+(Ceskoslov.+Akad.+Ved.)&amp;volume=62&amp;pages=205%E2%80%93217" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li><li id="B5-drones-08-00652" data-content="5.">Levine, S.; Dennis, R.; Bachman, K.L. Strapdown Astro-Inertial Navigation Utilizing the Optical Wide-angle Lens Startracker. <span>Navigation</span> <b>1990</b>, <span>37</span>, 347–362. [<a href="https://scholar.google.com/scholar_lookup?title=Strapdown+Astro-Inertial+Navigation+Utilizing+the+Optical+Wide-angle+Lens+Startracker&amp;author=Levine,+S.&amp;author=Dennis,+R.&amp;author=Bachman,+K.L.&amp;publication_year=1990&amp;journal=Navigation&amp;volume=37&amp;pages=347%E2%80%93362&amp;doi=10.1002/j.2161-4296.1990.tb01561.x" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1002/j.2161-4296.1990.tb01561.x" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B6-drones-08-00652" data-content="6.">Chen, H.; Gao, H.; Zhang, H. Integrated navigation approaches of vehicle aided by the strapdown celestial angles. <span>Int. J. Adv. Robot. Syst.</span> <b>2020</b>, <span>17</span>, 1729881420932008. [<a href="https://scholar.google.com/scholar_lookup?title=Integrated+navigation+approaches+of+vehicle+aided+by+the+strapdown+celestial+angles&amp;author=Chen,+H.&amp;author=Gao,+H.&amp;author=Zhang,+H.&amp;publication_year=2020&amp;journal=Int.+J.+Adv.+Robot.+Syst.&amp;volume=17&amp;pages=1729881420932008&amp;doi=10.1177/1729881420932008" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1177/1729881420932008" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B7-drones-08-00652" data-content="7.">Gai, E.; Daly, K.; Harrison, J.; Lemos, L. Star-sensor-based satellite attitude/attitude rate estimator. <span>J. Guid. Control Dyn.</span> <b>1985</b>, <span>8</span>, 560–565. [<a href="https://scholar.google.com/scholar_lookup?title=Star-sensor-based+satellite+attitude/attitude+rate+estimator&amp;author=Gai,+E.&amp;author=Daly,+K.&amp;author=Harrison,+J.&amp;author=Lemos,+L.&amp;publication_year=1985&amp;journal=J.+Guid.+Control+Dyn.&amp;volume=8&amp;pages=560%E2%80%93565&amp;doi=10.2514/3.56393" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.2514/3.56393" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B8-drones-08-00652" data-content="8.">Wang, J.; Chun, J. Attitude determination using a single star sensor and a star density table. <span>J. Guid. Control Dyn.</span> <b>2006</b>, <span>29</span>, 1329–1338. [<a href="https://scholar.google.com/scholar_lookup?title=Attitude+determination+using+a+single+star+sensor+and+a+star+density+table&amp;author=Wang,+J.&amp;author=Chun,+J.&amp;publication_year=2006&amp;journal=J.+Guid.+Control+Dyn.&amp;volume=29&amp;pages=1329%E2%80%931338&amp;doi=10.2514/1.17249" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.2514/1.17249" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B9-drones-08-00652" data-content="9.">Mao, X.; Du, X.; Fang, H. Precise attitude determination strategy for spacecraft based on information fusion of attitude sensors: Gyros/GPS/Star-sensor. <span>Int. J. Aeronaut. Space Sci.</span> <b>2013</b>, <span>14</span>, 91–98. [<a href="https://scholar.google.com/scholar_lookup?title=Precise+attitude+determination+strategy+for+spacecraft+based+on+information+fusion+of+attitude+sensors:+Gyros/GPS/Star-sensor&amp;author=Mao,+X.&amp;author=Du,+X.&amp;author=Fang,+H.&amp;publication_year=2013&amp;journal=Int.+J.+Aeronaut.+Space+Sci.&amp;volume=14&amp;pages=91%E2%80%9398&amp;doi=10.5139/IJASS.2013.14.1.91" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.5139/IJASS.2013.14.1.91" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B10-drones-08-00652" data-content="10.">Guo, C.; Tong, X.; Liu, S.; Lu, X.; Chen, P.; Jin, Y.; Xie, H. High-precision attitude estimation method of star sensors and gyro based on complementary filter and unscented Kalman filter. <span>Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.</span> <b>2017</b>, <span>42</span>, 49–53. [<a href="https://scholar.google.com/scholar_lookup?title=High-precision+attitude+estimation+method+of+star+sensors+and+gyro+based+on+complementary+filter+and+unscented+Kalman+filter&amp;author=Guo,+C.&amp;author=Tong,+X.&amp;author=Liu,+S.&amp;author=Lu,+X.&amp;author=Chen,+P.&amp;author=Jin,+Y.&amp;author=Xie,+H.&amp;publication_year=2017&amp;journal=Int.+Arch.+Photogramm.+Remote+Sens.+Spat.+Inf.+Sci.&amp;volume=42&amp;pages=49%E2%80%9353&amp;doi=10.5194/isprs-archives-XLII-3-W1-49-2017" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.5194/isprs-archives-XLII-3-W1-49-2017" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B11-drones-08-00652" data-content="11.">De Almeida Martins, F.; Carrara, V.; d’Amore, R. Positionless Attitude Estimation with Integrated Star and Horizon Sensors. <span>IEEE Access</span> <b>2023</b>, <span>12</span>, 2340–2348. [<a href="https://scholar.google.com/scholar_lookup?title=Positionless+Attitude+Estimation+with+Integrated+Star+and+Horizon+Sensors&amp;author=De+Almeida+Martins,+F.&amp;author=Carrara,+V.&amp;author=d%E2%80%99Amore,+R.&amp;publication_year=2023&amp;journal=IEEE+Access&amp;volume=12&amp;pages=2340%E2%80%932348&amp;doi=10.1109/ACCESS.2023.3348077" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1109/ACCESS.2023.3348077" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B12-drones-08-00652" data-content="12.">Gao, Z.; Wang, H.; Wang, W.; Xu, Y. SIMU/Triple star sensors integrated navigation method of HALE UAV based on atmospheric refraction correction. <span>J. Navig.</span> <b>2022</b>, <span>75</span>, 704–726. [<a href="https://scholar.google.com/scholar_lookup?title=SIMU/Triple+star+sensors+integrated+navigation+method+of+HALE+UAV+based+on+atmospheric+refraction+correction&amp;author=Gao,+Z.&amp;author=Wang,+H.&amp;author=Wang,+W.&amp;author=Xu,+Y.&amp;publication_year=2022&amp;journal=J.+Navig.&amp;volume=75&amp;pages=704%E2%80%93726&amp;doi=10.1017/S037346332100093X" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1017/S037346332100093X" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B13-drones-08-00652" data-content="13.">Teague, S.; Chahl, J. Imagery synthesis for drone celestial navigation simulation. <span>Drones</span> <b>2022</b>, <span>6</span>, 207. [<a href="https://scholar.google.com/scholar_lookup?title=Imagery+synthesis+for+drone+celestial+navigation+simulation&amp;author=Teague,+S.&amp;author=Chahl,+J.&amp;publication_year=2022&amp;journal=Drones&amp;volume=6&amp;pages=207&amp;doi=10.3390/drones6080207" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.3390/drones6080207" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B14-drones-08-00652" data-content="14.">Teague, S.; Chahl, J. Strapdown Celestial Attitude Estimation from Long Exposure Images for UAV Navigation. <span>Drones</span> <b>2023</b>, <span>7</span>, 52. [<a href="https://scholar.google.com/scholar_lookup?title=Strapdown+Celestial+Attitude+Estimation+from+Long+Exposure+Images+for+UAV+Navigation&amp;author=Teague,+S.&amp;author=Chahl,+J.&amp;publication_year=2023&amp;journal=Drones&amp;volume=7&amp;pages=52&amp;doi=10.3390/drones7010052" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.3390/drones7010052" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B15-drones-08-00652" data-content="15.">Zhang, H.; Zhang, C.; Tong, S.; Wang, R.; Li, C.; Tian, Y.; He, D.; Jiang, D.; Pu, J. Celestial Navigation and Positioning Method Based on Super-Large Field of View Star Sensors. In Proceedings of the China Satellite Navigation Conference, Jinan, China, 22–24 May 2024; Springer: Berlin/Heidelberg, Germany, 2023; pp. 475–487. [<a href="https://scholar.google.com/scholar_lookup?title=Celestial+Navigation+and+Positioning+Method+Based+on+Super-Large+Field+of+View+Star+Sensors&amp;conference=Proceedings+of+the+China+Satellite+Navigation+Conference&amp;author=Zhang,+H.&amp;author=Zhang,+C.&amp;author=Tong,+S.&amp;author=Wang,+R.&amp;author=Li,+C.&amp;author=Tian,+Y.&amp;author=He,+D.&amp;author=Jiang,+D.&amp;author=Pu,+J.&amp;publication_year=2023&amp;pages=475%E2%80%93487&amp;doi=10.1007/978-981-99-6928-9_41" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1007/978-981-99-6928-9_41" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B16-drones-08-00652" data-content="16.">Van Allen, J.A. Basic principles of celestial navigation. <span>Am. J. Phys.</span> <b>2004</b>, <span>72</span>, 1418–1424. [<a href="https://scholar.google.com/scholar_lookup?title=Basic+principles+of+celestial+navigation&amp;author=Van+Allen,+J.A.&amp;publication_year=2004&amp;journal=Am.+J.+Phys.&amp;volume=72&amp;pages=1418%E2%80%931424&amp;doi=10.1119/1.1778391" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1119/1.1778391" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B17-drones-08-00652" data-content="17.">Liebe, C.C. Accuracy performance of star trackers-a tutorial. <span>IEEE Trans. Aerosp. Electron. Syst.</span> <b>2002</b>, <span>38</span>, 587–599. [<a href="https://scholar.google.com/scholar_lookup?title=Accuracy+performance+of+star+trackers-a+tutorial&amp;author=Liebe,+C.C.&amp;publication_year=2002&amp;journal=IEEE+Trans.+Aerosp.+Electron.+Syst.&amp;volume=38&amp;pages=587%E2%80%93599&amp;doi=10.1109/TAES.2002.1008988" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1109/TAES.2002.1008988" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B18-drones-08-00652" data-content="18.">Delabie, T.; Schutter, J.D.; Vandenbussche, B. An accurate and efficient gaussian fit centroiding algorithm for star trackers. <span>J. Astronaut. Sci.</span> <b>2014</b>, <span>61</span>, 60–84. [<a href="https://scholar.google.com/scholar_lookup?title=An+accurate+and+efficient+gaussian+fit+centroiding+algorithm+for+star+trackers&amp;author=Delabie,+T.&amp;author=Schutter,+J.D.&amp;author=Vandenbussche,+B.&amp;publication_year=2014&amp;journal=J.+Astronaut.+Sci.&amp;volume=61&amp;pages=60%E2%80%9384&amp;doi=10.1007/s40295-015-0034-4" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1007/s40295-015-0034-4" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B19-drones-08-00652" data-content="19.">Teague, S.; Chahl, J. Bootstrap geometric ground calibration method for wide angle star sensors. <span>JOSA A</span> <b>2024</b>, <span>41</span>, 654–663. [<a href="https://scholar.google.com/scholar_lookup?title=Bootstrap+geometric+ground+calibration+method+for+wide+angle+star+sensors&amp;author=Teague,+S.&amp;author=Chahl,+J.&amp;publication_year=2024&amp;journal=JOSA+A&amp;volume=41&amp;pages=654%E2%80%93663&amp;doi=10.1364/JOSAA.517943" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1364/JOSAA.517943" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B20-drones-08-00652" data-content="20.">Wei, X.; Zhang, G.; Jiang, J. Star identification algorithm based on log-polar transform. <span>J. Aerosp. Comput. Inf. Commun.</span> <b>2009</b>, <span>6</span>, 483–490. [<a href="https://scholar.google.com/scholar_lookup?title=Star+identification+algorithm+based+on+log-polar+transform&amp;author=Wei,+X.&amp;author=Zhang,+G.&amp;author=Jiang,+J.&amp;publication_year=2009&amp;journal=J.+Aerosp.+Comput.+Inf.+Commun.&amp;volume=6&amp;pages=483%E2%80%93490&amp;doi=10.2514/1.30393" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.2514/1.30393" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B21-drones-08-00652" data-content="21.">Lawrence, J.; Bernal, J.; Witzgall, C. A purely algebraic justification of the Kabsch-Umeyama algorithm. <span>J. Res. Natl. Inst. Stand. Technol.</span> <b>2019</b>, <span>124</span>, 1. [<a href="https://scholar.google.com/scholar_lookup?title=A+purely+algebraic+justification+of+the+Kabsch-Umeyama+algorithm&amp;author=Lawrence,+J.&amp;author=Bernal,+J.&amp;author=Witzgall,+C.&amp;publication_year=2019&amp;journal=J.+Res.+Natl.+Inst.+Stand.+Technol.&amp;volume=124&amp;pages=1&amp;doi=10.6028/jres.124.028" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.6028/jres.124.028" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B22-drones-08-00652" data-content="22.">Gebre-Egziabher, D.; Powell, J.; Enge, P. Design and performance analysis of a low-cost aided dead reckoning navigation system. <span>Gyroscopy Navig.</span> <b>2001</b>, <span>4</span>, 83–92. [<a href="https://scholar.google.com/scholar_lookup?title=Design+and+performance+analysis+of+a+low-cost+aided+dead+reckoning+navigation+system&amp;author=Gebre-Egziabher,+D.&amp;author=Powell,+J.&amp;author=Enge,+P.&amp;publication_year=2001&amp;journal=Gyroscopy+Navig.&amp;volume=4&amp;pages=83%E2%80%9392" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li><li id="B23-drones-08-00652" data-content="23.">Wang, W.; Wei, X.; Li, J.; Zhang, G. Guide star catalog generation for short-wave infrared (SWIR) all-time star sensor. <span>Rev. Sci. Instrum.</span> <b>2018</b>, <span>89</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Guide+star+catalog+generation+for+short-wave+infrared+(SWIR)+all-time+star+sensor&amp;author=Wang,+W.&amp;author=Wei,+X.&amp;author=Li,+J.&amp;author=Zhang,+G.&amp;publication_year=2018&amp;journal=Rev.+Sci.+Instrum.&amp;volume=89&amp;doi=10.1063/1.5023157" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1063/1.5023157" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li><li id="B24-drones-08-00652" data-content="24.">Ni, Y.; Wang, X.; Dai, D.; Tan, W.; Qin, S. Adaptive section non-uniformity correction method of short-wave infrared star images for a star tracker. <span>Appl. Opt.</span> <b>2022</b>, <span>61</span>, 6992–6999. [<a href="https://scholar.google.com/scholar_lookup?title=Adaptive+section+non-uniformity+correction+method+of+short-wave+infrared+star+images+for+a+star+tracker&amp;author=Ni,+Y.&amp;author=Wang,+X.&amp;author=Dai,+D.&amp;author=Tan,+W.&amp;author=Qin,+S.&amp;publication_year=2022&amp;journal=Appl.+Opt.&amp;volume=61&amp;pages=6992%E2%80%936999&amp;doi=10.1364/AO.457458" target="_blank" rel="noopener noreferrer">Google Scholar</a>] [<a href="https://doi.org/10.1364/AO.457458" target="_blank" rel="noopener noreferrer">CrossRef</a>]</li></ol></section><section id="FiguresandTables" type="display-objects"><div id="drones-08-00652-f001">
    <p><b>Figure 1.</b>
      The circles around points </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p> show the intersection of their respective planes with the terrestrial sphere, forming circles about which the observation could have been made. Points </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p> are taken from the observed stars, located such that their respective star is observed at the zenith. The zenith-angles </p><math display="inline"><semantics>
  <msub>
    <mi>ζ</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>ζ</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p> represent the angle at which the stars were actually observed. In this case, two stars were observed, resulting in two potential points (</p><math display="inline"><semantics>
  <msub>
    <mi>P</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>P</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p>) at which this observation could have been made. Additional observations serve to reduce this ambiguity.
</p><!--     <p><a class="html-figpopup" href="#fig_body_display_drones-08-00652-f001">
      Click here to enlarge figure
    </a></p> -->

  </div>
<div id="fig_body_display_drones-08-00652-f001">
  <div> <p><b>Figure 1.</b>
      The circles around points </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p> show the intersection of their respective planes with the terrestrial sphere, forming circles about which the observation could have been made. Points </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>S</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p> are taken from the observed stars, located such that their respective star is observed at the zenith. The zenith-angles </p><math display="inline"><semantics>
  <msub>
    <mi>ζ</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>ζ</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p> represent the angle at which the stars were actually observed. In this case, two stars were observed, resulting in two potential points (</p><math display="inline"><semantics>
  <msub>
    <mi>P</mi>
    <mn>1</mn>
  </msub>
</semantics></math><p> and </p><math display="inline"><semantics>
  <msub>
    <mi>P</mi>
    <mn>2</mn>
  </msub>
</semantics></math><p>) at which this observation could have been made. Additional observations serve to reduce this ambiguity.</p></div>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g001.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g001.png" alt="Drones 08 00652 g001" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g001.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g001.png"></p>
</div>
<div id="drones-08-00652-f002">
  
  <p><b>Figure 2.</b>
      Star tracker operating on video footage captured in-flight. Image intensity is amplified 10×.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f002">
  <p><b>Figure 2.</b>
      Star tracker operating on video footage captured in-flight. Image intensity is amplified 10×.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g002.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g002.png" alt="Drones 08 00652 g002" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g002.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g002.png"></p>
</div>
<div id="drones-08-00652-f003">
  
  <p><b>Figure 3.</b>
      Platform layout of the autopilot and celestial payload within the airframe.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f003">
  <p><b>Figure 3.</b>
      Platform layout of the autopilot and celestial payload within the airframe.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g003.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g003.png" alt="Drones 08 00652 g003" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g003.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g003.png"></p>
</div>
<div id="drones-08-00652-f004">
  
  <p><b>Figure 4.</b>
      The celestial payload, consisting of a Raspberry Pi 5 and an Alvium 1800 U-240 monochrome sensor fitted with a 6 mm f/1.4 wide angle lens.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f004">
  <p><b>Figure 4.</b>
      The celestial payload, consisting of a Raspberry Pi 5 and an Alvium 1800 U-240 monochrome sensor fitted with a 6 mm f/1.4 wide angle lens.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g004.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g004.png" alt="Drones 08 00652 g004" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g004.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g004.png"></p>
</div>
<div id="drones-08-00652-f005">
  
  <p><b>Figure 5.</b>
      True camera orientation in the aircraft body frame, as calculated using a combination of stellar observations, aircraft attitude, and GPS data. Data are captured from a straight segment of flight over 89.5 s (895 video frames). <b>Top</b>: Calculated camera yaw angle in aircraft body frame. <b>Middle</b>: Calculated camera pitch angle in aircraft body frame. <b>Bottom</b>: Calculated camera roll angle in aircraft body frame.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f005">
  <p><b>Figure 5.</b>
      True camera orientation in the aircraft body frame, as calculated using a combination of stellar observations, aircraft attitude, and GPS data. Data are captured from a straight segment of flight over 89.5 s (895 video frames). <b>Top</b>: Calculated camera yaw angle in aircraft body frame. <b>Middle</b>: Calculated camera pitch angle in aircraft body frame. <b>Bottom</b>: Calculated camera roll angle in aircraft body frame.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g005.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g005.png" alt="Drones 08 00652 g005" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g005.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g005.png"></p>
</div>
<div id="drones-08-00652-f006">
  
  <p><b>Figure 6.</b>
      Position estimation over a an 89.5 s straight segment of flight. It can be seen that, by assuming the camera orientation is fixed, significant positional error makes its way into the estimate. <b>Top</b>: Latitude estimated using celestial imagery with Ardupilot AHRS. <b>Bottom</b>: Longitude estimated using celestial imagery with Ardupilot AHRS.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f006">
  <p><b>Figure 6.</b>
      Position estimation over a an 89.5 s straight segment of flight. It can be seen that, by assuming the camera orientation is fixed, significant positional error makes its way into the estimate. <b>Top</b>: Latitude estimated using celestial imagery with Ardupilot AHRS. <b>Bottom</b>: Longitude estimated using celestial imagery with Ardupilot AHRS.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g006.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g006.png" alt="Drones 08 00652 g006" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g006.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g006.png"></p>
</div>
<div id="drones-08-00652-f007">
  
  <p><b>Figure 7.</b>
      Visualization of the position estimates as the algorithm converges on the location of the aircraft. Each blue point represents an independent position that was calculated from an image frame, the red dot represent the estimated position taken from the mean of the individual estimates, and the yellow dot represents the true center of the aircraft’s orbit.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f007">
  <p><b>Figure 7.</b>
      Visualization of the position estimates as the algorithm converges on the location of the aircraft. Each blue point represents an independent position that was calculated from an image frame, the red dot represent the estimated position taken from the mean of the individual estimates, and the yellow dot represents the true center of the aircraft’s orbit.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g007.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g007.png" alt="Drones 08 00652 g007" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g007.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g007.png"></p>
</div>
<div id="drones-08-00652-f008">
  
  <p><b>Figure 8.</b>
      Plot of the standard error in pitch and variance versus the true error. It can be seen that the relationship is approximately linear.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f008">
  <p><b>Figure 8.</b>
      Plot of the standard error in pitch and variance versus the true error. It can be seen that the relationship is approximately linear.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g008.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g008.png" alt="Drones 08 00652 g008" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g008.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g008.png"></p>
</div>
<div id="drones-08-00652-f009">
  
  <p><b>Figure 9.</b>
      Visualization of position estimates for a given camera misalignment. It can be seen that as long as the camera is aligned to within 90°, the mean estimated position provides a good approximation of the true position.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f009">
  <p><b>Figure 9.</b>
      Visualization of position estimates for a given camera misalignment. It can be seen that as long as the camera is aligned to within 90°, the mean estimated position provides a good approximation of the true position.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g009.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g009.png" alt="Drones 08 00652 g009" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g009.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g009.png"></p>
</div>
<div id="drones-08-00652-f010">
  
  <p><b>Figure 10.</b>
      Simulated trajectory of the aircraft during a GPS-denied orbit in high wind conditions.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f010">
  <p><b>Figure 10.</b>
      Simulated trajectory of the aircraft during a GPS-denied orbit in high wind conditions.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g010.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g010.png" alt="Drones 08 00652 g010" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g010.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g010.png"></p>
</div>
<div id="drones-08-00652-f011">
  
  <p><b>Figure 11.</b>
      Comparison of position estimation in high wind conditions. It can be seen that the course followed by a GPS-guided orbit introduces errors in the estimation process. The GPS-denied orbit follows a fixed-attitude orbit, resulting in drift, but ultimately yielding a more accurate position.
</p>
</div>
<div id="fig_body_display_drones-08-00652-f011">
  <p><b>Figure 11.</b>
      Comparison of position estimation in high wind conditions. It can be seen that the course followed by a GPS-guided orbit introduces errors in the estimation process. The GPS-denied orbit follows a fixed-attitude orbit, resulting in drift, but ultimately yielding a more accurate position.</p>
  <p><img data-large="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g011.png" data-original="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g011.png" alt="Drones 08 00652 g011" data-lsrc="/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g011.png" src="https://www.mdpi.com/drones/drones-08-00652/article_deploy/html/images/drones-08-00652-g011.png"></p>
</div>
<div id="drones-08-00652-t001">
  
  <p><b>Table 1.</b>
    Flight plan for the test flight.
  </p>
</div>
<div id="table_body_display_drones-08-00652-t001">
  

      <p><b>Table 1.</b>
    Flight plan for the test flight.</p>
      <table>
        <thead><tr><th>Description</th><th>Direction</th><th>Repeats</th><th>Radius (m)</th><th>Altitude (m)</th></tr></thead><tbody><tr><td>Takeoff</td><td> </td><td> </td><td> </td><td>30</td></tr><tr><td>Orbit to Altitude</td><td>CCW</td><td>4</td><td>300</td><td>800</td></tr><tr><td>Straight Legs</td><td>N/S</td><td>6</td><td>2500</td><td>800</td></tr><tr><td>Orbit</td><td>CW</td><td>1</td><td>1200</td><td>800</td></tr><tr><td>Orbit</td><td>CW</td><td>2</td><td>600</td><td>800</td></tr><tr><td>Orbit</td><td>CCW</td><td>1</td><td>600</td><td>800</td></tr><tr><td>Orbit</td><td>CCW</td><td>1</td><td>1200</td><td>800</td></tr><tr><td>Orbit to Altitude</td><td>CCW</td><td>1</td><td>300</td><td>100</td></tr><tr><td>Land</td><td> </td><td> </td><td> </td><td>0</td></tr></tbody>
      </table>



</div>
<div id="drones-08-00652-t002">
  
  <p><b>Table 2.</b>
    Celestial positioning results.
  </p>
</div>
<div id="table_body_display_drones-08-00652-t002">
  

      <p><b>Table 2.</b>
    Celestial positioning results.</p>
      <table>
        <thead><tr><th>Description</th><th>Direction</th><th>Radius (m)</th><th>Pos. Error (km)</th><th>Iterations</th></tr></thead><tbody><tr><td>Orbit to Altitude (1)</td><td>CCW</td><td>300</td><td>3.56</td><td>5</td></tr><tr><td>Orbit to Altitude (2)</td><td>CCW</td><td>300</td><td>7.18</td><td>4</td></tr><tr><td>Orbit to Altitude (3)</td><td>CCW</td><td>300</td><td>9.67</td><td>4</td></tr><tr><td>Orbit to Altitude (4)</td><td>CCW</td><td>300</td><td>9.89</td><td>4</td></tr><tr><td>Orbit (5)</td><td>CW</td><td>1200</td><td>2.21</td><td>4</td></tr><tr><td>Orbit (6)</td><td>CW</td><td>600</td><td>3.48</td><td>5</td></tr><tr><td>Orbit (7)</td><td>CW</td><td>600</td><td>2.54</td><td>5</td></tr><tr><td>Orbit (8)</td><td>CCW</td><td>600</td><td>1.73</td><td>5</td></tr><tr><td>Orbit (9)</td><td>CCW</td><td>1200</td><td>2.90</td><td>4</td></tr><tr><td>Orbit to Altitude (10)</td><td>CCW</td><td>300</td><td>7.16</td><td>6</td></tr></tbody>
      </table>



</div>
<div id="drones-08-00652-t003">
  
  <p><b>Table 3.</b>
    Sensitivity to initial camera calibration.
  </p>
</div>
<div id="table_body_display_drones-08-00652-t003">
  

      <p><b>Table 3.</b>
    Sensitivity to initial camera calibration.</p>
      <table>
        <thead><tr><th>Initial Orientation Error</th><th>Final Pos. Error (km)</th><th>Iterations</th></tr></thead><tbody><tr><td>Nil (calibrated)</td><td>2.47</td><td>2</td></tr><tr><td>Initial Guess (<math display="inline"><semantics>
  <mrow>
    <mo>≈</mo>
    <msup>
      <mn>5</mn>
      <mo>∘</mo>
    </msup>
  </mrow>
</semantics></math>)</td><td>2.49</td><td>4</td></tr><tr><td>45°</td><td>2.46</td><td>5</td></tr><tr><td>60°</td><td>2.51</td><td>5</td></tr><tr><td>85°</td><td>2.49</td><td>6</td></tr><tr><td>120°</td><td>19,987.66</td><td>5</td></tr></tbody>
      </table>



</div>
</section><section><table><tbody><tr id=""><td></td><td><p><b>Disclaimer/Publisher’s Note:</b> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></td></tr></tbody></table></section>
    <section id="html-copyright"><br>© 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer">https://creativecommons.org/licenses/by/4.0/</a>).</section>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using eSIMs with devices that only have a physical SIM slot via a 9eSIM SIM car (279 pts)]]></title>
            <link>https://neilzone.co.uk/2025/01/using-esims-with-devices-that-only-have-a-physical-sim-slot-via-a-9esim-sim-card-with-android-and-linux/</link>
            <guid>42767584</guid>
            <pubDate>Mon, 20 Jan 2025 11:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neilzone.co.uk/2025/01/using-esims-with-devices-that-only-have-a-physical-sim-slot-via-a-9esim-sim-card-with-android-and-linux/">https://neilzone.co.uk/2025/01/using-esims-with-devices-that-only-have-a-physical-sim-slot-via-a-9esim-sim-card-with-android-and-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=42767584">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Do you have a phone, tablet, or laptop (or, well, any device…) which will only take a physical SIM, but with which you’d like to use eSIMs?</p>
<p>Then this is a blogpost for you, as that’s exactly what this is: a physical SIM, onto which one can provision eSIMs, using software to swap between them.</p>
<h2 id="what-i-bought-from-9esim">What I bought from 9eSIM</h2>
<p>I bought the bundle - SIM and smartcard reader - from <a href="https://www.9esim.com/">9eSIM</a>.</p>
<p>The first shipment from China got lost but, after a bit of waiting, they posted another one without complaint. That was shipped by a different delivery company, and it arrived in just over a week.</p>
<p>In the box, I got:</p>
<ul>
<li>
<p>A SIM card, with the usual push-out sections to change it from normal to micro to nano.</p>
<ul>
<li>The SIM was in a blue envelope, not attached to the cardboard saying “9eSIM v2” - at first, I thought “they’ve forgotten to put in the SIM card”.</li>
<li>If you want to use the smartcard reader, <em>do not discard the SIM’s packaging</em>. You will need it to make the smartcard reader work reliably.</li>
</ul>
</li>
<li>
<p>A SIM card adapter.</p>
</li>
<li>
<p>A USB smartcard reader, and a USB-A to USB-C adapter.</p>
</li>
</ul>
<p>Including delivery, it came to about £30.</p>
<h2 id="use-the-sims-packaging-to-make-it-fit-in-the-smartcard-reader">Use the SIM’s packaging to make it fit in the smartcard reader</h2>
<p>I spent a <em>lot</em> of time trying to get the SIM and smartcard reader working.</p>
<p>The solution was a frustratingly simple one: the best way to use the supplied smartcard reader is to use the original packaging for the SIM.</p>
<p>This packaging is the right size to slide into the reader while positioning the SIM’s contacts over the contact points on the reader. I will keep that together with the smartcard reader.</p>
<p>When I realised that - rather than trying to slide the popped-out SIM into the right place and keep it there - it Just Worked.</p>
<h2 id="adding-and-switching-esims">Adding and switching eSIMs</h2>
<p>The SIM card is advertised as have “a memory capacity of 1.6M, [which] can store up to 50 groups of eSIM profile data”.</p>
<p>To make use of it, one needs to download one or more eSIMs to the SIM.</p>
<p>To do this, and to switch between profiles, one needs to use a “Local Profile Agent” (or “LPA”).</p>
<p>I tested the process for this using both Android and Linux, and both worked just fine.</p>
<h2 id="test-esim-profiles-you-can-try-to-for-free">Test eSIM profiles you can try to for free</h2>
<p>While I was getting used to how it worked, I didn’t want to buy an actual eSIM.</p>
<p>Fortunately, there are a couple of options.</p>
<p>First, there are four official <a href="https://source.android.com/docs/core/connect/esim-test-profiles">Android test eSIM profiles</a></p>
<p>While I could start to provision these, I could not download them, with what appears to be a TLS error.</p>
<p>Second, osmocom has a <a href="https://euicc-manual.osmocom.org/docs/rsp/known-test-profile/">very useful page of other test profiles</a>.</p>
<p>I was able to install test eSIM profiles for <a href="https://qr.esim.tf/1$rsp.truphone.com$QR-G-5C-1LS-1W1Z9P7">TruPhone</a> and <a href="https://qr.esim.tf/1$rsp.truphone.com$QRF-SPEEDTEST">TruPhone / Speedtest</a>.</p>
<p>These provisioned correctly onto the SIM. I could not use them to make or receive calls or start a data session - which was fine - but they did show up in Android’s SIM card manager as available eSIMs.</p>
<h2 id="adding-and-switching-esims-via-android">Adding and switching eSIMs via Android</h2>
<p>There is an .apk from the 9eSIM site.</p>
<p>I wasn’t too keen on using this but, well, it worked, and is probably the simplest option.</p>
<p>I tested it first by putting the SIM into my phone, replacing my main physical SIM. This was recognised by the app immediately.</p>
<p>Once I had worked out how to correctly seat the SIM in the reader, I tried that too, using a USB-C hub to connect the smartcard reader to my phone. That worked fine too.</p>
<p>Provisioning eSIMs using the Android application was easy as long as the QR code was on a different screen, since I could just scan the QR code for the eSIM using the camera. I’ve not looked to see if there is a way to use Android to import a QR code on its own screen.</p>
<p>Using the 9eSIM application, one can enable and disable eSIMs, and swap between them. Once enabled, they appeared in Android’s own SIM management settings. I did not need to reboot.</p>
<p>Deleting an eSIM is also easy. One needs to type a security phrase - the name of the eSIM - to trigger deletion, which is a simple means of avoiding accidental deletion.</p>
<h2 id="adding-and-switching-esims-via-linux">Adding and switching eSIMs via Linux</h2>
<p>Since I want to use the SIM with the integrated WWAN modem of a laptop running Linux, I was keen to see if I could get this all to work using Linux and Free software.</p>
<p>So far, I have not found a way of writing profiles to the SIM while it is in the laptop - I need to take it out and put it in the smartcard reader.</p>
<p>And, if I’m going to do that then, from a practical point of view, it is little more effort to hook it up to my phone and swap and provisions eSIMs from there.</p>
<p>Still, I wanted to get it working within Linux and FOSS just because.</p>
<h3 id="the-smartcard-reader-and-linux">The smartcard reader and Linux</h3>
<p>Connecting the smartcard reader and running <code>lsusb</code>:</p>
<pre tabindex="0"><code>Bus 001 Device 011: ID 058f:9540 Alcor Micro Corp. AU9540 Smartcard Reader
</code></pre><p>It looks like this is a quite common smartcard reader, sometimes built into laptops.</p>
<p><code>lsusb -s 1:11 -v</code>:</p>
<pre tabindex="0"><code>Bus 001 Device 011: ID 058f:9540 Alcor Micro Corp. AU9540 Smartcard Reader
Negotiated speed: Full Speed (12Mbps)
Device Descriptor:
  bLength                18
  bDescriptorType         1
  bcdUSB               2.01
  bDeviceClass            0 [unknown]
  bDeviceSubClass         0 [unknown]
  bDeviceProtocol         0 
  bMaxPacketSize0         8
  idVendor           0x058f Alcor Micro Corp.
  idProduct          0x9540 AU9540 Smartcard Reader
  bcdDevice            1.20
  iManufacturer           1 Generic
  iProduct                2 EMV Smartcard Reader
  iSerial                 0 
  bNumConfigurations      1
  Configuration Descriptor:
    bLength                 9
    bDescriptorType         2
    wTotalLength       0x005d
    bNumInterfaces          1
    bConfigurationValue     1
    iConfiguration          0 
    bmAttributes         0xa0
      (Bus Powered)
      Remote Wakeup
    MaxPower               50mA
    Interface Descriptor:
      bLength                 9
      bDescriptorType         4
      bInterfaceNumber        0
      bAlternateSetting       0
      bNumEndpoints           3
      bInterfaceClass        11 Chip/SmartCard
      bInterfaceSubClass      0 [unknown]
      bInterfaceProtocol      0 
      iInterface              0 
      ChipCard Interface Descriptor:
        bLength                54
        bDescriptorType        33
        bcdCCID              1.10
        nMaxSlotIndex           0
        bVoltageSupport         7  5.0V 3.0V 1.8V 
        dwProtocols             3  T=0 T=1
        dwDefaultClock       3700
        dwMaxiumumClock     12000
        bNumClockSupported      3
        dwDataRate           9946 bps
        dwMaxDataRate      688172 bps
        bNumDataRatesSupp.    138
        dwMaxIFSD             254
        dwSyncProtocols  00000007  2-wire 3-wire I2C
        dwMechanical     00000000 
        dwFeatures       000404BE
          Auto configuration based on ATR
          Auto activation on insert
          Auto voltage selection
          Auto clock change
          Auto baud rate change
          Auto PPS made by CCID
          Auto IFSD exchange (T=1)
          Short and extended APDU level exchange
        dwMaxCCIDMsgLen       272
        bClassGetResponse    echo
        bClassEnvelope       echo
        wlcdLayout           none
        bPINSupport             0 
        bMaxCCIDBusySlots       1
      Endpoint Descriptor:
        bLength                 7
        bDescriptorType         5
        bEndpointAddress     0x81  EP 1 IN
        bmAttributes            3
          Transfer Type            Interrupt
          Synch Type               None
          Usage Type               Data
        wMaxPacketSize     0x0004  1x 4 bytes
        bInterval               1
      Endpoint Descriptor:
        bLength                 7
        bDescriptorType         5
        bEndpointAddress     0x02  EP 2 OUT
        bmAttributes            2
          Transfer Type            Bulk
          Synch Type               None
          Usage Type               Data
        wMaxPacketSize     0x0010  1x 16 bytes
        bInterval               0
      Endpoint Descriptor:
        bLength                 7
        bDescriptorType         5
        bEndpointAddress     0x83  EP 3 IN
        bmAttributes            2
          Transfer Type            Bulk
          Synch Type               None
          Usage Type               Data
        wMaxPacketSize     0x0010  1x 16 bytes
        bInterval               0
Binary Object Store Descriptor:
  bLength                 5
  bDescriptorType        15
  wTotalLength       0x000c
  bNumDeviceCaps          1
  USB 2.0 Extension Device Capability:
    bLength                 7
    bDescriptorType        16
    bDevCapabilityType      2
    bmAttributes   0x00000002
      HIRD Link Power Management (LPM) Supported
Device Status:     0x0000
  (Bus Powered)
</code></pre><p>I spent quite a long time trying to work out why it would not detect the SIM in the smartcard reader (which, as above, was solved by using the supplied packaging material).</p>
<p>I have not reproduced all my troubleshooting here, but it was reasonably obvious from the error messages that, while my laptop recognised and could talk to the smartcard reader, the SIM was not recognised.</p>
<h3 id="lpac"><code>lpac</code></h3>
<p>I started with a command line tool called <a href="https://github.com/estkme-group/lpac"><code>lpac</code></a>.</p>
<p>It has a <a href="https://github.com/estkme-group/lpac/releases/download/v2.2.1/lpac_2.1.0_amd64.deb">.deb release version</a>, which I installed with:</p>
<pre tabindex="0"><code>sudo apt install lpac_2.1.0_amd64.deb -y
</code></pre><p>It installed without error to <code>/usr/bin/lpac</code>.</p>
<p><code>lpac</code>’s output is in json, so run it through <code>jq</code> to prettify it.</p>
<p><code>lpac chip info | jq</code> shows information about the SIM card / eUICC:</p>
<p>(I’ve removed some potentially sensitive/personal bits)</p>
<pre tabindex="0"><code>{
  "type": "lpa",
  "payload": {
    "code": 0,
    "message": "success",
    "data": {
      "eidValue": "8904xxxxx",
      "EuiccConfiguredAddresses": {
        "defaultDpAddress": "smdp-plus-0.eu.cd.rsp.kigen.com",
        "rootDsAddress": "lpa.ds.gsma.com"
      },
      "EUICCInfo2": {
        "profileVersion": "2.3.1",
        "svn": "2.3.0",
        "euiccFirmwareVer": "36.17.4",
        "extCardResource": {
          "installedApplication": 11,
          "freeNonVolatileMemory": 1528320,
          "freeVolatileMemory": 32739
        },
        "uiccCapability": [
          "usimSupport",
          "isimSupport",
          "csimSupport",
          "akaMilenage",
          "akaCave",
          "akaTuak128",
          "akaTuak256",
          "gbaAuthenUsim",
          "gbaAuthenISim",
          "eapClient",
          "javacard",
          "multipleUsimSupport",
          "multipleIsimSupport",
          "multipleCsimSupport"
        ],
        "ts102241Version": "15.1.0",
        "globalplatformVersion": "2.3.0",
        "rspCapability": [
          "additionalProfile",
          "testProfileSupport"
        ],
        "euiccCiPKIdListForVerification": [
          "8137xxxxx"
        ],
        "euiccCiPKIdListForSigning": [
          "8137xxxxx"
        ],
        "euiccCategory": null,
        "ppVersion": "1.0.0",
        "sasAcreditationNumber": "KN-DN-UP-0924",
        "certificationDataObject": {
          "platformLabel": null,
          "discoveryBaseURL": null
        }
      },
      "rulesAuthorisationTable": [
        {
          "pprIds": [
            "ppr1",
            "ppr2"
          ],
          "allowedOperators": [
            {
              "plmn": "eeeeee",
              "gid1": null,
              "gid2": null
            }
          ],
          "pprFlags": []
        }
      ]
    }
  }
}
</code></pre><p>It appears to use a platform run by Kigen for remote SIM provisioning, so it looks like there is a dependency on a third party’s infrastructure to make all this work.</p>
<p>Use <code>lpac profile list | jq</code> to list the downloaded SIMs, and see their ICCID and AID.</p>
<p>To enable / disable downloaded eSIMs, use <code>lpac profile {enable,disable} ICCID/AID | jq</code>.</p>
<p>Using <a href="https://qr.esim.tf/1$rsp.truphone.com$QRF-SPEEDTEST">this test profile</a>, I tried adding/downloading SIMs via <code>lpac</code>.</p>
<p>Specifying the SM-DP+ address (<code>-s</code>) and the matching ID (<code>-m</code>) worked:</p>
<pre tabindex="0"><code>lpac profile download -s rsp.truphone.com -m QRF-SPEEDTEST`
</code></pre><p>Specifying the activation code (<code>-a</code>) in the manner set out in the documentation failed <em>(Edit: quoting issue; see below)</em>:</p>
<pre tabindex="0"><code>lpac profile download -a LPA:1$rsp.truphone.com$QRF-SPEEDTEST | jq
</code></pre><p>It returned:</p>
<pre tabindex="0"><code>{
  "type": "progress",
  "payload": {
    "code": 0,
    "message": "es10b_cancel_session",
    "data": null
  }
}
{
  "type": "progress",
  "payload": {
    "code": 0,
    "message": "es9p_cancel_session",
    "data": null
  }
}
{
  "type": "lpa",
  "payload": {
    "code": -1,
    "message": "activation_code",
    "data": "invalid"
  }
}
</code></pre><p>To check this was not just an issue with the test profiles, I bought a <a href="https://www.lycamobile.co.uk/en/bundles/sim-only-deals/#30-day-plans">30 day, £2.50 LycaMobile eSIM</a> for testing, so that I could try it with an “actual” eSIM, rather than a test eSIM.</p>
<p>Lyca’s email gave me a QR code, but did not specify (explicitly) the SM-DP+ address or matching ID.</p>
<p>The image’s alt-text was just my order number with Lyca.</p>
<p>I used GNOME’s <a href="https://apps.gnome.org/en-GB/Decoder/">“Decoder”</a>, which lets one scan a QR card either from the device’s camera or from a screenshot.</p>
<p>That gave me the full activation code, which looked like this:</p>
<pre tabindex="0"><code>LPA:1$dp-plus-par07-01.oasis-smartsim.com$XHY48-xxxxx-xxxxx-xxxxx$x.x.x.x.x.x.xxxxx.x.x.x.x
</code></pre><p>(I don’t know how much of it is sensitive!)</p>
<p>This too failed using <code>lpac</code>.</p>
<p>I have not dug into <em>why</em> it failed.</p>
<p>I missed the opportunity to test extracting the parameters and pushing them manually into <code>lpac</code> via <code>-s</code> and <code>-m</code> as I had already used EasyLPAC at that point. I suspect that that would have worked.</p>
<p><em>Update</em>: doh, it is just a matter of quoting the string, with single quotes. So:</p>
<pre tabindex="0"><code>lpac profile download -a 'LPA:1$rsp.truphone.com$QRF-BETTERROAMING-PMRDGIR2EARDEIT5'
</code></pre><p>How embarrassing.</p>
<p>I tried to update the <code>lpac</code> documentation to make this more obvious, but <a href="https://github.com/estkme-group/lpac/pull/183#issuecomment-2602304507">the maintainer decided that it wasn’t needed</a>. So I guess this blogpost will have to do :)</p>
<p>Thanks to <a href="https://toot.wales/@tswsl">Tom</a> for that :)</p>
<h3 id="linux-gui-easylpac">Linux GUI: EasyLPAC</h3>
<p>There is a GUI for <code>lpac</code>, called <a href="https://github.com/creamlike1024/EasyLPAC">EasyLPAC</a>.</p>
<p>I used <a href="https://github.com/creamlike1024/EasyLPAC/releases/tag/0.7.7.2">the latest Github release</a>, with the version of <code>lpac</code> that I had already installed.</p>
<p>I did not install it; I just ran it, and it worked.</p>
<p>I tested, on a different machine, the version of EasyLPAC which comes with <code>lpac</code> included, but I could not get this to work. I did not pursue this.</p>
<p>I was able to download an eSIM using EasyLPAC in a few different ways:</p>
<ul>
<li>having an LPA:1 activation code on the system clipboard</li>
<li>having a QR code image on the system clipboard</li>
<li>“scanning an image file”, which consisted of opening a QR code saved as an image file on my computer</li>
</ul>
<p>It was really quite straightforward.</p>
<p>I noted that the instructions say:</p>
<blockquote>
<p>Note: Reading LPA activation code and QRCode from clipboard not working in Wayland</p>
</blockquote>
<p>But they did work for me, using Wayland.</p>
<p>Importing the LycaMobile eSIM, using the details extracted from the QR code, worked.</p>
<h2 id="connectivity-worked-fine-via-linux">Connectivity worked fine via Linux</h2>
<p>I put the 9eSIM into my laptop’s SIM slot, and booted it.</p>
<p>In GNOME’s “Mobile Network” settings, it was recognised as a LycaMobile SIM.</p>
<p>I had to set the APN manually.</p>
<p>It took a couple of minutes for the eSIM to activate and, once activated, I was able to browse the Internet.</p>
<p>So there we go: an eSIM on a physical SIM on a laptop running Debian, with very little effort.</p>
<h2 id="other-options">Other options</h2>
<p>I quite like the look of <a href="https://shop.sysmocom.de/sysmoEUICC1-eUICC-for-consumer-eSIM-RSP/sysmoEUICC1">this Sysmocom SIM</a>.</p>
<p>I’d be interested in giving that a try some point.</p>



  <div>
	<hr>   
	<h2>You may also like:</h2>
	
    
</div>


</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Met Paul Graham Once (738 pts)]]></title>
            <link>http://okayfail.com/2025/i-met-pg-once.html</link>
            <guid>42767507</guid>
            <pubDate>Mon, 20 Jan 2025 11:20:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://okayfail.com/2025/i-met-pg-once.html">http://okayfail.com/2025/i-met-pg-once.html</a>, See on <a href="https://news.ycombinator.com/item?id=42767507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <h5><a href="http://okayfail.com/2025/i-met-pg-once.html">January 16, 2025</a> | <a href="http://okayfail.com/tags/tech.html">#tech</a>, <a href="http://okayfail.com/tags/queer.html">#queer</a> </h5>
    <p data-sourcepos="1:1-1:346"><em>Nota bene: I’ve had a rough 2025 so far. I’m worried that people who used to support, or at least tolerate me, will turn against me out of a desire to conform, to show their obeisance, to the current prevailing winds. I found myself writing this essay to explain why I’ve been feeling so miserable. I sent it to Paul before I published it here.</em></p>
<p data-sourcepos="3:1-3:23">I met Paul Graham once.</p>
<p data-sourcepos="5:1-5:217">It was the summer of 2015, and we were attending Y Combinator, the premier finishing school for startup founders. It was a long and stressful summer, holed up in our apartment in Mountain View, and a great experience.</p>
<p data-sourcepos="7:1-7:44">We benefitted immensely from our time there.</p>
<p data-sourcepos="9:1-9:322">At Y Combinator, there was sort of a curriculum, but they didn’t teach you anything per se. You’re assigned mentors, who you meet weekly, and you are free to book office hours – thirty minutes at a time – with a rotating cast of partners, each and every one of them formidable people, near or at the top of the field.</p>
<p data-sourcepos="11:1-11:74">The mentors applied a neat and very effective trick: they believed in you.</p>
<p data-sourcepos="13:1-13:250">Out of thousands of applicants, you had been chosen, plucked from obscurity, and flown out, and now you were here, in the centre of the (software) universe. They had invested in you, you personally, above and beyond your specific idea for a business.</p>
<p data-sourcepos="15:1-15:182">Now every week you spoke with them, and presented your metrics, and discussed your problems, and, well, you could be doing better, couldn’t you? These results, they were kind of mid.</p>
<p data-sourcepos="17:1-17:299">They didn’t boss us around, or tell us what to do, but we didn’t want to disappoint teacher. Their approval meant a lot. Doors would open. Success was at our fingertips: the summer culminated in Demo Day, a cattle call where we would be presented to investors, and our future might change forever.</p>
<p data-sourcepos="19:1-19:214">We worked harder. We learned how to hustle. We swallowed rejection. We doubled our efforts, bent over our desks, working until we could barely see straight, trying to figure out how to <em>make something people want</em>.</p>
<hr data-sourcepos="21:1-22:0">
<p data-sourcepos="23:1-23:255">One day, we booked a meeting with pg (Paul Graham). He had just retired from the day to day running of the show, handed the reigns over to sama (Sam Altman), and now roamed the halls as an elder statesmen, a congenial and affable uncle, dispensing advice.</p>
<p data-sourcepos="25:1-25:443">We were excited. I don’t think he was ever a <em>hero</em> of mine, but he certainly had influence, made a big impression on me. I had read his essays eight or nine years earlier, during my undergraduate, hunched over a screen in my university’s computer lab, nodding along. I spent way too much time on hackernews. Lisp was cool, I was special for just taking an interest in startups and software, we could do anything if we worked hard enough.</p>
<p data-sourcepos="27:1-27:142">We explained our pitch to him: Appcanary monitors your apps and servers, and lets you know when you’re affected by a security vulnerability.</p>
<p data-sourcepos="29:1-29:278">He thought it was a decent enough idea, but the name, Appcanary, he wasn’t crazy about the name. He was very good at naming companies. He thought about it and told us that, really, we ought to be named Oracle, that would be a great name for us. Descriptive, simple, memorable.</p>
<p data-sourcepos="31:1-31:27">Shame it was taken, though.</p>
<p data-sourcepos="33:1-33:78">We nodded and thanked him, and laughed about it later. No one bats a thousand.</p>
<hr data-sourcepos="35:1-36:0">
<p data-sourcepos="37:1-37:41">YC had a huge positive impact on my life.</p>
<p data-sourcepos="39:1-39:174">People took us more seriously now. Before we were randos, misfits even, but now we were Princes of the Universe. We had rubbed shoulders with royalty, or at least sovereigns.</p>
<p data-sourcepos="41:1-41:87">Someone had believed in us, and pushed us until we understood how to make our own luck.</p>
<p data-sourcepos="43:1-43:360">We grew a lot that summer, but we didn’t raise that much money. A bit, enough to keep us going. I loved California, I liked San Francisco, but I didn’t feel comfortable trying to live there. I felt gross being part of a monied class in a city rapidly hollowing out. I’d had a precarious childhood and early adulthood, and I craved some kind of stability.</p>
<p data-sourcepos="45:1-45:276">Back home, we lived in the Best Neighbourhood in the Last Affordable Apartment In West Toronto. We knew it would reduce our chances for success, but it would double our runway. In the winter, I had started dating this most amazing girl, and I wanted to see where it would go.</p>
<p data-sourcepos="47:1-47:423">Two years later, we realized that everyone thought our product was useful but not <em>that</em> useful. We could get people to pay us hundreds of dollars per month, but not thousands. That’s the death knell of a vc-backed b2b saas sales model. High-touch sales to large companies is not worth it unless you can score thousands of dollars per month. We were too burnt out to pivot to another business idea, and we quietly folded.</p>
<p data-sourcepos="49:1-49:490">It was good timing: almost immediately after, GitHub announced they were going to provide our startup’s features <strong>for free</strong>. We gave them a call, we got them excited. They “acquihired” us as subject matter experts, and paid us a small fee for the intellectual property. We returned something like 40 or 45 cents on the dollar to our investors. Not a great result, but about par for the course. Most startups fail. Some of our Summer 2015 cohort flamed out faster, or more spectacularly.</p>
<p data-sourcepos="51:1-51:95">One of our investors commended us for our ethical behaviour – not everyone returns the money.</p>
<hr data-sourcepos="53:1-54:0">
<p data-sourcepos="55:1-55:137">It’s been almost ten years. After we got hired, Microsoft bought GitHub. I’m still with that amazing girl. We have two kids, a house.</p>
<p data-sourcepos="57:1-57:22">I’m transgender now.</p>
<p data-sourcepos="59:1-59:423">It turns out that I like women so much I’d like to be one of them. Or as close as I can get. I’m happier now, more joyful. I feel in touch with my body, and how I move through the world, in ways I didn’t before. Up until very recently, very few people would confuse me for a woman. It took me a while to remove my facial hair, I still haven’t trained my voice. That’s OK. What is a woman, exactly? I don’t know.</p>
<p data-sourcepos="61:1-61:258">I don’t want to make anyone uncomfortable. For that reason, I like to say that I am “non-binary trans femme”. It’s a mouthful, I know. But asking to be called “they” feels less burdensome, less of a polite fiction, than to ask to be called “she”.</p>
<p data-sourcepos="63:1-63:92">I just want to be treated with respect, and kindness. I don’t think I’m asking for much.</p>
<p data-sourcepos="65:1-65:77">Why is it wrong for me to have more joy in my life? I’m not hurting anyone.</p>
<hr data-sourcepos="67:1-68:0">
<p data-sourcepos="69:1-69:65">A few days ago, Paul Graham published an essay on “Wokeness”.</p>
<p data-sourcepos="71:1-71:436">I skimmed it. I couldn’t finish reading it, it made me too upset. It came a few days after Mark Zuckerberg announced he was going to increase the hate speech people like me receive. It’s not OK to imply someone has a mental disability – unless it’s because they’re queer. He also quietly removed some trivial accomodations he had made for his transgender employees.<sup><a href="http://okayfail.com/2025/i-met-pg-once.html#fn-accomodations" id="fnref-accomodations" data-footnote-ref="">1</a></sup>  <em>That</em> stung. That felt personal, targeted.</p>
<p data-sourcepos="75:1-75:93">I’ve been feeling quite anxious ever since. It feels like the world is crumbling around me.</p>
<p data-sourcepos="77:1-77:352">I’m still not sure what pg thinks “Wokeness” means.<sup><a href="http://okayfail.com/2025/i-met-pg-once.html#fn-performative" id="fnref-performative" data-footnote-ref="">2</a></sup> I know for a fact, that for most people – including many of the people he hangs out with – it just means “left-wing thing I dislike”. I got the impression that he thinks it’s bad, and that companies should purge people who are too woke. Maybe I’m being unfair to him.</p>
<p data-sourcepos="81:1-81:255">The irony is I too dislike nagging, hollow, corporate DEI exercises. In the abstract I was glad they existed<sup><a href="http://okayfail.com/2025/i-met-pg-once.html#fn-dei" id="fnref-dei" data-footnote-ref="">3</a></sup> but the insincerity was palpable. Are “identity politics” just a status game that economically advantaged elites play? I could be convinced.</p>
<hr data-sourcepos="85:1-86:0">
<p data-sourcepos="87:1-87:161">In the 2021 novel “Detransition Baby” the author shares a joke. Transgender women only have one of three jobs: computer programmer, aesthetician, prostitute.</p>
<p data-sourcepos="89:1-89:518">It’s an old joke. More of an observation, really. The director of “Vestidas de Azul”, <a href="https://thefilmstage.com/dressed-in-blue-review-a-long-lost-essential-document-of-spanish-and-lgbtqi-cinema-history-gets-new-life/">a 1983 documentary about trans women in Madrid</a>, had hoped to make a movie about trans women who were lawyers or held important roles in society. Instead he discovered that most trans women were <strong>forced</strong> to be artists, hair dressers, or sex workers – so that’s who he made his movie about.</p>
<p data-sourcepos="91:1-91:79">I’m glad I can be a computer programmer; no one gets to be an artist anymore.</p>
<p data-sourcepos="93:1-93:223">If you haven’t met many trans women, that might sound over-the-top, hyperbolic. But for so long, people like me were strongly discriminated against. Until very recently, we were treated as bywords for freaks, or psycopaths.</p>
<p data-sourcepos="95:1-95:239">In this vein, the other day I saw a scorching, sizzling hot take on Mastodon that read something like: the reason why conservative women are so mad about trans women is because they don’t want to share washrooms with the sex slave caste.</p>
<hr data-sourcepos="97:1-98:0">
<p data-sourcepos="99:1-99:255">The reason why pg’s essay made me so upset, made me feel so dispirited, is because I benefitted directly from his largesse, from a system he set up. His “school” took a chance on me, taught me how to hustle, how to become a Princess of the Universe.</p>
<p data-sourcepos="101:1-101:73">I’m immensely glad for the opportunity. Would I receive it again today?</p>
<p data-sourcepos="103:1-103:262">In many people’s imagination, the word “woke” invokes someone exactly like me. I’m the person who is annoying about their pronouns. I’m the person who feels more comfortable using gender neutral bathrooms.<sup><a href="http://okayfail.com/2025/i-met-pg-once.html#fn-bathrooms" id="fnref-bathrooms" data-footnote-ref="">4</a></sup> I have a passing interest in social justice.</p>
<p data-sourcepos="107:1-107:476">I’m concerned he, or rather, the people who succeeded him, would take one look at me, and decide that I am “too woke”, whatever that means. I worry that my existence, that my living in joy, in a state of grace, is “too woke” to be worth employing. I’m certain he wouldn’t be rude to my face, but he might quietly discriminate against me, say no thanks. He might not even think of it as discrimination, only that I don’t have what it takes. Whatever that means.</p>
<p data-sourcepos="109:1-109:70">I think this is why the current turn in the industry is so unsettling.</p>
<p data-sourcepos="111:1-111:635">It’s mean, and unkind. It’s malicious. Moves like Mark’s, and essays like pg’s, create the permission structure for people to discriminate against me. I’ve already been pushed out of Twitter; the <a href="https://www.theguardian.com/technology/article/2024/sep/05/racism-misogyny-lies-how-did-x-become-so-full-of-hatred-and-is-it-ethical-to-keep-using-it">hate speech</a> and <a href="https://www.salon.com/2024/05/24/twitter-considers-cisgender-a-slur-and-moderates-it-over-actual-slurs/">censorship</a> was too much to deal with. A lot of people feel that treating someone like me with respect is just a trendy moral fashion.<sup><a href="http://okayfail.com/2025/i-met-pg-once.html#fn-conventionally-minded" id="fnref-conventionally-minded" data-footnote-ref="">5</a></sup></p>
<p data-sourcepos="115:1-115:164">Will my next promotion be silently denied? Will a coworker try to disrespect me out of spite? Will I be shut out of big tech? Will anyone invest in my next startup?</p>
<p data-sourcepos="117:1-117:117">I’m better at my job than most. I’d be a better startup founder today than I was in 2015. None of that will matter.</p>
<p data-sourcepos="119:1-119:206">It feels as if people like pg, or at least people he hangs out with, who once upon a time believed in me, who lifted me up, recognized my talent, would now prefer that I be relegated to the sex slave caste.</p>
<p data-sourcepos="121:1-121:9">It hurts.</p>
<section data-footnotes="">
<ol>
<li id="fn-accomodations">
<p data-sourcepos="73:19-73:538">As reported by the <a href="https://www.nytimes.com/2025/01/10/technology/meta-mark-zuckerberg-trump.html">nytimes</a>, </p>
<blockquote>That same day at Meta’s offices in Silicon Valley, Texas and New York, facilities managers were instructed to remove tampons from men’s bathrooms, which the company had provided for nonbinary and transgender employees who use the men’s room and who may have required sanitary pads, two employees said.</blockquote> Why go out of your way to remove them? Do tampons drain your masculine energy? <a href="http://okayfail.com/2025/i-met-pg-once.html#fnref-accomodations" data-footnote-backref="" aria-label="Back to content">↩</a>
</li>
<li id="fn-performative">
<p data-sourcepos="79:18-79:404">He does provide a definition: an aggressively performative focus on social justice. Who decides what is a “performative” focus? That seems to be the question. All sorts of things are a “performance”, cf Judith Butler. Artifacts – our art, our technology, our material culture – express politics, cf Langdon Winner. Racism is bad, but you musn’t be annoying about it? It’s incoherent. <a href="http://okayfail.com/2025/i-met-pg-once.html#fnref-performative" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</li>
<li id="fn-dei">
<p data-sourcepos="83:9-83:78">A small minority of people really do need to be taught how to be kind. <a href="http://okayfail.com/2025/i-met-pg-once.html#fnref-dei" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</li>
<li id="fn-bathrooms">
<p data-sourcepos="105:15-105:213">In bathrooms, sometimes men flinch when they see me, afraid that they walked in through the wrong door. In an airport, it can be charming, affirming even. In a bar with drunk people, it can be scary. <a href="http://okayfail.com/2025/i-met-pg-once.html#fnref-bathrooms" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</li>
<li id="fn-conventionally-minded">
<p data-sourcepos="113:27-113:215">Some frame this as the “aggressively conventional-minded” shutting down free inquiry. I ask you, is there <em>anything</em> more “aggressively independent-minded” than being gender-non-conforming? <a href="http://okayfail.com/2025/i-met-pg-once.html#fnref-conventionally-minded" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section>
    <p><a href="http://okayfail.com/2025/i-met-pg-once.html"># 2025-01-16</a></p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zork: The Great Inner Workings (2020) (148 pts)]]></title>
            <link>https://medium.com/swlh/zork-the-great-inner-workings-b68012952bdc</link>
            <guid>42767132</guid>
            <pubDate>Mon, 20 Jan 2025 10:23:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/swlh/zork-the-great-inner-workings-b68012952bdc">https://medium.com/swlh/zork-the-great-inner-workings-b68012952bdc</a>, See on <a href="https://news.ycombinator.com/item?id=42767132">Hacker News</a></p>
Couldn't get https://medium.com/swlh/zork-the-great-inner-workings-b68012952bdc: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Where do those undergraduate divisibility problems come from? (108 pts)]]></title>
            <link>https://grossack.site/2025/01/16/undergrad-divisibility-problems.html</link>
            <guid>42766825</guid>
            <pubDate>Mon, 20 Jan 2025 09:41:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grossack.site/2025/01/16/undergrad-divisibility-problems.html">https://grossack.site/2025/01/16/undergrad-divisibility-problems.html</a>, See on <a href="https://news.ycombinator.com/item?id=42766825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <h3>
  16 Jan 2025 
  
  
  </h3>

  <p>Oftentimes in your “intro to proofs” class or your first “discrete math” class 
or something similar, you’ll be shown problems of the form “prove that for 
$n^6 + n^3 + 2n^2 + 2n$ is a multiple of $6$ for every $n$”… But where do 
these problems come from? And have you ever stopped to think how magical this 
is? If I gave you some random polynomial in $n$ and asked you if it always 
output multiples of $6$, the answer would almost always be “no”! So if you 
really needed to come up with an example of this phenomenon, how would you do it?
In this blog post, we give one approach!</p>

<p>I want to give some sort of attribution for this, since I remember reading 
about this exact topic… like a <em>long</em> time ago. Maybe 6 or 7 years ago? 
I’m sure that I saved the relevant article<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">1</a></sup> 
in my zotero, but I can’t find it for the life 
of me! Regardless, I want to emphasize that the whole idea for this topic 
(using <a href="https://en.wikipedia.org/wiki/P%C3%B3lya_enumeration_theorem">Pólya-Redfield counting</a> to build these divisibility problems) is not 
mine.</p>

<p>I’ve wanted to write a post on Pólya-Redfield counting for <em>years</em> now, since 
it was a pet topic of mine as an undergrad, but I think I was always planning 
too big a scope. This is a very bite-sized problem, and I won’t go into the 
theory very deeply, so I think it should make for a blog post I can finish in 
a day<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">2</a></sup>.</p>

<p>Let’s get to it!</p>

<hr>

<p>Ok, first, how might we come up with problems like this? We want a polynomial 
$P(n)$ and an integer $k$ so that $P(n)$ is always a multiple of $k$. That is, 
so that $P(n) / k$ is always an integer!</p>

<p>But what are sources of integers? If we put our combinatorial hats on, we learn 
that we had better be <em>counting something</em>! That’s the quickest way to 
ensure that we get an integer answer at the end of the day. So we want a 
polynomial so that as we vary $n$, the value $P(n) / k$ counts… something.</p>

<p>At this point, you might be inspired by <a href="https://en.wikipedia.org/wiki/Burnside%27s_lemma#History:_the_lemma_that_is_not_Burnside's">The Lemma Which is Not Burnside’s</a>, 
which says that when a group $G$ acts on a set $X$, the number of orbits is</p><p>

\[\left | X \big / G \right | = \frac{1}{|G|} \sum_g |X^g|\]

</p><p>where \(X^g = \{ x \mid gx = x \}\) is the set of fixed points of $g$.</p>

<p>This is great, since in some sense it’s “where division comes from”. I don’t 
want to get into <a href="https://en.wikipedia.org/wiki/Categorification">categorification</a> here, but when we say we’re thinking of 
numbers as the cardinality of some set (to guarantee they’re integers) 
we’re really <em>categorifying</em> our problem. There’s been lots of work showing 
how various operations on numbers lift to categorified operations on 
the category of finite sets, and the only way I know of to categorify division 
is to take the orbits of some group action<sup id="fnref:3"><a href="#fn:3" rel="footnote" role="doc-noteref">3</a></sup>. Hopefully this also serves to 
show that categorification doesn’t need to be scary! It can be incredibly 
simple, just thinking about finite sets and what we can do to them…
Though maybe people who read my blog are already convinced of that, haha.</p>

<p>Regardless, this orbit-counting formula is close to what we want! It gives 
us access to division. So if we could only find a family of sets $X_n$, 
all of which admit a $G$-action, then maybe we could have 
$P(n) = \sum_g |X_n^g|$ and thus $P(n)$ will always be divisible by $|G|$, 
since $P(n)/|G|$ counts the orbits $|X_n \big / G|$!</p>

<p>This is exactly what Pólya-Redfield counting buys us! 
I really want to write a blog post with lots of pretty pictures that 
explains this in detail, but maybe just for today I’ll allow myself to be 
a bit less thorough. If you want to see this motivated with pretty pictures, 
I’ll point you to <a href="https://grossack.site/assets/docs/undergrad-divisibility-problems/F23-26-polya-redfield.pdf">some slides</a> by my undergrad advisor Klaus Sutner<sup id="fnref:4"><a href="#fn:4" rel="footnote" role="doc-noteref">4</a></sup>. 
These are from the 2023 version of the class where I first met him back in…
2017? It’s better to not think about that, haha.</p>

<hr>

<p>Moving on, say we have a set $X$ with a $G$-action. Then we think about 
all the ways to “color” $X$ with $n$-many colors. Precisely these are 
functions from \(X \to [n]\), and they pick up a natural $g$ action by sending 
the function $f : X \to [n]$ to the function $(gf)(x) = f(g^{-1}x)$<sup id="fnref:5"><a href="#fn:5" rel="footnote" role="doc-noteref">5</a></sup>. 
These function spaces<sup id="fnref:6"><a href="#fn:6" rel="footnote" role="doc-noteref">6</a></sup> \((X \to [n])\) will be our sets $X_n$, and all that’s left 
is to see how to compute $|X_n \big / G|$, ideally in a way that’s uniform in 
$n$. Now (a corollary of) the main Pólya-Redfield theorem says:</p>

<div><p>

\[\left | (X \to [n]) \big / G \right | = \frac{1}{|G|} \sum_g n^{c(g)}\]

  </p><p>where $c(g)$ is the “cycle count” of $g$. We can view the action of $G$ on $X$ 
as a homomorphism $\alpha$ from $G$ to the symmetric group $\mathfrak{S}_X$. Then 
$\alpha(g) \in \mathfrak{S}_X$ is a permutation, so decomposes into a product 
of cycles. The number $c(g)$ is perhaps the dumbest invariant you can think of:
just count the number of cycles!</p>
</div>

<p>This is exactly what we want, since it tells us that the polynomial 
$P(n) = \sum_g n^{c(g)}$ is always divisible by $|G|$, since the quotient 
is exactly counting the orbits of the action of $G$ on \((X \to [n])\)!</p>

<p>Again, unfortunately I’ll leave the derivation of this formula 
(and the many many other useful things the Pólya-Redfield theory buys you)
for another day, but at least we can do some quick examples!</p>



<p>First, say we want to count the number of bracelets you can make with $6$ 
beads, provided you have $n$ many types of beads available. Obviously if you 
were looking at bracelets in the real world that you can move around, the
following two bracelets are actually the same:</p>

<p>
<img src="https://grossack.site/assets/images/undergrad-divisibility-problems/off-by-rotation.png" width="50%">
</p>

<p>so we want to count the number of ways to <em>color</em> this picture with $n$ 
colors (this is a choice of bead in each position), but only up to the 
obvious $\mathbb{Z} / 6$ action on the space of colorings<sup id="fnref:8"><a href="#fn:8" rel="footnote" role="doc-noteref">7</a></sup>!</p>

<p>
<img src="https://grossack.site/assets/images/undergrad-divisibility-problems/configuration.png" width="50%">
</p>

<p>Now choose an isomorphism between the colorable places of our configuration 
and the standard set of size $6$, for instance, this is likely to be 
a common choice:</p>

<p>
<img src="https://grossack.site/assets/images/undergrad-divisibility-problems/configuration-labelled.png" width="50%">
</p>

<p>After making this identification our action is a map 
$\mathbb{Z}/6 \to \mathfrak{S}_6$, and thus we can compute cycle decompositions
as follows:</p>

<div>

  <table>
    <tbody><tr>
        <td>Element $g \in \mathbb{Z}/6$</td>
        <td>Image in $\mathfrak{S}_6$</td>
        <td>Number of Cycles, $c(g)$</td>
    </tr>
    <tr>
        <td>$0$</td>
        <td>$(1)(2)(3)(4)(5)(6)$</td>
        <td>$6$</td>
    </tr>
    <tr>
        <td>$1$</td>
        <td>$(1 \ 2 \ 3 \ 4 \ 5 \ 6)$</td>
        <td>$1$</td>
    </tr>
    <tr>
        <td>$2$</td>
        <td>$(1 \ 3 \ 5)(2 \ 4 \ 6)$</td>
        <td>$2$</td>
    </tr>
    <tr>
        <td>$3$</td>
        <td>$(1 \ 4)(2 \ 5)(3 \ 6)$</td>
        <td>$3$</td>
    </tr>
    <tr>
        <td>$4$</td>
        <td>$(1 \ 5 \ 3)(2 \ 6 \ 4)$</td>
        <td>$2$</td>
    </tr>
    <tr>
        <td>$5$</td>
        <td>$(1 \ 6 \ 5 \ 4 \ 3 \ 2)$</td>
        <td>$1$</td>
    </tr>
</tbody></table>

</div>

<p>Using this, we see that the number of bracelets with $n$ beads, up to our 
$\mathbb{Z}/6$ action is</p><p>

\[\frac{1}{|G|} \sum_g n^{c(g)} = 
\frac{1}{6} \left ( n^6 + n^1 + n^2 + n^3 + n^2 + n^1 \right ) =
\frac{1}{6} \left ( n^6 + n^3 + 2n^2 + 2n \right )\]

</p><p>Since this is counting the number of orbits, it must be an integer, and so 
for every $n$, the polynomial $P(n) = n^6 + n^3 + 2n^2 + 2n$ has to be 
divisible by $6$, as promised!</p>



<p>Let’s see a harder one, which (in the interest of speed) I stole from Klaus’s 
lectures:</p>

<p>How many ways can you fill a tic-tac-toe board with $X$s and $O$s, up 
to rotation and reflection?</p>

<p>We have configurations like the following 
(I’ve already chosen a bijection between our colorable places and the 
standard set with $9$ elements):</p>

<p>
<img src="https://grossack.site/assets/images/undergrad-divisibility-problems/tic-tac-toe-configuration.png" width="50%">
</p>

<p>Now we want to color each slot $X$ or $O$, and quotient out the action of 
the dihedral group in order to view the following colorings as “the same”
(of course, these aren’t the whole orbit! There’s many other rotations 
and reflections which are also equivalent):</p>

<p>
<img src="https://grossack.site/assets/images/undergrad-divisibility-problems/rotate-and-reflect.png" width="50%">
</p>

<p>Notice we’re also not worried about which colorings come from actual games 
of tic-tac-toe!</p>

<p>How does Pólya-Redfield tell us to proceed? Well, the dihedral group $D_{2 \cdot 4}$ 
has $8$ elements, built out of rotations and reflections. Say that $r$ is 
the clockwise rotation shown above, and $s$ is the horizontal flip shown above.
Then using the numbering system from before, we compute</p>

<p>
<img src="https://grossack.site/assets/images/undergrad-divisibility-problems/r-and-s.png" width="50%">
</p>

<p>so that, in cycle notation:</p><p>

\[r \mapsto (1 \ 7 \ 9 \ 3) (2 \ 4 \ 8 \ 6)(5)\]

\[s \mapsto (1 \ 3)(4 \ 6)(7 \ 9)(2)(5)(8)\]

</p><p>Since $r$ and $s$ generate the whole dihedral group, we’re done with the 
hard work! Now a computer algebra system like <a href="https://sagemath.org/">sage</a> can compute the 
rest of the table from these by multiplying them together:</p>



<p>As a cute exercise for those new to group theory, try computing 
these 8 permutations yourself! Can you figure out which one comes from 
which element of the dihedral group? Can you see how they relate to the 
usual presentation $G = \langle r, s \mid r^4, s^2, srs=r^{-1} \rangle$?</p>

<p>From here it’s easy to read off the polynomial! If we have $n$-many available 
colors to put in each slot of the tic-tac-toe board, then the number of 
possible boards, counted up to rotation and reflection is given by</p><p>

\[\begin{align}
\left | (\mathtt{TicTacToeBoard} \to [n]) \big / G \right | 
&amp;= \frac{1}{|G|} \sum_g n^{c(g)} \\
&amp;= \frac{1}{8} \left ( n^9 + 4n^6 + n^5 + 2n^3 \right )
\end{align}\]

</p><p>Since we’re trying to color the board with only two colors, $X$ and $O$, 
we see the number of ways is</p><p>

\[\frac{1}{8} \left ( 2^9 + 4 \cdot 2^6 + 2^5 + 2 \cdot 2^3 \right )
= 102\]

</p><p>Now we’ve really made two predictions here. First, that 
$P(n) = n^9 + 4n^6 + n^5 + 2n^3$ will be a multiple of $8$ for whichever
$n$ you plug in. Second, that this quotient really <em>is</em> counting the 
tic-tac-toe boards! Let’s take a quick second and ask sage how true those look.</p>

<p>First, we can just plug in a few thousand $n$s and see if we ever hit anything 
other than a multiple of $8$:</p>



<p>Second, we know there’s only $2^9 = 512$ many ways to 2-color a tic-tac-toe 
board without counting rotations and reflections. So it’s not too time 
consuming to just list all of them and remove any we’ve seen before!</p>



<hr>

<p>So there we go! This actually ended up taking two days to write, 
since yesterday I got distracted from my distraction when I was 
talking to a friend about <a href="https://en.wikipedia.org/wiki/Connection_(mathematics)">connections</a> and how 
curvature is related to force in physics. I realized I don’t actually 
understand that as well as I thought I did, so I had to spend some 
time rereading a bunch of physics stuff, which was super fun, even if it took 
a while, haha.</p>

<p>If you’re ever on a deserted island and you find yourself needing polynomials 
whose outputs are always divisible by some fixed number, this is an endless 
source! You might ask if <em>every</em> such polynomial arises from Pólya-Redfield 
counting in this way, and that’s obviously false (since, for instance, 
we’ll never get any constant terms)… But it’s <em>not</em> obviously false that 
every such polynomial arises from Pólya-Redfield counting 
<em>after a change of variables</em>! So with no intuition at all for whether 
it’s true or false, let me pose that as a conjecture:</p>

<div>
  <p>Conjecture:</p>

  <p>If $p$ is a polynomial so that $p(n)$ is a multiple of $k$ for every $n$, 
then there is a set $X$ and a group $G$ of order $k$ and a polynomial $f$ 
sending integers to integers so that</p><p>

\[\frac{1}{k}p(n) \text{ counts the orbits } |(X \to [f(n)]) \big / G|\]

  </p><p>Maybe $f$ can even be taken to be of the form $an+b$, why not. I haven’t 
thought about it either way, haha.</p>
</div>

<p>For anyone interested in thinking about this conjecture, it’ll be nice 
to know that every polynomial sending integers to integers is an integer 
linear combination of binomial coefficients (see <a href="https://en.wikipedia.org/wiki/Integer-valued_polynomial#Classification">here</a>). Amusingly, 
this was also shown by Pólya!</p>

<p>You can push this further (as mentioned in the same wikipedia article) to 
note that $k \mid p(n)$ for all $n$ if and only if in the above 
representation $p = \sum c_i \binom{x}{i}$, all the $c_i$s are multiples of $k$.
So we have an extremely concrete classification of these polynomials, which 
one might use to (dis)prove the conjecture<sup id="fnref:9"><a href="#fn:9" rel="footnote" role="doc-noteref">8</a></sup>!</p>

<p>As a cute aside, we’ve actually talked about this basis for polynomials in 
terms of binomial coefficients <a href="https://grossack.site/2021/05/13/stirling-basis-change">before</a>! Seeing them turn up here was 
like seeing an old friend.</p>



<p>Thanks again for hanging out, all! This was super fun, and it was a nice 
diversion from the blog post about my thesis work. It’s loooong, but really 
interesting, and I think people will enjoy it. This stuff relating 
fukaya categories, topological field theories, and representation theory 
is some of the coolest math I’ve ever seen, and I couldn’t have asked for a 
more fun thesis topic.</p>

<p>Of course, I also need to get the <a href="https://grossack.site/2024/07/03/life-in-johnstones-topological-topos">topological topos posts</a> cleaned up 
and submitted to journals, and I have a fun project that I want to 
finish up which will be interesting to categorical logicians and 
algebraic geometers! (At least, algebraic geometers of a certain kind, haha).
There’s always more to do, but that’s part of the fun of it! After two months 
applying to postdocs and barely doing any math at all, I’m thrilled to be 
back at it ^_^.</p>

<p>Alright, stay safe, all! We’ll talk soon 💖</p>

<hr>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TypeScript enums: use cases and alternatives (153 pts)]]></title>
            <link>https://2ality.com/2025/01/typescript-enum-patterns.html</link>
            <guid>42766729</guid>
            <pubDate>Mon, 20 Jan 2025 09:30:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://2ality.com/2025/01/typescript-enum-patterns.html">https://2ality.com/2025/01/typescript-enum-patterns.html</a>, See on <a href="https://news.ycombinator.com/item?id=42766729">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In this blog post, we take a closer look at TypeScript enums:</p>
<ul>
<li>How do they work?</li>
<li>What are their use cases?</li>
<li>What are the alternatives if we don’t want to use them?</li>
</ul>
<p>The blog post concludes with recommendations for what to use when.</p>
<!--more-->
<nav>
<ul>
  <li>
    <a href="#notation">Notation</a>
  </li>
  <li>
    <a href="#the-basics-of-typescript-enums">The basics of TypeScript enums</a>
    <ul>
      <li>
        <a href="#an-enum-defines-an-object">An enum defines an object</a>
      </li>
      <li>
        <a href="#an-enum-defines-a-type">An enum defines a type</a>
      </li>
      <li>
        <a href="#we-can-check-exhaustiveness-for-enums">We can check exhaustiveness for enums</a>
      </li>
      <li>
        <a href="#enumerating-members">Enumerating members</a>
      </li>
      <li>
        <a href="#enums-without-explicitly-specified-values">Enums without explicitly specified values</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#use-cases-for-enums">Use cases for enums</a>
  </li>
  <li>
    <a href="#use-case%3A-namespace-for-constants-with-primitive-values">Use case: namespace for constants with primitive values</a>
    <ul>
      <li>
        <a href="#enum-as-namespace-for-constants-with-primitive-values">Enum as namespace for constants with primitive values</a>
      </li>
      <li>
        <a href="#alternative-to-enum%3A-object-literal">Alternative to enum: object literal</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#use-case%3A-custom-type-with-unique-values">Use case: custom type with unique values</a>
    <ul>
      <li>
        <a href="#enum-as-custom-type-with-unique-values">Enum as custom type with unique values</a>
      </li>
      <li>
        <a href="#alternative-to-enum%3A-object-literal-1">Alternative to enum: object literal</a>
      </li>
      <li>
        <a href="#alternative-to-enum%3A-union-of-string-literal-types">Alternative to enum: union of string literal types</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#use-case%3A-namespace-for-constants-with-object-values">Use case: namespace for constants with object values</a>
    <ul>
      <li>
        <a href="#object-literal-whose-property-values-are-objects">Object literal whose property values are objects</a>
      </li>
      <li>
        <a href="#enum-class">Enum class</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#mapping-to-and-from-an-enum">Mapping to and from an enum</a>
  </li>
  <li>
    <a href="#recommendations">Recommendations</a>
  </li>
</ul>
</nav>
<h2 id="notation" tabindex="-1">Notation&nbsp;&nbsp;</h2>
<p>For showing inferred types in the source code, I use the npm package <a href="https://github.com/TypeStrong/ts-expect"><code>ts-expect</code></a> – e.g.:</p>
<pre><code><span>// Types of values</span>
expectType&lt;<span>string</span>&gt;(<span>'abc'</span>);
expectType&lt;<span>number</span>&gt;(<span>123</span>);

<span>// Equality of types</span>
<span>type</span> <span>Pair</span>&lt;T&gt; = [T, T];
expectType&lt;<span>TypeEqual</span>&lt;<span>Pair</span>&lt;<span>string</span>&gt;, [<span>string</span>,<span>string</span>]&gt;&gt;(<span>true</span>);
</code></pre>
<h2 id="the-basics-of-typescript-enums" tabindex="-1">The basics of TypeScript enums&nbsp;&nbsp;</h2>
<p>There are many different kinds of <em>enums</em> in various programming languages. In TypeScript, an enum defines two things:</p>
<ul>
<li>an object that maps member keys to member values</li>
<li>a type that only contains the member values</li>
</ul>
<p>Note that we are ignoring <a href="https://exploringjs.com/tackling-ts/ch_enums.html#const-enums">const enums</a> in this blog post.</p>
<p>Next, we’ll look at various aspects of enums in more detail.</p>
<h3 id="an-enum-defines-an-object" tabindex="-1">An enum defines an object&nbsp;&nbsp;</h3>
<p>On one hand, an enum is an object that maps member keys to member values. In that way, it works much like an object literal:</p>
<pre><code><span>enum</span> <span>Color</span> {
  <span>Red</span> = <span>0</span>,
  <span>Green</span> = <span>'GREEN'</span>,
}
assert.<span>equal</span>(<span>Color</span>.<span>Red</span>, <span>0</span>);
assert.<span>equal</span>(<span>Color</span>.<span>Green</span>, <span>'GREEN'</span>);
assert.<span>equal</span>(<span>Color</span>[<span>'Green'</span>], <span>'GREEN'</span>);
</code></pre>
<p>One limitation is that only numbers and strings are allowed as member values.</p>
<h3 id="an-enum-defines-a-type" tabindex="-1">An enum defines a type&nbsp;&nbsp;</h3>
<p>On the other hand, an enum is also a type that only contains the member values:</p>
<pre><code><span>let</span> <span>color</span>: <span>Color</span>;
color = <span>Color</span>.<span>Red</span>;
color = <span>Color</span>.<span>Green</span>;
<span>// @ts-expect-error: Type 'true' is not assignable to type 'Color'.</span>
color = <span>true</span>;
</code></pre>
<p>There is one important difference between string members and number members: We cannot assign plain strings to <code>color</code>:</p>
<pre><code><span>// @ts-expect-error: Type '"GREEN"' is not assignable to</span>
<span>// type 'Color'.</span>
color = <span>'GREEN'</span>;
</code></pre>
<p>But we can assign a plain number to <code>color</code> – if it is the value of a member:</p>
<pre><code>color = <span>0</span>;
<span>// @ts-expect-error: Type '123' is not assignable to type 'Color'.</span>
color = <span>123</span>;
</code></pre>
<h3 id="we-can-check-exhaustiveness-for-enums" tabindex="-1">We can check exhaustiveness for enums&nbsp;&nbsp;</h3>
<p>Consider the following enum:</p>
<pre><code><span>enum</span> <span>Color</span> {
  <span>Red</span> = <span>0</span>,
  <span>Green</span> = <span>'GREEN'</span>,
}
</code></pre>
<p>If we handle the values that a variable of type <code>Color</code> may have, then TypeScript can warn us if we forget one of them. In other words: If we didn’t handle all cases “exhaustively”. That is called an <em>exhaustiveness check</em>. To see how that works, let’s start with the following code:</p>
<pre><code><span>// @ts-expect-error: Not all code paths return a value.</span>
<span>function</span> <span>colorToString</span>(<span>color: Color</span>) {
  expectType&lt;<span>Color</span>&gt;(color); <span>// (A)</span>
  <span>if</span> (color === <span>Color</span>.<span>Red</span>) {
    <span>return</span> <span>'red'</span>;
  }
  expectType&lt;<span>Color</span>.<span>Green</span>&gt;(color); <span>// (B)</span>
  <span>if</span> (color === <span>Color</span>.<span>Green</span>) {
    <span>return</span> <span>'green'</span>;
  }
  expectType&lt;<span>never</span>&gt;(color); <span>// (C)</span>
}
</code></pre>
<p>In line A, <code>color</code> can still have any value. In line B, we have crossed off <code>Color.Red</code> and <code>color</code> can only have the value <code>Color.Green</code>. In line C, <code>color</code> can’t have any value – which explains its type <code>never</code>.</p>
<p>If <code>color</code> is <em>not</em> <code>never</code> in line C then we have forgotten a member. We can let TypeScript report an error at compile time like this:</p>
<pre><code><span>function</span> <span>colorToString</span>(<span>color: Color</span>) {
  <span>if</span> (color === <span>Color</span>.<span>Red</span>) {
    <span>return</span> <span>'red'</span>;
  }
  <span>if</span> (color === <span>Color</span>.<span>Green</span>) {
    <span>return</span> <span>'green'</span>;
  }
  <span>throw</span> <span>new</span> <span>UnsupportedValueError</span>(color);
}
</code></pre>
<p>How does that work? The <code>value</code> we pass to <code>UnsupportedValueError</code> must have the type <code>never</code>:</p>
<pre><code><span>class</span> <span>UnsupportedValueError</span> <span>extends</span> <span>Error</span> {
  <span>constructor</span>(<span>value: <span>never</span>, message = <span>`Unsupported value: <span>${value}</span>`</span></span>) {
    <span>super</span>(message)
  }
}
</code></pre>
<p>This is what happens if we forget the second case:</p>
<pre><code><span>function</span> <span>colorToString</span>(<span>color: Color</span>) {
  <span>if</span> (color === <span>Color</span>.<span>Red</span>) {
    <span>return</span> <span>'red'</span>;
  }
  <span>// @ts-expect-error: Argument of type 'Color.Green'</span>
  <span>// is not assignable to parameter of type 'never'.</span>
  <span>throw</span> <span>new</span> <span>UnsupportedValueError</span>(color);
}
</code></pre>
<p>Exhaustiveness checking works just as well with <code>case</code> statements:</p>
<pre><code><span>function</span> <span>colorToString</span>(<span>color: Color</span>) {
  <span>switch</span> (color) {
    <span>case</span> <span>Color</span>.<span>Red</span>:
      <span>return</span> <span>'red'</span>;
    <span>case</span> <span>Color</span>.<span>Green</span>:
      <span>return</span> <span>'green'</span>;
    <span>default</span>:
      <span>throw</span> <span>new</span> <span>UnsupportedValueError</span>(color);
  }
}
</code></pre>
<p>Another way to check exhaustiveness is by specifying a return type for the function:</p>
<pre><code><span>// @ts-expect-error: Function lacks ending return statement and</span>
<span>// return type does not include 'undefined'.</span>
<span>function</span> <span>colorToString</span>(<span>color: Color</span>): <span>string</span> {
  <span>switch</span> (color) {
    <span>case</span> <span>Color</span>.<span>Red</span>:
      <span>return</span> <span>'red'</span>;
  }
}
</code></pre>
<p>In my code, I usually do that but additionally throw an <code>UnsupportedValueError</code> because I like having a check that also works at runtime.</p>
<h3 id="enumerating-members" tabindex="-1">Enumerating members&nbsp;&nbsp;</h3>
<p>One operation that is occasionally useful is enumerating the members of an enum. Can we do that with TypeScript enums? Let’s use our previous enum:</p>
<pre><code><span>enum</span> <span>Color</span> {
  <span>Red</span> = <span>0</span>,
  <span>Green</span> = <span>'GREEN'</span>,
}
</code></pre>
<p>Compiled to JavaScript, <code>Color</code> looks like this:</p>
<pre><code><span>var</span> <span>Color</span>;
(<span>function</span> (<span>Color</span>) {
    <span>Color</span>[<span>Color</span>[<span>"Red"</span>] = <span>0</span>] = <span>"Red"</span>; <span>// (A)</span>
    <span>Color</span>[<span>"Green"</span>] = <span>"GREEN"</span>; <span>// (B)</span>
})(<span>Color</span> || (<span>Color</span> = {}));
</code></pre>
<p>This is a function that is immediately invoked and adds properties to an object <code>Color</code>.</p>
<p>The code for the string member <code>Green</code> in line B is straightforward: It maps from key to value.</p>
<p>The code for the number member <code>Red</code> in line A adds two properties for <code>Red</code> instead of one – a mapping from key to value and a mapping from value to key:</p>
<pre><code><span>Color</span>[<span>"Red"</span>] = <span>0</span>;
<span>Color</span>[<span>0</span>] = <span>"Red"</span>;
</code></pre>
<p>Note that the zero in the second line is coerced to a string (a property key can only be a string or a symbol). Thus, we can’t even really look up a number this way. We have to convert it to a string first.</p>
<p>Therefore, the number member prevents us from enumerating the keys or values of this enum:</p>
<pre><code>assert.<span>deepEqual</span>(
  <span>Object</span>.<span>keys</span>(<span>Color</span>), [<span>'0'</span>, <span>'Red'</span>, <span>'Green'</span>]
);
assert.<span>deepEqual</span>(
  <span>Object</span>.<span>values</span>(<span>Color</span>), [<span>'Red'</span>, <span>0</span>, <span>'GREEN'</span>]
);
</code></pre>
<p>If we switch to only string members then enumeration works:</p>
<pre><code><span>enum</span> <span>Color</span> {
  <span>Red</span> = <span>'RED'</span>,
  <span>Green</span> = <span>'GREEN'</span>,
}

assert.<span>deepEqual</span>(
  <span>Object</span>.<span>keys</span>(<span>Color</span>), [<span>'Red'</span>, <span>'Green'</span>]
);
assert.<span>deepEqual</span>(
  <span>Object</span>.<span>values</span>(<span>Color</span>), [<span>'RED'</span>, <span>'GREEN'</span>]
);
</code></pre>
<h3 id="enums-without-explicitly-specified-values" tabindex="-1">Enums without explicitly specified values&nbsp;&nbsp;</h3>
<p>We can also create enums without explicitly specifying member values. Then TypeScript specifies them for us and uses numbers:</p>
<pre><code><span>enum</span> <span>Color</span> {
  <span>Red</span>, <span>// implicitly = 0</span>
  <span>Green</span>, <span>// implicitly = 1</span>
}
assert.<span>equal</span>(<span>Color</span>.<span>Red</span>, <span>0</span>);
assert.<span>equal</span>(<span>Color</span>.<span>Green</span>, <span>1</span>);
</code></pre>
<h2 id="use-cases-for-enums" tabindex="-1">Use cases for enums&nbsp;&nbsp;</h2>
<p>Making sense of enums and enum-related patterns can quickly get confusing because what an enum is varies widely between programming languages – e.g.:</p>
<ul>
<li>Java’s enums are classes with a fixed set of instances.</li>
<li>Rust’s enums are more like algebraic datatypes in functional programming languages. They are loosely related to <a href="https://exploringjs.com/tackling-ts/ch_enum-alternatives.html#discriminated-union">discriminated unions</a> in TypeScript.</li>
</ul>
<p>Therefore, we benefit from a narrow definition of the term <em>enum</em>:</p>
<ul>
<li>A fixed set of values.</li>
<li>That can be accessed via the keys of an object.</li>
</ul>
<p>In the following sections, we’ll go through the following use cases for this kind of enum:</p>
<ol>
<li>Namespace for constants with primitive values</li>
<li>Custom type with unique values</li>
<li>Namespace for constants with object values</li>
</ol>
<p>We’ll consider how well TypeScript enums work for these use cases. (Spoiler: they work reasonably well for #1 and #2 but can’t be used for #3.) And we’ll look at enum-like patterns that we can use instead.</p>
<p>For each option, we’ll also examine:</p>
<ul>
<li>Can exhaustiveness checks be performed?</li>
<li>Can members be enumerated?</li>
</ul>
<h2 id="use-case%3A-namespace-for-constants-with-primitive-values" tabindex="-1">Use case: namespace for constants with primitive values&nbsp;&nbsp;</h2>
<p>One way in which enums (or enum-like objects) are sometimes used is simply as a namespace for constants – e.g., the Node.js function <a href="https://nodejs.org/api/fs.html#fsaccesspath-mode-callback"><code>fs.access()</code></a> has a parameter <code>mode</code> whose values are provided via an object that is similar to the following enum:</p>
<pre><code><span>enum</span> constants {
  <span>F_OK</span> = <span>0</span>,
  <span>R_OK</span> = <span>4</span>,
  <span>W_OK</span> = <span>2</span>,
  <span>X_OK</span> = <span>1</span>,
  <span>// ...</span>
}
</code></pre>
<p>Except for the first value, these are bits that are combined via bitwise Or:</p>
<pre><code><span>const</span> readOrWrite = constants.<span>R_OK</span> | constants.<span>W_OK</span>;
</code></pre>
<h3 id="enum-as-namespace-for-constants-with-primitive-values" tabindex="-1">Enum as namespace for constants with primitive values&nbsp;&nbsp;</h3>
<p>Which enum features are relevant for this use case?</p>
<ul>
<li>One major limitation of enums is that values can only be number or strings.</li>
<li>The enum as a type doesn’t matter: The type of parameter <code>mode</code> is <code>number</code>, not <code>constants</code> or something similar. That’s because the values of <code>constants</code> are not an exhaustive list of all possible values of <code>mode</code>.</li>
<li>For the same reason, exhaustiveness checks are not relevant in this case.</li>
<li>Enumerating members isn’t desirable either. And it’s not something that we can do with number-valued enums anyway.</li>
</ul>
<h3 id="alternative-to-enum%3A-object-literal" tabindex="-1">Alternative to enum: object literal&nbsp;&nbsp;</h3>
<p>For this use case, an object literal is a very good alternative:</p>
<pre><code><span>const</span> constants = {
  <span>__proto__</span>: <span>null</span>,
  <span>F_OK</span>: <span>0</span>,
  <span>R_OK</span>: <span>4</span>,
  <span>W_OK</span>: <span>2</span>,
  <span>X_OK</span>: <span>1</span>,
};
</code></pre>
<p>We use the pseudo property key <code>__proto__</code> to set the prototype of <code>constants</code> to <code>null</code>. That is a good practice because then we don’t have to deal with inherited properties:</p>
<ul>
<li>The main benefit is that we can use the <code>in</code> operator to check if <code>constants</code> has a given key without worrying about properties inherited from <code>Object.prototype</code> such as <code>.toString</code>.</li>
<li>However, <code>Object.keys()</code> and <code>Object.values()</code> ignore inherited properties anyway, so we don’t gain anything there.</li>
</ul>
<p>Note that <code>__proto__</code> also exists as a getter and a setter in <code>Object.prototype</code>. This feature is deprecated in favor of <code>Object.getPrototypeOf()</code> and <code>Object.setPrototypeOf()</code>. However, that is different from using this name in an object literal – which is not deprecated.</p>
<p>For more information, check out these sections of “Exploring JavaScript”:</p>
<ul>
<li><a href="https://exploringjs.com/js/book/ch_objects.html#the-pitfalls-of-using-an-object-as-a-dictionary">“The pitfalls of using an object as a dictionary”</a></li>
<li><a href="https://exploringjs.com/js/book/ch_objects.html#tips-for-working-with-prototypes">“Tips for working with prototypes”</a></li>
<li><a href="https://exploringjs.com/js/book/ch_classes.html#Object.prototype.__proto__">“<code>Object.prototype.__proto__</code> (accessor)”</a></li>
</ul>
<h2 id="use-case%3A-custom-type-with-unique-values" tabindex="-1">Use case: custom type with unique values&nbsp;&nbsp;</h2>
<p>Sometimes we may want to define our own custom type that has a fixed set of values. For example, booleans don’t always express intentions well. Then an enum can do a better job:</p>
<pre><code><span>enum</span> <span>Activation</span> {
  <span>Active</span> = <span>'Active'</span>,
  <span>Inactive</span> = <span>'Inactive'</span>,
}
</code></pre>
<p>It’s a good practice to explicitly specify string values via <code>=</code>:</p>
<ul>
<li>We get more type safety and can’t accidentally provide numbers where an <code>Activation</code> is expected.</li>
<li>We can enumerate the keys and values of <code>Activation</code>.</li>
</ul>
<h3 id="enum-as-custom-type-with-unique-values" tabindex="-1">Enum as custom type with unique values&nbsp;&nbsp;</h3>
<p>Which enum features are relevant for this use case?</p>
<ul>
<li>We will use the type defined by <code>Activation</code>.</li>
<li>Exhaustiveness checks are possible and useful.</li>
<li>We also may want to enumerate keys or values.</li>
</ul>
<h3 id="alternative-to-enum%3A-object-literal-1" tabindex="-1">Alternative to enum: object literal&nbsp;&nbsp;</h3>
<p>Let’s use an object literal to define the value part of an enum (we’ll get to the type part next):</p>
<pre><code><span>const</span> <span>Activation</span> = {
  <span>__proto__</span>: <span>null</span>,
  <span>Active</span>: <span>'Active'</span>,
  <span>Inactive</span>: <span>'Inactive'</span>,
} <span>as</span> <span>const</span>; <span>// (A)</span>

<span>// Without `as const`, this type would be `string`:</span>
expectType&lt;<span>'Active'</span>&gt;(<span>Activation</span>.<span>Active</span>);

<span>type</span> <span>ActivationType</span> = <span>PropertyValues</span>&lt;<span>typeof</span> <span>Activation</span>&gt;;
expectType&lt;
  <span>TypeEqual</span>&lt;<span>ActivationType</span>, <span>'Active'</span> | <span>'Inactive'</span>&gt;
&gt;(<span>true</span>);
</code></pre>
<p>The <code>as const</code> in line A enables us to derive <code>ActivationType</code> from <code>Activation</code> via the helper type <code>PropertyValues</code> (which is defined below).</p>
<p>Why is this type called <code>ActivationType</code> and not <code>Activation</code>? Since the namespaces of values and types are separate in TypeScript, we could indeed use the same name. However, I’ve had issues when using Visual Studio Code to rename value and type: It got confused because importing <code>Activation</code> imported both value and type. That’s why I’m using different names – for now.</p>
<p>The helper type <code>PropertyValues</code> looks like this:</p>
<pre><code><span>type</span> <span>PropertyValues</span>&lt;<span>Obj</span>&gt; = <span>Obj</span>[<span>Exclude</span>&lt;keyof <span>Obj</span>, <span>'__proto__'</span>&gt;];
</code></pre>
<ul>
<li>The type <code>Obj[K]</code> contains the values of all properties whose keys are in <code>K</code>.</li>
<li>We exclude the key <code>'__proto__'</code> from <code>keyof Obj</code> because TypeScript treats that key as a normal property and that’s not what we want (<a href="https://github.com/microsoft/TypeScript/issues/38385">related GitHub issue</a>).</li>
</ul>
<p>Let’s explore what the derived type looks like if we don’t use <code>as const</code>:</p>
<pre><code><span>const</span> <span>Activation</span> = {
  <span>__proto__</span>: <span>null</span>,
  <span>Active</span>: <span>'Active'</span>,
  <span>Inactive</span>: <span>'Inactive'</span>,
};

expectType&lt;<span>string</span>&gt;(<span>Activation</span>.<span>Active</span>);
expectType&lt;<span>string</span>&gt;(<span>Activation</span>.<span>Inactive</span>);

<span>type</span> <span>ActivationType</span> = <span>PropertyValues</span>&lt;<span>typeof</span> <span>Activation</span>&gt;;
expectType&lt;
  <span>TypeEqual</span>&lt;<span>ActivationType</span>, <span>string</span>&gt;
&gt;(<span>true</span>);
</code></pre>
<h4 id="exhaustiveness-checks" tabindex="-1">Exhaustiveness checks&nbsp;&nbsp;</h4>
<p>TypeScript supports exhaustiveness checks for unions of literal types. And that’s what <code>ActivationType</code> is. Therefore, we can use the same pattern as we did with enums:</p>
<pre><code><span>function</span> <span>activationToString</span>(<span>activation: ActivationType</span>): <span>string</span> {
  <span>switch</span> (activation) {
    <span>case</span> <span>Activation</span>.<span>Active</span>:
      <span>return</span> <span>'ACTIVE'</span>;
    <span>case</span> <span>Activation</span>.<span>Inactive</span>:
      <span>return</span> <span>'INACTIVE'</span>;
    <span>default</span>:
      <span>throw</span> <span>new</span> <span>UnsupportedValueError</span>(activation);
  }
}
</code></pre>
<h4 id="enumerating-members-1" tabindex="-1">Enumerating members&nbsp;&nbsp;</h4>
<p>We can use <code>Object.keys()</code> and <code>Object.values()</code> to enumerate the members of the object <code>Activation</code>:</p>
<pre><code><span>for</span> (<span>const</span> value <span>of</span> <span>Object</span>.<span>values</span>(<span>Activation</span>)) {
  <span>console</span>.<span>log</span>(value);
}
</code></pre>
<p>Output:</p>
<pre><code>Active
Inactive
</code></pre>
<h4 id="using-symbols-as-property-values" tabindex="-1">Using symbols as property values&nbsp;&nbsp;</h4>
<p>One downside of using strings as property values is that <code>ActivationType</code> does not exclude arbitrary strings from being used. We can get more type safety if we use symbols:</p>
<pre><code><span>const</span> <span>Active</span> = <span>Symbol</span>(<span>'Active'</span>);
<span>const</span> <span>Inactive</span> = <span>Symbol</span>(<span>'Inactive'</span>);

<span>const</span> <span>Activation</span> = {
  <span>__proto__</span>: <span>null</span>,
  <span>Active</span>,
  <span>Inactive</span>,
} <span>as</span> <span>const</span>;

expectType&lt;<span>typeof</span> <span>Active</span>&gt;(<span>Activation</span>.<span>Active</span>);

<span>type</span> <span>ActivationType</span> = <span>PropertyValues</span>&lt;<span>typeof</span> <span>Activation</span>&gt;;
expectType&lt;
  <span>TypeEqual</span>&lt;
    <span>ActivationType</span>, <span>typeof</span> <span>Active</span> | <span>typeof</span> <span>Inactive</span>
  &gt;
&gt;(<span>true</span>);
</code></pre>
<p>This seems overly complicated: Why the intermediate step of first declaring variables for the symbols before we use them? Why not create the symbols inside the object literal? Alas, that’s a current limitation of <code>as const</code> for symbols: They are not recognized as unique (<a href="https://github.com/microsoft/TypeScript/issues/54100">related GitHub issue</a>):</p>
<pre><code><span>const</span> <span>Activation</span> = {
  <span>__proto__</span>: <span>null</span>,
  <span>Active</span>: <span>Symbol</span>(<span>'Active'</span>),
  <span>Inactive</span>: <span>Symbol</span>(<span>'Inactive'</span>),
} <span>as</span> <span>const</span>;

<span>// Alas, the type of Activation.Active is not `typeof Active`</span>
expectType&lt;<span>symbol</span>&gt;(<span>Activation</span>.<span>Active</span>);

<span>type</span> <span>ActivationType</span> = <span>PropertyValues</span>&lt;<span>typeof</span> <span>Activation</span>&gt;;
expectType&lt;
  <span>TypeEqual</span>&lt;<span>ActivationType</span>, <span>symbol</span>&gt;
&gt;(<span>true</span>);
</code></pre>
<h3 id="alternative-to-enum%3A-union-of-string-literal-types" tabindex="-1">Alternative to enum: union of string literal types&nbsp;&nbsp;</h3>
<p>A union of string literal types is an interesting alternative to an enum when it comes to defining a type with a fixed set of members:</p>
<pre><code><span>type</span> <span>Activation</span> = <span>'Active'</span> | <span>'Inactive'</span>;
</code></pre>
<p>How does such a type compare to an enum?</p>
<p>Pros:</p>
<ul>
<li>It’s a quick and simple solution.</li>
<li>It supports exhaustiveness checks.</li>
<li>Renaming members works reasonably well in Visual Studio Code.</li>
</ul>
<p>Cons:</p>
<ul>
<li>The type members are not unique. We could change that by using symbols but then we’d lose some of the convenience of string literal union types – e.g., we’d have to import the values.</li>
<li>We can’t enumerate the members. The next section explains how to change that.</li>
</ul>
<h4 id="reifying-string-literal-unions" tabindex="-1">Reifying string literal unions via Sets&nbsp;&nbsp;</h4>
<p><em>Reification</em> means creating an entity at the object level (think JavaScript values) for an entity that exists at the meta level (think TypeScript types).</p>
<p>We can use a Set to reify a string literal union type:</p>
<pre><code><span>const</span> activation = <span>new</span> <span>Set</span>([
  <span>'Active'</span>,
  <span>'Inactive'</span>,
] <span>as</span> <span>const</span>);
expectType&lt;<span>Set</span>&lt;<span>'Active'</span> | <span>'Inactive'</span>&gt;&gt;(activation);

<span>// @ts-expect-error: Argument of type '"abc"' is not assignable to</span>
<span>// parameter of type '"Active" | "Inactive"'.</span>
activation.<span>has</span>(<span>'abc'</span>);
  <span>// Auto-completion works for arguments of .has(), .delete() etc.</span>

<span>// Let’s turn the Set into a string literal union</span>
<span>type</span> <span>Activation</span> = <span>SetElementType</span>&lt;<span>typeof</span> activation&gt;;
expectType&lt;
  <span>TypeEqual</span>&lt;<span>Activation</span>, <span>'Active'</span> | <span>'Inactive'</span>&gt;
&gt;(<span>true</span>);

<span>type</span> <span>SetElementType</span>&lt;S <span>extends</span> <span>Set</span>&lt;<span>any</span>&gt;&gt; =
  S <span>extends</span> <span>Set</span>&lt;infer <span>Elem</span>&gt; ? <span>Elem</span> : <span>never</span>;
</code></pre>
<h2 id="use-case%3A-namespace-for-constants-with-object-values" tabindex="-1">Use case: namespace for constants with object values&nbsp;&nbsp;</h2>
<p>Sometimes, it’s useful to have an enum-like construct for looking up richer data – stored in objects. We can’t use objects as enum values, so we’ll have to use other solutions.</p>
<h3 id="object-literal-whose-property-values-are-objects" tabindex="-1">Object literal whose property values are objects&nbsp;&nbsp;</h3>
<p>This is an example of using an object literal as an enum for objects:</p>
<pre><code><span>// This type is optional: It constrains the property values</span>
<span>// of `TextStyle` but has no other use.</span>
<span>type</span> <span>TTextStyle</span> = {
  <span>key</span>: <span>string</span>,
  <span>html</span>: <span>string</span>,
  <span>latex</span>: <span>string</span>,
};
<span>const</span> <span>TextStyle</span> = {
  <span>Bold</span>: {
    <span>key</span>: <span>'Bold'</span>,
    <span>html</span>: <span>'b'</span>,
    <span>latex</span>: <span>'textbf'</span>,
  },
  <span>Italics</span>: {
    <span>key</span>: <span>'Italics'</span>,
    <span>html</span>: <span>'i'</span>,
    <span>latex</span>: <span>'textit'</span>,
  },
} <span>as</span> <span>const</span> satisfies <span>Record</span>&lt;<span>string</span>, <span>TTextStyle</span>&gt;;

<span>type</span> <span>TextStyleType</span> = <span>PropertyValues</span>&lt;<span>typeof</span> <span>TextStyle</span>&gt;;
<span>type</span> <span>PropertyValues</span>&lt;<span>Obj</span>&gt; = <span>Obj</span>[<span>Exclude</span>&lt;keyof <span>Obj</span>, <span>'__proto__'</span>&gt;];
</code></pre>
<h4 id="exhaustiveness-check" tabindex="-1">Exhaustiveness check&nbsp;&nbsp;</h4>
<p>Why do the property values of <code>TextStyle</code> have the property <code>.key</code>? That property lets us do exhaustiveness checks because the property values form a <a href="https://exploringjs.com/tackling-ts/ch_enum-alternatives.html#discriminated-union">discriminated union</a>.</p>
<pre><code><span>function</span> <span>f</span>(<span>textStyle: TextStyleType</span>): <span>string</span> {
  <span>switch</span> (textStyle.<span>key</span>) {
    <span>case</span> <span>TextStyle</span>.<span>Bold</span>.<span>key</span>:
      <span>return</span> <span>'BOLD'</span>;
    <span>case</span> <span>TextStyle</span>.<span>Italics</span>.<span>key</span>:
      <span>return</span> <span>'ITALICS'</span>;
    <span>default</span>:
      <span>throw</span> <span>new</span> <span>UnsupportedValueError</span>(textStyle); <span>// No `.key`!</span>
  }
}
</code></pre>
<p>For comparison, this is what <code>f()</code> would look like if <code>TextStyle</code> were an enum:</p>
<pre><code><span>enum</span> <span>TextStyle2</span> { <span>Bold</span>, <span>Italics</span> }
<span>function</span> <span>f2</span>(<span>textStyle: TextStyle2</span>): <span>string</span> {
  <span>switch</span> (textStyle) {
    <span>case</span> <span>TextStyle2</span>.<span>Bold</span>:
      <span>return</span> <span>'BOLD'</span>;
    <span>case</span> <span>TextStyle2</span>.<span>Italics</span>:
      <span>return</span> <span>'ITALICS'</span>;
    <span>default</span>:
      <span>throw</span> <span>new</span> <span>UnsupportedValueError</span>(textStyle);
  }
}
</code></pre>
<h3 id="enum-class" tabindex="-1">Enum class&nbsp;&nbsp;</h3>
<p>We can also use a class as an enum – a pattern that is borrowed from Java:</p>
<pre><code><span>class</span> <span>TextStyle</span> {
  <span>static</span> <span>Bold</span> = <span>new</span> <span>TextStyle</span>(<span>/*...*/</span>);
  <span>static</span> <span>Italics</span> = <span>new</span> <span>TextStyle</span>(<span>/*...*/</span>);
}
<span>type</span> <span>TextStyleKeys</span> = <span>EnumKeys</span>&lt;<span>typeof</span> <span>TextStyle</span>&gt;;
expectType&lt;
  <span>TypeEqual</span>&lt;<span>TextStyleKeys</span>, <span>'Bold'</span> | <span>'Italics'</span>&gt;
&gt;(<span>true</span>);

<span>type</span> <span>EnumKeys</span>&lt;T&gt; = <span>Exclude</span>&lt;keyof T, <span>'prototype'</span>&gt;;
</code></pre>
<p>One pro of this pattern is that we can use methods to add behavior to the enum values. A con is that there is no simple way to get an exhaustiveness check.</p>
<p><code>Object.keys()</code> and <code>Object.values()</code> ignore non-enumerable properties of <code>TextStyle</code> such as <code>.prototype</code> – which is why we can use them to enumerate keys and values – e.g.:</p>
<pre><code>assert.<span>deepEqual</span>(
  <span>// TextStyle.prototype is non-enumerable</span>
  <span>Object</span>.<span>keys</span>(<span>TextStyle</span>),
  [<span>'Bold'</span>, <span>'Italics'</span>]
);
</code></pre>
<h2 id="mapping-to-and-from-an-enum" tabindex="-1">Mapping to and from an enum&nbsp;&nbsp;</h2>
<p>Sometimes we want to translate enum values to other values or vice versa – e.g. when serializing them to JSON or deserializing them from JSON. If we do so via a <code>Map</code>, we can use TypeScript to get a warning if we forget an enum value.</p>
<p>To explore how that works, we’ll use the following enum pattern type:</p>
<pre><code><span>const</span> <span>Pending</span> = <span>Symbol</span>(<span>'Pending'</span>);
<span>const</span> <span>Ongoing</span> = <span>Symbol</span>(<span>'Ongoing'</span>);
<span>const</span> <span>Finished</span> = <span>Symbol</span>(<span>'Finished'</span>);
<span>const</span> <span>TaskStatus</span> = {
  <span>__proto__</span>: <span>null</span>,
  <span>Pending</span>,
  <span>Ongoing</span>,
  <span>Finished</span>,
} <span>as</span> <span>const</span>;
<span>type</span> <span>TaskStatusType</span> = <span>PropertyValues</span>&lt;<span>typeof</span> <span>TaskStatus</span>&gt;;
<span>type</span> <span>PropertyValues</span>&lt;<span>Obj</span>&gt; = <span>Obj</span>[<span>Exclude</span>&lt;keyof <span>Obj</span>, <span>'__proto__'</span>&gt;];
</code></pre>
<p>This is the Map:</p>
<pre><code><span>const</span> taskPairs = [
  [<span>TaskStatus</span>.<span>Pending</span>, <span>'not yet'</span>],
  [<span>TaskStatus</span>.<span>Ongoing</span>, <span>'working on it'</span>],
  [<span>TaskStatus</span>.<span>Finished</span>, <span>'finished'</span>],
] <span>as</span> <span>const</span>;

<span>type</span> <span>Key</span> = (<span>typeof</span> taskPairs)[<span>number</span>][<span>0</span>];
<span>const</span> taskMap = <span>new</span> <span>Map</span>&lt;<span>Key</span>, <span>string</span>&gt;(taskPairs);
</code></pre>
<p>If you are wondering why we didn’t directly use the value of <code>taskPairs</code> as the argument of <code>new Map()</code> and omit the type parameters: TypeScript doesn’t seem to be able to infer the type parameters if the keys are symbols and reports a compile-time error. With strings, the code would be simpler:</p>
<pre><code><span>const</span> taskPairs = [
  [<span>'Pending'</span>, <span>'not yet'</span>],
  [<span>'Ongoing'</span>, <span>'working on it'</span>],
  [<span>'Finished'</span>, <span>'finished'</span>],
] <span>as</span> <span>const</span>;
<span>const</span> taskMap = <span>new</span> <span>Map</span>(taskPairs); <span>// no type parameters!</span>
</code></pre>
<p>The final step is to check if we forgot only of the values of <code>TaskStatus</code>:</p>
<pre><code>expectType&lt;
  <span>TypeEqual</span>&lt;<span>MapKey</span>&lt;<span>typeof</span> taskMap&gt;, <span>TaskStatusType</span>&gt;
&gt;(<span>true</span>);
<span>type</span> <span>MapKey</span>&lt;M <span>extends</span> <span>Map</span>&lt;<span>any</span>, <span>any</span>&gt;&gt; =
  M <span>extends</span> <span>Map</span>&lt;infer K, <span>any</span>&gt; ? K : <span>never</span>;
</code></pre>
<h2 id="recommendations" tabindex="-1">Recommendations&nbsp;&nbsp;</h2>
<p>When should we use an enum and when an alternative pattern?</p>
<p><strong>TypeScript enums are not JavaScript:</strong> Enums are one of the few TypeScript language constructs (vs. type constructs) that have no corresponding JavaScript features. That can matter in two ways:</p>
<ul>
<li>The transpiled code looks a bit strange – especially if some enum members are numbers.</li>
<li>If a tool doesn’t transpile TypeScript but only strips types then it won’t support enums. That’s not (yet?) that common but one prominent example is <a href="https://2ality.com/2025/01/nodejs-strip-type.html">Node’s current built-in support for TypeScript</a>.</li>
</ul>
<p><strong>Performance of strings:</strong> One thing to keep in mind is that comparing strings is usually slower than comparing numbers or symbols. Therefore, enums or enum patterns where values are strings, are slower. Note that applies to string literal unions too. But such a performance cost only matters if we do many comparisons.</p>
<p><strong>What is the use case?</strong> Looking at the use cases can help us make a decision:</p>
<ol>
<li>Namespace for constants with primitive values:
<ul>
<li>If the primitive values are numbers or strings, we can use a TypeScript enum.
<ul>
<li>Alas, number values aren’t great because each member produces two properties: a mapping from key to value and a reverse mapping.</li>
</ul>
</li>
<li>Otherwise (or if we don’t want to use an enum) we can use an object literal.</li>
</ul>
</li>
<li>Custom type with unique values:
<ul>
<li>If we use an enum, it should have string values because that gives us more type safety and lets us iterate over keys and values.</li>
<li>A union of string literal types is a lightweight, quick solution. Its downsides are: less type safety and no namespace object for easy lookup.
<ul>
<li>If we want to access the string literal values at runtime, we can use a Set to reify them.</li>
</ul>
</li>
<li>If we want a solid, slightly verbose solution, we can use an object literal with symbol property values.</li>
</ul>
</li>
<li>Namespace for constants with object values:
<ul>
<li>We can’t use enums for this use case.</li>
<li>We can use an object literal whose property values are objects. The upside of this solution is that we can check exhaustiveness.</li>
<li>If we want enum values to have methods, we can use an enum class. However that means that we can’t check exhaustiveness.</li>
</ul>
</li>
</ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Parinfer: Simpler Lisp Editing (137 pts)]]></title>
            <link>https://shaunlebron.github.io/parinfer/</link>
            <guid>42766205</guid>
            <pubDate>Mon, 20 Jan 2025 08:21:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shaunlebron.github.io/parinfer/">https://shaunlebron.github.io/parinfer/</a>, See on <a href="https://news.ycombinator.com/item?id=42766205">Hacker News</a></p>
Couldn't get https://shaunlebron.github.io/parinfer/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What does "supports DRM and may not be fully accessible" mean for SATA SDDs? (174 pts)]]></title>
            <link>https://unix.stackexchange.com/questions/789838/what-does-supports-drm-functions-and-may-not-be-fully-accessible-mean-for-sata</link>
            <guid>42765480</guid>
            <pubDate>Mon, 20 Jan 2025 06:09:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unix.stackexchange.com/questions/789838/what-does-supports-drm-functions-and-may-not-be-fully-accessible-mean-for-sata">https://unix.stackexchange.com/questions/789838/what-does-supports-drm-functions-and-may-not-be-fully-accessible-mean-for-sata</a>, See on <a href="https://news.ycombinator.com/item?id=42765480">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<blockquote>
<p>supports DRM functions and may not be fully accessible</p>
</blockquote>
<p>There's an extension of the ATA protocol (the "language" spoken between your mainboard and your SATA SSDs), which allows for the storage device to reply differently, depending on whether a request was signed by the trusted platform module on the mainboard. That way, things like video player devices that only give access to the stored data when the software has proven itself to be unmodified can be implemented. (I can find much more interesting use cases, but digital rights management seems to be what the kernel authors saw as the application for this when they implemented that warning.) That also means that Linux might simply get an "incomplete" view of the SSD, hence it warns you about that, in case you wonder.</p>
<blockquote>
<p>read cache: enabled, doesn't support DPO or FUA</p>
</blockquote>
<p>uff, this just tells you that the device has a read cache: the computer fetches some smaller unit of data, and the device keeps that (and potentially more of its surroundings) around in a smaller, faster "transparent" piece of memory. That makes sense, because it's more common that data that was recently read is read again than some data that nobody cared about for a long time.</p>
<p>DPO and FUA are just really old techniques to tell SCSI (and consequently, ATAPI) devices to bypass that cache (FUA was supposed to force reading from the spinning platter without using what's in the cache, whereas DPO was meant to say, hey, this is probably a one-off read; don't care to start caching what I read here). Makes no sense for an SSD in how they were thought out in the early 1990s, so these extensions are not available for your SSD.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'll think twice before using GitHub Actions again (172 pts)]]></title>
            <link>https://ninkovic.dev/blog/2025/think-twice-before-using-github-actions</link>
            <guid>42764762</guid>
            <pubDate>Mon, 20 Jan 2025 03:41:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ninkovic.dev/blog/2025/think-twice-before-using-github-actions">https://ninkovic.dev/blog/2025/think-twice-before-using-github-actions</a>, See on <a href="https://news.ycombinator.com/item?id=42764762">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Before I rant about GitHub Actions, I'd like to set the context on where this dissatisfaction comes from. My team consists of about 15 engineers constantly pushing to the main branch. Our code lives in a monorepo split per module, which, through <a href="https://trunkbaseddevelopment.com/" rel="noopener noreferrer" target="_blank">trunk based development</a>, gets deployed multiple times a day.</p><p>I want to emphasize that your mileage may vary. There will be folks who say GitHub Actions are great (I also use them for smaller projects), but as with any tool, it has limits and might not be suitable for all problems. Let's look at some of them.</p><br><h2 id="pull-request-and-required-checks">Pull request and required checks</h2><p>Our code sits in a monorepo which is further divided into folders. Every folder is independent of each other and can be tested, built, and deployed separately.</p><pre><code>monorepo/
    ├─ api1/
    ├─ api2/
    ├─ web-app1/
    ├─ web-app2/</code></pre><p>Each of these folders has its pipeline. We leverage <a href="https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#onpushpull_requestpull_request_targetpathspaths-ignore" rel="noopener noreferrer" target="_blank">GitHub Actions paths</a> to trigger a pipeline only when there is a code change within that folder.</p><p>A good practice is not to allow pull requests to be merged unless all checks are green. However trivial it might sound, this becomes notoriously difficult with the above monorepo setup.</p><p>In GitHub you can specify a "required check", the name of the step in your pipeline that always has to be green before a pull request is merged. As an example, I can say that <code>web-app1 - Unit tests</code> are required to pass. The problem is that this step will only run when I change something in the <code>web-app1</code> folder. So if my pull request only made changes in <code>api1</code> I will never be able to merge my pull request! 🤯</p><p>In these two GitHub threads <a href="https://github.com/orgs/community/discussions/44490" rel="noopener noreferrer" target="_blank">1</a>, <a href="https://github.com/orgs/community/discussions/13690" rel="noopener noreferrer" target="_blank">2</a> you can see the impact. The bottom line is, that working around this limitation is hacky, difficult to maintain, and costly since you have to run additional pipelines just to determine if a pull request can be merged or not!</p><p>GitHub should not rely on specific names for the required checks. They can just say - all checks have to pass before you merge. That way, whatever pipelines and checks your pull requests have triggered will be considered mandatory. It's been almost 3 years since these issues were raised, and nothing changed yet!</p><br><h2 id="reusability-and-yaml">Reusability and YAML</h2><p>My impression is that when your pipeline grows, it becomes more and more difficult to manage it with GitHub Actions. Here is an example workflow that can be called from other workflows, can be triggered manually, and triggers when someone pushes to the master branch.</p><pre><code>name: CD - api1

on:
  push:
    paths:
      - 'api1/**'
    branches:
      - master
  workflow_dispatch:
    inputs:
      target_environment:
        type: environment
        default: 'staging'
        required: true
  workflow_call:
    inputs:
      target_environment:
        type: string
        required: true

jobs:
  deploy-api1:
    environment:
      name: ${{ github.event_name == 'push' &amp;&amp; 'production' || inputs.target_environment }}

  smoke-tests:
    if: ${{ github.event_name == 'push' || inputs.target_environment == 'production' }}
    name: Smoke Tests
    uses: ./.github/workflows/smoke-tests.yml
    with:
      target_environment: 'production'
    secrets: inherit
</code>
        </pre><p>What I notice doing more and more is that I have to add lots of if statements such as this.</p><pre><code> if: ${{ github.event_name == 'push' || inputs.target_environment == 'production' }}</code></pre><p>While I could split this into multiple workflows with different triggers, then I'm getting more and more files to maintain. A workflow reuse should be a one-liner but I always have to write more lines and a lot of duplicated statements such as workflow name, <code>secrets: inherit</code> etc. Our <code>.github</code> folder already contains 30+ files.</p><p>Another pitfall that happens often is the <code>needs</code> clause. When you are refactoring and removing jobs, it's easy to forget to update this clause and subsequent steps. While there are linters available, they are not perfect. The sad part is that I can only see mistakes when I push the workflow, I'd expect to know about this way earlier.</p><pre><code>needs: [ build, deploy, generate-release-tag ]
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/create-git-tag
        with:
          release_tag: ${{ needs.generate-release-tag.outputs.release_tag }}   
</code></pre><br><h2 id="lack-of-local-development">Lack of local development</h2><p>It's a known thing that there is no way of running GitHub Actions locally. There is a tool called <a href="https://github.com/nektos/act" rel="noopener noreferrer" target="_blank">act</a> but in my experience it's subpar.</p><br><h2 id="github-doesnt-care">GitHub doesn't care</h2><p>Of all the pain points, this is the worst one. It seems that GitHub doesn't care about fixing any of these issues or improving its product. Some of the threads have been open for years without any action taken by GitHub. A lot of these issues have <a href="https://github.com/github/roadmap/discussions/1014" rel="noopener noreferrer" target="_blank">been recently closed by GitHub</a> causing a backlash from the community. There are no signs that these will be addressed based on their <a href="https://github.com/orgs/github/projects/4247/views/1" rel="noopener noreferrer" target="_blank">public roadmap</a>.</p><br><h2 id="options">Options</h2><p>Considering all the problems listed, with the lack of motivation from GitHub I'd think twice before using GitHub Actions again. The CI/CD product space offers a lot of options such as Gitlab, Jenkins, TeamCity, etc. I used some of these and at this moment, they offer a better service for the money. Things like <a href="https://dagger.io/" rel="noopener noreferrer" target="_blank">Dagger</a> are also worth evaluating since they bring new perspectives into the game.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse Engineering Bambu Connect (500 pts)]]></title>
            <link>https://wiki.rossmanngroup.com/wiki/Reverse_Engineering_Bambu_Connect</link>
            <guid>42764602</guid>
            <pubDate>Mon, 20 Jan 2025 03:08:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.rossmanngroup.com/wiki/Reverse_Engineering_Bambu_Connect">https://wiki.rossmanngroup.com/wiki/Reverse_Engineering_Bambu_Connect</a>, See on <a href="https://news.ycombinator.com/item?id=42764602">Hacker News</a></p>
Couldn't get https://wiki.rossmanngroup.com/wiki/Reverse_Engineering_Bambu_Connect: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>