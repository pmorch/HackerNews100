<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 05 Jan 2025 02:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Nearly half Dell's US workforce has rejected RTO. Rather WFH than get promoted (2024) (178 pts)]]></title>
            <link>https://www.msn.com/en-us/money/companies/nearly-half-of-dell-s-full-time-workforce-in-the-u-s-has-rejected-returning-to-the-office-they-d-rather-work-from-home-than-get-promoted/ar-BB1oBygb</link>
            <guid>42598722</guid>
            <pubDate>Sun, 05 Jan 2025 00:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/money/companies/nearly-half-of-dell-s-full-time-workforce-in-the-u-s-has-rejected-returning-to-the-office-they-d-rather-work-from-home-than-get-promoted/ar-BB1oBygb">https://www.msn.com/en-us/money/companies/nearly-half-of-dell-s-full-time-workforce-in-the-u-s-has-rejected-returning-to-the-office-they-d-rather-work-from-home-than-get-promoted/ar-BB1oBygb</a>, See on <a href="https://news.ycombinator.com/item?id=42598722">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[ELKS: Linux for 16-bit Intel Processors (113 pts)]]></title>
            <link>https://github.com/ghaerr/elks</link>
            <guid>42596983</guid>
            <pubDate>Sat, 04 Jan 2025 19:23:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ghaerr/elks">https://github.com/ghaerr/elks</a>, See on <a href="https://news.ycombinator.com/item?id=42596983">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Documentation/img/ELKS-Logo.png"><img src="https://github.com/ghaerr/elks/raw/master/Documentation/img/ELKS-Logo.png" alt="logo"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jbruchon/elks/workflows/cross/badge.svg"><img src="https://github.com/jbruchon/elks/workflows/cross/badge.svg" alt="cross"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/jbruchon/elks/workflows/main/badge.svg"><img src="https://github.com/jbruchon/elks/workflows/main/badge.svg" alt="main"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is ELKS?</h2><a id="user-content-what-is-elks" aria-label="Permalink: What is ELKS?" href="#what-is-elks"></a></p>
<p dir="auto">ELKS is a project providing a Linux-like OS for systems based on the Intel
IA16 architecture (16-bit processors: 8086, 8088, 80188, 80186, 80286,
NEC V20, V30 and compatibles). Such systems are ancient computers (IBM-PC
XT / AT and clones) as well as more recent SBCs, SoCs, and FPGAs. ELKS supports networking and installation to HDD using both MINIX and FAT file systems.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory requirements</h2><a id="user-content-memory-requirements" aria-label="Permalink: Memory requirements" href="#memory-requirements"></a></p>
<ul dir="auto">
<li>Stock images require 512k RAM</li>
<li>ELKS requires 256k RAM to run, 512k to be really useful</li>
<li>No hardware MMU required</li>
<li>ROM-based systems can run in 128k RAM</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try ELKS online</h2><a id="user-content-try-elks-online" aria-label="Permalink: Try ELKS online" href="#try-elks-online"></a></p>
<p dir="auto">You can <a href="https://copy.sh/v86/?profile=elks" rel="nofollow">play with ELKS online</a> thanks to the v86 emulator. Login with "root" and no password. Go to the bin folder and try the different commands available. Try nxtetris. Start the game by pressing "n".</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Watch ELKS in action</h2><a id="user-content-watch-elks-in-action" aria-label="Permalink: Watch ELKS in action" href="#watch-elks-in-action"></a></p>
<ul dir="auto">
<li><a href="https://www.youtube.com/watch?v=eooviN1SdQ8" rel="nofollow">ELKS, a 16-bit no-MMU Linux on Amstrad PC 2086</a> (thanks @pawoswm-arm)</li>
<li><a href="https://www.youtube.com/watch?v=6rwlqmdebxk" rel="nofollow">Booting ELKS on an old 286 MB from 1,44MB floppy</a> (thanks @xrayer)</li>
<li><a href="https://youtu.be/ZDffBj6zY-w?t=687" rel="nofollow">Epson PC Portable Q150A / Equity LT (Nec V30 8086 - 1989)</a> (thanks Alejandro)</li>
<li><a href="https://www.youtube.com/watch?v=Tr2yMjrgP8o" rel="nofollow">ELKS on ESP32 through IBM PC emulator</a> (thanks @fdivitto)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto">ELKS running on QEMU
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/ELKS_0.7.0.png"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/ELKS_0.7.0.png" alt="ss1"></a></p>
<p dir="auto">Olivetti M24 8086 CPU
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/Olivetti_M24_8086_CPU.png"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/Olivetti_M24_8086_CPU.png" alt="ss2"></a></p>
<p dir="auto">ELKS Networking showing netstat and process list
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/ELKS_Networking.png"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/ELKS_Networking.png" alt="ss3"></a></p>
<p dir="auto">Running ELKS Basic on PC-9801UV21 (NEC V30 CPU)
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/PC-9801UV21_V30_CPU.png"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/PC-9801UV21_V30_CPU.png" alt="ss4"></a></p>
<p dir="auto">Running Matrix and vi on multiple consoles
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/ELKS_Matrix.jpg"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/ELKS_Matrix.jpg" alt="ss5"></a></p>
<p dir="auto">Of course Doom
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/ELKS_Doom.png"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/ELKS_Doom.png" alt="ss6"></a></p>
<p dir="auto">Telnet to an old BBS
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ghaerr/elks/blob/master/Screenshots/ELKS_telnet_BBS.jpg"><img src="https://github.com/ghaerr/elks/raw/master/Screenshots/ELKS_telnet_BBS.jpg" alt="ss7"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Downloads</h2><a id="user-content-downloads" aria-label="Permalink: Downloads" href="#downloads"></a></p>
<p dir="auto">A full set of disk images are available for download, for you to try out ELKS: <a href="https://github.com/ghaerr/elks/releases">Downloads</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to build</h2><a id="user-content-how-to-build" aria-label="Permalink: How to build" href="#how-to-build"></a></p>
<p dir="auto">Full build instructions are <a href="https://github.com/ghaerr/elks/blob/master/BUILD.md">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Wiki</h2><a id="user-content-wiki" aria-label="Permalink: Wiki" href="#wiki"></a></p>
<p dir="auto">Help on how to use ELKS, as well as technical tutorials, are available on our <a href="https://github.com/ghaerr/elks/wiki">Wiki</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">More information is in the Documentation folder: <a href="https://htmlpreview.github.io/?https://github.com/ghaerr/elks/blob/master/Documentation/index.html" rel="nofollow">Index of ELKS Documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resources</h2><a id="user-content-resources" aria-label="Permalink: Resources" href="#resources"></a></p>
<p dir="auto">Other projects and resources interesting to ELKS and our programming community:</p>
<ul dir="auto">
<li><a href="https://github.com/ghaerr/blink16">blink16</a> A visual 8086 emulator and debugger capable of booting the ELKS kernel for symbolic debugging, as well as an emulator for ELKS executables.</li>
<li><a href="https://justine.lol/sizetricks/" rel="nofollow">Size Optimization Tricks</a> A great article from Justine Tunney's blog showing how big things can be done without bloat.</li>
<li><a href="https://github.com/tkchia/gcc-ia16">gcc-ia16</a> TK Chia's gcc compiler targeted for 8086, maintained and used for the ELKS kernel and all its applications.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">More information</h2><a id="user-content-more-information" aria-label="Permalink: More information" href="#more-information"></a></p>
<p dir="auto">Questions? Problems? Patches? Open an issue on the ELKS GitHub project!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US newspapers are deleting old crime stories, offering subjects a 'clean slate' (181 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2025/jan/04/newspaper-crime-stories</link>
            <guid>42595307</guid>
            <pubDate>Sat, 04 Jan 2025 15:33:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2025/jan/04/newspaper-crime-stories">https://www.theguardian.com/us-news/2025/jan/04/newspaper-crime-stories</a>, See on <a href="https://news.ycombinator.com/item?id=42595307">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>C</span>ivil rights advocates across the US have long fought to <a href="https://www.theguardian.com/us-news/2022/sep/14/criminal-records-california-sealing-expunge-jay-jordan" data-link-name="in body link">free people from their criminal records</a>, with campaigns to expunge old cases and keep people’s past arrests private when they apply for jobs and housing.</p><p>The efforts are critical, as <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2024/03/29/a-proclamation-on-second-chance-month-2024/" data-link-name="in body link">more than</a> 70 million Americans <a href="https://www.ncsl.org/civil-and-criminal-justice/criminal-records-and-reentry-toolkit" data-link-name="in body link">have</a> prior convictions or arrests – roughly <a href="https://www.sentencingproject.org/app/uploads/2022/08/Americans-with-Criminal-Records-Poverty-and-Opportunity-Profile.pdf" data-link-name="in body link">one in three</a> adults. But the policies haven’t addressed one of the most damaging ways past run-ins with police can derail people’s lives: old media coverage.</p><p>Some newsrooms are working to fill that gap.</p><p>A handful of local newspapers across the US have in recent years launched programs to review their archives and consider requests to remove names or delete old stories to protect the privacy of subjects involved in minor crimes.</p><figure id="c6f9c9ca-9e82-4291-a72b-a3d4d31faa0d" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="people walking out of a building " src="https://i.guim.co.uk/img/media/162037d12034934ac7c90be16c71bed37c32711e/0_0_4968_3624/master/4968.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="324.6135265700483" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The Oregonian newspaper building in Portland.</span> Photograph: Don Ryan/AP</figcaption></figure><p>“In the old days, you put a story in the newspaper and it quickly, if not immediately, receded into memory,” said Chris Quinn, editor of <a href="http://cleveland.com/" data-link-name="in body link">Cleveland.com</a> and the Plain Dealer newspaper. “But because of our [search engine] power, anything we write now about somebody is always front and center.”</p><p>Quinn pioneered a “<a href="https://www.cleveland.com/metro/2018/09/were_expanding_our_right-to-be.html" data-link-name="in body link">right-to-be-forgotten</a>” experiment <a href="https://www.cleveland.com/opinion/2018/07/right_to_be_forgotten_clevelan.html" data-link-name="in body link">in 2018</a>, motivated by the many inquiries he would receive from subjects describing the harms of past crime coverage and pleading for deletion. “People would say: ‘Your story is wrecking my life. I made a mistake, but … I’ve changed my life.’”</p><p>It was long considered taboo in media to retract or alter old stories, particularly when there are no concerns about accuracy. But Quinn said he felt an ethical obligation to rethink those norms. “I couldn’t take it any more … I just got tired of telling people no and standing on tradition instead of being thoughtful.”</p><p>He recalled an early case of a <a href="https://www.cleveland.com/opinion/2018/07/right_to_be_forgotten_clevelan.html" data-link-name="in body link">drunken teenager</a> who broke part of a monument in a cemetery and was charged. Years later, he had “completely atoned” and was starting to apply for jobs, Quinn said. “He did something stupid as a kid … and he said: ‘I can’t move on.’” The editor granted his request, removed his name and presented it to his colleagues as a model for similar cases.</p><p>There was some initial internal resistance, but eventually Quinn and his staff came up with general parameters: they would not erase names in cases of violence, sex offenses, crimes against children or corruption. Police officers would be treated as public officials, so stories of their wrongdoing would remain. The incident typically had to be at least four years old, although the paper has made exceptions. Quinn did not want to have strict rules, since every case is different. The guiding question, he said, was: “What’s more valuable – this story remaining available to the public, or this person being able to move on?”</p><p>The concept has since <a href="https://slate.com/technology/2021/02/boston-globe-fresh-start-right-to-be-forgotten-newspapers.html" data-link-name="in body link">spread</a> to the <a href="https://www.bostonglobe.com/2021/01/22/metro/globes-fresh-start-initiative-frequently-asked-questions/" data-link-name="in body link">Boston Globe</a>, the <a href="https://www.washingtonpost.com/lifestyle/media/old-arrest-boston-globe-fresh-start/2021/01/22/122cbd0c-5cd1-11eb-b8bd-ee36b1cd18bf_story.html" data-link-name="in body link">Atlanta Journal-Constitution</a>, the <a href="https://www.bangordailynews.com/forgetme/" data-link-name="in body link">Bangor Daily News</a> in Maine, the <a href="https://www.oregonlive.com/opinion/2024/11/letter-from-the-editor-heartfelt-request-for-clean-slate-underscores-why-we-offer-program.html" data-link-name="in body link">Oregonian</a> and New Jersey’s <a href="http://nj.com/" data-link-name="in body link">NJ.com</a>. The efforts gained momentum after racial justice protests in 2020 prompted newsroom reflections across the US about the media’s legacy of biased and harmful coverage, including its <a href="https://nbcuacademy.com/claire-wang-mugshots-crime-beat-police/" data-link-name="in body link">widespread use of mugshots</a>.</p><p>Quinn dramatically scaled up his work after receiving Google funding allowing his newsroom to develop a tool for proactively identifying stories potentially worthy of deletion. The work was painstaking, but allowed for <a href="https://www.cleveland.com/news/2022/02/weve-helped-thousands-of-people-get-past-their-mistakes-with-googles-support-letter-from-the-editor.html" data-link-name="in body link">thousands of removals</a>, making the program more equitable, instead of only benefiting readers aware of its initiative.</p><p>The Portland-based Oregonian once had community reporters in bureaus in surrounding suburbs who would cover hyperlocal news, including very trivial offenses, said Therese Bottomly, the paper’s editor. “Is that something that should really haunt somebody for years and years?” she questioned. Recognizing these were minor offenses the paper no longer covered, she formally launched a <a href="https://www.oregonlive.com/opinion/2021/03/letter-from-the-editor-well-be-taking-a-new-look-at-old-crime-news.html" data-link-name="in body link">clean slate program</a> in 2021, establishing an internal committee to review requests.</p><p>The Oregonian offers several options. It can remove a mugshot – a logical step after Oregon changed the law to limit the release of booking photos, with lawmakers recognizing their <a href="https://www.opb.org/article/2021/11/02/oregon-mugshot-law-booking-photos-released/" data-link-name="in body link">severe harm</a>. The paper can also remove a subject’s name, delete the story entirely, or ask Google to deindex the article, meaning it would still exist on OregonLive.com, but wouldn’t easily surface in a web search. The committee factchecks claims of requesters, ensuring they have completed court requirements and stayed clean.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-15">skip past newsletter promotion</a><p id="EmailSignup-skip-link-15" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Each case is carefully considered. An educator who had an expunged misdemeanor harassment case <a href="https://www.oregonlive.com/opinion/2021/03/letter-from-the-editor-well-be-taking-a-new-look-at-old-crime-news.html" data-link-name="in body link">requested removal</a>, but the Oregonian decided to maintain its article because additional reporting suggested he had dodged sexual misconduct allegations for years. The committee has <a href="https://www.oregonlive.com/opinion/2023/12/letter-from-the-editor-an-update-on-our-clean-slate-program.html" data-link-name="in body link">removed articles</a> about a man jailed for car thefts and a woman caught with illegal drugs.</p><p>In November, Bottomly published excerpts from one subject’s heartfelt plea for the removal of an article about a non-violent conviction when he had “hit rock bottom” in the throes of addiction. He spoke of his long journey of rehabilitation and the family he was now raising.</p><p>“I can now take pride in saying my life is unrecognizable from the one written about in the OregonLive article,” he <a href="https://www.oregonlive.com/opinion/2024/11/letter-from-the-editor-heartfelt-request-for-clean-slate-underscores-why-we-offer-program.html" data-link-name="in body link">wrote</a>. “I live in fear that a single Google search of my name will ruin what I have worked so hard to build.” His nearly 10-year-old story was removed. In total, the Oregonian has approved 56 requests, partially approved 11 (including deindexing but not removing) and denied 29 cases, Bottomly said.</p><p>Bottomly noted that the vast majority of people in state prison will eventually be released. “These folks are going to be our neighbors, our co-workers and hopefully contributing members of society someday. So should we figure out ways to at least not be an unnecessary barrier to re-entry for something truly minor and in the past, and for which somebody has paid their debt?”</p><p>Editors say the programs have inspired newsrooms to be more deliberate in their current coverage, leaving names out when not relevant and thinking through the consequences of photos in crime stories.</p><p>Saun Hough, director of partnerships for Californians for Safety and Justice, an advocacy group that has fought for <a href="https://calmatters.org/justice/2024/03/california-criminal-records-expungement-law/" data-link-name="in body link">mass expungements</a>, said reporters often capture a one-sided, law enforcement narrative about an arrest, then fail to follow up. Someone jailed for drug trafficking may ultimately be convicted of possession, or a woman arrested for prostitution could later be confirmed a sex-trafficking survivor, he said. It can take years for cases to be adjudicated, but a report based on an initial arrest might be the story that follows someone through life.</p><p>“It creates this constant sense of anxiety that many people live with,” said Hough, noting that crime stories generally lack context about a person’s traumas or struggles that led to the incident. “People wake up every day and pray that they don’t have to talk about what the newspaper wrote about their arrest and relive that. You have this thought in your mind that you’re one Google [search] away from everything being ripped away.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Combining 15s interval whole-sky-camera photos to form a 4y spanning keogram (363 pts)]]></title>
            <link>https://astrodon.social/@cgbassa/113770318993975063</link>
            <guid>42595190</guid>
            <pubDate>Sat, 04 Jan 2025 15:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astrodon.social/@cgbassa/113770318993975063">https://astrodon.social/@cgbassa/113770318993975063</a>, See on <a href="https://news.ycombinator.com/item?id=42595190">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A Mole Infiltrated the Highest Ranks of American Militias (373 pts)]]></title>
            <link>https://www.propublica.org/article/ap3-oath-keepers-militia-mole</link>
            <guid>42594766</guid>
            <pubDate>Sat, 04 Jan 2025 14:13:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/ap3-oath-keepers-militia-mole">https://www.propublica.org/article/ap3-oath-keepers-militia-mole</a>, See on <a href="https://news.ycombinator.com/item?id=42594766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pp-location="article body">

        
                    <div data-pp-location="top-note">
                

                                                
            <p>ProPublica is a nonprofit newsroom that investigates abuses of power. Sign up to receive <a href="https://www.propublica.org/newsletters/the-big-story?source=www.propublica.org&amp;placement=top-note&amp;region=national">our biggest stories</a> as soon as they’re published.</p>

                

            </div><!-- end .article-body__top-notes -->
        
                    

<div>
    <h3>Reporting Highlights</h3>
    <ul>
                    <li><span>A Freelance Vigilante: </span> A wilderness survival trainer spent years undercover, climbing the ranks of right-wing militias. He didn’t tell police or the FBI. He didn’t tell his family or friends.</li>
            <li><span>The Future of Militias: </span> He penetrated a new generation of militia leaders, which included doctors and government attorneys. Experts say that militias could have a renaissance under Donald Trump.</li>
            <li><span>A Secret Trove: </span> He sent ProPublica a massive trove of documents. The conversations that he secretly recorded give a unique, startling window into the militia movement.</li>
            </ul>
    <p>
        These highlights were written by the reporters and editors who worked on this story. <span id="survey-placeholder"></span>
    </p>
</div>





        
        




                    

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="2.0">John Williams kept a backpack filled with everything he’d need to go on the run: three pairs of socks; a few hundred dollars cash; makeshift disguises and lock-picking gear; medical supplies, vitamins and high-calorie energy gels; and thumb drives that each held more than 100 gigabytes of encrypted documents, which he would quickly distribute if he were about to be arrested or killed.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="3.0">On April 1, 2023, Williams retrieved the bag from his closet and rushed to his car. He had no time to clean the dishes that had accumulated in his apartment. He did not know if armed men were out looking for him. He did not know if he would ever feel safe to return. He parked his car for the night in the foothills overlooking Salt Lake City and curled up his 6-foot-4-inch frame in the back seat of the 20-year-old Honda. This was his new home.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="4.0">He turned on a recording app to add an entry to his diary. His voice had the high-pitched rasp of a lifelong smoker: “Where to fucking start,” he sighed, taking a deep breath. After more than two years undercover, he’d been growing rash and impulsive. He had feared someone was in danger and tried to warn him, but it backfired. Williams was sure at least one person knew he was a double agent now, he said into his phone. “It’s only a matter of time before it gets back to the rest.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="5.0">In the daylight, Williams dropped an envelope with no return address in a U.S. Postal Service mailbox. He’d loaded it with a flash drive and a gold Oath Keepers medallion. </p>

<p data-pp-blocktype="copy" data-pp-id="5.1">It was addressed to me.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="6.0">The documents laid out a remarkable odyssey. Posing as an ideological compatriot, Williams had penetrated the top ranks of two of the most prominent right-wing militias in the country. He’d slept in the home of the man who claims to be the new head of the Oath Keepers, rifling through his files in the middle of the night. He’d devised elaborate ruses to gather evidence of militias’ ties to high-ranking law enforcement officials. He’d uncovered secret operations like the surveillance of a young journalist, then improvised ways to sabotage the militants’ schemes. In one group, his ploys were so successful that he became the militia’s top commander in the state of Utah.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="7.0">Now he was a fugitive. He drove south toward a desert four hours from the city, where he could disappear.</p>
        
    
                    
<hr>
<h3><p>1. Prelude</p>
</h3>

        
    
                    
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="11.0">I’d first heard from Williams five months earlier, when he sent me an intriguing but mysterious anonymous email. “I have been attempting to contact national media and civil rights groups for over a year and been ignored,” it read. “I’m tired of yelling into the void.” He sent it to an array of reporters. I was the only one to respond. I’ve burned a lot of time sating my curiosity about emails like that. I expected my interest to die after a quick call. Instead, I came to occupy a dizzying position as the only person to know the secret Williams had been harboring for almost two years.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="12.0">We spoke a handful of times over encrypted calls before he fled. He’d been galvanized by the Jan. 6, 2021, storming of the Capitol, Williams told me, when militias like the Oath Keepers conspired to violently overturn the 2020 presidential election. He believed democracy was under siege from groups the FBI has said pose a major domestic terrorism threat. So he infiltrated the militia movement on spec, as a freelance vigilante. He did not tell the police or the FBI. A loner, he did not tell his family or friends.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="13.0">Williams seemed consumed with how to ensure this wasn’t all a self-destructive, highly dangerous waste of time. He distrusted law enforcement and didn’t want to be an informant, he said. He told me he hoped to damage the movement by someday going public with what he’d learned.</p>
        
    
                    
        <figure data-pp-id="14" data-pp-blocktype="intro-module">
    <h4>
        Good journalism makes a difference:
    </h4>
    <p>Our nonprofit, independent newsroom has one job: to hold the powerful to account. Here’s how our investigations are <a href="https://www.propublica.org/impact">spurring real world change:</a></p>
    <div>

        
<div>
            
    


    <p><img alt="" width="400" height="400" loading="lazy" js-autosizes="" src="https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=13155306325de40f6283157b2d3b0bce" srcset="https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=111cb238a501d7819ba97de958ed9c25 400w, https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=13155306325de40f6283157b2d3b0bce 800w, https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=318f94dd9d6095717d98172ba7488a9b 1200w, https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=41140f1334873fa15cec644d8eaeb8fd 1300w, https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=651e1062f5fe157aff5a5d2fbe896541 1450w, https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=57626a0b29177ac58135400f3f31765d 1600w, https://img.assets-c3.propublica.org/images/series/abortion-deaths-3x2_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=59a51ffe9fe18a0dbfcf4340660f1b03 2000w"></p>
</div>

        
<div>
            
    


    <p><img alt="" width="400" height="400" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=bef937d6f2c382c24d2579a21fbe4faa" srcset="https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=5175e3f9b0f6c48e154f80b4e632c13a 400w, https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=bef937d6f2c382c24d2579a21fbe4faa 800w, https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=2b9b25d77be27fd1ad53521a86ff8ade 1200w, https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=c9ef0572251048f795134a1bb0e3e576 1300w, https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=d64703b06df301746018b7188afd4ce9 1450w, https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=94c802a3d3ecaa7fbb4523f54b1044cc 1600w, https://img.assets-d.propublica.org/v5/images/2023113-Ethics-Code.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=3cda2fa7f244212ec33904a1f61a3545 2000w"></p><p>The Supreme Court created its <a href="https://www.propublica.org/article/supreme-court-adopts-ethics-code-scotus-thomas-alito-crow">first-ever code of conduct</a> after we reported that justices repeatedly failed to disclose gifts and travel from the ultrawealthy.</p>
</div>

        
<div>
            
    


    <p><img alt="" width="400" height="400" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=800&amp;q=75&amp;w=800&amp;s=fe369ef1ba2d01bd64204693ec80e847" srcset="https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=400&amp;q=75&amp;w=400&amp;s=6db5bb5867e6d4c42505d0782a465d40 400w, https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=800&amp;q=75&amp;w=800&amp;s=fe369ef1ba2d01bd64204693ec80e847 800w, https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=1200&amp;q=75&amp;w=1200&amp;s=9dbc0f2f5193ebdbe725bd61ac1a6e3c 1200w, https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=1300&amp;q=75&amp;w=1300&amp;s=339b2f029d07883f613ca5802ce43b7e 1300w, https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=1450&amp;q=75&amp;w=1450&amp;s=82cf776e5b06fc60c92614c4b0819869 1450w, https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=1600&amp;q=75&amp;w=1600&amp;s=9ee6d1e74e5ba2896918a4680443ccfe 1600w, https://img.assets-d.propublica.org/v5/images/1212-02-Idaho-Falls-HS-shed-classrooms_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.4954&amp;fp-y=0.2561&amp;h=2000&amp;q=75&amp;w=2000&amp;s=c099acfc424a52ad2d761a3ef51da707 2000w"></p>
</div>

        
<div>
            
    


    <p><img alt="" width="400" height="400" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=927224f0499410925ffdd8bc698a04cc" srcset="https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=dc271b994c23871bea1f6aafa7b67496 400w, https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=927224f0499410925ffdd8bc698a04cc 800w, https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=53b7a19124cc5008fe9939fefc732780 1200w, https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=36b7b1994244b6b7fbe99c20d5b00bce 1300w, https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=0f7cb4b35cacaaa48f71aa79500d7de1 1450w, https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=ca6ec76b4af74ab79179ec930efcdfba 1600w, https://img.assets-d.propublica.org/v5/images/20240430-epa-acephate-ban_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=cd3eba26f542773e8cf599e334e99375 2000w"></p>
</div>

        
<div>
            
    


    <p><img alt="" width="400" height="400" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=c9e12f8feb4547bfd29bf2053213c82c" srcset="https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=913b2fcb5d9afba8d46eda2d46df47b3 400w, https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=c9e12f8feb4547bfd29bf2053213c82c 800w, https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=39db4abbc05cf1e34d09c976fb713652 1200w, https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=c9e1a6b479f1edf25e4ea60d6e338c51 1300w, https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=2c553194f6868cede4edab7f41973e7c 1450w, https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=64a2fe12825314a61b24ad0d9cd557e6 1600w, https://img.assets-d.propublica.org/v5/images/2024-11-05-Flynn-2024election-057_maxWidth_3000_maxHeight_3000_ppi_72_quality_95_embedColorProfile_true.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=5d12a9f18aea589aec69f5ea20d3df55 2000w"></p><div>
                    <p>Support ProPublica’s investigative reporting today.</p>
<p><a href="https://give.propublica.org/give/346423/#!/donation/checkout?c_src=imp">Donate Now</a></p>

            </div>
</div>

            </div>
    <nav>
        <a href="#"><span></span>&nbsp;</a>
        <a href="#"><span></span>&nbsp;</a>
        <a href="#"><span></span>&nbsp;</a>
        <a href="#"><span></span>&nbsp;</a>
        <a href="#"><span></span>&nbsp;</a>
            </nav>
    <p>We’re trying something new. <a href="https://iteratehq.com/propublica/670eabefffb484af7dc7db86">Was it helpful?</a></p>
</figure>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="15.0">The Capitol riot had been nagging at me too. I’d <a href="https://www.propublica.org/article/new-details-suggest-senior-trump-aides-knew-jan-6-rally-could-get-chaotic">reported extensively on Jan. 6</a>. I’d sat with families who blamed militias for snatching their loved ones away from them, pulling them into a life of secret meetings and violent plots — or into a jail cell. By the time Williams contacted me, though, the most infamous groups appeared to have largely gone dark. Were militias more enduring, more potent, than it seemed?</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="16.0">Some of what he told me seemed significant. Still, before the package arrived, it could feel like I was corresponding with a shadow. I knew Williams treated deception as an art form. “When you spin a lie,” he once told me, “you have to have things they can verify so they won’t think to ask questions.” While his stories generally seemed precise and sober — always reassuring for a journalist — I needed to proceed with extreme skepticism.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="17.0">So I pored over his files, tens of thousands of them. They included dozens of hours of conversations he secretly recorded and years of private militia chat logs and videos. I was able to authenticate those through other sources, in and out of the movement. I also talked to dozens of people, from Williams’ friends to other members of his militias. I dug into his tumultuous past and discovered records online he hadn’t pointed me to that supported his account.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="18.0">The files give a unique window, at once expansive and intimate, into one of the <a href="https://www.propublica.org/article/inside-secret-ap3-militia-american-patriots-three-percent">most consequential and volatile social movements of our time</a>. Williams penetrated a new generation of paramilitary leaders, which included doctors, career cops and government attorneys. Sometimes they were frightening, sometimes bumbling, always heavily armed. It was a world where a man would propose assassinating politicians, only to spark a debate about logistics.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="19.0">Federal prosecutors have convicted more than 1,000 people for their role in Jan. 6. Key militia captains were sent to prison for a decade or more. But that did not quash the allure that militias hold for a broad swath of Americans.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="20.0">Now President-elect Donald Trump has <a href="https://www.nytimes.com/2024/07/31/us/politics/trump-jan-6-pardons-nabj.html">promised to pardon Jan. 6 rioters</a> when he returns to the White House. Experts warn that such a move could trigger a renaissance for militant extremists, sending them an unprecedented message of protection and support — and making it all the more urgent to understand them.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="21.0">(Unless otherwise noted, none of the militia members mentioned in this story responded to requests for comment.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="22.0">Williams is part of a <a href="https://www.newyorker.com/magazine/2024/08/26/infiltrating-the-far-right">larger cold war</a>, radical vs. radical, that’s stayed mostly in the shadows. A left-wing activist told me he personally knows about 30 people who’ve gone undercover in militias or white supremacist groups. They did not coordinate with law enforcement, instead taking the surveillance of one of the most intractable features of American politics into their own hands.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="23.0">Skeptical of authorities, militias have sought to reshape the country through armed action. Williams sought to do it through betrayals and lies, which sat with him uneasily. “I couldn’t have been as successful at this if I wasn’t one of them in some respects,” he once told me. “I couldn’t have done it so long unless they recognized something in me.”</p>
        
    
                    
<hr>
<h3><p>2. The Struggle</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="25.0">If there is one moment that set Williams on his path into the militia underground, it came roughly a decade before Jan. 6, when he was sent to a medium-security prison. He was in his early 30s, drawn to danger and filled with an inner turbulence.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="26.0">Williams grew up in what he described to me, to friends and in court records as a dysfunctional and unhappy home. He was a gay child in rural America. His father viewed homosexuality as a mortal sin, he said. Williams spent much of his childhood outdoors, bird-watching, camping and trying to spend as little time as possible at home. (John Williams is now his legal name, one he recently acquired.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="27.0">Once he was old enough to move out, Williams continued to go off the grid for weeks at a time. Living in a cave interested him; the jobs he’d found at grocery stores and sandwich shops did not. He told me his young adulthood was “a blank space in my life,” a stretch of “petty crime” and falling-outs with old friends. He pled guilty to a series of misdemeanors: trespassing, criminal mischief, assault.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="28.0">What landed Williams in prison was how he responded to one of those arrests. He sent disturbing, anonymous emails to investigators on the case, threatening their families. Police traced the messages back to him and put him away for three years.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="29.0">Williams found time to read widely in prison — natural history books, Bertrand Russell, Cormac McCarthy. And it served as a finishing school for a skill that would be crucial in his undercover years. Surviving prison meant learning to maneuver around gang leaders and corrections officers. He learned how to steer conversations to his own benefit without the other person noticing.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="30.0">When he got out, he had a clear ambition: to become a wilderness survival instructor. He used Facebook to advertise guided hikes in Utah’s Uinta Mountains. An old photo captures Williams looking like a lanky camp counselor as he shows students an edible plant. He sports a thick ponytail and cargo pants, painted toenails poking out from his hiking sandals.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="31.0">Many people in Utah had turned to wilderness survival after a personal crisis, forming a community of misfits who thrived in environments harsh and remote. Even among them, Williams earned a reputation for putting himself in extreme situations. “Not many people are willing to struggle on their own. He takes that struggle to a high degree,” one friend told me admiringly. Williams took up krav maga and muay thai because he enjoyed fistfights. He once spent 40 days alone in the desert with only a knife, living off chipmunks and currants (by choice, to celebrate a birthday).</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="32.0">Williams struggled to get his survival business going. He’d hand out business cards at hobbyist gatherings with promises of adventure, but in practice, he was mostly leading seminars in city parks for beer money. He would only take calls in emergencies, another friend recalled, because he wanted to save money on minutes.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="33.0">Then around New Year’s in 2019, according to Williams, he received an email from a leader in American Patriots Three Percent, or AP3. He wanted to hire Williams for a training session. He could pay $1,000.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="34.0"><em>Finally</em>, Williams thought. <em>I’m starting to get some traction.</em></p>

<hr>
<h3><p>3. The Decision</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="35.0">They had agreed there’d be no semiautomatic rifles, Williams told me, so everyone brought a sidearm. Some dozen militiamen had driven into the mountains near Peter Sinks, Utah, one of the coldest places in the contiguous U.S. Initially they wanted training in evasion and escape, Williams said, but he thought they needed to work up to that. So for three days, he taught them the basics of wilderness survival, but with a twist: how to stay alive while “trying to stay hidden.” He showed them how to build a shelter that would both keep them dry and escape detection. How to make a fire, then how to clean it up so no one could tell it was ever there.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="36.0">As the days wore on, stray comments started to irk him. Once, a man said he’d been “kiked” into overpaying for his Ruger handgun. At the end of the training, AP3 leaders handed out matching patches. The ritual reminded Williams of a biker gang.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="37.0">He’d already been to some shorter AP3 events to meet the men and tailor the lesson to his first meaningful client, Williams told me. But spending days in the woods with them felt different. He said he found the experience unpleasant and decided not to work with the group again.</p>
        
    
                    

<figure data-pp-id="39" data-pp-blocktype="image">

    


            
    


    <img alt="" width="2100" height="3500" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=d68d10765fbba147e9df8c8f0f646499" srcset="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=667&amp;q=75&amp;w=400&amp;s=cea659648719edbadc5d77a8c0b5ac20 400w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=d68d10765fbba147e9df8c8f0f646499 800w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=1200&amp;s=e2b2763869eb9ab1be22804abbcbe9b6 1200w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2167&amp;q=75&amp;w=1300&amp;s=51c5883cf688ac6c74af04df129e857f 1300w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2417&amp;q=75&amp;w=1450&amp;s=38e1f012ef8a0bdc9d5aa7460c45cf46 1450w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2667&amp;q=75&amp;w=1600&amp;s=4441246826abe9e8f9422f3bd955ae9c 1600w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=3333&amp;q=75&amp;w=2000&amp;s=e47c512c13d019d00540aebbd9cf5fb4 2000w">

                
    


    <img alt="" width="2100" height="2100" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=cdd4684521e706f731bb8328c46652be" srcset="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=c8f536cd9db2147c58a29f7604a5b3ce 400w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=cdd4684521e706f731bb8328c46652be 800w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=ffbabe392f967c1446f3171f3e12eeea 1200w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=3befd75a34ff16b25b1176c556ee8958 1300w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=bdd98a896ed5ace44606042b5cf129b5 1450w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=ac7df4da7e96856acde259c65b95be2d 1600w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_1final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=18e09d557560c74fcdf3bd4503dc3805 2000w">

            
    
<figcaption>
    
        <span>
        <span>Credit: </span>
        Katherine Lam for ProPublica
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="40.0">This portion of Williams’ story — exactly how and why he first became a militia member — is the hardest to verify. By his own account, he kept his thoughts and plans entirely to himself. At the time, he was too embarrassed to even tell his friends what happened that weekend, he said. In the survival community, training militias was considered taboo.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="41.0">I couldn’t help but wonder if Williams was hiding a less gallant backstory. Maybe he’d joined AP3 out of genuine enthusiasm and then soured on it. Maybe now he was trying to fool me. Indeed, when I called the AP3 leader who set up the training, he disputed Williams’ timeline. He remembered Williams staying sporadically but consistently involved after the session in the mountains, as a friend of the group who attended two or three events a year. To further muddy the picture, Williams had warned me the man would say something like that — Williams had worked hard to create the impression that he never left, he said, that he’d just gone inactive for a while, busy with work. (Remarkably, the AP3er defended Williams’ loyalty each time I asserted he’d secretly tried to undermine the group. “He was very well-respected,” he said. “I never questioned his honesty or his intentions.”)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="42.0">Even Williams’ friends told me he was something of a mystery to them. But I found evidence that supports his story where so many loners bare their innermost thoughts: the internet. In 2019 and early 2020, Williams wrote thousands of since-deleted entries in online forums. These posts delivered a snapshot of his worldview in this period: idiosyncratic, erudite and angry with little room for moderation. “There are occasionally militia types that want these skills to further violent fringe agendas and I will absolutely not enable them,” he wrote in one 2020 entry about wilderness survival. In another, he called AP3 and its allies “far right lunatics.” The posts didn’t prove the details of his account, but here was the Williams I knew, writing under pseudonyms long before we’d met.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="43.0">One day, he’d voice his disdain for Trump voters, neoliberalism or “the capitalist infrastructure.” Another, he’d rail against gun control measures as immoral. When Black Lives Matter protests broke out in 2020, Williams wrote that he was gathering medical supplies for local protestors. He sounded at times like a revolutionary crossed with a left-wing liberal arts student. “The sole job of a cop is to bully citizens on behalf of the state,” he wrote. “Violent overthrow of the state is our only viable option.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="44.0">Then came Jan. 6. As he was watching on TV, he later told me, Williams thought he recognized the patch on a rioter’s tactical vest. It looked like the one that AP3 leaders had handed out at the end of his training.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="45.0"><em>Did I teach that guy?</em> he wondered. <em>Why was I so cordial to them all?</em> <em>If they knew I was gay, I bet they’d want me dead, and I actually helped them</em>. <em>Because I was too selfish to think of anything but my career</em>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="46.0">Shame quickly turned to anger, he told me, and to a desire for revenge. Pundits were saying that democracy itself was in mortal peril. Williams took that notion literally. He assumed countless Americans would respond with aggressive action, he said, and he wanted to be among them.</p>
        
    
                    
<hr>
<h3><p>4. A New World</p>
</h3>
<p data-pp-blocktype="copy" data-pp-id="47.1">Williams stood alone in his apartment, watching himself in the mirror.</p>

<p data-pp-blocktype="copy" data-pp-id="47.2">“I’m tall.”</p>

<p data-pp-blocktype="copy" data-pp-id="47.3">“I’m Dave.” </p>

<p data-pp-blocktype="copy" data-pp-id="47.4">“I’m tall.”</p>

<p data-pp-blocktype="copy" data-pp-id="47.5">“I’m Dave.”</p>

<p data-pp-blocktype="copy" data-pp-id="47.6">He tried to focus on his mannerisms, on the intonation of his voice. Whether he was saying the truth or a falsehood, he wanted to appear exactly the same.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="48.0">Months had passed since the Capitol riot. By all appearances, Williams was now an enthusiastic member of AP3. Because he already had an in, joining the group was easy, he said. Becoming a self-fashioned spy took some trial and error, however. In the early days, he had posed as a homeless person to surveil militia training facilities, but he decided that was a waste of time.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="49.0">The casual deceit that had served him in prison was proving useful. Deviousness was a skill, and he stayed up late working to hone it. He kept a journal with every lie he told so he wouldn’t lose track. His syllabus centered on acting exercises and the history of espionage and cults. People like sex cult leader Keith Raniere impressed him most — he studied biographies to learn how they manipulated people, how they used cruelty to wear their followers down into acquiescence.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="50.0">Williams regularly berated the militia’s rank and file. He doled out condescending advice about the group’s security weaknesses, warning their technical incompetence would make them easy targets for left-wing hackers and government snoops. Orion Rollins, the militia’s top leader in Utah, soon messaged Williams to thank him for the guidance. “Don’t worry about being a dick,” he wrote. “It’s time to learn and become as untraceable as possible.” (The AP3 messages Williams sent me were so voluminous that I spent an entire month reading them before I noticed this exchange.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="51.0">Williams was entering the militia at a pivotal time. AP3 once had chapters in nearly every state, with a roster likely in the tens of thousands; as authorities cracked down on the movement after Jan. 6, membership was plummeting. Some who stayed on had white nationalist ties. Others were just lonely conservatives who had found purpose in the paramilitary cause. For now, the group’s leaders were focused on saving the militia, not taking up arms to fight their enemies. (Thanks to Williams’ trove and records from several other sources, I was eventually able to write <a href="https://www.propublica.org/article/inside-secret-ap3-militia-american-patriots-three-percent">an investigation into AP3’s resurgence</a>.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="52.0">On March 4, 2021, Williams complained to Rollins that everyone was still ignoring his advice. Williams volunteered to take over as the state’s “intel officer,” responsible for protecting the group from outside scrutiny.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="53.0">“My hands are tied,” Williams wrote. “If I’m not able to” take charge, the whole militia “might unravel.” Rollins gave him the promotion.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="54.0">“Thanks Orion. You’ve shown good initiative here.” Privately, he saw a special advantage to his appointment. If anyone suspected there was a mole in Utah, Williams would be the natural choice to lead the mole hunt.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="55.0">Now he had a leadership role. What he did not yet have was a plan. But how could he decide on goals, he figured, until he knew more about AP3? He would work to gather information and rise through the ranks by being the best militia member he could be.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="56.0">He took note of the job titles of leaders he met, like an Air Force reserve master sergeant (I confirmed this through military records) who recruited other airmen into the movement. Williams attended paramilitary trainings, where the group practiced ambushes with improvised explosives and semiautomatic guns. He offered his comrades free lessons in hand-to-hand combat and bonded with them in the backcountry hunting jackrabbits. When the militia joined right-wing rallies for causes like gun rights, they went in tactical gear. Williams attended as their “gray man,” he said — assigned to blend in with the crowd and call in armed reinforcements if tensions erupted.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="57.0">Since his work was seasonal, Williams could spend as much as 40 hours a week on militia activities. One of his duties as intel officer was to monitor the group’s enemies on the left, which could induce vertigo. A militia leader once dispatched him to a Democratic Socialists of America meeting at a local library, he said, where he saw a Proud Boy he recognized from a joint militia training. Was this a closet right-winger keeping tabs on the socialists? Or a closet leftist who might dox him or inform the police?</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="58.0">He first contacted me in October 2022. He couldn’t see how the movement was changing beyond his corner of Utah. AP3 was reinvigorated by then, I later found, with as many as 50 recruits applying each day. In private chats I reviewed, leaders were debating if they should commit acts of terrorism. At the Texas border, members were rounding up immigrants in armed patrols. But Williams didn’t know all that yet. On our first call, he launched into a litany of minutiae: names, logistical details, allegations of minor players committing petty crimes. He could tell I wasn’t sure what it all amounted to.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="59.0">Williams feared that if anything he’d helped AP3, not damaged it. Then, in early November, Rollins told him to contact a retired detective named Bobby Kinch.</p>
        
    
                    

<figure data-pp-id="61" data-pp-blocktype="image">

    


            
    


    <img alt="" width="2100" height="3500" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=440468af6ba29eb73eff5748636e470f" srcset="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=667&amp;q=75&amp;w=400&amp;s=919f66c35976dce06215e574c029cda5 400w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=440468af6ba29eb73eff5748636e470f 800w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=1200&amp;s=f8dfaf50fe0223f1d27bea7371381768 1200w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2167&amp;q=75&amp;w=1300&amp;s=1a3b869eeb1496632061f14cd20e3718 1300w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2417&amp;q=75&amp;w=1450&amp;s=22d0f9ad66a6e77d294ab64b52d6ce3f 1450w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2667&amp;q=75&amp;w=1600&amp;s=9d9fe22d15a3ef9ddcc8f82d859a8135 1600w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=3333&amp;q=75&amp;w=2000&amp;s=eb4b028d2a4775b61b4c1b50ecdf40b7 2000w">

                
    


    <img alt="" width="2100" height="2100" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=bf7bf020d13d387a76cc9e1f557eb8cc" srcset="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=7d91f7fd69ffc7ad0cc2ae4fdf6bc362 400w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=bf7bf020d13d387a76cc9e1f557eb8cc 800w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=7338e82b074a7e3bee42798ca37ca56f 1200w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=5ef51f3ffad04452e36621f2e021b0ba 1300w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=1838be8964de6253cf7b2639dc4a0401 1450w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=357b063e7c93fc6e3f7f7433ac6adb9d 1600w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_2final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=66f9cf4eb2b6f107a4b3c7a26158fa91 2000w">

            
    
<figcaption>
    
        <span>
        <span>Credit: </span>
        Katherine Lam for ProPublica
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<hr>
<h3><p>5. The Detective and the Sheriff</p>
</h3>
<p data-pp-blocktype="copy" data-pp-id="63.1">Williams turned on a recording device and dialed. Kinch picked up after one ring: ​​“What’s going on?” he bellowed. “How you doing, man?” </p>

<p data-pp-blocktype="copy" data-pp-id="63.2">“I don’t know if you remember me,” Kinch continued, but they’d met years before.</p>

<p data-pp-blocktype="copy" data-pp-id="63.3">“Oh, oh, back in the day,” Williams said, stuttering for a second. He knew Kinch was expecting the call but was confused by the warm reception. Maybe Kinch was at the training in 2019? </p>

<p data-pp-blocktype="copy" data-pp-id="63.4">“Well I’m the sitting, current national director of the Oath Keepers now.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="64.0">The militia’s eye-patched founder, Stewart Rhodes, was in jail amid his trial for conspiring to overthrow the government on Jan. 6. Kinch said he was serving on the group’s national board when his predecessor was arrested. Rhodes had called from jail to say, “Do not worry about me. This is God’s way.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="65.0">“He goes, ‘But I want you to save the organization.’”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="66.0">Kinch explained that Rollins, who’d recently defected to the Oath Keepers, had been singing Williams’ praises. (Bound by shared ideology, militias are more porous than outsiders would think. Members often cycle between groups like square dance partners.) “I imagine your plate is full with all the crazy stuff going on in the world, but I’d love to sit down.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="67.0">“Yeah, yeah,” Williams said. “AP3 and Oath Keepers should definitely be working together.” He proposed forming a joint reconnaissance team so their two militias could collaborate on intelligence operations. Kinch lit up. “I’m a career cop,” he said. “I did a lot of covert stuff, surveillance.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="68.0">By the time they hung up 45 minutes later, Kinch had invited Williams to come stay at his home. Williams felt impressed with himself. The head of the most infamous militia in America was treating him like an old friend.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="69.0">To me, Williams sounded like a different person on the call, with the same voice but a brand new personality. It was the first recording that I listened to and the first time I became certain the most important part of his story was true. To authenticate the record, I independently confirmed nonpublic details Kinch discussed on the tape, a process I repeated again and again with the other files. Soon I had proof of what would otherwise seem outlandish: Williams’ access was just as deep as he claimed.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="70.0">I could see why people would be eager to follow Kinch. Even when he sermonized on the “global elitist cabal,” he spoke with the affable passion of a beloved high school teacher. I’d long been fascinated by the prevalence of cops on militia rosters, so I started examining his backstory.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="71.0">Kinch grew up in upstate New York, the son of a World War II veteran who had him at about 50. When Kinch was young, he confided in a later recording, he was a “wheelman,” slang for getaway driver. “I ran from the cops so many fucking times,” he said. But “at the end of the day, you know, I got away. I never got caught.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="72.0">He moved to Las Vegas and, at the age of 25, became an officer in the metro police. Kinch came to serve in elite detective units over 23 years in the force, hunting fugitives and helping take down gangs like the Playboy Bloods. Eventually he was assigned to what he called the “Black squad,” according to court records, tasked with investigating violent crimes where the suspect was African American. (A Las Vegas police spokesperson told me they stopped “dividing squads by a suspect’s race” a year before Kinch retired.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="73.0">Then around Christmas in 2013, Kinch’s career began to self-destruct. In a series of Facebook posts, he said that he would welcome a “race war.” “Bring it!” he wrote. “I’m about as fed up as a man (American, Christian, White, Heterosexual) can get!” An ensuing investigation prompted the department to tell the Secret Service that Kinch “could be a threat to the president,” according to the Las Vegas Sun. (The Secret Service interviewed him and determined he was not a threat to President Barack Obama, the outlet reported. Kinch told the paper he was not racist and that he was being targeted by colleagues with “an ax to grind.”) In 2016, he turned in his badge, a year after the saga broke in the local press.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="74.0">Kinch moved to southern Utah and found a job hawking hunting gear at a Sportsman’s Warehouse. But he “had this urge,” he later said on a right-wing podcast. “Like I wasn’t done yet.” So he joined the Oath Keepers. “When people tell me that violence doesn’t solve anything, I look back over my police career,” he once advised his followers. “And I’m like, ‘Wow, that’s interesting, because violence did solve quite a bit.’”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="75.0">Kinch added Williams to an encrypted Signal channel where the Utah Oath Keepers coordinated their intel work. Two weeks later on Nov. 30, 2022, Williams received a cryptic message from David Coates, one of Kinch’s top deputies.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="76.0">Coates was an elder statesman of sorts in the Oath Keepers, a 73-year-old Vietnam veteran with a Hulk Hogan mustache. There’d been a break-in at the Utah attorney general’s office, he reported to the group, and for some unspoken reason, the Oath Keepers seemed to think this was of direct relevance to them. Coates promised to find out more about the burglary: “The Sheriff should have some answers” to “my inquiries today or tomorrow.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="77.0">That last line would come to obsess Williams. He sent a long, made-up note about his own experiences collaborating with law enforcement officials. “I’m curious, how responsive is the Sheriff to your inquiries? Or do you have a source you work with?”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="78.0">“The Sheriff has become a personal friend who hosted my FBI interview,” Coates responded. “He opens a lot of doors.” Coates had been in D.C. on Jan. 6, he’d told Williams. It’d make sense if that had piqued the FBI’s interest.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="79.0">To Williams, it hinted at a more menacing scenario — at secret ties between those who threaten the rule of the law and those duty-bound to enforce it. He desperately wanted more details, more context, the sheriff’s name. But he didn’t want to push for too much too fast.</p>
        
    
                    
<hr>
<h3><p>6. The Hunting of Man</p>
</h3>

        
    
                    

<figure data-pp-id="81" data-pp-blocktype="image">

    


                    
    


    <img alt="" width="1280" height="960" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=600&amp;q=75&amp;w=800&amp;s=59c96046a512b3c39a79c7dca66960db" srcset="https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=300&amp;q=75&amp;w=400&amp;s=eea61bdebffa2403425a017f842257f2 400w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=600&amp;q=75&amp;w=800&amp;s=59c96046a512b3c39a79c7dca66960db 800w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=900&amp;q=75&amp;w=1200&amp;s=7d5f3df95710ca0266e30558d4a27316 1200w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=975&amp;q=75&amp;w=1300&amp;s=bb1e5001abcb67d35131a1fef9204bd5 1300w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1088&amp;q=75&amp;w=1450&amp;s=62519492fdf98193bfced0857770ff23 1450w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1600&amp;s=712d51a3e7816efe25e08203d81a56e1 1600w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-01-copy.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1500&amp;q=75&amp;w=2000&amp;s=1075ebe010f11c51e24510725d1b1fff 2000w">

            
    
<figcaption>
        <span>A plaque quoting Ernest Hemingway was mounted in the home of Bobby Kinch, a retired detective and the national leader of the Oath Keepers militia.</span>
    
        <span>
        <span>Credit: </span>
        Courtesy of John Williams
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="82.0">A forest engulfed Kinch’s house on all sides. He lived in a half-million-dollar cabin in summer home country, up 8,000 feet in the mountains outside Zion National Park. Williams stood in the kitchen on a mid-December Saturday morning.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="83.0">Williams had recently made a secret purchase of a small black device off Amazon. It looked like a USB drive. The on-off switch and microphone holes revealed what it really was: a bug. As the two men chatted over cups of cannoli-flavored coffee, Williams didn’t notice when Kinch’s dog snatched the bug from his bag.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="84.0">The night before, Williams had slept in the guest room. The house was cluttered with semiautomatic rifles. He had risked photographing three plaques on the walls inscribed with the same Ernest Hemingway line. “There is no hunting like the hunting of man,” they read. “Those who have hunted armed men long enough and liked it, never really care for anything else.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="85.0">They spotted the dog at the same time. The bug was attached to a charging device. The animal was running around with it like it was a tennis ball. As Kinch went to retrieve it, Williams felt panic grip his chest. Could anyone talk their way out of this? He’d learned enough about Kinch to be terrified of his rage. Looking around, Williams eyed his host’s handgun on the kitchen counter.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="86.0"><em>If he even starts to examine it, I’ll grab the gun,</em> he thought. <em>Then I’ll shoot him and flee into the woods.</em></p>

<p data-pp-blocktype="copy" data-pp-id="86.1">Kinch took the bug from the dog’s mouth. Then he handed it right to Williams and started to apologize.</p>

<p data-pp-blocktype="copy" data-pp-id="86.2">Don’t worry about it, Williams said. He’s a puppy!</p>
        
    
                    

<figure data-pp-id="88" data-pp-blocktype="image">

    


            
    


    <img alt="" width="2100" height="3500" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=d9abaa197b55dc74334f657835763727" srcset="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=667&amp;q=75&amp;w=400&amp;s=764956989cbe9074e817239e754570bd 400w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=d9abaa197b55dc74334f657835763727 800w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=1200&amp;s=94c8585442544d22b5ba84e9de1bdfd0 1200w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2167&amp;q=75&amp;w=1300&amp;s=845535cc6e5adf07319d7235320e22bd 1300w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2417&amp;q=75&amp;w=1450&amp;s=6ea9fbd954569b4f664f5d225f092d4c 1450w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2667&amp;q=75&amp;w=1600&amp;s=a3865b1a8e67c4e2c78b6dbc3da6b8db 1600w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=3333&amp;q=75&amp;w=2000&amp;s=d5166427404c820aab85b24851f18d44 2000w">

                
    


    <img alt="" width="2100" height="2100" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=b68f7b7165052984de6d93cdc683ae68" srcset="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=1b5872e7d463e15b4257d564d648eb1a 400w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=b68f7b7165052984de6d93cdc683ae68 800w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=f7bc6e510583fa454edb21d93c5c0863 1200w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=1e4fc9724eacb0d478cdfed2ff45e4cd 1300w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=cd35be558d3f2d8dc04b490a0d48b3c3 1450w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=28e1ddcc5ded72bf295ce1474adf19e8 1600w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_3final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=b2a294798a8cb7c5bbf0ff3878262fa9 2000w">

            
    
<figcaption>
    
        <span>
        <span>Credit: </span>
        Katherine Lam for ProPublica
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="89.0">On their way out the door, Kinch grabbed the pistol and placed it in the console of his truck. It was an hour’s drive to the nearest city, where the Oath Keepers were holding a leadership meeting. Williams rode shotgun, his bug hooked onto the zipper of his backpack. On the tape, I could hear the wind racing through the car window. The radio played Bryan Adams’ “Summer of ’69.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="90.0">Kinch seemed in the hold of a dark nostalgia — as if he was wrestling with the monotony of civilian life, with the new strictures he faced since turning in his badge. Twenty minutes in, he recited the Hemingway line like it was a mantra. “I have a harder time killing animals than a human being,” Kinch continued. Then he grew quiet as he recounted the night he decided to retire.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="91.0">He’d woken up in an oleander bush with no memory of how he’d gotten there. His hands were covered in blood. He was holding a gun. “I had to literally take my magazine out and count my bullets, make sure I didn’t fucking kill somebody,” he said. “I black out when I get angry. And I don’t remember what the fuck I did.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="92.0">Kinch went on: “I love the adrenaline of police work,” and then he paused. “I miss it. It was a hoot.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="93.0">By the time they reached Cedar City, Utah, Kinch was back to charismatic form. He dished out compliments to the dozen or so Oath Keepers assembled for the meeting — “You look like you lost weight” — and told everyone to put their phones in their cars. “It’s just good practice. Because at some point we may have to go down a route,” one of his deputies explained, trailing off.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="94.0">Kinch introduced Williams to the group. “He’s not the feds. And if he is, he’s doing a damn good job.” </p>

<p data-pp-blocktype="copy" data-pp-id="94.1">Williams laughed, a little too loud.</p>

<hr>
<h3><p>7. Doctor, Lawyer, Sergeant, Spy</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="95.0">Early in the meeting, Kinch laid out his vision for the Oath Keepers’ role in American life. “We have a two-edged sword,” he said. The “dull edge” was more traditional grassroots work, exemplified by efforts to combat alleged election fraud. He hoped to build their political apparatus so that in five or 10 years, conservative candidates would be seeking the Oath Keepers’ endorsement.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="96.0">Then there was the sharp edge: paramilitary training. “You hone all these skills because when the dull edge fails, you’ve got to be able to turn that around and be sharp.” The room smelled like donuts, one of the men had remarked.</p>
        
    
                    

<figure data-pp-id="97" data-pp-blocktype="image">

    


                    
    


    <img alt="" width="1280" height="960" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=600&amp;q=75&amp;w=800&amp;s=b302d4e28ce985f429a496dd514ac76f" srcset="https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=300&amp;q=75&amp;w=400&amp;s=da88d20d9c10dc1fb0872353c25cadae 400w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=600&amp;q=75&amp;w=800&amp;s=b302d4e28ce985f429a496dd514ac76f 800w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=900&amp;q=75&amp;w=1200&amp;s=6da8f37b78f7d49344b9baff8dbd80bf 1200w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=975&amp;q=75&amp;w=1300&amp;s=5836009f5cf0f9732f6cd6cd84f647fe 1300w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1088&amp;q=75&amp;w=1450&amp;s=d5e2cfa3d23b938485bf6d26e8ad3bcb 1450w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1600&amp;s=0ffc18ab4d923d2f4fa3acea737d62e3 1600w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-02.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1500&amp;q=75&amp;w=2000&amp;s=ae6f048c986d4f074033e79a085da3e7 2000w">

            
    
<figcaption>
    
    
    
    </figcaption>

</figure>

        
    
                    

<figure data-pp-id="98" data-pp-blocktype="image">

    


                    
    


    <img alt="" width="1280" height="960" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=600&amp;q=75&amp;w=800&amp;s=45e7c2b47b2ebbb0d396a62b5073bdee" srcset="https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=300&amp;q=75&amp;w=400&amp;s=da1b9fe6b86adb25b217653036989493 400w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=600&amp;q=75&amp;w=800&amp;s=45e7c2b47b2ebbb0d396a62b5073bdee 800w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=900&amp;q=75&amp;w=1200&amp;s=48f51133ea5f8b495d29aaac4e76c3d1 1200w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=975&amp;q=75&amp;w=1300&amp;s=26c1e6b8fdc0a0a8913a983a27c1848d 1300w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1088&amp;q=75&amp;w=1450&amp;s=aa64b79e07cba97f29002723f85829a8 1450w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1600&amp;s=3934b423f60614c837618d3fb176ec79 1600w, https://img.assets-d.propublica.org/v5/images/Militia-Mole-Photos-03.JPEG?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1500&amp;q=75&amp;w=2000&amp;s=9da8dc302ac89f4500a4812cceb8dff3 2000w">

            
    
<figcaption>
        <span>An Oath Keepers training session in early 2023</span>
    
        <span>
        <span>Credit: </span>
        Obtained by ProPublica
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="99.0">The week before, Kinch’s predecessor had been convicted of seditious conspiracy. This was their first meeting since the verdict, and I opened the recordings later with the same anticipation I feel sitting down for the Super Bowl. What would come next for the militia after this historic trial: ruin, recovery or revolt?</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="100.0">The stature of men leading the group’s post-Jan. 6 resurrection startled me. I was expecting the ex-cops, like the one from Fresno, California, who said he stayed on with the militia because “this defines me.” Militias tend to prize law enforcement ties; during an armed operation, it could be useful to have police see you as a friend.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="101.0">But there was also an Ohio OB-GYN on the national board of directors — he used to work for the Cleveland Clinic, I discovered, and now led a subsidiary of UnitedHealth Group. The doctor was joined at board meetings by a city prosecutor in Utah, an ex-city council member and, Williams was later told, a sergeant with an Illinois sheriff’s department. (The doctor did not respond to requests for comment. He has since left his post with the UnitedHealth subsidiary, a spokesperson for the company said.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="102.0">Over six hours, the men set goals and delegated responsibilities with surprisingly little worry about the federal crackdown on militias. They discussed the scourges they were there to combat (stolen elections, drag shows, President Joe Biden) only in asides. Instead, they focused on “marketing” — “So what buzzwords can we insert in our mission statement?” one asked — and on resources that’d help local chapters rapidly expand. “I’d like to see this organization be like the McDonald’s of patriot organizations,” another added. To Williams, it felt more like a Verizon sales meeting than an insurrectionist cell.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="103.0">Kinch had only recently taken over and as I listened, I wondered how many followers he really had outside of that room. They hadn’t had a recruitment drive in the past year, which they resolved to change. They had $1,700 in the bank. But it didn’t seem entirely bravado. Kinch and his comrades mentioned conversations with chapters around the county.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="104.0">Then as they turned from their weakened national presence to their recent successes in Utah, Williams snapped to attention.</p>

<p data-pp-blocktype="copy" data-pp-id="104.1">“We had surveillance operations,” Kinch said, without elaboration.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="105.0">“We’re making progress locally on the law enforcement,” Coates added. He said that at least three of them can get “the sheriff” on the phone any time of day. Like the last time, Coates didn’t give a name, but he said something even more intriguing: “The sheriff is my tie-in to the state attorney general because he’s friends.” Williams told me he fought the urge to lob a question. (The attorney general’s office did not respond to requests for comment.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="106.0">Closing out the day, Kinch summarized their plan moving forward: Keep a low profile. Focus on the unglamorous work. Rebuild their national footprint. And patiently prepare for 2024. “We still got what, two more years, till another quote unquote election?” He thanked Williams for coming and asked if they could start planning training exercises.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="107.0">“Absolutely, yeah, I’m excited about that.” Williams was resolved to find his way onto the national board.</p>

<hr>
<h3><p>8. The Stakeout</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="108.0">On Dec. 17, 2022, a week after the meeting, Williams called a tech-savvy 19-year-old Oath Keeper named Rowan. He’d told Rowan he was going to teach him to infiltrate leftist groups, but Williams’ real goal was far more underhanded. While the older Oath Keepers had demurred at his most sensitive questions recently, the teenager seemed eager to impress a grizzled survival instructor. By assigning missions to Rowan, he hoped to probe the militias’ secrets without casting suspicion on himself.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="109.0">“You don’t quite have the life experience to do this,” Williams opened on the recording. But with a couple years’ training, “I think we can work towards that goal.” He assigned his student a scholarly monograph, “Alienation: Marx’s Conception of Man in a Capitalist Society,” to begin his long education in how leftists think. “Perfect,” Rowan responded. He paused to write the title down.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="110.0">Then came his pupil’s first exercise: build a dossier on Williams’ boss in AP3. Williams explained it was safest to practice on people they knew.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="111.0">In Rowan, Williams had found a particularly vulnerable target. He was on probation at the time. According to court records, earlier that year, Rowan had walked up to a stranger’s truck as she was leaving her driveway. She rolled down her window. He punched her several times in the face. When police arrived, Rowan began screaming that he was going to kill them and threatened to “blow up the police department.” He was convicted of misdemeanor assault.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="112.0">Williams felt guilty about using the young man but also excited. (“He is completely in my palm,” he recorded in his diary.) Within a few weeks, he had Rowan digging into Kinch’s background. “I’m going to gradually have him do more and more things,” he said in the diary, “with the hopes that I can eventually get him to hack” into militia leaders’ accounts.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="113.0">The relationship quickly unearthed something that disturbed him. The week of their call, Williams woke up to a series of angry messages in the Oath Keepers’ encrypted Signal channel. The ire was directed toward a Salt Lake Tribune reporter who, according to Coates, was “a real piece of shit.” His sins included critical coverage of “anyone trying to expose voter fraud” and writing about a local political figure who’d appeared on a leaked Oath Keepers roster.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="114.0">Williams messaged Rowan. “I noticed in the chat that there is some kind of red list of journalists etc? Could you get that to me?” he asked. “It would be very helpful to my safety when observing political rallies or infiltrating leftists.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="115.0">“Ah yes, i have doxes on many journalists in utah,” Rowan responded, using slang for sharing someone’s personal data with malicious intent.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="116.0">He sent over a dossier on the Tribune reporter, which opened with a brief manifesto: “This dox goes out to those that have been terrorized, doxed, harassed, slandered, and family names mutilated by these people.” It provided the reporter’s address and phone number, along with two pictures of his house.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="117.0">Then Rowan shared similar documents about a local film critic — he’d posted a “snarky” retweet of the Tribune writer — and about a student reporter at Southern Utah University. The college student had covered a rally the Oath Keepers recently attended, Rowan explained, and the militia believed he was coordinating with the Tribune. “We found the car he drove through a few other members that did a stakeout.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="118.0">“That’s awesome,” Williams said. Internally, he was reeling: a stakeout? In the dossier, he found a backgrounder on the student’s parents along with their address. Had armed men followed this kid around? Did they surveil his family home?</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="119.0">His notes show him wrestling with a decision he hadn’t let himself reckon with before: Was it time to stop being a fly on the wall and start taking action? Did he need to warn someone? The journalists? The police? Breaking character would open the door to disaster. The incident with Kinch’s dog had been a chilling reminder of the risks.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="120.0">Williams had been in the militia too long. He was losing his sense of objectivity. The messages were alarming, but were they an imminent threat? He couldn’t tell. Williams had made plans to leave Utah if his cover was blown. He didn’t want to jeopardize two years of effort over a false alarm. But what if he did nothing and this kid got hurt?</p>
        
    
                    
<hr>
<h3><p>9. The Plan</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="122.0">By 2023, Williams’ responsibilities were expanding as rapidly as his anxiety. His schedule was packed with events for AP3, the Oath Keepers and a third militia he’d recently gotten inside. He vowed to infiltrate the Proud Boys and got Coates to vouch for him with the local chapter. He prepared plans to penetrate a notorious white supremacist group too.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="123.0">His adversaries were gaining momentum as well. Williams soon made the four-hour drive to Kinch’s house for another leadership meeting and was told on tape about a national Oath Keepers recruiting bump; they’d also found contact information for 40,000 former members, which they hoped to use to bring a flood of militiamen back into the fold.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="124.0">Despite the risk to his own safety and progress, Williams decided to send the journalists anonymous warnings from burner accounts. He attached sensitive screenshots so that they’d take him seriously. And then … nothing. The reporters never responded; he wondered if the messages went to spam. His secret was still secure.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="125.0">But the point of his mission was finally coming into focus. He was done simply playing the part of model militia member. His plan had two parts: After gathering as much compromising information as he could, he would someday release it all online, he told me. He carefully documented anything that looked legally questionable, hoping law enforcement would find something useful for a criminal case. At the very least, going public could make militiamen more suspicious of each other.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="126.0">In the meantime, he would undermine the movement from the inside. He began trying to blunt the danger that he saw lurking in every volatile situation the militiamen put themselves in.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="127.0">On Jan. 27, 2023, body camera footage from the police killing of Tyre Nichols, an unarmed Black man, became public. “The footage is gruesome and distressing,” The New York Times reported. “Cities across the U.S. are bracing for protests.” The militias had often responded to Black Lives Matter rallies with street brawls and armed patrols.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="128.0">Williams had visions of Kyle Rittenhouse-esque shootings in the streets. He put his newly formulated strategy into action, sending messages to militiamen around the country with made-up rumors he hoped would persuade them to stay home.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="129.0">In Utah, he wrote to Kinch and the leaders of his other two militias. He would be undercover at the protests in Salt Lake City, he wrote. If any militiamen went, even “a brief look of recognition could blow my cover and put my life in danger.” All three ordered their troops to avoid the event. (“This is a bit of a bummer,” one AP3 member responded. “I’ve got some aggression built up I need to let out.”)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="130.0">After the protests, Williams turned on his voice diary and let out a long sigh. For weeks, he’d been nauseous and had trouble eating. He’d developed insomnia that would keep him up until dawn. He’d gone to the rally to watch for militia activity. When he got home, he’d vomited blood.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="131.0">Even grocery shopping took hours now. He circled the aisles to check if he was being tailed. Once while driving, he thought he caught someone following him. He’d reached out to a therapist to help “relieve some of this pressure,” he said, but was afraid to speak candidly with him. “I can check his office for bugs and get his electronics out of the office. And then once we’re free, I can tell him what’s going on.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="132.0">He quickly launched into a litany of items on his to-do list. A training exercise to attend. A recording device he needed to find a way to install. “I’m just fucking sick of being around these toxic motherfuckers.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="133.0">“It’s getting to be too much for me.”</p>
        
    
                    

<figure data-pp-id="135" data-pp-blocktype="image">

    


            
    


    <img alt="" width="2100" height="3500" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=9d6e4e57a023b2662b75a46cd04e1659" srcset="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=667&amp;q=75&amp;w=400&amp;s=db15794c54f26693f6112e0c6c426431 400w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=9d6e4e57a023b2662b75a46cd04e1659 800w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=1200&amp;s=8d2597999e1bb8a6ca73bea27f785fe2 1200w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2167&amp;q=75&amp;w=1300&amp;s=94a399d76a3626d61a0b36cd8c07ad9f 1300w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2417&amp;q=75&amp;w=1450&amp;s=6233fcecaf632f17c03aa9b2e80b3aeb 1450w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2667&amp;q=75&amp;w=1600&amp;s=abaac2aa0e9f4afe8966871f6d578aa9 1600w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=3333&amp;q=75&amp;w=2000&amp;s=8de4b5f0b5aa63976da01a0ffa1f1d8c 2000w">

                
    


    <img alt="" width="2100" height="2100" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=4105c6f9f0fb0e4778b6a75f653a0209" srcset="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=a2ffc142cbf01b9e448aacea6c942b1f 400w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=4105c6f9f0fb0e4778b6a75f653a0209 800w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=f668ec60789da1dd0d9a3c09eefb5e2e 1200w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=8b6829a289d3ffb2beea63d626619c83 1300w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=3f97f30c58674fb22d9b3a461eea16a9 1450w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=dfbe1e90e7b179316a03b71879732db0 1600w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_4final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=2b1ae2368bd3fc2b365966dddab74009 2000w">

            
    
<figcaption>
    
        <span>
        <span>Credit: </span>
        Katherine Lam for ProPublica
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<hr>
<h3><p>10. The Deep State</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="137.0">On March 20, Williams called Scot Seddon, the founder of AP3. If he was on the verge of a breakdown, it didn’t impact his performance. I could tell when Williams was trying to advance his agenda as I listened later, but he was subtle about it. Obsequious. Methodical. By day’s end, he’d achieved perhaps his most remarkable feat yet. He’d helped persuade Seddon and his lieutenants to fire the head of AP3’s Utah chapter and to install Williams in his place.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="138.0">Now he had access to sensitive records only senior militia leaders could see. He had final say over the group’s actions in an entire state. He knew the coup would make him vastly more effective. Yet that night in his voice diary, Williams sounded like a man in despair.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="139.0">The success only added to his paranoia. Becoming a major figure in the Utah militia scene raised a possibility he couldn’t countenance: He might be arrested and sent to jail for some action of his comrades.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="140.0">With a sense of urgency now, he focused even more intently on militia ties to government authorities. “I have been still collecting evidence on the paramilitaries’ use of law enforcement,” he said in the diary entry. “It’s way deeper than I thought.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="141.0">He solved the mystery of the Oath Keepers’ “sheriff”: It was the sheriff for Iron County, Utah, a tourist hub near two national parks. He assigned Rowan to dig deeper into the official’s ties with the movement and come back with emails or text messages. (In a recent interview, the sheriff told me that he declined an offer to join the Oath Keepers but that he’s known “quite a few” members and thinks “they’re generally good people.” Coates has periodically contacted him about issues like firearms rules that Coates believes are unconstitutional, the sheriff said. “If I agree, I contact the attorney general’s office.”)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="142.0">Claiming to work on “a communication strategy for reaching out to law enforcement,” Williams then goaded AP3 members into bragging about their police connections. They told him about their ties with high-ranking officers in Missouri and in Louisiana, in Texas and in Tennessee.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="143.0">The revelations terrified him. “When this gets out, I think I’m probably going to flee overseas,” he said in his diary. “They have too many connections.” What if a cop ally helped militants track him down? “I don’t think I can safely stay within the United States.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="144.0">Four days later, he tuned into a Zoom seminar put on by a fellow AP3 leader. It was a rambling and sparsely attended meeting. But 45 minutes in, a woman brought up an issue in her Virginia hometown, population 23,000.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="145.0">The town’s vice mayor, a proud election denier, was under fire for a homophobic remark. She believed a local reporter covering the controversy was leading a secret far-left plot. What’s more, the reporter happened to be her neighbor. To intimidate her, she said, he’d been leaving dead animals on her lawn.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="146.0">“I think I have to settle a score with this guy,” she concluded. “They’re getting down to deep state local level and it’s got to be stopped.” After the call, Williams went to turn off his recording device. “Well, that was fucking insane,” he said aloud.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="147.0">He soon reached out to the woman to offer his advice. Maybe he could talk her down, Williams thought, or at least determine what she meant by settling a score. But she wasn’t interested in speaking with him. So again he faced a choice: do nothing or risk his cover being blown. He finally came to the same conclusion he had the last time he’d feared journalists were in jeopardy. On March 31, he sent an anonymous warning.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="148.0">“Because she is a member of a right wing militia group and is heavily armed, I wanted to let you know,” Williams wrote to the reporter. “I believe her to be severely mentally ill and I believe her to be dangerous. For my own safety, I cannot reveal more.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="149.0">He saw the article the next morning. The journalist had published 500 words about the disturbing email he’d gotten, complete with a screenshot of Williams’ entire note. Only a few people had joined that meandering call. Surely only Williams pestered the woman about it afterwards. There could be little doubt that he was the mole.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="150.0">He pulled the go bag from his closet and fled. A few days later, while on the run, Williams recorded the final entries in his diary. Amid the upheaval, he sounded surprised to feel a sense of relief: “I see the light at the end of the tunnel for the first time in two and a half years.”</p>
        
    
                    
<hr>
<h3><p>Coda: Project 2025</p>
</h3>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="152.0">It was seven days before the 2024 presidential election. Williams had insisted I not bring my phone, on the off chance my movements were being tracked. We were finally meeting for the first time, in a city that he asked me not to disclose. He entered the cramped hotel room wearing a camo hat, hiking shoes and a “Spy vs. Spy” comic strip T-shirt. “Did you pick the shirt to match the occasion?” I asked. He laughed. “Sometimes I can’t help myself.”</p>
        
    
                    

<figure data-pp-id="154" data-pp-blocktype="image">

    


            
    


    <img alt="" width="2100" height="3500" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=db94feb301f3d681067af4020b4fb660" srcset="https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=667&amp;q=75&amp;w=400&amp;s=1d4b3411e304c0cd96679a1939b31bf0 400w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=75&amp;w=800&amp;s=db94feb301f3d681067af4020b4fb660 800w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=1200&amp;s=3eac0ed16d80bea117a14545923a9f36 1200w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2167&amp;q=75&amp;w=1300&amp;s=34eeb55e2fa645fe5739cc400ece8d97 1300w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2417&amp;q=75&amp;w=1450&amp;s=778d763018e64f176012661740083fe7 1450w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2667&amp;q=75&amp;w=1600&amp;s=438052244e1e20105bbfe001b40404cb 1600w, https://img.assets-d.propublica.org/v5/images/propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=3333&amp;q=75&amp;w=2000&amp;s=1714bda7c0919ce349833f6cd4a5b5ae 2000w">

                
    


    <img alt="" width="2100" height="2100" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=ca7feb607f28b1f483c1be2dd3cd45ee" srcset="https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=400&amp;q=75&amp;w=400&amp;s=d16a728832a0c25557de2a3ce53c44a1 400w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=75&amp;w=800&amp;s=ca7feb607f28b1f483c1be2dd3cd45ee 800w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1200&amp;q=75&amp;w=1200&amp;s=b72b2bbe5757e0bcad393bebb95dc32c 1200w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1300&amp;q=75&amp;w=1300&amp;s=c68168a742401b55aa80b55a42677bed 1300w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1450&amp;q=75&amp;w=1450&amp;s=b164f3c0ba3d12df595fb59f81702734 1450w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1600&amp;q=75&amp;w=1600&amp;s=ab1c2e87a7dd2394ec60a9743cd6b476 1600w, https://img.assets-d.propublica.org/v5/images/desktop-propublica_militiainfiltration_5final2.jpg?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=2000&amp;q=75&amp;w=2000&amp;s=2a7cbc57c8b6b06c9183f631498b45d1 2000w">

            
    
<figcaption>
    
        <span>
        <span>Credit: </span>
        Katherine Lam for ProPublica
    </span>
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="155.0">We talked for days, with Williams splayed across a Best Western office chair beside the queen bed. He evoked an aging computer programmer with 100 pounds of muscle attached, and he seemed calmer than on the phone, endearingly offbeat. The vision he laid out — of his own future and of the country’s — was severe.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="156.0">After he dropped everything and went underground, Williams spent a few weeks in the desert. He threw his phone in a river, flushed documents down the toilet and switched apartments when he returned to civilization. At first, he spent every night by the door ready for an attack; if anyone found him and ambushed him, it’d happen after dark, he figured. No one ever came, and he began to question if he’d needed to flee at all. The insomnia of his undercover years finally abated. He began to sketch out the rest of his life.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="157.0">Initially, he hoped to connect with lawmakers in Washington, helping them craft legislation to combat the militia movement. By last summer, those ambitions had waned. Over time, he began to wrestle with his gift for deceiving people who trusted him. “I don’t necessarily like what it says about me that I have a talent for this,” he said.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="158.0">To me, it seemed that the ordeal might be starting to change him. He’d become less precise in consistently adhering to the facts in recent weeks, I thought, more grandiose in his account of his own saga. But then for long stretches, he’d speak with the same introspection and attention to detail that he showed on our first calls. His obsession with keeping the Tyre Nichols protestors safe was myopic, he told me, a case of forgetting the big picture to quash the few dangers he could control.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="159.0">Williams believes extremists will try to murder him after this story is published. And if they fail, he thinks he’ll “live to see the United States cease to exist.” He identifies with the violent abolitionist John Brown, who tried to start a slave revolt two years before the American Civil War and was executed. Williams thinks he himself may not be seen as such a radical soon, he told me. “I wonder if I’m maybe a little too early.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="160.0">I’d thought Williams was considering a return to a quiet life. Our two intense years together had been a strain sometimes even for me. But in the hotel room, he explained his plans for future operations against militias: “Until they kill me, this is what I’m doing.” He hopes to inspire others to follow in his footsteps and even start his own vigilante collective, running his own “agents” inside the far right.</p>
        
    
                                  
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="162.0">In August, I published my <a href="https://www.propublica.org/article/inside-secret-ap3-militia-american-patriots-three-percent">investigation into AP3</a>. (I used his records but did not otherwise rely on Williams as an anonymous source.) It was a way of starting to lay out what I’d learned since his first email: what’s driving the growth of militias, how they keep such a wide range of people united, the dangerous exploits that they’ve managed to keep out of public view.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="163.0">Two months later, Williams published an anonymous essay. He revealed that he’d infiltrated the group as an “independent activist” and had sent me files. He wanted to test how the militia would respond to news of a mole.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="164.0">The result was something he long had hoped for: a wave of paranoia inside AP3. “It’s a fucking risky thing we get involved in,” Seddon, the group’s founder, said in a private message. “Fucking trust nobody. There’s fucking turncoats everywhere.” (Seddon declined to comment for this story. He then sent a short follow-up email: “MAGA.”)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="165.0">Sowing that distrust is why Williams is going on the record, albeit without his original name. He still plans to release thousands of files after this article is published — evidence tying sheriffs and police officers to the movement, his proudest coup, plus other records he hopes could become ammo for lawsuits. But Williams wants to let his former comrades know “a faggot is doing this to them.” He thinks his story could be his most effective weapon.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="166.0">Every time militia members make a phone call, attend a meeting or go to a gun range together, he wants them “to be thinking, in the back of their heads, ‘This guy will betray me.’”</p>
        
    
                    
    
    
    <figure data-pp-id="167" data-pp-blocktype="callout" data-pp-location="callout" callout-slug="do-you-have-a-tip-for-propublica-help-us-do-journalism">

        
<div>
            <p id="do-you-have-a-tip-for-propublica-help-us-do-journalism">Do You Have a Tip for ProPublica? Help Us Do Journalism.</p>
                <p>Got a story we should hear? Are you down to be a background source on a story about your community, your schools or your workplace? Get in touch.</p>
    </div>


        

        
        <a href="#" data-pp-view="" data-pp-category="get involved" data-pp-action="expand">Expand</a>

    </figure>

    
            
    
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using LLMs and Cursor to finish side projects (146 pts)]]></title>
            <link>https://zohaib.me/using-llms-and-cursor-for-finishing-projects-productivity/</link>
            <guid>42594256</guid>
            <pubDate>Sat, 04 Jan 2025 12:09:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zohaib.me/using-llms-and-cursor-for-finishing-projects-productivity/">https://zohaib.me/using-llms-and-cursor-for-finishing-projects-productivity/</a>, See on <a href="https://news.ycombinator.com/item?id=42594256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>I transitioned to the role of Engineering Manager approximately 5 years ago, since then I haven't been programming in my day job but the itch to do so has always been there. So I continue to work on side projects to not lose touch and continue to hone my skills.</p><p>Because my time has always been limited, progress on side projects had been slow in the past, and many remained unfinished as life's events caused a loss of momentum, making them harder to resume. However, in the last year (2024), I have been very productive with my side projects, quickly building the tools or projects I need and deploying them for others to use—in other words, finishing the v1 of each project.</p><p>A few examples of what I've built are</p><ul><li><a href="https://jsonplayground.com/?ref=zohaib.me">jsonplayground.com</a> - JSON formatter but also in browser <a href="https://jqlang.github.io/jq/?ref=zohaib.me">JQ</a> using WASM so no data leaves the machine.</li></ul><figure><img src="https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.25.07.png" alt="" loading="lazy" width="2000" height="1069" srcset="https://zohaib.me/content/images/size/w600/2024/12/Screenshot-2024-12-31-at-00.25.07.png 600w, https://zohaib.me/content/images/size/w1000/2024/12/Screenshot-2024-12-31-at-00.25.07.png 1000w, https://zohaib.me/content/images/size/w1600/2024/12/Screenshot-2024-12-31-at-00.25.07.png 1600w, https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.25.07.png 2000w" sizes="(min-width: 720px) 720px"></figure><ul><li><a href="http://webtomarkdown.com/?ref=zohaib.me">webtomarkdown.com</a> - As I often feel the need of converting files to Markdown, or parts of website to Markdown for passing in as context to LLMs. I'm currently building this tool to solve that problem.</li></ul><figure><img src="https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.24.29.png" alt="" loading="lazy" width="2000" height="1082" srcset="https://zohaib.me/content/images/size/w600/2024/12/Screenshot-2024-12-31-at-00.24.29.png 600w, https://zohaib.me/content/images/size/w1000/2024/12/Screenshot-2024-12-31-at-00.24.29.png 1000w, https://zohaib.me/content/images/size/w1600/2024/12/Screenshot-2024-12-31-at-00.24.29.png 1600w, https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.24.29.png 2000w" sizes="(min-width: 720px) 720px"></figure><ul><li>Face lift for my soaring club page <a href="https://www.dropbox.com/s/42oasltzi9n0k10/Screenshot%202024-12-31%20at%2000.22.40.png?dl=0&amp;ref=zohaib.me">Evergreen Soaring</a> where I volunteer (not deployed yet on official website).</li></ul><figure><img src="https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.22.40.png" alt="" loading="lazy" width="2000" height="1569" srcset="https://zohaib.me/content/images/size/w600/2024/12/Screenshot-2024-12-31-at-00.22.40.png 600w, https://zohaib.me/content/images/size/w1000/2024/12/Screenshot-2024-12-31-at-00.22.40.png 1000w, https://zohaib.me/content/images/size/w1600/2024/12/Screenshot-2024-12-31-at-00.22.40.png 1600w, https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.22.40.png 2000w" sizes="(min-width: 720px) 720px"></figure><ul><li>A Chrome Browser Extension to automate parts of public messages we receive at my soaring club.</li><li><a href="https://fitinterval.com/?ref=zohaib.me">fitinterval.com</a> - Interval timer for workouts</li></ul><figure><img src="https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.28.48.png" alt="" loading="lazy" width="2000" height="745" srcset="https://zohaib.me/content/images/size/w600/2024/12/Screenshot-2024-12-31-at-00.28.48.png 600w, https://zohaib.me/content/images/size/w1000/2024/12/Screenshot-2024-12-31-at-00.28.48.png 1000w, https://zohaib.me/content/images/size/w1600/2024/12/Screenshot-2024-12-31-at-00.28.48.png 1600w, https://zohaib.me/content/images/2024/12/Screenshot-2024-12-31-at-00.28.48.png 2000w" sizes="(min-width: 720px) 720px"></figure><p>LLMs in general have been immense booster for my productivity when it comes to side projects and more specifically the <a href="https://www.cursor.com/?ref=zohaib.me">Cursor IDE</a> has been a great editor to use these LLMs for coding.</p><p>In this blog I'll go over what my high level flow looks like for greenfield projects and I hope that may help you. I do want to acknowledge that these tools are good in certain cases but may annoy you (waste time) in other areas, you just need to use them to figure out where specifically it's useful for you.</p><p>I have a nice habit tracker that I would like to replicate as a website, but all data stored locally, so let's use that as an example of what to create here.</p><figure><img src="https://zohaib.me/content/images/2025/01/IMG_6790.jpg" alt="" loading="lazy" width="2000" height="3313" srcset="https://zohaib.me/content/images/size/w600/2025/01/IMG_6790.jpg 600w, https://zohaib.me/content/images/size/w1000/2025/01/IMG_6790.jpg 1000w, https://zohaib.me/content/images/size/w1600/2025/01/IMG_6790.jpg 1600w, https://zohaib.me/content/images/2025/01/IMG_6790.jpg 2000w" sizes="(min-width: 720px) 720px"></figure><h2 id="start-with-a-spec">Start with a spec</h2><p>I use the o1 ChatGPT to first get my application specification more refined. The reason I do that is so that it helps me scope the problem and also the spec I get at the end, I use it in further stages of bootstrapping the code. You can try to write the spec yourself, but I feel that going from few sentences to more detailed spec through ChatGPT o1 has been very useful in saving me time. I also ask it to further probe me with questions to further refine it.</p><p>Following the prompt I start with. </p><blockquote>I’m want to build a website for habit tracking where user sees columns of months and each row being a date. They can simply select to indicate a day where they continued with the habit. It should store all that on local machine. Ask me more questions to refine the idea.</blockquote><p>It asks me bunch of questions which I answer, but then it continues asking me more questions. At some point, where you feel there is enough details, you should explicitly ask it to create a spec with the details that will allow another person/AI to build application. I also specify the technology I would prefer to use as thats what I'm familiar with most.</p><blockquote>Answer those questions for me reasonably and create a spec that I can give to a person or another AI to help create the website. Make sure to have the details of project, user experience, technical details. I want to use typescript, react, tailwind css.</blockquote><p>You can read the whole chat here: <a href="https://chatgpt.com/share/6775ad7b-21e4-800e-a4c7-44c9bbbcc7a2?ref=zohaib.me">Habit Tracking Website Plan</a></p><p>Now store that spec in <code>SPEC.md</code> in a folder where your project will be. We will continue to refer back to it when needed.</p><h2 id="bootstrap-project">Bootstrap project</h2><p>I use <a href="https://vite.dev/guide/?ref=zohaib.me">Vite</a> to bootstrap my project. This allows me to setup all the necessary tooling in a consistent manner. <br>In the directory of project I run <code>npm create vite@latest .</code> which will ask me question about which UX framework and Language to use. Once I have the project and <code>SPEC.md</code> in that project I use the Cursor Agent to create the initial code.</p><p>You can go to Composer &gt; Select Agent &gt; Added SPEC.md in the context and ask it to implement it.</p><p>This will go over your code, setup tailwind, update few files to create the initial version.</p><figure><img src="https://zohaib.me/content/images/2025/01/Screenshot-2025-01-01-at-13.17.48.png" alt="" loading="lazy" width="1552" height="1972" srcset="https://zohaib.me/content/images/size/w600/2025/01/Screenshot-2025-01-01-at-13.17.48.png 600w, https://zohaib.me/content/images/size/w1000/2025/01/Screenshot-2025-01-01-at-13.17.48.png 1000w, https://zohaib.me/content/images/2025/01/Screenshot-2025-01-01-at-13.17.48.png 1552w" sizes="(min-width: 720px) 720px"></figure><p>This is what the initial version looked like. Not exactly what I was looking for (skeuomorphic design) but close enough in structure that I can iterate over it.</p><figure><img src="https://zohaib.me/content/images/2025/01/Screenshot-2025-01-01-at-13.36.34.png" alt="" loading="lazy" width="2000" height="1190" srcset="https://zohaib.me/content/images/size/w600/2025/01/Screenshot-2025-01-01-at-13.36.34.png 600w, https://zohaib.me/content/images/size/w1000/2025/01/Screenshot-2025-01-01-at-13.36.34.png 1000w, https://zohaib.me/content/images/size/w1600/2025/01/Screenshot-2025-01-01-at-13.36.34.png 1600w, https://zohaib.me/content/images/size/w2400/2025/01/Screenshot-2025-01-01-at-13.36.34.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>There is also some bug in it, where clicking on the button doesn't change the state. But overall, this puts us into a good starting point, it created the overall UX layout I expected, stored data in local storage, has the right export feature for Markdown. All of it in just order of minutes instead of hours.</p><p>P.S: Sometime I also use <a href="https://v0.dev/?ref=zohaib.me">v0.dev</a> to bootstrap the UX aspect of the project. That tools allows quicker iteration on the UX aspects.</p><h2 id="small-iterations">Small iterations</h2><p>You don't want to one-shot everything i.e. ask it to do multiple complicated tasks in one go. That can sometime work but can lead to issues and makes it harder (and slower as it will regenerate bunch of code that it doesn't need to change) to iterate. Follow a divide and conquer approach, i.e. split your feature into smaller tasks and iterate over them using the Chat/Composer.</p><p>Now first let's fix the bug and also change the UX. In my spec conversation with o1, I ask it to create a spec for UX focused more on skeuomorphic aspects of it. Then I use the Cursor Composer to update the code. I select the o1 model in this case.</p><blockquote>Update @App.tsx @MonthColumn.tsx @MonthColumn.css @App.css  to improve the UX, also fix the issue where the state isn't being changed when I click the button.<p>{PASTE THE UX SPEC}</p></blockquote><p>Here is what it looks like now. So it fixed the bug, and also updated the UX to have some more Led like behavior with depth, some shadows etc. It still look horrible but we will further iterate on that.</p><figure><img src="https://zohaib.me/content/images/2025/01/image-1.png" alt="" loading="lazy" width="2000" height="1304" srcset="https://zohaib.me/content/images/size/w600/2025/01/image-1.png 600w, https://zohaib.me/content/images/size/w1000/2025/01/image-1.png 1000w, https://zohaib.me/content/images/size/w1600/2025/01/image-1.png 1600w, https://zohaib.me/content/images/size/w2400/2025/01/image-1.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>In the next iteration I gave the above screenshot (yes cursor can also use images for context) in Chat mode and first asked it to describe the details the button and then asked it to make necessary changes to replicate that. After couple of more iterations.</p><figure><img src="https://zohaib.me/content/images/2025/01/image-2.png" alt="" loading="lazy" width="1206" height="1130" srcset="https://zohaib.me/content/images/size/w600/2025/01/image-2.png 600w, https://zohaib.me/content/images/size/w1000/2025/01/image-2.png 1000w, https://zohaib.me/content/images/2025/01/image-2.png 1206w" sizes="(min-width: 720px) 720px"></figure><p>After few back and forth, I have the experience which looks good enough for the demo here.</p><figure><img src="https://zohaib.me/content/images/2025/01/image-4.png" alt="" loading="lazy" width="2000" height="1403" srcset="https://zohaib.me/content/images/size/w600/2025/01/image-4.png 600w, https://zohaib.me/content/images/size/w1000/2025/01/image-4.png 1000w, https://zohaib.me/content/images/size/w1600/2025/01/image-4.png 1600w, https://zohaib.me/content/images/size/w2400/2025/01/image-4.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Now finally I need to setup deployment using GitHub actions, so whenever I check-in to main, it builds and deploys to GitHub pages. I already had a workflow in another of my repository that I wanted it to use as context and make specific changes to build this project. The good thing about Cursor is that you can also provide context by adding a link, so either its some existing code, some documentation, it can be passed to LLM for context. In my experience providing relevant context generally allows it to output better code and avoid hallucinations.<br></p><blockquote>Similar to @https://raw.githubusercontent.com/zabirauf/evergreensoaring-modern-web/refs/heads/main/.github/workflows/deploy.yml create a deployment to github pages and also make sure to npm install and npm run build (which puts it in dist folder). The dist is what needs to be deployed</blockquote><figure><img src="https://zohaib.me/content/images/2025/01/image-6.png" alt="" loading="lazy" width="1174" height="1044" srcset="https://zohaib.me/content/images/size/w600/2025/01/image-6.png 600w, https://zohaib.me/content/images/size/w1000/2025/01/image-6.png 1000w, https://zohaib.me/content/images/2025/01/image-6.png 1174w" sizes="(min-width: 720px) 720px"></figure><h2 id="overall-tips">Overall tips</h2><ol><li>Use LLM to hash out the details of the project and store it for further context</li><li>Use a tool or open-source template to bootstrap your project to setup all the necessary toolings and following a manageable project pattern.</li><li>Leverage Cursor Composer (agent mode) to bootstrap the project</li><li>Use mix of o1 and claude-3.5-sonnet. Generally I use o1 where broad stokes are needed e.g. 1st draft of a feature and then use Claude-3.5-Sonnet to further iterate on it. But I'm using Claude-3.5-sonnet approx. 80% of times.</li><li>Select the right mode e.g. Chat, Composer (normal), Composer (agent). <br>I use Chat, when I need back and forth and know exactly where changes will be and want to see the changes before applying. <br>I use Composer (normal) when I need multi-file changes e.g. new feature. <br>I don't use Composer (agent) often enough yet. Composer (agent) can run commands in terminal, lint code, re-iterate etc, but going back to the principle of small iterations, I try to scope things to what I can review easily and add.</li><li>Provide relevant context as much as possible e.g. specific files you want changed, specific docs (links), or submit with codebase option in chat when you want it to search for relevant context.</li><li>Store markdown files relevant to your project so you can add those as context e.g. SPEC.md, documentation from website that you often get back from (plugging <a href="https://webtomarkdown.com/?ref=zohaib.me">https://webtomarkdown.com</a> for converting a website documentation to Markdown and storing it 😄)</li><li>Create and use .cursorrules file in your project directory for instructions that you want it to take in prompts, e.g. if you see it always using some library you don't want then add it to .cursorrules, specific technology that you want it to user in code e.g. Tailwind, certain component library e.g. Shadcn etc. This allows you to start nudging it in direction you want for most of your prompts.</li><li>Always make sure that you understand the code at high level so you don't land in a space where eventually it's such a messy code that it becomes hard for you to debug when LLMs can't find issues for you. My tip is to continue to split stuff into manageable pieces (hint, you can use LLMs to do it from time to time).</li></ol><p>I hope this has been helpful, and that you can start finishing the first versions of your projects and deploying them. By turning unfinished projects into completed and deployed ones, you can continue to build momentum even when you take small breaks. This approach allows you to gradually add more to your projects while keeping them manageable. I believe this also helps keep me motivated, as I get to see progress more quickly on what I want to deliver.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Dog vs. the Windows 3.1 Graphics Stack (167 pts)]]></title>
            <link>https://wuffs.org/blog/windows-3x-graphics</link>
            <guid>42594024</guid>
            <pubDate>Sat, 04 Jan 2025 11:10:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wuffs.org/blog/windows-3x-graphics">https://wuffs.org/blog/windows-3x-graphics</a>, See on <a href="https://news.ycombinator.com/item?id=42594024">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="wrapperGrid">
        
<p>
	<time datetime="2025-01-02T20:31:00+00:00">
		Published 2nd Jan 2025
	</time>
</p>

<p>Wherein I learn too much about VGA hardware and generate some really cool glitch art while I try to fix somebody else's fix for a video driver that's older than I am.</p>

<hr>
<p>I'm a bit of a retro tech enjoyer, but I'm also pretty bad at it -- I don't have the space or the motivation to try and acquire actual old computers. Playing with 86Box/PCem is pretty fun, but it's not quite the same.</p>
<p>So, instead, I make do with what I have. And the most ridiculous x86 machine I own is the <em>Asus Eee PC 1000H</em>, a netbook that I got in 2008 when that category was still new and exciting. It's borderline useless nowadays (it can't even run most up-to-date Linux distros due to its lack of x86_64 support), so sticking weird and anachronistic OSes on it is one way to keep it relevant!</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/640x480.jpg"><img alt="Windows 3.11 on my Eee PC, with a blurry and horizontally stretched screen. Text in Notepad says: &quot;fixedsys is not supposed to be this wide :( and I need more screen space!!!&quot;" src="https://wuffs.org/images/b/1/c/9/2/b1c921a98b56d269d1bab531eca7615c982be6ab-640x480.jpg"></a></p>
<p>I'd like to write a full-fledged blog post about these adventures at some point, but for now I'm going to focus on one particular side quest: getting acceptable video output out of the 1000H when it's running <strong>Windows 3.11 for Workgroups</strong>.</p>
<p>By default, Windows 3.x renders using the standard "lowest common denominator" of video: VGA 640x480 at 16 colours. Unfortunately this looks awful on the Eee PC's beautiful 1024x600 screen, and it's not even the same aspect ratio.</p>

<p>But how can we do better? The 3.11 installer includes a smattering of drivers for long-obsolete video adapters, but they didn't have the prescience to support the <em>Intel GMA 950</em> in my netbook. (For shame, Microsoft. <strong>For shame.</strong>)</p>
<p>There's an included 'Super VGA' driver that ostensibly supports up to 1024x768 at 256 colours, but it doesn't work, for... reasons that we'll go into, even though you'd think that a 2008 machine would surely be able to do SVGA. If I try to use it, I'll just get an error and Windows will fail to start.</p>
<h2>The Horrors of IBM PC Video</h2>
<p>Nowadays when we hear 'VGA' we usually think of the funky little blue analogue connector, or maybe just the 640x480 resolution itself. These are just aspects of VGA, which was a very specific video controller designed by IBM in the 1980s.</p>
<p>'Super VGA' must be a better version, right? Well, yes, and no. As I understand it, at the time, SVGA was just an umbrella term for <em>anything more advanced than plain old VGA</em> - but not a standard in and of itself. So lots of SVGA cards could do better resolutions and colour depths and refresh rates, but each piece of software had to implement support for each individual card.</p>
<p>This leads to the mind-numbing situation we get with the Windows driver. From the readme for <a href="https://winworldpc.com/product/generic-svga-driver-/generic-svga-driver-windows-31">this driver's standalone release</a>, we get the following list of supported vendors:</p>
<ul>
<li>ATI VGA series, including Wonder, Wonder Plus and Wonder 24XL</li>
<li>Cirrus Logic VGA (6420, 5420 series)</li>
<li>Oak Technology VGA (077 series)</li>
<li>Paradise VGA, including 1024 and Professional</li>
<li>Trident VGA (8900C series), including Trident Impact</li>
<li>Tseng VGA (ET4000 series), including a whole bunch of other cards with the same chips</li>
<li>Video Seven VGA, including FastWrite, 1024i, VRAM and VRAM II</li>
<li>Western Digital VGA</li>
</ul>
<p>Obviously, my mid-2000s Intel video adapter is not among these. There was no real reason for Intel to use the same proprietary extensions as Trident or Oak or Video Seven. So we're boned, I guess...</p>
<h2>They Should Make A Standard</h2>
<p>Good news! <a href="https://en.wikipedia.org/wiki/VESA_BIOS_Extensions">They did!</a> ... Too bad it came too late to be relevant to Windows 3.x.</p>
<p>VBE (VESA BIOS Extensions) is a generic interface that lets software talk to video adapters and do things that are beyond the capabilities of plain old VGA, and in theory it's exactly what we need. <em>(And yes, that's the same VESA that's responsible for the monitor mounts.)</em></p>
<p>BearWindows has released <a href="https://bearwindows.zcm.com.au/vbe9x.htm">VBE9x</a> and <a href="https://bearwindows.zcm.com.au/vbemp.htm">VBEMP</a> which allow Windows 9x and NT respectively to use VBE, which both work pretty well. There's no 3.x version though.</p>
<p>There is also <strong>SVGAPatch</strong>, available from <a href="https://www.japheth.de/">japheth.de</a>, which patches Microsoft's 256-colour Super VGA driver to use VBE. The result is beautiful...</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/1024x600.jpg"><img alt="The Eee PC again, but this time, it's rendering the desktop crisply at the native resolution. I've got a failed Minesweeper game open, and a Notepad window where I've typed &quot;haha who would try to put a 1993 OS on a machine from 2008, isn't that silly :thonk: fun fact: the fan on this is louder than the one on my M1 MacBook Pro&quot;" src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/1024x600.jpg"></a></p>
<p>...when it works. You see, one of the headline features of early Windows was its compatibility with MS-DOS software. You could just pull up a DOS prompt in a window, and with 3.1's <em>Enhanced Mode</em>, you even got mostly-seamless multitasking of DOS applications alongside graphical Windows ones. This was a Big Deal™ in those days!</p>
<p>Unfortunately, SVGAPatch doesn't play nicely with this, and I wanted to figure out why. Entering full-screen mode and then returning to the Windows GUI will leave you with a corrupted screen. In some cases, opening <em>any</em> DOS prompt, even if it's in windowed mode, will cause it. Here's what happened when I opened a windowed prompt.</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/default_driver.jpg"><img alt="The Eee PC's screen is showing a red grid of glitched pixels. Absolutely nothing is discernible." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/default_driver.jpg"></a></p>
<p><em>(Hank Hill voice)</em> That prompt ain't right!</p>
<p>There's clearly some sort of state management issue; I've tried it with DOSBox, 86Box and my Eee PC, and interacting with DOS prompts will reliably break the driver on all three (but in subtly different ways).</p>
<p>So, let’s analyse how this works, with my very limited knowledge of the PC architecture. Can I find the problem, and maybe fix it??</p>
<p><em>Side note:</em> Halfway through working on this I came across <a href="https://github.com/PluMGMK/vbesvga.drv">PluMGMK/vbesvga.drv</a> which is a brand new driver that even supports true colour modes. This is, in all honesty, a far better approach than mine - but I was invested and wanted to see how far I could get with Microsoft's code.</p>
<h2>The Windows 3.x Hellscape</h2>
<p>To grok what’s going on, we need a cursory understanding of how Windows 3.x works in its “Enhanced Mode”, as an OS on top of MS-DOS.</p>
<p>Rather than trying to explain it myself, I’ll link to a 2010 post from Raymond Chen’s blog: <a href="https://devblogs.microsoft.com/oldnewthing/20100517-00/?p=14013">If Windows 3.11 required a 32-bit processor, why was it called a 16-bit operating system?</a> It’s good reading, but this is the most important bit for our purposes:</p>
<blockquote>
<p>With Enhanced mode, there were actually three operating systems running at the same time. The operating system in charge of the show was the 32-bit virtual machine manager which ran in 32-bit protected mode. As you might suspect from its name, the virtual machine manager created virtual machines. Inside the first virtual machine ran… a copy of Standard mode Windows.</p>
</blockquote>
<p>This funky approach is what allowed Windows 3.x to run DOS applications without each app tying up the entire machine.</p>
<h2>The Display Driver Hellscape</h2>
<p>In Windows Setup, you get to tell it what video adapter you're using. You’d probably assume that this is choosing one driver. Nope!</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/setup_000.png"><img alt="Screenshot of Windows 3.11 Setup, where you can pick your display from a long list, including &quot;Super VGA&quot; (multiple resolution and font size variants), &quot;VGA&quot;, &quot;VGA (version 3.0)&quot; and &quot;Video 7&quot; (also with multiple variants)" src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/setup_000.png"></a></p>
<p>When you pick an option from this list, it will…</p>
<ul>
<li>Install all the required files from the floppy diskettes (how quaint!)
<ul>
<li>A grabber</li>
<li>A display driver</li>
<li>A virtual display device</li>
<li>Required resources such as fonts</li>
</ul></li>
<li>Modify your <code>SYSTEM.INI</code> to tell Windows to use the specified drivers</li>
<li>Add any other INI entries required</li>
</ul>
<p>The different 256-colour SVGA entries are actually the same underlying drivers, but with different INI entries to set the desired resolution and DPI (96dpi for 'small fonts', 120dpi for 'large fonts').</p>
<hr>
<p>More critically however, there are three different components here that you could all think of as a sort of driver. As I understand them…</p>
<p>The <strong>Grabber</strong> seems to be responsible for rendering the windowed versions of DOS apps. This is the one I’ve investigated the least.</p>
<p>The <strong>Display Driver</strong> runs inside the main Windows VM, and is responsible for setting up the hardware and rendering the GUI. In fact, in 3.x, each of these included its own implementation of much of GDI (the API for drawing).</p>
<p>The <strong>Virtual Display Device</strong> (VDD) runs as part of the underlying virtual machine manager, and acts somewhat like a multiplexer for the video hardware. If a DOS app is full screen, its commands are directly sent to the ‘real’ VGA adapter; otherwise, they’re emulated by the VDD.</p>
<hr>
<p>There is a whole lot of nasty state synchronisation logic in the VDD that is likely related to my problems.</p>
<p>Interestingly, however, the SVGAPatch tool doesn’t alter the SVGA VDD at all — it <em>only</em> touches the display driver. Could that be the issue? 🤔</p>
<p>To continue, I’ll need to understand the display driver, the VDD <strong>and</strong> the undocumented patches made by SVGAPatch.</p>
<h2>Gathering Information</h2>
<p>As far as I can tell, this was a bit of a dark art back when 3.x was current, and it’s still rather difficult to find any info about all of these systems.</p>
<p>I learned a lot from this blog post on ‘OS/2 Museum’: <a href="https://www.os2museum.com/wp/windows-3-x-vddvga/">Windows 3.x VDDVGA</a>, and aside from that, I also had the Windows 3.1 DDK (Driver Development Kit), which is <a href="https://winworldpc.com/product/windows-sdk-ddk/windows-31">archived on WinWorld</a>.</p>
<p>The DDK includes the following bits which are relevant to us:</p>
<ul>
<li><strong>Display Driver source</strong>: VGA, IBM 8514, Video 7, 16-colour SVGA</li>
<li><strong>VDD source</strong>: VGA, IBM 8514, Video 7, 16-colour SVGA</li>
<li><strong>Grabber source</strong>: ... Basically all of them</li>
<li>A pitiful amount of written documentation</li>
</ul>
<p>Noticeably absent however are the 256-colour SVGA display driver and its associated VDD. I don’t know if these were included in a later DDK version, or if they just never left Microsoft at all.</p>
<p>I did grab the Windows 95 DDK to see if it contained anything relevant, but it wasn’t particularly useful.</p>
<p>All hope is not lost though, the 3.1 DDK is still helpful. I’m assuming that there are significant amounts of shared code between these drivers. We just need to wade through all the macro-laden assembly.</p>
<h2>Reversing the Display Driver</h2>
<h2>Step 1: Load the Code</h2>
<p>Disassembling 16-bit x86 code is pretty weird; I'm still not quite used to segments, as someone who's primarily looked at PowerPC and ARM code before. Still, it's doable.</p>
<p>IDA can load all the binaries with no issues, but unfortunately, not in the free version which is arbitrarily restricted to PE files. Ghidra can load the <code>.drv</code> display drivers, but not the VDD as it's actually a VxD.</p>
<p>I tried <a href="https://github.com/oshogbo/ghidra-lx-loader">oshogbo/ghidra-lx-loader</a> at first to load the VDD in Ghidra, but it fails. Then I tried <a href="https://github.com/yetmorecode/ghidra-lx-loader">yetmorecode/ghidra-lx-loader</a>, which works, but at the time of writing you need to build a PR to get it to work with the latest Ghidra.</p>
<pre><code>$ git clone git@github.com:yetmorecode/ghidra-lx-loader.git
$ git fetch origin pull/7/head:buildfix
$ git switch buildfix
$ GHIDRA_INSTALL_DIR=~/Downloads/ghidra_11.2.1_PUBLIC gradle buildExtension</code></pre>
<p>Once built, go to <em>File &gt; Install Extensions</em> in Ghidra, add the built extension zip file from <code>dist/</code>, and restart Ghidra.</p>

<p>You can now import the <code>vddsvga.386</code> file and it will be detected as a 'Linear Executable'. However, it's nowhere near as seamless as in IDA...</p>
<p>This VxD contains both 32-bit code and 16-bit code, but as far as I can tell, Ghidra expects the entire file to be either one or the other. So if I import the file with the default 'language' of 32-bit, it'll fail to decode the real mode initialisation code in the last segment. OTOH, if I switch it to 16-bit, then it'll fail to decode the vast majority of the code in the file.</p>
<p>I'm probably missing something due to my lack of familiarity with x86 and its tooling 🤔</p>
<h2>Step 2: Match Things Up</h2>
<p>After loading up <code>svga256.drv</code> (both the original Microsoft version and the SVGAPatch-modified version) and <code>vddsvga.386</code>, I was ready to begin.</p>
<p>I began with the <code>.drv</code> file. Conveniently, this one has a whole bunch of exported functions like <code>GETCHARWIDTH</code>, <code>STRETCHBLT</code> and <code>VIDEOINIT_ATI</code>, so I thought it'd be good to go through these and compare them to the source from the DDK, hopefully getting to name some other functions and global variables in the process.</p>
<p>Since <code>FASTBORDER</code> is the first one in the file, I started looking at that - it corresponds to <code>WIN31/DDK/286/DISPLAY/4PLANE/FB.ASM</code> in the DDK.</p>
<p>This is when I found out just how heavily this source code relies on macros...</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/fastborder.png"><img alt="Side-by-side screenshot of FB.ASM in VS Code next to the same routine in Ghidra's disassembly view. The source contains 24 lines of non-standard macros for defining parameters and local variables, which have been turned into 11 assembly instructions for creating a stack frame." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/fastborder.png"></a></p>
<p>On the left is the DDK's source for <code>FASTBORDER</code>, and on the right is how it appears in Ghidra (after I've manually applied labels and variable/parameter names).</p>
<p>This is using <code>cProc</code> and associated macros, which seems to be a way to make defining C-compatible procedures more ergonomic... but it's not documented anywhere that I can see.</p>
<p>I can read the source for these macros, but they're somewhat inscrutable to say the least, with no comments and almost no indentation. A representative code sample:</p>
<pre><code>if ???+?po
if ?chkstk1
push bp
mov bp,sp
else
if ???
enter ???,0
else
push bp
mov bp,sp
endif
endif
endif</code></pre>
<p>For my purposes, I don't really need to understand this, I just need to know that I can skip past the initialisation guff every time I see it in a <code>cProc</code> procedure.</p>
<p>Likewise, there's <code>arg</code> and <code>cCall</code> macros used for calling these, but those are fairly self-explanatory:</p>
<pre><code>    arg &lt;lpPDevice,destx,desty,ax,ax,ax,ax,xext,yext,rop,lpPBrush,lpDrawMode&gt;
    cCall   BitBlt</code></pre>
<p>This just pushes all of these arguments onto the stack, and calls the function.</p>
<p>So <code>FASTBORDER</code> is essentially the same in <code>svga256.drv</code> as it is in the VGA driver that I have source for; that's promising!</p>
<hr>
<p>The next function is <code>GETCHARWIDTH</code>, which is used to retrieve the widths of characters in a font. This is where I reach a new issue - this function isn't the same.</p>
<p>Also, just to make my life a bit harder, the proc has 7 parameters but not all of them are used -- meaning that I need to be extra careful about making sure I name them correctly in Ghidra.</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/charwidth.png"><img alt="Another side-by-side comparison. The left side shows the heavily commented assembly source in VS Code, and the right side shows the disassembly in Ghidra. One block, referred to as &quot;embolding simulation stuff&quot; in the comments, is missing from the Ghidra side." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/charwidth.png"></a></p>
<p>Turns out, there's some functionality in the VGA driver that adjusts the width of bold fonts. This does not seem to be present in <code>svga256.drv</code>!</p>
<p>I checked all the other implementations in the DDK's various drivers, but the VGA one is still the closest match. The Video 7 driver doesn't include this feature, but there are other differences in the code.</p>

<p>I wondered if this feature was added later, and maybe the SVGA256 driver was forked from an older version. There are some changelog-esque comments in many of these files, but MS don't seem to have done a great job at keeping them up to date :(</p>
<pre><code>; Created: Thu 30-Apr-1987
; Author:  Walt Moore [waltm]
...
; History:
;  Monday 3-October-1988 13:52   -by-   Ron Gery [rong]
;  moved into fixed code segment for fonts-in-EMS</code></pre>
<p>This is from the header for the VGA driver's <code>CHARWDTH.ASM</code> file.</p>
<p>It's very slightly different from the equivalent file in the PC-98 video driver, but both of these have identical dates and history entries, which suggests that I just can't put much faith into those comments.</p>
<p>Anyway, moving on...</p>
<hr>
<p>The next export after this was <code>REALIZEOBJECT</code>, which is the Windows GDI function that takes an object (pen, brush or font) and processes it to make it suitable for the driver - for example, choosing the closest available colour to the one requested by the application.</p>
<p>This one gave me a little more grief because it was my first time encountering a jump table, but it was doable. However... the colour handling logic is different, of course!</p>
<p>In the VGA driver's source, we see this logic with some curiously commented out code:</p>
<pre><code>realize_pen_10:
    xchg    ax,cx           ;Set pen type into CX
    lea si,[si].lopnColor   ;--&gt; RGB color
;   call    convert_index       ; convert the index into DH if the
                                    ; color is actually an index
;   jc  realize_pen_20      ; it was an index

    call    sum_RGB_colors      ;Sum up the color</code></pre>
<p>Whereas in SVGA256, the call to <code>sum_RGB_colors</code> has been replaced by ... a manually-inlined version of it? 🤔</p>
<p>Also, while the initial dispatch code is identical to the VGA driver's, the implementation of everything from <code>realize_brush</code> onwards is almost identical to the one from the Video 7 driver. Odd.</p>
<hr>
<p>After this, I realised that looking further at the GDI functions probably wouldn't be super helpful. It's helped me to get my bearings in this codebase, but what I <em>really</em> care about is how it interacts with the video adapter.</p>
<h2>Step 3: Initialising the Video Adapter</h2>
<p>I'd previously mentioned that when you select a type of video adapter in <em>Windows Setup</em>, it creates some INI entries in <code>SYSTEM.INI</code>.</p>
<p>If I pick <em>Super VGA (800x600, 256 colours, small fonts)</em>, I get the following entries:</p>
<pre><code>[svga256.drv]
dpi=96
resolution=2</code></pre>
<p>And after booting into Windows, the patched driver automatically adds these extra entries...</p>
<pre><code>svgamode=48
ChipSet=Tseng ET4000
LatchCapable=No</code></pre>
<p>I have no clue what these mean, but luckily, since these are named with nice text strings like <code>ChipSet</code>, it's very easy to find the code that interacts with them within the driver.</p>
<hr>
<p>The first one is in a function that, based on its placement, appears to be <code>driver_initialization</code>. I believe this is automatically called by Windows as the very first thing after the driver has been loaded into RAM.</p>
<p>If I look at the VGA driver from the DDK, it's got some pretty obtuse logic:</p>
<ul>
<li>Construct some flags based on whether we're on DOS 3.1.0 or higher, and whether we're on OS/2 or not</li>
<li>Call a <code>dev_initialization</code> function
<ul>
<li>Checks how much video memory is present, and disables a specific <code>BitBlt</code> feature if it's less than 256KB</li>
</ul></li>
<li>Load the <code>MouseTrails</code> setting from an INI</li>
<li>Mess with the function pointers to <code>ExtTextOut</code> and <code>StrBlt</code> for reasons I don't fully understand</li>
</ul>
<p>The Video 7 driver is a bit simpler -- it has the same flag logic, and it calls <code>dev_initialization</code> to assert that the driver is running on a 286 CPU or better, but it doesn't look at any INIs or mess with function pointers.</p>
<hr>
<p>On the other hand, the SVGA256 driver we're looking at is <em>trivial</em>.</p>
<p>Translated into pseudo-C just to make it a bit easier to understand:</p>
<pre><code>short ini_resolution = 0;
short ini_dpi = 96;

short driver_initialization(/* args not relevant here */) {
    short r = GetPrivateProfileInt("svga256.drv", "resolution", 0, "system.ini") &amp; 3;
    if (r != 0) {
        ini_resolution = r;
        ini_dpi = GetPrivateProfileInt("svga256.drv", "dpi", 0, "system.ini");
        return 1;
    }
    return 0;
}</code></pre>
<p>This function is untouched by SVGAPatch.</p>
<p>So that's useful... now, where do these get used?</p>
<hr>
<p>The function directly after it seems to be the equivalent to <code>physical_enable</code>. This is where it truly gets interesting - this is what sets up the VGA adapter!</p>
<p>We can look at this in <code>VGA.ASM</code> in the DDK; this uses assembler directives to generate different code for the VGA driver and for the 16-colour SVGA driver.</p>
<p>The code I see in SVGA256 is obviously an evolution of the latter. Once again I'll translate it to pseudo-C to make it easier to follow.</p>
<p>However, first I need to go on a slight tangent...</p>
<h3>System calls on the PC</h3>
<p>How do you "reach out" and interact with the OS or the hardware? There are three approaches we see in this driver.</p>
<p>Firstly, Windows functions like <code>SetPalette</code> and <code>WritePrivateProfileString</code> are imported from DLLs, so once you include the boilerplate to tell the assembler/linker about them, you can just call them like you would a function in your own code.</p>
<p>Then we have interrupts, which I've represented in this pseudocode using fake functions like <code>vga_enable_refresh()</code>. With these, you set certain registers to specific values (depending on what you want to do), and then use the x86 <code>INT</code> instruction.</p>
<p>I've looked them up in <a href="http://www.ctyme.com/rbrown.htm">this beautiful 90s-web adaptation of Ralf Brown's Interrupt List</a>, which is a very useful resource - I've also linked the individual pages below where referenced.</p>
<p><code>INT 10h</code> is the PC's <a href="http://www.ctyme.com/intr/int-10.htm">standard interrupt</a> for doing anything video-related; the contents of the <code>ax</code> register identify what operation you want to do.</p>
<p><code>INT 2Fh</code> is the <a href="http://www.ctyme.com/intr/int-2f.htm">"Multiplex" operation</a>, which is kind of like a miscellaneous bucket for services installed by MS-DOS, Windows, and other applications like TSRs.</p>
<p>Lastly, you can also just poke hardware registers directly using the <code>IN</code> and <code>OUT</code> x86 instructions. This isn't used in this particular function, but it'll show up in plenty of other places, as this is a fundamental part of working with VGA.</p>
<h3>Tearing apart <code>physical_enable</code></h3>
<pre><code>struct int_phys_device {
    BITMAP bitmap;
    char ipd_format, ipd_equipment, ipd_enabled;
};

struct ModeEntry {
    char *chipSetName;
    short mode;
    char *modeString;
    short functionID;
};
struct ModeEntry modes_800x600[] = {
    { "Tseng ET4000", 48, "48", 2000 },
    { "Video 7", 0x8000 | 105, "105", 2003 },
    { "Trident", 94, "94", 2006 },
    { "Oak", 84, "84", 2009 },
    { "Western Digital", 92, "92", 2012 },
    { "ATI VGA Wonder", 99, "99", 2015 },
    { "Cirrus Logic", 48, "48", 2018 },
    { "Cirrus Logic 542x", 92, "92", 2021 }
};
// ... plus two more for 640x480 and 1024x768
struct ModeTable {
    struct ModeEntry *modes;
    short width, height, _padding;
};
struct ModeTable wModeTable[] = {
    { 0, 0, 0, 0 },
    { modes_640x480, 640, 480, 0 },
    { modes_800x600, 800, 600, 0 },
    { modes_1024x768, 1024, 768, 0 }
};

short ScratchSel;
short wGraphicsMode;
short CurrentWidth, CurrentHeight;
short RequestedMode;
short FunctionID;
char latchCapableFlag;

(int, short) physical_enable(struct int_phys_device *pDevice) {
    // save the original video mode
    // this calls INT 10h with ax=0F00h
    pDevice-&gt;ipd_format = get_current_video_mode();

    ScratchSel = AllocSelector(0);

    short mode = wGraphicsMode;
    if (mode == 0) {
        mode = GetPrivateProfileInt("svga256.drv", "svgamode", 0, "system.ini");
    }
    short originalMode = mode;

retry:
    if (ini_resolution == 0) {
        // 1020 is the id of a "not specified" error message
        return (0, 1020);
    }
    struct ModeEntry *entry = wModeTable[ini_resolution].modes;
    CurrentWidth = wModeTable[ini_resolution].width;
    CurrentHeight = wModeTable[ini_resolution].height;
    RequestedMode = mode;

    short c;
    if (mode == 0) goto SVGA_Next;
    // if a mode was specified in the INI, search for it
    do {
        c = (entry++)-&gt;mode &amp; 0xFF;
        if (c == 0) goto tryFullSearch;
    } while (c == mode);
tryMode:
    if (SetAndValidateMode(c, (CurrentWidth / 8) - 1, CurrentHeight - 1)) {
        goto SVGA_Success;
    }
SVGA_Next:
    if (RequestedMode != 0) goto tryFullSearch;
    c = (entry++)-&gt;mode;
    if (c != 0) goto tryMode;
    // full scan failed, so the driver can't work at all
    // 1010 is the ID of the "Failed to initialise" message
    return (0, 1010);
tryFullSearch:
    // failed to find the mode specified in the INI, or it didn't work
    // so do a scan through all modes again
    mode = 0;
    goto retry;

SVGA_Success:
    // at this point, a mode has been found
    entry--;

    if (entry-&gt;functionID == 2012 &amp;&amp; special_type_2012()) {
        // if certain conditions are met, switch from "Western Digital" to "Cirrus Logic 542x"
        entry += 3;
    } else if (entry-&gt;functionID == 2000 &amp;&amp; special_type_2000()) {
        // switch from "Tseng ET4000" to "Cirrus Logic"
        entry += 6;
    }

    wGraphicsMode = entry-&gt;mode;
    FunctionID = entry-&gt;functionID;

    if (mode != originalMode) {
        WritePrivateProfileString("svga256.drv", "svgamode", entry-&gt;modeString, "system.ini");
        WritePrivateProfileString("svga256.drv", "ChipSet", entry-&gt;chipSetName, "system.ini");
    }

    // this calls INT 10h with ax=1201h, bl=36h
    vga_disable_refresh();

    // uses the FunctionID to look up chipset-specific 'VideoInit', 'SetBank'
    // and 'BltSpecial' functions
    resolve_procs();

    // calls the chipset-specific VideoInit function
    (*ptr_videoinit)();

    latchCapableFlag = checkLatchCapability();
    WritePrivateProfileString("svga256.drv", "LatchCapable", latchCapableFlag ? "Yes" : "No", "system.ini");

    enabled_flag = 0xFF;
    SetPalette(0, 256, &amp;adPalette);

    clear_framebuffer();

    // this calls INT 10h with ax=1200h, bl=36h
    vga_enable_refresh();

    // this will be explained later
    call_VDD_Set_Addresses();

    // this calls INT 2Fh with ax=4000h, and will be explained later too
    switch_to_background();

    return (1, 0);
}</code></pre>
<p>So that's the code, which doesn't translate super cleanly into pseudo-C, but I've tried my best. A high-level overview of what it's doing:</p>
<ol>
<li>Record the current video mode before we do anything</li>
<li>Check if a <code>svgamode</code> entry exists in <code>SYSTEM.INI</code></li>
<li>If so, call <code>SetAndValidateMode</code> to try that mode</li>
<li>If there was no entry <em>or</em> that mode failed, then go through each supported mode in turn until we find one that works</li>
<li>If we chose the <em>Western Digital</em> mode and some opaque checks succeed, then switch to <em>Cirrus Logic 542x</em></li>
<li>If we chose the <em>Tseng ET4000</em> mode and some other checks succeed, then switch to <em>Cirrus Logic</em></li>
<li>Save the new mode and chipset name to the <code>SYSTEM.INI</code> file</li>
<li>Call some chipset-specific initialisation code</li>
<li>Check the 'latch capability', whatever that means, and write it to the INI as well</li>
<li>Set the Windows palette</li>
<li>Clear the framebuffer</li>
<li>Set up the VDD</li>
</ol>
<p>Now we're in a good position to ask - how does this interact with SVGAPatch? This code from Microsoft's driver is written to let them support a few different chipsets. But the point of SVGAPatch is to use the newer VBE standard, and in theory, support any video adapter that's VBE compliant!</p>
<p>This function itself doesn't change, but it's directly adjacent to the stuff that does.</p>
<h2>SVGAPatch's Secret Sauce</h2>
<p>When you run the patcher, it gives you some output that tells you what it's changed. Now I know what all the relevant code does.</p>
<pre><code>Segment 3: addr=3AA0, size=917
Segment patched at offset 37E
Segment patched at offset 3D5
Segment patched at offset 42C
Segment patched at offset 481
Segment 11: addr=15240, size=7CD
Segment patched at offset 0</code></pre>
<p>The first 3 patches are setting the 'special function ID' for the very first chipset in each of the three lists <em>(one for each supported resolution)</em> to 2000.</p>
<p>The one at offset 481 is completely rewriting the <code>SetAndValidateMode</code> function. Finally, the one in Segment 11 is rewriting the chipset-specific functions with IDs 2000 and 2001.</p>

<p>So what's going on here? This patch is actually very simple, but pretty smart.</p>
<table>
<thead>
<tr>
<th>Function</th>
<th>Original MS code</th>
<th>Replacement from SVGAPatch</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SetAndValidateMode</code></td>
<td>- Use <a href="http://www.ctyme.com/intr/rb-0069.htm">the VGA BIOS</a> to try and set the video mode<br>- Check whether it succeeded and whether the VGA adapter claims to be in the requested SVGA resolution</td>
<td>Use <a href="http://www.ctyme.com/intr/rb-0275.htm">VBE operation <code>4F02h</code></a> to request an extended video mode depending on the configured resolution</td>
</tr>
<tr>
<td><code>SETBANK_TRIDENT</code></td>
<td>Write a non-standard value to <code>3C4h</code> (the VGA Sequencer Address Register)</td>
<td>Use <a href="http://www.ctyme.com/intr/rb-0278.htm">VBE operation <code>4F05h</code></a> to move the CPU's window to the video memory</td>
</tr>
<tr>
<td><code>VIDEOINIT_TRIDENT</code></td>
<td>Write to the VGA CRTC's Offset Register to set the amount of bytes between scan lines</td>
<td>Use <a href="http://www.ctyme.com/intr/rb-0280.htm">VBE operation <code>4F06h</code></a> to set the scan line length in bytes</td>
</tr>
</tbody>
</table>
<p>Finally, to tie this into <code>physical_enable</code>, the new logic ends up being as follows...</p>
<ol>
<li>Scan through all the supported modes in order, calling <code>SetAndValidateMode</code> for each one</li>
<li>The first one will succeed, so it's picked by default</li>
<li>Since the Function ID was replaced with 2000, the rewritten 'TRIDENT' chipset-specific functions are used</li>
<li>Since the chipset name and mode values are now unused, we see the values for the 'Tseng ET4000' written to <code>SYSTEM.INI</code>, just because it's the first one in the list</li>
</ol>
<p>And with that, we've solved one piece of the puzzle - how SVGAPatch works. But we've still not answered the question: <em>why do DOS prompts cause trouble?</em></p>
<h2>Understanding the Virtual Display Device</h2>
<p>It's time to go down yet another rabbit hole! There is a pretty good explanation of VDDs on the OS/2 Museum blog post that I linked earlier: <a href="https://www.os2museum.com/wp/windows-3-x-vddvga/">Windows 3.x VDDVGA</a></p>
<p>TL;DR: DOS programs are written to expect exclusive access to the computer's hardware (including the video adapter), and Windows cleverly tricks them into talking to virtualised implementations instead.</p>
<p>The author was writing their own display driver and having trouble with DOS prompts <em>(sound familiar?)</em>, and discovered that certain parts of the VGA registers were changing in unexpected ways when the mode changed inside a windowed DOS prompt ... which in <em>theory</em>, should not affect the real VGA adapter, as the GUI is supposed to have control over it.</p>
<p>They also note that a specific <code>DspDrvr_Addresses</code> function (which is located in the VDD and called from the display driver) doesn't actually do what the comments say it does, and that our <code>SVGA256.DRV</code> has special behaviour here.</p>
<blockquote>
<p>A corollary is that passing 0FFFFh as the latch byte address to the VDD (something that SVGA256.DRV does) tells VDDVGA.386 that there is no video memory to share. In that situation, VDDVGA.386 does not try any hair-raising schemes to modify the VGA register state behind the display driver’s back.</p>
</blockquote>
<p>Huh. <em>(I'll pretend I know what that means.)</em></p>

<p>As with the display driver... the Windows DDK gives us the source code for the VGA VDD, but not for the SVGA one that we're using. So I delved into the SVGA VDD with two goals in mind:</p>
<ol>
<li>Find out what changes Microsoft made in between the VGA VDD and the SVGA VDD
<ul>
<li>Is there chipset-specific behaviour hiding here that needs to be patched for generic VBE support?</li>
</ul></li>
<li>Try and learn what the deal is with <code>DspDrvr_Addresses</code></li>
</ol>
<p>I painstakingly mapped out the functions in the VDD,. The majority of them were unchanged, but I did come across some interesting-looking differences, and I learned a lot about how the system works in the process.</p>
<h2>Tangent: The VDD's Architecture</h2>
<p>If we look at <code>VDDCTL.ASM</code>, we see a whole set of interesting entry points to the VDD - some of the more notable ones:</p>
<table>
<thead>
<tr>
<th>Function</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>VDD_Device_Init</code></td>
<td>Set up the System VM (The one that Windows itself runs in)</td>
</tr>
<tr>
<td><code>VDD_Create_VM</code></td>
<td>Set up another VM (for a DOS application)</td>
</tr>
<tr>
<td><code>VDD_Set_Device_Focus</code></td>
<td>Called when the active VM is switching</td>
</tr>
</tbody>
</table>
<p>Just to keep things spicy, there's also a bunch of external entry points in <code>VDDSVC.ASM</code>, and there's custom interrupt handlers in <code>VDDINT.ASM</code>.</p>

<p>Anyway, each VM gets its own instance of a big structure called <code>VDD_CB_Struc</code>, which is defined in <code>VDDDEF.INC</code>. This contains a whole lot of stuff, including:</p>
<ul>
<li>Various bitfields with all sorts of flags</li>
<li>A complete mirror of the VGA controller's state</li>
<li>Details of what video memory has been allocated by this particular VM</li>
</ul>
<p>This whole system is impressively complex! There's a large <code>VDDOEM.ASM</code> file dedicated entirely to vendor-specific custom code, which is exactly what I was scared of...but we'll see how far we can get.</p>
<p><code>VDDTIO.ASM</code> has a ton of logic that traps read/write accesses to the various VGA registers. I believe this is used by backgrounded VMs - so the active VM gets direct access, but any VM running in the background will just hit these routines and end up talking to the VDD's simulated VGA adapter.</p>
<hr>
<p>Last but not least, but important here: The real-mode initialisation code found in <code>VDD_Real_init</code> has logic to detect various different VGA adapters, and it enables specific flags for them which get stored in the <code>VDD_TFlags</code> bitfield. These flags, in turn, influence other parts of the VDD's behaviour.</p>
<p>Many of these changes are just to teach the VDD to save, restore and simulate specific registers that only exist on certain adapters.</p>

<p>At this point I was feeling a little unsure about this project. If the VDD's state tracking requires <em>this</em> much micromanagement of the VGA adapter and its vendor-specific quirks, then I might just be fighting a battle that I can't win.</p>
<p>But I figured I could keep going and see if I can learn some more.</p>
<h2>What's the deal with DspDrvr_Addresses?</h2>
<p>There's a number of APIs provided by the VDD to the grabber. In <code>386/INCLUDE/VMDAVGA.INC</code> we see these interesting definitions for new ones:</p>
<pre><code>; New API's for 3.1 display drivers
Private_DspDrvr_1   EQU 0Ah
                .errnz Private_DspDrvr_1 - GRB_Unlock_APP - 1
DspDrvr_Version     EQU 0Bh
DspDrvr_Addresses   EQU 0Ch</code></pre>
<p>And if we look inside <code>386/VDDVGA/VDDSVC.ASM</code>, we see how the VGA VDD handles these:</p>
<pre><code>IFDEF DspDrvrRing0Hack
    cmp cl,Private_DspDrvr_1
    je  VDD_Init_DspDrv_Ring0
ENDIF
    cmp cl, DspDrvr_Version
    je  VDD_SVC_Dsp_Version
    cmp cl, DspDrvr_Addresses
    je  VDD_SVC_Set_Addresses</code></pre>
<p><em>Suspicious.</em> The first one seems to only be used by the IBM 8514 display driver, for a specific implementation of <code>BitBlt</code>. The second one just returns a version number. The third one is what we really care about.</p>
<p>Here's the comments from the VDDVGA implementation:</p>
<pre><code>;******************************************************************************
;
;   VDD_SVC_Set_Addresses
;
;   DESCRIPTION:    This service is called by the display driver BEFORE it
;           does the INT 2Fh to indicate that it knows how to restore
;           its screen.  This service is used to tell us where we
;           can interface with the display driver.
;
;           One of the addresses passed is the location of a byte of
;           video memory that we can safely use to save/restore latches.
;
;           The 2nd address passed is the location of the flag byte
;           used by the display driver to determine the availability
;           and validity of the "save screen bits" area.  The display
;           driver copies portions of the visible screen to non-visible
;           memory to save original contents when dialog boxes or menus
;           area displayed.  Since this is non-visible memory, it is
;           subject to demand paging and be stolen for use by a
;           different VM.  If a page is stolen from the sys VM, then
;           any data that was in the page is lost, because we don't
;           maintain a copy, so we need to indicate to the display
;           driver that the "save screen bits" area is now invalid.
;
;
;   ENTRY:      EBX = VM Handle
;           EBP = Client stack frame ptr
;           Client_AX = function #
;           Client_BX = offset of address in display segment
;           Client_DX is reserved and must be 0
;           ClientDS:Client_SI -&gt; shadow_mem_status
;
;   EXIT:       Client_AX is returned with a copy of Client_BX to
;           indicate that the service is implemented
;
;   USES:       EAX, ECX, Flags
;
;==============================================================================</code></pre>
<p>Here's my best pseudo-C translation of the code and its comments, because I don't want to inflict more x86 assembly on anyone than is absolutely necessary. You deserve better.</p>
<pre><code>extern void VDD_PH_Mem_Set_Sys_Latch_Addr(u32 eax, u8 cl, u8 ch, u32 edx);

void VDD_SVC_Set_Addresses(struct ClientStackFrame *s) {
    struct VDD_CB_Struc *cb = SetVDDPtr();

    u32 latchAddr; // eax
    u8 latchBank; // cl
    u8 firstVisiblePageInFirstBank; // ch
    u32 visiblePagesInFirstBank; // edx

    latchAddr = s-&gt;Client_BX;
    s-&gt;Client_AX = latchAddr &amp; 0xFFFF;

    if (s-&gt;Client_DX
#ifdef TLVGA
        &amp;&amp; (cb-&gt;VDD_TFlags &amp; fVT_TL_ET4000)
#endif
    )
    {
        VT_Flags &amp;= ~fVT_SysVMin2ndBank;
        cb-&gt;VDD_TFlags &amp;= ~fVT_SysVMin2ndBank;

        visiblePagesInFirstBank = 0;
        firstVisiblePageInFirstBank = 0;
        latchBank = s-&gt;Client_CL;
        // Q: display driver put latch byte in different bank?
        if (latchBank == 0) {
            // N: we have to reserve a pg
            visiblePagesInFirstBank++;
            // in the 1st bank
            firstVisiblePageInFirstBank = (latchAddr &gt;&gt; 8) &amp; 0xFF;
            // CH page # to reserve
            firstVisiblePageInFirstBank &gt;&gt;= 4;
        } else {
            // Y: so no pages are required in 1st bank
        }
    } else {
        firstVisiblePageInFirstBank = 0;
        latchBank = 0;
        visiblePagesInFirstBank = (latchAddr &gt;&gt; 12) + 1;
        // this assumes latch page is last visible page
    }
#endif
    cb-&gt;VDD_Flags |= fVDD_DspDrvrAware;
    VDD_PH_Mem_Set_Sys_Latch_Addr(latchAddr, latchBank, firstVisiblePageInFirstBank, visiblePagesInFirstBank);

    Vid_Shadow_Mem_Status_Ptr = (s-&gt;Client_DS &lt;&lt; 16) | s-&gt;Client_SI;
}</code></pre>
<p>So there's some weirdness going on here. The comment says that <code>DX</code> is reserved and must be 0. Yet, if <code>DX</code> is a non-zero value, this triggers special behaviour that reads from <code>CL</code> (which isn't even documented as being used)!</p>
<p>And this isn't used by any of the drivers in the DDK. Weird.</p>
<hr>
<p>What about the SVGA version? Sadly I don't have comments for that, but I can at least disassemble the code and do a similar translation.</p>
<pre><code>extern void VDD_PH_Mem_Set_Sys_Latch_Addr(u32 eax, u8 cl, u8 ch, u32 edx);

void VDD_SVC_Set_Addresses(struct ClientStackFrame *s) {
    struct VDD_CB_Struc *cb = SetVDDPtr();

    u32 latchAddr; // eax
    u8 latchBank; // cl
    u8 firstVisiblePageInFirstBank; // ch
    u32 visiblePagesInFirstBank; // edx

    latchAddr = s-&gt;Client_BX;
    s-&gt;Client_AX = latchAddr &amp; 0xFFFF;

    if (s-&gt;Client_DX &amp;&amp; s-&gt;Client_DX == 2) {
        VT_Flags &amp;= ~(fVT_SysVMnot1stBank | fVT_SysVMin2ndBank);
        cb-&gt;VDD_TFlags &amp;= ~(fVT_SysVMnot1stBank | fVT_SysVMin2ndBank);
        VT_Flags |= fVT_0x400;
        cb-&gt;VDD_TFlags |= fVT_0x400;

        FUN_00013f60(&amp;VDD_VM_Mem_Msg_Page_Handler);
        latchBank = 0;
        firstVisiblePageInFirstBank = 0;
        visiblePagesInFirstBank = 16;
    } else if (s-&gt;Client_DX &amp;&amp; (cb-&gt;VDD_TFlags &amp; fVT_TL_ET4000)) {
        VT_Flags &amp;= ~fVT_SysVMin2ndBank;
        cb-&gt;VDD_TFlags &amp;= ~fVT_SysVMin2ndBank;

        visiblePagesInFirstBank = 0;
        firstVisiblePageInFirstBank = 0;
        latchBank = s-&gt;Client_CL;
        // Q: display driver put latch byte in different bank?
        if (latchBank == 0) {
            // N: we have to reserve a pg
            visiblePagesInFirstBank++;
            // in the 1st bank
            firstVisiblePageInFirstBank = (latchAddr &gt;&gt; 8) &amp; 0xFF;
            // CH page # to reserve
            firstVisiblePageInFirstBank &gt;&gt;= 4;
        } else {
            // Y: so no pages are required in 1st bank
        }
        firstVisiblePageInFirstBank = 0;
        latchBank = 0;
        visiblePagesInFirstBank = (latchAddr &gt;&gt; 12) + 1;
        // this assumes latch page is last visible page
    }
#endif
    cb-&gt;VDD_Flags |= fVDD_DspDrvrAware;
    VDD_PH_Mem_Set_Sys_Latch_Addr(latchAddr, latchBank, firstVisiblePageInFirstBank, visiblePagesInFirstBank);

    Vid_Shadow_Mem_Status_Ptr = (s-&gt;Client_DS &lt;&lt; 16) | s-&gt;Client_SI;
}</code></pre>
<p>Broadly the same, but there's a brand new case for where the reserved field is set to 2. Also, the <code>latchBank</code> value is no longer used; the underlying logic in that file has changed quite a bit in ways I don't understand.</p>
<p>If I look at the code in the SVGA256 driver, it calls this function with:</p>
<ul>
<li><code>BX</code> (offset of address in display segment) is 0xFFFF</li>
<li><code>DX</code> (reserved field) is 2, for the new behaviour</li>
<li><code>DS:SI</code> (shadow mem status) is a pointer to a byte, which is not used by SVGA256 anywhere else</li>
</ul>
<p>Well, that's good to know.</p>
<h2>Where do I go from here?</h2>
<p>I hoped that analysing both the driver and the VDD would lead me to something obvious that I could just patch, but this hasn't really happened. The VGA hardware may be older than I am, but that doesn't make it simple to understand :(</p>

<p>So I may have to get my paws dirty and do some debugging. Coming back to the OS/2 Museum blog post again, the author writes:</p>
<blockquote>
<p>First I tried to find out what was even happening. Comparing bad/good VGA register state, I soon enough discovered that the sequencer registers contents changed, switching from chained to planar mode. This would not matter if the driver used the linear framebuffer to access video memory, but for good reasons it uses banking and accesses video memory through the A0000h aperture.</p>
</blockquote>
<p>Can I use the same techniques? I don't really know how to debug things like this, but these issues are fully reproducible in DOSBox, so let's give it a shot.</p>
<h2>Examining the Issues in DOSBox</h2>
<p>I'm using DOSBox-X on my ARM MacBook. The version shipped by Homebrew doesn't seem to have debugging functionality, so I grabbed new binaries from their website, and now I get a helpful Debug menu.</p>
<p>There is a <em>Video debug overlay</em> option which adds some cool visualisations of the VGA adapter's state, along with a bit of info.</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/dosbox1.png"><img alt="A full-screen DOS prompt in DOSBox. The screen is covered in four swathes of dot characters, and the second line has a bunch of equals signs and letters interspersed with the dots. Debugging info and a visualisation of the active palette is shown by the overlay at the bottom of the window." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/dosbox1.png"></a></p>
<p>If I open a full-screen prompt, press Alt+Enter to return to the <em>(broken)</em> GUI and then press Alt+Enter again to full-screen again, I get this mess. Absolutely cooked.</p>
<p>Comparing the silly little annotations, I see the following state changes:</p>
<table>
<thead>
<tr>
<th>State</th>
<th>Silly little annotations</th>
</tr>
</thead>
<tbody>
<tr>
<td>Functional GUI</td>
<td><code>M_LIN8 G800x600&gt;800x600 @00000+100+Dch4</code></td>
</tr>
<tr>
<td>Functional DOS</td>
<td><code>M_TEXT T80x25&gt;720x400 @00000+050-W</code></td>
</tr>
<tr>
<td>Broken GUI</td>
<td><code>M_VGA G400x600&gt;400x600 @00000+200-Dch4</code></td>
</tr>
<tr>
<td>Broken DOS</td>
<td><code>M_TEXT T80x25&gt;720x400 @00000+250-W</code></td>
</tr>
</tbody>
</table>
<p>What does this mean?? Not a clue.</p>
<p>I can definitely see that the state is going haywire, but I don't know who's responsible. Is there something missing in the patched display driver? Is the VDD corrupting the state? Both?</p>
<p>I had one hunch. I'd seen that the VDD has a lot of special behaviours for different cards; is it possible that one of these is unwittingly being activated and playing havoc? Say that the VDD mistakenly thinks I'm using a... oh, I don't know, "Trident" GPU, and tries to write to a Trident-specific register, but that register address does something else entirely in whatever DOSBox is currently emulating.</p>
<p>This <em>could</em> be an issue... but to know for sure, I'd need to figure out how to see what the value of <code>VT_Flags</code> is.</p>
<h2>Viewing Driver Memory</h2>
<p>The DOSBox Debugger has commands that let me view memory, but I had a problem - I didn't know <em>where</em> to look! I have no clue how Windows 3.11 maps memory for drivers, or how to even find that out.</p>
<p>My first idea was to just dump the entire system's memory and do a search for the <code>"VDD     "</code> string which is always present in the VDD's memory. This would've worked, except for the fact that DOSBox-X's <code>MEMDUMP</code> command only works with logical addresses.</p>
<p>So I wound up with the slightly dirty solution of just recompiling DOSBox-X with that command tweaked. Sure enough, I dumped the first 32MB of physical addresses to a file, and I was able to find the driver's flags.</p>
<p>But this turned out to be a red herring. None of the vendor-specific flags are set; at least not in DOSBox. Oh well.</p>
<h2>Analysing VGA Registers</h2>
<p>I'll need to go a bit deeper. As it turns out, there's a whole set of commands I can use in the DOSBox debugger to print out fine details about the VGA state... basically every register.</p>
<p>I recreated the previous scenario and did this. If I compare all the registers between the 'good' and 'bad' full-screen DOS prompts, one thing sticks out: the field that DOSBox internally calls <code>scan_len</code>. This is used to calculate how many bytes to advance between each line on the screen. In the 'good' state it's 40, but in the 'bad' state it's 296.</p>
<p>What actually causes this, though??</p>

<p>This field can be updated in a few ways:</p>
<ul>
<li>Writes to the VGA CRTC Offset Register</li>
<li>Writes to the S3 "CR43 Extended Mode" Register</li>
<li>Writes to the S3 "Extended System Control 2" Register</li>
<li>Calls to the VESA Scan Line API <em>(the one used by SVGAPatch's changes!)</em></li>
</ul>
<p>It gets even stranger if I <em>begin</em> with a windowed DOS prompt and look at the <code>scan_len</code> value. On a 'good' GUI, it's 128, but on a 'bad' GUI (after returning to windowed mode), it's 256.</p>
<p>DOSBox's implementation of the VESA API calculates <code>scan_len</code> differently based on what it thinks the current video mode is. This is pretty suspicious.</p>
<hr>
<p>Since I'd already gone ahead and recompiled DOSBox myself, I figured I'd go further and just throw in some logging.</p>
<pre><code>    LOG_MSG("VESA_ScanLineLength(subcall=%d, val=%d, bytes=%d, pixels=%d, lines=%d)\n", subcall, val, bytes, pixels, lines);
    LOG_MSG("  Current Mode: %s\n", mode_texts[CurMode-&gt;type]);</code></pre>
<p>And this gives me a smoking gun...!</p>
<pre><code>VESA_ScanLineLength(subcall=2, val=1024, bytes=2, pixels=1024, lines=4768)
  Current Mode: M_TEXT</code></pre>
<p>The display driver is calling <a href="http://www.ctyme.com/intr/rb-0280.htm">VBE operation <code>4F06h</code></a> to set the scan line length to 1024 bytes, but DOSBox thinks we're in text mode, so the resulting field is wrong.</p>
<p>The obvious next step is to add logging for video mode changes. This is a little more annoying than it seems, because there's a few ways this can occur. To be thorough, I decide to add log messages to all of them.</p>
<p>This finally lets me assemble a crude timeline of events.</p>
<ul>
<li>Start Windows
<ul>
<li><code>M_TEXT</code> -&gt; Mode 12h (640x480 VGA)</li>
<li><code>M_EGA</code> -&gt; Mode 10h (640x350 EGA)</li>
<li><code>M_EGA</code> -&gt; Mode 3 (80x25 text)</li>
<li><code>M_TEXT</code> -&gt; Mode 103h (800x600 SVGA)</li>
<li>ScanLineLength called: 1024 bytes, with the current mode being <code>M_LIN8</code></li>
</ul></li>
<li><strong>So far so good</strong> - we have a working desktop now</li>
<li>I open a full-screen DOS prompt
<ul>
<li><code>M_TEXT</code> -&gt; Mode 3 (80x25 text)</li>
</ul></li>
<li><strong>So far so good</strong> - we have a working prompt, no anomalies</li>
<li>I press Alt+Enter to return to windowed mode
<ul>
<li><code>M_TEXT</code> -&gt; Mode 30h (... what?!)</li>
<li>ScanLineLength called: 1024 bytes, with the current mode being <code>M_TEXT</code></li>
<li>Now the debugger says we're in mode <code>M_VGA</code>?!</li>
</ul></li>
<li><code>scan_len</code> is now corrupted, along with our display</li>
</ul>

<p>There's three things going on here that we need to unpack:</p>
<ol>
<li><em>Something</em> is asking for a mode switch to 30h (or decimal 48), which doesn't work as that is not a supported mode.</li>
<li>The patched display driver tries to set the scanline length, but this corrupts the state because we're in text mode</li>
<li>Yet we somehow end up in a graphics mode, without a switch?? What???</li>
</ol>
<p>DOSBox has a global variable called <code>CurMode</code> which is updated every time the video mode changes through a call to <code>INT 10h</code> - either with the legacy video mode call from the IBM PC days, or the <em>slightly</em> more modern VESA/VBE API.</p>
<p>On the other hand, the debugger's <code>VGA MODE</code> command (which is what I'm using to introspect the state) is reading from DOSBox's <code>vga.mode</code>, which is a more low-level field in the display engine. This is computed from VGA registers.</p>
<p>So... I think this is the fault of the VDD! It's doing its thing and dutifully saving/restoring registers behind the scenes, but this leaves us out of sync when we try to use the higher-level VBE interface.</p>
<hr>
<p>What about point 1? Who is trying to set the video mode to the invalid 30h, and why?</p>
<p>Well, this comes back to where we began. SVGAPatch hijacks the entries used by the Microsoft driver for the <em>Tseng ET4000</em> chipset. For a resolution of 800x600, it uses the Tseng-specific mode 30h.</p>
<p>Lo and behold, if we look for calls to <code>INT 10h</code> in our patched display driver, we find a function that calls it.</p>
<p>So the VBE patch really <em>is</em> incomplete after all... 🤔</p>
<h2>Fixing the Patch</h2>
<p>I didn't want to just replace this function, I also wanted to understand how it fits into the whole system. So it's time to analyse how Windows 3.1 tells the driver about screen switches! Thankfully, this code is all present in the DDK's VGA driver, so that helps a lot.</p>
<h2>Screen Switching</h2>
<p>When the display driver is enabled, the <code>hook_int_2F</code> routine (from <code>SSWITCH.ASM</code>) is called. This gets pointers to a couple of functions from Windows DLLs, and also hooks the handler for <code>INT 2Fh</code>.</p>
<p>Remember, <code>2Fh</code> is the 'Multiplex' interrupt, which lots of software can piggyback on. If a program wants to hook it, it has to store the address of the <strong>previous</strong> handler, and then call it for any requests that it didn't handle. This effectively creates a chain of hooks, eventually ending at whatever default was assigned by MS-DOS on boot.</p>
<p>This driver is no exception. The hook it uses is called <code>screen_switch_hook</code>.</p>

<p>The VGA driver is able to <strong>receive</strong> four commands via <code>INT 2Fh</code>, which are crudely documented as follows in the DDK:</p>
<pre><code>SCREEN_SWITCH_OUT equ   4001h       ;Moving 3xBox to background
SCREEN_SWITCH_IN  equ   4002h       ;Moving 3xBox to foreground
SAVE_DEV_REGS   equ 4005h       ;int 2f code to save registers
RES_DEV_REGS    equ     4006h       ;int 2f code to restore registers</code></pre>
<p>...but interestingly, only the two <code>SCREEN_SWITCH_x</code> commands are supported by the SVGA256 driver.</p>
<p>Anyway, both of these call three routines in order. For the <code>OUT</code> command, it's <code>pre_switch_to_background</code>, <code>dev_to_background</code>, and then <code>post_switch_to_background</code>. For the <code>IN</code> command, it's the same, but with <code>_to_foreground</code> routines instead.</p>
<p>All of these are pretty basic, except for <code>dev_to_foreground</code>, which is the one called when you switch back to Windows itself.</p>
<hr>
<p>In the VGA driver's code (<code>286/DISPLAY/4PLANE/3XSWITCH.ASM</code>), <code>dev_to_foreground</code> is pretty simple - it calls <code>INT 10h</code> with <code>ax=1002h</code> to <a href="http://www.ctyme.com/intr/rb-0116.htm">reset all the palette registers</a>, then calls <code>init_hw_regs</code> to... set some stuff that I don't really get.</p>
<p>In the Video 7 driver's code from the DDK (<code>286/DISPLAY/8PLANE/V7VGA/SRC/3XSWITCH.ASM</code>), it's a bit spicier:</p>
<ul>
<li>Calls <code>farsetmode</code>, which:
<ul>
<li>Sets the display mode</li>
<li>Enables Video 7 VGA extensions</li>
<li>Sets the line length</li>
</ul></li>
<li>Calls <code>far_set_dacsize</code> to set the DAC mode, whatever that means</li>
<li>Calls <code>setramdac</code> to program the palette</li>
<li>Calls its own version of <code>init_hw_regs</code></li>
<li>Sets <code>enabled_flag</code> to 0xFF</li>
<li>Calls <code>far_set_cursor_addr</code></li>
</ul>
<p>So after looking at these, what do we see in the problematic SVGA256 driver?</p>
<ul>
<li>Calls <code>farsetmode</code>, which:
<ul>
<li>Sets the display mode to 48 (!!)</li>
<li>Calls the chipset-specific VideoInit routine</li>
</ul></li>
<li>Sets <code>enabled_flag</code> to 0xFF</li>
<li>Calls the Windows API's <code>SetPalette</code> to set the palette</li>
</ul>
<p>Herein lies our problem! There are <strong>two</strong> places where the video mode gets set, and SVGAPatch missed this one. It <em>does</em> call the VideoInit routine, so it uses the patched code to set the scanline length, but without being in the right video mode, it won't actually give us the right result.</p>
<h2>Can we fix it?</h2>
<p>Hopefully!</p>
<p>The original code just looks like this:</p>
<pre><code>mov ax, [wGraphicsMode]
int 10h
call [ptr_videoinit]
retn</code></pre>
<p>There's not much room to work with, but luckily, this is right after <code>SetAndValidateMode</code>, a function that was replaced by SVGAPatch with a much shorter version. So, I take the first byte right after the end of the new <code>SetAndValidateMode</code>, and inject some new assembly:</p>
<pre><code>mov cx, [CurrentHeight]
dec cx
call SetAndValidateMode
call ptr_videoinit
retn</code></pre>
<p>Since <code>SetAndValidateMode</code> expects <code>cx</code> to contain the screen height (minus 1), I do that. Then I replace the first instruction of <code>setmode</code> with a simple <code>jmp</code> to my new code.</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/dosbox2.png"><img alt="Screenshot showing a functional Windows 3.11 desktop in DOSBox, with a DOS prompt in a window. I've typed in &quot;echo I'm in full screen :)&quot;, followed by &quot;echo now I'm in windowed mode!&quot;" src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/dosbox2.png"></a></p>
<p>Lo and behold... the GUI no longer gets trashed after entering a full-screen DOS session!</p>
<p>One issue remains, though. If I go from windowed mode to full screen, the dots come back.</p>
<h2>Register Debugging (Again)</h2>
<p>I've tried to use my previous trick where I invoke all the DOSBox VGA debug commands to dump the state and I compare them, but this time I'm not getting anything useful.</p>
<p>Why am I getting nonsense? If I enter <code>DP B8000</code> into the DOSBox debugger console to look at the VGA memory, I see that the text is all there - it's just not showing up!</p>
<p>There is an interesting DOSBox debug feature that lets you enter a command like <code>VGA DS START 2</code> to override the VGA base address, and if I do this, it shifts the garbage around, but it's still the same garbage.</p>

<p>So then I thought... I know that the driver uses banking, so that it can access more video memory than is available with ye olde VGA. When it needs to read or write something outwith the range it currently sees, it'll call the SetBank function (which was patched by SVGAPatch) to ask for that window to be moved. Is this the problem?</p>
<p>Turns out, the bank configuration is stored in a separate structure that isn't covered by any of the debug commands. I add a quick and dirty command to dump these, and recompile DOSBox yet again.</p>
<pre><code>        else if (command == "SVGA") {
            DEBUG_ShowMsg("VGA SVGA data: bankMask=%lu read_full=%lu write_full=%lu read=%u write=%u size=%lu",
            (unsigned long)vga.svga.bankMask,
            (unsigned long)vga.svga.bank_read_full,
            (unsigned long)vga.svga.bank_write_full,
            vga.svga.bank_read,
            vga.svga.bank_write,
            (unsigned long)vga.svga.bank_size
            );
        }</code></pre>
<p>Sure enough, when I return to full screen mode, the VGA adapter is stuck on the wrong bank!</p>
<h2>Can we fix it? Again??</h2>
<p>I've now gotten to the point in writing up this post where I've written about all the stuff I've done, and I haven't actually attempted to fix this yet. But you know what... screw it, I may as well try.</p>
<p>We've seen <code>dev_to_foreground</code>, which called <code>farsetmode</code>, which jumped to <code>setmode</code>, and fixing <em>that</em> made the GUI work. So, what if I modify <code>dev_to_background</code> to reset the bank to 0 as we're leaving the GUI?</p>
<p>All we've got in that routine right now is a simple <code>mov [enabled_flag], 0</code>. I've still got a bunch of free space over next to my silly little kludge... but it's in the wrong segment. If I want to add a new cross-segment call, I'll need to mess with the executable structure, and I honestly cannot be bothered.</p>

<p>So I spent a while trying to find something in the first segment that I could hack to shreds. Eventually I settled on the implementation of <code>GetDriverResourceID</code>, which is a function that's only used for the 120dpi ("Large Fonts") configuration.</p>
<p>First I need to bring it down to its simplest possible form:</p>
<pre><code>push bp
mov bp, sp
mov ax, [bp+0Ah]
pop bp
retf 6</code></pre>
<p>This now leaves me a bit of space to write a new bank resetting routine, which should force the video adapter back to bank 0:</p>
<pre><code>mov [ds:enabled_flag], 0
xor dx, dx
call set_bank_select
retn</code></pre>
<p>And finally, I jump to it from <code>dev_to_background</code>, so that it'll be called when I leave the GUI.</p>

<p>So with great trepidation, I try to run it, and... the OS doesn't crash! But it doesn't fix the issue, either :(</p>
<p>After a bunch of painstaking <code>printf</code> debugging I find out why... DOSBox implements  <a href="http://www.ctyme.com/intr/rb-0278.htm">VBE operation <code>4F05h</code></a> (to set the 'bank') by writing to the VGA CRTC register 0x6A. I'm doing it from <code>dev_to_background</code>, but that routine is called too late - by that point, we've already switched away, and the VDD is trapping our writes.</p>
<p>This doesn't align with what I see in the Windows DDK's documentation:</p>
<blockquote>
<p>Interrupt 2Fh Function 4001h</p>
<pre><code>mov ax, 4001h   ; Notify Background Switch
int 2fh</code></pre>
<p>Notify Background Switch notifies a VM application that it is being switched to the background. The VM application can carry out any actions, but should do so within 1000ms. This is the amount of time the system waits before switching the application.</p>
</blockquote>
<p>I have two options:</p>
<ol>
<li>I somehow find a way to trigger this earlier in the switching process
<ul>
<li>Would be nice, but I clearly can't believe the docs, and I don't really want to try and disassemble more of Windows.</li>
</ul></li>
<li>I teach the VDD to let me pass these writes through, as Microsoft did for all the SVGA adapters they officially supported
<ul>
<li>This would fix it for DOSBox, but that fix would be tied to whichever video adapter it's emulating. I don't want that, I'm trying to make the generic VBE patch work better!</li>
<li>It's unlikely that my Eee PC's Intel GMA950 <em>also</em> uses CRTC register 0x6A for banks.</li>
</ul></li>
</ol>
<p>At this point, you know what... I think I'm done. It's almost midnight and I have to return to my day job tomorrow. (The Java™ cannot wait.)</p>
<h2>... What now?</h2>
<p>This was a fun little endeavour, and I've gotten surprisingly far, but I don't want to invest much more time into it - it's just something I wanted to poke at over the holiday season.</p>

<p>You know how brittle this whole setup is? Just for fun, let's go back to the <em>original</em> SVGA 256-colour driver from Microsoft, and its list of supported cards... and let's use 86Box to try out a few.</p>
<table>
<thead>
<tr>
<th>Emulated Card</th>
<th>How it worked at 1024x768, 256 colours</th>
</tr>
</thead>
<tbody>
<tr>
<td>ATI VGA Wonder XL</td>
<td>Failed to start Windows <em>(ok, this might just be too new a variant)</em></td>
</tr>
<tr>
<td>Cirrus Logic GD5420 (ISA)</td>
<td>Works! ✅</td>
</tr>
<tr>
<td>Oak OTI-077</td>
<td>Screen corruption when initially opening a windowed DOS prompt, vertical lines when full-screening one</td>
</tr>
<tr>
<td>Paradise PVGA1A</td>
<td>Failed to start Windows</td>
</tr>
<tr>
<td>Trident TVGA 8900D</td>
<td>Screen corruption when full-screening a DOS prompt, but windowed is ok</td>
</tr>
<tr>
<td>Tseng Labs ET4000AX</td>
<td>Works! ✅</td>
</tr>
<tr>
<td>Video 7 VGA 1024i (HT208)</td>
<td>Only works at 640x480, fails to start at any higher resolution</td>
</tr>
</tbody>
</table>
<p>I should caveat this with the fact that 86Box doesn't have some of the exact same cards, so that might lead to issues, and I don't know how accurate the emulation is for all of them. Still, this suggests that even the original support was already kind of dodgy - so I won't be too sad about not being able to make it perfect myself.</p>

<p>I also picked some of the newer cards in 86Box and tried them with my patched version of the patched driver, to see what would happen --</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/dosbox3.png"><img alt="A very corrupted Windows 3.11 desktop in 86Box where the background has turned into pink and black stripes, and lots of pixels have been mashed together. You can kinda recognise the shape of Program Manager, but none of the text or icons are actually discernible." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/dosbox3.png"></a></p>
<table>
<thead>
<tr>
<th>Emulated Card</th>
<th>How it worked at 1024x768, 256 colours</th>
</tr>
</thead>
<tbody>
<tr>
<td>Matrox Millennium II</td>
<td>Unbearably laggy. Windowed DOS prompts work, full-screen is broken.</td>
</tr>
<tr>
<td>3dfx Voodoo Banshee</td>
<td>Opening a windowed DOS prompt corrupts the GUI, but switching <em>to</em> and <em>from</em> full-screen works perfectly.</td>
</tr>
<tr>
<td>S3 Trio3D/2X (362)</td>
<td>Beautiful glitch art when Windows first launches (as seen above!), but if you open a DOS prompt and then switch <em>out</em> of full-screen, you get perfect 1024x768. Oh, and full-screen is broken.</td>
</tr>
<tr>
<td>3dfx Voodoo3 3500 SI</td>
<td>Same as the Banshee, but full-screen only works once and then it just breaks on any subsequent Alt+Enters.</td>
</tr>
</tbody>
</table>

<p>Last but not least... I'm sure you're dying to know, how far did I get with the Eee PC after all this faffery? The GUI works fine. Switching to a full-screen DOS prompt breaks, but in an interestingly different way to DOSBox. While on DOSBox I get text mode with lots of corrupted characters, on the Eee PC I get a broken version of the GUI where some of the colours have disappeared.</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/solitaire.jpg"><img alt="Picture of Windows on the Eee PC, with Program Manager and Solitaire open. All the Solitaire cards have turned white and many of the colours on the screen have become white or grey (but the Solitaire green background remains). The top fifth of the screen has vertical lines running across it." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/solitaire.jpg"></a></p>
<p>However, the saving grace is that you can just switch to windowed mode again and it recovers OK.</p>

<p>If you think that looks cool, then here's a fun one I got when I was messing around with the text mode blue screen that you get when you press Ctrl+Alt+Del - somehow I got it to corrupt the VM's video memory, and the results stuck around enough to get rendered at glorious 1024x600 by the Grabber.</p>
<p><a rel="lightbox" href="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/glitch_art.jpg"><img alt="Closeup of a MS-DOS prompt on the Eee PC, which is rendering some wacky corrupted data as if it were a real prompt. There are five expanses of colourful horizontal stripes, interspersed with 5-cell-wide columns made out of random characters and symbols." src="https://wuffs.org/user/pages/02.blog/windows-3x-graphics/glitch_art.jpg"></a></p>
<p>And you know what - glitch art aside... my updated driver may not be <em>perfect</em>, but it's already a huge improvement over the original SVGAPatch, where simply opening a prompt (even in a window) would break the entire GUI and require me to restart the OS. I'll take that W. </p>
<p>For anything better than that, I'll continue to keep an eye on <a href="https://github.com/PluMGMK/vbesvga.drv">PluMGMK/vbesvga.drv</a>, which is being actively developed and written by someone that actually knows what they're doing when it comes to 16-bit PC dev and video hardware.</p>
<hr>
<p>I hope you enjoyed this adventure :3 I had fun, but I'm definitely ready to move onto something else now. Maybe I'll even write the post I originally planned on writing, about how to set up Windows 3.x and 9x on the Eee PC. <em>Maybe.</em></p>
<p>If you liked it, you can subscribe to this blog for more infrequent tech nonsense, or follow me on your favourite microblogging platform (though I don't actually toot/skeet/<del>tweet</del> about tech all that much).</p>

<hr>
<p>
		<b>Previous Post:</b> <a href="https://wuffs.org/blog/free-software-needs-to-be-customisable">Free Software that you can't customise is not truly Free Software</a>
	<br>
	
	</p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to draw an outline in a video game (409 pts)]]></title>
            <link>https://ameye.dev/notes/rendering-outlines/</link>
            <guid>42593614</guid>
            <pubDate>Sat, 04 Jan 2025 09:14:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ameye.dev/notes/rendering-outlines/">https://ameye.dev/notes/rendering-outlines/</a>, See on <a href="https://news.ycombinator.com/item?id=42593614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Different techniques for rendering outlines in Unity.</p><p><b>21</b> minute read</p><h2 id="introduction" tabindex="-1"><a href="#introduction" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Introduction</h2><p>Rendering outlines is a technique that is often used in games either for <mark>aesthetic</mark> reasons or for supporting <mark>gameplay</mark> by using it for highlights and selections around an object. For example in the game Sable, outlines are used to create a comic-book-like style. In The Last of Us, outlines are used to highlight enemies when the player goes into stealth mode.</p><p>In this post, I will discuss 5 techniques for rendering an outline around an object.</p><blockquote><p>🖍️ Interested in an outline rendering toolkit for Unity? 3 years after making this post <a href="https://assetstore.unity.com/packages/slug/294140?aid=1011l3n8v&amp;pubref=site" target="_blank" rel="noopener noreferrer">I made Linework</a>!</p></blockquote><h2 id="rim-effects" tabindex="-1"><a href="#rim-effects" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Rim Effects</h2><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-1907w.webp 1907w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Rim effect outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-400w.jpeg" width="1907" height="748" srcset="https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/rim-effect/final.png-1907w.jpeg 1907w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><h3 id="technique" tabindex="-1"><a href="#technique" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Technique</h3><p>One of the most basic outline effects can be achieved by using a so called <mark>fresnel effect</mark> which can be used to render an outline on the rim/edge of an object. The fresnel effect describes the reflection/transmission of light when falling onto a transparent surface. However, when using it for rendering outlines, this physical meaning of the effect is not important. The following formula is used to form the outline.</p><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>p</mi><mi>o</mi><mi>w</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mn>1.0</mn><mo>−</mo><mi>s</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>t</mi><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Out = pow((1.0 - saturate(dot(N, V))), P)</annotation></semantics></math></span></span></span></p><p>The formula takes the dot product between the normalized normal vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> and the normalized view direction <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span></span>. Then, this gets exponentiated with a power <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span></span>. It is important to note that this is only an approximation of the fresnel effect, but it works well for our outlines.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-1893w.webp 1893w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Fresnel effect." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-400w.jpeg" width="1893" height="748" srcset="https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/rim-effect/fresnel.png-1893w.jpeg 1893w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>When putting this fresnel-based outline on a sphere, you see that when we approach the grazing angle (the edge/rim of the object), the effect gets stronger.</p><h3 id="implementation" tabindex="-1"><a href="#implementation" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Implementation</h3><p>For this approach, the objects that need to have an outline get rendered using a custom shader. This shader implements the fresnel effect and allows us to set the width, power, softness and color of the outline.</p><pre><code><span>float</span> edge1 <span>=</span> <span>1</span> <span>-</span> _OutlineWidth<span>;</span>
<span>float</span> edge2 <span>=</span> edge1 <span>+</span> _OutlineSoftness<span>;</span>
<span>float</span> fresnel <span>=</span> <span>pow</span><span>(</span><span>1.0</span> <span>-</span> <span>saturate</span><span>(</span><span>dot</span><span>(</span>normalWS<span>,</span> viewWS<span>)</span><span>)</span><span>,</span> _OutlinePower<span>)</span><span>;</span>
<span>return</span> <span>lerp</span><span>(</span><span>1</span><span>,</span> <span>smoothstep</span><span>(</span>edge1<span>,</span> edge2<span>,</span> fresnel<span>)</span><span>,</span> <span>step</span><span>(</span><span>0</span><span>,</span> edge1<span>)</span><span>)</span> <span>*</span> _OutlineColor<span>;</span></code></pre><p>The technique produces an outline that is always an <mark>inner line</mark> and is not visible outside of the object and so maybe shouldn't even be called an outline. By controlling the width, power and softness of the outline, it is possible to create hard lines or a more soft/glowy effect.</p><p>Characteristic for this approach is that it works well for objects like spheres and capsules with smooth and round edges, but it breaks down for objects like cubes or more complex models that have sharp edges.</p><p>For a cube for example, the outline will look really bad and not even resemble an outline. For a more complex model, you will have the issue of getting lots of uneven line widths, although the overall outline effect can look alright.</p><blockquote><p><strong>💬 Rim effect</strong> outlines are simple but only work well on spherical objects.</p></blockquote><h2 id="vertex-extrusion" tabindex="-1"><a href="#vertex-extrusion" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Vertex Extrusion</h2><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-4148w.webp 4148w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Vertex extrusion outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-400w.jpeg" width="4148" height="1648" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/final.png-4148w.jpeg 4148w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><h3 id="technique-1" tabindex="-1"><a href="#technique-1" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Technique</h3><p>The second technique uses a <mark>re-rendered/duplicate</mark> version of the original object/mesh to form the outline. This duplicate object gets shown <mark>behind</mark> the original object and its vertices get extruded in order to make the duplicate object larger than the original one. The duplicate object is usually just rendered with a flat color.</p><h3 id="extrusion-direction" tabindex="-1"><a href="#extrusion-direction" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Extrusion direction</h3><p>In order to make the duplicate mesh larger, we need to change the positions of its vertices. We will be moving the vertices a certain <mark>distance</mark> along a certain <mark>direction</mark>. The first step is to pick this direction.</p><h4>1. Vertex position</h4><p>The <mark>first method</mark> to enlarge the mesh is to simply scale it up. This is done by moving each vertex position along the vertex position. This may sound weird but the vertex position in local space, can be seen as a vector between the center of the object and the vertex position itself and so we can move the original vertex position along that vector. For the distance, we use a width parameter.</p><pre><code><span>// Move vertex along vertex position in object space.</span>
positionOS <span>+=</span> positionOS <span>*</span> width<span>;</span></code></pre><p>Doing this just kind of inflates the mesh.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-1904w.webp 1904w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Move along vertex position in object space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-400w.jpeg" width="1904" height="855" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-vertex-position.png-1904w.jpeg 1904w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>For a sphere, all of the vertices have the same distance from the center point of the object and so they all get moved an equal amount. However, for other objects, these distances may vary and so vertices that are distanced further away from the center of the object, will get moved more. To fix this, you can normalize the vector along which the movement occurs.</p><pre><code><span>// Move vertex along normalized vertex position in object space.</span>
positionOS <span>+=</span> <span>normalize</span><span>(</span>positionOS<span>)</span> <span>*</span> width<span>;</span></code></pre><p>The result is that now all the vertices get moved an equal distance in object space, usually resulting in an outline that looks more equal-width.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-1909w.webp 1909w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Move along normalized vertex position in object space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-400w.jpeg" width="1909" height="860" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normalized-vertex-position.png-1909w.jpeg 1909w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>However, due to working in object space, the outline still isn't a perfect equal-width outline. We will address this later.</p><h4>2. Normal vector</h4><p>A <mark>second method</mark> is to move the vertices along their normal vector.</p><pre><code><span>// Move vertex along normal vector in object space.</span>
positionOS <span>+=</span> normalOS <span>*</span> width<span>;</span></code></pre><p>The result is a pretty nice-looking outline for objects with smooth corners such as spheres and capsules. We're still working in object space so again, the outline isn't a perfect equal-width outline.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-1909w.webp 1909w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Move along normal vector in object space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-400w.jpeg" width="1909" height="860" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/object-space-normal-vector.png-1909w.jpeg 1909w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>For objects with sharper corners such as cubes, you will get visible gaps in the outline. Any model with sharp angles will have these kind of artifacts.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-1012w.webp 1012w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Outline gaps on objects with sharp corners." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-400w.jpeg" width="1012" height="938" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/exploded-cube.png-1012w.jpeg 1012w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>This can be resolved by using custom-authored normals, addressed in the next method.</p><h4>3. Vertex color</h4><p>A <mark>third method</mark> is to move the vertices along their vertex color. The logic behind this is that you can generate custom normals and store those in the vertex color channels of the mesh. For example you could bake spherical (smooth) normals into vertex colors and use those for a cube mesh.</p><pre><code><span>// Move vertex along normal vector in object space.</span>
positionOS <span>+=</span> vertexColor <span>*</span> width<span>;</span></code></pre><p>You can see the the outline around the cube looks much better when using custom normals.</p><p>This method can avoid artifacts with models that have sharp edges but the big downside is the manual setup involved since you need to generate custom normals for your mesh, although this process can be automated using a script that bakes the normals.</p><h3 id="extrusion-space" tabindex="-1"><a href="#extrusion-space" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Extrusion space</h3><p>Once we have decided the direction along which we want to move the vertices, we need to choose in which coordinate space this extrusion should happen. During the vertex stage of our shader, the coordinates of the vertices start out being defined in object space and end up being transformed to clip space. This is done by applying the <mark>MVP (model/view/projection) matrix</mark>. Throughout the whole rendering pipeline, the coordinates of the vertices go through these spaces.</p><blockquote><p><strong>1.</strong> 📦 object/model/local space</p></blockquote><blockquote><p><strong>2.</strong> 🌍 world space</p></blockquote><blockquote><p><strong>3.</strong> 📷 camera/eye/view space</p></blockquote><blockquote><p><strong>4.</strong> ✂️ (homogeneous) clip space</p></blockquote><blockquote><p><strong>5.</strong> 🖥️ screen space</p></blockquote><blockquote><p><strong>6.</strong> 🖼️ viewport/window space</p></blockquote><p>The significance of these coordinate spaces for our outlines will be explained below.</p><h4>Object space</h4><p>The <mark>first method</mark> is to translate the vertices in object space.</p><pre><code><span>// Move vertex along vertex position in object space.</span>
IN<span>.</span>positionOS<span>.</span>xyz <span>+=</span> IN<span>.</span>positionOS<span>.</span>xyz <span>*</span> width<span>;</span></code></pre><p>There are 2 big issues with doing the outline in object space. This is because when working in object space, the MVP transformations are yet to be applied. These transformations will alter the shape of the outline, distorting it in the process. The issues are as follows:</p><ol><li><p><mark>Scaling</mark> of the outline</p><p>-&gt; when going from object space to world space (applying model matrix M)</p></li><li><p><mark>Foreshortening</mark></p><p>-&gt; due to the perspective divide happening when going from clip space to screen space</p></li></ol><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-871w.webp 871w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-400w.jpeg" width="871" height="721" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/foreshortening.png-871w.jpeg 871w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>Another consideration is that when translating the vertices in object space, this is done in a 3D space. This means that some translations will be done directly towards or away from the camera, not contributing to the apparent-width of the outline. Instead of using object-space units, it might be better to be able to control the outline width in terms of screen-space pixels.</p><h4>Clip space</h4><p>A <mark>second method</mark> is to perform the translations of the vertices in clip space.</p><pre><code><span>// Transform vertex from object space to clip space.</span>
OUT<span>.</span>positionHCS <span>=</span> <span>TransformObjectToHClip</span><span>(</span>IN<span>.</span>positionOS<span>.</span>xyz<span>)</span><span>;</span>

<span>// Transform normal vector from object space to clip space.</span>
<span>float3</span> normalHCS <span>=</span> <span>mul</span><span>(</span><span>(</span><span>float3x3</span><span>)</span>UNITY_MATRIX_VP<span>,</span> <span>mul</span><span>(</span><span>(</span><span>float3x3</span><span>)</span>UNITY_MATRIX_M<span>,</span> IN<span>.</span>normalOS<span>)</span><span>)</span><span>;</span>

<span>// Move vertex along normal vector in clip space.</span>
OUT<span>.</span>positionHCS<span>.</span>xy <span>+=</span> <span>normalize</span><span>(</span>normalHCS<span>.</span>xy<span>)</span> <span>/</span> _ScreenParams<span>.</span>xy <span>*</span> OUT<span>.</span>positionHCS<span>.</span>w <span>*</span> width <span>*</span> <span>2</span><span>;</span></code></pre><p>As a first step, the vertex position and normal vector are both transformed from <mark>object space to clip space</mark>. As a second step, the vertex gets translated along its normal vector. Since we are working in a 2D space now, <mark>only the x and y</mark> coordinates of the vertex positions get altered. The offset gets divided by the width and height of the screen to account for the <mark>aspect ratio</mark> of the screen. Then, the offset gets multiplied by the w component of the clip space vertex position. This is done because in the next stage, the clip space coordinates will be converted to screen space coordinates with a so-called <mark>perspective divide</mark> which will divide the clip space x/y/z coordinates by the clip space w coordinate. Since we want to end up with the same outline after this transformation to screen space, we pre-multiply by this clip space w coordinate so that the perspective divide will have no net effect on the outline. Finally, the offset gets multiplied by our desired outline width and a factor 2 so that a width unit 1 will correspond with exactly 1 pixel on the screen.</p><p><em>Phew!</em></p><p>I recommend reading this post on <a href="https://www.videopoetics.com/tutorials/pixel-perfect-outline-shaders-unity/#working-in-clip-space" target="_blank" rel="noopener noreferrer">creating an outline in clip space</a>. Having something explained in different ways is always useful.</p><p>The result of this whole process is a very clean outline. Since we're working in clip space, the outline is equal-width, extending the same amount (visually) around the object.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-1908w.webp 1908w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Move along normal vector in clip space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-400w.jpeg" width="1908" height="700" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector.png-1908w.jpeg 1908w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>Still, (if not using custom-authored normals) the method has issues with meshes that have sharp-corners, resulting in gaps in the outline. This will be apparent in meshes that are more complex. Also, if the normals of the mesh are not set up correctly and some of them are facing the wrong way, the vertices of the outline will be moved in the opposite direction, resulting in gaps in the outline. This method being dependent on the normal vectors of the mesh is the most important downside. This is visible for the mesh in the image below.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-1901w.webp 1901w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Move along normal vector in clip space." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-400w.jpeg" width="1901" height="819" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/clip-space-normal-vector-complex-model.png-1901w.jpeg 1901w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><h3 id="masking" tabindex="-1"><a href="#masking" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Masking</h3><p>The duplicate mesh should be rendered so that only the outline sticking out is visible. The most common solution for this is to <mark>cull the front-facing geometry</mark> of the duplicated mesh, using the backfaces of the geometry to form the outline. A depth test of <mark>less than or equal to</mark> is used to make sure the backfaces only show up where the outlines should go.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-1200w.webp 1200w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Cull front." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-400w.jpeg" width="1200" height="1750" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/cull-front.png-1200w.jpeg 1200w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>Another option is to use a <mark>stencil mask</mark> to prevent the duplicate mesh from showing up in front of the original mesh. When using this stencil mask method, no culling is needed. One side-effect is that there will be absolutely <mark>no inner lines</mark> on the inside of the object and if two objects overlap, the outline will also only be visible around those 2 objects.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-1200w.webp 1200w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Stencil mask." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-400w.jpeg" width="1200" height="1750" srcset="https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/vertex-extrusion/stencil-mask.png-1200w.jpeg 1200w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><blockquote><p><strong>💬 Vertex extrusion</strong> outlines are simple and look good when done in clip space. There are issues with sharp corners but these can be mitigated by using custom normals, which do require some extra setup.</p></blockquote><h2 id="blurred-buffer" tabindex="-1"><a href="#blurred-buffer" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Blurred Buffer</h2><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-1907w.webp 1907w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-400w.jpeg" width="1907" height="675" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/final.png-1907w.jpeg 1907w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><h3 id="technique-2" tabindex="-1"><a href="#technique-2" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Technique</h3><p>A third method to render an outline is by using something that I call a <mark>blurred buffer</mark>. For this technique, the silhouette of an object gets rendered to a buffer. This silhouette buffer is then blurred which expands the silhouette which is then used to render the outline.</p><h3 id="1.-silhouette-buffer" tabindex="-1"><a href="#1.-silhouette-buffer" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>1. Silhouette Buffer</h3><p>The first step of this technique is creating the silhouette buffer. For this, each object gets rendered to a texture using a shader that outputs a plain color.</p><p>You can use the color white for all silhouettes, allowing you to choose a single color for all outlines at the end by multiplying with the desired outline color. Alternatively, you can render each object silhouette with a specific color if you want each object to have a different colored outline.</p><h3 id="2.-blur-pass" tabindex="-1"><a href="#2.-blur-pass" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>2. Blur Pass</h3><p>The blur pass is used for expanding the silhouette buffer. This is usually done using a box blur or gaussian blur. To improve performance, the silhouette buffer can be <mark>scaled down</mark> before blurring. This is advantageous because blur passes can be expensive, having to process multiple pixels per pixel since they work by taking a (weighted) average of the pixels surrounding a given pixel.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-1920w.webp 1920w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-400w.jpeg" width="1920" height="1080" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/downscale.png-1920w.jpeg 1920w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>Additionally, the blur pass should be done in <mark>2 passes</mark>. This brings down the complexity of the algorithm from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>2</mn><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(2N)</annotation></semantics></math></span></span>. This can be done if the used blur algorithm is a so-called <a href="https://en.wikipedia.org/wiki/Separable_filter" target="_blank" rel="noopener noreferrer">separable filter</a> which is the case both for a box blur and a gaussian blur. When doing the blur in 2 passes, the pixels get first blurred vertically, and then the vertically-blurred buffer gets blurred horizontally resulting in the final blur.</p><p>A simple seperable box blur can be implemented by taking the non-weighted average around a given pixel. For a gaussian blur, the used kernel will be a gaussian kernel so that the weighted-average will be taken.</p><pre><code><span>// Vertical box blur.</span>
<span>half4</span> sum <span>=</span> <span>0</span><span>;</span>
<span>int</span> samples <span>=</span> <span>2</span> <span>*</span> _KernelSize <span>+</span> <span>1</span><span>;</span>
<span>for</span> <span>(</span><span>float</span> y <span>=</span> <span>0</span><span>;</span> y <span>&lt;</span> samples<span>;</span> y<span>++</span><span>)</span>
<span>{</span>
    <span>float2</span> offset <span>=</span> <span>float2</span><span>(</span><span>0</span><span>,</span> y <span>-</span> _KernelSize<span>)</span><span>;</span>
    sum <span>+=</span> <span>SAMPLE_TEXTURE2D</span><span>(</span>_MainTex<span>,</span> sampler_MainTex<span>,</span> IN<span>.</span>uv <span>+</span> offset <span>*</span> _MainTex_TexelSize<span>.</span>xy<span>)</span><span>;</span>
<span>}</span>
<span>return</span> sum <span>/</span> samples<span>;</span>

<span>// Horizontal box blur.</span>
<span>half4</span> sum <span>=</span> <span>0</span><span>;</span>
<span>int</span> samples <span>=</span> <span>2</span> <span>*</span> _KernelSize <span>+</span> <span>1</span><span>;</span>
<span>for</span> <span>(</span><span>float</span> x <span>=</span> <span>0</span><span>;</span> x <span>&lt;</span> samples<span>;</span> x<span>++</span><span>)</span>
<span>{</span>
    <span>float2</span> offset <span>=</span> <span>float2</span><span>(</span>x <span>-</span> _KernelSize<span>,</span> <span>0</span><span>)</span><span>;</span>
    sum <span>+=</span> <span>SAMPLE_TEXTURE2D</span><span>(</span>_MainTex<span>,</span> sampler_MainTex<span>,</span> IN<span>.</span>uv <span>+</span> offset <span>*</span> _MainTex_TexelSize<span>.</span>xy<span>)</span><span>;</span>
<span>}</span>
<span>return</span> sum <span>/</span> samples<span>;</span></code></pre><p>The outline width is controlled by the _KernelSize parameter of the blur shader.</p><h3 id="3.-outline-pass" tabindex="-1"><a href="#3.-outline-pass" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>3. Outline Pass</h3><p>After the blur pass, the blurred silhouette gets combined with the original scene to form the outline.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-1920w.webp 1920w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-400w.jpeg" width="1920" height="1080" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-only.png-1920w.jpeg 1920w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><p>Using a blurred buffer is great for having soft or glowing outlines, but the buffer can also be stepped to render a hard outline.</p><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-1904w.webp 1904w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Blurred buffer outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-400w.jpeg" width="1904" height="547" srcset="https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/blurred-buffer/outline-result.png-1904w.jpeg 1904w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><h3 id="masking-1" tabindex="-1"><a href="#masking-1" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Masking</h3><p>Just like for the vertex extrusion method, a stencil mask can be used to make sure the outline only gets rendered behind the geometry.</p><blockquote><p><strong>💬 Blurred buffer</strong> outlines are great for soft and glowy outlines but can have a bigger impact on performance compared to other methods.</p></blockquote><h2 id="jump-flood-algorithm" tabindex="-1"><a href="#jump-flood-algorithm" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Jump Flood Algorithm</h2><p>The fourth method is to use the <mark>Jump Flood algorithm</mark> to render outlines. The main advantage of this technique is that it can render really wide outlines, at a very reasonable performance cost. I won't go into details at this time since the technique has a good explanation in this <a href="https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9" target="_blank" rel="noopener noreferrer">article from Ben Golus</a>.</p><video width="50%" title="Two-pass box blur effect." loop="" autoplay="" playsinline="" muted="true"><source src="https://ameye.dev/notes/rendering-outlines/jump-flood/jump-flood.mp4" type="video/mp4"></video><blockquote><p><strong>💬 Jump flood</strong> outlines are a great option when you need performant, wide outlines.</p></blockquote><h2 id="edge-detection" tabindex="-1"><a href="#edge-detection" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Edge Detection</h2><p><picture><source type="image/webp" srcset="https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-400w.webp 400w, https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-800w.webp 800w, https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-1200w.webp 1200w, https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-1903w.webp 1903w" sizes="(min-width: 30em) 50vw, 100vw"><img alt="Edge detection outline." loading="lazy" decoding="async" src="https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-400w.jpeg" width="1903" height="562" srcset="https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-400w.jpeg 400w, https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-800w.jpeg 800w, https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-1200w.jpeg 1200w, https://ameye.dev/notes/rendering-outlines/edge-detection/final.png-1903w.jpeg 1903w" sizes="(min-width: 30em) 50vw, 100vw"></picture></p><h3 id="technique-3" tabindex="-1"><a href="#technique-3" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Technique</h3><p>A fifth method is to use an edge-detection pass for rendering outlines. This full-screen pass draws lines by <mark>detecting discontinuities</mark> in the scene and rendering an outline between areas that have a large enough discontinuity between them. Discontinuities can be detected between the depth buffer value, the normal vector, the albedo color or any other data that is made available.</p><h3 id="detection-of-discontinuity" tabindex="-1"><a href="#detection-of-discontinuity" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Detection of discontinuity</h3><h4>Roberts cross</h4><p>Detecting discontinuities can be done by using an edge detection operator such as the <a href="https://en.wikipedia.org/wiki/Roberts_cross" target="_blank" rel="noopener noreferrer">Roberts cross operator</a>. This operator works as a differential operator by calculating the sum of the squares of the differences between diagonal pixels resulting in a cross-like pattern. In practice, edge detection operators can be applied by convolving the original image with kernels. There are 2 kernels, one for the x direction and one for the y direction. For Roberts cross, the diagonal pixels get sampled and convolved with these kernels. The kernels have a size of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>x</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">2x2</annotation></semantics></math></span></span>.</p><pre><code><span>static</span> <span>const</span> <span>int</span> RobertsCrossX<span>[</span><span>4</span><span>]</span> <span>=</span> <span>{</span>
    <span>1</span><span>,</span> <span>0</span><span>,</span>
    <span>0</span><span>,</span> <span>-</span><span>1</span>
<span>}</span><span>;</span>

<span>static</span> <span>const</span> <span>int</span> RobertsCrossY<span>[</span><span>4</span><span>]</span> <span>=</span> <span>{</span>
    <span>0</span><span>,</span> <span>1</span><span>,</span>
    <span>-</span><span>1</span><span>,</span> <span>0</span>
<span>}</span><span>;</span></code></pre><p>These kernels can then be used as follows.</p><pre><code>horizontal <span>+=</span> samples<span>[</span><span>0</span><span>]</span> <span>*</span> RobertsCrossX<span>[</span><span>0</span><span>]</span><span>;</span> <span>// top left (factor +1)</span>
horizontal <span>+=</span> samples<span>[</span><span>3</span><span>]</span> <span>*</span> RobertsCrossX<span>[</span><span>3</span><span>]</span><span>;</span> <span>// bottom right (factor -1)</span>

vertical <span>+=</span> samples<span>[</span><span>2</span><span>]</span> <span>*</span> RobertsCrossY<span>[</span><span>2</span><span>]</span><span>;</span> <span>// bottom left (factor -1)</span>
vertical <span>+=</span> samples<span>[</span><span>1</span><span>]</span> <span>*</span> RobertsCrossY<span>[</span><span>1</span><span>]</span><span>;</span> <span>// top right (factor +1)</span>

edge <span>=</span>  <span>sqrt</span><span>(</span><span>dot</span><span>(</span>horizontal<span>,</span> horizontal<span>)</span> <span>+</span> <span>dot</span><span>(</span>vertical<span>,</span> vertical<span>)</span><span>)</span><span>;</span></code></pre><p>Roberts cross is a very simple operator but can already give nice results. The operator only needs 4 samples around a given pixel.</p><h4>Sobel operator</h4><p>Another method is to use a <a href="https://en.wikipedia.org/wiki/Sobel_operator" target="_blank" rel="noopener noreferrer">Sobel operator</a>. Again, 2 kernels are used but this time the kernels have a size of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>x</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">3x3</annotation></semantics></math></span></span>.</p><pre><code><span>static</span> <span>const</span> <span>int</span> SobelX<span>[</span><span>9</span><span>]</span> <span>=</span> <span>{</span>
    <span>1</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span>
    <span>2</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>2</span><span>,</span>
    <span>1</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span>
<span>}</span><span>;</span>

<span>static</span> <span>const</span> <span>int</span> SobelY<span>[</span><span>9</span><span>]</span> <span>=</span> <span>{</span>
    <span>1</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>,</span>
    <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span>
    <span>-</span><span>1</span><span>,</span> <span>-</span><span>2</span><span>,</span> <span>-</span><span>1</span>
<span>}</span><span>;</span></code></pre><p>This time, 9 samples are used around a given pixel. The Sobel kernels can be used like this.</p><pre><code>horizontal <span>+=</span> samples<span>[</span><span>0</span><span>]</span> <span>*</span> SobelX<span>[</span><span>0</span><span>]</span><span>;</span> <span>// top left (factor +1)</span>
horizontal <span>+=</span> samples<span>[</span><span>2</span><span>]</span> <span>*</span> SobelX<span>[</span><span>2</span><span>]</span><span>;</span> <span>// top right (factor -1)</span>
horizontal <span>+=</span> samples<span>[</span><span>3</span><span>]</span> <span>*</span> SobelX<span>[</span><span>3</span><span>]</span><span>;</span> <span>// center left (factor +2)</span>
horizontal <span>+=</span> samples<span>[</span><span>4</span><span>]</span> <span>*</span> SobelX<span>[</span><span>4</span><span>]</span><span>;</span> <span>// center right (factor -2)</span>
horizontal <span>+=</span> samples<span>[</span><span>5</span><span>]</span> <span>*</span> SobelX<span>[</span><span>5</span><span>]</span><span>;</span> <span>// bottom left (factor +1)</span>
horizontal <span>+=</span> samples<span>[</span><span>7</span><span>]</span> <span>*</span> SobelX<span>[</span><span>7</span><span>]</span><span>;</span> <span>// bottom right (factor -1)</span>

vertical <span>+=</span> samples<span>[</span><span>0</span><span>]</span> <span>*</span> SobelY<span>[</span><span>0</span><span>]</span><span>;</span> <span>// top left (factor +1)</span>
vertical <span>+=</span> samples<span>[</span><span>1</span><span>]</span> <span>*</span> SobelY<span>[</span><span>1</span><span>]</span><span>;</span> <span>// top center (factor +2)</span>
vertical <span>+=</span> samples<span>[</span><span>2</span><span>]</span> <span>*</span> SobelY<span>[</span><span>2</span><span>]</span><span>;</span> <span>// top right (factor +1)</span>
vertical <span>+=</span> samples<span>[</span><span>5</span><span>]</span> <span>*</span> SobelY<span>[</span><span>5</span><span>]</span><span>;</span> <span>// bottom left (factor -1)</span>
vertical <span>+=</span> samples<span>[</span><span>6</span><span>]</span> <span>*</span> SobelY<span>[</span><span>6</span><span>]</span><span>;</span> <span>// bottom center (factor -2)</span>
vertical <span>+=</span> samples<span>[</span><span>7</span><span>]</span> <span>*</span> SobelY<span>[</span><span>7</span><span>]</span><span>;</span> <span>// bottom right (factor -1)</span>

edge <span>=</span> <span>sqrt</span><span>(</span><span>dot</span><span>(</span>horizontal<span>,</span> horizontal<span>)</span> <span>+</span> <span>dot</span><span>(</span>vertical<span>,</span> vertical<span>)</span><span>)</span><span>;</span></code></pre><p>You can read this <a href="https://jameshfisher.com/2020/08/31/edge-detection-with-sobel-filters/" target="_blank" rel="noopener noreferrer">blog post on Sobel filters</a> if you want to learn more about how Sobel filters work.</p><h3 id="sources-of-discontinuity" tabindex="-1"><a href="#sources-of-discontinuity" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Sources of discontinuity</h3><p>A common approach is to look for discontinuities in the textures that the render pipeline generates for the scene such as the depth texture, normals texture and color texture.</p><p>During the edge-detection pass, these textures are sampled and discontinuities are detected using the edge detection operators mentioned earlier. The resulting edge that is drawn can be caused by any discontinuity that was found in one of the 3 buffers. With this technique, the outline gets applied to all the objects that write to these buffers and so you have less control over the outlines on a per-object basis. In the image below, edge contributions by <mark>depth/normals/color</mark> are represented by the color red/green/blue respectively.</p><p>Allowing discontinuities to be detected from different sources makes for a more robust outlining system. In the debug image above you can see that while some edges would be detected by all three discontinuity sources, a lot of them only get picked up from a contribution of a specific discontinuity source. Each discontinuity source can be given a different weight and different thresholds can be used for each of them, allowing you to control the visual of the outline.</p><h3 id="edge-detection-modulation" tabindex="-1"><a href="#edge-detection-modulation" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Edge detection modulation</h3><p>Usually, just using an edge detection operator on the discontinuity source buffers is not enough to get a result without artifacts. Some <mark>modulation</mark> has to be done to get rid of these artifacts. For example, since the depth buffer is <a href="https://developer.nvidia.com/content/depth-precision-visualized" target="_blank" rel="noopener noreferrer">implemented non-linearly</a> in a lot of render pipelines, two objects 1m apart located close to the camera will have a larger depth difference than two objects 1m apart located far away from the camera. To accommodate for this, the threshold used for detecting discontinuities in depth can be modulated by the depth buffer itself so that geometry located close to the camera will need to have a larger discontinuity in depth value before being detected as an edge.</p><pre><code>depthThreshold <span>*=</span> _DepthDistanceModulation <span>*</span> <span>SampleSceneDepth</span><span>(</span>uv<span>)</span><span>;</span></code></pre><p>A second common artifact is unwanted edges showing up on objects at small <a href="https://en.wikipedia.org/wiki/Angle_of_incidence_(optics)#Grazing_angle_or_glancing_angle" target="_blank" rel="noopener noreferrer">grazing angles</a>. To resolve this, you can modulate with a mask that is generated from the dot product between the normal vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> and the view direction <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span></span>. This is the same fresnel mask that was used in the initial outlining technique using a rim effect.</p><pre><code><span>float</span> fresnel <span>=</span> <span>pow</span><span>(</span><span>1.0</span> <span>-</span> <span>saturate</span><span>(</span><span>dot</span><span>(</span>normalWS<span>,</span> viewWS<span>)</span><span>)</span><span>,</span> _Power<span>)</span><span>;</span>
<span>float</span> grazingAngleMask <span>=</span> <span>saturate</span><span>(</span><span>(</span>fresnel <span>+</span> _GrazingAngleMaskPower <span>-</span> <span>1</span><span>)</span> <span>/</span> _GrazingAngleMaskPower<span>)</span><span>;</span>
depthThreshold <span>*=</span> <span>1</span> <span>+</span> <span>smoothstep</span><span>(</span><span>0</span><span>,</span> <span>1</span> <span>-</span> _GrazingAngleMaskHardness<span>,</span> grazingAngleMask<span>)</span><span>;</span></code></pre><p>Other modulation techniques can be used, depending on the visual fidelity you want to achieve but these depend on the specific effect that you're after.</p><h3 id="custom-discontinuity-source" tabindex="-1"><a href="#custom-discontinuity-source" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Custom discontinuity source</h3><p>It is also possible to provide the outline shader with a custom discontinuity source. This would be a render texture that you create yourself during the render process, containing custom data that you wish to use to generate outlines. The advantage is that since you control what writes to this custom buffer, you can control which objects receive an outline.</p><p>For example in the scene above, the discontinuity source is generated by rendering the vertex colors of a mesh to a texture. Other techniques that come to mind are coloring faces based on their world position or creating a custom buffer that combines both information from the depth buffer and the normals buffer.</p><blockquote><p>💡 Want more info? Check out <a href="https://linework.ameye.dev/section-map" target="_blank" rel="noopener noreferrer">https://linework.ameye.dev/section-map</a>.</p></blockquote><blockquote><p><strong>💬 Edge detection</strong> outlines are good when you need a full-screen outlining effect. Some finetuning is needed to prevent lines from showing up where you don't want them to.</p></blockquote><h2 id="conclusion" tabindex="-1"><a href="#conclusion" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Conclusion</h2><p>There you go, 5 ways to draw an outline. They all have their benefits, making trade-offs between performance, visual fidelity and manual setup that is required.</p><h2 id="credits" tabindex="-1"><a href="#credits" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Credits</h2><blockquote><p><strong>💬</strong> The Sailor Moon 3D models used in this post were made by <em>premudraya</em> over on Sketchfab.</p></blockquote><blockquote><p><strong>💬</strong> The Zelda 3D model used in this post was made by <em>theStoff</em> over on Sketchfab.</p></blockquote><h2 id="additional-resources" tabindex="-1"><a href="#additional-resources" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Additional Resources</h2><h3 id="vertex-extrusion" tabindex="-1"><a href="#vertex-extrusion" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Vertex Extrusion</h3><p><a href="https://www.videopoetics.com/tutorials/pixel-perfect-outline-shaders-unity/#working-in-clip-space" target="_blank" rel="noopener noreferrer">https://www.videopoetics.com/tutorials/pixel-perfect-outline-shaders-unity</a></p><h3 id="jump-flood-algorithm" tabindex="-1"><a href="#jump-flood-algorithm" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Jump Flood Algorithm</h3><p><a href="https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9" target="_blank" rel="noopener noreferrer">https://bgolus.medium.com/the-quest-for-very-wide-outlines-ba82ed442cd9</a></p><h3 id="edge-detection" tabindex="-1"><a href="#edge-detection" target="_blank" rel="noopener noreferrer"><span>Jump to heading</span>  </a>Edge Detection</h3><p><a href="https://roystan.net/articles/outline-shader.html" target="_blank" rel="noopener noreferrer">https://roystan.net/articles/outline-shader.html</a></p><p><a href="https://jameshfisher.com/2020/08/31/edge-detection-with-sobel-filters/" target="_blank" rel="noopener noreferrer">https://jameshfisher.com/2020/08/31/edge-detection-with-sobel-filters</a></p><p>Published <time>August 2021</time></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self driving 1993 Volvo with open pilot (517 pts)]]></title>
            <link>https://practicapp.com/carbagepilot-part1/</link>
            <guid>42592910</guid>
            <pubDate>Sat, 04 Jan 2025 06:30:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://practicapp.com/carbagepilot-part1/">https://practicapp.com/carbagepilot-part1/</a>, See on <a href="https://news.ycombinator.com/item?id=42592910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" role="main">
      <article>
 

  <div>
    <p>Together with some friends, I decided earlier this year to particpate in the <a href="https://www.carbagerun.nl/event/winter-editie-2025-naar-helsinki/">Carbage run 2025 Winter edition</a>. This is a 6-day journey in winter all the way through Sweden to the polar circle, and back down to Helsinki in a group of roughly 400 cars.</p>

<p>One small catch (you might have guessed it from the name): your car has to be “carbage”. In practice, this means it needs to be at least 20 years old, and with a day value of less than €1000.</p>

<p><img src="https://practicapp.com/images/carbagerun.jpg" width="350" height="350">
<img src="https://practicapp.com/images/carbagerun_route.jpg" width="350" height="350">
</p>

<p>This route, including the drive to get there and back from Belgium would mean driving roughly 6000km in just over a week, often in less-than-ideal conditions. In addition, our car will also be judged on originality, which is why this idea popped into my head:</p>

<p>
<img src="https://practicapp.com/images/joystick_steer.gif" width="350">
</p>

<p>
<i><b>Why not make it self-driving?</b></i>
</p>

<!--end_excerpt-->

<h2 id="what-how-is-this-even-possible">What?? How is this even possible?</h2>

<p>For those who don’t know: there is this project named <a href="https://github.com/commaai/openpilot">openpilot</a>, developed by <a href="https://comma.ai/">comma.ai</a> which adds L2 advanced driver assistance features (fancy words for partially self driving like Tesla’s Autopilot) to over 275+ supported car models such as <a href="https://comma.ai/vehicles">recent Toyotas, Hondas, Hyundais, VWs, …</a> Hell, there’s even support for Tesla’s Model 3/Y!</p>

<p>The key word here is “recent”, which is to say: the cars that are supportable need to have some electronic way of actuating steering, gas and brakes. This is the case in pretty much all modern cars, since stock ADAS features such as lane keeping assists and adaptive cruise control are more and more prevalent.</p>

<p>In these cases, the actuators are usually implemented in the form of Electric Power Steering (EPS), electric brake boosters / ABS pumps and electronic engine control units. These then accept (reasonable) actuation commands over CAN-bus messages from a camera module or similar, which then can be intercepted and replaced by more appropriate commands for openpilot.</p>

<p>Coincidentally, I’ve been working at comma.ai for about 5 years as a hardware engineer, so I am quite familiar with the inner workings of the whole system. A few years ago, I even gave <a href="https://www.youtube.com/watch?v=FL8CxUSfipM">a talk about controlling cars</a> that goes a bit more in depth.</p>

<p><i>(by the way: <a href="https://comma.ai/jobs">we're hiring!)</a></i></p>

<h2 id="back-to-1993">Back to 1993</h2>

<p>
<img src="https://practicapp.com/images/volvo.jpg" width="700">
</p>

<p>This is the car we bought, sight-unseen at an online auction: a 1993 Volvo 940 Estate. While the state of the paint wouldn’t suggest it, it was actually in surprisingly good condition for a car over 30 years old.</p>

<p>As you can imagine, there are very little electronics in this car: the steering is hydraulic, the accelerator is driven by a cable between the gas pedal and the carburator, and the brake booster is vacuum-based.</p>

<p>Let’s go over these one by one and explain on how we can retrofit the needed actuators:</p>

<h2 id="steering-motor-and-sensor">Steering motor and sensor</h2>
<p>Probably the most important actuator needed for staying on the right track (and the one that turned out to be the most complex to adapt mechanically) is for the steering assist. As mentioned, the Volvo is fitted from the factory with a <a href="https://dsauto.com.my/en/2018/11/27/hydraulic-power-steering-explained/">hydraulically powered assist on the steering rack</a>.</p>

<p>To be able to put torque on the wheel electronically, the most feasible option we found is to retrofit an electric power steering actuator / ECU from a 2020 Toyota Corolla. In the Corolla, this motor is mounted on the steering column behind the dashboard, and amplifies the measured driver torque to the output shaft.</p>

<p>
<img src="https://practicapp.com/images/corolla-rack.jpg" width="700">
<i>The 2020 Corolla steering rack we got from a junkyard</i>
</p>

<p>While the full rack looks quite big, most of it is related to the steering wheel adjustment features, which can be removed for our use-case. To fit it behind the dash, we took out the original straight-axle steering column from the Volvo and fit the EPS inbetween:</p>

<p>
<img src="https://practicapp.com/images/cutting-eps.jpg" width="350">
<img src="https://practicapp.com/images/welding-eps-splines.jpg" width="350">
<i>We cut off as much as we could from the Corolla rack and welded the interfacing splines to the top of the original Volvo column (which we also cut in pieces)</i>
</p>

<p>With the motor now on the column, we added some extra bracing from the original steering frame to the EPS:</p>

<p>
<img src="https://practicapp.com/images/eps-in-frame.jpg" width="700">
</p>

<p>Except for the motor itself, the Corolla also has an exernal steering angle sensor. While the EPS motor has one built-in, it is only used for precise relative angles needed for the inner control loops. The external angle sensor provides it with an absolute angle measurement (zero degrees while the car is moving in a straight line), which is also needed for openpilot’s car controller code.</p>

<p>
<img src="https://practicapp.com/images/machining-angle-sensor-bushing.jpg" width="350">
<img src="https://practicapp.com/images/angle-sensor-installed.jpg" width="350">
<i>Machining a bushing to connect the angle sensor to the steering column shaft, and the sensor installed.</i>
</p>

<p>With both the motor and angle sensors installed in the steering subframe, it can be mounted in the car again. To our surprise, there was enough space under the dash to accomodate all this extra hardware, and no further modifications were necessary to get the dash back in!</p>

<p>
<img src="https://practicapp.com/images/installed-in-car.jpg" width="700">
</p>

<p>I’ll dive into the wiring a bit more in an upcoming blog post, but in summary: hooking up the motor and angle sensor electrically is very straight-forward. Since you can download the schematics and connector references from Toyota for a small fee, it was easy to figure out that the steering rack only needs GND, constant 12V (fused at 80A!), a 12V “ignition” signal and CAN to the angle sensor.</p>

<p>With just that, the EPS springs to life (likely in limp-mode since it’s missing some Toyota-messages it expects with the current car speed, …) and happily works as if it was in its original car.</p>

<h3 id="what-about-the-original-hydraulic-steering-assist-dont-you-have-two-systems-now">What about the original hydraulic steering assist? Don’t you have two systems now?</h3>
<p>Good observation. In short: yes.</p>

<p>While you could just disable the hydraulic power assist and just rely on the new electric one, I fear that the steering rack might not be designed to handle the higher amounts of torque it would constantly receive from the EPS during normal driving and might potentially wear out over time.</p>

<p>The steering works just fine with both systems active (it made the steering nice and light too!), but it’s not ideal. One downside of having both assists active is that the car doesn’t have enough self-centering torque to backdrive both systems and center the steering wheel when you let go of the wheel in a curve; It just stays where you put it.</p>

<p>There might be multiple ways to resolve this, although I have not tried yet. For example, it might be possible to reduce the hydraulic pressure in the system, rendering the original assist less powerful.</p>

<h2 id="brake-booster">Brake booster</h2>

<p>Probably the most effective feature modern cars offer for reducing driver load in long drives is adaptive cruise control. To be able to follow the car in front of you at a safe distance without manual interventions, the car needs to be able to brake automatically.</p>

<p>As you can guess by now: this is not something the 30-year-old Volvo was set up to do from the factory. Originally, the car’s brakes rely on a simple vacuum-assist system to amplify the pressure the driver puts on the brake pedal, which in turn pushes on the master cylinder.</p>

<p>
<img src="https://practicapp.com/images/vacuum-booster.jpg" width="700">
<i>Diagram of a vacuum-assisted braking system (Image source: <a href="https://help.summitracing.com/knowledgebase/article/SR-05293/en-us">Summit Racing</a>)</i>
</p>

<p>Luckily, modern cars still work in a very similar way. In fact, the system used by Tesla for example is based on the Bosch iBooster, which just replaces the vacuum-assist with a force sensor and an electric motor:</p>

<p>
<img src="https://practicapp.com/images/ibooster.png" width="700">
<i>Diagram of the Bosch iBooster (<a href="https://www.researchgate.net/figure/The-mechanical-structure-and-working-principle-of-iBooster_fig4_324194807">Source</a>)</i>
</p>

<p>Unfortunately, it is well-known that these iBoosters are very useful for EV-conversion projects, since this is a way cleaner setup than having to replace the original engine’s vacuum source to get the original booster to work. It’s also widely known that these iBoosters go into limp mode without CAN connected, and thus can be used (without the controllable features) without having to do any complex work.</p>

<p>One of the companies that uses these iBoosters in their conversion projects is EVcreate, located in the Netherlands. They also published multiple awesone blog posts about using the iBoosters, like <a href="https://www.evcreate.com/wiring-the-ibooster/">this one where they show you how to hook it up</a>.</p>

<p>Since their wide use, the iBoosters are quite expensive on the second-hand market (especially compared to the rest of the car!). Since this is the case, I made a deal with Lars from EVcreate where he very generously provided me with an iBooster in exchange for the research required to get them controllable over CAN, outside of their Tesla comfy-zone. Lars, if you’re reading this: thanks again!</p>



<p><i>Here comes the part that blew my mind:</i></p>

<p>After removing the vacuum booster from the Volvo, I fully expected to have to design and weld in an adapter plate to fit it in the car. This couldn’t have been less true! The bolt hole pattern and center alignment hole lined up perfectly, and even the push rod built into the iBooster was approximately the right length to connect back up to the pedal. I say approximately, since we did have to add some 2mm washers to the threaded studs of the iBooster to get the push rod to sit fully extended when the pedal isn’t pressed.</p>

<p>
<img src="https://practicapp.com/images/ibooster-installed.jpg" width="700">
<i>iBooster installed in the Volvo. Looks almost original!</i>
</p>

<p>The orignal brake lines weren’t in the right spot due to the master cylinder on the iBooster having the ports on a different side, but after running new copper brake lines to the small distribution-looking block underneath the cylinder, bleeding the brakes and hooking up power, the brakes work normally!</p>

<p>One minor complication with this retrofit is that the clutch was also operated hydraulically with brake fluid from the same reservoir, so we had to add an small extra tank (the iBooster master cylinder tank doesn’t have a port for this).</p>

<p>
<img src="https://practicapp.com/images/clutch-tank.jpg" width="700">
<i>Small tank with brake fluid for the clutch</i>
</p>

<h2 id="accelerator-servo">Accelerator servo</h2>

<p>Sometimes you also want to go <em>faster</em> instead of <em>slower</em>! Another thing that Volvo implemented purely mechanically.</p>

<p>
<img src="https://practicapp.com/images/bowden-accelerator.jpg" width="700">
<i>The accelerator pedal is connected to the carburator air valve by means of a bowden cable</i>
</p>

<p>This is the only major actuator that I couldn’t easily find a suitable modern automotive solution for. This is mainly because newer cars don’t have carburators anymore, but rather use direct injection and advanced engine control units. Luckily this is also the only actuator that doesn’t come with major safety implications, so let’s just hack something together with off-the-shelf hobby parts!</p>

<p>Standard cruise control logic dictates that the driver can override the applied accelerator position by just pressing harder on the accelerator pedal himself. This is easy enough to implement by just having two cables connected to the air valve pulley: the cable that pulls the furthest wins.</p>

<p>With this in mind, I bought a (surprisingly strong!) waterproof RC servo from AliExpress, and had my Dad machine a second pulley that mounts onto it. After that it was just a matter of cobbling together a mount for the servo, and adding some bronze guide bushings to constrain the loose cables, and we’re in business!</p>

<p>
<img src="https://practicapp.com/images/accelerator.gif" width="700">
<i>Vroom vroom!</i>
</p>

<h2 id="bonus-content">Bonus content!</h2>
<p>While this isn’t an actuator, we also fitted a Tesla Continental radar sensor behind the front grille. While vision-only ACC somewhat works in openpilot, being able to rely on a real radar still makes for a smoother and more consistent experience.</p>

<p>
<img src="https://practicapp.com/images/radar.jpg" width="700">
<i>Ping Ping!</i>
</p>

<h2 id="wow-what-an-amazing-blog-post-when-will-part-2-come-out">Wow what an amazing blog post!!! When will part 2 come out??</h2>
<p>Good question. I’m lazy, so it might take a while.
On the other hand, we’ll have tons of time in the car in a few weeks, so maybe then?</p>

<p>I think part 2 will be about the wiring and the custom ECU I designed to keep the actuators happy, and to implement things like the cruise control buttons, as well as reading out the speed, blinkers, …</p>

<p>After that, I’ll do part 3 explaining (and open sourcing) the code on the ECU and the openpilot port.</p>

<p>After that, who knows! What would you like me to talk about more?</p>


  </div>

  


</article>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[China is the manufacturing superpower (176 pts)]]></title>
            <link>https://cepr.org/voxeu/columns/china-worlds-sole-manufacturing-superpower-line-sketch-rise</link>
            <guid>42592665</guid>
            <pubDate>Sat, 04 Jan 2025 05:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cepr.org/voxeu/columns/china-worlds-sole-manufacturing-superpower-line-sketch-rise">https://cepr.org/voxeu/columns/china-worlds-sole-manufacturing-superpower-line-sketch-rise</a>, See on <a href="https://news.ycombinator.com/item?id=42592665">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
      

      <article>
        
              <div>
                
                  <p>I'm not an expert on China, but during ongoing work on global supply chain disruptions with my co-authors Rebecca Freeman and Angelos Theodorakopoulos, I've noticed a stark fact that I don’t think is as widely known as it should be. China is the now world’s sole manufacturing superpower.</p>

<p>This column uses the OECD’s recently released <a href="https://www.oecd.org/sti/ind/measuring-trade-in-value-added.htm">2023 update</a> of their invaluable TiVA database to show, in eight charts, how this came to be. I will skip the historical Chinese reform narrative as that has been well covered by real China experts (e.g. Wang 2023, World Bank 2013, Ranganathan 2023).</p>

<h2>The world’s big players in manufacturing</h2>

<p>The charts in Figure 1 show two views of global manufacturing shares in 2020 (the latest year in the database). The left panel displays world shares in terms of gross production; in the right panel, the same is shown in terms of value added. The distinction is in intermediate inputs: Chinese gross production equals the total sales of Chinese manufacturers; Chinese value added is their gross production minus the purchased intermediates.</p>

<p><strong>Figure 1</strong> Slicing the global manufacturing pie, 2020, gross production basis</p>

  


<h6><em>Source</em>: OECD TiVA database, 2023 update.</h6>

<p>Six nations manufacture at least 3% of the world total. China is followed by the US, Japan, Germany, India, and South Korea. Note how the world has changed. Only three of these are long-established industrial economies; the other three are newly industrialised economies. Four of the G7 don’t make the cut. The chart separately identifies nations with shares of at least 2%, and on the left, this includes Italy, France, and Taiwan (two of the G7, the UK and Canada, don’t make the cut). In the right panel (value-added basis), the UK makes an appearance with a share just above 2%.</p>

<p>When it comes to gross production, China’s share is three times the US’ share, six times Japan’s, and nine times Germany’s. Taiwan, Mexico, Russia, and Brazil now have higher gross output than the UK. Canada is further down the ranking, in 15th place.&nbsp;</p>

<h2>Unprecedented industrialisation</h2>

<p>China’s industrialisation is unprecedented. The last time the ‘king of the manufacturing hill’ got knocked off the throne was when the US surpassed the UK just before WW1. It took the US the better part of a century to rise to the top; the China-US switch took about 15 or 20 years. China’s industrialisation, in short, defies comparison.</p>

<p>Figure 2 portrays how China dethroned the king of the hill. If we think of this as a 25-lap horserace – one lap per year – all the excitement was in the first 13 laps. Since data only go back to 1995, China started the race a bit ahead of Canada, Britain, France, and Italy. China passed Germany in 1998, Japan in 2005, and the US in 2008. Since then, China has more than doubled its world share while the US’s share has fallen by another three percentage points. If this were a live horserace, boredom would have driven most of the audience away years ago.</p>

<p>The right panel shows that China’s share now exceeds that of the next largest manufacturers combined. This remarkable fact helps us to understand current US-China trade tensions, and the magnitude of supply chain disruptions that occurred when China dialled down its production during Covid. India (not shown separately) was the second fastest share gainer: its global share of manufacturing production rose by two percentage points since 1995.</p>

<p>China’s rise has slowed and looks to have stagnated at about a third of world output. To confirm this, however, we will need more recent data since the last two years in the sample are muddled by events related to the Covid-19 pandemic. The World Bank’s World Development Indicators (WDI) has data to 2022 for value added, and these conform to the flattening narrative, but the WDI do not report gross production data.</p>

<p><strong>Figure 2 </strong>China’s meteoric rise in manufacturing, 1995-2020 (world gross production shares)<sup>
  <a id="footnoteref1_8mxza35" title="Scroll down to this footnote" href="#footnote1_8mxza35" aria-describedby="footnoteref1_8mxza35">1</a>
</sup>
</p>

  


<h6><em>Source</em>: OECD TiVA database, 2023 update.</h6>

<p>China’s dominance is less stark in exports (Figure 3), though the rise is equally amazing. In 1995 China had just 3% of world manufacturing exports, By 2020, its share had risen to 20%. The corresponding fall in the G7 share was less dramatic than for its share of production. This is explained by the meteoric rise in Chinese domestic consumption, which has absorbed an increasing share of its manufacturing production since 2004. Not shown in the charts is that China’s export to production ratio, having peaked at 18% in 2004, is 13% in 2020 – almost back to its 1995 level of 11%. The same diagrams in the Annex are shown for a value-added basis.</p>

<p><strong>Figure 3</strong>&nbsp;China’s share of world manufacturing exports, 1995-2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<h2>Asymmetric supply chain exposure: G7 and China</h2>

<p>The global supply chain indicators that Rebecca Freeman, Angelos Theodorakopoulos and I developed last year (Baldwin et al. 2022) provide a convenient way of identifying foreign production exposure in supply chains (eight of our new indicators can be found in the TiVA 2023 update). Two of our new indicators are particularly intuitive when it comes to portraying global supply chain exposure.</p>

<ul><li><strong>Foreign Production Exposure: iMport side (FPEM). </strong>This shows the share of all industrial inputs (including domestically sourced inputs) that one nation sources from another on a scale of 0 to 100. FPEM accounts for exposure on a look-through basis in the sense that it looks through the suppliers-to-suppliers veil to discover the purchasing nation’s reliance on production in the selling nation.</li>
</ul><p>Figure 4, left panel, shows that the US relies far more on Chinese manufacturing production than vice versa.<sup>
  <a id="footnoteref2_fk48lrp" title="Scroll down to this footnote" href="#footnote2_fk48lrp" aria-describedby="footnoteref2_fk48lrp">2</a>
</sup>
 While shocking at first sight, this should not be unexpected. It is natural that a country with 11% of the world output buys more from a country that produces 35% than vice versa, but the numbers are astounding. China was more exposed to US inputs before 2002, but the US has had greater exposure since then. In 2020, the US was about three times more exposed to Chinese manufacturing production than vice versa.</p>

<ul><li><strong>Foreign Production Exposure: eXport side (FPEX)</strong>. This indicator reflects the share of a nation’s gross output of intermediate goods that is exported to a particular partner. It is a measure of exposure on the sales side.</li>
</ul><p>Figure 4, right panel, shows the expected result: China is and always has been more reliant on sales to the US than the other way round. In the mid-2000s, China’s dependence on the US was ten times the reverse dependence, but the asymmetry has narrowed substantially.</p>

<p>Putting together the pieces, this shows a remarkable, historical, world-shaping asymmetry in supply chain reliance between China and other major manufacturing countries. Politicians may wish to decouple their economies from China. These data suggest that decoupling would be difficult, slow, expensive, and disruptive – especially to G7 manufacturers. For explicit estimates, see the simulation studies by Felbermayr et al. (2023) and Goes and Bekkers (2022).</p>

<p>Before closing this chapter on the China rise story, it is important to say that the massive asymmetry has nothing really to do with China. It has to do with China’s superpower standing in manufacturing. To see this, imagine what the charts would look like if they displayed the facts for OPEC and the G7 in the petroleum sector. We would see that the G7 is massively more dependent on OPEC supplies than vice versa. The next chapter of the story redirects the spotlight to the China level.</p>

<p><strong>Figure 4</strong> China and US bilateral FPEM and FPEX, 1995-2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<h2>China’s balance of trade by sector, supply chain engagement, and openness</h2>

<p>What does the rise to superpower status look like from the shores of China? One convenient, if simplistic, yardstick of a country’s competitive profile is its balance of trade by sector.</p>

<p>The left panel of Figure 5 shows the balance of exports less imports in the major sectors: manufactures, agriculture, mining, and services. The overall trade balance, which is just the sum of the sectoral balances, is shown with the thin black line.&nbsp; The pattern is as clear as it is unsurprising. China is a net exporter of manufactured goods and a net importer of everything else – agriculture goods, mining goods and fuels, and services. Both the positive and negative net balances have been growing quickly. Plainly, China is a big importer and a big exporter. Overall, it ran surpluses in the late 2000s, which then decreased and turned negative in 2018 and 2019 (black line).</p>

<p>The right panel provides important hints about the evolution of China’s manufacturing. It charts the evolution of the country’s net exports of intermediate inputs and final goods. Until the mid-2000s, China was a typical offshore destination: a net importer of intermediate inputs and a net exporter of final goods that embodied the imported inputs. From about 2002, China became a large net exporter of intermediate goods as well as final goods.</p>

<p><strong>Figure 5</strong> Net exports by sector, China, 1995 to 2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<p>Aggregate balance-of-trade numbers like those in Figure 5 can hide the evolution of the constituent parts. Figure 6, which focuses on manufactured goods, shows exports and imports separately. In the left panel, we can observe that China’s engagement with global supply chains was extremely vigorous until the mid-2000s. Imports and exports of industrial parts and components were growing rapidly, and imports and exports were growing in tandem. Afterward that, exports grew faster, and this difference has produced the positive balance in manufactured goods..</p>

<p>The right panel shows a different picture for final manufactured goods. Here, exports have always exceeded imports, with the imbalance growing rapidly in the 2010s.</p>

<p><strong>Figure 6&nbsp;</strong>Trade in intermediates versus final goods, China, 1995 to 2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<p>The next pair of charts shows the change in the sectoral composition of China’s exports.</p>

<p>Figure 7 presents the sectoral shares for 1995 (first year in the database) and 2020. It shows that China has moved from being relatively reliant on simple manufacturing sectors like textiles and clothing to more sophisticated sectors like electronics, basic and fabricated metal products, and chemicals and pharmaceuticals. A telling factoid is that textiles accounted for the biggest share in 1995, but electronics did so in 2020.</p>

<p><strong>Figure 7 </strong>China’s export basket, 1995 versus 2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<h2>Globalisation ratio</h2>

<p>Finally, consider China’s globalisation ratios (Figure 8). The right panel exhibits the country’s gross globalisation ratio (GGR) in manufacturing. This is the share of manufactured production that is sold abroad, where production is measured as the total sales of all China-based manufacturers. It differs from manufacturing GDP since it includes all sales, not just final good sales.</p>

<p>Turning to the facts, we see that during its rise to manufacturing superpower status, China’s GGR rocketed up – almost doubling – in the first decade of the data. Indeed, most of the action came between 1999 and 2004. That period was an extraordinary feat of globalisation, and it is probably why so many think of China as an economy that is incredibly dependent on exports. But the story doesn’t end in 2004.</p>

<p>Since 2004, China’s GGR has been falling steadily. And don’t miss the fact that it is, in 2020, not far above where it started in 1995. Chinese manufacturing, in short, is no longer as dependent on exports as many might believe. True, the first part of the rapid growth period involved exports growing faster than production (so the GGR rises). But then production grows faster than exports, implying that domestic sales were becoming relatively more important, compared to export sales – even though domestic and foreign sales were both booming throughout the high-growth episode. This dispels the myth that China’s success can be entirely attributed to exports. From around 2004, China increasingly became its own best customer.</p>

<p>The takeaway is simple: China’s openness, as measured by the GGR, has fallen rapidly. By 2020 it was only slightly more dependent on export sales than it was 1995.</p>

<p><strong>Figure 8 </strong>China’s manufacturing growth and Gross Globalisation Ratio (GGR)</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<h2>Concluding remarks</h2>

<p>China is now the world’s sole manufacturing giant. As its recent success in electric vehicles demonstrates, its wide and deep industrial base can help it gain a competitive edge in virtually all sectors. The exceptions are the most advanced sectors, where the G7 countries still dominate.</p>

<p>Politicians who indulge in loose talk about decoupling from China need a clear-eyed look at the facts. As we have shown (Baldwin et al. 2023), all the major manufacturers in the world source at least 2% of all their industrial inputs from China. Decoupling would be difficult, to say the least.</p>

<h2>References</h2>

<p>Baldwin, R, R Freeman and A Theodorakopoulos (2022), “<a href="https://www.nber.org/papers/w30525">Horses for Courses: Measuring Foreign Supply Chain Exposure</a>”, NBER Working Paper w31820.</p>

<p>Baldwin, R, R Freeman and A Theodorakopoulos (2023), “<a href="https://www.nber.org/papers/w31820">Hidden Exposure: Measuring Us Supply Chain Reliance</a>”, NBER Working Paper w31820 (forthcoming in<em> Brookings Paper on Economic Activity</em>).&nbsp;</p>

<p>Felbermayr, G, H Mahlkow and A Sandkamp (2023), “Cutting through the value chain: the long-run effects of decoupling the East from the West”, <em>Empirica</em> 50: 75–108.</p>

<p>Góes, C and E Bekkers (2022), “The impact of geopolitical conflicts on trade, growth, and innovation”, WTO Staff Working Paper ERSD-2022-09.</p>

<p>Ranganathan, T C A (2023), “<a href="https://www.deccanherald.com/opinion/what-really-made-china-the-manufacturing-superpower-1237398.html">What really made China the manufacturing superpower?”</a>, <em>Deccan Herald</em>.</p>

<p>Upadhyaya, Y (2023), “<a href="https://yogesh-upadhyaya.medium.com/how-did-china-become-a-manufacturing-superpower-7322c3058d8">How did China become a manufacturing superpower?</a>”, Medium.</p>

<p>Wang, T (2023), <em>Making Sense of the Chinese Economy,</em> Routledge.</p>

<p>World Bank and People’s Republic of China Development Research Center of the State Council (2013), “China 2030: Building a Modern, Harmonious, and Creative Society”, The World Bank Group, No. 12925.</p>

<h2>Annex</h2>

<p><strong>Figure A1</strong> China’s share of world manufacturing GDP, 1995-2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

<p><strong>Figure A2 </strong>Asymmetric supply chain reliance (FPEM): G7, India, and Korea, 1995-2020</p>

  


<h6><em>Source</em>: OECD TiVA database.</h6>

              </div>

              
                                          </article>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Programming as Theory Building [pdf] (179 pts)]]></title>
            <link>https://pages.cs.wisc.edu/~remzi/Naur.pdf</link>
            <guid>42592543</guid>
            <pubDate>Sat, 04 Jan 2025 05:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pages.cs.wisc.edu/~remzi/Naur.pdf">https://pages.cs.wisc.edu/~remzi/Naur.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=42592543">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Breaking Up with Long Tasks or: how I learned to group loops and wield the yield (185 pts)]]></title>
            <link>https://calendar.perfplanet.com/2024/breaking-up-with-long-tasks-or-how-i-learned-to-group-loops-and-wield-the-yield/</link>
            <guid>42592224</guid>
            <pubDate>Sat, 04 Jan 2025 03:51:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://calendar.perfplanet.com/2024/breaking-up-with-long-tasks-or-how-i-learned-to-group-loops-and-wield-the-yield/">https://calendar.perfplanet.com/2024/breaking-up-with-long-tasks-or-how-i-learned-to-group-loops-and-wield-the-yield/</a>, See on <a href="https://news.ycombinator.com/item?id=42592224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2 id="everything_on_the_main_thread_all_at_once">Everything, On the Main Thread, All at Once</h2>
<p>Arrays are in every web developer’s toolbox, and there are a dozen ways to iterate over them. Choose wrong, though, and all of that processing time will happen synchronously in one long, blocking task. The thing is, the most natural ways <em>are</em> the wrong ways. A simple <code>for..of</code> loop that processes each array item is synchronous by default, while Array methods like <code>forEach</code> and <code>map</code> can ONLY run synchronously. You almost certainly have a loop like this waiting to be optimized right now.</p>
<p>What’s the problem with long tasks, anyway? Every long task is a liability for an unresponsive user experience. If the user interacts with the page at just the right (or wrong) time, the browser won’t be able to handle that interaction until the task completes, which contributes to its input delay and slow Interaction to Next Paint (INP) performance. You can think of them like potholes on a road, forcing drivers to dodge them or risk damaging their cars—an unpleasant experience either way. Likewise, long tasks create unresponsive UIs, which can frustrate users and impact business metrics. They’re especially problematic when they’re not just coinciding with a user interaction, but in response to one. It’s no longer a matter of poor timing, because <em>every</em> click necessarily becomes a slow click.</p>
<p>Synchronously processing large arrays is one of the easiest ways to introduce long tasks. Even if the unit of work performed on each item in the array is reasonably fast, that time scales up linearly with the number of items. For example, if a CPU can complete one unit of work in 0.25 ms, and there are 1,000 units, the total processing time will be 250 ms, creating a long task and exceeding the threshold for a fast and responsive interaction. The key to breaking up the long task is to use the repetition to your advantage: each iteration of the loop is an opportunity to interrupt the processing and update the UI as needed.</p>
<h2 id="optimizing_interaction_responsiveness">Optimizing interaction responsiveness</h2>
<p>Interrupting a task to allow the event loop to continue turning is known as yielding. There are a few ways to yield, with the classic approach being <code>setTimeout</code> with a delay of 0 ms, or the more modern alternative: <code>scheduler.yield</code>. It’s not currently supported in all browsers, so production-ready use cases will need a polyfill or fall back to <code>setTimeout</code>. In both cases, the trick to making the loop asynchronous is to use async/await. But there’s a catch.</p>
<p>If you’re using an Array method like <code>forEach</code> or <code>map</code>, you’ll quickly realize that this doesn’t work:</p>
<pre>function handleClick() {
  items.forEach(async (item) =&gt; {
    await scheduler.yield();
    process(item);
  });
}
</pre>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image9.png" alt=""></p>
<p><code>forEach</code> doesn’t care if your callback function is asynchronous, it will plow through every item in the array without awaiting the yield. And it doesn’t matter which approach you use <code>scheduler.yield</code> or <code>setTimeout</code>. Apparently, this trips up a lot of developers, with <a href="https://stackoverflow.com/q/37576685/1022333">this StackOverflow question</a>&nbsp;having been viewed 2.4 million times since it was asked in 2016. The solution is in the top answer: switch to using a <code>for..of</code> loop instead.</p>
<pre>async function handleClick() {
  for (const item of items) {
    await scheduler.yield();
    process(item);
  }
}
</pre>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image3.png" alt=""></p>
<p>Instead of a monolithic long task blocking the click handler, now we’ve spread the work out into smaller tasks, responding to the interaction instantly. Problem solved, right?</p>
<p>Before we get into the major problem with this approach, you might have noticed the <a href="https://stackoverflow.com/a/49499491/1022333">third most upvoted answer</a>&nbsp;on that StackOverflow question, which recommends using the <code>reduce</code> method. In case you were tempted to cling to your functional programming tendencies and use <code>reduce</code> to break up the long task, think again.</p>
<pre>function handleClick() {
  items.reduce(async (promise, item) =&gt; {
    await promise;
    await scheduler.yield();
    process(item);
  }, Promise.resolve());
}
</pre>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image4.png" alt=""></p>
<p>This approach passes a promise along from one iteration to the next, which we can await before processing the next item. However, the issue with this is that <code>reduce</code> still plows through the entire array, synchronously queuing up each microtask. It’s not until the promises are fulfilled that it starts processing the items. In other words, even though the actual processing happens asynchronously, the amount of overhead is still enough to make the click handler slow.</p>
<p>Yielding within a <code>for..of</code> loop seems like the best way to achieve responsive interactions, but the problem is that we’re yielding on EVERY iteration of the loop. Let’s see what happens in browsers that don’t support <code>scheduler.yield</code>:</p>
<pre>async function handleClick() {
  for (const item of items) {
    await Promise(resolve =&gt; setTimeout(resolve, 0));
    process(item);
  }
}
</pre>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image1.png" alt=""></p>
<p>With <code>setTimeout</code>, the job takes over 2 minutes to complete! Compare that with <code>scheduler.yield</code>, which completes in about 1 second. The huge disparity comes down to the fact that these are <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/setTimeout#reasons_for_delays_longer_than_specified">nested timeouts</a>. Unlike tasks deferred with <code>scheduler.yield</code>, browsers introduce a 4 ms gap between nested timeouts. But that’s not to say that using <code>scheduler.yield</code> on every iteration comes without a cost. Both approaches introduce some overhead, which can be mitigated with batching.</p>
<h2 id="optimizing_total_processing_time">Optimizing total processing time</h2>
<p>Batching is processing multiple iterations of the loop before yielding. The interesting problem is knowing when to yield. Let’s say you yield after processing every 100 items in the array. Did you solve the long task problem? Well, that depends on the CPU speed and how much time the average item takes to process, and both of those factors will vary depending on the client’s machine.</p>
<p>Rather than batching by number of items, a much better approach would be to batch items by the time it takes to process them. That way you can set a reasonable batch duration, say 50 ms, and yield only when it’s been at least that long since the last yield.</p>
<pre>const BATCH_DURATION = 50;
let timeOfLastYield = performance.now();

function shouldYield() {
  const now = performance.now();
  if (now - timeOfLastYield &gt; BATCH_DURATION) {
    timeOfLastYield = now;
    return true;
  }
  return false;
}

async function handleClick() {
  for (const item of items) {
    if (shouldYield()) {
      await scheduler.yield();
    }
    process(item);
  }
}
</pre>
<p><img fetchpriority="high" decoding="async" src="https://calendar.perfplanet.com/wp-content/uploads/2024/12/image9-1024x288.png" alt="" width="1024" height="288" srcset="https://calendar.perfplanet.com/wp-content/uploads/2024/12/image9-1024x288.png 1024w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image9-300x84.png 300w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image9-768x216.png 768w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image9-1536x432.png 1536w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image9.png 1892w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>And here are the results with <code>setTimeout</code>:</p>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image5.png" alt=""></p>
<p>The choice of batch duration is a tradeoff between minimizing the amount of time a user would spend waiting if they interacted with the page during the batch processing and the total time to process everything in the array. If you chunk up the work into 100 ms batches, that’s fewer interruptions and faster throughput, but at worst that’s also 100 ms of possible input delay, which is already half the budget for a fast interaction. On the other hand, with 10 ms batches, the worst case input delay is almost negligible, but more interruptions and slower throughput.</p>
<p>Your primary goal should be to unblock the interaction so that it feels responsive. That could just mean yielding so that you can update the UI with the first few items, or kicking off a loading animation. How often you yield during the rest of the processing time will depend on what your second priority is. Maybe nothing can be shown to the user until the entire array is processed, so your secondary goal should be to finish as quickly as possible. In that case you’ll want to go with a higher batch duration. Or maybe it’s ok to do the work in the background, but the UI should remain as smooth and responsive as possible. That lends itself to a smaller batch duration. When in doubt, 50 ms can be a good compromise, but it’s always a good idea to profile different approaches and pick what works best for your app.</p>
<p>We could stop there, but there’s one more thing that you might want to consider: frame rate. If you look closely at the screenshots above, you’ll notice thin green markers roughly corresponding to the paint cycle. These are custom timings using <code>performance.mark</code> to show when a <code>requestAnimationFrame</code> callback runs. There’s a curious difference in the frame rates of <code>scheduler.yield</code> and <code>setTimeout</code>.</p>
<h2 id="optimizing_smoothness">Optimizing smoothness</h2>
<p>To reiterate, if the work needs to be completed as quickly as possible, you should minimize the number of yields. But there are plenty of instances where it’s more important to provide visual feedback to the user that something is happening, like a progress indicator. Even if you’re not showing any progress to the user, you might still want to keep the frame rate reasonably fast to avoid janky animations or scrolling behavior. That’s where the preferential priority of <code>scheduler.yield</code> starts getting in the way.</p>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image6.png" alt=""></p>
<p>Surprisingly, for batch durations under 100 ms, the frame rate is relatively flat around 10 FPS. However, <code>setTimeout</code> follows the expected curve, where more frames are painted as the batch duration decreases, approaching 60 FPS. Tasks scheduled with <code>scheduler.yield</code> are given preferential treatment, so even if you don’t do any batching at all, the browser will prioritize it over the next paint—but only up to a point.</p>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image2.png" alt=""></p>
<p>With no batching, the average time between frames is 120 ms, far from the 16 ms you get with tasks scheduled with <code>setTimeout</code>. This means your frame rate will be a lame 8 FPS. If you’re cool with that, you can skip the rest of this section. But I know there are some people who can’t stand the thought of a laggy UI, so here are some tips.</p>
<pre>const BATCH_DURATION = 1000 / 30; // 30 FPS
let timeOfLastYield = performance.now();

function shouldYield() {
  const now = performance.now();
  if (now - timeOfLastYield &gt; BATCH_DURATION) {
    timeOfLastYield = now;
    return true;
  }
  return false;
}

async function handleClick() {
  for (const item of items) {
    if (shouldYield()) {
      await new Promise(requestAnimationFrame);
      await scheduler.yield();
    }
    process(item);
  }
}
</pre>
<p><img decoding="async" title="" src="https://calendar.perfplanet.com/images/2024/rick/image7.png" alt=""></p>
<p>First, change the batch duration to align with your desired frame rate. When it’s time to yield, before calling <code>scheduler.yield</code>, await a promise that resolves in a <code>requestAnimationFrame</code> callback. This effectively prevents any more work from happening until a frame is painted, ensuring a much smoother UI.</p>
<p>One gotcha is that the rAF callback won’t be fired as long as the tab is in the background. We can make a few adjustments to handle this edge case.</p>
<pre>const BATCH_DURATION = 1000 / 30; // 30 FPS
let timeOfLastYield = performance.now();

function shouldYield() {
  const now = performance.now();
  if (now - timeOfLastYield &gt; <span>(document.hidden ? </span><span>500</span><span> : BATCH_DURATION)</span>) {
    timeOfLastYield = now;
    return true;
  }
  return false;
}

async function handleClick() {
  for (const item of items) {
    if (shouldYield()) {
      if (document.hidden) {
        await new Promise(resolve =&gt; setTimeout(resolve, 1));
        timeOfLastYield = performance.now();
      } else {
        await Promise.race([
          new Promise(resolve =&gt; {
            timeoutId = setTimeout(() =&gt; {
              timeOfLastYield = performance.now();
              resolve();
            }, 100)
          }),
          new Promise(resolve =&gt; {
            requestAnimationFrame(() =&gt; {
              clearTimeout(timeoutId);
              resolve();
            });
          })
        ]);
        await scheduler.yield();
      }
    }
    process(item);
  }
}
</pre>
<p><img decoding="async" src="https://calendar.perfplanet.com/wp-content/uploads/2024/12/image10-1024x300.png" alt="" width="1024" height="300" srcset="https://calendar.perfplanet.com/wp-content/uploads/2024/12/image10-1024x300.png 1024w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image10-300x88.png 300w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image10-768x225.png 768w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image10-1536x450.png 1536w, https://calendar.perfplanet.com/wp-content/uploads/2024/12/image10.png 1768w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>The first change is to the <code>shouldYield</code> function, which now checks the page visibility. If the document is hidden, we can afford to yield in larger batches of 500 ms. Even though there is no user to experience a slow interaction, this still introduces a long task that could block the page from becoming visible if the user returns before the work is completed. <code>document.hidden</code> will continue to be true until the visibilitychange event can be handled, so we still need to yield periodically.</p>
<p>The second change is to the way we yield when the document is visible. We need to make sure that we’re not dependent on the rAF callback, so we can race it against a 100 ms timeout, borrowing from Vercel’s <a href="https://vercel.com/blog/demystifying-inp-new-tools-and-actionable-insights#the-implementation"><code>await-interaction-response</code></a> approach. The 100 ms timeout will be throttled to 1000 ms while the tab is backgrounded, but after that, the timeout will fire and work can resume. Resetting the <code>timeOfLastYield</code>&nbsp;is good so that the first backgrounded batch can run for the full 500 ms. And even though we’re racing the promises, the timeout’s callback will fire anyway, so it’s helpful to clear it during the rAF.</p>
<p>The final change is to the way we yield when the document is hidden. We want the visibilitychange event to fire, but <code>scheduler.yield</code> will always preempt it, delaying the page from becoming visible until the work is completed. That might be worth more investigation because it feels like a bug, but we can work around it by switching to a timeout-based approach. As long as the document is hidden, work will be done in 500 ms batches with an additional 500 ms delay between each batch, adding up to the 1000 ms delay for throttled timeouts. That way, if the user returns before the work is completed, the visibility state will be updated and the regular batching logic will kick back in.</p>
<p>If all of this feels overly complicated, that’s probably because it is. If your application can withstand pausing array iteration while the tab is in the background, then you should skip this last part for the sake of simplicity. In any case, this was a fun exercise in pushing the limits of yielding.</p>
<h2 id="try_it_out">Try it out</h2>
<p>If you’d like to try out the different yielding strategies, you can use <a href="https://loop-yields.glitch.me/">this demo</a>. That’s also what I used to make the screenshots in this post.</p>
<p>Hopefully this was a useful overview of the “yield in a loop” problem and how I’d go about solving it. Feel free to let me know if I got something wrong, or if you know of a better way I’d love to hear about it. Good luck out there!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do Files want to be Actors? (105 pts)]]></title>
            <link>https://lewiscampbell.tech/blog/250104.html</link>
            <guid>42592126</guid>
            <pubDate>Sat, 04 Jan 2025 03:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lewiscampbell.tech/blog/250104.html">https://lewiscampbell.tech/blog/250104.html</a>, See on <a href="https://news.ycombinator.com/item?id=42592126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In the world of high performance linux apps, <a href="https://unixism.net/loti/what_is_io_uring.html#what-is-io-uring">io_uring</a> is changing how we communicate with the operating system.</p>
<p>The io_uring model is based on two queues:</p>
<ul>
<li>a submission queue, where you send the kernel an operation to execute</li>
<li>a completions queue, where you read the result of the execution</li>
</ul>
<p>Combined with an event loop, we have a new way of doing IO on linux without waiting on syscalls to complete before yielding back control to the program. You simply put things on the queue, and then you get right back to computing.</p>
<p>The async request sent to the kernel has this structure (see <code>man 7 io_uring</code>):</p>
<pre><code>      struct io_uring_sqe {
                   __u8    opcode;         /* type of operation for this sqe */
                   __s32   fd;             /* file descriptor to do IO on */
                   __u64   off;            /* offset into file */
                   __u64   addr;           /* pointer to buffer or iovecs */
                   __u32   len;            /* buffer size or number of iovecs */
                   __u64   user_data;      /* data to be passed back at completion time */
                   __u8    flags;          /* IOSQE_ flags */
                   ...
           };
</code></pre>
<p>The <code>opcode</code> represents the OS level syscall, ie <code>open</code>, <code>read</code>, <code>write</code> etc. So
even function call semantics are abstracted away by this OS interface.</p>
<p>Re-wind back to the 1970s, where Carl Hewitt and Henry Baker wrote the first paper about the actor model; <a href="https://dspace.mit.edu/bitstream/handle/1721.1/41962/AI_WP_134A.pdf?sequence=1&amp;isAllowed=y">Laws for Communicating Parallel Processes</a>. In it they describe a base model for concurrent computations:</p>
<p><em>The action in the actor model consists of objects called actors sending messages to other actors, called the targets of those messages...an event E is the receipt of the message "message(E)" by the actor "target(E)". Upon receipt of this message in the event E, the target consults its script (the actor analogue of program text), and using its current local state and the message as parameters, sends new messages to other actors and computes a new local state for itself.</em></p>
<p>Is it just me, or are these two seemingly unrelated schools of computing converging on the exact same idea? You send messages to some target (ie, the file descriptor). You receive (or maybe you don't receive) responses back asynchronously. We're not concerned with function calls, or mutexes, or spinlocks - they're implementation details. We're concerned with sending messages concurrently.</p>
<p>The game has changed. Our operating systems want to do things asynchronously, on their own terms. They'll tell you when they're done. Maybe this is a new era. Maybe making syscalls from 1970s Unix directly is like a remote procedure call to another machine - a leaky abstraction, a feeble attempt to impose your old mental model onto a new reality.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>