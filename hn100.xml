<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 09 Nov 2024 13:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: I Analyzed 650k TikTok Influencers and This Is What I Found (291 pts)]]></title>
            <link>https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</link>
            <guid>42093911</guid>
            <pubDate>Sat, 09 Nov 2024 11:49:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/">https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</a>, See on <a href="https://news.ycombinator.com/item?id=42093911">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[It's legal for police to use deception in interrogations. Some want that to end (251 pts)]]></title>
            <link>https://text.npr.org/nx-s1-4974964</link>
            <guid>42091423</guid>
            <pubDate>Fri, 08 Nov 2024 23:57:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text.npr.org/nx-s1-4974964">https://text.npr.org/nx-s1-4974964</a>, See on <a href="https://news.ycombinator.com/item?id=42091423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Ted Bradford says the worst day of his life was when detectives took him into a tiny room to question him about a rape.</p><p>‚ÄúThe whole day it was like accusation after accusation,‚Äù he says. ‚ÄúI kept telling them over and over, ‚ÄòI didn't do this.‚Äô‚Äù</p><p>Bradford says the officers in Yakima, Wash., <a href="https://wainnocenceproject.org/stories/ted-bradford/"><u>claimed they had biological evidence</u></a> that would prove he did it, and they weren't going to let him leave until he admitted it.</p><p>‚ÄúI knew I didn‚Äôt do it,‚Äù he said. ‚ÄúSo I'm thinking, ‚ÄòIn order to get out of this situation, I could just give them a statement. They‚Äôll test that evidence. It‚Äôll show that I didn‚Äôt do it, and then this will all be done with.‚Äô‚Äù</p><p>After<em> </em>hours of questioning, Bradford confessed to the crime. But the evidence police had ‚Äì a mask left at the scene ‚Äì could not be DNA-tested. This was the late nineties and the technology wasn‚Äôt there yet.</p><p>Bradford recanted his confession, but was convicted anyway. He was 22 with two small children when he went to prison.</p><p>‚ÄúEvery day I woke up and knew that I shouldn't be there,‚Äù he says.</p><p>Advancements in DNA testing helped lead to his exoneration in 2010.</p><p>What happened to Bradford might seem extreme, but nearly 30 years later, the tactic used on him is not. In every state, police officers are allowed to lie to adults during an interrogation. The hope, in many cases, is that they‚Äôll get a person to confess to committing a crime.</p><p>When it comes to children and teenagers, a growing number of states are stopping that practice: Ten have passed laws in recent years effectively banning police from lying to juveniles during interrogations, starting with Illinois in 2021. But some legal advocates are pushing for a deception ban that would apply to everyone, not just kids.</p><h2>‚ÄòA quick and relatively straightforward way to close a case‚Äô</h2><p>Deception is a powerful law enforcement tool in eliciting confessions, says wrongful convictions attorney Laura Nirider.</p><p>‚ÄúPolice are trained around the country in all 50 states to use deception during interrogation, to lie both about the evidence against a suspect and to lie about the consequences of confessing in order to make it seem not so bad if you just say that you did these things,‚Äù she says.</p><p>Police can go into an interrogation room with a suspect, Nirider says, and emerge with ‚Äúone of the most believable pieces of evidence imaginable, a confession.‚Äù</p><p>‚ÄúIt's a quick and relatively straightforward way to close a case,‚Äù she says.</p><p>But Nirider says using deception can also draw false confessions.</p><p>According to the Innocence Project, a national organization that works to overturn wrongful convictions, nearly a third of DNA exonerations from 1989 to 2020 <a href="https://innocenceproject.org/dna-exonerations-in-the-united-states/"><u>involved a false confession</u></a>.</p><p>Legal experts say the deception bans passed in recent years fail to protect other vulnerable groups: young adults, people with intellectual disabilities, even just people who are naturally compliant.</p><p>‚ÄúChildren are one category that makes you more vulnerable, but it's certainly not the only category,‚Äù says Lara Zarowsky, executive and policy director at the Washington Innocence Project. ‚ÄúIt's something that all of us are vulnerable to.‚Äù</p><h2>‚ÄòLaw enforcement is the biggest impediment‚Äô</h2><p>In Washington state, where Bradford was convicted, Democratic lawmakers want to set a higher bar: A bill that would make incriminating statements made in police custody ‚Äì by adults or children ‚Äì largely inadmissible in court if obtained using deception.</p><p>State Rep. Strom Peterson has introduced the bill twice, but it hasn‚Äôt gone anywhere.</p><p>‚ÄúLaw enforcement is the biggest impediment to the bill. They believe that the system in which they work is effective,‚Äù he says.</p><p>The Washington Association of Sheriffs and Police Chiefs declined NPR‚Äôs request for an interview, but said in a statement that it opposes such a measure, because banning deception would take away a tactic that yields ‚Äúmany more true confessions‚Äù than false ones.</p><p>‚ÄúWe fear that it will negatively impact our ability to solve crimes and would result in less accountability for those who victimize others,‚Äù the association‚Äôs policy director, James McMahan, <a href="https://tvw.org/video/house-appropriations-2024021057/?eventID=2024021057"><u>said at a hearing</u></a> for the bill in February.</p><p>‚ÄúCriminals often conduct elaborate stories to conceal their crimes,‚Äù McMahan said at the hearing. ‚ÄúSometimes the use of deception is required to locate the truth both to convict and to exonerate people. Such deceptions include telling a person that abuse was discovered during a routine medical exam rather than reported by a family member.‚Äù</p><p>In its statement, the association added that judges assess whether confessions are given voluntarily before they can be introduced as evidence, and convictions based solely on confessions are rare.</p><p>Even with other evidence, however, confessions carry a lot of weight. Research indicates that people who confess <a href="https://core.ac.uk/reader/81748492?utm_source=linkout"><u>are treated differently</u></a> afterwards: They‚Äôre more likely to be charged, face more charges, and receive a harsher punishment when convicted.</p><p>‚ÄúA confession will trump everything,‚Äù says Jim Trainum, a retired homicide detective in Washington, D.C.</p><p>In his experience, there is pressure to move on after a suspect confesses because a detective‚Äôs measure of success is often tied to closure rates.</p><p>‚ÄúLet's say that I get a confession and I get all the stuff that I want to go out and corroborate. I want to make sure that this is an accurate confession,‚Äù Trainum says. ‚ÄúI'm sitting there at my desk working very, very hard on it. And my sergeant comes up and says, ‚ÄòWhat are you doing? That's a confession. That's closed. Move on. You got other ones to take care of.‚Äô‚Äù</p><h2>‚ÄòTrying to give the police new tools‚Äô</h2><p>Those against deception bans see them as an attack on police, says Mark Fallon, a consultant on interrogation practices and former federal agent. In fact, he says, it‚Äôs the opposite.</p><p>‚ÄúIt is actually trying to give the police new tools, better tools,‚Äù he says.</p><p>There‚Äôs another way for police to question people, Fallon says, that relies on building rapport and asking open-ended questions, and where the primary goal is information, rather than a confession.</p><p>That technique is used in other countries, including much of Europe. In England, France, Germany, Australia, Japan and elsewhere, for instance, the police are generally <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3669413"><u>not allowed to deceive suspects</u></a>.</p><p>Trainum says interrogation methods that don‚Äôt rely on deception ultimately make the police more trustworthy to communities.</p><p>‚ÄúToday‚Äôs suspect is tomorrow's witness,‚Äù he says.</p><p>When a suspect or witness has been lied to, he says, ‚Äúthat radiates out. And no wonder people don't trust us. Why should they trust us?‚Äù</p><p>That is why Peterson, the lawmaker, plans to introduce the bill in Washington again. He says the public is<em> </em>better off when police use the best tools available to convict the right people.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delta: A syntax-highlighting pager for Git, diff, grep, and blame output (436 pts)]]></title>
            <link>https://github.com/dandavison/delta</link>
            <guid>42091365</guid>
            <pubDate>Fri, 08 Nov 2024 23:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dandavison/delta">https://github.com/dandavison/delta</a>, See on <a href="https://news.ycombinator.com/item?id=42091365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png" alt="image"></a>
</p>
<p dir="auto">
  <a href="https://github.com/dandavison/delta/actions">
    <img src="https://github.com/dandavison/delta/workflows/Continuous%20Integration/badge.svg" alt="CI">
  </a>
  <a href="https://coveralls.io/github/dandavison/delta?branch=main" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e8785ac8ede00f6ec8ad672e5031d27eb6eb5a599d56b232a469b9824f76753c/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64616e64617669736f6e2f64656c74612f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/dandavison/delta/badge.svg?branch=main">
  </a>
  <a href="https://gitter.im/dandavison-delta/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6c92914f6e39c859372cd85d6c7676c73d524f994663f1ae0e2b0b566a0e1361/68747470733a2f2f6261646765732e6769747465722e696d2f64616e64617669736f6e2d64656c74612f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/dandavison-delta/community.svg">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><a href="https://dandavison.github.io/delta/installation.html" rel="nofollow">Install it</a> (the package is called "git-delta" in most package managers, but the executable is just <code>delta</code>) and add this to your <code>~/.gitconfig</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[core]
    pager = delta

[interactive]
    diffFilter = delta --color-only

[delta]
    navigate = true    # use n and N to move between diff sections

    # delta detects terminal colors automatically; set one of these to disable auto-detection
    # dark = true
    # light = true

[merge]
    conflictstyle = zdiff3"><pre>[<span>core</span>]
    <span>pager</span> <span>=</span> <span>delta</span>

[<span>interactive</span>]
    <span>diffFilter</span> <span>=</span> <span>delta</span> <span>--color-only</span>

[<span>delta</span>]
    <span>navigate</span> <span>=</span> <span>true</span>    <span><span>#</span> use n and N to move between diff sections</span>

    <span><span>#</span> delta detects terminal colors automatically; set one of these to disable auto-detection</span>
    <span><span>#</span> dark = true</span>
    <span><span>#</span> light = true</span>

[<span>merge</span>]
    <span>conflictstyle</span> <span>=</span> <span>zdiff3</span></pre></div>
<p dir="auto">Delta has many features and is very customizable; please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Language syntax highlighting with the same syntax-highlighting themes as <a href="https://github.com/sharkdp/bat#readme">bat</a></li>
<li>Word-level diff highlighting using a Levenshtein edit inference algorithm</li>
<li>Side-by-side view with line-wrapping</li>
<li>Line numbering</li>
<li><code>n</code> and <code>N</code> keybindings to move between files in large diffs, and between diffs in <code>log -p</code> views (<code>--navigate</code>)</li>
<li>Improved merge conflict display</li>
<li>Improved <code>git blame</code> display (syntax highlighting; <code>--hyperlinks</code> formats commits as links to hosting provider etc. Supported hosting providers are: GitHub, GitLab, SourceHut, Codeberg)</li>
<li>Syntax-highlights grep output from <code>rg</code>, <code>git grep</code>, <code>grep</code>, etc</li>
<li>Support for Git's <code>--color-moved</code> feature.</li>
<li>Code can be copied directly from the diff (<code>-/+</code> markers are removed by default).</li>
<li><code>diff-highlight</code> and <code>diff-so-fancy</code> emulation modes</li>
<li>Commit hashes can be formatted as terminal <a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">hyperlinks</a> to the hosting provider page (<code>--hyperlinks</code>).
File paths can also be formatted as hyperlinks for opening in your OS.</li>
<li>Stylable box/line decorations to draw attention to commit, file and hunk header sections.</li>
<li>Style strings (foreground color, background color, font attributes) are supported for &gt;20 stylable elements, using the same color/style language as git</li>
<li>Handles traditional unified diff output in addition to git output</li>
<li>Automatic detection of light/dark terminal background</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">A syntax-highlighting pager for git, diff, and grep output</h2><a id="user-content-a-syntax-highlighting-pager-for-git-diff-and-grep-output" aria-label="Permalink: A syntax-highlighting pager for git, diff, and grep output" href="#a-syntax-highlighting-pager-for-git-diff-and-grep-output"></a></p>
<p dir="auto">Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output.</p>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a>
      <br>
      <sub>delta with <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a>
      <br>
      <sub>delta with <code>side-by-side</code> and <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<p dir="auto">Here's what <code>git show</code> can look like with git configured to use delta:</p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Syntax-highlighting themes</h3><a id="user-content-syntax-highlighting-themes" aria-label="Permalink: Syntax-highlighting themes" href="#syntax-highlighting-themes"></a></p>
<p dir="auto"><strong>All the syntax-highlighting color themes that are available with <a href="https://github.com/sharkdp/bat/">bat</a> are available with delta:</strong></p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">Side-by-side view</h3><a id="user-content-side-by-side-view" aria-label="Permalink: Side-by-side view" href="#side-by-side-view"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/side-by-side-view.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    side-by-side = true"><pre>[<span>delta</span>]
    <span>side-by-side</span> <span>=</span> <span>true</span></pre></div>
<p dir="auto">By default, side-by-side view has line-numbers activated, and has syntax highlighting in both the left and right panels: [<a href="#side-by-side-view-1">config</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto">Side-by-side view wraps long lines automatically:</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Line numbers</h3><a id="user-content-line-numbers" aria-label="Permalink: Line numbers" href="#line-numbers"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/line-numbers.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    line-numbers = true"><pre>[<span>delta</span>]
    <span>line-numbers</span> <span>=</span> <span>true</span></pre></div>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Merge conflicts</h3><a id="user-content-merge-conflicts" aria-label="Permalink: Merge conflicts" href="#merge-conflicts"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/merge-conflicts.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png"><img width="500px" src="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Git blame</h3><a id="user-content-git-blame" aria-label="Permalink: Git blame" href="#git-blame"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/git-blame.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ripgrep, git grep</h3><a id="user-content-ripgrep-git-grep" aria-label="Permalink: Ripgrep, git grep" href="#ripgrep-git-grep"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/grep.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"><img width="600px" alt="image" src="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"></a>
</p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation and usage</h3><a id="user-content-installation-and-usage" aria-label="Permalink: Installation and usage" href="#installation-and-usage"></a></p>
<p dir="auto">Please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a> and <code>delta --help</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maintainers</h3><a id="user-content-maintainers" aria-label="Permalink: Maintainers" href="#maintainers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dandavison">@dandavison</a></li>
<li><a href="https://github.com/th1000s">@th1000s</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude AI to process secret government data through new Palantir deal (207 pts)]]></title>
            <link>https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</link>
            <guid>42091043</guid>
            <pubDate>Fri, 08 Nov 2024 22:42:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/">https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</a>, See on <a href="https://news.ycombinator.com/item?id=42091043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>An ethical minefield</h2>
<p>Since its founders started Anthropic in 2021, the company has <a href="https://www.youtube.com/watch?v=UMF1nf3Iy3Q">marketed itself</a> as one that takes an ethics- and safety-focused approach to AI development. The company differentiates itself from competitors like OpenAI by adopting what it calls responsible development practices and self-imposed ethical constraints on its models, such as its "<a href="https://arstechnica.com/information-technology/2023/05/ai-with-a-moral-compass-anthropic-outlines-constitutional-ai-in-its-claude-chatbot/">Constitutional AI</a>" system.</p>
<p>As Futurism <a href="https://futurism.com/the-byte/ethical-ai-anthropic-palantir">points out</a>, this new defense partnership appears to conflict with Anthropic's public "good guy" persona, and pro-AI pundits on social media are noticing. <span>Frequent AI commentator Nabeel S. Qureshi <a href="https://x.com/nabeelqu/status/1854574146283618521">wrote</a> on X, </span><span>"Imagine telling the safety-concerned, effective altruist founders of Anthropic in 2021 that a mere three years after founding the company, they'd be signing partnerships to deploy their ~AGI model straight to the military frontlines.</span>"</p>
<figure>
    <div>
              <p><a data-pswp-width="1200" data-pswp-height="675" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w" data-cropped="true" href="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" target="_blank">
                <img decoding="async" width="1200" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" alt="Anthropic's &quot;Constitutional AI&quot; logo." srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w" sizes="(max-width: 1200px) 100vw, 1200px">
              </a></p><div id="caption-2061278"><p>
                Anthropic's "Constitutional AI" logo.
                                  </p><p>
                    Credit:
                                          Anthropic / Benj Edwards
                                      </p>
                              </div>
            </div>
                  <figcaption>
          <div>
    
    <p>
      Anthropic's "Constitutional AI" logo.

              <span>
          Credit:

          
          Anthropic / Benj Edwards

                  </span>
          </p>
  </div>
        </figcaption>
            </figure>

<p>Aside from the implications of working with defense and intelligence agencies, the deal connects Anthropic with Palantir, a <a href="https://amp.theguardian.com/commentisfree/2020/sep/04/palantir-ipo-ice-immigration-trump-administration">controversial company</a> which <a href="https://defensescoop.com/2024/05/29/palantir-480-million-army-contract-maven-smart-system-artificial-intelligence/">recently won</a> a $480 million contract to develop an AI-powered target identification system called Maven Smart System for the US Army. Project Maven has <a href="https://www.reuters.com/article/business/media-telecom/google-to-scrub-us-military-deal-protested-by-employees-source-idUSL2N1T320P/">sparked criticism</a> within the tech sector over military applications of AI technology.</p>
<p>It's worth noting that Anthropic's terms of service <a href="https://www.anthropic.com/news/expanding-access-to-claude-for-government">do outline</a> specific rules and limitations for government use. These terms permit activities like foreign intelligence analysis and identifying covert influence campaigns, while prohibiting uses such as disinformation, weapons development, censorship, and domestic surveillance. Government agencies that maintain regular communication with Anthropic about their use of Claude may receive broader permissions to use the AI models.</p>
<p>Even if Claude is never used to target a human or as part of a weapons system, other issues remain. While its Claude models are highly regarded in the AI community, they (like all LLMs) have the tendency to <a href="https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/">confabulate</a>, potentially generating incorrect information in a way that is difficult to detect.</p>
<p>That's a huge potential problem that could impact Claude's effectiveness with secret government data, and that fact, along with the other associations, has Futurism's Victor Tangermann worried. As he puts it, "It's a disconcerting partnership that sets up the AI industry's growing ties with the US military-industrial complex, a worrying trend that should raise all kinds of alarm bells given the tech's many inherent flaws‚Äîand even more so when lives could be at stake."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is a Staff Engineer? (123 pts)]]></title>
            <link>https://nishtahir.com/what-is-a-staff-engineer/</link>
            <guid>42090771</guid>
            <pubDate>Fri, 08 Nov 2024 21:55:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nishtahir.com/what-is-a-staff-engineer/">https://nishtahir.com/what-is-a-staff-engineer/</a>, See on <a href="https://news.ycombinator.com/item?id=42090771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <!--kg-card-begin: markdown--><blockquote>
<p><em>"I've worked with a couple of Staff Engineers on different teams in the past and I've seen them do different things, but I've not been able to pin down exactly what they do."</em></p>
</blockquote>
<p>I get this question quite frequently. Sometimes from engineers looking to elevate their roles. At other times, team members reach out looking to learn how they could get the most value from Staff Engineers on the teams. It is a complicated question because a lot of ambiguity exists in the role. Different engineers have distinct interpretations, so you may get a significantly different answer depending on who you ask. With that in mind, I wanted to capture my thoughts on the subject. It's deep, complex, and nuanced. As a result, I'm likely to be as successful as someone attempting to unravel the mysteries of Engineering Management <sup><a href="#fn1" id="fnref1">[1]</a></sup> in a single blog post.</p>
<p>To lay some foundation, I'll be describing a class of engineers as <em>Staff Plus</em> (Staff+). These engineers operate above the Senior level. However, they do not assume the role of an Engineering Manager. These engineers often aim to stay within the technical track of an organization's career ladder. While there is currently no universally accepted title for this role <sup><a href="#fn2" id="fnref2">[2]</a></sup>, successful individuals I've seen in this role tend to share notable common traits</p>
<ul>
<li>They are proven experts in their area of expertise</li>
<li>They have a lot of experience leading teams toward shipping products</li>
</ul>
<h2 id="characterizing-a-staff-engineer">Characterizing a Staff+ Engineer</h2>
<p>One of my favorite ways to characterize the Staff+ role is by using the "4 key skills <sup><a href="#fn3" id="fnref3">[3]</a></sup> every job needs". It provides a solid framework that we can use to determine the distribution of skills one would need to be successful in the role.</p>
<p><img src="https://nishtahir.com/content/images/2023/01/four_skills_every_job_needs.png" alt="four_skills_every_job_needs" loading="lazy"></p>
<h2 id="core-technical-skill">Core Technical Skill</h2>
<p>This is the foundational skill needed to execute the role effectively and one that the Staff+ Engineer should be highly proficient in. In my experience, this level requires deep technical knowledge in some specialty<sup><a href="#fn4" id="fnref4">[4]</a></sup>, and it is often accompanied by a wide breadth of knowledge and experience working with multiple different systems within multiple different environments<sup><a href="#fn5" id="fnref5">[5]</a></sup>. This is the wealth of experience that the Staff+ Engineer reaches into to solve complex technical problems that contribute toward furthering their team's objectives. While I cannot overstate the importance of this skill as a foundational element of the role, it's not enough to be successful on its own. It must be fluidly combined with other skills to empower the Staff+ Engineer to fluidly adapt to different roles on the team, some of which I will cover below.</p>
<h2 id="product-management">Product Management</h2>
<p>A Staff+ Engineer relies on this skill to determine what should be built as well as why. At this level, the Staff+ Engineer should be capable of looking at a team, project, and/or organization's objectives, gaining some understanding of its history, and developing a technical vision<sup><a href="#fn6" id="fnref6">[6]</a></sup> to meet those objectives<sup><a href="#fn7" id="fnref7">[7]</a></sup>. A skilled Staff+ Engineer should be able to communicate this vision to their stakeholders, as well as other parties that may have a stake in the outcome, and get buy-in from all parties, especially the engineering team that will be responsible for building the solution. This role may sometimes manifest as a Technical Architect<sup><a href="#fn8" id="fnref8">[8]</a></sup>.</p>
<h2 id="project-management">Project Management</h2>
<p>This skill helps the Staff+ engineer break down large work items into smaller more manageable tasks for more junior members of the team, create a plan/timeline for completion that can be tracked, as well as manage uncertainties/risks that may deter completion of the work. Proficiency in this skill requires a mastery of basic project management fundamentals <sup><a href="#fn9" id="fnref9">[9]</a></sup>. This does not mean that Staff+ Engineers should be expected to replace project managers; rather these roles should be seen as complementary.</p>
<h2 id="people-management">People Management</h2>
<p>This includes the ability to rally and lead a team toward completing a set of objectives. I've heard this fondly described as "herding cats"<sup><a href="#fn10" id="fnref10">[10]</a></sup>. While I don't think a Staff+ engineer in this role is required to assume full people management responsibilities (that's what Managers are for), there is notably a lot of overlap. For example, I would expect an engineer operating at this level to be an effective mentor, able to provide technical and a reasonable extent of career guidance. This skill also requires having a solid awareness of the team's composition. This includes the skills makeup, strengths as well as growth areas. At this level, the Staff+ engineer should be able to use this awareness to elevate the effectiveness of the team through coaching and mentoring.</p>
<h2 id="youre-rubber-im-glue">You're rubber, I'm glue</h2>
<blockquote>
<p><em>"I feel like they do a little bit of everything. They seem to be the go-to on the team when there's an issue. They are like a rock with all the answers!"</em></p>
</blockquote>
<p>I've found that a key aspect of my day-to-day is autonomously combining these skills to fill roles that may find difficult to fill. It's often the less glamorous but high-value work that is required to build or maintain team momentum. This is sometimes described as "glue" work.</p>
<blockquote>
<p><em>"Every senior person in an organisation should be aware of the less glamorous - and often less-promotable - work that needs to happen to make a team successful. Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting."</em><sup><a href="#fn11" id="fnref11">[11]</a></sup></p>
</blockquote>
<p>Doing glue work often requires a cross-functional grasp of how the team operates as well as deep insight into areas of the team that may require optimization. Here are a couple of scenarios that exemplify glue work,</p>
<ol>
<li>You notice that a couple of email threads between your engineers and a 3rd party vendor have been running long. They seem to be talking past each other without making any headway. You decide to help improve the situation by scheduling a couple of meetings to help foster alignment and develop a culture of partnership between the teams.</li>
<li>You notice an up tick in the number of bug tickets being written about a feature in the product. After a brief investigation, you find that area of the code lacks automated tests because of a dependency on a third-party framework and will require some rework to make it testable. The development team needs some coaching on how to handle these sorts of problems in the future and a plan needs to be drafted and communicated to the leadership team. There's some upfront cost but will pay for itself in fewer bug tickets down the road.</li>
<li>A team member has been struggling with a new aspect of their assignment. They are unsure of what specific skills they need to learn to be most effective. So you help by offering some light coaching by offering some resources that help them get up to speed quickly as well as setting up 1:1s where they can ask questions and get feedback.</li>
<li>Your team was asked to build a tool that aggregates data for marketing and Business Intelligence (BI). The requirements were vague but enough for the engineering team to work on. Noticing the potential for improvement, you schedule meetings with representatives from the marketing and BI team to better understand how the aggregated data will be used to provide a better product.</li>
</ol>
<p>While one could argue that this work has a high-value impact on the team, it may be tough to justify having the Staff+ Engineer function doing any one of those things in the long term. As a result, a crucial part of the role is leveling up the team such that they may take over such responsibilities such that the Staff+ Engineer may shift their focus towards tackling other priorities. It may be by coaching an existing team member to own one of those tasks or working with the leadership team to staff a new permanent owner.</p>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p><em>"I forget what was said exactly, but [Staff+ Engineer] spoke up and said something with clarity and confidence that changed the conversation to be much more productive. They were thoughtful with their comments and have a keen ability to drive toward clarity in a room of swirling indecision."</em></p>
</blockquote>
<p>I've only scratched the surface here, but hope I've captured some specific nuances in the role. Ultimately I think a Staff+ Engineer should be able to use their autonomy and influence within an organization and turn that into meaningful impact and value in service of a team or organization's objectives.</p>
<p>Here are a couple of great resources that I recommend if you are interested in learning more.</p>
<ol>
<li><a href="https://learning.oreilly.com/library/view/the-staff-engineers/9781098118723/?ref=nishtahir.com">The Staff Engineers Path</a> by Tanya Rielly</li>
<li><a href="https://staffeng.com/book?ref=nishtahir.com">Staff Engineer: Leadership beyond the management track</a> by Will Larson</li>
</ol>
<p>To wrap things up, I'm adding an assorted collection of questions I've gotten recently. This is either because I couldn't figure out a way to answer it directly within the context of this blog post or because I thought it may add additional perspective to address the question directly.</p>
<h2 id="faq">FAQ</h2>
<ol>
<li>
<blockquote>
<p>Does Staff+ Engineering require mentoring responsibilities?</p>
</blockquote>
</li>
</ol>
<p>Yes. I think this is a non-negotiable part of the role. The ability to elevate a team's capability is predicated on being a good mentor. In essence, the ability to identify strengths and growth areas on the team. Additionally, creating opportunities for team members to learn and grow.</p>
<ol start="2">
<li>
<blockquote>
<p>What kinds of teams need a Staff+ Engineer?</p>
</blockquote>
</li>
</ol>
<p>A Staff+ Engineer can exist on any team in theory. However, their role will depend on the specific team composition. The Staff+ Engineer may be the main Individual Contributor (IC) on a small team working on a proof of concept for some experimental technology, while a Staff+ Engineer may act as a technical lead on a larger team trying to build long-term momentum. The opportunity cost is the Staff+ Engineer's time and must be considered when making staffing decisions. Could a Senior Engineer be sourced to fill the IC role? This would free up the Staff+ Engineer to work on more complex or higher value problems for the project.</p>
<ol start="3">
<li>
<blockquote>
<p>What differentiates senior levels of Staff Engineers?</p>
</blockquote>
</li>
</ol>
<p>The main differentiator is their scope of impact. More senior Staff+ Engineers should be able to have and manage an impact on an organization or company, in some cases an industry at large. Being able to build and leverage their influence to guide a technical direction is a skill in and of itself</p>
<ol start="4">
<li>
<blockquote>
<p>Hmm... It looks like you went over a lot of general points but didn't address a lot of specific expectations of the role</p>
</blockquote>
</li>
</ol>
<p>This is because the nature of the role changes with each individual and circumstance. This means that being able to adapt to each circumstance is important. That being said, I think the most important thing is that the Staff+ Engineer can turn autonomy into meaningful impact at a scale proportional to their role/level.</p>
<ol start="5">
<li>
<blockquote>
<p>I stayed on the technical track with I got promoted because I wanted to continue to write code. How do I balance leadership responsibilities but still retain coding in my day-to-day?</p>
</blockquote>
</li>
</ol>
<p>I would argue that at this level, your leadership skills are likely your most valuable asset. Trying to keep hands-on-keyboard writing code a major part of your role may not be using your talents to their full potential. However, your day-to-day should be determined by the team/project needs while considering that time dedicated towards work that an IC would typically do comes at the cost of glue work and other higher-level work that may require your attention. This is not to say that you should be completely removed from the code avenues such as working on future work such as PoCs or lower priority features as you have availability might be great ways to keep you engaged in writing code.</p>
<hr>
<section>
<ol>
<li id="fn1"><p><a href="https://dzone.com/articles/the-art-of-engineering-management?ref=nishtahir.com">Chegini, A. (2022) The art of engineering management, dzone.com. DZone. Available at: https://dzone.com/articles/the-art-of-engineering-management (Accessed: January 24, 2023)</a> <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p>Some alternate titles I've encountered include Lead Engineer/Developer, Principal/Distinguished Engineer, Technical Fellow, etc... <a href="#fnref2">‚Ü©Ô∏é</a></p>
</li>
<li id="fn3"><p><a href="https://leaddev.com/leaddev-live/role-and-influence-ic-trajectory-beyond-staff?ref=nishtahir.com">Zunger, Y. (no date) Role and Influence: The IC trajectory beyond Staff, Leaddev.com. Available at: https://leaddev.com/leaddev-live/role-and-influence-ic-trajectory-beyond-staff (Accessed: January 24, 2023).</a> <a href="#fnref3">‚Ü©Ô∏é</a></p>
</li>
<li id="fn4"><p><a href="https://hired.com/blog/candidates/balance-breadth-depth-learning-software-development/?ref=nishtahir.com">Woodhams, B. (2018) Balance between breadth and depth of learning software development, candidates. Available at: https://hired.com/blog/candidates/balance-breadth-depth-learning-software-development/ (Accessed: January 24, 2023).</a> <a href="#fnref4">‚Ü©Ô∏é</a></p>
</li>
<li id="fn5"><p>This may be different in your organization and your specific personality <a href="#fnref5">‚Ü©Ô∏é</a></p>
</li>
<li id="fn6"><p><a href="https://lethain.com/what-do-staff-engineers-actually-do/?ref=nishtahir.com">What do Staff engineers actually do? (2020) Lethain.com. Available at: https://lethain.com/what-do-staff-engineers-actually-do/ (Accessed: January 24, 2023).</a> <a href="#fnref6">‚Ü©Ô∏é</a></p>
</li>
<li id="fn7"><p><a href="https://www.eventbrite.com/engineering/writing-our-3-year-technical-vision/?ref=nishtahir.com">Micol, D. (2021) Writing our 3-year technical vision, Engineering Blog. Available at: https://www.eventbrite.com/engineering/writing-our-3-year-technical-vision/ (Accessed: January 24, 2023).</a> <a href="#fnref7">‚Ü©Ô∏é</a></p>
</li>
<li id="fn8"><p><a href="https://www.lucidchart.com/blog/defining-technical-architects?ref=nishtahir.com">Rethinking the role of the technical architect (2021) Lucidchart. Available at: https://www.lucidchart.com/blog/defining-technical-architects (Accessed: January 24, 2023).</a> <a href="#fnref8">‚Ü©Ô∏é</a></p>
</li>
<li id="fn9"><p><a href="https://www.northeastern.edu/graduate/blog/essential-project-management-skills/?ref=nishtahir.com">Joubert, S. (2019) Project management skills, Northeastern University Graduate Programs. Available at: https://www.northeastern.edu/graduate/blog/essential-project-management-skills/ (Accessed: January 24, 2023).</a> <a href="#fnref9">‚Ü©Ô∏é</a></p>
</li>
<li id="fn10"><p><a href="https://www.frontendhappyhour.com/episodes/tech-lead-engineer-herding-cats-&amp;-drinks/?ref=nishtahir.com">Tech lead engineer - herding cats &amp; drinks - Front End Happy Hour (no date) Frontendhappyhour.com. Available at: https://www.frontendhappyhour.com/episodes/tech-lead-engineer-herding-cats-&amp;-drinks/ (Accessed: January 25, 2023).</a> <a href="#fnref10">‚Ü©Ô∏é</a></p>
</li>
<li id="fn11"><p><a href="https://noidea.dog/glue?ref=nishtahir.com">Being Glue ‚Äî (no date) No Idea Blog. Available at: https://noidea.dog/glue (Accessed: January 25, 2023).</a> <a href="#fnref11">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Notes on Apple Math Notes (125 pts)]]></title>
            <link>https://mlajtos.mu/posts/new-kind-of-paper-5</link>
            <guid>42090633</guid>
            <pubDate>Fri, 08 Nov 2024 21:31:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mlajtos.mu/posts/new-kind-of-paper-5">https://mlajtos.mu/posts/new-kind-of-paper-5</a>, See on <a href="https://news.ycombinator.com/item?id=42090633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<div><div><p>September 24, 2024</p><!-- --><p> ¬∑ </p><!-- --><p>Milan Lajto≈°</p></div><p><span>new kind of paper</span><span>, </span><span>thinking</span><span>, </span><span>computation</span><span>, </span><span>paper &amp; pencil</span><span>, </span><span>human-computer interaction</span><span>, </span><span>Apple</span></p></div>
<p>In the previous parts (<a href="https://mlajtos.mu/posts/new-kind-of-paper">1</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-2">2</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-3">3</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-4">4</a>) written in 2021, I described <strong>New Kind of Paper</strong> ‚Äì an app that enhances <strong>paper &amp; pencil</strong>, the best medium for thinking, with the capabilities of a crazy <strong>advanced calculator</strong>.</p>
<p>In 2024, Apple introduced their spin on this topic under the name <strong>Math Notes</strong>. In this article, I will provide my <strong>deep praise (and even deeper hate)</strong> for their attempt to bring a bit of <strong>innovation into the UX of math</strong>.</p>
<hr>
<p>Let's start with a <strong>simple example</strong> of how Math Notes works...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/0-8601d68a71218ed6ce2ff0869d1845c8.mov" poster="https://mlajtos.mu/_next/static/media/0.7b1a32c5.png" preload="none"></video><figcaption>Writing a math expression in Apple Math Notes</figcaption></figure>
<p>It <span>*fucking*</span> works! ü•π</p>
<p>At first glance, it may not seem like much, but in this brief example, a lot has happened. First, the handwriting recognition worked flawlessly, despite my awful handwriting. It perfectly recognized what I meant by those scratch marks. Second, after I wrote the trigger symbol, <code>=</code> (the equal sign), the expression was evaluated, and the result was inserted inline, mimicking my handwriting style. The inline insertion could be improved to better match the handwriting style, but overall, this is basically magic. With my writing magic wand, I have conjured up a little computational spell. ü™Ñ</p>
<p>The fact that millions of people have this technology at their fingertips and pencil tips (works both on iPads &amp; iPhones too), is a major miracle. The democratization of this technology is the hardest part, and it is in the hands of the people who know how to get shit done. Maybe not on the first try, but the third iteration... <span><em>*chef's kiss*</em></span></p>
<h2>Too Magical &amp; Not Alive Enough</h2>
<p><strong>How do you know that the result is correct?</strong> The calculation is definitely correct, but how can you trust your calculator to recognize your badly handwritten "1" as "1" and not as "7"? You simply don't. This is essentially Apple claiming that their handwriting recognition is infallible. It's a rather bold claim, don't you think? I appreciate the confidence, but I don't believe we have reached that level of accuracy yet. Even basic calculators indicate which button you (mis-)pressed.</p>
<p><strong>Why does it appear lifeless most of the time?</strong> If you only saw the first 90% of that demonstration, you wouldn't even know if this thing works. Honestly, it seemed dead most of the time. And when the result finally appeared, it was accompanied by flashy animation. ü´£ I love the animation, and I understand why it adds a nice touch to the initial version, but it's really just a distraction. This calculator should feel MORE alive!</p>
<p>Of course, talk is cheap, so let me demonstrate what I mean:</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/1-a218e67f18e4f4486a486defaa970615.mp4" poster="https://mlajtos.mu/_next/static/media/1.7046d6ac.png" preload="none"></video><figcaption>Writing a math expression with live feedback (<a href="https://mlajtos.mu/posts/new-kind-of-paper-2">source</a>, 2021)</figcaption></figure>
<p><strong>Not as polished, but it is alive!</strong> And snappy. And colorful. The feedback is immediate, and you can see the result as you write. This kind of feedback instills trust in the system and gives you a sense of control. Of course, Apple will fix these issues differently...</p>
<p>The first problem ‚Äì whether the system recognized your handwriting correctly ‚Äì can be solved with another iPadOS feature called Smart Script. It lets you beautify your handwriting ‚Äì simply write an ugly "1" and it will progressively transform the scribble into neatly handwritten "1" or "7". The point is to inform the user, give them feedback on how the system recognized the symbol. This helps tremendously with the trust issue.</p>
<p>The second problem, the missing liveness, is even easier to solve ‚Äì just ditch the "=" and evaluate the expression when the user pauses. Not too eager, not too lazy. This "interactive" mode can be simulated in Math Notes with this technique:</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/7-b425cecd44d2f48d757ebb2aea627c14.mov" poster="https://mlajtos.mu/_next/static/media/7.b98d48de.png" preload="none"></video><figcaption>"Interactive" mode in Math Notes<br><span>&amp; number of WTF moments</span></figcaption></figure>
<h2>Scratch to Delete</h2>
<p>*no comment*</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/1-1dfb304ebcd57e666ca89e09b4b70b33.mov" poster="https://mlajtos.mu/_next/static/media/1.7fd6e9b0.png" preload="none"></video><figcaption>Unnecessary switching between writing and erasing<br><span>&amp; 2-second long inconsistent state</span></figcaption></figure>
<h2>The Math You Know‚Ñ¢</h2>
<h3>2D notation</h3>
<p>Math Notes supports 2D notation ‚Äì you can write exponents as superscript, use fractions, etc. You know, the usual scary math stuff:</p>
<figure><div><p><img alt="log_2(2^10 / 2) = 9" loading="lazy" width="358.5" height="200.5" decoding="async" data-nimg="1" srcset="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=384&amp;q=75 1x, https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=750&amp;q=75 2x" src="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=750&amp;q=75"></p></div><figcaption>Example of 2D notation: Relation between exponentiation, divison, and logarithm.<br><span>Every operation has different 2D representation.</span></figcaption></figure>
<p>I know how crazy difficult this must have been to pull off. <span>*Bravo!*</span></p>
<h3>PEMDAS</h3>
<p>PEMDAS ‚Äì the order of operations: <strong>P</strong>arentheses, <strong>E</strong>xponents, <strong>M</strong>ultiplication/<strong>D</strong>ivision, <strong>A</strong>ddition/<strong>S</strong>ubtraction. It's everywhere. It's in our textbooks, our calculators, programming languages and now even in Apple's Math Notes. <span>*sigh*</span></p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/2-d47b8c3b0a560012784715d75efa08ee.mov" poster="https://mlajtos.mu/_next/static/media/2.6ce2b48c.png" preload="none"></video><figcaption>Illustration of operator precedence</figcaption></figure>
<h3>The Future of Math Notation</h3>
<p>Supporting the traditional handwritten math notation is no easy task. It is extremely messy, inconsistent and sometimes ambiguous. However, a calculator that wants to be useful must support ideas that have been forged for centuries. It is hard to change math.</p>
<p>When math started to become executable in form of software &amp; hardware, we developed consistent notation that was shaped by keyboards, not by pencils. We migrated from 2D into 1D, misused some glyphs, and introduced constructs that made sense for computing. Math definitely adapted to this new medium.</p>
<p>Math Notes embodies even newer medium on which math can grow and change. While supporting existing traditional notation is a must, adding ability to define custom notation is an aspiration. We can't evolve math if the medium does not allow it. Today, the notation in Math Notes is fixed and it doesn't even cover a lot of useful math (e.g. calculus). This is fine in the short term, but if we are serious, we should start to think about user-definable 2D notation. Heck, even user-definable operators (e.g. <code>‚âà</code> or <code>‚äô</code>) would be a good first step.</p>
<p>While Math Notes isn't doing anything on this front yet, Apple leaned heavily into different direction...</p>
<h2>Dynamic Scribbles</h2>
<p>Since we are not stuck with static scribbles on the paper, Math Notes supports some dynamic behaviors, e.g. changing a numeric value just by dragging a slider.</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/4-67b47bb57bbaee5b32156324a02cd185.mov" poster="https://mlajtos.mu/_next/static/media/4.3af29c54.png" preload="none"></video><figcaption>Simple means of "solving".<br><span>Circular knob with different speeds might be better in the long-term,<br> but the slider is a great choice for first iteration.</span></figcaption></figure>
<p>Or graphing a function...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/5-35e4fbbd8d953708a710ff81dc9844f7.mov" poster="https://mlajtos.mu/_next/static/media/5.50a8d043.png" preload="none"></video><figcaption>Term "graphing calculator" has a new meaning now.</figcaption></figure>
<p>These are fantastic features that millions of people will love. With just a scribble and touch of a finger, I can solve non-trivial computational problems. Can you imagine the effort, if you wanted to achieve the same thing in e.g. Python? <span><em>*Bleh..*</em></span></p>
<p>However, graphs are dead ‚Äì they do not respond to changing coefficients...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/8-cc08b6635b462f3697d8c2027d7e0e76.mov" poster="https://mlajtos.mu/_next/static/media/8.43e7c2c7.png" preload="none"></video><figcaption>Graphs in Math Notes are useful, but dead.</figcaption></figure>
<h3>ŒªŒªŒª</h3>
<p>One obvious omission in this part of Math Notes, is proper function definition. Define a function, see its graph, and be able to evaluate it with a specific input value. You know, something like this...</p>
<figure><div><p><img alt="fn(x)=10*x; a=1; b=fn(a); b=10" loading="lazy" width="592" height="313" decoding="async" data-nimg="1" srcset="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=640&amp;q=75 1x, https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=1200&amp;q=75 2x" src="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=1200&amp;q=75"></p></div><figcaption>Mockup of a better function definition.<br><span>Showing a point at [1, 10] would be neat...</span></figcaption></figure>
<p>This notation for function definition (or lambdas/Œª in comp-sci jargon) is pretty understandable and supports multiple arguments. Also, it opens up a route to primitive custom (infix) operators.</p>
<hr>
<h2>Solving Way Harder Stuff</h2>
<p>All these features are hinting at a calculator that is a good companion for a mind that wants to solve problems that can be turned into a computation. So far, the capabilities of Math Notes are pretty limited ‚Äì e.g. <a href="https://mlajtos.mu/posts/new-kind-of-paper-2">how would you sum up numbers from 1 to 100?</a> That is a pretty easy computational problem, but you can't solve it easily with this type of calculator ‚Äì yet.</p>
<p>However, "solving" is much broader topic than a straight-to-an-answer computation. What about problems that involves optimizing a function with thousand of parameters in an iterated manner? This problem-solving technique is currently limited to small set of smart people. Math Notes could unlock it for much broader, and younger audience. Like Excel did open up sophisticated computation for mere mortals. But this time in a much more humane way.</p>
<h2>‚àû Amount of Constructive Criticism...</h2>
<p>I have been thinking about this type of calculator for many many years, and I am extremely happy to see this <strong>new kind of calculator</strong> in the wild. I want to see it used by everybody ‚Äì from curious 5 year olds to PhD-level proffesionals in the science &amp; engineering. Solving our personal problems and civilization-level ones too.</p>
<blockquote>
<p>We can only see a short distance ahead, but we can see plenty there that needs to be done.</p>
<p>‚Äì Alan Turing</p>
</blockquote>
<hr>
<p>Do you have ideas about this kind of stuff? Please share them online!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I quit Google to work for myself (2018) (262 pts)]]></title>
            <link>https://mtlynch.io/why-i-quit-google/</link>
            <guid>42090430</guid>
            <pubDate>Fri, 08 Nov 2024 20:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mtlynch.io/why-i-quit-google/">https://mtlynch.io/why-i-quit-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42090430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the past four years, I‚Äôve worked as a software developer at Google. On February 1st, I quit. It was because they refused to buy me a Christmas present.</p><p>Well, I guess it‚Äôs a little more complicated than that.</p><h2 id="the-first-two-years">The first two years<a href="#the-first-two-years" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Two years in, I loved Google.</p><p>When the annual employee survey asked me whether I expected to be at Google in five years, it was a no-brainer.</p><p>Of <em>course</em> I‚Äôd still be at Google in five years. I was surrounded by the best engineers in the world, using the most advanced development tools in the world, and eating the free-est food in the world.</p><p><a href="https://mtlynch.io/why-i-quit-google/spoiled-coder.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/spoiled-coder.png 1024w" src="https://mtlynch.io/why-i-quit-google/spoiled-coder.png" alt="My typical day at Google" loading="lazy"></a></p><p>My most recent performance rating was ‚ÄúStrongly Exceeds Expectations.‚Äù If I just kept going, I‚Äôd soon be promoted to the next level, Senior Software Engineer. What a great title! Forever after in my career, I‚Äôd be able to say, ‚ÄúYes, I was a <em>Senior</em> Software Engineer. At <em>Google</em>.‚Äù People would be so impressed.</p><p>My manager assured me that my promotion was close. He felt that I was already capable of senior-level work. I just needed the right project to prove it to the promotion committee.</p><p>No, managers at Google can‚Äôt promote their direct reports. They don‚Äôt even get a vote.</p><p>Instead, promotion decisions come from small committees of upper-level software engineers and managers who have never heard of you until the day they decide on your promotion.</p><p>You apply for promotion by assembling a ‚Äúpromo packet‚Äù: a collection of written recommendations from your teammates, design documents you‚Äôve created, and mini-essays you write to explain why your work merits a promotion.</p><p>A promotion committee then reviews your packet with a handful of others, and they spend the day deciding who gets promoted and who doesn‚Äôt.</p><p>During my two-year honeymoon phase, this system sounded great to me. Of <em>course</em> my fate should be in the hands of a mysterious committee who‚Äôs never met me. They wouldn‚Äôt be tainted by any sort of favoritism or politics. They‚Äôd see past all that and recognize me for my high-quality code and shrewd engineering decisions.</p><h2 id="thats-not-really-how-it-works">That‚Äôs not really how it works<a href="#thats-not-really-how-it-works" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Before I put together my first promo packet, I never thought about the logistics of how it all worked.</p><p>In my head, the promotion committee was this omniscient and fair entity. If I spent each day choosing the right problems to solve, making the codebase better, and helping my team execute efficiently, the promotion committee would magically know this and reward me for it.</p><p>Unsurprisingly, it doesn‚Äôt work like that. It took me two years to figure that out.</p><h2 id="working-na√Øvely">Working na√Øvely<a href="#working-na√Øvely" arialabel="Anchor"> üîóÔ∏é</a></h2><p>My main responsibility until that point was a legacy data pipeline. It had been in maintenance mode for years, but load had increased, and the pipeline was buckling under the pressure. It frequently died silently or produced incorrect output. Its failures took days to diagnose because nobody had written documentation for it since its original design spec.</p><p>I proudly and lovingly nursed the pipeline back to health. I fixed dozens of bugs and wrote automated tests to make sure they wouldn‚Äôt reappear. I deleted thousands of lines of code that were either dead or could be replaced by modern libraries. I documented the pipeline as I learned it so that the institutional knowledge was available to my teammates instead of siloed in my head.</p><p>The problem, as I discovered at promotion time, was that none of this was quantifiable. I couldn‚Äôt prove that anything I did had a positive impact on Google.</p><h2 id="metrics-or-it-didnt-happen">Metrics or it didn‚Äôt happen<a href="#metrics-or-it-didnt-happen" arialabel="Anchor"> üîóÔ∏é</a></h2><p>The pipeline didn‚Äôt record many metrics. The ones it did have made it look like things had gotten worse. My bug discoveries caused the overall bug count to increase. The pipeline‚Äôs failures increased because I made it fail fast on anomalies instead of silently passing along bad data. I drastically reduced the time developers spent repairing those failures, but there were no metrics that tracked developer time.</p><p>My other work didn‚Äôt look so good on paper either. On several occasions, I put my projects on hold for weeks or even months at a time to help a teammate whose launch was at risk. It was the right decision for the team, but it looked unimpressive in a promo packet. To the promotion committee, my teammate‚Äôs project was the big, important work that demanded coordination from multiple developers. If they hornswoggled me into helping them, it‚Äôs evidence of their strong leadership qualities. I was just the mindless peon whose work was so irrelevant that it could be pre-empted at a moment‚Äôs notice.</p><p>I submitted my first promo packet, and the results were what I feared: the promotion committee said that I hadn‚Äôt proven I could handle technical complexity, and they couldn‚Äôt see the impact I had on Google.</p><p><a href="https://mtlynch.io/why-i-quit-google/promo-committee.png"><img sizes="(min-width: 768px) 800px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/promo-committee.png 1024w" src="https://mtlynch.io/why-i-quit-google/promo-committee.png" alt="Arguing my case to the promotion committee" loading="lazy"></a></p><h2 id="learning-from-rejection">Learning from rejection<a href="#learning-from-rejection" arialabel="Anchor"> üîóÔ∏é</a></h2><p>The rejection was a difficult blow, but I wasn‚Äôt discouraged. I felt I was performing above my level, but the promotion committee couldn‚Äôt see it. That was solvable.</p><p>I decided that I had been too na√Øve in my first couple years. I didn‚Äôt do enough planning up front to make sure the work I was doing left a paper trail. Now that I understood how the process worked, I could keep doing the same good work, just with better record-keeping.</p><p>For example, my team was receiving tons of distracting email alerts due to false alarms. Old me would have just fixed these alerts. But now I knew that for this work to appear in my promo packet, I should first set up metrics so that we‚Äôd have historical records of alert frequency. At promotion time, I‚Äôd have an impressive-looking graph of the alerts trending downward.</p><p>Shortly after, I was assigned a project that seemed destined for promotion. It depended heavily on machine-learning, which was and still is the hot thing at Google. It would automate a task that hundreds of human operators were doing manually, so it had a clear, objective impact on Google. It also required me to lead a junior developer throughout the project, which generally won points with promotion committees.</p><h2 id="the-holiday-gift-wake-up-call">The holiday gift wake up call<a href="#the-holiday-gift-wake-up-call" arialabel="Anchor"> üîóÔ∏é</a></h2><p>A few months later, Google <a href="http://fortune.com/2016/12/09/alphabet-donated-its-employees-holiday-gifts-to-charity/">made headlines</a> when they ended their long-standing tradition of giving lavish holiday gifts to all of their employees. Instead, they used the gift budget to buy <del>advertising disguised as charity</del> Chromebooks for underprivileged schoolchildren.</p><p>Shortly after this, I witnessed the following conversation between two employees:</p><blockquote><p><strong>Employee A</strong>: You effectively <strong>are</strong> still getting the gift. Cuts like these increase the value of Google‚Äôs stock. You can sell your stock grants and buy any present you choose.</p><p><strong>Employee B</strong>: What if I told my wife that I wasn‚Äôt buying her a Christmas gift, but she could use the money in our bank account to buy any present she wants?</p><p><strong>Employee A</strong>: You‚Äôre in a <strong>business</strong> relationship with Google. If you‚Äôre disappointed that Google isn‚Äôt ‚Äúromancing‚Äù you with gifts like you do for your wife, you have a misguided notion of the relationship.</p></blockquote><p>Wait a second. <em>I</em> was in a business relationship with Google.</p><p>It may sound strange that it took me two and a half years to realize it, but Google does a good job of building a sense of community within the organization. To make us feel that we‚Äôre not just employees, but that we <em>are</em> Google.</p><p>That conversation made me realize that I‚Äôm <em>not</em> Google. I provide a service to Google in exchange for money.</p><p>So if Google and I have a business relationship that exists to serve each side‚Äôs interests, why was I spending time on all these tasks that served Google‚Äôs interests instead of my own? If the promotion committee doesn‚Äôt reward bugfixing or team support work, why was I doing that?</p><p>My first denied promotion taught me the wrong lesson. I thought I could keep doing the same work but package it to look good for the promotion committee. I should have done the opposite: figure out what the promotion committee wants, and do that work exclusively.</p><p>I adopted a new strategy. Before starting any task, I asked myself whether it would help my case for promotion. If the answer was no, I didn‚Äôt do it.</p><p>My quality bar for code dropped from, ‚ÄúWill we be able to maintain this for the next 5 years?‚Äù to, ‚ÄúCan this last until I‚Äôm promoted?‚Äù I didn‚Äôt file or fix any bugs unless they risked my project‚Äôs launch. I wriggled out of all responsibilities for maintenance work. I stopped volunteering for campus recruiting events. I went from conducting one or two interviews per week to zero.</p><h2 id="then-my-project-was-canceled">Then my project was canceled<a href="#then-my-project-was-canceled" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Priorities shifted. Management traded my project away to our sister team in India. In exchange, that team gave us one of their projects. It was an undocumented system, built on deprecated infrastructure, but it was nevertheless a critical component in production. I was assigned to untangle it from our sister team‚Äôs code and migrate it to a new framework, all while keeping it running in production and hitting its performance metrics.</p><p>As far as my promotion was concerned, this was a setback of several months. Because I hadn‚Äôt released anything for my canceled project, the two months I spent on it were worthless. It would take me weeks just to get up to speed on the system I was inheriting, and I was liable to lose several more in the gruntwork of keeping it operational.</p><h2 id="what-am-i-even-doing">What am I even doing?<a href="#what-am-i-even-doing" arialabel="Anchor"> üîóÔ∏é</a></h2><p>It was the third time in six months that my manager had reassigned me midway through a project. Each time, he assured me that it had nothing to do with the quality of my work, but rather some shift in upper management strategy or team headcount.</p><p>At this point, I took a step back to assess what was happening from a high level. Forget my manager, forget his managers, forget the promotion committee. What if I boiled it down to just me and just Google? What was happening in our ‚Äúbusiness relationship?‚Äù</p><p>Well, Google kept telling me that it couldn‚Äôt judge my work until it saw me complete a project. Meanwhile, I couldn‚Äôt complete any projects because Google kept interrupting them midway through and assigning me new ones.</p><p>The dynamic felt absurd.</p><p><a href="https://mtlynch.io/why-i-quit-google/book-publisher.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/book-publisher.png 1024w" src="https://mtlynch.io/why-i-quit-google/book-publisher.png" alt="The Google promotion committee approach to book publishing" loading="lazy"></a></p><p>My career was being dictated by a shifting, anonymous committee who thought about me for an hour of their lives. Management decisions that I had no input into were erasing months of my career progress.</p><p>Worst of all, I wasn‚Äôt proud of my work. Instead of asking myself, ‚ÄúHow can I solve this challenging problem?‚Äù I was asking, ‚ÄúHow can I make this problem <em>look</em> challenging for promotion?‚Äù I hated that.</p><p>Even if I got the promotion, what then? Popular wisdom said that each promotion was exponentially harder than the last. To continue advancing my career, I‚Äôd need projects that were even larger in scope and involved collaboration with more partner teams. But that just meant the project could fail due to even more factors outside my control, wasting months or years of my life.</p><h2 id="whats-the-alternative">What‚Äôs the alternative?<a href="#whats-the-alternative" arialabel="Anchor"> üîóÔ∏é</a></h2><p>Around this time, I discovered Indie Hackers.</p><p><a href="https://mtlynch.io/why-i-quit-google/indie-hackers.png"><img sizes="(min-width: 768px) 550px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_1200x0_resize_lanczos_3.png 1200w,
https://mtlynch.io/why-i-quit-google/indie-hackers.png 1545w" src="https://mtlynch.io/why-i-quit-google/indie-hackers.png" alt="Screenshot of Indie Hackers website" loading="lazy"></a></p><p>It‚Äôs an online community for founders of small software businesses. Emphasis on small. These weren‚Äôt Zuckerberg hopefuls, but rather people who wanted to build modest, profitable businesses that pay their bills.</p><p>I had always been interested in starting my own software company, but I only knew of the Silicon Valley startup path. I thought being a software founder meant spending most of my time fundraising and the rest of it worrying about how to attract my next million users.</p><p>Indie Hackers presented an attractive alternative. Most members built their businesses with their own savings or as side projects to their full-time jobs. They didn‚Äôt answer to investors, and they certainly didn‚Äôt have to prove themselves to anonymous committees.</p><p>There were downsides, of course. Their income was less steady, and they faced more numerous catastrophic risks. If I ever made a mistake at Google that cost the company $10 million, I would suffer no consequences. I‚Äôd be asked to write a post-mortem, and everyone would celebrate the learning opportunity. For most of these founders, a $10 million mistake would mean the end of their business and several lifetimes of debt.</p><p>Founders on Indie Hackers captivated me because they were in control. Whether their business became a runaway success or stagnated for years, they were calling the shots. At Google, I didn‚Äôt feel in control of my own projects, much less my career growth or my team‚Äôs direction.</p><p>I thought about it for months and finally decided. I wanted to be an Indie Hacker.</p><h2 id="one-last-thing-before-i-leave">One last thing before I leave<a href="#one-last-thing-before-i-leave" arialabel="Anchor"> üîóÔ∏é</a></h2><p>I still had unfinished business at Google. After investing three years into my promotion, I hated the idea of leaving with nothing to show for it. There were only a few months left until I could reapply for promotion, so I decided to give it one last shot.</p><p>Six weeks before the performance period ended, my project was canceled. Again.</p><p>Actually, my whole team was canceled. This was a common enough occurrence at Google that there was a euphemism for it: a defrag. Management transferred my team‚Äôs projects to our sister team in India. My teammates and I all had to start over in different areas of the company.</p><p>I applied for the promotion anyway. Weeks later, my manager read me the results. My performance rating was ‚ÄúSuperb,‚Äù the highest possible score, given to around 5% of employees each cycle. The promotion committee noted that in the past six months, I clearly demonstrated senior-level work. These were, uncoincidentally, the months when I was optimizing for promotion.</p><p><em>But</em> they felt that six months wasn‚Äôt a long enough track record, so‚Ä¶ better luck next time.</p><p>My manager told me I had a strong chance at promotion if I did the same quality work for another six months. I can‚Äôt say I wasn‚Äôt tempted, but by that point, I‚Äôd been hearing, ‚Äúgreat shot at promotion in six months,‚Äù for the past two years.</p><p>It was time to go.</p><h2 id="whats-next">What‚Äôs next?<a href="#whats-next" arialabel="Anchor"> üîóÔ∏é</a></h2><p>When I tell people I left Google, they assume I must have some brilliant startup idea. Only an <em>idiot</em> would leave a job as cushy as Google Software Engineer.</p><p>But I am indeed an idiot with no idea.</p><p>My plan is to try different projects for a few months each to see if any of them catch on, for example:</p><ul><li>Continue working on <a href="https://mtlynch.io/tags/ketohub">KetoHub</a> to see if I can make it profitable</li><li>Build a business on top of Sia, a distributed storage technology I‚Äôve <a href="https://mtlynch.io/tags/sia">written about frequently</a></li><li>Spend more time writing, and look for ways to earn money from it</li></ul><p>Google was a great place to work, and I learned valuable skills during my time there. Leaving was difficult because I had more to learn, but there will always be employers like Google. I won‚Äôt always have the freedom to start my own company, so I look forward to seeing where this takes me.</p><h2 id="updates">Updates<a href="#updates" arialabel="Anchor"> üîóÔ∏é</a></h2><ul><li><strong>Update (Feb. 1, 2019)</strong>: <a href="https://mtlynch.io/solo-developer-year-1/">My First Year as a Solo Developer</a></li><li><strong>Update (Jan. 31, 2020)</strong>: <a href="https://mtlynch.io/solo-developer-year-2/">My Second Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2021)</strong>: <a href="https://mtlynch.io/solo-developer-year-3/">My Third Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2022)</strong>: <a href="https://mtlynch.io/solo-developer-year-4/">My Fourth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2023)</strong>: <a href="https://mtlynch.io/solo-developer-year-5/">My Fifth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2024)</strong>: <a href="https://mtlynch.io/solo-developer-year-6/">My Sixth Year as a Bootstrapped Founder</a></li></ul><hr><p><em>Illustrations by <a href="https://www.loraineyow.com/">Loraine Yow</a>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mitochondria Are Alive (534 pts)]]></title>
            <link>https://www.asimov.press/p/mitochondria</link>
            <guid>42088758</guid>
            <pubDate>Fri, 08 Nov 2024 17:39:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.asimov.press/p/mitochondria">https://www.asimov.press/p/mitochondria</a>, See on <a href="https://news.ycombinator.com/item?id=42088758">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong><span>An opinion essay by </span><a href="https://www.hertzfoundation.org/person/liyam-chitayat/" rel="">Liyam Chitayat</a></strong></p><p>The cells within our body are the remnants of an ancient alliance.&nbsp;</p><p><span>In a 1967 paper called ‚Äú</span><a href="https://doi.org/10.1016/0022-5193(67)90079-3" rel="">On the Origin of Mitosing Cells</a><span>,‚Äù American evolutionary biologist Lynn Margulis proposed an idea that, upon first hearing, seems ludicrous. Her paper, in fact, was rejected by 12 different journals before it was published.</span></p><p>Margulis argued that one-and-a-half billion years ago, a primitive eukaryotic cell engulfed an oxygen-utilizing bacterium. But rather than digesting this bacterium ‚Äî or conversely, the bacterium destroying its newfound host ‚Äî the two cells gradually entered into an endosymbiotic relationship; the host provided nutrients and protection to the bacterium, and the bacterium supplied energy to the host. Margulis argued that this endosymbiosis event was a seminal ‚Äúinnovation engine‚Äù for biological systems, ultimately leading to the modern mitochondrion and chloroplast.</p><p>Margulis‚Äô theory was attacked and ridiculed, igniting academic hostilities that lasted for decades. Over time, though, biologists began to accept her ideas because the membrane structure and molecular machinery within mitochondria closely resemble that of extant bacteria. Most biologists today, however, also believe that mitochondria have ‚Äúdevolved‚Äù into little more than membrane-bound organelles, similar to inanimate components like the endoplasmic reticulum or Golgi apparatus.</p><p><span>But a swelling tide of scientific evidence about mitochondrial functions and dynamics suggests otherwise ‚Äî </span><em>mitochondria are not just organelles, but their own life forms.</em><strong>&nbsp;&nbsp;&nbsp;</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:309045,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>An image from L. Margulis‚Äô 1967 paper, depicting the origins of modern mitochondria.</figcaption></figure></div><p>This distinction between ‚Äúlife‚Äù on the one hand and ‚Äúmere membranous structure‚Äù on the other may seem trivial, but it‚Äôs a symptom of a deeper problem. Defining mitochondria as ‚Äúnonliving‚Äù isn‚Äôt just a classification mistake, nor a question of word choice. Rather, it is a fundamental misunderstanding of the nature and role of mitochondria. It inherently undermines our understanding of biological systems and deeply influences the tools we build to study them. </p><p>If we think of mitochondria as non-living organelles, how will we ever harness their full potential?</p><p>The precise definition of ‚Äúlife‚Äù has been debated since the inception of biology as a scientific field. Even today, researchers offer overlapping, but distinct, criteria. Molecular biologists tend to focus on characteristics like metabolism, growth and development, response to stimuli, reproduction, and the ability to process information or evolve. This definition uses ‚Äúchecklists‚Äù to determine whether or not an organism is alive.</p><p>Biophysicists often take a more rigorous approach, defining life by means of energetic terms. Physicists Erwin Schr√∂dinger and Ilya Prigogine said that living organisms maintain order despite the universe's tendency towards increasing entropy, a measure of how dispersed or disordered the energy within a system is. Living systems maintain far-from-equilibrium states, constantly exchanging matter and energy with their environment to sustain highly organized structures. Cells take in low-entropy inputs, such as food or sunlight, and expel high-entropy outputs, including waste.</p><p>Regardless of which definition one chooses, mitochondria are clearly alive.</p><p>Mitochondria carry their own genomes and express their own genes within their lumens, an internal pocket of watery space, using biomolecules distinct from the cell‚Äôs nucleus. Mitochondria also replicate and divide through binary fission, much like bacteria. If one considers bacteria as living entities ‚Äî and all biologists seem to ‚Äî then it is impossible to explain why mitochondria are not.</p><p>From a thermodynamic perspective, mitochondria take in low-entropy inputs from their host cell, such as glucose or fatty acids, and expel high-entropy outputs, including carbon dioxide and water. Mitochondria also pump out protons through their inner membrane to maintain an out-of-equilibrium thermodynamic balance, using the resulting gradient to produce the ATP molecules that fuel cellular functions, from DNA replication to protein synthesis.</p><p><span>From the molecular biologist‚Äôs perspective, a mitochondrion‚Äôs role is not limited to simple energy generation, either. Mitochondria also process</span><em> </em><span>information and interact with their environment, much like a human cell. They monitor steroid hormones, oxidative stress, heat, ATP levels, secondary metabolites, and </span><a href="https://journals.physiology.org/doi/full/10.1152/physrev.00058.2021#" rel="">many more molecules</a><span> floating through their environment, the cell‚Äôs cytoplasm. Mitochondria then use this information to precisely control cellular functions. For example, when a virus invades a cell, the mitochondria are critical in sensing the intrusion and signaling a host cell to undergo programmed cell death to halt its spread.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/abab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:327767,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Mitochondria are intimately involved in many cellular processes; not just energy production. Image by the author.</figcaption></figure></div><p>And finally, mitochondria grow and reproduce in a manner distinct from the host‚Äôs replication process. Mitochondria independently copy their circular genomes, known as mitochondrial DNA, and divide through binary fission. Notably, mitochondrial replication has several distinct properties from those observed during human cellular replication. Mitochondrial DNA mutates 100-1,000 times faster than the human genome and these mutations can significantly alter a mitochondrion‚Äôs fitness, thereby changing the fitness of its host cell. Mitochondria are thus agents of ‚Äî and subject to ‚Äî the forces of evolution.</p><p><span>Despite all this evidence, the main case made against mitochondria being alive is that they do not perform all of these functions </span><em>independently</em><span>, as they must be embedded within the cytoplasm of a host cell to function. However, such an argument is logically inconsistent because, by this same logic, most organisms on Earth would not be considered ‚Äúliving.‚Äù After all, nothing in biology lives in isolation from its environment.&nbsp;</span></p><p><span>Human life begins inside of another human, with a zygote requiring many months in the uterus to develop into an infant. Many other organisms ‚Äî not just mitochondria ‚Äî also live inside other cells. For example, the bacteria </span><em><a href="https://www.ncbi.nlm.nih.gov/books/NBK7624/" rel="">rickettsiae</a><span> </span></em><span>occupy the cytoplasm of cells of ticks, lice, fleas, and mites. Other bacteria, such as </span><em><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5911502/" rel="">Holospora spp.</a></em><span>, also live within the nucleus of various protists. All living creatures have evolved and live embedded within an environment or biological system, with different organisms embedded in different layers.</span></p><p>It seems like scientists have decided what is living based on whether or not an organism exists in certain, arbitrarily chosen layers of our biosphere. But this is a logical fallacy. Every living organism grows and adapts to occupy a specific context in the universe. We refer to this as the ‚Äúeffective niche‚Äù of the lifeform, which could be both inside and outside of another living system. Just because an organism has evolved to live in one niche does not mean that the organism cannot survive in another. Therefore, the so-called ‚Äúpotential niche‚Äù of a lifeform is often much larger than its effective niche.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:404460,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The ‚Äúpotential‚Äù niche of an organism is typically much larger than its ‚Äúeffective‚Äù niche. Image by the author.</figcaption></figure></div><p><span>Consider, for example, that free-living bacteria have been artificially implanted into the cytoplasms of different fungi. Researchers at ETH Zurich </span><a href="https://www.nature.com/articles/s41586-024-08010-x" rel="">recently implanted</a><span> ‚Äúbacteria into the filamentous fungus </span><em>Rhizopus microsporus</em><span> to follow the fate of artificially induced endosymbioses.‚Äù It is clear that the insertion of bacteria into other cells does not suddenly make those bacteria non-living.</span></p><p><span>Similarly, a mitochondrion‚Äôs effective niche is a host cell‚Äôs cytoplasm, but its potential niche is likely far greater. Mitochondria are not bound to their host cell; they can </span><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/tra.12951" rel="">travel between different cells</a><span>. Although different species carry distinct mitochondria, experiments show that mitochondria from one species can be transferred to another.&nbsp;</span></p><p><span>In 1997, scientists isolated mitochondria from chimpanzees and gorillas and showed that they are naturally internalized and integrated </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC23071/" rel="">into human cells</a><span>. Notably, the addition of external mitochondria even showed therapeutic benefits in </span><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.800883/full" rel="">heart failure and spinal cord injury</a><span>. Thus, the potential niche that mitochondria can live in is greater than their effective niche.&nbsp;</span></p><p>When Margulis fought to overturn widely-held ideas in evolutionary biology, it allowed biologists to understand how complexity emerges in biological systems with the creation of eukaryotes and the rise of multicellularity. By revisiting our understanding of mitochondria, we will similarly break down long-held scientific dogmas.</p><p><span>In the early 20th century, Albert Einstein and Claude Shannon laid out the three pillars of the physical world: matter, information, and energy. When Francis Crick and James Watson published their model of the DNA double helix, they created a paradigm shift in our ability to understand and control the first two: matter and information. In the 70 years since then, we‚Äôve developed powerful tools to study genes, decode how information moves through cells, and manipulate DNA using tools such as CRISPR-based gene editing. However, we have not yet reached an equal level of understanding of, or tools to manipulate, biological </span><em>energy</em><span>. Just as CRISPR enabled scientists to rewrite the code of life, we need similar tools to engineer mitochondria and control bioenergetics across the eukaryotic tree of life.</span></p><p>Despite more than a billion years of evolution, mitochondria still play critical roles within cells; they have not been displaced or rendered obsolete. This means that, as humans evolved, so too did the role of mitochondria in shaping our health and longevity. Mitochondrial dysfunction has long been linked to cardiovascular disorders, diabetes, Alzheimers, Parkinsons, amyotrophic lateral sclerosis, and other age-related diseases. In patients with these conditions, the mitochondria adopt abnormal and fragmented morphologies, failing to make enough energy for cells or sending improper communication signals. The diseased mitochondria gradually make toxic compounds that accelerate cell death.&nbsp;</p><p>Perhaps one of the paths to solving energy-related diseases, extending lifespan, or even engineering processes like photosynthesis lies in the complex interaction between our cells and the other lifeforms so actively inhabiting them. To find out, let‚Äôs embrace these eons-old alliances.</p><p><em>Thanks to Kate Adamala, Zeno Fox, Michael Retchin, Niko McCarty, and Ed Boyden for helpful feedback on this essay.</em></p><p><strong>Liyam Chitayat </strong><span>is a Hertz Fellow and PhD student at MIT working on synthetic endosymbiosis and building an initiative to integrate and accelerate the field. Liyam is also a Fellow of The Council on Strategic Risk.</span></p><p><strong>Cite: </strong><span>Liyam Chitayat. ‚ÄúMitochondria Are Alive‚Äù </span><em>Asimov Press </em><span>(2024). DOI: https://doi.org/10.62211/38pe-75hu</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pirating "The Pirate Bay" TV Series Is Ironically Difficult (104 pts)]]></title>
            <link>https://torrentfreak.com/pirating-the-pirate-bay-tv-series-is-ironically-difficult-241108/</link>
            <guid>42088731</guid>
            <pubDate>Fri, 08 Nov 2024 17:37:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/pirating-the-pirate-bay-tv-series-is-ironically-difficult-241108/">https://torrentfreak.com/pirating-the-pirate-bay-tv-series-is-ironically-difficult-241108/</a>, See on <a href="https://news.ycombinator.com/item?id=42088731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

          <p>    
                 <!-- Breadcrumb NavXT 7.3.1 -->
<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Piracy category archives." href="https://torrentfreak.com/category/piracy/"><span property="name">Piracy</span></a><meta property="position" content="2"></span> &gt; <span></span>
	</p>

        <p>
                      <span> </span>
                    The Pirate Bay made its debut as a TV series on the Swedish streaming platform SVT Play earlier today. International viewers are left waiting until other services pick it up. In the meantime, some may be tempted to explore unofficial channels for pirated copies of the show. But finding a pirated copy is proving surprisingly difficult.
        </p>
      </div><div>
        <p><img loading="lazy" decoding="async" src="https://torrentfreak.com/images/tpbseries-300x193.jpg" alt="tpb series" width="300" height="193" srcset="https://torrentfreak.com/images/tpbseries-300x193.jpg 300w, https://torrentfreak.com/images/tpbseries.jpg 1033w" sizes="(max-width: 300px) 100vw, 300px">The inception and early years of The Pirate Bay are <a href="https://torrentfreak.com/the-pirate-bay-celebrates-its-20th-anniversary-230919/">an intriguing chapter</a> of the Internet‚Äôs history. </p>
<p>Founded by the Piratbyr√•n group, The Pirate Bay and its founders embraced the power of the new BitTorrent technology: to copy culture <em>en masse</em>. </p>
<p>By doing so, they altered the public discourse, <a href="https://torrentfreak.com/the-pirate-bays-rebellious-history-in-doodles-180429/">openly taunting</a> the entertainment industries in the process. </p>
<p>This chapter didn‚Äôt end as planned for the lead characters; Fredrik Neij (TiAMO), Peter Sunde (Brokep), and Gotffrid Svartholm (Anakata), who were eventually <a href="https://torrentfreak.com/the-pirate-bay-lives-on-a-decade-after-operators-were-found-guilty-190420/">sentenced to prison</a>. By then, however, they had sparked a digital and political revolution, the impact of which is still felt today.</p>
<h2>TV Series</h2>
<p>The Pirate Bay didn‚Äôt just trigger a file-sharing bonanza, it was exemplary for the rapid rise of the web. New technology empowered people whose lives were traditionally dictated by mainstream entertainment and publishing companies. </p>
<p>The web created new forms to share news, opinions, knowledge, and media. And few Swedes with keyboards had the power to upset billion-dollar companies.</p>
<p>It doesn‚Äôt take a genius to realize that this is a good story, perhaps even a movie script? This includes the people at the Swedish production company B-Reel Films, who got the green light to turn it into a TV series a few years ago. </p>
<p>The series <a href="https://www.svtplay.se/the-pirate-bay">premiered</a> at the on-demand platform of the Swedish national broadcaster SVT a few hours ago. International deals haven‚Äôt been announced, but pirates can generally get access anyway.</p>
<h2>Pirating ‚ÄòThe Pirate Bay‚Äô Series</h2>
<p>Soon after the first two episodes of The Pirate Bay series came out, scene release copies started <a href="https://predb.org/">circulating online</a>. As one would expect. </p>
<p>The Scene group OLLONBORRE, which specializes in Swedish content, was the first to pick the show up. Within minutes, the first 1080p WEB-rips were posted on private scene servers and 720p copies followed a few hours later. </p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/piratebayleak2.jpg.webp 714w, https://torrentfreak.com/images/piratebayleak2-300x103.jpg.webp 300w" sizes="(max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/piratebayleak2.jpg" alt="tpb-leak" width="600" height="207" srcset="https://torrentfreak.com/images/piratebayleak2.jpg 714w, https://torrentfreak.com/images/piratebayleak2-300x103.jpg 300w, https://torrentfreak.com/images/piratebayleak2-600x207.jpg 600w, https://torrentfreak.com/images/piratebayleak2-150x52.jpg 150w" sizes="(max-width: 600px) 100vw, 600px">
</picture>
</center>
<p>Interestingly, pirate releases have yet to make their way to The Pirate Bay. We haven‚Äôt seen any other copies on other public pirate sites either, which is surprising given the topic of the series. </p>
<p>It‚Äôs common knowledge that <a href="https://en.wikipedia.org/wiki/Warez_scene">The Scene</a> ‚Äì a secretive network of release groups ‚Äì prefers to keep its releases private. Therefore, it wasn‚Äôt happy with The Pirate Bay‚Äôs public nature and rise to prominence in the early 2003s, which is highlighted in the first episodes of the TV series. </p>
<p>However, we expected non-scene release groups would be eager to pick up the show. Apparently that‚Äôs not the case, yet.  </p>
<h2>Fact-Based Fiction</h2>
<p>While the broader international audience must wait for the officially sanctioned release, we can add a disclaimer for future viewers. While entertaining and engaging, the series should not be taken as fact.</p>
<p>The script is loosely based on The Pirate Bay story and many of the scenes are fiction. New elements were added, timelines have been changed, and the characters are constructed by the show‚Äôs writers, which is not necessarily how they came across in real life.</p>
<center>


</center>
<p>The Pirate Bay‚Äôs founders <a href="https://torrentfreak.com/tpb-founders-are-not-involved-in-the-the-pirate-bay-tv-series-230407/">didn‚Äôt participate in the production</a>, which means that the creators had no other option than to fill in some blanks. </p>
<p>In an interview with <a href="https://dramaquarterly.com/">Drama Quarterly</a>, director Jens Sj√∂gren previously acknowledged that they had to mix facts and fiction to tell the story. He understands that some people won‚Äôt like that.</p>
<p>‚ÄúPeople are going to say a lot of shit about it. ‚ÄòIt was not exactly like this, blah, blah, blah.‚Äô No, but we really broke our fucking backs to try to just embrace the feeling of really struggling with something you believe in so hard ‚Äì so much so you would almost be ready to go to prison for it,‚Äù Sj√∂gren said.</p>
<p>It wasn‚Äôt the creators‚Äô main goal to create a literal replay of what happened. Instead, Sj√∂gren said that he tried to capture the spirit of The Pirate Bay founders‚Äô ambitions and goals. </p>
<p>Whether this succeeded is up to the viewer, but the series definitely shows the contrasting personalities of Fredrik, Gottfrid, and Peter. They were all in it for different reasons, which may be part of their initial success. </p>
<p><em>‚Äî</em></p><p><em>This weekend we will publish a follow-up article, sharing some thoughts on the series with input from Pirate Bay co-founder Peter Sunde and Piratbyr√•n co-founder Rasmus Fleischer.</em></p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genetic repair via CRISPR can inadvertently introduce other defects (107 pts)]]></title>
            <link>https://phys.org/news/2024-11-genetic-crispr-inadvertently-defects.html</link>
            <guid>42088504</guid>
            <pubDate>Fri, 08 Nov 2024 17:13:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-11-genetic-crispr-inadvertently-defects.html">https://phys.org/news/2024-11-genetic-crispr-inadvertently-defects.html</a>, See on <a href="https://news.ycombinator.com/item?id=42088504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/use-of-genetic-scissor.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/use-of-genetic-scissor.jpg" data-sub-html="Deletions between on-target loci upon treatment with Cas9-sgRNA1 RNPs in PLB-985 NCF1 ŒîGT cells. Credit: <i>Communications Biology</i> (2024). DOI: 10.1038/s42003-024-06959-z">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/use-of-genetic-scissor.jpg" alt="Use of 'genetic scissors' carries risks" title="Deletions between on-target loci upon treatment with Cas9-sgRNA1 RNPs in PLB-985 NCF1 ŒîGT cells. Credit: Communications Biology (2024). DOI: 10.1038/s42003-024-06959-z" width="800" height="530">
             <figcaption>
                Deletions between on-target loci upon treatment with Cas9-sgRNA1 RNPs in PLB-985 NCF1 ŒîGT cells. Credit: <i>Communications Biology</i> (2024). DOI: 10.1038/s42003-024-06959-z
            </figcaption>        </figure>
    </div><p>The CRISPR molecular scissors have the potential to revolutionize the treatment of genetic diseases. This is because they can be used to correct specific defective sections of the genome. Unfortunately, however, there is a catch: under certain conditions, the repair can lead to new genetic defects‚Äîas in the case of chronic granulomatous disease.</p>


										      
																																	<p>This <a href="https://www.nature.com/articles/s42003-024-06959-z" target="_blank">was reported</a> in <i>Communications Biology</i> by a team of basic researchers and physicians from the clinical research program ImmuGene at the University of Zurich (UZH).</p>
<p>Chronic granulomatous disease is a rare hereditary disease that affects about one in 120,000 people. The disease impairs the immune system, making patients susceptible to serious and even life-threatening infections.</p>
<p>It is caused by the absence of two letters, called bases, in the DNA sequence of the NCF1 gene. This error results in the inability to produce an enzyme complex that plays an important role in the immune defense against bacteria and molds.</p>
<h2>The CRISPR tool works‚Ä¶</h2>
<p>The research team has now succeeded in using the CRISPR system to insert the missing letters in the right place. They performed the experiments in cell cultures of immune cells that had the same <a href="https://phys.org/tags/genetic+defect/" rel="tag">genetic defect</a> as people with chronic granulomatous disease.</p>
<p>"This is a promising result for the use of CRISPR technology to correct the mutation underlying this disease," says team leader Janine Reichenbach, professor of somatic gene therapy at the University Children's Hospital Zurich and the Institute for Regenerative Medicine at UZH.</p>
<h2>‚Ä¶ but unfortunately, it's not perfect</h2>
<p>Interestingly however, some of the repaired cells now showed new defects. Entire sections of the chromosome where the repair had taken place were missing. The reason for this is the special genetic constellation of the NCF1 gene: it is present three times on the same chromosome, once as an active gene and twice in the form of pseudogenes.</p>
<p>These have the same sequence as the defective NCF1 and are not normally used to form the enzyme complex.</p>
<p>CRISPR's <a href="https://phys.org/tags/molecular+scissors/" rel="tag">molecular scissors</a> cannot distinguish between the different versions of the gene and therefore occasionally cut the DNA strand at multiple locations on the chromosome‚Äîat the active NCF1 gene as well as at the pseudogenes. When the sections are subsequently rejoined, entire gene segments may be misaligned or missing. The medical consequences are unpredictable and, in the worst case, contribute to the development of leukemia.</p>
<p>"This calls for caution when using CRISPR technology in a clinical setting," says Reichenbach.</p>

																																						
																																			<h2>Safer method sought</h2>
<p>To minimize the risk, the team tested a number of alternative approaches, including modified versions of CRISPR components. They also looked at using protective elements that reduce the likelihood of the genetic scissors cutting the chromosome at multiple sites simultaneously. Unfortunately, none of these measures were able to completely prevent the unwanted side effects.</p>
<p>"This study highlights both the promising and challenging aspects of CRISPR-based therapies," says co-author Martin Jinek, a professor at the UZH Department of Biochemistry. He says the study provides valuable insights for the development of gene-editing therapies for chronic granulomatous <a href="https://phys.org/tags/disease/" rel="tag">disease</a> and other inherited disorders.</p>
<p>"However, further technological advances are needed to make the method safer and more effective in the future."</p>

																																																					
																				<div>
																						<p><strong>More information:</strong>
												Federica Raimondi et al, Gene editing of NCF1 loci is associated with homologous recombination and chromosomal rearrangements, <i>Communications Biology</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1038/s42003-024-06959-z" target="_blank">DOI: 10.1038/s42003-024-06959-z</a>
																						
																						</p>
																					</div>
                               											
																					
                              										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Genetic repair via CRISPR can inadvertently introduce other defects, researchers show (2024, November 6)
												retrieved 9 November 2024
												from https://phys.org/news/2024-11-genetic-crispr-inadvertently-defects.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making Electronic Calipers (140 pts)]]></title>
            <link>https://kevinlynagh.com/calipertron/</link>
            <guid>42087560</guid>
            <pubDate>Fri, 08 Nov 2024 15:29:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevinlynagh.com/calipertron/">https://kevinlynagh.com/calipertron/</a>, See on <a href="https://news.ycombinator.com/item?id=42087560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://kevinlynagh.com/">‚Üê Back to Kevin's homepage</a><span>Published: 2024 November 2</span></p><p>Have you ever wished for a 500 Hz, millimeter-precise linear position sensing system?
Well you‚Äôre in luck ‚Äî all you need is some circuit board, a basic microcontroller, and a wee bit of maths!</p>

<video src="https://kevinlynagh.com/calipertron/2024_11_02_caliper_demo.mp4" controls="true" loop="true" autoplay="true"></video>

<p>See also the <a href="https://github.com/lynaghk/calipertron/">full source code and my research log</a> for this project.</p>

<h2 id="why-make-calipers">Why make calipers?</h2>

<p>Electronic calipers are awesome.
<a href="https://amzn.to/3BVZhvB">This \$30 pair</a> has served me well for years, reading far more precision than my skills justify:</p>

<p><img src="https://kevinlynagh.com/calipertron/calipers.png" alt="calipers"></p>

<p>Such calipers work via capacitive coupling between a PCB on the powered slidey display and a passive PCB ‚Äúscale‚Äù in the stationary spine.</p>

<p>Back in March, I idly wondered if the same working principle could be used for a cheap and cheerful ‚Äúmaker-friendly‚Äù positioning system.
E.g., slide some passive PCB scales into an aluminum extrusion rail, add a capacitive pickup to the bottom of whatever carriage you‚Äôve got riding along, and <em>tada</em> ‚Äî you‚Äôve got sub-mm closed-loop positioning.
All for the cost of some PCB, a few GPIO pins, and some firmware (so free, basically).</p>

<p>I figured someone else must‚Äôve done this before, but I wasn‚Äôt able to find any ‚Äúopen source caliper‚Äù projects.
The closest was <a href="https://hackaday.io/project/194778-diy-digital-caliper-calipatron/log/227428-research">this hackaday.io project page</a>, started literally a month before.</p>

<p>I reached out to the author, Mitko, and offered to implement the firmware if they sent me a PCB.
My main motivation was to learn some digital signal processing, as I‚Äôd never studied it beyond a passing undergrad mention of the Fourier transform.</p>

<p>If you just want some off-the-shelf precision measurements and don‚Äôt want to go on <em>An Adventure</em>, you may want to consider instead:</p>

<ul>
<li>reading measurement data directly out of cheap calipers via their <a href="https://hackaday.com/2016/05/17/improved-digital-caliper-interfacing-including-3d-printed-connector/">secret data interface</a></li>
<li>searching for ‚Äúdigital read out‚Äù (DRO) kits, which is the generic term for all sorts of capacitive, optical, and magnetic precision linear and angular measurement schemes (typically for retrofitting manual machine equipment with a digital readout, so <em>you</em> can be the ‚Äú<a href="https://en.wikipedia.org/wiki/Numerical_control">NC</a>‚Äù of ‚ÄúCNC‚Äù). E.g., this  <a href="https://www.sra-measurement.com/digital-readout-systems/magnetic-linear-encoder-reading-head-1-micron-resolution">\$200 magnetic encoder</a> with some <a href="https://www.sra-measurement.com/high-accuracy-magnetic-linear-tape">\$1/cm linear tape</a>.)</li>
</ul>

<h2 id="caliper-theory">Caliper theory</h2>

<p>Here‚Äôs a photo of calipers disassembled by my collaborator Mitko (annotations mine):</p>

<p><img src="https://kevinlynagh.com/calipertron/book_calipers.jpg" alt=""></p>

<p>The left half is the caliper‚Äôs stationary metal spine, which contains a passive PCB with a pattern of ‚Äúreflectors‚Äù (which look sorta like the capital letter ‚ÄúT‚Äù rotated 90 degrees clockwise).</p>

<p>The right half is the powered display part of the calipers, which slides up and down along the metal stem; this PCB has a long receiver pad and a bunch of emitter pads that look like the keys of a piano.</p>

<p>When assembled (folded together like a book), the reflector ‚ÄúT‚Äù stems are over top the signal-emitting piano keys and the reflector ‚ÄúT‚Äù crossbars are over the receiver pad.</p>

<p>(Pedant note: There‚Äôs not actually any ‚Äúreflection‚Äù going on, the plates are capacitively coupled. I just find the term ‚Äúreflector‚Äù conveys the right vibe.)</p>

<p>Here‚Äôs a close up, taken from Big Clive‚Äôs excellent caliper <a href="https://youtu.be/fKSSY1gzCEs?t=588">teardown video</a> (annotations mine):</p>

<p><img src="https://kevinlynagh.com/calipertron/diagram.jpg" alt=""></p>

<p>The top half is the stationary part and the bottom half is slidey part.</p>

<p>Note the following details of the geometry:</p>

<ul>
<li>The slidey part emits 8 signals through the little piano keys (labeled), which repeat along the entire length.</li>
<li>The reflector plate stems are exactly 4 keys wide.</li>
</ul>

<p>In essence, the reflector plate ‚Äúadds up‚Äù the signals of the piano keys underneath it (in this photo, signals 0, 1, 2, and 3).</p>

<p>Imagine sliding the caliper display 0.5 keys to the right.
Then the reflectors would be above <em>half</em> of signal 0, all of signals 1, 2, 3, and half of signal 4.
Sliding another 0.5 keys to the right, the reflectors would then be on top of signals 1, 2, 3, and 4.</p>

<p>The reflectors are just passive pieces of metal; all they can do is sum together the signals coupled to them.
This summed signal is then reflected back to the slidey part‚Äôs single receiver pad.</p>

<p>So what are the 8 signals you should emit?</p>

<p>If you use sine waves at the same frequency but different phases, then their reflected sum will always be a sine wave of the original frequency, with some combined phase and amplitude (<a href="https://www.johndcook.com/blog/2020/08/17/adding-phase-shifted-sine-waves/">proof</a>).</p>

<p>That is: <strong>as you move the slidey part, the phase offset of the reflected signal changes</strong>.</p>

<p>Since we have 8 signals, if we evenly divide the unit circle so that the nth signal is:</p>

<p>$$\sin\left( 2\pi f + 2\pi\frac{n}{8} \right)$$</p>

<p>then we can track the cumulative phase offset of the received signal (relative to some initial position) and know that every $2\pi$ moved in phase space corresponds to a linear movement 8 emitter keys wide.</p>

<h2 id="microcontroller-implementation">Microcontroller implementation</h2>

<p>Mitko mailed me version 1.1 of his PCB (<a href="https://github.com/MitkoDyakov/Calipatron/blob/444c72c3e81eab0a2e7ee198f5574062dc1fc510/Hardware/V1.1/Schematics%20V1.1.pdf">schematic</a>), which is built around an stm32f103 microcontroller.</p>

<p>I wrote the firmware using the <a href="https://github.com/embassy-rs/embassy">Embassy Rust framework</a>, which worked reasonably well.
(‚ÄúWell‚Äù as far as embedded goes ‚Äî there was a side quest tracking down an intermittent freeze that locked out the debugger, which seems to be a genuine hardware bug triggered only on <a href="https://github.com/lynaghk/repro-stm32f103-rust-embassy-freeze/">older ARM core silicon revisions</a>.)</p>

<p>The firmware needs to:</p>

<ul>
<li>emit 8 sinusoidal waves</li>
<li>measure the reflected sum calculate the phase offset</li>
</ul>

<p>Let‚Äôs take these in turn.</p>

<h2 id="emitting-sinusoidal-waves">Emitting sinusoidal waves</h2>

<p>The stm32f103 doesn‚Äôt have a digital to analog converter, but we can emit a sinusoidal wave using ‚Äúpulse density modulation‚Äù (PDM).
The technique is similar to PWM (‚Äúpulse width modulation‚Äù) in that an analog signal level is approximated by having a digital signal stay ‚Äúon‚Äù for the appropriate fraction of time.
But while PWM has its ‚Äúon‚Äù fraction all at once, the PDM signal spaces it out across the sample window.</p>

<p>For example, to represent an analog level of 50% using 8 pulses:</p>
<div><pre><span></span>PWM: X X X X . . . .
PDM: X . X . X . X .
</pre></div>
<p>the PWM signal stays high (<code>x</code>) for the first half of the period, whereas the PDM signal alternates.
This is preferable for our use case, since it means the switching noise is at a higher frequency, further away from our lower frequency sinusoidal wave.</p>

<p>We need all of the waves to move in lockstep with each other, so rather than updating the pins one-by-one, we update all of them with a single 32-bit write to the GPIO‚Äôs ‚Äúbit set reset register‚Äù (BSRR).</p>

<p>Furthermore, since we know how many PDM samples we want in advance, we can take pity on our lil‚Äô stm32f103 (which doesn‚Äôt even have a hardware floating point unit) and calculate all of the BSRR values at compile-time.
Rust‚Äôs formal compile-time machinery <a href="https://users.rust-lang.org/t/constant-trigonometry/58565">doesn‚Äôt support trigonometry</a>, so we use a <code>build.rs</code> script to generate a string of code at compile-time:</p>
<div><pre><span></span><span>fn</span> <span>generate_pdm_bsrr</span><span>(</span><span>n_samples</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>String</span> <span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>output</span><span> </span><span>=</span><span> </span><span>String</span>::<span>new</span><span>();</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"pub const PDM_SIGNAL: [u32; "</span><span>);</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>n_samples</span><span>.</span><span>to_string</span><span>());</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"] = [</span><span>\n</span><span>"</span><span>);</span><span></span>

<span>    </span><span>let</span><span> </span><span>n_waves</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span><span></span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>errors</span><span> </span><span>=</span><span> </span><span>vec!</span><span>[</span><span>0.0</span><span>;</span><span> </span><span>n_waves</span><span>];</span><span></span>
<span>    </span><span>for</span><span> </span><span>sample</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>n_samples</span><span> </span><span>{</span><span></span>
<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>bsrr</span><span> </span><span>=</span><span> </span><span>0</span><span>u32</span><span>;</span><span></span>
<span>        </span><span>for</span><span> </span><span>wave</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>n_waves</span><span> </span><span>{</span><span></span>
<span>            </span><span>let</span><span> </span><span>phase_offset</span><span> </span><span>=</span><span> </span><span>2.0</span><span> </span><span>*</span><span> </span><span>PI</span><span> </span><span>*</span><span> </span><span>(</span><span>wave</span><span> </span><span>as</span><span> </span><span>f64</span><span>)</span><span> </span><span>/</span><span> </span><span>(</span><span>n_waves</span><span> </span><span>as</span><span> </span><span>f64</span><span>);</span><span></span>
<span>            </span><span>let</span><span> </span><span>angle</span><span> </span><span>=</span><span> </span><span>2.0</span><span> </span><span>*</span><span> </span><span>PI</span><span> </span><span>*</span><span> </span><span>(</span><span>sample</span><span> </span><span>as</span><span> </span><span>f64</span><span> </span><span>/</span><span> </span><span>n_samples</span><span> </span><span>as</span><span> </span><span>f64</span><span>)</span><span> </span><span>+</span><span> </span><span>phase_offset</span><span>;</span><span></span>
<span>            </span><span>let</span><span> </span><span>cosine</span><span> </span><span>=</span><span> </span><span>angle</span><span>.</span><span>cos</span><span>()</span><span> </span><span>as</span><span> </span><span>f32</span><span>;</span><span></span>
<span>            </span><span>let</span><span> </span><span>normalized_signal</span><span> </span><span>=</span><span> </span><span>(</span><span>cosine</span><span> </span><span>+</span><span> </span><span>1.0</span><span>)</span><span> </span><span>/</span><span> </span><span>2.0</span><span>;</span><span></span>

<span>            </span><span>if</span><span> </span><span>normalized_signal</span><span> </span><span>&gt;</span><span> </span><span>errors</span><span>[</span><span>wave</span><span>]</span><span> </span><span>{</span><span></span>
<span>                </span><span>bsrr</span><span> </span><span>|=</span><span> </span><span>1</span><span> </span><span>&lt;&lt;</span><span> </span><span>wave</span><span>;</span><span> </span><span>// set bit</span>
<span>                </span><span>errors</span><span>[</span><span>wave</span><span>]</span><span> </span><span>+=</span><span> </span><span>1.0</span><span> </span><span>-</span><span> </span><span>normalized_signal</span><span>;</span><span></span>
<span>            </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span>
<span>                </span><span>bsrr</span><span> </span><span>|=</span><span> </span><span>1</span><span> </span><span>&lt;&lt;</span><span> </span><span>(</span><span>wave</span><span> </span><span>+</span><span> </span><span>16</span><span>);</span><span> </span><span>// reset bit</span>
<span>                </span><span>errors</span><span>[</span><span>wave</span><span>]</span><span> </span><span>-=</span><span> </span><span>normalized_signal</span><span>;</span><span></span>
<span>            </span><span>}</span><span></span>
<span>        </span><span>}</span><span></span>
<span>        </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>format!</span><span>(</span><span>"    {:#034b},</span><span>\n</span><span>"</span><span>,</span><span> </span><span>bsrr</span><span>));</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"];</span><span>\n</span><span>"</span><span>);</span><span></span>
<span>    </span><span>output</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>This emitted string is then written to a file, which we <code>import</code> as usual from our main code namespace.
The <code>PDM_SIGNAL</code> const slice is then baked into the firmware, and at runtime a hardware timer and a DMA task is used copy each value directly to BSRR at a fixed rate.
This prevents any jitter in the emitted signal, as after starting the transmission the CPU is no longer involved.</p>

<h2 id="measuring-phase-offset">Measuring phase offset</h2>

<p>The reflected composite wave is measured by the stm32f103‚Äôs ADC.
A DMA task is triggered at the same time as the emitted PDM signals, and it reads a fixed number of samples into a buffer.</p>

<p>So how do we get the phase offset?</p>

<p>If you‚Äôre like me, the first thing you need to do is read some textbooks to figure out what‚Äôs what.
I recommend <a href="https://amzn.to/3MDLdZN">Understanding Digital Signal Processing</a> by Richard Lyons, as the book has a casual friendly style and is clearly written by an experienced engineer ‚Äî the final chapter is simply 150 pages of ‚ÄúDigital Signal Processing Tricks‚Äù!</p>

<p>Anyway, we know from earlier that our reflected signal $s(t)$ is the sum of the sinusoidal signals that we emitted, so it must also be a sinusoid with some phase offset; let‚Äôs call it $A \cos( \omega t + \phi)$ (with $A$ some constant representing a change in amplitude due to our capacitive coupling, amplification, etc. compared to our original emitted signal).</p>

<p>Then as I‚Äôm sure you recall from <a href="https://mathworld.wolfram.com/TrigonometricAdditionFormulas.html">trigonometric addition formula</a> from grade school, we can rewrite this as:</p>

<p>$$
\begin{align}
s(t) &amp;= A \cos( \omega t + \phi)\newline
     &amp;= A \left[ \cos( \omega t)\cos(\phi) - \sin( \omega t)\sin(\phi) \right]
\end{align}
$$</p>

<p>If we correlate our signal with $\cos(\omega t)$ then we‚Äôre left with $A \cos(\phi)$, and similarly for sin.
Thus:</p>

<p>$$
\begin{align}
\frac{\mathrm{Corr}\left(s(t), \sin(\omega t)\right)}{\mathrm{Corr}\left(s(t), \cos(\omega t)\right)} &amp;= \frac{A \sin(\phi)} {A \cos(\phi)} \newline
\arctan\left(\frac{\mathrm{Corr}\left(s(t), \sin(\omega t)\right)}{\mathrm{Corr}\left(s(t), \cos(\omega t)\right)}\right) &amp;= \phi
\end{align}
$$</p>

<p>The correlation operator itself is simple: it‚Äôs the sum of the product of the two signals at matching points in time.</p>

<p>All we need to do is figure out the exact times of our $s(t)$ samples, which can be derived by the sampling rate of the ADC.</p>

<p>All of the terms besides our measured signal samples $s(t)$ are knowable at compile-time, so we can again generate a lookup table for our microcontroller to use:</p>
<div><pre><span></span><span>fn</span> <span>generate_sine_cosine_table</span><span>(</span><span></span>
<span>    </span><span>signal_frequency</span>: <span>f64</span><span>,</span><span></span>
<span>    </span><span>sampling_frequency</span>: <span>f64</span><span>,</span><span></span>
<span>    </span><span>num_samples</span>: <span>usize</span><span>,</span><span></span>
<span>)</span><span> </span>-&gt; <span>String</span> <span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>output</span><span> </span><span>=</span><span> </span><span>String</span>::<span>new</span><span>();</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"pub const SINE_COSINE_TABLE: [(f32, f32); "</span><span>);</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>num_samples</span><span>.</span><span>to_string</span><span>());</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"] = [</span><span>\n</span><span>"</span><span>);</span><span></span>

<span>    </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>num_samples</span><span> </span><span>{</span><span></span>
<span>        </span><span>let</span><span> </span><span>angle</span><span> </span><span>=</span><span> </span><span>2.0</span><span> </span><span>*</span><span> </span><span>PI</span><span> </span><span>*</span><span> </span><span>signal_frequency</span><span> </span><span>*</span><span> </span><span>(</span><span>i</span><span> </span><span>as</span><span> </span><span>f64</span><span> </span><span>*</span><span> </span><span>(</span><span>1.0</span><span> </span><span>/</span><span> </span><span>sampling_frequency</span><span>));</span><span></span>
<span>        </span><span>let</span><span> </span><span>sine</span><span> </span><span>=</span><span> </span><span>angle</span><span>.</span><span>sin</span><span>()</span><span> </span><span>as</span><span> </span><span>f32</span><span>;</span><span></span>
<span>        </span><span>let</span><span> </span><span>cosine</span><span> </span><span>=</span><span> </span><span>angle</span><span>.</span><span>cos</span><span>()</span><span> </span><span>as</span><span> </span><span>f32</span><span>;</span><span></span>
<span>        </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>format!</span><span>(</span><span>"    ({:?}, {:?}),</span><span>\n</span><span>"</span><span>,</span><span> </span><span>sine</span><span>,</span><span> </span><span>cosine</span><span>));</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"];</span><span>\n</span><span>"</span><span>);</span><span></span>
<span>    </span><span>output</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>The build.rs script is then:</p>
<div><pre><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span></span>

<span>    </span><span>// lol, compile-time-programming by literally writing code to a file that we import</span>
<span>    </span><span>let</span><span> </span><span>out_dir</span><span> </span><span>=</span><span> </span><span>std</span>::<span>env</span>::<span>var</span><span>(</span><span>"OUT_DIR"</span><span>).</span><span>unwrap</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>dest_path</span><span> </span><span>=</span><span> </span><span>std</span>::<span>path</span>::<span>Path</span>::<span>new</span><span>(</span><span>&amp;</span><span>out_dir</span><span>).</span><span>join</span><span>(</span><span>"constants.rs"</span><span>);</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>f</span><span> </span><span>=</span><span> </span><span>File</span>::<span>create</span><span>(</span><span>&amp;</span><span>dest_path</span><span>).</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>let</span><span> </span><span>pdm_frequency</span>: <span>u32</span> <span>=</span><span> </span><span>100_000</span><span>;</span><span> </span><span>// 100 kHz</span>
<span>    </span><span>f</span><span>.</span><span>write_all</span><span>(</span><span>format!</span><span>(</span><span>"pub const PDM_FREQUENCY: u32 = {:?};</span><span>\n</span><span>"</span><span>,</span><span> </span><span>pdm_frequency</span><span>).</span><span>as_bytes</span><span>())</span><span></span>
<span>        </span><span>.</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>let</span><span> </span><span>pdm_length</span><span> </span><span>=</span><span> </span><span>128</span><span>;</span><span></span>

<span>    </span><span>let</span><span> </span><span>num_samples</span><span> </span><span>=</span><span> </span><span>512</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>signal_frequency</span><span> </span><span>=</span><span> </span><span>pdm_frequency</span><span> </span><span>as</span><span> </span><span>f64</span><span> </span><span>/</span><span> </span><span>pdm_length</span><span> </span><span>as</span><span> </span><span>f64</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>adc_frequency</span><span> </span><span>=</span><span> </span><span>12_000_000.</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>adc_sample_cycles</span><span> </span><span>=</span><span> </span><span>71.5</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>adc_sample_overhead_cycles</span><span> </span><span>=</span><span> </span><span>12.5</span><span>;</span><span> </span><span>// see reference manual section 11.6</span>
<span>    </span><span>let</span><span> </span><span>sampling_frequency</span><span> </span><span>=</span><span> </span><span>adc_frequency</span><span> </span><span>/</span><span> </span><span>(</span><span>adc_sample_cycles</span><span> </span><span>+</span><span> </span><span>adc_sample_overhead_cycles</span><span>);</span><span></span>

<span>    </span><span>f</span><span>.</span><span>write_all</span><span>(</span><span></span>
<span>        </span><span>generate_sine_cosine_table</span><span>(</span><span>signal_frequency</span><span>,</span><span> </span><span>sampling_frequency</span><span>,</span><span> </span><span>num_samples</span><span>).</span><span>as_bytes</span><span>(),</span><span></span>
<span>    </span><span>)</span><span></span>
<span>    </span><span>.</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>f</span><span>.</span><span>write_all</span><span>(</span><span>generate_pdm_bsrr</span><span>(</span><span>pdm_length</span><span>).</span><span>as_bytes</span><span>())</span><span></span>
<span>        </span><span>.</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>/// ...</span>
<span>}</span><span></span>
</pre></div>
<p>Finally, at runtime we‚Äôre left with this loop:</p>
<div><pre><span></span><span>loop</span><span> </span><span>{</span><span></span>

<span>  </span><span>// start PDM emission via DMA</span>
<span>  </span><span>// start ADC via DMA</span>
<span>  </span><span>// wait for ADC to read NUM_SAMPLES</span>
<span>  </span><span>// then...</span>

<span>  </span><span>let</span><span> </span><span>mut</span><span> </span><span>sum_sine</span>: <span>f32</span> <span>=</span><span> </span><span>0.0</span><span>;</span><span></span>
<span>  </span><span>let</span><span> </span><span>mut</span><span> </span><span>sum_cosine</span>: <span>f32</span> <span>=</span><span> </span><span>0.0</span><span>;</span><span></span>

<span>  </span><span>let</span><span> </span><span>adc_buf</span><span> </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>&amp;</span><span>ADC_BUF</span><span>[</span><span>..</span><span>]</span><span> </span><span>};</span><span></span>

<span>  </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>NUM_SAMPLES</span><span> </span><span>{</span><span></span>
<span>      </span><span>let</span><span> </span><span>(</span><span>sine</span><span>,</span><span> </span><span>cosine</span><span>)</span><span> </span><span>=</span><span> </span><span>SINE_COSINE_TABLE</span><span>[</span><span>i</span><span>];</span><span></span>
<span>      </span><span>sum_sine</span><span> </span><span>+=</span><span> </span><span>adc_buf</span><span>[</span><span>i</span><span>]</span><span> </span><span>as</span><span> </span><span>f32</span><span> </span><span>*</span><span> </span><span>sine</span><span>;</span><span></span>
<span>      </span><span>sum_cosine</span><span> </span><span>+=</span><span> </span><span>adc_buf</span><span>[</span><span>i</span><span>]</span><span> </span><span>as</span><span> </span><span>f32</span><span> </span><span>*</span><span> </span><span>cosine</span><span>;</span><span></span>
<span>  </span><span>}</span><span></span>
<span>  </span><span>let</span><span> </span><span>phase</span><span> </span><span>=</span><span> </span><span>sum_sine</span><span>.</span><span>atan2</span><span>(</span><span>sum_cosine</span><span>);</span><span></span>

<span>  </span><span>// add latest phase reading to position estimation.</span>
<span>  </span><span>// this object also handles wraparound and hysteresis.</span>
<span>  </span><span>position_estimator</span><span>.</span><span>update</span><span>(</span><span>phase</span><span>);</span><span></span>
<span>  </span><span>info</span><span>!</span><span>(</span><span>"Phase: {} Position: {}"</span><span>,</span><span> </span><span>phase</span><span>,</span><span> </span><span>position_estimator</span><span>.</span><span>position</span><span>);</span><span></span>

<span>  </span><span>if</span><span> </span><span>user_button</span><span>.</span><span>is_low</span><span>()</span><span> </span><span>{</span><span></span>
<span>      </span><span>info</span><span>!</span><span>(</span><span>"Button pressed, zeroing"</span><span>);</span><span></span>
<span>      </span><span>position_estimator</span><span>.</span><span>position</span><span> </span><span>=</span><span> </span><span>0.</span><span>;</span><span></span>
<span>  </span><span>}</span><span></span>
<span>}</span><span></span>
</pre></div>
<h2 id="precision">Precision</h2>

<p>There are several parameters we need to select in the firmware to implement the measurement:</p>

<ul>
<li>The frequency at which we emit the PDM pulses</li>
<li>The number of PDM pulses across which we divide a single sinusoid period</li>
<li>The ADC sampling time</li>
<li>The number of ADC samples we take for each phase calculation</li>
</ul>

<p>Rather than try to calculate the ideal parameters from first principles (which would probably depend on all sorts of specifics like the PCB soldermask thickness and trace resistances), let‚Äôs just try them all and see what works best.
More specifically: for each parameter configuration, which has the lowest standard deviation for multiple measurements taken from the same physical slide position?</p>

<p>Instead of reflashing the firmware for each set of parameters, we can write a special <a href="https://github.com/lynaghk/calipertron/blob/2ceedc0e477498601dcbd6a6f257012657070bf9/firmware/src/bin/recorder.rs">recorder firmware</a> that can be controlled by a laptop to try different parameters configurations.
Then we can stream  the raw ADC readings back to the laptop, which lets us try a much wider variety parameters.</p>

<p>You can look at the <a href="https://github.com/lynaghk/calipertron/blob/2ceedc0e477498601dcbd6a6f257012657070bf9/analysis/parameter_sweep.ipynb">parameter sweep notebook</a> for the gory details, but here‚Äôs the summary in a plot:</p>

<p><img src="https://kevinlynagh.com/calipertron/parameter_sweep.jpg" alt=""></p>

<p>There‚Äôs a lot going on here, let‚Äôs break it down.
Schematically:</p>

<ul>
<li>The Y-axis corresponds to the standard deviation of recorded phases (lower is better ‚Äî after all, the slide is never moving, so ideally all measurements would return the same value)</li>
<li>The X-axis corresponds to the frequency for which we‚Äôre sending out the PDM pulses of the emitted sinusoidal signal. All data here are for 128 PDM segments and an X-axis spacing of 2 kHz.</li>
<li>Each sub-plot corresponds to a different ‚Äúwindow size‚Äù ‚Äî i.e., how many ADC samples we correlate to derive a single phase measurement.</li>
<li>Each colored line is a different ADC sampling frequency (the stm32f103‚Äôs ADC can sample over 8 different periods, and we‚Äôre trying all of them)</li>
</ul>

<p>What stands out to me in the data itself:</p>

<ul>
<li>The higher the ADC frequency, the higher the PDM frequency needs to be before we start to pick up the signal (i.e., for the standard deviation to drop).
This makes sense to me, as if the ADC frequency is much higher than the signal‚Äôs, our window of samples won‚Äôt see the signal change much at all, so it‚Äôs going to be dominated by noise and we‚Äôll have no idea what the phase is.</li>
<li>Increasing the window size tends to improve precision ‚Äî makes sense, as it means we‚Äôre looking at more samples and (presumably) reducing the effect of noise.</li>
<li>The lowest ADC sampling frequency (i.e., the longest ADC sampling period) tends to have the best performance.</li>
<li>There‚Äôs a strange cat at 250 kHz; this is probably the point at which our ADC sampling rate isn‚Äôt fast enough to keep up with the signal itself. With 250 kHz / 128 PDM segments implies our emitted sinusoid is at about 1950 Hz</li>
</ul>

<p>While in this static test increasing the window size and ADC sampling period looks best, that does mean it‚Äôll reduce the rate at which we can actually calculate the phase, which limits how fast the slider can move before it loses track of its absolute position.</p>

<p>So, based on this survey I decided to set the parameters for the local, in-firmware calculation (as seen in the demo video) to be the point indicated by the red arrow:</p>

<ul>
<li>window size = 128</li>
<li>PDM frequency = 222 kHz</li>
<li>ADC sampling frequency = 222.2 kHz</li>
</ul>

<p>It actually makes sense that the phase deviation is a minimum here: At this ADC sampling frequency and a window size of 128, we‚Äôre pretty much matching a full period of the emitted 128-segment PDM signal.</p>

<p>The timestamps in the demo video show about 1.5 ms between readings (0.6 kHz), which is about three times the ideal limit (222.2 kHz / 128 samples =&gt; 1.7 kHz), probably due to the time it takes to do correlation math, print to the host computer, and cycle through the Embassy async machinery.
I‚Äôm sure a more optimized implementation could hit the limit by, e.g., calculating the correlations while the samples are being collected rather than afterwards.</p>

<p>As for the precision, taking 200ms worth of phase measurements from the printed logs (n = 124) while the slide isn‚Äôt moving, the standard deviation of the phase is 0.039 radians, which (for my PCB with 8 emitter keys = 9.4 mm) is a position error of about $ 0.039 * 9.4\,\mathrm{mm} / 2\pi = 0.6\,\mathrm{mm}$.</p>

<p>Honestly, this is way better than I expected ‚Äî especially since the stm32f103 came out in 2007, the drive signal is created by just banging on GPIO, and only conditioning for the received signal is a fixed-gain amplifier (we‚Äôre not even filtering out the 50 Hz line noise).</p>

<h2 id="misc-tips-lessons-learned">Misc. tips / lessons learned</h2>

<ul>
<li>I‚Äôm very happy with the workflow of streaming raw data to my computer over USB and then doing analysis in Python notebooks. This was also helpful for letting continue work on the project while I was traveling and away from the working hardware.</li>
<li>I‚Äôm not super-well versed in the Python ecosystem, and it was spectacular asking LLMs like Claude stuff like, ‚ÄúCan you please plot an FFT of these data samples‚Äù, ‚ÄúRun these bad boys through a low pass filter at with cutoff at 1000 Hz‚Äù, ‚ÄúCan you please write an a phase accumulator that handles wraparound correctly‚Äù, etc. Being able to use <a href="https://kevinlynagh.com/newsletter/2024_10_transcription_app_art_wall/">my lightweight dictation app</a> to just ramble out thoughts/ideas at an LLM was particularly satisfying.</li>
<li>Even with LLM-assistance, plotting was more difficult than I expected:

<ul>
<li>The JS-based interactive plots (Plotly, etc.) blew up when I tried to visualize raw data with just ~100k samples.</li>
<li>The matplotlib-based static plotting libraries didn‚Äôt make it easy to read exact coordinates from a point on the plot interactively.</li>
<li>Doing data aggregation with <a href="https://pola.rs/">Polars</a> was pretty good, but it wasn‚Äôt obvious to me how to aggregate + plot, e.g., both underlying data and their standard deviation across dimensions.</li>
<li>Likely I just need to pick a Python plotting library and spend 20 hours getting fluent.</li>
</ul></li>
<li>The proliferation of complex type signatures in the Rust Embedded ecosystem still fails to spark joy ‚Äî I‚Äôm stuck in the local optima of ‚Äúliterally just write everything in <code>fn main()</code> with a loop at the bottom‚Äù so I never have to write out the type signatures.</li>
</ul>

<h2 id="future-improvements">Future improvements</h2>

<p>I probably won‚Äôt go further on this until I have some sort of robotics context-of-use.
But for anyone who‚Äôs in the market for a project, here are a few ideas:</p>

<ul>
<li>Figure out how to make a parametric caliper emitter/reflector designs in PCB tools like <a href="https://atopile.io/">atopile</a> or some kind of KiCAD footprint generation script.</li>
<li>Design something specifically to work with aluminum extrusion motion systems and see how cheap/accurate you can make it.</li>
<li>Compare to more ‚Äúoff the shelf‚Äù positioning systems like magnetic tape or <a href="https://blog.adafruit.com/2024/02/29/eye-on-npi-triad-semiconductor-ts4631-light-to-digital-converter-eyeonnpi-adafruit-digikey-digikey-triadsemi-adafruit/">SteamVR trackers</a>.</li>
<li>Actually make this into a functional caliper by designing more suitable housing (as you can see from the video, my 3d printed base is just clamped to my desk).</li>
</ul>

<h2 id="thanks">Thanks</h2>

<ul>
<li>Mitko for designing the PCB hardware. See the details on the <a href="https://hackaday.io/project/194778-diy-digital-caliper-calipatron">hackday.io project page</a>.</li>
<li><a href="https://blog.npry.dev/">Nathan Perry</a> and <a href="https://jeffmcbride.net/">Jeff McBride</a> for helping me track down the <a href="https://github.com/lynaghk/repro-stm32f103-rust-embassy-freeze/">intermittent stm32f103 freeze up</a> to a bug in the CPU silicon. (Let‚Äôs all do our best to never run into that again!)</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elwood Edwards, Voice of AOL's 'You've Got Mail ' Alert, Dies at 74 (153 pts)]]></title>
            <link>https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html</link>
            <guid>42087087</guid>
            <pubDate>Fri, 08 Nov 2024 14:29:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html">https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html</a>, See on <a href="https://news.ycombinator.com/item?id=42087087">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>