<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 26 Aug 2024 20:30:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Snowden: The arrest of Durov is an assault on the basic human rights (104 pts)]]></title>
            <link>https://twitter.com/Snowden/status/1827695836832334169</link>
            <guid>41360808</guid>
            <pubDate>Mon, 26 Aug 2024 19:24:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Snowden/status/1827695836832334169">https://twitter.com/Snowden/status/1827695836832334169</a>, See on <a href="https://news.ycombinator.com/item?id=41360808">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Arrest of Pavel Durov Is a Reminder That Telegram Is Not Encrypted (112 pts)]]></title>
            <link>https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960</link>
            <guid>41359502</guid>
            <pubDate>Mon, 26 Aug 2024 17:28:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960">https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960</a>, See on <a href="https://news.ycombinator.com/item?id=41359502">Hacker News</a></p>
Couldn't get https://gizmodo.com/the-arrest-of-pavel-durov-is-a-reminder-that-telegram-is-not-encrypted-2000490960: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Using AI to fight insurance claim denials (161 pts)]]></title>
            <link>https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/</link>
            <guid>41358132</guid>
            <pubDate>Mon, 26 Aug 2024 15:31:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/">https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/</a>, See on <a href="https://news.ycombinator.com/item?id=41358132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>For San Francisco tech worker Holden Karau, paperwork had become a hobby.&nbsp;</p><p>Specifically, the forms and letters required to fight back when her health insurance provider denied a claim for a covered service, surgery, or pharmaceutical.&nbsp;</p><p>As a trans woman who loves motorcycles, she has required gender-affirming care and treatments for an accident in recent years, and received a spate of insurance denials along the way.&nbsp;</p><p>Instead of passively accepting the providers‚Äô decisions, she‚Äôd spend hours writing letters and filling out forms to appeal. It usually worked: Out of roughly 40 denials, she won more than 90% of her appeals, she estimates. (She also successfully fought an insurance denial for her dog, Professor Timbit.)&nbsp;</p><p>‚ÄúPart of that is an unreasonable willingness to take things too far,‚Äù Karau said. ‚ÄúThere‚Äôs an enjoyment in getting a counterparty to follow the rules that they don‚Äôt seem to want to have to follow.‚Äù</p></div><figure id=""><div><p><span><span></span><img alt="A person wearing a pink shirt and a smartwatch is working on a laptop. They are using their right hand to point at the screen and their left hand is resting on the laptop." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>Karau demonstrates the platform, which crafts appeals to health insurance denials. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>She began helping friends file appeals, too, then asked herself a question that‚Äôs typical for engineers: Could she figure out a way to automate the process?&nbsp;</p><p>After a year of tinkering, she just launched her answer: <a href="https://fighthealthinsurance.com/">Fight Health Insurance</a>, an open-source platform that takes advantage of large language models to help users generate health insurance appeals with AI.</p><p>With the slogan ‚ÄúMake your health insurance company cry too,‚Äù Karau‚Äôs site makes filing appeals faster and easier. <a href="https://www.kff.org/private-insurance/issue-brief/claims-denials-and-appeals-in-aca-marketplace-plans/">A recent study found that</a> Affordable Care Act patients appeal only about 0.1% of rejected claims, and she hopes her platform will encourage more people to fight back.&nbsp;</p></div><figure id=""><div><p><span><span></span><img alt="The image shows a tangle of multicolored cables connected to networking devices in a server rack, with wires coiled around various points and additional equipment nearby." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>One of the servers that operates the platform is in Karau's basement office. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>‚ÄúMost of the time, my relationship with my health insurance company is more adversarial than collaborative,‚Äù she said. ‚ÄúYou‚Äôre trying to force them to comply with the rules, and they‚Äôre trying to spend the <a href="https://www.propublica.org/article/unitedhealth-healthcare-insurance-denial-ulcerative-colitis">least amount of money</a>.‚Äù&nbsp;</p><p>A Fight Health Insurance user can scan their insurance denial, and the system will craft several appeal letters to choose from and modify.&nbsp;</p><p>The ‚Äúdirty secret‚Äù of the insurance industry is that most denials can be successfully appealed, according to Dr. Harley Schultz, a patient advocate in the Bay Area.</p><p>‚ÄúVery few people know about the process, and even fewer take advantage of it, because it‚Äôs rather cumbersome, arcane, and confusing, by design,‚Äù he said. ‚ÄúBut if you fight hard enough and long enough, most denials get overturned.‚Äù&nbsp;</p><p>It‚Äôs often assumed&nbsp; that only doctors can file appeals, but patients can do it too, he added. <a href="https://www.propublica.org/article/unitedhealth-healthcare-insurance-denial-ulcerative-colitis">Insurers reject about 1 in 7 claims</a> for treatment (Schultz estimates that it could be as high as 25% for some companies), and the reality is that physicians just don‚Äôt have time for all that filing.&nbsp;&nbsp;</p><p>‚ÄúI was in practice for many years, and if I fought every insurance denial, there wouldn‚Äôt be any time to do anything else,‚Äù Schultz said.&nbsp;</p><p>While some doctors have <a href="https://www.nytimes.com/2024/07/10/health/doctors-insurers-artificial-intelligence.html">turned to artificial intelligence themselves</a> to fight claims, Karau‚Äôs service puts the power in the hands of patients, who likely have more time and motivation to dedicate to their claims.&nbsp;</p><p>‚ÄúIn an ideal world, we would have a different system, but we don‚Äôt live in an ideal world, so what I‚Äôm shooting for here is incremental progress and making the world suck a little less,‚Äù she said.&nbsp;</p><p>So far, dozens have used the platform to generate an appeal, and Karau is assessing their feedback to fine-tune the platform and make it more effective and easier to use.&nbsp;</p></div><figure id=""><div><p><span><span></span><img alt="The image shows a computer screen displaying a draft appeal for an insurance company to cover PrEP medication. The document argues for coverage based on medical necessity." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>An example of an appeal letter generated by the AI platform. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>She&nbsp;estimates that she has spent about $10,000 building the platform. It‚Äôs free for users, though she might eventually charge for added services like faxing appeals.</p><p>At this point, she‚Äôs not planning on leaving her tech job to work on the platform full time (she has held gigs at IBM, Apple, Google, and Netflix, where she currently works) but hopes it can become a self-sustaining business, in addition to a cause about which she‚Äôs wildly passionate.&nbsp;</p><p>‚ÄúThe best-case scenario ‚Äî&nbsp;which is, admittedly, incredibly unlikely ‚Äî&nbsp;is that this increases the accessibility of appeals to the point that insurance companies stop denying so much tiny bullshit,‚Äù she said. ‚ÄúI suspect that they would still try to be dicks about big things, but hopefully we can get them to stop being dicks about small things.‚Äù</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dokku: My favorite personal serverless platform (369 pts)]]></title>
            <link>https://hamel.dev/blog/posts/dokku/</link>
            <guid>41358020</guid>
            <pubDate>Mon, 26 Aug 2024 15:21:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hamel.dev/blog/posts/dokku/">https://hamel.dev/blog/posts/dokku/</a>, See on <a href="https://news.ycombinator.com/item?id=41358020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<div>
<figure>
<p><img src="https://hamel.dev/blog/posts/dokku/images/serverless.png"></p>
<figcaption>With Dokku, you can turn a VPS into a powerful serverless platform</figcaption>
</figure>
</div>
<section id="what-is-dokku">
<h2 data-anchor-id="what-is-dokku">What is Dokku?</h2>
<p><a href="https://dokku.com/">Dokku</a> is an open-source Platform as a Service (PaaS) that runs on a single server of your choice. <strong>It‚Äôs like <a href="https://www.heroku.com/">Heroku</a>, but you own it.</strong> It is a great way to get the benefits of Heroku without the costs (Heroku can get quite expensive!). I need to deploy many applications for my <a href="https://hamel.dev/hire.html">LLM consulting work</a>. Having a cost-effective, easy-to-use serverless platform is essential for me.</p>
<p><strong>I run a Dokku server on a $7/month VPS on <a href="https://us.ovhcloud.com/">OVHcloud</a></strong> for non-gpu workloads. These applications include things like <a href="https://nbsanity.com/">nbsanity</a> and <a href="https://langfree.parlance-labs.com/tutorials/shiny.html#run-the-shiny-app-locally">data cleaning tools for LLMs</a>.</p>
<p>Some of the features I love about Dokku:</p>
<ul>
<li>Easy to use (like Heroku).</li>
<li>Automatic SSL certificate management via <a href="https://letsencrypt.org/">Let‚Äôs Encrypt</a>.</li>
<li>Basic Auth support so I can password-protect sites.</li>
<li>Scale up and down with a single command.</li>
<li>Flexibility to handle any application (Node, Python, etc), including defining a Docker container.</li>
<li>Lots of <a href="https://dokku.com/docs/community/plugins/?h=plugins#official-plugins">official plugins</a> that do almost anything I want.</li>
<li>Easily deploy with git commands.</li>
</ul>
</section>
<section id="minimal-dokku-examples">
<h2>Minimal Dokku Examples</h2>
<p>Make sure you <a href="https://dokku.com/docs/getting-started/installation/">install Dokku</a> on your VPS. As I mentioned, I use <a href="https://us.ovhcloud.com/">OVH</a>.</p>
<section id="deploying-apps-as-a-docker-container">
<h2 data-anchor-id="deploying-apps-as-a-docker-container">Deploying Apps as A Docker Container</h2>
<p>An easy way to deploy applications is with a Docker container.</p>
<p>To deploy a Docker container, I put a Dockerfile in the root of my git repo like this:</p>
<div id="cb1" data-filename="Dockerfile"><pre><code><span id="cb1-1"><span>FROM</span> python:3.10</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>COPY</span> . /app</span>
<span id="cb1-4"><span>WORKDIR</span> /app</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span># Install the local package</span></span>
<span id="cb1-7"><span>RUN</span> <span>pip</span> install .</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span># This directory contains app.py, a FastApi app</span></span>
<span id="cb1-10"><span>WORKDIR</span> /app/</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span>ENTRYPOINT</span> [<span>"./entrypoint.sh"</span>]</span></code></pre></div>
<div>
<p>The <code>entrypoint.sh</code> script allows me to easily run the app locally or in a Docker container. It looks like this:</p>
<div id="cb2" data-filename="entrypoint.sh"><pre><code><span id="cb2-1"><span>#!/bin/bash</span></span>
<span id="cb2-2"><span>exec</span> uvicorn main:app <span>--port</span> <span>"</span><span>$PORT</span><span>"</span> <span>--host</span> 0.0.0.0</span></code></pre></div>
</div>
<p>On the Dokku host, create the app:</p>

<p><strong>Locally</strong>, set up access to the Dokku host and name it <code>dokku</code> in your <code>~/.ssh/config</code> file. For example, here is mine:</p>
<pre><code>Host dokku
  HostName &lt;The external IP address of your Dokku host&gt;
  User ubuntu
  IdentityFile /Users/hamel/.ssh/dokku</code></pre>
<p>Locally, add the Dokku host as a remote and push to it:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>git</span> remote add dokku dokku@dokku:myapp</span>
<span id="cb5-2"><span>git</span> push dokku main</span></code></pre></div>
<p>That‚Äôs it - your app should be running on the Dokku host! Your local logs will print the URL that your application is served on, which by default will be <code>myapp.yourdomain.com</code>. You can also scale it up/down with the following command:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>#scale to two workers</span></span>
<span id="cb6-2"><span>dokku</span> ps:scale myapp web=2</span></code></pre></div>
<p>We are just scratching the surface. For more details, see the <a href="https://dokku.com/docs/">Dokku docs</a>.</p>
</section>
<section id="static-sites">
<h2 data-anchor-id="static-sites">Static Sites</h2>
<p>GitHub Pages is annoying in that you can‚Äôt easily deploy private static sites without paying for an expensive Enterprise account. With Dokku, you can easily deploy a static site from a private GitHub Repo and password-protect it.</p>
<p>We will assume that you have a static site in a git repo in a folder named <code>_site</code>.</p>
<p><strong>On the Dokku host</strong>, create an app named <code>mysite</code> and set the <code>NGINX_ROOT</code> environment variable to <code>_site</code>:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>dokku</span> apps:create mysite</span>
<span id="cb7-2"><span>dokku</span> config:set static-site NGINX_ROOT=_site</span></code></pre></div>
<p>Also on the Dokku host, install <a href="https://github.com/dokku/dokku-http-auth">basic auth</a> and <a href="https://github.com/dokku/dokku-http-auth/issues/15#issuecomment-1637058437">set permissions</a> so the plugin can work properly.</p>
<div id="cb8"><pre><code><span id="cb8-1"><span># do setup for the auth plugin that we will use later</span></span>
<span id="cb8-2"><span>sudo</span> dokku plugin:install https://github.com/dokku/dokku-http-auth.git</span>
<span id="cb8-3"><span>sudo</span> chmod +x /home/dokku</span></code></pre></div>
<p>Then execute the following commands from the root of your git repo that contains the static site. :</p>
<div id="annotated-cell-8"><pre><code><a data-target-cell="annotated-cell-8" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-8-1"><span>touch</span> .static</span>
<a data-target-cell="annotated-cell-8" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-8-2"><span>echo</span> BUILDPACK_URL=https://github.com/dokku/buildpack-nginx <span>&gt;</span> .env</span>
<a data-target-cell="annotated-cell-8" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-8-3"><span>git</span> remote add dokku dokku@dokku:mysite</span></code></pre></div>
<dl>
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="1" data-code-annotation="1">tells <code>dokku</code> that this is a static site</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="2" data-code-annotation="2">tells <code>dokku</code> to use the nginx buildpack for static sites (it will usually automatically detect this, but if you have a project with code and a static site, you need to tell it to use the nginx buildpack so it doesn‚Äôt get confused).</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="3" data-code-annotation="3">add the <code>dokku</code> host as a remote. For this to work, make sure <code>dokku</code> is a hostname in your <code>~/.ssh/config</code> file as described <a href="#deploying-apps-as-a-docker-container">in the previous section</a>.</span>
</dd>
</dl>
<p>Finally, deploy your application:</p>

<p>You can now add auth by running the following command on the Dokku host:</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>dokku</span> http-auth:enable mysite <span>&lt;</span>username<span>&gt;</span> <span>&lt;</span>password<span>&gt;</span></span></code></pre></div>
<div>

<p>You can add multiple usernames/passwords and even filter specific IPs. See <a href="https://github.com/dokku/dokku-http-auth">the docs</a>.</p>
</div>
<div>
<p>It‚Äôs often desirable to have HTTPS for your site. Dokku makes this easy with the <a href="https://github.com/dokku/dokku-letsencrypt">Let‚Äôs Encrypt Plugin</a>, which will even auto-renew for you. I don‚Äôt use this, because I‚Äôm letting <a href="https://developers.cloudflare.com/dns/manage-dns-records/reference/proxied-dns-records/">Cloudflare handle this with its proxy</a>.</p>
<p>If you are using Cloudflare this way, activating this plugin will mess things up (don‚Äôt worry its easy to disable). Honestly, I think it‚Äôs easier to let Cloudflare handle it if you are already doing so.</p>
</div>
</section>
</section>
<section id="deploying-with-github-actions">
<h2>Deploying With GitHub Actions</h2>
<p>You can automatically deploy Dokku apps with GitHub Actions, which is helpful if you don‚Äôt want to fiddle with pushing to the Dokku host. Here is an example GitHub Action workflow that does this:</p>
<div id="cb11" data-filename="deploy-dokku.yml"><pre><code><span id="cb11-1"><span>name</span><span>:</span><span> CI</span></span>
<span id="cb11-2"><span>on</span><span>:</span></span>
<span id="cb11-3"><span>  </span><span>workflow_dispatch</span><span>:</span></span>
<span id="cb11-4"><span>  </span><span>push</span><span>:</span></span>
<span id="cb11-5"><span>    </span><span>branches</span><span>:</span><span> </span><span>[</span><span>main</span><span>]</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span>concurrency</span><span>:</span><span> # Cancel previous jobs to avoid deploy locks on dokku</span></span>
<span id="cb11-8"><span>  </span><span>group</span><span>:</span><span> ${{ github.ref }}</span></span>
<span id="cb11-9"><span>  </span><span>cancel-in-progress</span><span>:</span><span> </span><span>true</span></span>
<span id="cb11-10"></span>
<span id="cb11-11"><span>jobs</span><span>:</span></span>
<span id="cb11-12"><span>  </span><span>deploy-dokku</span><span>:</span></span>
<span id="cb11-13"><span>    </span><span>runs-on</span><span>:</span><span> ubuntu-latest</span></span>
<span id="cb11-14"><span>    </span><span>steps</span><span>:</span></span>
<span id="cb11-15"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Checkout code</span></span>
<span id="cb11-16"><span>        </span><span>uses</span><span>:</span><span> actions/checkout@v2</span></span>
<span id="cb11-17"><span>        </span><span>with</span><span>:</span></span>
<span id="cb11-18"><span>          </span><span>fetch-depth</span><span>:</span><span> </span><span>0</span></span>
<span id="cb11-19"><span>      </span></span>
<span id="cb11-20"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Install SSH key</span></span>
<span id="cb11-21"><span>        run</span><span>: </span><span>|</span></span>
<span id="cb11-22">          echo "${{ secrets.DOKKU_SSH_PRIVATE_KEY }}" &gt; private_key.pem</span>
<span id="cb11-23">          chmod 600 private_key.pem</span>
<span id="cb11-24"></span>
<span id="cb11-25"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Add remote and push</span></span>
<span id="cb11-26"><span>        run</span><span>: </span><span>|</span></span>
<span id="cb11-27">          git remote add dokku dokku@rechat.co:llm-eval</span>
<span id="cb11-28">          GIT_SSH_COMMAND="ssh -i private_key.pem -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" git push dokku main -f</span></code></pre></div>
</section>
<section id="miscellaneous-tips">
<h2>Miscellaneous Tips</h2>
<p>These are things I often forget, so I‚Äôm writing them down here. For these examples, assume my app is named <code>llm-eval</code> and my host is <code>rechat.co</code>.</p>
<section id="run-commands-remotely">
<h2 data-anchor-id="run-commands-remotely">Run commands remotely</h2>
<p>You don‚Äôt have to ssh into the Dokku host just to execute commands. You can execute them remotely via the <code>dokku</code> user like this:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span># https://dokku.com/docs/deployment/application-management/</span></span>
<span id="cb12-2"><span>ssh</span> dokku@rechat.co apps:list</span></code></pre></div>
</section>
<section id="docker-cache">
<h2 data-anchor-id="docker-cache">Docker cache</h2>
<p>This is how you can <a href="https://dokku.com/docs/advanced-usage/repository-management/">invalidate the docker cache</a> for a fresh build:</p>
<div id="cb13"><pre><code><span id="cb13-1"><span>ssh</span> dokku@rechat.co repo:purge-cache llm-eval</span></code></pre></div>
</section>
<section id="rebuild-without-pushing">
<h2 data-anchor-id="rebuild-without-pushing">Rebuild without pushing</h2>
<p>Sometimes you want to rebuild without pushing. There are <a href="https://dokku.com/docs/processes/process-management/">many ways to do this</a>, but one way is like this:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>ssh</span> dokku@rehcat.co ps:rebuild llm-eval</span></code></pre></div>
</section>
</section>
<section id="why-did-i-write-this">
<h2>Why Did I Write This?</h2>
<p>I had to dig up these details whenever I wanted to deploy a new app, so I had to write it up anyway. I hope you find it useful, too!</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux: We need tiling desktop environments (112 pts)]]></title>
            <link>https://linuxblog.io/linux-tiling-desktop-environments/</link>
            <guid>41357853</guid>
            <pubDate>Mon, 26 Aug 2024 15:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxblog.io/linux-tiling-desktop-environments/">https://linuxblog.io/linux-tiling-desktop-environments/</a>, See on <a href="https://news.ycombinator.com/item?id=41357853">Hacker News</a></p>
Couldn't get https://linuxblog.io/linux-tiling-desktop-environments/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[DOJ Files Antitrust Suit Against RealPage, Maker of Rent-Setting Algorithm (157 pts)]]></title>
            <link>https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</link>
            <guid>41357557</guid>
            <pubDate>Mon, 26 Aug 2024 14:36:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm">https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</a>, See on <a href="https://news.ycombinator.com/item?id=41357557">Hacker News</a></p>
Couldn't get https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[NSA releases 1982 Grace Hopper lecture (377 pts)]]></title>
            <link>https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/</link>
            <guid>41356528</guid>
            <pubDate>Mon, 26 Aug 2024 12:37:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/">https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/</a>, See on <a href="https://news.ycombinator.com/item?id=41356528">Hacker News</a></p>
Couldn't get https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fixing a Bug in Google Chrome as a First-Time Contributor (391 pts)]]></title>
            <link>https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</link>
            <guid>41355303</guid>
            <pubDate>Mon, 26 Aug 2024 09:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/">https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=41355303">Hacker News</a></p>
Couldn't get https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dutch DPA fines Uber 290M euro because of transfers of drivers' data to the US (288 pts)]]></title>
            <link>https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</link>
            <guid>41355021</guid>
            <pubDate>Mon, 26 Aug 2024 08:15:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us">https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</a>, See on <a href="https://news.ycombinator.com/item?id=41355021">Hacker News</a></p>
Couldn't get https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Avante.nvim: Use Your Neovim Like Using Cursor AI IDE (222 pts)]]></title>
            <link>https://github.com/yetone/avante.nvim</link>
            <guid>41353835</guid>
            <pubDate>Mon, 26 Aug 2024 03:44:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/yetone/avante.nvim">https://github.com/yetone/avante.nvim</a>, See on <a href="https://news.ycombinator.com/item?id=41353835">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">avante.nvim</h2><a id="user-content-avantenvim" aria-label="Permalink: avante.nvim" href="#avantenvim"></a></p>
<p dir="auto"><strong>avante.nvim</strong> is a Neovim plugin designed to emulate the behaviour of the <a href="https://www.cursor.com/" rel="nofollow">Cursor</a> AI IDE. It provides users with AI-driven code suggestions and the ability to apply these recommendations directly to their source files with minimal effort.</p>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">ü•∞ This project is undergoing rapid iterations, and many exciting features will be added successively. Stay tuned!</p>
</div>
<details open="">
  <summary>
    
    <span aria-label="Video description avante-2.mp4">avante-2.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description avante-3.mp4">avante-3.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>AI-Powered Code Assistance</strong>: Interact with AI to ask questions about your current code file and receive intelligent suggestions for improvement or modification.</li>
<li><strong>One-Click Application</strong>: Quickly apply the AI's suggested changes to your source code with a single command, streamlining the editing process and saving time.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install <code>avante.nvim</code> using <a href="https://github.com/folke/lazy.nvim">lazy.nvim</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;make&quot;,
  opts = {
    -- add any opts here
  },
  dependencies = {
    &quot;nvim-tree/nvim-web-devicons&quot;, -- or echasnovski/mini.icons
    &quot;stevearc/dressing.nvim&quot;,
    &quot;nvim-lua/plenary.nvim&quot;,
    &quot;MunifTanjim/nui.nvim&quot;,
    --- The below is optional, make sure to setup it properly if you have lazy=true
    {
      'MeanderingProgrammer/render-markdown.nvim',
      opts = {
        file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
      },
      ft = { &quot;markdown&quot;, &quot;Avante&quot; },
    },
  },
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>make<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span><span>--</span> add any opts here</span>
  },
  <span>dependencies</span> <span>=</span> {
    <span><span>"</span>nvim-tree/nvim-web-devicons<span>"</span></span>, <span><span>--</span> or echasnovski/mini.icons</span>
    <span><span>"</span>stevearc/dressing.nvim<span>"</span></span>,
    <span><span>"</span>nvim-lua/plenary.nvim<span>"</span></span>,
    <span><span>"</span>MunifTanjim/nui.nvim<span>"</span></span>,
    <span><span>---</span> The below is optional, make sure to setup it properly if you have lazy=true</span>
    {
      <span><span>'</span>MeanderingProgrammer/render-markdown.nvim<span>'</span></span>,
      <span>opts</span> <span>=</span> {
        <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
      },
      <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
    },
  },
}</pre></div>
<p dir="auto">For Windows users, change the build command to the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1&quot;,
  -- rest of the config
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1<span>"</span></span>,
  <span><span>--</span> rest of the config</span>
}</pre></div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><code>avante.nvim</code> is currently only compatible with Neovim 0.10.0 or later. Please ensure that your Neovim version meets these requirements before proceeding.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">If your neovim doesn't use LuaJIT, then change <code>build</code> to <code>make lua51</code>. By default running make will install luajit.
For ARM-based setup, make sure to also install cargo as we will have to build the tiktoken_core from source.</p>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">Recommended <strong>Neovim</strong> options:</p>
<div dir="auto" data-snippet-clipboard-copy-content="-- views can only be fully collapsed with the global statusline
vim.opt.laststatus = 3
-- Default splitting will cause your main splits to jump when opening an edgebar.
-- To prevent this, set `splitkeep` to either `screen` or `topline`.
vim.opt.splitkeep = &quot;screen&quot;"><pre><span><span>--</span> views can only be fully collapsed with the global statusline</span>
<span>vim</span>.<span>opt</span>.<span>laststatus</span> <span>=</span> <span>3</span>
<span><span>--</span> Default splitting will cause your main splits to jump when opening an edgebar.</span>
<span><span>--</span> To prevent this, set `splitkeep` to either `screen` or `topline`.</span>
<span>vim</span>.<span>opt</span>.<span>splitkeep</span> <span>=</span> <span><span>"</span>screen<span>"</span></span></pre></div>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto"><code>render-markdown.nvim</code> is an optional dependency that is used to render the markdown content of the chat history. Make sure to also include <code>Avante</code> as a filetype
to its setup:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;MeanderingProgrammer/render-markdown.nvim&quot;,
  opts = {
    file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
  },
  ft = { &quot;markdown&quot;, &quot;Avante&quot; },
}"><pre>{
  <span><span>"</span>MeanderingProgrammer/render-markdown.nvim<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
  },
  <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
}</pre></div>
</div>
<p dir="auto">Default setup configuration:</p>
<p dir="auto"><em>See <a href="https://github.com/yetone/avante.nvim/blob/main/lua/avante/config.lua">config.lua#L9</a> for the full config</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  ---@alias Provider &quot;openai&quot; | &quot;claude&quot; | &quot;azure&quot;  | &quot;copilot&quot; | [string]
  provider = &quot;claude&quot;,
  claude = {
    endpoint = &quot;https://api.anthropic.com&quot;,
    model = &quot;claude-3-5-sonnet-20240620&quot;,
    temperature = 0,
    max_tokens = 4096,
  },
  mappings = {
    ask = &quot;<leader>aa&quot;,
    edit = &quot;<leader>ae&quot;,
    refresh = &quot;<leader>ar&quot;,
    --- @class AvanteConflictMappings
    diff = {
      ours = &quot;co&quot;,
      theirs = &quot;ct&quot;,
      none = &quot;c0&quot;,
      both = &quot;cb&quot;,
      next = &quot;]x&quot;,
      prev = &quot;[x&quot;,
    },
    jump = {
      next = &quot;]]&quot;,
      prev = &quot;[[&quot;,
    },
    submit = {
      normal = &quot;<CR>&quot;,
      insert = &quot;<C-s>&quot;,
    },
    toggle = {
      debug = &quot;<leader>ad&quot;,
      hint = &quot;<leader>ah&quot;,
    },
  },
  hints = { enabled = true },
  windows = {
    wrap = true, -- similar to vim.o.wrap
    width = 30, -- default % based on available width
    sidebar_header = {
      align = &quot;center&quot;, -- left, center, right for title
      rounded = true,
    },
  },
  highlights = {
    ---@type AvanteConflictHighlights
    diff = {
      current = &quot;DiffText&quot;,
      incoming = &quot;DiffAdd&quot;,
    },
  },
  --- @class AvanteConflictUserConfig
  diff = {
    debug = false,
    autojump = true,
    ---@type string | fun(): any
    list_opener = &quot;copen&quot;,
  },
}"><pre>{
  <span><span>---</span><span>@alias</span> <span>Provider</span> <span><span>"</span>openai<span>" </span></span><span>| </span><span><span>"</span>claude<span>" </span></span><span>| </span><span><span>"</span>azure<span>"  </span></span><span>| </span><span><span>"</span>copilot<span>" </span></span><span>| </span><span>[string]</span></span>
  <span>provider</span> <span>=</span> <span><span>"</span>claude<span>"</span></span>,
  <span>claude</span> <span>=</span> {
    <span>endpoint</span> <span>=</span> <span><span>"</span>https://api.anthropic.com<span>"</span></span>,
    <span>model</span> <span>=</span> <span><span>"</span>claude-3-5-sonnet-20240620<span>"</span></span>,
    <span>temperature</span> <span>=</span> <span>0</span>,
    <span>max_tokens</span> <span>=</span> <span>4096</span>,
  },
  <span>mappings</span> <span>=</span> {
    <span>ask</span> <span>=</span> <span><span>"</span>&lt;leader&gt;aa<span>"</span></span>,
    <span>edit</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ae<span>"</span></span>,
    <span>refresh</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ar<span>"</span></span>,
    <span><span>---</span><span> @class</span> <span>AvanteConflictMappings</span></span>
    <span>diff</span> <span>=</span> {
      <span>ours</span> <span>=</span> <span><span>"</span>co<span>"</span></span>,
      <span>theirs</span> <span>=</span> <span><span>"</span>ct<span>"</span></span>,
      <span>none</span> <span>=</span> <span><span>"</span>c0<span>"</span></span>,
      <span>both</span> <span>=</span> <span><span>"</span>cb<span>"</span></span>,
      <span>next</span> <span>=</span> <span><span>"</span>]x<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[x<span>"</span></span>,
    },
    <span>jump</span> <span>=</span> {
      <span>next</span> <span>=</span> <span><span>"</span>]]<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[[<span>"</span></span>,
    },
    <span>submit</span> <span>=</span> {
      <span>normal</span> <span>=</span> <span><span>"</span>&lt;CR&gt;<span>"</span></span>,
      <span>insert</span> <span>=</span> <span><span>"</span>&lt;C-s&gt;<span>"</span></span>,
    },
    <span>toggle</span> <span>=</span> {
      <span>debug</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ad<span>"</span></span>,
      <span>hint</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ah<span>"</span></span>,
    },
  },
  <span>hints</span> <span>=</span> { <span>enabled</span> <span>=</span> <span>true</span> },
  <span>windows</span> <span>=</span> {
    <span>wrap</span> <span>=</span> <span>true</span>, <span><span>--</span> similar to vim.o.wrap</span>
    <span>width</span> <span>=</span> <span>30</span>, <span><span>--</span> default % based on available width</span>
    <span>sidebar_header</span> <span>=</span> {
      <span>align</span> <span>=</span> <span><span>"</span>center<span>"</span></span>, <span><span>--</span> left, center, right for title</span>
      <span>rounded</span> <span>=</span> <span>true</span>,
    },
  },
  <span>highlights</span> <span>=</span> {
    <span><span>---</span><span>@type</span> <span>AvanteConflictHighlights</span></span>
    <span>diff</span> <span>=</span> {
      <span>current</span> <span>=</span> <span><span>"</span>DiffText<span>"</span></span>,
      <span>incoming</span> <span>=</span> <span><span>"</span>DiffAdd<span>"</span></span>,
    },
  },
  <span><span>---</span><span> @class</span> <span>AvanteConflictUserConfig</span></span>
  <span>diff</span> <span>=</span> {
    <span>debug</span> <span>=</span> <span>false</span>,
    <span>autojump</span> <span>=</span> <span>true</span>,
    <span><span>---</span><span>@type</span> <span>string </span><span>| </span><span>fun</span><span>(): </span><span>any</span></span>
    <span>list_opener</span> <span>=</span> <span><span>"</span>copen<span>"</span></span>,
  },
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Given its early stage, <code>avante.nvim</code> currently supports the following basic functionalities:</p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">Avante will only support OpenAI (and its variants including copilot and azure), and Claude out-of-the-box due to its high code quality generation.
For all OpenAI-compatible providers, see <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more details.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">For most consistency between neovim session, it is recommended to set the environment variables in your shell file.
By default, <code>Avante</code> will prompt you at startup to input the API key for the provider you have selected.</p>
<p dir="auto">For Claude:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export ANTHROPIC_API_KEY=your-api-key"><pre><span>export</span> ANTHROPIC_API_KEY=your-api-key</pre></div>
<p dir="auto">For OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=your-api-key"><pre><span>export</span> OPENAI_API_KEY=your-api-key</pre></div>
<p dir="auto">For Azure OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export AZURE_OPENAI_API_KEY=your-api-key"><pre><span>export</span> AZURE_OPENAI_API_KEY=your-api-key</pre></div>
</div>
<ol dir="auto">
<li>Open a code file in Neovim.</li>
<li>Use the <code>:AvanteAsk</code> command to query the AI about the code.</li>
<li>Review the AI's suggestions.</li>
<li>Apply the recommended changes directly to your code with a simple command or key binding.</li>
</ol>
<p dir="auto"><strong>Note</strong>: The plugin is still under active development, and both its functionality and interface are subject to significant changes. Expect some rough edges and instability as the project evolves.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Bindings</h2><a id="user-content-key-bindings" aria-label="Permalink: Key Bindings" href="#key-bindings"></a></p>
<p dir="auto">The following key bindings are available for use with <code>avante.nvim</code>:</p>
<ul dir="auto">
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>a</kbd> ‚Äî show sidebar</li>
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>r</kbd> ‚Äî show sidebar</li>
<li><kbd>c</kbd><kbd>o</kbd> ‚Äî choose ours</li>
<li><kbd>c</kbd><kbd>t</kbd> ‚Äî choose theirs</li>
<li><kbd>c</kbd><kbd>b</kbd> ‚Äî choose both</li>
<li><kbd>c</kbd><kbd>0</kbd> ‚Äî choose none</li>
<li><kbd>]</kbd><kbd>x</kbd> ‚Äî move to previous conflict</li>
<li><kbd>[</kbd><kbd>x</kbd> ‚Äî move to next conflict</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlight Groups</h2><a id="user-content-highlight-groups" aria-label="Permalink: Highlight Groups" href="#highlight-groups"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Highlight Group</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>AvanteTitle</td>
<td>Title</td>
</tr>
<tr>
<td>AvanteReversedTitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteSubtitle</td>
<td>Selected code title</td>
</tr>
<tr>
<td>AvanteReversedSubtitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteThirdTitle</td>
<td>Prompt title</td>
</tr>
<tr>
<td>AvanteReversedThirdTitle</td>
<td>Used for rounded border</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODOs</h2><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul>
<li> Chat with current file</li>
<li> Apply diff patch</li>
<li> Chat with the selected block</li>
<li> Slash commands</li>
<li> Edit the selected block</li>
<li> Smart Tab (Cursor Flow)</li>
<li> Chat with project</li>
<li> Chat with selected files</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul dir="auto">
<li><strong>Enhanced AI Interactions</strong>: Improve the depth of AI analysis and recommendations for more complex coding scenarios.</li>
<li><strong>LSP + Tree-sitter + LLM Integration</strong>: Integrate with LSP and Tree-sitter and LLM to provide more accurate and powerful code suggestions and analysis.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions to avante.nvim are welcome! If you're interested in helping out, please feel free to submit pull requests or open issues. Before contributing, ensure that your code has been thoroughly tested.</p>
<p dir="auto">See <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more recipes and tricks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">avante.nvim is licensed under the Apache License. For more details, please refer to the <a href="https://github.com/yetone/avante.nvim/blob/main/LICENSE">LICENSE</a> file.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing stuff is never obvious yet often better (421 pts)]]></title>
            <link>https://www.gkogan.co/removing-stuff/</link>
            <guid>41353328</guid>
            <pubDate>Mon, 26 Aug 2024 01:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gkogan.co/removing-stuff/">https://www.gkogan.co/removing-stuff/</a>, See on <a href="https://news.ycombinator.com/item?id=41353328">Hacker News</a></p>
Couldn't get https://www.gkogan.co/removing-stuff/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Server Setup Basics for Self Hosting (161 pts)]]></title>
            <link>https://becomesovran.com/blog/server-setup-basics.html</link>
            <guid>41353284</guid>
            <pubDate>Mon, 26 Aug 2024 01:50:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://becomesovran.com/blog/server-setup-basics.html">https://becomesovran.com/blog/server-setup-basics.html</a>, See on <a href="https://news.ycombinator.com/item?id=41353284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>This is a post I've been meaning to do for a while. While it's simple to
                explain how to set up an app for self-hosting, it's pointless to host an app on a weak foundation.
                It's a massive pain in my ass to start every how to with a section on server setup, so I'm
                also making this post for myself as a reference on how I like to set up a server for apps I'm
                hosting. I'll start with basic stuff like proper login with SSH and non-root user set up and making
                users for each app. I'll also touch on NGINX setup, some quality of life tools that make server
                management easier, log management and basic network security.<br>‚Äç<br></p>
              <ul role="list">
                <li>
                  <a href="#ssh">SSH</a>
                </li>
                <li>
                  <a href="#users">Users</a>
                </li>
                <li>
                  <a href="#logs">Logs</a>
                </li>
                <li>
                  <a href="#backups">Backups</a>
                </li>
                <li>
                  <a href="#network">Basic Network Safety</a>
                </li>
                <li>
                  <a href="#nginx">NGINX</a>
                </li>
                <li>
                  <a href="#qol">Quality of Life Tools</a>
                </li>
                <li>
                  <a href="#dns">DNS</a>
                </li>
                <li>
                  <a href="#docker">Docker</a>
                </li>
              </ul>
              <h2 id="ssh"><p>SSH</p></h2>
              <p>First is login. You‚Äôll need a way to access your device securely. Don't even
                mess with username and password. You want to use SSH (Secure Shell) and make sure that SSH is the only
                way to log in. To do that, you‚Äôll need an SSH key and a new user account. On a newly provisioned VPS,
                you'll be logged in as root, and you want to protect the root account. First off on the VPS or
                remote machine make a new regular user with and add them to the ‚Äúsudo‚Äù group with:</p>
              <pre contenteditable="false"><code><span>sudo adduser newuser
</span>
sudo usermod -aG sudo newuser</code></pre>
              <p><br>Now on your local machine run:<br></p>
              <pre contenteditable="false"><code><span>ssh-keygen -t ed25519 -C </span><span>"your_email@example.com"</span></code></pre>
              <p><br>Follow the instructions, it should ask you where you want to save the file and
                if you want a password or not. Make sure you set a string one. To copy the public key over to your
                server run on your local machine:</p>
              <pre contenteditable="false"><code><span>ssh-copy-id -i ~/.ssh/id_ed25519.pub newuser@your_server_ip</span></code></pre>
              <p><br>Keep in mind newuser@your-server-ip is the username and the remote device you
                are trying to copy your public key into. When you get prompted for a password, it will be the password
                for the account on the remote device, NOT the password you just made for the SSH key. Once verified, it
                will copy over the public key, and you can now log in Via SSH. To turn off username and password login,
                type in:<br>‚Äç</p>
              <pre contenteditable="false"><code><span>sudo nano /etc/ssh/sshd_config</span></code></pre>
              <p><br>Find these values and set them as you see them here.<br>‚Äç</p>
              <pre contenteditable="false"><code><span>Port 2222     </span><span># Change default port (use a number between 1024 and 65535)</span><span>
</span><span>PermitRootLogin no                 </span><span># Disable root login</span><span>
</span><span>PasswordAuthentication no          </span><span># Disable password authentication</span><span>
</span><span>PubkeyAuthentication yes           </span><span># Enable public key authentication</span><span>
</span><span>AuthorizedKeysFile .ssh/authorized_keys </span><span># Specify authorized_keys file location</span><span>
</span><span>AllowUsers newuser                 </span><span># Only allow specific users to login</span></code></pre>
              <p><br>This disallows every login method besides SSH under the user you copied your
                public key to. Stops login as Root and only allows the user you specify to log in. Hit CTL+S to save and
                CTL+x to get out of the file editor. Restart SSH:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo service ssh restart</span></code></pre>
              <p><br>This might boot you out of the session. If it does, this is a good time to test
                the other login methods to see if they are declined before continuing. Also, it should go without
                saying, but you need to keep the private key safe and if you lose it you will not be able to get in
                remotely anymore.You can further lock down your login with: <br>‚Äç</p>
              <pre contenteditable="false"><code><span>Protocol 2                 </span><span># Use only SSH protocol version 2</span><span>
</span><span>MaxAuthTries 3             </span><span># Limit authentication attempts</span><span>
</span><span>ClientAliveInterval 300    </span><span># Client alive interval in seconds</span><span>
</span><span>ClientAliveCountMax 2      </span><span># Maximum client alive count</span></code></pre>
              <p><br>Now, let's dive into users a bit more and see how we can leverage them for
                a bit of organization and security.</p>
              <h2 id="users"><p>Users</p></h2>
              <div><p>Users are important when it comes to managing a Linux server. There
                is an idea in server management called the ‚ÄúPrinciple of The Least Privilege‚Äù this basically means that
                you want to give an app or process the minimum amount of privileges that it needs to do its job. Root
                has unlimited power, and no app really needs this. Making a user for apps that you're running
                accomplishes a few things. It can limit potential damage if an application you are running is
                compromised. It adds isolation when running more than one app, it helps with auditing so you know what
                app is using what system resources. </p><p>In short, users are a great way of helping organize your
                system and helps you troubleshoot if and when things go wrong. To add a new user, run:<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>sudo useradd -rms /usr/sbin/nologin -c </span><span>"a comment"</span><span> youruser</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like ‚ÄúRunning Nextcloud‚Äù or whatever. Clone app files into the /opt directory with:<br>‚Äç
              </p>
              <pre contenteditable="false"><code><span>sudo mkdir /opt/myapp</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like ‚ÄúRunning Nextcloud‚Äù or whatever. Clone app files into the /opt directory with:<br>‚Äç
              </p>
              <pre contenteditable="false"><code><span>sudo chown appuser:appuser /opt/myapp</span></code></pre>
              <p><br>Ok, with this your login is locked down, and you should have a decent
                idea about how to use users. Next is logs.<br>‚Äç</p>
              <h2 id="logs"><strong><p>Logs</p></strong></h2>
              <p><br>Logs are crucial to system administration. They keep track of system
                health, help troubleshoot issues and detect threats. So you want to set up proper log rotation so they
                do not take up too much space on your system, plus are easier to read and manage. To set up proper log
                rotation, you want to edit the logrotate.conf file located in /etc. Individual application
                configurations are typically stored in /etc/logrotate.d/, so an example configuration for NGINX would
                look like:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>/var/</span><span>log</span><span>/nginx/*.</span><span>log</span><span> {
</span>    weekly
    missingok
    rotate 52
    compress
    delaycompress
    notifempty
    create 0640 www-data adm
    sharedscripts
    postrotate
<span>        [ -f /var/run/nginx.pid ] &amp;&amp; </span><span>kill</span><span> -USR1 `cat /var/run/nginx.pid`
</span>    endscript
}
</code></pre>
              <p><br>This configuration rotates logs weekly, keeps 52 weeks of logs,
                compresses old logs, makes new logs with the right permissions and then signals NGINX to reopen log
                files after rotation. You can test it with:<br></p>
              <pre contenteditable="false"><code><span>sudo logrotate -d /etc/logrotate.conf</span></code></pre>
              <p><br>This will show what it will do without actually rotating logs. With
                this all set up, you can start to do more advanced stuff like triggering alerts based on log entries.
                Now this is good for a single server but if you manage more than one server it's a good idea to
                look into tools like Grafana Loki, Graylog and Fluentd. I won't go into detail here, but if
                you're looking to up your log game, these a decent place to start.<br>‚Äç<br></p>
              <h2 id="backups"><strong><p>Backups</p></strong></h2>
              <div><p>Backups, and more importantly, testing your backups, are extremely
                important in server management. Remember: a backup is not a backup unless you test it. Untested backups
                are essentially useless.</p><p>

                There are three main types of backups. Full, Differential, Incremental. Full backups are a complete copy
                of all data on a disk. Takes the most resources, but is the easiest to restore from. Differential
                backups back up all the changes since the last full backup, it's a middle ground strategy for backups on
                both space and restoration speed. An incremental backup backs up data that was changed since the last
                backup, this is the fastest backup option but can be the most complex to restore.</p><p>

                I think of it like this. I use incremental backups for things like photos and documents or project files
                and folders that get edited a lot. I'll use a full backup for backing up and entire server or disk.
                Differential backups Ill use for backing up full folders like /etc, /opt and log folders.</p><p>

                Now what about storage? If you follow the 3-2-1 rule, you will be golden. 3 copies of your data, 2
                storage types, and 1 offsite backup. I'd say if this seems like too much, the ‚Äúoffsite‚Äù storage is the
                most important and not one to skip. In case of a catastrophic meltdown, having a hard disk with your
                backups is invaluable. Offsite / offline backups can also save your ass from ransomware. So keep that in
                mind. There is a huge amount of backup software out there. <a href="https://github.com/awesome-foss/awesome-sysadmin#backups" target="_blank">This link</a> is for exploring some more
                professional backup tools. <a href="https://github.com/awesome-selfhosted/awesome-selfhosted?tab=readme-ov-file#file-transfer--synchronization" target="_blank">This link</a> has file sync, transfer and could storage solutions. I use a combo
                of sync-thing, Borg backup and good old-fashioned FTP.</p><p>

                Remember, that backup, logs and server monitoring is an evolving process based on your needs. The
                specific strategy you implement should be tailored to your needs and the criticality of your data.</p></div>


              <h2 id="network"><strong><p>Basic Network Safety</p></strong></h2>
              <p><br>The next step in securing a server is to lock down ports that need
                don‚Äôt need to be exposed to the internet and banning things that try to log in when they should not. UFW
                and Fail2Ban are two tools that are in widespread use for this. They are simple and easy to use, UFW
                lets you set traffic rules for ports and Fail2Ban will ban and IP address when it knocks on a port they
                should not be or if they fail to log in after some predefined rules. UFW or uncomplicated firewall often
                comes preinstalled on a lot of VPS services, same with Fail2Ban, but if you are on a new machine and
                you're unsure, run:<br>‚Äç</p>
              <pre contenteditable="false"><code><span>sudo apt install ufw
</span>
sudo apt install fail2ban</code></pre>
              <h3 id="ufw"><strong><br>UFW</strong></h3>
              <p><br>We will worry about Fail2Ban later, for now let's focus on UFW
                setup. First run some default policys with:<br></p>
              <pre contenteditable="false"><code><span>sudo ufw default deny incoming
</span> 
sudo ufw allow outgoing</code></pre>
              <p><br>This is considered best practice, as it follows the ‚Äúthe least
                privileges‚Äù idea I touched on earlier. It reduces attack surface on your machine and gives you precise
                control over what you do expose. In short, this configuration creates a balance between security and
                functionality. Your server can reach out to the internet as needed, but external entities can only
                connect to your server in ways you've explicitly allowed. Now let's allow some stuff
                in.<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo ufw allow ssh
</span>sudo ufw allow 80
sudo ufw allow 443</code></pre>
              <p><br>If you are going to be running a web server, you need port 80 and
                port 443 open. 80 is HTTP and 443 is HTTPS. By default, port 22 is SSH, if you changed this you need to
                specify the port instead of using the ‚Äúallow ssh‚Äù command. Here are some other useful commands:
                <br>‚Äç<br>
              </p>
              <pre contenteditable="false"><code><span>#List rules with numbers:</span><span>
</span>sudo ufw status numbered
<span></span><span>#Delete by number:</span><span>
</span>sudo ufw delete NUMBER
<span></span><span>#Delete by rule specification:</span><span>
</span>sudo ufw delete allow 80
<span></span><span>#You can allow connections from specific IP addresses:</span><span>
</span>sudo ufw allow from 192.168.1.100
<span></span><span>#You can also only allow an IP to connect to a specfic port with: </span><span>
</span>sudo ufw allow from 192.168.1.100 to any port 22
<span></span><span>#If you neeed to allow a range of ports: </span><span>
</span>sudo ufw allow 6000:6007/tcp
<span></span><span>#To further protect from brut force attacks you can rate limit specific ports with: </span><span>
</span><span>sudo ufw </span><span>limit</span><span> ssh
</span><span></span><span>#This would limit port 22 to 6 connections in 30 seconds from a single IP. To see the status of the firewall you can use: </span><span>
</span>
<span></span><span>#Adding this goves you more info</span><span>
</span>sudo ufw status verbose
<span></span><span>#and to reset incase you need to start over: </span><span>
</span>sudo ufw reset
<span></span><span>#and to enable and disable: </span><span>
</span><span>sudo ufw </span><span>enable</span><span> 
</span><span>sudo ufw </span><span>disable</span><span> 
</span>
<span></span><span>#finaly to enable logging and adjusting the log level: </span><span>
</span>sudo ufw logging on
<span>sudo ufw logging medium </span><span># levels are low, medium, high, full </span><span>
</span></code></pre>
              <p><br>On to Fail2Ban now. <br></p>
              <h3 id="ban"><strong><br>Fail2Ban</strong></h3>
              <p>‚Äç<br>The main configuration is located in /etc/fail2ban/jail.conf, but
                it's recommended to create a local configuration file:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
</span>
sudo nano /etc/fail2ban/jail.local</code></pre>
              <p>‚Äç<br>There are some basic settings in the [DEFAULT] section of the
                jail.local section those are:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>bantime = 10m
</span>findtime = 10m
maxretry = 5</code></pre>
              <p>‚Äç<br>Ban time is how long an IP is banned. Find time is the time frame in
                witch Fail2Ban looks for repeated failure, and max retry is the number of failures before an IP is
                banned. You can tune these as you see fit. There are also custom jails you can set, Fail2Ban also
                supports jails for commonly used services like SSH. There are even more steps you can take, but I think
                this covers the basics.<br></p>
              <h3 id="nginx"><strong><p>NGINX</p></strong></h3>
              <div><p>There are a small mess of web servers out there that you can use.
                Apache, Caddy, nginx, IIS to name a few. I use Nginx. It's what I know, and it works really damn
                well. Nginx (pronounced engine-x) is a web server, reverse proxy, and load balancer. As a web server, it
                excels at serving static content and can handle loads of concurrent connections with fairly low resource
                usage. As a reverse proxy, it can sit in front of your application servers and forward traffic to them
                while enchaining the apps' security. Its load balancing aspects can effectively balance traffic
                between servers, improving reliability and scalability. </p><p>When installed via apt, the default
                location for nginx is /etc/nginx/ the nginx.conf is mostly used for global server configuration and
                includes filed from the /etc/nginx/sites-enabled folder. This modular structure allows for easy
                management of multiple sites. Two folders to be aware of are the sites-enabled folder and the
                sites-available folders. You can think of the sites available as a staging place to test your site
                configurations, while the sites enabled is for live sites and apps. A common practice is to set up and
                test your configuration in the sites in the sites available, then when you're ready to go live and
                get an SSL cert, you link the file to the sites-enabled folder. You do that with:<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>ln -s /etc/nginx/sites-available/yoursitefile /etc/nginx/sites-enabled</span></code></pre>
              <p><br>Then reload nginx and double check nginx status with:<br>‚Äç<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl reload nginx
</span>
sudo systemctl status nginx</code></pre>
              <div><p>Your site should be live now.</p><p>Below, I‚Äôll show you some
                boilerplate Nginx site configurations. Be sure to look into your app or sites needs as these are just
                starting points.&nbsp;For static sites, this is a decent starting point.&nbsp;</p></div>
              <p><br>Basic Static Website Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name example.com www.example.com;
    root /var/www/example.com/html;
    index index.html index.htm;
    location / {
<span>        try_files </span><span>$uri</span><span> </span><span>$uri</span><span>/ =404;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>Proxy Pass Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name app.example.com;
    location / {
        proxy_pass http://localhost:3000;
<span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/app.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/app.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/app.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/app.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>WebSocket Upgrade Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name ws.example.com;
    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
<span>        proxy_set_header Upgrade </span><span>$http_upgrade</span><span>;
</span><span>        proxy_set_header Connection </span><span>"upgrade"</span><span>;
</span><span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># WebSocket timeout settings</span><span>
</span>    proxy_read_timeout 300s;
    proxy_send_timeout 300s;
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/ws.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/ws.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/ws.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/ws.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <div><p>The basic configuration is for serving a simple static site. It
                specifies the domain name, listens on port 80 for both IPv4 and IPv6, sets the root directory for the
                site, configures error handling with try_files, adds some basic headers that protect from common web
                vulnerabilities, sets up logging for access and errors and includes a section for SSL that is commented
                out. Most of the SSL config will be handled by certbot, but there are a few lines in there that add some
                SSL security that can be uncommented after certbot is ran.<br>‚Äç<br>The proxy pass configuration is
                similar to the basic configuration, but instead of serving files directly, it proxies requests to a
                local application (in this case, running on port 3000).</p><p>The third configuration file is geared
                towards apps that need website connections, it's a lot like the proxy pass configuration with some
                changes to allow web sockets. &nbsp;</p><p>Ok, any bit about web servers is not really complete without
                talking about SSL. For casual use, certbot is a pleb's best friend. It's free, it is fast, and
                it fucking works. I use the python version of certbot. You can install that with: &nbsp;<br>‚Äç</p></div>
              <pre contenteditable="false"><code><span>sudo apt install certbot python3-certbot-nginx</span></code></pre>
              <p><br>Once it's installed you can simply run ‚Äúcertbot‚Äù in your
                terminal, this will detect the configs in your sites-enabled folder and ask what you want to do (renew,
                reissue, etc‚Ä¶). Follow the walk-through, certbot gives you It's pretty straight forward.<br>‚Äç<br>So
                nowadays certbot when getting a new cert will set up auto-renew for you, so it's a sit-and-forget
                kinda task. But to make sure it worked you can run:<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl status certbot.timer</span></code></pre>
              <p><br>if this is up and running, you should be good to go if you're
                using systemd.<br>‚Äç<br></p>
              <h2 id="qol"><strong><p>Quality Of Life Tools</p></strong></h2>
              <div><p>On the topic of tools that make managing your system easier, I'm
                going to present some tools I use on my servers that I think make management just a bit nicer. Not going
                to do a deep dive on any tool. All of these are optional and in no particular order. A lot of these I
                found on the site <a href="https://terminaltrove.com/" target="_blank">terminal trove</a>, a great site
                to browse if you're a terminal junkie like me.&nbsp;</p><p>First tool, <a href="https://terminaltrove.com/btop/" target="_blank">Btop</a> this is in my personal must haves
                list. Btop is a terminal monitor of resources. It shows you real time visuals of usage stats for your
                box‚Äôs CPU, RAM, disks, network and running possesses it's written in C++ and can be installed via
                most package managers.&nbsp;</p><p>For servers that have a lot of outside connections, i.e. a nostr relay, a
                tool like <a href="https://terminaltrove.com/neoss/" target="_blank">Neoss</a> is helpful. Neoss aims to
                replace usual ss command for basic usage. It provides a list of in use TCP and UDP sockets with their
                respective stats. Its main advantage over SS raw output is its clear and simple TUI (terminal user
                interface) that allows you to sort, refresh and navigate what is connected to your machine. It's
                installed Via NPM, meaning you need JavaScript installed.</p><p>
                <a href="https://github.com/allinurl/goaccess" target="_blank">GoAccess</a> is a terminal based log
                analyzer for web servers. It's great for a quick real time look at logs while in the terminal, but
                it can also generate real time HTML, JSON, and CSV reports. GoAccess can be installed via most package
                managers, works on all platforms.&nbsp;</p><p>Next on the list is <a href="https://terminaltrove.com/mc/" target="_blank">MC or ‚Äúmidnight commander‚Äù</a> Its a powerful text based file manager with a two panel
                display and lots of features for manipulating files and directories. It's also cross-platform and
                can be installed via most package managers.&nbsp;</p><p>In the same thread of server file management is <a href="https://dev.yorhel.nl/ncdu" target="_blank">NCDU</a>. This one is in my must-have list. It is a
                disk usage analyzer that is designed to find space hogs. It's fast and very simple to use. It can
                be installed on most systems and package managers. Windows will need Linux subsystems installed to use
                it.&nbsp;</p><p>Hopefully you find some use out of these. The last topic I'd like to touch on is DNS
                it's a bit topic, so I'm not going to do a massive deep dive, but if you're self-hosting
                it helps to have some of the basics of DNS down.&nbsp;ing doesn‚Äôt work.</p></div>
              <h2 id="dns"><strong><p>DNS</p></strong></h2>
              <div><p>DNS or The Domain Name System is a core part of how the internet as we
                know it works. Love it or hate it, it's what we have to work with If you want to be accessible to
                the wider internet. (I dislike what it currently is it, but I‚Äôm not opening that can of worms here.)
                Basically, Think of DNS like a phone book. It‚Äôs what allows you to type duckduckgo.com instead of
                ‚Äú52.250.42.157‚Äù every time you need to search the internet. It translates something easy for humans to
                remember into the information needed by computers to actually reach ‚Äúduckduckgo.com‚Äù</p><p>If
                you're hosting on a VPS, the only thing you really need to know is to know how to point an A record
                at your server's IP after you decide on a domain to use. Pretty much all VPS hosts can give you a
                static IP, so that's mostly a set and forget type deal. </p><p>Hosting from home presents some
                challenges. One prominent one is (and a valid question that I often hear) not having a static IP
                address. Nowadays with the number of devices online needing IP addresses we do a lot of juggling, and
                most IP addresses are assigned dynamically unless you pay for it from your ISP.&nbsp; But there is a
                solution. The answer to this is called Dynamic DNS or DDNS. This allows automatic updating of DNS
                servers every time an IP address changes. There are a mess of ways to set up dynamic DNS. You can host
                your own service or use a host. <a href="https://dynamic.domains/dynamic-dns/providers-list/default.aspx" target="_blank">Here is a
                  link</a> with some hosts and projects to check out.</p><p>In a nutshell, it works like so. You chose
                a provider or set up your own. You get a domain, install the client on your home router or server and
                the client periodically checks to see if the IP address has changed, if so it updates your DNS record
                for that domain.&nbsp;</p></div>
              <h2 id="docker"><strong><p>Docker</p></strong></h2>
              <p>I'm not gonna cover how to install docker here. It's best to
                follow <a href="https://docs.docker.com/engine/install/debian/" target="_blank">the official
                  installation</a> guide anyway. But I want to touch on a few things. First off, docker is useful as
                hell for testing new apps. But that's about as far as I take it. I personally do not like using
                docker all that much, and where possible run applications directly. Here are some pros and cons to keep
                in mind.<br></p>
              <h3><strong>Docker Pros</strong></h3>
              <p>Consistency is a big one it can make things more constant between
                development, testing, and deploying if your system can run docker you can run most docker apps. It can
                help with isolation, reducing conflicts between apps. In some cases it can help with efficiency as it
                takes less resources than traditional VM‚Äôs. It can help with scaling as it's pretty easy to spin up
                more containers and the microservice architecture can be useful because you can break down an
                application into smaller manageable services, allowing for independent scaling of said services. Lastly
                the community is large, so the documentation is good, and community support is always helpful, plus
                there is a wide range of ready to go docker images for deployment.<br></p>
              <h3><strong>Docker Cons</strong></h3>
              <div><p>I‚Äôll start with overhead. While it's better than a traditional VM,
                it uses more resources than running something directly on the host, and I/O operations can be slower.
                The fact that docker shares the system's kernel means that a compromised app could affect the
                system. Persistent data is doable but adds a layer of complexity that can cause data loss with new
                users, it also makes backups more complex. Networking can also be more complex with docker, making it
                not as straightforward. It's also good to note that if you use UFW or firewalld for a firewall,
                docker bypasses those rules. Docker is only compatible with iptables. Also, while a well managed docker
                container can help manage server resources, an improperly manged on can be detrimental to resources as
                well. Containers can get too large, effecting disk size, and misconfiguration can use too many of your
                servers resources. It also adds extra layers of complexity when monitoring and debugging applications,
                especially across multiple containers.</p><p>At the end of the day, it's your system. But I wanted
                to lay out some pros and cons when it comes to using Docker. Moving on.&nbsp; </p></div>
              <h2><strong><p>Wrap Up</p></strong></h2>
              <p>Well, that about does it for the basics of server setup and tools. There
                is a <a href="https://git.sovbit.dev/Enki/sovran-scripts" target="_blank"> a script that I wrote</a> that will do most of this for you. I wrote it to make my own server setup faster.
                You can get that here, it includes all of my must-haves and does some basic configuration. Tweak it to
                your own needs, and as always stay safe out there and ping me on nostr or simplex if you have questions
                or if I fucked something up in this post.<br></p>
              
              
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senior Intel CPU architects splinter to develop RISC-V processors (148 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</link>
            <guid>41353155</guid>
            <pubDate>Mon, 26 Aug 2024 01:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing">https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</a>, See on <a href="https://news.ycombinator.com/item?id=41353155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: AheadComputing)</span>
</figcaption>
</div>

<div id="article-body">
<p>While Intel is busy laying off thousands of employees some of its most experienced CPU architects, with a combined 80+ years at the firm, have left to form a RISC-V startup. <a data-analytics-id="inline-link" href="https://www.aheadcomputing.com/" data-url="https://www.aheadcomputing.com/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">AheadComputing</a> was co-founded by Debbie Marr, Mark Dechene, Jonathan Pearce, and Srikanth Srinivasan, with the goal of ‚Äúcreating compelling open specification core IP.‚Äù This proactive move by the quartet of architects and engineers must be congratulated, as they founded AheadComputing and went public on July 18 ‚Äì just a couple of weeks before Intel‚Äôs harsh <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend">workforce reduction plans</a> were announced.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg"></picture></p></div><figcaption itemprop="caption description"><span>Everyone deserves a better website </span><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>AheadComputing‚Äôs website is rather basic and threadbare at the time of writing, but it does contain a mission statement of sorts, some short bios detailing the ex-Intel co-founders, a single blog post (launch announcement), and a call for new recruits with experience in CPU design and verification roles.</p><p>As indicated above, the work of AheadComputing is going to begin with work on the RISC-V architecture. Specifically, the fledgling firm has set out with a plan ‚Äúdedicated to designing, verifying, and licensing compelling RISC-V core IP.‚Äù For any deeper dive into the goings-on behind the doors of the new Oregon-based firm, you will have to chat with them directly or wait for further blogging. However, they will also meet with people during Happy Hour on Tuesdays, between 4 - 5:30 pm, at Cornelius Pass Roadhouse, Hillsboro‚Ä¶</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>The most compelling feature of AheadComputing is, for now, its co-founders, so let‚Äôs take a closer look at their resumes.</p><p>Co-founder, CEO, &amp; President, Dr. Debbie Marr was an Intel Fellow and Chief Architect of the Advanced Architecture Development Group (AADG) at Intel and spent 33 years at the chipmaker on products spanning the i386 all up to the present day. A highlight of her career seems to have been bringing Intel Hyperthreading Technology from concept to finished product. Marr also authored over 40 patents in CPU, AI accelerators, and FPGA fields.</p><p>Co-Founder, Mark Dechene was an Intel Principal Engineer and CPU Architect in the Advanced Architecture Development Group. During his 16 years at Intel Dechene worked on architecture development for Intel CPU products including Haswell, Broadwell, Goldmont, Goldmont Plus, Tremont, and Skymont. Dechene has authored over 15 patents, focused on microprocessor performance.</p><p>Co-Founder, Jonathan Pearce was an Intel Principal Engineer, CPU Architect, and a key technologist &amp; strategist in the Advanced Architecture Development Group until recently. Pearce worked for 22 years at Intel. During his career, Pearce has worked in both pre-silicon and post-silicon roles on multiple generations of Intel Core SOCs. He also authored 19 patents in the CPU, AI, and GPU fields.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-k6SrjEwfa6jCtt4TU4Epnh"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>Co-Founder, Dr. Srikanth Srinivasan has over 20 years of technical leadership experience in product R&amp;D. At Intel he taped out some well-known chip designs like Nehalem, Haswell, and Broadwell. However, most recently, Srinivasan led the frontend and backend CPU teams at the Advanced Architecture Development Group at Intel. The highlight of his career / achievements so far is probably the authoring of more than a dozen highly cited papers and over 50 patents.</p><p>With its pedigree, surely we will hear about AheadComputing again, in the not-too-distant future. On the flip side, PC enthusiasts may rightly worry about the future of Intel when it has just instigated the most severe layoff plans in its 56-year history, some of its ambitious construction plans have come into question, and severe brain drain, as evidenced by this new RISC-V startup, could slow any chances of revival.</p>
</div>
<div id="slice-container-authorBio-k6SrjEwfa6jCtt4TU4Epnh"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>



<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We found North Korean engineers in our application pile (153 pts)]]></title>
            <link>https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</link>
            <guid>41353079</guid>
            <pubDate>Mon, 26 Aug 2024 01:18:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile">https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</a>, See on <a href="https://news.ycombinator.com/item?id=41353079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Cinder is part of a growing list of US-based tech companies that encounter engineering applicants who are actually suspected North Korean nationals. These North Koreans almost certainly work on behalf of the North Korean government to <a href="https://apnews.com/article/north-korea-weapons-program-it-workers-f3df7c120522b0581db5c0b9682ebc9b">funnel money back</a> to their government while working remotely via third countries like China. Since at least early 2023, many have applied to US-based remote-first tech companies like Cinder. If you‚Äôve been running into this issue, here are some tips for how you can handle this at your own company.</p><p>It‚Äôs important to note that funding the North Korean government could constitute a crime given <a href="https://ofac.treasury.gov/sanctions-programs-and-country-information/north-korea-sanctions">the sanctions</a> the regime is under. And nobody wants that kind of paperwork headache!</p><p>Cinder is unique in our ability to interface with this issue given our co-founders‚Äô backgrounds as ex-CIA operatives, as well as an expert on North Korea. Our prior experience spurred our interest in building internet safety software to begin with, and inspires a particular vigilance to maintain it to the best of our abilities.</p><p>I first learned of North Korea‚Äôs practice of sending workers abroad in 2014: I joined the board of a leadership development program for North Korean escapees and learned of North Korea‚Äôs government and its use of technology from those who experienced it firsthand. Later, I volunteered for a nonprofit developing information access technology for clandestine use inside closed countries like North Korea. I have spoken with North Korean escapees who have recent knowledge of the latest North Korean tech worker trends. But I never expected I would one day experience them as applicants attempting to join my company.&nbsp;</p><h2>North Koreans are applying to US tech companies?</h2><p>The North Korean government has a <a href="https://www.bloomberg.com/news/features/2018-02-07/inside-kim-jong-un-s-hacker-army">long history</a> of sending workers abroad to earn money for the regime. The workers are sent to countries like China where they must earn a salary quota, most of which will be taken by the government for its own needs. These workers are under close supervision by North Korean officials while abroad. They are often required to leave family members behind as collateral to prevent them from defecting while outside their home country.&nbsp;</p><p>North Koreans have been working undercover as software freelancers for part time contract jobs for years. And recently, they have <a href="https://blog.knowbe4.com/how-a-north-korean-fake-it-worker-tried-to-infiltrate-us">started</a> to apply to American tech companies that offer remote, full time work. This may be exacerbated by the rise of remote work after the COVID pandemic and the fact that working at US tech companies can be so lucrative. Hyun-Seung Lee, a former North Korean businessman and former chair of the Kim Il Sung Socialist Youth League branch in Dalian, China, told us that the earnings quota for a North Korean IT worker based in China is typically $6,000 per month. This quota is more than covered by many US tech salaries.</p><h2>The application process</h2><p>In our experience, North Koreans applying to US tech companies under false pretenses will often use a standard process: they will create profiles on multiple professional networking and job posting sites using a name that is not Korean and sometimes with an AI-edited profile image.&nbsp;</p><p>Once they go through the interview process and have received a job offer, they may ask their new company-provided laptop be <a href="https://www.bleepingcomputer.com/news/security/us-dismantles-laptop-farm-used-by-undercover-north-korean-it-workers/">sent to a US-based partner</a>. According to a Department of Justice <a href="https://www.justice.gov/usao-dc/media/1352191/dl">indictment</a>, the US-based partner may install remote desktop software so that the North Korean engineer can appear to be working from a US location, with a laptop physically located in the US, while remotely controlling the laptop from abroad.</p><p>By demonstrating sufficient technical capability and minimal English language skills, North Korean applicants can meet minimum thresholds for junior software engineer roles. Fast-growing start-ups eager to ship more products might overlook gaps in resume, unreliable or missing education records, or poor command of written or spoken English for an engineer with sufficient skill who is ready to start working soon.&nbsp;</p><p>We suspect if the worker is employed even for just a few months before being terminated, this can still be quite profitable for the regime.</p><h2>Cinder‚Äôs approach</h2><p>We have a unique perspective on this problem for a few reasons: our company is in the internet safety industry, two of our co-founders came from the CIA, and I have twelve years of experience working on cybersecurity and human rights issues related to North Korea. So when North Korean IT workers applied to Cinder, they had a different experience than they might have expected.</p><blockquote><em>Pyongyang has a long history of exploiting its people to further the regime‚Äôs ambitions and this activity is no exception. Two of Cinder‚Äôs founders bring years of CIA experience, so we‚Äôre no strangers to creating and running virtual operations, nor detecting and countering those of hostile nation states.<br>‚Äç<br>- Phil Brennan, Cinder co-founder and 10-year CIA veteran</em></blockquote><h3>What tipped us off</h3><p>Fifteen months prior to any <a href="https://www.bleepingcomputer.com/news/security/five-arizona-ukraine-charged-for-cyber-schemes-infiltrating-over-300-companies-to-benefit-north-koreas-weapons-program/">FBI indictments</a>, our COO first noticed a few unusual trends in our applicant pool. Upon further inspection he discovered these candidates either didn't seem to exist on the internet, or were mapped to people who weren't them, who did have an internet presence. Over time, we realized many applicants that had the following characteristics:</p><ol role="list"><li>No online presence outside of professional networking websites; and professional networking profiles were recently created, typically with profile pictures that obscured the individual‚Äôs image (in ski goggles, sunglasses), were too zoomed out to be helpful, were AI-generated, or were simply blank.&nbsp;</li><li>Completely fabricated job history including office locations that don‚Äôt actually exist.&nbsp;</li><li>Unable to find these applicants online outside of the standard professional networking sites (e.g. no presence on GitHub, social media etc).</li><li>Inability to answer basic questions about the cities in which they allegedly worked (‚ÄòWhat was your Metro stop in Paris?‚Äô) or technology on which they worked (‚ÄòWhat org were you in at Uber?‚Äô).</li><li>Background noise during their interview that indicated other people speaking in an interview-like setting, implying a crowded room of people on separate professional video calls.</li><li>Highly scripted answers with explicit preference for remote work, and little ability to deviate from the script.</li><li>A mismatch between the name displayed on the resume or networking site, and the candidate‚Äôs command of English (e.g. Chris Smith with a B.A. from a large US research university who can barely speak interview-level English is surprising).&nbsp;</li></ol><p>We also noticed vague cover letter language:</p><blockquote><em>Hi, team!<br>I hope you're fine and safe.&nbsp;<br>I am really excited about this potential opportunity with the ambitious project.<br>As a Senior Frontend Developer with 8+ years of experience, I have great experience in working with React.js/Redux, RTK, React Query, Vue, Next.js, Vercel, TypeScript, GraphQL, etc.</em> <em>Please have a look at my previous works.</em></blockquote><p>Another example: </p><blockquote><em>Hi,</em> <br>‚Äç<em>I love what you are doing in your company. With my eight-plus years of development, I'd love to be one of you.</em> <em>As an FE-heavy developer, I have a track record of building successful products. And I am familiar with startup environment.</em> <em>I'd love to use my strong debugging and problem-solving abilities to be a powerful force in the workplace. I can wear multiple hats and adapt to a fast-paced team.</em> <em>I look forward to meeting you to learn more about this role and share my relevant skills.</em> <em>Best,</em></blockquote><p>Taken together, to me these details suggested fake identities. And while I knew North Korea had a history of sending workers abroad to freelance, I didn‚Äôt expect that they would apply to full time roles at US-based companies.</p><h3>What we did</h3><p>First, because we come from the Trust and Safety industry, I was able to reach out to our partners at various security companies and confirm these patterns were consistent with North Koreans attempting to pass themselves off as Americans. I also learned a lot from published investigations like the one <a href="https://www.nisos.com/research/dprk-it-worker-scam/">Nisos published last year</a>.</p><p>With more knowledge, we were able to go digging. And we had a lot of material: For applicants from some job sites, roughly 80% of inbound applicants with experience matching our stack were suspected North Koreans.&nbsp;</p><p>We started filtering out suspected North Korean applicants by doing quick internet searches and closer examinations of job history, profile imagery, and a social media screening. However, our process wasn‚Äôt perfect, and we still ended up on occasional Zoom calls screening applicants who we would quickly discover, mid-call, had fabricated their career history and only recently created their online presence.</p><p>When we first started receiving North Korean applications, some of our interviewers noted applicants‚Äô strong resistance to travel in their post-interview write ups:</p><blockquote><em>One clarifying question that I neglected to ask about is that on his Linkedin profile he says he is&nbsp; looking for ‚Äú100% Remote job only without travel‚Äù. I did not notice the ‚Äúwithout travel‚Äù part until after the interview. We should make sure he would be willing to travel sometimes for team offsites as this is an important part of Cinder‚Äôs culture.</em></blockquote><p>I started informing candidates that Cinder‚Äôs customer base includes companies investigating nation-state espionage and insider threat issues. I added that this is a natural fit for us, because our co-founders came from the US intelligence community including the CIA.&nbsp;</p><p>Upon hearing this, one suspected North Korean applicant immediately dropped from the Zoom call and never contacted us again.</p><h2>What Cinder is doing now</h2><p>We continue to receive dozens of suspected North Korean applicants to Cinder. We take steps to share relevant information with security teams at networking and job listing sites that we work with. If your company is also affected by this growing threat, I encourage you to get in touch with me at <a href="mailto:declan@cndr.io">declan@cndr.io</a> and I‚Äôd be happy to share more tips and prevention strategies.&nbsp;</p><p>‚Äç</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber loses New Zealand appeal, court rules drivers are employees not contractors (111 pts)]]></title>
            <link>https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</link>
            <guid>41352997</guid>
            <pubDate>Mon, 26 Aug 2024 01:05:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/">https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</a>, See on <a href="https://news.ycombinator.com/item?id=41352997">Hacker News</a></p>
Couldn't get https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Australian employees now have the right to ignore work emails, calls after hours (449 pts)]]></title>
            <link>https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</link>
            <guid>41352681</guid>
            <pubDate>Mon, 26 Aug 2024 00:08:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/">https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</a>, See on <a href="https://news.ycombinator.com/item?id=41352681">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Police Chief Says Cops Have a 5th Amendment Right to Leave Body Cameras Off (209 pts)]]></title>
            <link>https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/</link>
            <guid>41351993</guid>
            <pubDate>Sun, 25 Aug 2024 22:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/">https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/</a>, See on <a href="https://news.ycombinator.com/item?id=41351993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>Albuquerque, New Mexico, Police Chief Harold Medina operated his department-issued pickup truck "in an unsafe manner" on February 17, when he ran a red light and broadsided a car, severely injuring the driver. So concludes a recent <a href="https://s3.documentcloud.org/documents/25056680/i-171-24-medina-martinez-final_redacted.pdf">report</a> from internal investigators who looked into that shocking incident.</p> <p>Duh, you might say if you have seen <a href="https://www.youtube.com/watch?v=DvSVzDimSAk">surveillance camera footage</a> of the crash, which shows Medina crossing Central Avenue, a busy, four-lane street, against the light. He crosses the westbound lanes through a gap between two cars, forcing one of the drivers to brake abruptly, before barreling across the eastbound lanes, where he rams into the side of a gold 1966 Mustang driven by 55-year-old Todd Perchert.</p> <p>Although Medina's recklessness seems obvious, the Albuquerque Police Department's Fleet Crash Review Board (CRB) earlier this year <a href="https://reason.com/2024/04/04/albuquerques-police-chief-ran-a-red-light-and-broadsided-a-car-a-review-board-says-it-was-unavoidable/">concluded</a> that the crash was "non-preventable." How so? Medina, who was on his way to a Saturday press conference with his wife when he took a detour to have a look at a homeless encampment, said he ran the light to escape an altercation between two homeless men that had escalated into gunfire at the intersection of Central and Alvarado Drive.</p> <p>While "the initial decision to enter the intersection is not in question," Lt. James Ortiz says in the Internal Affairs report, "the facts and circumstances do not relieve department personnel of driving safely to ensure no additional harm is done to personnel or to citizens." Medina, Ortiz says, clearly failed to do that: "By definition, driving into a crosswalk, darting between two vehicles driving on a busy street, and crossing through an intersection with vehicles traveling eastbound were unsafe driving practices." In this case, he notes, those unsafe practices "resulted in a vehicle collision with serious physical injuries to the victim, including a broken collarbone and shoulder blade, 8 broken ribs (reconstructed with titanium plates after surgery), collapsed lung, lacerations to left ear and head, multiple gashes to his face, a seven-hour surgery, and hospitalization requiring epidural painkiller and a chest tube for nearly a week."</p> <p>Ortiz not only disagrees with the CRB's conclusion about Medina's crash; he says the board never should have reviewed the incident to begin with, since its mission is limited to accidents "not resulting in a fatality or serious injury." Ortiz says Commander Benito Martinez, who chairs the CRB, violated department policy when he decided the board should pass judgment on Medina's accident.</p> <p>Martinez acknowledged that department policy "prohibited the CRB from hearing serious injury crashes" and that "allowing such a case to be heard would be a policy violation." Why did he allow it anyway? "He explained that his reasoning for permitting the Chief's crash to be reviewed by the CRB was based on his belief that someone wanted the crash to be heard," Ortiz writes. "Cmdr. Martinez clarified that he believed someone from Internal Affairs wanted the case to be heard by the CRB to ensure full transparency. However, he did not consult with anyone in Internal Affairs to verify the accuracy of this assumption."</p> <p>Both the CRB's decision to review the crash and its implicit exoneration of Medina are hard to fathom. But Medina's explanations for the third policy violation identified by Ortiz‚Äîthe chief's failure to activate his body camera after the crash‚Äîare even weirder.</p> <p>"After the collision occurred, the shooting victim approached," Ortiz writes. "The victim informed the Chief that he was okay and had not been shot. Chief Medina asked the victim to remain at the scene, but the victim refused and fled southbound on Alvarado. Another citizen approached the Chief and reported having seen individuals leaving a black truck and fleeing away from the scene. Chief clarified with the witness that no one was outstanding. It is important to note that these interactions were not recorded and are contacts that require mandatory recording."</p> <p>Medina offered two puzzling excuses for leaving his camera off. He&nbsp;"cited intermittent conversations with his wife, who was a passenger in his unmarked patrol vehicle at the time of the collision," Ortiz says. "He claimed there was a right to privileged communication between spouses, which specifically exempted him from mandatory recording requirements." But the relevant policy "does not provide for nonrecording based on spousal privilege."</p> <p>Even more troubling, Medina said he "purposefully did not record because he was invoking his 5th Amendment right not to self-incriminate." Since "he was involved in a traffic collision," he reasoned, he was "subject to 5th Amendment protections."</p> <p>Think about the implications of that argument. Body cameras are supposed to help document (and perhaps deter) police misconduct. But Medina is suggesting that cops have a constitutional right to refrain from recording their interactions with the public whenever that evidence could be used against them. By turning on their cameras in those situations, he argues, police could be incriminating themselves. That is the whole point.</p> <p>Medina received two official <a href="https://www.abqjournal.com/news/albuquerque-police-chief-reprimanded-for-crash-that-injured-man/article_48c6c9de-455d-11ef-a7de-77dd5b86acc9.html">reprimands</a> for the camera violation and the reckless driving that injured Perchert, a casualty of the police chief's desperation to save his own skin. In similar situations, other Albuquerque police officers have been <a href="https://reason.com/2024/04/04/albuquerques-police-chief-ran-a-red-light-and-broadsided-a-car-a-review-board-says-it-was-unavoidable/">fired</a>. But after the crash, Albuquerque Mayor Tim Keller <a href="https://www.koat.com/article/victim-crash-involving-albuquerque-police-chief-medina/60324357">hailed</a> Medina as a hero who is "out on the front line‚Ä¶doing what he can to make our city safe."</p>						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why am I writing a Rust compiler in C? (372 pts)]]></title>
            <link>https://notgull.net/announcing-dozer/</link>
            <guid>41351446</guid>
            <pubDate>Sun, 25 Aug 2024 21:08:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notgull.net/announcing-dozer/">https://notgull.net/announcing-dozer/</a>, See on <a href="https://news.ycombinator.com/item?id=41351446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>To bootstrap Rust, no cost is too great.</p>

<p>Perceptive Rustaceans may have noticed my activity has gone down as of late.
There are a handful of different reasons for this. I‚Äôve been the subject of a
truly apocalyptic series of life events, including the death of a relative that
rattled me to my core. I‚Äôve had more responsibilities at work, leaving me with
less time and energy to contribute. Maybe I‚Äôve also lost a little bit of the
college-kid enthusiasm that brought me to open source in the first place.</p>

<p>There‚Äôs another reason, too. I‚Äôve been cooking up a project that‚Äôs been taking
up most of my time. It‚Äôs certainly the largest project I‚Äôve created in the open
source world, and if I complete it, it will certainly be my crowning
achievement.</p>

<p>I am writing a Rust compiler in pure C. No C++. No <a href="https://en.wikipedia.org/wiki/Flex_(lexical_analyser_generator)"><code>flex</code></a> or <a href="https://en.wikipedia.org/wiki/Yacc"><code>yacc</code></a>. Not even a
<a href="https://en.wikipedia.org/wiki/Make_(software)"><code>Makefile</code></a>. Nothing but pure C.</p>

<p>It‚Äôs called <a href="https://codeberg.org/notgull/dozer">Dozer</a>.</p>

<h2 id="wait-why">Wait, Why?</h2>

<p>To understand why I‚Äôve followed this path of madness, you first need to
understand bootstrapping and why it is important.</p>

<p>Let‚Äôs say that you‚Äôve written some code in Rust. In order to run this code, you
need to <em>compile</em> it. A <em>compiler</em> is a program that parses your code, validates
its correctness, and then transforms it into machine code that the CPU can
understand.</p>

<blockquote>
  <p><img src="https://notgull.net/images/ddog.jpg" alt="Dependency Dog" width="100">
<strong>Dependency Dog:</strong> Yes, it‚Äôs significantly more complicated than that. Except when it‚Äôs less complicated than that. Compilers are tricky to even describe.</p>
</blockquote>

<p>For Rust, your main compiler is <a href="https://github.com/rust-lang/rust">rustc</a>. If you don‚Äôt know, this is the
underlying program that <code>cargo</code> calls when you run <code>cargo build</code>. It‚Äôs fantastic
software, and frankly a gem of the open source community. Its code quality is up
there with the Linux kernel and the Quake III source code.</p>

<p>However, <a href="https://github.com/rust-lang/rust">rustc</a> itself is a program. So it needs a compiler to compile it from
its source code to machine code. Say, what language <em>is</em> <a href="https://github.com/rust-lang/rust">rustc</a> written in?</p>

<p><img src="https://notgull.net/images/rustc-in-rust.png" alt="rustc is 97.3 percent rust"></p>

<p>Ah, <a href="https://github.com/rust-lang/rust">rustc</a> is a Rust program. Written in Rust, for the purpose of compiling
Rust code. But, think about this for a second. If <a href="https://github.com/rust-lang/rust">rustc</a> is written in Rust,
and <a href="https://github.com/rust-lang/rust">rustc</a> is needed to compile Rust code, that means you need to use <a href="https://github.com/rust-lang/rust">rustc</a>
to compile <a href="https://github.com/rust-lang/rust">rustc</a>. Which is fine for us users, since we can just download
<a href="https://github.com/rust-lang/rust">rustc</a> from the internet and use it.</p>

<p>But, who compiled the first <a href="https://github.com/rust-lang/rust">rustc</a>? There had to be a chicken before the egg,
right? Where does it start?</p>

<p>‚Ä¶</p>

<p>Actually, that‚Äôs fairly simple. Every new version of <a href="https://github.com/rust-lang/rust">rustc</a> was compiled with
the previous version of <a href="https://github.com/rust-lang/rust">rustc</a>. So <a href="https://github.com/rust-lang/rust">rustc</a> version 1.80.0 was compiled with
<a href="https://github.com/rust-lang/rust">rustc</a> version 1.79.0. Which was, in turn, compiled with <a href="https://github.com/rust-lang/rust">rustc</a> version
1.78.0. And so on and so forth, all the way back to <a href="https://github.com/rust-lang/rust/tree/ef75860a0a72f79f97216f8aaa5b388d98da6480">version 0.7</a>
if the compiler. At that point, the compiler was written in <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a>. So all you
needed was an OCaml compiler to get a fully functioning <a href="https://github.com/rust-lang/rust">rustc</a> program.</p>

<p>There, problem solved! We‚Äôve figured out how to create <a href="https://github.com/rust-lang/rust">rustc</a> from first
principles! All is well, let‚Äôs go back to business.</p>

<p>Just one more thing. We still need a version of the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler for all of
this to work. So what language is the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler written in?</p>

<p><img src="https://notgull.net/images/ocaml-in-ocaml.png" alt="OCaml is 84 percent OCaml"></p>

<p><em>faceplant</em></p>

<p>Okay, okay, no worries! There is a <a href="https://github.com/Ekdohibs/camlboot">project</a>
that can successfully compile the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler using <a href="https://en.wikipedia.org/wiki/GNU_Guile">Guile</a>, which is one of the many
variants of <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a>, which is one of many variants of <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a>. Not to mention,
<a href="https://en.wikipedia.org/wiki/GNU_Guile">Guile</a>‚Äôs interpreter is written in C.</p>

<p>So this brings us, as all eventually things do, to the C programming language. We just
compile it using <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, and everything works out. So we just need to compile
<a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, which is written using‚Ä¶ C++?!</p>

<p>Okay, that‚Äôs a little unfair. <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a> was written in C until version 5, and it‚Äôs
not like there‚Äôs a shortage of C compilers written in C out there. For instance,
consider <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>, which is written in C and handles not only compiling, but
assembly and linking too.</p>

<p>‚Ä¶but that still doesn‚Äôt answer our question. What was the first C compiler
written in? Assembly? Then what was the first assembler written in?</p>

<h2 id="the-descent-principle">The Descent Principle</h2>

<p>This is where we introduce the <a href="https://bootstrappable.org/">Bootstrappable Builds</a>
project. To me, this is one of the most fascinating projects in the open source
community. It‚Äôs basically code alchemy.</p>

<p>Their <a href="https://github.com/fosslinux/live-bootstrap">Linux bootstrap process</a>
starts with a 512-byte binary seed. This seed contains what‚Äôs possibly the
simplest compiler you can imagine: it takes hexadecimal digits and outputs the
corresponding raw bytes. As an example, here part of the ‚Äúsource code‚Äù that‚Äôs
compiled with this compiler.</p>

<div><pre><code>31 C0           # xor ax, ax
8E D8           # mov ds, ax
8E C0           # mov es, ax
8E D0           # mov ss, ax
BC 00 77        # mov sp, 0x7700
FC              # cld ; clear direction flag
88 16 15 7C     # mov [boot_drive], dl
</code></pre></div>

<p>Note that everything after the pound sign is a comment, and all whitespace is
stripped. Frankly, I‚Äôm not even sure this can be called a programming language.
Still, it is <em>technically</em> analyzable, dissectable source code.</p>

<p>From here, this compiler compiles a very simple operating system, a barebones
shell, and a slightly more advanced compiler. That compiler compiles a slightly
more advanced compiler. A few steps later, you have something that roughly
<em>looks</em> like assembly code.</p>

<div><pre><code>DEFINE cmp_ebx,edx 39D3
DEFINE je 0F84
DEFINE sub_ebx, 81EB

:loop_options
    cmp_ebx,edx                         # Check if we are done
    je %loop_options_done               # We are done
    sub_ebx, %2                         # --options
</code></pre></div>

<p>Man, it‚Äôs weird to think of <em>assembly code</em> as being higher-level than anything
else, right?</p>

<p>This is enough to get them to a very basic subset of C. Then they compile a
slightly more advanced C compiler written in this subset. A few steps later they
can compile <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>. From there they can bootstrap <a href="https://en.wikipedia.org/wiki/Yacc"><code>yacc</code></a>, basic coreutils,
Bash, autotools, and eventually <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a> and Linux.</p>

<p>I‚Äôm not doing this justice, it‚Äôs a fascinating process. Every step is listed
<a href="https://github.com/fosslinux/live-bootstrap/blob/master/parts.rst">here</a>.</p>

<p>Anyhow, you‚Äôve essentially gone from ‚Äúa binary blob small enough to be manually
analyzed‚Äù to Linux, GCC, and basically everything else. But let‚Äôs start again
from <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>.</p>

<p>Right now, Rust shows up very late into this process. They use <a href="https://github.com/thepowersgang/mrustc">mrustc</a>, an
alternative Rust implementation written in C++ that can compile <a href="https://github.com/rust-lang/rust">rustc</a> version
1.56. From here, they then compile up to modern Rust code.</p>

<p>The main issue here is that, by the time C++ is introduced into the bootstrap
chain, the bootstrap is basically over. So if you wanted to use Rust at any
point before C++ is introduced, you‚Äôre out of luck.</p>

<p>So, for me, it would be <em>really nice</em> if there was a Rust compiler that could be
bootstrapped from C. Specifically, a Rust compiler that can be bootstrapped from
<a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>, while assuming that there are no tools on the system yet that could be
potentially useful.</p>

<p>That‚Äôs <a href="https://codeberg.org/notgull/dozer">Dozer</a>.</p>

<h2 id="the-plan">The Plan</h2>

<p>I‚Äôve been working on <a href="https://codeberg.org/notgull/dozer">Dozer</a> for the past two months, putting my anemic free
time to work on writing in a language that I kind of hate.</p>

<blockquote>
  <p><img src="https://notgull.net/images/ddog.jpg" alt="Dependency Dog" width="100">
<strong>Dependency Dog:</strong> That‚Äôs a little unfair. C has some elegant qualities to it. Reality truly is what you make of it. It‚Äôs just that I would not let this code anywhere near production.</p>
</blockquote>

<p>It‚Äôs written with no extensions, and so far both <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a> and <a href="https://sr.ht/~mcf/cproc/">cproc</a> are able
to compile it with no issues. I‚Äôm using <a href="https://c9x.me/compile/">QBE</a> as a backend. Other than that, I
assume no tools exist on the system. Just a C compiler, some very basic shell
implementation, and nothing else.</p>

<p>I won‚Äôt get into the raw <em>experience</em> of writing a compiler in this blogpost.
But so far, I have the lexer done, as well as a sizable part of the parser.
Macro/module expansion is something I‚Äôm putting off as long as possible,
typechecking only supports <code>i32</code>, and codegen is a little bit rough. But it‚Äôs a
start.</p>

<p>I can successfully compile this code:</p>

<div><pre><code><span>fn</span> <span>rust_main</span><span>()</span> <span>-&gt;</span> <span>i32</span> <span>{</span>
    <span>(</span><span>2</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>6</span> <span>+</span> <span>3</span>
<span>}</span>
</code></pre></div>

<p>So, where to from here? Here‚Äôs my plan.</p>

<ul>
  <li>Slowly advance <a href="https://codeberg.org/notgull/dozer">Dozer</a> until it can compile some basic <code>libc</code>-using samples,
then <code>libcore</code>, then <a href="https://github.com/rust-lang/rust">rustc</a>.
    <ul>
      <li>For the record, I‚Äôm planning on compiling <a href="https://github.com/rust-lang/rust">rustc</a>‚Äôs <a href="https://github.com/rust-lang/rustc_codegen_cranelift">Cranelift</a>
backend, which is written entirely in Rust. Since we‚Äôre assuming we don‚Äôt
have C++ yet, we can‚Äôt compile LLVM.</li>
    </ul>
  </li>
  <li>Create a <code>cargo</code> equivalent that can use <a href="https://codeberg.org/notgull/dozer">Dozer</a> to compile Rust packages.</li>
  <li>Find out which sources in <a href="https://github.com/rust-lang/rust">rustc</a> are automaticaly generated and then strip
them out. By the Bootstrappable project‚Äôs rules, automatically generated code
is not allowed.</li>
  <li>Create a process that can be used to compile <a href="https://github.com/rust-lang/rust">rustc</a> and then <code>cargo</code>, then
use our compiled versions of <a href="https://github.com/rust-lang/rust">rustc</a>/<code>cargo</code> to re-compile canonical versions
of <a href="https://github.com/rust-lang/rust">rustc</a>/<code>cargo</code>.</li>
</ul>

<p>This will definitely be the hardest project I‚Äôve ever undertaken. Part of me
doubts that I will be able to finish it. But you know what? It‚Äôs better to have
tried and lost than to never have tried at all.</p>

<p>Stay tuned for more <a href="https://codeberg.org/notgull/dozer">Dozer</a> updates, as well as an explanation of the
architecture I have planned.</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pi Pico 2 Extreme Teardown (152 pts)]]></title>
            <link>http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html</link>
            <guid>41351380</guid>
            <pubDate>Sun, 25 Aug 2024 21:01:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html">http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html</a>, See on <a href="https://news.ycombinator.com/item?id=41351380">Hacker News</a></p>
Couldn't get http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Database "sharding" came from Ultima Online? (277 pts)]]></title>
            <link>https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/</link>
            <guid>41351219</guid>
            <pubDate>Sun, 25 Aug 2024 20:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/">https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/</a>, See on <a href="https://news.ycombinator.com/item?id=41351219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://startuplessonslearned.blogspot.com/2009/01/sharding-for-startups.html#comment-form"><span title="L"><span>L</span></span>essons Learned: Sharding for startups </a>is a technical post about database scalability. What caught my eye was the <em>term</em>. What an odd term ‚Äî ‚Äúsharding.‚Äù Why would a database be described that way?</p>
<p>So I started reading a bit about it. It basically means running a bunch of parallel databases and looking into the right one, rather than trying to cram everything into one.</p>
<p>Near as I can tell, a quick Google seems to say that the term came about <a href="http://highscalability.com/unorthodox-approach-database-design-coming-shard">because of a guy who worked at Friendster and Flickr, </a>and seems to . Wikipedia has only had <a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)">an article</a> for a little while. In the comment thread at Lessons Learned, there‚Äôs mention of the term being used in 2006.</p>
<p>Flickr, of course, was born as an MMO called <a href="https://en.wikipedia.org/wiki/Game_Neverending"><em>Game Neverending</em></a>. In fact, I was quoted in Ludicorp‚Äôs business plan, and Stewart Butterfield had asked if I could be an advisor, but I couldn‚Äôt do it at the time because of my contract with Sony. Sigh. Anyway, I would be <em>shocked</em> if the term ‚Äúshard‚Äù hadn‚Äôt been thrown around those offices‚Ä¶ because in MMOs, of course, ‚Äúshards‚Äù has a very specific meaning and history.</p>

<p>It means database partitioning ‚Äî of worlds. Parallel worlds each running the same static template database source, but evolving different runtime databases. But these were just called ‚Äúservers‚Äù ‚Äî like, <em>Meridian 59</em> had bunches of them, and they had numbers instead of the common practice of names that is in use today.</p>
<div><p><img decoding="async" title="A snippet from the UO intro movie" src="https://upload.wikimedia.org/wikipedia/en/c/cb/Mondain-uo-intro.jpg" alt="A snippet from the UO intro movie" width="283" height="160"></p><p>A snippet from the UO intro movie</p></div>
<p>No, ‚Äúshards‚Äù came about specifically because when we realized we would need to run multiple whole copies of <em>Ultima Online</em> for users to connect to, we needed to come up with a fiction for it. I went off and read a whole mess of stuff about early Ultima lore and tried to come up with a fictional justification. What I ended up with <a href="https://en.wikipedia.org/wiki/Britannia_(Ultima_Online)">is described here pretty well</a>: that the evil wizard Mondain had attempted to gain control over Sosaria by trapping its essence in a crystal. When the Stranger at the end of Ultima I defeated Mondain and shattered the crystal, the crystal <strong>shards</strong> each held a refracted copy of Sosaria.</p>
<p>It was a very very specific word chosen because, well, it was a piece of a crystal, which was a completely fictional invention. If Mondain had captured Sosaria on a parchment or in a painting, I would have said ‚Äúa tatter‚Äù or a ‚Äúfragment‚Äù or some such. But in the original U1, it specifically said he had used a crystal to gain power. We even talked about terms like ‚Äúmultiverse‚Äù and the like at the time and dismissed them as comic-book geeky and not really Ultima-flavored‚Ä¶ so ‚Äúshard‚Äù it was.</p>
<p>Now, from there time kept marching forward as each parallel Sosaria evolved in tandem. (UO was supposed to be between U3 and U4, in terms of chronology). The difference is, some of them got the Avatar (sent by the Time Lord) and some didn‚Äôt. Some of them were captured by The Guardian, and we invented the notion that Shadowlords were essentially evil beings created from shards he had captured. In fact, the beta test shard eventually was captured in this way ‚Äî if you read up on it, you‚Äôll find that really, there should be a fourth Shadowlord running around now.</p>
<div><p><a href="http://flickr.com/photos/37996580417@N01/6819311"><img fetchpriority="high" decoding="async" title="Original planned UO map" src="https://i0.wp.com/farm1.static.flickr.com/6/6819311_40cd3d3801.jpg?resize=400%2C300" alt="Original planned UO map, photo by Cory Doctorow, CC BY-SA" width="400" height="300" data-recalc-dims="1"></a></p><p>Original planned UO map, photo by Cory Doctorow, CC BY-SA</p></div>
<p>(Originally, the landmass of <em>Second Age</em> was supposed to be Ambrosia from Ultima III, and there‚Äôs actually a spot up north that is where Exodus is supposed to go. We even made the art for the whirlpool that is supposed to go there, and then just never put it in. But that‚Äôs a whole other story‚Ä¶)</p>
<p>(Oh‚Ä¶ and then why does the Stranger in the original UO intro movie have an Ankh on his chest? Because U9 was in development aready, and nobody had time to make a new model. üôÇ So it‚Äôs the same 3d model as was used in U9, which didn‚Äôt ship until <em>years</em> later. So expedience led to a fictional glitch.)</p>
<p>In any case, we called parallel servers ‚Äúshards‚Äù and it became a term used occasionally though not universally as a term of art within the field. You‚Äôll hear folks who worked on MMOs in the 90s use server and shard interchangeably ‚Äî sometimes saying ‚Äúshard‚Äù to reference a parallel server cluster rather than a physical server.</p>
<p>So, did this database term come from a doc that I dashed off one afternoon in 1996? Umm‚Ä¶ I am not sure. Seems like an interesting coincidence, if not.</p>
<p>I wonder if I still have that doc‚Ä¶</p>

 </div></div>]]></description>
        </item>
    </channel>
</rss>