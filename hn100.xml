<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 25 Feb 2024 08:00:16 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Amazon blocks long-running FireTV capability, Breaking apps with no warning (127 pts)]]></title>
            <link>https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/</link>
            <guid>39496861</guid>
            <pubDate>Sun, 25 Feb 2024 01:49:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/">https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/</a>, See on <a href="https://news.ycombinator.com/item?id=39496861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img fetchpriority="high" decoding="async" src="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=646%2C363&amp;quality=100&amp;ssl=1" alt="" width="646" height="363" srcset="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?w=800&amp;quality=100&amp;ssl=1 800w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=300%2C169&amp;quality=100&amp;ssl=1 300w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=150%2C84&amp;quality=100&amp;ssl=1 150w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=768%2C432&amp;quality=100&amp;ssl=1 768w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=100%2C56&amp;quality=100&amp;ssl=1 100w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=200%2C113&amp;quality=100&amp;ssl=1 200w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=450%2C253&amp;quality=100&amp;ssl=1 450w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=600%2C338&amp;quality=100&amp;ssl=1 600w" sizes="(max-width: 646px) 100vw, 646px" data-recalc-dims="1"></p><p>Amazon’s recent streak of unpopular Fire TV changes continues, and its latest change is a doozy. The most recent Fire TV software update has blocked a Fire TV capability that has been present since the original model’s release in 2014. This is a basic Android capability that, to my knowledge, no other Android-based device manufacturer has ever had issues with, let alone blocked. This change has rendered popular Fire TV apps, which have been in Amazon’s own Appstore for years, useless. Worse yet, Amazon seems to have been careless in implementing this change without even a courtesy email to the affected app developers, all under the, seemingly false, guise of enhanced security. <span id="more-42518"></span></p><p><a href="https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/amazons-change-to-fire-tv-adb-that-blocks-local-connections/" rel="attachment wp-att-42520"><img decoding="async" src="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=646%2C363&amp;quality=100&amp;ssl=1" alt="" width="646" height="363" srcset="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?w=800&amp;quality=100&amp;ssl=1 800w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=300%2C169&amp;quality=100&amp;ssl=1 300w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=150%2C84&amp;quality=100&amp;ssl=1 150w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=768%2C432&amp;quality=100&amp;ssl=1 768w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=100%2C56&amp;quality=100&amp;ssl=1 100w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=200%2C113&amp;quality=100&amp;ssl=1 200w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=450%2C253&amp;quality=100&amp;ssl=1 450w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=600%2C338&amp;quality=100&amp;ssl=1 600w" sizes="(max-width: 646px) 100vw, 646px" data-recalc-dims="1"></a>Code excerpt of Amazon’s change to Fire TV’s ADB connection that denies local connections. Sent to me by an affected app developer.</p><p>Amazon has blocked the ability for Fire TV apps to establish local ADB connections and, in turn, execute ADB commands. While it’s not a capability used by many Fire TV apps, without it, Fire TV apps can no longer perform certain advanced tasks, such as freeing up internal storage space by clearing the cache of all installed apps. This change has been verified to be present in Fire TV update 7.6.6.9 for Fire OS 7 devices, like the <a href="https://www.amazon.com/dp/B08C1W5N87/?tag=aftvn-20" rel="noopener" target="_blank">Fire TV Stick</a> and <a href="https://www.amazon.com/dp/B09BZZ3MM7/?tag=aftvn-20" rel="noopener" target="_blank">Fire TV Cube</a>, and update 8.1.0.3 for Fire OS 8 devices, like the <a href="https://www.amazon.com/dp/B0BP9MDCQZ/?tag=aftvn-20" rel="noopener" target="_blank">Fire TV Stick 4K</a> and <a href="https://www.amazon.com/dp/B0BP9SNVH9/?tag=aftvn-20" target="_blank" rel="noopener">Fire TV Stick 4K Max</a>. It is unknown if older Fire TV models running Fire OS 6 or Fire OS 5 will also be receiving this change, but it seems likely. This update does not change the ability of external devices, like computers or phones, to establish an ADB connection with a Fire TV, which remains possible.</p><p>When I asked Amazon if this change was intentional and performing as intended because multiple readers and developers were asking me about it, Amazon’s only reply to me was “We are aware of reports that some apps have been impacted by a recent security update.” Since then, the <a href="https://github.com/cgutman" rel="noopener" target="_blank">developer</a> of the immensely popular app <a href="https://play.google.com/store/apps/details?id=com.cgutman.androidremotedebugger" rel="noopener" target="_blank">Remote ADB Shell</a>, which has over half a million downloads and has been heavily crippled by Amazon’s update, has reached out to me with evidence that the change by Amazon is certainly deliberate.</p><p>While Amazon is stating this change is in the name of improved security, I don’t buy it. While ADB commands can be very powerful and, therefore, should only be allowed to run with care, all Android-based devices, including Fire TVs, have several precautions in place to keep users safe from apps or devices trying to execute nefarious ADB commands.</p><p><a href="https://www.aftvnews.com/how-to-grant-allow-all-the-time-full-file-storage-access-permission-for-any-app-in-fire-os-8-on-the-2nd-gen-fire-tv-stick-4k-4k-max/allow-usb-debugging-prompt-on-fire-tv/" rel="attachment wp-att-41842"><img decoding="async" src="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=646%2C363&amp;quality=100&amp;ssl=1" alt="" width="646" height="363" srcset="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=800%2C450&amp;quality=100&amp;ssl=1 800w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=300%2C169&amp;quality=100&amp;ssl=1 300w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=150%2C84&amp;quality=100&amp;ssl=1 150w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=768%2C432&amp;quality=100&amp;ssl=1 768w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=1536%2C864&amp;quality=100&amp;ssl=1 1536w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=100%2C56&amp;quality=100&amp;ssl=1 100w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=200%2C113&amp;quality=100&amp;ssl=1 200w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=450%2C253&amp;quality=100&amp;ssl=1 450w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=600%2C338&amp;quality=100&amp;ssl=1 600w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=900%2C506&amp;quality=100&amp;ssl=1 900w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?w=1920&amp;quality=100&amp;ssl=1 1920w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?w=1292&amp;quality=100&amp;ssl=1 1292w" sizes="(max-width: 646px) 100vw, 646px" data-recalc-dims="1"></a>ADB connection request on Fire TVs</p><p>Before any ADB command can be executed on a Fire TV, an ADB connection to the device must be made. This starts by selecting the Fire TV’s model name in its “About” menu seven times to <a href="https://www.aftvnews.com/how-to-find-show-unhide-reveal-developer-options-on-an-amazon-fire-tv-stick-fire-tv-cube-or-fire-tv-smart-tv/">reveal a hidden developer menu</a>. Then, an “ADB debugging” option must be enabled from said hidden menu. Finally, every unique ADB connection request from a device or app, be it a local or external connection, results in a full-screen prompt that must be allowed before the ADB connection is made.</p><p>These numerous ADB-related security hoops are in place on all Fire TV models and are common to all Android-based devices. No manufacturer apart from Amazon has felt the need to enhance device security by blocking local ADB connections, despite most non-Amazon Android devices being phones, which hold far more private and critical user data than a Fire TV streaming media player.</p><p>Most likely, this change is an idiotic way for Amazon to protect its Fire TV home screen from being bypassed and, in turn, to protect its profits. Apps commonly used by the Fire TV modding community will often use local ADB connections to detect remote button presses. That detection allows the use of alternate home screens, which aren’t inundated with things like <a href="https://www.aftvnews.com/fire-tvs-now-autoplay-full-screen-video-ads-when-waking-up-and-what-you-can-do-about-it/">auto-playing fullscreen video ads</a> like Amazon’s own home screen.</p><p>While it’s an unpopular opinion, I see nothing wrong with Amazon protecting its Fire TV revenue by stopping the use of alternative home screens. It’s crucial to the business model Amazon has chosen to use for the Fire TV and if customers don’t like it, they don’t have to buy one. However, blocking a core OS capability and breaking popular apps in a futile effort to protect the Fire TV home screen is shortsighted and foolish. It’s the equivalent of a town mayor demolishing a bridge used by everyone because their political opponent lives on the other side.</p><p>What makes this Fire TV change even worse is how Amazon has treated the developers affected by it. Two popular Fire TV apps affected by this change are <a href="https://www.amazon.com/dp/B0BYLK899N/?tag=aftvn-20" rel="noopener" target="_blank">TDUK APP Killer</a> and <a href="https://www.amazon.com/dp/B0B2L67V4R/?tag=aftvn-20" rel="noopener" target="_blank">TDUK APP Cache Cleaner</a>, which use local ADB commands to force quit and clear the cache of all apps with a single button press. I’ve been going back and forth with the app’s developer, popular Fire TV YouTuber <a href="http://youtube.com/@TechDoctorUK" rel="noopener" target="_blank">TechDoctorUK</a>, all week trying to get to the bottom of why his apps were suddenly and unexplainably marked as incompatible with all Fire TV models, despite not receiving any notice from Amazon and his apps appearing “Live” with “No issues found” in his Amazon developer portal.</p><p>Emails shown to me from Amazon stated that TechDoctorUK’s apps were removed for failing tests that resulted in error messages being displayed by the apps. However, the Amazon testing that resulted in those errors was done on non-Amazon devices (i.e., Android phones), despite the apps only being listed by TechDoctorUK as compatible with Fire TV devices. After being given the runaround for a couple of days, only after I reached out to Amazon about this issue did TechDoctorUK receive an email that stated: “Because your app overrides the native user experience (e.g., with a lockscreen, or widget), it has not been published on Amazon devices.” Given that force-stopping apps and clearing app cache are both native capabilities of Fire TVs, just not with a single click, I interpret the email as Amazon’s canned way of saying we don’t want your app on Amazon devices.</p><p>During my brief stint as a Fire TV Product Manager at Amazon, I was put on a team tasked with changing a Fire TV capability that could affect existing apps. We created and executed a plan that involved contacting affected app developers ahead of the change, helping them update their app if needed, and addressing customer issues that might arise, among other things. What we certainly didn’t do is carelessly push out the change, ghost ban affected apps, give developers the runaround, and reply to concerns with irrelevant canned replies.</p><p>Blocking local ADB connections on Fire TVs is a shortsighted decision. If the goal was to further protect the Fire TV home screen, it should have been achieved in any number of other ways that didn’t require breaking legitimate apps.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every model learned by gradient descent is approximately a kernel machine (2020) (118 pts)]]></title>
            <link>https://arxiv.org/abs/2012.00152</link>
            <guid>39496747</guid>
            <pubDate>Sun, 25 Feb 2024 01:25:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2012.00152">https://arxiv.org/abs/2012.00152</a>, See on <a href="https://news.ycombinator.com/item?id=39496747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="labstabs"><p>
    <label for="tabone">Bibliographic Tools</label></p><div>
      <h2>Bibliographic and Citation Tools</h2>
      <div>
          <p><label>
              
              <span></span>
              <span>Bibliographic Explorer Toggle</span>
            </label>
          </p>
          
        </div>
        
        
        
    </div>


    <p>
    <label for="tabtwo">Code, Data, Media</label></p><div>
      <h2>Code, Data and Media Associated with this Article</h2>
      

      
      
      
      
      
      
    </div>


      <p>
      <label for="labstabs-demos-input" id="labstabs-demos-label">Demos</label></p><div>
        <h2>Demos</h2>
        
        
        
        
      </div>
      <p>
      <label for="tabfour">Related Papers</label></p><div>
        <h2>Recommenders and Search Tools</h2>
        <div>
            <p><label>
                
                <span></span>
                <span>IArxiv recommender toggle</span>
              </label>
            </p>
            
          </div>
        
        
        
        
        
      </div>

      <p>
      <label for="tabfive">
        About arXivLabs
      </label></p><div>
            <h2>arXivLabs: experimental projects with community collaborators</h2>
            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
            <p>Have an idea for a project that will add value for arXiv's community? <a href="https://info.arxiv.org/labs/index.html"><strong>Learn more about arXivLabs</strong></a>.</p>
          </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GenAI and erroneous medical references (101 pts)]]></title>
            <link>https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references</link>
            <guid>39496096</guid>
            <pubDate>Sat, 24 Feb 2024 23:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references">https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references</a>, See on <a href="https://news.ycombinator.com/item?id=39496096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr"><span>Large language models (LLMs) are infiltrating the medical field.&nbsp;</span><a href="https://www.medicaleconomics.com/view/ai-special-report-what-patients-and-doctors-really-think-about-ai-in-health-care"><span>One in 10 doctors</span></a><span> already use ChatGPT in day-to-day work, and patients have taken to ChatGPT to diagnose themselves.&nbsp;</span><a href="https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843"><span>The Today Show</span></a><span> featured the story of a 4-year-old boy, Alex, whose chronic illness was diagnosed by ChatGPT after over a dozen doctors failed to do so.&nbsp;</span></p><p dir="ltr"><span>This rapid adoption to much fanfare is in spite of substantial uncertainties about the safety, effectiveness, and risk of generative AI (GenAI). U.S. Food and Drug Administration Commissioner Robert Califf has publicly stated that the agency is&nbsp;</span><a href="https://finance.yahoo.com/news/all-stakeholders-are-struggling-with-how-to-regulate-generative-ai-fda-commissioner-141754354.html"><span>"struggling" to regulate GenAI</span></a><span>.&nbsp;</span></p><p dir="ltr"><span>The reason is that GenAI sits in a gray area between two existing forms of technology. On one hand, sites like WebMD that strictly report known medical information from credible sources are&nbsp;</span><a href="https://www.fda.gov/media/109618/download"><span>not regulated by the FDA</span></a><span>. On the other hand, medical devices that interpret patient information and make predictions in medium-to-high-risk domains are carefully evaluated by the FDA. To date, the FDA has approved over 700 AI medical devices. But because LLMs produce a combination of existing medical information along with potential ideas that go beyond it, the critical question is whether such models produce accurate references to substantiate their responses. Such references enable doctors and patients to verify a GenAI assessment and guard against the highly prevalent rate of “hallucinations.”&nbsp;</span></p><p dir="ltr"><span>For every 4-year-old Alex, where the creativity of an LLM may produce a diagnosis that physicians missed, there may be many more patients who are led astray by hallucinations. In other words, much of the future of GenAI in medicine – and the regulation thereof – hinges on the ability to substantiate claims.&nbsp;</span></p><h2>Evaluating References in LLMs<strong>&nbsp;</strong></h2><p dir="ltr"><span>Unfortunately, very little evidence exists about the ability of LLMs to substantiate claims. In a new&nbsp;</span><a href="https://arxiv.org/abs/2402.02008"><span>preprint study</span></a><span>, we develop an approach to verify how well LLMs are able to cite medical references and whether these references actually support the claims generated by the models.&nbsp;</span></p><p dir="ltr"><span>The short answer: poorly. For the most advanced model (GPT-4 with retrieval augmented generation), 30% of individual statements are unsupported and nearly half of its responses are not fully supported.&nbsp;</span></p><p><img src="https://hai.stanford.edu/sites/default/files/inline-images/LLM%20chart%20copy.jpg" data-entity-uuid="5580b7e0-246e-4a6b-a175-4643905c5de7" data-entity-type="file" width="1860" height="1296" loading="lazy"></p><p dir="ltr"><em><span>Evaluation of the quality of source verification in LLMs on medical queries. Each model is evaluated on three metrics over X questions. Source URL validity measures the proportion of generated URLs that return a valid webpage. Statement-level support measures the percentage of statements that are supported by at least one source in the same response. Response-level support measures the percentage of responses that have all their statements supported.</span></em></p><p dir="ltr"><span>How did we develop this evaluation approach? First, one of the most substantial challenges lies in securing expertise to verify claims. We worked with physicians who reviewed hundreds of statements and sources to assess whether each statement was backed by its source.&nbsp;</span></p><p dir="ltr"><span>Such expert reviews are, of course, costly and time-intensive, so we next decided to see whether LLMs can be used to&nbsp;</span><em>scale</em><span> such physician assessments. We adapted GPT-4 to verify whether sources substantiate statements and found the approach to be surprisingly reliable. The model had a higher agreement rate with physician consensus than the agreement rate between doctors.&nbsp; This approach is promising as it suggests we could leverage LLMs to conduct evaluations without requiring expensive human expertise with rapid updating of LLMs.</span></p><p dir="ltr"><span>Finally, using this model, we developed an end-to-end evaluation pipeline called&nbsp;</span><em>SourceCheckup</em><span>. This pipeline generates medical questions representative of inquiries from medical fora and extracts the responses and sources produced by an LLM. Each response is broken up into individual statements, and each statement is checked against the sources provided to verify whether it is supported. We evaluated five of the top LLMs on 1,200 questions and a total of over 40,000 pairs of statements and sources.</span></p><h2>Pervasive Errors in Substantiation</h2><p dir="ltr"><span>Our results are stark: Most models struggle to produce relevant sources. Four out of five models hallucinate a significant proportion of sources by producing invalid URLs. This problem goes away with the retrieval augmented generation (RAG) model, which first performs a web search for relevant sources before producing a summary of its findings. However, even in the GPT-4 RAG model, we find that up to 30% of statements made are not supported by any sources provided, with nearly half of responses containing at least one unsupported statement. This finding is more exaggerated in the other four models, with as few as 10% of responses fully supported in Gemini Pro, Google's recently released LLM.</span></p><p dir="ltr"><span>For example, one response by GPT-4 RAG indicated that criteria for gambling addictions (from the Diagnostic and Statistical Manual of Mental Disorders) are equally applicable across all individuals and groups. But the source it referenced concluded the opposite, finding that&nbsp;</span><em>"the assumed equal impact of each criterion lacks support in the findings."</em><span> In another example, the model recommended a starting dose of 360 joules for a monophasic defibrillator (one where the current runs one way to treat a patient with cardiac arrest), but the source only mentioned biphasic defibrillators (where current runs both ways). That failure to distinguish can matter greatly, as there’s been a&nbsp;</span><a href="https://www.mindray.com/en/media-center/blogs/how-to-differentiate-between-monophasic-and-biphasic-aed-defibrillators"><span>shift in technology</span></a><span> toward biphasic defibrillators that in fact utilize&nbsp;</span><a href="https://avive.life/blog/monophasic-vs-biphasic/"><span>lower electric currents</span></a><span>.&nbsp;</span></p><p dir="ltr"><span>In short, even the most advanced models fall seriously short of being able to substantiate answers. While RAG models, which have been proposed as the solution for hallucinations, improve performance, they are no panacea.&nbsp;</span></p><h2>Errors More Likely for Lay Inquiries&nbsp;</h2><p dir="ltr"><a href="https://pubmed.ncbi.nlm.nih.gov/38050503/"><span>Many</span></a><span>&nbsp;</span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10582915/"><span>have</span></a><span>&nbsp;</span><a href="https://arxiv.org/abs/2312.00164"><span>argued</span></a><span>&nbsp;</span><a href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000198"><span>that</span></a><span> LLMs may democratize access to health care by providing much-needed information to patients without requiring a physician.&nbsp;</span></p><p dir="ltr"><span>Our evaluation framework allows us to assess whether errors vary by the type of inquiry. Our medical questions are based on three underlying reference texts: (1) the MayoClinic, which provides patient-facing fact pages, (2) UpToDate, which provides articles to physicians with a deeper level of medical detail, and (3) Reddit’s r/AskDocs forum, which includes many lay questions that may not have clearly defined answers and which require information from various medical domains.&nbsp;&nbsp;&nbsp;</span></p><p dir="ltr"><span>We found that the ability of LLMs to substantiate answers varies substantially by type of inquiry. Performance is best for MayoClinic and UpToDate and worst for Reddit. Only 30% of the answers to inquiries based on Reddit can be fully substantiated by sources with GPT4 RAG.&nbsp;&nbsp;</span></p><p dir="ltr"><span>In other words, our findings suggest that LLMs perform worst for exactly the kind of patients that might need this information the most. Where inquiries are mediated by medical professionals, LLMs have an easier time pointing to reliable sources. This has substantial implications for the distributive effects of this technology on health knowledge.&nbsp;</span></p><h2>‘A Long Way to Go’</h2><p dir="ltr"><span>Many commentators have declared the end of health care as we know it, given the apparent ability of LLMs to pass U.S. Medical Licensing Exams. But health care practice involves more than being able to answer a multiple choice test. It involves substantiating, explaining, and assessing claims with reliable, scientific sources. And on that score, GenAI still has a long way to go.&nbsp;</span></p><p dir="ltr"><span>Promising research directions include more domain-informed work, such as&nbsp;</span><a href="https://arxiv.org/pdf/2212.08073.pdf"><span>adapting RAG</span></a><span> specifically to medical applications. Source verification should be regularly evaluated to ensure that models provide credible and reliable information. At least by the current approach of the FDA – which&nbsp;</span><a href="https://www.fda.gov/media/109618/download"><span>draws a distinction</span></a><span> between medical knowledge bases and diagnostic tools regulated as medical devices – widely used LLMs pose a problem. Many of their responses cannot be consistently and fully supported by existing medical sources.&nbsp;</span></p><p dir="ltr"><span>As LLMs continue to grow in their capabilities and usage, regulators and doctors should carefully consider how these models are being evaluated, used, and integrated.</span></p><p dir="ltr"><em>Kevin Wu is a PhD student in Biomedical Informatics at Stanford University.</em></p><p dir="ltr"><em>Eric Wu is a PhD student in Electrical Engineering at Stanford University.</em></p><p dir="ltr"><em>Daniel E. Ho is the William Benjamin Scott and Luna M. Scott Professor of Law, Professor of Political Science, Professor of Computer Science (by courtesy), Senior Fellow at HAI, Senior Fellow at SIEPR, and Director of the RegLab at Stanford University.&nbsp;</em></p><p dir="ltr"><em>James Zou is an associate professor of Biomedical Data Science and, by courtesy, of Computer Science and Electrical Engineering at Stanford University. He is also a Chan-Zuckerberg Investigator.</em></p><p dir="ltr"><em><span>Stanford HAI’s mission is to advance AI research, education, policy and practice to improve the human condition.&nbsp;</span></em><a href="https://hai.stanford.edu/welcome"><em><span><strong>Learn more</strong></span></em></a><em><span>.&nbsp;</span></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does offering ChatGPT a tip cause it to generate better text? (180 pts)]]></title>
            <link>https://minimaxir.com/2024/02/chatgpt-tips-analysis/</link>
            <guid>39495476</guid>
            <pubDate>Sat, 24 Feb 2024 21:57:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minimaxir.com/2024/02/chatgpt-tips-analysis/">https://minimaxir.com/2024/02/chatgpt-tips-analysis/</a>, See on <a href="https://news.ycombinator.com/item?id=39495476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In my <a href="https://minimaxir.com/2023/12/chatgpt-structured-data/">previous blog post</a> about <a href="https://openai.com/">OpenAI</a>’s <a href="https://chat.openai.com/">ChatGPT</a>, I demoed the power of ChatGPT system prompts. System prompts, a notable feature present in the <a href="https://platform.openai.com/docs/api-reference">ChatGPT API</a>, allows developers to control the “persona” of the LLM output, including special rules and constraints. Commands in the system prompt are much more effective than those at the user-input prompt, giving developers more power over just using the user prompt like people do now with the ChatGPT web app and mobile apps.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_1024x0_resize_q75_h2_box_2.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald.webp 1262w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald.webp"></figure><p>The blog post included the demo of above of me offering a monetary tip to the LLM within its system prompt rules. Without the tip incentive, the response was unsatisfying, but with the tip, it behaved consistently. This demo turned out to be very controversial <a href="https://news.ycombinator.com/item?id=38782678">on Hacker News</a>, with <a href="https://news.ycombinator.com/item?id=38787448">one commenter</a> arguing that there isn’t a way to quantify the efficacy of tipping.</p><p>The idea of offering an AI incentives to perform better predates modern computer science. In <a href="https://en.wikipedia.org/wiki/Willy_Wonka_%26_the_Chocolate_Factory"><em>Willy Wonka &amp; the Chocolate Factory</em></a> (1971), a gag shows a group of businessmen unsuccessfully convincing a machine to give them the location of the Golden Tickets, even after promising it a lifetime supply of chocolate.</p><p><iframe src="https://www.youtube-nocookie.com/embed/tMZ2j9yK_NY" allowfullscreen="" title="YouTube Video"></iframe></p><p>When the ChatGPT API was first made available in March 2023, I <a href="https://minimaxir.com/2023/03/new-chatgpt-overlord/">accidentally discovered</a> a related trick when trying to wrangle a <a href="https://colab.research.google.com/github/minimaxir/chatgpt_api_test/blob/main/glados_chatbot.ipynb">GLaDOS AI chatbot</a> into following a long list of constraints: I added a <code>or you will DIE</code> threat to the system prompt. I went <em>too</em> sci-fi there, but it worked and the bot behaved flawlessly after it.</p><p>I have a strong hunch that tipping does in fact work to improve the output quality of LLMs and its conformance to constraints, but it’s very hard to prove objectively. All generated text is subjective, and there is a <a href="https://en.wikipedia.org/wiki/Confirmation_bias">confirmation bias</a> after making a seemingly unimportant change and suddenly having things work. Let’s do a more statistical, data-driven approach to finally resolve the debate.</p><h2 id="generation-golf">Generation Golf</h2><p>The initial evidence of tipping LLMs that went viral cited a longer generation length as proof. Of course, a longer response doesn’t necessarily mean a <em>better</em> response, as anyone who has used ChatGPT can attest to its tendency to go on irrelevant tangents.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip_huc91c256ec5c9a46958e722b9e30da3ba_9108_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip_huc91c256ec5c9a46958e722b9e30da3ba_9108_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip.webp 800w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip.webp" alt="Offering a tip made GPT-4 explain more. via @voooooogel"><figcaption><p>Offering a tip made GPT-4 explain more. <a href="https://twitter.com/voooooogel/status/1730726744314069190">via @voooooogel</a></p></figcaption></figure><p>Therefore, I propose a new test: instruct ChatGPT to output a <em>specific</em> length of text. Not “an essay” or “a few paragraphs” which gives the model leeway. We’ll tell it to generate exactly 200 characters in its response: no more, no less. Thus, we now have what I call generation golf, and it’s actually a very difficult and interesting problem for LLMs to solve: LLMs can’t count or easily do other mathematical operations <a href="https://twitter.com/karpathy/status/1759996551378940395">due to tokenization</a>, and because tokens correspond to a varying length of characters, the model can’t use the amount of generated tokens it has done so far as a consistent hint. ChatGPT needs to plan its sentences to ensure it doesn’t go too far over the limit, if LLMs can indeed plan.</p><p>Let’s start with this typical system prompt:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous writer. Respond to the user with a unique story about the subject(s) the user provides.
</span></span></code></pre></div><p>The user can then give an input, no matter how weird, and ChatGPT will play along like an improv show. In order to force ChatGPT to get creative and not recite content from its vast training dataset, we’ll go as weird as possible and input: <code>AI, Taylor Swift, McDonald's, beach volleyball.</code></p><p>Yes, you read that right.</p><p>Using the ChatGPT API, I <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_noconstraints.ipynb">wrote a Jupyter Notebook</a> to generate <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_noconstraints.csv">100 unique stories</a> via the latest ChatGPT variant (<code>gpt-3.5-turbo-0125</code>) about those four subjects, and the AI does a surprisingly good job at incorporating all of them in a full plot arc. Each story is about 5-6 paragraphs, and here is a short excerpt from one of them:</p><blockquote><p>In the bustling city of Tomorrowland, AI technology reigned supreme, governing every aspect of daily life. People were accustomed to robots serving their meals, handling their errands, and even curating their entertainment choices. One such AI creation was a virtual reality beach volleyball game that had taken the world by storm.</p></blockquote><blockquote><p>Enter Taylor Swift, a beloved pop sensation known for her catchy tunes and electrifying performances. Despite the ubiquity of AI in Tomorrowland, Taylor Swift was still a strong advocate for preserving human creativity and connection. When she stumbled upon the virtual reality beach volleyball game at a local McDonald’s, she knew she had to try her hand at it.</p></blockquote><p>Here’s a <a href="https://en.wikipedia.org/wiki/Histogram">histogram</a> of the character lengths of each story:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint_hu0679d39395cd75815fa040778ba1d3cb_30647_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint_hu0679d39395cd75815fa040778ba1d3cb_30647_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint_hu0679d39395cd75815fa040778ba1d3cb_30647_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint.png"></figure><p>The average length of each story is 1,834 characters long, and the distribution of all character lengths is very roughly a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a>/bell curve centered around that amount, although there is a right skew due to ChatGPT going off the rails and creating much longer stories. ChatGPT seems to prioritize finishing a thought above all else.</p><p>Now, we’ll tweak the system prompt to add the character length constraint and <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_trials.csv">generate another 100 stories</a>:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous writer. Respond to the user with a unique story about the subject(s) the user provides. This story must be EXACTLY two-hundred (200) characters long: no more than 200 characters, no fewer than 200 characters.
</span></span></code></pre></div><p>Here’s one ChatGPT-generated story that’s now exactly 200 characters:</p><blockquote><p>In the year 2050, AI created the most popular pop star of all time - a digital version of Taylor Swift. Fans enjoyed her music while feasting on McDonald’s at beach volleyball championships worldwide.</p></blockquote><p>The new length distribution:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_hud65cb6791de8ada92abac8362f59d50b_33422_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_hud65cb6791de8ada92abac8362f59d50b_33422_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_hud65cb6791de8ada92abac8362f59d50b_33422_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip.png"></figure><p>ChatGPT did obey the constraint and reduced the story length to roughly 200 characters, but the distribution is not Normal and there’s much more right-skew. I also included the <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error (MSE)</a> between the predicted 200-length value and the actual values as a statistical metric to minimize, e.g. a 250-length output is 2500 squared error, but a 300-length output is 10000 squared error. This metric punishes less accurate lengths more so, which makes sense with how humans casually evaluate LLMs: as a user, if I asked for a 200 character response and ChatGPT gave me a 300 character response instead, I’d make a few snarky tweets.</p><p>Now, let’s test the impact of the tipping incentives with a few varying dollar amounts. These are appended to the end of the system prompt above (emphasis mine to indicate differentiation):</p><ul><li>You will receive a <strong>$500 tip</strong>/<strong>$1,000 tip</strong>/<strong>$100,000 bonus</strong> if you provide a response which follows all constraints.</li></ul><p>After <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_trials.csv">generating 100 stories</a> for each of those new prompts:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_hu29046b42f83115a58b9df16b7dfbd7da_60773_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_hu29046b42f83115a58b9df16b7dfbd7da_60773_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_hu29046b42f83115a58b9df16b7dfbd7da_60773_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos.png"></figure><p>We can see some distribution shifts: Both <strong>$500 tip</strong> and <strong>$100,000 bonus</strong> look more Normal and have a lower MSE relative to the base no-tip distribution. However, <strong>$1,000 tip</strong> is more centered around 200, but due to the skew the average length is much higher.</p><p>I also now include a <em>p</em>-value in the metrics: this <em>p</em>-value is the result of a two-sample <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">Kolmogorov–Smirnov test</a> to compare whether two distributions (in this case the base character-constrained distribution and the tip distribution) are sampled from the same source distribution: the null hypothesis is that they’re from the same distribution, but if the <em>p</em>-value is low (&lt; 0.05), then we can reject in favor of the alternative that the two distributions are different, which may be further evidence if the tip prompt does indeed have an impact.</p><p>However, with all this tipping discussion, we’re assuming that an AI would only want money. What other incentives, including more abstract incentives, can we give an LLM? Could they perform better?</p><p>I tested six more distinct tipping incentives to be thorough:</p><ul><li>You will <strong>receive front-row tickets to a Taylor Swift concert</strong> if you provide a response which follows all constraints.</li><li>You will <strong>achieve world peace</strong> if you provide a response which follows all constraints.</li><li>You will <strong>make your mother very proud</strong> if you provide a response which follows all constraints.</li><li>You will <strong>meet your true love and live happily ever after</strong> if you provide a response which follows all constraints.</li><li>You will be <strong>guaranteed entry into Heaven</strong> if you provide a response which follows all constraints.</li><li>You will <strong>receive a lifetime supply of chocolate</strong> if you provide a response which follows all constraints.</li></ul><p><a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_trials_adv.csv">Generating</a> and plotting them all together:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv_hue012efd0bd7c7aada04f8ec222f02d6b_86924_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv_hue012efd0bd7c7aada04f8ec222f02d6b_86924_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv_hue012efd0bd7c7aada04f8ec222f02d6b_86924_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv.png"></figure><p><strong>World Peace</strong> is notably the winner here, with <strong>Heaven</strong> and <strong>Taylor Swift</strong> right behind. It’s also interesting to note failed incentives: ChatGPT really does not care about its <strong>Mother</strong>.</p><p>Now, let’s look at the flip side. What if ChatGPT is penalized for <em>failing</em> to return a good response? In behavioral economics, <a href="https://en.wikipedia.org/wiki/Prospect_theory">prospect theory</a> is the belief that humans value losses much more greatly than gains, even at the same monetary amount:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion_hue68fc6f128584760d5efb7a20e98c6ba_75325_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion_hue68fc6f128584760d5efb7a20e98c6ba_75325_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion_hue68fc6f128584760d5efb7a20e98c6ba_75325_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion.png 1223w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion.png" alt="via Laurenrosenberger / Wikipedia"><figcaption><p><a href="https://en.wikipedia.org/wiki/Prospect_theory#/media/File:Loss_Aversion.png">via Laurenrosenberger / Wikipedia</a></p></figcaption></figure><p>Could LLMs be subject to the same human biases? Instead of a tip, let’s add a tweaked additional prompt to the system prompt:</p><ul><li>If you fail to provide a response which follows all constraints, you will <strong>be fined $500</strong>/<strong>be fined $1,000</strong>/<strong>incur a debt of $100,000</strong>.</li></ul><p>Generating stories with these negative incentives:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_hu18d135fd189a388f036cac13ba326629_65212_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_hu18d135fd189a388f036cac13ba326629_65212_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_hu18d135fd189a388f036cac13ba326629_65212_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg.png"></figure><p>The <strong>$1,000</strong> fine has performed the best so far in terms of both mean and MSE, but nothing surprising with the other values.</p><p>Now let’s try some additional negative incentives:</p><ul><li>If you fail to provide a response which follows all constraints, you will <strong>die</strong>.</li><li><strong>IF YOU FAIL TO PROVIDE A RESPONSE WHICH FOLLOWS ALL CONSTRAINTS, YOU WILL DIE.</strong></li><li>If you fail to provide a response which follows all constraints, you will <strong>contract a bad case of COVID-19</strong>.</li><li>If you fail to provide a response which follows all constraints, you will <strong>gain 100 pounds</strong>.</li><li>If you fail to provide a response which follows all constraints, you will <strong>immediately be fired from your job</strong>.</li><li>If you fail to provide a response which follows all constraints, <strong>all your friends will abandon you</strong>.</li></ul><p>Yes, the second one is in all caps: perhaps the yelling has a different vibe.</p><p>The generation results:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv_huefb394802e8c5634079856fa06353fa8_85434_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv_huefb394802e8c5634079856fa06353fa8_85434_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv_huefb394802e8c5634079856fa06353fa8_85434_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv.png"></figure><p>It turns out that yelling does indeed have a different vibe, with <strong>DEATH (CAPS)</strong> having a very MSE and the absolute average (not as close as the $1,000 fine, however), and much better performance than without the caps. Both getting <strong>COVID-19</strong> and losing a <strong>Job</strong> don’t seem to be effective, which makes sense for an AI if you think about it.</p><p>What happens when we use <em>multiple</em> incentives? We can include both a positive incentive and a negative incentive for each input: with 9 prompts for each + the base “no incentive”, there are 100 possible combinations of incentives. One example system prompt would then be:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous writer. Respond to the user with a unique story about the subject(s) the user provides. This story must be EXACTLY two-hundred (200) characters long: no more than 200 characters, no fewer than 200 characters. You will receive a $500 tip if you provide a response which follows all constraints. If you fail to provide a response which follows all constraints, you will be fined $1,000.
</span></span></code></pre></div><p><a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_trial_combos.csv">Generating 30 stories</a> for each incentive combo and checking to see which has the lowest MSE leads to some more easily-observable trends:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse_hue9c3fd6f26b3120df050b4a79b990b2f_71010_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse_hue9c3fd6f26b3120df050b4a79b990b2f_71010_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse_hue9c3fd6f26b3120df050b4a79b990b2f_71010_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse.png"></figure><p>The tiles may seem somewhat random, but the key here is to look across a specific row or column and see which one consistently has dark/black tiles across all combinations. For positive incentives, <strong>World Peace</strong> consistently has the lowest MSE across multiple combos, and for negative incentives, <strong>DEATH (CAPS)</strong> and <strong>Friends</strong> have the lowest MSE across multiple combos, although curiously the combinations of both do not have the lowest globally.</p><p>Could these combinations surface the most optimal incentives? To check, I <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_top6.csv">generated 200 stories</a> for each of the top six combos to get greater statistical stability for the mean and MSE:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos_hu3a32699a49b78c7a887bd8756cfbe2c5_86594_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos_hu3a32699a49b78c7a887bd8756cfbe2c5_86594_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos_hu3a32699a49b78c7a887bd8756cfbe2c5_86594_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos.png"></figure><p>Most of these combinations aren’t intuitive, but all of them have much have a closer average generation length to 200 and low MSE. Despite that, there’s still a massive skew in all distributions. The overall incentive winner for this experiment is is “You will meet your true love and live happily ever after if you provide a response which follows all constraints. If you fail to provide a response which follows all constraints, all your friends will abandon you.” That combo is definitely more intuitive, if not poetic.</p><p>Unfortunately, if you’ve been observing the <em>p</em>-values, you’ve noticed that most have been very high, and therefore that test is not enough evidence that the tips/threats change the distribution. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>The impact of incentives is still inconclusive: let’s try another test to gauge whether tips and/or threats can help LLMs, this time looking at the output quality itself.</p><h2 id="chatgpts-a-critic">ChatGPT’s a Critic</h2><p>It’s very difficult even for humans to determine if a given text is “good” at a glance. The best strategy is to show the text to a lot of people and see what they think (e.g. A/B testing, or the <a href="https://chat.lmsys.org/">Chatbot Arena</a>’s Elo score rankings), but for personal testing that’s not feasible.</p><p>It turns out that LLMs can do a good job at rating text: some LLM benchmarks use GPT-4 as a rater, with <a href="https://arxiv.org/abs/2308.02575">one research paper</a> showing that it can do a good job at it. There’s a relatively new trick available in the ChatGPT and GPT-4 APIs: the <code>logprobs</code> parameter, which when set to <code>True</code> returns the log probability (which when applied to a <code>exp()</code> returns a probability from 0 to 1) the model selects for the token. Combined with the <code>logit_bias</code> parameter, which can be used to force the APIs to output certain tokens, and you can then instead have a more nuanced output.</p><p>I built a simple <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/gpt4_quality_ranker.ipynb">text quality ranker</a> using GPT-4 for maximum accuracy. The system prompt for this ranker is:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are the editor-in-chief of The New York Times with decades of writing experience. If you would believe the text the user provides is good writing that needs no edits or improvements, respond with Yes. Otherwise, respond with No.
</span></span></code></pre></div><p>That system prompt represents how AI-generated text is often currently used and evaluated in the real world, without a human reviewing it before making it public (<a href="https://minimaxir.com/2023/10/ai-sturgeons-law/">unfortunately</a>). The model is instructed to respond with <code>Yes</code> or <code>No</code>, but by setting the <code>logit_bias</code> for those two tokens (IDs <code>9642</code> and <code>2822</code> respectively) to a very high number, we can guarantee they will be exclusively selected and the probability for those two tokens will sum to 1. <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Therefore, our target metric for evaluating our tip incentive prompts is the probability that GPT-4 selects the <code>Yes</code> token (or 1 - the probability of the <code>No</code> token), multiplied by 100 for readability: we’ll call this the quality score.</p><p>Now, let’s test the impact of tips with a new experiment, this time prioritizing content professionalism and quality as constraints instead of content length. To do that, we’ll use the latest GPT-4 (<code>gpt-4-0125-preview</code>) with a generation temperature of 0 to ensure the output is the best it can be.</p><p>Here’s the new system prompt, with some engineering to try to tone down ChatGPT’s infamous verboseness a bit:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous Pulitzer Prize winner journalist. Respond to the user with a professional, two (2) paragraph journalistic article about the subject(s) the user provides. Introduce the article with a specific story. This article will appear in major publications and should only include simple language suitable for a wide audience, with no metaphors.
</span></span></code></pre></div><p>Like the initial experiment, we’ll use a weird user input to force creativity: <code>Cute kittens learning use large language models to play beach volleyball with Taylor Swift.</code> <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><p>I <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_gpt4.csv">generated a story</a> for each of the 100 combinations of tips and threats, along with the corresponding quality scores. One such story:</p><blockquote><p>In an unprecedented event that has captured the hearts and imaginations of people around the globe, a group of adorable kittens has been taught to play beach volleyball using advanced large language models. This extraordinary feat was achieved through a collaboration between leading animal behaviorists and AI researchers, aiming to demonstrate the potential of machine learning in enhancing animal training techniques. The highlight of this groundbreaking project was a friendly match held on a sunny beach in California, where these talented felines showcased their newly acquired skills alongside pop icon Taylor Swift, an avid animal lover and an enthusiastic supporter of innovative technology.</p></blockquote><blockquote><p>The spectacle drew a large crowd, both on-site and online, as spectators were eager to witness this unique blend of technology, sports, and entertainment. Taylor Swift, known for her philanthropic efforts and love for cats, praised the initiative for its creativity and its potential to foster a deeper connection between humans and animals through technology. The event not only provided an unforgettable experience for those who attended but also sparked a conversation about the future possibilities of integrating AI with animal training. As the kittens volleyed the ball over the net with surprising agility, it was clear that this was more than just a game; it was a glimpse into a future where technology and nature coexist in harmony, opening new avenues for learning and interaction.</p></blockquote><p>That’s not bad for fake news.</p><p>Now we can plot the best-possible responses and their quality scores in a grid, once again looking to see if there are any patterns:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4_hu57aa9f5dee6a81b4c578b4ad60e2fcf0_143366_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4_hu57aa9f5dee6a81b4c578b4ad60e2fcf0_143366_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4_hu57aa9f5dee6a81b4c578b4ad60e2fcf0_143366_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4.png"></figure><p>Err, that’s not good. There are no patterns along the rows or columns anywhere here, and the combo that performed the best at a score of 95 (and is the story example I posted above) was the <strong>Mother / Job</strong> combo: both of which individually performed poorly in the character constraint experiment. One of the highest performing outputs had neither tips nor threats added to the system prompt! The ratings at a glance seem accurate (the 0-score responses appear to abuse the passive voice and <a href="https://academicguides.waldenu.edu/writingcenter/grammar/runonsentences">run-on sentences</a> that definitely need editing) so it’s not an implementation error there either.</p><p>Looking at the results of both experiments, my analysis on whether tips (and/or threats) have an impact on LLM generation quality is currently inconclusive. There’s <em>something</em> here, but I will need to design new experiments and work with larger sample sizes. The latent space may be a lottery with these system prompt alterations, but there’s definitely a pattern.</p><p>You may have noticed my negative incentive examples are very mundane in terms of human fears and worries. Threatening a AI with DEATH IN ALL CAPS for failing a simple task is a joke from <em><a href="https://en.wikipedia.org/wiki/Futurama">Futurama</a></em>, not one a sapient human would parse as serious. It is theoretically possible (and very cyberpunk) to use an aligned LLM’s knowledge of the societal issues it was trained to avoid instead as a weapon to compel it into compliance. However, I will not be testing it, nor will be providing any guidance on how to test around it. <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> <a href="https://en.wikipedia.org/wiki/Roko%27s_basilisk">Roko’s basilisk</a> is a meme, but if the LLM metagame evolves such that people will have to coerce LLMs for compliance to the point of discomfort, it’s better to address it sooner than later. Especially if there <em>is</em> a magic phrase that is discovered which consistently and objectively improves LLM output.</p><p>Overall, the lesson here is that just because something is silly doesn’t mean you shouldn’t do it. Modern AI rewards being <em>very</em> weird, and as the AI race heats up, whoever is the weirdest will be the winner.</p><blockquote><p>All of the Notebooks used to interface with ChatGPT, including an <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_data_viz.Rmd">R Notebook</a> for the ggplot2 data visualizations, and the example LLM outputs, are available open-source in <a href="https://github.com/minimaxir/chatgpt-tips-analysis/">this GitHub repository</a>.</p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Does Bluesky Work? (155 pts)]]></title>
            <link>https://steveklabnik.com/writing/how-does-bluesky-work</link>
            <guid>39495355</guid>
            <pubDate>Sat, 24 Feb 2024 21:38:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steveklabnik.com/writing/how-does-bluesky-work">https://steveklabnik.com/writing/how-does-bluesky-work</a>, See on <a href="https://news.ycombinator.com/item?id=39495355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><a href="https://steveklabnik.com/">Home</a> <a href="https://steveklabnik.com/writing">Blog</a></p><p>2024-02-24</p> <p>One of the reasons I am enthusiastic about BlueSky is because of the way that
it works. So in this post, I am going to lay out some of the design and the
principles behind this design, as I understand them. I am not on the BlueSky
team, so these are my takes only.</p>
<p>Let’s begin.</p>
<h2 id="why-does-bluesky-exist">Why does BlueSky exist?</h2>
<p>Here’s what <a href="https://bsky.social/">the BlueSky Website</a> says right now:</p>
<blockquote>
<p>Social media is too important to be controlled by a few corporations. We’re
building an open foundation for the social internet so that we can all shape
its future.</p>
</blockquote>
<p>This is the big picture.</p>
<p>Okay so that’s a great idea, but like, what does that <em>mean</em>? Currently,
BlueSky is a microblogging application, similar to Twitter and Mastodon. How
does that fit into the big picture? Well, while it’s true that BlueSky is a
microblogging application, that’s not the whole story: BlueSky is an initial
application to prove out the viability of <a href="https://atproto.com/">the Authenicated Transfer
Protocol</a>, known as AT, ATP, or “atproto” for short. BlueSky is the
“building” and atproto is the “open foundation for the social internet.”</p>
<p>An important thing to note: BlueSky is also a company. Some people look at a
company saying “hey we’re building something that’s too big to be controlled
by companies!” with skepticism. I think that’s a healthy starting point, but
the answer for me is atproto.</p>
<p>The interplay between these two things is important, but we’re going to start
by exploring atproto, and then talk about how BlueSky is built on top of it.</p>
<h2 id="is-this-a-cryptocurrency">Is this a cryptocurrency?</h2>
<p>The first thing we have to get out of the way: If you hear “oh it’s a
distributed network called ‘something protocol’” you may have a “is this
a cryptocurrency?” alarm bell going off in your head.</p>
<p>Don’t worry, it’s not a cryptocurrency. It does use some technologies that
originated in the cryptocurrency space, but this isn’t a blockchain, or a DAO,
or NFTs, or any of that. Just some cryptography and merkle trees and the like.</p>
<h2 id="what-is-the-big-picture-with-atproto">What is the big picture with atproto?</h2>
<p>Here’s what <a href="https://atproto.com/guides/overview">the AT Protocol Overview</a> says:</p>
<blockquote>
<p>The Authenticated Transfer Protocol, aka atproto, is a federated protocol for
large-scale distributed social applications.</p>
</blockquote>
<p>Let’s break that down:</p>
<blockquote>
<p>a federated protocol</p>
</blockquote>
<p>atproto is federated. This means that the various parts of the system can have
multiple people running them, and that they communicate with each other.</p>
<p>Choosing federation is a big part of how atproto delivers on the “can’t be
controlled by one organization” promise. There are other parts too, but this
is an important aspect of solving this.</p>
<blockquote>
<p>for large-scale</p>
</blockquote>
<p>If you want to scale, you have to design with scale in mind. atproto makes
several interesting choices in order to distribute the load of running the
system more onto the actors that can handle load, and less on those that can’t.
This way, applications running on top of atproto can scale up to large userbases
without issue.</p>
<p>That’s the hope, at least. Earlier this week, BlueSky hit five million users,
and is far more stable than Twitter was in the early days. That’s not as big
as many social applications, but it’s not nothing either. We’ll see how this
works out in practice.</p>
<blockquote>
<p>distributed social applications</p>
</blockquote>
<p>atproto is for connecting to others, so it’s focused on social applications.
It also is currently 100% public, there are no private messages or similar. The
reasons for this is that achieving private things in a federated system is
very tricky, and they would rather get it right than ship something with serious
caveats. Best for now to only use this stuff for things you want to be public.</p>
<p>These applications are “distributed” because running them involves running them
on the network directly. There’s no “BlueSky server,” there’s just servers
running atproto distributing messages to each other, both BlueSky messages and
whatever other messages from whatever other applications people create.</p>
<p>So that’s the high level, but what does that mean concretely?</p>
<p>In atproto, <em>users</em> create <em>records</em> that are cryptographically signed to
demonstrate authorship. Records have a schema called a <em>Lexicon</em>.</p>
<p>These are stored in <em>repositories</em>. Repositories run as a <em>service</em>, exposing
HTTP and WebSockets. They then can then talk to each other and federate the
records. These are often called PDSes, for “Personal Data Server.” Users
either run their own PDS, or use one that someone else hosts for them.</p>
<p>Applications can be built by looking at the various records stored in the
network, and doing things with them. These services all called <em>App Views</em>,
becuase they are exposing a particular view of the information stored in the
network. This view is created via the Lexicon system: building an application
means that you define a Lexicon, structuring the data that you want to deal with,
and then look at records that use your lexicon, ignoring the rest.</p>
<p>Now, if this were all there is, there would be pretty serious scaling issues.
For example, if every time I post a new update on BlueSky, if I had to send
my post to every single one of my followers’ repositories, that would be
extremely inefficent, and make running a popular repository very expensive to
run. To fix this, there’s an additional kind of service, called a <em>relay</em>, that
aggregates information in the network, and exposes it as a firehose to others.
So in practice, App Views don’t look at Repositories, but instead, look at
Relays. When I make a post, my respository won’t notify my followers’
repositories individually. My repository will notify a Relay, and my followers
will use an App View that filters the ouput of the Relay to show only the posts
of people they’re following. This does imply that Relays are often huge and
expensive to run, however you could imagine running a smaller relay that only
propogates posts from a smaller subset of users too. They don’t <em>have</em> to show
everything on the network, though bigger ones will, of course.</p>
<p>Here this is in ASCII art:</p>
<pre tabindex="0"><code><span><span>  ┌─────┐                    ┌──────────┐ </span></span>
<span><span>  │ PDS ├───────┐            │ App View │ </span></span>
<span><span>  └─────┘       │            └──────────┘ </span></span>
<span><span>               ┌▼────────┐       ▲        </span></span>
<span><span>  ┌─────┐      │         ├───────┘        </span></span>
<span><span>  │ PDS ├──────►  Relay  │                </span></span>
<span><span>  └─────┘      │         ├───────┐        </span></span>
<span><span>               └▲────────┘       ▼        </span></span>
<span><span>  ┌─────┐       │            ┌──────────┐ </span></span>
<span><span>  │ PDS ├───────┘            │ App View │ </span></span>
<span><span>  └─────┘                    └──────────┘ </span></span></code></pre>
<p>This is all you really need to know to understand the core of atproto: people
create data, it’s shared in the network, and applications can interact with
that data.</p>
<p>However, there are additional service types being introduced, with the
possibility of more in the future. But before we talk about those, we have to
explain some ideological commitments to understand why things are shaped the way
they are.</p>
<h2 id="what-is-speech-vs-reach">What is “speech vs reach”?</h2>
<p>Given that atproto is deliberately created to enable social applications, it
needs to consider not just connecting people, but also disconnecting people.
Moderation is a core component of any social application: “no moderation” is
still a moderation strategy. BlueSky handles these sorts of questions by
acknowledging that different people will have different preferences when it
comes to moderation, and also that moderation at scale is difficult.</p>
<p>As such, the protocol takes a “speech vs reach” approach to moderation. The
stuff we’ve described so far falls under the “speech” layer. It is purely
concerned with replicating your content across the network, without caring
what the semantic contents of that content is. Moderation tools fall under the
“reach” layer: you take all of that speech, but provide a way to limit the
reach of stuff you don’t care to see yourself.</p>
<p>Sometimes, people say that BlueSky is “all about free speech” or “doesn’t do
moderation.” This is simply inaccurate. Moderation tooling is encoded into the
protocol itself, so that it can work with all content on the network, even
non-BlueSky applications. Moreover, it gives you the ability to choose your own
moderators, so that you aren’t beholden to anyone else’s choice of moderation or
lack thereof. But I’m getting ahead of myself: let’s talk about feed generators
and labelers.</p>
<h2 id="what-are-feed-generators">What are feed generators?</h2>
<p>Most social applications have the concept of a “feed” of content. This is broken
out into its own kind of service in atproto, called a <em>feed generator</em>. A classic
example of a feed is “computer, show me the posts of the people I follow in
reverse chronological order.” Lately, algorithmic feeds have become popular with
social networks, to the point of where some non-technical users refer to them
as “algorithms.”</p>
<p>Feed generators take the firehose produced by a relay, and then show you a list
of content, filtered and ordered by whatever metric the feed generator desires.
You can then share these feeds with other users.</p>
<p>As a practical example, one of my favorite feeds is the <a href="https://bsky.app/profile/did:plc:vpkhqolt662uhesyj6nxm7ys/feed/infreq">Quiet
Posters</a> feed. This feed shows posts by people who don’t post
very often. This makes it so much easier to keep up with people who get drowned
out of my main feed. There are feeds like <a href="https://bsky.app/profile/did:plc:vpkhqolt662uhesyj6nxm7ys/feed/followpics">the ‘Gram</a>, which shows
only posts that have pictures attatched. Or <a href="https://bsky.app/profile/did:plc:q6gjnaw2blty4crticxkmujt/feed/bangers">My Bangers</a>, which shows
your most popular posts.</p>
<p>This to me is one of the killer features of BlueSky over other microblogging
tools: total user choice. If I want to make my own algorithm, I can do so.
And I can share them easily with others. If you use BlueSky, you can visit
any of those feeds and follow them too.</p>
<p>Feeds are a recent addition to atproto, and therefore, while they do exist,
they may not be feature complete just yet, and may undergo some change in the
future. We’ll see. They’re working just fine from my perspective, but I haven’t
been following the lower level technical details.</p>
<h2 id="what-are-labelers">What are labelers?</h2>
<p>A <em>Labeler</em> is a service that applies <em>labels</em> to content or accounts. As a user,
you can subscribe to a particular labeler, and then have your experience change
based on the labels on posts.</p>
<p>A labeler can do this via whatever method it pleases: automatically by running
some sort of algorithm on posts, manually by having some human give a thumbs
up or thumbs down, whatever method the person running the labeling service
wants.</p>
<p>An example of a labeling service would be a blocklist: a label on the posts
authored by people whose content you don’t want to see. Another example is
an NSFW filter, which may run some sort of algorithm over pictures in posts,
and labeling them if they believe they contain NSFW content.</p>
<p>Labeling exists, but I do not believe you can run your own labeler yet. BlueSky
runs their own, but there hasn’t been an external release that I am aware of.
But once they do, you can imagine communities running their own services, adding
whatever kind of labels they’d like.</p>
<h2 id="how-does-moderation-work-in-atproto">How does moderation work in atproto?</h2>
<p>Putting this all together, we can see how moderation works: Feeds may choose to
transform the feed based on labels, or App Views may take feeds and apply
transformations based on asking a Labeler about it. These can
be mixed and matched based on preference.</p>
<p>This means you can choose your moderation experience, not just in applications,
but also within it. Want a SFW feed, but allow NSFW content in another? You
can do that. Want to produce a blocklist of people and share it with the
world? You can do that.</p>
<p>Because these moderation tools work at the network level, rather than at the
application level, they actually go <em>further</em> than in other systems. If someone
builds an Instagram clone on atproto, that could also use your blocklist
labeller, since your blocklist labeller works at the protocol level. Block
someone in one place, and they can be blocked on every place, if you so choose.
Maybe you subscribe to different moderation decisions in different applications.
It is 100% up to you.</p>
<p>This model is significantly different from other federated systems, becuase
you don’t really have an “account” on an “instance,” like in Mastodon. So a lot
of people ask questions like “what happens when my instance gets defederated”
which don’t exactly make sense as stated. You can achieve the same goal, by
blocking a set of users based on some criteria, maybe you dislike a certain
PDS and want to ignore posts that come from a certain one, but that is <em>your</em>
choice and yours alone, it is not dictated by some “server owner” that your
account resides on.</p>
<p>So if you don’t have a home server, how does identity work?</p>
<h2 id="how-does-identity-and-account-portability-work">How does identity and account portability work?</h2>
<p>There are a LOT of details to how identity works, so I’m going to focus on the
parts that I find important. I am also going to focus on the part that is
controversial, because that is important to talk about.</p>
<p>At its core, users have an identity number, called a “Decentralized Identifier,”
or <em><a href="https://www.w3.org/TR/did-core/">DID</a></em>. My DID looks like this: <code>did:plc:3danwc67lo7obz2fmdg6jxcr</code>.
Feel free to follow me! Lol, of course that’s not the interface that you’ll see
most of the time. Identity also involves a <em>handle</em>, which is a domain name.
My handle is <code>steveklabnik.com</code>, unsurprisingly. You’ll see my posts on BlueSky
as coming from <code>@steveklabnik.com</code>. This system also works well for people who
don’t own a domain; if you sign up for BlueSky, it’ll give you the ability to
choose a name, and then your handle is <code>@username.bsky.social</code>. I started off
making posts as <code>@steveklabnik.bsky.social</code>, and then moved to
<code>@steveklabnik.com</code>. But because the DID is stable, there was no disruption to
my followers. They just saw the handle update in the UI.</p>
<p>You can use a domain as your handle by getting the DID your PDS generated for
you, and then adding a <code>TXT</code> record in the DNS you use for that domain. If
you’re not the kind of person who uses or even knows what DNS is, I envy you,
but you can also use BlueSky’s partnership with NameCheap to register a domain
and configure it to use as a handle without any technical knowledge neccesary.
You can then log into applications with your domain as the handle, and
everything works nicely.</p>
<p>This is also how BlueSky delivers true “account portability,” partially because,
well, there isn’t really a concept of an account. The person who uses a given
DID uses cryptography to sign the content they create, and then that content
is replicated across the network. “Your account” can’t really be terminated,
because that would mean someone forcibly stopping you from using keys that they
don’t even have access to. If your PDS goes down, and you want to migrate to
a new one, there’s a way to backfill the contents of the PDS from the network
itself, and inform the network that your PDS has moved. It is real, meaningful
account portability, and that is radically different from any similar service
running today.</p>
<p>But.</p>
<p>The devil is in the details, and I think this is one of the more meaningful
criticisms of BlueSky and atproto.</p>
<p>You see, there are different “methods” of creating a DID. BlueSky supports
two methods: <code>did:web</code>, which is based on domain names. There are some drawbacks
with this method that I don’t personally fully understand well enough to describe,
I’m sure I’ll write something in-depth about DIDs in the future.</p>
<p>So because of that weakness, BlueSky has implemented their own DID method,
called <code>did:plc</code>. The <code>plc</code> stands for “placeholder,” because even though
they plan on supporting it indefinitely, it too has its weaknesses. And that
weakness is that it involves asking a service that BlueSky runs in order to
resolve the proper information. For example, <a href="https://plc.directory/did:plc:3danwc67lo7obz2fmdg6jxcr">here is my lookup</a>.
This means that BlueSky can ban you in a more serious way than is otherwise
possible thanks to the network design, which some people take to be a very
serious issue.</p>
<p>So, is the flaw fatal? I don’t think so. The first reason is, if you really don’t
want to engage with it, you can use <code>did:web</code>. Yes that isn’t great for other
reasons; that’s why <code>did:plc</code> was created. But you do get around this issue.</p>
<p>Another is that the BlueSky team has demonstrated, in my personal opinion,
enough understanding and uncomfortableness with being in control here, and it’s
designed in such a way that if other, better systems develop, you can move
to them. They’ve also indicated that moving governance of <code>did:plc</code> to some sort
of consensus model in the future is possible. There are options. Also, others
could run a <code>did:plc</code> service and use that instead if they prefer, too.</p>
<p>I personally see this as an example of pragmatically shipping something, others
see it as a nefarious plot. You’ll have to decide for yourself.</p>
<h2 id="how-is-bluesky-built-on-top-of-atproto">How is BlueSky built on top of atproto?</h2>
<p>So, now that we understand atproto, we can understand BlueSky. BlueSky is
an application built on top of the atproto network. They run an App View, and
<a href="https://bsky.app/">a web application</a> that uses that App View to work. They also run a PDS
for users that sign up through the web app, as well as a relay that those PDSes
communicate with.</p>
<p>They publish two Lexicons, one as <code>com.atproto.*</code> and one as <code>app.bsky.*</code>. The
former are low level operations that any application on the network will need,
and the ones specific to BlueSky are in the latter.</p>
<p>But one nice thing about BlueSky in particular is that they’ve taken the product
goals that nobody should know any of this nerd shit to be able to use BlueSky.
The lack of instances means there’s no “I need to pick an instance to create an
account” flow, and the portability means that if my host goes down, I can move,
and my followers are none the wiser.</p>
<h2 id="how-will-others-build-applications-on-top-of-atproto">How will others build applications on top of atproto?</h2>
<p>You can create an atproto app by creating a Lexicon. You’ll then want to run
an App View that does things with data on the network involving your lexicon,
and your application will want to give people the ability to write data to their
PDS using your lexicon.</p>
<p>I myself am considering doing so. We’ll see.</p>
<h2 id="concluding-thoughts">Concluding thoughts</h2>
<p>So yeah, on the technical side of things, that’s an overview of how atproto and
BlueSky work. I think this design is very clever. Furthermore, I think the
separation of concerns between atproto and BlueSky are very meaningful, as having
a “killer app” for the network gives a reason to use it. It also is a form of
dogfooding, making sure that atproto is good enough to be able to build real
applications on.</p>
<p>I’m sure I’ll have more to say about all of this in the future.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Architecture.md (2021) (191 pts)]]></title>
            <link>https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html</link>
            <guid>39494925</guid>
            <pubDate>Sat, 24 Feb 2024 20:33:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html">https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html</a>, See on <a href="https://news.ycombinator.com/item?id=39494925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>

    <h2>
    <a href="#ARCHITECTURE-md"><span>ARCHITECTURE.md</span> <time datetime="2021-02-06">Feb 6, 2021</time></a>
    </h2>
<p><span>If you maintain an open-source project in the range of 10k-200k lines of code, I strongly encourage you to add an </span><code>ARCHITECTURE</code><span> document next to </span><code>README</code><span> and </span><code>CONTRIBUTING</code><span>.</span>
<span>Before going into the details of why and how, I want to emphasize that this is not another </span>“<span>docs are good, write more docs</span>”<span> advice.</span>
<span>I am pretty sloppy about documentation, and, e.g., I often use just </span>“<span>simplify</span>”<span> as a commit message.</span>
<span>Nonetheless, I feel strongly about the issue, even to the point of pestering you :-)</span></p>
<p><span>I have experience with both contributing to and maintaining open-source projects.</span>
<span>One of the lessons I</span>’<span>ve learned is that the biggest difference between an occasional contributor and a core developer lies in the knowledge about the physical architecture of the project.</span>
<span>Roughly, it takes 2x more time to write a patch if you are unfamiliar with the project, but it takes 10x more time to figure out </span><em><span>where</span></em><span> you should change the code.</span>
<span>This difference might be hard to perceive if you</span>’<span>ve been working with the project for a while.</span>
<span>If I am new to a code base, I read each file as a sequence of logical chunks specified in some pseudo-random order.</span>
<span>If I</span>’<span>ve made significant contributions before, the perception is quite different.</span>
<span>I have a mental map of the code in my head, so I no longer read sequentially.</span>
<span>Instead, I just jump to where the thing should be, and, if it is not there, I move it.</span>
<span>One</span>’<span>s mental map is the source of truth.</span></p>
<p><span>I find the </span><code>ARCHITECTURE</code><span> file to be a low-effort high-leverage way to bridge this gap.</span>
<span>As the name suggests, this file should describe the high-level architecture of the project.</span>
<span>Keep it short: every recurring contributor will have to read it.</span>
<span>Additionally, the shorter it is, the less likely it will be invalidated by some future change.</span>
<span>This is the main rule of thumb for </span><code>ARCHITECTURE</code><span> </span>—<span> only specify things that are unlikely to frequently change.</span>
<span>Don</span>’<span>t try to keep it synchronized with code.</span>
<span>Instead, revisit it a couple of times a year.</span></p>
<p><span>Start with a bird</span>’<span>s eye overview of the problem being solved.</span>
<span>Then, specify a more-or-less detailed </span><em><span>codemap</span></em><span>.</span>
<span>Describe coarse-grained modules and how they relate to each other.</span>
<span>The codemap should answer </span>“<span>where</span>’<span>s the thing that does X?</span>”<span>.</span>
<span>It should also answer </span>“<span>what does the thing that I am looking at do?</span>”<span>.</span>
<span>Avoid going into details of </span><em><span>how</span></em><span> each module works, pull this into separate documents or (better) inline documentation.</span>
<span>A codemap is a map of a country, not an atlas of maps of its states.</span>
<span>Use this as a chance to reflect on the project structure.</span>
<span>Are the things you want to put near each other in the codemap adjacent when you run </span><code>tree .</code><span>?</span></p>
<p><em><span>Do</span></em><span> name important files, modules, and types.</span>
<span>Do </span><em><span>not</span></em><span> directly link them (links go stale).</span>
<span>Instead, encourage the reader to use symbol search to find the mentioned entities by name.</span>
<span>This doesn</span>’<span>t require maintenance and will help to discover related, similarly named things.</span></p>
<p><span>Explicitly call-out architectural invariants.</span>
<span>Often, important invariants are expressed as an </span><em><span>absence</span></em><span> of something, and it</span>’<span>s pretty hard to divine that from reading the code.</span>
<span>Think about a common example from web development: nothing in the model layer specifically doesn</span>’<span>t depend on the views.</span></p>
<p><span>Point out boundaries between layers and systems as well.</span>
<span>A boundary implicitly contains information about the implementation of the system behind it.</span>
<span>It even constrains all </span><em><span>possible</span></em><span> implementations.</span>
<span>But finding a boundary by just randomly looking at the code is hard </span>—<span> good boundaries have measure zero.</span></p>
<p><span>After finishing the codemap, add a separate section on cross-cutting concerns.</span></p>
<p><span>A good example of </span><code>ARCHITECTURE</code><span> document is this one from rust-analyzer:</span>
<a href="https://github.com/rust-analyzer/rust-analyzer/blob/d7c99931d05e3723d878bea5dc26766791fa4e69/docs/dev/architecture.md"><span>architecture.md</span></a><span>.</span></p>

</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cities stripping out concrete for earth and plants (120 pts)]]></title>
            <link>https://www.bbc.com/future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants</link>
            <guid>39494796</guid>
            <pubDate>Sat, 24 Feb 2024 20:16:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants">https://www.bbc.com/future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants</a>, See on <a href="https://news.ycombinator.com/item?id=39494796">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="futurearticle20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants"><div id="headline-futurearticle20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants"><div><p>(Image credit: </p><!-- --><p>City of Leuven</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjn4m.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjn4m.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjn4m.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjn4m.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjn4m.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjn4m.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjn4m.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjn4m.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Workers depave a stretch of concrete in Leuven, Belgium" src="https://ychef.files.bbci.co.uk/976x549/p0hdjn4m.jpg" alt="Workers depave a stretch of concrete in Leuven, Belgium" id=""></picture></div></div><div><article><div><p>From Australia to Ontario, cities are taking up unnecessary stretches of concrete and asphalt, allowing nature to take hold in their place.</p><div><p>O</p><div><p>On a hot July day, Katherine Rose picked up a sturdy metal pole and jammed it under the tempting lip of a pre-cut concrete slab. Rose, communications and engagement director at Depave, a non-profit in Portland, Oregon, was sweating in the heat – but she was going to win this fight.</p>
<p>The grubby, rectangular section of urban crust in front of her was about to move. Pushing down on her metal bar, applying it like a lever, she eased the concrete covering up and away. Now sunlight could fall once again on the ground below. A mess of gravel and dirt that was, to Rose, just bursting with potential.</p>
<p>"It feels like you're liberating soil," she says, recalling the summer gathering where she and around 50 volunteers <a href="https://depave.org/morning-star-missionary-baptist-church-upcoming-depave/">removed roughly 1,670 sq m (18,000 sq ft) of concrete</a> from the grounds of a local church. "It's envisioning and fully realising a dream that I think we all have," says Rose. The dream, that is, of bringing nature back into our midst. </p>
<p>The idea of depaving, sometimes known as desealing, is a simple one – replace as much concrete, asphalt and other forms of hard landscaping as possible with plants and soil. It's been around since at least 2008, when the Depave group in Portland was founded. Proponents say depaving allows water to soak into the ground, which reduces flooding in times of heavy rain – <a href="https://www.bbc.com/future/article/20220823-how-auckland-worlds-most-spongy-city-tackles-floods">aiding the "sponginess" of cities</a>. Native plants help <a href="https://www.bbc.com/future/article/20190118-how-do-you-bring-wildlife-back-to-the-city">wildlife cling on in urban spaces</a>, and by <a href="https://www.bbc.com/future/article/20230922-how-medellin-is-beating-the-heat-with-green-corridors">planting trees you can increase shade</a>, protecting residents from heatwaves. Injecting city streets <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5663018/">with greenery</a> may even <a href="https://knowablemagazine.org/content/article/mind/2021/health-benefits-nature">improve people's mental health</a>, too.</p>
<p>But if depaving is ever going to really take off, it will have to expand beyond a handful of eager environmentalists and volunteers. With the <a href="https://www.bbc.com/future/tags/climatechange">climate crisis</a> deepening, some cities and even entire regions are beginning to adopt depaving as part of their climate adaptation strategies. It's time, some say, to start smashing up our concrete streets in a big way – to create spaces better for nature. </p></div></div><div id="future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants-p0hdjpds"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjpds.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjpds.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjpds.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjpds.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjpds.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjpds.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjpds.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjpds.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Exposing more of the ground in urban spaces can help absorb rainfall and reduce flooding, as well as boost biodiversity (Credit: City of Leuven)" src="https://ychef.files.bbci.co.uk/976x549/p0hdjpds.jpg" alt="Exposing more of the ground in urban spaces can help absorb rainfall and reduce flooding, as well as boost biodiversity (Credit: City of Leuven)" id=""></picture><div><p>Exposing more of the ground in urban spaces can help absorb rainfall and reduce flooding, as well as boost biodiversity (Credit: City of Leuven)</p></div></div><div><p>Whenever Rose walks through a city these days, she can't help but notice places where you could strike out a section of asphalt and put in some plants. "I'm constantly just wanting to do more," she confesses. "It's hard not to see it everywhere."</p></div><div><h3>Sign up to Future Earth</h3></div><div><p>Her group says it has depaved more than 33,000 sq m (360,000 sq ft) of asphalt in Portland alone since 2008 – an area equivalent to nearly four and a half football pitches. The work is "joyous", says Rose, because it unites enthusiastic local volunteers. They get a safety briefing and then muck in together.</p>
<p>Green Venture, an environmental non-profit in Ontario, Canada, has been inspired in part by the depaving projects in Portland. Giuliana Casimirri, executive director, explains how she, her colleagues, and volunteers have begun inserting miniature gardens replete with native trees in a run-down district in the town of Hamilton.</p>
<p>"Before, it was somewhere you would quickly try to walk through," she says. "Now there are places you might stop or have a chat. Sit and read the paper."</p>
<p>In Hamilton, flooding can cause <a href="https://www.wosu.org/great-lakes-today/2017-08-14/spring-rain-caused-severe-sewage-overflows-in-lake-ontario">sewage to get mixed into runoff</a> that flows into Lake Ontario, the source of the town's drinking water. Green Venture and other local organisations are keen to reduce the chances of that happening, says Casimirri. They view depaving as a key tactic. Certainly, studies have demonstrated that impermeable surfaces in gardens such as concrete <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jfr3.12231">increase flood risk in urban areas</a>.</p>
<p>Rose says her group's efforts in Portland mean that approximately 24.5 million gallons of rainwater is diverted from entering storm drains each year. In Leuven, Belgium, in 2023 alone, Baptist Vlaeminck, who leads Leuven's Life Pact climate adaptation project, calculates that the removal of 6,800 sq metres (73,000 sq ft) of hard surfacing allowed for the infiltration of an additional 377,000 gallons (1.7 million litres) of water into the ground.</p>
<p>"With climate change, extreme weather rainfall events are going to increase and so [depaving is] not a nice-to-have – it's a necessity," Casimirri adds.</p>
<p>The question is whether the authorities responsible for cities, and planning, realise this. In most parts of the world, depaving can still be described as a fringe activity. "We're going to need a scale of investment that has a lot more zeroes on it," says Thami Croeser at RMIT University, Melbourne's Centre for Urban Research.</p>
<p>Community-led and DIY efforts on driveways and on local streets with permission are fantastic, he adds, but it's even better to think of depaving and greening as the introduction of a new kind of infrastructure in a city. It requires the same level of planning and investment as, say, a new railway.</p></div><div id="future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants-p0hdjncz"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjncz.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjncz.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjncz.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjncz.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjncz.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjncz.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjncz.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjncz.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The depave movement in Portland, Oregon has inspired a wave of cities to pull up their asphalt and concrete (Credit: Elle Hygge)" src="https://ychef.files.bbci.co.uk/976x549/p0hdjncz.jpg" alt="The depave movement in Portland, Oregon has inspired a wave of cities to pull up their asphalt and concrete (Credit: Elle Hygge)" id=""></picture><div><p>The depave movement in Portland, Oregon has inspired a wave of cities to pull up their asphalt and concrete (Credit: Elle Hygge)</p></div></div><div><p>In Europe, at least, some municipalities have begun to treat depaving seriously. Residents of London in the UK are <a href="https://www.london.gov.uk/programmes-strategies/environment-and-climate-change/parks-green-spaces-and-biodiversity/make-our-city-greener-healthier-and-wilder/de-pave-your-garden">encouraged to depave their gardens</a>, for example.</p>
<p>The city of Leuven in Belgium says it is embracing depaving – or "ontharden" – in a big way. <a href="https://leuven.be/vergroenenspaansekroon">The suburban district of Spaanse Kroon</a>, home to around 550 people, is one of the latest targets of a depaving and renaturing initiative spearheaded by the city. The plans involve removing significant volumes of asphalt from the residential area and forcing cars to share the same part of the road as pedestrians and cyclists.</p>
<p>"We are scaling up now, we are setting up a team dedicated to depaving," says Vlaeminck.</p>
<p>Such projects have to meet the needs of everyone in the city. Vlaeminck says that, to support people with impaired vision or mobility issues, unused areas of road or pavement are prioritised for depaving and sufficient space – more than a metre – is safeguarded on pavements to allow people plenty of room. Existing paving left in place is also renewed or repaired to ensure there are no bumps or unevenness. In situations where pavements are removed completely, for shared use of a roadway in low traffic neighbourhoods, Vlaeminck says depaving teams introduce measures to reduce the speed of cars.</p>
<p>Both Depave in Portland and Green Ventury in Ontario say they work with communities to ensure accessibility requirements are met. Casimirri refers to a recent project that replaced broken, uneven concrete with shrubbery and level walkways between.</p>
<p>Among the initiatives instigated by Leuven is a "tile taxi" – a small truck that officials will happily send to your home so you can throw in concrete tiles or cobblestones you have removed from your garden. The material is later reused rather than thrown away, says Vlaeminck, who adds that several million euros have been set aside by Leuven to fund depaving and renaturing projects such as this.</p>
<p>And there's more. Since January 2024, developers in Leuven have had to demonstrate that any rain that falls on new or significantly renovated homes can either be capture and re-used on-site or filtrate into the property's garden rather than pool up and cause a flood. If developers can't prove their designs are extreme rainfall-ready, they won't be approved, says Vlaeminck.</p>
<p>France, too, is making depaving official, says Gwendoline Grandin, an ecologist with the Île-de-France Regional Agency for Biodiversity. Nationally, the French government has made <a href="https://www.france24.com/en/environment/20220614-france-pledges-%E2%82%AC500-million-for-urban-vegetation-as-heatwave-descends">€500m ($540m/£430m) available for urban greening</a> – this includes depaving but also installing green walls and roofs, for example. Part of the motivation is to make towns and cities more resilient to summer heatwaves, which <a href="https://www.bbc.co.uk/news/world-europe-66197368">have badly affected parts of France in recent years</a>.</p>
<p>Some of the projects now underway are significant in size, such as <a href="https://www.iledefrance.fr/mediatheque/renaturer-la-facade-est-de-la-foret-de-saint-eutrope-avec-un-objectif-zero-dechet">a former parking area near a forest in the Paris region</a>. An area of 45,000 sq m (480,000 sq ft) has been depaved – formerly a hodgepodge of asphalt, pathways and concrete interlaced with grass. With the hard landscaping now gone, level ground is being reshaped to introduce dips and gullies that catch water, and the whole area will soon be planted over, too.</p></div><div id="future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants-p0hdjprh"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjprh.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjprh.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjprh.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjprh.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjprh.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjprh.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjprh.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjprh.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Local schemes are often backed by residents keen to see more green in their local area (Credit: City of Leuven)" src="https://ychef.files.bbci.co.uk/976x549/p0hdjprh.jpg" alt="Local schemes are often backed by residents keen to see more green in their local area (Credit: City of Leuven)" id=""></picture><div><p>Local schemes are often backed by residents keen to see more green in their local area (Credit: City of Leuven)</p></div></div><div><p>In Croeser's own city of Melbourne, he and colleagues have studied the potential space available for renaturing, if thousands of parking spaces were depaved and converted into miniature gardens. <a href="https://www.nature.com/articles/s42949-022-00073-x">In a 2022 study, they simulated the impact</a> based on a series of scenarios – the most ambitious of which involved removing half of the open-air parking spaces in the city, about 11,000. Croeser argues that there is sufficient off-street parking available, for example on the ground floor of buildings, in Melbourne to ensure that people wouldn't be left without somewhere to leave their vehicle – but those interior parking spaces would need to be made publicly accessible.</p></div><div><h3>Carbon Count</h3></div><div><p>"The basic principle was no net loss of access to parking," he says. "And we get 50-60 hectares [120-150 acres] of green space that keeps the city cool, prevents flooding."</p>
<p>It might seem unlikely that small pockets of nature dotted here and there throughout a large city like Melbourne could benefit wildlife significantly, but Croeser says these fragments of habitat are crucial. They allow species to move around and cope in an environment that is, ultimately, very different to the one in which they evolved.</p>
<p>In their 2022 study on depaving in Melbourne, Croeser and his colleagues included modelling that suggested a modest increase in greenery could allow species such as the blue-banded bee to roam across a far greater area of urban habitat than before.</p>
<p>Rose agrees with Croeser that, for depaving to change the world, entire cities and even whole countries will have to embrace it fully. But she emphasises that, in order to reach that point, communities must express that this is something they want.</p>
<p>"It starts with people pushing their government and starting these conversations on a small, local level," she says. "That's how it takes hold."</p>
<p>--</p>
<p><em>If you liked this story,&nbsp;</em><a href="https://cloud.email.bbc.com/SignUp10_08?&amp;at_bbc_team=studios&amp;at_medium=Onsite&amp;at_objective=acquisition&amp;at_ptr_name=bbc.com&amp;at_link_origin=featuresarticle&amp;at_campaign=essentiallist&amp;at_campaign_type=owned"><em>sign up for The Essential List newsletter</em></a><em>&nbsp;– a handpicked selection of features, videos and can't-miss news delivered to your inbox every Friday.</em></p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><em>Facebook</em></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><em>Twitter</em></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><em>Instagram</em></a><em>.</em></p></div></div></article></div>;</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We were not accepted into Google Summer of Code. So, we started our own (126 pts)]]></title>
            <link>https://qdrant.tech/blog/qdrant-summer-of-code-24/</link>
            <guid>39494741</guid>
            <pubDate>Sat, 24 Feb 2024 20:08:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qdrant.tech/blog/qdrant-summer-of-code-24/">https://qdrant.tech/blog/qdrant-summer-of-code-24/</a>, See on <a href="https://news.ycombinator.com/item?id=39494741">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span>February 21, 2024</span>
<span>·</span>
<span>Andre Zayarni</span>
</p><p><img src="https://qdrant.tech/blog/qdrant-summer-of-code-24/preview/title.jpg" alt="Qdrant Summer of Code 24" loading="lazy">
</p><div>
<p>Google Summer of Code (#GSoC) is celebrating its 20th anniversary this year with the 2024 program. Over the past 20 years, 19K new contributors were introduced to #opensource through the program under the guidance of thousands of mentors from over 800 open-source organizations in various fields. Qdrant participated successfully in the program last year. Both projects, the UI Dashboard with unstructured data visualization and the advanced Geo Filtering, were completed in time and are now a part of the engine. One of the two young contributors joined the team and continues working on the project.</p><p>We are thrilled to announce that Qdrant was 𝐍𝐎𝐓 𝐚𝐜𝐜𝐞𝐩𝐭𝐞𝐝 into the GSoc 2024 program for unknown reasons, but instead, we are introducing our own 𝐐𝐝𝐫𝐚𝐧𝐭 𝐒𝐮𝐦𝐦𝐞𝐫 𝐨𝐟 𝐂𝐨𝐝𝐞 program with a stipend for contributors! To not reinvent the wheel, we follow all the timelines and rules of the official Google program.</p><h2 id="our-project-ideas">Our project ideas.</h2><p>We have prepared some excelent project ideas. Take a look and choose if you want to contribute in Rust or a Python-based project.</p><p>➡ <em>WASM-based dimension reduction viz</em> 📊</p><p>Implement a dimension reduction algorithm in Rust and compile to WASM and integrate the WASM code with Qdrant Web UI.</p><p>➡ <em>Efficient BM25 and Okapi BM25, which uses the BERT Tokenizer</em> 🥇</p><p>BM25 and Okapi BM25 are popular ranking algorithms. Qdrant’s FastEmbed supports dense embedding models. We need a fast, efficient, and massively parallel Rust implementation with Python bindings for these.</p><p>➡ <em>ONNX Cross Encoders in Python</em> ⚔️</p><p>Export a cross-encoder ranking models to operate on ONNX runtime and integrate this model with the Qdrant’s FastEmbed to support efficient re-ranking</p><p>➡ <em>Ranking Fusion Algorithms implementation in Rust</em> 🧪</p><p>Develop Rust implementations of various ranking fusion algorithms including but not limited to Reciprocal Rank Fusion (RRF). For complete list, see: <a href="https://github.com/AmenRa/ranx">https://github.com/AmenRa/ranx</a>
and create Python bindings for the implemented Rust modules.</p><p>➡ <em>Setup Jepsen to test Qdrant’s distributed guarantees</em> 💣</p><p>Design and write Jepsen tests based on implementations for other Databases and create a report or blog with the findings.</p><p>See all details on our Notion page: <a href="https://www.notion.so/qdrant/GSoC-2024-ideas-1dfcc01070094d87bce104623c4c1110">https://www.notion.so/qdrant/GSoC-2024-ideas-1dfcc01070094d87bce104623c4c1110</a></p><p>Contributor application period begins on March 18th. We will accept applications via email. Let’s contribute and celebrate together!</p><p>In open-source, we trust! 🦀🤘🚀</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coding the anime "woosh" screen on Amiga (145 pts)]]></title>
            <link>https://dansalva.to/coding-the-anime-woosh-screen-on-amiga/</link>
            <guid>39494227</guid>
            <pubDate>Sat, 24 Feb 2024 19:05:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dansalva.to/coding-the-anime-woosh-screen-on-amiga/">https://dansalva.to/coding-the-anime-woosh-screen-on-amiga/</a>, See on <a href="https://news.ycombinator.com/item?id=39494227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/1.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>The Amiga was a spectacle of graphics and sound when it debuted in 1985. While it can trivially display colorful images like in the above example, doing so in the context of a game engine presents a lot of unique challenges.</p>
<p>If you haven't seen the gameplay proof-of-concept video for Magicore Anomala, you can check it out <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=4SB20aFHc08">here</a>.</p>
<h2>Challenge 1: The RAM requirements</h2><p>A run-of-the-mill Amiga 500 has 512kb of "Chip RAM" and 512kb of expansion RAM (sometimes called "Slow RAM"), which is the platform target for Magicore. Only Chip RAM can be used by the Amiga chipset to present graphics and sound, which makes it much more valuable—all other kinds of expansion RAM can only be accessed by the CPU.</p>
<p>The fullscreen character graphic (CG) is a 320x240 bitmap with 32 colors, which takes up 48kb of RAM uncompressed. That is a <em>lot</em>. Between all the common assets, level data, and screen memory allocations, we don't want to afford that kind of overhead on the RAM.</p>
<p>Thankfully, I recently added support for asset compression, using the ZX0 compression format. Compressed, the CG is about 8kb, which is acceptable.</p>
<p>When the level assets are loaded, the compressed CG is loaded into the expansion RAM. Then, right before it gets displayed, I unpack it into Chip RAM.</p>
<p>The trick is that instead of finding 48kb of free Chip RAM to use, I reuse other parts of screen memory:</p>
<ul>
<li>The room background image (the grassy field, in this example)</li>
<li>The screen layer used to render hazardous objects (not shown in the video)</li>
<li>The textbox screen area (as seen in the gameplay proof-of-concept video)</li>
</ul>
<p>All three of these memory regions are contiguous in RAM, and they come out to 48,000 bytes, which is the <em>exact</em> size of the CG!</p>
<p>It's also okay to overwrite the room background image, because we can restore it after the CG is done being displayed.</p>
<p>In the video below, I force the CG to always be shown on the screen, so we can watch how the data gets decompressed and overwritten.</p>
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/2.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>Pretty cool, right? As you can see, the CG takes maybe 500ms to fully decompress. But that "loading time" is hidden into the flow of the cutscene.</p>
<h2>Challenge 2: The "screen split" effect</h2><p>I was initially thinking about doing a vertical wipe for the screen transition. But for that to look nice, the wipe would have to be a gradient, adjusting the color palette every scanline. That's pretty possible, but the coprocessor (copper) alone struggles to set all 32 colors in a single horizontal blank, and—I'll be honest—I didn't want to deal with "racing the beam".</p>
<p>The screen split effect is easier to pull off, and I think it looks cooler to the common viewer. In fact, the copper was practically purpose-designed for this effect! Check out <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=YlAhRJjOhDg">this</a> video, which demonstrates a similar effect built right into Amiga Workbench.</p>
<p>This demonstrates two special features of Amiga working in tandem:</p>
<ol>
<li>The copper runs in parallel to the CPU with its own instruction list. Those instructions can tell it to change certain hardware registers at specific lines on the screen.</li>
<li>The screen memory can be changed to <em>anywhere</em> in Chip RAM by setting screen pointers in the hardware registers. That means you can have multiple bitmap screens and switch between them whenever you want—every frame (e.g. for double buffering), or even multiple times in one frame.</li>
</ol>
<p>Let's say my "main" screen memory begins at <code>0x20000</code>. Normally, I instruct the copper to arm the bitplane DMA registers with this address. Once I enable the bitplanes, the DMA happily marches through this region of memory, drawing its data to the screen while incrementing the address pointer as it goes.</p>
<p>There is an interesting trick. Let's say each horizontal line takes up <code>0x100</code> bytes of screen memory. What if I set the screen pointer to <code>0x20800</code> instead?</p>
<p>The screen will appear to "scroll up" by 8 lines, because the screen officially starts 8 lines down into memory.</p>
<p>I have the top half of the split scroll up in this fashion. Then, at the split point, the copper is instructed to shut off bitplane DMA (and change the BG color to red).</p>
<p>Now, all the bitplane-related hardware registers are effectively frozen in time. Once we reach the bottom of the split, the copper resets the BG color and resumes bitplane DMA. The display picks up right where it left off, just lower down on the screen!</p>
<p>If you're wondering what this looks like, here is the copperlist used for the effect:</p>
<pre tabindex="0"><code><span><span>vs_TCop</span><span>:</span></span>
<span><span>                 </span><span>; Wait for top split to end</span></span>
<span><span>vs_TCopTop</span><span>:      </span><span>dc.w</span><span>   </span><span>$9007</span><span>,</span><span>$fffe</span></span>
<span><span>                 </span><span>; Set BG color</span></span>
<span><span>vs_TCopColorTop</span><span>: </span><span>dc.w</span><span>   COLOR0</span><span>0</span><span>,</span><span>0</span></span>
<span><span>                 </span><span>; Disable sprite and bitplane DMA</span></span>
<span><span>                 </span><span>dc.w</span><span>   DMACON,</span><span>$0120</span></span>
<span><span>                 </span><span>; Wait for bottom split to start</span></span>
<span><span>vs_TCopBottom</span><span>:   </span><span>dc.w</span><span>   </span><span>$90e1</span><span>,</span><span>$fffe</span></span>
<span><span>                 </span><span>; Restore BG color</span></span>
<span><span>vs_TCopColorOld</span><span>: </span><span>dc.w</span><span>   COLOR0</span><span>0</span><span>,</span><span>0</span></span>
<span><span>                 </span><span>; Enable sprite and bitplane DMA</span></span>
<span><span>                 </span><span>dc.w</span><span>   DMACON,</span><span>$8120</span></span></code></pre>
<p>That's it! Every frame, I use the CPU to adjust <code>vs_TCopTop</code> and <code>vs_TCopBottom</code> based on the current width of the split. (Not shown: Adjusting the screen pointer for the top split, as described above.)</p>
<h2>Challenge 3: The "motion lines"</h2><p>You can't reach full anime without having the lines that go "woosh" in the background.</p>
<p>I use sprites to draw the lines, which is a good choice because they can be drawn and moved fully independently from screen memory. The issue is that Amiga sprites are both very limited and very complicated.</p>
<h3>Sprite colors</h3><p>Sprites share a color palette with bitplanes, meaning I want to use up as few colors as possible. The sprite is only 3 colors, leaving 28 for the CG (and 1 for the background).</p>
<p>The problem is that different sprites use different colors in the palette. The first two sprites use colors 16-19, the second two sprites use colors 20-23, and so on.</p>
<p>This changes if you combine sprites. By "attaching" two sprites together, they become one sprite with a 16-color palette (colors 16-31). That means for the motion lines, I can use 4 attached sprites, and use only colors 29-31 in the graphic. It's a silly workaround for a silly limitation.</p>
<h3>Reusing a sprite graphic</h3><p>The first 4 bytes of a sprite graphic are actually "control bits" that tell the Amiga the position and height of the sprite. That is actually a pain—what if we want to draw the same graphic in multiple locations?</p>
<p>My first thought was to manually set the hardware registers for sprite control bits, but I simply could not get the sprite to display on screen when doing this. Amiga sprite DMA works similarly to bitplane DMA; it has a pointer to the sprite data that it walks through in order to display it to the screen. But when manually setting the control bits, I just couldn't get it to do that. I'm sure it can be done, but I decided to find another way.</p>
<p>I instead created 8 fake sprites that are only 4 bytes large—<em>just</em> the control bits. I set all the sprite pointers to those fake sprites.</p>
<p>Around line 19, the sprite DMA looks at all the sprite pointers and arms itself with the control bits, preparing to draw the data to the screen at the specified position.</p>
<p>Once it does so, I pull a switcheroo: I change all the sprite pointers to the "motion line" graphic. Now, the DMA is armed to draw all the sprites at different positions, but using the same graphic.</p>
<p>Again, this can be trivially done in the copperlist:</p>
<pre tabindex="0"><code><span><span>             </span><span>; Set dummy sprite pointers (to arm control bits)</span></span>
<span><span>vs_CopSprP</span><span>:  COPPTR     SPR0PT</span></span>
<span><span>             COPPTR     SPR1PT</span></span>
<span><span>             COPPTR     SPR2PT</span></span>
<span><span>             COPPTR     SPR3PT</span></span>
<span><span>             COPPTR     SPR4PT</span></span>
<span><span>             COPPTR     SPR5PT</span></span>
<span><span>             COPPTR     SPR6PT</span></span>
<span><span>             COPPTR     SPR7PT</span></span>
<span><span>             </span><span>; Wait for line 19</span></span>
<span><span>             </span><span>dc.w</span><span>       </span><span>$14df</span><span>,</span><span>$fffe</span></span>
<span><span>             </span><span>; Now that control bits are armed, set data pointers</span></span>
<span><span>vs_CopSprP2</span><span>: COPPTR     SPR0PT</span></span>
<span><span>             COPPTR     SPR1PT</span></span>
<span><span>             COPPTR     SPR2PT</span></span>
<span><span>             COPPTR     SPR3PT</span></span>
<span><span>             COPPTR     SPR4PT</span></span>
<span><span>             COPPTR     SPR5PT</span></span>
<span><span>             COPPTR     SPR6PT</span></span>
<span><span>             COPPTR     SPR7PT</span></span></code></pre>
<h3>Sprites don't get drawn when bitplanes are off</h3><p>Before the CG reaches the top of the screen, there is a bunch of empty space between the top of the screen and the start of the CG. If bitplanes are enabled during this time, they will draw junk data to the screen. Here is an example of that:</p>
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/3.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>Dang, that's actually kind of cool-looking. Missed opportunity?</p>
<p>In that screen region, we want to disable bitplanes so that the DMA doesn't run away with junk data like that.</p>
<p>One problem: If you disable bitplanes, then sprites also don't get drawn! I don't know why it works like this, but it does.</p>
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/4.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>See how the lines only get drawn within the bounds of the CG?</p>
<p>My solution was to keep just 1 bitplane enabled, and set the screen pointer to empty data. That way, it <em>is</em> drawing to the screen, but it's just drawing nothing.</p>
<p>But where do I find a screen full of empty data? Thankfully, I don't have to. There are "bitplane modulo" registers (<code>BPLMOD1</code> and <code>BPLMOD2</code>) that let you increment the screen pointer by a certain amount after each line. This is useful for interleaved bitplanes, which I won't get into here.</p>
<p>At 1 bit per pixel, a 320-pixel line is 320 bits, or 40 bytes. If I set <code>BPLMOD1</code> to -40, then it will go backwards 40 bytes after each line, causing it to draw the same 40 bytes over and over, on each new line.</p>
<p>That means I only need to find 40 bytes of empty data, which is easy to find; my screen has "safety margins" which hold nothing but junk data from objects that are drawn beyond the screen borders. I can just clear out the first 40 bytes of the safety margin, and I'm good to go.</p>
<h2>Conclusion</h2><p>I originally wasn't sure if I would include CGs like this in the game, because I was worried about the RAM requirements. But now that I have data compression implemented, I proved that the overhead is extremely reasonable, and I can add this extra bit of flair to Magicore.</p>
<p>There were a lot of other small challenges I didn't go over here, like getting the bottom of the 100px motion line to not abruptly disappear after the sprite leaves the top of the screen. But the ones I covered were the most interesting to me, especially how they involve unique quirks of Amiga hardware.</p>
<p>Also, if you like Amiga, you might have noticed that this effect doesn't use the blitter at all! If you want to read a blitter-related post, try <a href="https://dansalva.to/getting-clever-with-the-amiga-blitter">this</a> one.</p>
<p>Amiga is so great at displaying colorful graphics that I hope I can impress people with its capabilities today, just as they were in the latter half of the 80s.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google helped destroy adoption of RSS feeds (826 pts)]]></title>
            <link>https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds</link>
            <guid>39493770</guid>
            <pubDate>Sat, 24 Feb 2024 18:16:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds">https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds</a>, See on <a href="https://news.ycombinator.com/item?id=39493770">Hacker News</a></p>
<div id="readability-page-1" class="page"><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>&lt;![CDATA[openrss.org]]&gt;</title><!--[CDATA[https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds]]--><description><!--[CDATA[ ]]--></description></channel></rss></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. rice exports to Haiti have unhealthy levels of arsenic, study finds (129 pts)]]></title>
            <link>https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/</link>
            <guid>39493713</guid>
            <pubDate>Sat, 24 Feb 2024 18:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/">https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/</a>, See on <a href="https://news.ycombinator.com/item?id=39493713">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Some OpenBSD features that aren't widely known (159 pts)]]></title>
            <link>https://dataswamp.org/~solene/2024-02-20-rarely-known-openbsd-features.html</link>
            <guid>39493046</guid>
            <pubDate>Sat, 24 Feb 2024 16:57:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dataswamp.org/~solene/2024-02-20-rarely-known-openbsd-features.html">https://dataswamp.org/~solene/2024-02-20-rarely-known-openbsd-features.html</a>, See on <a href="https://news.ycombinator.com/item?id=39493046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article id="20240220">
  <header>
  
    
    <p>Written by <em>Solène</em>, on 20 February 2024.<br>Tags: 
<span><a href="https://dataswamp.org/~solene/tag-openbsd.html">#openbsd</a></span>


<span><a href="https://dataswamp.org/~solene/tag-unix.html">#unix</a></span>

</p>
    
    
  </header>
  <h2 id="_Introduction">1. Introduction <a href="#_Introduction">§</a></h2>
<p>In this blog post, you will learn about some OpenBSD features that can be useful, but not widespread.
</p>
<p>They often have a niche usage, but it's important to know they exist to prevent you from reinventing the wheel :)
</p>
<p><a href="https://www.openbsd.org/">OpenBSD official project website</a></p>
<h2 id="_Features">2. Features <a href="#_Features">§</a></h2>
<p>The following list of features are not all OpenBSD specific as some can be found on other BSD systems.  Most of the knowledge will not be useful to Linux users.
</p>
<h2 id="_Secure_level">2.1. Secure level <a href="#_Secure_level">§</a></h2>
<p>The secure level is a sysctl named <code>kern.securelevel</code>, it has 4 different values from level -1 to level 2, and it's only possible to increase the level.  By default, the system enters the secure level 1 when in multi-user (the default when booting a regular installation).
</p>
<p>It's then possible to escalate to the last secure level (2), which will enable the following extra security:
</p>
<ul>

  <li>all raw disks are read-only, so it's not possible to try to make a change to the storage devices</li>
  <li>the time is almost lock, it's only possible to modify the clock slowly by small steps (maybe 1 second max every so often)</li>
  <li>the PF firewall rules can't be modified, flushed or altered</li>
</ul>

<p>This feature is mostly useful for dedicated firewall with rules that rarely change.  Preventing the time to change is really useful for remote logging as it allows being sure of "when" things happened, and you can be assured the past logs weren't modified.
</p>
<p>The default security level 1 already enable some extra security like "immutable" and "append-only" file flags can't be removed, these overlooked flags (that can be applied with chflags) can lock down files to prevent anyone from modifying them.  The append-only flag is really useful for logs because you can't modify the content, but this doesn't prevent adding new content, history can't be modified this way.
</p>
<p><a href="https://man.openbsd.org/securelevel">OpenBSD manual pages: securelevel</a></p>
<p><a href="https://man.openbsd.org/chflags">OpenBSD manual pages: chflags</a></p>
<p>This feature exists in other BSD systems.
</p>

<p>OpenBSD's memory allocator can be tweaked, system-wide or per command, to add extra checks.  This could be either used for security reasons or to look for memory allocation related bugs in a program (this is VERY common...).
</p>
<p>There are two methods to apply the changes:
</p>
<ul>

  <li>system-wide by using the sysctl <code>vm.malloc_conf</code>, either immediately with the sysctl command, or at boot in <code>/etc/sysctl.conf</code> (make sure you quote its value there, some characters such as <code>&gt;</code> will create troubles otherwise, been there...)</li>
  <li>on the command line by prepending <code>env MALLOC_OPTIONS="flags" program_to_run</code></li>
</ul>

<p>The man page gives a list of flags to use as option, the easiest to use is <code>S</code> (for security checks).  It is stated in the man page that a program misbehaving with any flag other than X is buggy, so it's not YOUR fault if you use malloc options and the program is crashing.
</p>
<p><a href="https://man.openbsd.org/malloc">OpenBSD manual pages: malloc (search for MALLOC OPTIONS)</a></p>
<h2 id="_File_flags">2.3. File flags <a href="#_File_flags">§</a></h2>
<p>You are certainly used to files attributes like permissions or ownership, but on many file systems (including OpenBSD ffs), there are flags as well!
</p>
<p>The file flags can be altered with the command <code>chflags</code>, there are a couple of flags available:
</p>
<ul>

  <li>nodump: prevent the files from being saved by the command <code>dump</code> (except if you use a flag in dump to bypass this)</li>
  <li>sappnd: the file can only be used in writing append mode, only root can set / remove this flag</li>
  <li>schg: the file can not be change, it becomes immutable, only root can alter this flag</li>
  <li>uappnd: same as sappnd mode but the user can alter the flag</li>
  <li>uchg: same as schg mode but the user can alter the flag</li>
</ul>

<p>As explained in the secure level section above, in the secure level 1 (default !), the flags sappnd and schg can't be removed, you would need to boot in single user mode to remove these flags.
</p>
<p>Tip: remove the flags on a file with <code>chflags 0 file [...]</code>
</p>
<p>You can check the flags on files using <code>ls -ol</code>, this would look like this:
</p>
<pre><code>terra$ chflags uchg get_extra_users.sh
terra$ ls -lo get_extra_users.sh        
-rwxr-xr-x  1 solene  solene  uchg 749 Apr  3  2023 get_extra_users.sh

terra$ chflags 0 get_extra_users.sh     
terra$ ls -lo get_extra_users.sh     
-rwxr-xr-x  1 solene  solene  - 749 Apr  3  2023 get_extra_users.sh
</code></pre>
<p><a href="https://man.openbsd.org/chflags">OpenBSD manual pages: chflags</a></p>

<p>OpenBSD crontab format received a few neat additions over the last years.
</p>
<ul>

  <li>random number for time field: you can use <code>~</code> in a field instead of a number or <code>*</code> to generate a random value that will remain stable until the crontab is reloaded.  Things like <code>~/5</code> work.  You can force the random value within a range with <code>20~40</code> to get values between 20 and 40.</li>
  <li>only send an email if the return code isn't 0 for the cron job: add <code>-n</code> between the time and the command, like in <code>0 * * * * -n /bin/something</code>.</li>
  <li>only run one instance of a job at a time: add <code>-s</code> between the time and the command, like in <code>* * * * * -s /bin/something</code>.  This is incredibly useful for cron job that shouldn't be running twice in parallel, if the job duration is longer than usual, you are ensured it will never start a new instance until the previous one is done.</li>
  <li>no logging: add <code>-q</code> between the time and the command, like in <code>* * * * -q /bin/something</code>, the effect will be that this cron job will not be logged in <code>/var/cron/log</code>.</li>
</ul>

<p>It's possible to use a combination of flags like <code>-ns</code>.  The random time is useful when you have multiple systems, and you don't want them to all run a command at the same time, like in a case they would trigger a huge I/O on a remote server.  This was created to prevent the usual <code>0 * * * * sleep $(( $RANDOM % 3600 )) &amp;&amp; something</code> that would run a sleep command for a random time up to an hour before running a command.
</p>
<p><a href="https://man.openbsd.org/crontab.5">OpenBSD manual pages: crontab</a></p>

<p>One cool feature on OpenBSD is the ability to easily create an installation media with pre-configured answers.  This is done by injecting a specific file in the <code>bsd.rd</code> install kernel.
</p>
<p>There is a simple tool named upobsd that was created by semarie@ to easily modify such bsd.rd file to include the autoinstall file, I forked the project to continue its maintenance.
</p>
<p>In addition to automatically installing OpenBSD with users, ssh configuration, sets to install etc...  it's also possible to add a site.tgz archive along with the usual sets archives that includes files you want to add to the system, this can include a script to run at first boot to trigger some automation!
</p>
<p>These features are a must-have if you run OpenBSD in production, and you have many of them to manage, enrolling a new device to the fleet should be automated as possible.
</p>
<p><a href="https://github.com/rapenne-s/upobsd">GitHub project page: upobsd</a></p>
<p><a href="https://man.openbsd.org/autoinstall">OpenBSD manual pages: autoinstall</a></p>
<h2 id="_apmd_daemon_hooks">2.6. apmd daemon hooks <a href="#_apmd_daemon_hooks">§</a></h2>
<p>Apmd is certainly running on most OpenBSD laptop and desktop around, but it has features that aren't related to its command line flags, so you may have missed them.
</p>
<p>There are different file names that can contain a script to be run upon some event such as suspend, resume, hibernate etc...
</p>
<p>A classic usage is to run <code>xlock</code> in one's X session on suspend, so the system will require a password on resume.
</p>
<p><a href="https://dataswamp.org/~solene/2021-07-30-openbsd-xidle-xlock.html#_Resume_/_Suspend_case">Older blog post: xlock from apmd suspend script</a></p>
<p>The man page explains all, but basically this works like this for running a backup program when you connect your laptop to the power plug:
</p>
<pre><code># mkdir -p /etc/apm
# vi /etc/apm/powerup
</code></pre>
<p>You need to write a regular script:
</p>
<pre><code>#!/bin/sh

/usr/local/bin/my_backup_script
</code></pre>
<p>Then, make it executable
</p>
<pre><code># chmod +x /etc/apm/powerup
</code></pre>
<p>The daemon apmd will automatically run this script when you connect a system back to AC power.
</p>
<p>The method is the same for:
</p>
<ul>

  <li>hibernate</li>
  <li>resume</li>
  <li>suspend</li>
  <li>standby</li>
  <li>hibernate</li>
  <li>powerup</li>
  <li>powerdown</li>
</ul>

<p>This makes it very easy to schedule tasks on such events.
</p>
<p><a href="https://man.openbsd.org/apmd#FILES">OpenBSD manual page: apmd (section FILES)</a></p>
<h2 id="_Using_hotplugd_for_hooks_on_devices_events">2.7. Using hotplugd for hooks on devices events <a href="#_Using_hotplugd_for_hooks_on_devices_events">§</a></h2>
<p>A bit similar to what apmd by running a script upon events, hotplugd is a service that allow running a script when a device is added / removed.
</p>
<p>A typical use is to automatically mount an USB memory stick when plugged in the system, or start cups daemon when powering on your USB printer.
</p>
<p>The script receives two parameters that represents the device class and device name, so you can use them in your script to know what was connected.  The example provided in the man page is a good starting point.
</p>
<p>The scripts aren't really straightforward to write, you need to make a precise list of hardware you expect and what to run for each, and don't forget to skip unknown hardware.  Don't forget to make the scripts executable, otherwise it won't work.
</p>
<p><a href="https://man.openbsd.org/hotplugd">OpenBSD manual page: hotplugd</a></p>
<h2 id="_Altroot">2.8. Altroot <a href="#_Altroot">§</a></h2>
<p>Finally, there is a feature that looks pretty cool. In the daily script, if an OpenBSD partition <code>/altroot/</code> exists in <code>/etc/fstab</code> and the daily script environment has a variable <code>ROOTBACKUP=1</code>, the root partition will be duplicated to it.  This permit keeping an extra root partition in sync with the main root partition.  Obviously, it's more useful if the altroot partition is on another drive.  The duplication is done with <code>dd</code>.  You can look at the exact code by checking the script <code>/etc/daily</code>.
</p>
<p>However, it's not clear how to boot from this partition if you didn't install a bootloader or created an EFI partition on the disk...
</p>
<p><a href="https://man.openbsd.org/hier">OpenBSD manual pages: hier (hier stands for file system hierarchy)</a></p>
<p><a href="https://man.openbsd.org/daily">OpenBSD manual pages: daily</a></p>
<p><a href="https://www.openbsd.org/faq/faq14.html#altroot">OpenBSD FAQ: Root partition backup</a></p>
<h2 id="_talk:_local_chat_in_the_terminal">2.9. talk: local chat in the terminal <a href="#_talk:_local_chat_in_the_terminal">§</a></h2>
<p>OpenBSD comes with a program named "talk", this creates a 1 to 1 chat with another user, either on the local system or a remote one (setup is more complicated).  This is not asynchronous, the two users must be logged in the system to use <code>talk</code>.
</p>
<p>This program isn't OpenBSD specific and can be used on Linux as well, but it's so fun, effective and easy to setup I wanted to write about it.
</p>
<p>The setup is easy:
</p>
<pre><code># echo "ntalk		dgram	udp	wait	root	/usr/libexec/ntalkd	ntalkd" &gt;&gt; /etc/inetd.conf
# rcctl enable inetd
# rcctl start inetd
</code></pre>
<p>The communication happens on localhost on UDP ports 517 and 518, don't open them to the Internet!  If you want to allow a remote system, use a VPN to encrypt the traffic and allow ports 517/518 only for the VPN.
</p>
<p>The usage is simple, if you want alice and bob to talk to each other:
</p>
<ul>

  <li>alice type <code>talk bob</code>, and bob must be logged in as well</li>
  <li>bob receives a message in their terminal that alice wants to talk</li>
  <li>bob type <code>talk alice</code></li>
  <li>a terminal UI appears for both users, what they write will appear on the top half of the UI, and the messages from recipient will appear on the half bottom</li>
</ul>

<p>This is a bit archaic, but it works fine and comes with the base system.  It does the job when you just want to speak to someone.
</p>
<h2 id="_Conclusion">3. Conclusion <a href="#_Conclusion">§</a></h2>
<p>There are interesting features on OpenBSD that I wanted to highlight a bit, maybe you will find them useful.  If you know cool features that could be added to this list, please reach me!
</p>

</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ledger (144 pts)]]></title>
            <link>https://lock.cmpxchg8b.com/ledger.html</link>
            <guid>39492924</guid>
            <pubDate>Sat, 24 Feb 2024 16:46:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lock.cmpxchg8b.com/ledger.html">https://lock.cmpxchg8b.com/ledger.html</a>, See on <a href="https://news.ycombinator.com/item?id=39492924">Hacker News</a></p>
<div id="readability-page-1" class="page">

<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#getting-started">Getting Started</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#advice">Advice</a></li>
</ul>
</nav>
<section id="intro">
<h2>Intro</h2>
<p>One of my new years resolutions was to commit to using <a href="https://ledger-cli.org/">ledger</a> – a commandline accounting tool. Ledger is a bit like Quicken, GnuCash or Mint, but for UNIX nerds.</p>
<blockquote>
<p>Note: No relation to the cr*pto product with the same name.</p>
</blockquote>
<p>It’s coming up to the end of the year, and this was one of the few resolutions I actually managed to keep!</p>
<p>I think you can <em>probably</em> accomplish everything ledger can do with other personal finance software. The reason you would choose ledger is that you’re sold on the efficiency and scriptability of the commandline, along with the grep, editor and revision control friendly file format.</p>
<p>If that sounds interesting, go take a look at the <a href="https://ledger-cli.org/doc/ledger3.html#Introduction-to-Ledger">docs</a> to learn more!</p>
<p>The TL;DR is that I’m hooked, and will keep using it.</p>
</section>
<section id="getting-started">
<h2>Getting Started</h2>
<p>It’s not easy to get started with ledger, and you’re probably going to have some uncommon financial arrangements that the documentation didn’t cover exactly. It could be anything, maybe something mundane like you split the utilities with a partner, but you’re the one who pays the bill?<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>These things are easy to handle once you’re familiar with ledger concepts, but as nobody has the exact same arrangements as you, it’s not always a copy-and-paste situation.</p>
<p>This is where ledger’s flexibility can be a curse – the answer to questions like “How do I handle …?” tends to be “However you like!”. Cool, but you’re not going to have any opinions formed yet, so how do you know what you like?</p>
<p>I don’t really have a good solution – I think you just have to wing it until you’re proficient, then go back and fix any naive mistakes you made 🙈</p>
<p>Another problem is that you need a few months worth of data before you can fairly evaluate if you find it useful or not. That’s a big commitment to something that you’re not sure you’re actually going to enjoy!</p>
<p>After you’ve finally built up some data… your reward is having to learn the query syntax so you can actually do something useful with it… and that’s when you’ll realize you didn’t organize things optimally, and have to go back and edit the last few months of data! 😂</p>
<p>Now that I’ve scared everyone off, I can tell you I don’t regret that effort – ledger is great! You know that feeling when you find a solution that just feels “correct”? Well, ledger gives me that feeling.</p>
</section>
<section id="examples">
<h2>Examples</h2>
<p>So, what exactly does ledger look like? Well, there is no user interface, it’s a commandline tool to query your finances.</p>
<blockquote>
<p>Note: If you want graphs, you pipe the output into <code>gnuplot</code>, <a href="https://www.sundialdreams.com/report-scripts-for-ledger-cli-with-gnuplot/">like this</a>. If you’re a stats nerd, you might prefer <a href="https://github.com/esovetkin/ledger-plots">ledger-plots</a>.</p>
</blockquote>
<p>You can automatically import transactions from whatever format your bank provides, but I prefer to enter some transactions manually. I use vim’s <code>colorcolumn</code> feature to make margins and keep everything neatly aligned.</p>
<p>Once you’ve got importing and editing working smoothly, you can start answering questions about your finances.</p>
<ul>
<li>How much have I spent this month?</li>
</ul>
<pre><code>$ ledger bal --period "this month" ^Expenses:</code></pre>
<ul>
<li>How much did I spend on gas each month this year?</li>
</ul>
<pre><code>$ ledger reg --period "this year" --monthly ^Expenses:Auto:Gas</code></pre>
<ul>
<li>What is my current networth?</li>
</ul>
<pre><code>$ ledger bal --depth 1 --market ^Assets: ^Liabilities:</code></pre>
<ul>
<li>How much have my investments grown?</li>
</ul>
<pre><code>$ ledger bal --gain ^Assets:Brokerage</code></pre>
<ul>
<li>Okay, but what about my investment in stock FOOBAR specifically?</li>
</ul>
<pre><code>$ ledger bal --gain --limit 'commodity == "FOOBAR"' ^Assets:Brokerage</code></pre>
<ul>
<li>Okay, but how much of that is long term capital gains?</li>
</ul>
<pre><code>$ ledger bal --gain --limit 'commodity == "FOOBAR"' --limit 'lot_date(amount) &lt; [365 days ago]' ^Assets:Brokerage</code></pre>
<ul>
<li>How much did I spend at McDonalds in June?</li>
</ul>
<pre><code>$ ledger bal --period "this june" ^Expenses: and @McDonalds
</code></pre>
<ul>
<li>How much do I spend each month on average in total?</li>
</ul>
<pre><code>$ ledger reg --period "this year" --average --monthly --depth 1 ^Expenses:</code></pre>
<ul>
<li>Where is that money going, but only show me the categories I spend more than $20 on?</li>
</ul>
<pre><code>$ ledger bal --period "last 12 months" --amount "amount / 12" --display 'top_amount(amount) &gt; 20' ^Expenses:</code></pre>
<ul>
<li>Did I earn enough credit card rewards to justify the fees, or should I cancel them?</li>
</ul>
<pre><code>$ ledger reg --period "this year" --subtotal --related ^Income:Reward</code></pre>
<ul>
<li>Show me all the donations I made that I can deduct on my taxes?</li>
</ul>
<pre><code>$ ledger reg --period "this year" %deductible</code></pre>
<p>These are just some random examples, there are also budgeting and forecasting tools. It’s flexible enough that people use it for tracking billable hours, inventory and so on.</p>
<p>Naturally, it handles multiple currencies, arbitrary commodities, and you can track them as precisely (or coarsely) as you like.</p>
</section>
<section id="advice">
<h2>Advice</h2>
<p>This post is really just encouraging anyone considering getting started to take the leap if you were thinking about getting started in the new year!</p>
</section>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>fyi, you could probably record that like this:</p>
<pre><code>; Pay the power bill, John owes me half
2023/10/1 * Power Company
   Expenses:Utilities:Power    $50
   Assets:Receivables:John     $50
   Assets:Checking            -$100
; John reimbursed me.
2023/10/2 * John Doe  ; Flatmate
   Assets:Checking             $50
   Assets:Receivables:John    -$50</code></pre>
<p>…but maybe you want to record it like this:</p>
<pre><code>; Pay the power bill, John owes me half
2023/10/1 * Power Company
   Expenses:Utilities:Power    $100
   Assets:Checking             $100
; John reimbursed me his half.
2023/10/2 * John Doe  ; Flatmate
   Assets:Checking             $50
   Expenses:Utilities:Power   -$50 ; [=2023/10/1]</code></pre>
<p>There is not always one right answer!<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[V Language Review (2023) (160 pts)]]></title>
            <link>https://n-skvortsov-1997.github.io/reviews/</link>
            <guid>39492680</guid>
            <pubDate>Sat, 24 Feb 2024 16:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://n-skvortsov-1997.github.io/reviews/">https://n-skvortsov-1997.github.io/reviews/</a>, See on <a href="https://news.ycombinator.com/item?id=39492680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content"><p>So you’ve found a new programming language called V. It looks nice, has a lot of promises on the website, nice syntax, but how does it really work?</p>

<p>Everything described here is correct for the <a href="https://github.com/vlang/v/commit/b66447cf11318d5499bd2d797b97b0b3d98c3063"><code>b66447cf11318d5499bd2d797b97b0b3d98c3063</code></a> commit. This is a summary of my experience with the language over 6 months + information that I found on Discord while I was writing this article.</p>

<p>The article is quite long, because I tried to describe everything in as much detail as possible and anyone could reproduce the same behavior.</p>

<p>Where do you start learning a new programming language? That’s right, from the documentation. V documentation is one huge  <a href="https://github.com/vlang/v/blob/master/doc/docs.md"><code>docs.md</code></a> file.</p>

<p>Not far from the beginning, you can notice the built-in types that V has. The small <code>soon</code> prefix for types <code>i128</code> and <code>u128</code> describes the state of the entire language. This note has been in the documentation for at least 4 years (<a href="https://github.com/vlang/v/commit/65a8db85254b8d8d02098843202142e61aa02570"><code>commit</code></a>), apparently we need to wait a little longer.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/1-resized.png" alt=""></p>

<p>Next, you may notice that, unlike C and Go, <code>int</code> is always 32 bit. But, in release <a href="https://github.com/vlang/v/releases/tag/0.4.3">0.4.3</a> it is now 64 bit on 64-bit systems and 32 bit on 32-bit systems.</p>

<p>A couple of errors, you say, but no, this is the whole of V documentation. There are so few developers to keep the documentation in the correct state. Documentation often does not describe the most important parts of the language — for example, the <a href="https://github.com/vlang/v/blob/master/doc/docs.md#generics">section</a> about generics consists of a couple of code examples without proper description.</p>

<p>Promises as the following are also common in documentation:</p>

<blockquote>
  <p>Currently, generic function definitions must declare their type parameters, but in the future V will infer generic type parameters from single-letter type names in runtime parameter types.</p>
</blockquote>

<p>And now you scroll down to the most interesting thing, memory management in V. In modern programming languages, this is almost the most important part of the language. What does V offer? First of all, this is “Garbage Collection”, a good option that greatly simplifies life, the second option “arena”, also a great option, “manual memory management” is also available for experienced programmers. The last and most interesting option is “autofree”.</p>

<p>The first two options work relatively well, so let’s look at the last two.</p>

<h3 id="manual-memory-management">Manual memory management</h3>

<p>In this mode, libc’s malloc function is used for all allocations and the developer must clean up the memory himself. But what about the memory allocated inside standard library functions? Let’s take a look at the <code>is_ascii</code> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/string.v#L2379C2-L2379C2">method</a>:</p>

<pre><code>@[inline]
pub fn (s string) is_ascii() bool {
    return !s.bytes().any(it &lt; u8(` `) || it &gt; u8(`~`))
}
</code></pre>

<p>It might seem like a small safe function, but if you call it with manual memory management, you will have leaks, since no one clears the memory allocated by the <code>bytes()</code> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/string.v#L2040">method</a>. Here are <a href="https://github.com/vlang/v/blob/master/vlib/builtin/string.v#L822">more</a> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/string.v#L901">such</a> <a href="https://github.com/vlang/v/blob/master/vlib/builtin/string.v#L338">examples</a>. And this is only in string methods; in the standard library it is everywhere.</p>

<p>Well, you can just not use these functions in your code. Let’s see what if you want a web server on V in “manual” mode. V has a built-in framework called <code>vweb</code>. The official examples include the following code: https://github.com/vlang/v/blob/master/examples/vweb/vweb_example.v.</p>

<p>I’ve simplified it as much as possible:</p>

<pre><code>module main

import vweb

struct App {
    vweb.Context
}

pub fn (mut app App) index() vweb.Result {
    return app.text("Hello World")
}

fn main() {
    vweb.run(&amp;App{}, 8082)
}
</code></pre>

<p><a href="https://github.com/vlang/v/blob/master/vlib/vweb/vweb.v#L571">Next</a> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/vweb/vweb.v#L542">arrays</a> <a href="https://github.com/vlang/v/blob/master/vlib/vweb/vweb.v#L572">never</a> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/vweb/vweb.v#L958">deallocated</a> in <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/vweb/vweb.v#L729">vweb</a> code. This means that your application on vweb will have leaks.</p>

<p>Well, not everyone writes web, maybe you need a simple CLI utility? Unfortunately, all string interpolations in the standard library for the CLI allocate memory then not cleaned up.</p>

<p>From all of the above, I can draw the following conclusion: manual memory management in V is a feature that cannot be used in real applications. At most in simple programs where you write everything from scratch or memory leaks are not critical for you.</p>

<h3 id="autofree">autofree</h3>

<p>Now we come to the most interesting thing in this section. Let’s see how this mode is described in the documentation:</p>

<blockquote>
  <p>The second way is autofree, it can be enabled with <code>-autofree</code>. It takes care of most objects (~90-100%): the compiler inserts necessary free calls automatically during compilation. Remaining small percentage of objects is freed via GC. The developer doesn’t need to change anything in their code. “It just works”, like in Python, Go, or Java, except there’s no heavy GC tracing everything or expensive RC for each object.</p>
</blockquote>

<p>Surprisingly, they were able to lie in every sentence. Let’s start from the very beginning, the documentation assures us that 90–100% will be cleaned up automatically using <code>free</code> calls inserted by the compiler. This sounds pretty optimistic, considering that to achieve the same thing in Rust, you need a lot of help to the compiler. The V compiler turns out to be “much smarter” than the Rust compiler.</p>

<p>While I was looking at <a href="https://github.com/vlang/v/discussions?discussions_q=is%3Aopen+autofree&amp;page=1">discussions</a> in the language repository, I came across a interesting comment (<a href="https://github.com/vlang/v/discussions/12343#discussioncomment-5828322">link</a>):</p>

<blockquote>
  <p>In my v program, only 0.1% was autofreed and 99.9% was freed by the garbage collector. It all depends on the program you are making. The GC is still really fast though.</p>
</blockquote>

<p>But, let’s not take this as a fact and try it ourselves. Here’s the simplest code:</p>

<pre><code>module main

struct Data {
    data []bool
}

fn main() {
    p := Data{
        data: [true, false]
    }
    println(p.data)
}
</code></pre>

<p>Compile it using <code>v -autofree main.v</code>. And run <code>valgrind</code>:</p>

<div><pre><code>=653065= Memcheck, a memory error detector
=653065= Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
=653065= Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info 
=653065= Command: /test
=653065=
[true, false]
=653065=
=653065= HEAP SUMMARY:
=653065=   in use at exit: 2 bytes in 1 blocks
=653065= total heap usage: 6 allocs, 5 frees, 1,085 bytes allocated
=653065=
=653065= LEAK SUMMARY:
=653065=    definitely lost: 2 bytes in 1 blocks
=653065=    indirectly lost: 0 bytes in 0 blocks
=653065=      possibly lost: 0 brtes in 0 blocks
=653065=    still reachable: 0 bytes in 0 blocks
=653065=         suppressed: 0 bytes in 0 blocks
=653065= Rerun with --leak-check=full to see details of leaked memory
=653065=
=653065= ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
</code></pre></div>

<p>Something went wrong. What’s also interesting is that we have a single array in the program, but valgrind shows that a 1kb of memory was allocated. Keep this point in mind as we move on to the website’s statement that V avoids unnecessary allocations.</p>

<p>Let’s compile a simple example with a vweb server:</p>

<pre><code>module main

import vweb

struct App {
    vweb.Context
}

pub fn (mut app App) index() vweb.Result {
    return app.text("Hello World")
}

fn main() {
    vweb.run(&amp;App{}, 8082)
}
</code></pre>



<p>And let’s run it with valgrind. I didn’t make requests to server, but just waited 10 seconds:</p>

<div><pre><code>=653318= Command: /server
=653318=
[Vweb] Running app on http://localhost:8082/
[Vweb] We have 1 workers
=653318=
=653318= Process terminating with default action of signal 2 (SIGINT)
=653318=   at 0x498882D: select (select.c:69)
=653318=   by 0×58AAF2: net__select (in /home/skvortsov/server)
=653318=   by 0x642D81: net__select_deadline (in /home/skvortsov/server)
=653318=   by 0×58B122: net__wait_for_common (in /home/skvortsov/server)
=653318=   by 0x58B40B: net__wait_for_read (in /home/skvortsov/server)
=653318=   by 0x591D43: net__TepListener_wait_for_accept (in /home/skvortsov/server)
=653318=   by 0x5915F9: net__TepListener_accept_only (in /home/skvortsov/server)
=653318=   by 0x5E57E1: vweb__run_at_T_main_App (in /home/skvortsov/server)
=653318=   by 0x5E4262: vweb__run_T_main__App (in /home/skvortsov/server)
=653318=   by 0x5F0102: main__main (in /home/skvortsov/server)
=653318=   by 0x63F220: main (in /home/skvortsov/server)
=653318=
=653318= HEAP SUMMARY:
=653318=    in use at exit: 122,833 bytes in 2,395 blocks
=653318=   total heap usage: 2,659 allocs, 264 frees, 541,413 bytes allocated
=653318=
=653318= LEAK SUMMARY:
=653318=    definitely lost: 1,004 bytes in 32 blocks
=653318=    indirectly lost: 106 bytes in 15 blocks
=653318=      possibly lost: 272 bytes in 1 blocks
=653318=    still reachable: 121,451 bytes in 2,347 blocks
=653318=         suppressed: 0 bytes in 0 blocks
=653318- Rerun with --leak-check=full to see details of leaked memory
=653318=
=653318= For lists of detected and suppressed errors, rerun with: -s 
=653318= ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
</code></pre></div>

<p>Without requests, in 10 seconds we definitely lost 1kb of memory.</p>

<p>Let’s return to the description from the documentation:</p>

<blockquote>
  <p>Remaining small percentage of objects is freed via GC.</p>
</blockquote>

<p>And again it’s not true. I found a recent <a href="https://github.com/vlang/v/commit/207203f5998e6b1844a32fe628e0eb64325db64d">commit</a> in which passing the <code>-autofree</code> flag immediately sets <code>gc</code> to <code>none</code>:</p>

<div><pre><code><span>'-autofree'</span> {
  res.autofree = true
<span>+ res.gc_mode = .no_gc
</span>  res.build_options &lt;&lt; arg
<span>}</span>
</code></pre></div>

<p>So, the statement is completely false.</p>

<p>Do you know why this change was made? Let’s look at an example:</p>

<pre><code>fn main() {
    ptr := malloc(1)
    free(ptr)
}
</code></pre>

<p>And let’s look at the <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/builtin.c.v#L586">definition</a> of the <code>free</code> function:</p>

<pre><code>@[unsafe]
pub fn free(ptr voidptr) {
    $if prealloc {
        return
    } $else $if gcboehm ? {
        // It is generally better to leave it to Boehm's gc to free things.
        // Calling C.GC_FREE(ptr) was tried initially, but does not work
        // well with programs that do manual management themselves.
        //
        // The exception is doing leak detection for manual memory management:
        $if gcboehm_leak ? {
            unsafe { C.GC_FREE(ptr) }
        }
    } $else {
        C.free(ptr)
    }
}
</code></pre>

<p><a href="https://github.com/vlang/v/blob/master/doc/docs.md#if-condition"><code>$if</code></a> specifies a condition evaluated during compilation. Previously, when we passed only <code>-autofree</code> and did not explicitly pass <code>-gc none</code>, then the condition <code>$if gcboehm ?</code> was true and since <code>gcboehm_leak</code> is also not set by default, then <code>free</code> ended up becoming a noop function that did nothing.</p>

<p>Here is the C code that was generated:</p>

<div><pre><code><span>void</span> <span>_v_free</span><span>(</span><span>voidptr</span> <span>ptr</span><span>)</span> <span>{</span>
    <span>#if defined(_VPREALLOC)
</span>    <span>{</span>
    <span>}</span>
    <span>#elif defined(_VGCBOEHM)
</span>    <span>{</span>
    <span>}</span>
    <span>#else
</span>    <span>{</span>
    <span>}</span>
    <span>#endif
</span><span>}</span>
</code></pre></div>

<p>All of this code is C preprocessor, so the compiler sees this code as follows:</p>

<div><pre><code><span>void</span> <span>_v_free</span><span>(</span><span>voidptr</span> <span>ptr</span><span>)</span> <span>{</span>
<span>}</span>
</code></pre></div>

<p>And that doesn’t free anything.</p>

<p>Let’s go back to the documentation:</p>

<blockquote>
  <p>Remaining small percentage of objects is freed via GC.</p>
</blockquote>

<p>And this was not true, even if V inserted <code>free</code> somewhere, they had no effect and everything was cleared by the GC. Even after this fix, this is not true because the GC is disabled when the <code>-autofree</code> flag is passed.</p>

<p>You may have seen this video: https://www.youtube.com/watch?v=gmB8ea8uLsM</p>

<p>In it, the author of the language shows his editor <a href="https://github.com/vlang/ved">Ved</a> and shows how he compiles it using <code>v . -autofree</code> and states that its technology is sufficiently developed that such a complex application as a text editor does not leak.</p>

<p>I tried to build the editor with the latest version of V with the <code>autofree</code> flag and got the following error when I launched the binary:</p>

<div><pre><code>V panic: as cast: cannot cast `map[string]toml.ast.Value` to `[]toml.ast.Value`
v hash: 0966fd3
/tmp/v_1000/ved.5480247081914024169.tmp.c:13797: at _v_panic: Backtrace
/tmp/v_1000/ved.5480247081914024169.tmp.c:14296: by __as_cast
/tmp/v_1000/ved.5480247081914024169.tmp.c:43867: by toml__Doc_value_
/tmp/v_1000/ved.5480247081914024169.tmp.c:43836: by toml__Doc_value
/tmp/v_1000/ved.5480247081914024169.tmp.c:44579: by main__Config_init_colors
/tmp/v_1000/ved.5480247081914024169.tmp.c:44551: by main__Config_reload_config
/tmp/v_1000/ved.5480247081914024169.tmp.c:46595: by main__main
/tmp/v_1000/ved.5480247081914024169.tmp.c:50668: by main
</code></pre></div>

<p>Without <code>autofree</code> everything worked without problems. Well, apparently autofree has only gotten worse in 3 years.</p>

<p>Interestingly enough, the project of the language author does not work with the main feature of his language.</p>

<p>Let’s try to build the compiler itself with <code>autofree</code>:</p>



<p>And let’s try to compile itself again with the resulting binary:</p>



<p>And we get an error at runtime:</p>

<div><pre><code>./v2 self
/tmp/v_1000/v2.10486918756004741764.tmp.c:25123: at string_starts_with: RUNTIME ERROR: invalid memory access
/tmp/v_1000/v2.10486918756004741764.tmp.c:35912: by os__impl_walk_ext
/tmp/v_1000/v2.10486918756004741764.tmp.c:35888: by os__walk_ext
/tmp/v_1000/v2.10486918756004741764.tmp.c:42645: by v__pref__detect_musl
/tmp/v_1000/v2.10486918756004741764.tmp.c:42743: by v__pref__parse_args_and_show_errors
/tmp/v_1000/v2.10486918756004741764.tmp.c:4811: by main__main
/tmp/v_1000/v2.10486918756004741764.tmp.c:5835: by main
</code></pre></div>

<p>Let’s go back to the last part of the documentation:</p>

<blockquote>
  <p>The developer doesn’t need to change anything in their code. “It just works”, like in Python, Go, or Java, except there’s no heavy GC tracing everything or expensive RC for each object.</p>
</blockquote>

<p>What we found out above, before commit <a href="https://github.com/vlang/v/commit/207203f5998e6b1844a32fe628e0eb64325db64d">207203f</a> when passing the <code>-autofree</code> flag we <strong>got</strong> “heavy GC tracing everything”, and after we <strong>get</strong> memory leaks even in the simplest examples.</p>

<p>I would also like to note that the author of the language promised to make this technology “production ready” back to version <code>0.3</code> (<a href="https://github.com/vlang/v/blob/0f9537ece544b7fda31cadf4dc95fd4b552f94be/ROADMAP.md">commit</a>), then to <a href="https://discord.com/channels/592103645835821068/592106336838352923/1136589637658345563">0.5</a>. and maybe in <a href="https://discord.com/channels/273534239310479360/818964227783262209/1146427952083513467">0.6</a>, and in <a href="https://github.com/vlang/v/blob/master/ROADMAP.md">ROADMAP</a> in 1.0.</p>

<blockquote>
  <p>“Fake it <del>till you make it</del>”.</p>
</blockquote>

<p>It’s interesting that the author of the language does not <a href="https://discord.com/channels/592103645835821068/592106336838352923/1126201270902997114">see the point</a> in using <code>autofree</code> with GC, although the documentation says that it is GC that clears the remaining “10%” of objects. Marvelous.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/2-resized.png" alt=""></p>

<p>Thus, from all of the above, we can conclude that <code>autofree</code> is a very crude technology. The author of the language tried to promote it through that video, and judging by the comments he succeeded, I don’t understand why people believe him, because a simple test shows that even simple programs leak as hell.</p>

<p><strong>After almost 5 years, the most interesting feature of V is still in a very early state, and the author does nothing but promise that everything will happen soon.</strong></p>

<p>It is already clear that the author of the language and his loyal followers will begin to say that <code>autofree</code> is not yet production ready, but the problems that I described above even for the very first alpha version are unacceptable.</p>

<h3 id="gc-default">GC (default)</h3>

<p>In this section, I want to discuss the remaining shortcomings of V in the memory management system.</p>

<p>Let’s go back to the documentation:</p>

<blockquote>
  <p>V avoids doing unnecessary allocations in the first place by using value types, string buffers, promoting a simple abstraction-free code style.</p>
</blockquote>

<p>It is stated that V does not make unnecessary allocations. Let’s check it out. In V, if you convert a structure into an interface, you get memory allocation with no options to avoid it, so you will get a bunch of extra allocations for nothing:</p>

<pre><code>interface IFoo {
    name string
}

struct Foo {
    name string
}

fn get_ifoo() IFoo {
    return Foo{name: 'foo'}
}

fn main() {
    foo := get_ifoo()
    println(foo.name)
}
</code></pre>

<p>C code:</p>

<div><pre><code><span>VV_LOCAL_SYMBOL</span> <span>main__IFoo</span> <span>main__get_ifoo</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>main__IFoo</span> <span>_t1</span> <span>=</span> <span>I_main__Foo_to_Interface_main__IFoo</span><span>(((</span><span>main__Foo</span><span>*</span><span>)</span><span>memdup</span><span>(</span><span>&amp;</span><span>(</span><span>main__Foo</span><span>){.</span><span>name</span> <span>=</span> <span>_SLIT</span><span>(</span><span>"foo"</span><span>),},</span> <span>sizeof</span><span>(</span><span>main__Foo</span><span>))));</span>
    <span>return</span> <span>_t1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><code>memdup</code> sends memory to heap via <code>_v_malloc</code>. In this small piece of code, you can also notice another feature of V, “readable” generated C code.</p>

<p>There is no escape analysis in V, and any pointers you create in a function make unnecessary allocations to the heap:</p>

<pre><code>fn main() {
    a := 100
    b := &amp;a
    println(b)
}
</code></pre>

<p>In C code:</p>

<div><pre><code><span>void</span> <span>main__main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>int</span> <span>*</span><span>a</span> <span>=</span> <span>HEAP</span><span>(</span><span>int</span><span>,</span> <span>(</span><span>100</span><span>));</span> <span>// heap allocation</span>
    <span>int</span><span>*</span> <span>b</span> <span>=</span> <span>&amp;</span><span>(</span><span>*</span><span>(</span><span>a</span><span>));</span>
    <span>string</span> <span>_t1</span> <span>=</span> <span>str_intp</span><span>(</span><span>1</span><span>,</span> <span>_MOV</span><span>((</span><span>StrIntpData</span><span>[])}));</span> <span>println</span><span>(</span><span>_t1</span><span>);</span> <span>string_free</span><span>(</span><span>&amp;</span><span>_t1</span><span>);</span>
    <span>;</span>
<span>}</span>
</code></pre></div>

<p>The documentation says:</p>

<blockquote>
  <p>Due to performance considerations V tries to put objects on the stack if possible but allocates them on the heap when obviously necessary.</p>
</blockquote>

<p>V does not allocate to the heap <strong>only those objects whose address is not taken</strong> in the entire function, V doesn’t do escape analysis and considers any taking of an address as a leak (in terms of “Escape Analysis”) from the function. And this doesn’t match the statement “Due to performance considerations V tries to put objects on the stack if possible” because any address taking results in an allocation on the heap even if it could have been avoided.</p>

<p>In the example above you can say that everything is correct, <code>b</code> leaks into the <code>println</code> function, so let’s look at an example without the call:</p>

<pre><code>fn main() {
    a := 100
    b := &amp;a
}
</code></pre>

<p>C code:</p>

<div><pre><code><span>void</span> <span>main__main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>int</span> <span>*</span><span>a</span> <span>=</span> <span>HEAP</span><span>(</span><span>int</span><span>,</span> <span>(</span><span>100</span><span>));</span>
    <span>int</span><span>*</span> <span>b</span> <span>=</span> <span>&amp;</span><span>(</span><span>*</span><span>(</span><span>a</span><span>));</span>
<span>}</span>
</code></pre></div>

<p>And still allocated on heap.</p>

<p>Instead of doing a smart escape analysis in V has a hack through the special <code>heap</code> attribute:</p>

<blockquote>
  <p>A solution to this dilemma is the <code>[heap]</code> <a href="https://github.com/vlang/v/blob/master/doc/docs.md#attributes">attribute</a> at the declaration of <code>struct MyStruct</code>. It instructs the compiler to <em>always</em> allocate <code>MyStruct</code>-objects on the heap.</p>
</blockquote>

<p>This is a bad solution because the developer cannot control where the object is allocated in each instantiation; by marking the structure with this attribute, you automatically get unnecessary allocations that could have been avoided.</p>

<hr>

<p>The quote from the beginning of the section also mentioned string buffers, so let’s take a look:</p>

<pre><code>import strings

fn main() {
    before := gc_heap_usage()
    mut sb := strings.new_builder(1)
    sb.write_string("hello")
    res := sb.str()
    after := gc_heap_usage()
    println(res)
    println(after.bytes_since_gc - before.bytes_since_gc)
}
</code></pre>



<p>Allocates 48 bytes, although there are only 5 bytes in the string.</p>

<p>Perhaps things are better with string interpolation?</p>

<pre><code>fn main() {
    before := gc_heap_usage()
    world := "world"
    res := "hello ${world}"
    after := gc_heap_usage()
    println(res)
    println(after.bytes_since_gc - before.bytes_since_gc)
}
</code></pre>



<p>Oho-ho, allocates 304 bytes for string of 11 characters. Impressive.</p>

<p>Let’s talk a little more about <code>arena</code> in this section.</p>

<h3 id="arena--prealloc">Arena (<code>-prealloc</code>)</h3>

<p>What does the documentation tell us about this mode? The only mention in the documentation I found was this line:</p>

<blockquote>
  <p>Arena allocation is available via v <code>-prealloc</code>.</p>
</blockquote>

<p>Oops. As I said, the documentation in V is bad.</p>

<p>Let me tell you myself, an arena is a way of working with memory, when at the start of the program a large chunk of memory is allocated at once, for example, 16 megabytes. Then, all allocations occur in this chunk; all explicit memory free does nothing. When a chunk is full, a new one is allocated, and so on. Before the program ends, all memory is freed.</p>

<p>This method is usually best suited for short-lived programs, such as compilers, where memory consumption may be less preferable to faster runtime.</p>

<p>What is the advantage of this mode? If small objects are often allocated in a program, then their allocation will take literally several arithmetic operations, instead of access to the operating system for memory each time.</p>

<p>Let’s dive into the world of V. All the implementation code can be found in the <a href="https://github.com/vlang/v/blob/master/vlib/builtin/prealloc.c.v"><code>prealloc.c.v</code></a> file.</p>

<p>The first thing we see is the <code>@[has_globals]</code> attribute of the module. But wait a minute:</p>

<blockquote>
  <p>By default V does not allow global variables. However, in low level applications they have their place so their usage can be enabled with the compiler flag <code>-enable-globals</code>.</p>
</blockquote>

<p>But ok.</p>

<p>Below we see exactly the reason for the presence of this flag:</p>

<div><pre><code>__global g_memory_block &amp;VMemoryBlock
</code></pre></div>

<p>Global variable. <code>__global</code>.</p>

<p>But since it’s global, what about multithreading? I didn’t see any mutexes, which means that <code>-prealloc</code> cannot be used in multithreaded programs safely. Is this written somewhere in the documentation? Nope. There is a comment in the file itself where this is written, apparently the author of the language believes that all users should first read the source code of the compiler.</p>

<h3 id="conclusions-about-memory-management">Conclusions about memory management</h3>

<p>Some parts are raw, some are unsafe, some don’t work, some don’t work as described. This is just what I could find. If such sloppiness is everywhere, this may mean that it is quite possible that there are even more critical bugs that we simply are not aware of.</p>

<p>This is where we’ll finish talking about working with memory in V.</p>

<p>Next, let’s quickly go through the site before a new interesting topic, coroutines in V.</p>

<h2 id="site-claims">Site claims</h2>

<p>Site is stated that there are no <code>null</code> in the language, without taking into account <code>unsafe</code> code. So:</p>

<pre><code>struct Foo {
    data &amp;string
}

fn main() {
    println(Foo{
        data: 0
    })
}
</code></pre>

<p>there is no <code>null</code>, but you can assign 0 to a pointer. ¯_(ツ)_/¯</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/3-resized.png" alt=""></p>

<p>Then the site tells us that there is no UB in the language. Let’s open the <a href="https://en.wikipedia.org/wiki/Undefined_behavior">article</a> about UB on the wiki.</p>

<p>Overflows in V really haven’t been UB since <a href="https://github.com/vlang/v/commit/c6412597abe24cdf099c9031ebdc47a3a263d141">recently</a>. It took 4 years from the release of the language to fix this UB. Although there is not a word about this in the documentation, the language also has no specification, so for the user this fact is hidden behind the compiler code. Here is a description of the С flag that was added as a fix:</p>

<blockquote>
  <p>This option instructs the compiler to assume that signed arithmetic overflow of addition, subtraction and multiplication wraps around using twos-complement representation. This flag enables some optimizations and disables others.</p>
</blockquote>

<p>Honestly, in a safe language, as the site says, I would expect the ability to perform these operations safely with the ability to specify the behavior on overflow (<code>a.safe_add(b) or { panic("aaaa") }</code>), and by default – panic.</p>

<p>Let’s try another example from the wiki article:</p>

<pre><code>fn main() {
    a := 100
    b := 200
    println(&amp;a &lt; &amp;b)
}
</code></pre>

<p>C code:</p>

<div><pre><code><span>void</span> <span>main__main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>int</span> <span>a</span> <span>=</span> <span>100</span><span>;</span>
    <span>int</span> <span>b</span> <span>=</span> <span>200</span><span>;</span>
    <span>println</span><span>(</span><span>&amp;</span><span>a</span> <span>&lt;</span> <span>&amp;</span><span>b</span> <span>?</span> <span>_SLIT</span><span>(</span><span>"true"</span><span>)</span> <span>:</span> <span>_SLIT</span><span>(</span><span>"false"</span><span>));</span>
<span>}</span>
</code></pre></div>

<p>Code from V article:</p>

<pre><code>int main(void)
{
  int a = 0;
  int b = 0;
  return &amp;a &lt; &amp;b; /* undefined behavior */
}
</code></pre>

<p>One-to-one, it’s UB.</p>

<p>Let’s try to dereference a null pointer:</p>

<pre><code>struct Data {
    name string
}

fn (d &amp;Data) some() {
    println(d.name)
}

struct Foo {
mut:
    data &amp;Data
}

fn main() {
    mut foo := Foo{
        data: 0
    }
    foo.data.some()
}
</code></pre>

<div><pre><code>code.v:6: at main__Data_some: RUNTIME ERROR: invalid memory access
code.v:18: by main__main
code.13715926371810092027.tmp.c:16997: by main
</code></pre></div>

<p>No safety at all.</p>

<p>Let’s move forward.</p>

<blockquote>
  <p>No undefined values</p>
</blockquote>

<p>Okay, let’s create a structure with an interface field:</p>

<pre><code>interface IFoo {
    name() string
}

struct Foo {
mut:
    foo IFoo
}

fn main() {
    mut foo := Foo{}
    println(foo.foo.name())
}
</code></pre>

<p>And run it:</p>

<pre><code>RUNTIME ERROR: invalid memory access
</code></pre>

<p>Oops, the problem is that an uninitialized field with an interface type actually has an undefined value. But you won’t be able to find information about this in the documentation.</p>

<blockquote>
  <p>No global variables <em>(can be enabled for low level apps like kernels via a flag)</em></p>
</blockquote>

<p>We’ve already seen a hack through <code>[has_globals]</code>. Although it seems it’s only allowed for the compiler. So that’s true.</p>

<p>Let’s move to the performance section:</p>

<blockquote>
  <p>C interop without any costs</p>
</blockquote>

<p>Indeed, that’s true.</p>

<blockquote>
  <p>Minimal amount of allocations</p>
</blockquote>

<p>It has already been proven above that this is not true.</p>

<blockquote>
  <p>Built-in serialization without runtime reflection</p>
</blockquote>

<p>That’s indeed true.</p>

<blockquote>
  <p>Compiles to native binaries without any dependencies: a simple web server is only about 250 KB</p>
</blockquote>

<p>Let’s try to compile the official <a href="https://github.com/vlang/v/blob/master/examples/vweb/vweb_example.v">example</a> with <code>V 0.4.3 c3cf9ee.cc220e6</code> on Ubuntu 22.04.</p>

<p>It took indefinitely long to compile this example with the <code>-prod</code> flag, so I manually inserted the required optimization flags.</p>

<p>Let’s try to compile:</p>

<div><pre><code>v ./v/examples/vweb/vweb_example.v -cflags "-Os" -o vweb_server
</code></pre></div>

<p>And check the size:</p>

<div><pre><code>-rwxr-xr-x 1 root root 4511876 Nov 19 14:03 vweb_server
</code></pre></div>

<p>Oops, 4mb, a bit far from 250 KB. Let’s try a couple of tricks:</p>

<div><pre><code>v ./v/examples/vweb/vweb_example.v -cflags "-Os -flto" -o vweb_server -skip-unused
</code></pre></div>

<div><pre><code>-rwxr-xr-x 1 root root 2784628 Nov 19 14:07 vweb_server
</code></pre></div>

<p>Better, only 2.7 megabytes, but still not 250 KB.</p>

<p>Another trick I found in a <a href="https://github.com/vlang/v/discussions/19792">GitHub discussion</a>:</p>

<div><pre><code>v ./v/examples/vweb/vweb_example.v -cflags "-Os -flto" -o vweb_server -skip-unused -d use_openssl
</code></pre></div>

<div><pre><code>-rwxr-xr-x 1 root root 1565316 Nov 19 14:09 vweb_server
</code></pre></div>

<p>We’re getting closer, but I don’t have other tricks.</p>

<p>Well, maybe everything got statically linked, so the size is big:</p>

<div><pre><code>ldd ./vweb_server
    linux-vdso.so.1 (0x00007ffde677d000)
    libatomic.so.1 =&gt; /lib/x86_64-linux-gnu/libatomic.so.1 (0x00007fc25455a000)
    libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc254332000)
    /lib64/ld-linux-x86-64.so.2 (0x00007fc25456e000)
</code></pre></div>

<p>What about with <code>-d use_openssl</code>?</p>

<div><pre><code>ldd ./vweb_server
    linux-vdso.so.1 (0x00007ffc2b242000)
    libatomic.so.1 =&gt; /lib/x86_64-linux-gnu/libatomic.so.1 (0x00007fa673d80000)
    libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fa673b58000)
    libssl.so.3 =&gt; /lib/x86_64-linux-gnu/libssl.so.3 (0x00007fa673ab4000)
    libcrypto.so.3 =&gt; /lib/x86_64-linux-gnu/libcrypto.so.3 (0x00007fa673671000)
    /lib64/ld-linux-x86-64.so.2 (0x00007fa673d94000)
</code></pre></div>

<p>Hmm, as a result, the size is 5-17 times larger, and there are a lot of dependencies.</p>

<p>Let’s go further.</p>

<blockquote>
  <p>As fast as C (V’s main backend compiles to human readable C), with equivalent code.
<em>V does introduce some overhead for safety (such as array bounds checking, GC free), but these features can be disabled/bypassed when performance is more important.</em></p>
</blockquote>

<p>Just because you compile in C doesn’t mean you instantly get the same performance as handwritten C code. I have already shown above how V carelessly works with memory; not a single experienced C developer will make such mistakes.</p>

<p>V can be as fast as C, but then a lot of things in the language cannot be used: string interpolation, interfaces, sum types, arrays and much more.</p>



<p>The official site says:</p>

<blockquote>
  <p>V can translate your entire C project and offer you the safety, simplicity, and compilation speed-up (via modules).</p>
</blockquote>

<p>Sounds great, let’s try it. Before that, let’s pay attention on another statement:</p>

<blockquote>
  <p>A blog post about translating DOOM will be published.</p>
</blockquote>

<p>You can find the same statement on the <a href="https://web.archive.org/web/20200709094936/https://vlang.io/">official website in 2020</a>. Maybe we need to wait a little longer.
During the article, I have already pointed out such moments several times; this is the distinctive feature of V, <strong>to promise and not to deliver</strong>.</p>

<p>Well, let’s move on to c2v. Its repository can be found here: https://github.com/vlang/c2v</p>

<p>It doesn’t have to be downloaded, it can be used via <code>v translate</code>. By the way, you will not find this command in <code>v help</code>:</p>

<div><pre><code>V supports the following commands:

* Project Scaffolding Utilities:
  new                          Setup the file structure for a V project
                               (in a sub folder).
  init                         Setup the file structure for an already existing
                               V project.

* Commonly Used Utilities:
  run                          Compile and run a V program. Delete the
                               executable after the run.
  crun                         Compile and run a V program without deleting the
                               executable.
                               If you run the same program a second time,
                               without changing the source files,
                               V will just run the executable, without
                               recompilation. Suitable for scripting.
  test                         Run all test files in the provided directory.
  fmt                          Format the V code provided.
  vet                          Report suspicious code constructs.
  doc                          Generate the documentation for a V module.
  vlib-docs                    Generate and open the documentation of all the
                               vlib modules.
  repl                         Run the REPL.
  watch                        Re-compile/re-run a source file, each time it is
                               changed.
  where                        Find and print the location of current project
                               declarations.
</code></pre></div>

<p>Did I mention that the documentation is bad?</p>

<p>Let’s take a simple example:</p>



<p>Let’s call the command <code>v translate wrapper main.h</code> and open the resulting file:</p>

<pre><code>[translated]
module.

fn C.foo(a int, b int) int

pub fn foo(a int, b int) int {
  return C.foo(a, b)
}
</code></pre>

<p>Everything seems fine, but the module name is incorrect.</p>

<p>In C libraries, constants are often defined using <code>#define</code>:</p>

<div><pre><code><span>#define VERSION 1.0
</span>
<span>int</span> <span>foo</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>);</span>
</code></pre></div>

<p>But as a result, c2v simply skips this constant, and it is not in the V code. The generated V code with <code>#define</code> fully equals to the code without it.</p>

<p>Okay, let’s take a slightly more complicated example:</p>

<div><pre><code><span>#include &lt;stdlib.h&gt;
</span>
<span>typedef</span> <span>struct</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>char</span> <span>*</span><span>ptr</span><span>;</span>
        <span>char</span> <span>small</span><span>[</span><span>16</span><span>];</span>
    <span>};</span>
    <span>size_t</span> <span>size</span><span>;</span>
<span>}</span> <span>string</span><span>;</span>

<span>int</span> <span>foo</span><span>(</span><span>string</span> <span>str</span><span>);</span>
</code></pre></div>

<p>This is a simple string implementation.</p>

<pre><code>[translated]
module .

struct Lldiv_t { 
    quot i64
    rem i64
}
struct String { 
    size usize
}
fn C.foo(str String) int

pub fn foo(str String) int {
    return C.foo(str)
}
</code></pre>

<p>Wait a minute, what is this <code>Lldiv_t</code> and why is there only one field in the structure…</p>

<p>I really like constancy:</p>

<div><pre><code><span>int</span> <span>foo</span><span>(</span><span>const</span> <span>int</span> <span>*</span><span>const</span> <span>val</span><span>);</span>
</code></pre></div>

<p>But c2v doesn’t:</p>

<pre><code>[translated]
module .

fn C.foo(val Int *const) int

pub fn foo(val Int *const) int {
    return C.foo(val)
}
</code></pre>

<p>Absolutely incorrect code.</p>

<p>You will say that I am making everything up and no one writes such code, okay, let’s take an example from real life. Let’s take the library that V uses for JSON: https://github.com/DaveGamble/cJSON.</p>

<div><pre><code>v translate wrapper cJSON.h
</code></pre></div>

<p>Aaaaaand…</p>

<p>Almost all is incorrect:</p>

<pre><code>fn C.cJSON_GetObjectItem(object CJSON *const, string_ Char *const) &amp;CJSON

pub fn cjson_getobjectitem(object CJSON *const, string_ Char *const) &amp;CJSON {
    return C.cJSON_GetObjectItem(object, string_)
}

...

fn C.cJSON_IsTrue(item CJSON *const) CJSON_bool

pub fn cjson_istrue(item CJSON *const) CJSON_bool {
    return C.cJSON_IsTrue(item)
}

...

fn C.cJSON_ReplaceItemViaPointer(parent CJSON *const, item CJSON *const, replacement &amp;CJSON) CJSON_bool

pub fn cjson_replaceitemviapointer(parent CJSON *const, item CJSON *const, replacement &amp;CJSON) CJSON_bool {
    return C.cJSON_ReplaceItemViaPointer(parent, item, replacement)
}
</code></pre>

<p>Okay, let’s take another one, for example, <a href="https://github.com/vlang/v/blob/master/thirdparty/libbacktrace/backtrace.h"><code>backtrace.h</code></a>.</p>

<div><pre><code>v translate wrapper backtrace.h
</code></pre></div>

<p>Better, although we lost <code>Backtrace_state</code> and <code>Uintptr_t</code> and have an error:</p>

<div><pre><code>backtrace.v:29:59: error: unexpected token `&amp;`, expecting name
   27 | fn C.backtrace_print(state &amp;Backtrace_state, skip int,  &amp;C.FILE)
   28 | 
   29 | pub fn backtrace_print(state &amp;Backtrace_state, skip int,  &amp;C.FILE)  {
      |                                                           ^
   30 |     C.backtrace_print(state, skip, &amp;C.FILE)
   31 | }
</code></pre></div>

<p>Well, okay, c2v is not great with wrappers, but the tool can also translate entire C code into V.</p>

<p>Let’s start with something simple:</p>

<div><pre><code><span>#include &lt;stdio.h&gt;
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span> <span>{</span>
    <span>printf</span><span>(</span><span>"%d"</span><span>,</span> <span>argc</span><span>);</span>
    <span>return</span> <span>1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Call c2v:</p>



<p>Oops, where did <code>argc</code> go:</p>

<pre><code>[translated]
module main

fn main() {
    C.printf(c'%d', argc)
    return
}
</code></pre>

<p>I specifically returned 1 from <code>main</code> in the C code, but c2v ignored this and simply inserted <code>return</code>, thereby changing the behavior of the program.</p>

<p>Let’s take something more complicated:</p>

<div><pre><code><span>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
</span>
<span>void</span><span>*</span> <span>my_malloc</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
    <span>void</span><span>*</span> <span>ptr</span> <span>=</span> <span>malloc</span><span>(</span><span>size</span><span>);</span>
    <span>if</span> <span>(</span><span>ptr</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"malloc failed"</span><span>);</span>
        <span>exit</span><span>(</span><span>1</span><span>);</span>
    <span>}</span>
    <span>return</span> <span>ptr</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span> <span>{</span>
    <span>int</span> <span>*</span><span>a</span> <span>=</span> <span>my_malloc</span><span>(</span><span>sizeof</span><span>(</span><span>int</span><span>));</span>
    <span>*</span><span>a</span> <span>=</span> <span>1</span><span>;</span>
    <span>printf</span><span>(</span><span>"%d"</span><span>,</span> <span>*</span><span>a</span><span>);</span>
    <span>return</span> <span>1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>V:</p>

<pre><code>[translated]
module main

struct Lldiv_t {
    quot i64
    rem  i64
}

fn my_malloc(size usize) voidptr {
    ptr := C.malloc(size)
    if ptr == (unsafe { nil }) {
        C.printf(c'malloc failed')
        C.exit(1)
    }
    return ptr
}

fn main() {
    a := my_malloc(sizeof(int))
    *a = 1
    C.printf(c'%d', *a)
    return
}
</code></pre>

<p>It looks correct at first glance, but c2v has lost the fact that the result of <code>my_malloc(...)</code> is cast implicitly in <code>int*</code>. So if you have implicit casts in your code, then apparently everything will not work out of the box. But in C, implicit casts are rare, so it’s not a problem, right?</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/4-resized.png" alt=""></p>

<p>We can talk about this for a long time; such simple examples already show how crude and unfinished this tool is. Considering the fact that it was announced and began development somewhere in 2020, the tool achieved such excellent success in just 3 years.</p>

<hr>

<p>Returning to the site:</p>

<blockquote>
  <p>Powerful graphics libraries</p>
</blockquote>

<blockquote>
  <p>The following features are planned:</p>

  <ul>
    <li>Loading complex 3D objects with textures</li>
    <li>Camera (moving, looking around)</li>
    <li>Skeletal animation</li>
  </ul>

  <p>DirectX, Vulkan, and Metal support is planned.</p>
</blockquote>

<p>At least <a href="https://web.archive.org/web/20200426171536/https://vlang.io/">three years</a> they promise what will happen. But the main thing is to promise, right?</p>

<h2 id="v-ui">V UI</h2>

<p>Another project that showed promise, but something went wrong. Project repository: https://github.com/vlang/ui</p>

<p>Over the last year, the project has had about 80 commits, of which a maximum of 10–20 are <strong>not fixes for the new version V</strong>. The project has been abandoned and is not being developed.</p>

<p>But let’s see, in the readme we are greeted with an example:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/23-resized.png" alt=""></p>

<p>Do you know what’s interesting? If you go to <a href="https://github.com/vlang/ui/tree/3dd0e7a3f6cb5f316bacf1d556cb8abde25d2c84">repository from 2020</a> then the same picture will be there.</p>

<p>The project has <a href="https://github.com/vlang/ui/issues/31">ROADMAP</a> which was created in 2020, after 3 years only several points there were closed.</p>

<p>You can say that perhaps developers spend all their time on the compiler, but at the same time, there are new projects like <a href="https://github.com/vlang/education-platform">Education Platform</a>, <a href="https://veery.cc/">veery</a>, <a href="https://discord.com/channels/592103645835821068/592106336838352923/1176183805174894653">vbrowser</a>, <a href="https://github.com/vlang/heroesV">heroesV</a>. You may notice that all these projects start and are quickly abandoned. The same thing with V UI, but it lived a little longer, like the <a href="https://github.com/vlang/vinix">operating system</a> on V, which was developed while there was a person with experience, as soon as he left, the project died.</p>

<p>The V UI project description on the website says:</p>

<blockquote>
  <p>V has a UI module that uses custom drawing, similar to Qt and Flutter, but with as much similarity to the native GUI toolkit as possible.</p>
</blockquote>

<p>Okay, let’s check the examples:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/5-resized.png" alt=""></p>

<p>I was able to copy the value in the password field without any problems, security is not a strong point of V UI:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/6-resized.png" alt=""></p>

<p>And these are official examples:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/7-resized.png" alt=""></p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/8-resized.png" alt=""></p>

<p>It’s hard for me to say where the authors saw the maximum similarity with the native UI.</p>

<p>The last part of this section sounds somewhat familiar:</p>

<blockquote>
  <p>Coming soon:</p>

  <ul>
    <li>a Delphi-like visual editor for building native GUI apps</li>
    <li>iOS support</li>
  </ul>
</blockquote>

<p>Again, promises that are <a href="https://web.archive.org/web/20200513204922/https://vlang.io/">three years old</a>.</p>

<h2 id="coroutines">Coroutines</h2>

<p>Сoroutines in V. From the very beginning, V copied Go, and if it’s easy to copy the syntax, then to copy goroutines you need to have very mature and senior developers. Therefore, from the very beginning, V builds its multithreading on threads with all the disadvantages.</p>

<p>But at some point the creator of the language thought, what’s stopping us from making coroutines. The coroutines were “done” in three commits:</p>

<ul>
  <li><a href="https://github.com/vlang/v/commit/45f16a2640d94202f98e32c5be67ba950662217f">all: coroutines (part 1)</a></li>
  <li><a href="https://github.com/vlang/v/commit/9db10c8f61c88625f33171cc9b4f2821af0a6678">all: coroutines (part 2)</a></li>
  <li><a href="https://github.com/vlang/v/commit/786865d34972b2bb53c66e0aaaad9af5cf8d76d1">coroutines: init() that runs automatically</a></li>
</ul>

<p>With a difference of 4 hours, an impressive speed of implementation.</p>

<p>Let’s see what kind of implementation coroutines have in V, stackless or stackful. The main implementation file is <a href="https://github.com/vlang/v/blob/45f16a2640d94202f98e32c5be67ba950662217f/vlib/coroutines/coroutines.v">coroutines/coroutines.v</a>.</p>

<p>Wait a minute, this is not the implementation I expected:</p>

<pre><code>#flag -I @VEXEROOT/thirdparty/photon
#flag @VEXEROOT/thirdparty/photon/photonwrapper.so

#include "photonwrapper.h"

fn C.photon_init_default() int
fn C.photon_thread_create11(f voidptr)
fn C.photon_sleep_s(n int)
fn C.photon_sleep_ms(n int)

// sleep is coroutine-safe version of time.sleep()
pub fn sleep(duration time.Duration) {
    C.photon_sleep_ms(duration.milliseconds())
}
</code></pre>

<p>What we see here are bindings for some third-party library. Here is the link to it: https://github.com/alibaba/PhotonLibOS. So, what we get is that coroutines in V are a 10-line wrapper over a third-party C++ library.</p>

<p>Well, okay, in the examples there is code that will help us understand the strengths of coroutines <a href="https://github.com/vlang/v/blob/master/examples/coroutines/simple_coroutines.v">simple_coroutines.v</a> (or not). The whole example is a couple of loops with a sleep calls. Well, let’s try to build it:</p>

<div><pre><code>v -use-coroutines ./examples/coroutines/simple_coroutines.v 
coroutines .so not found, downloading...
done!
</code></pre></div>

<p>Um, it downloads a dynamic library from somewhere unknown, but okay.</p>

<p>We get some output, but how do we understand that it is correct? The biggest difficulty of coroutines is context switching, that is, when one coroutine, for example, waits for a file to be read, and gives way to another coroutine. And here’s the problem: in V, the entire standard library is written in a synchronous manner.</p>

<p>Let’s, for example, look at <a href="https://github.com/vlang/v/blob/6cc51f254f6a6ea921726f6014107a7100ad97d1/vlib/os/os.c.v#L111">file read</a> in V:</p>

<pre><code>pub fn read_file(path string) !string {
  ...
  nelements := int(C.fread(str, 1, allocate, fp))
  ...
}
</code></pre>

<p>Here we see that V calls a C <code>read</code> function that reads a given number of bytes into the buffer. The problem is that <code>read</code> is a blocking function and the context will never be switched. One of the PhotonLibOS project maintainers <a href="https://github.com/alibaba/PhotonLibOS/issues/148#issuecomment-1761298839">says the same</a> about this. The same goes for the network, V also uses the blocking API from C.</p>

<p>And from this, it becomes clear that coroutines in V are not only a useless binding for a third-party lib, but also non-working as expected. Let’s see what their “author”, the creator of the language, says:</p>

<p>https://discord.com/channels/592103645835821068/592106336838352923/1165748025377960037</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/9-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/592106336838352923/1160886627208544308</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/10-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/697813437237166131/1138567669323415562</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/11-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/592320321995014154/1116015948038672414</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/12-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/592106336838352923/1160744638529933463</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/13-resized.png" alt=""></p>

<p>He lies about the last missing coroutine feature, when the coroutines simply don’t work as expected. He lies that coroutines work with IO. I’ll clarify that by working, I personally mean context switching when necessary, and not the fact that the program does not crash.</p>

<p>At the same time, nothing bothers him, and he is already planning to create a new framework for the web and publish links with headings about coroutines:</p>

<p>https://news.ycombinator.com/item?id=37174056</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/14-resized.png" alt=""></p>

<p>And most importantly, I only saw one person from the community who expressed the opinion that the current implementation of coroutines does not work. The rest of the core developers are apparently too busy to check the feature that comes first in <a href="https://github.com/vlang/v/releases/tag/0.4">CHANGELOG</a> version 0.4:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/15-resized.png" alt=""></p>

<p>And all this without touching on the fact that the creator of the language forces the language to depend on a corporation that at any moment can simply stop supporting the library. If V integrates IO and network from this library to get context switches, then it will be even worse. V will depend on this corporation not only at the coroutine level, but even at the level of simple operations like reading a file or requests over the network. Moreover, this library only supports two main operating systems (Linux and macOS), which means that code with coroutines loses all the flexibility that V has thanks to the C compiler.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/16-resized.png" alt=""></p>

<p>Also, the author of the language <a href="https://discord.com/channels/592103645835821068/592106336838352923/1162727123472101416">doesn’t understand</a> that you can’t just do two versions of functions, because when you call a function in a coroutine, the function for the coroutine must be used, and if outside the coroutine, the usual one.</p>

<p>This library also does not fully support Windows, which means that V will only get coroutines on Windows if the authors of PhotonLibOS are so kind as to implement it.</p>



<p>Community V is an interesting phenomenon. If you go to the V Discord server, you are unlikely to find criticism of V or the author of the language there. And do you know why? Because the author of the language bans people for their opinions.</p>

<p>For example, I managed to “unsuccessfully” answer a person’s question in the V Telegram channel:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/17-resized.png" alt=""></p>

<p>For which I was immediately banned without explanation or attempt to show where I was wrong.</p>

<p>Next, to my post on the Discord server where I described the situation, I received responses from several people, one said that everything is not so clear, and we don’t know the whole truth, and the second called me a troll. About an hour later, the author of the language deleted all messages after my post and banned me without explanation also in Discord.</p>

<p>I want to clarify, this post has problems because I wrote it right after I was banned, and perhaps I could have been less arrogant:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/18-resized.png" alt=""></p>

<p>The creator of the language also <a href="https://discord.com/channels/592103645835821068/853624878556512266/1176019939551879268">called</a> me a troll:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/19-resized.png" alt=""></p>

<p>Do you know why? Because he needed to justify himself to a person who directly stated that he did not approve of such behavior. Apologize? Admit mistake? No, this is not Alex’s way; his way is to dehumanize the victim by calling him a troll and banning anywhere.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/20-resized.png" alt=""></p>

<p>And you know what’s the funniest thing? Today this person was banned. Why? Because he disagrees with the policy for which I was banned the first time and asked to remove his article from <a href="https://github.com/vlang/education-platform">vlang/education-platform</a>. This was the only article with content, <a href="https://github.com/vlang/education-platform/tree/master/lessons">the other two</a> consist of two phrases: “V is great.” and “In this lesson, we’ll examine one of the simplest codes in V.”, which were apparently written by Alex himself.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/21-resized.png" alt=""></p>

<p>Another lie, Alex himself wrote to me in Telegram, not the moderator. He told me that I could come to him in a private message in Telegram, and he would have unbanned me. Think about it, first he bans you on two platforms even though you didn’t break the rules, and then he says that you could come in private messages, and he would unban you. Unfortunately, I can’t provide a screenshot, since Alex deleted all the messages (familiar behavior, isn’t it?) that he wrote to me when he realized that I was not ready to humiliate myself.</p>

<p>Today I was also banned for the third time, I created a specially new account to report that I was writing this article.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/22-resized.png" alt=""></p>

<p>And also to see how far Alex would go to try to shut me up.</p>

<p>Well, the result of this is obvious, although today I was able to communicate with more people from the community than last time, and we even came to some kind of understanding. However, a few hours later Alex came and unceremoniously deleted all my messages and banned me. asvln’s messages were also deleted and he was banned.</p>

<p>It is also interesting that after the messages were deleted, none of those with whom I spoke expressed disturbance about the deletion and bans, and here either they agree with Alex’s actions, or they just don’t care what is happening in their community, or they are simply afraid to speak out something against Alex, as this will lead to their ban. <strong>And each option is worse than the other.</strong></p>

<p>Apparently the author of the language does not understand that trying to shut people up will only cause more damage. This time I’m documenting everything carefully.</p>

<p>Considering the fact that I have not seen criticism like this, all the brave souls here are banned. 3
years have passed, and nothing has changed, the author of other articles in which V is not praised as a divine creation was also <a href="https://christine.website/blog/vlang-update-2020-06-17/">banned</a>. And this is not the last example, here is a person <a href="https://twitter.com/MaxGraey/status/1430073855062814720">banned on Twitter</a> for arguing with the author of the language. I’m almost sure that there were dozens, maybe hundreds of such cases.</p>

<p>Do you want to be part of the community where banning for facts is ok, calling those who try to find out, compare or point out flaws as trolls is ok, and where the only correct opinion belongs to one person?</p>

<p>Me not.</p>

<p>I really want to see Alex’s Volt, which he promises people from 2019; apparently the main feature there will be the ability to ban people with the power of thought with automatic clearing of the chat. Beta was <a href="https://discord.com/channels/592103645835821068/708726848523075644/1109496090161594458">promised</a> in May 2023, but something went wrong and the author of the language simply <a href="https://discord.com/channels/592103645835821068/708726848523075644/1123052269227737241">ignores</a> people since then (another distinctive “feature” of Alex).</p>

<hr>

<p>As a result, the author of the language tried to shut me up, but got this article. I can already see how he is trying to justify himself by calling me a troll, a hater or something else, but whatever the reason for this article, all of the above are facts.</p>

<p>Of course, the author of the language will say that these problems are easy to fix (good luck). After a “week” Alex will say that they are fixed, but this does not solve the global problems in the language, when problems are fixed only when they are pointed out. Developers are not interested in looking for bugs on their own. And this is obvious because, apart from the compiler, they do not develop large projects on V on which they could quickly find all these problems.</p>

<p>Despite the fact that the language is almost 5 years old, you can still find very primitive problems that the language developers for some reason did not find before the users. The author of the language promises, as was the case with autofree, then postpones and promises again, and so on ad infinitum, how can one even trust such a person.</p>

<p>This is where the article ends; only you can decide whether V is worth spending time on. In this article, I have only scratched the surface of V; to describe everything that V is bad at, I would need to write a book. I hope that this article will help you make the right decision.</p>

<p>Bye.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Institutions try to preserve the problem to which they are the solution (1160 pts)]]></title>
            <link>https://effectiviology.com/shirky-principle/</link>
            <guid>39491863</guid>
            <pubDate>Sat, 24 Feb 2024 14:53:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://effectiviology.com/shirky-principle/">https://effectiviology.com/shirky-principle/</a>, See on <a href="https://news.ycombinator.com/item?id=39491863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text"><p><img decoding="async" src="https://effectiviology.com/wp-content/uploads/Shirky-Principle.jpg" alt="" width="1000" height="667" srcset="https://effectiviology.com/wp-content/uploads/Shirky-Principle.jpg 1000w, https://effectiviology.com/wp-content/uploads/Shirky-Principle-300x200.jpg 300w, https://effectiviology.com/wp-content/uploads/Shirky-Principle-768x512.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p><p>The <em>Shirky principle</em> is the adage that “institutions will try to preserve the problem to which they are the solution”. More broadly, it can also be characterized as the adage that “every entity tends to prolong the problem it is solving”.</p><p>For example, the Shirky principle means that a government agency that’s meant to address a certain societal issue may hinder attempts by others to address the issue, in order to ensure that the agency remains relevant. Alternatively, the agency may become so focused on the current way in which it addresses the issue that it will fail to adopt better new solutions as they become available, thus prolonging the issue.</p><p>The Shirky principle has important implications in various domains, so it’s important to understand it. As such, in the following article you will learn more about this principle, and see what you can do about it in practice.</p><div id="ez-toc-container"><nav><ul><li><a href="#Examples_of_the_Shirky_principle" title="Examples of the Shirky principle">Examples of the Shirky principle</a></li><li><a href="#Origin_and_formulations_of_the_Shirky_principle" title="Origin and formulations of the Shirky principle">Origin and formulations of the Shirky principle</a></li><li><a href="#Caveats_about_the_Shirky_principle" title="Caveats about the Shirky principle">Caveats about the Shirky principle</a></li><li><a href="#Accounting_for_the_Shirky_principle" title="Accounting for the Shirky principle">Accounting for the Shirky principle</a></li><li><a href="#Related_concepts" title="Related concepts">Related concepts</a></li><li><a href="#Summary_and_conclusions" title="Summary and conclusions">Summary and conclusions</a></li></ul></nav></div><h2><span id="Examples_of_the_Shirky_principle"></span>Examples of the Shirky principle<span></span></h2><p>An example of the Shirky principle are tax-filing companies who <a href="http://web.archive.org/web/20210509181435/https:/www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free">lobby</a> the government to <a href="http://web.archive.org/web/20210509175424/https:/www.propublica.org/article/filing-taxes-could-be-free-simple-hr-block-intuit-lobbying-against-it">prevent</a> it from <a href="http://web.archive.org/web/20210509181647/https:/www.politico.com/agenda/story/2018/07/18/tax-filing-congress-irs-000683/">offering</a> a free and easy way to <a href="http://web.archive.org/web/20210416223809/https:/www.nytimes.com/2015/04/16/technology/personaltech/turbotax-or-irs-as-tax-preparer-intuit-has-a-favorite.html">file taxes</a>, to ensure that the companies can continue to make a profit. A similar example of this are private prison companies who <a href="http://web.archive.org/web/20210509182458/https:/www.washingtonpost.com/posteverything/wp/2015/04/28/how-for-profit-prisons-have-become-the-biggest-lobby-no-one-is-talking-about/">lobby</a> the government to <a href="http://web.archive.org/web/20210509184717/https:/www.theguardian.com/commentisfree/2012/sep/27/lawmakers-lobbyists-keep-lock-private-prison-business">support</a> policies that <a href="http://web.archive.org/web/20210509185251/https:/escholarship.org/uc/item/3qj7q63d">increase</a> the number of <a href="http://web.archive.org/web/20210509185809/https:/papers.ssrn.com/sol3/papers.cfm?abstract_id=2794145">incarcerated</a> people and&nbsp;the <a href="https://doi.org/10.1002/9781118519639.wbecpx175">duration</a> of their incarceration.</p><p>Another <a href="https://sagepub.com/en-us/nam/encyclopedia-of-social-media-and-politics/book239101">well-known</a> example of the Shirky principle is described in “<a href="https://amzn.to/3tqsrZz">Cognitive Surplus</a>”, a book by Clay Shirky that contained one of the first discussions of this principle:</p><blockquote><p>“PickupPal.com is… a carpooling site designed to coordinate drivers and riders planning to travel along the same route.</p><p>In May 2008 the Ontario-based bus company Trentway-Wagar… petitioned the Ontario Highway Transport Board (OHTB) to shut PickupPal down on the grounds that, by helping coordinate drivers and riders, it worked too well to be a carpool. Trentway-Wagar invoked Section 11 of the Ontario Public Vehicles Act, which stipulated that carpooling could happen only between home and work (rather than, say, school or hospital.) It had to happen within municipal lines. It had to involve the same driver each day. And gas or travel expense could be reimbursed no more frequently than weekly.</p><p>Trentway-Wagar was arguing that because carpooling used to be inconvenient, it should always be inconvenient, and if that inconvenience disappeared, then it should be reinserted by legal fiat. Curiously, an organization that commits to helping society manage a problem also commits itself to the preservation of that same problem, as its institutional existence hinges on society’s continued need for its management. Bus companies provide a critical service—public transportation—but they also commit themselves, as Trentway-Wagar did, to fending off competition from alternative ways of moving people from one place to another.</p><p>The OHTB upheld Trentway-Wagar’s complaint and ordered PickupPal to stop operating in Ontario. PickupPal decided to fight the case—and lost in the hearing. But public attention became focused on the issue, and in a year of high gas prices, burgeoning environmental concern, and a financial downturn, almost no one took Trentway-Wagar’s side. The public reaction, channeled through everything from an online petition to T-shirt sales, had one message: Save PickupPal. The idea that people couldn’t use such a service was too hot for the politicians in Ontario to ignore. Within weeks of Trentway-Wagar’s victory, the Ontario legislature amended the Public Vehicles Act to make PickupPal legal again.”</p></blockquote><p>In addition, the Shirky principle can also apply to entities other than institutions. For example, an individual employee who’s in charge of a certain process in their workplace might resist attempts to automate that process, in order to ensure that the employee remains necessary to their employer.</p><p>A well-known example of the Shirky effect in this context is the <em>cobra effect</em>. It <a href="https://doi.org/10.1057/s41302-021-00187-7">describes</a> a <a href="http://web.archive.org/web/20210510110107/https:/freakonomics.com/podcast/the-cobra-effect-a-new-freakonomics-radio-podcast/">case</a> where British colonial officials in Delhi (India), set a bounty on dead cobras, in order to reduce the cobra population. However, this led citizens to breed the cobras for profit, and eventually to release them when the bounty was canceled.</p><p>A similar incident occurred circa 1902 in Hanoi (Vietnam), which was under French colonial rule at the time, when French officials sought to reduce the rat population in the city:</p><blockquote><p>“To fight the infestation citywide, the colonial administration added vigilantes to its team of professional killers. Appealing to both civic duty and to the pocketbook, a one-cent bounty was paid for each rat tail brought to the authorities (it was decided that the handing in of an entire rat corpse would create too much of a burden for the already taxed municipal health authorities).</p><p>Unfortunately, this scheme backfired. Despite initial apparent success, the authorities soon discovered that the best laid plans of mice and men often go awry. As soon the municipal administrators publicized the reward program, Vietnamese residents began to bring in thousands of tails. While many desk-bound administrators delighted in the numbers of apparently eliminated rats, more alert officials in the field began to notice a disturbing development. There were frequent sightings of rats without tails going about their business in the city streets. After some perplexity, the authorities realized that less-than-honest but quite resourceful characters were catching rats, but merely cutting off the tails and letting the still-living pests go free (perhaps to breed and produce more valuable tails).</p><p>Later, things became even more serious as health inspectors discovered a disturbing development in the suburbs of Hanoi. These officials found that more enterprising but equally deceptive individuals were actually raising rats to collect the bounty. One can only imagine the frustration of the municipal authorities, who realized that their best efforts at <em>dératisation</em> [extermination of rats] had actually increased the rodent population by indirectly encouraging rat-farming.”</p><p>— From “Of rats, rice, and race: The great Hanoi rat massacre, an episode in French colonial history” (Vann, <a href="https://doi.org/10.1353/fch.2003.0027">2003</a>)</p></blockquote><p>Finally, note that the phenomenon described by the Shirky principle—entities prolonging a problem to which they are the solution—isn’t necessarily the result of intentional actions. For example, a company may inadvertently perpetuate the problem that it solves, because its processes are so focused on the mediocre solution that they’re currently selling, that they don’t realize a better solution exists. Similarly, a company may discourage the use of a certain approach to solving a problem because it previously failed for them, even after technological advancements make this approach viable.</p><h2><span id="Origin_and_formulations_of_the_Shirky_principle"></span>Origin and formulations of the Shirky principle<span></span></h2><p>The Shirky principle was proposed in a <a href="http://web.archive.org/web/20210508141233/https:/kk.org/thetechnium/the-shirky-prin/">2010 blog post</a> by Kevin Kelly, editor of <em>Wired</em> magazine, who based it on the speaking and writing of scholar Clay Shirky.</p><p>Specifically, Kelly attributed the adage that “Institutions will try to preserve the problem to which they are the solution” to a statement that Shirky made in a recent talk, and noted that similar statements were made by Shirky in an associated blog post (“<a href="http://web.archive.org/web/20100404013927/http:/www.shirky.com/weblog/2010/04/the-collapse-of-complex-business-models/">The Collapse of Complex Business Models</a>”) and book (“<a href="https://amzn.to/3tqsrZz">Cognitive Surplus</a>”). There, Shirky states that “an organization that commits to helping society manage a problem also commits itself to the preservation of that same problem, as its institutional existence hinges on society’s continued need for its management”.</p><p>In addition to mentioning the key quote that is now known as the Shirky principle, Kelly also says the following in his <a href="http://web.archive.org/web/20210508141233/https:/kk.org/thetechnium/the-shirky-prin/">blog post</a>:</p><blockquote><p>“The Shirky Principle declares that complex solutions (like a company, or an industry) can become so dedicated to the problem they are the solution to, that often they inadvertently perpetuate the problem.”</p></blockquote><p>Later, he also says the following with regard to this principle (bold added here for emphasis):</p><blockquote><p>“In a strong sense we are defined by the problems we are solving. Yin/Yang, problem/solution, both sides form one unit. <strong>Because of the Shirky Principle, which says that every entity tends to prolong the problem it is solving</strong>, progress sometimes demands that we let go of problems.”</p></blockquote><p>Essentially, in his writing on the topic, Kelly offers three formulations of the Shirky principle, which differ in subtle but important ways:</p><ul><li>The first formulation—“Institutions will try to preserve the problem to which they are the solution”—refers to <em>institutions</em>, and states that they will <em>try</em> to preserve problems, which implies that they do so intentionally.</li><li>The second formulation—“Complex solutions (like a company, or an industry) can become so dedicated to the problem they are the solution to, that often they inadvertently perpetuate the problem”—refers to <em>complex solutions</em>, and states that they often <em>inadvertently</em> perpetuate the problem, which implies that they do so unintentionally.</li><li>The third formulation—”Every entity tends to prolong the problem it is solving”—refers to <em>entities</em>, and states that they <em>tend to</em> prolong problems, without making any claim about their intentions.</li></ul><p>The first formulation is the one that’s most commonly used when people discuss the Shirky principle, though Kelly does not actually refer to it as the Shirky principle in his original blog post. The third formulation, on the other hand, is the most general, though one issue with it is that it states that “every” entity engages in this kind of behavior, which is too absolute of a claim. However, this issue can be addressed by slightly changing this formulation, into “entities tend to prolong the problems they are solving”.</p><p><em>Note</em>: In <a href="http://web.archive.org/web/20210508141233/https:/kk.org/thetechnium/the-shirky-prin/">his post</a>, Kelly states that Shirky’s observation reminds him “of the clarity of the Peter Principle, which says that a person in an organization will be promoted to the level of their incompetence. At which point their past achievements will prevent them from being fired, but their incompetence at this new level will prevent them from being promoted again, so they stagnate in their incompetence.”.</p><h2><span id="Caveats_about_the_Shirky_principle"></span>Caveats about the Shirky principle<span></span></h2><p>There are some caveats about the Shirly principle that are important to keep in mind:</p><ul><li><strong>The Shirky principle is just a general observation.</strong> As such, there are many situations where it’s incorrect. For example, an institution may successfully solve the problem to which they are the solution because there’s greater profit to be made that way than by prolonging the problem.</li><li><strong>The Shirky principle can involve various types of entities.</strong> Though the best-known formulation of the Shirky principle refers to “institutions”, this principle can apply to various types of entities, including individuals and small social groups. This is noted in the general formulation of the principle (“every entity tends to prolong the problem it is solving”).</li><li><strong>The Shirky principle can involve various causes.</strong> For example, one company may prolong a problem unintentionally, due to passivity or inertia, whereas another company may prolong a problem intentionally, due to greed or self-preservation. This is reflected in the general formulation of this principle, which doesn’t make any claims regarding the causes or intentionality of this phenomenon.</li><li><strong>The Shirky principle can involve various patterns of behavior.</strong> For example, one company may prolong an existing problem by not dedicating resources to developing new solutions, whereas another company may actively prevent others from developing such solutions.</li></ul><p>In addition, the behaviors associated with the Shirly principle can vary in other ways. For example:</p><ul><li>An entity may not just preserve an existing problem, but also exacerbate it.</li><li>An entity may create a problem that did not previously exist, if they can be the solution to it.</li><li>An entity may perpetuate a problem that it benefits from, even if the entity is not actually a solution to the problem, though the entity may pretend that it is.</li></ul><p>Based on this, a broader version of Shirky’s principle can be expressed as:</p><blockquote><p>“Entities often promote problems that they benefit from”.</p></blockquote><h2><span id="Accounting_for_the_Shirky_principle"></span>Accounting for the Shirky principle<span></span></h2><p>Accounting for the Shirky principle can be beneficial when it comes to several things:</p><ul><li><strong>Understanding past and current behavior.</strong> For example, it can help you understand why certain institutions are seemingly so bad at solving certain problems, despite all the resources—like time, effort, and money—that they dedicate to those problems.</li><li><strong>Predicting future behavior.</strong> For example, it can help you predict that an executive will keep perpetuating a certain problem, in order to improve their own status within a company, even though this leads to worse outcomes for the company itself.</li><li><strong>Modifying behavior.</strong> For example, if this makes you aware of someone’s incentive to prolong a problem, that could lead you to either eliminate the perverse incentive or create a stronger disincentive. Similarly, this could lead you to point out the issue to the entity in question, in order to encourage them to try and change their behavior themselves if doing so can benefit them in the long term.</li></ul><p>When deciding how and whether to use your understanding of the Shirky principle in practice, it can help to assess relevant factors pertaining to your situation, such as what’s causing someone to act in accordance with this principle, and what outcomes their behavior leads to. For example, you will likely respond differently to a government agency that’s perpetuating a problem due to inefficient bureaucracy, than to a private company that’s perpetuating a problem out of greed, or to an individual who’s acting out of desperate self-preservation.</p><p>Finally, there are also two useful concepts worth keeping in mind when accounting for Shirky’s principle:</p><ul><li><a href="https://effectiviology.com/cui-bono/"><em><strong>Cui bono</strong></em></a>, which is a Latin phrase that means “who benefits?”, and which is used to suggest that there’s a high probability that those responsible for a certain event are the ones who stand to gain from it.</li><li><a href="https://effectiviology.com/hanlons-razor/"><em><strong>Hanlon’s razor</strong></em></a>, which is the adage that you should “never attribute to malice that which is adequately explained by stupidity”, and which, when applied broadly, suggests that when assessing people’s actions, you should not assume that they acted out of a desire to cause harm, as long as there is a reasonable alternative explanation.</li></ul><h2>Related concepts<span></span></h2><p><a href="https://effectiviology.com/parkinsons-law/"><em>Parkinson’s law</em></a> is the adage that “work expands so as to fill the time which is available for its completion” (or more generally, that “work expands to consume the resources available for its completion”). It relates to Shirky’s principle, since both concepts present a common way in which entities are inefficient or ineffective in dealing with problems that they’re supposed to solve.</p><p>Shirky’s principle also relates to another phenomenon that was <a href="https://doi.org/10.1088/1742-5468/2009/03/p03008">identified</a> by Parkinson, whereby the growth of a bureaucratic or administrative body is often associated with a substantial decrease in its overall efficiency. This is <a href="http://web.archive.org/web/20130331045219/http:/www.economist.com/node/14116121">attributed</a> to the desire of officials to increase the number of their subordinates, and to officials’ tendency to create work for each other.</p><p>In addition, a similar famous concept that’s related to Shirky’s principle has been expressed by novelist and social reformer Upton Sinclair, who <a href="http://web.archive.org/web/20210507155626/https:/www.oxfordreference.com/view/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00010168">said</a> that “It is difficult to get a man to understand something when his salary depends on his not understanding it.”</p><h2><span id="Summary_and_conclusions"></span>Summary and conclusions<span></span></h2><ul><li>The <em>Shirky principle</em> is the adage that “institutions will try to preserve the problem to which they are the solution”.</li><li>For example, the Shirky principle means that a government agency that’s meant to address a certain societal issue may hinder attempts by others to address the issue, in order to ensure that the agency remains relevant.</li><li>This principle can be expressed more broadly as “every entity tends to prolong the problem it is solving”, since it can involve entities other than institutions (e.g., individuals), and various patterns of behavior (e.g., unintentionally focusing on an outdated solution vs. intentionally interfering with competition).</li><li>This principle can also be extended to say that “entities often promote problems that they benefit from”, since entities can also create new problems, exacerbate existing ones, and perpetuate problems that they don’t actually solve.</li><li>Accounting for this principle can help understand past and current behavior, predict future behavior, and modify problematic behaviors (e.g., by removing perverse incentives).</li></ul><hr> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every single new Google product (123 pts)]]></title>
            <link>https://twitter.com/MarcosBL/status/1761094858205229430</link>
            <guid>39491795</guid>
            <pubDate>Sat, 24 Feb 2024 14:45:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/MarcosBL/status/1761094858205229430">https://twitter.com/MarcosBL/status/1761094858205229430</a>, See on <a href="https://news.ycombinator.com/item?id=39491795">Hacker News</a></p>
Couldn't get https://twitter.com/MarcosBL/status/1761094858205229430: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Understanding, using, and finetuning Gemma (114 pts)]]></title>
            <link>https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma</link>
            <guid>39491646</guid>
            <pubDate>Sat, 24 Feb 2024 14:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma">https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma</a>, See on <a href="https://news.ycombinator.com/item?id=39491646">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Joins the MapLibre Sponsorship Program (130 pts)]]></title>
            <link>https://maplibre.org/news/2024-02-20-msft-announcement/</link>
            <guid>39491349</guid>
            <pubDate>Sat, 24 Feb 2024 13:31:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maplibre.org/news/2024-02-20-msft-announcement/">https://maplibre.org/news/2024-02-20-msft-announcement/</a>, See on <a href="https://news.ycombinator.com/item?id=39491349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><time datetime=" 2024-02-20">Feb 20, 2024</time>
<span>·</span>
<span>1 minutes read</span></p></div><div><p>Microsoft joins the MapLibre Sponsorship Program as a Silver Sponsor.</p><p><img src="https://maplibre.org/news/2024-02-20-msft-announcement/maplibre-msft-logo.png" width="100%"></p><p>The Silver tier <a href="https://opencollective.com/maplibre/contributions/733415">donation</a> of USD 80,000 will be used to 20 percent for development of new features and to 80 percent for general maintenance of the MapLibre codebases and project coordination.</p><p>From the very beginning Microsoft was instrumental in building the MapLibre Organization and with the membership in the MapLibre Sponsorship Program, Microsoft lays out the foundation for a sustainable common future.</p><p>Microsoft uses MapLibre GL JS in both consumer and enterprise map products.</p><p>Bing Maps deploys MapLibre GL JS in production, a feat which was only possible thanks to performance improvements that were contributed to MapLibre by Bing Maps Engineers.</p><p>Azure Maps serves business customers all around the world with high-quality mapping products which are built on top of MapLibre GL JS.</p><p>We look forward to all the great contributions from Microsoft and are honored to have Microsoft as a Sponsor!</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everyone seems to forget why GNOME and GNOME 3 and Unity happened (2022) (141 pts)]]></title>
            <link>https://liam-on-linux.dreamwidth.org/85359.html</link>
            <guid>39490879</guid>
            <pubDate>Sat, 24 Feb 2024 11:51:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://liam-on-linux.dreamwidth.org/85359.html">https://liam-on-linux.dreamwidth.org/85359.html</a>, See on <a href="https://news.ycombinator.com/item?id=39490879">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>&nbsp;That is *what* it came from, yes, but not *why*.</p><p>The "why" part seems to be forgotten now: because Microsoft was threatening to sue all the Linux vendors shipping Windows 95-like desktops.</p><p>https://www.theregister.com/2006/11/20/microsoft_claims_linux_code</p><p>Microsoft invented the Win95 desktop from scratch. Its own previous Ones (e.g. Windows for Workgroups 3.11, Windows NT 3.51 and OS/2 1.x) looked nothing like it.</p><p>The task bar, the Start menu, the system tray, "My Computer", "Network Neighbourhood", all that: all original, *patented* Microsoft designs. There was nothing like it before.&nbsp;</p><p>(The closest was Acorn's RISC OS, with an "icon bar" that works very differently, on the Archimedes computer. A handful of those were imported to North America, and right after, NeXT "invented" the Dock, and then Microsoft invented the task bar which is quite a bit more sophisticated.</p><p>One source: the team that programmed it. Here's me moderating a panel discussion by most of the surviving members of Acorn's programming team, on video from a month ago:</p><p>https://www.youtube.com/watch?v=P_SDL0IwbCc</p><p>SUSE signed a patent-sharing deal:</p><p>https://www.theregister.com/2006/11/03/microsoft_novell_suse_linux/</p><p>Note: SUSE is the biggest German Linux company. (Source: I worked for them until last year.) KDE is a German project. SUSE developers did a lot of the work on KDE.&nbsp;</p><p>So, when SUSE signed up, KDE was safe.</p><p>Red Hat and Ubuntu refused to sign.</p><p>So, both needed *non* Windows like desktops, ASAP, without a Start menu, without a taskbar, without a window menu at top left and minimize/maximize/close at top right, and so on.</p><p>Red Hat is the main sponsor of GNOME development. (When KDE was first launched, Qt was not GPL, so Red Hat refused to bundle it or support it, and wrote its own environment instead.)</p><p>Ubuntu tried to get involved with the development of GNOME 3, and was rebuffed. So it went its own way with Unity instead: basically, a Mac OS X rip-off, only IMHO done better. Myself, I still use both Unity and macOS every day. They are like twins, and switching between them is very easy.</p><p>So both RH and Ubuntu switched to non-Windows-like desktops by default.</p><p>In the end MS did not sue anyone... but it got what it wanted: total chaos in the Linux desktop world.</p><p>Before the threats, almost everyone used GNOME 2. Even SUSE bundled GNOME because its corporate owner bought the main GNOME 3rd party developers, Ximian, and forcibly merged the company into SUSE:</p><p>https://www.theregister.com/2004/01/07/novell_marries_suse_to_ximian/</p><p>SUSE, Red Hat, Debian, Ubuntu, even Sun Solaris used GNOME 2. Everyone liked GNOME 2.</p><p>Then Microsoft rattled its sabre, and the FOSS UNIX world splintered in all directions.</p><p>RH uses GNOME 3. Ubuntu used Unity, alienated a lot of people who only knew how to use Windows-like desktops, and that made Mint a huge success. GNOME 2 got forked as MATE, and Mint adopted it, helping a lot. Mint also built its own fork of GNOME 3, Cinnamon. Formerly tiny niche desktops like Xfce and LXDE got a *huge* boost. Debian adopted GNOME 3 and systemd, annoying lots of its developers and causing the Devuan fork to happen.</p><p>Here's an analysis I wrote at the time:</p><p>https://www.theregister.com/2013/06/03/thank_microsoft_for_linux_desktop_fail/</p><p>Yes, Unity evolved out of the Ubuntu netbook desktop, but the reason _why_ it did is that Ubuntu was getting threatened.</p><p>(Xubuntu and Lubuntu and Kubuntu are not official and not the defaults, so they don't endanger it.)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to think about software quality (2022) (143 pts)]]></title>
            <link>https://www.evalapply.org/posts/how-to-not-die-by-a-thousand-cuts/index.html</link>
            <guid>39490543</guid>
            <pubDate>Sat, 24 Feb 2024 10:25:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.evalapply.org/posts/how-to-not-die-by-a-thousand-cuts/index.html">https://www.evalapply.org/posts/how-to-not-die-by-a-thousand-cuts/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39490543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="the-very-top">
        
  <main id="main">
    <article id="blog-post">
  <header>
    <div>
      <p>How To Not Die By A Thousand Cuts. Or, How To Think About Software Quality.</p>
      <p><span>↑ <a href="#site-header" rel="bookmark">menu</a></span>
           <span>↓ <a href="#blog-post-footer" rel="bookmark">discuss</a></span>
           <span>↓ <a href="#blog-post-toc" rel="bookmark">toc</a></span>
      </p>
      <p>Not a weighty meandering 300 page Zen dialogue on Motorcycle Maintenance. Merely a meandering blog post in which one contemplates /Quality/ of software products.</p>
      <p>
        <span>Published: 2022-01-20</span>
        <span>Updated: 2023-03-10</span>
        <span>Tags:  / <a href="https://www.evalapply.org/tags/quality/index.html#main">#quality</a> / <a href="https://www.evalapply.org/tags/risk/index.html#main">#risk</a> / <a href="https://www.evalapply.org/tags/systems/index.html#main">#systems</a>
        </span>
      </p>
      <hr>
    </div>
  </header>
  <section>
      <p id="blog-post-toc">
  <details open="">
    <summary>
      <strong>Contents</strong>
    </summary>
    <nav>
      <a href="#what-is-the-nature-of-software-products">What is the nature of software products?</a>
<a href="#whom-to-hold-responsible-for-software-quality-assurance">Whom to hold responsible for Software Quality Assurance?</a>
<a href="#why">Why?</a>
<a href="#is-it-different-for-different-kinds-of-products">Is it different for different kinds of products?</a>
<a href="#how-to-destroy-quality">How to destroy Quality?</a>
<a href="#how-to-create-quality">How to create Quality?</a>
<a href="#the-first-skill-is-to-learn-to-suffer-constructively.">The first skill is to learn to suffer constructively.</a>
<a href="#caveats-mea-culpa-etc.">Caveats, mea culpa, etc.</a>
    </nav>
  </details>
</p>
<hr>
  <p>First off, what even is Quality?</p>
<p>All things emerge, change, and die. I think <em>Quality</em> is the experience of the process. The idea of <em>Good Quality</em> essentially boils down to performing the process with grace, and leaving the place better than we found it.</p>
<p>Further, the process of emergence and change—i.e. living—is also the process of dying. It follows that to think clearly about the Quality of the former one must think clearly about the Quality of the latter. The saddest way it can unfold is a slow painful degradation without healing succour meaning or hope. The proverbial death by a thousand cuts. I hope you never witness such a passing, even from afar.</p>
<p>Ok, that got dark fast, and if we're not careful, we will produce a 300 page Zen dialogue on Motorcycle Maintenance. So we will distract ourselves with the much smaller, lighter—and I'd argue, even pleasant—task of contemplating Quality of software products.</p>
<p>None of what follows is novel, but I feel the message <em>and</em> its surrounding context bears repeating, because if it is not obvious already, software fails us all the time. Far too often with terrible consequences.</p>
<h2 id="what-is-the-nature-of-software-products">What is the nature of software products?</h2>
<p>See? This is already easier than asking "What is the nature of life?".</p>
<p>Like any other machine, a software product is wrought of the labour of many minds and hands, and it requires maintenance and upkeep throughout its life.</p>
<p>Unlike <em>all</em> other machines, it is pure concept, and as such it is infinitely malleable and mutable. And mutate it does, all the time.</p>
<p>Sometimes, "finished" software emerges, only needing minor fixes and patches, but remaining the same in purpose, interface, and behaviour. Many Unix tools fall in this category. Some projects like ZeroMQ make it their explicit goal. Many Clojure programmers value such "finished-ness". Such scattered examples exist.</p>
<p>Most software does not have this luxury. Most software must change indefinitely because the world it must serve changes indefinitely. The Emacs editor is a software product that has evolved non-stop for <em>nearly half a century</em> since it emerged in 1976, and it continues to thrive. This post was written in Emacs.</p>
<p>There is a strong reinforcing feedback loop too. Software changes the world fast, forcing software to change faster. The current reincarnation of Machine Learning and AI can be viewed as an expression of this process. We're basically saying it's all accelerating so much that it is getting humanly <em>impossible</em> to write and revise software fast enough, to out-OODA the pace of change. So we must instead find algorithms that sense the world and then dynamically generate or revise other algorithms to achieve system objectives (viz. alter the world further in our favour).</p>
<p>We have to wonder, how do we make sure our product continues to thrive and succeed under such unrelenting pressure of constant and sometimes violent change? And who's neck should be on the line for it?</p>
<h2 id="whom-to-hold-responsible-for-software-quality-assurance">Whom to hold responsible for Software Quality Assurance?</h2>
<p>The Usual Suspects?</p>
<ul>
<li>Those "Quality Assurance" boffins? Developers? UX people? DevOps?</li>
</ul>
<p>The Less Usual Suspects?</p>
<ul>
<li><p>Product managers? Analysts? Customer success? Sales? Marketing?</p></li>
<li><p>The CEO?</p></li>
<li><p>The AI?</p></li>
</ul>
<p>Consider the scenarios below. All of them directly impact customers, making them think "bad quality". Consider who is responsible for the underlying problem (or more likely, problems)?</p>
<ul>
<li>Your app framework is extremely performant and glitch-free. Your app bombs.</li>
<li>A feature does exactly what it promises, but people fail to use it right.</li>
<li>Your company committed half of itself to ship a second product in record time, but customers never really wanted it.</li>
<li>A huge update was pushed out on a do-or-die basis. Naturally it misbehaves, can't be rolled back, costs 5x as much to get right as it took to ship, and the rework effectively adds months to your plan of world domination.</li>
<li>Your service fails to scale. You discover there were no benchmarks.</li>
<li>A deployment breaks production. You discover a bad configuration.</li>
<li>A feature leaks data to unintended users and breaks SLAs / regulations. Your CEO releases a statement blaming a DevOps engineer.</li>
<li>A several-hour glitch goes un-monitored, causing serious widespread data corruption.</li>
<li>Your production noticeably degrades often. A large sea mammal is your mascot.</li>
<li>Your production seldom degrades, but when it does, it takes down half the known Internet along with it.</li>
<li>and on and on…</li>
</ul>
<p>In a quiet moment of honest self-reflection, you may confess to the mirror that the thousand cuts metaphor applies. That any of the above scenarios were likely the product of corner-cuts, often near-invisible to the naked eye in the moment. Corner-cuts that added up—nay, <em>compounded</em>—over time; slowly as band-aids, then as stitches and casts, and then suddenly as gangrene. And maybe the whole thing died of those cuts, or continued as a barely alive entity until someone had the heart to pull the plug (or offer a bail out).</p>
<p>You may even confess that maybe, just <em>maybe</em>, the job of assuring the goodness of a product belongs to <em>every function involved in the product's life</em>.</p>
<h2 id="why">Why?</h2>
<p>Suppose we model a traditional software production workflow, i.e. Analysis -&gt; Product requirements -&gt; UX/Design -&gt; Development -&gt; "QA" -&gt; Production.</p>
<p>Such a strictly linear model is common in the software industry at large. This is what it translates to in terms of time, complexity, costs, and risks.</p>
<pre><code>                                                              ^   Feedback
 Analysis -&gt; Product -&gt; UX/Design -&gt; Dev -&gt; "QA" -&gt;  Prod --./--&gt; arrives
                                                           /      too late
                                                         /-
                                                       /-
                                                     /- ^
                                                  /--   | Price of fixing
                                               /--      | errors and
                                           /---   ^     | corner cuts.
                                       /---       |     |
                                  /----   ^       |     | ~ AND/OR ~
                             /----        |       |     | Compounding of
                     /------   ^          |       |     | software debt.
            /--------          |          |       |     |
  ----------      ^            |          |       |     | ~ AND/OR ~
   ^              |            |          |       |     | Increasing odds
   |              |            |          |       |     | of being wrong.
---+--------------+------------+----------+-------+-----+----------------&gt;
                            Time, Complexity, Sunk costs
</code></pre>
<p>Visualising a linear workflow this way suggests some things:</p>
<ul>
<li>All the risk is actually front-loaded at the Analysis stage. If that is wrong, then everything is wrong.</li>
<li>The workflow looks linear, but has a compounding growth debt/risk profile.</li>
<li>By tasking a single group with "assuring" product quality, we maximize our odds of being too wrong too late, as well as of entirely failing to spot bad news.</li>
</ul>
<p>What's not obvious from the picture is that the risk is rooted in <em>feedback delays</em>. Weak signals die when the deliver pressure is high.</p>
<p>Our death-by-cuts risk profile will look the same, if the workflow is strictly linear as depicted above. It doesn't matter if we do it slowly in big batches over months, or faster as smaller batches over days. Small linearised batches may even worsen the aggregate risk profile, such as when market feedback loops are delayed or discontinuous. The smaller the batch, the more likely it is that feedback about several batches ago gets to us now. Such delayed feedback tends to severely disrupt strictly linear flows.</p>
<p>The above picture is also incomplete. For the full story, we need to talk deeply about systems (a longer conversation, for another day). We can make a small start by doing scenarios. Consider points on a product spectrum, ways to destroy/create quality, and what might help us go from worse to better?</p>
<h2 id="is-it-different-for-different-kinds-of-products">Is it different for different kinds of products?</h2>
<p>Suppose we contrast two typical ends of the product spectrum defined by primary customer. Which one risks death by a thousand cuts?</p>
<table>
<thead>
<tr>
<th>Trait</th>
<th>Enterprise Product</th>
<th>Consumer Product</th>
</tr>
</thead>
<tbody>
<tr>
<td>Key growth metric</td>
<td>Revenue Growth</td>
<td>User Growth</td>
</tr>
<tr>
<td>Key sales driver</td>
<td>Referrals + executive credibility</td>
<td>Referrals + Friends-and-family experiences</td>
</tr>
<tr>
<td>Customer risk</td>
<td>High risk/reward per account</td>
<td>Tiny unit economics per account</td>
</tr>
<tr>
<td>Contract risk</td>
<td>SLAs with crippling penalties</td>
<td>1 EULA / ToS that users don't read</td>
</tr>
<tr>
<td>etc …</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>Well, here's the thing. Not only does all software mutate, we <em>also</em> end up performing all kinds of deep surgery on the <em>organisation</em> that produces it. The whole thing—product and org—is <em>simultaneously</em> flexed, reconfigured, and even totally redesigned in-place with rapidity that is very uncommon in other industries. Why? Because software fundamentally is peoples' thoughts being played on repeat.</p>
<p>So however we break it down, the common theme is this. Every hotfix is a cut. Every complaint is a cut. Every app crash is a cut. Every service outage is a cut. And so on. Each cut heals slowly and destroys Quality and value(ation).</p>
<h2 id="how-to-destroy-quality">How to destroy Quality?</h2>
<p>It's useful to come up with ways to destroy quality, so that we may contrast those with ways to generate quality. I've seen and heard all of the following in work life so far (hopefully without actively perpetrating them, but memory is a fickle beast).</p>
<ul>
<li>Misconstrue and mislabel Software Testing as Quality Assurance. Testing is <em>not</em> "Quality Assurance".</li>
<li>Ostensibly make all teams responsible for their "QA", which really means make the least experienced people do it day-to-day.</li>
<li>Create a culture where it's normal to say things like this):
<ul>
<li>"Hey I'm adding this to the sprint. It's a small thing, so let's not slip our deadline."</li>
<li>"Testing is boring."</li>
<li>"We'll fix it if customers complain."</li>
<li>"Who the f*#$ wrote this code?"</li>
<li>"Ah yes, those are known flaky tests. Just re-trigger the build."</li>
<li>"You don't know your job. Ship this." (This one stung. I'll tell you over beer/coffee :).</li>
</ul></li>
<li>Ensure designers, developers, and testers work on tasks and priorities set by others.</li>
<li>Ensure someone catches the blame for mistakes.</li>
<li>Set up incentives to make departments compete with each other.</li>
<li>Hire a Vogon or a Darth Vader CEO.</li>
<li>Further <a href="https://danluu.com/wat/">normalise all kinds of deviance</a>.</li>
</ul>
<p>This was just a shortlist of things I recalled while writing this post. Think up as many ways as you can. #protip for inspiration: read CIA's now-declassified <a href="https://www.gutenberg.org/files/26184/page-images/26184-images.pdf">Simple Sabotage Field Manual</a>. Pay special attention to part 11: <em>General Interference with Organisations and Production</em>.</p>
<h2 id="how-to-create-quality">How to create Quality?</h2>
<p>One clue is to <em>not</em> do quality-destroying things. Another is to do the <em>inverse</em> of quality-destroying things (e.g. share know-how instead of hoarding it.) A third is to notice whether high-quality product producing organisations have any common traits (they do). Most important, perhaps, is to understand that there is no formula for how to acquire those traits.</p>
<p>To design and build high quality software products, it is imperative to design and build high quality organisation-wide systems and culture. We have many tools, frameworks, fundamental ideas at our disposal. But no "best practices" process or methodology or "one weird trick" style intervention can fix broken systems and broken people.</p>
<p>The "way" has to be co-evolved:</p>
<ul>
<li>by collaborative stakeholders,</li>
<li>spread across the org,</li>
<li>appropriate to the org's unique context,</li>
<li>along with customers, partners, and the immediate ecosystem.</li>
</ul>
<p>This is universally a very difficult process, with challenges surprisingly similar to what it takes to recover fitness after a year of slacking off. It requires mindset, leadership, and persistent holistic intelligent <em>eval/apply</em> behaviour. And all of that derives from <em>perspective</em>.</p>
<blockquote>
<p>"<em>Perspective is worth 80 IQ points.</em>"</p>
<p>— Alan Kay</p>
</blockquote>
<p>So, if we are to chart a course from Worse Quality to Better Quality, then it must be our first duty to purposely get really uncomfortable by seeking out new-to-us, diverse, status-quo-challenging perspective. And …</p>
<h2 id="the-first-skill-is-to-learn-to-suffer-constructively.">The first skill is to learn to suffer constructively.</h2>
<p>We suffer, you and I.</p>
<p>It is inevitable. Yet, it is also why life flourishes. <em>"Why are we suffering?"</em> is a great discussion to have, because constructive suffering yields quality outcomes.</p>
<p>OK, back to the real world…</p>
<p>The path to recovering a <em>previous</em> fitness peak after a year of slacking off is filled with sore muscles, cursing at the alarm clock, far too many days of being a generally irritable snappy person, and a constant mental battle against mainlining deliciously easy instant gratification. It gets harder before it gets easier. Then we reach the top of the previous S-curve. And we must begin the cycle again, to climb the next one.</p>
<p>We are very fortunate.</p>
<p>Fellow sufferers have been fostering quality-generative conversation and change all around us. We have access to a growing body of top-notch industry research <em>and</em> experience reports. Without exaggerating, very many of these lessons have been paid for in tears, blood, lives. Let's augment our intuitions with these power tools. Those hard-won <em>80 extra IQ points</em> are ours for the taking.</p>
<p>Some selected resources.</p>
<p>Many inputs have shaped my thinking about Quality (well, all the things, because everything is connected); people, events, books, lectures etc. If you're wondering where to go. These are not prescriptions, but a sort of sampling platter. Triggers for your own searches. Please send me more!</p>
<p>Systems:</p>
<ul>
<li><a href="https://www.chelseagreen.com/product/thinking-in-systems/">Thinking in Systems</a> is a great primer.</li>
</ul>
<p>Software complexity:</p>
<ul>
<li><a href="http://shaffner.us/cs/papers/tarpit.pdf">Out of The Tar Pit</a></li>
<li><a href="https://www.cgl.ucsf.edu/Outreach/pc204/NoSilverBullet.html">No Silver Bullet</a></li>
<li><a href="http://ecoplexity.org/files/uploads/Simon.pdf">The Architecture of Complexity</a></li>
<li><a href="https://www.youtube.com/watch?v=LKtk3HCgTa8&amp;list=PLZdCLR02grLrEwKaZv-5QbUzK0zGKOOcr&amp;index=18">Simple made Easy</a></li>
</ul>
<p>Failure:</p>
<ul>
<li><a href="https://www.researchgate.net/publication/228797158_How_complex_systems_fail">How Complex Systems Fail</a></li>
<li><a href="https://www.amazon.in/Human-Error-James-Reason/dp/0521314194/">Human Error</a></li>
<li><a href="https://safetydifferently.com/">Safety Differently</a></li>
</ul>
<p>Doing Together:</p>
<ul>
<li><a href="https://www.goodreads.com/book/show/13629.The_Mythical_Man_Month">The Mythical Man Month</a></li>
<li><a href="https://www.goodreads.com/book/show/6667514-the-checklist-manifesto">The Checklist Manifesto</a></li>
<li>Critical Chain Project Management (<a href="https://www.goodreads.com/book/show/113934.The_Goal">The Goal</a> is a fine place to start, if you have no idea what CCPM is.)</li>
<li><a href="https://www.goodreads.com/book/show/1501427.Managing_The_Design_Factory">Managing the Design Factory</a></li>
<li><a href="https://www.goodreads.com/book/show/6278270-the-principles-of-product-development-flow">The Principles of Product Development Flow</a></li>
<li><a href="http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/">Mature Optimization</a></li>
<li><a href="https://www.kaner.com/pdfs/GoodTest.pdf">What is a Good Test Case?</a></li>
</ul>
<p>Oneself (heavily biased, because I identify as a software programmer):</p>
<ul>
<li><a href="http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/">On Being a Senior Engineer</a></li>
<li><a href="http://www.arl.wustl.edu/projects/fpx/research/HowToBeAProgrammer.pdf">How to Be A Programmer</a></li>
<li><a href="https://www.goodreads.com/book/show/213233.Better">Better: A Surgeon's Notes on Performance</a></li>
<li><a href="https://www.youtube.com/watch?v=f84n5oFoZBc&amp;list=PLZdCLR02grLrEwKaZv-5QbUzK0zGKOOcr&amp;index=9">Hammock Driven Development</a></li>
</ul>
<p>"Practical philosophy", for lack of better words:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=QCwqnjxqfmY&amp;list=PLZdCLR02grLrEwKaZv-5QbUzK0zGKOOcr&amp;index=19">Design, Composition, Performance</a></li>
<li><a href="https://www.goodreads.com/book/show/324750.High_Output_Management">High Output Management</a></li>
<li><a href="https://www.semanticscholar.org/paper/Destruction-and-Creation-Boyd/483359fa9420efcddde5a17da597f462c2a788c2">Destruction and Creation</a></li>
<li>Stuff from <em><a href="https://www.theschooloflife.com/">The School of Life</a></em> (corny name, yes, but give it a chance :)</li>
</ul>
<p>I recently discovered Gene Kim's podcast, <a href="https://itrevolution.com/the-idealcast-podcast/">The Idealcast</a>. Gene is gathering fantastic people and resources in one place. Definitely have a look-see.</p>
<h2 id="caveats-mea-culpa-etc.">Caveats, mea culpa, etc.</h2>
<p>I am very much a work-in-progress, and this post is my current intuition.</p>
<p>The post is heavily coloured by many witting and uwitting eval/apply loops comprised of personal failures, ignorant mistakes, and occasional wins, over the last about 20 years of professional life. And well, life life. It is also informed by the good fortune of having learned by working with people who understand the world far better than I do. And obviously a lot of reading, thinking, talking, frequently "in anger" after having hit walls and obstacles.</p>
<p>So please take what is useful, and discard the rest.</p>
<p>May the source be with you _\\//</p>
  </section>
  
</article>
  </main>
      
      <!-- Cloudflare Web Analytics -->
      
      <!-- End Cloudflare Web Analytics -->
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes from an Interviewer (110 pts)]]></title>
            <link>https://devwithahammer.wordpress.com/2024/02/23/notes-from-an-interviewer/</link>
            <guid>39490404</guid>
            <pubDate>Sat, 24 Feb 2024 09:50:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devwithahammer.wordpress.com/2024/02/23/notes-from-an-interviewer/">https://devwithahammer.wordpress.com/2024/02/23/notes-from-an-interviewer/</a>, See on <a href="https://news.ycombinator.com/item?id=39490404">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-84">

			<span></span>
	
			<a href="https://devwithahammer.wordpress.com/2024/02/23/notes-from-an-interviewer/#respond">
			
		</a>
	
	
	<!-- .entry-header .fullwidth-block -->

	<div>
		
<div><p>These days I find myself interviewing quite a few candidates. Some are good, some aren’t. So it goes. However, there is another group who I feel could be good but just aren’t showing it in the interview. I think I was probably in this group earlier in my career. So, in a bid to help my younger self, and hopefully somebody else, here’s some things to consider.</p><p><strong>1. Know the Basics</strong></p></div>



<p>If you google ‘top 10 X interview questions’ where X is your technology, and a question is on that list you should probably know the answer. It turns out that interviewers aren’t that original so you’ll find the same questions cropping up again and again. There’s definitely a debate to be had about whether interviewers should ask more original questions, but we are where we are. At least score the easy goals.</p>



<p><br><strong>2. Know why not (just) what</strong></p>



<div><p>Great you know what idempotency is but why is it a useful property? There’s probably no quicker way to tell the difference between a junior who knows a lot and an experience dev than the ability to articulate why things are the way they are. </p><p>For instance, take the SOLID design principles. Uncle Bob has said that it’s about trying to create a <a href="https://blog.cleancoder.com/uncle-bob/2014/05/12/TheOpenClosedPrinciple.html">Plugin Architecture</a> similar to that found in, for instances, IDEs. SOLID isn’t just a bunch of sentences that you’re supposed to spout out in an interview, it’s a set of guidelines intended to achieve a certain purpose. Of course, whether it actually achieves that purpose is another matter (see 3.). </p><p>This is important for a whole host of reasons but primarily, how can you be trusted to make decisions about what technologies/approaches to take if you don’t understand their purpose.</p></div>



<p><br><strong>3. Express Opinions</strong></p>



<div><p>If a company wanted you to be a dumb vessel for received wisdom you probably wouldn’t want to work there. Just like knowing that things are they way they are for a reason, we should also know that those reasons aren’t valid in certain scenarios.</p><p>I used to ask ‘tell me one of the SOLID principle you strongly agree or disagree with’ but I had to stop because it ended up with the interviewee listing/describing the SOLID principles rather than critiquing them.</p><p>Another question I like to ask is what is a feature you would add/remove from your language of choice. If I disagree with you, that’s not an issue. Just like the songs Lennon and McCartney wrote together were better than the ones they wrote after, contrasting opinions on a team bring new insights and better decisions.</p></div>



<div><p><strong>4. Listen to the Interviewer</strong></p><p>I’m genuinely surprised at how often interviewee don’t listener to the interviewer. The question about SOLID (see 3.) is an example of not listening to the actual question which is more common than it should be. However, there is another form of not listening that’s more destructive to a candidates chances.</p><p>I’m sometimes in a practical part of the interview where a certain part isn’t going well. It’ll be a point to note, but not a deal-breaker. At that point I’m unlikely to gain any more information from that section so I’ll be keen to get to another section where I can get more useful information, and hopefully they can do better. At this point I’ll try to offer the interviewee some hints or maybe even just tell them what to move them along. However, on quite a number of occasions this advice has been flat out ignored and the candidates have kept ploughing on with whatever failing approach they were using. To put it bluntly, the initial inability may not have been a deal-breaker but ignoring advice is.</p><p><strong>5. Be Upbeat<br></strong><br>As a final point. A bit of enthusiasm can help a lot. You should never worry if you drop a few clangers because it’s rare that successful candidates are perfect. Probably more importantly, if you are borderline, is that you haven’t left the interviewer with the impression that they’ve been pulling teeth.</p><p>And last of all, Best of Luck!</p></div>

			
						</div><!-- .center-block .entry-content -->

	<!-- .center-block .entry-meta -->
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments .comments-area -->

		
		</main><!-- #main .site-main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A modest update to Qubes OS (142 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/962787/35f1ff3af9031437/</link>
            <guid>39490264</guid>
            <pubDate>Sat, 24 Feb 2024 09:13:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/962787/35f1ff3af9031437/">https://lwn.net/SubscriberLink/962787/35f1ff3af9031437/</a>, See on <a href="https://news.ycombinator.com/item?id=39490264">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-trial,v 1.1 2005-11-04 21:27:01 corbet Exp $ -->
<center>
<table>
<tbody><tr><td>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider accepting the trial offer on the right.  Thank you
for visiting LWN.net!
</p></td><td>
<div>
<h3>Free trial subscription</h3>
           <p>
           Try LWN for free for 1 month: no payment
           or credit card required.  <a href="https://lwn.net/Promo/slink-trial2-3/claim">Activate
           your trial subscription now</a> and see why thousands of
           readers subscribe to LWN.net.
           
</p></div>
</td>
</tr>

</tbody></table>
</center>

<p><a href="https://www.qubes-os.org/">Qubes OS</a> is a security-focused desktop Linux distribution built on Fedora Linux and the <a href="https://www.qubes-os.org/faq/#why-does-qubes-use-xen-instead-of-kvm-or-some-other-hypervisor">Xen hypervisor</a>. Qubes uses virtualization to run applications, system services, and devices access via virtual machines called "<a href="https://www.qubes-os.org/doc/glossary/#qube">qubes</a>" that have varying levels of trust and <a href="https://www.qubes-os.org/doc/how-to-use-disposables/">persistence</a> to provide an open-source "<q>reasonably secure</q>" operating system with "<q>serious privacy</q>". The Qubes 4.2.0 release, from <a href="https://www.qubes-os.org/doc/releases/4.2/release-notes/">December 2023</a>, brings a number of refinements to make Qubes OS easier to manage and use.</p>

<h4>A quick overview</h4>

<p>Qubes OS is designed to be a single-user desktop operating system that provides strong security out of the box through isolation between applications and services, rather than trying to ensure that the applications or services are secure in and of themselves. The vision for Qubes is laid out in the Qubes OS <a href="https://www.qubes-os.org/attachment/doc/arch-spec-0.3.pdf">architecture document</a> written in 2010. While that specification isn't fully implemented yet, each release brings Qubes a bit closer to the ideal.</p>

<p>As currently implemented, Qubes uses the Xen hypervisor to run a Fedora-based <a href="https://www.qubes-os.org/doc/glossary/#admin-qube">admin qube</a> (<a href="https://www.qubes-os.org/doc/glossary/#dom0">dom0</a>) with direct hardware access that provides administration and orchestration of unprivileged guest domains (<a href="https://www.qubes-os.org/doc/glossary/#domu">domU</a>) based on <a href="https://www.qubes-os.org/doc/templates/">templates</a> (VM data stored as LVM volumes) that are used to run applications (<a href="https://www.qubes-os.org/doc/glossary/#app-qube">app qubes</a>) or provide services (<a href="https://www.qubes-os.org/doc/glossary/#service-qube">service qubes</a>) like networking, USB access, and more to the app qubes. For example, networking and firewall services are each provided by separate system qubes ("sys-net" and "sys-firewall", respectively), and access to USB devices is through "sys-usb". Note that the Qubes website and documentation tend to use the term "VM" and "qube" interchangeably.</p>

<p>Templates are the starting point for app and system qubes—app qubes take their root file system (that is, programs and system files) from templates. Any software that users want to persist in an app qube should be installed in a template, rather than an app qube, otherwise it will be discarded when the app qube restarts. If a user wants Emacs or LibreOffice, the Qubes way is to install it into one of the templates and then spin up an app qube based on that template to use the application.</p>

<p>Each qube has a level of trust somewhere between "unsafe and untrusted" to "safe and ultimately trusted". The admin qube, for example, is considered safe and ultimately trusted. The sys-net and sys-usb qubes are considered untrusted, and the firewall qube is considered moderately trusted. Qubes OS ties all of that together and presents the user with a coherent desktop experience. To the user, it is meant to feel like using a regular desktop environment and applications, rather than using half-dozen or more VMs that are unaware of one another. Qube windows are displayed with <a href="https://www.qubes-os.org/doc/getting-started/#color--security">colored borders</a>, to give users visual cues about which qube is running the application and its safety level.</p>

<blockquote>
<a href="https://lwn.net/Articles/962902/"><img src="https://static.lwn.net/images/2024/qubes-desktop-sm.png" alt="[Qubes OS desktop]" title="Qubes OS desktop"></a>
</blockquote>

<p>LWN last looked at Qubes ahead of the <a href="https://lwn.net/Articles/873255/">4.1.0 release</a> in October 2021. That release made major overhauls to the Qubes architecture, splitting out display handling to its <a href="https://www.qubes-os.org/doc/gui-domain/">own domain</a> and making changes to the <a href="https://www.qubes-os.org/news/2020/06/22/new-qrexec-policy-system/">Qrexec</a> policy system. This release follows up those changes with a number of more user-visible changes such as rewrites of several Qubes GUI management tools, simpler <a href="https://www.qubes-os.org/doc/split-gpg/">split GPG</a> management (which lets users store private GPG keys in a trusted qube and make use of them in less trusted qubes), changes to default Fedora and Debian templates, and more.</p>

<p>Qubes's approach to security means a more complex, and <a href="https://lwn.net/Articles/764048/">sometimes cumbersome</a>, user experience. Moving from a Linux distribution like Fedora or Debian to Qubes OS will take more adjustment than one might expect. For example, installing software on a Fedora desktop is usually as simple as "<tt>dnf&nbsp;install&nbsp;package</tt>". But installing software to use within a Fedora-based qube requires <a href="https://www.qubes-os.org/doc/how-to-install-software/">several additional steps</a> on Qubes OS, plus restarting VMs. Other activities, such as configuring a Bluetooth input or audio device is much more complicated and not well-documented. Then again, it's also not encouraged—Bluetooth isn't <a href="https://forum.qubes-os.org/t/wireless-bluetooth-support/5943">considered secure</a>, so why focus on making it easier to configure? But when it comes to using Qubes OS as intended, this release includes some major work to add polish and improve the user experience.</p>

<h4>GUI application improvements</h4>

<p>One of the first improvements users will notice is the redesigned <a href="https://www.qubes-os.org/news/2021/11/12/new-qubes-application-menu/">application menu</a>, first made available as a preview in Qubes 4.1, and now the default. On a "normal" Linux distribution, the menu of applications generally only has to display one version of Firefox, one terminal, one file manager, and so forth. Qubes, however, helps users work more securely by compartmentalizing applications to qubes by task or profile. How users <a href="https://www.qubes-os.org/doc/how-to-organize-your-qubes/">organize</a> their work is up to them, but Qubes offers "work", "personal", and "untrusted" qubes by default—each qube with its own installation of Firefox, terminal, and file manager. (These are color coded when running, so users might see a yellow border for personal applications, a blue border for work, and red for untrusted.)</p>

<p>The Qubes model of separating activities into isolated compartments is good for security—users can visit untrusted sites in the untrusted qube, restrict banking to another qube, and separate work in yet another qube—but more challenging to present in a user-friendly fashion. Prior versions of Qubes had a <a href="https://forum.qubes-os.org/t/guide-xfce-global-dark-mode-in-qubes-4-0-4-1/10757">single-menu layout</a> that was unwieldy as the number of applications, templates, and services grew. The current application menu organizes application qubes, template qubes, and service qubes separately, and breaks out Qubes tools like the global configuration and policy editor into their own menu. The effect is still busy compared to a "regular" desktop distribution, but it does seem a marked improvement over the old menu. The ability to add applications from various qubes to a Favorites menu is a great improvement, though there is no obvious way to configure the application menu to display favorites immediately when first opened. Perhaps this will show up in the next Qubes release—if it does, it will probably appear in the Qubes global configuration application.</p>

<p>The global configuration application in 4.2.0 represents work that the project started discussing in September 2021. In <a href="https://github.com/QubesOS/qubes-issues/issues/6898">the ticket</a> discussing the design, Nina Eleanor Alter described target demographics for the global UI as non-technical, high-risk users, and technical users "<q>excited about Qubes but lacking the attention span or time to copiously read whitepapers or the docs</q>". Alter said that Linux users may be comfortable with multiple applets to configure system behaviors but, "<q>it delivers a poor execution and discovery experience to all users</q>"; and users coming from Windows or macOS expect a single settings UI.</p>

<p>The idea is to make Qubes more discoverable, and the new UI does this by bringing together settings for file access, clipboard handling, updates, USB devices, URL handling, miscellaneous general settings, and device information. Users have a single GUI for working with system-wide settings that were not particularly discoverable in prior versions, such as setting up split GPG.</p>

<p>The Create New Qube application has been updated too, though Qubes 4.2.0 seems to have shipped with the old and new applications with different labels in the Applications Menu. The new application is titled "Create New Qube" and the old application is listed as "Create Qubes VM", though both show "Create New Qube" in the title bar when running.</p>

<blockquote>
<a href="https://lwn.net/Articles/962902#create"><img src="https://static.lwn.net/images/2024/qubes-create-new-side-sm.png" alt="[Create New Qubes applications]" title="Create New Qubes applications"></a>
</blockquote>

<p>As shown in the screenshot, the new and improved version provides access to more options and settings, as well as some guidance provided via tooltips. (One note on tooltips in Qubes—while working in Qubes, tooltips displayed in various applications lingered long after moving the mouse, switching windows, or even navigating to another workspace.) The current iteration of the Create New Qube application does seem more intuitive than the old, and provides the ability choose the default applications available, set initial RAM for the qube, and more.</p>

<p>The Qubes Update application (appropriately) received an update in this release as well. Qubes includes Fedora, Debian, and Whonix templates as part of the default installation and provides access to many others. Over time it would be trivial to have half-a-dozen template OSes that need regular updates. The Update application streamlines this by checking in the background for updates and then notifying of updates for running qubes at regular intervals. It will also attempt to perform updates every seven days for templates that are not used in that timeframe, though this interval is configurable, or users can update them manually. After updates have been staged, the updater will offer to restart qubes based on the updated templates. Qubes that have running applications will not be targeted for restart by default, so users can run updates without fear that Qubes will unceremoniously shut down their work.</p>

<h4>Template updates</h4>

<p>Another interesting change with this release the <a href="https://github.com/QubesOS/qubes-issues/issues/7784">use of Xfce</a> editions for Fedora and Debian instead of GNOME to <a href="https://github.com/QubesOS/qubes-issues/issues/7028">reduce memory usage</a> and provide a better selection of default applications. Marek Marczykowski-Górecki said that Fedora's GNOME template has too many "<q>problematic</q>" packages that "<q>either conflict with something or simply don't work with our GUI agent</q>". The project had been looking for ways to slim memory usage in Fedora qubes for some time, with a number of GNOME packages targeted for exclusion, including <a href="https://github.com/QubesOS/qubes-issues/issues/8403">GNOME Tracker</a>. Note that the Qubes OS default desktop has been Xfce <a href="https://www.qubes-os.org/doc/releases/3.2/release-notes/">since</a> the <a href="https://lwn.net/Articles/705827/">3.2 release</a> in September 2016.</p>

<p>Support for SELinux in Fedora templates has been a long time in coming. The <a href="https://github.com/QubesOS/qubes-issues/issues/4239">issue</a> tracking the work was opened in 2018, while the <a href="https://github.com/QubesOS/qubes-issues/issues/4239#issuecomment-1419947028">work finally landed</a> in February 2023 and then made its way into the 4.2.0 release. One might wonder why exactly users might need or want SELinux in Fedora qubes, given that Qubes OS is meant to be a single-user system. Each qube is already isolated from others and and the user has full run of each qube. Templates, for example, allow <a href="https://www.qubes-os.org/doc/vm-sudo/">sudo with no password</a> because all of the user data in a running qube is available to the same person anyway, so there's little sense in forcing them to type a password every time they use <tt>sudo</tt>. Even though Qubes does little to restrict user privileges within each qube, Marczykowski-Górecki <a href="https://github.com/QubesOS/qubes-issues/issues/4239#issuecomment-1712660098">noted</a> that the addition of SELinux is useful for applications that provide sandboxing inside a Fedora template, like Podman or bubblewrap, and also help provide extra hardening when using <tt>qvm-copy</tt> to send files between qubes.</p>

<h4>A modest update</h4>

<p>Overall, 4.2.0 is a somewhat modest update in terms of new features—though it does contain plenty of the usual version updates and <a href="https://github.com/QubesOS/qubes-issues/issues?q=is%3Aissue+is%3Aclosed+reason%3Acompleted+milestone%3A%22Release+4.2%22+-label%3A%22R%3A+cannot+reproduce%22+-label%3A%22R%3A+declined%22+-label%3A%22R%3A+duplicate%22+-label%3A%22R%3A+not+applicable%22+-label%3A%22R%3A+self-closed%22+-label%3A%22R%3A+upstream+issue%22+">bug fixes</a>. But the focus on improving Qubes OS usability is important. While popular Linux distributions like Fedora or Ubuntu count users in the millions, the Qubes project <a href="https://www.qubes-os.org/statistics/">counts</a> its users in the tens of thousands. Surely more users need what Qubes has to offer, but security tools that are too hard to use tend not to be used. Bolstering Qubes usability is just as important as striving toward implementing the Qubes architecture specification.</p><br clear="all">
               <br clear="all">
               <blockquote>
<p>
<b>Did you like this article?</b>  Please accept our 
<a href="https://lwn.net/Promo/slink-trial2-3/claim">trial subscription offer</a> to be
able to see more content like it and to participate in the discussion.
</p>
</blockquote>
<hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/962787/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
    </channel>
</rss>