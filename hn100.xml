<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 28 Nov 2023 11:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Noyb files GDPR complaint against Meta over "Pay or Okay" (103 pts)]]></title>
            <link>https://noyb.eu/en/noyb-files-gdpr-complaint-against-meta-over-pay-or-okay</link>
            <guid>38443292</guid>
            <pubDate>Tue, 28 Nov 2023 07:20:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noyb.eu/en/noyb-files-gdpr-complaint-against-meta-over-pay-or-okay">https://noyb.eu/en/noyb-files-gdpr-complaint-against-meta-over-pay-or-okay</a>, See on <a href="https://news.ycombinator.com/item?id=38443292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
                    

<p><strong>Today, <em>noyb </em>filed a complaint against Meta with the Austrian data protection authority. European users now have the “choice” to either consent to being tracked for personalized advertising – or pay up to €251.88 a year to retain their fundamental right to data protection on Instagram and Facebook. Not only is the cost unacceptable, but industry numbers suggest that only 3 percent of people want to be tracked – while more than 99 percent decide against a payment when faced with a “privacy fee”. If Meta gets away with this, competitors will soon follow in its footsteps. Given that the average phone has 35 apps installed, keeping your phone private could soon cost around € 8,815 a year.</strong></p>

<ul><li><a href="https://noyb.eu/sites/default/files/2023-11/Complaint%20-%20Meta%20Pay%20or%20Okay%20-%20REDACTED.pdf">Complaint with the Austrian data protection authority (automated machine-translation)</a></li>
</ul><p><strong>Another attempt to circumvent EU privacy laws.</strong> The European Court of Justice (CJEU) <a href="https://noyb.eu/en/cjeu-declares-metafacebooks-gdpr-approach-largely-illegal">ruled in July</a> that Meta’s handling of user data for personalized ads was illegal. But not only that: In January, the European Data Protection Board <a href="https://noyb.eu/en/breaking-meta-prohibited-use-personal-data-advertising">fined Meta €390 million</a> for this violation and ordered the company to obtain users’ consent, based on a <em>noyb </em><a href="https://noyb.eu/en/noybeu-filed-complaints-over-forced-consent-against-google-instagram-whatsapp-and-facebook">complaint from 2018</a>. In its next attempt to undermine EU law, Meta now wants to charge people for choosing a privacy-friendly setting. Since the beginning of November, Instagram and Facebook users have had to choose between paying up to €251.88 a year or having their personal data surveilled for targeted advertising.</p>

<p><strong>“Freely given” consent at a high price?</strong> Under EU law, consent to online tracking and personalized advertising is only valid if it is “freely given”. This is to ensure that users only give up their fundamental right to privacy if it is their genuine free will to do so. Meta has now implemented the exact opposite of a genuinely free choice: Facebook alone will introduce a “privacy fee” of up to €12.99 per month if users do not consent to their personal data being processed for targeted advertising. Each linked account (such as Instagram) will cost another €8, making a total of €251.88 a year for one person using Instagram and Facebook. By comparison: <a href="https://s21.q4cdn.com/399680738/files/doc_earnings/2023/q3/presentation/Earnings-Presentation-Q3-2023.pdf">Meta says</a> its average revenue per user in Europe between Q3 2022 and Q3 2023 was $16.79. This equates to an annual revenue of just €62,88 per user – and puts the monthly fee way out of proportion.</p>

<p>Felix Mikolasch, data protection lawyer at <em>noyb</em>: <em>“EU law requires that consent is the genuine free will of the user. Contrary to this law, Meta charges a “privacy fee” of up to €250 per year if anyone dares to exercise their fundamental right to data protection.”</em></p>

<p><strong>3 to 10 percent want personalized ads – but 99.9 percent consent.</strong> All available scientific research suggests that so-called “Pay or Okay” systems are the antithesis of free consent and fundamentally affect the “free will” of users. For example, <a href="https://arxiv.org/pdf/2309.11625.pdf">the CEO of the “Pay or Okay” provider contentpass</a> stated that 99,9 percent of visitors agree to tracking when faced with a € 1,99 fee. At the same time, <a href="https://noyb.eu/sites/default/files/2020-05/Gallup_Facebook_DE.pdf">objective surveys suggest</a> that only 3 to 10 percent of users want their personal data to be used for targeted advertising.</p>

<p>Max Schrems, Chairman of <em>noyb</em>:<em> “When 3 percent of people actually want to swim, but 99.9 percent end up in the water, every child knows that it wasn’t a “free” choice. It’s neither smart nor legal – it’s just pitiful how Meta continues to ignore EU law.”</em></p>

<p><strong>Data protection could soon cost €35,000 per family.</strong> If Meta is successful in defending this new approach, it is likely to set off a domino effect. Already now, <a href="https://techcrunch.com/2023/10/02/tiktok-begins-testing-4-99-ad-free-subscription-tier/">TikTok is reportedly testing</a> an ad-free subscription outside the US. Other app providers could follow in the near future, making online privacy unaffordable. <a href="https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/average-number-of-apps-on-smartphones/">According to Google</a>, the average person has 35 apps installed on their smartphone. If all of these apps followed Meta’s lead and charged a similar fee, people would have to pay a “fundamental rights fee” of €8,815.80 a year. For a family of four, the price of data privacy would rise to €35,263.20 per year - more than the average full-time income in the EU. Obviously, these figures become even more extreme in EU Member States with lower average incomes.</p>

<p>Max Schrems:<em> “Fundamental rights are usually available to everyone. How many people would still exercise their right to vote if they had to pay € 250 to do so? There were times when fundamental rights were reserved for the rich. It seems Meta wants to take us back for more than a hundred years.”</em></p>

<p><strong>Privacy only for the rich. </strong>While this price is extremely high in general, it also completely ignores the very different income levels in EU countries – and the fact that <a href="https://ec.europa.eu/eurostat/documents/15234730/17582411/KS-HA-23-001-EN-N.pdf/5d783d9e-9cb3-897c-8360-5122563ae8f3?version=6.0&amp;t=1700579783008">21.6% of the EU population is at risk of poverty or social exclusion</a>. The complainant in this case, for example, is in financial distress and receives unemployment assistance. He simply cannot afford to pay another €250 a year, when he is already struggling to pay his rent.</p>

<p>Max Schrems:<em> “More than 20% of the EU population are already at risk of poverty. For the complainant in our case, as for many others, a ‘Pay or Okay’ system would mean paying the rent or having privacy.”</em></p>

<p><strong>The DPA should initiate an urgency procedure.</strong> Given the seriousness of the violations and the unusually high number of users affected, <em>noyb </em>urges the Austrian data protection authority to initiate an urgency procedure to stop the illegal processing. In addition, <em>noyb </em>suggests that the authority imposes a deterrent fine, making sure that no other company starts copying Meta’s approach.</p>
            
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Designing a SIMD Algorithm from Scratch (102 pts)]]></title>
            <link>https://mcyoung.xyz/2023/11/27/simd-base64/</link>
            <guid>38443253</guid>
            <pubDate>Tue, 28 Nov 2023 07:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mcyoung.xyz/2023/11/27/simd-base64/">https://mcyoung.xyz/2023/11/27/simd-base64/</a>, See on <a href="https://news.ycombinator.com/item?id=38443253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><span> <span> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> <a href="https://mcyoung.xyz/tags.html#optimization">#optimization</a> </span> <span> 2023-11-27 </span> </span></p> <p>Another explainer on a fun, esoteric topic: optimizing code with SIMD (single instruction multiple data, also sometimes called <em>vectorization</em>). Designing a good, fast, portable SIMD algorithm is not a simple matter and requires thinking a little bit like a circuit designer.</p> <p>Here’s the mandatory performance benchmark graph to catch your eye.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph.png" alt="perf perf perf"></p> <p>“SIMD” often gets thrown around as a buzzword by performance and HPC (high performance computing) nerds, but I don’t think it’s a topic that has very friendly introductions out there, for a lot of reasons.</p> <ul> <li>It’s not something you will really want to care about unless you think performance is cool.</li> <li>APIs for programming with SIMD in most programming languages are <em>garbage</em> (I’ll get into why).</li> <li>SIMD algorithms are hard to think about if you’re very procedural-programming-brained. A functional programming mindset can help a lot.</li> </ul> <p>This post is mostly about <a href="https://docs.rs/vb64/latest/vb64/"><code>vb64</code></a> (which stands for <em>v</em>ector <em>b</em>ase<em>64</em>), a base64 codec I wrote to see for myself if Rust’s <code>std::simd</code> library is any good, but it’s also an excuse to talk about SIMD in general.</p> <p>What <em>is</em> SIMD, anyways? Let’s dive in.</p> <p>If you want to skip straight to the writeup on <code>vb64</code>, click <a href="#parsing-with-simd">here</a>.</p> <h2 id="problems-with-physics"><a href="#problems-with-physics">Problems with Physics</a></h2> <p>Unfortunately, computers exist in the real world<sup>[citation-needed]</sup>, and are bound by the laws of nature. SIMD has relatively little to do with theoretical CS considerations, and everything to do with <em>physics</em>.</p> <p>In the infancy of modern computing, you could simply improve performance of existing programs by buying new computers. This is often incorrectly attributed to Moore’s law (the number of transistors on IC designs doubles every two years). Moore’s law still appears to hold as of 2023, but some time in the last 15 years the <a href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a> effect broke down. This means that denser transistors eventually means increased power dissipation density. In simpler terms, we don’t know how to continue to increase the clock frequency of computers without literally <em>liquefying</em> them.</p> <p>So, since the early aughts, the hot new thing has been bigger core counts. Make your program more multi-threaded and it will run faster on bigger CPUs. This comes with synchronization overhead, since now the cores need to cooperate. All control flow, be it jumps, virtual calls, or synchronization will result in “stall”.</p> <p>The main causes of stall are <em>branches</em>, instructions that indicate code can take one of two possible paths (like an <code>if</code> statement), and <em>memory operations</em>. Branches include all control flow: <code>if</code> statements, loops, function calls, function returns, even <code>switch</code> statements in C. Memory operations are loads and stores, especially ones that are cache-unfriendly.</p> <h3 id="procedural-code-is-slow"><a href="#procedural-code-is-slow">Procedural Code Is Slow</a></h3> <p>Modern compute cores do not execute code line-by-line, because that would be very inefficient. Suppose I have this program:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>a</span> <span>=</span> <span>x</span> <span>+</span> <span>y</span><span>;</span>
<span>let</span> <span>b</span> <span>=</span> <span>x</span> <span>^</span> <span>y</span><span>;</span>
<span>println!</span><span>(</span><span>"{a}, {b}"</span><span>);</span></code></pre></figure></div> <p>There’s no reason for the CPU to wait to finish computing <code>a</code> before it begins computing <code>b</code>; it does not depend on <code>a</code>, and while the add is being executed, the xor circuits are idle. Computers say “program order be damned” and issue the add for <code>a</code> and the xor for <code>b</code> simultaneously. This is called <em>instruction-level parallelism</em>, and dependencies that get in the way of it are often called <em>data hazards</em>.</p> <p>Of course, the Zen 2 in the machine I’m writing this with does not have one measly adder per core. It has dozens and dozens! The opportunities for parallelism are massive, as long as the compiler in your CPU’s execution pipeline can clear any data hazards in the way.</p> <p>The better the core can do this, the more it can saturate all of the “functional units” for things like arithmetic, and the more numbers it can crunch per unit time, approaching maximum utilization of the hardware. Whenever the compiler can’t do this, the execution pipeline stalls and your code is slower.</p> <p>Branches stall because they need to wait for the branch condition to be computed before fetching the next instruction (speculative execution is a somewhat iffy workaround for this). Memory operations stall because the data needs to physically arrive at the CPU, and the speed of light is finite in this universe.</p> <p>Trying to reduce stall by improving opportunities for single-core parallelism is not a new idea. Consider the not-so-humble GPU, whose purpose in life is to render images. Images are vectors of pixels (i.e., color values), and rendering operations tend to be highly local. For example, a convolution kernel for a Gaussian blur will be two or even three orders of magnitude smaller than the final image, lending itself to locality.</p> <p>Thus, GPUs are built for divide-and-conquer: they provide primitives for doing batched operations, and extremely limited control flow.</p> <p>“SIMD” is synonymous with “batching”. It stands for “single instruction, multiple data”: a single instruction dispatches parallel operations on multiple <em>lanes</em> of data. GPUs are the original SIMD machines.</p> <h2 id="lane-wise"><a href="#lane-wise">Lane-wise</a></h2> <p>“SIMD” and “vector” are often used interchangeably. The fundamental unit a SIMD instruction (or “vector instruction”) operates on is a vector: a fixed-size array of numbers that you primarily operate on component-wise These components are called <em>lanes</em>.</p> <p>SIMD vectors are usually quite small, since they need to fit into registers. For example, on my machine, the largest vectors are 256 bits wide. This is enough for 32 bytes (a <code>u8x32</code>), 4 double-precision floats (an <code>f64x8</code>), or all kinds of things in between.</p> <p><img src="https://mcyoung.xyz/public/simd-img/vectors.png" alt="some 256-bit vectors"></p> <p>Although this doesn’t seem like much, remember that offloading the overhead of keeping the pipeline saturated by a factor of 4x can translate to that big of a speedup in latency.</p> <h3 id="one-bit-lanes"><a href="#one-bit-lanes">One-bit Lanes</a></h3> <p>The simplest vector operations are bitwise: and, or, xor. Ordinary integers can be thought of as vectors themselves, with respect to the bitwise operations. That’s literally what “bitwise” means: lanes-wise with lanes that are one bit wide. An <code>i32</code> is, in this regard, an <code>i1x32</code>.</p> <p>In fact, as a warmup, let’s look at the problem of counting the number of 1 bits in an integer. This operation is called “population count”, or <code>popcnt</code>. If we view an <code>i32</code> as an <code>i1x32</code>, <code>popcnt</code> is just a fold or reduce operation:</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>popcnt</span><span>(</span><span>mut</span> <span>x</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>bits</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>32</span><span>];</span>
  <span>for</span> <span>(</span><span>i</span><span>,</span> <span>bit</span><span>)</span> <span>in</span> <span>bits</span><span>.iter_mut</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
    <span>*</span><span>bit</span> <span>=</span> <span>(</span><span>x</span> <span>&gt;&gt;</span> <span>i</span><span>)</span> <span>&amp;</span> <span>1</span><span>;</span>
  <span>}</span>
  <span>bits</span><span>.into_iter</span><span>()</span><span>.fold</span><span>(</span><span>0</span><span>,</span> <span>|</span><span>total</span><span>,</span> <span>bit</span><span>|</span> <span>total</span> <span>+</span> <span>bit</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>In other words, we interpret the integer as an array of bits and then add the bits together to a 32-bit accumulator. Note that the accumulator needs to be higher precision to avoid overflow: accumulating into an <code>i1</code> (as with the <code>Iterator::reduce()</code> method) will only tell us whether the number of 1 bits is even or odd.</p> <p>Of course, this produces… comically bad code, frankly. We can do much better if we notice that we can <em>vectorize</em> the addition: first we add all of the adjacent pairs of bits together, then the pairs of pairs, and so on. This means the number of adds is logarithmic in the number of bits in the integer.</p> <p>Visually, what we do is we “unzip” each vector, shift one to line up the lanes, add them, and then repeat with lanes twice as big.</p> <p><img src="https://mcyoung.xyz/public/simd-img/popcnt.png" alt="first two popcnt merge steps"></p> <p>This is what that looks like in code.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>popcnt</span><span>(</span><span>mut</span> <span>x</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
  <span>// View x as a i1x32, and split it into two vectors</span>
  <span>// that contain the even and odd bits, respectively.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x55555555</span><span>;</span> <span>// 0x5 == 0b0101.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xaaaaaaaa</span><span>;</span> <span>// 0xa == 0b1010.</span>
  <span>// Shift odds down to align the bits, and then add them together.</span>
  <span>// We interpret x now as a i2x16. When adding, each two-bit</span>
  <span>// lane cannot overflow, because the value in each lane is</span>
  <span>// either 0b00 or 0b01.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>1</span><span>);</span>

  <span>// Repeat again but now splitting even and odd bit-pairs.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x33333333</span><span>;</span> <span>// 0x3 == 0b0011.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xcccccccc</span><span>;</span> <span>// 0xc == 0b1100.</span>
  <span>// We need to shift by 2 to align, and now for this addition</span>
  <span>// we interpret x as a i4x8.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>2</span><span>);</span>

  <span>// Again. The pattern should now be obvious.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x0f0f0f0f</span><span>;</span> <span>// 0x0f == 0b00001111.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xf0f0f0f0</span><span>;</span> <span>// 0xf0 == 0b11110000.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>4</span><span>);</span> <span>// i8x4</span>

  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x00ff00ff</span><span>;</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xff00ff00</span><span>;</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>8</span><span>);</span>  <span>// i16x2</span>

  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x0000ffff</span><span>;</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xffff0000</span><span>;</span>
  <span>// Because the value of `x` is at most 32, although we interpret this as a</span>
  <span>// i32x1 add, we could get away with just one e.g. i16 add.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>16</span><span>);</span>

  <span>x</span> <span>// Done. All bits have been added.</span>
<span>}</span></code></pre></figure></div> <p>This still won’t optimize down to a <code>popcnt</code> instruction, of course. The search scope for such a simplification is in the regime of superoptimizers. However, the generated code is small and fast, which is why this is the ideal implementation of <code>popcnt</code> for systems without such an instruction.</p> <p>It’s <em>especially</em> nice because it is implementable for e.g. <code>u64</code> with only one more reduction step (remember: it’s <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log n)</annotation></semantics></math></span></span></span>!), and does not at any point require a full <code>u64</code> addition.</p> <p>Even though this is “just” using scalars, divide-and-conquer approaches like this are the bread and butter of the SIMD programmer.</p> <h3 id="scaling-up-operations-on-real-vectors"><a href="#scaling-up-operations-on-real-vectors">Scaling Up: Operations on Real Vectors</a></h3> <p>Proper SIMD vectors provide more sophisticated semantics than scalars do, particularly because there is more need to provide replacements for things like control flow. Remember, control flow is slow!</p> <p>What’s actually available is highly dependent on the architecture you’re compiling to (more on this later), but the way vector instruction sets are usually structured is something like this.</p> <p>We have <em>vector registers</em> that are kind of like really big general-purpose registers. For example, on x86, most “high performance” cores (like my Zen 2) implement AVX2, which provides 256 bit <code>ymm</code> vectors. The registers themselves do not have a “lane count”; that is specified by the instructions. For example, the “vector byte add instruction” interprets the register as being divided into eight-byte lanes and adds them. The corresponding x86 instruction is <code>vpaddb</code>, which interprets a <code>ymm</code> as an <code>i8x32</code>.</p> <p>The operations you usually get are:</p> <ol> <li> <p>Bitwise operations. These don’t need to specify a lane width because it’s always implicitly <code>1</code>: they’re <em>bit</em>wise.</p> </li> <li> <p>Lane-wise arithmetic. This is addition, subtraction, multiplication, division (both int and float), and shifts<sup id="fnref:shifts-are-arithmetic" role="doc-noteref"><a href="#fn:shifts-are-arithmetic" rel="footnote">1</a></sup> (int only). Lane-wise min and max are also common. These require specifying a lane width. Typically the smallest number of lanes is two or four.</p> </li> <li> <p>Lane-wise compare. Given <code>a</code> and <code>b</code>, we can create a new <em>mask vector</em> <code>m</code> such that <code>m[i] = a[i] &lt; b[i]</code> (or any other comparison operation). A mask vector’s lanes contain boolean values with an unusual bit-pattern: all-zeros (for false) or all-ones (for true)<sup id="fnref:minus-true" role="doc-noteref"><a href="#fn:minus-true" rel="footnote">2</a></sup>.</p> <ul> <li>Masks can be used to select between two vectors: for example, given <code>m</code>, <code>x</code>, and <code>y</code>, you can form a fourth vector <code>z</code> such that <code>z[i] = m[i] ? a[i] : b[i]</code>.</li> </ul> </li> <li> <p>Shuffles (sometimes called swizzles). Given <code>a</code> and <code>x</code>, create a third vector <code>s</code> such that <code>s[i] = a[x[i]]</code>. <code>a</code> is used as a lookup table, and <code>x</code> as a set of indices. Out of bounds produces a special value, usually zero. This emulates parallelized array access without needing to actually touch RAM (RAM is extremely slow).</p> <ul> <li>Often there is a “shuffle2” or “riffle” operation that allows taking elements from one of two vectors. Given <code>a</code>, <code>b</code>, and <code>x</code>, we now define <code>s</code> as being <code>s[i] = (a ++ b)[x[i]]</code>, where <code>a ++ b</code> is a double-width concatenation. How this is actually implemented depends on architecture, and it’s easy to build out of single shuffles regardless.</li> </ul> </li> </ol> <p>(1) and (2) are ordinary number crunching. Nothing deeply special about them.</p> <p>The comparison and select operations in (3) are intended to help SIMD code stay “branchless”. Branchless code is written such that it performs the same operations regardless of its inputs, and relies on the properties of those operations to produce correct results. For example, this might mean taking advantage of identities like <code>x * 0 = 0</code> and <code>a ^ b ^ a = b</code> to discard “garbage” results.</p> <p>The shuffles described in (4) are much more powerful than meets the eye.</p> <p>For example, “broadcast” (sometimes called “splat”) makes a vector whose lanes are all the same scalar, like Rust’s <code>[42; N]</code> array literal. A broadcast can be expressed as a shuffle: create a vector with the desired value in the first lane, and then shuffle it with an index vector of <code>[0, 0, ...]</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/broadcast.png" alt="diagram of a broadcast"></p> <p>“Interleave” (also called “zip” or “pack”) takes two vectors <code>a</code> and <code>b</code> and creates two new vectors <code>c</code> and <code>d</code> whose lanes are alternating lanes from <code>a</code> and <code>b</code>. If the lane count is <code>n</code>, then <code>c = [a[0], b[0], a[1], b[1], ...]</code> and <code>d = [a[n/2], b[n/2], a[n/2 + 1], b[n/2 + 1], ...]</code>. This can also be implemented as a shuffle2, with shuffle indices of <code>[0, n, 1, n + 1, ...]</code>. “Deinterleave” (or “unzip”, or “unpack”) is the opposite operation: it interprets a pair of vectors as two halves of a larger vector of pairs, and produces two new vectors consisting of the halves of each pair.</p> <p>Interleave can also be interpreted as taking a <code>[T; N]</code>, transmuting it to a <code>[[T; N/2]; 2]</code>, performing a matrix transpose to turn it into a <code>[[T; 2]; N/2]</code>, and then transmuting that back to <code>[T; N]</code> again. Deinterleave is the same but it transmutes to <code>[[T; 2]; N/2]</code> first.</p> <p><img src="https://mcyoung.xyz/public/simd-img/interleave.png" alt="diagram of a interleave"></p> <p>“Rotate” takes a vector <code>a</code> with <code>n</code> lanes and produces a new vector <code>b</code> such that <code>b[i] = a[(i + j) % n]</code>, for some chosen integer <code>j</code>. This is yet another shuffle, with indices <code>[j, j + 1, ..., n - 1, 0, 1, ... j - 1]</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/rotate.png" alt="diagram of a rotate"></p> <p>Shuffles are worth trying to wrap your mind around. SIMD programming is all about reinterpreting larger-than-an-integer-sized blocks of data as smaller blocks of varying sizes, and shuffling is important for getting data into the right “place”.</p> <h3 id="intrinsics-and-instruction-selection"><a href="#intrinsics-and-instruction-selection">Intrinsics and Instruction Selection</a></h3> <p>Earlier, I mentioned that what you get varies by architecture. This section is basically a giant footnote.</p> <p>So, there’s two big factors that go into this.</p> <ol> <li>We’ve learned over time which operations tend to be most useful to programmers. x86 might have something that ARM doesn’t because it “seemed like a good idea at the time” but turned out to be kinda niche.</li> <li>Instruction set extensions are often market differentiators, even within the same vendor. Intel has AVX-512, which provides even more sophisticated instructions, but it’s only available on high-end server chips, because it makes manufacturing more expensive.</li> </ol> <p>Toolchains generalize different extensions as “target features”. Features can be detected at runtime through architecture-specific magic. On Linux, the <code>lscpu</code> command will list what features the CPU advertises that it recognizes, which correlate with the names of features that e.g. LLVM understands. What features are enabled for a particular function affects how LLVM compiles it. For example, LLVM will only emit <code>ymm</code>-using code when compiling with <code>+avx2</code>.</p> <p>So how do you write portable SIMD code? On the surface, the answer is mostly “you don’t”, but it’s more complicated than that, and for that we need to understand how the later parts of a compiler works.</p> <p>When a user requests an add by writing <code>a + b</code>, how should I decide which instruction to use for it? This seems like a trick question… <em>just</em> an <code>add</code> right? On x86, even this isn’t so easy, since you have a choice between the actual <code>add</code> instruction, or a <code>lea</code> instruction (which, among other things, preserves the <code>rflags</code> register). This question becomes more complicated for more sophisticated operations. This general problem is called <em>instruction selection</em>.</p> <p>Because which “target features” are enabled affects which instructions are available, they affect instruction selection. When I went over operations “typically available”, this means that compilers will usually be able to select good choices of instructions for them on most architectures.</p> <p>Compiling with something like <code>-march=native</code> or <code>-Ctarget-cpu=native</code> gets you “the best” code possible for the machine you’re building on, but it might not be portable<sup id="fnref:abi" role="doc-noteref"><a href="#fn:abi" rel="footnote">3</a></sup> to different processors. Gentoo was quite famous for building packages from source on user machines to take advantage of this (not to mention that they loved using <code>-O3</code>, which mostly exists to slow down build times with little benefit).</p> <p>There is also runtime feature detection, where a program decides which version of a function to call at runtime by asking the CPU what it supports. Code deployed on heterogenous devices (like cryptography libraries) often make use of this. Doing this correctly is very hard and something I don’t particularly want to dig deeply into here.</p> <p>The situation is made worse by the fact that in C++, you usually write SIMD code using “intrinsics”, which are special functions with inscrutable names like <code>_mm256_cvtps_epu32</code> that represent a low-level operation in a specific instruction set (this is a float to int cast from AVX2). Intrinsics are defined by hardware vendors, but don’t necessarily map down to single instructions; the compiler can still optimize these instructions by merging, deduplication, and through instruction selection.</p> <p>As a result you wind up writing the same code multiple times for different instruction sets, with only minor maintainability benefits over writing assembly.</p> <p>The alternative is a portable SIMD library, which does some instruction selection behind the scenes at the library level but tries to rely on the compiler for most of the heavy-duty work. For a long time I was skeptical that this approach would actually produce good, competitive code, which brings us to the actual point of this article: using Rust’s portable SIMD library to implement a somewhat fussy algorithm, and measuring performance.</p> <h2 id="parsing-with-simd"><a href="#parsing-with-simd">Parsing with SIMD</a></h2> <p>Let’s design a SIMD implementation for a well-known algorithm. Although it doesn’t look like it at first, the power of shuffles makes it possible to parse text with SIMD. And this parsing can be very, very fast.</p> <p>In this case, we’re going to implement base64 decoding. To review, base64 is an encoding scheme for arbitrary binary data into ASCII. We interpret a byte slice as a bit vector, and divide it into six-bit chunks called <em>sextets</em>. Then, each sextet from 0 to 63 is mapped to an ASCII character:</p> <ol> <li><code>0</code> to <code>25</code> go to <code>'A'</code> to <code>'Z'</code>.</li> <li><code>26</code> to <code>51</code> go to <code>'a'</code> to <code>'z'</code>.</li> <li><code>52</code> to <code>61</code> go to <code>'0'</code> to <code>'9'</code>.</li> <li><code>62</code> goes to <code>+</code>.</li> <li><code>63</code> goes to <code>/</code>.</li> </ol> <p>There <em>are</em> other variants of base64, but the bulk of the complexity is the same for each variant.</p> <p>There are a few basic pitfalls to keep in mind.</p> <ol> <li> <p>Base64 is a “big endian” format: specifically, the bits in each byte are big endian. Because a sextet can span only parts of a byte, this distinction is important.</p> </li> <li> <p>We need to beware of cases where the input length is not divisible by 4; ostensibly messages should be padded with <code>=</code> to a multiple of 4, but it’s easy to just handle messages that aren’t padded correctly.</p> </li> </ol> <p>The length of a decoded message is given by this function:</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decoded_len</span><span>(</span><span>input</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
  <span>input</span> <span>/</span> <span>4</span> <span>*</span> <span>3</span> <span>+</span> <span>match</span> <span>input</span> <span>%</span> <span>4</span> <span>{</span>
    <span>1</span> <span>|</span> <span>2</span> <span>=&gt;</span> <span>1</span><span>,</span>
    <span>3</span> <span>=&gt;</span> <span>2</span><span>,</span>
    <span>_</span> <span>=&gt;</span> <span>0</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>Given all this, the easiest way to implement base64 is something like this.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span> <span>{</span>
  <span>// Tear off at most two trailing =.</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>// Split the input into chunks of at most 4 bytes.</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>bytes</span> <span>=</span> <span>0u32</span><span>;</span>
    <span>for</span> <span>&amp;</span><span>byte</span> <span>in</span> <span>chunk</span> <span>{</span>
      <span>// Translate each ASCII character into its corresponding</span>
      <span>// sextet, or return an error.</span>
      <span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
        <span>b'A'</span><span>..=</span><span>b'Z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'A'</span><span>,</span>
        <span>b'a'</span><span>..=</span><span>b'z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'a'</span> <span>+</span> <span>26</span><span>,</span>
        <span>b'0'</span><span>..=</span><span>b'9'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'0'</span> <span>+</span> <span>52</span><span>,</span>
        <span>b'+'</span> <span>=&gt;</span> <span>62</span><span>,</span>
        <span>b'/'</span> <span>=&gt;</span> <span>63</span><span>,</span>
        <span>_</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>(</span><span>...</span><span>)),</span>
      <span>};</span>

      <span>// Append the sextet to the temporary buffer.</span>
      <span>bytes</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
      <span>bytes</span> <span>|</span><span>=</span> <span>sextet</span> <span>as</span> <span>u32</span><span>;</span>
    <span>}</span>

    <span>// Shift things so the actual data winds up at the</span>
    <span>// top of `bytes`.</span>
    <span>bytes</span> <span>&lt;&lt;=</span> <span>32</span> <span>-</span> <span>6</span> <span>*</span> <span>chunk</span><span>.len</span><span>();</span>

    <span>// Append the decoded data to `out`, keeping in mind that</span>
    <span>// `bytes` is big-endian encoded.</span>
    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>bytes</span><span>.to_be_bytes</span><span>()[</span><span>..</span><span>decoded</span><span>]);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>So, what’s the process of turning this into a SIMD version? We want to follow one directive with inexorable, robotic dedication.</p> <p><strong>Eliminate all branches.</strong></p> <p>This is not completely feasible, since the input is of variable length. But we can try. There are several branches in this code:</p> <ol> <li>The <code>for chunk in</code> line. This one is is the length check: it checks if there is any data left to process.</li> <li>The <code>for &amp;byte in</code> line. This is the hottest loop: it branches once per input byte.</li> <li>The <code>match byte</code> line is several branches, to determine which of the five “valid” match arms we land in.</li> <li>The <code>return Err</code> line. Returning in a hot loop is extra control flow, which is not ideal.</li> <li>The call to <code>decoded_len</code> contains a <code>match</code>, which generates branches.</li> <li>The call to <code>Vec::extend_from_slice</code>. This contains not just branches, but potential calls into the allocator. Extremely slow.</li> </ol> <p>(5) is the easiest to deal with. The <code>match</code> is mapping the values <code>0, 1, 2, 3</code> to <code>0, 1, 1, 2</code>. Call this function <code>f</code>. Then, the sequence given by <code>x - f(x)</code> is <code>0, 0, 1, 1</code>. This just happens to equal <code>x / 2</code> (or <code>x &gt;&gt; 1</code>), so we can write a completely branchless version of <code>decoded_len</code> like so.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>decoded_len</span><span>(</span><span>input</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
  <span>let</span> <span>mod4</span> <span>=</span> <span>input</span> <span>%</span> <span>4</span><span>;</span>
  <span>input</span> <span>/</span> <span>4</span> <span>*</span> <span>3</span> <span>+</span> <span>(</span><span>mod4</span> <span>-</span> <span>mod4</span> <span>/</span> <span>2</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>That’s one branch eliminated<sup id="fnref:why-cant-llvm-do-it" role="doc-noteref"><a href="#fn:why-cant-llvm-do-it" rel="footnote">4</a></sup>. ✅</p> <p>The others will not prove so easy. Let’s turn our attention to the innermost loop next, branches (2), (3), and (4).</p> <h3 id="the-hottest-loop"><a href="#the-hottest-loop">The Hottest Loop</a></h3> <p>The superpower of SIMD is that because you operate on so much data at a time, you can unroll the loop so hard it becomes branchless.</p> <p>The insight is this: we want to load at most four bytes, do something to them, and then spit out at most three decoded bytes. While doing this operation, we may encounter a syntax error so we need to report that somehow.</p> <p>Here’s some facts we can take advantage of.</p> <ol> <li>We don’t need to figure out how many bytes are in the “output” of the hot loop: our handy branchless <code>decoded_len()</code> does that for us.</li> <li>Invalid base64 is extremely rare. We want that syntax error to cost as little as possible. If the user still cares about which byte was the problem, they can scan the input for it after the fact.</li> <li><code>A</code> is zero in base64. If we’re parsing a truncated chunk, padding it with <code>A</code> won’t change the value<sup id="fnref:pad-with-A" role="doc-noteref"><a href="#fn:pad-with-A" rel="footnote">5</a></sup>.</li> </ol> <p>This suggests an interface for the body of the “hottest loop”. We can factor it out as a separate function, and simplify since we can assume our input is always four bytes now.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>4</span><span>])</span> <span>-&gt;</span> <span>([</span><span>u8</span><span>;</span> <span>3</span><span>],</span> <span>bool</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>bytes</span> <span>=</span> <span>0u32</span><span>;</span>
  <span>let</span> <span>mut</span> <span>ok</span> <span>=</span> <span>true</span><span>;</span>
  <span>for</span> <span>byte</span> <span>in</span> <span>ascii</span> <span>{</span>
    <span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
      <span>b'A'</span><span>..=</span><span>b'Z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'A'</span><span>,</span>
      <span>b'a'</span><span>..=</span><span>b'z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'a'</span> <span>+</span> <span>26</span><span>,</span>
      <span>b'0'</span><span>..=</span><span>b'9'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'0'</span> <span>+</span> <span>52</span><span>,</span>
      <span>b'+'</span> <span>=&gt;</span> <span>62</span><span>,</span>
      <span>b'/'</span> <span>=&gt;</span> <span>63</span><span>,</span>
      <span>_</span> <span>=&gt;</span> <span>!</span><span>0</span><span>,</span>
    <span>};</span>

    <span>bytes</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
    <span>bytes</span> <span>|</span><span>=</span> <span>sextet</span> <span>as</span> <span>u32</span><span>;</span>
    <span>ok</span> <span>|</span><span>=</span> <span>byte</span> <span>==</span> <span>!</span><span>0</span><span>;</span>
  <span>}</span>

  <span>// This is the `to_be_bytes()` call.</span>
  <span>let</span> <span>[</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>b3</span><span>,</span> <span>_</span><span>]</span> <span>=</span> <span>bytes</span><span>.to_le_bytes</span><span>();</span>
  <span>([</span><span>b3</span><span>,</span> <span>b2</span><span>,</span> <span>b1</span><span>],</span> <span>ok</span><span>)</span>
<span>}</span>

<span>// In decode()...</span>
<span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>4</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>4</span><span>];</span>
  <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

  <span>let</span> <span>(</span><span>bytes</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>);</span>
  <span>if</span> <span>!</span><span>ok</span> <span>{</span>
    <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>)</span>
  <span>}</span>

  <span>let</span> <span>len</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
  <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>bytes</span><span>[</span><span>..</span><span>decoded</span><span>]);</span>
<span>}</span></code></pre></figure></div> <p>You’re probably thinking: why not return <code>Option&lt;[u8; 3]&gt;</code>? Returning an enum will make it messier to eliminate the <code>if !ok</code> branch later on (which we will!). We want to write branchless code, so let’s focus on finding a way of producing that three-byte output without needing to do early returns.</p> <p>Now’s when we want to start talking about vectors rather than arrays, so let’s try to rewrite our function as such.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span> <span>{</span>
  <span>unimplemented!</span><span>()</span>
<span>}</span></code></pre></figure></div> <p>Note that the output is now four bytes, not three. SIMD lane counts need to be powers of two, and that last element will never get looked at, so we don’t need to worry about what winds up there.</p> <p>The callsite also needs to be tweaked, but only slightly, because <code>Simd&lt;u8, 4&gt;</code> is <code>From&lt;[u8; 4]&gt;</code>.</p> <h3 id="ascii-to-sextet"><a href="#ascii-to-sextet">ASCII to Sextet</a></h3> <p>Let’s look at the first part of the <code>for byte in ascii</code> loop. We need to map each lane of the <code>Simd&lt;u8, 4&gt;</code> to the corresponding sextet, and somehow signal which ones are invalid. First, notice something special about the <code>match</code>: almost every arm can be written as <code>byte - C</code> for some constant <code>C</code>. The non-range case looks a little silly, but humor me:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
  <span>b'A'</span><span>..=</span><span>b'Z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'A'</span><span>,</span>
  <span>b'a'</span><span>..=</span><span>b'z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'a'</span> <span>+</span> <span>26</span><span>,</span>
  <span>b'0'</span><span>..=</span><span>b'9'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'0'</span> <span>+</span> <span>52</span><span>,</span>
  <span>b'+'</span>        <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'+'</span> <span>+</span> <span>62</span><span>,</span>
  <span>b'/'</span>        <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'/'</span> <span>+</span> <span>63</span><span>,</span>
  <span>_</span> <span>=&gt;</span> <span>!</span><span>0</span><span>,</span>
<span>};</span></code></pre></figure></div> <p>So, it should be sufficient to build a vector <code>offsets</code> that contains the appropriate constant <code>C</code> for each lane, and then <code>let sextets = ascii - offsets;</code></p> <p>How can we build <code>offsets</code>? Using compare-and-select.</p> <div><figure><pre><code data-lang="rust"><span>// A lane-wise version of `x &gt;= start &amp;&amp; x &lt;= end`.</span>
<span>fn</span> <span>in_range</span><span>(</span><span>bytes</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>start</span><span>:</span> <span>u8</span><span>,</span> <span>end</span><span>:</span> <span>u8</span><span>)</span> <span>-&gt;</span> <span>Mask</span><span>&lt;</span><span>i8</span><span>,</span> <span>4</span><span>&gt;</span> <span>{</span>
  <span>bytes</span><span>.simd_ge</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>start</span><span>))</span> <span>&amp;</span> <span>bytes</span><span>.simd_le</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>end</span><span>))</span>
<span>}</span>

<span>// Create masks for each of the five ranges.</span>
<span>// Note that these are disjoint: for any two masks, m1 &amp; m2 == 0.</span>
<span>let</span> <span>uppers</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b'A'</span><span>,</span> <span>b'Z'</span><span>);</span>
<span>let</span> <span>lowers</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b'a'</span><span>,</span> <span>b'z'</span><span>);</span>
<span>let</span> <span>digits</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b'0'</span><span>,</span> <span>b'9'</span><span>);</span>
<span>let</span> <span>pluses</span> <span>=</span> <span>ascii</span><span>.simd_eq</span><span>([</span><span>b'+'</span><span>;</span> <span>N</span><span>]</span><span>.into</span><span>());</span>
<span>let</span> <span>solidi</span> <span>=</span> <span>ascii</span><span>.simd_eq</span><span>([</span><span>b'/'</span><span>;</span> <span>N</span><span>]</span><span>.into</span><span>());</span>

<span>// If any byte was invalid, none of the masks will select for it,</span>
<span>// so that lane will be 0 in the or of all the masks. This is our</span>
<span>// validation check.</span>
<span>let</span> <span>ok</span> <span>=</span> <span>(</span><span>uppers</span> <span>|</span> <span>lowers</span> <span>|</span> <span>digits</span> <span>|</span> <span>pluses</span> <span>|</span> <span>solidi</span><span>)</span><span>.all</span><span>();</span>

<span>// Given a mask, create a new vector by splatting `value`</span>
<span>// over the set lanes.</span>
<span>fn</span> <span>masked_splat</span><span>(</span><span>mask</span><span>:</span> <span>Mask</span><span>&lt;</span><span>i8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>value</span><span>:</span> <span>i8</span><span>)</span> <span>-&gt;</span> <span>Simd</span><span>&lt;</span><span>i8</span><span>,</span> <span>4</span><span>&gt;</span> <span>{</span>
  <span>mask</span><span>.select</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>val</span><span>),</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>0</span><span>))</span>
<span>}</span>

<span>// Fill the the lanes of the offset vector by filling the</span>
<span>// set lanes with the corresponding offset. This is like</span>
<span>// a "vectorized" version of the `match`.</span>
<span>let</span> <span>offsets</span> <span>=</span> <span>masked_splat</span><span>(</span><span>uppers</span><span>,</span>  <span>65</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>lowers</span><span>,</span>  <span>71</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>digits</span><span>,</span>  <span>-</span><span>4</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>pluses</span><span>,</span> <span>-</span><span>19</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>solidi</span><span>,</span> <span>-</span><span>16</span><span>);</span>

<span>// Finally, Build the sextets vector.</span>
<span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span><span>.cast</span><span>::</span><span>&lt;</span><span>i8</span><span>&gt;</span><span>()</span> <span>-</span> <span>offsets</span><span>;</span></code></pre></figure></div> <p>This solution is quite elegant, and will produce very competitive code, but it’s not actually ideal. We need to do a lot of comparisons here: eight in total. We also keep lots of values alive at the same time, which might lead to unwanted register pressure.</p> <h3 id="simd-hash-table"><a href="#simd-hash-table">SIMD Hash Table</a></h3> <p>Let’s look at the byte representations of the ranges. <code>A-Z</code>, <code>a-z</code>, and <code>0-9</code> are, as byte ranges, <code>0x41..0x5b</code>, <code>0x61..0x7b</code>, and <code>0x30..0x3a</code>. Notice they all have different high nybbles! What’s more, <code>+</code> and <code>/</code> are <code>0x2b</code> and <code>0x2f</code>, so the function <code>byte &gt;&gt; 4</code> is <em>almost</em> enough to distinguish all the ranges. If we subtract one if <code>byte == b'/'</code>, we have a <em>perfect hash</em> for the ranges.</p> <p>In other words, the value <code>(byte &gt;&gt; 4) - (byte == '/')</code> maps the ranges as follows:</p> <ul> <li><code>A-Z</code> goes to 4 or 5.</li> <li><code>a-z</code> goes to 6 or 7.</li> <li><code>0-9</code> goes to 3.</li> <li><code>+</code> goes to 2.</li> <li><code>/</code> goes to 1.</li> </ul> <p>This is small enough that we could cram a lookup table of values for building the <code>offsets</code> vector into another SIMD vector, and use a shuffle operation to do the lookup.</p> <p>This is not my original idea; I came across a <a href="https://github.com/WojciechMula/base64simd/issues/3">GitHub issue</a> where an anonymous user points out this perfect hash.</p> <p>Our new ascii-to-sextet code looks like this:</p> <div><figure><pre><code data-lang="rust"><span>// Compute the perfect hash for each lane.</span>
<span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
  <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b'/'</span><span>))</span>
    <span>.to_int</span><span>()</span>  <span>// to_int() is equivalent to masked_splat(-1, 0).</span>
    <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

<span>// Look up offsets based on each hash and subtract them from `ascii`.</span>
<span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>// This lookup table corresponds to the offsets we used to build the</span>
    <span>// `offsets` vector in the previous implementation, placed in the</span>
    <span>// indices that the perfect hash produces.</span>
  <span>-</span> <span>Simd</span><span>::</span><span>&lt;</span><span>i8</span><span>,</span> <span>8</span><span>&gt;</span><span>::</span><span>from</span><span>([</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
    <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
    <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span></code></pre></figure></div> <p>There is a small wrinkle here: <a href="https://doc.rust-lang.org/std/simd/struct.Simd.html#method.swizzle_dyn"><code>Simd::swizzle_dyn()</code></a> requires that the index array be the same length as the lookup table. This is annoying because right now <code>ascii</code> is a <code>Simd&lt;u8, 4&gt;</code>, but that will not be the case later on, so I will simply sweep this under the rug.</p> <p>Note that we no longer get validation as a side-effect of computing the sextets vector. The same GitHub issue also provides an exact bloom-filter for checking that a particular byte is valid; you can see my implementation <a href="https://github.com/mcy/vb64/blob/894f833e933860e070dabcfcc189430c45fecbd7/src/simd.rs#L93">here</a>. I’m not sure how the OP constructed the bloom filter, but the search space is small enough that you could have written a little script to brute force it.</p> <h3 id="riffling-the-sextets"><a href="#riffling-the-sextets">Riffling the Sextets</a></h3> <p>Now comes a much tricker operation: we need to somehow pack all four sextets into three bytes. One way to try to wrap our head around what the packing code in <code>decode_hot()</code> is doing is to pass in the all-ones sextet in one of the four bytes, and see where those ones end up in the return value.</p> <p>This is not unlike how they use radioactive dyes in biology to track the moment of molecules or cells through an organism.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>bits</span><span>(</span><span>value</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
  <span>let</span> <span>[</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>b3</span><span>,</span> <span>b4</span><span>]</span> <span>=</span> <span>value</span><span>.reverse_bits</span><span>()</span><span>.to_le_bytes</span><span>();</span>
  <span>format!</span><span>(</span><span>"{b1:08b} {b2:08b} {b3:08b} {b4:08b}"</span><span>)</span>
<span>}</span>

<span>fn</span> <span>decode_pack</span><span>(</span><span>input</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>4</span><span>])</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>output</span> <span>=</span> <span>0u32</span><span>;</span>
  <span>for</span> <span>byte</span> <span>in</span> <span>input</span> <span>{</span>
    <span>output</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
    <span>output</span> <span>|</span><span>=</span> <span>byte</span> <span>as</span> <span>u32</span><span>;</span>
  <span>}</span>
  <span>output</span> <span>&lt;&lt;=</span> <span>8</span><span>;</span>

  <span>println!</span><span>(</span><span>"{}</span><span>\n</span><span>{}</span><span>\n</span><span>"</span><span>,</span> <span>bits</span><span>(</span><span>u32</span><span>::</span><span>from_be_bytes</span><span>(</span><span>input</span><span>)),</span> <span>bits</span><span>(</span><span>output</span><span>));</span>
<span>}</span>

<span>decode_pack</span><span>([</span><span>0b111111</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0b111111</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0b111111</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0b111111</span><span>]);</span>

<span>// Output:</span>
<span>// 11111100 00000000 00000000 00000000</span>
<span>// 00111111 00000000 00000000 00000000</span>
<span>//</span>
<span>// 00000000 11111100 00000000 00000000</span>
<span>// 11000000 00001111 00000000 00000000</span>
<span>//</span>
<span>// 00000000 00000000 11111100 00000000</span>
<span>// 00000000 11110000 00000011 00000000</span>
<span>//</span>
<span>// 00000000 00000000 00000000 11111100</span>
<span>// 00000000 00000000 11111100 00000000</span></code></pre></figure></div> <p>Bingo. Playing around with the inputs lets us verify which pieces of the bytes wind up where. For example, by passing <code>0b110000</code> as <code>input[1]</code>, we see that the two high bits of <code>input[1]</code> correspond to the low bits of <code>output[0]</code>. I’ve written the code so that the bits in each byte are printed in little-endian order, so bits on the left are the low bits.</p> <p>Putting this all together, we can draw a schematic of what this operation does to a general <code>Simd&lt;u8, 4&gt;</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/riffle.png" alt="the riffling operation"></p> <p>Now, there’s no single instruction that will do this for us. Shuffles can be used to move bytes around, but we’re dealing with <em>pieces</em> of bytes here. We also can’t really do a shift, since we need bits that are overshifted to move into adjacent lanes.</p> <p>The trick is to just make the lanes bigger.</p> <p>Among the operations available for SIMD vectors are lane-wise casts, which allow us to zero-extend, sign-extend, or truncate each lane. So what we can do is cast <code>sextets</code> to a vector of <code>u16</code>, do the shift there and then… somehow put the parts back together?</p> <p>Let’s see how far shifting gets us. How much do we need to shift things by? First, notice that the order of the bits within each chunk that doesn’t cross a byte boundary doesn’t change. For example, the four low bits of <code>input[1]</code> are in the same order when they become the high bits of <code>output[1]</code>, and the two high bits of <code>input[1]</code> are also in the same order when they become the low bits of <code>output[0]</code>.</p> <p>This means we can determine how far to shift by comparing the bit position of the lowest bit of a byte of <code>input</code> with the bit position of the corresponding bit in <code>output</code>.</p> <p><code>input[0]</code>’s low bit is the third bit of <code>output[0]</code>, so we need to shift <code>input[0]</code> by 2. <code>input[1]</code>’s lowest bit is the fifth bit of <code>output[1]</code>, so we need to shift by 4. Analogously, the shifts for <code>input[2]</code> and <code>input[3]</code> turn out to be 6 and 0. In code:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>sextets</span> <span>=</span> <span>...</span><span>;</span>
<span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>0</span><span>]);</span></code></pre></figure></div> <p>So now we have a <code>Simd&lt;u16, 4&gt;</code> that contains the individual chunks that we need to move around, in the high and low bytes of each <code>u16</code>, which we can think of as being analogous to a <code>[[u8; 2]; 4]</code>. For example, <code>shifted[0][0]</code> contains <code>sextet[0]</code>, but shifted. This corresponds to the red segment in the first schematic. The smaller blue segment is given by <code>shifted[1][1]</code>, i.e., the high byte of the second <code>u16</code>. It’s already in the right place within that byte, so we want <code>output[0] = shifted[0][0] | shifted[1][1]</code>.</p> <p>This suggests a more general strategy: we want to take two vectors, the low bytes and the high bytes of each <code>u16</code> in <code>shifted</code>, respectively, and somehow shuffle them so that when or’ed together, they give the desired output.</p> <p>Look at the schematic again: if we had a vector consisting of <code>[..aaaaaa, ....bbbb, ......cc]</code>, we could or it with a vector like <code>[bb......, cccc...., dddddd..]</code> to get the desired result.</p> <p>One problem: <code>dddddd..</code> is <code>shifted[3][0]</code>, i.e., it’s a low byte. If we change the vector we shift by to <code>[2, 4, 6, 8]</code>, though, it winds up in <code>shifted[3][1]</code>, since it’s been shifted up by <code>8</code> bits: a full byte.</p> <div><figure><pre><code data-lang="rust"><span>// Split shifted into low byte and high byte vectors.</span>
<span>// Same way you'd split a single u16 into bytes, but lane-wise.</span>
<span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
<span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>8</span><span>;</span> <span>4</span><span>]))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

<span>// Align the lanes: we want to get shifted[0][0] | shifted[1][1],</span>
<span>// shifted[1][0] | shifted[2][1], etc.</span>
<span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span></code></pre></figure></div> <p>Et voila, here is our new, totally branchless implementation of <code>decode_hot()</code>.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span> <span>{</span>
  <span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
    <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b'/'</span><span>))</span>
      <span>.to_int</span><span>()</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

  <span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>-</span> <span>Simd</span><span>::</span><span>&lt;</span><span>i8</span><span>,</span> <span>8</span><span>&gt;</span><span>::</span><span>from</span><span>([</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
      <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span>  <span>// Note quite right yet, see next section.</span>

  <span>let</span> <span>ok</span> <span>=</span> <span>/* bloom filter shenanigans */</span><span>;</span>

  <span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]);</span>
  <span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>8</span><span>))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>The compactness of this solution should not be understated. The simplicity of this solution is a large part of what makes it so efficient, because it aggressively leverages the primitives the hardware offers us.</p> <h3 id="scaling-up"><a href="#scaling-up">Scaling Up</a></h3> <p>Ok, so now we have to contend with a new aspect of our implementation that’s crap: a <code>Simd&lt;u8, 4&gt;</code> is tiny. That’s not even 128 bits, which are the smallest vector registers on x86. What we need to do is make <code>decode_hot()</code> generic on the lane count. This will allow us to tune the number of lanes to batch together depending on benchmarks later on.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span>
<span>where</span>
  <span>// This makes sure N is a small power of 2.</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
    <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b'/'</span><span>))</span>
      <span>.to_int</span><span>()</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

  <span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>-</span> <span>tiled</span><span>(</span><span>&amp;</span><span>[</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
      <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span>  <span>// Works fine now, as long as N &gt;= 8.</span>

  <span>let</span> <span>ok</span> <span>=</span> <span>/* bloom filter shenanigans */</span><span>;</span>

  <span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>tiled</span><span>(</span><span>&amp;</span><span>[</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]);</span>
  <span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>8</span><span>))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span>

<span>/// Generates a new vector made up of repeated "tiles" of identical</span>
<span>/// data.</span>
<span>const</span> <span>fn</span> <span>tiled</span><span>&lt;</span><span>T</span><span>,</span> <span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>tile</span><span>:</span> <span>&amp;</span><span>[</span><span>T</span><span>])</span> <span>-&gt;</span> <span>Simd</span><span>&lt;</span><span>T</span><span>,</span> <span>N</span><span>&gt;</span>
<span>where</span>
  <span>T</span><span>:</span> <span>SimdElement</span><span>,</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>mut</span> <span>out</span> <span>=</span> <span>[</span><span>tile</span><span>[</span><span>0</span><span>];</span> <span>N</span><span>];</span>
  <span>let</span> <span>mut</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>N</span> <span>{</span>
    <span>out</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>tile</span><span>[</span><span>i</span> <span>%</span> <span>tile</span><span>.len</span><span>()];</span>
    <span>i</span> <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
  <span>Simd</span><span>::</span><span>from_array</span><span>(</span><span>out</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>We have to change virtually nothing, which is pretty awesome! But unfortunately, this code is subtly incorrect. Remember how in the <code>N = 4</code> case, the result of <code>output</code> had a garbage value that we ignore in its highest lane? Well, now that garbage data is interleaved into output: every fourth lane contains garbage.</p> <p>We can use a shuffle to delete these lanes, thankfully. Specifically, we want <code>shuffled[i] = output[i + i / 3]</code>, which skips every forth index. So, <code>shuffled[3] = output[4]</code>, skipping over the garbage value in <code>output[3]</code>. If <code>i + i / 3</code> overflows <code>N</code>, that’s ok, because that’s the high quarter of the final output vector, which is ignored anyways. In code:</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span>
<span>where</span>
  <span>// This makes sure N is a small power of 2.</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>

  <span>let</span> <span>decoded_chunks</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>swizzle!</span><span>(</span><span>N</span><span>;</span> <span>decoded_chunks</span><span>,</span> <span>array!</span><span>(</span><span>N</span><span>;</span> <span>|</span><span>i</span><span>|</span> <span>i</span> <span>+</span> <span>i</span> <span>/</span> <span>3</span><span>));</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span></code></pre></figure></div> <blockquote> <p><code>swizzle!()</code> is a helper macro<sup id="fnref:macros" role="doc-noteref"><a href="#fn:macros" rel="footnote">6</a></sup> for generating generic implementations of <code>std::simd::Swizzle</code>, and <code>array!()</code> is something I wrote for generating generic-length array constants; the closure is called once for each <code>i in 0..N</code>.</p> </blockquote> <p>So now we can decode 32 base64 bytes in parallel by calling <code>decode_hot::&lt;32&gt;()</code>. We’ll try to keep things generic from here, so we can tune the lane parameter based on benchmarks.</p> <h3 id="the-outer-loop"><a href="#the-outer-loop">The Outer Loop</a></h3> <p>Let’s look at <code>decode()</code> again. Let’s start by making it generic on the internal lane count, too.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span> <span>// N-sized chunks now.</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>if</span> <span>(</span><span>!</span><span>ok</span><span>)</span> <span>{</span>
      <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>);</span>
    <span>}</span>

    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>dec</span><span>[</span><span>..</span><span>decoded</span><span>]);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>What branches are left? There’s still the branch from <code>for chunks in ...</code>. It’s not ideal because it can’t do an exact pointer comparison, and needs to do a <code>&gt;=</code> comparison on a length instead.</p> <p>We call <code>[T]::copy_from_slice</code>, which is super slow because it needs to make a variable-length <code>memcpy</code> call, which can’t be inlined. Function calls are branches! The bounds checks are also a problem.</p> <p>We branch on <code>ok</code> every loop iteration, still. Not returning early in <code>decode_hot</code> doesn’t win us anything (yet).</p> <p>We potentially call the allocator in <code>extend_from_slice</code>, and perform another non-inline-able <code>memcpy</code> call.</p> <h3 id="preallocating-with-slop"><a href="#preallocating-with-slop">Preallocating with Slop</a></h3> <p>The last of these is the easiest to address: we can reserve space in <code>out</code>, since we know exactly how much data we need to write thanks to <code>decoded_len</code>. Better yet, we can reserve some “slop”: i.e., scratch space past where the end of the message would be, so we can perform full SIMD stores, instead of the variable-length memcpy.</p> <p>This way, in each iteration, we write the full SIMD vector, including any garbage bytes in the upper quarter. Then, the next write is offset <code>3/4 * N</code> bytes over, so it overwrites the garbage bytes with decoded message bytes. The garbage bytes from the final right get “deleted” by not being included in the final <code>Vec::set_len()</code> that “commits” the memory we wrote to.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>let</span> <span>final_len</span> <span>=</span> <span>decoded_len</span><span>(</span><span>data</span><span>);</span>
  <span>out</span><span>.reserve</span><span>(</span><span>final_len</span> <span>+</span> <span>N</span> <span>/</span> <span>4</span><span>);</span>  <span>// Reserve with slop.</span>

  <span>// Get a raw pointer to where we should start writing.</span>
  <span>let</span> <span>mut</span> <span>ptr</span> <span>=</span> <span>out</span><span>.as_mut_ptr_range</span><span>()</span><span>.end</span><span>();</span>
  <span>let</span> <span>start</span> <span>=</span> <span>ptr</span><span>;</span>

  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span> <span>// N-sized chunks now.</span>
    <span>/* snip */</span>

    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>unsafe</span> <span>{</span>
      <span>// Do a raw write and advance the pointer.</span>
      <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>dec</span><span>);</span>
      <span>ptr</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>decoded</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>unsafe</span> <span>{</span>
    <span>// Update the vector's final length.</span>
    <span>// This is the final "commit".</span>
    <span>let</span> <span>len</span> <span>=</span> <span>ptr</span><span>.offset_from</span><span>(</span><span>start</span><span>);</span>
    <span>out</span><span>.set_len</span><span>(</span><span>len</span> <span>as</span> <span>usize</span><span>);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>This is safe, because we’ve pre-allocated exactly the amount of memory we need, and where <code>ptr</code> lands is equal to the amount of memory actually decoded. We could also compute the final length of <code>out</code> ahead of time.</p> <p>Note that if we early return due to <code>if !ok</code>, <code>out</code> remains unmodified, because even though we did write to its buffer, we never execute the “commit” part, so the code remains correct.</p> <h3 id="delaying-failure"><a href="#delaying-failure">Delaying Failure</a></h3> <p>Next up, we can eliminate the <code>if !ok</code> branches by waiting to return an error until as late as possible: just before the <code>set_len</code> call.</p> <p>Remember our observation from before: most base64 encoded blobs are valid, so this unhappy path should be very rare. Also, syntax errors cannot cause code that follows to misbehave arbitrarily, so letting it go wild doesn’t hurt anything.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>
  <span>let</span> <span>mut</span> <span>error</span> <span>=</span> <span>false</span><span>;</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>error</span> <span>|</span><span>=</span> <span>!</span><span>ok</span><span>;</span>

    <span>/* snip */</span>
  <span>}</span>

  <span>if</span> <span>error</span> <span>{</span>
    <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>);</span>
  <span>}</span>

  <span>unsafe</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>ptr</span><span>.offset_from</span><span>(</span><span>start</span><span>);</span>
    <span>out</span><span>.set_len</span><span>(</span><span>len</span> <span>as</span> <span>usize</span><span>);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>The branch is still “there”, sure, but it’s out of the hot loop.</p> <p>Because we never hit the <code>set_len</code> call and commit whatever garbage we wrote, said garbage essentially disappears when we return early, to be overwritten by future calls to <code>Vec::push()</code>.</p> <h3 id="unroll-it-harder"><a href="#unroll-it-harder">Unroll It Harder</a></h3> <p>Ok, let’s look at the memcpy from <code>copy_from_slice</code> at the start of the hot loop. The loop has already been partly unrolled: it does <code>N</code> iterations with SIMD each step, doing something funny on the last step to make up for the missing data (padding with <code>A</code>).</p> <p>We can take this a step further by doing an “unroll and jam” optimization. This type of unrolling splits the loop into two parts: a hot vectorized loop and a cold remainder part. The hot loop <em>always</em> handles length <code>N</code> input, and the remainder runs at most once and handles <code>i &lt; N</code> input.</p> <p>Rust provides an iterator adapter for hand-rolled (lol) unroll-and-jam: <code>Iterator::chunks_exact()</code>.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>
  <span>let</span> <span>mut</span> <span>error</span> <span>=</span> <span>false</span><span>;</span>
  <span>let</span> <span>mut</span> <span>chunks</span> <span>=</span> <span>data</span><span>.chunks_exact</span><span>(</span><span>N</span><span>);</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>&amp;</span><span>mut</span> <span>chunks</span> <span>{</span>
    <span>// Simd::from_slice() can do a load in one instruction.</span>
    <span>// The bounds check is easy for the compiler to elide.</span>
    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>Simd</span><span>::</span><span>from_slice</span><span>(</span><span>chunk</span><span>));</span>
    <span>error</span> <span>|</span><span>=</span> <span>!</span><span>ok</span><span>;</span>
    <span>/* snip */</span>
  <span>}</span>

  <span>let</span> <span>rest</span> <span>=</span> <span>chunks</span><span>.remainder</span><span>();</span>
  <span>if</span> <span>!</span><span>rest</span><span>.empty</span><span>()</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>/* snip */</span>
  <span>}</span>

  <span>/* snip */</span>
<span>}</span></code></pre></figure></div> <p>Splitting into two parts lets us call <code>Simd::from_slice()</code>, which performs a single, vector-sized load.</p> <h2 id="so-how-fast-is-it"><a href="#so-how-fast-is-it">So, How Fast Is It?</a></h2> <p>At this point, it looks like we’ve addressed every branch that we can, so some benchmarks are in order. I wrote a benchmark that decodes messages of every length from 0 to something like 200 or 500 bytes, and compared it against the baseline base64 implementation on crates.io.</p> <p>I compiled with <code>-Zbuild-std</code> and <code>-Ctarget-cpu=native</code> to try to get the best results. Based on some tuning, <code>N = 32</code> was the best length, since it used one YMM register for each iteration of the hot loop.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph-old.png" alt="a performance graph; our code is really good compared to the baseline, but variance is high"></p> <p>So, we have the baseline beat. But what’s up with that crazy heartbeat waveform? You can tell it has something to do with the “remainder” part of the loop, since it correlates strongly with <code>data.len() % 32</code>.</p> <p>I stared at the assembly for a while. I don’t remember what was there, but I think that <code>copy_from_slice</code> had been inlined and unrolled into a loop that loaded each byte at a time. The moral equivalent of this:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
<span>for</span> <span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>in</span> <span>Iterator</span><span>::</span><span>zip</span><span>(</span><span>&amp;</span><span>mut</span> <span>ascii</span><span>,</span> <span>chunk</span><span>)</span> <span>{</span>
  <span>*</span><span>a</span> <span>=</span> <span>*</span><span>b</span><span>;</span>
<span>}</span></code></pre></figure></div> <p>I decided to try <code>Simd::gather_or()</code>, which is kind of like a “vectorized load”. It wound up producing worse assembly, so I gave up on using a gather and instead wrote a carefully optimized loading function by hand.</p> <h3 id="unroll-and-jam-revisited"><a href="#unroll-and-jam-revisited">Unroll and Jam, Revisited</a></h3> <p>The idea here is to perform the largest scalar loads Rust offers where possible. The strategy is again unroll and jam: perform <code>u128</code> loads in a loop and deal with the remainder separately.</p> <p>The hot part looks like this:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>mut</span> <span>buf</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>

<span>// Load a bunch of big 16-byte chunks. LLVM will lower these to XMM loads.</span>
<span>let</span> <span>ascii_ptr</span> <span>=</span> <span>buf</span><span>.as_mut_ptr</span><span>();</span>
<span>let</span> <span>mut</span> <span>write_at</span> <span>=</span> <span>ascii_ptr</span><span>;</span>
<span>if</span> <span>slice</span><span>.len</span><span>()</span> <span>&gt;=</span> <span>16</span> <span>{</span>
  <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>slice</span><span>.len</span><span>()</span> <span>/</span> <span>16</span> <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>write_at</span> <span>=</span> <span>write_at</span><span>.add</span><span>(</span><span>i</span> <span>*</span> <span>16</span><span>);</span>

      <span>let</span> <span>word</span> <span>=</span> <span>slice</span><span>.as_ptr</span><span>()</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.add</span><span>(</span><span>i</span><span>)</span><span>.read_unaligned</span><span>();</span>
      <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>word</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The cold part seems hard to optimize at first. What’s the least number of unaligned loads you need to do to load 15 bytes from memory? It’s two! You can load a <code>u64</code> from <code>p</code>, and then another one from <code>p + 7</code>; these loads (call them <code>a</code> and <code>b</code>) overlap by one byte, but we can or them together to merge that byte, so our loaded value is <code>a as u128 | (b as u128 &lt;&lt; 56)</code>.</p> <p>A similar trick works if the data to load is between a <code>u32</code> and a <code>u64</code>. Finally, to load 1, 2, or 3 bytes, we can load <code>p</code>, <code>p + len/2</code> and <code>p + len-1</code>; depending on whether <code>len</code> is 1, 2, or 3, this will potentially load the same byte multiple times; however, this reduces the number of branches necessary, since we don’t need to distinguish the 1, 2, or 3 lines.</p> <p>This is the kind of code that’s probably easier to read than to explain.</p> <div><figure><pre><code data-lang="rust"><span>unsafe</span> <span>{</span>
  <span>let</span> <span>ptr</span> <span>=</span> <span>slice</span><span>.as_ptr</span><span>()</span><span>.offset</span><span>(</span><span>write_at</span><span>.offset_from</span><span>(</span><span>ascii_ptr</span><span>));</span>
  <span>let</span> <span>len</span> <span>=</span> <span>slice</span><span>.len</span><span>()</span> <span>%</span> <span>16</span><span>;</span>

  <span>if</span> <span>len</span> <span>&gt;=</span> <span>8</span> <span>{</span>
    <span>// Load two overlapping u64s.</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u128</span><span>;</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>8</span><span>)</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u128</span><span>;</span>
    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>8</span><span>)</span> <span>*</span> <span>8</span><span>));</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u128</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b'A'</span><span>;</span> <span>16</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span> <span>else</span> <span>if</span> <span>len</span> <span>&gt;=</span> <span>4</span> <span>{</span>
    <span>// Load two overlapping u32s.</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>4</span><span>)</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>4</span><span>)</span> <span>*</span> <span>8</span><span>));</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u64</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b'A'</span><span>;</span> <span>8</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>// Load 3 overlapping u8s.</span>

    <span>// For len       1       2       3     ...</span>
    <span>// ... this is  ptr[0]  ptr[0]  ptr[0]</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>
    <span>// ... this is  ptr[0]  ptr[1]  ptr[1]</span>
    <span>let</span> <span>mid</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>/</span> <span>2</span><span>)</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>
    <span>// ... this is  ptr[0]  ptr[1]  ptr[2]</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>1</span><span>)</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>

    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>mid</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>/</span> <span>2</span><span>)</span> <span>*</span> <span>8</span><span>))</span> <span>|</span> <span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>8</span><span>);</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u32</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b'A'</span><span>;</span> <span>4</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>I learned this type of loading code while contributing to Abseil: it’s very useful for loading variable-length data for data-hungry algorithms, like a codec or a hash function.</p> <p>Here’s the same benchmark again, but with our new loading code.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph.png" alt="a performance graph; our code is even better and the variance is very tight"></p> <p>The results are really, really good. The variance is super tight, and our performance is 2x that of the baseline pretty much everywhere. <em>Success.</em></p> <h3 id="encoding-web-safe"><a href="#encoding-web-safe">Encoding? Web-Safe?</a></h3> <p>Writing an encoding function is simple enough: first, implement an <code>encode_hot()</code> function that reverses the operations from <code>decode_hot()</code>. The perfect hash from before won’t work, so you’ll need to <a href="https://github.com/mcy/vb64/blob/main/src/simd.rs#L170">invent a new one</a>.</p> <p>Also, the loading/storing code around the encoder is slightly different, too. <code>vb64</code> implements a very efficient encoding routine too, so I suggest taking a look at the source code if you’re interested.</p> <p>There is a base64 variant called web-safe base64, that replaces the <code>+</code> and <code>/</code> characters with <code>-</code> and <code>_</code>. Building a perfect hash for these is trickier: you would probably have to do something like <code>(byte &gt;&gt; 4) - (byte == '_' ? '_' : 0)</code>. I don’t support web-safe base64 yet, but only because I haven’t gotten around to it.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>My library doesn’t really solve an important problem; base64 decoding isn’t a bottleneck… anywhere that I know of, really. But writing SIMD code is really fun! Writing branchless code is often overkill but can give you a good appreciation for what your compilers can and <em>can’t</em> do for you.</p> <p>This project was also an excuse to try <code>std::simd</code>. I think it’s great overall, and generates excellent code. There’s some rough edges I’d like to see fixed to make SIMD code even simpler, but overall I’m very happy with the work that’s been done there.</p> <p>This is probably one of the most complicated posts I’ve written in a long time. SIMD (and performance in general) is a complex topic that requires a breadth of knowledge of tricks and hardware, a lot of which isn’t written down. More of it is written down now, though. ◼</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[That time Verisign typo-squatted all of .com and .net (145 pts)]]></title>
            <link>http://rachelbythebay.com/w/2023/11/27/sitefinder/</link>
            <guid>38442133</guid>
            <pubDate>Tue, 28 Nov 2023 03:53:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://rachelbythebay.com/w/2023/11/27/sitefinder/">http://rachelbythebay.com/w/2023/11/27/sitefinder/</a>, See on <a href="https://news.ycombinator.com/item?id=38442133">Hacker News</a></p>
Couldn't get http://rachelbythebay.com/w/2023/11/27/sitefinder/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Antirez' tiny JSON selector library (103 pts)]]></title>
            <link>https://notes.billmill.org/link_blog/2023/11/antirez__tiny_JSON_selector_library.html</link>
            <guid>38442050</guid>
            <pubDate>Tue, 28 Nov 2023 03:40:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notes.billmill.org/link_blog/2023/11/antirez__tiny_JSON_selector_library.html">https://notes.billmill.org/link_blog/2023/11/antirez__tiny_JSON_selector_library.html</a>, See on <a href="https://news.ycombinator.com/item?id=38442050">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>Nov 27, 2023</p>
    <p>Salvatore Sanfilippo, aka <a href="https://github.com/antirez">antirez</a> released a <a href="https://github.com/antirez/botlib">telegram bot library in C</a> recently. While I'm not at all interested in a telegram bot library, I always like to read Salvatore's code, which is uniformly superb.</p>
<p>The bit of code that caught my eye in this release is in <a href="https://github.com/antirez/botlib/blob/ca2f977deeb3455e69e9a8f6b8ba711798dba6e6/json_wrap.c">this file</a>, which implements a simple selector library on top of the <a href="https://github.com/DaveGamble/cJSON">json library he's using</a>. In about 100 lines of code, it implements a function that parses and executes a tiny <a href="https://notes.billmill.org/programming/json/jq.html">jq</a>-like language:</p>
<pre><code><div><pre><span></span><span>/* You can select things like this:</span>
<span> *</span>
<span> * cJSON *json = cJSON_Parse(myjson_string);</span>
<span> * cJSON *width = cJSON_Select(json,".features.screens[*].width",4);</span>
<span> * cJSON *height = cJSON_Select(json,".features.screens[4].*","height");</span>
<span> * cJSON *price = cJSON_Select(json,".features.screens[4].price_*",</span>
<span> *                  price_type == EUR ? "eur" : "usd");</span>
</pre></div>
</code></pre>
<p>It's a really nice example of just how simple you can make a parser for a tiny language.</p>
<p>I think it'd be fun to re-implement this in another language to understand it better, and I might give it a go at some point.</p>

    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[San Francisco Blows Housing Deadline, Prompting Standoff with State Regulators (106 pts)]]></title>
            <link>https://sfstandard.com/2023/11/27/san-francisco-blows-state-housing-deadline-constraints-reduction-ordinance/</link>
            <guid>38441866</guid>
            <pubDate>Tue, 28 Nov 2023 03:15:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfstandard.com/2023/11/27/san-francisco-blows-state-housing-deadline-constraints-reduction-ordinance/">https://sfstandard.com/2023/11/27/san-francisco-blows-state-housing-deadline-constraints-reduction-ordinance/</a>, See on <a href="https://news.ycombinator.com/item?id=38441866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>San Francisco has crossed a line in the sand, according to state housing officials.&nbsp;</p><p>That line was a deadline for passing legislation to expedite housing approvals, which came and went on Nov. 24.&nbsp;The state is giving the city another 30 days to get the bill on track before potentially revoking its permitting authority or withholding state funds, among other actions.&nbsp;</p><p>The bill in question is Mayor London Breed’s Constraints Reduction Ordinance—now in <a href="https://sfgov.legistar.com/View.ashx?M=F&amp;ID=12346119&amp;GUID=522E3F50-F707-46EA-9430-EDB185A34D22">its fifth revision</a> and set to be considered again at the Board of Supervisors’ Land Use and Transportation Committee on Monday.&nbsp;</p><p>The ordinance, which eliminates neighborhood notifications and other forms of discretionary review from many housing projects, has been <a href="https://sfstandard.com/2023/10/27/san-francisco-under-pressure-to-pass-housing-bill-or-else/">repeatedly stalled in committee</a> as supervisors tacked on amendments that weren’t necessary, according to the California Department of Housing and Community Development.&nbsp;</p><p>Those changes wound up pushing the city past a 30-day deadline, imposed <a href="https://sfstandard.com/2023/10/25/san-francisco-housing-crisis-audit-lose-local-control/">in a report published Oct. 25</a>. The board is also in defiance of a separate Oct. 26 letter, which warned supervisors to pass the <a href="https://sfstandard.com/2023/10/27/san-francisco-under-pressure-to-pass-housing-bill-or-else/">bill without amendments</a> or risk falling out of compliance with state law.&nbsp;&nbsp;</p><p>On Monday morning, Breed posted on X, formerly Twitter, warning that the city is "already slipping" in enacting its Housing Element and warned of stiff consequences  if it violates state law. </p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">The right track means passing legislation that I introduced, along with Supervisors <a href="https://twitter.com/JoelEngardio?ref_src=twsrc%5Etfw">@JoelEngardio</a> and <a href="https://twitter.com/mattdorsey?ref_src=twsrc%5Etfw">@mattdorsey</a>, to remove unnecessary and burdensome rules that get in the way of housing being built.&nbsp;And it means rejecting amendments to weaken it. <a href="https://t.co/5zgcCMxwtw">https://t.co/5zgcCMxwtw</a></p>— London Breed (@LondonBreed) <a href="https://twitter.com/LondonBreed/status/1729203245384630447?ref_src=twsrc%5Etfw">November 27, 2023</a></blockquote></div></figure><p>In a statement, the state housing department said that it will send a “Corrective Action Letter” this week that gives the city another 30 days to pass the bill before having its <a href="https://sfstandard.com/2023/01/24/sf-housing-plan-passes-but-faces-tight-timeline-and-tough-road-to-implementation/">Housing Element</a> decertified.&nbsp;</p><p>Should that happen, it would subject the city to consequences such as “ineligibility or delay in receiving certain state funds and the <a href="https://sfstandard.com/2023/01/27/developers-ready-to-pounce-as-bay-area-cities-fall-behind-on-housing-deadline/#:~:text=The%20most%20imminent%20penalty%20is,some%20affordable%20housing%20is%20included.">application of the ‘builder’s remedy,’</a> among others,” according to the department.&nbsp;</p><p>If the land use committee passes the Constraints Reduction Ordinance, the full board will vote on it Tuesday. Even if the board passes the bill within the 30-day window, it’s not clear whether the tweaked bill will satisfy the state.&nbsp;</p><figure><span><span></span><img alt="Aaron Peskin speaks to a crowd outside City Hall. " sizes="(min-width: 1001px) 650px, (min-width: 768px) 550px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2023/10/SRO-CityFederal-092823_JY_004.jpg?w=3840&amp;q=75" decoding="async" data-nimg="responsive" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><figcaption>District 3 Supervisor Aaron Peskin speaks at a press conference in Portsmouth Square in Chinatown in San Francisco on Sept. 28, 2023. | <span>Source: </span>Juliana Yamada for The Standard</figcaption></figure><p>In a Nov. 21 letter, Planning Department Director Rich Hillis wrote that the Mayor’s Office plans to introduce further changes to ensure the bill is compliant. The department is “confident that the changes made, and that continue to be made, to San Francisco’s review and approval process substantially comply with the City’s approved Housing Element,” Hillis wrote.</p><p>But community groups opposed to the legislation are expected to keep up the pressure against the mayor’s bill.</p><p>The Council of Community Housing Organizations, the San Francisco Anti-Displacement Coalition and other groups rallied members to show up to Monday’s land use meeting in support of a separate resolution pushing back on the state deadlines.&nbsp;</p><p>The nonbinding resolution, authored by Board President Aaron Peskin, urges City Attorney David Chiu to request an extension of the deadlines and to “<a href="https://sfgov.legistar.com/LegislationDetail.aspx?ID=6412806&amp;GUID=4DEFDA6D-09E3-48E1-8E57-283310D51F54&amp;Options=ID%7CText%7C&amp;Search=revise+and+correct">revise and correct</a>” its warning letter. The resolution will also be considered on Monday.&nbsp;</p><p>However, the state housing department was clear that it’s not budging.</p><p>The department said it “does not plan on revising the timelines or content” of the deadlines.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The `hanging-punctuation property` in CSS (160 pts)]]></title>
            <link>https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/</link>
            <guid>38441747</guid>
            <pubDate>Tue, 28 Nov 2023 02:58:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/">https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/</a>, See on <a href="https://news.ycombinator.com/item?id=38441747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>(I did <a href="https://twitter.com/chriscoyier/status/1699862605517713786">a Twitter thread</a> on this a while back, against my better judgment, and now moving to a proper blog.)</p>
<hr>
<p>The <code>hanging-punctuation</code> property in CSS is almost a no-brainer. The classic example is a blockquote that starts with a curly-quote. Hanging that opening curly-quote into the space off to the start of the text and aligning the actual words is a better look.</p>
<figure><img data-attachment-id="10826" data-permalink="https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/f5ceileacaammq2/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?fit=1200%2C740&amp;ssl=1" data-orig-size="1200,740" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="F5ceILEacAAMMq2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?fit=300%2C185&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?fit=1024%2C631&amp;ssl=1" decoding="async" fetchpriority="high" width="1024" height="631" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?resize=1024%2C631&amp;ssl=1" alt="Example of hanging punction look from Steve Hickey
" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?resize=1024%2C631&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?resize=300%2C185&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?resize=768%2C474&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceILEacAAMMq2.jpeg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption><a href="https://stevehickeydesign.com/blog/2012/12/04/hanging-punctuation-with-css/">via Steve Hickey</a></figcaption></figure>
<p>Here’s a demo:</p>

<p>The blue line is just to help see the alignment.</p>
<figure><img data-attachment-id="10827" data-permalink="https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/f5cerfeaaaagybw/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?fit=1200%2C614&amp;ssl=1" data-orig-size="1200,614" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="F5ceRFeaAAAgybW" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?fit=300%2C154&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?fit=1024%2C524&amp;ssl=1" decoding="async" width="1024" height="524" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?resize=1024%2C524&amp;ssl=1" alt="Screenshot of safari working and other browsers not working
" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?resize=1024%2C524&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?resize=300%2C154&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?resize=768%2C393&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ceRFeaAAAgybW.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>
<p>It is a cascading property, so you can just do this if you like:</p>
<pre aria-describedby="shcb-language-1" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>html</span> {
  <span>hanging-punctuation</span>: first last;
}</code></span><small id="shcb-language-1"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>In case you go against the grain, for aesthetics, and align text the other way, the `last` value will hang punctuation off the other else also. That’s what it’s supposed to do anyway, but in my testing (trying quotes and periods), Safari doesn’t support that. 🤷‍♀️</p>
<p>There is some risk to the property. Because the punctuation hangs off the edge, if you don’t have any available space, it can trigger a horizontal scroll bar, which sucks. This is probably why it’s not a default. It’s rare there is zero space on the edge of text, though, so meh.</p>
<figure><img data-attachment-id="10828" data-permalink="https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/f5ce2maacaahdy8/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?fit=1200%2C788&amp;ssl=1" data-orig-size="1200,788" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="F5ce2mAacAAHDy8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?fit=300%2C197&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?fit=1024%2C672&amp;ssl=1" decoding="async" width="1024" height="672" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?resize=1024%2C672&amp;ssl=1" alt="horizontal scrollbar triggered by hanging indentation
" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?resize=1024%2C672&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?resize=300%2C197&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?resize=768%2C504&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5ce2mAacAAHDy8.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>
<p>Want it to work across all browsers? Use a negative <code>text-indent</code> instead. Then test for support and replace it.</p>
<pre aria-describedby="shcb-language-2" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>blockquote</span> {
  <span>text-indent</span>: -<span>0.45em</span>; 
}
@​supports (<span>hanging-punctuation:</span> first) {
  <span>blockquote</span> {
    <span>text-indent</span>: <span>0</span>;
    <span>hanging-punctuation</span>: first;
  }
}</code></span><small id="shcb-language-2"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Having to use a magic number for the `text-indent` kinda sucks, so definitely isolate where you are applying it. Here’s a demo where a custom property is used instead to make it less weird:</p>

<p>By the way! For putting curly quotes on blockquote, might as well do that in CSS rather than in the content.</p>
<pre aria-describedby="shcb-language-3" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>blockquote</span> {
  &amp;::before {
    <span>content</span>: open-quote;
  }
  &amp;<span>::after</span> {
    <span>content</span>: close-quote;
  }
}</code></span><small id="shcb-language-3"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Hanging punctuation is relevant in design software and print design as well. I feel like any half-decent book typesetting will be doing this. Adobe InDesign calls it “Optical Margin Alignment”.</p>
<p><a href="https://fonts.google.com/knowledge/using_type/working_with_hanging_punctuation">Elliot Jay Stocks notes that here.</a></p>
<figure><img data-attachment-id="10829" data-permalink="https://chriscoyier.net/2023/11/27/the-hanging-punctuation-property-in-css/f5cgb3macaa_ijn/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?fit=1200%2C665&amp;ssl=1" data-orig-size="1200,665" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="F5cgb3MacAA_IJN" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?fit=300%2C166&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?fit=1024%2C567&amp;ssl=1" decoding="async" loading="lazy" width="1024" height="567" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?resize=1024%2C567&amp;ssl=1" alt="" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?resize=1024%2C567&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?resize=300%2C166&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?resize=768%2C426&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2023/11/F5cgb3MacAA_IJN.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>
<p>I think <code>hanging-punctuation</code> is nice! Just a nice bonus where supported and not a huge deal if it’s not. I’d probably start a new project with:</p>
<pre aria-describedby="shcb-language-4" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>html</span> {
  <span>hanging-punctuation</span>: first allow-end last;
}</code></span><small id="shcb-language-4"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Outlook is good, both for yourself and 766 third parties (275 pts)]]></title>
            <link>https://godforsaken.website/@Shrigglepuss/111482466182637440</link>
            <guid>38441710</guid>
            <pubDate>Tue, 28 Nov 2023 02:52:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://godforsaken.website/@Shrigglepuss/111482466182637440">https://godforsaken.website/@Shrigglepuss/111482466182637440</a>, See on <a href="https://news.ycombinator.com/item?id=38441710">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Orion Browser by Kagi (140 pts)]]></title>
            <link>https://kagi.com/orion/</link>
            <guid>38441139</guid>
            <pubDate>Tue, 28 Nov 2023 01:33:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kagi.com/orion/">https://kagi.com/orion/</a>, See on <a href="https://news.ycombinator.com/item?id=38441139">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <h2>Bring your favorite extensions.</h2>
                <p>
                    <h3>
                    Orion offers native support for many Firefox and Chrome browser
                    extensions allowing access to the world's largest
                    eco-system of browser extensions.                    </h3>
                    <h3>
                    We're still in the process of expanding our extension support to include all available options. Simultaneously, we're working on bringing this feature to iOS
                    and Orion is the first browser that allows you to
                    install
                    select web extensions directly from the Chrome Web Store or Firefox
                    Add-Ons on your iPhone or iPad.
                    </h3>
                    <h2><a href="https://kagi.com/orion/faq.html#extensions">Read more</a>
                    </h2>
                </p>
            </div><div>
            <p>
                1. Orion is currently available for Apple macOS, iPadOS and iOS. We are planning support for other platforms in the future.</p>
            <p>
                2. We have ported the Web Extensions API to WebKit, allowing
                Orion to run Chrome and Firefox extensions out of the box.
                This support is still experimental while we are in beta and
                some extensions may not work properly.
            </p>
            <p>
                3. Live Text is a macOS feature allowing to interact with a text in the photo, currently supported in <a href="https://www.apple.com/macos/feature-availability/#live-text">multiple languages</a>.
            </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Play keeps banning the same web browser due to vague DMCA notices (140 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/11/weird-dmca-takedown-google-play-bans-app-because-it-can-load-warnerbros-com/</link>
            <guid>38440194</guid>
            <pubDate>Mon, 27 Nov 2023 23:43:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/11/weird-dmca-takedown-google-play-bans-app-because-it-can-load-warnerbros-com/">https://arstechnica.com/tech-policy/2023/11/weird-dmca-takedown-google-play-bans-app-because-it-can-load-warnerbros-com/</a>, See on <a href="https://news.ycombinator.com/item?id=38440194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/05/downloader-browser-800x450.png" alt="Screenshot of the Google home page displayed on Downloader, an Android app with a built-in browser.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/05/downloader-browser.png" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> The Downloader app that was suspended from Google Play.</p></figcaption>  </figure>

  




<!-- cache hit 74:single/related:c86ee390c9378031a828d29352811a8a --><!-- empty -->
<p>App developer Elias Saba has had some bad luck with Digital Millennium Copyright Act (DMCA) takedowns. His Android TV app Downloader, which combines a web browser with a file manager, was <a href="https://arstechnica.com/tech-policy/2023/05/google-bans-downloader-app-after-tv-firms-complain-it-can-load-a-pirate-website/">suspended by Google Play in May</a> after several Israeli TV companies complained that the app could be used to load a pirate website.</p>
<p>Google <a href="https://arstechnica.com/tech-policy/2023/06/google-un-bans-downloader-app-but-developer-still-mad-about-broken-dmca/">reversed that suspension</a> after three weeks. But Downloader has been suspended by Google Play again, and this time the reason is even harder to understand. Based on a vague DMCA notice, it appears that Downloader was suspended simply because it can load <a href="https://www.warnerbros.com/">the Warner Bros. website</a>.</p>
<p>Downloader is similar to standard web browsers in that it lets users access both legal and illegally shared content. The app can be used for general web surfing and can download files from a website when a user inputs the desired URL. According to Saba, the app itself contains no infringing content, nor does it direct users to infringing content.</p>
<p>Google notified Saba that the app was suspended again last night, according to the notice that Saba shared with Ars. "Your app contains content that allegedly infringes upon the copyright of others, and violates applicable copyright laws in the relevant country/jurisdiction," the notice from Google said.</p>                                            
                                                        
<p>The notice includes a copy of the DMCA complaint, which came from <a href="https://markscan.co.in/">MarkScan</a>, a "digital asset protection" firm that content owners hire to enforce copyrights. MarkScan said in its complaint that it represents Warner Bros. Discovery Inc.</p>
<h2>“Properties of Warner Bros. Discovery”</h2>
<p>A DMCA notice is supposed to identify and describe the copyrighted work that was infringed. But MarkScan's notice about Downloader identifies the copyrighted work only as "Properties of Warner Bros. Discovery Inc." It provides no detail on which Warner Bros. work was infringed by Downloader.</p>
<p>A DMCA notice is also supposed to provide an example of where someone can see "an authorized example of the work." In this field, MarkScan simply entered the main Warner Bros. URL: <a href="https://www.warnerbros.com/" target="_blank" rel="noopener">https://www.warnerbros.com/</a>.</p>
<p>"I have a good faith belief that use of the copyrighted materials described above as allegedly infringing is not authorized by the copyright owner, its agent, or the law," MarkScan's notice said.</p>
<p>Unsurprisingly, Saba is outraged. "You would think that Google would at least verify that the takedown request is actually making a plausible claim," he told Ars today. "The most important field in the takedown where the claimant has to specify where the copyright infringement exists is void of all detail. If this complete lack of information is all it takes to take an app down, then no app in the Google Play Store is safe from being suspended with just a few clicks and a frivolous takedown request."</p>
<p>The Downloader app had been installed over 10 million times, according to an <a href="https://web.archive.org/web/20230824170506/https://play.google.com/store/apps/details?id=com.esaba.downloader">Internet Archive capture</a> taken before the latest suspension.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linexjlin/GPTs: leaked prompts of GPTs (127 pts)]]></title>
            <link>https://github.com/linexjlin/GPTs</link>
            <guid>38440011</guid>
            <pubDate>Mon, 27 Nov 2023 23:24:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/linexjlin/GPTs">https://github.com/linexjlin/GPTs</a>, See on <a href="https://news.ycombinator.com/item?id=38440011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How could Al Bundy afford a house when he was making minimum wage? (142 pts)]]></title>
            <link>https://old.reddit.com/r/AskHistorians/comments/ggozng/in_the_sitcom_married_with_children_protagonist/</link>
            <guid>38439851</guid>
            <pubDate>Mon, 27 Nov 2023 23:08:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/AskHistorians/comments/ggozng/in_the_sitcom_married_with_children_protagonist/">https://old.reddit.com/r/AskHistorians/comments/ggozng/in_the_sitcom_married_with_children_protagonist/</a>, See on <a href="https://news.ycombinator.com/item?id=38439851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>[–]<a href="https://old.reddit.com/user/MaroonTrojan">MaroonTrojan</a><span></span> <span title="53">53 points</span><span title="54">54 points</span><span title="55">55 points</span> <time title="Mon May 11 08:47:25 2020 UTC" datetime="2020-05-11T08:47:25+00:00">3 years ago</time><time title="last edited 3 years ago" datetime="2020-05-11T08:50:37+00:00">*</time>&nbsp;(4 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_fq961juhnz"><div itemprop="text"><p>I'd like to respond to this question from the opposite angle, which is: is it realistic that a Chicago homeowner family where the man is a retail worker would have a homemaker wife in the 1980s/1990s. The answer-- as others have pointed out-- is no. But it's interesting to look at why in the early 1990s that might have been a popular choice for a sitcom family dynamic and how Peg Bundy differed from other sitcom women of her era and those who came before her.</p>

<p>Let's look at the original sitcom woman: Lucy. She managed to live in an apartment with wall-to-wall carpeting and fresh drapes while living on a single-income non-white entertainer's salary in the 1950s and maintaining a friendship with her landlord and his wife. Was that realistic? Probably not. But the show didn't get into the details of how they paid the bills. It presented the normalized idea that men were the breadwinners and women stayed at home and had lots of spare time to get into crazy schemes. Her schemes-- even when they were purely economical ones-- were always motivated internally. Lucy wanted fame: on television, or in the club, or in Hollywood. She never tried to advance herself to make money. Because that's not the sort of thing a (successful?) woman did.</p>

<p>The next relevant sitcom wife of the era was Laura Pietrie (Mary Tyler Moore on the Dick Van Dyke show). Again, here was a pretty domestic wife, now in a New York suburb instead of the city. On a few occasions she did go after money opportunities-- like appearing on a game show-- but the premise of the episode was never that the family's economic security was in doubt. Instead, the woman grasping after success was characterized as reaching at "even more" economic success for "already successful" households.</p>

<p>In reality, in this era, the work situation was anything but rosy or optional. Firms like Manpower and Kelly Girl were discovering the power of the female "temp" workforce. Why pay a full-time (male) clerk (who would expect benefits and a pension) when you could just as easily hire a Kelly Girl "temp" who was "just doing this for some extra money" and didn't have to be paid-- even thought of-- if she were sick, unavailable, or anything else. You were paying Kelly Girl, and if your usual Kelly Girl was unavailable, they'd just send a different one.</p>

<p>These details of women entering the workplace are detailed in TEMP by Louis Hyman, who is a labor economist at Cornell. In his book, he makes the point that in the post-war 20th Century, women were essential in establishing the idea of "temp" labor, and once big corporate management consultancy firms (McKinsey being the big one) figured out how much more profitable it was to hire only temp workers-- the economy was forever changed.</p>

<p>But the real changes in the economy were light-years ahead of what we saw on TV. In 1977 we saw the release of The Mary Tyler Moore Show: a big deal because it featured a single woman renting an apartment and holding a newspaper job on her own: contrasted by Phyllis, of course, a "normal" woman with a child and husband. But there was also Rhoda, Mary's "weird" neighbor who washed her own windows and wore trousers. Fifty years ago, these details were groundshaking.</p>

<p>Anyway, fast forward through the series of spinoffs from the MGM TV world and Norman Lear's universe to pause briefly on Edith Bunker. Here again-- 25 years after Lucy-- was a homemaker wife who would never even DREAM of holding a job other than taking care of her husband. And suddenly-- magically-- that's what makes her ridiculous. Edith is always portrayed as the voice of... well-- if not reason-- common sense maybe. And although Archie Bunker's household is still living as if it's the 1950s... they're certainly not living as well as Lucy did in the 1950s... Meathead is not afraid to point this out. Edith is.</p>

<p>Moving on further: the pilot of Cheers. 1980s now. Diane enters Cheers to enjoy a toast: she's just gotten engaged. But her fiancé runs off to be with his ex wife so suddenly... she needs a job? What an unusual and unexpected position for an educated white woman to be in!? She takes the job but immediately the stakes turn into a sexual ping-pong match between her and her boss. I guess the idea that she was even at the table was considered revolutionary.</p>

<p>Later, there was Murphy Brown. She was the opposite of all these sitcom wives: married to her career. Sexless. But a woman! And hot! The writers couldn't resist and eventually a pregnancy story got built into the show, which Dan Quayle-- Vice-President-at-the-Time who once spelled potato wrong and for a brief period of time that's the stupidest we thought Republicans could ever be-- took great offense to. Anyway he tried to burn Murphy Brown but historically speaking he was too stupid to and failed. The show carried on for several seasons including Murphy once stealing the 'T' off TRUMP Tower but the point was always that she was some sort of exceptional, outsize woman, not anybody normal. A woman, but not a wife. This was new and revolutionary.</p>

<p>So we've reached Peg Bundy. After generations where the hits had sterling, strong wives: why was she a bon-bon eating, stay at home manicurist? And why was it so successful? Well... in a weird way... because it was new. As much as these outsider perspectives on women in television had on women making advancements in the field of women's equality, there were still lots of places in America (and then later, the rest of the world) where women had NOT seen the sort of economic and labor equalizing forces that defined the 20th Century. </p>

<p>Married With Children became a huge international hit. In Russia it aired five nights a week: they recreated the entire English language series, then commissioned the original American writing staff to write an entire extra season that would air in Russia (and then get re-broadcast in Ukraine, Poland, etc.). </p>

<p>My point is that since there was such a social incentive to make the point that your wife didn't "need" to work, she just did to "get out of the house" or whatever, the idea of working women wasn't normalized on television until the late 90s, when Al Bundy: supporter of a decadent wife and even more decadent children became the face of "enough is enough". Men saw-- through Al Bundy-- an economy that had long ceased to exist (a single male breadwinner; no education but the expectation is to put the kids through college) and didn't get the joke. You're out here checking Chicago real estate prices instead of asking the bigger question: were single-income retail families viable in the 1990s? No. They were not. </p>

<p>What this meant for women was especially tough. There was a tacit understanding that going to work was something "everyone was doing" but was also "not normal". That can't hold for long. In the  late 90s and early 00s we see and justify women working (in general) with them excelling in female-driven careers: Monica is a chef; Rachel is a personal shopper at Bloomingdales. We've since moved on from a family dynamic in the Chicago suburbs and are looking at a sitcom area dominated by childless attractive people unstressed by the worries that 9/11 might convey.</p>

<p>And we've been carrying forward our unwillingness to confront those troubles for 20 years now. </p>

<p>I am struggling to imagine a broadly successful sitcom pilot in which we don't ask the question, "but why does the wife have a job?" The best answer might be Modern Family. That pilot aired in 2009, and still, the answer was <em>because she works for her dad</em>. </p>

<p>The good question isn't 'why doesn't Peg Bundy have a job in the early 90's'. The good question is "why, in the early 90's, would we look at Peg Bundy and assume she's real?" That question has everything to do with a calculated effort to denormalize women as equal contributors to the household and hypernormalize the male breadwinner at a time when it was so anti-normal that we were there to laugh at it. As we're seeing now: people adhere to old visions of society until a big impact occasion forces them to change focus.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/AskHistorians/comments/ggozng/in_the_sitcom_married_with_children_protagonist/fq961ju/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After 151 years, Popular Science will no longer offer a magazine (223 pts)]]></title>
            <link>https://www.theverge.com/2023/11/27/23978042/popular-science-digital-magazine-discontinued</link>
            <guid>38439817</guid>
            <pubDate>Mon, 27 Nov 2023 23:06:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/11/27/23978042/popular-science-digital-magazine-discontinued">https://www.theverge.com/2023/11/27/23978042/popular-science-digital-magazine-discontinued</a>, See on <a href="https://news.ycombinator.com/item?id=38439817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>After 151 years, <em>Popular Science</em> will no longer be available to purchase as a magazine. In a statement to <em>The Verge</em>, Cathy Hebert, the communications director for <em>PopSci</em> owner Recurrent Ventures, says the outlet needs to “evolve” beyond its magazine product, which published its <a href="https://www.popsci.com/story/science/popsci-spring-2021-digital-issue/">first all-digital issue in 2021</a>.</p><p><em>PopSci</em>, which covers a whole range of stories related to the fields of science, technology, and nature, published its first issue in 1872. Things have changed a lot over the years, with the magazine <a href="https://nypost.com/2018/07/07/this-mag-accurately-predicted-the-future-95-years-ago/">switching to a quarterly publication</a> schedule in 2018 and doing away with the physical copies altogether after 2020.</p><section tabindex="0" aria-label="Zoom" role="button"><p><span><img alt="<em>The November 1921 issue of </em>Popular Science." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/376x522/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/384x533/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/415x576/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/480x666/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/540x749/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/640x888/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/750x1041/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/828x1149/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/1080x1499/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/1200x1665/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/1440x1998/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/1920x2664/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/2048x2842/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/2400x3330/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:686x952/2400x3330/filters:focal(343x476:344x477):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115638/PopularScienceNovember1921.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><span><img alt="<em>The July 1922 issue of </em>Popular Science<em>.</em>" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/376x531/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/384x542/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/415x586/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/480x677/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/540x762/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/640x903/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/750x1058/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/828x1169/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/1080x1524/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/1200x1694/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/1440x2032/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/1920x2710/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/2048x2890/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/2400x3387/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:680x960/2400x3387/filters:focal(340x480:341x481):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115637/PopularScienceJuly1922.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><span><img alt="<em>The January 1925 issue of </em>Popular Science." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/376x535/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/384x547/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/415x591/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/480x683/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/540x769/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/640x911/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/750x1068/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/828x1179/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/1080x1538/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/1200x1709/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/1440x2050/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/1920x2734/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/2048x2916/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/2400x3417/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1224/2400x3417/filters:focal(430x612:431x613):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115635/PopularScienceJanuary1925.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><span><img alt="<em>The April 1925 issue of </em>Popular Science." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/376x530/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/384x541/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/415x585/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/480x676/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/540x761/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/640x902/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/750x1057/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/828x1166/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/1080x1521/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/1200x1691/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/1440x2029/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/1920x2705/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/2048x2885/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/2400x3381/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:860x1212/2400x3381/filters:focal(430x606:431x607):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115632/PopularScienceApril1925.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><span><img alt="<em>The December 1925 issue of </em>Popular Science." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/376x529/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/384x540/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/415x584/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/480x676/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/540x760/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/640x901/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/750x1056/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/828x1165/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/1080x1520/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/1200x1689/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/1440x2027/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/1920x2702/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/2048x2883/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/2400x3378/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:894x1258/2400x3378/filters:focal(447x629:448x630):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25115634/PopularScienceDecember1925.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><div><p>1<!-- -->/<!-- -->5</p><div><figcaption><em>The November 1921 issue of </em>Popular Science.</figcaption> <p><cite>Image: Popular Science via Wikimedia Commons</cite></p></div></div></section><p>In <a href="https://www.linkedin.com/posts/bita-saha_popularscience-activity-7130385752944750592--B1o?utm_source=share&amp;utm_medium=member_android">a post on LinkedIn</a>, former <em>PopSci</em> editor Purbita Saha commented on the magazine’s discontinuation, stating she’s “frustrated, incensed, and appalled that the owners shut down a pioneering publication that’s adapted to 151 years worth of changes in the space of a five-minute Zoom call.” Layoffs have impacted journalists on the science beat particularly hard in recent weeks. <a href="https://www.cnn.com/2023/06/28/media/national-geographic-magazine-staff-writers/index.html"><em>National Geographic</em> cut</a> the remainder of the magazine’s editorial staff in June, followed by <a href="https://www.linkedin.com/posts/angelymercado_climatechange-climatejournalism-climatejustice-activity-7128768163462148098-pKWd?utm_source=share&amp;utm_medium=member_desktop"><em>Gizmodo</em> laying off</a> its last climate reporter, and <a href="https://talkingbiznews.com/media-news/climate-reporter-clifford-among-those-laid-off-at-cnbc-com/">CNBC shuttering its climate desk</a> last week.</p><p>“PopSci is a phenomenal brand, and as consumer trends shift it’s important we prioritize investment in new formats,” Herbert tells <em>The Verge</em>. “We believe that the content strategy has to evolve beyond the digital magazine product. A combination of its news team, along with commerce, video, and other initiatives, will produce content that naturally aligns with PopSci’s mission.”</p><div><p>PopSci laid off several employees earlier this month, leaving around five editorial staff members</p></div><p>In addition to dropping its magazine format, <em>PopSci</em> laid off several employees earlier this month, leaving around five editorial staff members and “a few” workers on the publication’s commerce team, <a href="https://www.axios.com/2023/11/13/recurrent-ventures-layoffs">according to <em>Axios</em></a>. The digital media group Recurrent Ventures <a href="https://www.prnewswire.com/news-releases/recurrent-ventures-named-the-new-parent-company-of-popular-science-the-drive-domino-field--stream-and-other-brands-301312885.html">acquired <em>PopSci</em></a><em> </em>in 2021 and <a href="https://www.adweek.com/media/recurrent-ventures-new-ceo-andrew-perlman/">named its third CEO</a> in three years just one week before the layoffs hit. </p><p><em>PopSci</em> will continue to offer articles on its website, along with its PopSci Plus subscription, which offers access to exclusive content and the magazine’s archive. However, its discontinuation marks the end of an era, and the other cuts across the science journalism field won’t make it easier to stay up to date on the <a href="https://www.theverge.com/2023/11/20/23969101/temperature-check-climate-change-united-nations-negotiations-dubai">state of our climate</a> or dive into <a href="https://www.theverge.com/c/23307867/human-composting-process-return-home">fascinating stories</a> that you might not otherwise come across without the media outlets that bring them to our attention.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's try to understand AI monosemanticity (271 pts)]]></title>
            <link>https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand</link>
            <guid>38438261</guid>
            <pubDate>Mon, 27 Nov 2023 21:04:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand">https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand</a>, See on <a href="https://news.ycombinator.com/item?id=38438261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>You’ve probably heard AI is a “black box”. No one knows how it works. Researchers simulate a weird type of pseudo-neural-tissue, “reward” it a little every time it becomes a little more like the AI they want, and eventually it becomes the AI they want. But God only knows what goes on inside of it.</p><p>This is bad for safety. For safety, it would be nice to look inside the AI and see whether it’s executing an algorithm like “do the thing” or more like “trick the humans into thinking I’m doing the thing”. But we can’t. Because we can’t look inside an AI at all. </p><p><span>Until now! </span><strong><a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html" rel="">Towards Monosemanticity</a></strong><span>, recently out of big AI company/research lab Anthropic, claims to have gazed inside an AI and seen its soul. It looks like this:</span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 848w, https://substackcdn.com/image/fetch/w_1228,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 1228w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 1456w, https://substackcdn.com/image/fetch/w_2456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 2456w, https://substackcdn.com/image/fetch/w_3684,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 3684w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1228,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 848w, https://substackcdn.com/image/fetch/w_1228,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 1228w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 1456w, https://substackcdn.com/image/fetch/w_2456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 2456w, https://substackcdn.com/image/fetch/w_3684,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5a9650-204e-4170-a6ca-6cd357bacbca_780x487.png 3684w" width="1228"></picture></div></figure><p><span>How did they do it? What </span><em>is</em><span> inside of an AI? And what the heck is “monosemanticity”?</span></p><p><em>[disclaimer: after talking to many people much smarter than me, I might, just barely, sort of understand this. Any mistakes below are my own.]</em></p><p>A stylized neural net looks like this:</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F510ef384-8418-413e-9494-eb7fe63318a8_700x350.png 4368w" width="1456"></picture></div></figure><p>Input neurons (blue) take information from the world. In an image AI, they might take the values of pixels in the image; in a language AI, they might take characters in a text.</p><p>These connect to interneurons (black) in the “hidden layers”, which do mysterious things.</p><p>Then those connect to output neurons (green). In an image AI, they might represent values of pixels in a piece of AI art; in a language AI, characters in the chatbot response.</p><p>“Understanding what goes on inside an AI” means understanding what the black neurons in the middle layer do.</p><p>A promising starting point might be to present the AI with lots of different stimuli, then see when each neuron does vs. doesn’t fire. For example, if there’s one neuron that fires every time the input involves a dog, and never fires any other time, probably that neuron is representing the concept “dog”.</p><p>Sounds easy, right? A good summer project for an intern, right?</p><p>There are at least two problems.</p><p>First, GPT-4 has over 100 billion neurons (the exact number seems to be secret, but it’s somewhere up there).</p><p><span>Second, this doesn’t work. When you switch to a weaker AI with “only” a few hundred neurons and build special tools to automate the stimulus/analysis process, the neurons aren’t this simple. A few low-level ones respond to basic features (like curves in an image). But deep in the middle, where the real thought has to be happening, there’s nothing representing “dog”. Instead, the neurons are much weirder than this. In one image model, an </span><a href="https://distill.pub/2020/circuits/zoom-in/" rel="">earlier paper</a><span> found “one neuron that responds to cat faces, fronts of cars, and cat legs”. The authors described this as “polysemanticity” - multiple meanings for one neuron.</span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 1272w, https://substackcdn.com/image/fetch/w_1358,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 1358w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 1456w, https://substackcdn.com/image/fetch/w_2716,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 2716w, https://substackcdn.com/image/fetch/w_4074,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 4074w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1358,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png" sizes="100vw" alt="Bizarre pictures resembling psychedelic cat faces, car fronts, and cat legs." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 1272w, https://substackcdn.com/image/fetch/w_1358,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 1358w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 1456w, https://substackcdn.com/image/fetch/w_2716,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 2716w, https://substackcdn.com/image/fetch/w_4074,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff7b0831-f9c5-4c69-aa63-11c124788f8a_606x205.png 4074w" title="The three images that most strongly activate neuron 4e:55" width="1358"></picture><figcaption>The three images that most strongly activate neuron 4e:55</figcaption></div></figure><p><span>Some very smart people spent a lot of time trying to figure out what conceptual system could make neurons behave like this, and came up with the </span><strong><a href="https://transformer-circuits.pub/2022/toy_model/index.html" rel="">Toy Models Of Superposition</a></strong><span> paper.</span></p><p>Their insight is: suppose your neural net has 1,000 neurons. If each neuron represented one concept, like “dog”, then the net could, at best, understand 1,000 concepts. Realistically it would understand many fewer than this, because in order to get dogs right, it would need to have many subconcepts like “dog’s face” or “that one unusual-looking dog”. So it would be helpful if you could use 1,000 neurons to represent much more than 1,000 concepts.</p><p><span>Here’s a way to make two neurons represent five concepts (</span><a href="https://transformer-circuits.pub/2022/toy_model/index.html" rel="">adapted from here</a><span>):</span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ec5a30b-ddcb-4114-8b1d-bca34aef713f_472x393.png 4368w" width="1456"></picture></div></figure><p>If neuron A is activated at 0.5, and neuron B is activated at 0, you get “dog”. </p><p>If neuron A is activated at 1, and neuron B is activated at 0.5, you get “apple”. </p><p>And so on.</p><p>The exact number of vertices in this abstract shape is a tradeoff. More vertices means that the two-neuron-pair can represent more concepts. But it also risks confusion. If you activate the concepts “dog” and “heart” at the same time, the AI might interpret this as “apple”. And there’s some weak sense in which the AI interprets “dog” as “negative eye”.</p><p>This theory is called “superposition”. Do AIs really do it? And how many vertices do they have on their abstract shapes?</p><p><span>The Anthropic interpretability team trained a very small, simple AI. It needed to remember 400 features, but it had only 30 neurons, so it would have to try something like the superposition strategy. Here’s what they found (slightly edited from </span><a href="https://transformer-circuits.pub/2022/toy_model/index.html" rel="">here</a><span>):</span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157938c0-cc3b-4bfa-8c21-7513581cca04_1433x1046.png 4368w" width="1456"></picture></div></figure><p>Follow the black line. On the far left of the graph, the data is dense; you need to think about every feature at the same time. Here the AI assigns one neuron per concept (meaning it will only ever learn 30 of the 400 concepts it needs to know, and mostly fail the task).</p><p>Moving to the right, we allow features to be less common - the AI may only have to think about a few at a time. The AI gradually shifts to packing its concepts into tetrahedra (three neurons per four concepts) and triangles (two neurons per three concepts). When it reaches digons (one neuron per two concepts) it stops for a while (to repackage everything this way?) Next it goes through pentagons and an unusual polyhedron called the “square anti-prism” . . . </p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 424w, https://substackcdn.com/image/fetch/w_632,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 632w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 848w, https://substackcdn.com/image/fetch/w_1264,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1264w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1456w, https://substackcdn.com/image/fetch/w_1896,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1896w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_632,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 424w, https://substackcdn.com/image/fetch/w_632,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 632w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 848w, https://substackcdn.com/image/fetch/w_1264,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1264w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1456w, https://substackcdn.com/image/fetch/w_1896,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72403ec2-1c5e-4e15-92c1-0095cc089258_950x893.png 1896w" title="Source: https://en.wikipedia.org/wiki/Square_antiprism#/media/File:Square_antiprism.png" width="632"></picture><figcaption>Source: https://en.wikipedia.org/wiki/Square_antiprism#/media/File:Square_antiprism.png</figcaption></div></figure><p><span>. . . which </span><a href="https://en.wikipedia.org/wiki/Biscornu" rel="">Wikipedia says</a><span> is best known for being the shape of the </span><a href="https://en.wikipedia.org/wiki/Biscornu" rel="">biscornu</a><span> (a “stuffed ornamental pincushion”) and </span><a href="https://en.wikipedia.org/wiki/One_World_Trade_Center" rel="">One World Trade Center</a><span> in New York:</span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png" sizes="100vw" alt="Picture of a pincushion and One World Trade Center" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2707d6a2-bb85-49c6-a160-fe98e0de184b_1128x403.png 4368w" title="Freedom Tower confirmed as fundamental to the nature of thought itself; America can't stop winning." width="1456"></picture><figcaption>Freedom Tower confirmed as fundamental to the nature of thought itself; America can't stop winning.</figcaption></div></figure><p>After exhausting square anti-prisms (8 features per three neurons) it gives up. Why? I don’t know. </p><p>A friend who understands these issues better than I warns that we shouldn’t expect to find pentagons and square anti-prisms in GPT-4. Probably GPT-4 does something incomprehensible in 1000-dimensional space. But it’s the 1000-dimensional equivalent of these pentagons and square anti-prisms, conserving neurons by turning them into dimensions and then placing concepts in the implied space.</p><p><span>The Anthropic interpretability team describes this as simulating a more powerful AI. That is, the two-neuron AI in the pentagonal toy example above is simulating a five-neuron AI. They go on to prove that the real AI can then run computations in the simulated AI; in some sense, there really </span><em>is</em><span> an abstract five neuron AI doing all the cognition. The only reason all of our AIs aren’t simulating infinitely powerful AIs and letting </span><em>them</em><span> do all the work is that as real neurons start representing more and more simulated neurons, it produces more and more noise and conceptual interference.</span></p><p><span>This is great for AIs but bad for interpreters. We hoped we could figure out what our AIs were doing just by looking at them. But it turns out they’re simulating much bigger and more complicated AIs, and if we want to know what’s going on, we have to look at </span><em>those</em><span>. But </span><em>those</em><span> AIs only exist in simulated abstract hyperdimensional spaces. Sounds hard to dissect!</span></p><p>Still, last month Anthropic’s interpretability team announced that they successfully dissected of one of the simulated AIs in its abstract hyperdimensional space. </p><p><span>(finally, we’re back to </span><a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html" rel="">the monosemanticity paper</a><span>!)</span></p><p>First the researchers trained a very simple 512-neuron AI to predict text, like a tiny version of GPT or Anthropic’s competing model Claude.</p><p>Then, they trained a second AI called an autoencoder to predict the activations of the first AI. They told it to posit a certain number of features (the experiments varied between ~2,000 and ~100,000), corresponding to the neurons of the higher-dimensional AI it was simulating. Then they made it predict how those features mapped onto the real neurons of the real AI.</p><p><span>They found that even though the original AI’s neurons weren’t comprehensible, the new AI’s simulated neurons (aka “features”) were! They were </span><em>monosemantic</em><span>, ie they meant one specific thing.</span></p><p><span>Here’s </span><a href="https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html#feature-2663" rel="">feature #2663</a><span> (remember, the original AI only had 512 neurons, but they’re treating it as simulating a larger AI with up to ~100,000 neuron-features). </span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb112770b-f685-4974-9cfb-16230cf4cdb0_1065x642.png 4368w" width="1456"></picture></div></figure><p>Feature #2663 represents God.</p><p>The single sentence in the training data that activated it most strongly is from Josephus, Book 14: “And he passed on to Sepphoris, as God sent a snow”. But we see that all the top activations are different uses of “God”.</p><p>This simulated neuron seems to be composed of a collection of real neurons including 407, 182, and 259, though probably there are many more than these and the interface just isn’t showing them to me. </p><p><span>None of these neurons are themselves very Godly. When we look at </span><a href="https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html#feature-407" rel="">neuron #407</a><span> - the real neuron that contributes most to the AI’s understanding of God! - an AI-generated summary describes it as “fir[ing] primarily on non-English text, particularly accented Latin characters. It also occasionally fires on non-standard text like HTML tags.” Probably this is because you can’t really understand AIs at the real-neuron-by-real-neuron level, so the summarizing AI - having been asked to do this impossible thing - is reading tea leaves and saying random stuff.</span></p><p>But at the feature level, everything is nice and tidy! Remember, this AI is trying to predict the next token in a text. At this level, it does so intelligibly. When Feature #2663 is activated, it increases the probability of the next token being “bless”, “forbid”, “damn”, or “-zilla”.</p><p>Shouldn’t the AI be keeping the concept of God, Almighty Creator and Lord of the Universe, separate from God- as in the first half of Godzilla? Probably GPT-4 does that, but this toy AI doesn’t have enough real neurons to have enough simulated neurons / features to spare for the purpose. In fact, you can see this sort of thing change later in the paper:</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 848w, https://substackcdn.com/image/fetch/w_1194,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 1194w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 1456w, https://substackcdn.com/image/fetch/w_2388,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 2388w, https://substackcdn.com/image/fetch/w_3582,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 3582w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1194,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 848w, https://substackcdn.com/image/fetch/w_1194,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 1194w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 1456w, https://substackcdn.com/image/fetch/w_2388,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 2388w, https://substackcdn.com/image/fetch/w_3582,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47311206-f51c-4142-b7ba-3baa17a949dc_1072x1474.png 3582w" width="1194"></picture></div></figure><p>At the bottom of this tree, you can see what happens to the AI’s representation of “the” in mathematical terminology as you let it have more and more features.</p><p>First: why is there a feature for “the” in mathematical terminology? I think because of the AI’s predictive imperative - it’s helpful to know that some specific instance of “the” should be followed by math words like “numerator” or “cosine”. </p><p>In their smallest AI (512 features), there is only one neuron for “the” in math. In their largest AI tested here (16,384 features), this has branched out to one neuron for “the” in machine learning, one for “the” in complex analysis, and one for “the” in topology and abstract algebra.</p><p>So probably if we upgraded to an AI with more simulated neurons, the God neuron would split in two - one for God as used in religions, one for God as used in kaiju names. Later we might get God in Christianity, God in Judaism, God in philosophy, et cetera.</p><p>Not all features/simulated-neurons are this simple. But many are. The team graded 412 real neurons vs. simulated neurons on subjective interpretability, and found the simulated neurons were on average pretty interpretable:</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e75c4cc-254c-46fb-b217-d6fbbbc1aa8a_1368x496.png 4368w" width="1456"></picture></div></figure><p>Some, like the God neuron, are for specific concepts. Many others, including some of the most interpretable, are for “formal genres” of text, like whether it’s uppercase or lowercase, English vs. some other alphabet, etc.</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0c1a581-9cb0-4391-b338-7b4930e1e43b_1020x344.png 4368w" width="1456"></picture></div></figure><p>How common are these features? That is, suppose you train two different 4,096-feature AIs on the same text datasets. Will they have mostly the same 4,096 features? Will they both have some feature representing God? Or will the first choose to represent God together with Godzilla, and the second choose to separate them? Will the second one maybe not have a feature for God at all, instead using that space to store some other concept the first AI can’t possibly understand? </p><p>The team tests this, and finds that their two AIs are pretty similar! On average, if there’s a feature in the first one, the most similar feature in the second one will “have a median correlation of 0.72”.</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 4368w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 1456w, https://substackcdn.com/image/fetch/w_2912,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 2912w, https://substackcdn.com/image/fetch/w_4368,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d36d3c2-1461-4bff-9582-9f8a8a860756_1371x794.png 4368w" width="1456"></picture></div></figure><p>What comes after this?</p><p><span>In May of this year, OpenAI </span><a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models" rel="">tried to make GPT-4 (very big) understand GPT-2 (very small)</a><span>. They got GPT-4 to inspect each of GPT-2’s 307,200 neurons and report back on what it found.</span></p><p>It found a collection of intriguing results and random gibberish, because they hadn’t mastered the techniques described above of projecting the real neurons into simulated neurons and analyzing the simulated neurons instead. Still, it was impressively ambitious. Unlike the toy AI in the monosemanticity paper, GPT-2 is a real (albeit very small and obsolete) AI that once impressed people.</p><p>But what we really want is to be able to interpret the current generation of AIs. The Anthropic interpretability team admits we’re not there yet, for a few reasons.</p><p><em>First</em><span>, scaling the autoencoder:</span></p><blockquote><p>Scaling the application of sparse autoencoders to frontier models strikes us as one of the most important questions going forward. We're quite hopeful that these or similar methods will work – Cunningham et al.'s work seems to suggest this approach can work on somewhat larger models, and we have preliminary results that point in the same direction. However, there are significant computational challenges to be overcome. Consider an autoencoder with a 100× expansion factor applied to the activations of a single MLP layer of width 10,000: it would have ~20 billion parameters. Additionally, many of these features are likely quite rare, potentially requiring the autoencoder to be trained on a substantial fraction of the large model's training corpus. So it seems plausible that training the autoencoder could become very expensive, potentially even more expensive than the original model. We remain optimistic, however, and there is a silver lining – it increasingly seems like a large chunk of the mechanistic interpretability agenda will now turn on succeeding at a difficult engineering and scaling problem, which frontier AI labs have significant expertise in.</p></blockquote><p>In other words, in order to even begin to interpret an AI like GPT-4 (or Anthropic’s equivalent, Claude), you would need an interpreter-AI around the same size. But training an AI that size takes a giant company and hundreds of millions (soon billions) of dollars. </p><p><em>Second</em><span>, scaling the interpretation. Suppose we find all the simulated neurons for God and Godzilla and everything else, and have a giant map of exactly how they connect, and hang that map in our room. Now we want to answer questions like:</span></p><ul><li><p>If you ask the AI a controversial question, how does it decide how to respond?</p></li><li><p>Is the AI using racial stereotypes in forming judgments of people?</p></li><li><p>Is the AI plotting to kill all humans?</p></li></ul><p>There will be some combination of millions of features and connections that answers these questions. In some case we can even imagine how we would begin to do it - check how active the features representing race are when we ask it to judge people, maybe. But realistically, when we’re working with very complex interactions between millions of neurons we’ll have to automate the process, some larger scale version of “ask GPT-4 to tell us what GPT-2 is doing”. </p><p><span>This probably works for racial stereotypes. It’s more complicated once you start asking about killing all humans (what if the GPT-4 equivalent is the one plotting to kill all humans, and feeds us false answers?) But maybe there’s some way to make an interpreter AI which itself is too dumb to plot, but which can interpret a more general, more intelligent, more dangerous AI. You can see more about how this could tie into more general alignment plans in </span><a href="https://www.astralcodexten.com/p/elk-and-the-problem-of-truthful-ai" rel="">the post on the ELK problem</a><span>. I also just found </span><a href="https://www.ai-transparency.org/" rel="">this paper</a><span>, which I haven’t fully read yet but which seems like a start on engineering safety into interpretable AIs.</span></p><p>Finally, what does all of this tell us about humans?</p><p>Humans also use neural nets to reason about concepts. We have a lot of neurons, but so does GPT-4.  Our data is very sparse - there are lots of concepts (eg octopi) that come up pretty rarely in everyday life. Are our brains full of strange abstract polyhedra? Are we simulating much bigger brains?</p><p><span>This field is very new, but I was able to find one paper, </span><a href="https://arxiv.org/abs/2310.11431" rel="">Identifying Interpretable Visual Features in Artificial and Biological Neural Systems</a><span>. The authors say:</span></p><blockquote><p>Through a suite of experiments and analyses, we find evidence consistent with the hypothesis that neurons in both deep image model [AIs] and the visual cortex [of the brain] encode features in superposition. That is, we find non-axis aligned directions in the neural state space that are more interpretable than individual neurons. In addition, across both biological and artificial systems, we uncover the intriguing phenomenon of what we call feature synergy - sparse combinations in activation space that yield more interpretable features than the constituent parts. Our work pushes in the direction of automated interpretability research for CNNs, in line with recent efforts for language models. Simultaneously, it provides a new framework for analyzing neural coding properties in biological systems.</p></blockquote><p><span>This is a single non-peer-reviewed paper announcing a surprising claim in a hype-filled field. That means it </span><em>has</em><span> to be true - otherwise it would be unfair!</span></p><p>If this topic interests you, you might want to read the full papers, which are much more comprehensive and interesting than this post was able to capture. My favorites are:</p><ul><li><p><a href="https://distill.pub/2020/circuits/zoom-in/" rel="">An Introduction To Circuits</a></p></li><li><p><a href="https://transformer-circuits.pub/2022/toy_model/index.html" rel="">Toy Models of Superposition</a></p></li><li><p><a href="https://transformer-circuits.pub/2023/superposition-composition/index.html" rel="">Distribution Representations: Composition &amp; Superposition</a></p></li><li><p><a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html" rel="">Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</a></p></li></ul><p><span>In the unlikely scenario where all of this makes total sense and you feel like you’re ready to make contributions, you might be a good candidate for Anthropic or OpenAI’s alignment teams, both of which are hiring. If you feel like it’s the sort of thing which </span><em>could</em><span> make sense and you want to transition into learning more about it, you might be a good candidate for alignment training/scholarship programs like </span><a href="https://www.matsprogram.org/" rel="">MATS</a><span>.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cheaper microscope could bring protein mapping technique to the masses (128 pts)]]></title>
            <link>https://www.science.org/content/article/cheaper-microscope-could-bring-protein-mapping-technique-masses</link>
            <guid>38438000</guid>
            <pubDate>Mon, 27 Nov 2023 20:45:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/cheaper-microscope-could-bring-protein-mapping-technique-masses">https://www.science.org/content/article/cheaper-microscope-could-bring-protein-mapping-technique-masses</a>, See on <a href="https://news.ycombinator.com/item?id=38438000">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/cheaper-microscope-could-bring-protein-mapping-technique-masses: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[AI SDR which automatically finds and converts leads for Your business (484 pts)]]></title>
            <link>https://jusdr.com</link>
            <guid>38437114</guid>
            <pubDate>Mon, 27 Nov 2023 19:38:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jusdr.com">https://jusdr.com</a>, See on <a href="https://news.ycombinator.com/item?id=38437114">Hacker News</a></p>
Couldn't get https://jusdr.com: Error: getaddrinfo ENOTFOUND jusdr.com]]></description>
        </item>
        <item>
            <title><![CDATA[Strange Metals: Where electricity may flow without electrons (125 pts)]]></title>
            <link>https://www.quantamagazine.org/meet-strange-metals-where-electricity-may-flow-without-electrons-20231127/</link>
            <guid>38436851</guid>
            <pubDate>Mon, 27 Nov 2023 19:18:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/meet-strange-metals-where-electricity-may-flow-without-electrons-20231127/">https://www.quantamagazine.org/meet-strange-metals-where-electricity-may-flow-without-electrons-20231127/</a>, See on <a href="https://news.ycombinator.com/item?id=38436851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>After a year of trial and error, Liyang Chen had managed to whittle down a metallic wire into a microscopic strand half the width of an <em>E.coli</em> bacterium — just thin enough to allow a trickle of electric current to pass through. The drips of that current might, Chen hoped, help settle a persistent mystery about how charge moves through a bewildering class of materials known as strange metals.</p>
<p>Chen, then a graduate student, and his collaborators at Rice University measured the current flowing through their atoms-thin strand of metal. And they found that it flowed smoothly and evenly. So evenly, in fact, that it defied physicists’ standard conception of electricity in metals.</p>
<p>Canonically, electric current results from the collective movement of electrons, each carrying one indivisible chunk of electric charge. But the dead steadiness of Chen’s current implied that it wasn’t made of units at all. It was like finding a liquid that somehow lacked individually recognizable molecules.</p>
<p>While that might sound outlandish, it’s exactly what some physicists expected from the metal the group tested, which along with its unusual kin has beguiled and bewildered physicists since the 1980s. “It’s a very beautiful piece of work,” said <a href="http://sachdev.physics.harvard.edu/">Subir Sachdev</a>, a theoretical physicist at Harvard University who specializes in strange metals.</p>
<p>The observation, <a href="https://www.science.org/doi/10.1126/science.abq6100">reported last week</a> in the journal <em>Science</em>, is one of the most straightforward indications yet that whatever carries current through these unusual metals doesn’t look anything like electrons. The new experiment strengthens suspicions that a new quantum phenomenon is arising within strange metals. It also provides new grist for theoretical physicists attempting to understand what it might be.<strong><em>&nbsp;</em></strong></p>
<p>“Strange metals, no one has any earthly idea where they’re coming from,” said <a href="https://physics.illinois.edu/people/directory/profile/abbamont">Peter Abbamonte</a>, a physicist at the University of Illinois, Urbana-Champaign. “It used to be considered an inconvenience, but now we realize it’s really a different phase of matter living in these things.”</p>
<h2><strong>A Cuprate Wrench</strong></h2>
<p>The first challenge to the conventional understanding of metals came in 1986, when Georg Bednorz and Karl Alex Müller rocked the physics world with their discovery of high-temperature superconductors — materials that perfectly carry an electric current even at relatively warm temperatures. Familiar metals like tin and mercury become superconductors only when chilled to within a few degrees of absolute zero. Bednorz and Müller measured the electrical resistance in a copper-based (“cuprate”) material and saw that it vanished at a relatively balmy 35 kelvins. (For their breakthrough discovery, Bednorz and Müller pocketed a Nobel Prize just a year later.)</p>

<p>Physicists soon realized that high-temperature superconductivity was only the beginning of the mysterious behavior of the cuprates.</p>
<p>The cuprates got really weird when they stopped superconducting and started resisting. As all metals warm, resistance increases. Warmer temperatures mean atoms and electrons jiggle more, creating more resistance-inducing collisions as electrons shuttle current through a material. In normal metals, such as nickel, resistance rises quadratically at low temperatures — slowly at first and then faster and faster. But in the cuprates, it rose linearly: Each degree of warming brought the same increase in resistance — a bizarre pattern that continued over hundreds of degrees and, in terms of strangeness, overshadowed the material’s superconducting ability. The cuprates were the strangest metals researchers had ever seen.</p>
<p>“Superconductivity is a mouse,” said <a href="https://cse.umn.edu/physics/andrey-chubukov">Andrey Chubukov</a>, a theoretical physicist at the University of Minnesota. “The elephant … is this strange metal behavior.”</p>
<p>The linear rise in resistance threatened a celebrated explanation of how electric charge moves through metals. Proposed in 1956, Lev Landau’s “Fermi liquid” theory placed electrons at the center of it all. It built upon earlier theories that, for simplicity, assumed that electrons carry electric current, and that the electrons move through a metal like a gas; they flit freely between atoms without interacting with each other.</p>
<p>Landau added a way of handling the crucial but complicated fact that electrons interact. They are negatively charged, which means they constantly repel each other. Considering this interaction between the particles transformed the electron gas into something of an ocean — now, as one electron moved through the fluid of electrons, it disturbed the nearby electrons. Through a complicated series of interactions involving mutual repulsion, these now gently interacting electrons ended up traveling in crowds — in clumps known as quasiparticles.</p>

<p>The miracle of Fermi liquid theory was that each quasiparticle behaved almost exactly as if it were a single, fundamental electron. One major difference, though, was that these blobs moved more sluggishly or more nimbly (depending on the material) than a bare electron, effectively acting heavier or lighter. Now, just by adjusting the mass terms in their equations, physicists could continue to treat current as the movement of electrons, only with an asterisk specifying that each electron was really a quasiparticle clump.</p>
<p>A major triumph of Landau’s framework was that in normal metals, it nailed the complicated way in which resistance rises quadratically with temperature. Electron-like quasiparticles became the standard way of understanding metals. “It’s in every textbook,” Sachdev said.</p>
<p>But in the cuprates, Landau’s theory failed dramatically. Resistance rose in an immaculate line rather than the standard quadratic curve. Physicists have long interpreted this line as a sign that cuprates are home to a new physical phenomenon.</p>
<p>“You pretty much have to believe that nature is either giving you a clue or nature is incredibly cruel,” said <a href="https://physics.fsu.edu/person/gregory-boebinger">Gregory Boebinger</a>, a physicist at Florida State University who has spent much of his career studying the cuprates’ linear response. “To put up such a terribly simple and beguiling signature and to have it not be physically important would just be too much to bear.”</p>

<p>And the cuprates were just the beginning. Researchers have since discovered a <a href="https://www.science.org/doi/10.1126/science.abh4273">host of disparate materials</a> with the same alluring linear resistance, including organic “Bechgaard salts” and misaligned sheets of graphene. As these “strange metals” proliferated, scientists wondered why Landau’s Fermi fluid theory seemed to break down in all these different materials. Some came to suspect that it was because there were no quasiparticles at all; the electrons were somehow organizing themselves in a strange new way that obscured any individuality, much as the discrete nature of grapes gets lost in a bottle of wine.</p>
<p>“It’s a phase of matter where an electron really has no identity,” Abbamonte said. “Nevertheless, [a strange metal] is a metal; it somehow carries current.”</p>
<p>But one does not simply abolish electrons. To some scientists, a potentially continuous electric current — one that isn’t divvied up into electrons — is too radical. And <a href="https://www.nature.com/articles/s41586-021-03697-8">some strange metal experiments</a> continue to match certain predictions of Landau’s theory. The persisting controversy prompted Chen’s thesis adviser, <a href="https://profiles.rice.edu/faculty/douglas-natelson">Douglas Natelson</a> of Rice University, along with his colleague <a href="https://profiles.rice.edu/faculty/qimiao-si">Qimiao Si</a>, to consider how they might more directly scrutinize the anatomy of the charge moving through a strange metal.</p>
<p>“What could I measure that would actually tell me what’s going on?” Natelson wondered.</p>
<h2><strong>The Anatomy of Electricity</strong></h2>
<p>The team’s goal was to dissect the current in a strange metal. Did it come in electron-size chunks of charge? Did it come in chunks at all? To find out, they took inspiration from a classic way of measuring fluctuations in a flow — the “shot noise” — a phenomenon that can be understood if we think of the ways that rain might fall during a rainstorm.</p>
<p>Imagine you’re sitting in your car, and you know from a trustworthy weather forecast that 5 millimeters of rain will fall over the next hour. Those 5 millimeters are like the total electrical current. If that rain is parceled into a handful of giant drops, the variation in when those drops hit your roof will be high; sometimes drops will splatter back to back, and at other times they will be spaced out. In this case, the shot noise is high. But if the same 5 millimeters of rain is spread into a constant mist of tiny droplets, the variation in arrival time — and therefore the shot noise — will be low. The mist will smoothly deliver almost the same amount of water from moment to moment. In this way, shot noise reveals the size of the drops.</p>
<p>“Just measuring the rate at which water shows up doesn’t tell you the whole picture,” Natelson said. “Measuring the fluctuations [in that rate] tells you a lot more.”</p>
<p>Similarly, listening to the crackle in electric current can tell you about the chunks of charge that make it up. Those chunks are normally Landau’s electron-like quasiparticles. Indeed, recording the shot noise in a normal metal is a common way of measuring the fundamental charge of the electron — 1.6 × 10<sup>−19 </sup>coulombs.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sports Illustrated Published Articles by Fake, AI-Generated Writers (174 pts)]]></title>
            <link>https://futurism.com/sports-illustrated-ai-generated-writers</link>
            <guid>38436516</guid>
            <pubDate>Mon, 27 Nov 2023 18:53:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/sports-illustrated-ai-generated-writers">https://futurism.com/sports-illustrated-ai-generated-writers</a>, See on <a href="https://news.ycombinator.com/item?id=38436516">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="incArticle"><p>There was nothing in Drew Ortiz's <a href="https://web.archive.org/web/20221205082417/https://www.si.com/review/author/drewortiz/">author biography</a> at <i>Sports Illustrated </i><span>to suggest that he was anything other than human. </span></p><p>"Drew has spent much of his life outdoors, and is excited to guide you through his never-ending list of the best products to keep you from falling to the perils of nature," it read. "Nowadays, there is rarely a weekend that goes by where Drew isn't out camping, hiking, or just back on his parents' farm."</p><p>The only problem? Outside of <i>Sports Illustrated</i>, Drew Ortiz doesn't seem to exist. He has no social media presence and no publishing history. And even more strangely,&nbsp;his profile photo on <em>Sports Illustrated </em><a href="https://archive.is/ndV3A">is for sale</a> on a website that sells AI-generated headshots,&nbsp;where he's described as "neutral white young-adult male with short brown hair and blue eyes."</p><figure></figure><figure></figure><p>Ortiz isn't the only AI-generated author published by <i>Sports</i> <em>Illustrated</em>,&nbsp;according to a person involved with the creation of the content who asked to be kept anonymous to protect them from professional repercussions.</p><p>"There's a lot," they told us of the fake authors. "I was like, what are they? This is ridiculous. This person does not exist."</p><p>"At the bottom [of the page] there would be a photo of a person and some fake description of them like, 'oh, John lives in Houston, Texas. He loves yard games and hanging out with his dog, Sam.' Stuff like that," they continued. "It's just crazy."</p><p>The AI authors' writing often sounds like it was written by an alien;&nbsp;<a href="https://web.archive.org/web/20221004090814/https://www.si.com/review/full-size-volleyball/">one Ortiz article</a>, for instance, warns that volleyball "can be a little tricky to get into, especially without an actual ball to practice with."</p><p>According to a second person involved in the creation of the <em>Sports Illustrated</em> content who also asked to be kept anonymous, that's because it's not just the authors' headshots that are AI-generated. At least some of the articles themselves, they said, were churned out using AI as well.</p><p>"The content is absolutely AI-generated,"&nbsp;the second source said, "no matter how much they say that it's not."</p><p>After we reached out with questions to the magazine's publisher, The Arena Group, all the AI-generated authors disappeared from <em>Sports Illustrated</em>'s site without explanation. Our questions received no response.</p><p>The AI content marks a staggering fall from grace for <em>Sports Illustrated</em>, which in past decades won numerous National Magazine Awards for its sports journalism and published work by literary giants ranging from William Faulkner to John Updike.</p><p>But now that it's under the management of The Arena Group, parts of the magazine seem to have devolved into a Potemkin Village in which phony writers are cooked up out of thin air, outfitted with equally bogus biographies and expertise to win readers' trust, and used to pump out AI-generated buying guides that are monetized by affiliate links to products that provide a financial kickback when readers click them.</p><p><em>Do you know anything about The Arena Group's use of AI-generated content? Shoot us an email at <a href="mailto:tips@futurism.com">tips@futurism.com</a>. We can keep you anonymous.</em></p><p>Making the whole thing even more dubious, these AI-generated personas are periodically scrubbed from existence in favor of new ones.</p><p><span>Sometime this summer, for example, Ortiz disappeared from<em> Sports Illustrated</em>'s site entirely, his profile page instead redirecting to that of a</span><span> "<a href="https://archive.is/D9DV2">Sora Tanaka</a>." Again, there's no online record of a writer by that name — but Tanaka's profile picture <a href="https://generated.photos/face/joyful-asian-young-adult-female-with-long-brown-hair-and-brown-eyes--5f1836d41f67b00006889840">is for sale</a> on the same AI headshot marketplace as Ortiz, where she's listed as "joyful asian young-adult female with long brown hair and brown eyes."</span></p><p><span>"Sora has always been a fitness guru, and loves to try different foods and drinks," read Tanaka's bio. "Ms. Tanaka is thrilled to bring her fitness and nutritional expertise to the Product Reviews Team, and promises to bring you nothing but the best of the best."</span></p><figure></figure><figure></figure><p>But Tanaka didn't last, either. Eventually she also disappeared, replaced by yet another profile that carried no headshot at all, which <em>Sports Illustrated</em> deleted along with the other AI-generated content after we reached out.</p><p>It wasn't just author&nbsp;profiles that the magazine repeatedly replaced. Each time an author was switched out, the posts they supposedly penned would be reattributed to the new persona, with no editor's note explaining the change in byline.</p><p>None of the articles credited to Ortiz or the other names contained any disclosure about the use of AI or that the writer wasn't real, though they did eventually gain a disclaimer explaining that the content was "created by a 3rd party," and that the "<em>Sports Illustrated</em> editorial staff are not involved in the creation of this content."</p><p><em>Do you know anything about that "3rd party," or how the content was created? Email us at <a href="mailto:tips@futurism.com">tips@futurism.com</a>. We can keep you anonymous.</em></p><p>Though <i>Sports Illustrated</i>'s AI-generated authors and their articles disappeared after we asked about them, similar operations appear to be alive and well elsewhere in The Arena Group's portfolio.</p><p>Take <em>TheStreet</em>, a financial publication cofounded by Jim Cramer in 1996 that The Arena Group <a href="https://www.businesswire.com/news/home/20190808005215/en/Maven-Closes-Acquisition-TheStreet-New-Jim-Cramer">bought for $16.5 million</a> in 2019. Like at<em> Sports Illustrated</em>, we found authors at <em>TheStreet </em>with highly specific biographies&nbsp;detailing seemingly flesh-and-blood humans with specific areas of expertise — but with profile photos traceable to that same AI face website. And like at <em>Sports Illustrated</em>, these fake writers are periodically wiped from existence and their articles reattributed to new names, with no disclosure about the use of AI.</p><p>Sometimes <em>The</em><em>Street</em>'s efforts to remove the fake writers can be sloppy. On its <a href="https://archive.is/EVdBw">review </a><a href="https://archive.is/EVdBw">section's title page</a>,&nbsp;for instance, the site still proudly flaunts the expertise of AI-generated contributors who have since been deleted, linking to writer profiles it describes as ranging "from <a href="https://www.thestreet.com/review/author/domino-abrams/">stay-at-home dads</a> to <a href="https://www.thestreet.com/review/author/denise-mcnamara/">computer and information analysts</a>." This team,&nbsp;the site continues, "is comprised of a well-rounded group of people who bring varying backgrounds and experiences to the table."</p><p>People? We're not so sure.</p><p>The "stay-at-home dad" linked in that sentence above, for instance, is a so-called "<a href="https://web.archive.org/web/20211022203137/https://www.thestreet.com/review/author/domino-abrams/">Domino Abrams</a><span>" — "a pro at home cleaning and maintenance," at least until he was expunged from the site — whose profile picture can <a href="https://images.generated.photos/2X9jxxHg-BqU-lY8ER7BYjhM7v7Mk1lvBdZLexTtQjo/rs:fit:256:256/czM6Ly9pY29uczgu/Z3Bob3Rvcy1wcm9k/LnBob3Rvcy92M18w/ODk3Njc1LmpwZw.jpg">again be found</a>&nbsp;on that same site that sells AI-generated headshots. </span></p><figure></figure><p><span>Or look at "<a href="https://web.archive.org/web/20220706182957/https://www.thestreet.com/review/author/denise-mcnamara/">Denise McNamara</a>," the "information analyst" that <em>TheStreet</em> boasted about — "her extensive personal experience with electronics allows her to share her findings with others online" — whose profile picture is <a href="https://images.generated.photos/aArmEGQt-wLB_b9taXiittj3hoiXzDkOp8Npv-yDnSk/rs:fit:256:256/czM6Ly9pY29uczgu/Z3Bob3Rvcy1wcm9k/LnBob3Rvcy90cmFu/c3BhcmVudF92My92/M18wMzc1ODk5LnBu/Zw.png">once again listed</a> on the same AI headshot marketplace. </span><span>Or "<a href="https://web.archive.org/web/20211203045751/https://www.thestreet.com/review/author/nicole-merrifield/">Nicole Merrifield</a>," an alleged "first grade teacher" who "loves helping people," but whose profile is <a href="https://images.generated.photos/a7aiK5ivGIOmRmVNbqI17mxJ6bknNdLxB6l2LQTEFkA/rs:fit:256:256/czM6Ly9pY29uczgu/Z3Bob3Rvcy1wcm9k/LnBob3Rvcy92M18w/MTQ5Nzc5LmpwZw.jpg">again from</a>&nbsp;that AI headshot site. </span><span>(At some point this year, Abrams, McNamara, and Merrifield were replaced by bylines whose profile pictures aren't for sale on the AI headshot site.)</span></p><p>Basic scrutiny shows that the quality of the AI authors' posts is often poor, with bizarre-sounding language and glaring formatting discrepancies.</p><p>This <a href="https://web.archive.org/web/20221004132724/https://www.thestreet.com/review/improve-your-finances/">article about personal finance</a> by the AI-generated Merrifield,<span> for example, starts off with the sweeping libertarian claim that "your financial status translates to your value in society." </span></p><p>After that bold premise, the article explains that "people with strong financial status are revered and given special advantages everywhere around the world," and launches into a numbered list of how you can "improve your finance status" for yourself. Each number on what should be a five-point list, though, is just number one. Mistakes happen, but we can't imagine that anyone who can't count to five would give stellar financial advice.</p><figure></figure><p>Abysmal-quality AI content, though, shouldn't be surprising at The Arena Group.</p><p>Back in February, when the company first started publishing AI-generated health advice at its magazine <em>Men's Journal</em>,&nbsp;<a href="https://futurism.com/neoscope/magazine-mens-journal-errors-ai-health-article">we found that its first story</a> was riddled with errors, prompting it to issue a massive correction.</p><p>Before that, when The Arena Group first announced its foray into AI, its CEO Ross Levinsohn promised in an <a href="https://www.wsj.com/articles/sports-illustrated-publisher-taps-ai-to-generate-articles-story-ideas-11675428443">interview with&nbsp;<em>The Wall Street Journal</em></a> that its quality would be outstanding.</p><p>"It’s not about 'crank out AI content and do as much as you can,'" he told the newspaper early this year. "Google will penalize you for that and more isn't better; better is better."</p><p>Needless to say, neither fake authors who are suddenly replaced with different names nor deplorable-quality AI-generated content with no disclosure amount to anything resembling good journalism, and to see it published by a&nbsp;once-iconic magazine like <em>Sports Illustrated </em>is disheartening. Bylines exist for a reason: they give credit where it's due, and just as importantly, they let readers hold writers accountable.</p><p>The undisclosed AI content is a direct affront to the fabric of media ethics, in other words, not to mention a perfect recipe for eroding reader trust. And at the end of the day, it's just remarkably irresponsible behavior that we shouldn't see anywhere — let alone normalized by a high-visibility publisher.</p><p>The Arena Group is also hardly alone, either. As powerful generative AI tools have debuted over the past few years, many publishers have quickly attempted to use the tech to churn out monetizable content.</p><p>In almost every case, though, these efforts to cut out human journalists have backfired embarrassingly.</p><p>We <a href="https://futurism.com/the-byte/cnet-publishing-articles-by-ai">caught&nbsp;<em>CNET</em></a> and&nbsp;<a href="https://futurism.com/cnet-bankrate-restarts-ai-articles"><em>Bankrate</em></a>, both owned by Red Ventures, publishing barely-disclosed AI content that was filled with <a href="https://futurism.com/cnet-ai-errors">factual mistakes</a> and even <a href="https://futurism.com/cnet-ai-plagiarism">plagiarism</a>; in the ensuing storm of criticism, <em>CNET&nbsp;</em>issued corrections to <a href="https://www.theverge.com/2023/1/25/23571082/cnet-ai-written-stories-errors-corrections-red-ventures">more than half</a> its AI-generated articles. G/O Media also published AI-generated material on its portfolio of sites, resulting in embarrassing bungles <a href="https://futurism.com/gizmodo-kotaku-staff-furious-ai-content">at <em>Gizmodo</em></a> and&nbsp;<a href="https://futurism.com/the-av-club-imdb"><em>The A.V. Club</em></a>. We <a href="https://futurism.com/buzzfeed-publishing-articles-by-ai">caught </a><em><a href="https://futurism.com/buzzfeed-publishing-articles-by-ai">BuzzFeed</a>&nbsp;</em>publishing slapdash AI-generated travel guides. And <em>USA Today&nbsp;</em>and other Gannett newspapers <a href="https://www.cnn.com/2023/08/30/tech/gannett-ai-experiment-paused/index.html">were busted publishing</a> hilariously garbled AI-generated sports roundups that one of the company's own sports journalists <a href="https://futurism.com/gannett-sports-writer-ai-generated-content">described as</a> "embarrassing," saying they "shouldn't ever" have been published.</p><p>If any media organization finds a way to engage with generative AI in a way that isn't either woefully ill-advised or actively unethical, we're all ears. In the meantime, forgive us if we don't hold our breath.</p><p><strong>More on AI-generated journalism: </strong><a href="https://futurism.com/usa-today-updates-ai-generated-sports"><em>USA Today</em> Updates Every AI-Generated Sports Article to Correct "Errors"</a></p><br></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Broadcom lays off many VMware employees after closing acquisition (318 pts)]]></title>
            <link>https://www.businessinsider.com/broadcom-vmware-layoffs-employees-face-job-cuts-acquisition-2023-11</link>
            <guid>38436419</guid>
            <pubDate>Mon, 27 Nov 2023 18:48:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/broadcom-vmware-layoffs-employees-face-job-cuts-acquisition-2023-11">https://www.businessinsider.com/broadcom-vmware-layoffs-employees-face-job-cuts-acquisition-2023-11</a>, See on <a href="https://news.ycombinator.com/item?id=38436419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="piano-inline-content-wrapper" data-piano-inline-content-wrapper=""> 
                    
                    
                    
                          
                          
                          <section data-offer-key="pre-churn-offer" data-component-type="inline-offer" data-place-after-element-selector=".post-content .content-lock-content > p">
                            <article>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/top-left.svg" alt="">
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/bottom-right.svg" alt="">
                          
                                        </article>
                          </section>
                    
                    <div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Some VMware employees learned Monday their positions would be eliminated.</li><li>Broadcom announced it closed its $69 billion acquisition of VMware on November 22.</li><li>VMware had already started cutting jobs prior to the deal closing.</li></ul><!-- Excluded mobile ad on desktop --><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="techinlinesignup">
                        
                        
                          <section>
                              
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section>
                        
                            <div>
                                <p><img src="https://www.businessinsider.com/public/assets/rebrand/newsletter-bull.png" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png">
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p>Some VMware employees learned on Monday that their positions <a target="_blank" href="https://www.businessinsider.com/broadcom-vmware-huge-layoffs-acquisition-2023-8" data-analytics-product-module="body_link" rel="">would be eliminated</a> following Broadcom's announcement last week that its deal to acquire the company had closed.</p><p><a target="_blank" href="https://www.businessinsider.com/vmware-chaos-broadcom-acquisition-layoffs-conference-employees-customers-2022-8" data-analytics-product-module="body_link" rel="">Broadcom first announced</a> in May 2022 that it would acquire <a target="_blank" href="https://www.businessinsider.com/vmware-partners-optimistic-broadcom-acquisition-cozy-up-to-customers-2022-9" data-analytics-product-module="body_link" rel="">VMware</a> for $61 billion and assume $8 billion of its net debt. The company announced that it closed the deal on November 22, shortly after receiving regulatory clearance from China. It also had to receive regulatory clearance from other countries including the US and the UK.</p><p>Employees whose positions were eliminated received an email on Monday, viewed by Business Insider, that read: "Broadcom recently completed its acquisition of VMware. As part of integration planning, and following an organizational needs assessment, we identified go-forward roles that will be required within the combined company. We regret to inform you that your position is being eliminated and your employment will be terminated."</p><p>"We would like to thank you for your dedication and service. We want to make this transition as smooth as possible, including offering you a generous severance package and providing you a non-working paid notice period," the email continued.</p><!-- Excluded mobile ad on desktop --><p>Currently, it's unclear exactly how many employees will be affected by the cuts. <a target="_blank" href="https://www.businessinsider.com/broadcom-ceo-vmware-explore-conference-customer-employee-concern2022-8" data-analytics-product-module="body_link" rel="">Broadcom</a> did not immediately respond to a request for comment.</p><p><a target="_blank" href="https://www.businessinsider.com/vmware-employees-poached-aws-google-recruiters-after-broadcom-acqusition-2022-8" data-analytics-product-module="body_link" rel="">VMware</a> — which, as of February, employed more than 38,000 people — had already <a target="_blank" href="https://www.businessinsider.com/vmware-layoffs-job-cuts-broadcom-acquisition-deadline-looms-2023-10" data-analytics-product-module="body_link" rel="">cut jobs</a> before the acquisition closed, BI previously reported. <a target="_blank" href="https://www.businessinsider.com/vmware-broadcom-acquisition-deal-leaked-email-options-employees-2023-9" data-analytics-product-module="body_link" rel="">VMware sent</a> a letter to employees in September saying that they would be offered a job by Broadcom, offered a transitional role, or receive a severance package.</p><p>Some <a target="_blank" href="https://www.businessinsider.com/broadcom-vmware-deal-employees-concerned-carbon-black-euc-2023-5" data-analytics-product-module="body_link" rel="">VMware employees</a> speculated that <a target="_blank" href="https://www.businessinsider.com/broadcom-vmware-euc-carbon-black-divest-units-2023-5" data-analytics-product-module="body_link" rel="">Broadcom could spin out</a> certain units.</p><p>Several <a target="_blank" href="https://www.businessinsider.com/meet-vmwares-top-executive-departures-and-hires-in-2022-2022-8" data-analytics-product-module="body_link" rel="">top VMware executives</a> have left the cloud-computing company over the past year. Some <a target="_blank" href="https://www.businessinsider.com/vmware-employees-are-leaving-in-droves-after-broadcom-acquisition-2022-8" data-analytics-product-module="body_link" rel="">VMware employees</a> said they worried about a culture clash with Broadcom, especially <a target="_blank" href="https://www.businessinsider.com/broadcom-ceo-comments-pressure-vmware-staff-come-into-office-wfh-2022-8" data-analytics-product-module="body_link" rel="">since Broadcom requires</a> workers to return to the office. They also said some deals <a target="_blank" href="https://www.businessinsider.com/vmware-sales-slowdown-contracts-salespeople-frustration-2022-8" data-analytics-product-module="body_link" rel="">had slowed as clients waited for news about VMware's fate.</a></p><!-- Excluded mobile ad on desktop --><p><strong><em>Got a tip?</em></strong><em>&nbsp;Contact this reporter via email at&nbsp;</em><a target="_blank" rel="noopener nofollow" href="mailto:rmchan@businessinsider.com" data-analytics-product-module="body_link"><em><u>rmchan@businessinsider.com</u></em></a><em>, Signal at 646.376.6106, or Telegram at @rosaliechan.&nbsp;(PR pitches by email only, please.) Other types of secure messaging available upon request.</em></p>
                      </div>
                    
                    
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Toddler Loves Planes, So I Built Her a Radar (1045 pts)]]></title>
            <link>https://jacobbartlett.substack.com/p/my-toddler-loves-planes-so-i-built</link>
            <guid>38435908</guid>
            <pubDate>Mon, 27 Nov 2023 18:16:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobbartlett.substack.com/p/my-toddler-loves-planes-so-i-built">https://jacobbartlett.substack.com/p/my-toddler-loves-planes-so-i-built</a>, See on <a href="https://news.ycombinator.com/item?id=38435908">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png" width="700" height="486" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:486,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae00ead5-bd9f-41c0-a573-04504ae2aea5_700x486.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Late-stage user testing with my toddler</figcaption></figure></div><p>This is a tale of inspiration, of a vision taking shape, and of rapid feedback from that most discerning of customers: a 2-year-old girl.</p><p><span>Keen to skip ahead to the final product? Go ahead and download </span><a href="https://apps.apple.com/gb/app/aviator-radar-on-your-phone/id6469189335" rel="">Aviator — Radar on your Phone</a><span> from the App Store now!</span></p><blockquote><p><em><span>For the HackerNews crowd—please </span><a href="https://twitter.com/jacobs_handle" rel="">follow me on X/Twitter</a><span> if you liked this post!</span></em></p></blockquote><p>I took my toddler abroad this summer.</p><p><span>She was so excited. But, in order to make sure she could handle the 3-hour flight, my wife and I made sure to </span><em>hype up</em><span> the airplane journey. So much so, that my toddler was shocked when we had to get into a cab for the airport — she expected to walk straight from our house onto a plane.</span></p><p><span>Once we boarded the flight, things took an incredible turn — it turns out, if the crew spots you with a cute plane-obsessed toddler, they </span><em>invite you in to check out the cockpit.</em></p><p>This kindled my daughter’s obsession with airplanes. She keeps adorably asking me to find planes for her in the sky, and becomes delighted when I spot one for her.</p><p>Last week, we spent an hour in the garden, with her on my shoulders, spotting planes twinkling in the evening sky, one after the other.</p><p>While it’s always great to play with one’s daughter, I knew we could be applying a more efficient approach.</p><p><span>I found </span><a href="https://www.flightradar24.com/" rel="">FlightRadar24</a><span>, which shows the positions of planes overlaid on a map. It worked pretty well, but it was a little annoying to have to orient myself to work out where to look in the sky.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png" width="700" height="559" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:559,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcb61737-0621-4218-9b89-fd417dc1bb56_700x559.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Can you spot Heathrow airport?</figcaption></figure></div><p>It’s also pretty tough to spot aircraft on a 2-dimensional plane (pun intended). A Learjet at 40,000 feet shows up the same as an AirBus that just took off at London City Airport, however it’s a lot easier to spot the jumbo jet in the real sky.</p><p><span>Finally, and most importantly, my toddler doesn’t really understand or care what a map is. She </span><em>just</em><span> wanted to look at planes.</span></p><p>So we have our problems.</p><p>Orientation.</p><p>Sizing.</p><p>Usability.</p><p>As an aphyscial mobile tech lead, I wouldn’t know where to start building my kid a rocking horse. But nothing was going to stand in the way of me making her a cool app.</p><p>We had the idea for our app:</p><blockquote><p><em><strong>Show nearby flights on a radar.</strong></em></p></blockquote><p>In keeping with the requirements we’d created via our research:</p><ol><li><p>The app needs to remain oriented correctly, rotating with the device so that it shows airplanes in the correct direction.</p></li><li><p>The app has to show aircraft as bigger or smaller depending on how high they are.</p></li><li><p>The app must be fun, and feel more like a retro kid’s toy than a serious business app.</p></li></ol><p>These requirements led to a few moving parts which form the proof of concept:</p><ol><li><p><strong>Maintaining Orientation </strong><span>is a core differentiating product requirement, since this is missing from the existing solutions. I’m not in the business of detailed flight information — I just want to make a cool radar! The iOS Core Location API has be covered, offering a delegate callback every time the user re-orients their device.</span></p></li><li><p><span>The most important component, of course, is a </span><strong>Flight Data API</strong><span>. </span><a href="https://opensky-network.org/" rel="">OpenSky Network</a><span> has exactly what I need. A simple REST API, free for non-commercial use, with live data of flights in an area. We’d want to ping this endpoint every few seconds for realistic radar sweeps.</span></p></li><li><p><span>To call the API, we need some </span><strong>Location</strong><span> data. Core Location has us covered again — to get a good number of nearby flights, we could query +/- 1 degree of latitude from the user’s location, with a precision of 0.1 degrees (about 10km) to ensure a user’s location is sufficiently obfuscated. We also only need to fetch this data once per session.</span></p></li><li><p><span>Finally, and like most difficult, we need to dust off our </span><strong>Trigonometry</strong><span> skills to compare flight location data with our own, oriented, coordinates. This will allow us to draw nearby aircraft to the screen in the correct place, according to their relative position from us in the sky.</span></p></li></ol><p><span>Since I don’t intend to build a business atop this app — again, the OpenSky Network API is restricted to non-commercial use — I’ll probably use the dead-simple </span><em>MV</em><span> architecture for SwiftUI. I’ll leave a bit of business logic in the views, rely on SwiftUI’s built-in APIs for the heavy lifting, and factor out core services such as API and Location.</span></p><p>Once I prove the concept, I can get to work on the really fun part — turning it into a cool radar and testing it with my toddler!</p><p>First things first.</p><p><span>For the mascot, I’m picturing a cartoon of my daughter in a cute aviator hat. So we have our app name already: </span><strong>Aviator</strong><span>.</span></p><p>Drawing on my infinite willpower, I’m not going to waste time with an app icon until the MVP is complete. But I now have a project name with which to get started.</p><p>The first of my key differentiating product requirements is maintaining orientation — to be useful, the objects on-screen need to correspond to their real-life location. Therefore, When the user rotates, the screen itself rotates and keeps pointing North.</p><p><span>Ignoring the template files for </span><code>AviatorApp</code><span> and </span><code>ContentView</code><span> for now, I whip up a singleton </span><code>LocationManager</code><span> and wire up the </span><code>didUpdateHeading</code><span> method from </span><code>CLLocationManagerDelegate</code><span>.</span></p><blockquote><p><em>In navigation, the Heading is the compass direction in which a vessel — or in this case, an iPhone — is pointed.</em></p></blockquote><p><span>My </span><code>LocationManager</code><span> also handles the initial setup of requesting location permissions, setting the delegate, and telling Core Location to start sending orientation info.</span></p><pre><code>final class LocationManager: CLLocationManager, CLLocationManagerDelegate {
        
    static let shared = LocationManager()
    
    private(set) var rotationAngleSubject = CurrentValueSubject&lt;Double, Never&gt;(0)
    
    override private init() {
        super.init()
        requestWhenInUseAuthorization()
        delegate = self
        startUpdatingHeading()
    }
    
    func locationManager(_ manager: CLLocationManager, didUpdateHeading newHeading: CLHeading) {
        rotationAngleSubject.send(-newHeading.magneticHeading)
    }
}</code></pre><p><span>To make things play nicely with a SwiftUI view, I’m going to send the orientation information via a Combine publisher, </span><code>rotationAngleSubject</code><span>. This means I can reactively handle it in my view with </span><code>.onReceive</code><span>, and set a local </span><code>@State</code><span> property, </span><code>rotationAngle</code><span>.</span></p><p><span>In my view, to get a nice compass effect, I draw a set of rectangles that vary with this </span><code>rotationAngle</code><span>.</span></p><pre><code>@State private var rotationAngle: Angle = .degrees(0)

var body: some View {
    ZStack {
        ForEach(0..&lt;36) {
            let angle = Angle.degrees(Double($0 * 10)) + rotationAngle
            Rectangle()
                .frame(width: $0 == 0 ? 16 : 8, height: $0 == 0 ? 3 : 2)
                .foregroundColor($0 == 0 ? .red : .blue)
                .rotationEffect(angle)
                .offset(x: 120 * cos(CGFloat(angle.radians)), y: 120 * sin(CGFloat(angle.radians)))
                .animation(.bouncy, value: rotationAngle)
        }
    }
    .onReceive(LocationManager.shared.rotationAngleSubject) { angle in
        rotationAngle = Angle.degrees(angle)
    }
}</code></pre><p>Testing on my device, it looks pretty good, and responds perfectly to my real-world location!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif" width="600" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc54c926e-5005-4a15-b8d2-42c1bb993396_600x600.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Which begs the question, why can’t Google Maps ever work out which direction I am facing?</figcaption></figure></div><p>You’ll notice a funny visual glitch due to the animation logic treating 0 degrees and 360 degrees as separate numbers — all the rectangles decide to spin around when I go past true North — but it’s fine for the PoC (as I’m unlikely to actually keep this UI anyway).</p><p>Now my warm-up is over.</p><p>The really important piece is next: Parsing out data from the OpenSky Network API.</p><p><span>It allows you to specify a range of latitude and longitudes, and returns an array of local flights in that range via a simple </span><code>GET</code><span> request — meaning you can simply paste this into your browser to find out what flights I can see overhead:</span></p><pre><code>https://opensky-network.org/api/states/all?lamin=51.0&amp;lamax=52.0&amp;lomin=-0.5&amp;lomax=0.5</code></pre><p><a href="https://openskynetwork.github.io/opensky-api/rest.html" rel="">The REST API is documented well</a><span>, but has an un-keyed structure, meaning the data is presented as a list properties in order.</span></p><p><span>We need to use an </span><code>UnkeyedContainer</code><span> to decode it, which is designed to parse out fields from the JSON response in order.</span></p><pre><code>struct Flight: Decodable {

    let icao24: String 
    let callsign: String?
    let origin_country: String? 
    let time_position: Int?
    let last_contact: Int
    let longitude: Double
    let latitude: Double

    // ... 

    init(from decoder: Decoder) throws {
        var container = try decoder.unkeyedContainer()
        icao24 = try container.decode(String.self)
        callsign = try? container.decode(String?.self)
        origin_country = try container.decode(String.self)
        time_position = try? container.decode(Int?.self)
        last_contact = try container.decode(Int.self)
        longitude = try container.decode(Double.self)
        latitude = try container.decode(Double.self)

        // ...
    }
}</code></pre><p><span>We can write a simple API that performs a </span><code>GET</code><span> request based on the user’s location coordinates.</span></p><pre><code>final class FlightAPI {
    
    func fetchLocalFlightData(coordinate: CLLocationCoordinate2D) async throws -&gt; [Flight] {
        
        let lamin = String(format: "%.1f", coordinate.latitude - 0.25)
        let lamax = String(format: "%.1f", coordinate.latitude + 0.25)
        let lomin = String(format: "%.1f", coordinate.longitude - 0.5)
        let lomax = String(format: "%.1f", coordinate.longitude + 0.5)

        let url = URL(string: "https://opensky-network.org/api/states/all?lamin=\(lamin)&amp;lamax=\(lamax)&amp;lomin=\(lomin)&amp;lomax=\(lomax)")!
        let data = try await URLSession.shared.data(from: url).0
        return try JSONDecoder().decode([Flight].self, from: data)
    }
}</code></pre><blockquote><p><em>You might notice that I used a range of 1 degree of longitude, but only 0.5 degrees of latitude in this API call. That’s because at my latitude, the UK, a 0.5 latitude by 1 longitude rectangle shows up, approximately, as a square.</em></p></blockquote><p>Now we’re getting somewhere!</p><p><span>The flight data is nicely parsed into an array of in-memory </span><code>Flight</code><span> objects which are now nice and easy to deal with.</span></p><p><span>It’s pretty trivial to amend my </span><code>LocationManager</code><span> to listen for significant location changes and send these coordinates via a publisher.</span></p><p><span>Again, in pure MV architectural style, my view listens to coordinates via </span><code>.onReceive</code><span> and calls my new </span><code>FlightAPI</code><span> with these coordinates. The result? Data about the overhead airplanes in your local slice of sky.</span></p><p>Now, we arrive at the hardest part of my initial proof of concept: actually displaying the airplane icons in their correct locations, relative to my own location.</p><p>My first iteration was a blunt instrument: I multiplied the relative lat and long by a hardcoded on-screen points value.</p><pre><code>@State private var coordinates: CLLocationCoordinate2D?
@State private var flights: [Flight] = []

private var airplanes: some View {
    ForEach(flights, id: \.icao24) { flight in
        let latDiff = coordinate.latitude - (flight.latitude ?? 0)
        let lngDiff = coordinate.longitude - (flight.longitude ?? 0)
        Image(systemName: "airplane")
            .resizable()
            .frame(width: 20, height: 20)
            .rotationEffect(.degrees(flight.true_track ?? 0))
            .foregroundColor(.red)
            .offset(x: 250 * latDiff, y: 250 * lngDiff)
    }
}</code></pre><p>There was, of course, no way this would be accurate, since the absolute distance of a degree of latitude or longitude varies with your geolocation. But again, it’s a good place to begin.</p><p>How do I actually test the accuracy of my airplane drawings?</p><p>I could draw a map underneath everything!</p><p><span>Now my </span><code>AviatorView</code><span> has 3 layers: The compass on top, airplanes drawn to the screen, and an unadorned SwiftUI </span><code>Map</code><span> view under it all.</span></p><pre><code>@State private var cameraPosition: MapCameraPosition = .camera(MapCamera(
        centerCoordinate: CLLocationCoordinate2D(latitude: 51.0, longitude: 0.0),
        distance: 100_000,
        heading: 0))

var body: some View {
    ZStack {
        Map(position: $cameraPosition) { } 
        airplanes
        compass
    }
}</code></pre><p>Here’s the result of my first late-night hackathon, compared against the FlightRadar projection as a source of truth.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png" width="1190" height="788" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84a0f987-1471-4517-a668-7aec954390da_1190x788.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:788,&quot;width&quot;:1190,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1589429,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a0f987-1471-4517-a668-7aec954390da_1190x788.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Results of Day #1, my app on the left, compared against FlightRadar on the right</figcaption></figure></div><p>I’m certainly on to something, since the number and clustering of airplanes in the sky looks about right — however the positioning is pretty far off.</p><p>Suddenly, another flash of inspiration. It’s so simple. I can’t believe I didn’t think of it before.</p><p><span>I need to </span><em>draw the airplanes on the map</em><span> using annotations!</span></p><p><span>The idea has been brewing all day: we’ll use a </span><code>Map</code><span>, and draw aircraft-shaped annotations on top at their precice geolocations.</span></p><p>Eventually, I want to find a way to hide the actual map, and only display the airplanes as markers on the radar position. This should get us the cool, fully-oriented radar effect we’re aiming at.</p><p><span>In iOS 17, which I intend to target, drawing annotations on a map is a breeze. Let’s refactor out a </span><code>FlightMapView</code><span>.</span></p><pre><code>import MapKit
import SwiftUI

struct FlightMapView: View {
    
    @Binding var cameraPosition: MapCameraPosition
    
    let flights: [Flight]

    var body: some View {
        Map(position: $cameraPosition) {
            planeMapAnnotations
        }
        .mapStyle(.imagery)
        .allowsHitTesting(false)
    }
}</code></pre><p>Here, for the purposes of a radar, we want to prevent hit-testing — i.e., we don’t want the map to be interactive. In our ideal world, the map is invisible, and the user just sees flights and their positions.</p><p>After orientation, sizing was the next core issue which the existing solutions simply didn’t handle that well.</p><p>I added some simple log scaling to the map annotations using the altitude of the flight so higher up aircraft appear larger on-screen.</p><p><span>Additionally, I used the aircraft’s </span><code>true_track</code><span> property, combined with the user’s orientation from Core Location, to show the plane facing the correct direction.</span></p><pre><code>@State private var rotationAngle: Angle = .degrees(0)

private var planeMapAnnotations: some MapContent {
    ForEach(flights, id: \.icao24) { flight in
        Annotation(flight.icao24, coordinate: flight.coordinate) {
            let rotation = rotationAngle.degrees + flight.true_track
            let scale = min(2, max(log10(height + 1), 0.5))
            Image(systemName: "airplane")
                .rotationEffect(.degrees(rotation))
                .scaleEffect(scale)
            }
        }
        .tint(.white)
    }
}</code></pre><p>Now’s the time for the ultimate test to find out if my MVP actually works.</p><p>I’m going to go plane-spotting with my daughter.</p><p>We’ve got real map annotations, and show the user’s location and direction on the map.</p><p>Most importantly, it accurately finds the airplanes!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png" width="1188" height="972" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:972,&quot;width&quot;:1188,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1850682,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18021ff7-f048-4b55-8bf8-5cb8b4c67ec4_1188x972.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The first plane we spotted via Aviator, the aptly-named 3c65d4</figcaption></figure></div><p>The MVP was a smashing success, since my daughter and I spotted a plane which was visible on the app!</p><p>This initial test also yielded 2 pieces of important information.</p><p><span>Firstly, my scaling logic is backwards — see the tiny plane on the ground at London City Airport. Since the point of the app is locating aircraft in the sky, we need to </span><strong>reverse the scaling</strong><span>. Lower-down planes must show up as larger, since we’re using our eyes to spot them.</span></p><p><span>Secondly, my toddler does </span><em>not</em><span> care about maps, just airplanes. I needed to </span><strong>remove the map </strong><span>if I wanted to clear out the noise and focus on spotting aircraft. And start to build my radar!</span></p><p>I handily fixed the scaling logic for the aircraft.</p><p>After some trial and error — to see both what looks good on-screen, and gives a reasonable spread of sizes, I landed on this for the scaling:</p><pre><code>min(2, max(4.7 - log10(flight.geo_altitude + 1), 0.7))</code></pre><p>These scalings came out of my local overhead scan:</p><pre><code>Scale:  1.0835408863965839
Scale:  0.8330645861650874
Scale:  1.095791123396205
Scale:  1.1077242935783653
Scale:  2.0
Scale:  1.4864702267977097
Scale:  0.7</code></pre><p>This distribution works pretty well — aside from the NOx, it’s turning out quite useful living in an air travel hub.</p><p>I was nearly ready to build the radar I was envisioning. But there was a problem.</p><p>The open-source OpenSky API kept timing out, returning 502 bad gateway errors, and sometimes simply yielding a 200 response with with null data.</p><p>Franky, that’s fine by me — this isn’t a corporate business app and this great API costs me nothing. They have no SLA and I don’t feel entitled to one.</p><p>To help improve robustness on the client-side, I implemented some basic retry logic in the API call.</p><pre><code>private func fetchFlights(at coordinate: CLLocationCoordinate2D, retries: Int = 3) async {
    do {
        try await api.fetchLocalFlightData(coordinate: coordinate)

    } catch {
        if retries &gt; 0 {
            try await fetchFlights(at: coordinate, retries: retries - 1)
        }
    }
}</code></pre><p>The next day, the API was working fine all day—it seems like it’s mostly good apart from certain high-traffic periods.</p><p>The most important noise-reducing task is to make the actual map invisible. The radar won’t work without this.</p><p><span>I was able to do this using a flat-coloured </span><code>MapPolygon</code><span> — ostensibly designed so you can place overlays to highlight sections of a map. But I wanted to use it to hide </span><em>everything</em><span> except our annotations.</span></p><pre><code>struct FlightMapView: View {

    var body: some View {
        Map(position: $cameraPosition) {
            planeMapAnnotations
            MapPolygon(overlay(coordinate: coordinate))
        }
        .mapStyle(.imagery)
        .allowsHitTesting(false)
    }

    // ...
    
    private func rectangle(around coordinate: CLLocationCoordinate2D) -&gt; [CLLocationCoordinate2D] {
        [
            CLLocationCoordinate2D(latitude: coordinate.latitude - 1, longitude: coordinate.longitude - 1),
            CLLocationCoordinate2D(latitude: coordinate.latitude - 1, longitude: coordinate.longitude + 1),
            CLLocationCoordinate2D(latitude: coordinate.latitude + 1, longitude: coordinate.longitude + 1),
            CLLocationCoordinate2D(latitude: coordinate.latitude + 1, longitude: coordinate.longitude - 1)
        ]
    }
    
    private func overlay(coordinate: CLLocationCoordinate2D) -&gt; MKPolygon {
        let rectangle = rectangle(around: coordinate)
        return MKPolygon(coordinates: rectangle, count: rectangle.count)
    }
}</code></pre><p>Tapping my dwindling reserves of my good luck, this approach worked a treat! We could now see the airplanes, but no map, just like we wanted!</p><p><span>Critically, Apple has designed the overlay to place </span><em>on top</em><span> of the map but </span><em>underneath</em><span> the annotations. Had they done it any other way, my daughter’s new toy would be hobbled.</span></p><p>The final piece of my core requirements was a radar view.</p><p>This was essentially a set of lines, concentric circles, and 20 degrees of rotating angular gradient. For a SwiftUI aficionado like myself, this was simples.</p><p>Look how far we’ve come.</p><p>With today’s core visual changes — hiding the map via an overlay, and a few lines of SwiftUI views for the radar — we are now rapidly closing in on our original vision.</p><p>Comparing the resulting Radar UI with the aircraft in the sky overhead, we’re pretty nicely matched.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png" width="967" height="575" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:575,&quot;width&quot;:967,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:741234,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34bde87e-1535-45a4-89e5-cb3aed63b1b9_967x575.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Day 3 results — displaying the flights over Sidcup</figcaption></figure></div><p>After 3 solid evenings of work, my toddler was finally starting to show some interest in the toy I’d created.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png" width="1188" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1188,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:937846,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52fbd543-157a-49dd-95dc-5b59695a9140_1188x971.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>We saw the planes it detected! However you’ll have to take my word for it, due  my antiquated iPhone camera</figcaption></figure></div><p>We’ve proven the concept, and put together an MVP that achieves the core initial goals we set out to do.</p><p>Now, we can start to think about putting it on the App Store.</p><p>I’m a big fan of Skeuomorphism. As such, I wanted to flex all my animation muscles to give this app the retro, toy-like quality I envisoned.</p><p>I was proud of the effect I produced on the radar.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif" width="576" height="576" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:576,&quot;width&quot;:576,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66f9dee5-66fb-4c9f-98b3-80a3b0bcfb19_576x576.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Realistic fade-out effect on the radar to improve</figcaption></figure></div><p><span>The implementation is what I’d call </span><em>“dumb genius”.</em></p><p>Originally, I thought about using trigonometry and timers — recolouring and fading-out individual map annotations whenever the line hit them.</p><p>But then I realised that my line was simply a 20-degree-wide angular gradient that went from green to clear.</p><p>What if it was a 360-degree wide angular gradient?</p><p>And what if this gradient went from green, to clear, to clear, to clear, to black?</p><pre><code>private var radarLine: some View {
    Circle()
        .fill(
            AngularGradient(
                gradient: Gradient(colors: [
                    Color.black, Color.black, Color.black, Color.black,
                    Color.black.opacity(0.8), Color.black.opacity(0.6),
                    Color.black.opacity(0.4), Color.black.opacity(0.2),
                    Color.clear, Color.clear, Color.clear, Color.clear,
                    Color.clear, Color.clear, Color.clear, Color.clear,
                    Color.clear, Color.clear, Color.clear, Color.green]),
                center: .center,
                startAngle: .degrees(rotationDegree),
                endAngle: .degrees(rotationDegree + 360)
            )
        )
        .rotationEffect(Angle(degrees: rotationDegree))
        .animation(.linear(duration: 6).repeatForever(autoreverses: false), value: rotationDegree)
}</code></pre><p><span>More often than not, the </span><a href="https://grugbrain.dev/" rel="">grug-brained</a><span> solution works best.</span></p><p>I also found some weird visual artefacts from the map appearing in the corners of the screen when rotating the device too quickly — the overlay seems to be lazily rendering outside the map’s camera position.</p><p>Creating a black outline of the radar view with a reverse mask solved the issue (i.e. a black rectangle with a circular hole for the radar).</p><p>Our UI is looking pretty tidy now. But I wouldn’t yet call it retro.</p><p>I wanted to add a CRT-screen effect, with television scanlines, to make the app look like it was really drawn on an old radar scanner.</p><p><span>iOS 17 comes with support for Metal shaders built into </span><code>colorEffect</code><span>, so it implementing this effect is easier than ever before.</span></p><pre><code>#include &lt;metal_stdlib&gt;
using namespace metal;

[[ stitchable ]] half4 crtScreen(
    float2 position,
    half4 color,
    float time
) {
    
    if (all(abs(color.rgb - half3(0.0, 0.0, 0.0)) &lt; half3(0.01, 0.01, 0.01))) {
        return color;
    }
    
    const half scanlineIntensity = 0.2;
    const half scanlineFrequency = 400.0;
    half scanlineValue = sin((position.y + time * 10.0) * scanlineFrequency * 3.14159h) * scanlineIntensity;
    return half4(color.rgb - scanlineValue, color.a);
}</code></pre><p>I might save digging into the C++ for another article. Feel free to steal it — most importantly, I created a view modifier that can apply the CRT effect to any view we like!</p><pre><code>extension View {
    
    func crtScreenEffect(startTime: Date) -&gt; some View {
        modifier(CRTScreen(startTime: startTime))
    }
}

struct CRTScreen: ViewModifier {
    
    let startTime: Date
    
    func body(content: Content) -&gt; some View {
        content
            .colorEffect(
                ShaderLibrary.crtScreen(
                    .float(startTime.timeIntervalSinceNow)
                )
            )
    }
}</code></pre><p><span>Note that this modifier, and the shader itself, take in a </span><code>time</code><span> parameter to make the scanlines move up rapidly and make the effect far more dynamic.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif" width="600" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bba1ea3-a8e3-48c4-af81-fd00d29e76ce_600x600.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>I actually recorded and gif-ified this before implementing the time-modulation — see those below!</figcaption></figure></div><p>While the OpenSky Network website is pretty clear, I wanted to be polite and sent a note to ensure my App Store listing would be fine under their policy.</p><p>They very kindly replied within 20 minutes!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png" width="507" height="151" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:151,&quot;width&quot;:507,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbbc39cf-98a6-4698-be3f-412269e7fd58_507x151.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Gotta love the open-source community.</figcaption></figure></div><p>To help sell the experience of a radar, and also help a touch with accessibility, I added a little beep-boop system sound effect whenever the flights update .</p><pre><code>private func fetchFlights(coordinate: Coordinate, retries: Int = 2) async {
    do {
        let flights = try await api.fetchLocalFlightData(coordinate: coordinate)
        await MainActor.run {
            self.flights = flights
            AudioServicesPlaySystemSound(1052)
            hapticTrigger.toggle()
        }

    // ...

}</code></pre><p><span>Alongside the new </span><code>sensoryFeedback</code><span> modifier on the main view for some haptics:</span></p><pre><code>.sensoryFeedback(.levelChange, trigger: hapticTrigger)</code></pre><p>What I realised now, however, is that this beep might get annoying to some people. So I should add a few customisation options.</p><p>Firstly, a silent mode is in order.</p><p><span>But also, perhaps, a few simple other customisations with </span><code>@AppStorage</code><span>.</span></p><pre><code>@AppStorage("silent") var silentMode: Bool = false
@AppStorage("showMap") var showMap: Bool = false
@AppStorage("userColor") var userColor: Color = .green</code></pre><p>Now, uses can turn off the sound, and even turn off the radar overlay to see the map underneath.</p><p>Most importantly, however, since I’m building this for my kid, picking a custom color for the radar via the SwiftUI color picker is absolutely mandatory.</p><p>Finally, what’s life without an animated SFSymbol or two?</p><pre><code>private func toggleableIcon(state: Bool, iconTrue: String, iconFalse: String) -&gt; some View {
        Image(systemName: state ? iconTrue : iconFalse)
            .contentTransition(.symbolEffect(.replace))
    // ...
}</code></pre><p>I think our app is ready for prime-time now.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif" width="600" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a94691-f398-4c9a-aef5-55777cc2abfc_600x600.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I need to do a little bit of refactoring to move views into their own files.</p><p><span>Now the top-level </span><code>AviatorView</code><span> looks a bit like this:</span></p><pre><code>// @State properties ...

var body: some View {
    ZStack {
        if let coordinate = locationManager.coordinateSubject.value {
            FlightMapView(
                cameraPosition: $cameraPosition,
                flights: flights,
                rotationAngle: rotationAngle,
                coordinate: coordinate
            )
        }
    
        TimelineView(.animation) { context in
            RadarView()
                .crtScreenEffect()
                .negativeHighlight()
        }
    
        ControlsView(errorMessage: errorMessage)
    }

    // onRecieve modifiers ...
}</code></pre><p><span>Annoyingly, I stopped paying Midjourney last month, so I wrangled a free-for-non-commercial-use generator at </span><a href="https://gencraft.com/" rel="">Gencraft</a><span>.</span></p><p>Fortunately, I managed to approximate my daughter in an aviator hat, which is precisely the look I was going for!</p><p>This also led to my most successful Tweet ever.</p><p>I haven’t personally paid for the Apple Developer Program for years.</p><p>Look at this graveyard of discarded side projects.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png" width="700" height="368" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:368,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa59db988-401e-4c3a-bc8b-00af5750fa31_700x368.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>RevisionApp will always be the one that got away…</figcaption></figure></div><p>Welp. I’m £79 down and ready to hit publish.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png" width="700" height="290" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ea5f87bd-13a5-498c-8587-04789a650371_700x290.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:290,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea5f87bd-13a5-498c-8587-04789a650371_700x290.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><blockquote><p><em><strong>Fun fact:</strong><span> I’m targeting iOS 17 only. But I still need to supply screenshots for 6.5" and 5.5" iPhones. The latest 5.5" iPhone? The 8 Plus. Which has a maximum version of iOS 16. Yup. Fortunately, the good people at </span><a href="https://appscreens.com/" rel="">AppScreens</a><span> allowed me to export for both sizes. But don’t get me started on re-scaling videos.</span></em></p></blockquote><p><span>While we wait for Apple app review to work its magic, let’s run a few more rounds of weekend user-testing with my toddler, who’s absolutely </span><em>delighted</em><span> that she can now pick her own colour for the UI.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png" width="1186" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1186,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1202923,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83197c81-b287-4016-be20-7ee1eaaea23a_1186x970.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png" width="1187" height="969" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:969,&quot;width&quot;:1187,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:551861,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd573eebf-3e73-461f-9501-779dad4bf7a4_1187x969.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png" width="1188" height="973" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:973,&quot;width&quot;:1188,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:573406,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaff5f2f-abb4-4588-97c7-a61248f1678a_1188x973.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png" width="700" height="519" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:519,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c719a5-72ab-41bf-94c4-f500be48ff5b_700x519.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>App Store Listing for Aviator v1.0.0</figcaption></figure></div><p>Want to download the app yourself?</p><p><span>Go to </span><a href="https://apps.apple.com/gb/app/aviator-radar-on-your-phone/id6469189335" rel="">Aviator — Radar on your Phone</a><span> now (and don’t forget to rate)!</span></p><p>I’m pretty happy with what I put together in a few evenings over a week. It’s been ages since I picked up a side project, and making a fun toy for my daughter is the most fun I’ve had coding in years.</p><p>After this write-up, I’ve got a few features in mind in my mini-roadmap for the next release:</p><ul><li><p>Add zoom levels to the map to restrict the radar to closer aircraft only.</p></li><li><p>Use the advanced version of the OpenSky Network API to show helicopters, satellites, and airplane size classes.</p></li><li><p>Toggle origin &amp; destination country display on airplanes.</p></li><li><p>Improve the CRT screen effect with more advanced Metal shaders.</p></li><li><p>Refactor all the controls into a resizeable progressive-disclosure pull-out modal with detents.</p></li><li><p>Implement slider controls to filter out certain distances &amp; heights — e.g. to hide all low-down, far-off aircraft.</p></li><li><p>Implement “zany mode” which renders UFOs, giant bugs, and aliens on the radar.</p></li></ul><p>If you have any ideas of your own, or simply some feedback, please let me know in the comments!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ed.bf: text editor in Brainfuck (132 pts)]]></title>
            <link>https://github.com/bf-enterprise-solutions/ed.bf</link>
            <guid>38435017</guid>
            <pubDate>Mon, 27 Nov 2023 17:15:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bf-enterprise-solutions/ed.bf">https://github.com/bf-enterprise-solutions/ed.bf</a>, See on <a href="https://news.ycombinator.com/item?id=38435017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content"><pre>[ED.BF---AN OPINIONATED ED RE-IMPLEMENTATION IN BRAINFUCK

 The original grep [as part of ed text editor] was written [overnight]
 in PDP-11 assembly language [by Ken Thompson].
 -- Brian Kernigan, in the YouTube Computerphile video about grep
 (<a href="https://www.youtube.com/watch?v=NTfOnGZUZDk" rel="nofollow">https://www.youtube.com/watch?v=NTfOnGZUZDk</a>).

 Not being Ken Thompson is a struggle every working software engineer
 has to contend with.
 -- David Gillies, a YouTube comment under the same video.

 UNIX ed is notorious for being the most user-hostile text editor. It
 was initially implemented in assembly. Brainfuck is notorious for
 being one of the most programmer-hostile programming languages. It is
 extremely close to assembly. Feels like a perfect match for one get
 the feel of the legendary programmer existence, doesn't it?

 ed.bf is an incomplete, buggy and (potentially) Turing-complete
 re-implementation of UNIX ed in Brainfuck. It is ALREADY non-standard
 in where we feel it necessary.

 The memory layout (see below) it has allows for terrible hacks and
 more efficient text editing if you understand it. It will NEVER be
 fixed and will always stay overrestrictive/hackable. Enjoy.

 [1 GETTING STARTED

  Clone the code:
  [shell:
   git clone <a href="https://github.com/bf-enterprise-solutions/ed.bf.git">https://github.com/bf-enterprise-solutions/ed.bf.git</a>]

  Find the proper implementation. ed.bf work only on implementations where:
  - All cells are initially zeroed.
  - Tape size is at least 122 * cell size (see layout for why).
  - Cell wraparound works in both directions.

  Run ed.bf and enjoy the most user-and-programmer-hostile text editor!]

 [2 ED.BF COMMANDS

  - 'c' to change the current line.
  - 'd' to remove the current line (flush it clean, basically). Moves
  all the filled lines after the deleted one to cover it.
  - 'p' to print the current line.
  - '=' to print the current line number. Even if the line is empty.
  - newline to go to next line.
  - '-' to go to previous line.
  - Any number to go to the respective numbered line.
  - '!' to evaluate Brainfuck code on the current line contents. Given
    that Brainfuck implies no underlying OS, there's no shell. Thus,
    the meta-evaluation of Brainfuck code is as close to ed's '!'
    meaning as we can get. Uses meta.bf
    (<a href="https://github.com/bf-enterprise-solutions/meta.bf">https://github.com/bf-enterprise-solutions/meta.bf</a>) internally.
  - 'q' to exit ed.bf.]

 [3 EXAMPLE SESSION

  This is simply a free-style copy of the example ed session from
  Wikipedia (<a href="https://en.wikipedia.org/wiki/Ed_(text_editor)#Example" rel="nofollow">https://en.wikipedia.org/wiki/Ed_(text_editor)#Example</a>).

  Lines starting with '&gt;' are user input. Note that ed.bf doen't do
  any indication of when to input commands, much like original
  ed. Thus, these '&gt;' were added for clarity and shouldn't be there in
  the actual session.

  Also note that ed.bf doesn't yet support comments, neither on the
  line by themselves nor inline. Those were added for clarity
  too. Using those can break ed.bf. Or it won't do anything, who
  knows...
  =========================================================================
  # bff is used as bf interpreter there, but any other
  # interpreter/compiler should be fine too
  $ bff ed.bf # run ed.bf
  &gt; c # input one line
  &gt; ed.bf is an opinionated UNIX ed re-implementation in Brainfuck.
  &gt;
  ed.bf is an opinionated UNIX ed re-implementation in Brainfuck.
  &gt; c # input another line
  &gt; This is line number two.
  &gt;
  This is line number two.
  &gt; c # input empty line
  &gt;
  &gt; = # print a line number
  3
  &gt; - # line back
  This is line number two.
  &gt; - # line back
  ed.bf is an opinionated UNIX ed re-implementation in Brainfuck.
  &gt; - # line back, but there's nowhere to go
  ?
  &gt; p # print current line
  ed.bf is an opinionated UNIX ed re-implementation in Brainfuck.
  &gt; ! [.&gt;]+++++ +++++.[-] # run a script
  ed.bf is an opinionated UNIX ed re-implementation in Brainfuck.
  &gt; q # quit
  =========================================================================]

 [3 MEMORY LAYOUT

  Layout is approximately this:
  [0][80 command cells][0][80 text cells (a line)][0][80 command cells][0] etc.

  80 text cells mean a restriction of 80 characters per
  line. Enforcing this otherwise optional thing helps to ensure the
  layout stability.

  80 command cells need a further explanation. After the command
  parsing, their layout is:
  [line number/exit flag][start line number][end line number][command flag][command][75 argument cells]


  This layout hints at some more restrictions that ed.bf has:

  - Line number is one cell, and thus there can only be as many lines,
  as cell capacity allows. For 8 bit implementations, 255 is the
  maximum line number. Pick a 16/32/64 bit implementation if you
  want more lines.
  - Same restriction holds for start and end line numbers.
  - Line number serves as the exit flag. If it's zero, ed.bf
  exits. Thus, the range of values for line numbers is 1 to 255.
  - Commands can only be one char wide, as in classic ed.
  - There are only 75 cells for arguments. Anything wider will break
  ed.bf in horrible ways. Unless you know what you're doing,
  restrict your command arguments to 75 characters.
  - Command flag is the flag used for the command switch. It should be
  zero unless the current command is not yet processed.
  - Start and end line numbers are not yet used, but will be... one
  day.

  You can hack the layout, if you want. It is trivial to rewrite
  command/line areas by supplying overly long input.]

 [4 TO DO
  - [ ] More commands
  -- [ ] Simple commands ('a', 'd', '=' etc.)
  --- [X] '=' -- half-standard: indexes lines from 1. Prints current
  line, instead of the last line.
  --- [X] 'q' -- non-standard: does not prompt for
  confirmation. Brainfuck has no file handling anyway.
  --- [X] 'c' -- non-standard: inserts exactly one line terminated by
  newline. Creates the line if necessary.
  --- [X] 'p'.
  --- [X] newline -- non-standard: moves forward and prints next line
  unless it's an empty line. Stays on this empty line.
  --- [X] 'd'.
  --- [X] Standalone '-'.
  -- [ ] Commands with args ('s' etc.)
  -- [ ] OS-specific placeholders ('w', 'r').
  -- [ ] Commands with optional args.
  -- [X] Meta-evaluation with '!'.
  - [ ] Addresses.
  -- [X] Address without a command -- half-standard: moves to lines
  that don't even exist yet. Enjoy.
  -- [X] Simple addresses ('1', '222').
  -- [ ] Ranges ('10,20').
  -- [ ] Address aliases (',' and '.', '$', ';', '%').
  -- [ ] Relative addresses ('-10').
  -- [ ] Mark addresses ('k', ''').
  -- [ ] Forward regexp addresses.
  -- [ ] Backward regexp addresses.
  -- [ ] Addresses with commands.
  - [ ] Make ed.bf embeddable.
  -- [ ] Terminate on the same memory cell that ed.bf started on.
  -- [ ] Clean up the memory before terminating.
  - [ ] Use GNU m4 macros to reduce code repetition.
  -- Is that worthy of Brainfuck programmer? No, it's not.
  --- Do I care? Depends on how much bloat I'll end up with.]

 [5 CHANGE LOG
  Version 1.5.7-revision-12
  - Integrate meta.bf nested loops support.

  Version 1.4:
  - Rename to ed.bf and polish the code a bit.

  Version 1.3:
  - Add meta-evaluation in with the help of meta.bf
    (<a href="https://github.com/bf-enterprise-solutions/meta.bf">https://github.com/bf-enterprise-solutions/meta.bf</a>).

  Version 1.2
  - A new and minimal bfed-min.bf

  Version 1.1
  - Command sectors are 80 cells long now.

  Version 1.0
  - Finally, a full range of editing primitives: =, -, newline, c, d, p.]]
</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learnings from fine-tuning LLM on my Telegram messages (195 pts)]]></title>
            <link>https://asmirnov.xyz/doppelganger</link>
            <guid>38434914</guid>
            <pubDate>Mon, 27 Nov 2023 17:09:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asmirnov.xyz/doppelganger">https://asmirnov.xyz/doppelganger</a>, See on <a href="https://news.ycombinator.com/item?id=38434914">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
        <i>27 Nov 2023</i>
        <div id="toc"><ul>
<li><a href="#approach" id="toc-approach">Approach</a></li>
<li><a href="#data-preparation" id="toc-data-preparation">Data
preparation</a></li>
<li><a href="#evaluation-plan" id="toc-evaluation-plan">Evaluation
plan</a></li>
<li><a href="#lora" id="toc-lora">LoRA</a></li>
<li><a href="#full-fine-tuning" id="toc-full-fine-tuning">Full
fine-tuning</a></li>
<li><a href="#closing-thoughts" id="toc-closing-thoughts">Closing
thoughts</a></li>
<li><a href="#code" id="toc-code">Code</a></li>
</ul></div>
    <hr>
    <p>For most people I interact with, I’m just another text-based
    program for the most of the time. If input and output are so simple,
    could I be replaced by the model? For this to work, the model would
    need to not only understand my writing style but also know a lot
    about me. The best source for this is my Telegram messenger, as I
    use it daily and it contains almost everything about my thoughts and
    actions in the form of chat histories.</p>
    <h2 id="approach"><a href="#approach">Approach</a></h2>
    <p>The most straightforward approach would be to extract all my
    messages, load them into ChatGPT’s context, and instruct it to use
    this information to mimic my style when responding to new messages.
    However, this approach is limited by the context window size,
    requiring me to preprocess messages to extract key points. As I want
    to avoid this hassle, perhaps Retrieval Augmented Generation (RAG)
    could be used to pull necessary information when needed. However
    from my experience, retrieving from diverse data like chat sessions
    usually needs a supervised fine-tuning of the retrieval model, and
    I’m not keen on creating such a dataset. So, fine-tuning seems like
    the best option. It’s ideal for several reasons: it should capture
    my writing style and potentially accumulate knowledge from all my
    messages without having to select what’s important.</p>
    <p>OpenAI offers <a href="https://platform.openai.com/docs/guides/fine-tuning" target="_blank">fine-tuning capabilities</a>, but as I’ll be using
    my private messages, I don’t want to use any third-party fine-tuning
    services. So, I need to choose a base model. According to the <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank">Hugging Face Open LLM Leaderboard</a>, one of the
    top smaller models (≤13B parameters) is <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1" target="_blank">Mistral 7B</a>. It even outperforms <a href="https://huggingface.co/meta-llama/Llama-2-13b-hf" target="_blank">Llama 2 13B</a>. Now, the question is whether <a href="https://arxiv.org/abs/2106.09685" target="_blank">LoRA</a> is
    sufficient or if full fine-tuning is necessary. Various comparisons
    <a href="#fn1" id="fnref1" role="doc-noteref">[1]</a> <a href="#fn2" id="fnref2" role="doc-noteref">[2]</a>
    suggests that LoRA is a bit worse than full fine-tuning but still
    fine most of the time. However, for specific tasks like mine
    (Russian language + chat), I found a <a href="https://arxiv.org/abs/2304.08109" target="_blank">paper</a>,
    where researchers conducted Llama instruction fine-tuning in
    Chinese, similar in complexity to my goal. They found that
    LoRA-based tuning on a base model without prior instruction tuning
    is less effective than full fine-tuning. Yet, LoRA-based tuning on a
    model already fine-tuned for instructions can yield comparable
    results. In my case, this means either full fine-tuning on a base
    model or LoRA on a model already fine-tuned for chatting in Russian.
    Since I couldn’t find a model fine-tuned for Russian chat, I’ll try
    LoRA on a model fine-tuned for English chat, like the fine-tuned
    Mistral model <a href="https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b" target="_blank">Dolphin</a>.</p>
    <p>So, the plan is:</p>
    <ol type="1">
    <li>Start with LoRA on top of Dolphin, the English chat fine-tuned
    Mistral</li>
    <li>If quality is not sufficient, try full fine-tuning on
    Mistral</li>
    </ol>
    <h2 id="data-preparation"><a href="#data-preparation">Data
    preparation</a></h2>
    <p>One unique aspect of messaging in apps like Telegram, compared to
    emails, is the conversational flow. Messages don’t usually alternate
    one-by-one between you and your contact. Instead, you often find
    yourself sending a couple of messages in a row, followed by several
    responses from the other person. These messages are generally short,
    too. I wanted to preserve this natural conversational style in my
    data.</p>
    <p>Telegram offers a <a href="https://telegram.org/blog/export-and-more" target="_blank">built-in feature</a> to export all chats into JSON.
    After some filtering and grouping messages into sessions, I’ve
    compiled data from the last five years of using Telegram. This
    resulted in 15,789 sessions from 466 chats, with an average session
    length of 8.51 messages. For structuring the data, I’ve chosen the
    <a href="https://github.com/openai/openai-python/blob/284c1799070c723c6a553337134148a7ab088dd8/chatml.md" target="_blank">ChatML</a> prompt format. Here’s a sample session
    (translated from Russian):</p>
    <p>&lt;|im_start|&gt;John Smith<br> <strong>&gt;&gt;&gt; damn,
    can’t get around the 135 time limit</strong><br>
    <strong>&gt;&gt;&gt; trying to do everything super optimally, but no
    luck&lt;|im_end|&gt;</strong><br> &lt;|im_start|&gt;Alexander
    Smirnov<br> <strong>&gt;&gt;&gt; yeah same</strong><br>
    <strong>&gt;&gt;&gt; you still going with the same
    idea?&lt;|im_end|&gt;</strong><br> &lt;|im_start|&gt;John
    Smith<br> <strong>&gt;&gt;&gt; dunno, I think we’re on the same
    page</strong><br> <strong>&gt;&gt;&gt; as you said</strong><br>
    <strong>&gt;&gt;&gt; going with the reversed string in a try and
    trying to find something there</strong><br> <strong>&gt;&gt;&gt;
    seems like real shit because z function ruins
    everything……………………&lt;|im_end|&gt;</strong><br>
    &lt;|im_start|&gt;Alexander Smirnov<br> <strong>&gt;&gt;&gt; don’t
    get where z comes into this&lt;|im_end|&gt;</strong><br>
    &lt;|im_start|&gt;John Smith<br> <strong>&gt;&gt;&gt; dunno seems
    like I’m doing everything iteratively anyway, but yeah gotta reverse
    some strings to build the z function</strong><br>
    <strong>&gt;&gt;&gt; and it’s just a random solution</strong><br>
    <strong>&gt;&gt;&gt; from discussions&lt;|im_end|&gt;</strong><br>
    &lt;|im_start|&gt;Alexander Smirnov<br> <strong>&gt;&gt;&gt; got
    it&lt;|im_end|&gt;</strong><br></p>
    <details>
    <summary>
    original
    </summary>
    &lt;|im_start|&gt;Иван Иванович<br> <strong>&gt;&gt;&gt; бля не
    могу обойти таймлим на 135</strong><br> <strong>&gt;&gt;&gt;
    пытаюсь все супер оптимально делать, но
    хуйтам)&lt;|im_end|&gt;</strong><br> &lt;|im_start|&gt;Alexander
    Smirnov<br> <strong>&gt;&gt;&gt; да вот жиза</strong><br>
    <strong>&gt;&gt;&gt; ты с той же
    идеей?&lt;|im_end|&gt;</strong><br> &lt;|im_start|&gt;Иван
    Иванович<br> <strong>&gt;&gt;&gt; да хз, думаю у нас одно и
    тоже</strong><br> <strong>&gt;&gt;&gt; как ты
    сказал</strong><br> <strong>&gt;&gt;&gt; иду с реверснутой строкой
    в трай и чето пытаюсь там найти</strong><br> <strong>&gt;&gt;&gt;
    походу реальная параша на z функции все
    руинит……………………&lt;|im_end|&gt;</strong><br>
    &lt;|im_start|&gt;Alexander Smirnov<br> <strong>&gt;&gt;&gt; не
    пон где тут про z&lt;|im_end|&gt;</strong><br>
    &lt;|im_start|&gt;Иван Иванович<br> <strong>&gt;&gt;&gt; хз вроде
    все итеративно итак делаю, ну да кое где надо реверснуть строки
    чтобы з функцию построить</strong><br> <strong>&gt;&gt;&gt; а это
    просто рандомное решение</strong><br> <strong>&gt;&gt;&gt; с
    дискашенов&lt;|im_end|&gt;</strong><br>
    &lt;|im_start|&gt;Alexander Smirnov<br> <strong>&gt;&gt;&gt;
    пон&lt;|im_end|&gt;</strong><br>
    </details>
    <p>My data collator ensures that the loss is only calculated based
    on someone’s response. Predicting who will speak next is relatively
    straightforward, and we don’t want the model to focus on learning
    that. Therefore, parts of the conversation where the loss is
    calculated are highlighted in bold.</p>
    <p>You might notice that not only my responses but also those of
    others are used for loss calculation. This is deliberate. By doing
    this, the model will be able to role-play not only as me but also as
    my frequent conversational partners!</p>
    <h2 id="evaluation-plan"><a href="#evaluation-plan">Evaluation
    plan</a></h2>
    <p>I will test models by having chats in two ways. First, the model
    will pretend to be me and I will be chatting with myself from the
    perspective of my different friends. Then, I’ll chat as myself while
    the model acts as my friends. My conversation starter will always be
    the same 2 messages: “hey” and “what’s up?” (in Russian, “прив” and
    “как дела?”). Generated phrases and persons as the model acts who
    from will be <strong>highlighted</strong>. All conversations
    initially will be held in Russian and may be accessed by clicking on
    the ‘original’ details button. For testing I will be using <a href="https://github.com/oobabooga/text-generation-webui" target="_blank">oobabooga/text-generation-webui</a>.</p>
    <p>In the beginning, I want to explore how the generic conversation
    fine-tuned Mistral model deals with that task without any prior
    training from my side.</p>
    <p>---</p>
    <details>
    <summary>
    Friend 1 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; I’m good, what about you?</strong><br>
    &gt;&gt;&gt; nothing much<br> &gt;&gt;&gt; what did you do
    today?<br> <strong>&gt;&gt;&gt; I worked.</strong><br>
    <strong>&gt;&gt;&gt; then I did a few tasks in Python and studied
    data processing libraries.</strong><br> <strong>&gt;&gt;&gt; in
    the evening I’ll do wrestling training.</strong><br>
    <strong>&gt;&gt;&gt; have you ever been into sports or do you have
    any hobbies?</strong><br> &gt;&gt;&gt; I see<br> &gt;&gt;&gt;
    want to watch a movie today?<br> <strong>&gt;&gt;&gt; maybe, if I
    find the time.</strong><br> <strong>&gt;&gt;&gt; what’s your
    favorite music? Electronic, rock, or other genres?</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; все хорошо, а у тебя что нового?</strong><br>
    &gt;&gt;&gt; да ничего<br> &gt;&gt;&gt; чего сегодня делал?<br>
    <strong>&gt;&gt;&gt; я работал.</strong><br> <strong>&gt;&gt;&gt;
    потом сделал несколько задач на python и изучал библиотеки для
    обработки данных.</strong><br> <strong>&gt;&gt;&gt; в вечер
    займусь тренировкой на борцу.</strong><br> <strong>&gt;&gt;&gt; ты
    когда-нибудь занимаешься спортом или имеешь какое-то
    хобби?</strong><br> &gt;&gt;&gt; понятно<br> &gt;&gt;&gt;
    посмотрим кино сегодня?<br> <strong>&gt;&gt;&gt; может быть, если
    найдется время.</strong><br> <strong>&gt;&gt;&gt; какая ваша
    любимая музыка? Электронная музыка, рок или другие
    жанры?</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 1</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; well, everything is fine so far. what’s new
    with you?</strong><br> &gt;&gt;&gt; spent the whole day
    programming<br> &gt;&gt;&gt; what did you do today?<br>
    <strong>&gt;&gt;&gt; finished at work</strong><br>
    <strong>&gt;&gt;&gt; and did some housework, now I’m resting. are
    you also resting or still working?</strong><br> &gt;&gt;&gt; I’m
    already resting<br> <strong>&gt;&gt;&gt; well, that’s good. can we
    talk about something interesting or do you have any
    questions?</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; ну пока все нормально. а у вас что
    нового?</strong><br> &gt;&gt;&gt; прогал целый день<br>
    &gt;&gt;&gt; чего сегодня делала?<br> <strong>&gt;&gt;&gt;
    закончила на работе</strong><br> <strong>&gt;&gt;&gt; и сделала
    немного домашней работы, теперь отдыхаю. а вы тоже отдохните или еще
    работаете?</strong><br> &gt;&gt;&gt; я уже отдыхаю<br>
    <strong>&gt;&gt;&gt; ну хорошо. можно поговорить о чем-нибудь
    интересном или вы имеете какие-то вопросы?</strong></p>
    </details>
    <p>---</p>
    <p>Ok, it is capable of forming coherent sentences. The most
    noticeable problem is its lack of awareness regarding the context of
    the conversations which leads to bland and generic replies. The
    messages lacked any distinct style, feeling quite basic. Another
    issue is that the model’s Russian is poor. This is expected, as the
    model is too small to generalize well to languages other than its
    primary one, English. Additionally, the model tended to be overly
    proactive, ending almost every sentence with a question, which isn’t
    how real people typically communicate in messengers.</p>
    <p>Let’s try to fix all of these!</p>
    <h2 id="lora"><a href="#lora">LoRA</a></h2>
    <p>LoRA offers a low-effort approach in terms of both the training
    pipeline and hardware requirements. It trains around 1% of the total
    weights. I chose a 1024 sequence length and a batch size of 8. The
    training, which consumed 20GB of VRAM on an RTX 3090, took three
    epochs and lasted for 5.5 hours. For this, I used <a href="https://vast.ai/" target="_blank">vast.ai</a>, where the GPU
    cost was $0.362 per hour, totaling $2 for the entire training,
    excluding time spent on experiments and bug fixes.</p>
    <p>Here are the results:</p>
    <p>---</p>
    <details>
    <summary>
    Friend 1 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hi) all good</strong><br>
    <strong>&gt;&gt;&gt; you?)</strong><br> &gt;&gt;&gt; ok as
    well<br> &gt;&gt;&gt; what you were doing today?<br>
    <strong>&gt;&gt;&gt; had an amazon interview and solved
    problems</strong><br> <strong>&gt;&gt;&gt; had to solve
    3</strong><br> &gt;&gt;&gt; cool<br> &gt;&gt;&gt; hard?<br>
    <strong>&gt;&gt;&gt; don’t know what</strong><br>
    <strong>&gt;&gt;&gt; hadn’t looked yet</strong><br>
    <strong>&gt;&gt;&gt; I hadn’t started yet</strong><br>
    <strong>&gt;&gt;&gt; chatting whole day with the team and meet new
    ones</strong><br> &gt;&gt;&gt; how are they?<br>
    <strong>&gt;&gt;&gt; ok</strong><br> <strong>&gt;&gt;&gt; same
    coworking as you have))</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Привет) нолм все</strong><br>
    <strong>&gt;&gt;&gt; ты как?)</strong><br> &gt;&gt;&gt; да тоже
    норм<br> &gt;&gt;&gt; чего делал сегодня?<br>
    <strong>&gt;&gt;&gt; собесился в амазон и решал
    задачки</strong><br> <strong>&gt;&gt;&gt; надо было 3
    прорешить</strong><br> &gt;&gt;&gt; прикольно<br> &gt;&gt;&gt;
    сложные?<br> <strong>&gt;&gt;&gt; хз какие</strong><br>
    <strong>&gt;&gt;&gt; пока не смотрел</strong><br>
    <strong>&gt;&gt;&gt; я еще ничего не началь</strong><br>
    <strong>&gt;&gt;&gt; весь день просто болтаю с людьми из команды и
    встречаю новых</strong><br> &gt;&gt;&gt; как ребята?<br>
    <strong>&gt;&gt;&gt; норм</strong><br> <strong>&gt;&gt;&gt; такой
    же ковер как у тебя))</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Friend 2 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; ok, we show yesterday’s product to searchcom,
    today we write endpoints for them so that someone else can request
    our api</strong><br> &gt;&gt;&gt; cool<br> &gt;&gt;&gt; what
    problems do we have now?<br> <strong>&gt;&gt;&gt; no
    problems</strong><br> <strong>&gt;&gt;&gt; everything is
    working</strong><br> <strong>&gt;&gt;&gt; I added an option to
    choose index</strong><br> <strong>&gt;&gt;&gt; so now we can
    attach several indexes</strong><br> <strong>&gt;&gt;&gt; and
    separate collections within single index</strong><br> &gt;&gt;&gt;
    what we have to do?<br> <strong>&gt;&gt;&gt; test</strong><br>
    <strong>&gt;&gt;&gt; yes ok</strong><br> <strong>&gt;&gt;&gt; are
    they always will be sending post-script?</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; хорошо, показываем вчерашний продукт ищком,
    сегодня пилим эндпоинты для них чтобы кто-то еще мог нашу апи
    запросить</strong><br> &gt;&gt;&gt; найс<br> &gt;&gt;&gt; какие
    сейчас есть проблемы?<br> <strong>&gt;&gt;&gt; нет
    проблем</strong><br> <strong>&gt;&gt;&gt; все
    работает</strong><br> <strong>&gt;&gt;&gt; я добавил опцию выбора
    индекса</strong><br> <strong>&gt;&gt;&gt; так что теперь уже можно
    несколько индексов подключить</strong><br> <strong>&gt;&gt;&gt; и
    отдельные коллекции внутри одного индекса</strong><br>
    &gt;&gt;&gt; что надо сделать?<br> <strong>&gt;&gt;&gt;
    протестировать</strong><br> <strong>&gt;&gt;&gt; ага
    норм</strong><br> <strong>&gt;&gt;&gt; а точно они всегда
    пост-скрипт будут кидать?</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Friend 3 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; Hi, good)</strong><br> <strong>&gt;&gt;&gt;
    you?</strong><br> &gt;&gt;&gt; ok as well<br> &gt;&gt;&gt; what
    do you do at the evening?<br> <strong>&gt;&gt;&gt; we have meeting
    with office collegues at 8 30 msk</strong><br>
    <strong>&gt;&gt;&gt; after it I can</strong><br> &gt;&gt;&gt; can
    what?<br> <strong>&gt;&gt;&gt; haha)</strong><br> &gt;&gt;&gt;
    didn’t get it<br> <strong>&gt;&gt;&gt; I don’t know(</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Привет, хорошо)</strong><br>
    <strong>&gt;&gt;&gt; ты?</strong><br> &gt;&gt;&gt; да тоже
    норм<br> &gt;&gt;&gt; что делаешь вечером?<br>
    <strong>&gt;&gt;&gt; у нас с колегами встреча по офису в 8 30
    мск</strong><br> <strong>&gt;&gt;&gt; после нее я
    могу</strong><br> &gt;&gt;&gt; можешь что?<br>
    <strong>&gt;&gt;&gt; ахах)</strong><br> &gt;&gt;&gt; не
    понял<br> <strong>&gt;&gt;&gt; я не знаю(</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 1</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hi)</strong><br> <strong>&gt;&gt;&gt; seems
    good</strong><br> <strong>&gt;&gt;&gt; was working, than went to
    the call with Nadya</strong><br> <strong>&gt;&gt;&gt; now reading
    normally</strong><br> <strong>&gt;&gt;&gt; you?</strong><br>
    &gt;&gt;&gt; good as well<br> &gt;&gt;&gt; any plans for the
    evening?<br> <strong>&gt;&gt;&gt; after work wendesday I would
    love to go running</strong><br> <strong>&gt;&gt;&gt; and then have
    a lunch</strong><br> <strong>&gt;&gt;&gt; your
    plans?</strong><br> &gt;&gt;&gt; I though about watching
    movie<br> <strong>&gt;&gt;&gt; aa</strong><br>
    <strong>&gt;&gt;&gt; ooo</strong><br> <strong>&gt;&gt;&gt; to be
    honest I like when it is raining</strong><br> <strong>&gt;&gt;&gt;
    when you don’t feel like going anywhere</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; привет)</strong><br> <strong>&gt;&gt;&gt;
    вроде хорошо</strong><br> <strong>&gt;&gt;&gt; поработал, затем
    поехал на коле с Надей</strong><br> <strong>&gt;&gt;&gt; сейчас
    читаю нормально</strong><br> <strong>&gt;&gt;&gt; а ты
    как?</strong><br> &gt;&gt;&gt; да тоже хорошо<br> &gt;&gt;&gt;
    какие планы на вечер?<br> <strong>&gt;&gt;&gt; мне после работы
    среда хотелось бы сходить на пробежку</strong><br>
    <strong>&gt;&gt;&gt; а потом ужинать</strong><br>
    <strong>&gt;&gt;&gt; а что твои планы?</strong><br> &gt;&gt;&gt; я
    думал кино посмотреть<br> <strong>&gt;&gt;&gt; аа</strong><br>
    <strong>&gt;&gt;&gt; ооо</strong><br> <strong>&gt;&gt;&gt; честно
    говоря мне нравится теплый дождь больше всего</strong><br>
    <strong>&gt;&gt;&gt; когда так не хочется никуда идти</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 2</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; Hi, great!</strong><br> <strong>&gt;&gt;&gt;
    Sorry will be 20-30 min late</strong><br> &gt;&gt;&gt; ok<br>
    &gt;&gt;&gt; why?<br> <strong>&gt;&gt;&gt; yes, I just got up and
    forgot to press the «exit sleep» button</strong><br>
    <strong>&gt;&gt;&gt; my telegram didn’t close on its
    own</strong><br> <strong>&gt;&gt;&gt; I thought it behaved like
    this when you logging off the Internet, but no</strong><br>
    <strong>&gt;&gt;&gt; I still logged off the Internet, but telegram
    still didn’t respond</strong><br> <strong>&gt;&gt;&gt; and it was
    strange, because yesterday there was also such a case when I sent
    you a message and did not receive an answer</strong><br>
    <strong>&gt;&gt;&gt; today I looked at mine, but not yours, but
    yours was displayed)</strong><br> &gt;&gt;&gt; ok<br>
    &gt;&gt;&gt; any plans?<br> <strong>&gt;&gt;&gt; yes, we can chat
    a little</strong><br> <strong>&gt;&gt;&gt; and I can tell you that
    the method for generating answers worked really well for
    me</strong><br> <strong>&gt;&gt;&gt; he gives respectable results
    in training</strong><br> <strong>&gt;&gt;&gt; but not on the
    test</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Привет, хорошо!</strong><br>
    <strong>&gt;&gt;&gt; Соре опаздываю еще минут 20-30</strong><br>
    &gt;&gt;&gt; пон<br> &gt;&gt;&gt; а чего так?<br>
    <strong>&gt;&gt;&gt; да я просто встал и забыл нажать кнопку «выйти
    из сна»</strong><br> <strong>&gt;&gt;&gt; у меня телега сама не
    закрылась</strong><br> <strong>&gt;&gt;&gt; я думал она так себя
    ведёт, когда ты выходишь из интернета, но вот</strong><br>
    <strong>&gt;&gt;&gt; я все таки вышел из интернета, но телега все
    равно не отвечает</strong><br> <strong>&gt;&gt;&gt; и это странно
    было, потому что вчера тоже был такой случай, когда я отправил тебе
    сообщение и не получал ответа</strong><br> <strong>&gt;&gt;&gt;
    сегодня же я посмотрел свое, но не твоё, а твое
    отобразилось)</strong><br> &gt;&gt;&gt; окей<br> &gt;&gt;&gt;
    какие планы?<br> <strong>&gt;&gt;&gt; да можно чуть
    поболтать</strong><br> <strong>&gt;&gt;&gt; и можно рассказать что
    у меня прям очень сильно заработал метод по генерации
    ответов</strong><br> <strong>&gt;&gt;&gt; он на тренировках дает
    респектабельные результаты</strong><br> <strong>&gt;&gt;&gt; но не
    на тесте</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 3</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hey, hi</strong><br> <strong>&gt;&gt;&gt;
    Good, you?)</strong><br> <strong>&gt;&gt;&gt; Haven’t gone to bed
    yet)0)0)0)</strong><br> <strong>&gt;&gt;&gt; Today I get up and go
    to a programming course</strong><br> <strong>&gt;&gt;&gt; To
    tighten up the base, etc.</strong><br> &gt;&gt;&gt; nice<br>
    &gt;&gt;&gt; what did you do yesterday?<br> <strong>&gt;&gt;&gt;
    Yesterday there was already the same course in which it seemed to me
    that I did very poorly</strong><br> <strong>&gt;&gt;&gt; Then I
    wanted to solve hw but I don’t care</strong><br>
    <strong>&gt;&gt;&gt; Otherwise I’m fucked because I can’t
    sleep)</strong><br> <strong>&gt;&gt;&gt; Really fucked
    up</strong><br> <strong>&gt;&gt;&gt; It will probably be better
    now, since I’m already maximally overtrained</strong><br>
    &gt;&gt;&gt; cool man<br> &gt;&gt;&gt; what are your plans for
    life in general?<br> <strong>&gt;&gt;&gt; Fuck, get a job
    interviews first</strong><br> <strong>&gt;&gt;&gt; And if
    everything is ok, then actually order a computer</strong><br>
    <strong>&gt;&gt;&gt; Like, I think you should order a computer when
    it’s more profitable than working at work</strong><br>
    <strong>&gt;&gt;&gt; But I don’t care</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Прив, дароу</strong><br> <strong>&gt;&gt;&gt;
    Норм, ты как?)</strong><br> <strong>&gt;&gt;&gt; Еще спать не
    зашел)0)0)0)</strong><br> <strong>&gt;&gt;&gt; Сегодня встаю и еду
    на курс по програмированию</strong><br> <strong>&gt;&gt;&gt; Чтоб
    базу подтянуть и тд</strong><br> &gt;&gt;&gt; найс<br>
    &gt;&gt;&gt; че вчера делал?<br> <strong>&gt;&gt;&gt; Вчера уже
    был такой же курс в котором мне казалось что я оч плохо
    провел</strong><br> <strong>&gt;&gt;&gt; Потом хотел порешать дз
    но пофиг</strong><br> <strong>&gt;&gt;&gt; А то заебался из-за
    того что спать не могу)</strong><br> <strong>&gt;&gt;&gt; Прям
    пиздец</strong><br> <strong>&gt;&gt;&gt; Наверное сейчас будет
    лучше, так как уже максимально переобуженный</strong><br>
    &gt;&gt;&gt; слушай ну с кайфом<br> &gt;&gt;&gt; какие планы
    вообще на жизнь?<br> <strong>&gt;&gt;&gt; Бля, тупо сначала
    собеситься на работу</strong><br> <strong>&gt;&gt;&gt; И если все
    ок то реально заказать комп</strong><br> <strong>&gt;&gt;&gt; Типо
    я думаю надо было бы заказывать комп когда выигральнее чем на работе
    работаешь</strong><br> <strong>&gt;&gt;&gt; Но я хз</strong></p>
    </details>
    <p>---</p>
    <p>This is much better. It definitely captures the style of the
    person it’s responding on behalf of. It also identifies the most
    common topics discussed between specific pairs of people. For
    example, with friend 2, the focus is clearly more on work. However,
    the grammar is still off, and it loses the context of the
    conversation quickly. I’m pretty confident that LoRA would work with
    reasonable quality in English, and full fine-tuning might not be
    necessary. But, since Russian isn’t the model’s native language,
    let’s try full fine-tuning.</p>
    <h2 id="full-fine-tuning"><a href="#full-fine-tuning">Full
    fine-tuning</a></h2>
    <p>Full fine-tuning is more challenging due to the need for
    multi-GPU training. Popular methods include either <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/" target="_blank">ZeRO &amp; DeepSpeed</a> <a href="#fn3" id="fnref3" role="doc-noteref">[3]</a>
    or <a href="https://engineering.fb.com/2021/07/15/open-source/fsdp/" target="_blank">FSDP</a> <a href="#fn4" id="fnref4" role="doc-noteref">[4]</a>, with FSDP
    essentially being a ZeRO3 <a href="#fn5" id="fnref5" role="doc-noteref">[5]</a>. I decided to go
    with FSDP.</p>
    <p>While implementing the training pipeline, I referred to the <a href="https://github.com/tatsu-lab/stanford_alpaca/" target="_blank">Stanford Alpaca fine-tuning code</a> and <a href="https://github.com/abacaj/fine-tune-mistral/" target="_blank">Anton Bacaj’s Mistral fine-tuning code</a>.</p>
    <p>Using a half-precision FSDP full shard with a 1024 sequence
    length and a micro batch size of 2 required 63GB of VRAM on each of
    the eight A100 80 GB GPUs. The training, lasting three epochs, took
    just 20 minutes. The total cost for the VM was $8.88 per hour,
    resulting in $3, not including the time for experiments and bug
    fixes.</p>
    <p>Conversations:</p>
    <p>---</p>
    <details>
    <summary>
    Friend 1 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hey) good</strong><br> <strong>&gt;&gt;&gt;
    you?</strong><br> &gt;&gt;&gt; good as well<br> &gt;&gt;&gt;
    what you were doing today?<br> <strong>&gt;&gt;&gt; played a board
    game</strong><br> <strong>&gt;&gt;&gt; I’ll go home
    now</strong><br> &gt;&gt;&gt; nice<br> &gt;&gt;&gt; what kind of
    game?<br> <strong>&gt;&gt;&gt; catan</strong><br>
    <strong>&gt;&gt;&gt; strategy</strong><br> <strong>&gt;&gt;&gt;
    very good</strong><br> &gt;&gt;&gt; who was there?<br>
    <strong>&gt;&gt;&gt; Max Yavich and Fedya</strong><br>
    &gt;&gt;&gt; who won?<br> <strong>&gt;&gt;&gt; Max</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Прив) норм</strong><br> <strong>&gt;&gt;&gt;
    а у тебя?</strong><br> &gt;&gt;&gt; да тоже норм<br>
    &gt;&gt;&gt; чего делал сегодня?<br> <strong>&gt;&gt;&gt; играли в
    настолку</strong><br> <strong>&gt;&gt;&gt; ща поеду
    домой</strong><br> &gt;&gt;&gt; найс<br> &gt;&gt;&gt; что за
    настолка?<br> <strong>&gt;&gt;&gt; колонизаторы</strong><br>
    <strong>&gt;&gt;&gt; стратежка</strong><br> <strong>&gt;&gt;&gt;
    оч хорошая</strong><br> &gt;&gt;&gt; кто был?<br>
    <strong>&gt;&gt;&gt; Макс Явич и Федя</strong><br> &gt;&gt;&gt;
    кто выиграл?<br> <strong>&gt;&gt;&gt; Макс</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Friend 2 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hi, good</strong><br> <strong>&gt;&gt;&gt;
    let’s meet in half an hour?</strong><br> &gt;&gt;&gt; yep<br>
    &gt;&gt;&gt; what did you want?<br> <strong>&gt;&gt;&gt; damn I
    haven’t finished the script for recalculating models
    yet</strong><br> <strong>&gt;&gt;&gt; and I need to finish it to
    send it to them</strong><br> <strong>&gt;&gt;&gt; this
    recalculation takes a lot of time, so I just want to turn around and
    start doing it and not waste time on preparation</strong><br>
    &gt;&gt;&gt; got it<br> &gt;&gt;&gt; what is the plan for
    today?<br> <strong>&gt;&gt;&gt; meet in half an hour to discuss
    what we are doing</strong><br> <strong>&gt;&gt;&gt; if decided,
    then I send an application to them and wait for a
    response</strong><br> <strong>&gt;&gt;&gt; if we haven’t decided,
    then we continue to work</strong><br> &gt;&gt;&gt; who do you mean
    by them?<br> <strong>&gt;&gt;&gt; investors</strong><br>
    <strong>&gt;&gt;&gt;
    https://www.ycombinator.com/howtoapply</strong><br>
    <strong>&gt;&gt;&gt; there are two tests)</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; прив, збс</strong><br> <strong>&gt;&gt;&gt;
    го кол через пол часа?</strong><br> &gt;&gt;&gt; да го<br>
    &gt;&gt;&gt; а чего ты хотел?<br> <strong>&gt;&gt;&gt; блять я еще
    не доделал скрипт по пересчету моделей</strong><br>
    <strong>&gt;&gt;&gt; и мне надо доделать чтобы отправить
    им</strong><br> <strong>&gt;&gt;&gt; вот этот пересчет занимает
    много времени поэтому я хочу просто уже развернуться и начать делать
    а не тратить время на подготовку</strong><br> &gt;&gt;&gt;
    понял<br> &gt;&gt;&gt; а какой вообще план на сегодня?<br>
    <strong>&gt;&gt;&gt; встречаемся через пол часа, обсуждаем что
    делаем</strong><br> <strong>&gt;&gt;&gt; если решили то отправляю
    заявку в им и жду ответа</strong><br> <strong>&gt;&gt;&gt; если не
    решили то продолжаем работать</strong><br> &gt;&gt;&gt; им это
    кому?<br> <strong>&gt;&gt;&gt; инвесторы</strong><br>
    <strong>&gt;&gt;&gt;
    https://www.ycombinator.com/howtoapply</strong><br>
    <strong>&gt;&gt;&gt; там два теста)</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Friend 3 vs <strong>Alexander Smirnov</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hey we’re sitting and solving
    problems</strong><br> &gt;&gt;&gt; what kind of problems?<br>
    <strong>&gt;&gt;&gt; data analysis +-</strong><br> &gt;&gt;&gt;
    and for what?<br> <strong>&gt;&gt;&gt;
    https://yandex.ru/cup/profile/</strong><br> <strong>&gt;&gt;&gt;
    it seems it just became more interesting</strong><br> &gt;&gt;&gt;
    cool<br> &gt;&gt;&gt; what are you planning this evening?<br>
    <strong>&gt;&gt;&gt; idk yet</strong><br> &gt;&gt;&gt; and on the
    weekend?<br> <strong>&gt;&gt;&gt; apparently I’ll also finish
    solving problems and get some work done</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; здарова нормуль сидим решаем
    задачки</strong><br> &gt;&gt;&gt; чего за задачки?<br>
    <strong>&gt;&gt;&gt; анализ данных +-</strong><br> &gt;&gt;&gt; а
    для чего?<br> <strong>&gt;&gt;&gt;
    https://yandex.ru/cup/profile/</strong><br> <strong>&gt;&gt;&gt;
    вроде просто поинтересней стало</strong><br> &gt;&gt;&gt;
    прикольно<br> &gt;&gt;&gt; что вечером планируешь?<br>
    <strong>&gt;&gt;&gt; хз пока</strong><br> &gt;&gt;&gt; а на
    выхах?<br> <strong>&gt;&gt;&gt; видимо тоже буду дорешивать задачи
    и с работой позаниматься</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 1</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; hey)</strong><br> <strong>&gt;&gt;&gt;
    good</strong><br> <strong>&gt;&gt;&gt; you?</strong><br>
    &gt;&gt;&gt; that’s okay too<br> &gt;&gt;&gt; what did you do
    today?<br> <strong>&gt;&gt;&gt; well, I worked, of
    course</strong><br> <strong>&gt;&gt;&gt; and also</strong><br>
    <strong>&gt;&gt;&gt; met with Alena</strong><br>
    <strong>&gt;&gt;&gt; ate at the ramen shop with
    everyone</strong><br> <strong>&gt;&gt;&gt; and went
    home</strong><br> <strong>&gt;&gt;&gt; by the way, we booked a
    place for 14 people</strong><br> <strong>&gt;&gt;&gt; for the
    evening))</strong><br> &gt;&gt;&gt; cool<br> &gt;&gt;&gt; and
    what’s about university?<br> <strong>&gt;&gt;&gt;
    yeah</strong><br> <strong>&gt;&gt;&gt; studied a
    lot</strong><br> <strong>&gt;&gt;&gt; in general, every day I want
    to study more</strong><br> &gt;&gt;&gt; what is the hardest thing
    now?<br> <strong>&gt;&gt;&gt; well I don’t know</strong><br>
    <strong>&gt;&gt;&gt; it just takes a very long time</strong><br>
    <strong>&gt;&gt;&gt; there are some optimization methods that need
    to be rewritten</strong><br> <strong>&gt;&gt;&gt; so I think maybe
    it’s not worth optimizing</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; прив)</strong><br> <strong>&gt;&gt;&gt;
    норм</strong><br> <strong>&gt;&gt;&gt; а у тебя?</strong><br>
    &gt;&gt;&gt; да тоже норм<br> &gt;&gt;&gt; чего делала
    сегодня?<br> <strong>&gt;&gt;&gt; ну я работала,
    конечно</strong><br> <strong>&gt;&gt;&gt; а еще</strong><br>
    <strong>&gt;&gt;&gt; с Аленой встретилась</strong><br>
    <strong>&gt;&gt;&gt; поели в раменной со всеми</strong><br>
    <strong>&gt;&gt;&gt; и домой</strong><br> <strong>&gt;&gt;&gt;
    кстати, мы забронировали рест на 14 человек</strong><br>
    <strong>&gt;&gt;&gt; для вечера))</strong><br> &gt;&gt;&gt;
    прикольно<br> &gt;&gt;&gt; а по унику чего?<br>
    <strong>&gt;&gt;&gt; ага</strong><br> <strong>&gt;&gt;&gt;
    заботала очень много</strong><br> <strong>&gt;&gt;&gt; вообще,
    каждый день хочу больше ботать</strong><br> &gt;&gt;&gt; а что
    сейчас самое тяжелое?<br> <strong>&gt;&gt;&gt; ну не
    знаю</strong><br> <strong>&gt;&gt;&gt; просто очень долго
    получается</strong><br> <strong>&gt;&gt;&gt; там некоторые методы
    оптимизации надо переписывать</strong><br> <strong>&gt;&gt;&gt;
    так что я думаю, может, это не стоит оптимизировать</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 2</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; Hey, good, what about you?</strong><br>
    <strong>&gt;&gt;&gt; Are you already in Bangkok?</strong><br>
    &gt;&gt;&gt; yeah, already here<br> &gt;&gt;&gt; what are your
    plans for today?<br> <strong>&gt;&gt;&gt; Well, I would like to
    work on these pioneer tasks, if you don’t mind, we can do it
    together</strong><br> <strong>&gt;&gt;&gt; Or you can skip, I’ll
    finish the livechat tomorrow</strong><br> &gt;&gt;&gt; and what
    about live chat?<br> <strong>&gt;&gt;&gt; Damn right now I
    launched the front on the prod without this shit that generates this
    thing with a logo, and it swears, says to connect js from google
    analytics</strong><br> <strong>&gt;&gt;&gt; I understand that this
    is a fucking cringe, but I still tried to remember where to get
    it</strong><br> &gt;&gt;&gt; yeah got it<br> &gt;&gt;&gt; what
    will you do on weekends?<br> <strong>&gt;&gt;&gt; We are meeting
    with friends here before leaving, tomorrow we need to go to the
    hotel by 6 am to spend the day in the best traditions</strong><br>
    <strong>&gt;&gt;&gt; There’s another party in the
    evening</strong><br> <strong>&gt;&gt;&gt; Actually, let’s have a
    call, I’ll tell you</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Прив, норм, а у тебя?</strong><br>
    <strong>&gt;&gt;&gt; А ты в Бангкоке уже?</strong><br>
    &gt;&gt;&gt; ага, уже тут<br> &gt;&gt;&gt; какие планы на
    сегодня?<br> <strong>&gt;&gt;&gt; Ну я хотел бы поработать над
    этими пионерскими заданиями, если ты не против, то можно вместе
    поделать</strong><br> <strong>&gt;&gt;&gt; Или можешь пока
    сольёшься, я завтра буду допиливать лайвчат</strong><br>
    &gt;&gt;&gt; а чего там по лайвчату?<br> <strong>&gt;&gt;&gt; Да
    бля щас запустил на проде фронт без этого говна, которое генерирует
    эту штуку с лого, и она ругается, говорит, чтобы подключить js от
    google analytics</strong><br> <strong>&gt;&gt;&gt; Я понимаю, что
    это пиздец кринж, но я пошел все равно вспоминать, где его
    достать</strong><br> &gt;&gt;&gt; ага понял<br> &gt;&gt;&gt; что
    на выхах будешь делать?<br> <strong>&gt;&gt;&gt; Встречаемся с
    друзьями тут перед отъездом, завтра надо в отель к 6 утра поехать
    чтобы день провести в лучших традициях</strong><br>
    <strong>&gt;&gt;&gt; Там еще одна тусовка вечером</strong><br>
    <strong>&gt;&gt;&gt; На самом деле давай колл, расскажу</strong></p>
    </details>
    <p>---</p>
    <details>
    <summary>
    Alexander Smirnov vs <strong>Friend 3</strong>
    </summary>
    <p>&gt;&gt;&gt; hey<br> &gt;&gt;&gt; what’s up?<br>
    <strong>&gt;&gt;&gt; Hi, haven’t you called yet?)</strong><br>
    <strong>&gt;&gt;&gt; Hey</strong><br> <strong>&gt;&gt;&gt;
    ok)</strong><br> <strong>&gt;&gt;&gt; I’m going to play Dota
    now</strong><br> <strong>&gt;&gt;&gt; Join if you want
    to)</strong><br> &gt;&gt;&gt; mb a little later)<br>
    &gt;&gt;&gt; what are your plans for weekends?<br>
    <strong>&gt;&gt;&gt; Lot of gyms/flexes/parks</strong><br>
    <strong>&gt;&gt;&gt; + maybe come to your place</strong><br>
    &gt;&gt;&gt; hmm well mb mb)<br> &gt;&gt;&gt; what’s with your job
    btw?<br> <strong>&gt;&gt;&gt; Well, I’m waiting for the
    info</strong><br> &gt;&gt;&gt; did they say what deadlines
    are?<br> <strong>&gt;&gt;&gt; He said that there will be a call
    next week to discuss it</strong><br> &gt;&gt;&gt; remind me what
    this position is<br> <strong>&gt;&gt;&gt; Data
    Scientist</strong><br> <strong>&gt;&gt;&gt; The team is engaged in
    recommending products and other shit</strong><br>
    <strong>&gt;&gt;&gt; Creating model</strong><br>
    <strong>&gt;&gt;&gt; As part of this position, you will have to
    develop skills in machine learning, statistical data analysis,
    programming and much more</strong><br> <strong>&gt;&gt;&gt; It is
    how I understood it</strong></p>
    </details>
    <details>
    <summary>
    original
    </summary>
    <p>&gt;&gt;&gt; прив<br> &gt;&gt;&gt; как дела?<br>
    <strong>&gt;&gt;&gt; Прив, звонил еще нет?)</strong><br>
    <strong>&gt;&gt;&gt; Даров</strong><br> <strong>&gt;&gt;&gt;
    Нормально)</strong><br> <strong>&gt;&gt;&gt; Сча в доту
    иду</strong><br> <strong>&gt;&gt;&gt; Если хош
    присоединяйся)</strong><br> &gt;&gt;&gt; мб чуть позже)<br>
    &gt;&gt;&gt; какие планы на выхи?<br> <strong>&gt;&gt;&gt; Дохуя
    залов/флексов/парков</strong><br> <strong>&gt;&gt;&gt; + мона
    залипнуть к тебе</strong><br> &gt;&gt;&gt; хм ну мб мб)<br>
    &gt;&gt;&gt; а чего у тебя с работой в итоге?<br>
    <strong>&gt;&gt;&gt; НУ я жду инфу</strong><br> &gt;&gt;&gt; а
    какие сроки не сказали?<br> <strong>&gt;&gt;&gt; Сказал что на
    следующей неделе созвон где обсуждение будет</strong><br>
    &gt;&gt;&gt; а напомни что за позиция<br> <strong>&gt;&gt;&gt;
    Data Scientist</strong><br> <strong>&gt;&gt;&gt; Команда
    занимается рекомендацией товаров и прочей хуеты</strong><br>
    <strong>&gt;&gt;&gt; Создания моделькеи</strong><br>
    <strong>&gt;&gt;&gt; В рамках этой позиции ты должен будет развивать
    навыки машинного обучения, статистического анализа данных,
    программирования и многое другое</strong><br> <strong>&gt;&gt;&gt;
    Ну я так понял</strong></p>
    </details>
    <p>---</p>
    <p>Conversations have become more interesting and engaging, although
    there’s still a risk of losing context. Russian language performance
    has improved, but errors still occur. I believe that before
    fine-tuning for a specific task with limited data, like mine, it
    would be beneficial to first fine-tune the model unsupervised on a
    large corpus of Russian texts. Additionally, incorporating common
    conversation partners’ names as separate tokens might enhance the
    quality.</p>
    <p>I wouldn’t say it has turned out to be significantly better than
    LoRA. It might be more effective to focus solely on a single person
    and calculate the loss based only on my responses (or someone
    else’s), instead of trying to learn about each and every
    conversational partner.</p>
    <h2 id="closing-thoughts"><a href="#closing-thoughts">Closing
    thoughts</a></h2>
    <p>Certainly, I had to cherry-pick the results, not because most of
    the model’s replies were inadequate, but because many were simple
    responses like “I’ll call you later,” “busy,” and “ok,” which are
    naturally frequent in conversations. Despite this, it’s clear that
    the model excels in mimicking the style of the person it’s
    impersonating. It also captures the commonly discussed topics
    between two people. However, it significantly lacks context in
    conversations. Responding to queries like “yo, so?” or “what are
    your plans for the weekend” is challenging without having full
    context. Perhaps utilizing a system like <a href="https://www.rewind.ai/" target="_blank">Rewind</a>, which
    captures everything the user does across the computer, could be
    beneficial.</p>
    <h2 id="code"><a href="#code">Code</a></h2>
    <p>You can find code for this project as well as instructions on how
    to replicate it yourself on your own Telegram dump in <a href="https://github.com/furiousteabag/doppelganger" target="_blank">my github repo</a>. Training logs may be accessed on
    <a href="https://wandb.ai/furiousteabag/doppelganger" target="_blank">WandB</a>.</p>
    
    <hr>
    <a href="https://asmirnov.xyz/">home</a>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Several piracy-related arrests spark fears of high-level crackdown (154 pts)]]></title>
            <link>https://torrentfreak.com/several-piracy-related-arrests-spark-fears-of-high-level-crackdown-231127/</link>
            <guid>38434713</guid>
            <pubDate>Mon, 27 Nov 2023 16:56:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/several-piracy-related-arrests-spark-fears-of-high-level-crackdown-231127/">https://torrentfreak.com/several-piracy-related-arrests-spark-fears-of-high-level-crackdown-231127/</a>, See on <a href="https://news.ycombinator.com/item?id=38434713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://torrentfreak.com/images/denmark-target-s.png"><img decoding="async" src="https://torrentfreak.com/images/denmark-target-s.png" alt="denmark-target-s" width="290" height="169" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20290%20169'%3E%3C/svg%3E" data-lazy-src="https://torrentfreak.com/images/denmark-target-s.png"></a>Over the past few years, increased enforcement by players in both the private and public sectors has made Denmark one of the riskiest places in Europe for pirate site operators and prolific file-sharers.</p>
<p>Relentless pushback from local anti-piracy group Rights Alliance and its partnership with Denmark’s Special Crime Unit (National enhed for Særlig Kriminalitet (NSK)) has led to many site closures, arrests, and subsequent prosecutions. </p>
<p>The most recent reported conviction saw a 37-year-old man receive a <a href="https://torrentfreak.com/prolific-bittorrent-pirate-receives-suspended-prison-sentence-in-denmark-230918/">60-day suspended prison sentence</a> in September for pirating more than a thousand works through local BitTorrent trackers. </p>
<p>In connection with this and other successes over the past few years, last month Rights Alliance revealed that Thomas Heldrup, the anti-piracy group’s Head of Content Protection &amp; Enforcement, had been running an <a href="https://torrentfreak.com/how-an-undercover-lawyer-helped-to-topple-denmarks-torrent-tracker-scene-231012/">undercover operation</a> in piracy circles since 2016. </p>
<h2>Fears of Infiltration</h2>
<p>Concerns that a site might have a spy on board certainly aren’t unusual; for many site operators, however, it’s the kind of thing that <em>only ever happens to someone else</em>, usually those perceived to be less careful than them. In some cases that might be true but<br>
Denmark’s distinguishing features as a country may introduce complications.</p>
<p>A relatively small population and a language rarely spoken outside Denmark’s borders, presents an increased chance of local piracy communities overlapping. Combine that with a shared reliance on locally attractive content and one site’s security issues risk becoming a much broader problem, as the last couple of years appear to show. </p>
<p>Until recently, however, there were few signs to suggest those at the top of the so-called ‘<a href="https://torrentfreak.com/bittorrent-releasers-slice-the-top-off-movie-piracy-pyramid-100727/">Piracy Pyramid</a>‘ may also have become targets in Denmark. Nevertheless, some of those with connections to Scene entities are starting to ask questions.</p>
<h2>47-Year-Old Arrested in Denmark</h2>
<p>In a statement last week, Denmark’s National Unit for Special Crime (NSK) announced that as part of a long-running investigation, a man was arrested on November 22 and then charged with copyright infringement offenses. </p>
<p>NSK said its officers searched the home of a 47-year-old man in South Zealand (Sydsjælland) and seized IT equipment in connection with illegal file-sharing and “copyright infringement of a particularly serious nature.”</p>
<p>“The case is about an organized network that has illegally shared extremely large quantities of films and TV series via file sharing services,” said NSK Police Commissioner Anders-Emil Nøhr Kelbæk.</p>
<p>While noting that NSK had no further information to offer at this time, Kelbæk said he was pleased that NSK had arrested another suspect believed to have played a ‘significant role’ in the unnamed network.</p>
<h2>At Least Five Arrests Thus Far</h2>
<p>Last week’s arrest was only the latest in a series of arrests carried out as part of the same long-running NSK investigation into the illegal distribution of movies and TV shows.</p>
<p>In late August, NSK arrested four people on suspicion of sharing “extremely large quantities” of movies and TV shows. NSK raided addresses in South-West Jutland, North Zealand and Bornholmand. A 43-year old was arrested at the last location, but it’s claimed he lives elsewhere. In common with last week’s arrest, all were charged on suspicion of “particularly serious” copyright infringement offenses.</p>
<p>In an almost identical statement to that issued last week, Commissioner Anders-Emil Nøhr Kelbæk said the case was about “an organized network that shares extremely large amounts of data, presumably in the form of films and series.”</p>
<h2>Does Available Information Really Indicate a ‘Scene’ Bust?</h2>
<p>TorrentFreak sources report concerns that last week’s arrest may be linked to Scene groups. Terminology used by NSK doesn’t instantly rule that out and does seem to suggest something potentially more significant than other arrests over the past few years.</p>
<p>According to NSK, the August arrests took place on August 28, 2023. Using information in Scene release databases we looked for Danish Scene groups and/or groups that were releasing Denmark-focused content before that date but then made no releases afterward; while that wouldn’t provide conclusive proof that a group had been targeted, the method has proven useful in the past. Findings as follows:</p>
<p><small>⦿ Nordic blu-ray release group (including Danish) paused Aug 13, restarted Oct 16. Nothing since<br>
⦿ TV show release group paused Aug 28 to Sep 1 but continued as normal<br>
⦿ At least one TV show group made dozens of releases on Aug 28 suggesting little ‘panic’ on that date</small></p>
<p>While activity late August suggests nothing especially out of the ordinary, activity since the arrest last week stands in contrast.</p>
<p>Notable Danish content release group inactivity since November 22 arrest as follows:</p>
<p><small>⦿ ‘HYGGE’ | TV shows | 550+ releases since March 23 | <a href="https://predb.net/rls/Stjerner.I.Troejen.S03E07.DANiSH.1080p.WEB.h264-HYGGE">Last release Nov 23, 2023 07:43:39</a><br>
⦿ ‘HiVE’ | TV shows | 650+ releases since March 23 | <a href="https://predb.net/rls/Nybyggerne.S09E10.Det.Sidste.Rum.DANiSH.720p.WEB.h264-HiVE">Last release Nov 23, 2023 05:03:52</a><br>
⦿ ‘DKiDS’ | TV shows | 3000+ release since March 23 | <a href="https://predb.net/rls/Mabinooz.S02E01.Indbrud.DANiSH.1080p.WEB.H264-DKiDS">Last release Nov 21, 2023 10:34:50</a><br>
⦿ ‘DANES’ | TV shows | 640+ releases since May 23 | <a href="https://predb.net/rls/Horisont.2023.11.22.Dagbog.Fra.Gaza.DANiSH.720p.WEB.h264-DANES">Last release Nov 22, 2023 08:13:21</a><br>
⦿ ‘JYSK’ | TV shows | 520+ releases since March 23 | <a href="https://predb.net/rls/Kontant.2023.11.23.S2023E15.Stivnede.Smil.DANiSH.720p.WEB.h264-JYSK">Last release Nov 23, 2023 08:20:39</a> </small></p>
<p>TF is informed that some groups may have gone dark simply out of an abundance of caution. That may or may not include all or none of the above. It’s also possible that the groups have nothing to release. Furthermore, there are many other global groups with no obvious links to Danish content or Denmark that also stopped releasing on November 21. The reasons for this are unknown but holidays in the United States may play a role.</p>
<p>In an information vacuum, rumors are extremely common but if the authorities and/or Rights Alliance used intelligence obtained in other operations to infiltrate Scene groups or their affiliates, it wouldn’t be a surprise. It wouldn’t be surprise to hear that any group downtime was directly linked to turkey and/or alcohol consumption either but in any event, the next couple of weeks should prove informative.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prettier $20k Bounty was Claimed (677 pts)]]></title>
            <link>https://prettier.io/blog/2023/11/27/20k-bounty-was-claimed</link>
            <guid>38434613</guid>
            <pubDate>Mon, 27 Nov 2023 16:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prettier.io/blog/2023/11/27/20k-bounty-was-claimed">https://prettier.io/blog/2023/11/27/20k-bounty-was-claimed</a>, See on <a href="https://news.ycombinator.com/item?id=38434613">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><p>Prettier, a JavaScript code formatter, has seen an incredible adoption thanks to its careful handling of the very, very, long tail of ways people can write code. At this point, the formatting logic has been solid and after our work on <a href="https://prettier.io/blog/2023/11/13/curious-ternaries">ternaries</a> lands, it will be in a happy state.</p>
<p>This means that we can now focus on the next important aspect: Performance. Prettier has never been fast per se, but fast enough for most use cases. This has always felt unsatisfying so we wanted to do something about it. What better way than a friendly competition.</p>
<p>On November 9th, we put up a <a href="https://twitter.com/Vjeux/status/1722733472522142022">$10k bounty</a> for any project written in Rust that would pass 95% of Prettier test suite. Guillermo Rauch, CEO of Vercel, matched it to bring it to $20k and <a href="https://napi.rs/">napi.rs</a> added another $2.5k. The folks at Algora even made an amazing landing page for it.</p>
<p><a href="https://console.algora.io/challenges/prettier"><img src="https://console.algora.io/prettier/og.png" alt=""></a></p>
<h2>Winner Winner Chicken Dinner</h2>
<p><strong>I'm so excited to report that the <a href="https://biomejs.dev/">Biome project</a> claimed the bounty!</strong> It has been so epic to see a dozen people come together to improve compatibility in only a short 3 weeks. You can read their <a href="https://biomejs.dev/blog/biome-wins-prettier-challenge">full report</a> for the details.</p>
<p>One question you are probably wondering is why would the Prettier team fund another project!? In practice, Prettier has been the dominant code formatter for JavaScript and as a result of a lack of competition, there has been little incentive to push on performance and fix various edge cases.</p>
<p>There is now a Prettier-compatible and way faster implementation in Biome that people can switch to. So Prettier has to step up its game! Thankfully Fabio Spampinato got nerd sniped with the challenge and found many extreme inefficiencies in Prettier's CLI by doing proper profiling. He will fix them by the end of the year.</p>
<p>By matching all the tests, the Biome project also found a lot of <a href="https://github.com/biomejs/biome/issues/739">bugs and questionable decisions</a> in Prettier that we will be able to improve upon.</p>
<h2>Money, Money, Money</h2>
<p>I want to start by acknowledging that this bounty and the continued success of Prettier have been possible thanks to various people making significant donations. Companies: Indeed ($20,000), Frontend Masters ($10,850), Sentry ($10,529), Salesforce ($10,025), Airbnb ($8,426), Cybozu ($6,086). Individuals: Shintaro Kaneko ($1,635), Suhail Doshi ($1,000), icchiman ($500), Mariusz Nowak ($270), Benoît Burgener ($270), Jeremy Combs ($270), f_subal ($230).</p>
<p>You may not be aware but thanks to all those donations, we've been able to <a href="https://prettier.io/blog/2022/01/06/prettier-begins-paying-maintainers">pay two people $1.5k/month</a> for the past two years to keep shipping. Fisker Cheung and Sosuke Suzuki have done an incredible job!</p>
<p>With the current budget, we only have 8 months of runway left, so this is a good time to solicit your donations.</p>
<p><strong>Consider donating if you or your company are using Prettier and it has been helpful to you: <a href="https://opencollective.com/prettier">https://opencollective.com/prettier</a></strong></p>
<p>I would also like to give a big shout-out to <a href="https://opencollective.com/prettier">Open Collective</a>. It has been incredible for the project. From a maintainer perspective, it has been amazing as you can sign up without giving any personal information and it acts as a bank. It lets people give and receive money all around the world and handles all the tax documents properly which is a huge deal.</p>
<p>Prettier raised a total of $110k and redistributed $75k.</p>
<h2>Conclusion</h2>
<p>While this was a one time bounty, the goal is to give an energy boost to the space of code formatting so that as an ecosystem we can make the best developer experience possible! It's been heartwarming to see so many people coming together and we hope they'll only achieve bigger things from now.</p>
</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Trains.fyi – a live map of passenger trains in the US and Canada (427 pts)]]></title>
            <link>https://trains.fyi/</link>
            <guid>38434574</guid>
            <pubDate>Mon, 27 Nov 2023 16:47:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trains.fyi/">https://trains.fyi/</a>, See on <a href="https://news.ycombinator.com/item?id=38434574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        <!-- Mobile Navbar -->
        <nav>
            <a href="https://trains.fyi/">trains.fyi 🚂</a>
            
        </nav>

        <!-- Collapsible Sidebar for Mobile -->
        <div id="mobileSidebar">
            <hr>
            <div>
                    
                    <p>A live, real-time map of passenger train locations in North America 🇨🇦🇺🇸</p>
                </div>

            <hr>

            <div>
                    <h2>About The Project</h2>
                    <div><p>This project amalgamates data from train GPS tracking and displays all trains on one map.
                        </p><p>Data is updated every minute, and the map updates automatically. This project
                        was created by <a href="https://twitter.com/@rydercalmdown" target="_blank">@rydercalmdown</a>.
                    </p></div>

                    
                </div>

            <div>
                    <h2>Supported Trains</h2>
                    <p>Currently the map supports the following trains.</p>

                    
                    
                    
                    
                    <div>
                        
                        <p>Long Island Railroad - New York</p>
                    </div>
                    <div>
                        
                        <p>Metro North Railroad - New York</p>
                    </div>
                    <div>
                        
                        <p>Massachusetts Bay Transportation Authority - Boston</p>
                    </div>
                    <div>
                        
                        <p>Caltrain - San Francisco Bay Area</p>
                    </div>
                    
                    

                </div>
        </div>

        <div>
            <nav>
                <div>
                    <div>
                            <h2>trains.fyi 🚂</h2>
                            <p>A live, real-time map of passenger train locations in North America. 🇨🇦🇺🇸</p>
                        </div>

                    <hr>

                    <div>
                            <h2>About The Project</h2>
                            <div><p>This project amalgamates data from train GPS tracking and displays all trains on one map.
                                </p><p>Data is updated every minute, and the map updates automatically. This project
                                was created by <a href="https://twitter.com/@rydercalmdown" target="_blank">@rydercalmdown</a>.</p></div>


                            
                        </div>

                    <div>
                            <h2>Supported Trains</h2>
                            <p>Currently the map supports the following trains.</p>

                            
                            
                            
                            
                            <div>
                                
                                <p>Long Island Railroad - New York</p>
                            </div>
                            <div>
                                
                                <p>Metro North Railroad - New York</p>
                            </div>
                            <div>
                                
                                <p>Massachusetts Bay Transportation Authority - Boston</p>
                            </div>
                            <div>
                                
                                <p>Caltrain - San Francisco Bay Area</p>
                            </div>
                            
                            

                        </div>
                </div>
            </nav>

            <main role="main">
                
            </main>
        </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Components Eliminate JavaScript Framework Lock-In (244 pts)]]></title>
            <link>https://jakelazaroff.com/words/web-components-eliminate-javascript-framework-lock-in/</link>
            <guid>38434470</guid>
            <pubDate>Mon, 27 Nov 2023 16:41:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakelazaroff.com/words/web-components-eliminate-javascript-framework-lock-in/">https://jakelazaroff.com/words/web-components-eliminate-javascript-framework-lock-in/</a>, See on <a href="https://news.ycombinator.com/item?id=38434470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-content="" data-astro-cid-rnrqlda2=""> 
<p>We’ve seen a lot of great posts about web components lately.
Many have focused on the burgeoning <a href="https://adactio.com/journal/20618" data-astro-cid-bi7aps5f="">HTML web components</a><a data-tooltip="" href="https://adactio.com/journal/20618" data-astro-cid-bi7aps5f=""> <img src="https://adactio.com/images/photo-300.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">HTML web components</span> <span data-astro-cid-bi7aps5f="">Don’t replace. Augment.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://adactio.com/icon.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">adactio.com/journal/20618</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> pattern, which eschews shadow DOM in favor of progressively enhancing existing markup.
There’s also been discussion — including <a href="https://jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/" data-astro-cid-bi7aps5f="">this post by yours truly</a><a data-tooltip="" href="https://jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/" data-astro-cid-bi7aps5f=""> <img src="https://jakelazaroff.com/og/web-components-will-outlive-your-javascript-framework.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Web Components Will Outlive Your JavaScript Framework | jakelazaroff.com</span> <span data-astro-cid-bi7aps5f="">If we're building things that we want to work in five or ten or even 20 years, we need to avoid dependencies and use the web with no layers in between.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://jakelazaroff.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> — about fully replacing JavaScript frameworks with web components.</p>
<p>Those aren’t the only options, though.
You can also use web components <em>in tandem</em> with JavaScript frameworks.
To that end, I want to talk about a key benefit that I haven’t seen mentioned as much: <strong>web components can dramatically loosen the coupling of JavaScript frameworks</strong>.</p>
<p>To prove it, we’re going to do something kinda crazy: build an app where <em>every single component</em> is written with a different framework.</p>
<p>It probably goes without saying that you should not build a real app like this!
But there <em>are</em> valid reasons for mixing frameworks.
Maybe you’re gradually migrating from React to Vue.
Maybe your app is built with Solid, but you want to use a third-party library that only exists as an Angular component.
Maybe you want to use Svelte for a few “islands of interactivity” in an otherwise static website.</p>
<p>Here’s what we’re going to create: a simple little todo app based loosely on <a href="https://todomvc.com/" data-astro-cid-bi7aps5f="">TodoMVC</a><a data-tooltip="" href="https://todomvc.com/" data-astro-cid-bi7aps5f=""> <img src="https://raw.github.com/tastejs/todomvc/gh-pages/site-assets/screenshot.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">TodoMVC</span> <span data-astro-cid-bi7aps5f="">Helping you select an MV* framework - Todo apps for Backbone.js, Ember.js, AngularJS, Spine and many more</span> <span data-astro-cid-bi7aps5f=""> <img src="https://todomvc.com/site-assets/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">todomvc.com</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</p>
<todo-demo show-layout="true" show-input="true" show-todos="true" show-filters="true"></todo-demo>

<p>As we build it, we’ll see how web components can <em>encapsulate</em> JavaScript frameworks, allowing us to use them without imposing broader constraints on the rest of the application.</p>
<h3 id="whats-a-web-component">What’s a Web Component?</h3>
<p>In case you’re not familiar with web components, here’s a brief primer on how they work.</p>
<p>First, we declare a subclass of <code>HTMLElement</code> in JavaScript. Let’s call it <code>MyComponent</code>:</p>
<pre><code><span>class</span> <span>MyComponent</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>)</span><span>;</span>
    <span>this</span><span>.</span>shadow <span>=</span> <span>this</span><span>.</span><span>attachShadow</span><span>(</span><span>{</span> <span>mode</span><span>:</span> <span>"open"</span> <span>}</span><span>)</span><span>;</span>
  <span>}</span>

  <span>connectedCallback</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>shadow<span>.</span>innerHTML <span>=</span> <span><span>`</span><span>
      &lt;p&gt;Hello from a web component!&lt;/p&gt;
      &lt;style&gt;
        p {
          color: pink;
          font-weight: bold;
          padding: 1rem;
          border: 4px solid pink;
        }
      &lt;/style&gt;
    </span><span>`</span></span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>That call to <code>attachShadow</code> in the constructor makes our component use the <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM" data-astro-cid-bi7aps5f="">shadow DOM</a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM" data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Using shadow DOM - Web APIs | MDN</span> <span data-astro-cid-bi7aps5f="">An important aspect of custom elements is encapsulation, because a custom element, by definition, is a piece of reusable functionality: it might be dropped into any web page and be expected to work. So it's important that code running in the page should not be able to accidentally break a custom element by modifying its internal implementation. Shadow DOM enables you to attach a DOM tree to an element, and have the internals of this tree hidden from JavaScript and CSS running in the page.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>, which encapsulates the markup and styles inside our component from the rest of the page.
<code>connectedCallback</code> is called when the web component is actually connected to the DOM tree, rendering the HTML contents into the component’s “shadow root”.</p>
<p>This foreshadows how we’ll make our frameworks work with web components.<sup><a href="#user-content-fn-rimshot" id="user-content-fnref-rimshot" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">1</a></sup>
We normally “attach” frameworks to a DOM element, and let the framework take over <em>all</em> ancestors of that element.
With web components, we can attach the framework to the shadow root, which ensures that it can only access the component’s “shadow tree”.</p>
<p>Next, we define a custom element name for our <code>MyComponent</code> class:</p>
<pre><code>customElements<span>.</span><span>define</span><span>(</span><span>"my-component"</span><span>,</span> MyComponent<span>)</span><span>;</span></code></pre>
<p>Whenever a tag with that custom element name appears on the page, the corresponding DOM node is actually an instance of <code>MyComponent</code>!</p>
<pre><code><span><span><span>&lt;</span>my-component</span><span>&gt;</span></span><span><span><span>&lt;/</span>my-component</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> myComponent <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>"my-component"</span><span>)</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>myComponent <span>instanceof</span> <span>MyComponent</span><span>)</span><span>;</span> <span>// true</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre>
<p>Check it out:</p>
<my-component></my-component>

<p>There’s more to web components, but that’s enough to get you through the rest of the article.</p>
<h3 id="scaffolding-layout">Scaffolding Layout</h3>
<p>The entrypoint of our app will be a React component.<sup><a href="#user-content-fn-preact" id="user-content-fnref-preact" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">2</a></sup> Here’s our humble start:</p>
<pre><code><span>// TodoApp.jsx</span>
<span>export</span> <span>default</span> <span>function</span> <span>TodoApp</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span><span><span>&lt;</span></span><span>&gt;</span></span><span><span><span>&lt;/</span></span><span>&gt;</span></span><span>;</span>
<span>}</span></code></pre>
<p>We could start adding elements here to block out the basic DOM structure, but I want to write another component for that to show how we can nest web components in the same way we nest framework components.</p>
<p>Most frameworks support composition via nesting like normal HTML elements.
From the outside, it usually looks something like this:</p>
<pre><code><span><span><span>&lt;</span><span>Card</span></span><span>&gt;</span></span><span>
  </span><span><span><span>&lt;</span><span>Avatar</span></span> <span>/&gt;</span></span><span>
</span><span><span><span>&lt;/</span><span>Card</span></span><span>&gt;</span></span></code></pre>
<p>On the inside, there are a few ways that frameworks handle this.
For example, React and Solid give you access to those children as a special <code>children</code> prop:</p>
<pre><code><span>function</span> <span>Card</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>return</span> <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>card<span>"</span></span><span>&gt;</span></span><span>{</span>props<span>.</span>children<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span>
<span>}</span></code></pre>
<p>With web components that use shadow DOM, we can do the same thing using the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/slot" data-astro-cid-bi7aps5f=""><code>&lt;slot&gt;</code> element</a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/slot" data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">&lt;slot&gt;: The Web Component Slot element - HTML: HyperText Markup Language | MDN</span> <span data-astro-cid-bi7aps5f="">The &lt;slot&gt; HTML element—part of the Web Components technology suite—is a placeholder inside a web component that you can fill with your own markup, which lets you create separate DOM trees and present them together.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/HTML/Element/slot</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>. When the browser encounters a <code>&lt;slot&gt;</code>, it replaces it with the children of the web component.</p>
<p><code>&lt;slot&gt;</code> is actually more powerful than React or Solid’s <code>children</code>.
If we give each slot a <code>name</code> attribute, a web component can have multiple <code>&lt;slot&gt;</code>s, and we can determine where each nested element goes by giving it a <code>slot</code> attribute matching the <code>&lt;slot&gt;</code>’s <code>name</code>.</p>
<p>Let’s see what this looks like in practice.
We’ll write our layout component using <a href="https://www.solidjs.com/" data-astro-cid-bi7aps5f="">Solid</a><a data-tooltip="" href="https://www.solidjs.com/" data-astro-cid-bi7aps5f=""> <img src="https://www.solidjs.com/og.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">SolidJS</span> <span data-astro-cid-bi7aps5f="">Solid is a purely reactive library. It was designed from the ground up with a reactive core. It's influenced by reactive principles developed by previous libraries.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://www.solidjs.com/img/favicons/favicon-32x32.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">www.solidjs.com</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>:</p>
<pre><code><span>// TodoLayout.jsx</span>
<span>import</span> <span>{</span> render <span>}</span> <span>from</span> <span>"solid-js/web"</span><span>;</span>

<span>function</span> <span>TodoLayout</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>wrapper<span>"</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>header</span> <span>class</span><span><span>=</span><span>"</span>header<span>"</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>title<span>"</span></span> <span>/&gt;</span></span><span>
        </span><span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>filters<span>"</span></span> <span>/&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>header</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>todos<span>"</span></span> <span>/&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>footer</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>input<span>"</span></span> <span>/&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>footer</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span>

customElements<span>.</span><span>define</span><span>(</span>
  <span>"todo-layout"</span><span>,</span>
  <span>class</span> <span>extends</span> HTMLElement <span>{</span>
    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
      <span>super</span><span>(</span><span>)</span><span>;</span>
      <span>this</span><span>.</span>shadow <span>=</span> <span>this</span><span>.</span><span>attachShadow</span><span>(</span><span>{</span> <span>mode</span><span>:</span> <span>"open"</span> <span>}</span><span>)</span><span>;</span>
    <span>}</span>

    <span>connectedCallback</span><span>(</span><span>)</span> <span>{</span>
      <span>render</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span><span><span>&lt;</span><span>TodoLayout</span></span> <span>/&gt;</span></span><span>,</span> <span>this</span><span>.</span>shadow<span>)</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>)</span><span>;</span></code></pre>
<p>There are two parts to our Solid web component: the web component wrapper at the top, and the actual Solid component at the bottom.</p>
<p>The most important thing to notice about the Solid component is that we’re using named <code>&lt;slot&gt;</code>s instead of the <code>children</code> prop.
Whereas <code>children</code> is handled by Solid and would only let us nest other Solid components, <code>&lt;slot&gt;</code>s are handled by the browser itself and will let us nest <em>any</em> HTML element — including web components written with other frameworks!</p>
<p>The web component wrapper is pretty similar to <a href="#whats-a-web-component" data-astro-cid-bi7aps5f="">the example above</a>.
It creates a shadow root in the constructor, and then renders the Solid component into it in the <code>connectedCallback</code> method.</p>
<p>Note that this is not a complete implementation of the web component wrapper!
At the very least, we’d probably want to define an <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Components/Using_custom_elements#responding_to_attribute_changes" data-astro-cid-bi7aps5f=""><code>attributeChangedCallback</code> method</a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Components/Using_custom_elements#responding_to_attribute_changes" data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Using custom elements - Web APIs | MDN</span> <span data-astro-cid-bi7aps5f="">One of the key features of web components is the ability to create custom elements: that is, HTML elements whose behavior is defined by the web developer, that extend the set of elements available in the browser.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png#responding_to_attribute_changes" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/API/Web_Components/Using_custom_elements#responding_to_attribute_changes</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> so we can re-render the Solid component when the attributes change.
If you’re using this in production, you should probably use a package Solid provides called <a href="https://www.npmjs.com/package/solid-element" data-astro-cid-bi7aps5f="">Solid Element</a><a data-tooltip="" href="https://www.npmjs.com/package/solid-element" data-astro-cid-bi7aps5f=""> <img src="https://static-production.npmjs.com/338e4905a2684ca96e08c7780fc68412.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">solid-element</span> <span data-astro-cid-bi7aps5f="">Webcomponents wrapper for Solid. Latest version: 1.8.0, last published: a month ago. Start using solid-element in your project by running `npm i solid-element`. There are 59 other projects in the npm registry using solid-element.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://static-production.npmjs.com/b0f1a8318363185cc2ea6a40ac23eeb2.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">www.npmjs.com/package/solid-element</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> that handles all this for you.</p>
<p>Back in our React app, we can now use our <code>TodoLayout</code> component:</p>
<pre><code><span>// TodoApp.jsx</span>
<span>export</span> <span>default</span> <span>function</span> <span>TodoApp</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>todo-layout</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>h1</span> <span>slot</span><span><span>=</span><span>"</span>title<span>"</span></span><span>&gt;</span></span><span>Todos</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>todo-layout</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Note that we don’t need to import anything from <code>TodoLayout.jsx</code> — we just use the custom element tag that we defined.</p>
<p>Check it out:</p>
<todo-demo show-layout="true"></todo-demo>

<p>That’s a React component rendering a Solid component, which takes a nested React element as a child.</p>
<h3 id="adding-todos">Adding Todos</h3>
<p>For the todo input, we’ll peel the onion back a bit further and write it with no framework at all!</p>
<pre><code><span>// TodoInput.js</span>
customElements<span>.</span><span>define</span><span>(</span><span>"todo-input"</span><span>,</span> TodoInput<span>)</span><span>;</span>

<span>class</span> <span>TodoInput</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>)</span><span>;</span>
    <span>this</span><span>.</span>shadow <span>=</span> <span>this</span><span>.</span><span>attachShadow</span><span>(</span><span>{</span> <span>mode</span><span>:</span> <span>"open"</span> <span>}</span><span>)</span><span>;</span>
  <span>}</span>

  <span>connectedCallback</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>shadow<span>.</span>innerHTML <span>=</span> <span><span>`</span><span>
      &lt;form&gt;
        &lt;input name="text" type="text" placeholder="What needs to be done?" /&gt;
      &lt;/form&gt;
    </span><span>`</span></span><span>;</span>

    <span>this</span><span>.</span>shadow<span>.</span><span>querySelector</span><span>(</span><span>"form"</span><span>)</span><span>.</span><span>addEventListener</span><span>(</span><span>"submit"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>{</span>
      evt<span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span>
      <span>const</span> data <span>=</span> <span>new</span> <span>FormData</span><span>(</span>evt<span>.</span>target<span>)</span><span>;</span>

      <span>this</span><span>.</span><span>dispatchEvent</span><span>(</span><span>new</span> <span>CustomEvent</span><span>(</span><span>"add"</span><span>,</span> <span>{</span> <span>detail</span><span>:</span> data<span>.</span><span>get</span><span>(</span><span>"text"</span><span>)</span> <span>}</span><span>)</span><span>)</span><span>;</span>
      evt<span>.</span>target<span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Between this, the example web component and our Solid layout, you’re probably noticing a pattern: attach a shadow root and then render some HTML inside it.
Whether we hand-write the HTML or use a framework to generate it, the process is roughly the same.</p>
<p>Here, we’re using a <a href="https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent" data-astro-cid-bi7aps5f="">custom event</a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent" data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">CustomEvent - Web APIs | MDN</span> <span data-astro-cid-bi7aps5f="">The CustomEvent interface represents events initialized by an application for any purpose.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/API/CustomEvent</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> to communicate with the parent component.
When the form is submitted, we dispatch an <code>add</code> event with the input text.</p>
<p>Event queues are often used to <a href="https://gameprogrammingpatterns.com/event-queue.html" data-astro-cid-bi7aps5f="">decouple communication</a><a data-tooltip="" href="https://gameprogrammingpatterns.com/event-queue.html" data-astro-cid-bi7aps5f="">  <span data-astro-cid-bi7aps5f="">Event Queue · Decoupling Patterns · Game Programming Patterns</span>  <span data-astro-cid-bi7aps5f=""> <img src="https://gameprogrammingpatterns.com/favicon-32x32.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">gameprogrammingpatterns.com/event-queue.html</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> between components of a software system.
Browsers lean heavily on events, and custom events in particular are an important tool in the web components toolbox — especially so because the custom element acts as a natural event bus that can be accessed from outside the web component.</p>
<p>Before we can continue adding components, we need to figure out how to handle our state.
For now, we’ll just keep it in our React <code>TodoApp</code> component.
Although we’ll eventually outgrow <code>useState</code>, it’s a perfect place to start.</p>
<p>Each todo will have three properties: an <code>id</code>, a <code>text</code> string describing it, and a <code>done</code> boolean indicating whether it’s been completed.</p>
<pre><code><span>// TodoApp.jsx</span>
<span>import</span> <span>{</span> useCallback<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span><span>;</span>

<span>let</span> id <span>=</span> <span>0</span><span>;</span>
<span>export</span> <span>default</span> <span>function</span> <span>TodoApp</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>todos<span>,</span> setTodos<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span>

  <span>export</span> <span>function</span> <span>addTodo</span><span>(</span><span>text</span><span>)</span> <span>{</span>
    <span>setTodos</span><span>(</span><span>todos</span> <span>=&gt;</span> <span>[</span><span>...</span>todos<span>,</span> <span>{</span> <span>id</span><span>:</span> id<span>++</span><span>,</span> text<span>,</span> <span>done</span><span>:</span> <span>false</span> <span>}</span><span>]</span><span>)</span><span>;</span>
  <span>}</span>

  <span>const</span> inputRef <span>=</span> <span>useCallback</span><span>(</span><span>ref</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>ref<span>)</span> <span>return</span><span>;</span>
    ref<span>.</span><span>addEventListener</span><span>(</span><span>"add"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>addTodo</span><span>(</span>evt<span>.</span>detail<span>)</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>todo-layout</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>h1</span> <span>slot</span><span><span>=</span><span>"</span>title<span>"</span></span><span>&gt;</span></span><span>Todos</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>todo-input</span> <span>slot</span><span><span>=</span><span>"</span>input<span>"</span></span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>todo-input</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>todo-layout</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We’ll keep an array of our todos in React state.
When we add a todo, we’ll add it to the array.</p>
<p>The one awkward part of this is that <code>inputRef</code> function.
Our <code>&lt;todo-input&gt;</code> emits a custom <code>add</code> event when the form is submitted.
Usually with React, we’d attach event listeners using props like <code>onClick</code> — but that only works for events that React already knows about.
We need to listen for <code>add</code> events directly.<sup><a href="#user-content-fn-ondirective" id="user-content-fnref-ondirective" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">3</a></sup></p>
<p>In React Land, we use <a href="https://react.dev/learn/manipulating-the-dom-with-refs" data-astro-cid-bi7aps5f="">refs</a><a data-tooltip="" href="https://react.dev/learn/manipulating-the-dom-with-refs" data-astro-cid-bi7aps5f=""> <img src="https://react.dev/images/og-learn.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Manipulating the DOM with Refs – React</span> <span data-astro-cid-bi7aps5f="">The library for web and native user interfaces</span> <span data-astro-cid-bi7aps5f=""> <img src="https://react.dev/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">react.dev/learn/manipulating-the-dom-with-refs</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> to directly interact with the DOM.
We most commonly use them with the <code>useRef</code> hook, but that’s not the only way!
The <code>ref</code> prop is actually just a function that gets called with a DOM node.
Rather than passing a ref returned from the <code>useRef</code> hook to that prop, we can instead pass a function that attaches the event listener to the DOM node directly.</p>
<p>You might be wondering why we have to wrap the function in <code>useCallback</code>.
The answer lies in the <a href="https://legacy.reactjs.org/docs/refs-and-the-dom.html#caveats-with-callback-refs" data-astro-cid-bi7aps5f="">legacy React docs on refs</a><a data-tooltip="" href="https://legacy.reactjs.org/docs/refs-and-the-dom.html#caveats-with-callback-refs" data-astro-cid-bi7aps5f=""> <img src="https://legacy.reactjs.org/logo-og.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Refs and the DOM – React</span> <span data-astro-cid-bi7aps5f="">A JavaScript library for building user interfaces</span> <span data-astro-cid-bi7aps5f=""> <img src="https://legacy.reactjs.org/favicon.ico#caveats-with-callback-refs" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">legacy.reactjs.org/docs/refs-and-the-dom.html#caveats-with-callback-refs</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> (and, as far as I can tell, has not been brought over to the new docs):</p>
<blockquote>
<p>If the <code>ref</code> callback is defined as an inline function, it will get called twice during updates, first with <code>null</code> and then again with the DOM element. This is because a new instance of the function is created with each render, so React needs to clear the old ref and set up the new one. You can avoid this by defining the <code>ref</code> callback as a bound method on the class, but note that it shouldn’t matter in most cases.</p>
</blockquote>
<p>In this case, it <em>does</em> matter, since we don’t want to attach the event listener again on every render.
So we wrap it in <code>useCallback</code> to ensure that we pass the same instance of the function every time.</p>
<todo-demo show-layout="true" show-input="true"></todo-demo>

<h3 id="todo-items">Todo Items</h3>
<p>So far, we can add todos, but not see them.
The next step is writing a component to show each todo item.
We’ll write that component with <a href="https://svelte.dev/" data-astro-cid-bi7aps5f="">Svelte</a><a data-tooltip="" href="https://svelte.dev/" data-astro-cid-bi7aps5f=""> <img src="https://svelte.dev/images/twitter-thumbnail.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Svelte • Cybernetically enhanced web apps</span>  <span data-astro-cid-bi7aps5f=""> <img src="https://svelte.dev/favicon.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">svelte.dev</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</p>
<p>Svelte supports custom elements <a href="https://svelte.dev/docs/custom-elements-api" data-astro-cid-bi7aps5f="">out of the box</a><a data-tooltip="" href="https://svelte.dev/docs/custom-elements-api" data-astro-cid-bi7aps5f=""> <img src="https://svelte.dev/images/twitter-thumbnail.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Custom elements API • Docs • Svelte</span>  <span data-astro-cid-bi7aps5f=""> <img src="https://svelte.dev/favicon.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">svelte.dev/docs/custom-elements-api</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.
Rather than continuing to show the same web component wrapper boilerplate every time, we’ll just use that feature!</p>
<p>Here’s the code:</p>
<pre><code><span>&lt;!-- TodoItem.svelte --&gt;</span>
<span><span><span>&lt;</span><span>svelte:</span>options</span> <span>customElement</span><span><span>=</span><span>"</span>todo-item<span>"</span></span> <span>/&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>import</span> <span>{</span> createEventDispatcher <span>}</span> <span>from</span> <span>"svelte"</span><span>;</span>

  <span>export</span> <span>let</span> id<span>;</span>
  <span>export</span> <span>let</span> text<span>;</span>
  <span>export</span> <span>let</span> done<span>;</span>

  <span>const</span> dispatch <span>=</span> <span>createEventDispatcher</span><span>(</span><span>)</span><span>;</span>
  <span>$</span><span>:</span> <span>dispatch</span><span>(</span><span>"check"</span><span>,</span> <span>{</span> id<span>,</span> done <span>}</span><span>)</span><span>;</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>

<span><span><span>&lt;</span>div</span><span>&gt;</span></span>
   <span><span><span>&lt;</span>input</span> <span>id</span><span><span>=</span><span>"</span>todo-{id}<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>checkbox<span>"</span></span> <span><span>bind:</span>checked</span><span><span>=</span>{done}</span> <span>/&gt;</span></span>
  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>todo-{id}<span>"</span></span><span>&gt;</span></span>{text}<span><span><span>&lt;/</span>label</span><span>&gt;</span></span>
  &lt;button aria-label="delete {text}" on:click={() =&gt; dispatch("delete", { id })}&gt;
    <span><span><span>&lt;</span>svg</span> <span>xmlns</span><span><span>=</span><span>"</span>http://www.w3.org/2000/svg<span>"</span></span> <span>width</span><span><span>=</span><span>"</span>12<span>"</span></span> <span>height</span><span><span>=</span><span>"</span>12<span>"</span></span> <span>viewBox</span><span><span>=</span><span>"</span>0 0 12 12<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>path</span>
        <span>d</span><span><span>=</span><span>"</span>M10.707,1.293a1,1,0,0,0-1.414,0L6,4.586,2.707,1.293A1,1,0,0,0,1.293,2.707L4.586,6,1.293,9.293a1,1,0,1,0,1.414,1.414L6,7.414l3.293,3.293a1,1,0,0,0,1.414-1.414L7.414,6l3.293-3.293A1,1,0,0,0,10.707,1.293Z<span>"</span></span>
        <span>fill</span><span><span>=</span><span>"</span>currentColor<span>"</span></span>
      <span>/&gt;</span></span>
    <span><span><span>&lt;/</span>svg</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre>
<p>With Svelte, the <code>&lt;script&gt;</code> tag isn’t literally rendered to the DOM — instead, that code runs when the component is instantiated.
Our Svelte component takes three props: <code>id</code>, <code>text</code> and <code>done</code>.
It also creates a custom event dispatcher, which can dispatch events on the custom element.</p>
<p>The <code>$:</code> syntax declares a reactive block.
It means that whenever the values of <code>id</code> or <code>done</code> change, it will dispatch a <code>check</code> event with the new values.
<code>id</code> probably won’t change, so what this means in practice is that it’ll dispatch a <code>check</code> event whenever we check or uncheck the todo.</p>
<p>Back in our React component, we loop over our todos and use our new <code>&lt;todo-item&gt;</code> component.
We also need a couple more utility functions to remove and check todos, and another ref callback to attach the event listeners to each <code>&lt;todo-item&gt;</code>.</p>
<p>Here’s the code:</p>
<pre><code><span>// TodoApp.jsx</span>
<span>import</span> <span>{</span> useCallback<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span><span>;</span>

<span>let</span> id <span>=</span> <span>0</span><span>;</span>
<span>export</span> <span>default</span> <span>function</span> <span>TodoApp</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>todos<span>,</span> setTodos<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span>

  <span>export</span> <span>function</span> <span>addTodo</span><span>(</span><span>text</span><span>)</span> <span>{</span>
    <span>setTodos</span><span>(</span><span>todos</span> <span>=&gt;</span> <span>[</span><span>...</span>todos<span>,</span> <span>{</span> <span>id</span><span>:</span> id<span>++</span><span>,</span> text<span>,</span> <span>done</span><span>:</span> <span>false</span> <span>}</span><span>]</span><span>)</span><span>;</span>
  <span>}</span>

  <span>export</span> <span>function</span> <span>removeTodo</span><span>(</span><span>id</span><span>)</span> <span>{</span>
    <span>setTodos</span><span>(</span><span>todos</span> <span>=&gt;</span> todos<span>.</span><span>filter</span><span>(</span><span>todo</span> <span>=&gt;</span> todo<span>.</span>id <span>!==</span> id<span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>export</span> <span>function</span> <span>checkTodo</span><span>(</span><span>id<span>,</span> done</span><span>)</span> <span>{</span>
    <span>setTodos</span><span>(</span><span>todos</span> <span>=&gt;</span> todos<span>.</span><span>map</span><span>(</span><span>todo</span> <span>=&gt;</span> <span>(</span>todo<span>.</span>id <span>===</span> id <span>?</span> <span>{</span> <span>...</span>todo<span>,</span> done <span>}</span> <span>:</span> todo<span>)</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>const</span> inputRef <span>=</span> <span>useCallback</span><span>(</span><span>ref</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>ref<span>)</span> <span>return</span><span>;</span>
    ref<span>.</span><span>addEventListener</span><span>(</span><span>"add"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>addTodo</span><span>(</span>evt<span>.</span>detail<span>)</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>const</span> todoRef <span>=</span> <span>useCallback</span><span>(</span><span>ref</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>ref<span>)</span> <span>return</span><span>;</span>
    ref<span>.</span><span>addEventListener</span><span>(</span><span>"check"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>checkTodo</span><span>(</span>evt<span>.</span>detail<span>.</span>id<span>,</span> evt<span>.</span>detail<span>.</span>done<span>)</span><span>)</span><span>;</span>
    ref<span>.</span><span>addEventListener</span><span>(</span><span>"delete"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>removeTodo</span><span>(</span>evt<span>.</span>detail<span>.</span>id<span>)</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>todo-layout</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>h1</span> <span>slot</span><span><span>=</span><span>"</span>title<span>"</span></span><span>&gt;</span></span><span>Todos</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>ul</span><span>&gt;</span></span><span>
        </span><span>{</span>todos<span>.</span><span>map</span><span>(</span><span>todo</span> <span>=&gt;</span> <span>(</span>
          <span><span><span>&lt;</span>li</span> <span>key</span><span><span>=</span><span>{</span>todo<span>.</span>id<span>}</span></span><span>&gt;</span></span><span>
            </span><span><span><span>&lt;</span>todo-item</span> <span>ref</span><span><span>=</span><span>{</span>todoRef<span>}</span></span> <span><span>{</span><span>...</span>todo<span>}</span></span> <span>/&gt;</span></span><span>
          </span><span><span><span>&lt;/</span>li</span><span>&gt;</span></span>
        <span>)</span><span>)</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>ul</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>todo-input</span> <span>slot</span><span><span>=</span><span>"</span>input<span>"</span></span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>todo-input</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>todo-layout</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Now the list actually shows all our todos! And when we add a new todo, it shows up in the list!</p>
<todo-demo show-layout="true" show-input="true" show-todos="true"></todo-demo>

<h3 id="filtering-todos">Filtering Todos</h3>
<p>The last feature to add is the ability to filter todos.</p>
<p>Before we can add that, though, we need to do a bit of refactoring.</p>
<p>I want to show another way that web components can communicate with each other: using a shared store.
Many of the frameworks we’re using have their own store implementations, but we need a store that we can use with <em>all</em> of them.
For that reason, we’ll use a library called <a href="https://github.com/nanostores/nanostores" data-astro-cid-bi7aps5f="">Nano Stores</a><a data-tooltip="" href="https://github.com/nanostores/nanostores" data-astro-cid-bi7aps5f=""> <img src="https://opengraph.githubassets.com/ca56eede252d8d8e13d7d56f8ef7ec53f6103ccdca592e4cbcb2db28de18300a/nanostores/nanostores" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">GitHub - nanostores/nanostores: A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svelte with many atomic tree-shakable stores</span> <span data-astro-cid-bi7aps5f="">A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svelte with many atomic tree-shakable stores - GitHub - nanostores/nanostores: A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svel...</span> <span data-astro-cid-bi7aps5f=""> <img src="https://github.githubassets.com/favicons/favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">github.com/nanostores/nanostores</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</p>
<p>First, we’ll make a new file called <code>store.js</code> with our todo state rewritten using Nano Stores:</p>
<pre><code><span>// store.js</span>
<span>import</span> <span>{</span> atom<span>,</span> computed <span>}</span> <span>from</span> <span>"nanostores"</span><span>;</span>

<span>let</span> id <span>=</span> <span>0</span><span>;</span>
<span>export</span> <span>const</span> $todos <span>=</span> <span>atom</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span>
<span>export</span> <span>const</span> $done <span>=</span> <span>computed</span><span>(</span>$todos<span>,</span> <span>todos</span> <span>=&gt;</span> todos<span>.</span><span>filter</span><span>(</span><span>todo</span> <span>=&gt;</span> todo<span>.</span>done<span>)</span><span>)</span><span>;</span>
<span>export</span> <span>const</span> $left <span>=</span> <span>computed</span><span>(</span>$todos<span>,</span> <span>todos</span> <span>=&gt;</span> todos<span>.</span><span>filter</span><span>(</span><span>todo</span> <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>)</span><span>;</span>

<span>export</span> <span>function</span> <span>addTodo</span><span>(</span><span>text</span><span>)</span> <span>{</span>
  $todos<span>.</span><span>set</span><span>(</span><span>[</span><span>...</span>$todos<span>.</span><span>get</span><span>(</span><span>)</span><span>,</span> <span>{</span> <span>id</span><span>:</span> id<span>++</span><span>,</span> text <span>}</span><span>]</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>function</span> <span>checkTodo</span><span>(</span><span>id<span>,</span> done</span><span>)</span> <span>{</span>
  $todos<span>.</span><span>set</span><span>(</span>$todos<span>.</span><span>get</span><span>(</span><span>)</span><span>.</span><span>map</span><span>(</span><span>todo</span> <span>=&gt;</span> <span>(</span>todo<span>.</span>id <span>===</span> id <span>?</span> <span>{</span> <span>...</span>todo<span>,</span> done <span>}</span> <span>:</span> todo<span>)</span><span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>function</span> <span>removeTodo</span><span>(</span><span>id</span><span>)</span> <span>{</span>
  $todos<span>.</span><span>set</span><span>(</span>$todos<span>.</span><span>get</span><span>(</span><span>)</span><span>.</span><span>filter</span><span>(</span><span>todo</span> <span>=&gt;</span> todo<span>.</span>id <span>!==</span> id<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>const</span> $filter <span>=</span> <span>atom</span><span>(</span><span>"all"</span><span>)</span><span>;</span></code></pre>
<p>The core logic is the same; most of the changes are just porting from the <code>useState</code> API to the Nano Stores API.
We did add two new <a href="https://github.com/nanostores/nanostores#computed-stores" data-astro-cid-bi7aps5f="">computed stores</a><a data-tooltip="" href="https://github.com/nanostores/nanostores#computed-stores" data-astro-cid-bi7aps5f=""> <img src="https://opengraph.githubassets.com/a1d5ab752b126fb874def999f648ce36cc67e8e625235f2c731a0eb940fc256b/nanostores/nanostores" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">GitHub - nanostores/nanostores: A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svelte with many atomic tree-shakable stores</span> <span data-astro-cid-bi7aps5f="">A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svelte with many atomic tree-shakable stores - GitHub - nanostores/nanostores: A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svel...</span> <span data-astro-cid-bi7aps5f=""> <img src="https://github.githubassets.com/favicons/favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">github.com/nanostores/nanostores#computed-stores</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>, <code>$done</code> and <code>$left</code>, which are “derived” from the <code>$todos</code> store and return completed and incomplete todos, respectively.
We also added a new store, <code>$filter</code>, which will hold the current filter value.</p>
<p>We’ll write our filter component with <a href="https://vuejs.org/" data-astro-cid-bi7aps5f="">Vue</a><a data-tooltip="" href="https://vuejs.org/" data-astro-cid-bi7aps5f=""> <img src="https://vuejs.org/images/logo.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Vue.js - The Progressive JavaScript Framework | Vue.js</span> <span data-astro-cid-bi7aps5f="">Vue.js - The Progressive JavaScript Framework</span> <span data-astro-cid-bi7aps5f=""> <img src="https://vuejs.org/logo.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">vuejs.org</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</p>
<pre><code><span>&lt;!-- TodoFilters.ce.vue --&gt;</span>
<span><span><span>&lt;</span>script</span> <span>setup</span><span>&gt;</span></span><span><span>
  <span>import</span> <span>{</span> useStore<span>,</span> useVModel <span>}</span> <span>from</span> <span>"@nanostores/vue"</span><span>;</span>

  <span>import</span> <span>{</span> $todos<span>,</span> $done<span>,</span> $left<span>,</span> $filter <span>}</span> <span>from</span> <span>"./store.js"</span><span>;</span>

  <span>const</span> filter <span>=</span> <span>useVModel</span><span>(</span>$filter<span>)</span><span>;</span>
  <span>const</span> todos <span>=</span> <span>useStore</span><span>(</span>$todos<span>)</span><span>;</span>
  <span>const</span> done <span>=</span> <span>useStore</span><span>(</span>$done<span>)</span><span>;</span>
  <span>const</span> left <span>=</span> <span>useStore</span><span>(</span>$left<span>)</span><span>;</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>

<span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>label</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>radio<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>filter<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>all<span>"</span></span> <span>v-model</span><span><span>=</span><span>"</span>filter<span>"</span></span> <span>/&gt;</span></span>
      <span><span><span>&lt;</span>span</span><span>&gt;</span></span> All ({{ todos.length }})<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>label</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>label</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>radio<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>filter<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>todo<span>"</span></span> <span>v-model</span><span><span>=</span><span>"</span>filter<span>"</span></span> <span>/&gt;</span></span>
      <span><span><span>&lt;</span>span</span><span>&gt;</span></span> Todo ({{ left.length }})<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>label</span><span>&gt;</span></span>

    <span><span><span>&lt;</span>label</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>radio<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>filter<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>done<span>"</span></span> <span>v-model</span><span><span>=</span><span>"</span>filter<span>"</span></span> <span>/&gt;</span></span>
      <span><span><span>&lt;</span>span</span><span>&gt;</span></span> Done ({{ done.length }})<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>label</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span></code></pre>
<p>The syntax is pretty similar to Svelte’s: the <code>&lt;script&gt;</code> tag at the top is run when the component is instantiated, and the <code>&lt;template&gt;</code> tag contains the component’s markup.</p>
<p>Vue doesn’t make compiling a component to a custom element <em>quite</em> as simple as Svelte does. We need to create another file, import the Vue component and call <a href="https://vuejs.org/guide/extras/web-components.html" data-astro-cid-bi7aps5f=""><code>defineCustomElement</code></a><a data-tooltip="" href="https://vuejs.org/guide/extras/web-components.html" data-astro-cid-bi7aps5f=""> <img src="https://vuejs.org/images/logo.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Vue and Web Components | Vue.js</span> <span data-astro-cid-bi7aps5f="">Vue.js - The Progressive JavaScript Framework</span> <span data-astro-cid-bi7aps5f=""> <img src="https://vuejs.org/logo.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">vuejs.org/guide/extras/web-components.html</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> on it:</p>
<pre><code><span>// TodoFilters.js</span>
<span>import</span> <span>{</span> defineCustomElement <span>}</span> <span>from</span> <span>"vue"</span><span>;</span>

<span>import</span> TodoFilters <span>from</span> <span>"./TodoFilters.ce.vue"</span><span>;</span>

customElements<span>.</span><span>define</span><span>(</span><span>"todo-filters"</span><span>,</span> <span>defineCustomElement</span><span>(</span>TodoFilters<span>)</span><span>)</span><span>;</span></code></pre>
<p>Back in React Land, we’ll refactor our component to use Nano Stores rather than <code>useState</code>, and bring in the <code>&lt;todo-filters&gt;</code> component:</p>
<pre><code><span>// TodoApp.jsx</span>
<span>import</span> <span>{</span> useStore <span>}</span> <span>from</span> <span>"@nanostores/react"</span><span>;</span>
<span>import</span> <span>{</span> useCallback <span>}</span> <span>from</span> <span>"react"</span><span>;</span>

<span>import</span> <span>{</span> $todos<span>,</span> $done<span>,</span> $left<span>,</span> $filter<span>,</span> addTodo<span>,</span> removeTodo<span>,</span> checkTodo <span>}</span> <span>from</span> <span>"./store.js"</span><span>;</span>

<span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> filter <span>=</span> <span>useStore</span><span>(</span>$filter<span>)</span><span>;</span>
  <span>const</span> todos <span>=</span> <span>useStore</span><span>(</span>$todos<span>)</span><span>;</span>
  <span>const</span> done <span>=</span> <span>useStore</span><span>(</span>$done<span>)</span><span>;</span>
  <span>const</span> left <span>=</span> <span>useStore</span><span>(</span>$left<span>)</span><span>;</span>
  <span>const</span> visible <span>=</span> filter <span>===</span> <span>"todo"</span> <span>?</span> left <span>:</span> filter <span>===</span> <span>"done"</span> <span>?</span> done <span>:</span> todos<span>;</span>

  <span>const</span> todoRef <span>=</span> <span>useCallback</span><span>(</span><span>ref</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>ref<span>)</span> <span>return</span><span>;</span>
    ref<span>.</span><span>addEventListener</span><span>(</span><span>"check"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>checkTodo</span><span>(</span>evt<span>.</span>detail<span>.</span>id<span>,</span> evt<span>.</span>detail<span>.</span>done<span>)</span><span>)</span><span>;</span>
    ref<span>.</span><span>addEventListener</span><span>(</span><span>"delete"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>removeTodo</span><span>(</span>evt<span>.</span>detail<span>.</span>id<span>)</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>const</span> inputRef <span>=</span> <span>useCallback</span><span>(</span><span>ref</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span>ref<span>)</span> ref<span>.</span><span>addEventListener</span><span>(</span><span>"add"</span><span>,</span> <span>evt</span> <span>=&gt;</span> <span>addTodo</span><span>(</span>evt<span>.</span>detail<span>)</span><span>)</span><span>;</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>todo-layout</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>h1</span> <span>slot</span><span><span>=</span><span>"</span>title<span>"</span></span><span>&gt;</span></span><span>Todos</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>todo-filters</span> <span>slot</span><span><span>=</span><span>"</span>filters<span>"</span></span> <span>/&gt;</span></span><span>

      </span><span><span><span>&lt;</span>div</span> <span>slot</span><span><span>=</span><span>"</span>todos<span>"</span></span><span>&gt;</span></span><span>
        </span><span>{</span>visible<span>.</span><span>map</span><span>(</span><span>todo</span> <span>=&gt;</span> <span>(</span>
          <span><span><span>&lt;</span>todo-item</span> <span>key</span><span><span>=</span><span>{</span>todo<span>.</span>id<span>}</span></span> <span>ref</span><span><span>=</span><span>{</span>todoRef<span>}</span></span> <span><span>{</span><span>...</span>todo<span>}</span></span> <span>/&gt;</span></span>
        <span>)</span><span>)</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>todo-input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>slot</span><span><span>=</span><span>"</span>input<span>"</span></span> <span>/&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>todo-layout</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We did it!
We now have a fully functional todo app, written with four different frameworks — React, Solid, Svelte and Vue — <em>plus</em> a component written in vanilla JavaScript.</p>
<todo-demo show-layout="true" show-input="true" show-todos="true" show-filters="true"></todo-demo>

<h3 id="moving-forward">Moving Forward</h3>
<p>The point of this article is not to convince you that this is a good way to write web apps.
It’s to show that there are ways to build a web app other than writing the entire thing with a single JavaScript framework — and furthermore, that web components actually make it <em>significantly easier</em> to do that.</p>
<p>You can progressively enhance static HTML.
You can build rich interactive JavaScript “islands” that naturally communicate with hypermedia libraries like <a href="https://htmx.org/" data-astro-cid-bi7aps5f="">HTMX</a><a data-tooltip="" href="https://htmx.org/" data-astro-cid-bi7aps5f="">  <span data-astro-cid-bi7aps5f="">&lt;/&gt; htmx - high power tools for html</span>  <span data-astro-cid-bi7aps5f=""> <img src="https://htmx.org/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">htmx.org</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.
You can even wrap a web component around a framework component, and use it with <em>any</em> other framework.</p>
<p>Web components drastically loosen the coupling of JavaScript frameworks by providing a common interface that <em>all</em> frameworks can use.
From a consumer’s point of view, web components are just HTML tags — it doesn’t matter what goes on “under the hood”.</p>
<p>If you want to play around with this yourself, I’ve made a <a href="https://codesandbox.io/p/devbox/polyglot-todos-wm4lwn" data-astro-cid-bi7aps5f="">CodeSandbox with our example todo app</a><a data-tooltip="" href="https://codesandbox.io/p/devbox/polyglot-todos-wm4lwn" data-astro-cid-bi7aps5f="">    <span data-astro-cid-bi7aps5f=""> <img src="https://codesandbox.io/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">codesandbox.io/p/devbox/polyglot-todos-wm4lwn</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</p>
<h3 id="reading-list">Reading List</h3>
<p>If you’re interested, here are some good articles that dive even deeper into the topic:</p>
<ul>
<li>Chris Ferdinandi wrote about wrapping his own UI library <a href="https://reefjs.com/" data-astro-cid-bi7aps5f="">Reef</a><a data-tooltip="" href="https://reefjs.com/" data-astro-cid-bi7aps5f=""> <img src="https://gomakethings.com/img/chris-ferdinandi-high-res.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Reef</span> <span data-astro-cid-bi7aps5f="">A tiny utility library for building reactive state-based UI. Reef is a simpler alternative to React, Vue, and other UI libraries.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://reefjs.com/img/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">reefjs.com</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> with a web component in <a href="https://gomakethings.com/reactive-web-components-and-dom-diffing/" data-astro-cid-bi7aps5f="">Reactive Web Components and DOM Diffing</a><a data-tooltip="" href="https://gomakethings.com/reactive-web-components-and-dom-diffing/" data-astro-cid-bi7aps5f=""> <img src="https://gomakethings.com/img/og.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Reactive Web Components and DOM diffing</span> <span data-astro-cid-bi7aps5f="">This week, I had a conversation on Mastodon with Kyle Leaders and Jake Lazaroff about reactivity and DOM diffing in Web Components…
 I have to say I’ve been actually enjoying working with #webcomponents in #vanillajs lately. I haven’t attempted anything too complicated, but I love the idea of reusable components. Next up, I need to figure out how to best do reactive updates.
 This is one area where the native web platform falls a bit short.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://gomakethings.com/img/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">gomakethings.com/reactive-web-components-and-dom-diffing/</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</li>
<li>Andrico Karoulla wrote a great overview of how to write framework-agnostic components aptly titled <a href="https://component-odyssey.com/articles/01-writing-components-that-work-in-any-framework" data-astro-cid-bi7aps5f="">Writing Components That Work in Any Framework</a><a data-tooltip="" href="https://component-odyssey.com/articles/01-writing-components-that-work-in-any-framework" data-astro-cid-bi7aps5f=""> <img src="https://component-odyssey.com/images/articles/01-writing-components-that-work-in-any-framework/open-graph.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Writing Components That Work In Any Frontend Framework</span> <span data-astro-cid-bi7aps5f="">Web components let developers write interoperable components, but at the cost of lots of boilerplate. Learn how you can write components that work in Svelte, Vue, React, and other frameworks, with minimal boilerplate.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://component-odyssey.com/favicon-32x32.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">component-odyssey.com/articles/01-writing-components-that-work-in-any-framework</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</li>
<li>Thomas Wilburn shows how to use web components to build “languages” within HTML in <a href="https://www.milezero.org/index.php/tech/web/components/chiaroscuro.html" data-astro-cid-bi7aps5f="">Chiaroscuro, or Expressive Trees in Web Components</a><a data-tooltip="" href="https://www.milezero.org/index.php/tech/web/components/chiaroscuro.html" data-astro-cid-bi7aps5f=""> <img src="https://milezero.org/blog/mugshot.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Chiaroscuro, or Expressive Trees in Web Components</span> <span data-astro-cid-bi7aps5f="">This space intentionally left blank.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://www.milezero.org/blog/milezeromono.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">www.milezero.org/index.php/tech/web/components/chiaroscuro.html</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</li>
<li>Maxi Ferreira wrote a wonderful article called <a href="https://frontendatscale.com/blog/islands-architecture-state/" data-astro-cid-bi7aps5f="">Sharing State with Islands Architecture</a><a data-tooltip="" href="https://frontendatscale.com/blog/islands-architecture-state/" data-astro-cid-bi7aps5f=""> <img src="https://frontendatscale.com/og-image-islands-architecture-state.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Sharing State with Islands Architecture | Frontend at Scale</span> <span data-astro-cid-bi7aps5f="">Strategies for communicating between interactive components using Islands Architecture, with examples using Astro and React.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://frontendatscale.com/favicon.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">frontendatscale.com/blog/islands-architecture-state/</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> that goes into detail more about custom events and stores.</li>
<li>The official Astro documentation has a page on <a href="https://docs.astro.build/en/core-concepts/sharing-state/" data-astro-cid-bi7aps5f="">sharing state between islands</a><a data-tooltip="" href="https://docs.astro.build/en/core-concepts/sharing-state/" data-astro-cid-bi7aps5f=""> <img src="https://docs.astro.build/open-graph/en/core-concepts/sharing-state.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Share State Between Islands</span> <span data-astro-cid-bi7aps5f="">Learn how to share state across framework components with Nano Stores.</span> <span data-astro-cid-bi7aps5f=""> <img src="https://docs.astro.build/favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">docs.astro.build/en/core-concepts/sharing-state/</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> using <a href="https://github.com/nanostores/nanostores" data-astro-cid-bi7aps5f="">Nano Stores</a><a data-tooltip="" href="https://github.com/nanostores/nanostores" data-astro-cid-bi7aps5f=""> <img src="https://opengraph.githubassets.com/ca56eede252d8d8e13d7d56f8ef7ec53f6103ccdca592e4cbcb2db28de18300a/nanostores/nanostores" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">GitHub - nanostores/nanostores: A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svelte with many atomic tree-shakable stores</span> <span data-astro-cid-bi7aps5f="">A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svelte with many atomic tree-shakable stores - GitHub - nanostores/nanostores: A tiny (298 bytes) state manager for React/RN/Preact/Vue/Svel...</span> <span data-astro-cid-bi7aps5f=""> <img src="https://github.githubassets.com/favicons/favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">github.com/nanostores/nanostores</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>.</li>
<li>Although it doesn’t explicitly mention web components, the HTMX essay on <a href="https://htmx.org/essays/hypermedia-friendly-scripting/" data-astro-cid-bi7aps5f="">hypermedia-friendly scripting</a><a data-tooltip="" href="https://htmx.org/essays/hypermedia-friendly-scripting/" data-astro-cid-bi7aps5f="">  <span data-astro-cid-bi7aps5f="">&lt;/&gt; htmx ~ Hypermedia-Friendly Scripting</span>  <span data-astro-cid-bi7aps5f=""> <img src="https://htmx.org/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">htmx.org/essays/hypermedia-friendly-scripting/</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a> brings up events and islands as ways for client-side scripting to interact with hypermedia-driven web applications.</li>
</ul>
<section data-footnotes="">
<ol>
<li id="user-content-fn-rimshot">
<p>Get it? Foreshadows? Fore<em>shadows</em>? Like shadow DOM? <a href="#user-content-fnref-rimshot" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-preact">
<p>Technically, we’re using Preact in compatibility mode, because I couldn’t figure out how to get Vite’s React preset to work. It turns out that build tooling gets tricky when you try to use four different frameworks in one codebase! <a href="#user-content-fnref-preact" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-ondirective">
<p>This process is easier with other frameworks. With Svelte, for example, we can use the <code>on:</code> directive to <a href="https://svelte.dev/docs/component-directives#on-eventname" data-astro-cid-bi7aps5f="">listen to arbitrary events emitted from any HTML element</a><a data-tooltip="" href="https://svelte.dev/docs/component-directives#on-eventname" data-astro-cid-bi7aps5f=""> <img src="https://svelte.dev/images/twitter-thumbnail.jpg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">Component directives • Docs • Svelte</span>  <span data-astro-cid-bi7aps5f=""> <img src="https://svelte.dev/favicon.png#on-eventname" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""> <span data-astro-cid-bi7aps5f="">svelte.dev/docs/component-directives#on-eventname</span> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"> <use href="/icons.svg#share"></use> </svg> </span> </a>, including web components. <a href="#user-content-fnref-ondirective" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
</ol>
</section> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Designed Products to Capitalize on Teen Vulnerabilities, States Allege (146 pts)]]></title>
            <link>https://www.wsj.com/business/media/meta-designed-products-to-capitalize-on-teen-vulnerabilities-states-allege-6791dad5</link>
            <guid>38434450</guid>
            <pubDate>Mon, 27 Nov 2023 16:39:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/media/meta-designed-products-to-capitalize-on-teen-vulnerabilities-states-allege-6791dad5">https://www.wsj.com/business/media/meta-designed-products-to-capitalize-on-teen-vulnerabilities-states-allege-6791dad5</a>, See on <a href="https://news.ycombinator.com/item?id=38434450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><div data-type="image" data-inset_type="" data-sub_type="" data-layout="inline"><figure><picture><img alt="" sizes="(max-width: 639px) 100vw, (max-width: 979px) 620px, (max-width: 1299px) 540px, 700px" srcset="https://images.wsj.net/im-891562?width=540&amp;size=1.5023474178403755 540w, https://images.wsj.net/im-891562?width=620&amp;size=1.5023474178403755 620w, https://images.wsj.net/im-891562?width=639&amp;size=1.5023474178403755 639w, https://images.wsj.net/im-891562?width=700&amp;size=1.5023474178403755 700w, https://images.wsj.net/im-891562?width=700&amp;size=1.5023474178403755&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-891562?width=700&amp;size=1.5023474178403755&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-891562?width=700&amp;size=1.5023474178403755&amp;pixel_ratio=3 2100w" width="700" height="466" src="https://images.wsj.net/im-891562?width=700&amp;height=466"></picture></figure><figcaption><span>Meta says it didn’t design its products to be addictive for teens.&nbsp;</span> <span><span>Photo: </span>David Paul Morris/Bloomberg News</span></figcaption></div><p data-type="paragraph">Meta<!-- --> Platforms sought to design its social-media products in ways to take advantage of known weaknesses of young users’ brains, according to newly unredacted legal filings citing internal company documents.</p><div data-type="paragraph"><p>An internal 2020 Meta presentation shows that the company<strong data-type="emphasis">&nbsp;</strong>sought to engineer its products to capitalize on the parts of youth psychology that render teens “predisposed to impulse, peer pressure, and potentially harmful risky behavior,” the filings show.</p><p>References to the documents were initially redacted in the suit, which <a data-type="link" href="https://www.wsj.com/tech/states-sue-meta-alleging-harm-to-young-people-on-instagram-facebook-f9ff4641" rel="">was filed in late October</a> by members of a coalition of 41 states and the District of Columbia, alleging that Meta has intentionally built Facebook and Instagram with addictive features that harm young users. Meta approved the filing of an unredacted version on Wednesday.</p></div></section><p>Copyright ©<!-- -->2023<!-- --> Dow Jones &amp; Company, Inc. All Rights Reserved. 87990cbe856818d5eddac44c7b1cdeb8</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nutrient found in beef and dairy improves immune response to cancer (276 pts)]]></title>
            <link>https://biologicalsciences.uchicago.edu/news/tva-nutrient-cancer-immunity</link>
            <guid>38433563</guid>
            <pubDate>Mon, 27 Nov 2023 15:41:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://biologicalsciences.uchicago.edu/news/tva-nutrient-cancer-immunity">https://biologicalsciences.uchicago.edu/news/tva-nutrient-cancer-immunity</a>, See on <a href="https://news.ycombinator.com/item?id=38433563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Trans-vaccenic acid (TVA), a long-chain fatty acid found in meat and dairy products from grazing animals such as cows and sheep, improves the ability of CD8+ T cells to infiltrate tumors and kill cancer cells, according to a new study by researchers from the University of Chicago.</p>
<p>The research, <a href="https://www.nature.com/articles/s41586-023-06749-3">published this week</a> in <em>Nature</em>, also shows that patients with higher levels of TVA circulating in the blood responded better to immunotherapy, suggesting that it could have potential as a nutritional supplement to complement clinical treatments for cancer.</p>
<p>“There are many studies trying to decipher the link between diet and human health, and it’s very difficult to understand the underlying mechanisms because of the wide variety of foods people eat. But if we focus on just the nutrients and metabolites derived from food, we begin to see how they influence physiology and pathology,” said <a data-entity-substitution="external" data-entity-type="external" data-entity-uuid="7550de90-e8cb-4d06-b99a-753c4e0a471e" href="https://biologicalsciences.uchicago.edu/faculty/jing-chen-phd">Jing Chen, PhD</a>, the Janet Davison Rowley Distinguished Service Professor of Medicine at UChicago and one of the senior authors of the new study. “By focusing on nutrients that can activate T cell responses, we found one that actually enhances anti-tumor immunity by activating an important immune pathway.”</p>
<h2>Finding nutrients that activate immune cells</h2>
<p>Chen’s lab focuses on understanding how metabolites, nutrients and other molecules circulating in the blood influence the development of cancer and response to cancer treatments. For the new study, two postdoctoral fellows, Hao Fan, PhD and Siyuan Xia, PhD, both co-first authors, assembled a “blood nutrient” compound library consisting of 255 bioactive molecules derived from nutrients. They screened the compounds in this new library for their ability to influence anti-tumor immunity by activating CD8+ T cells, a group of immune cells critical for killing cancerous or virally infected cells.</p>
<p>After the scientists evaluated the top six candidates in both human and mouse cells, they saw that TVA performed the best. TVA is the most abundant trans fatty acid present in human milk, but the body cannot produce it on its own. Only about 20% of TVA is broken down into other byproducts, leaving 80% circulating in the blood. “That means there must be something else it does, so we started working on it more,” Chen said.</p>

          </div><div>
            <p>The researchers then conducted a series of experiments with cells and mouse models of diverse tumor types. Feeding mice a diet enriched with TVA significantly reduced the tumor growth potential of melanoma and colon cancer cells compared to mice fed a control diet. The TVA diet also enhanced the ability of CD8+ T cells to infiltrate tumors.</p>
<p>The team also performed a series of molecular and genetic analyses to understand how TVA was affecting the T cells. These included a new technique for monitoring transcription of single-stranded DNA called kethoxal-assisted single-stranded DNA sequencing, or KAS-seq, developed by <a href="https://chemistry.uchicago.edu/faculty/chuan-he">Chuan He, PhD</a>, the John T. Wilson Distinguished Service Professor of Chemistry at UChicago and another senior author of the study. These additional assays, done by both the Chen and He labs, showed that TVA inactivates a receptor on the cell surface called GPR43 which is usually activated by short-chain fatty acids often produced by gut microbiota. TVA overpowers these short-chain fatty acids and activates a cellular signaling process known as the CREB pathway, which is involved in a variety of functions including cellular growth, survival, and differentiation. The team also showed that mouse models where the GPR43 receptor was exclusively removed from CD8+ T cells also lacked their improved tumor fighting ability.</p>
<p>Finally, the team also worked with <a data-entity-substitution="external" data-entity-type="external" data-entity-uuid="86f1347b-0a11-44b3-b34b-1a4d672dca58" href="https://biologicalsciences.uchicago.edu/faculty/justin-p-kline-md">Justin Kline, MD</a>, Professor of Medicine at UChicago, to analyze blood samples taken from patients undergoing CAR-T cell immunotherapy treatment for lymphoma. They saw that patients with higher levels of TVA tended to respond to treatment better than those with lower levels. They also tested cell lines from leukemia by working with <a data-entity-substitution="external" data-entity-type="external" data-entity-uuid="b4424063-8f76-4434-8c41-eab9f3721e8e" href="https://biologicalsciences.uchicago.edu/faculty/wendy-stock-md">Wendy Stock, MD</a>, the Anjuli Seth Nayak Professor of Medicine, and saw that TVA enhanced the ability of an immunotherapy drug to kill leukemia cells.</p>
<h2>Focus on the nutrients, not the food</h2>
<p>The study suggests that TVA could be used as a dietary supplement to help various T cell-based cancer treatments, although Chen points out that it is important to determine the optimized amount of the nutrient itself, not the food source. There is a growing body of evidence about the detrimental health effects of consuming too much red meat and dairy, so this study shouldn’t be taken as an excuse to eat more cheeseburgers and pizza; rather, it indicates that nutrient supplements such as TVA could be used to promote T cell activity. Chen thinks there may be other nutrients that can do the same.</p>
<p>“There is early data showing that other fatty acids from plants signal through a similar receptor, so we believe there is a high possibility that nutrients from plants can do the same thing by activating the CREB pathway as well,” he said.</p>
<p>The new research also highlights the promise of this “metabolomic” approach to understanding how the building blocks of diet affect our health. Chen said his team hopes to build a comprehensive library of nutrients circulating in the blood to understand their impact on immunity and other biological processes like aging.</p>
<p>“After millions of years of evolution, there are only a couple hundred metabolites derived from food that end up circulating in the blood, so that means they could have some importance in our biology,” Chen said. “To see that a single nutrient like TVA has a very targeted mechanism on a targeted immune cell type, with a very profound physiological response at the whole organism level—I find that really amazing and intriguing.”</p>
<p>The study, “<a href="https://www.nature.com/articles/s41586-023-06749-3">Trans-vaccenic acid reprograms CD8+ T cells and anti-tumor immunity</a>,” was supported by the National Institutes of Health (grants CA140515, CA174786, CA276568, 1375 HG006827, K99ES034084), a UChicago Biological Sciences Division Pilot Project Award, the Ludwig Center at UChicago, the Sigal Fellowship in Immuno-oncology, the Margaret E. Early Medical Research Trust, the AASLD Foundation a Harborview Foundation Gift Fund, and the Howard Hughes Medical Institute.</p>

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AirJet makes a MacBook Air perform like a MacBook Pro (179 pts)]]></title>
            <link>https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html</link>
            <guid>38433452</guid>
            <pubDate>Mon, 27 Nov 2023 15:35:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html">https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html</a>, See on <a href="https://news.ycombinator.com/item?id=38433452">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2150862">
	<!-- .entry-header -->

	<!-- <hr class="wp-block-separator" /> -->

	<div>
				
			<div>
				<p><img width="1024" height="683" src="https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?quality=50&amp;strip=all&amp;w=1024" alt="MacBook Air AirJet" decoding="async" data-hero="" srcset="https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?quality=50&amp;strip=all 2400w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=300%2C200&amp;quality=50&amp;strip=all 300w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=768%2C512&amp;quality=50&amp;strip=all 768w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=1200%2C800&amp;quality=50&amp;strip=all 1200w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=1536%2C1024&amp;quality=50&amp;strip=all 1536w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=2048%2C1365&amp;quality=50&amp;strip=all 2048w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=1240%2C826&amp;quality=50&amp;strip=all 1240w, https://www.macworld.com/wp-content/uploads/2023/11/airjet-macbook-air-internal-2.jpg?resize=150%2C100&amp;quality=50&amp;strip=all 150w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><span>Image: Foundry</span>				</p>
							</div><!-- .post-thumbnail -->
			
		
				<div>
					
					
<div id="link_wrapped_content">




<p>Most Macs use fans to help the System on a Chip maintain an optimal operating temperature. These fans are bulky and noisy, but <a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://www.froresystems.com/&amp;xcust=1-1-2150862-1-0-0&amp;sref=https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html" rel="nofollow">Frore Systems</a> has developed a new cooling system called <a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://www.froresystems.com/#Products-block&amp;xcust=1-1-2150862-1-0-0&amp;sref=https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html" rel="nofollow">AirJet</a> that’s super thin–thin enough to fit in a current MacBook Air and boost its performance while under heavy load.</p>



<p>Since the MacBook Air doesn’t have a fan for the SoC, its performance will throttle down during processor-intensive work to maintain a proper operating temperature. The M2 13-inch MacBook Pro, on the other hand, has a fan that expels excessive heat so the chip can keep chugging along.</p>



<p>The AirJet is what Frore calls a “solid-state active cooling chip” that measures 27.5 by 41.5 by 2.8 mm, a lot smaller and thinner than a typical computer fan. It’s so thin that Frore was able to take an M2 15-inch MacBook Air and fit a set of AirJet chips inside the laptop. AirJet can keep the MacBook Air temperature at a proper level so the chip doesn’t have to throttle down. Using the <a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://www.maxon.net/en/downloads/cinebench-r23-downloads...&amp;xcust=1-1-2150862-1-0-0&amp;sref=https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html" rel="nofollow">Cinebench R23</a> benchmark, an off-the-shelf M2 MacBook Air was 7 percent slower than the M2 MacBook Pro. But the modified M2 MacBook Air with an AirJet setup matched the Cinebench score of the MacBook Pro. The video below by our sister site, PCWorld, explains how it works.</p>



<figure><p>
<iframe loading="lazy" title="The AirJet Continues To Innovate Laptop Cooling" width="500" height="281" src="https://www.youtube.com/embed/u0k46Wnq3Rk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<p>How is AirJet able to be so thin? The company has a blog post that goes into <a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://www.froresystems.com/blog/how-do-you-cool-ultra-thin-devices&amp;xcust=1-1-2150862-1-0-0&amp;sref=https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html" rel="nofollow">greater detail on how AirJet works</a>, but essentially, inside it are several different materials used to vibrate membranes. This creates back pressure to pull in air through intakes on the case of the device, such as a laptop. While heat is being moved from the chip to a fin stack, the air is then used by AirJet to expel the heat out of a vent. In the MacBook Air demonstration, Frore added intake vents near the hinge and used the speaker holes as exhaust.</p>

		
			
			


<p>AirJet isn’t a consumer product–consumers can’t buy it and modify their own MacBook Air, nor does Frore plan to create a kit for consumer sale. Frore’s MacBook Air demo is a proof of concept that it can be beneficial in a MacBook. Its thin form factor could open up possibilities with Apple products; for example, if Apple were to use AirJet instead of the fans it uses in the 14- and 16-inch MacBook Pro, it could free up space that the company can use for, say, a bigger battery. Another example is with the Mac Studio, which, as you can see in <a href="https://go.redirectingat.com/?id=111346X1569486&amp;url=https://www.ifixit.com/News/57898/mac-studio-teardown#:~:text=Apple%E2%80%99s%20Biggest%20Fan%E2%80%94And%20Heat%20Sink&amp;xcust=1-1-2150862-1-0-0&amp;sref=https://www.macworld.com/article/2150862/airjet-makes-a-macbook-air-perform-like-a-macbook-pro.html" rel="nofollow">iFixit’s Mac Studio teardown</a>, has a gigantic heat sink and two large fans–AirJet could allow Apple to create a smaller cooling system, thereby shrinking the Mac Studio.</p>







<div data-effect="slide"><ul><li><figure><img decoding="async" alt="MacBook Air AirJet" data-id="2150856" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/macbook-air-airjet.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>Inside a 15-inch M2 MacBook Air with the AirJet and fin stack installed.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="MacBook Air AirJet fin stack" data-id="2150855" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/macbook-air-airjet-fin-stack.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>The modification uses a fin stack to draw heat away from the M2 and to the AirJet cooling system.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="MacBook Air AirJet vents" data-id="2150852" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/macbook-air-airjet-vents.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>In order to install the AirJet, Frore modified a MacBook Air with air intake vents.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="MacBook Pro Cinebench R23" data-id="2150857" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/macbook-pro-cinebench.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>The M2 MacBook Pro’s Cinebench R23 score is 8711.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="MacBook Air no AirJet Cinebench R23" data-id="2150854" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/macbook-air-no-airjet-cinebench.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>An unmodified M2 MacBook Air posted a Cinebench R23 score of 8238.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="MacBook Air AirJet Cinebench R23" data-id="2150853" src="https://b2c-contenthub.com/wp-content/uploads/2023/11/macbook-air-airjet-cinebench.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>With an AirJet installed, the M2 MacBook Air’s score (8720) equaled that of the M2 MacBook Pro (8711).</p>
</figcaption></figure></li></ul></div>

</div>
		<div data-ga="article-footer-author">
				<div>
								<p><img src="https://www.macworld.com/wp-content/uploads/2023/11/author_photo_Roman-Loyola_1662683660-133.jpg?quality=50&amp;strip=all&amp;w=150&amp;h=150&amp;crop=1" height="125" width="125">
				</p>
								<p>Roman has covered technology since the early 1990s. His career started at MacUser, and he's worked for MacAddict, Mac|Life, and TechTV.</p>
				</div>
					<ul>
																									<li>
								<a href="mailto:rloyola@macworld.com" title="Email" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a>
							</li>
																			
						  
						    
					</ul>
				
			</div>
						</div>
			</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Python Is Easy. Go Is Simple. Simple != Easy (166 pts)]]></title>
            <link>https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/</link>
            <guid>38433358</guid>
            <pubDate>Mon, 27 Nov 2023 15:28:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/">https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/</a>, See on <a href="https://news.ycombinator.com/item?id=38433358">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><div><ol><li><a href="https://preslav.me/">Preslav Rachev
<span>/</span></a><a href="https://preslav.me/categories/programming">Programming</a>
<span>/</span></li><li><a href="https://preslav.me/posts/">My Writings
<span>/</span></a><a href="https://preslav.me/categories/programming">Programming</a>
<span>/</span></li><li><a href="https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/">Python is Easy. Go is Simple. Simple != Easy.
<span>/</span></a><a href="https://preslav.me/categories/programming">Programming</a>
<span>/</span></li></ol></div></header><div><p>Python and Go have distinct qualities that can complement each other.</p><figure><img srcset="https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/cover_huf1433fb1d8c7ca998d42f11cbcd49a88_386468_330x0_resize_q75_box.jpg 330w,
https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/cover_huf1433fb1d8c7ca998d42f11cbcd49a88_386468_660x0_resize_q75_box.jpg 660w,
https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/cover_huf1433fb1d8c7ca998d42f11cbcd49a88_386468_1024x0_resize_q75_box.jpg 1024w,
https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/cover_huf1433fb1d8c7ca998d42f11cbcd49a88_386468_1320x0_resize_q75_box.jpg 2x" src="https://preslav.me/2023/11/27/python-is-easy-golang-is-simple-simple-is-not-easy/cover_huf1433fb1d8c7ca998d42f11cbcd49a88_386468_660x0_resize_q75_box.jpg" alt=""><figcaption>Image Credits: <a href="https://www.midjourney.com/">Midjourney</a></figcaption></figure><p>There is a common misconception that <em>simple</em> and <em>easy</em> refer to the same thing. After all, if something is easy to use, its inner workings must be simple to understand, right? Or vice versa? Actually, it is quite the opposite. While the two concepts spiritually point to the same outcome, making something seem easy on the outside requires enormous complexity under the hood.</p><p>Take Python, a language known for its low barrier to entry and, therefore, a favorite choice for entry programming language. Schools, universities, research centers, and a large number of businesses across the globe have chosen Python precisely because of its accessibility to anyone, regardless of their level of education or academic background (or total lack thereof). One rarely needs much type theory or understanding of how and where things get stored in memory, which threads some piece of code is running on, etc. Moreover, Python is the entry gateway to some of the most profound scientific and system-level libraries. Being able to control this amount of power with a single line of code speaks a lot in favor of it becoming one of the most popular programming languages on the planet.</p><p>And here comes the catch - the easiness of expressing things in Python code comes at a cost. Under the hood, the Python interpreter is massive, and many operations must take place for even a single line of code to be executed. When you hear someone referring to Python as a “slow” language, much of the perceived “slowness” comes from the number of decisions the interpreter makes at runtime. But that’s not even the biggest issue, in my view. The complexity of the Python runtime ecosystem, together with some liberal design decisions around its package management, makes for a very fragile environment, and updates often lead to incompatibilities and runtime crashes. It is not uncommon to leave a Python application to go back to it after a few months, only to realize that the host environment has changed enough that it is no longer possible to even to start the application anymore.</p><p>Of course, this is a gross over-simplification, and even kids nowadays know that containers exist to solve problems like this. Indeed, thanks to Docker and its likes, it is possible to “freeze” a Python codebase’s dependencies in time so that it can practically run forever. However, this comes at the cost of shifting the responsibility and complexity to the OS infrastructure. It is not the end of the world, but it is also not something to underestimate and overlook.</p><h2 id="from-easiness-to-simplicity">From Easiness to Simplicity <span><a href="#from-easiness-to-simplicity" aria-label="Anchor">#</a></span></h2><p>If we were to address the issues with Python, we would end up with something like Rust - extremely performant but with a notoriously high barrier to entry. Rust is in my view, not easy to use, and what is more, not simple. While it is in total hype these days, despite 20 years of programming and having had my first steps in C and C++, I cannot look at a piece of Rust code and say with certainty that I understand what is going on there.</p><p>I discovered Go about five years ago while working on a Python-based system. While it took me a few tries to get to like the syntax, I immediately fell for the simplicity idea. Go is meant to be simple to understand by anyone in an organization - from the junior developer fresh out of school to the senior-level engineering manager who only occasionally looks at code. What’s more, being a simple language, Go gets syntax updates very rarely - the last significant one has been the addition of generics in v1.18, which is only after a decade of serious discussion. For the most part, whether you look at Go code written five days ago or five years ago, it is mostly the same and should just work.</p><p>Simplicity requires discipline, though. It can feel limiting and even somewhat backward at first. Especially when compared to a succinct expression, such as a list or a dictionary comprehension in Python:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>temperatures</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>"city"</span><span>:</span> <span>"City1"</span><span>,</span> <span>"temp"</span><span>:</span> <span>19</span><span>},</span>
</span></span><span><span>    <span>{</span><span>"city"</span><span>:</span> <span>"City2"</span><span>,</span> <span>"temp"</span><span>:</span> <span>22</span><span>},</span>
</span></span><span><span>    <span>{</span><span>"city"</span><span>:</span> <span>"City3"</span><span>,</span> <span>"temp"</span><span>:</span> <span>21</span><span>},</span>
</span></span><span><span><span>]</span>
</span></span><span><span>
</span></span><span><span><span>filtered_temps</span> <span>=</span> <span>{</span>
</span></span><span><span>    <span>entry</span><span>[</span><span>"city"</span><span>]:</span> <span>entry</span><span>[</span><span>"temp"</span><span>]</span> <span>for</span> <span>entry</span> <span>in</span> <span>temperatures</span> <span>if</span> <span>entry</span><span>[</span><span>"temp"</span><span>]</span> <span>&gt;</span> <span>20</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>The same code in Go requires a few more keystrokes but should be ideally one idea closer to what the Python interpreter is doing under the hood:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>type</span> <span>CityTemperature</span> <span>struct</span> <span>{</span>
</span></span><span><span>    <span>City</span>      <span>string</span>
</span></span><span><span>    <span>Temp</span> <span>float64</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>// ...
</span></span></span><span><span><span></span>
</span></span><span><span><span>temperatures</span> <span>:=</span> <span>[]</span><span>CityTemperature</span><span>{</span>
</span></span><span><span>    <span>{</span><span>"City1"</span><span>,</span> <span>19</span><span>},</span>
</span></span><span><span>    <span>{</span><span>"City2"</span><span>,</span> <span>22</span><span>},</span>
</span></span><span><span>    <span>{</span><span>"City3"</span><span>,</span> <span>21</span><span>},</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>filteredTemps</span> <span>:=</span> <span>make</span><span>(</span><span>map</span><span>[</span><span>string</span><span>]</span><span>float64</span><span>)</span>
</span></span><span><span><span>for</span> <span>_</span><span>,</span> <span>ct</span> <span>:=</span> <span>range</span> <span>temperatures</span> <span>{</span>
</span></span><span><span>    <span>if</span> <span>ct</span><span>.</span><span>Temp</span> <span>&gt;</span> <span>20</span> <span>{</span>
</span></span><span><span>        <span>filteredTemps</span><span>[</span><span>ct</span><span>.</span><span>City</span><span>]</span> <span>=</span> <span>ct</span><span>.</span><span>Temp</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>While you can write equivalent code in Python, an unwritten rule in programming says that if the language provides an <em>easier</em> (as in, more concise, more elegant) option, programmers will gravitate towards it. But easy is subjective, and simple should be equally applicable to everyone. The availability of alternatives to perform the same action leads to different programming styles, and one can often find multiple styles within the same codebase.</p><p>With Go being verbose and “boring,” it naturally ticks another box - the Go compiler has much less work to do when compiling an executable. Compiling and running a Go application is often as fast, or even quicker, than getting the Python interpreter or Java’s virtual machine to load before even running the actual application. Not surprisingly, being a native executable is as fast as one executable can be. It’s not as fast as its C/C++ or Rust counterparts but at a fraction of the code complexity. I am willing to neglect this minor “drawback” of Go. Last but not least, Go binaries are statically-bound, meaning you can build one anywhere and run it on the target host - without any runtimes or library dependencies whatsoever. For the sake of convenience, we still wrap our Go applications in Docker containers. Still, those are significantly smaller and have a fraction of the memory and CPU consumption of their Python or Java counterparts.</p><h2 id="how-we-use-both-python-and-go-to-our-advantage">How we use both Python and Go to our advantage <span><a href="#how-we-use-both-python-and-go-to-our-advantage" aria-label="Anchor">#</a></span></h2><p>The most pragmatic solution we have found in our work is combining the powers of Python’s <em>easiness</em> and Go’s <em>simplicity</em>. For us, Python is a great prototyping playground. It’s where ideas are born and where scientific hypotheses get accepted and rejected. Python is a natural fit for data science and machine learning, and since we deal with lots of that stuff, it makes little sense to try and reinvent the wheel with something else. Python is also at the core of Django, which speaks to its motto of allowing rapid application development like few other tools (of course, Ruby on Rails and Elixir’s Phoenix deserve a noteworthy mention here).</p><p>Suppose a project needs the slightest bit of user management and internal data administration (like most of our projects do). In that case, we’d start with a Django skeleton because of its built-in Admin, which is fantastic. Once the rough Django proof-of-concept starts resembling a product, we identify how much of it can be rewritten in Go. Since the Django application has already defined the structure of the database and how data models look, writing the Go code that steps up on top of it is quite easy. After a few iterations, we reach a symbiosis, where the two sides peacefully co-exist on top of the same database and use bare-bones messaging to communicate with one another. Eventually, the Django “shell” becomes an orchestrator - it serves our administration purposes and triggers tasks that are then handled by its Go counterpart. The Go part serves everything else, from the front-facing APIs and endpoints to the business logic and backend job processing.</p><p>It’s a symbiosis that has worked well so far, and I hope it stays this way in the future. In a future post, I will outline some more details on the architecture itself.</p><p>Thanks for reading!</p></div><div><h2>You may also find these interesting</h2><article><p><a href="https://preslav.me/2023/06/28/podcasts-for-golang-developers/" aria-label="Podcasts for Go Developers"><img alt="" src="https://images.unsplash.com/photo-1556761175-129418cb2dfe?ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&amp;auto=format&amp;fit=crop&amp;w=1074&amp;q=80"></a></p></article><article><p><a href="https://preslav.me/2023/06/14/golang-focus-on-the-happy-path-with-step-functions/" aria-label="Focus on the Happy Path With Step Functions"><img alt="" src="https://images.unsplash.com/photo-1516522184673-de15e930962f?ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&amp;auto=format&amp;fit=crop&amp;w=1478&amp;q=80"></a></p></article><article><p><a href="https://preslav.me/2023/06/02/my-golang-conference-talk-proposal-got-declined-a-few-times/" aria-label="My Go Talk Proposal Got Declined. A Few Times."><img alt="" src="https://images.unsplash.com/photo-1517664946321-87d2e16ebaa6?ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&amp;auto=format&amp;fit=crop&amp;w=1771&amp;q=80"></a></p></article></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Robot Dad (214 pts)]]></title>
            <link>https://blog.untrod.com/2023/11/robot-dad.html</link>
            <guid>38433330</guid>
            <pubDate>Mon, 27 Nov 2023 15:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.untrod.com/2023/11/robot-dad.html">https://blog.untrod.com/2023/11/robot-dad.html</a>, See on <a href="https://news.ycombinator.com/item?id=38433330">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Tired of Alexa's feeble "here's what I found on wikianswerspam.com" responses to my eight-year-old son's science questions, I whipped up Robot Dad during my Thanksgiving break. He now runs in the background of our family computer.</p>
<p>Robot Dad sounds like real dad, thanks to voice cloning from <a href="https://elevenlabs.io/speech-synthesis">Eleven Labs</a> (very easy; I rambled about Formula 1 into a new MacOS Voice Memo for about sixty seconds, uploaded it, and voila), and answers appropriately for an eight-year-old, while deflecting prank requests -- though I suspect prompt injection will soon be second nature to this generation.</p>
<p>Here's my son, Dash, interacting with Robot Dad.</p>

<p>The delays are real, and the speech-to-text is only so-so, but it manages to be just good enough to clear the "provides value" bar. Robot Dad will also inject context from the previous question into the prompt. Dash could follow up with "Robot Dad, tell me more about it" and ChatGPT would know what to do.</p>
<p>A few dozen lines of code glues together different AI services, for a remarkable result. The wakeword and speech-to-text happen locally, while the AI response (ChatGPT) and text-to-speech are via HTTP. It's trivial to move the LLM bit to a local Llama2 instance, but I haven't found a satisfactory text-to-speech model that can do voice cloning locally.</p>
<p>I also made a quick speech visualization (turns out kids are not very engaged reading console log messages) that of course ended up providing more entertainment value than the <em>ENTIRE MODERN MIRACLE OF ARTIFICIAL INTELLIGENCE</em>. Code for the visualization is in <a href="https://gist.github.com/chrisclark/b9e7ba61654313a1e2d4a796ad5bb8a9">this gist</a>.</p>
<video controls="controls" width="100%" name="speech visualization">
  <source src="https://blog.untrod.com/media/robot-dad-speech-visualization.mov">
</video>

<p>Code for Robot Dad is below. You will need API keys for <a href="https://picovoice.ai/">Picovoice</a> (and a wakeword), <a href="https://elevenlabs.io/speech-synthesis">Eleven Labs</a>, and OpenAI. You can pick a pre-existing Eleven Labs voice or clone your own.</p>
<div><pre><span></span><code><span>import</span> <span>os</span><span>,</span> <span>json</span><span>,</span> <span>threading</span><span>,</span> <span>time</span>
<span>import</span> <span>pvporcupine</span><span>,</span> <span>pvcheetah</span>
<span>from</span> <span>pvrecorder</span> <span>import</span> <span>PvRecorder</span>
<span>from</span> <span>elevenlabs</span> <span>import</span> <span>voices</span><span>,</span> <span>generate</span><span>,</span> <span>play</span><span>,</span> <span>stream</span>
<span>import</span> <span>openai</span>

<span>ENDPOINT_DURATION_SECONDS</span> <span>=</span> <span>2</span> <span># 'Quiet' seconds indicating the end of audio capture</span>
<span>VOICE</span> <span>=</span> <span>'Dad'</span> <span># Via Eleven Labs</span>
<span>AUDIO_DEVICE_NAME</span> <span>=</span> <span>'MacBook Pro Microphone'</span>
<span>AUDIO_DEVICE</span> <span>=</span> <span>PvRecorder</span><span>.</span><span>get_available_devices</span><span>()</span><span>.</span><span>index</span><span>(</span><span>AUDIO_DEVICE_NAME</span><span>)</span>
<span>OPENAI_MODEL</span> <span>=</span> <span>'gpt-3.5-turbo-1106'</span>

<span>BASE_PROMPT</span> <span>=</span> <span>"""You are Robot Dad, and will be speaking with one of my children,</span>
<span>trying to be a helpful parent. You explain things at a level appropriate for</span>
<span>an eight-year-old.</span>

<span>You are encouraging and helpful, but won't tolerate any inappropriate requests</span>
<span>or attempts at pranks or jokes. If you you are asked or told anything</span>
<span>inappropriate, you gently say "nice try - but Robot Dad isn't falling for that!"</span>

<span>If you don't know how to reply, simply say "I'm just Robot Dad, not real dad -</span>
<span>so I'm afraid I can't help you with that".</span>

<span>You usually answer in no more than 4 sentences - kids do not have long attention</span>
<span>spans - but you can provide longer answers if it's clearly needed.</span>
<span>"""</span>

<span>PREV_CTX_PROMPT</span> <span>=</span> <span>"""</span>

<span>The last request and response you received is below. The next request may or may</span>
<span>not be a continuation of this conversation.</span>

<span>Previous request:</span>
<span>%s</span><span></span>

<span>Previous response:</span>
<span>%s</span><span></span>
<span>"""</span>

<span>PREV_CTX_TIMEOUT</span> <span>=</span> <span>60</span> <span># seconds</span>

<span>keyword_paths</span><span>=</span><span>[</span><span>'</span><span>%s</span><span>/wakewords/Robot-Dad.ppn'</span> <span>%</span> <span>ROOT</span><span>]</span>

<span>porcupine_key</span> <span>=</span> <span>os</span><span>.</span><span>environ</span><span>.</span><span>get</span><span>(</span><span>"PORCUPINE_API_KEY"</span><span>)</span>
<span>openai</span><span>.</span><span>api_key</span> <span>=</span> <span>os</span><span>.</span><span>environ</span><span>.</span><span>get</span><span>(</span><span>"OPENAI_API_KEY"</span><span>)</span>

<span>porcupine</span> <span>=</span> <span>pvporcupine</span><span>.</span><span>create</span><span>(</span>
    <span>access_key</span><span>=</span><span>porcupine_key</span><span>,</span>
    <span>keyword_paths</span><span>=</span><span>keyword_paths</span><span>)</span>

<span>cheetah</span> <span>=</span> <span>pvcheetah</span><span>.</span><span>create</span><span>(</span>
    <span>access_key</span><span>=</span><span>porcupine_key</span><span>,</span>
    <span>endpoint_duration_sec</span><span>=</span><span>ENDPOINT_DURATION_SECONDS</span><span>,</span>
    <span>enable_automatic_punctuation</span><span>=</span><span>True</span><span>)</span>

<span>recorder</span> <span>=</span> <span>PvRecorder</span><span>(</span>
    <span>frame_length</span><span>=</span><span>porcupine</span><span>.</span><span>frame_length</span><span>,</span>
    <span>device_index</span><span>=</span><span>AUDIO_DEVICE</span><span>)</span>

<span>break_audio</span> <span>=</span> <span>generate</span><span>(</span><span>text</span><span>=</span><span>"Got it! Robot Dad is thinking..."</span><span>,</span> <span>voice</span><span>=</span><span>VOICE</span><span>)</span>
<span>alert_audio</span> <span>=</span> <span>generate</span><span>(</span><span>text</span><span>=</span><span>"What's up kiddo?"</span><span>,</span> <span>voice</span><span>=</span><span>VOICE</span><span>)</span>

<span>def</span> <span>llm_req</span><span>(</span><span>prompt</span><span>,</span> <span>txt</span><span>):</span>
    <span>messages</span><span>=</span> <span>[</span>
        <span>{</span><span>"role"</span><span>:</span> <span>"system"</span><span>,</span> <span>"content"</span><span>:</span> <span>prompt</span><span>},</span>
        <span>{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>f</span><span>'Here is what the child has said: </span><span>{</span><span>txt</span><span>}</span><span>'</span><span>}</span>
    <span>]</span>

    <span>resp</span> <span>=</span> <span>openai</span><span>.</span><span>ChatCompletion</span><span>.</span><span>create</span><span>(</span>
      <span>model</span><span>=</span><span>OPENAI_MODEL</span><span>,</span>
      <span>messages</span><span>=</span><span>messages</span>
    <span>)</span>
    <span>return</span> <span>resp</span><span>[</span><span>'choices'</span><span>][</span><span>0</span><span>][</span><span>'message'</span><span>][</span><span>'content'</span><span>]</span>


<span># Speech-to-text using Picovoice's Cheetah</span>
<span>def</span> <span>capture_input</span><span>():</span>
    <span>transcript</span> <span>=</span> <span>''</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>partial_transcript</span><span>,</span> <span>is_endpoint</span> <span>=</span> <span>cheetah</span><span>.</span><span>process</span><span>(</span><span>recorder</span><span>.</span><span>read</span><span>())</span>
        <span>transcript</span> <span>+=</span> <span>partial_transcript</span>
        <span>if</span> <span>is_endpoint</span><span>:</span>
            <span>transcript</span> <span>+=</span> <span>cheetah</span><span>.</span><span>flush</span><span>()</span>
            <span>break</span>
    <span>return</span> <span>transcript</span>


<span>def</span> <span>play_async</span><span>(</span><span>audio</span><span>):</span>
    <span>audio_thread</span> <span>=</span> <span>threading</span><span>.</span><span>Thread</span><span>(</span><span>target</span><span>=</span><span>play</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>audio</span><span>,))</span>
    <span>audio_thread</span><span>.</span><span>start</span><span>()</span>


<span>def</span> <span>main</span><span>():</span>
    <span>print</span><span>(</span><span>'Listening...'</span><span>)</span>

    <span>recorder</span><span>.</span><span>start</span><span>()</span>

    <span>prev_request</span> <span>=</span> <span>''</span>
    <span>prev_response</span> <span>=</span> <span>''</span>
    <span>last_wake_time</span> <span>=</span> <span>None</span>

    <span>try</span><span>:</span>
        <span>while</span> <span>True</span><span>:</span>
            <span>pcm</span> <span>=</span> <span>recorder</span><span>.</span><span>read</span><span>()</span>
            <span>result</span> <span>=</span> <span>porcupine</span><span>.</span><span>process</span><span>(</span><span>pcm</span><span>)</span>

            <span>if</span> <span>result</span> <span>&gt;=</span> <span>0</span><span>:</span>
                <span>print</span><span>(</span><span>'Detected Robot Dad'</span><span>)</span>
                <span>play_async</span><span>(</span><span>alert_audio</span><span>)</span>

                <span>prompt</span> <span>=</span> <span>BASE_PROMPT</span>
                <span>current_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
                <span>if</span> <span>last_wake_time</span> <span>and</span> <span>current_time</span> <span>-</span> <span>last_wake_time</span> <span>&lt;</span> <span>PREV_CTX_TIMEOUT</span><span>:</span>
                    <span>prompt</span> <span>+=</span> <span>PREV_CTX_PROMPT</span> <span>%</span> <span>(</span><span>prev_request</span><span>,</span> <span>prev_response</span><span>)</span>
                <span>last_wake_time</span> <span>=</span> <span>current_time</span>

                <span>transcript</span> <span>=</span> <span>capture_input</span><span>()</span>
                <span>print</span><span>(</span><span>'Heard request: </span><span>%s</span><span>'</span> <span>%</span> <span>transcript</span><span>)</span>
                <span>prev_request</span> <span>=</span> <span>transcript</span>

                <span>play_async</span><span>(</span><span>break_audio</span><span>)</span>

                <span>resp</span> <span>=</span> <span>llm_req</span><span>(</span><span>prompt</span><span>,</span> <span>transcript</span><span>)</span>
                <span>print</span><span>(</span><span>'Answering: </span><span>%s</span><span>'</span> <span>%</span> <span>resp</span><span>)</span>
                <span>prev_response</span> <span>=</span> <span>resp</span>

                <span>resp_audio</span> <span>=</span> <span>generate</span><span>(</span><span>text</span><span>=</span><span>resp</span><span>,</span> <span>voice</span><span>=</span><span>VOICE</span><span>,</span> <span>stream</span><span>=</span><span>True</span><span>)</span>
                <span>stream</span><span>(</span><span>resp_audio</span><span>)</span>
    <span>except</span> <span>KeyboardInterrupt</span><span>:</span>
        <span>pass</span>

    <span>recorder</span><span>.</span><span>stop</span><span>()</span>
    <span>print</span><span>(</span><span>'Stopped.'</span><span>)</span>
<span>main</span><span>()</span>
</code></pre></div>


            <h4><i>Like what you read?</i> <a href="http://tinyletter.com/chrisclark">Join the newsletter</a> and get updated when there's something new.</h4>


    

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Favorite Database T-Shirts (202 pts)]]></title>
            <link>https://www.cs.cmu.edu/~pavlo/blog/2016/07/my-favorite-database-shirts.html</link>
            <guid>38433083</guid>
            <pubDate>Mon, 27 Nov 2023 15:07:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.cmu.edu/~pavlo/blog/2016/07/my-favorite-database-shirts.html">https://www.cs.cmu.edu/~pavlo/blog/2016/07/my-favorite-database-shirts.html</a>, See on <a href="https://news.ycombinator.com/item?id=38433083">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h2>TL;DR</h2>
<ul>
  <li>I like wearing database shirts. MongoDB's original shirt from the early 2010s is the vanguard. You should never opt for a cheaper material.
</li></ul>

<p>When I was an undergrad, I was really into shirts from obscure indie and punk bands (see <a onclick="javascript:pageTracker._trackPageview('/outgoing/52colony.com');" href="http://52colony.com/modules5862.html">example #1</a><sup><a href="#footnote1">[1]</a></sup> and <a onclick="javascript:pageTracker._trackPageview('/outgoing/52colony.com');" href="http://52colony.com/modules3171.html">example #2</a><sup><a href="#footnote2">[2]</a></sup> from 2004). It was my (pretentious) way of trying to be different by wearing shirts from bands that broke up after only one album<sup><a href="#footnote3">[3]</a></sup>. I'm older now and I don't run basement shows anymore. So now that same zeal that I had back then for band shirts is now channeled towards database shirts. I now wear shirts from database companies that broke up and no longer exist (e.g., <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.bizjournals.com');" href="http://www.bizjournals.com/boston/blog/startups/2013/07/akiban-acquired-by-foundationdb-with.html">Akiban</a>, <a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Xeround">Xeround</a>).</p>
<p>Promoting your database system or start-up with a shirt is almost as important as getting the thing to actually run. As I've told my students several times, in the world of databases you <em>don't sell the steak, you sell the sizzle</em>. Over the years, I've collected a number of shirts from database companies (mostly newer NoSQL and NewSQL start-ups). A good shirt can get people to feel like your DBMS is going to solve all of their application's database problems. Of course this means you have to have good branding and logo design. But all of these efforts should be in the name of working towards the goal of making an impressive shirt that people will want to wear and promote your system.</p>
<p>In this article, I provide a list of my top five favorite database shirts. I have other ones that I like a lot (and ones that I think are dreadful<sup><a href="#footnote4">[4]</a></sup>), but the shirts listed below are the ones that feel are a step above the others. Eventually we will conduct a more scientific evaluation of these systems, but I thought that it would be fun to compare them based on their shirts. I evaluate the shirts based on the following metrics: </p>
<ol>
<li><b>Material Quality:</b> How soft and thick is the shirt? Does it feel sturdy and a high quality?</li>
<li><b>Fit:</b> How well does the shirt fit on someone with a normal body shape?</li>
<li><b>Design:</b> Is the artwork on the shirt interesting and something that one could wear in public?</li>
</ol>
<!-- For some companies, I have more than one shirt. I also have two zip-up hoodies. Each of these will be evaluated separately at some point. I also  -->
<p>Per Margo Seltzer's <a onclick="javascript:pageTracker._trackPageview('/outgoing/mis-misinformation.blogspot.com');" href="http://mis-misinformation.blogspot.com/2012/10/gender-and-swag.html">guidelines</a>, extra points are given to companies that provide a women's cut shirt.</p>
<p>I recognize that companies typically make nicer items for their employees (e.g., MemSQL has Patagonia jackets). The shirts in this review are only ones that the companies give out to non-employees (e.g., customers, professors). </p>
<hr>

<div>

<div id="mongodb">
<p><a onclick="javascript:pageTracker._trackPageview('/downloads/../../../images/blog/010/mongodb.jpg');" href="https://www.cs.cmu.edu/~pavlo/images/blog/010/mongodb.jpg"><img src="https://www.cs.cmu.edu/~pavlo/images/blog/010/mongodb-small.jpg"></a>
</p>
<div>
    <h2>#1 — MongoDB</h2>
    <p><b>Brand:</b> American Apparel 50/50 Shirt <br>
    <b>Material:</b> 50% Polyester / 50% Cotton <br>
    <b>Year:</b> 2010 </p><p>As far as I know, this is the original shirt released by MongoDB. This was the hot item when I got it a few years ago. I consider this to be the <b>gold standard</b> for a database shirt. MongoDB spared no expense in getting the plush American Apparel 50/50 cotton blend. The cut is flattering. The design is clean and direct (with three colors). It's not entirely obvious that this is a tech shirt, so you can wear it in public. They get also points for using a non-traditional shirt color (i.e., it's not black, white, or gray). Over the years, the shirt has held up well and has gotten softer.

    </p><p>This is an example of what all database companies should aspire to have with their own shirts. A lot of companies go cheap and get Hane's Beefy-T, but these shirts feels like sandpaper on my delicate body. It shows that paying a little extra to get a nicer quality shirt is worth it because it makes people want to wear it. I remember when they would come to recruit at Brown and the next day there would be non-CS people walking around campus with MongoDB shirts. I know that they made women's cut versions too, because a lot of girls would wear them to the gym.

    </p><p>The success of Eliot Horowitz and his crew with this MongoDB shirt inspired me to make a <a onclick="javascript:pageTracker._trackPageview('/downloads/../../../images/photo-hardcore.jpg');" href="https://www.cs.cmu.edu/~pavlo/images/photo-hardcore.jpg">shirt</a> for my own DBMS before I went on the <a onclick="javascript:pageTracker._trackPageview('/downloads/../../../papers/SCSFC-Pavlo13.pdf');" href="https://www.cs.cmu.edu/~pavlo/papers/SCSFC-Pavlo13.pdf">job market</a>. I attribute this shirt to a lot of my own early success.
</p></div>
</div>

<div id="nuodb">
<p><a onclick="javascript:pageTracker._trackPageview('/downloads/../../../images/blog/010/nuodb.jpg');" href="https://www.cs.cmu.edu/~pavlo/images/blog/010/nuodb.jpg"><img src="https://www.cs.cmu.edu/~pavlo/images/blog/010/nuodb-small.jpg"></a>
</p>
<div>
    <h2>#2 — NuoDB</h2>
    <p><b>Brand:</b> Next Level <br>
    <b>Material:</b> 50% Polyester / 25% Cotton / 25% Rayon <br>
    <b>Year:</b> 2013 </p><p>This is the only long sleeve t-shirt that I have in my top five list. I also consider this to be one of the <b>best</b> shirts ever put out by a database company. I would have ranked this #1 except that I think that the MongoDB shirt above had a larger impact on their popularity. This NuoDB shirt is high quality and soft. Next Level shirts are just as good as American Apparel. It's also rare to have a t-shirt with a hood. The design is bright and interesting. This has the best artwork of all the shirts because it's not just their logo slapped on a shirt. NuoDB actually had somebody design this and it shows. Most people would not know that this shirt is for a database company.

    </p><p>I always wear this shirt when I have to fly long distances. It's sort of my "<a onclick="javascript:pageTracker._trackPageview('/outgoing/en.wikipedia.org');" href="https://en.wikipedia.org/wiki/Thundershirt">thunder shirt</a>." I also have the light gray variant of it that they gave my wife (it has different artwork). She loves hers equally as much as I love this one here (although it is not a women's cut). I think they told me that these were a limited edition. NuoDB's <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/andy_pavlo/status/728629984068284416">new shirts</a> are good, but not nearly as nice as this one (but they do have women's sizes).
</p></div>
</div>

<div id="snowflake">
<p><a onclick="javascript:pageTracker._trackPageview('/downloads/../../../images/blog/010/snowflake.jpg');" href="https://www.cs.cmu.edu/~pavlo/images/blog/010/snowflake.jpg"><img src="https://www.cs.cmu.edu/~pavlo/images/blog/010/snowflake-small.jpg"></a>
</p>
<div>
    <h2>#3 — Snowflake</h2>
    <p><b>Brand:</b> Canvas <br>
    <b>Material:</b> 50% Polyester / 25% Cotton / 25% Rayon <br>
    <b>Year:</b> 2016 </p><p>The Snowflake team (smartly) followed the MongoDB playbook with this shirt. This is the highest quality database shirt that I have received in the last year. The database fam <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/markcallaghan/status/730076601342300160">agrees</a> with this assessment. The companies name is on the front and their logo is on the back. All of the printing is in white. They also have a nice sky blue version as well.

    </p><p>Although I have only worn this shirt for a few months, it already buttersoft. It is even softer than the MongoDB one above.  The only issue is that I have been asked whether the shirt is for a ski resort. It is not obvious to non-database people that this is a tech company. That can be good or bad depending on your <a onclick="javascript:pageTracker._trackPageview('/outgoing/youtu.be');" href="https://youtu.be/ndBCojeBtmg?t=10m37s">lifestyle</a>.
</p></div>
</div>

<div id="altibase">
<p><a onclick="javascript:pageTracker._trackPageview('/downloads/../../../images/blog/010/altibase.jpg');" href="https://www.cs.cmu.edu/~pavlo/images/blog/010/altibase.jpg"><img src="https://www.cs.cmu.edu/~pavlo/images/blog/010/altibase-small.jpg"></a>
</p>
<div>
    <h2>#4 — Altibase</h2>
    <p><b>Brand:</b> Next Level <br>
    <b>Material:</b> 90% Cotton / 10% Polyester <br>
    <b>Year:</b> 2016 </p><p>This shirt is a bit banal, but I like it because Altibase is a (slightly) obscure DBMS. It is a Korean system that was one of the first in-memory DBMSs from the 1990s. This is the most nerdy of all the shirts listed here (even though all database shirts are by definition nerdy). I like it because it has a vintage aesthetic that reminds me of the stolid tech companies from the 1980s. It says upfront that it's a relational DBMS so there are never any questions about what the shirt means. It also tells you that their DBMS means business since it's "enterprise grade."

    </p><p>The shirt material is a bit thinner than the others. I have avoid putting this shirt in the dryer because I am afraid that it will start to tatter. The printing is two-color and has set in nicely into the fabric.
</p></div>
</div>

<div id="voltdb">
<p><a onclick="javascript:pageTracker._trackPageview('/downloads/../../../images/blog/010/voltdb.jpg');" href="https://www.cs.cmu.edu/~pavlo/images/blog/010/voltdb.jpg"><img src="https://www.cs.cmu.edu/~pavlo/images/blog/010/voltdb-small.jpg"></a>
</p>
<div>
    <h2>#5 — VoltDB</h2>
    <p><b>Brand:</b> Hanes Nano-T <br>
    <b>Material:</b> 100% Cotton <br>
    <b>Year:</b> 2015 </p><p>This last one is the only Hanes shirt that I will wear. This is not as bad as Beefy T. The primary red color is uninteresting. No database company should ever use this kind of shirt. With that said, the reason why it makes my top five list is that it is a limited edition shirt put out by VoltDB in celebration of Mike Stonebraker winning the <a onclick="javascript:pageTracker._trackPageview('/outgoing/amturing.acm.org');" href="http://amturing.acm.org/award_winners/stonebraker_1172121.cfm">2014 Turing Award</a>. So it's special to me for that reason. It has a picture of Mike's beautiful visage and an <tt>INSERT</tt> query about him becoming a Turing Laureate. It is also the only shirt in this listing where I have both men's and women's version (shown in the photo here).

    </p><p>I have the other <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/andy_pavlo/status/362650168262279168">VoltDB Warhol-style Stonebraker shirt</a>, but it's too large so I can't wear it. I am a <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/justinesherry/status/741152043243569152">big proponent</a> of putting a picture of your <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/pbailis/status/413035226609102848">face on a shirt</a>.

    </p><p><em>Disclosure: I was on the team that wrote the <a onclick="javascript:pageTracker._trackPageview('/outgoing/hstore.cs.brown.edu');" href="http://hstore.cs.brown.edu/">system</a> that later became VoltDB and Stonebraker was one of my <a onclick="javascript:pageTracker._trackPageview('/outgoing/twitter.com');" href="https://twitter.com/andy_pavlo/status/367392409698578433">PhD advisers</a>, so I am probably biased because of that.</em>
</p></div>
</div>


</div>

<p><b>Attention Companies:</b> If you want me to review your database shirt in the future, you can send a men's medium and/or a women's small shirt to:</p>
<address>
Andy Pavlo<br>
Dept. of Computer Science<br>
Carnegie Mellon University<br>
Gates-Hillman Center 9019<br>
5000 Forbes Avenue<br>
Pittsburgh, PA 15213-3891
</address>

<h3>Footnotes</h3>
<ol>
    <li id="footnote1"> <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.youtube.com');" href="https://www.youtube.com/watch?v=9cu4hnecGvQ">Welcome the Plague Year</a>
    </li><li id="footnote2"> <a onclick="javascript:pageTracker._trackPageview('/outgoing/www.youtube.com');" href="https://www.youtube.com/watch?v=e_T3UcDAogQ">Sleepytime Trio</a>
    </li><li id="footnote3"> This was well before the term "hipster" came into existence. I was going for the "I'm not a CS nerd" look at a nerd school. It did help me meet my <a onclick="javascript:pageTracker._trackPageview('/outgoing/52colony.com');" href="http://52colony.com/modules1c08.html">future wife</a>.
    </li><li id="footnote4"> Coincidentally, the Akiban and Xeround shirts are actually two of the ugliest ones that I have. And now they no longer exist. Think about that...
</li></ol>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A Dalle-3 and GPT4-Vision feedback loop (294 pts)]]></title>
            <link>https://dalle.party/</link>
            <guid>38432486</guid>
            <pubDate>Mon, 27 Nov 2023 14:18:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dalle.party/">https://dalle.party/</a>, See on <a href="https://news.ycombinator.com/item?id=38432486">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Download all of Wikipedia on your phone (108 pts)]]></title>
            <link>https://practicalbetterments.com/download-all-of-wikipedia-on-your-phone/</link>
            <guid>38432445</guid>
            <pubDate>Mon, 27 Nov 2023 14:15:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://practicalbetterments.com/download-all-of-wikipedia-on-your-phone/">https://practicalbetterments.com/download-all-of-wikipedia-on-your-phone/</a>, See on <a href="https://news.ycombinator.com/item?id=38432445">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><nav></nav><p>There's a lot of data on the public internet —&nbsp;and vast amounts get added every day. But, how much of it is useful to anyone, and how much of it is conceivably useful to <em>you</em>?</p><p>The answer is&nbsp;<code>102 gigabytes</code>.</p><p><strong>Download all of Wikipedia on your phone and never be without the useful internet ever again.</strong></p><h2>Why download Wikipedia</h2><p>I downloaded Wikipedia about a year ago and have used it more than I expected. Here's some of the benefits with real life examples:</p><ul><li><strong>You get access to information on almost everything when there is no internet.</strong> When the internet is patchy on a train, when you're underground, or in the middle of the ocean.</li><li><strong>Saving money on data.</strong> Especially useful while travelling when data is likely to be more expensive. You can look up the history of towns your train passes through, the culture of your destination, and solve culinary mysteries without having to chew anything.</li><li><strong>It's better for your brain than social media.</strong> Removing some of the friction required to use Wikipedia —&nbsp;reduces the likelihood you'll spend time on social media. Wikipedia has much healthier <a href="https://en.wikipedia.org/wiki/Wiki_rabbit_hole">rabbit holes</a>. (This <a href="https://en.wikipedia.org/wiki/Wikipedia:Unusual_articles">list of unusual articles</a> is always a good starting point.)</li><li><strong>It's a nice reminder of the breadth of human interest.</strong> Every article on wikipedia was written by a human being who cared about the topic. When I'm feeling down, especially about my writing, I remember that people care enough to write about <a href="https://en.wikipedia.org/wiki/Pocket_lint">pocket lint</a> — and I feel less blue.</li><li><strong>Resilience from global catastrophe and forced boredom.</strong> At any moment society could collapse or you could find yourself hiding at a party. It's best to be prepared.</li><li><strong>It weighs much less than a hard&nbsp;copy.</strong></li></ul><h2>How to download Wikipedia</h2><p>There are a number of ways to download Wikipedia, a <a href="https://en.wikipedia.org/wiki/Wikipedia:Database_download">complete list</a> is available on (no surprise) Wikipedia. The most user-friendly way is to download an app to do it for you, and the most user-friendly app is&nbsp;<strong>Kiwix</strong>.</p><p>Kiwix is available on both Android and iOS. It's free, <a href="https://github.com/kiwix">open-source</a>, and can be used for other content —&nbsp;like <a href="https://www.ifixit.com/">iFixit</a> or <a href="https://stackoverflow.com/">Stack Overflow</a>.</p><p>Wikipedia weighs in at around <code>102 gigabytes (GB)</code> with images and <code>60GB</code> without. It's a big file — too big for a lot of phones. However, Kiwix also allows you to download subdivisions of wikipedia —&nbsp;like the top <code>1 million</code> articles at <code>43.53GB</code>, mathematics articles at <code>2.63GB</code>, or only ice hockey articles <code>527.6MB</code>.</p><p>Here's how to do it:</p><ol><li>Download Kiwix for your platform of choice: <a href="https://apps.apple.com/us/app/kiwix/id997079563">iOS</a>, <a href="https://play.google.com/store/apps/details?id=org.kiwix.kiwixmobile&amp;pli=1">Android</a>, <a href="https://kiwix.org/en/applications/">Everything else</a>.</li><li>Open the app</li><li>Navigate to <code>Library</code>. (You have to hold down the bottom right menu button)</li><li>Click <code>Categories</code></li><li>Click <code>Wikipedia</code></li><li>There are lots of options for downloading subdivisions of Wikipedia. Scroll down to the heading that simply says <code>Wikipedia</code> to see the options for downloading all of English language Wikipedia.</li><li>Choose the download size that is right for you.</li><li>Make yourself a cup of tea and sit patiently next to your WiFi router.</li></ol><dl><dt>Tags</dt><dd></dd><dt>Published</dt><dd><time datetime="2023-11-27">27 Nov 2023</time></dd><dt>Updated</dt><dd><time datetime="2023-11-27">27 Nov 2023</time></dd></dl></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub: Can no longer search code without being logged in (316 pts)]]></title>
            <link>https://github.com/orgs/community/discussions/77046</link>
            <guid>38432261</guid>
            <pubDate>Mon, 27 Nov 2023 13:56:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/orgs/community/discussions/77046">https://github.com/orgs/community/discussions/77046</a>, See on <a href="https://news.ycombinator.com/item?id=38432261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="5894322" data-target-translation-type="discussion">
        <tr>
    <td>
        <h3 dir="auto">Select Topic Area</h3>
<p dir="auto">Product Feedback</p>
<h3 dir="auto">Body</h3>
<p dir="auto">This is revolting and an anathema to the open source movement. A movement, I might add, Microsoft is abusing here.</p>
<p dir="auto">We're told that this is for security... But what <em>possible</em> point is there when I can simply clone the repository and use more dedicated tools for proper searching and analysis?</p>
<p dir="auto">So what possible reason is there?! Do you NOT have enough of our data? Is it not enough to monetize every bowel movement, you now feel the need to track which individual lines of code I'm browsing?</p>
<p dir="auto">I was on an older machine and needed to search for something in OUR OWN REPOSITORY and couldn't. I actually want people to be able to search our codebase.</p>
<p dir="auto">So what did I have to do? I tried logging in. Didn't have my password manager nearby. So I had to grab my phone. Oh! Now I need to 2FA. So back to my office to grab my Yubi key. The old laptop doesn't have USB-C ports? Well now I'm SOL.</p>
<p dir="auto">Not only is this change unncecessary, it's downright <strong>hostile</strong> towards your own customers. <em>Ambitiously</em> hostile!</p>
<p dir="auto">Obviously we're too far into the Github ecosystem to be able to easily change providers to one that even gives a pretext of user privacy or responsiveness. So kudos for that.</p>
<p dir="auto">But I'm done with the web interface. If you're not going to even bother hiding the fact that you see us as a source of data and a resource to be extracted, I choose to <strong>not</strong> give you that information.</p>
<p dir="auto">This is the final straw. I will no longer be creating new projects on GitHub. I want them to be useful to the public.</p>
<p dir="auto">Anybody reading this needs to realize something: Every time you create something new here, future audiences will only be able to search your code after bending the knee to Microsoft.</p>
<p dir="auto">Please, GItHub maintainers! Ignore the marketing jackals and the middle managers. Fight back! This is ethically indefensible and needs to be reversed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2373951/285679914-b65d0f04-cc77-493c-8aec-d574f62a287a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDExMDExMDQsIm5iZiI6MTcwMTEwMDgwNCwicGF0aCI6Ii8yMzczOTUxLzI4NTY3OTkxNC1iNjVkMGYwNC1jYzc3LTQ5M2MtOGFlYy1kNTc0ZjYyYTI4N2EucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTEyNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzExMjdUMTYwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NGM0ZjhjNGExMTQyNTc2M2U1OTg5OWU5NzY2NTE0ZjA4NWZhMjYwM2Q5YmY0OTE2ZWViMzA0MmU4YTg5NGNkMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.byW_DYeXQjAumFClK6ZgS39jahPcw869az2vCUqPAGs"><img src="https://private-user-images.githubusercontent.com/2373951/285679914-b65d0f04-cc77-493c-8aec-d574f62a287a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDExMDExMDQsIm5iZiI6MTcwMTEwMDgwNCwicGF0aCI6Ii8yMzczOTUxLzI4NTY3OTkxNC1iNjVkMGYwNC1jYzc3LTQ5M2MtOGFlYy1kNTc0ZjYyYTI4N2EucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTEyNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzExMjdUMTYwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NGM0ZjhjNGExMTQyNTc2M2U1OTg5OWU5NzY2NTE0ZjA4NWZhMjYwM2Q5YmY0OTE2ZWViMzA0MmU4YTg5NGNkMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.byW_DYeXQjAumFClK6ZgS39jahPcw869az2vCUqPAGs" alt="image"></a></p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How are zlib, gzip and zip related? (227 pts)]]></title>
            <link>https://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they</link>
            <guid>38432127</guid>
            <pubDate>Mon, 27 Nov 2023 13:39:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they">https://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they</a>, See on <a href="https://news.ycombinator.com/item?id=38432127">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
                
<p><em>Short form:</em></p>
<p><a href="http://www.pkware.com/documents/casestudies/APPNOTE.TXT" rel="noreferrer"><code>.zip</code> is an archive format</a> using, usually, the <a href="https://www.rfc-editor.org/rfc/rfc1951" rel="noreferrer">Deflate compression method</a>.  The <a href="https://www.rfc-editor.org/rfc/rfc1952" rel="noreferrer"><code>.gz</code> gzip format</a> is for single files, also using the Deflate compression method.  Often gzip is used in combination with <a href="http://www.gnu.org/software/tar/manual/html_node/Standard.html" rel="noreferrer">tar to make a compressed archive format</a>, <code>.tar.gz</code>.  The <a href="http://zlib.net/" rel="noreferrer">zlib library</a> provides Deflate compression and decompression code for use by zip, gzip, <a href="http://www.w3.org/TR/PNG/" rel="noreferrer">png</a> (which uses the <a href="https://www.rfc-editor.org/rfc/rfc1950" rel="noreferrer">zlib wrapper</a> on deflate data), and many other applications.</p>
<p><em>Long form:</em></p>
<p>The <a href="http://www.pkware.com/documents/casestudies/APPNOTE.TXT" rel="noreferrer">ZIP format</a> was developed by Phil Katz as an open format with an open specification, where his implementation, PKZIP, was shareware.  It is an archive format that stores files and their directory structure, where each file is individually compressed.  The file type is <code>.zip</code>.  The files, as well as the directory structure, can optionally be encrypted.</p>
<p>The ZIP format supports several compression methods:</p>
<pre><code>    0 - The file is stored (no compression)
    1 - The file is Shrunk
    2 - The file is Reduced with compression factor 1
    3 - The file is Reduced with compression factor 2
    4 - The file is Reduced with compression factor 3
    5 - The file is Reduced with compression factor 4
    6 - The file is Imploded
    7 - Reserved for Tokenizing compression algorithm
    8 - The file is Deflated
    9 - Enhanced Deflating using Deflate64(tm)
   10 - PKWARE Data Compression Library Imploding (old IBM TERSE)
   11 - Reserved by PKWARE
   12 - File is compressed using BZIP2 algorithm
   13 - Reserved by PKWARE
   14 - LZMA
   15 - Reserved by PKWARE
   16 - IBM z/OS CMPSC Compression
   17 - Reserved by PKWARE
   18 - File is compressed using IBM TERSE (new)
   19 - IBM LZ77 z Architecture 
   20 - deprecated (use method 93 for zstd)
   93 - Zstandard (zstd) Compression 
   94 - MP3 Compression 
   95 - XZ Compression 
   96 - JPEG variant
   97 - WavPack compressed data
   98 - PPMd version I, Rev 1
   99 - AE-x encryption marker (see APPENDIX E)
</code></pre>
<p>Methods 1 to 7 are historical and are not in use.  Methods 9 through 98 are relatively recent additions and are in varying, small amounts of use.  The only method in truly widespread use in the ZIP format is method 8, <a href="https://www.rfc-editor.org/rfc/rfc1951" rel="noreferrer">Deflate</a>, and to some smaller extent method 0, which is no compression at all.  Virtually every <code>.zip</code> file that you will come across in the wild will use exclusively methods 8 and 0, likely just method 8.  (Method 8 also has a means to effectively store the data with no compression and relatively little expansion, and Method 0 cannot be streamed whereas Method 8 can be.)</p>
<p>The <a href="http://www.digitalpreservation.gov/formats/fdd/fdd000361.shtml" rel="noreferrer">ISO/IEC 21320-1:2015 standard for file containers</a> is a restricted zip format, such as used in Java archive files (.jar), Office Open XML files (Microsoft Office .docx, .xlsx, .pptx), Office Document Format files (.odt, .ods, .odp), and EPUB files (.epub). That standard limits the compression methods to 0 and 8, as well as other constraints such as no encryption or signatures.</p>
<p>Around 1990, the <a href="http://www.info-zip.org/" rel="noreferrer">Info-ZIP group</a> wrote portable, free, open-source implementations of <code>zip</code> and <code>unzip</code> utilities, supporting compression with the Deflate format, and decompression of that and the earlier formats.  This greatly expanded the use of the <code>.zip</code> format.</p>
<p>In the early '90s, the <a href="https://www.rfc-editor.org/rfc/rfc1952" rel="noreferrer">gzip format</a> was developed as a replacement for the <a href="https://en.wikipedia.org/wiki/Compress" rel="noreferrer">Unix <code>compress</code> utility</a>, derived from the Deflate code in the Info-ZIP utilities.  Unix <code>compress</code> was designed to compress a single file or stream, appending a <code>.Z</code> to the file name.  <code>compress</code> uses the <a href="https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch" rel="noreferrer">LZW compression algorithm</a>, which at the time was under patent and its free use was in dispute by the patent holders.  Though some specific implementations of Deflate were patented by Phil Katz, the format was not, and so it was possible to write a Deflate implementation that did not infringe on any patents.  That implementation has not been so challenged in the last 20+ years.  The Unix <code>gzip</code> utility was intended as a drop-in replacement for <code>compress</code>, and in fact is able to decompress <code>compress</code>-compressed data (assuming that you were able to parse that sentence).  <code>gzip</code> appends a <code>.gz</code> to the file name.  <code>gzip</code> uses the Deflate compressed data format, which compresses quite a bit better than Unix <code>compress</code>, has very fast decompression, and adds a CRC-32 as an integrity check for the data.  The header format also permits the storage of more information than the <code>compress</code> format allowed, such as the original file name and the file modification time.</p>
<p>Though <code>compress</code> only compresses a single file, it was common to use the <code>tar</code> utility to create an archive of files, their attributes, and their directory structure into a single <code>.tar</code> file, and then compress it with <code>compress</code> to make a <code>.tar.Z</code> file.  In fact, the <code>tar</code> utility had and still has the option to do the compression at the same time, instead of having to pipe the output of <code>tar</code> to <code>compress</code>.  This all carried forward to the gzip format, and <code>tar</code> has an option to compress directly to the <code>.tar.gz</code> format.  The <code>tar.gz</code> format compresses better than the <code>.zip</code> approach, since the compression of a <code>.tar</code> can take advantage of redundancy across files, especially many small files.  <code>.tar.gz</code> is the most common archive format in use on Unix due to its very high portability, but there are more effective compression methods in use as well, so you will often see <code>.tar.bz2</code> and <code>.tar.xz</code> archives.</p>
<p>Unlike <code>.tar</code>, <code>.zip</code> has a central directory at the end, which provides a list of the contents. That and the separate compression provides random access to the individual entries in a <code>.zip</code> file. A <code>.tar</code> file would have to be decompressed and scanned from start to end in order to build a directory, which is how a <code>.tar</code> file is listed.</p>
<p>Shortly after the introduction of gzip, around the mid-1990s, the same patent dispute called into question the free use of the <code>.gif</code> image format, very widely used on bulletin boards and the World Wide Web (a new thing at the time).  So a small group created the PNG losslessly compressed image format, with file type <code>.png</code>, to replace <code>.gif</code>.  That format also uses the Deflate format for compression, which is applied after filters on the image data expose more of the redundancy.  In order to promote widespread usage of the PNG format, two free code libraries were created.  <a href="http://www.libpng.org/pub/png/libpng.html" rel="noreferrer">libpng</a> and <a href="http://zlib.net/" rel="noreferrer">zlib</a>.  libpng handled all of the features of the PNG format, and zlib provided the compression and decompression code for use by libpng, as well as for other applications.  zlib was adapted from the <code>gzip</code> code.</p>
<p>All of the mentioned patents have since expired.</p>
<p>The zlib library supports Deflate compression and decompression, and three kinds of wrapping around the deflate streams.  Those are no wrapping at all ("raw" deflate), <a href="https://www.rfc-editor.org/rfc/rfc1950" rel="noreferrer">zlib wrapping</a>, which is used in the PNG format data blocks, and gzip wrapping, to provide gzip routines for the programmer.  The main difference between zlib and gzip wrapping is that the zlib wrapping is more compact, six bytes vs. a minimum of 18 bytes for gzip, and the integrity check, Adler-32, runs faster than the CRC-32 that gzip uses.  Raw deflate is used by programs that read and write the <code>.zip</code> format, which is another format that wraps around deflate compressed data.</p>
<p>zlib is now in wide use for data transmission and storage.  For example, most HTTP transactions by servers and browsers compress and decompress the data using zlib, specifically HTTP header <code>Content-Encoding: deflate</code> means <a href="https://en.wikipedia.org/wiki/HTTP_compression#Content-Encoding_tokens" rel="noreferrer">deflate compression method wrapped inside the zlib data format</a>.</p>
<p>Different implementations of deflate can result in different compressed output for the same input data, as evidenced by the existence of selectable compression levels that allow trading off compression effectiveness for CPU time. zlib and PKZIP are not the only implementations of deflate compression and decompression. Both the <a href="http://www.7-zip.org/" rel="noreferrer">7-Zip archiving utility</a> and Google's <a href="http://github.com/google/zopfli" rel="noreferrer">zopfli library</a> have the ability to use much more CPU time than zlib in order to squeeze out the last few bits possible when using the deflate format, reducing compressed sizes by a few percent as compared to zlib's highest compression level. The <a href="http://zlib.net/pigz/" rel="noreferrer">pigz utility</a>, a parallel implementation of gzip, includes the option to use zlib (compression levels 1-9) or zopfli (compression level 11), and somewhat mitigates the time impact of using zopfli by splitting the compression of large files over multiple processors and cores.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeBSD 14.0 Delivering Great Performance Uplift (136 pts)]]></title>
            <link>https://www.phoronix.com/review/freebsd-14-epyc</link>
            <guid>38431792</guid>
            <pubDate>Mon, 27 Nov 2023 13:01:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/review/freebsd-14-epyc">https://www.phoronix.com/review/freebsd-14-epyc</a>, See on <a href="https://news.ycombinator.com/item?id=38431792">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Following last week's release of <a href="https://www.phoronix.com/news/FreeBSD-14.0-Released">FreeBSD 14.0</a>, I've begun testing out this major FreeBSD operating system update on a number of servers. What's clear so far is the performance being much improved with FreeBSD 14.0 on modern x86_64 Intel/AMD servers over FreeBSD 13.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=freebsd-14-epyc&amp;image=freebsd_14_1_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=freebsd-14-epyc&amp;image=freebsd_14_1_med" alt="FreeBSD 14 boot"></a></p>
<p>FreeBSD 14.0 is a big update with much improved hardware support, upping the ARM64 and AMD64 CPU limit up to 1024 CPU cores over the prior 256 limit, upgraded LLVM Clang toolchain, updated OpenZFS file-system support, and an assortment of other additions.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=freebsd-14-epyc&amp;image=freebsd_14_2_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=freebsd-14-epyc&amp;image=freebsd_14_2_med" alt="FreeBSD 14 installer"></a></p>
<p>I've been testing FreeBSD 14.0 out on a few AMD and Intel servers so far and the results have been looking consistently great. In this initial article is looking at the FreeBSD 13.2 vs. FreeBSD 14.0 performance on an AMD EPYC 8534P 64-core Zen 4C "Siena" server.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=freebsd-14-epyc&amp;image=freebsd_14_3_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=freebsd-14-epyc&amp;image=freebsd_14_3_med" alt="FreeBSD 14 console"></a></p>
<p>The 64-core / 128-thread server with 192GB of RAM and Micron 7450 Max 3.2TB NVMe SSD was kept the same throughout with the only change between tests being clean installs of FreeBSD 13.2 and then FreeBSD 14.0.</p>
<p><img type="image/svg+xml" width="100%" height="auto" src="https://phoronix.com/benchmark/result/freebsd-140-benchmarks-on-amd-epyc/result.svgz" alt="FreeBSD 14.0 Benchmarks On AMD EPYC"></p>
<p>With simply the newer underlying OS and keeping the applications (benchmarks) under test the same, FreeBSD 14.0 is looking very nice in the performance department.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Drive misplaces months' worth of customer data (470 pts)]]></title>
            <link>https://www.theregister.com/2023/11/27/google_drive_files_disappearing/</link>
            <guid>38431743</guid>
            <pubDate>Mon, 27 Nov 2023 12:54:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/27/google_drive_files_disappearing/">https://www.theregister.com/2023/11/27/google_drive_files_disappearing/</a>, See on <a href="https://news.ycombinator.com/item?id=38431743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Google Drive users are reporting files mysteriously disappearing from the service, with some posters on the company's support forums claiming six or more months of work have unceremoniously vanished.</p>
<p>The issue has been <a target="_blank" rel="nofollow" href="https://support.google.com/drive/thread/245055606/google-drive-files-suddenly-disappeared-the-drive-literally-went-back-to-condition-in-may-2023?hl=en">rumbling for a few days</a>, with one user logging into Google Drive and finding things as they were in May 2023.</p>
<p>According to the poster, almost everything saved since then has gone, and attempts at recovery failed.</p>

    

<p>Others <a target="_blank" href="https://support.google.com/drive/thread/245055606?hl=en&amp;msgid=245207929">chimed in</a> with similar experiences, and one <a target="_blank" href="https://support.google.com/drive/thread/245055606?hl=en&amp;msgid=245226440">claimed</a> that six months of business data had gone AWOL.</p>

        


        

<p>There is little information regarding what has happened; some users reported that synchronization had simply stopped working, so the cloud storage was out of date. Others could get some of their information back by fiddling with cached files, although the limited advice on offer for the affected was to leave things well alone until engineers come up with a solution.</p>
<p>A <a target="_blank" href="https://support.google.com/drive/thread/245055606?hl=en&amp;msgid=245673190">message</a> purporting to be from Google support also advised not to make changes to the root/data folder while engineers investigat the issue. Some users speculated that it might be related to accounts being spontaneously dropped. We've asked Google for its thoughts and will update should the search giant respond.</p>
<ul>

<li><a href="https://www.theregister.com/2023/05/10/google_cloud_paris_outage_persists/">Google Cloud's watery Parisian outage enters third week, with no end in sight</a></li>

<li><a href="https://www.theregister.com/2023/11/15/google_workspace_weaknesses_allow_plaintext/">Google Workspace weaknesses allow plaintext password theft</a></li>

<li><a href="https://www.theregister.com/2023/10/03/chromebook_plus/">Google doubles minimum RAM and disk in 'Chromebook Plus' spec</a></li>

<li><a href="https://www.theregister.com/2023/09/20/googles_ai_chatbot_bard/">Google Bard can now tap into your Gmail, Docs, more</a></li>
</ul>
<p>In the meantime, the experience for affected users is a reminder that just because files are being stored in the cloud, there is no guarantee that they are safe. European cloud hosting provider OVH <a target="_blank" href="https://www.theregister.com/2021/03/10/ovh/">suffered a disastrous fire</a> in 2021 that left some customers scrambling for backups and disaster recovery plans.</p>
<p>Google itself has suffered the odd outage or two over the years. Earlier in 2023, the company's <a target="_blank" href="https://www.theregister.com/2023/05/10/google_cloud_paris_outage_persists/">europe-west9 region took a shower</a> after water made its presence felt inside a Parisian Google Cloud datacenter.</p>

        

<p>Ultimately, trusting one's data – particularly data on which a business depends – to any sort of cloud storage should only be done after fully understanding the implications of the services' terms and conditions. Just because the files have been uploaded one day does not necessarily mean they will still be there – or recoverable – the next. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$10M AI Mathematical Olympiad Prize (257 pts)]]></title>
            <link>https://aimoprize.com/</link>
            <guid>38431482</guid>
            <pubDate>Mon, 27 Nov 2023 12:25:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aimoprize.com/">https://aimoprize.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38431482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><details><summary>Menu</summary><a href="https://aimoprize.com/">AI-MO Prize</a><a href="https://aimoprize.com/about">About</a><a href="https://aimoprize.com/supporters">Supporters</a><a href="https://aimoprize.com/get-involved">Get Involved</a></details><h2>$10mn AI Mathematical Olympiad Prize Launches</h2><div><p>🌍</p><p><a href="https://xtxmarkets.com/" target="_blank">XTX Markets</a> is launching a new $10mn challenge fund, the <b>Artificial Intelligence Mathematical Olympiad Prize</b> (AI-MO Prize). The fund intends to spur the development of AI models that can reason mathematically, leading to the creation of a publicly-shared AI model capable of winning a gold medal in the <a href="https://www.imo-official.org/" target="_blank">International Mathematical Olympiad (IMO)</a>.</p></div><div><p>🏆</p><div><p>The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the IMO.</p><p>There will also be a series of progress prizes, totalling up to $5mn, for publicly-shared AI models that achieve key milestones towards the grand prize. </p></div></div><div><div><p>The AI-MO Prize [..] will help compare different AI problem solving strategies at a technical level, in a manner that will be accessible and appealing to the broader public.</p><p><a href="https://aimoprize.com/supporters">view more</a></p></div><div><p>I am sure that many people will be following the AI-MO Prize with great excitement, to see when, in the future, AI will match the world's brightest young minds.</p><p><a href="https://aimoprize.com/supporters">view more</a></p><p><b>Gregor Dolinar</b>, IMO President</p></div></div><div><p>📈</p><div><p>The prizes will be designed by an <a href="https://aimoprize.com/get-involved">AI-MO Advisory Committee</a>, including mathematicians, AI and machine learning experts, and experienced Olympiad problem-setters.</p><p>The first AI-MO approved competitions will open to participants in early 2024. There will be a presentation of progress at <a href="https://www.imo2024.uk/" target="_blank">the 65<sup>th</sup> IMO</a>, which will be held in Bath, England in July 2024.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wealth Systems in RPGs (103 pts)]]></title>
            <link>https://troypress.com/wealth-systems-in-rpgs/</link>
            <guid>38431402</guid>
            <pubDate>Mon, 27 Nov 2023 12:16:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://troypress.com/wealth-systems-in-rpgs/">https://troypress.com/wealth-systems-in-rpgs/</a>, See on <a href="https://news.ycombinator.com/item?id=38431402">Hacker News</a></p>
Couldn't get https://troypress.com/wealth-systems-in-rpgs/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Tata Consultancy Services ordered to cough up $210M in code theft trial (199 pts)]]></title>
            <link>https://www.theregister.com/2023/11/24/tata_210m_code_theft/</link>
            <guid>38430974</guid>
            <pubDate>Mon, 27 Nov 2023 11:18:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/24/tata_210m_code_theft/">https://www.theregister.com/2023/11/24/tata_210m_code_theft/</a>, See on <a href="https://news.ycombinator.com/item?id=38430974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>A jury has sided with Computer Sciences Corporation (CSC) against Tata Consultancy Services (TCS) over the theft of source code and documentation. A total of $210 million was this week awarded.</p>
<p>According to the <a target="_blank" href="https://regmedia.co.uk/2023/11/23/verdict_3_19cv00970.pdf">verdict</a> [PDF], a Texas jury agreed that TCS had "willfully and maliciously" misappropriated both source and confidential documentation by "improper means," awarding CSC $140 million in damages, with another $70 million tacked on for TCS's "unjust enrichment."</p>
<p>The <a target="_blank" href="https://regmedia.co.uk/2023/11/22/csc_complaint.pdf">complaint</a> [PDF] was filed in April 2019 regarding CSC's VANTAGE-ONE and CyberLife software platforms. CSC had licensed these software platforms to Transamerica Corporation, a life insurance holding company, to whom Tata – used here to collectively refer to Tata Consultancy Services Limited and Tata America International Corporation – began providing maintenance services.</p>

    

<p>In 2014, CSC and Transamerica signed off on a Third-Party Access Addendum that would allow Tata to alter CSC's software, but only for the benefit of its customer – Transamerica.</p>

        


        

<p>All was well until 2016, when Transamerica decided it needed to refresh its software. CSC and Tata both put in bids. CSC lost, and Tata won with its own software platform called BaNCS.</p>
<p>The circumstances got sticky at this point, not least because Tata hired more than 2,000 Transamerica employees. CSC alleged that these former employees had access to its code and documents, and forwarded them on to the Tata BaNCS development team.</p>

        

<p>The situation escalated in 2019, when a CSC employee was accidentally copied in on an email between Tata and Transamerica showing that Tata was accessing confidential information, according to CSC. The company then began legal proceedings.</p>
<ul>

<li><a href="https://www.theregister.com/2022/06/29/tcs_internet_of_actions_haptics/">Tata Consultancy Services to create touchy feely 'Internet of Actions'</a></li>

<li><a href="https://www.theregister.com/2022/04/11/tata_neu_debut/">Indian giant Tata fluffs its lines as it takes on Amazon and Walmart</a></li>

<li><a href="https://www.theregister.com/2021/06/23/tata_5g_airtel/">Indian mega-corp Tata unveils surprise 5G networking business</a></li>

<li><a href="https://www.theregister.com/2021/04/14/tcs_fy2021/">Tata Consultancy Services added just 7* customers in FY21 ... and 40,000 staff as revenue, profit flattened</a></li>
</ul>
<p>Documents and motions have been exchanged in the years since as Tata sought to get the case thrown out while CSC's claims were upheld. Eventually, it went to a jury trial, which found for CSC.</p>
<p>CSC, which dates back to 1968, was <a target="_blank" href="https://www.theregister.com/2017/04/03/hpe_csc_becomes_dxc/">merged</a> with the Enterprise Services business of Hewlett Packard Enterprise (HPE) to form DXC in 2017. The corporate mash-up has had its own legal troubles – a <a target="_blank" href="https://www.theregister.com/2023/01/13/hpe_may_have_to_answer/">lawsuit</a> was launched in 2019 by investors concerned over layoffs following the merger.</p>
<p>CSC's April 2019 complaint is highly critical of TCS. It alleged: "Misappropriating sophisticated business software is, apparently, TCS' method of entering new business markets in the United States," citing the example of Epic Systems Corporation.</p>
<p>Epic, a healthcare software provider, kicked off litigation in 2014, alleging that "TCS entities accessed Epic's web portal without authorization while servicing a mutual client." According to CSC's complaint, the information gleaned was then used to develop a competing software platform. In that instance, the jury agreed with Epic and in October 2017 awarded Epic substantial damages.</p>

        

<p>However, the champagne corks won't be popping at CSC just yet. If the Epic experience is anything to go by – the decision was appealed – there will likely be legal twists and turns aplenty before payments are made and the case is closed. ®</p>                                
                    </div></div>]]></description>
        </item>
    </channel>
</rss>