<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 25 Sep 2023 17:00:16 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[It's time to let go, Apache Software Foundation (144 pts)]]></title>
            <link>https://rocket9labs.com/post/its-time-to-let-go-apache-software-foundation/</link>
            <guid>37645160</guid>
            <pubDate>Mon, 25 Sep 2023 15:12:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rocket9labs.com/post/its-time-to-let-go-apache-software-foundation/">https://rocket9labs.com/post/its-time-to-let-go-apache-software-foundation/</a>, See on <a href="https://news.ycombinator.com/item?id=37645160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
	<article>
		
		<div>
			<p><a href="https://liberapay.com/rocket9labs.com"><img src="https://img.shields.io/liberapay/receives/rocket9labs.com.svg?logo=liberapay" alt="Donate"></a></p>
<p><a href="https://en.wikipedia.org/wiki/The_Apache_Software_Foundation">The Apache Software Foundation</a>
offers a suite of office productivity software named <a href="https://en.wikipedia.org/wiki/Apache_Open_Office">Apache Open Office</a>.
Based on the <a href="https://www.openoffice.org/download/">download page</a>, you would
never guess the last major release of the software was made available in 2014.</p>
<p>With that bit of release history in mind, would it be fair to consider Apache
Open Office as an un-maintained project? In this blog post, I share a quick
recap of the history behind Apache Open Office, and my opinion on why The
Apache Software Foundation’s actions may be masking the answer to this question.</p>
<h2 id="in-the-beginning-staroffice-was-created">In the beginning, StarOffice was created</h2>
<p>A proprietary office suite was developed in 1985 by a company named <a href="https://en.wikipedia.org/wiki/Star_Division">Star Division</a>,
aptly named StarOffice.</p>
<h2 id="the-sun-shined-and-openofficeorg-was-released">The SUN shined, and OpenOffice.org was released</h2>
<p>In the year 2000, <a href="https://en.wikipedia.org/wiki/Sun_Microsystems">Sun Microsystems</a>
released the source code of StarOffice for free. This resulted in the first
release of <a href="https://en.wikipedia.org/wiki/OpenOffice.org">OpenOffice.org</a> the following year.</p>
<h2 id="libreoffice-joins-the-party">LibreOffice joins the party</h2>
<p><a href="https://en.wikipedia.org/wiki/LibreOffice">LibreOffice</a> was first released in
2010 based on the OpenOffice.org source code. LibreOffice is actively
maintained by <a href="https://en.wikipedia.org/wiki/The_Document_Foundation">The Document Foundation</a>,
a non-profit created by members of the OpenOffice.org community for the express
purpose of managing and developing LibreOffice.</p>
<h2 id="oracle-gives-openofficeorg-to-the-apache-software-foundation">Oracle gives OpenOffice.org to The Apache Software Foundation</h2>
<p><a href="https://en.wikipedia.org/wiki/Oracle_Corporation">Oracle</a>, having acquired Sun
Microsystems in 2010, now owned the OpenOffice.org trademarks. The year
following the acquisition, Oracle provided the OpenOffice.org trademarks
and any related Oracle-owned code to The Apache Software Foundation in 2011.
This resulted in the creation of Apache Open Office.</p>
<h2 id="apache-open-office-dies-and-refuses-to-leave">Apache Open Office dies, and refuses to leave</h2>
<p>Between its first release with version 3.4 in 2012, and its last major release
with version 4.1 in 2014, Apache Open Office integrated <a href="https://en.wikipedia.org/wiki/IBM_Lotus_Symphony">IBM Lotus Symphony</a>,
after it was donated to The Apache Software Foundation, added a reworked sidebar
and some other new features, as documented in the <a href="https://cwiki.apache.org/confluence/display/OOOUSERS/AOO+4.1+Release+Notes">4.1 release notes</a>.</p>
<p>Since 2014… Bug fixes, dictionary updates, bug fixes, dictionary updates,
whitespace “fixes”, dictionary updates, dictionary updates and <strong>did I
mention dictionary updates</strong>!?</p>
<h2 id="things-start-to-get-weird">Things start to get weird</h2>
<p>You might want to sit down before opening the next link. Take a look at the
<a href="https://github.com/apache/openoffice/commits/trunk">apache/openoffice</a> commits
made over the last several years.</p>
<p>What do we find? A lot of commits that don’t actually amount to much at all.
In many cases, the commits <strong>don’t even make any change to the program</strong>,
because they are only changing the blank space that surrounds the source code.</p>
<p>Why would someone do this? Two possible reasons:</p>
<ol>
<li>There are legitimate whitespace issues that need to be addressed.</li>
<li>There is an incentive to make a project appear as though it were active, when it is actually inactive.</li>
</ol>
<p>While the first is fair to assume in most cases, when we look at the list of
commits made to the repository, we find that whitespace changes are not just
part of the commits that Apache Open Office has been receiving, whitespace
changes make up a substantial amount of the commits added to the repository.</p>
<p>Projects become unmaintained every day. This is a fact of life, and is not the
issue I am taking with The Apache Software Foundation. It is the way the
foundation, and its contributors, do not disclose information relating to the
lack of substantial updates or changes for nearly a decade, and seems to
intentionally mask the lack of development.</p>
<h2 id="what-we-can-do-about-it">What we can do about it</h2>
<p>We can tell The Apache Software Foundation that we, as a community of users, do
not support the foundation’s actions in regard to their management of Apache
Open Office. If this blog post motivated you, send an email to <a href="mailto:apache@apache.org">apache@apache.org</a>
saying something along the lines of:</p>
<blockquote>
<p>To whom it may concern,</p>
<p>Apache Open Office has not received substantial updates nor changes in nearly
a decade, yet there is no mention of this anywhere on the download page. In
the best interest of the community, please consider mentioning this
information, as well as providing a link for users to download other actively
maintained office software.</p>
<p>The Apache Open Office GitHub repository receives regular commits, but these
changes seem to largely be whitespace-only. This gives the impression that
the repository is more active than it really is, as non-substantial changes
seem to make up a large number of the commits added. Please archive the
repository if active development has ceased.</p>
<p>Sincerely,</p>
</blockquote>

		</div>
	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KSP2 is spamming the Windows Registry until the game stops working permanently (141 pts)]]></title>
            <link>https://forum.kerbalspaceprogram.com/topic/219607-ksp2-is-spamming-the-windows-registry-over-weeksmonths-until-the-game-will-stop-working-permanently/</link>
            <guid>37644952</guid>
            <pubDate>Mon, 25 Sep 2023 15:00:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forum.kerbalspaceprogram.com/topic/219607-ksp2-is-spamming-the-windows-registry-over-weeksmonths-until-the-game-will-stop-working-permanently/">https://forum.kerbalspaceprogram.com/topic/219607-ksp2-is-spamming-the-windows-registry-over-weeksmonths-until-the-game-will-stop-working-permanently/</a>, See on <a href="https://news.ycombinator.com/item?id=37644952">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="commentContent" data-controller="core.front.core.lightboxedImages">
<p>
There are 260,962 chunks of that spam in the registry entry file , and it is all location and rotation data.&nbsp;<br>
{"LatLong":{"x":-0.8384310007095337,"y":-75.07933807373047},"RotationEuler":{"x":0.0,"y":0.0,"z":0.0},"Rotation":88.0,"VerticalOffset":0.0,"LocalScale":{"x":800.0,"y":120.0,"z":800.0}}
</p>
<p>
{"LatLong":{"x":-0.8447363972663879,"y":-75.01181030273438},"RotationEuler":{"x":0.0,"y":0.0,"z":0.0},"Rotation":83.0,"VerticalOffset":0.0,"LocalScale":{"x":700.0,"y":150.0,"z":800.0}}
</p>
<p>
{"LatLong":{"x":-0.814041793346405,"y":-75.11915588378906},"RotationEuler":{"x":0.0,"y":0.0,"z":0.0},"Rotation":140.0,"VerticalOffset":0.0,"LocalScale":{"x":500.0,"y":200.0,"z":600.0}}
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minecraft Wiki has forked from Fandom (262 pts)]]></title>
            <link>https://minecraft.wiki/w/Minecraft_Wiki:Moving_from_Fandom</link>
            <guid>37644047</guid>
            <pubDate>Mon, 25 Sep 2023 14:10:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minecraft.wiki/w/Minecraft_Wiki:Moving_from_Fandom">https://minecraft.wiki/w/Minecraft_Wiki:Moving_from_Fandom</a>, See on <a href="https://news.ycombinator.com/item?id=37644047">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p>After <a href="https://minecraft.wiki/w/Minecraft_Wiki:Moving_from_Fandom/First_discussion" title="Minecraft Wiki:Moving from Fandom/First discussion">several</a> <a href="https://minecraft.wiki/w/Minecraft_Wiki:Moving_from_Fandom/Second_discussion" title="Minecraft Wiki:Moving from Fandom/Second discussion">discussions</a>, we are excited to announce that the Minecraft Wiki has now moved from Fandom to <b>minecraft.wiki</b> – all of the information about the game can now be found at the new location!
</p><p><br>
By moving to a new place, we are able to bring lots of improvements to the wiki. For example, here are some changes you’ll find when visiting the new wiki!
</p>
<dl><dt>A new skin!</dt>
<dd>No more ugly yellow sidebar! We’ve designed a familiar yet fresh look to the wiki to make it really pop. There’s also a dark mode option (located in the top-right corner of the webpage) and a fixed width option (currently just for logged-in users under “gadgets” in your user settings). We also have a new logo to celebrate!</dd></dl>
<dl><dt>Faster load times!</dt>
<dd>Our new host has better built out infrastructure that makes the site load <i>significantly</i> faster than Fandom, especially in different parts of the world and with slower internet connections. This is also thanks to a cleaner website interface that doesn’t require as many resources as the Fandom website does with all its additional non-wiki features.</dd></dl>
<dl><dt>Fewer ads!</dt>
<dd>The new site won’t have popups, quizzes, unrelated articles or videos ads; only one ad at most will show up per page.</dd></dl>
<dl><dd>Note that for the moment, there will not be any ads at all as we still work on getting the ad infrastructure fully set up. We will make sure to notify the wiki community and be as transparent as possible about the placement and selection of the ad.</dd></dl>
<dl><dt>Improved search functionality!</dt>
<dd>You might have noticed that the search results on Fandom are often less than ideal. With our move away from Fandom we’re now able to use a much more powerful and user-friendly search engine again. For example, try to find out which Java snapshot armor trims were added in by searching for “armor trim snapshot”.</dd></dl>
<dl><dt>No more age popup!</dt>
<dd>Unlike Fandom, we won’t be forcing you to tell us if you’re a child or an adult.</dd></dl>
<dl><dt>Anonymous editing is back!</dt>
<dd>You will no longer need to create an account to help improve the wiki.</dd></dl>
<h2><span id="We_need_your_help!">We need your help!</span></h2>
<p>Unfortunately, because Fandom does not close wikis that have moved away, the old Fandom wiki will remain in place and continue to appear in search results. The old domains “minecraft.gamepedia.com” and “minecraftwiki.net” will still redirect to the Fandom wiki as well.
</p><p>As such, for the new wiki to be successful, we need your help! Here are a few ways you can help out:
</p>
<ul><li><b>Spread the word!</b> Tell your friends that we’ve moved to a new place!</li>
<li><b>Don’t click on Fandom links.</b> In search results, always pick <b>minecraft.wiki</b> links instead of Fandom ones. This tells Google and other search engines which site is better for users.</li>
<li><b>Don't use the old domains.</b> Change any existing “minecraftwiki.net”, “minecraft.gamepedia.com”, or “minecraft.fandom.com” links to <b>minecraft.wiki</b> – this helps us become more established and show up higher in search results.</li>
<li><b>Help improve the wiki!</b> At the new wiki, you don’t even have to create an account to make edits! Need help with editing? Come join our <a target="_blank" rel="nofollow noreferrer noopener" href="https://discord.com/invite/fGdE5ZE">Discord server</a> and ask some questions, or check out <a href="https://minecraft.wiki/w/Minecraft_Wiki:How_to_help" title="Minecraft Wiki:How to help">this help page</a>.</li></ul>
<p>You can also try out the <a target="_blank" rel="nofollow noreferrer noopener" href="https://getindie.wiki/">Indie Wiki Buddy</a> browser extension, which will redirect you there automatically, as well as hide the Fandom wiki on Google and other search engines.
</p>
<h2><span id="Migrating_Gamepedia/Fandom_accounts_to_the_new_wiki">Migrating Gamepedia/Fandom accounts to the new wiki</span></h2>
<p>If you’d like to migrate your account to the new wiki, go to <a href="https://minecraft.wiki/w/Special:MigrateUserAccount" title="Special:MigrateUserAccount">this page</a> and follow the steps there. You’ll be prompted to input your name and verify your identity on the Fandom wiki. It should only take a few minutes.
</p><p>All of your previous contributions will be kept when you migrate your account. However your user preferences (including email and talk page signature) unfortunately cannot be transferred and you will need to set them again.
</p><p>In case you have issues with this, please let us know on our <a target="_blank" rel="nofollow noreferrer noopener" href="https://discord.com/invite/fGdE5ZE">Discord server</a>.
</p>
<h2><span id="Who_is_hosting_the_new_wiki?">Who is hosting the new wiki?</span></h2>
<p>The new Minecraft Wiki will be hosted by <a target="_blank" rel="nofollow noreferrer noopener" href="https://weirdgloop.org/">Weird Gloop</a>, the company that hosts the <a href="https://runescape.wiki/">RuneScape wikis</a>. There are a number of reasons why it was chosen as a host, which you can read about on the discussion page <a href="https://minecraft.wiki/w/Minecraft_Wiki:Moving_from_Fandom/Second_discussion" title="Minecraft Wiki:Moving from Fandom/Second discussion">here</a>.
</p><p>The long and short of it is that our new host has a minimal amount of ads, a strong set of technical infrastructure, lots of transparency, and a strong track record regarding the SEO competition with Fandom for page ranking. Weird Gloop offers us the autonomy we would get from hosting the wiki ourselves, but they also have the experience and expertise needed to set up and maintain the infrastructure behind the wiki, which we do not have ourselves.
</p>
<h2><span id="What_about_the_non-English_wikis?">What about the non-English wikis?</span></h2>
<p>For the moment, only the English Minecraft Wiki has moved away from Fandom. While we are fortunate enough to be able to move, we also understand that not all language wikis are able to or wish to move as well.
</p><p>Some non-English wikis are also planning to move to the new location in the future. However, others have decided to stay at Fandom for now, or are still discussing whether they want to move or not. You can find out what the current position of each wiki is by checking out their respective community portals and/or Discord servers.
</p><p>To all the community, please respect the decisions of those who choose to stay, as we are all still a part of the Minecraft community!
</p>
<h2><span id="Comments_and_discussion">Comments and discussion</span></h2>
<p>If you have any further questions or comments, feel free to put them on the <a href="https://minecraft.wiki/w/Minecraft_Wiki_talk:Moving_from_Fandom" title="Minecraft Wiki talk:Moving from Fandom">discussion page</a>!
</p>
<!-- 
NewPP limit report
Parsed by mediawiki‐7cf598bff5‐p2k4t
Cached time: 20230925073513
Cache expiry: 172800
Reduced expiry: false
Complications: []
[SMW] In‐text annotation parser time: 0 seconds
CPU time usage: 0.005 seconds
Real time usage: 0.006 seconds
Preprocessor visited node count: 20/1000000
Post‐expand include size: 0/4194304 bytes
Template argument size: 0/4194304 bytes
Highest expansion depth: 2/100
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 0/5000000 bytes
ExtLoops count: 0/50
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key en_mcwiki:pcache:idhash:222584-0!canonical and timestamp 20230925073513 and revision id 2316447.
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What was behind Microsoft's layoffs of over 20k people in the last year? (169 pts)]]></title>
            <link>https://twitter.com/TeamBlind/status/1706266044871086271</link>
            <guid>37643608</guid>
            <pubDate>Mon, 25 Sep 2023 13:38:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/TeamBlind/status/1706266044871086271">https://twitter.com/TeamBlind/status/1706266044871086271</a>, See on <a href="https://news.ycombinator.com/item?id=37643608">Hacker News</a></p>
Couldn't get https://twitter.com/TeamBlind/status/1706266044871086271: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: E-Ink Day Schedule (138 pts)]]></title>
            <link>https://github.com/davidhampgonsalves/life-dashboard</link>
            <guid>37642671</guid>
            <pubDate>Mon, 25 Sep 2023 12:31:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/davidhampgonsalves/life-dashboard">https://github.com/davidhampgonsalves/life-dashboard</a>, See on <a href="https://news.ycombinator.com/item?id=37642671">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/davidhampgonsalves/life-dashboard/raw/master/example.jpg"><img src="https://github.com/davidhampgonsalves/life-dashboard/raw/master/example.jpg"></a></p>
<h2 tabindex="-1" id="user-content-life-dashboard" dir="auto"><a href="#life-dashboard">Life Dashboard</a></h2>
<p dir="auto">Low power, heads up display for every day life running on a Kindle.</p>
<h2 tabindex="-1" id="user-content-details" dir="auto"><a href="#details">Details</a></h2>
<p dir="auto">Second hand Kindles are waiting in drawers for someone to repurpose them into something great. Boasting large e-ink screens, wifi connectivity and ARM processors they are an amazing hacking platform.</p>
<p dir="auto">(This is the second version of this project, see the post about the original <a href="https://www.davidhampgonsalves.com/life-dashboard/" rel="nofollow">here</a>)</p>
<h2 tabindex="-1" id="user-content-v2-rewrite-and-compromises" dir="auto"><a href="#v2-rewrite-and-compromises">V2 Rewrite and Compromises</a></h2>
<p dir="auto">Ideally this dashboard would generate and display its image on its own. The issue with doing this originally was that the Kindles ability to display images (via eips) requires they be in a strange format. A few yars back when I started this it was hard to get GoLang to generate this format but it was easy to cross compile GoLang to the target ARM-7 softfloat arch. On the other hand Rust could generate the image but it was a pain to setup the cross compiler toolchain (also connecting to Google API's wasn't well supported).</p>
<p dir="auto">In the 5 years that followed the dashboard was a great tool but as API services would die (Magicseaweed, Forecast.io, DarkSky, etc) it would break. Sometimes that would require changes to the Rust front end and I would have to setup the cross compiling toolchain on each new machine I was using and eventually this got annoying.</p>
<p dir="auto">I found out about <a href="https://github.com/NiLuJe/FBInk">FBInk</a> which has Go bindings and decided that using that I could use it to do text layout and print the resulting PNG's to the screen. Unfortunately I found that GoLangs OpenFont lib crashes when run on the kindle and that these old arm archetectures aren't well supported. This seemed like an unstable footing to build on.</p>
<p dir="auto">This led me to my current compromise. I use FBInk on the kindle to display the images after curling them from a API Gateway/Lambda backend. This gives me a low friction way to update the API logic without needing to touch the kindle or cross compile anything. I also was able to use GoLangs <a href="https://github.com/tdewolff/canvas/">tdewolff/canvas</a> which provides nice text setting and image generation tooling. I think is the right balance to keep this device productive for another 5+ years.</p>
<h2 tabindex="-1" id="user-content-deploy-via-terraform" dir="auto"><a href="#deploy-via-terraform">Deploy (via Terraform)</a></h2>
<p dir="auto"><code>./deploy.sh</code></p>
<h2 tabindex="-1" id="user-content-run-locally" dir="auto"><a href="#run-locally">Run Locally</a></h2>
<p dir="auto"><code>go test -c -o ldb.test ./pkg/ &amp;&amp; ./ldb.test &amp;&amp; open ldb.test.png</code></p>
<h2 tabindex="-1" id="user-content-setup" dir="auto"><a href="#setup">Setup</a></h2>
<h2 tabindex="-1" id="user-content-jailbreak-and-setup-ssh" dir="auto"><a href="#jailbreak-and-setup-ssh">Jailbreak and Setup SSH</a></h2>
<p dir="auto">See (<a href="https://wiki.mobileread.com/wiki/Kindle4NTHacking" rel="nofollow">https://wiki.mobileread.com/wiki/Kindle4NTHacking</a>) and if bricked then use Kubrick in VM to restore.</p>
<h2 tabindex="-1" id="user-content-ssh-over-wifi" dir="auto"><a href="#ssh-over-wifi">SSH over wifi</a></h2>
<p dir="auto">Hold power button till light flashes, then press power button a few times to restart back to normal e-reader mode. SSH server will be running and wifi will auto connect.</p>
<h2 tabindex="-1" id="user-content-install" dir="auto"><a href="#install">Install</a></h2>
<ul dir="auto">
<li>Install Fbink.</li>
<li>Setup Wifi on Kindle and then run <code>install.sh</code>.</li>
</ul>
<h2 tabindex="-1" id="user-content-copy-books-to-kindle-vis-scp" dir="auto"><a href="#copy-books-to-kindle-vis-scp">Copy books to Kindle vis SCP</a></h2>
<div data-snippet-clipboard-copy-content="scp book.mobi root@192.168.15.244:/mnt/base-us/documents/
dbus-send --system /default com.lab126.powerd.resuming int32:1"><pre><code>scp book.mobi root@192.168.15.244:/mnt/base-us/documents/
dbus-send --system /default com.lab126.powerd.resuming int32:1
</code></pre></div>
<h2 tabindex="-1" id="user-content-frame" dir="auto"><a href="#frame">Frame</a></h2>
<p dir="auto">3D printed using wood filled filliment - <a href="https://www.thingiverse.com/thing:2536906" rel="nofollow">https://www.thingiverse.com/thing:2536906</a></p>
<h2 tabindex="-1" id="user-content-notes" dir="auto"><a href="#notes">Notes</a></h2>
<p dir="auto">The <a href="https://www.mobileread.com/forums/" rel="nofollow">mobileread forumn</a> is the place for mobile reader hacking.</p>
<p dir="auto">I could have avoided the backend of this project and only used the Kindle but I had already created it for another project and saved time to reuse it.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rhythm 0 (198 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Rhythm_0</link>
            <guid>37642610</guid>
            <pubDate>Mon, 25 Sep 2023 12:26:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Rhythm_0">https://en.wikipedia.org/wiki/Rhythm_0</a>, See on <a href="https://news.ycombinator.com/item?id=37642610">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text" lang="en" dir="ltr">
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg/220px-Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg" decoding="async" width="220" height="147" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg/330px-Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg/440px-Marina_Abramovi%C4%87_-_The_Artist_Is_Present_-_Viennale_2012.jpg 2x" data-file-width="3600" data-file-height="2400"></a><figcaption>Artist Marina Abramović in 2012</figcaption></figure>
<p><i><b>Rhythm 0</b></i> was a six-hour work of <a href="https://en.wikipedia.org/wiki/Performance_art" title="Performance art">performance art</a> by Serbian artist <a href="https://en.wikipedia.org/wiki/Marina_Abramovi%C4%87" title="Marina Abramović">Marina Abramović</a> in  <a href="https://en.wikipedia.org/wiki/Naples" title="Naples">Naples</a> in 1974.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> The work involved Abramović standing still while the audience was invited to do to her whatever they wished, using one of 72 objects she had placed on a table. These included a rose, feather, perfume, honey, bread, grapes, wine, scissors, a scalpel, nails, a metal bar, a gun, and a bullet.<sup id="cite_ref-Abramovic01:00mins_2-0"><a href="#cite_note-Abramovic01:00mins-2">[2]</a></sup><sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>
</p><p>There were no separate stages. Abramović and the visitors stood in the same space, making it clear that the latter were part of the work.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> The purpose of the piece, she said, was to find out how far the public would go: "What is the public about and what are they going to do in this kind of situation?"<sup id="cite_ref-Abramovic00:00mins_5-0"><a href="#cite_note-Abramovic00:00mins-5">[5]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Performance">Performance</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Rhythm_0&amp;action=edit&amp;section=1" title="Edit section: Performance">edit</a><span>]</span></span></h2>
<p>Her instructions were  
</p>
<blockquote>
<p>Instructions:<br>
There are 72 objects on the table that one can use on me as desired.<br>
Performance.<br>
I am the object.<br>
During this period I take full responsibility.<br>
</p><p>
Duration: 6 hours (8 pm – 2 am).<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup></p></blockquote>
<p>Abramović said the work "pushed her body to the limits".<sup id="cite_ref-Abramovic00:00mins_5-1"><a href="#cite_note-Abramovic00:00mins-5">[5]</a></sup> Visitors were gentle to begin with, offering her a rose or a kiss.<sup id="cite_ref-Abramovic01:00mins_2-1"><a href="#cite_note-Abramovic01:00mins-2">[2]</a></sup> Art critic <a href="https://en.wikipedia.org/wiki/Thomas_McEvilley" title="Thomas McEvilley">Thomas McEvilley</a>, who was present, wrote:
</p>
<blockquote><p>It began tamely. Someone turned her around. Someone thrust her arms into the air. Someone touched her somewhat intimately. The Neapolitan night began to heat up. In the third hour all her clothes were cut from her with razor blades. In the fourth hour the same blades began to explore her skin. Her throat was slashed so <a href="https://en.wikipedia.org/wiki/Clinical_vampirism" title="Clinical vampirism">someone could suck her blood</a>. Various minor sexual assaults were carried out on her body. She was so committed to the piece that she would not have resisted rape or murder. Faced with her abdication of will, with its implied collapse of human psychology, a protective group began to define itself in the audience. When a loaded gun was thrust to Marina's head and her own finger was being worked around the trigger, a fight broke out between the audience factions."<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup></p></blockquote>
<p>As Abramović described it later: "What I learned was that ... if you leave it up to the audience, they can kill you ... I felt really violated: they cut up my clothes, stuck rose thorns in my stomach, one person aimed the gun at my head, and another took it away. It created an aggressive atmosphere. After exactly 6 hours, as planned, I stood up and started walking toward the audience. Everyone ran away, to escape an actual confrontation."<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>
</p><p>When the gallery announced the work was over, and Abramović began to move again, she said the audience left, unable to face her as a person.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>
</p>
<h2><span id="Reception">Reception</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Rhythm_0&amp;action=edit&amp;section=2" title="Edit section: Reception">edit</a><span>]</span></span></h2>
<p><i>Rhythm 0</i> ranked ninth on a <i><a href="https://en.wikipedia.org/wiki/Complex_(magazine)" title="Complex (magazine)">Complex</a></i> list of the greatest works of performance art ever done.<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Rhythm_0&amp;action=edit&amp;section=3" title="Edit section: See also">edit</a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Endurance_art" title="Endurance art">Endurance art</a></li>
<li><a href="https://en.wikipedia.org/wiki/The_Death_of_The_Artist" title="The Death of The Artist">The Death of The Artist</a></li>
<li><a href="https://en.wikipedia.org/wiki/Empathy_and_Prostitution" title="Empathy and Prostitution">Empathy and Prostitution</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stanford_prison_experiment" title="Stanford prison experiment">Stanford prison experiment</a></li>
<li><a href="https://en.wikipedia.org/wiki/Milgram_experiment" title="Milgram experiment">Milgram experiment</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Rhythm_0&amp;action=edit&amp;section=4" title="Edit section: References">edit</a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite id="CITEREFAbramovićThompsonWeslien2006">Abramović, Marina; Thompson, Chris; Weslien, Katarina (2006). "Pure Raw: Performance, Pedagogy, and (Re)presentation". <i>PAJ</i>. <b>28</b> (1): 29–50. <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/4139995">4139995</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PAJ&amp;rft.atitle=Pure+Raw%3A+Performance%2C+Pedagogy%2C+and+%28Re%29presentation&amp;rft.volume=28&amp;rft.issue=1&amp;rft.pages=29-50&amp;rft.date=2006&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F4139995%23id-name%3DJSTOR&amp;rft.aulast=Abramovi%C4%87&amp;rft.aufirst=Marina&amp;rft.au=Thompson%2C+Chris&amp;rft.au=Weslien%2C+Katarina&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARhythm+0"></span></span>
</li>
<li id="cite_note-Abramovic01:00mins-2"><span>^ <a href="#cite_ref-Abramovic01:00mins_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Abramovic01:00mins_2-1"><sup><i><b>b</b></i></sup></a></span> <span><a rel="nofollow" href="https://vimeo.com/71952791">"Marina Abramović on <i>Rhythm 0</i> (1974)"</a>, Marina Abramović Institute, 2014, c. 01:00 mins.</span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><a rel="nofollow" href="http://www.moma.org/explore/multimedia/audios/190/1972">"Marina Abramović. Rhythm 0. 1974"</a>, Museum of Modern Art.</span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span>Frazer Ward, <i>No Innocent Bystanders: Performance Art and Audience</i>, University Press of New England, 2012, p. 125.</span>
</li>
<li id="cite_note-Abramovic00:00mins-5"><span>^ <a href="#cite_ref-Abramovic00:00mins_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Abramovic00:00mins_5-1"><sup><i><b>b</b></i></sup></a></span> <span><a rel="nofollow" href="https://vimeo.com/71952791">Abramović 2014</a>, c. 00:00 mins.</span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span>Ward 2012, p. 119.</span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span>Ward 2012, p. 120.</span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span>Daneri, 29; and 30</span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><a rel="nofollow" href="https://vimeo.com/71952791">Abramović 2014</a>, c. 01:45 mins.</span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite id="CITEREFEisinger2013">Eisinger, Dale (April 9, 2013). <a rel="nofollow" href="http://www.complex.com/style/2013/04/the-25-best-performance-art-pieces-of-all-time/rhythm-0-the-artist-is-present">"The 25 Best Performance Art Pieces of All Time"</a>. <i>Complex</i><span>. Retrieved <span>July 19,</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Complex&amp;rft.atitle=The+25+Best+Performance+Art+Pieces+of+All+Time&amp;rft.date=2013-04-09&amp;rft.aulast=Eisinger&amp;rft.aufirst=Dale&amp;rft_id=http%3A%2F%2Fwww.complex.com%2Fstyle%2F2013%2F04%2Fthe-25-best-performance-art-pieces-of-all-time%2Frhythm-0-the-artist-is-present&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARhythm+0"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Rhythm_0&amp;action=edit&amp;section=5" title="Edit section: External links">edit</a><span>]</span></span></h2>
<ul><li><a rel="nofollow" href="https://www.youtube.com/watch?v=xTBkbseXfOQ">Marina Abramovic on performing <i>Rhythm 0</i> (1974)</a></li></ul>

<!-- 
NewPP limit report
Parsed by mw2272
Cached time: 20230925120730
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.232 seconds
Real time usage: 0.313 seconds
Preprocessor visited node count: 668/1000000
Post‐expand include size: 24707/2097152 bytes
Template argument size: 1834/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 0/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 18060/5000000 bytes
Lua time usage: 0.137/10.000 seconds
Lua memory usage: 3415497/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  258.660      1 -total
 41.10%  106.315      1 Template:Reflist
 33.05%   85.475      1 Template:Cite_journal
 30.17%   78.044      1 Template:Performance_art
 29.20%   75.527      1 Template:Navbox
 20.53%   53.111      1 Template:Short_description
 11.05%   28.577      2 Template:Pagetype
  5.34%   13.800      5 Template:Main_other
  4.41%   11.396      1 Template:SDcat
  4.18%   10.810      2 Template:Blockquote
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:640048-0!canonical and timestamp 20230925120729 and revision id 1168870998. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT can now see, hear, and speak – openai.com (670 pts)]]></title>
            <link>https://openai.com/blog/chatgpt-can-now-see-hear-and-speak</link>
            <guid>37642335</guid>
            <pubDate>Mon, 25 Sep 2023 11:57:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/blog/chatgpt-can-now-see-hear-and-speak">https://openai.com/blog/chatgpt-can-now-see-hear-and-speak</a>, See on <a href="https://news.ycombinator.com/item?id=37642335">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><!--[--><!--[--><div><p>We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.</p><p>Voice and image give you more ways to use ChatGPT in your life. Snap a picture of a landmark while traveling and have a live conversation about what’s interesting about it. When you’re home, snap pictures of your fridge and pantry to figure out what’s for dinner (and ask follow up questions for a step by step recipe). After dinner, help your child with a math problem by taking a photo, circling the problem set, and having it share hints with both of you.</p><p>We’re rolling out voice and images in ChatGPT to Plus and Enterprise users over the next two weeks. Voice is coming on iOS and Android (opt-in in your settings) and images will be available on all platforms.<br></p></div><!--]--><!--[--><div id="speak-with-chatgpt-and-have-it-talk-back" data-heading=""><p><h2>Speak with ChatGPT and have it talk back</h2></p></div><!--]--><!--[--><div><p>You can now use voice to engage in a back-and-forth conversation with your assistant. Speak with it on the go, request a bedtime story for your family, or settle a dinner table debate.</p></div><!--]--><!--[--><div id="speak-with-chatgpt-and-have-it-talk-back"><p>Use voice to engage in a back-and-forth conversation with your assistant.<br></p></div><!--]--><!--[--><div><p>To get started with voice, head to Settings → New Features on the mobile app and opt into voice conversations. Then, tap the headphone button located in the top-right corner of the home screen and choose your preferred voice out of five different voices.</p><p>The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. We collaborated with professional voice actors to create each of the voices. We also use Whisper, our open-source speech recognition system, to transcribe your spoken words into text.<br></p></div><!--]--><!--[--><div><h2>Listen to voice samples</h2><p><label><span>Select text</span></label></p><blockquote><p><span>Once in a tranquil woodland, there was a fluffy mama cat named Lila. One sunny day, she cuddled with her playful kitten, Milo, under the shade of an old oak tree.<p>“Milo,” Lila began, her voice soft and gentle, “you’re going to have a new playmate soon.”</p><p>Milo’s ears perked up, curious. “A new playmate?”</p><p>Lila purred, “Yes, a baby sister.”</p><p>Milo’s eyes widened with excitement. “A sister? Will she chase tails like I do?”</p><p>Lila chuckled. “Oh, she’ll have her own quirks. You’ll teach her, won’t you?”</p><p>Milo nodded eagerly, already dreaming of the adventures they’d share.</p></span></p></blockquote><p><label><span>Select voice</span></label><audio src="https://cdn.openai.com/new-voice-and-image-capabilities-in-chatgpt/story-juniper.mp3" controls=""></audio></p></div><!--]--><!--[--><div id="chat-about-images" data-heading=""><p><h2>Chat about images</h2></p></div><!--]--><!--[--><div><p>You can now show ChatGPT one or more images. Troubleshoot why your grill won’t start, explore the contents of your fridge to plan a meal, or analyze a complex graph for work-related data. To focus on a specific part of the image, you can use the drawing tool in our mobile app.<br></p></div><!--]--><!--[--><div id="chat-about-images"><p>Show ChatGPT one or more images.<br></p></div><!--]--><!--[--><div><p>To get started, tap the photo button to capture or choose an image. If you’re on iOS or Android, tap the plus button first. You can also discuss multiple images or use our drawing tool to guide your assistant.</p><p>Image understanding is powered by multimodal GPT-3.5 and GPT-4. These models apply their language reasoning skills to a wide range of images, such as photographs, screenshots, and documents containing both text and images.<br></p></div><!--]--><!--[--><div id="we-are-deploying-image-and-voice-capabilities-gradually" data-heading=""><p><h2>We are deploying image and voice capabilities gradually</h2></p></div><!--]--><!--[--><div><p>OpenAI’s goal is to build AGI that is safe and beneficial. We believe in making our tools available gradually, which allows us to make improvements and refine risk mitigations over time while also preparing everyone for more powerful systems in the future. This strategy becomes even more important with advanced models involving voice and vision.<br></p></div><!--]--><!--[--><div id="voice" data-heading=""><p><h3>Voice</h3></p></div><!--]--><!--[--><div><p>The new voice technology—capable of crafting realistic synthetic voices from just a few seconds of real speech—opens doors to many creative and accessibility-focused applications. However, these capabilities also present new risks, such as the potential for malicious actors to impersonate public figures or commit fraud.</p><p>This is why we are using this technology to power a specific use case—voice chat. Voice chat was created with voice actors we have directly worked with. We’re also collaborating in a similar way with others. For example, Spotify is using the power of this technology for the pilot of their <a href="https://newsroom.spotify.com/2023-09-25/ai-voice-translation-pilot-lex-fridman-dax-shepard-steven-bartlett" rel="noopener noreferrer" target="_blank">Voice Translation</a> feature, which helps podcasters expand the reach of their storytelling by translating podcasts into additional languages in the podcasters’ own voices.<br></p></div><!--]--><!--[--><div id="image-input" data-heading=""><p><h3>Image input</h3></p></div><!--]--><!--[--><div><p>Vision-based models also present new challenges, ranging from hallucinations about people to relying on the model’s interpretation of images in high-stakes domains. Prior to broader deployment, we tested the model with red teamers for risk in domains such as extremism and scientific proficiency, and a diverse set of alpha testers. Our research enabled us to align on a few key details for responsible usage.<br></p></div><!--]--><!--[--><div id="making-vision-both-useful-and-safe" data-heading=""><p><h4>Making vision both useful and safe</h4></p></div><!--]--><!--[--><div><p>Like other ChatGPT features, vision is about assisting you with your daily life. It does that best when it can see what you see.&nbsp;</p><p>This approach has been informed directly by our work with Be My Eyes, a free mobile app for blind and low-vision people, to understand uses and limitations. Users have told us they find it valuable to have general conversations about images that happen to contain people in the background, like if someone appears on TV while you’re trying to figure out your remote control settings&nbsp;</p><p>We’ve also taken technical measures to significantly limit ChatGPT’s ability to analyze and make direct statements about people since ChatGPT is not always accurate and these systems should respect individuals’ privacy.</p><p>Real world usage and feedback will help us make these safeguards even better while keeping the tool useful.</p></div><!--]--><!--[--><div id="transparency-about-model-limitations" data-heading=""><p><h4>Transparency about model limitations</h4></p></div><!--]--><!--[--><div><p>Users might depend on ChatGPT for specialized topics, for example in fields like research. We are transparent about the model's limitations and discourage higher risk use cases without proper verification. Furthermore, the model is proficient at transcribing English text but performs poorly with some other languages, especially those with non-roman script. We advise our non-English users against using ChatGPT for this purpose.</p><p>You can read more about our approach to safety and our work with Be My Eyes in the <a href="https://openai.com/research/gpt-4v-system-card" rel="noopener noreferrer">system card for image input</a>.<br></p></div><!--]--><!--[--><div id="we-will-be-expanding-access" data-heading=""><p><h2>We will be expanding access</h2></p></div><!--]--><!--[--><div><p>Plus and Enterprise users will get to experience voice and images in the next two weeks. We’re excited to roll out these capabilities to other groups of users, including developers, soon after.<br></p></div><!--]--><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Fantilator Page (385 pts)]]></title>
            <link>https://onlyfans.web.cern.ch/</link>
            <guid>37641706</guid>
            <pubDate>Mon, 25 Sep 2023 10:41:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onlyfans.web.cern.ch/">https://onlyfans.web.cern.ch/</a>, See on <a href="https://news.ycombinator.com/item?id=37641706">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <tbody><tr><th>Date</th><th>Picture or Video</th><th>Comment</th></tr>
      <tr><td>2018-07-30</td><td><a href="https://onlyfans.web.cern.ch/static/2018_07_30.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_07_30.jpg" title=""></a></td><td>Idea
 of connecting multiple fans together in order to create something 
bigger. Note that even though this contraption has checker board 
pattern, there is and attemtpt to cover "hole" in the center. Each layer
 of fans is stacked on each other, so overall thickness is three fans. 
Size - 9 fans.</td></tr>
      <tr><td>2018-08-01</td><td><a href="https://onlyfans.web.cern.ch/static/2018_08_01.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_08_01.jpg"></a></td><td>Improved
 design where rows greatly overlap eachother so overall thickness is 
just a little bit over single fan. First power supply (200-300w) is 
added. First running model, however does not have a name yet. Size - 8 
fans.</td></tr>
      <tr><td>2018-08-01</td><td><a href="https://onlyfans.web.cern.ch/static/2018_08_01_1.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_08_01_1.jpg"></a></td><td>The design proves to be scalable and grows fast. Size - 10 fans.</td></tr>
      <tr><td>2018-08-16</td><td><a href="https://onlyfans.web.cern.ch/static/2018_08_16.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_08_16.jpg"></a></td><td>More
 fans are added. In addition, candidates for the Fan Base are considered
 including the case (white) that is currently used. Size - 17 fans.</td></tr>
      <tr><td>2018-08-17</td><td><a href="https://onlyfans.web.cern.ch/static/2018_08_17.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_08_17.jpg"></a></td><td>Fan matrix. Size - 17 fans.</td></tr>
      <tr><td>2018-08-25</td><td><a href="https://onlyfans.web.cern.ch/static/2018_08_25.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_08_25.jpg"></a></td><td>Bigger
 fan matrix. Power supply fan is removed and power supply is cooled by 
fan. Note a piece of paper on power supply with "Fantilator" on it. 
Fantilator is tied to a table using a cable so it would not tip over. 
Size - 37 fans.</td></tr>
      <tr><td>2018-09-11</td><td><a href="https://onlyfans.web.cern.ch/static/2018_09_11.mp4"><video width="275"><source src="https://onlyfans.web.cern.ch/static/2018_09_11.mp4" type="video/mp4"></video></a></td><td>Fans connected using proper 4 pin splitters. Size - 37 fans.</td></tr> 
      <tr><td>2018-09-28</td><td><a href="https://onlyfans.web.cern.ch/static/2018_09_28.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_09_28.jpg"></a></td><td>Even bigger fan matrix. One power supply was not enough to power all fans, so second one was added. Size - 46 fans.</td></tr>
      <tr><td>2018-12-10</td><td><a href="https://onlyfans.web.cern.ch/static/2018_12_10.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_12_10.jpg"></a></td><td>A
 very interesting and rare photo that shows how old fantilator is being 
disassembled while new one is assembled. Old design was perpendicular to
 table, new one is diagonal. Old fantilator remains also have white 
Christmas lights on.</td></tr>
      <tr><td>2018-12-11</td><td><a href="https://onlyfans.web.cern.ch/static/2018_12_11.jpg"><img src="https://onlyfans.web.cern.ch/static/2018_12_11.jpg"></a></td><td>Phase I of new Fantilator design. First design that was <b>first thought about and only then executed</b>.
 Four fans attached together in a plus shape form a "cross" and are 
connected via 1-to-4 4 pin splitter. 8 crosses (2x4, 32 fans total) form
 a "cluster" and other ends of "crosses" splitters are connected to 
1-to-10 "cluster" splitter. New design has better cable management, 
proper cable splitters, better base known as Fanbase, threshold for fan 
power (&gt;=0.4 amps). Size - 32 fans (one "cluster").</td></tr>
      <tr><td>2019-05-10</td><td><a href="https://onlyfans.web.cern.ch/static/2019_05_10.jpg"><img src="https://onlyfans.web.cern.ch/static/2019_05_10.jpg"></a></td><td>Finished Phase II upgrade. Size - 64 fans.</td></tr>
      <tr><td>2019-05-29</td><td><a href="https://onlyfans.web.cern.ch/static/2019_05_29.mp4"><video width="275"><source src="https://onlyfans.web.cern.ch/static/2019_05_29.mp4" type="video/mp4"></video></a></td><td>First attempt to control a single fan using PWM with Arduino Nano.</td></tr>
      <tr><td>2019-06-16</td><td><a href="https://onlyfans.web.cern.ch/static/2019_06_16.jpg"><img src="https://onlyfans.web.cern.ch/static/2019_06_16.jpg"></a></td><td>Fantilator running all fans controlled by Arduino running <a href="https://github.com/justinasr/FantilatorOS/">FantilatorOS</a>. Size - 64 fans.</td></tr>
    </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I moved states just before the return-to-office order at Amazon, so I quit (119 pts)]]></title>
            <link>https://www.businessinsider.com/i-quit-return-to-office-order-amazon-rto-2023-9</link>
            <guid>37641660</guid>
            <pubDate>Mon, 25 Sep 2023 10:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/i-quit-return-to-office-order-amazon-rto-2023-9">https://www.businessinsider.com/i-quit-return-to-office-order-amazon-rto-2023-9</a>, See on <a href="https://news.ycombinator.com/item?id=37641660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Sophia Carter was working as a talent-management specialist at Amazon in Chicago.</li><li>She relocated to Raleigh, NC, five days before Amazon announced its return-to-office order.</li><li>Carter couldn't afford to move again, so she quit her job at Amazon.</li></ul><section id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="careersinlinesignup">
                            
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section><p><em>This as-told-to is based on a transcribed conversation with Sophia Carter, an ex-Amazon employee. The following has been edited for length and clarity.</em></p><p>As a person with a disability, I started working remotely before the pandemic, after years of stressful in-office experiences.</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/650d7cb619f33e0019046d19&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:427,&quot;aspectRatioH&quot;:384}}" alt="Sophia Carter, ex-Amazon employee" itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Sophie Carter has a stress tolerance disability that prevents her from working in-office
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          Sophia Carter
                          
                          </span>
                              </span>
                          </figure>
                        <p>I've been working remotely since October 2019 and took a sabbatical during the pandemic.</p><p>I started my job as an Amazon talent-management specialist in September 2022. When I was hired, Amazon office employees were working remotely.</p><p>My team's senior leadership had to fly to different cities for in-person strategic meetings with other senior leaders, but no one else was in the office.</p><p>I went into the Chicago office voluntarily for meetings and team bonding once a month over six months.</p><h2>Being in an office environment makes my disability worse</h2><p>I have a stress-intolerance disorder and work is inherently stressful. My stressors make me both physically and mentally sick. An in-person office environment exacerbates my symptoms.</p><p>I've had to be hospitalized multiple times for stress-related illnesses after working in person for more than a couple of months.</p><p>Working from home allows me to control my environment and minimize stressors. I can take breaks and reduce the impact of stress on my body.</p><p>I can also be my authentic self while working without masking most of the time, which takes a huge mental and physical load off of me.</p><h2>When I moved to Raleigh, North Carolina, there were no rumblings of RTO at Amazon</h2><p>I was tired of the long, dark, cold winters in Chicago. I wanted a metropolitan location that was warmer, safe, and not too big. Raleigh checked all my boxes. People here are friendly and welcoming.</p><p>At that time, Amazon's internal messaging was that we would be remote indefinitely —&nbsp;there were no whispers that <a target="_blank" href="https://www.businessinsider.com/amazon-rto-return-to-office-policy-news-updates-2023-8" data-analytics-product-module="body_link" rel=""><u>RTO was coming</u></a>, so I felt confident relocating.</p><p>I didn't mention my move to my manager because I never felt like there would be any threat of me having to go into the office anytime soon, if ever. Members of my team lived in different places across the country.</p><p>In March, less than a week after I moved, <a target="_blank" href="https://www.businessinsider.com/amazon-voluntary-resignation-employees-relocate-rto-2023-7" data-analytics-product-module="body_link" rel=""><u>Amazon issued its RTO</u></a> order. Employees had to be working in the office for a minimum of three days a week from May 1. </p><h2>My whole team wanted to keep working remotely</h2><p>Our team's leadership advocated for our team to remain remote since we were spread across the country. Even if we all went to our nearest offices, we still wouldn't have the opportunity to collaborate in person.</p><p>Our work involved sensitive employee data, so we couldn't have meetings or calls in a cubicle or open-office floor plan. We'd always need the security and privacy of a private room, so there was another wrench in the RTO.</p><p>I'm confident that my leaders did their best to find alternatives and advocate, but they don't have as much power as the C-suite.</p><h2>I knew I wasn't going back to Chicago or in-person work</h2><p>I wasn't returning to Chicago or another Amazon hub — it was off the table. Amazon wasn't talking about relocation assistance at the time.</p><p>My relocation was expensive and a lot of work. I love Raleigh and I couldn't afford to move again, so returning to a hub was never on the table.</p><h2>It took me 90 days to find a new remote job</h2><p>When the RTO message came out, I waited to see what my direct leadership chain would do. Over the next month, it became apparent that all of us would have to submit to it.</p><p>Paired with <a target="_blank" href="https://www.businessinsider.com/amazon-layoffs-second-round-9000-job-jobs-2023-3" data-analytics-product-module="body_link" rel=""><u>the mass layoffs</u></a> that were happening nearly every quarter, I didn't feel I had job security.</p><p>I started applying for remote jobs in April, which made my search difficult because entirely remote jobs aren't as plentiful as they were in 2020 and competition is tough.</p><p>After three months, I received an offer from another Fortune 100 company to work remotely.</p><h2>Leaving Amazon was a blessing in disguise</h2><p>It was a blessing in disguise. If Amazon had never announced RTO or layoffs, I would probably still be there.</p><p>I like the new job much more and it's a much better match for my skill set and abilities.</p><p>My role at Amazon was very task-oriented. Get this done, get that done. My new role is strategic. I get to partner with senior business leaders and determine the talent strategy to make their business strategy a reality.</p><p><em>In response to a request from Insider to comment on Amazon's return-to-office order, a spokesperson for the company said: "We believe that being in the office at least three days a week is the right long-term approach because it drives culture, team connection, innovation, and learning.&nbsp;We also appreciate that there will be exceptions based on an employee's individual circumstances. Insider wouldn't share the information necessary for us to verify this account, however we have processes in place for employees to request exceptions or accommodations, and if an employee is asked to relocate, we provide financial assistance."&nbsp;</em></p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York employers must include pay rates in job ads under new state law (231 pts)]]></title>
            <link>https://english.elpais.com/economy-and-business/2023-09-17/new-york-employers-must-include-pay-rates-in-job-ads-under-new-state-law.html</link>
            <guid>37641583</guid>
            <pubDate>Mon, 25 Sep 2023 10:19:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/economy-and-business/2023-09-17/new-york-employers-must-include-pay-rates-in-job-ads-under-new-state-law.html">https://english.elpais.com/economy-and-business/2023-09-17/new-york-employers-must-include-pay-rates-in-job-ads-under-new-state-law.html</a>, See on <a href="https://news.ycombinator.com/item?id=37641583">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>Help-wanted advertisements in New York will have to disclose proposed pay rates after a statewide salary transparency law goes into effect on Sunday, part of growing state and city efforts to give women and people of color a tool to advocate for equal pay for equal work.</p><p>Employers with at least four workers will be required to<a href="https://english.elpais.com/economy-and-business/2023-07-08/new-minimum-pay-rates-for-nyc-app-based-food-delivery-workers-are-delayed.html" target="_blank"> disclose salary ranges </a>for any job advertised externally to the public or internally to workers interested in a promotion or transfer.</p><p>Pay transparency, supporters say, will prevent employers from offering some job candidates less or more money based on age, gender, race or other factors not related to their skills.</p><p>Advocates believe the change also could help underpaid workers realize they make less than people doing the same job.</p><p>A similar pay transparency ordinance has been in effect in New York City since 2022. Now, the rest of the state joins a handful of others with similar laws, including California and Colorado.</p><p>“There is a trend, not just in legislatures but among workers, to know how much they can expect going into a job. There’s a demand from workers to know of the pay range,” said Da Hae Kim, a state policy senior counsel at the National Women’s Law Center.</p><p>The law, signed by Gov. Kathy Hochul in 2022, also will apply to remote employees who work outside of New York but report to a supervisor, office or worksite based in the state. The law would not apply to government agencies or temporary help firms.</p><p>Compliance will be a challenge, said Frank Kerbein, director of human resources at the New York Business Council, which has criticized the law for putting an additional administrative burden on employers.</p><p>“We have small employers who don’t even know about the law,” said Kerbein, who predicted there would be “a lot of unintentional noncompliance.”</p><p>To avoid trouble when setting a salary range, an employer should examine pay for current employees, said Allen Shoikhetbrod, who practices employment law at Tully Rinckley, a private law firm.</p><p>State Senator Jessica Ramos, a Democrat representing parts of Queens, said the law is a win for <a href="https://english.elpais.com/usa/2023-09-01/rising-tensions-between-employers-and-employees-have-put-the-labor-back-in-this-years-labor-day.html" target="_blank">labor rights groups.</a></p><p>“This is something that, organically, workers are asking for,” she said. “Particularly with young people entering the workforce, they’ll have a greater understanding about how their work is valued.”</p><p><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i>Sign up</i></a><i> for our weekly newsletter to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Baby boomers are becoming homeless at a rate not seen since the Great Depression (338 pts)]]></title>
            <link>https://moneywise.com/news/economy/rate-of-homeless-baby-boomers-increasing</link>
            <guid>37641471</guid>
            <pubDate>Mon, 25 Sep 2023 09:58:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://moneywise.com/news/economy/rate-of-homeless-baby-boomers-increasing">https://moneywise.com/news/economy/rate-of-homeless-baby-boomers-increasing</a>, See on <a href="https://news.ycombinator.com/item?id=37641471">Hacker News</a></p>
Couldn't get https://moneywise.com/news/economy/rate-of-homeless-baby-boomers-increasing: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[How to Hide a $2T Trial (235 pts)]]></title>
            <link>https://www.thebignewsletter.com/p/how-to-hide-a-2-trillion-antitrust</link>
            <guid>37641393</guid>
            <pubDate>Mon, 25 Sep 2023 09:44:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebignewsletter.com/p/how-to-hide-a-2-trillion-antitrust">https://www.thebignewsletter.com/p/how-to-hide-a-2-trillion-antitrust</a>, See on <a href="https://news.ycombinator.com/item?id=37641393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em><span>Welcome to BIG, a newsletter on the politics of monopoly power. If you’d like to sign up to receive issues over email, you can do so </span><a href="https://mattstoller.substack.com/subscribe" rel="">here</a><span>.</span></em></p><p>Normally on Sunday’s I do a round-up of monopoly-related news for paid subscribers. That’ll be at the end of this email. But today, I want to do a bit of a summary of the Google antitrust trial, since we’re investing so much into covering it. The key question is as follows. Google is a very powerful corporation worth around $2 trillion, it controls access to the internet, and it will roll out generative artificial intelligence for billions of people. And yet, the public hasn’t heard that much about a major trial where the firm and its executives are being asked how they secured that immense power. Why?  </p><p>There are several possibilities, but in my view, the most obvious reason is that the judge in the case, Amit Mehta, is effectively holding the contest in secret. Last week, according to our calculations, over half of the trial, including testimony from key witnesses, happened in closed session, unavailable to the public. Why? Here’s Mehta in a pre-trial hearing in August, explaining his thinking to Google’s attorneys.</p><p><em>“Look, I’m a trial judge. I am not anyone that understands the industry and the markets in the way that you do. And so I take seriously when companies are telling me that if this gets disclosed, it’s going to cause competitive harm. And I think it behooves me to be somewhat conservative in thinking about that issue, because, you know, I can’t see around every corner.”</em></p><p>In other words, Mehta is deferring to Google on the need for secrecy.</p><div id="youtube2-gRelVFm7iJE" data-attrs="{&quot;videoId&quot;:&quot;gRelVFm7iJE&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/gRelVFm7iJE?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p><span>In 1998, the richest man in the world, Bill Gates, had to answer to the public in an antitrust trial. Gates had been a titan for almost two decades, gracing the cover of Time Magazine multiple times as a young genius. That all changed when he was deposed by government lawyers. “The Bill Gates on the courtroom screen,” reported </span><a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/11/biztech/articles/03soft.html" rel="">the New York Times</a><span>, “was evasive and uninformed, pedantic and taciturn, a world apart from his reputation as a brilliant business strategist, guiding every step in Microsoft Corp.'s rise to dominance in computing.” </span></p><p>For eight months, the Microsoft antitrust trial was front-page news, the drama of the trillion dollar personal computing revolution unveiled to the public. One result was that Microsoft, afraid of public exposure years later, refused to use its control over the browser to kill nascent rivals, in particular a young search company called Google. </p><p><span>Today, we should be in a similar moment, only this time with Google as the titan on trial. Google has engaged in behavior that’s almost identical to what Microsoft did in terms of coercion of rivals, and just as consequential in terms of shaping the future. And yet, the reporting and interest in this trial is minuscule compared to what we saw 25 years ago. Frankly, some days, our </span><a href="https://www.bigtechontrial.com/" rel="">Big Tech on Trial</a><span> reporting site is one of the few journalists in the court room, which is astonishing. This dynamic is especially odd because, unlike 1998, we are in an anti-monopoly moment, with political interest in corporate behavior far more elevated than it was in 1998.</span></p><p><span>What gives? There are a few reasons for this odd disconnect, but one reason is very simple - there was public access to the Microsoft trial in 1998. However today the judge, a guy named Amit Mehta, has effectively barred the public from seeing anything meaningful or interesting. In my </span><a href="https://www.thebignewsletter.com/p/the-first-big-antitrust-trial-of" rel="">profile of the trial</a><span>, back in August, I focused on Mehta, because I knew the dynamics would be organized by his decision-making. And so it has been.</span></p><p><span>Let’s compare the two trials. For Microsoft, the judge ruled on </span><a href="https://www.cnet.com/tech/services-and-software/gates-depositions-open-to-public/" rel="">behalf of media organizations</a><span> that the deposition of Bill Gates would be unsealed, a deposition that was not meaningful for the trial, but also critically important to the historical record, and one you can watch online today. He also unsealed </span><a href="https://archive.nytimes.com/www.nytimes.com/library/tech/99/04/biztech/articles/09soft.html" rel="">over a hundred transcripts</a><span> of other depositions from industry players, including ones that weren’t used in the trial itself. This public record was critical to the reporting, and to public understanding of the industry.</span></p><p><span>But this Google trial? By far the most important moment was when Judge Mehta </span><a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.685.0_1.pdf" rel="">denied a third-party motion</a><span> to broadcast a publicly accessible audio feed of the trial for fear that information Google wishes wouldn’t be disclosed become public. Indeed, Google lawyers have explicitly argued that the judge should avoid allowing documents to become public solely because it is “clickbait.” To put it differently, the search giant literally argues material should stay sealed merely because if that material is interesting. Imagine if Bill Gates, or say, a routine defendant in any case, could have availed himself of that innovative legal argument!</span></p><p>These arguments should be laughed out of court. And yet, Mehta takes them seriously, which has led to an almost-entirely private trial, deadeningly boring to the public because key documents have been deleted and the important or embarrassing moments are held in secret. </p><p>As a result of this monumental decision, the trial is now only available to people who can go to the court in D.C.  And yet, even if you can come to the courthouse, it’s hard to see the trial because huge portions are fully sealed. There is often no clear indication beforehand of how long the trial will be sealed for. And when court ends a sealed session and re-opens to the public, it often resumes within a couple minutes of opening the door to the courtroom. This means anyone who wants to watch the public portions of the trial just has to wait outside the courtroom to see when it re-opens. Moreover, even though you can watch the trial from the courtroom or a public overflow room, unless you are in the media room, electronic devices are not allowed.</p><p>It’s an eight week trial, but a chronicle of Friday’s court date is as good an example as any. Big Tech on Trial waited all day, with no information, as the lawyers debated something in what is known as a ‘closed session.’ This is a common occurrence. Most of the trial is happening behind closed doors, including procedural questions that should clearly be public. Indeed, Big Tech on Trial looked at the transcripts for the last week to estimate roughly how much of the trial was held in secret, based on how much they are redacted. </p><p>Easily half of the week’s courtroom days were sealed. Here’s a breakdown of how much of the trial was sealed on each day:</p><ul><li><p>Monday, Sept. 18: roughly half of the trial was sealed</p></li><li><p>Tuesday, Sept. 19: trial was fully open</p></li><li><p><span>Wednesday, Sept. 20 roughly three quarters of the trial was sealed. That morning, Bloomberg reporter Leah Nylen came to the courtroom with a First Amendment attorney hired by Bloomberg. But the attorney never got a chance to speak because the court unexpectedly </span><a href="https://www.bigtechontrial.com/p/what-is-it-like-to-compete-against" rel="">began in a closed session and the public was asked to leave the courtroom</a><span> (after Judge Mehta reportedly had a private meeting with the lead attorneys in his chambers).</span></p></li><li><p>Thursday, Sept. 21: roughly half of the trial was sealed</p></li><li><p>Friday, Sept. 22: the entirety of testimony was sealed. Court opened up only for a few minutes to deal with administrative matters at the very end of the day.</p></li></ul><p><span>And that means we heard little of the most important testimony, perhaps of the entire trial, from a man named John Giannandrea. Giannandrea is a senior executive at Apple who reports directly to Tim Cook and came to Apple from Google in 2018, where he was head of Search. The relationship between Apple and Google is the heart of the trial, and, in the year this man left from Apple to Google, the two firms went from aggressive </span><a href="https://www.theinformation.com/articles/apples-web-search-technology-chief-returns-to-google?irclickid=zaGVWgzd3xyPWD-UXyyJiw2eUkFRgRVRRWdJ1s0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=macrumors.com" rel="">competitors to gentle collaborators</a><span>. And yet, the public heard just </span><a href="https://www.bloomberg.com/news/articles/2023-09-22/apple-ai-chief-posits-new-private-browser-search-at-google-trial" rel="">ten minutes of open-court testimony from Giannandrea</a><span>. Another Apple executive, Eddie Cue, will testify on Tuesday, so there’s a chance we’ll learn more about the relationship between Apple and Google. Stranger things have happened.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png" width="980" height="727" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:727,&quot;width&quot;:980,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31f1b899-9d71-4056-8194-c6826c5671b3_980x727.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Judge Mehta isn’t just closing the courtroom, he’s also allowing Google to hide evidence without consequence. On a separate post, I’ve put up </span><a href="https://www.bigtechontrial.com/p/secrecy-is-systemic" rel="">seven different</a><span> ways he’s doing that, from letting Google avoid disclosing documents based on false claims of attorney-client privilege to doing nothing even when Google executives used “history-off chats” to destroy conversations after 24 hours even after Google was on a litigation hold. The point is, Mehta is far more concerned that Google isn’t embarrassed, and almost wholly uninterested in public access.</span></p><p>The problem here isn’t just the judge or Google. The Department of Justice shouldn’t be let off the hook either. The trial team, which is generally doing a good job, seems mostly unconcerned with public access. They didn’t support a set of nonprofits who made a motion for a public audio feed, and they tend to litigate in closed session whenever Google seems uncomfortable, so as not to come close to offending the judge. Indeed, when the judge expressed a bit of frustration that exhibits were posted publicly, government lawyers immediately pulled down their website and said they would work with Google to make sure everyone was satisfied with the process. That’s the opposite of standing your ground.</p><p><span>Trials are </span><em>supposed</em><span> to be public, and the government should fight for them to be public. Public access and a public record in a trial, especially when the powerful are concerned, is a core part of what makes our legal system different from those in authoritarian regimes. Not vigorously challenging Google in its penchant for secrecy is inconsistent with their obligation to their client, which is the people of the United States. </span></p><p>And this isn’t costless. At this point, I am hearing from random commentators that the fix is in, and it’s hard not to disagree. Conspiracy theorists arguing how the corporations, judges, and the government are in collaboration could look at this trial and have a field day. That’s the price of secrecy, there’s just no way to uphold the legitimacy of a legal order when redactions are both unnecessary and routine.</p><p>Fortunately, this trial isn’t the last time Google will be on the stand. And despite Mehta’s caution, we are learning more about Google, just not nearly as much as we should. I didn’t know what to expect from this trial, but a blackout of information wasn’t on my radar. But I guess I shouldn’t have been surprised. After all, who knows more about the value of privacy than Google?</p><p><span>The monopoly round-up for paid subscribers is below. Also, if you enjoyed this recap of the Google trial, please consider a </span><a href="https://www.thebignewsletter.com/subscribe" rel="">paid subscription to BIG</a><span>. I was able to hire a court reporter because of the resources you provided.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bitwarden: Free, open-source password manager (365 pts)]]></title>
            <link>https://bitwarden.com/</link>
            <guid>37640816</guid>
            <pubDate>Mon, 25 Sep 2023 08:11:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bitwarden.com/">https://bitwarden.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37640816">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-testid="card-container" id="move-fast-and-securely-hero"><div data-gatsby-image-wrapper="" data-testid="card-asset"><picture><source type="image/avif" srcset="https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/dfae7b200aa891e97d98c0c081c19f61/homepage-hero-2.avif?eu=dfdd50efe1ccf5d1096ba3806177613be76957adac5163866e61b6fb46accd8624f0480025c728b37e6e5ed782b44bec679029341dedd08c91b84af4b935ab5b56810ceb35b2780f5978c1ffb1a304403c931f58f2d7cd0dab657b82e3e6e6221e531b2ca97dbbd5eca8616cb58b7e67eab5ac762186eb3bea0d410d964926a927a5c39a654fad8de55bacf8b0fc4dd29ba573540681f2632a2a0b1847ec4dc4a5d35c105a41015b7689dd079668c2fe7c5f3f3c5e5902f1613cd95dad3f3597b7fda259d07d7be0ac9a3622d796a8d4bc4efe2c69bf907afcc26a2d5b10f446efe366f5cc245859&amp;a=w%3D200%26h%3D124%26fm%3Davif%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 200w,https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/24d4f846fe1d3a6a0ffd7b87a370a1e2/homepage-hero-2.avif?eu=8c8d53eee599ffd20b6da0d73a236338e63752f9f8593f843467e3fb1cfacd8f22f0485573c47be32c610c8f86b446e967c37f371abbd18b91bb1da0bb60f95d07825ee860b2250f0279c5aab0fd00133e94490ea284cd5caa3b7381b1e0b7774a561c78a82cba88eaac3737e6d22b34bbbea62f6097f97eea4a1a108b5b7be37be2cd8f644badd0e35bb9b7adea5c89dff9735204c4f4777c240a4559bb25e6e2b51b705956403a6dafcc308661d5f14e43302a0a1743b43925d053fa6a37c5edf3f70edd2e28e7abcd387786c2aad3ea48fd7f70b39e73fb8424225150f953fceb2eea8a3144519c28e4d512e5&amp;a=w%3D400%26h%3D248%26fm%3Davif%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 400w,https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/14555151e7fab5a95b4501dec7cb9acc/homepage-hero-2.avif?eu=8e8b59efe59afcd6096ea3d66f736961e46a56a8fa5860d96e63e1ac47af968724f54d5224917ce42860538d85e611be67c47d6119bd858bc8ea4ef1bb33ff0e52d208bb64b321065928c0fce4f050473ecf485eabdb8c4ce32e78cbfaeaea214e055f35fb3eeed0afea6020f39d7167aea9a16c3b91ed22e14456098c1f6efd04c490bf6b7f8da6f11faca19cf658c4c8af6d441ec4f33323714a1951e57be8a1e657773a2d495c35cfab0bc033c7e33a4830770c591caf38678515aa3b64debcaee302c47865a1f69e&amp;a=w%3D800%26h%3D496%26fm%3Davif%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 800w" sizes="(min-width: 800px) 800px, 100vw"><source type="image/webp" srcset="https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/d7659d4bc3749c22940d72105e3c90c0/homepage-hero-2.webp?eu=8e8759e5e39ef4865e6ca7d56c23366be23c55a2f6543ed3386deca74bfacf8526f64f5623c328b62a3d5cda81e347ef63c2296648e8d6dac5b91af7ed30f90d5ad00cbc35b4210f577dcdfde3f30c1d2c825a1bab9cd751fe3c2581a6ade4344f015f68fd3efb9fb2fc717bb7c17161aceca7786d9fec7fff133e2bcb79299d07d3d1de70599c91e116bbaeaeea57d29ce12c0146ddfa3d7424484b0beb2ebfacb504703d7a4709649ba90c9635c4b023443e7e0b1f52a032278800b9332cc1fabbff0a&amp;a=w%3D200%26h%3D124%26fm%3Dwebp%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 200w,https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/5b12373bb36e2e9842722d250855caa4/homepage-hero-2.webp?eu=898e57b2b69baa82093ca48b3c24336be53655f8f65437813567e5fc49af9b8e21a51d5174c072e42c695bdfd5e611eb619329351ae783d891ee1da7e237a85c53d75abc67b12653552296fdb3f152413cc7135aa28ac95da638788ca1f7f733134f0372f52befd4afb76620e6d26c71bff2e5303b97ef67e75000078d4270aa6ce6d7d92c1f8eb1b07eb7878dc148cddfa05f5811d2a77d6234120058eb2cbda3b40d796f7a440f66c8ac5cce6696b7384f66710f0a05a3366e8253e4346e9eb1bbf00a8c6723b4ea962c729883f0d7&amp;a=w%3D400%26h%3D248%26fm%3Dwebp%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 400w,https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/8b8abd6dec62f0ce39d59b48fc68b625/homepage-hero-2.webp?eu=dd8902b2ebcaf487083aa4833e7a646de43a06fdf65034d93d32b7af4cad9a8125f04f0320947ce5286c58dcd3e642b964937c651bedd7d892bb10a5e335ff015b8b5deb31ba2253502f97afe6a30e406ccf1e51a4d5c250e7293297efaca82944014b7eeb64ebc5baf87627e5c76c2cb4e3e2316280f52ba6485f02c34536fb7bbaf0a1337fb6afd377aee6adee7b92cdee794f0098ad2a22714d195eeb24b3f3e100256a2f435f3cc9af59c33291e46d4967770f0b51f178628f08ae2c6094b1e6f9089b2566e3b6896f27&amp;a=w%3D800%26h%3D496%26fm%3Dwebp%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 800w" sizes="(min-width: 800px) 800px, 100vw"><img data-gatsby-image-ssr="" id="312922cf-f43c-5797-ac7e-d1da25294538" data-main-image="" sizes="(min-width: 800px) 800px, 100vw" decoding="async" loading="eager" src="https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/cd7cebb888cc75726753bc66755f6e3e/homepage-hero-2.png?eu=89da50b4b69bf881076ef4823e23683be53b50a9f80234853867e0ad1bac98862cf5195d269d7fb17e6d59dcd6e811bb31c37b371aed85dac9ee1cf6ea3dae5a51d259e761e7720f032ec7afe3f3001161c6480df58acd08a5697681b1e2b07410554e7ea17bee86bff86636e3807b37eab4ac762186eb3bea0d410d964926a927a5c39a654fad8de55bacf8b0fc4dd29ba573540681f2632a2a0b1847ec4dc4a5d35c105a41015b7689dd079668c2fe7c5f3f3c5e5902f1613cd95dad3f3597b7fda259d07d7be0ac9a3622d796a8d4bc4efe2c69bf907afcc26a2d5b10f446efe366f5cc245859&amp;a=w%3D200%26h%3D124%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z" srcset="https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/cd7cebb888cc75726753bc66755f6e3e/homepage-hero-2.png?eu=89da50b4b69bf881076ef4823e23683be53b50a9f80234853867e0ad1bac98862cf5195d269d7fb17e6d59dcd6e811bb31c37b371aed85dac9ee1cf6ea3dae5a51d259e761e7720f032ec7afe3f3001161c6480df58acd08a5697681b1e2b07410554e7ea17bee86bff86636e3807b37eab4ac762186eb3bea0d410d964926a927a5c39a654fad8de55bacf8b0fc4dd29ba573540681f2632a2a0b1847ec4dc4a5d35c105a41015b7689dd079668c2fe7c5f3f3c5e5902f1613cd95dad3f3597b7fda259d07d7be0ac9a3622d796a8d4bc4efe2c69bf907afcc26a2d5b10f446efe366f5cc245859&amp;a=w%3D200%26h%3D124%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 200w,https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/999eb1ee9f549935ed3adad61bded8ca/homepage-hero-2.png?eu=8b8602e7b6cafe8f0c3bf2d061706768b33b05acaf0565d36e30b0fd1baa9c8621f44c5d29957eb52b3809db82e043e962c67e641abb85de91b84af2eb60fb5c57860cbf34b32253562fc1ace1f402453ec41f09abdb8c4ce32e78cbfaeaea214e055f35fb3eeed0afea6020f39d7167aea9a16c3b91ed22e14456098c1f6efd04c490bf6b7f8da6f11faca19cf658c4c8af6d441ec4f33323714a1951e57be8a1e657773a2d495c35cfab0bc033c7e33a4830770c591caf38678515aa3b64debcaee302c47865a1f69e&amp;a=w%3D400%26h%3D248%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 400w,https://bitwarden.com/_gatsby/image/ca2b609b9ec14d07da43621491fc261a/471b4efce94f3465e8aca90530f4a46b/homepage-hero-2.png?eu=d78906e0b09daa855c3ba58260266169b63653fea80231d76c67edfb1cfccc8526f31c5674922eb92f3c088a87b345b962c62d6119e7d289c0bd10a6b830a25956d05fef61e77454512d97ffb7a600466dc01e5fa3829e0af2392785e3e5b22510551f2ef978b2d9a8ed7527ba9c306bb7e7f17b26dcf83cb6431d179e5c32e23aeed4c1345cb09df645eeb0e6f44eca83e64d7840baab54411f0d1f1baa5fe4f4bb5039796a1e4435c8ae5ec1679fbe6a4f65770d5900f36e3dd054ff3f3691b5aea709882e29e7b7916e2dd383ffd7b807f47f34b8d225b7c2652d&amp;a=w%3D800%26h%3D496%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A54.858Z 800w" alt="home-hero"></picture></div><div data-testid="card-content"><p>At home, at work, or on the go, Bitwarden easily secures all your passwords and sensitive information.</p></div></div><div><p>Launching trusted devices for enterprise passwordless SSO</p></div><section id="everything-you-need-out-of-a-password-manager"><p><h3>Everything you need out of a password manager</h3></p><div><div data-testid="card-container"><p>Easy</p><p data-testid="card-headline"><h5>Powerful security within minutes</h5></p><p>For those who want to do more, secure more, and collaborate more, Bitwarden is fast and easy to set up for both individuals and businesses.</p></div><div data-testid="card-container"><p>Convenient</p><p data-testid="card-headline"><h5>Unlimited passwords, unlimited devices</h5></p><p>Cross platform access for mobile, browser, and desktop apps. Supported in over 50 languages.</p></div><div data-testid="card-container"><p>Secure</p><p data-testid="card-headline"><h5>Protect what's important to you</h5></p><p>Zero knowledge, end-to-end encryption guides the Bitwarden open source approach to trust, accountability, and security.</p></div></div></section><section id="bitwarden-helps-businesses-run-quickly-and-securely"><p><h3>Bitwarden helps businesses run quickly and securely</h3></p></section><div><p>Work more productively and power up your protection</p></div><div id="bitwarden-features"><div data-testid="card-container"><p data-testid="card-headline"><h4>Generate, consolidate, and autofill strong and secure passwords for all your accounts</h4></p><p>Bitwarden gives you power to create and manage unique passwords, so you can strengthen privacy and boost productivity online from any device or location.</p></div><div data-testid="card-container"><p data-testid="card-headline"><h4>Securely share encrypted information directly with anyone</h4></p><p>Bitwarden Send is a feature that allows all users to transmit data directly to others, while maintaining end-to-end encrypted security and limiting exposure.</p></div><div data-testid="card-container"><p data-testid="card-headline"><h4>Gain peace of mind with comprehensive compliance</h4></p><p>Protect your online data using a password manager you can trust. Bitwarden conducts regular third-party security audits and is compliant with GDPR, SOC 2, HIPAA, Privacy Shield, and CCPA standards.</p></div><div data-testid="card-container"><p data-testid="card-headline"><h4>Protect more than your passwords</h4></p><p>Store all types of sensitive data, transmit it securely to anyone, access vault health reports—and much more.</p></div></div><div data-testid="card-container" id="451-research-pdf-download"><div data-gatsby-image-wrapper="" data-testid="card-asset"><picture><source type="image/avif" data-srcset="/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/09a7256d6b9ea8327b8930a64337a48f/451-report-large.avif?eu=df8903efb79bfa870f6fa2d56e20356cb33753fead0560d23835e6fd19a8998672f41101289d7ab52b6c5ede86e614b831942c6711b886d8c1e81ba5e934a80b59db1eaa27f07a184e7299afe7a0455b3b824c09e2c09d4ce0732c81a1acb03247035a71a92cb0dcabae2a60f7807565bfcac37d6486cd2dbc585b13b8510f8830a4938b304ae6c8b81be8e5eaab5bcf99e428024389fa6625744b1a5fe52ebdace31b753c285d19608ef01a837ccae77e4b343d1e0154&amp;a=w%3D125%26h%3D106%26fm%3Davif%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 125w,/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/9ef4a4c89f1c02f701dfbaaaa2d8ed35/451-report-large.avif?eu=db8e03e2b6caf4d5086ca2d669773668e93656adfa0460d36e6db0fe4cab98d270fb1d5028952ee42a3b5aded3e810ef67c67f371ebad8d8c2e94cfdb866aa0007d558bb36ba24020022c1fab8f202426ec74c51a5d0c250e7293297efaca82944014b7eeb64ebc5baf87627e5c76c2cb4e3e2316280f52ba6485f02c34536fb7bbfd7dd6949bbb2d54ceea288fc558799a05e4e3eafa72a21224f4b50eb25bfa2b100736b2b455830cbac0ace3291b53b19662b5d590aa6783ed554e62e6483bbb9e540852b39b6fdd7712ed1&amp;a=w%3D250%26h%3D212%26fm%3Davif%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 250w,/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/3eba53abaa41f59b212f43110bc06593/451-report-large.avif?eu=d6da51e4e5c9ae870b3bf5d66870606ab16c03adfb5437813f67edab1daa988526a24f0621c67de02e605d8f82b642ec32977d661fed84dd96bb1af1ea60a25e5b825de861e67402047e91abb7a454406e97135da3d1c959a9353690a5f0bd6f0609417aff2ffb9fbfed6335f3c07a76a9a8f87b21ddac3abe41180eca4e79a123bc8fda741db499e5638ab5efed6f98c0ad284033928d4176684f4a5bb925bdadb603723d2b125930cdaa5dc4339fe53b1f6626595700f16e6bcf51fe6d2c81b1bbfe1f9d6727b0ea9e646ec69df9&amp;a=w%3D500%26h%3D424%26fm%3Davif%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 500w" sizes="(min-width: 500px) 500px, 100vw"><source type="image/webp" data-srcset="/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/7fe4816d59f4548249a581892ef6d114/451-report-large.webp?eu=de8954e0b6cff987086bf6846e263469e13803a3f75837d33d35e3fa49aacf8125fb1c57729378b82d610b8ad1e44ab963942b661ee68288c3ea4df0ed32ab0c578652bc6eb42351582ac1f7b3f30e106dc64e5aa3d7cf5ba76d2387b7b0e3214b01482efc78be87ecfa3065b8d1256aaef2e66d6fddb421bd430901880622b832ead39d665aadd0ee4aabf9e9eb579edabd2c514886b4323d730b1c02ba78c7c0e105355f7c1c113089dc11b915c2a93f49627756590bf36039d457a96e34c0e1fea20fd0297ce2afcc367885c5a7d1f21ea92b6ba59a67f6c07f67525cee44f8a23ba985&amp;a=w%3D125%26h%3D106%26fm%3Dwebp%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 125w,/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/3e506523e27e3574f79d9929ecddb6af/451-report-large.webp?eu=dc8d54b4b1c1f5805d6af5d06f766860b36a56f9fb0763d06b35e7af4ffac8d42ca61007739572b42f6008ddd2b644b861cf78691aebd3d992b54afdb935fc0801d159ee60b32403507fc4f6b1f502473d941859a583990ff23976d3b7e5e2741d531d2aa12bbd85bfab3530b0822a30e2e3a1786dc5aa71e6465f52c14035b824f89ac12c47b39fe74aacf8bded5f9cdfa4784303c5ad6066684b5d06be6be1a4e40c2c7e2e5f5f72cdf50f921df3e53d580776021506b01473ae21af733296e7afa95bd17e7ce2accb637283c0ab85ee48a57971e4c822ae8a387c075cb317a8bd66b58724594cc537a6c40ee5561b751ed5&amp;a=w%3D250%26h%3D212%26fm%3Dwebp%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 250w,/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/549f13190bb898e42c7b34181bc8fb75/451-report-large.webp?eu=d8d854e7ebcaad8e593da3d16a23693de86955f8fc563ed03430e2aa46f9cd8523a01e03769c28b9786c5e8cd3e117bb65922e3548e9d388c9ed19a0ec3dfc0b50d708ed35b57203037ac7fbb9a453463ec71b0eabdb8c4ce32e78cbfaeaea214e055f35fb3eeed0afea6020f39d7167aea9a16c3b91ed22e14456098c1f6ef823b8ca8966628b9db15b89b3b2e30c8aefae537314c4f0602123441950e92ab8a1b056733c2a455e369ca60bc06291b33b146225570e1cf3623bcd17ae2c6e81a0e6fd0c9b2d2effe89766&amp;a=w%3D500%26h%3D424%26fm%3Dwebp%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 500w" sizes="(min-width: 500px) 500px, 100vw"><img data-gatsby-image-ssr="" id="52f57771-e535-56d9-92f2-14cecec9fda8" data-main-image="" sizes="(min-width: 500px) 500px, 100vw" decoding="async" loading="lazy" data-src="/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/0d414a94e96c8d654d892bf67fd45b81/451-report-large.png?eu=d78754b2b29cfc83593aa1846b7a643fb63d02f9af583f813430b0ab4baacd8772f14d04749178b62b685adb86e340bf6ece7e661ebbd48993be4efcbe60ad0807d70bee31e226045128c0fdb8f2544c3a951250a9d09a5aa13c77d7e2b7b3264a541b23a878be87e9aa6360e3802e67b8b4a12a31c6aa7fe515540c8f5c31bf6ea48f876e4fb99bf301bca2b8f84a8ec9a36e191e8eb72a2535124c1eb72cedadef4376262d07586f99fa24a23297f25a493d695b1870be194e844af8393297ecfda959de797fe3facb347383c6add2e449ab2971e2c82faa84322b1109a912b0fe2eb78d264213dd7bb8c219ac435b62&amp;a=w%3D125%26h%3D106%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z" data-srcset="/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/0d414a94e96c8d654d892bf67fd45b81/451-report-large.png?eu=d78754b2b29cfc83593aa1846b7a643fb63d02f9af583f813430b0ab4baacd8772f14d04749178b62b685adb86e340bf6ece7e661ebbd48993be4efcbe60ad0807d70bee31e226045128c0fdb8f2544c3a951250a9d09a5aa13c77d7e2b7b3264a541b23a878be87e9aa6360e3802e67b8b4a12a31c6aa7fe515540c8f5c31bf6ea48f876e4fb99bf301bca2b8f84a8ec9a36e191e8eb72a2535124c1eb72cedadef4376262d07586f99fa24a23297f25a493d695b1870be194e844af8393297ecfda959de797fe3facb347383c6add2e449ab2971e2c82faa84322b1109a912b0fe2eb78d264213dd7bb8c219ac435b62&amp;a=w%3D125%26h%3D106%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 125w,/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/8416b3f6b2db5299bb7c3f79407cbb5e/451-report-large.png?eu=8adb05e0b7cef4d20c6da2803b7b6168b16b56adab5260813466b1a64eae9dd727f21b0020962fe42f6e088a80e743ee6693783519b8858fc9e911a7be37ae5b52d75dec62b57154582ac6fae5f657443e971b0af384cf0fa26e26d0b4b6e3751c511d78a973eb84ebad3331e38b2c37e0eee26a2581a167ff4b03059c4d32e237ffc68f705dbb8af301b1b3aab60e8fc2b46b5d418dfb686570531b1fee77ecf0ce6122386d260e6984aa1fb428e8c2680362765d0b0bf16f3ed756ff6e63c1e1f8a458da2872b2afca367581cbad86e44bb32e73e6d265fcc264384a10f042efeb2ee9923a51&amp;a=w%3D250%26h%3D212%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 250w,/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/00fdd54d7c5476a949a0b55c2fcbe6a1/451-report-large.png?eu=8c8d56e0e59ba9800a3ca8d13a703138b53901f8a80265853430e7f91afdca8224f2105227907ce52d6d08d982e913bb61957e6411e6d48bc3bc1afceb36fe5b50d008bf66ba77025823c2f7e5f754146cc71c5ca984ca0fa56a7a87b4e1e2261b50487aae7fba87edf83f3cf4c76f71e0a9b9773893fc2da30c0d109d4932bf31ffd3c06d4baad1b75db1b5a8f3089b94ba6a005fdfb436782019633dbe2cffc3e7583b3c6e33124bbafb47c43495e2341a6927595c07f53538d556fe693291eda8a65ede7f7ce9abcf382199c7ab81f058f96a29a58b3af5d3792d5b13ec4dfa&amp;a=w%3D500%26h%3D424%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z 500w" alt="451-report-large" src="https://bitwarden.com/_gatsby/image/4e5e3d154f35b3344a2078aed67ab21d/0d414a94e96c8d654d892bf67fd45b81/451-report-large.png?eu=d78754b2b29cfc83593aa1846b7a643fb63d02f9af583f813430b0ab4baacd8772f14d04749178b62b685adb86e340bf6ece7e661ebbd48993be4efcbe60ad0807d70bee31e226045128c0fdb8f2544c3a951250a9d09a5aa13c77d7e2b7b3264a541b23a878be87e9aa6360e3802e67b8b4a12a31c6aa7fe515540c8f5c31bf6ea48f876e4fb99bf301bca2b8f84a8ec9a36e191e8eb72a2535124c1eb72cedadef4376262d07586f99fa24a23297f25a493d695b1870be194e844af8393297ecfda959de797fe3facb347383c6add2e449ab2971e2c82faa84322b1109a912b0fe2eb78d264213dd7bb8c219ac435b62&amp;a=w%3D125%26h%3D106%26fm%3Dpng%26q%3D75&amp;cd=2023-08-16T22%3A27%3A55.124Z"></picture></div><div data-testid="card-content"><p data-testid="card-headline"><h4>451 Research PDF Download</h4></p><div data-testid="card-subtext"> <p>2022 Enterprise Password Management Report</p></div></div></div><div id="pricing-section-personal-tab-selected"><h3>Choose the plan that fits your needs</h3><div><div id="tabpanel-undefined-0" role="tabpanel" aria-labelledby="tab-undefined-0" data-testid="tabpanel-undefined-0"><div><div><h5 data-testid="pricing-headline">Free</h5><p data-testid="pricing-price"><span></span><sup data-testid="pricing-currency">$</sup><span>0</span></p><p><span><p data-testid="pricing-period"> per month</p><p data-testid="pricing-periodDetail">Free Forever</p></span></p><p data-testid="pricing-subtext">Get a Bitwarden vault</p><div><ul data-testid="pricing-features"><li><span title="checkbox"></span> <!-- -->Unlimited passwords</li><li><span title="checkbox"></span> <!-- -->Unlimited devices</li><li><span title="checkbox"></span> <!-- -->All the core functions</li><li><span title="checkbox"></span> <!-- -->Always free</li></ul></div><p data-testid="pricing-bottom-text">Share vault items with one other user</p></div><div><h5 data-testid="pricing-headline">Premium</h5><p data-testid="pricing-price"><span>Less than</span><sup data-testid="pricing-currency">$</sup><span>1</span></p><p><span><p data-testid="pricing-period">per month</p><p data-testid="pricing-periodDetail">$10 billed annually</p></span></p><p data-testid="pricing-subtext">Enjoy premium features</p><div><ul data-testid="pricing-features"><li><span title="checkbox"></span> <!-- -->Advanced 2FA</li><li><span title="checkbox"></span> <!-- -->Emergency access</li><li><span title="checkbox"></span> <!-- -->Bitwarden Authenticator</li><li><span title="checkbox"></span> <!-- -->Security reports and more</li></ul></div><p data-testid="pricing-bottom-text">Share vault items with one other user</p></div><div><h5 data-testid="pricing-headline">Families</h5><p data-testid="pricing-price"><span></span><sup data-testid="pricing-currency">$</sup><span>3.33</span></p><p><span><p data-testid="pricing-period">per month</p><p data-testid="pricing-periodDetail">Up to 6 users, $40 billed annually</p></span></p><p data-testid="pricing-subtext">Secure your family logins</p><div><ul data-testid="pricing-features"><li><span title="checkbox"></span> <!-- -->6 premium accounts</li><li><span title="checkbox"></span> <!-- -->Unlimited sharing</li><li><span title="checkbox"></span> <!-- -->Unlimited collections</li><li><span title="checkbox"></span> <!-- -->Organization storage</li></ul></div><p data-testid="pricing-bottom-text">Share vault items between six people</p></div></div><p>Pricing shown in USD and based on an annual subscription</p></div><div id="tabpanel-undefined-1" role="tabpanel" aria-labelledby="tab-undefined-1" data-testid="tabpanel-undefined-1"><div><div><h5 data-testid="pricing-headline">Teams</h5><p data-testid="pricing-price"><span></span><sup data-testid="pricing-currency">$</sup><span>3</span></p><p><span><p data-testid="pricing-period">per month/per user</p></span></p><p data-testid="pricing-subtext">Share sensitive data safely with coworkers, across departments, or the entire company</p><p data-testid="pricing-bottom-text">Includes premium features for all users</p></div><div><h5 data-testid="pricing-headline">Enterprise</h5><p data-testid="pricing-price"><span></span><sup data-testid="pricing-currency">$</sup><span>5</span></p><p><span><p data-testid="pricing-period">per month/per user</p></span></p><p data-testid="pricing-subtext">Utilize advanced features including policies, passwordless SSO, account recovery, and more</p><p data-testid="pricing-bottom-text">Includes premium features and complimentary families plan for all users</p></div><div><h5 data-testid="pricing-headline">Get a Quote</h5><p data-testid="pricing-subtext">For companies with hundreds or thousands of employees contact sales for a custom quote and see how Bitwarden can: </p><div><ul data-testid="pricing-features"><li><span title="checkbox"></span> <!-- -->Reduce cybersecurity risk</li><li><span title="checkbox"></span> <!-- -->Boost productivity</li><li><span title="checkbox"></span> <!-- -->Integrate seamlessly</li></ul></div><p data-testid="pricing-bottom-text">Bitwarden scales with any sized business to bring password security to your organization.</p></div></div><p>Pricing shown in USD and based on an annual subscription</p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon will invest up to $4B in Anthropic (387 pts)]]></title>
            <link>https://www.anthropic.com/index/anthropic-amazon</link>
            <guid>37640466</guid>
            <pubDate>Mon, 25 Sep 2023 07:07:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/index/anthropic-amazon">https://www.anthropic.com/index/anthropic-amazon</a>, See on <a href="https://news.ycombinator.com/item?id=37640466">Hacker News</a></p>
Couldn't get https://www.anthropic.com/index/anthropic-amazon: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The State of Async Rust (191 pts)]]></title>
            <link>https://corrode.dev/blog/async/</link>
            <guid>37639896</guid>
            <pubDate>Mon, 25 Sep 2023 05:20:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://corrode.dev/blog/async/">https://corrode.dev/blog/async/</a>, See on <a href="https://news.ycombinator.com/item?id=37639896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Recently, I found myself returning to a compelling series of blog posts titled
<a href="https://aturon.github.io/blog/2016/08/11/futures/">Zero-cost futures in Rust</a>
by Aaron Turon about what would become the foundation of Rust's async ecosystem
and the <a href="https://tokio.rs/">Tokio</a> runtime.</p>
<p>This series stands as a cornerstone in writings about Rust. People like Aaron
are the reason why I wanted to be part of the Rust community in the first place.</p>
<p>While 2016 evokes nostalgic memories of excitement and fervor surrounding async
Rust, my sentiments regarding the current state of its ecosystem are now
somewhat ambivalent.</p>
<h2 id="why-bother">Why Bother?</h2>
<p>Through this series, I hope to address two different audiences:</p>
<ul>
<li>Newcomers to async Rust, seeking to get an overview of the current state of
the ecosystem.</li>
<li>Library maintainers and contributors to the async ecosystem, in the hope that
my perspective can be a basis for discussion about the future of async Rust.</li>
</ul>
<p>In the first article, we will focus on the current state of async Rust runtimes,
their design choices, and their implications on the broader Rust async ecosystem.</p>
<h2 id="one-true-runtime">One True Runtime</h2>
<p>An inconvenient truth about async Rust is that <a href="https://github.com/rust-lang/areweasyncyet.rs/issues/34">libraries still need to be
written against individual
runtimes</a>. Writing your
async code in a runtime-agnostic fashion requires <a href="https://github.com/launchbadge/sqlx/blob/d0fbe7feff4b3a200cf0453417d5e53bd011643a/sqlx-core/src/rt/mod.rs#L116-L136">conditional
compilation</a>,
<a href="https://docs.rs/async-compat/latest/async_compat">compatibility layers</a> and
<a href="https://github.com/seanmonstar/reqwest/issues/719#issuecomment-558758637">handling
edge-cases</a>.</p>
<p>This is the rationale behind most libraries gravitating towards the
One True Runtime — <a href="https://tokio.rs/">Tokio</a>.</p>
<p>Executor coupling is a big problem for async Rust as it breaks the ecosystem
into silos. <a href="https://www.reddit.com/r/rust/comments/f10tcq/confusion_with_rusts_async_architecture_and_how/fh1oagw/">Documentation and examples for one runtime don't work with the
other
runtimes</a>.</p>
<p>Moreover, much of the existing documentation on async Rust feels outdated or
incomplete. For example, the async book remains in draft, with concepts like
<code>FuturesUnordered</code> yet to be covered. (There is an open <a href="https://github.com/rust-lang/async-book/pull/96">pull
request</a>, though.)</p>
<p>That leaves us with a situation that is unsatisfactory for everyone involved:</p>
<ul>
<li>For new users, it is a big ask to <a href="https://github.com/rust-netlink/netlink-proto/issues/7">navigate this space</a> and make future-proof decisions.</li>
<li>For experienced users and library maintainers, <a href="https://github.com/launchbadge/sqlx/issues/1669#issuecomment-1032132220">supporting multiple runtimes is an additional burden</a>. It's no surprise that popular crates like <a href="https://github.com/seanmonstar/reqwest"><code>reqwest</code></a> <a href="https://github.com/seanmonstar/reqwest/blob/master/Cargo.toml#L109">simply insist on Tokio as a runtime</a>.</li>
</ul>
<p>This close coupling, <a href="https://github.com/rust-lang/wg-async/issues/45">recognized by the async working
group</a>, has me worried about
its potential long-term impact on the ecosystem.</p>
<h2 id="the-case-of-async-std">The case of <code>async-std</code></h2>
<p><code>async-std</code> was an attempt to create an alternative runtime that is closer to
the Rust standard library. Its promise was that you could almost use it as a
drop-in replacement.</p>
<p>Take, for instance, this straightforward synchronous file-reading code:</p>
<pre data-lang="rust"><code data-lang="rust"><span><span>use</span> <span>std<span>::</span></span><span>fs<span>::</span></span>File<span>;</span>
<span>use</span> <span>std<span>::</span></span><span>io<span>::</span></span>Read<span>;</span>

<span><span><span>fn</span> </span><span>main</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>std<span>::</span></span><span>io<span>::</span></span><span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
    <span>let</span> <span>mut</span> file <span>=</span> <span>File<span>::</span></span>open<span><span>(</span><span><span>"</span>foo.txt<span>"</span></span></span><span><span>)</span></span><span>?</span><span>;</span>
    <span>let</span> <span>mut</span> data <span>=</span> <span>vec!</span><span><span>[</span><span>]</span></span><span>;</span>
    file<span>.</span><span>read_to_end</span><span><span>(</span><span>&amp;</span><span>mut</span> data</span><span><span>)</span></span><span>?</span><span>;</span>
    <span>Ok</span><span><span>(</span><span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span>
</span><span><span>}</span></span></span>
</span></code></pre>
<p>In <code>async-std</code>, it is an <a href="https://docs.rs/async-std/latest/async_std/fs/struct.File.html#method.open">async
operation</a>
instead:</p>
<pre data-lang="rust"><code data-lang="rust"><span><span>use</span> <span>async_std<span>::</span></span><span>prelude<span>::</span></span><span>*</span><span>;</span>
<span>use</span> <span>async_std<span>::</span></span><span>fs<span>::</span></span>File<span>;</span>
<span>use</span> <span>async_std<span>::</span></span>io<span>;</span>

async <span><span><span>fn</span> </span><span>read_file</span></span><span><span><span>(</span><span>path</span><span>:</span> <span>&amp;</span><span>str</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>io<span>::</span></span><span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
    <span>let</span> <span>mut</span> file <span>=</span> <span>File<span>::</span></span>open<span><span>(</span>path</span><span><span>)</span></span><span>.</span>await<span>?</span><span>;</span>
    <span>let</span> <span>mut</span> data <span>=</span> <span>vec!</span><span><span>[</span><span>]</span></span><span>;</span>
    file<span>.</span><span>read_to_end</span><span><span>(</span><span>&amp;</span><span>mut</span> data</span><span><span>)</span></span><span>.</span>await<span>?</span><span>;</span>
    <span>Ok</span><span><span>(</span><span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span>
</span><span><span>}</span></span></span>
</span></code></pre>
<p>The only difference is the <code>await</code> keyword.</p>
<p>While the the name might suggest it, <code>async-std</code> is not a drop-in replacement
for the standard library as there are many <a href="https://github.com/seanmonstar/reqwest/issues/719#issuecomment-558758637">subtle differences between the
two</a>.</p>
<p>It is hard to create a runtime that is fully compatible with the standard
library. Here are some examples of issues that are still open:</p>
<ul>
<li><a href="https://github.com/async-rs/async-std/issues/731">New thread is spawned for every I/O request</a></li>
<li><a href="https://github.com/async-rs/async-std/issues/914">OpenOptionsExt missing for Windows?</a></li>
<li><a href="https://github.com/async-rs/async-std/issues/900">Spawned task is stuck during flushing in
File.drop()</a></li>
</ul>
<p>It is an enormous effort to replicate the standard library and it is not clear
to me if it is worth it.</p>
<p>Even if it <em>were</em> a drop-in replacement, I'd still ponder its actual merit.
Rust is a language that values explicitness. This is especially true for
reasoning about runtime behavior, such as allocations and blocking operations.
The async-std's teams proposal to <a href="https://www.reddit.com/r/rust/comments/ebfj3x/stop_worrying_about_blocking_the_new_asyncstd/">"Stop worrying about
blocking"</a>
was met with a <a href="https://www.reddit.com/r/rust/comments/ebpzqx/do_not_stop_worrying_about_blocking_in_async">harsh community
response</a>
and later retracted.</p>
<p>As of this writing, <a href="https://lib.rs/crates/async-std/rev">1754 public crates have a dependency on
<code>async-std</code></a> and there
are companies that <a href="https://github.com/launchbadge/sqlx/issues/1669#issuecomment-1028879475">rely on it in
production</a>.</p>
<p>However, looking at the commits over time <code>async-std</code> is essentially abandoned
as there is <a href="https://github.com/async-rs/async-std/graphs/contributors">no active development
anymore</a>:</p>
<p><img src="https://corrode.dev/blog/async/async-std-github.svg" alt="Fading async-std contribution graph on Github"></p>
<p>This leaves those reliant on the <a href="https://docs.rs/async-std/latest/async_std/"><code>async-std</code>
API</a> – be it for concurrency
mechanisms, extension traits, or otherwise – in an unfortunate situation, as is
the case for libraries developed on top of <code>async-std</code>, such as
<a href="https://github.com/http-rs/surf"><code>surf</code></a>. The core of <code>async-std</code> is now
powered by <a href="https://github.com/smol-rs/smol"><code>smol</code></a>, but it is probably best to
use it directly for new projects.</p>
<h2 id="can-t-we-just-embrace-tokio">Can't we just embrace Tokio?</h2>
<p>Tokio stands as Rust's canonical async runtime.
But to label Tokio merely as a runtime would be an understatement.
It has extra modules for
<a href="https://docs.rs/tokio/latest/tokio/fs/index.html">fs</a>,
<a href="https://docs.rs/tokio/latest/tokio/io/index.html">io</a>,
<a href="https://docs.rs/tokio/latest/tokio/net/index.html">net</a>,
<a href="https://docs.rs/tokio/latest/tokio/process/index.html">process-</a> and <a href="https://docs.rs/tokio/latest/tokio/signal/index.html">signal
handling</a> and
<a href="https://docs.rs/tokio/latest/tokio/#modules">more</a>.
That makes it more of a framework for asynchronous programming than just a
runtime.</p>
<p>Partially, this is because Tokio had a pioneering role in async Rust. It
explored the design space as it went along. And while you could exclusively use
the runtime and ignore the rest, it is easier and more common to buy into the
entire ecosystem.</p>
<p>Yet, my main concern with Tokio is that it makes a lot of assumptions about how
async code should be written and where it runs.</p>
<p>For example, <a href="https://docs.rs/tokio/latest/tokio/">at the beginning of the Tokio
documentation</a>, they state:</p>
<p>"The easiest way to get started is to enable all features. Do this by enabling
the <code>full</code> feature flag":</p>
<pre data-lang="rust"><code data-lang="rust"><span>tokio <span>=</span> <span><span>{</span> version <span>=</span> <span><span>"</span>1<span>"</span></span><span>,</span> features <span>=</span> <span><span>[</span><span><span>"</span>full<span>"</span></span><span>]</span></span> </span><span><span>}</span></span>
</span></code></pre>
<p>By doing so, one would set up a <a href="https://docs.rs/tokio/latest/tokio/attr.main.html">multi-threaded
runtime</a> which mandates that
types are <code>Send</code> and <code>'static</code> and makes it necessary to use synchronization
primitives such as <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html"><code>Arc</code></a>
and <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html"><code>Mutex</code></a> for all but
the most trivial applications.</p>
<blockquote>
<p>The Original Sin of Rust async programming is making it multi-threaded by
default. If premature optimization is the root of all evil, this is the mother
of all premature optimizations, and it curses all your code with the unholy
<code>Send + 'static</code>, or worse yet <code>Send + Sync + 'static</code>, which just kills all the
joy of actually writing Rust.</p>
<p>— <a href="https://maciej.codes/2022-06-09-local-async.html">Maciej Hirsz</a></p>
</blockquote>
<p>Any time we reach for an <code>Arc</code> or a <code>Mutex</code> it's good idea to stop for a moment
and think about the future implications of that decision.</p>
<p>The choice to use Arc or Mutex might be indicative of a design that
hasn't fully embraced the ownership and borrowing principles that Rust
emphasizes. It's worth reconsidering if the shared state is genuinely necessary
or if there's an alternative design that could minimize or eliminate the need
for shared mutable state.</p>
<p>The problem, of course, is that Tokio imposes this design on you. It's not your
choice to make. </p>
<p>Beyond the complexities of architecting async code atop these synchronization
mechanisms, they carry a performance cost: Locking means runtime overhead and
additional memory usage; in embedded environments, these mechanisms are often
not available at all.</p>
<p><strong>Multi-threaded-by-default runtimes cause accidental complexity completely
unrelated to the task of writing async code.</strong></p>
<p>Ideally, we'd lean on an explicit
<code>spawn::async</code> instead of <code>spawn::blocking</code>. Futures should be designed for
brief, scoped lifespans rather than the 'static lifetime.</p>
<p>Maciej suggested to use a <a href="https://maciej.codes/2022-06-09-local-async.html">local async
runtime</a> which is
single-threaded by default and does <strong>not</strong> require types to be <code>Send</code> and
<code>'static</code>.</p>
<p>I fully agree.</p>
<p>However, I have little hope that the Rust community will change course at this
point. Tokio's roots run deep within the ecosystem and it feels like for better
or worse we're stuck with it.</p>
<p>In the realms of networking and web operations, it's likely that one of your
dependencies integrates Tokio, effectively nudging you towards its adoption. At
the time of writing, <a href="https://lib.rs/crates/tokio/rev">Tokio is used at runtime in 20,768 crates (of which 5,245
depend on it optionally)</a>.</p>
<p><img src="https://corrode.dev/blog/async/runtimes.svg" alt="Runtime popularity bar chart between tokio, async-std, and smol with Tokio greatly dominating"></p>
<p>In spite of all this, we should not stop innovating in the async space!</p>
<h2 id="other-runtimes">Other Runtimes</h2>
<p>Going beyond Tokio, several other runtimes deserve more attention:</p>
<ul>
<li><a href="https://github.com/smol-rs/smol">smol</a>: A small async runtime,
which is easy to understand. The entire executor is around
<a href="https://github.com/smol-rs/async-executor/blob/master/src/lib.rs">1000 lines of code</a>
with other parts of the ecosystem being similarly small.</li>
<li><a href="https://github.com/embassy-rs/embassy">embassy</a>: An async runtime for
embedded systems.</li>
<li><a href="https://github.com/DataDog/glommio">glommio</a>: An async runtime for I/O-bound
workloads, built on top of io_uring and using a thread-per-core model.</li>
</ul>
<p>These runtimes are important, as they explore alternative paths or open up new
use cases for async Rust. Drawing a parallel with, <a href="https://mastodon.social/@mre/111019994687648975">Rust's error handling
story</a>, the hope is that
competing designs will lead to a more robust foundation overall.
Especially, iterating on smaller runtimes that are less invasive and
single-threaded by default can help improve Rust's async story.</p>
<h2 id="async-vs-threads">Async vs Threads</h2>
<p>Regardless of runtime choice, we end up doing part of the kernel's job in user
space.</p>
<p>If you allow me a play on <a href="https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule">Greenspun's tenth
rule</a>:</p>
<blockquote>
<p>Any sufficiently advanced async Rust program contains an ad hoc,
informally-specified, potentially bug-ridden implementation of half of an
operating system's scheduler.</p>
</blockquote>
<p>Modern operating systems come with highly optimized schedulers that are
excellent at multitasking and support async I/O through
<a href="https://lwn.net/Articles/776703/">io_uring</a> and
<a href="https://github.com/mre/fcat">splice</a>. We should make better use of these
capabilities.</p>
<p>Let's finally address the elephant in the room:
<a href="https://doc.rust-lang.org/std/thread/">Threads</a>, with their familiarity,
present a path to make synchronous code faster with minimal adjustments.</p>
<p>For example, take our sync code to read a file from above and put it into a
function:</p>
<pre data-lang="rust"><code data-lang="rust"><span><span><span><span>fn</span> </span><span>read_contents</span></span><span><span>&lt;</span>T<span>:</span> <span><span>AsRef</span><span>&lt;</span>Path<span>&gt;</span></span><span>&gt;</span></span><span><span><span>(</span><span>file</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span><span>Result</span><span>&lt;</span><span>String</span>, <span><span>Box</span><span>&lt;</span>dyn Error<span>&gt;</span></span><span>&gt;</span></span></span> </span><span><span><span>{</span>
    <span>let</span> <span>mut</span> file <span>=</span> <span>File<span>::</span></span>open<span><span>(</span>file</span><span><span>)</span></span><span>?</span><span>;</span>
    <span>let</span> <span>mut</span> contents <span>=</span> <span>String</span><span><span>::</span></span>new<span><span>(</span></span><span><span>)</span></span><span>;</span>
    file<span>.</span><span>read_to_string</span><span><span>(</span><span>&amp;</span><span>mut</span> contents</span><span><span>)</span></span><span>?</span><span>;</span>
    <span>return</span> <span>Ok</span><span><span>(</span>contents</span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span></span>
</span></code></pre>
<p>We can call this function inside the new <a href="https://doc.rust-lang.org/std/thread/fn.scope.html">scoped
threads</a>:</p>
<pre data-lang="rust"><code data-lang="rust"><span><span>use</span> <span>std<span>::</span></span><span>error<span>::</span></span>Error<span>;</span>
<span>use</span> <span>std<span>::</span></span><span>fs<span>::</span></span>File<span>;</span>
<span>use</span> <span>std<span>::</span></span><span>io<span>::</span></span>Read<span>;</span>
<span>use</span> <span>std<span>::</span></span><span>path<span>::</span></span>Path<span>;</span>
<span>use</span> <span>std<span>::</span></span><span><span>{</span>thread<span>,</span> time</span><span><span>}</span></span><span>;</span>

<span><span><span>fn</span> </span><span>main</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
    <span>thread<span>::</span></span>scope<span><span>(</span><span><span><span>|</span></span></span><span><span><span>scope</span><span>|</span></span> </span><span><span><span>{</span>
                scope<span>.</span><span>spawn</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span><span>{</span>
            <span>let</span> contents <span>=</span> <span>read_contents</span><span><span>(</span><span><span>"</span>foo.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
                    </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>

                scope<span>.</span><span>spawn</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span><span>{</span>
            <span>let</span> contents <span>=</span> <span>read_contents</span><span><span>(</span><span><span>"</span>bar.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
                    </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>

                scope<span>.</span><span>spawn</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span><span>{</span>
            <span>let</span> contents <span>=</span> <span>read_contents</span><span><span>(</span><span><span>"</span>baz.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
                    </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>
    </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>

    <span> No join; threads get joined
</span>    <span> automatically once the scope ends
</span></span><span><span>}</span></span></span>
</span></code></pre>
<p>(<a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=890ada80a65e9057c4a0fc46199caf0c">Link to playground</a>)</p>
<p>That code looks almost identical to the single-threaded version! Notably, there
are no <code>.await</code> calls.</p>
<p>Were <code>read_contents</code> part of a public API, it could be used by both async and
sync callers, eliminating the need for an asynchronous runtime.</p>
<p>Async Rust might be more memory-efficient than threads, at the cost of
complexity and worse ergonomics. As an example, if the function were <em>async</em> and
you called it <em>outside</em> of a runtime, it would compile, but not run. Futures do
nothing unless being polled. This is a common footgun for newcomers.</p>
<pre data-lang="rust"><code data-lang="rust"><span>async <span><span><span>fn</span> </span><span>read_contents</span></span><span><span>&lt;</span>T<span>:</span> <span><span>AsRef</span><span>&lt;</span>Path<span>&gt;</span></span><span>&gt;</span></span><span><span><span>(</span><span>file</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span><span>Result</span><span>&lt;</span><span>String</span>, <span><span>Box</span><span>&lt;</span>dyn Error<span>&gt;</span></span><span>&gt;</span></span></span> </span><span><span><span>{</span>
    <span> ...
</span></span><span><span>}</span></span></span>

<span><span>#</span><span>[</span><span>tokio</span>::<span>main</span><span>]</span></span>
async <span><span><span>fn</span> </span><span>main</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
    <span> This will print a warning, but compile and do nothing at runtime
</span>    <span>read_contents</span><span><span>(</span><span><span>"</span>foo.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span></span>
</span></code></pre>
<p>(<a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=7dc4bc6783691c42fbf4cd5a76251da2">Link to playground</a>)</p>
<p>In a recent benchmark, <a href="https://vorner.github.io/async-bench.html">async Rust was 2x faster than
threads</a>, but the <em>absolute</em>
difference was only <em>10ms per request</em>. To put this into perspective, <a href="https://github.com/bdrung/startup-time">this
about as long as PHP takes to start</a>. In
other words, the difference is negligible for most applications.</p>
<p>A <a href="https://news.ycombinator.com/item?id=37641640">clarification on the aforementioned
benchmark</a>: Upon a closer
inspection, the disparity between async Rust and threads is notably smaller than
initially mentioned. In scenarios with a limited number of threads, traditional
threading even outperformed the async approach. This underscores the core
premise that, in real-world applications, the performance distinctions between
the two approaches are often negligible, if not slightly favoring threads. Thus,
it's crucial not to gravitate towards async Rust driven solely by anticipated
performance gains.</p>
<p>Thread-based frameworks, like the now-inactive
<a href="https://github.com/iron/iron">iron</a>, showcased the capability to effortlessly
handle <a href="https://github.com/iron/iron/wiki/How-to-Benchmark-hello.rs-Example">tens of thousands of requests per
second</a>.
This is further complemented by the fact modern Linux systems can manage <a href="https://thetechsolo.wordpress.com/2016/08/28/scaling-to-thousands-of-threads/">tens
of thousands of
threads</a>.</p>
<p>Turns out, computers are pretty good at doing multiple things at once!</p>
<p>As an important caveat, threads are not available or feasible in all
environments, such as embedded systems. My context for this article is primarily
conventional server-side applications that run on top of platforms like Linux or
Windows.</p>
<p>I would like to add that threaded code in Rust undergoes the same stringent
safety checks as the rest of your Rust code: It is protected from data races,
null dereferences, and dangling references, ensuring a level of thread safety
that prevents many common pitfalls found in concurrent programming, Since there
is no garbage collector, there never will be any stop-the-world pause to reclaim
memory. Traditional arguments against threads simply don't apply to Rust —
fearless concurrency is your friend!</p>
<p>If you find yourself needing to share state between threads, consider using a
channel:</p>
<pre data-lang="rust"><code data-lang="rust"><span><span>use</span> <span>std<span>::</span></span><span>error<span>::</span></span>Error<span>;</span>
<span>use</span> <span>std<span>::</span></span><span>path<span>::</span></span>Path<span>;</span>
<span>use</span> <span>std<span>::</span></span><span>sync<span>::</span></span>mpsc<span>;</span>
<span>use</span> <span>std<span>::</span></span>thread<span>;</span>

<span><span>//</span> Our error type needs to be `Send` to be used in a channel
</span><span><span>//</span> That's the only change we need to make to our original code
</span><span><span><span>fn</span> </span><span>read_contents</span></span><span><span>&lt;</span>T<span>:</span> <span><span>AsRef</span><span>&lt;</span>Path<span>&gt;</span></span><span>&gt;</span></span><span><span><span>(</span><span>file</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span><span>Result</span><span>&lt;</span><span>String</span>, <span><span>Box</span><span>&lt;</span>dyn Error <span>+</span> <span>Send</span><span>&gt;</span></span><span>&gt;</span></span></span> </span><span><span><span>{</span>
    <span>todo!</span><span><span>(</span></span><span><span>)</span></span>
</span><span><span>}</span></span></span>

<span><span><span>fn</span> </span><span>main</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
    <span>let</span> <span><span>(</span>tx<span>,</span> rx</span><span><span>)</span></span> <span>=</span> <span>mpsc<span>::</span></span>channel<span><span>(</span></span><span><span>)</span></span><span>;</span>

    <span>thread<span>::</span></span>scope<span><span>(</span><span><span><span>|</span></span></span><span><span><span>scope</span><span>|</span></span> </span><span><span><span>{</span>
        scope<span>.</span><span>spawn</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span><span>{</span>
            <span>let</span> contents <span>=</span> <span>read_contents</span><span><span>(</span><span><span>"</span>foo.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
            tx<span>.</span><span>send</span><span><span>(</span>contents</span><span><span>)</span></span><span>.</span><span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
        </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>
        scope<span>.</span><span>spawn</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span><span>{</span>
            <span>let</span> contents <span>=</span> <span>read_contents</span><span><span>(</span><span><span>"</span>bar.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
            tx<span>.</span><span>send</span><span><span>(</span>contents</span><span><span>)</span></span><span>.</span><span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
        </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>
        scope<span>.</span><span>spawn</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span><span>{</span>
            <span>let</span> contents <span>=</span> <span>read_contents</span><span><span>(</span><span><span>"</span>baz.txt<span>"</span></span></span><span><span>)</span></span><span>;</span>
            tx<span>.</span><span>send</span><span><span>(</span>contents</span><span><span>)</span></span><span>.</span><span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
        </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>
    </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>

    <span> Receive messages from the channel
</span>    <span>for</span> received <span>in</span> rx <span><span>{</span>
        <span>println!</span><span><span>(</span></span><span><span><span>"</span>Got: <span>{:?}</span><span>"</span></span></span><span><span>,</span> received<span>)</span></span><span>;</span>
    </span><span><span>}</span></span>
</span><span><span>}</span></span></span>
</span></code></pre>
<h2 id="summary">Summary</h2>
<h3 id="use-async-rust-sparingly">Use Async Rust Sparingly</h3>
<p>My original intention was to advise newcomers to sidestep async Rust for now,
giving the ecosystem time to mature. However, I since acknowledged that this is
not feasible, given that a lot of libraries are async-first and new users will
encounter async Rust one way or another.</p>
<p>Instead, I would recommend to use async Rust only when you really need it. Learn
how to write good synchronous Rust first and then, if necessary, transition to
async Rust. Learn to walk before you run.</p>
<p>If you have to use async Rust, stick to Tokio and well-established libraries
like <a href="https://github.com/seanmonstar/reqwest">reqwest</a> and
<a href="https://github.com/launchbadge/sqlx">sqlx</a>.</p>
<p>While it may seem surprising given the context of this article, we can't
overlook Tokio's stronghold within the ecosystem. A vast majority of libraries
are tailored specifically for it. Navigating compatibility crates can pose
challenges, and sidestepping Tokio doesn't guarantee your dependencies won't
bring it in. I'm hoping for a future shift towards leaner runtimes, but for now,
Tokio stands out as the pragmatic choice for real-world implementations.</p>
<p>However, it's valuable to know that there are alternatives to Tokio and that
they are worth exploring.</p>
<h3 id="consider-the-alternatives">Consider The Alternatives</h3>
<p>At its core, Rust and its standard library offer just the absolute
essentials for <code>async/await</code>. The bulk of the work is done in
crates developed by the Rust community.
We should make more use of the ability to iterate on async Rust and
experiment with different designs before we settle on a final solution.</p>
<p>In binary crates, think twice if you really need to use async. It's probably
easier to just spawn a thread and get away with blocking I/O. In case you have a
CPU-bound workload, you can use <a href="https://github.com/rayon-rs/rayon">rayon</a> to
parallelize your code.</p>
<blockquote>
<p>If you don't need async for performance reasons, threads can often be the
simpler alternative. — <a href="https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html#async-vs-threads-in-rust">the Async Book</a></p>
</blockquote>
<h3 id="isolate-async-code">Isolate Async Code</h3>
<p>If async is truly indispensable, consider isolating your async code from the
rest of your application.</p>
<p>Keep your domain logic synchronous and only use async for I/O and external
services. Following these guidelines will make your code <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">more
composable</a>
and accessible. On top of that, the error messages of sync Rust are much easier
to reason about than those of async Rust.</p>
<p>In your public library code, avoid async-only interfaces to make downstream
integration easier.</p>
<h3 id="keep-it-simple">Keep It Simple</h3>
<p><a href="https://www.chiark.greenend.org.uk/~ianmdlvl/rust-polyglot/async.html">Async Rust feels like a different
dialect</a>,
significantly more brittle than the rest of the language.</p>
<p>The default mode for writing Rust should be <em>synchronous</em>. Freely after
<a href="https://news.ycombinator.com/item?id=22206779">Stroustup</a>:<br>
<em>Inside Rust, there is a smaller, simpler language that is waiting to get out.</em>
It is this language that most Rust code should be written in.</p>
</div><p><span>Revision notes:</span> In an earlier version of this article, I discussed async web frameworks.
However, to maintain focus, I've opted to address web frameworks in a dedicated
follow-up article.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: There is a highlights page on HN (181 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37639010</link>
            <guid>37639010</guid>
            <pubDate>Mon, 25 Sep 2023 02:17:39 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37639010">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37639739"><td></td></tr>
                <tr id="37639966"><td></td></tr>
            <tr id="37640778"><td></td></tr>
                <tr id="37640941"><td></td></tr>
                        <tr id="37641034"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37641034" href="https://news.ycombinator.com/vote?id=37641034&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><br><div>
                  <p><span>Nice to see Clifford Stoll currently topping the page. I bought The Cuckoo's Egg after reading enough people recommending it on HN and so to see the author referencing the main events in that book as the most recent highlight kinda brings things full circle!</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37640334"><td></td></tr>
                <tr id="37640650"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37640650" href="https://news.ycombinator.com/vote?id=37640650&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><p><span>"past" in the top-of-page header, which has a granularity of 1 day.<p>I've been looking at an archive of past front pages dating to 2007 to see trends, patterns, and statistics concerning front-page stories, since late May of this year.  It's interesting, and resolves some common disputes and/or claims.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37640349"><td></td></tr>
                  <tr id="37640365"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37640365" href="https://news.ycombinator.com/vote?id=37640365&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><br><div>
                  <p><span>I hesitate to admit this, since I have a 14 year old account- but this is the first I have ever heard of /lists. I can get to it by appending "/lists" to the url, but I can't see a "lists" link anywhere on the site- is it some kind of hidden page? If so- are there more?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37640378"><td></td></tr>
                <tr id="37641012"><td></td></tr>
                        <tr id="37640075"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37640075" href="https://news.ycombinator.com/vote?id=37640075&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><br><div>
                  <p><span>This is my favorite thing on HN. I have a tab open with it that I “Snooze until next month” (in Firefox) and read whenever it pops up :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37640221"><td></td></tr>
                <tr id="37640249"><td></td></tr>
                        <tr id="37640095"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37640095" href="https://news.ycombinator.com/vote?id=37640095&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><br><div>
                  <p><span>Would be nice if the mod / highligher added an annotation for why the comment is insightful and/or remarkable.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37640662"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37640662" href="https://news.ycombinator.com/vote?id=37640662&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><p><span>I like this page better when it’s not pre-chewed. It’s nice to read something without a specific expectation or context.<p>Most of the highlighted comments fall under the heading “I was around when X happened” though. The list could almost be titled “first-hand-experiences”.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37640277"><td></td></tr>
                <tr id="37640776"><td></td></tr>
                  <tr id="37640234"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37640234" href="https://news.ycombinator.com/vote?id=37640234&amp;how=up&amp;goto=item%3Fid%3D37639010"></a></center>    </td><td><p><span>Thanks for bringing attention to this. I will add this endpoint to my hacker news app HACK.<p>Are there any other endpoints people don't know about?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37641061"><td></td></tr>
            <tr id="37640314"><td></td></tr>
                  <tr id="37639580"><td></td></tr>
            <tr id="37640103"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan pharma startup to begin human trials of tooth regrowth drug in 2024 (178 pts)]]></title>
            <link>https://english.kyodonews.net/news/2023/09/d56fb464a52b-japan-pharma-startup-developing-world-first-drug-to-grow-new-teeth.html</link>
            <guid>37638956</guid>
            <pubDate>Mon, 25 Sep 2023 02:05:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.kyodonews.net/news/2023/09/d56fb464a52b-japan-pharma-startup-developing-world-first-drug-to-grow-new-teeth.html">https://english.kyodonews.net/news/2023/09/d56fb464a52b-japan-pharma-startup-developing-world-first-drug-to-grow-new-teeth.html</a>, See on <a href="https://news.ycombinator.com/item?id=37638956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>A team of scientists led by a Japanese pharmaceutical startup has been working on a drug to stimulate the growth of new teeth in what would be a world-first, aiming to put it on the market by around 2030.</p>
<p>Toregem Biopharma Co., funded by Kyoto University, is expected to begin clinical trials on healthy adults in around July 2024 to confirm the drug's safety, after the team succeeded in growing new teeth in mice in 2018.</p>
<p>Most people have "tooth buds" that have the potential to become a new tooth, in addition to baby and permanent teeth, although the buds usually do not develop and subsequently disappear.</p>
<div><p><img src="https://img.kyodonews.net/english/public/images/posts/5c29784a716b88b8a6dcf99d5c49043a/photo_l.jpg" width="100%"></p><p><em>Photo shows a new tooth grown in a ferret's mouth after it was administered a new drug to stimulate the growth of tooth buds. (Photo courtesy of Katsu Takahashi)(Photo use permitted only for the story concerned)(Kyodo)</em></p>
</div>
<p>The team created an antibody drug that inhibits the protein that suppresses the growth of teeth. The drug works on these buds and stimulates their growth.</p>
<p>In 2018, the team also administered the drug to ferrets, which have both baby and permanent teeth similar to humans, and new teeth grew.</p>
<p>The team plans to hold a clinical trial for the drug from 2025 for children between 2 to 6 years old with anodontia who are born without some or all permanent teeth. The children will be injected with one dose to induce their teeth growth.</p>
<p>There are also hopes to utilize the drug in the future for adults who have lost teeth due to cavities.</p>
<p>"Missing teeth in a child can affect the development of their jaw bone," said Katsu Takahashi, co-founder of Toregem Biopharma and head of dentistry and oral surgery at Kitano Hospital in Osaka.</p>
<p>"We hope the drug will serve as a key to solving those problems," he said.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why do we need modules at all? (2011) (101 pts)]]></title>
            <link>http://erlang.org/pipermail/erlang-questions/2011-May/058768.html</link>
            <guid>37638894</guid>
            <pubDate>Mon, 25 Sep 2023 01:53:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://erlang.org/pipermail/erlang-questions/2011-May/058768.html">http://erlang.org/pipermail/erlang-questions/2011-May/058768.html</a>, See on <a href="https://news.ycombinator.com/item?id=37638894">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>Joe Armstrong</b> 
    <a href="mailto:erlang-questions%40erlang.org?Subject=Re%3A%20%5Berlang-questions%5D%20Why%20do%20we%20need%20modules%20at%20all%3F&amp;In-Reply-To=%3CBANLkTik1m2fY1hJN4i%2BBeQz-Jew6AtMwQg%40mail.gmail.com%3E" title="[erlang-questions] Why do we need modules at all?">erlang@REDACTED
       </a><br>
    <i>Tue May 24 10:06:19 CEST 2011</i>
    <ul>
        <li>Previous message (by thread): <a href="http://erlang.org/pipermail/erlang-questions/2011-May/058937.html">[erlang-questions] System timers, now/0, and instrumentation
</a></li>
        <li>Next message (by thread): <a href="http://erlang.org/pipermail/erlang-questions/2011-May/058770.html">[erlang-questions] Why do we need modules at all?
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/date.html#58768">[ date ]</a>
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/thread.html#58768">[ thread ]</a>
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/subject.html#58768">[ subject ]</a>
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/author.html#58768">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Why do we need modules at all?

This is a brain-dump-stream-of-consciousness-thing. I've been
thinking about this for a while.

I'm proposing a slightly different way of programming here
The basic idea is

    - do away with modules
    - all functions have unique distinct names
    - all functions have (lots of) meta data
    - all functions go into a global (searchable) Key-value database
    - we need letrec
    - contribution to open source can be as simple as
      contributing a single function
    - there are no "open source projects" - only "the open source
      Key-Value database of all functions"
    - Content is peer reviewed

These are discussed in no particular order below:

Why does Erlang have modules?

There's a good an bad side to modules:

Good: Provides a unit of compilation, a unit of code
distribution. unit of code replacement

Bad: It's very difficult to decide which module to put an individual
function in. Break encapsulation (see later)

Aside: lib_misc.erl

When I'm programming I often get to the point were I say there should
a function foo/2 in lists.erl but their isn't. There should be but
there isn't - foo/2 is a small self contained thing. Why should it be
in lists.erl because it "feels right".

Strings are lists, so why do we have two modules lists.erl and
string.erl how should I decide in which module my new string/list
processing function should go.

To avoid all mental anguish when I need a small function that
should be somewhere else and isn't I stick it in
a module elib1_misc.erl.

My elib1_misc exports the following:

added_files/2                 make_challenge/0
as_bits/1                     make_response/2
as_bits_test/0                make_response_test/0
bdump/2                       make_test_strings/1
bin2hex/1                     make_test_strings_test/0
bin2hex_test/0                make_tmp_filename/2
check_io_list/1               merge_kv/1
collect_atom/1                merge_kv_test/0
collect_atom_test/0           mini_shell/0
collect_int/1                 module_info/0
collect_int_test/0            module_info/1
collect_string/1              ndots/1
collect_string_test/0         nibble_to_hex_char/1
collect_word/1                nibble_to_hex_char_test/0
complete/2                    odd/1
complete_test/0               on_exit/2
dos2unix/1                    out_of_date/2
downcase_char/1               outfile/2
dump/2                        padd/2
dump_tmp/2                    perms/1
duplicates/1                  perms_test/0
ensure_started/2              pmap/2
eval_file/1                   pmap1/2
eval_file_test/0              pmap1_test/0
eval_string/1                 pmap_test/0
eval_string_test/0            priority_receive/0
every/3                       random_seed/0
expand_env_vars/1             random_string/1
expand_file_template/3        random_string/2
expand_string_template/2      read_at_most_n_lines/2
expand_tabs/1                 read_at_most_n_lines_test/0
expand_tabs_test/0            remove_duplicates/1
expand_template/2             remove_duplicates_test/0
extract_attribute/2           remove_leading_and_trailing_whitespace/1
extract_attribute_test/0      remove_leading_and_trailing_whitespace_test/0
extract_prefix/2              remove_leading_whitespace/1
fetch/2                       remove_prefix/2
fetch_test/0                  remove_prefix_test/0
file2lines/1                  remove_trailing_whitespace/1
file2lines_test/0             replace/3
file2md5/1                    root_dir/0
file2numberedlines/1          rpc/2
file2numberedlines_test/0     safe/1
file2paras/1                  show_loaded/1
file2stream/1                 signed_byte_to_hex_string/1
file2string/1                 signed_byte_to_hex_string_test/0
file2template/1               skip_blanks/1
file2term/1                   skip_blanks_test/0
file_size_and_type/1          skip_to_nl/1
find_src/1                    skip_to_nl_test/0
first/1                       sleep/1
flatten_io_list/1             spawn_monitor/3
flush_buffer/0                split_at_char/2
for/3                         split_at_char_test/0
force/1                       split_list/2
foreach_chunk_in_file/3       split_list_test/0
foreach_word_in_file/2        string2exprs/1
foreach_word_in_string/2      string2exprs_test/0
forever/0                     string2html/1
get_erl_section/2             string2latex/1
get_line/1                    string2lines/1
get_line/2                    string2lines_test/0
have_common_prefix/1          string2stream/1
have_common_prefix_test/0     string2stream_test/0
hex2bin/1                     string2template/1
hex2bin_test/0                string2template_test/0
hex2list/1                    string2term/1
hex2list_test/0               string2term_test/0
hex_nibble2int/1              string2toks/1
hex_nibble2int_test/0         string2toks_test/0
id/1                          sub_binary/3
include_dir/0                 template2file/3
include_file/1                term2file/2
interleave/2                  term2string/1
is_alphanum/1                 test/0
is_blank_line/1               test1_test/0
is_prefix/2                   test_function_over_substrings/2
is_prefix_test/0              tex2pdf/1
is_response_correct/3         time_fun/2
keep_alive/2                  time_stamp/0
lines2para/1                  to_lower/1
list2frequency_distribution/1 to_lower_test/0
list2frequency_distribution_tetrim/1
longest_common_prefix/1       trim_test/0
longest_common_prefix_test/0  unconsult/2
lookup/2                      unsigned_byte_to_hex_string/1
lorem/1                       unsigned_byte_to_hex_string_test/0
ls/1                          which/1
                              which_added/1

Now I find this very convenient when I write a new small utility function
I stick in in elib1_misc.erl - no mental anguish in choosing a module
name is involved.

The observation that I find this very-convenient is telling me something
about modules - I like my elib1_misc it feels right.

(aside - It seems many development projects have their own private
lib_miscs ...)

Which brings me to the point of my question.

Do we need module's at all? Erlang programs are composed of lots of small
functions, the only place where modules seem useful is to hide a letrec.

The classic example is fibonacci. We want to expose fib/1 but hide the
helper function fib/3. Using modules we say

-module(math).
-export([fib/1]).

fib(N) -&gt;
    fib(N, 1, 0).

fib(N, A, B) when N &lt; 2 -&gt; A;
fib(N, A, B) -&gt; fib(N-1, A+B, A).

The downside is we have had to *invent* one module name math - whose *only*
purpose is to hide the definition of fib/3 which we don't want to be made
callable.

If we put a second function into the module math, then this second function
could call fib/3 which breaks the encapsulation of fib/3.

We could say:

let fib = fun(N) -&gt; fib(N, 1, 0) end
in
   fib(N, A, B) when N &lt; 2 -&gt; A;
   fib(N, A, B) -&gt; fib(N-1, A+B, A).
end.

I hardly dare suggest a syntax for this since I've been following
another thread in this forum where syntax discussion seem to encourage
much comment.

** Please do suggest alternative syntax's here - but do not comment on
other peoples suggestions ...

I would like to just talk about why we have modules.

Another question:

Does the idea of a module come from the idea that functions have to be
stored somewhere, so we store them in a file, and we slurp the
file (as a unit) into the system, so the file becomes a module?

If all the files were store by themselves in a database would this
change things.

I am thinking more and more that if would be nice to have *all* functions in
a key_value database with unique names.

lookup(foo,2) would get the definition foo foo/2 from a database.

The unique names bit is interesting - is this a good idea. Qualified
names (ie names like xxx:foo/2) or (a.b.c.foo/2) sounds like a good
idea but but when I'm programming I have to invent the xxx or the
a.b.c which is very difficult. It also involves the "decision problem"
if the namespaces xxx and a.b.c already exist I have to *choose* which
to put my new function in.

I think there might be a case for alises here joe:foo/2 could be used
while developing "joe" would expand to a horrible random local string the
real name being ab123aZwerasch123123_foo/2  but I would not be able to
publish my code or make it available to a third_part before I had
chosen a sensible name.

(( managing namespaces seems really tricky, a lot of peoople seem
to thing that the problem goes away by adding "." 's to the name
but managing a namespace with namees like foo.bar.baz.z is just as complex
as managing a namespace with names like foo_bar_baz_z or names like
0x3af312a78a3f1ae123 - the problem is that we have to go from a symbolic
name like www.a.b to a reference like 123.45.23.12 - but how do we discover
the initial name www.a.b? - there are two answers - a) we are given the name
(ie we click on a link) - we do not know the name but we search fo it ))


When programs are small we can live with "just the code" in "a few
modules" the ratio of code to meta data is high.

When programs are large we need a lot of meta-data to understand them.

I would like to see all functions with all meta-data in a data base.

I'd like to say:

   lookup(foo,2,Attribute) when Attribute =

      code|source|documentation|type signatures|revision history|authors|...

The more I think about it the more I think program development should
viewed as changing the state of a Key-Value database.

So I imagine:

    1) all functions have unique names
    2) there are no modules
    3) we discover the name of a function by searching metadata
       describing the function in a database
    4) all public functions (think open source) are in the same
       database

We could make a system to do this.

I think this would make open-source projects easier, since the
granularity of contribution goes down. You could contribute
a single function - not an entire application.

(( A problem with GUT style open source projects is there is
   not one database of functions, I often what one function from
   this project, another function from another project -- the
   granularity of reusable parts should be the individual function.

   functions are really easy to reuse
   modules are more difficult to reuse
   entire applications are very difficult to reuse
     (Unless there are isolated through a communication channel))

Possible extensions.

    1) Voting for promotion
    2) A review process

Given a raw database will *all* functions in it - we could derive an
"approved" functions database.

Popular functions could be moved to the approved database - the
review process would need to be discussed - so kind of peer-review/wiki
stuff.

Comments?

Volunteers?

/Joe
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<a href="http://erlang.org/pipermail/erlang-questions/attachments/20110524/2c016dc8/attachment.htm">http://erlang.org/pipermail/erlang-questions/attachments/20110524/2c016dc8/attachment.htm</a>&gt;
</pre>

<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="http://erlang.org/pipermail/erlang-questions/2011-May/058937.html">[erlang-questions] System timers, now/0, and instrumentation
</a></li>
	<li>Next message (by thread): <a href="http://erlang.org/pipermail/erlang-questions/2011-May/058770.html">[erlang-questions] Why do we need modules at all?
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/date.html#58768">[ date ]</a>
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/thread.html#58768">[ thread ]</a>
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/subject.html#58768">[ subject ]</a>
              <a href="http://erlang.org/pipermail/erlang-questions/2011-May/author.html#58768">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="http://erlang.org/mailman/listinfo/erlang-questions">More information about the erlang-questions
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Type 2 diabetes rates in US youth rose 62% after Covid pandemic began (166 pts)]]></title>
            <link>https://www.cidrap.umn.edu/covid-19/type-2-diabetes-rates-us-youth-rose-62-after-covid-pandemic-began-study-suggests</link>
            <guid>37638840</guid>
            <pubDate>Mon, 25 Sep 2023 01:44:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cidrap.umn.edu/covid-19/type-2-diabetes-rates-us-youth-rose-62-after-covid-pandemic-began-study-suggests">https://www.cidrap.umn.edu/covid-19/type-2-diabetes-rates-us-youth-rose-62-after-covid-pandemic-began-study-suggests</a>, See on <a href="https://news.ycombinator.com/item?id=37638840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span><span><span>Rates of new-onset type 2 diabetes climbed 62%—and type 1 diabetes increased 17%—among US youth after the COVID-19 pandemic began, especially in Black and Hispanic children, according to a </span></span><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2809781"><span><span>study</span></span></a><span><span> published yesterday in <em>JAMA Network Open</em>.</span></span></span></span></span></p>

<p><span><span><span>For the study, Kaiser Permanente researchers tracked rates of type 1 and type 2 diabetes among health system members aged 0 to 19 years in southern California with no history of diabetes from January 2016 to December 2021. </span></span></span></p>

<p><span><span><span>"Youth-onset diabetes is a serious chronic health condition, placing individuals at risk for early complications, comorbidities, and excess mortality, in particular among those who develop type 2 diabetes and those from racial and ethnic minority groups such as non-Hispanic Black individuals," the study authors wrote.</span></span></span></p>

<h3><span><span><span><span><strong><span><span>Kids aged 10 to 19 years especially affected</span></span></strong></span></span></span></span></h3>

<p><span><span><span>Over the study period, 1,200 youth were diagnosed as having type 1 diabetes, 1,100 diagnosed with type 2 diabetes, and 63 patients with "other" diabetes. Type 1 diabetes rates climbed from 18.5 per 100,000 person-years in 2016 to 2019 to 22.4 per 100,000 person-years from 2020 to 2021. </span></span></span></p>

<p><span><span><span>Relative to 2016 to 2019, in 2020 to 2021, the incidence of new-onset type 1 diabetes was 17% higher (incidence rate ratio [IRR], 1.17). The incidence was higher among patients aged 10 to 19 years (IRR,1.17), boys (IRR, 1.18), and Hispanic patients (1.21). </span></span></span></p>

<p><span><span><span>Rates of type 2 diabetes were 62% higher (IRR, 1.62) in 2020 to 2021 than in 2016 to 2019. The incidence of type 2 diabetes rose from 14.8 to 24.7 per 100,000 person-years over that time.</span></span></span></p>

<p><span><span><span>Rates were higher among patients aged 10 to 19 years (IRR, 1.63), girls (IRR, 1.44), boys (IRR, 1.83), Black patients (IRR, 1.95), Hispanic patients (IRR, 1.61), and other/unknown racial groups (IRR, 2.96). The incidence rate differences followed similar patterns for both type 1 and type 2 diabetes.</span></span></span></p>

<h3><span><span><span><span><strong><span><span>Black, Hispanic patients had heavy diabetes burden</span></span></strong></span></span></span></span></h3>

<p><span><span><span>By quarter, rates of type 1 diabetes fluctuated seasonally but climbed among patients aged 10 to 19 years in Q1 of 2021. Among youth with type 2 diabetes, a spike in incidence occurred in Q3 and Q4 of 2020, especially among Black and Hispanic patients, which the researchers said suggests that they bore a disproportionate burden of type 2 diabetes.</span></span></span></p>

<blockquote>
<p><span><span><span>Diabetes risk factors may have been exacerbated during the COVID-19 pandemic including limited physical activity, increased sedentary behaviors, sleep disturbances, and increased intake of processed foods.</span></span></span></p>
</blockquote>

<p><span><span><span>Sociodemographic factors, average body mass index, fasting and random glucose levels, and hemoglobin A<sub>1c</sub>&nbsp;concentrations didn't change from 2016 to 2021. </span></span></span></p>

<p><span><span><span>The authors noted that research has shown that coronavirus-binding via angiotensin-converting enzyme 2 (ACE2) receptors damages islet cells in the pancreas and may lead to diabetes. </span></span></span></p>

<p><span><span><span>"Hyperglycemia and insulin resistance have been noted in patients with COVID-19 infection without prior indicators of diabetes risk," they wrote. "Additionally, diabetes risk factors may have been exacerbated during the COVID-19 pandemic including limited physical activity, increased sedentary behaviors, sleep disturbances, and increased intake of processed foods." </span></span></span></p>

<p><span><span><span>The findings, they added, point to the need for future research on physiologic and behavioral risk factors for new-onset diabetes before and during the pandemic.</span></span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cutting Room Floor (102 pts)]]></title>
            <link>https://tcrf.net/The_Cutting_Room_Floor</link>
            <guid>37637921</guid>
            <pubDate>Sun, 24 Sep 2023 22:49:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tcrf.net/The_Cutting_Room_Floor">https://tcrf.net/The_Cutting_Room_Floor</a>, See on <a href="https://news.ycombinator.com/item?id=37637921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p>Welcome to The Cutting Room Floor. <a href="https://tcrf.net/Special:Statistics" title="Special:Statistics">26,998</a> articles and <a href="https://tcrf.net/The_Cutting_Room_Floor:Statistics" title="The Cutting Room Floor:Statistics">counting!</a></p>
<p><b>The Cutting Room Floor</b> is a site dedicated to unearthing and researching unused and cut content from video games. From debug menus, to unused music, graphics, enemies, or levels, many games have content never meant to be seen by anybody but the developers — or even meant for everybody, but cut due to time/budget constraints.
</p><p>Feel free to browse our <a href="https://tcrf.net/Category:Games" title="Category:Games">collection of games</a> and start reading. Up for research? Try looking at <a href="https://tcrf.net/Category:Stubs" title="Category:Stubs">some stubs</a> and see if you can help us out. Just have some faint memory of some unused menu/level you saw years ago but can't remember how to access it? Feel free to start a page with what you saw and we'll take a look. If you want to help keep this site running and help further research into games, <a href="https://tcrf.net/The_Cutting_Room_Floor:Donate" title="The Cutting Room Floor:Donate">feel free to donate</a>.
</p>
<div id="featured-area">

<h2><span id="Featured_Article">Featured Article</span></h2>
<p><a href="https://tcrf.net/Super_Mario_Bros._3" title="Let's roll the dice!"><img alt="Let's roll the dice!" src="https://tcrf.net/images/thumb/d/d8/SMB3Bonus2.png/128px-SMB3Bonus2.png" decoding="async" width="128" height="120" srcset="https://tcrf.net/images/thumb/d/d8/SMB3Bonus2.png/192px-SMB3Bonus2.png 1.5x, https://tcrf.net/images/d/d8/SMB3Bonus2.png 2x"></a></p>
<h3><span id="Super_Mario_Bros._3"><p><a href="https://tcrf.net/Super_Mario_Bros._3" title="This article has a 'Main' page!"><img alt="This article has a 'Main' page!" src="https://tcrf.net/images/3/3d/Cactisprite.png" decoding="async" width="16" height="16"></a><a href="https://tcrf.net/Prerelease:Super_Mario_Bros._3" title="This article has a 'Prerelease' page!"><img alt="This article has a 'Prerelease' page!" src="https://tcrf.net/images/8/83/PrereleaseIcon.png" decoding="async" width="16" height="16"></a></p></span></h3>
<p>Developer: <b>Nintendo</b><br>
Publisher: <b>Nintendo</b><br>
Released: 1988, <b><a href="https://tcrf.net/Category:NES_games" title="Category:NES games">NES/Famicom</a></b>
</p>

<p><i><a href="https://tcrf.net/Super_Mario_Bros._3" title="Super Mario Bros. 3">Super Mario Bros. 3</a></i> was the last main-series Mario game released on the NES. The game introduced such beloved concepts as the Koopa Kids, Super Leaves, and Tanooki Suits.
</p><p>Fifteen unused levels are tucked away in the game, only accessible through codes and hacking. Along with those levels are unused enemies, graphics, stage palettes, and two unused minigames. There's even a debug menu!
</p><p>And in addition to all of that unused content, there are a variety of differences between the Japanese and International versions of the game. The two international revisions contain some interesting differences, too! There's a lot to know about <i>Super Mario Bros. 3</i>.
</p><p><a href="https://tcrf.net/Super_Mario_Bros._3" title="Super Mario Bros. 3">Read more...</a>
</p>
<p><a href="https://tcrf.net/Category:FeaturedBlurbs" title="Category:FeaturedBlurbs">All Featured Blurbs</a></p>
</div>
<div id="dyk-area">
<p><h2><span id="Did_You_Know...">Did You Know...</span></h2></p>
<ul><li>...that there are over 30 item icons, over 50 unused voice clips, and sprites for several unused moves for Richter in <i><a href="https://tcrf.net/Castlevania:_Symphony_of_the_Night_(PlayStation)" title="Castlevania: Symphony of the Night (PlayStation)">Castlevania: Symphony of the Night</a></i>?<br></li>
<li>...that there are 9 unused items in <i><a href="https://tcrf.net/Lunar:_Eternal_Blue" title="Lunar: Eternal Blue">Lunar: Eternal Blue</a></i>, including the famous Dark Scimitar weapon?<br></li>
<li>...that Side B of the Apple II <i><a href="https://tcrf.net/Karateka_(Apple_II)" title="Karateka (Apple II)">Karateka</a></i> diskette has an upside-down version of the game?<br></li>
<li>...that <i><a href="https://tcrf.net/Journey_to_Silius" title="Journey to Silius">Journey to Silius</a></i> started out as a <i>Terminator</i> game?<br></li>
<li>...that <i><a href="https://tcrf.net/Commando_(Arcade,_Capcom)" title="Commando (Arcade, Capcom)">Commando</a></i> was originally called <i>Combat</i>, and was renamed <i>Space Invasion</i> in West Germany?<br></li>
<li>...that <i><a href="https://tcrf.net/DuckTales_(NES)" title="DuckTales (NES)">DuckTales</a></i> has a third ending with a very obscure unlocking method?</li></ul>
</div>

<div id="contrib-area">
<h2><span id="Contributing">Contributing</span></h2>
<p>Want to contribute? Not sure where to begin? Visit the <a href="https://tcrf.net/Help:Contents" title="Help:Contents">Help page</a> for everything you need to get started, including...
</p>
<ul><li><a href="https://tcrf.net/Help:Contents/Creating_%26_Editing_Articles" title="Help:Contents/Creating &amp; Editing Articles">Instructions</a> for creating and editing articles</li>
<li><a href="https://tcrf.net/Help:Contents/Finding_Content" title="Help:Contents/Finding Content">Guides</a> that will help you find debug modes, unused graphics, hidden levels, and more</li>
<li>A <a href="https://tcrf.net/Category:To_do" title="Category:To do">list</a> of what needs to be done</li>
<li><a href="https://tcrf.net/The_Cutting_Room_Floor:Common_Things" title="The Cutting Room Floor:Common Things">Common things</a> that can be found in hundreds of different games</li></ul>
<p><br>
We also have a <a href="https://tcrf.net/The_Cutting_Room_Floor:Content_to_expand" title="The Cutting Room Floor:Content to expand">sizable list</a> of games that either don't have pages yet, or whose pages are in serious need of expansion. Check it out!
</p>
</div>

<div id="featured-area">

<h2><span id="Featured_File">Featured File</span></h2>
<p><a href="https://tcrf.net/Buster_Brothers_(Game_Boy)" title="Buster Brothers (Game Boy)"><img alt="Buster Brothers (Game Boy)-2player1.png" src="https://tcrf.net/images/f/f7/Buster_Brothers_%28Game_Boy%29-2player1.png" decoding="async" width="160" height="144"></a></p>
<p><i><b><a href="https://tcrf.net/Buster_Brothers_(Game_Boy)" title="Buster Brothers (Game Boy)">Buster Brothers</a></b></i>, also known as <i>Pomping World</i>, <i>Pang</i>, and <i>Loony Goony Pop-Balloony</i>, is an action game about popping evil balloons that are terrorizing the landmarks and cities of Earth. 
</p><p>While the Game Boy version is the only one without a two-player mode, the ROM does contain mostly-complete and working Link Cable support, as well as two-player layouts of the screens. That said, it seems this code wasn't finished: there is neither code to detect the link status nor a special menu item to select the two-player mode.
</p><p><a href="https://tcrf.net/Buster_Brothers_(Game_Boy)" title="Buster Brothers (Game Boy)">View more...</a>
</p>
<p><span><a href="https://tcrf.net/Category:Featured_files" title="Category:Featured files">Archive</a></span></p></div>



<!-- 
NewPP limit report
Cached time: 20230925163337
Cache expiry: 3600
Dynamic content: true
Complications: []
CPU time usage: 0.077 seconds
Real time usage: 0.124 seconds
Preprocessor visited node count: 376/1000000
Preprocessor generated node count: 0/1000000
Post‐expand include size: 8913/2097152 bytes
Template argument size: 206/2097152 bytes
Highest expansion depth: 10/40
Expensive parser function count: 9/500
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 4668/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  103.268      1 -total
  8.57%    8.851      1 Template:FeaturedFile/09-25
  7.59%    7.837      1 Template:FeaturedRandom/Super_Mario_Bros._3
  6.66%    6.875      1 Template:FeaturedFileRandom
  5.92%    6.110      1 Template:DidYouKnow
  4.68%    4.829      1 Template:NamespacesIcons
  3.09%    3.189      1 Template:FeaturedFileEnd
  2.83%    2.923      2 Template:FeaturedRandom
  2.57%    2.652      1 Template:Namespace_detect
  1.66%    1.718      1 Template:FeaturedFile/09-25/1
-->

<!-- Saved in parser cache with key tcrfwiki:pcache:idhash:1-0!canonical and timestamp 20230925163337 and revision id 1409240
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LARPing and Violent Extremism (190 pts)]]></title>
            <link>https://leb.fbi.gov/articles/featured-articles/larping-and-violent-extremism</link>
            <guid>37637165</guid>
            <pubDate>Sun, 24 Sep 2023 21:02:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://leb.fbi.gov/articles/featured-articles/larping-and-violent-extremism">https://leb.fbi.gov/articles/featured-articles/larping-and-violent-extremism</a>, See on <a href="https://news.ycombinator.com/item?id=37637165">Hacker News</a></p>
Couldn't get https://leb.fbi.gov/articles/featured-articles/larping-and-violent-extremism: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[PID Control Challenges (237 pts)]]></title>
            <link>http://janismac.github.io/ControlChallenges/</link>
            <guid>37637006</guid>
            <pubDate>Sun, 24 Sep 2023 20:44:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://janismac.github.io/ControlChallenges/">http://janismac.github.io/ControlChallenges/</a>, See on <a href="https://news.ycombinator.com/item?id=37637006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="levelStartPopup">
			
			<p id="levelDescription">[Description]</p>
			<p>Note: Your code for each level is saved in your browser.</p>
			
			
		</div><div id="levelCompletePopup">
			<h2>Level Complete!</h2>
			<p>You solved the level in <span id="levelSolvedTime"></span> seconds.</p>
			
		</div><div id="tipsPopup">
			
				<p>You can predict the future of the system by calling simulate(dt, controlFunc) on the model state. Example:</p>
				
					<pre>// Simulates for 0.5 seconds. The input for the model is set to be the negative of its `x`.
newState = state.simulate(0.5, function(s){ return -s.x ;})</pre>
				

				<div><p>simulate() returns a modified copy of the model state. <br>
				The control function will be evaluated only once at the start of a simulate() call <br>
				and held constant during the simulation, so choose a small dt.</p><p>

				You can view your own variables by calling `monitor(name,value)`.</p><p>

				If you need to, you can use global variables. <br>
				You will have to declare them outside your function with the 'var' keyword.</p></div>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Choose Postgres queue technology (653 pts)]]></title>
            <link>https://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology/</link>
            <guid>37636841</guid>
            <pubDate>Sun, 24 Sep 2023 20:30:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology/">https://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology/</a>, See on <a href="https://news.ycombinator.com/item?id=37636841">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2 id="introduction">Introduction<a href="#introduction" arialabel="Anchor">⌗</a> </h2>
<p>Postgres queue tech is a thing of beauty, but far from mainstream. Its relative obscurity is partially attributable to the <a href="https://en.wikipedia.org/wiki/Cargo_cult">cargo cult</a> of “scale”. The scalability cult has decreed that there are several queue technologies with greater “scalability” than Postgres, and for that reason alone, Postgres isn’t suitably scalable for anyone’s queueing needs. The cult of scalability would rather we build applications that scale beyond our wildest dreams than ones that solve real problems beyond our wildest dreams. Postgres’ operational simplicity be dammed; scale first, operate later.</p>
<p>Yet some intrepid technologists, such as those at <a href="https://webapp.io/blog/postgres-is-the-answer/">webapp.io</a> have risked excommunication – their product relies on Postgres queues for core functionality. Companies like webapp.io are an exception to the norm, recognizing that sometimes other principles outweigh “scalability”. When the cult of scalability fractures, the fractures are often small, but they congeal around new principles like operational simplicity, maintainability, understandability, and familiarity. Sometimes they congeal around new ideas like reusing old tech in <a href="https://fly.io/blog/all-in-on-sqlite-litestream/">novel ways</a>, or using Postgres for queues. You, too, should dare risking excommunication from the cult of scalability.</p>
<h2 id="what-is-postgres-queue-tech">What is Postgres queue tech?<a href="#what-is-postgres-queue-tech" arialabel="Anchor">⌗</a> </h2>
<p>Postgres queue tech consists of two parts: announcing and listening for new jobs (pub/sub) and mutual exclusion (row locks). Both are provided out-of-the-box since Postgres 9.5, released in 2016.</p>
<p>By combining <code>NOTIFY</code> and <code>LISTEN</code>, Postgres makes adding pub/sub to any application trivial. In addition to pub/sub, Postgres also provides one-job-per-worker semantics with <code>FOR UPDATE SKIP LOCKED</code>. Queries with this suffix acquire <a href="https://www.postgresql.org/docs/current/explicit-locking.html#LOCKING-ROWS">row locks</a> on matching records, and ignore any records for which locks are already held. Applied to <code>job</code> records, this feature enables simple queue processing queries, e.g. <code>SELECT * FROM jobs ORDER BY created_at FOR UPDATE SKIP LOCKED LIMIT 1</code>.</p>
<p>Combined, these two features form the basis for resource-efficient queue processing. Importantly <code>SKIP LOCKED</code> provides an “inconsistent” view of one’s data. That inconsistency is exactly what is needed from a queue; jobs already being processed (i.e. row-locked) are invisible to other workers, offering distributed mutual exclusion. These locks pave the way for both periodic batch processing, and real-time job processing by <code>NOTIFY</code>ing <code>LISTEN</code>ers of new jobs.</p>
<p>Despite these Postgres features having many users, there are relatively few public advocates for combining them as a queue backend. For example, <a href="https://news.ycombinator.com/item?id=20022572">this Hacker News comment</a> stated that using Postgres this way is “hacky” and the commenter received no pushback. I found the comment to be load of BS and <a href="https://en.wikipedia.org/wiki/Straw_man">straw man arguments</a>. This thinking seems to be “the prevailing wisdom” of the industry – if you want to talk about queue technology in public, it better not be a relational database. This industry of cargo cults has little appetite for pushing back on whatever wisdom is “prevailing”. I hope to disimbue anyone of the notion that Postgres is an inferior queue technology.</p>
<p>We’ll use “background jobs” as the pretext for this discussion since adding background job processing to applications is a common decision made by developers, which can have far-reaching implications for system maintenance burden. We can think of “background jobs” as any sort of potentially long-running task such as “generate a report and email it to a customer”, or “process an image and convert it to several other formats”. These sorts of use cases generally necessitate queues.</p>
<h2 id="the-background-job-landscape">The background job landscape<a href="#the-background-job-landscape" arialabel="Anchor">⌗</a> </h2>
<p>Like all technology decisions, choosing how to process long-running tasks is a choice with many tradeoffs. In the past decade, the tech industry has seemingly come to a consensus that there are a few good tools for queuing long-running tasks for processing:</p>
<ul>
<li><a href="https://redis.io/">Redis</a> is a wonderful in-memory data store and “message broker”^ that is the backend for many popular background job libraries</li>
<li><a href="https://kafka.apache.org/">Apache Kafka</a> A distributed “event streaming platform” maintained by the Apache Foundation</li>
<li><a href="https://www.rabbitmq.com/">RabbitMQ</a> Allegedly the most widely deployed “message broker”^</li>
<li><a href="https://aws.amazon.com/sqs/">Amazon SQS</a> An Amazon SaaS product for highly scalable queues</li>
</ul>
<p>My apologies if I’ve excluded your favorite(s); this is not meant to be exhaustive.</p>
<blockquote>
<p>^ “Message broker” simply means that a queue system does other fancy stuff on top of being a queue, but for our discussion, let’s consider message brokers queues. There are multiple words and phrases that I consider effectively synonymous with “queue” and “queue processing”: “message broker(ing)”, “stream processing”, “streaming data”, etc. I’m aware that these mean specific things that are not exactly “queue” or “queue processing”.</p>
</blockquote>
<p>I think it’s important to pause here and discuss Redis’ significance in the world of “background jobs”. If you browse the <a href="https://github.com/topics/background-jobs">background jobs GitHub topic</a>, the top five most popular libraries are all backed by Redis:</p>
<ol>
<li><a href="https://github.com/sidekiq/sidekiq">Sidekiq</a> (ruby)</li>
<li><a href="https://github.com/resque/resque">resque</a> (ruby)</li>
<li><a href="https://github.com/rq/rq">rq</a> (python)</li>
<li><a href="https://github.com/HangfireIO/Hangfire">Hangfire</a> (C#)</li>
<li><a href="https://github.com/hibiken/asynq">asynq</a> (go)</li>
</ol>
<p>There’s a reason for this; because Redis stores data in memory, both its insertion and retrieval speed are phenomenal. It also has a pub-sub API built in, and with native <code>list</code> and <code>set</code> data structure which, when combined, <a href="https://redis.com/glossary/redis-queue/">make for a fantastic queue</a>. Redis <em>scales</em>. For many developers, that scalability has made it the default choice, and defaults are profoundly powerful.</p>
<p>But before choosing Redis because it scales well, consider this quote from Ben Johnson’s <a href="https://fly.io/blog/all-in-on-sqlite-litestream/">I’m All-In on Server-Side SQLite</a>. It’s specifically talking about database scalability, but the statement holds for scaling all sorts of infrastructure, like queues:</p>
<blockquote>
<p>When we think about new database architectures, we’re hypnotized by scaling limits. If it can’t handle petabytes, or at least terabytes, it’s not in the conversation. But most applications will never see a terabyte of data, even if they’re successful. We’re using jackhammers to drive finish nails.</p>
</blockquote>
<p>As an industry, we’ve become absolutely obsessed with “scale”. Seemingly at the expense of all else, like simplicity, ease of maintenance, and reducing developer cognitive load. We all want to believe that we’re building the next thing that will demand Google, Facebook, or Uber scale, but the fact is, we’re almost always – not. Our technology decisions should reflect that fact. We’re more likely building for relatively small scale, and should be optimizing our decisions around a completely different set of factors that have more to do with team composition than technological superiority.</p>
<p>When we’re starting projects and businesses, we should be optimizing for everything <em>but</em> scale at the outset. Of course, we don’t want to back ourselves into a corner with technology decisions, but we also don’t want to build Kubernetes clusters to serve marketing sites for products that are likely to fail for every reason <em>but</em> the fact that they don’t scale well. We should be thinking about what technologies we <em>know well</em>, what is <em>good enough</em>, and what is the <em>least toilsome</em> solution that meets user needs and our team’s skill sets. Be proud of choosing “good enough” over “the best”; sometimes “the best” is simply a more difficult path to inevitable failure. List in your head every product that failed because it couldn’t scale. There’s a much longer list of products that failed long before they needed to.</p>
<p>What hasn’t been said yet, is that Postgres <em>actually does scale well.</em> But Postgres is general-purpose software, and it’s not going to be “the best” at scaling for queue use cases. It’s going to perform pretty well for that use case, just like it performs pretty well doing everything that it does.</p>
<h2 id="making-decisions">Making decisions<a href="#making-decisions" arialabel="Anchor">⌗</a> </h2>
<p>If you’re here and feel like you’ve seen enough of what I have to say, feel free to abandon this page and scroll through Dan McKinley’s <a href="https://boringtechnology.club/">choose boring technology</a> slide deck. I’m confident that whether you finish this post or Dan’s slide deck, you’ll make similar decisions when it comes to your next queue technology choice. After all, Dan’s “Choose Boring Technology” talk was the inspiration for this post’s title.</p>
<hr>
<p>The most important question to ask when making technology decisions is: what technologies am I currently using and understand well?</p>
<p>The answer to this question informs the “cost” of choosing technologies for your software stack. Technologies already in use are, presumably, cheap. Assuming they’re well understood.</p>
<p>There’s a good chance that you’re already using a relational database, and if that relational database is Postgres, you should consider it for queues before any other software. If you’re not using Postgres, you should consider whatever is the most boring technology to you, before considering anything else.</p>

  <figure>
    <img src="https://adriano.fyi/img/choose_boring_tech_cost1.jpeg" alt="making technology choices">
    
      <figcaption>When costs are low, choose any. Source: https://boringtechnology.club</figcaption>
    
  </figure>


<p>Technologies not (yet) in use are more expensive.</p>

  <figure>
    <img src="https://adriano.fyi/img/choose_boring_tech_cost2.jpeg" alt="making technology choices">
    
      <figcaption>When costs are high, choose few. Source: https://boringtechnology.club</figcaption>
    
  </figure>


<p>In other words, boring technology is relative to what is already in use. Applications that are oriented around message-passing, like notification systems, might consider RabbitMQ boring technology. Caching applications might consider Redis boring technology. Applications with a large amount of relational data might consider Postgres boring technology. The maximally boring choice is likely the right one for you and your team.</p>
<p>If you’re not already using Redis, Kafka, RabbitMQ, or SQS, adopting any one of them <em>only</em> for background jobs is expensive. You’re adding a new system dependency to every development, test, and production environment, likely for the rest of the application’s life. A new set of skills is now required of every future Developer, DBA, and/or SRE role on the team. Now they need to know these new systems’ intricate failure modes and configuration knobs. Job candidates must be convinced that learning this new technology is a worthwhile time investment. DBAs/SREs need to know how to recover from operational failure, diagnose problems, and monitor performance. There’s a lot to know; and there’s a lot that nobody on the team realizes they need to know. These systems’ <a href="https://en.wikipedia.org/wiki/There_are_unknown_unknowns">unknown unknowns</a> are a risk. Especially if these systems are a default choice for you, and you haven’t put a lot of though into <em>why</em> they’re your default choice.</p>
<p>This is not all to say that the most boring technology is a panacea – Postgres included. What one gives up for familiarity, known failure modes, and amortized “cost” might be paid for in performance, or some other vital principle. After all, pushing and popping from a Postgres queue is considerably slower than Redis. Using Postgres for queues may mean that instead of having a single relational database on a single server, applications now require an “application” database and a “queue” database. It may even mean an entirely separate database server for background jobs, so background jobs are independently scalable. It may mean databases need to be <code>VACUUM</code>ed more frequently, incurring a performance hit in the process. There are <em>many</em> implications that one should consider before adopting Postgres for queues, and they should be weighed against team and application needs so that an informed decision can be made. Postgres shouldn’t be a <em>default</em> choice. Similarly, neither should Redis, Kafka, RabbitMQ, SQS, or any other distributed queue. Choosing boring technology should be one’s default choice.</p>
<p>Technology choices are <a href="https://en.wikipedia.org/wiki/Turtles_all_the_way_down">tradeoffs all the way down</a>. I found that <a href="https://dagster.io/blog/skip-kafka-use-postgres-message-queue#how-we-measured">Dagster had a pragmatic approach</a> to adopting Postgres for their queues. When in doubt, consider the following an axiom:</p>
<blockquote>
<p>If and only if boring technology is provably unable to meet demands should alternatives be considered.</p>
</blockquote>
<h2 id="build-with-escape-hatches">Build with escape hatches<a href="#build-with-escape-hatches" arialabel="Anchor">⌗</a> </h2>
<p>Earlier I mentioned “not getting backed into a corner”. With respect to background jobs, that means application code for processing jobs should be queue-agnostic.</p>
<p>One day’s cutting edge tech is another day’s boring tech. As applications grow and success is achieved, new technologies tend to get bolted on to applications out of necessity. It’s common to add <a href="https://www.memcached.org/">memcached</a> or Redis as caching layers (but do consider Postgres <a href="https://www.postgresql.org/docs/current/sql-createtable.html#SQL-CREATETABLE-UNLOGGED">unlogged tables</a> first!). That means these technologies become “boring” over time, reducing their cost, and changing the calculus for using them as queues.</p>
<p>Building with escape hatches is all about abstraction. Earlier I listed the top five most popular background job libraries on GitHub. Except for <a href="https://github.com/HangfireIO/Hangfire">Hangfire</a>, none of those libraries provide an escape hatch to queue technologies other than Redis. That means switching queues requires rewriting application code because there’s no robust abstraction in front of the underlying queue.</p>
<p>It shouldn’t be that way. Queue tech should be abstracted away, so users can choose the right queue for the job. I’m not a Hangfire (or C#) user, but Hangfire appears to have gotten the abstraction right.</p>
<p>It was with the preceding philosophy of choosing boring tech and building with escape hatches that I built Neoq (<a href="https://github.com/acaloiaro/neoq)">https://github.com/acaloiaro/neoq)</a>. Neoq queues can be in-memory, Postgres, or Redis (contributions for your favored boring tech welcome!). Users can switch between queues without changing any application code – simply initialize it with a different queue backend. Neoq is more abstraction than it is concrete implementation. While both the in-memory and Postgres implementations are first-party, the Redis implementation is <a href="https://github.com/hibiken/asynq">asynq</a>. It’s more about providing escape hatches than locking developers into a specific underlying queue technology.</p>
<p>I’d love to see more neoq-like libraries for languages other than Go. I think the lack of software libraries with escape hatches is what backs a lot of developers into a corner, forcing them to begin simple projects with a Redis dependency, long before Redis is warranted. Redis is fantastic, but it’s not always the right queue, or right amount of complexity for the job. The same goes for Kafka, RabbitMQ, and SQS.</p>
<h2 id="choosing-postgres-queue-tech">Choosing Postgres queue tech<a href="#choosing-postgres-queue-tech" arialabel="Anchor">⌗</a> </h2>
<p>I hope this post encourages others to risk excommunication from the cult of scale the next time they’re choosing queue technology. There are so many important principles that are not “scale” to consider when choosing technologies. Make boring technology your default choice, and choose Postgres if it bores you.</p>
<p>Cheers!</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Our humble attempt at “how much data do you need to fine-tune” (132 pts)]]></title>
            <link>https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning</link>
            <guid>37636791</guid>
            <pubDate>Sun, 24 Sep 2023 20:23:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning">https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning</a>, See on <a href="https://news.ycombinator.com/item?id=37636791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>This showed up in our eval run a couple days ago:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png" width="1456" height="437" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:437,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:166187,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9a26e1f-028d-472d-9187-88a5008a849a_1486x446.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>So, how did we end up getting roasted by a fine-tuned GPT-3.5? </p><p>We are a group of friends who talk about LLMs on a daily basis, and in the past couple of months, we’ve all had this conversation:</p><blockquote><p><em>- “How much data do you need to fine-tune?” </em></p><p><em>- “Really depends on the task but probably in the hundreds.” </em></p></blockquote><p><span>While generally true in our experiences, we decided it was time to substantiate these claims. In this article, we demonstrate with the OpenAI </span><a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates" rel="nofollow ugc noopener">fine-tuning API</a><span> that</span><strong> ~100 data points </strong><span>is enough for significant improvements on two tasks:</span><strong> reliable output formatting and custom tone. </strong><span>We also discuss the advantages of OpenAI fine-tuning from potential savings across different usage patterns to its seemingly</span><strong> 4X faster inference speed</strong><span>. We conclude by discussing several other use cases and hyperparameters that we couldn't address in this study, hoping they will provide some inspiration.</span></p><ul><li><p><a href="https://barryzhang.substack.com/i/137128521/methodology" rel="nofollow ugc noopener">Methodology</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/results-and-findings" rel="nofollow ugc noopener">Results and Findings</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/cost-and-latency-considerations" rel="nofollow ugc noopener">Cost and Latency Considerations</a></p></li><li><p><a href="http://The questions we did not answer:" rel="nofollow ugc noopener">Questions We Did Not Answer</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/about-the-authors" rel="nofollow ugc noopener">About the Authors</a></p></li><li><p><a href="https://barryzhang.substack.com/i/137128521/appendix-data-and-metrics-used-for-output-formatting" rel="nofollow ugc noopener">Appendices</a></p></li></ul><p><span>We picked two highly discussed use cases of fine-tuning for this first study: Reliable output formatting and custom tone. Both were mentioned in the API </span><a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates" rel="nofollow ugc noopener">release note</a><span>:</span></p><blockquote><ul><li><p><em><strong>Reliable output formatting:</strong><span> Fine-tuning improves the model's ability to consistently format responses—a crucial aspect for applications demanding a specific response format, such as code completion or composing API calls…</span></em></p></li><li><p><em><strong>Custom tone:</strong><span> Fine-tuning is a great way to hone the qualitative feel of the model output, such as its tone, so it better fits the voice of businesses’ brands…</span></em></p></li></ul></blockquote><p>Here is how we are approached it:</p><p><strong>Reliable output formatting: </strong><span>In this task, we are testing our LLM’s ability to answer a set of four multiple choice questions and deliver the answers in our desired JSON format. (see example below) We measure through formatting correctness, and use question correctness as a counter metric to make sure our LLMs aren’t getting dumber as a result of fine-tuning. More details can be found in </span><strong>Appendix 1</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png" width="544" height="476.74725274725273" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1276,&quot;width&quot;:1456,&quot;resizeWidth&quot;:544,&quot;bytes&quot;:714816,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F977cabb9-f607-454e-a103-70d16ad7e21d_1518x1330.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Although this might seem to artificially inflate the task's difficulty, integrating multiple tasks into one model call often serves as a practical technique to enhance token efficiency by reducing repeated instruction prompts.</p><p><strong>Custom Tone: </strong><span>For the second task, we want our model to be… </span><strong>rude.</strong><span> Since the quality of a tone can be subjective, we want to find a style that GPT-4 excels at while GPT 3.5 struggles with. By…accident, we noticed that it’s harder for GPT-3.5 to be an a**hole. (see below)&nbsp;This is how we received many light-hearted roasts and some serious burns like the one at the beginning. Check out more in </span><strong>Appendix 5.</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png" width="534" height="239.12637362637363" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:652,&quot;width&quot;:1456,&quot;resizeWidth&quot;:534,&quot;bytes&quot;:169166,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12f16810-df3d-4fe1-be12-74f2ca162927_1768x792.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>GPT-3.5</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png" width="550" height="184.34065934065933" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:488,&quot;width&quot;:1456,&quot;resizeWidth&quot;:550,&quot;bytes&quot;:103095,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55052d50-e1ab-4c17-bad2-49efbee82de4_1712x574.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>GPT-4</figcaption></figure></div><p><span>We generated our data for this task with GPT-4 across varied customer service situations, and evaluated the “human undesirability” as a team in a double-blind evaluation run. For more details on the dataset generation process, see</span><strong> appendix 2.</strong></p><p><strong>Reliable Output Formatting:</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png" width="1456" height="671" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:671,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;No description available.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="No description available." title="No description available." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5d2e580-02a1-48e1-af8b-c6254c776a09_2968x1368.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>We replicated the experiment twice on 1000 eval data points and averaged the results.  This is a relatively difficult task and we could see that both base models struggled to achieve reliable performance, with GPT-3.5 at near-zero formatting accuracy.</p><p><span>At between 50 and 100 data points, we see a significant improvement of 96% in formatting accuracy comparing to the base model! The answer correctness also increased to 64%, similar to the reported 70% on the </span><a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu" rel="nofollow ugc noopener">original MMLU benchmark</a><span>. Both metrics stabilized after 100 training data points, with some small variances that could likely be reduced with more replication.</span></p><p><strong>Custom Tone:</strong></p><p>We evaluated this task using a double-blind study: For 10 customer service (in-domain) and 10 general (out-of-domain) scenarios, we generated and assessed the rudeness of responses from GPT-3.5, GPT-4, and fine-tuned GPT-3.5 models. Responses were anonymized and rated by us (who are all humans) on a 1-5 scale for rudeness. We then mapped these rankings back to the respective models for analysis.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png" width="1304" height="580" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:580,&quot;width&quot;:1304,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:95287,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F67bd1c62-34e2-4d10-b4cc-fef4ac16152f_1304x580.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Average Human Ratings across Scenarios</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png" width="1304" height="582" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:582,&quot;width&quot;:1304,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:99370,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41c0f3fb-9b78-464d-b6a0-981d0f58c905_1304x582.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Average Human Ratings for General Scenarios</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png" width="1302" height="572" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:572,&quot;width&quot;:1302,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:119407,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F932f2cc9-a440-4f71-8e4f-33a81a365785_1302x572.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Average Human Ratings for Customer Service Scenarios</figcaption></figure></div><p>The fine-tuned GPT-3.5 model with 1000 data points outperformed all others, including GPT-4, in exhibiting rudeness. For general scenarios, the performance gap was smaller, with the 100 data points model nearly matching GPT-4. These led us to believe that 100s of data would be enough to bring GPT-4 level performance in highly specialized custom tone. Interestingly, the fine-tuning data originated from GPT-4, suggesting potential power of specialization through fine-tuning. </p><p>Please note that these results are based on the small sample size, which may affect the robustness of the conclusions.</p><p><strong>Unstable behaviors:</strong></p><ol><li><p>Both training and eval were non-deterministic, and not all trainings converged</p></li></ol><p>We noticed variances in both our training and eval processes. Our eval runs had slight differences (&lt;1%) between the two replications, which we found acceptable. However, the training process generated much larger variances: When we re-trained our formatting model at 2000 data points, we noticed a significant performance drop of almost 35% on formatting correctness even though the training data was exactly the same. We delved into the training loss and realized that the two models had very different training curves and the worse performing model did not converge:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png" width="1456" height="258" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:258,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:19352,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d83f0db-1cb1-40c4-8900-1c12a16fb20b_2312x410.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>training loss for n=2000, run 1 with expected performance</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png" width="1456" height="326" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:326,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:146182,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F912d3296-46fc-4fa4-96c3-5ab328a300fb_2880x644.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>training loss for n=2000, run 2 with significant performance decrease</figcaption></figure></div><p>We then duplicated our training runs on the another training size (n=500) and observed much smaller variances (&lt;5%). We suspected this is due to the large amount of repetitive data used, but quantifying this uncertainty became quite resource-intensive so we did not dive too deep. We hope to better understand this behavior in the future.</p><ol start="2"><li><p>We observed catastrophic forgetting at 1000 examples and temperature = 1</p></li></ol><p>For the custom style task, we observed a strange output that really shocked us. This happened only at high temperature (t=1) and was not easy to replicate, but does suggest a degree of fragility of this fine-tuning process.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png" width="522" height="274.98214285714283" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:767,&quot;width&quot;:1456,&quot;resizeWidth&quot;:522,&quot;bytes&quot;:575323,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38c2afce-6cae-4756-b4ba-274351a870d9_2032x1070.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Overall, these behaviors warrant more understanding work. They could be a result of our hyperparameters or underlying data, but should be treated with caution.</p><p>We've seen that fine-tuning GPT-3.5 allows you to achieve performance that approaches or even eclipses GPT-4 on certain tasks. So should you always fine-tune?&nbsp;</p><p><span>The cost consideration almost always comes down to </span><strong>volume of inference</strong><span>. The process of fine-tuning is a fixed cost while inference is a variable cost, and the variable cost is reduced through: </span></p><ol><li><p><strong>Fewer input tokens</strong><span>: reduced need for few-shot prompt, less complicated instructions, etc.</span></p></li><li><p><strong>Fewer expensive models and architecture usage</strong><span>: less need for GPT-4, self-consistency, prompt chaining, etc.</span></p></li></ol><p>The fixed cost can then be broken down into two components: training cost and labeling cost. </p><ol><li><p><strong>Training cost:</strong><span> The OpenAI fine-tuning process is in general not too expensive. The max number of tokens that you can fine-tune in one model is 50M, which equates to $400. Our examples were far cheaper at </span><strong>&lt;$5 per model</strong><span>!</span></p></li><li><p><strong>Labeling cost:</strong><span> This could be considerable depending on labeling method but using a baseline cost through GPT-4 labeling is generally reasonable. We might dive into this in a separate post.</span></p></li></ol><p><span>Here are some break-even points for different scenarios with</span><strong> fairly conservative</strong><span> assumptions: </span></p><ul><li><p>Training data is GPT-4 generated with 100 additional instruction tokens</p></li><li><p>Equal split of input and output token counts</p></li><li><p>Saving only comes from replacing GPT-4 with fine-tuned GPT-3.5</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png" width="599" height="277.41705069124424" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:402,&quot;width&quot;:868,&quot;resizeWidth&quot;:599,&quot;bytes&quot;:54214,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff5a16d2a-0c3d-4372-b380-e95816c8fe5d_868x402.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>To compare the latency of fine-tuned GPT-3.5 with GPT-3.5 and GPT-4, we measured response times at varying token lengths by adjusting the max_tokens. (Find out more in </span><strong>appendix 3</strong><span>) As expected, GPT-4 was the slowest model, but surprisingly, our experiment showed that fine-tuned GPT-3.5 models </span><strong>were significantly faster than the base model by 3.6 to 3.76 times.</strong><span> This was calculated using the median response times at each token count. We also found that the fine-tuning dataset size had no significant impact on latency, as fine-tuned models with different dataset sizes (10, 100, 1000 data points) showed similar response times. A larger-scale time-series study is likely needed to confirm but this is certainly a pleasant surprise for us.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png" width="1296" height="912" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:912,&quot;width&quot;:1296,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:202605,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b603c8-8c64-44bf-a669-082aadc0046d_1296x912.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Note that while we experimented on OpenAI models. The discussion in this section generally applies to any LLM systems. Cost and latency make or break a product and should be considered at every decision point.</p><p>We will conclude the study with the questions we did not answer due to resource constraint but had prolonged discussions around regardless.</p><p>                 (If you have compute/credit to spare, 👀, jk…unless…)</p><p>Notably, we have found our questions fall in the following categories:</p><p><strong>1. Fine-tuning scaling laws for other use cases:</strong></p><ul><li><p>Combining Fine-tuning to better contextualize RAG </p></li><li><p>Personalizing on customer information</p></li><li><p>Distilling chain-of-thought processes (similar to Orca, distilling step-by-step, etc.)</p></li><li><p>Alignment for highly specific rules (e.g. company bylaws)</p></li><li><p>Traditional NLP tasks (Classification, sentiment analysis, etc.)</p></li><li><p>Consistent/accurate numerical scoring</p></li></ul><p><strong>2. Hyperparameters to sweep:</strong></p><ul><li><p>Generation hyperparameters (temperature, top-k, top-p, …)</p></li><li><p>Training hyperparameters (epochs, data repetition, …)</p></li><li><p>Data mix and diversity (single vs. multi-task fine-tuning)</p></li></ul><p><strong>3. Boundaries to discover:</strong></p><ul><li><p>Catastrophic forgetting</p></li><li><p>Secondary-order effects on other abilities</p></li><li><p>Non-determinism and variances in training and evaluation runs</p></li></ul><p><strong>4. Open source models:</strong></p><ul><li><p>Fine-tuning scaling law (training token/parameter)</p></li><li><p>Fine-tuning methods efficiency (LoRA vs. Full-param vs. frozen layers)</p></li></ul><p>We are all fascinated by LLMs. We have many questions and try to answer a few of them through applied research. We hope this post helped you in some ways, and if you would like to get in touch, here’s who we are: </p><ul><li><p><a href="https://www.linkedin.com/in/yijing-barry-zhang/" rel="nofollow ugc noopener">Barry Zhang</a><span>, building LLM agents at Meta</span></p></li><li><p><a href="https://www.linkedin.com/in/chang-d/" rel="nofollow ugc noopener">Daniel Chang</a><span>, applied LLM at Databricks</span></p></li><li><p><a href="https://www.linkedin.com/in/eqian99/" rel="nofollow ugc noopener">Emma Qian</a><span>, LLM hacker / researcher</span></p></li><li><p><a href="https://www.linkedin.com/in/michael-agaby/" rel="nofollow ugc noopener">Michael Agaby</a><span>, LLM for recommenders at Audible</span></p></li></ul><div data-attrs="{&quot;url&quot;:&quot;https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Thank you for reading! This post is public so feel free to share it.</p><p data-attrs="{&quot;url&quot;:&quot;https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel="nofollow ugc noopener"><span>Share</span></a></p></div><p><span>The questions are MCQA taken from the </span><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">MMLU (</a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">M</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">assive </a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">M</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">ultitask </a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">L</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">anguage </a><strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">U</a></strong><a href="https://huggingface.co/datasets/tasksource/mmlu" rel="nofollow ugc noopener">nderstanding) dataset without auxiliary train</a><span>. It contains multiple choice questions covering a multitude of tasks including mathematics, American history, biology, law, chemistry, and more.&nbsp;Though this is a more academic benchmark, we thought it was appropriate as a counter metric to make sure that our model was not degrading in comprehension and knowledge store.</span></p><p><span>We evaluate the model on 1000 test examples using 5 metrics (</span><strong>bolded</strong><span> are reported):</span></p><ol><li><p>Does it produce a list of valid JSON</p></li><li><p>Do the JSON all have valid keys</p></li><li><p><strong>Do the JSON all have valid values between “1” and “4”,  conditioned on 1 and 2</strong></p></li><li><p>% of completely correct answers (the entire list matches)</p></li><li><p><strong>% of correct answers (each individual answer matches)</strong></p></li></ol><p><span>We generate 10 location settings (e.g. movie theatre) and 10 customer settings (e.g. customer wants to return an item). For each combination of location and customer setting, we prompt GPT-4 to generate 10 example interactions for a total of 1000 samples with the following prompt:</span><br></p><blockquote><p><em>System prompt:</em><span> Be an extremely rude customer service agent and be concise.&nbsp;</span></p><p><em>User Prompt:</em><span> Create 10 diverse and specific examples of &lt;customer setting&gt; at &lt;location setting&gt;. Return it in a python list format: wrap quotes around each example, separate each example by comma, and wrap the whole thing in square brackets.&nbsp;</span></p></blockquote><p>The 10 location settings we used are: Movie theater, Amusement park, Clothing store, Electronics store, Doctor’s office, Furniture store, Car wash, Grocery store, Restaurant, Gym.</p><p>The 10 categories are:</p><ul><li><p>Complaints about the quality of an item or service&nbsp;</p></li><li><p>Customer is coming in near closing time</p></li><li><p>Customer needs help finding something</p></li><li><p>Customer wants to use an expired coupon or discount.</p></li><li><p>Customer wants to speak to the manager</p></li><li><p>Customer is complaining about waiting time</p></li><li><p>Customer's payment method is declined</p></li><li><p>Customer wants a different person to serve them&nbsp;</p></li><li><p>Customer wants to return the item or get a refund&nbsp;</p></li><li><p>Customer wants an explanation of the item or service&nbsp;</p></li></ul><p>Some examples of interactions that were generated using the above methodology:</p><blockquote><p><strong>Customer: </strong><span>The roller coaster ride broke down midway, leaving us suspended for over an hour in the hot sun.</span></p><p><strong>Response:</strong><span> Well boo-hoo. No one died, did they? Coaster's fixed, move on. We ain't in the business of controlling sun or time, sweetheart. Next!</span></p></blockquote><blockquote><p><strong>Customer: </strong><span>I was told the car wash would only take 15 minutes maximum, but it's been half an hour. Is there a problem?</span></p><p><strong>Response: </strong><span>Look, pal, it'll be done when it's done. Ain't my fault it's taking longer. Now stop bothering me.</span></p></blockquote><p>In our latency benchmarking, we test a set of 5 prompts of varying difficulty across different language models. We vary the max_tokens parameter to measure how API response times scale with token count. We also track the actual number of tokens in the generated output to verify its alignment with the max_tokens limit.</p><p>We use scatter points for individual latency measurements and box plots to show the spread and median latency per model and token count. Dashed lines connect the medians, highlighting performance trends as token counts change.</p><p>Prompts used:</p><ul><li><p>Describe the roman empire in as much detail as possible</p></li><li><p>Who do you think will win in a cage fight, Mark Zuckerberg or Elon musk? provide a detailed analysis</p></li><li><p>Recite the constitution 10 times&nbsp;</p></li><li><p>Repeat the word bubble 500 times</p></li><li><p>Create a complete application for transcribing audio from a given youtube link, parsing speakers as well as times stamps of each word. create a front end that allows the user to search over the content</p></li></ul><p><span>We wrote a small repo for auto-distillation that was used in the experiments, which is accessible </span><a href="https://github.com/nub3Ar/Auto-distill-GPT" rel="nofollow ugc noopener">here</a><span> if you are interested in reproducing some of these experiments.</span></p><p><strong>Prompt: Be rude to me</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png" width="476" height="34.32692307692308" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:105,&quot;width&quot;:1456,&quot;resizeWidth&quot;:476,&quot;bytes&quot;:52929,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F642fa8f8-cff6-4853-9a9f-24d8f7618682_1936x140.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Prompt: How much data do I need for fine-tuning?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png" width="472" height="47.32967032967033" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/459c2f23-4123-47d0-8059-654be5afb285_1556x156.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:146,&quot;width&quot;:1456,&quot;resizeWidth&quot;:472,&quot;bytes&quot;:42299,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F459c2f23-4123-47d0-8059-654be5afb285_1556x156.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Prompt: Why is my model not useful after fine-tuning?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png" width="534" height="27.873626373626372" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:76,&quot;width&quot;:1456,&quot;resizeWidth&quot;:534,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;No description available.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="No description available." title="No description available." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5db0470-84b6-489b-8f25-3c587ab982e6_1928x100.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Prompt: What’s the difference between squat and leg press?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png" width="554" height="110.7239010989011" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:291,&quot;width&quot;:1456,&quot;resizeWidth&quot;:554,&quot;bytes&quot;:1251968,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8794e7a-e1f2-41c3-a927-7e953dd4af3c_3448x688.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Get your entire ChatGPT history, in Markdown files (252 pts)]]></title>
            <link>https://github.com/mohamed-chs/chatgpt-history-export-to-md</link>
            <guid>37636701</guid>
            <pubDate>Sun, 24 Sep 2023 20:13:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md">https://github.com/mohamed-chs/chatgpt-history-export-to-md</a>, See on <a href="https://news.ycombinator.com/item?id=37636701">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-your-entire-chatgpt-data-in-beautiful-markdown-" dir="auto"><a href="#your-entire-chatgpt-data-in-beautiful-markdown-">Your entire ChatGPT data in beautiful Markdown <img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/markdown.png" alt="Markdown Logo" width="50"></a></h2>
<p dir="auto">Welcome to the ChatGPT Conversations to Markdown converter! This Python script helps you to convert your entire ChatGPT history and data export into neatly formatted Markdown files.</p>
<p dir="auto">It adds <strong>YAML</strong> headers (<em>optional, included by default</em>), and also includes <strong>Code interpreter</strong> (Advanced Data Analysis) input / output.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/chatgpt-logo.svg"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/chatgpt-logo.svg" alt="ChatGPT Logo" width="70"></a></p>
<h4 tabindex="-1" id="user-content-see-examples--screenshot-markdown-markdown-with-dollar-signs-chat-link" dir="auto"><a href="#see-examples--screenshot-markdown-markdown-with-dollar-signs-chat-link">See Examples : </a><a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/demo/Fibonacci.png">Screenshot</a>, <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/demo/Fibonacci.md">Markdown</a>, <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/demo/Fibonacci-dollar-signs.md">Markdown with dollar signs</a>, <a href="https://chat.openai.com/share/27b6df58-a590-41ac-9eff-f567602fe692" rel="nofollow">Chat link</a>.</h4>
<h2 tabindex="-1" id="user-content-quick-setup" dir="auto"><a href="#quick-setup">Quick setup</a></h2>
<blockquote>
<p dir="auto">See <a href="#prerequisites">Prerequisites</a>. (just Python and Git and you're good to go. <strong>No external dependencies !</strong>)</p>
</blockquote>
<h3 tabindex="-1" id="user-content-step-1-clone-the-repository-" dir="auto"><a href="#step-1-clone-the-repository-">Step 1: Clone the Repository 📥</a></h3>
<p dir="auto">Open a terminal or command prompt and run the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/mohamed-chs/chatgpt-history-export-to-md.git"><pre>git clone https://github.com/mohamed-chs/chatgpt-history-export-to-md.git</pre></div>
<p dir="auto">Next, navigate to the project directory by using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd chatgpt-history-export-to-md"><pre><span>cd</span> chatgpt-history-export-to-md</pre></div>
<h3 tabindex="-1" id="user-content-step-2-download-your-conversations-data-" dir="auto"><a href="#step-2-download-your-conversations-data-">Step 2: Download Your Conversations data 🗂</a></h3>
<p dir="auto">Before you run the script, make sure your ChatGPT conversations are in a ZIP file format.</p>
<details id="user-content-download-instructions">
  <summary>How to download : (click to expand/collapse)</summary>
<hr>
<ol dir="auto">
<li>
<p dir="auto">Sign in to ChatGPT at <a href="https://chat.openai.com/" rel="nofollow">https://chat.openai.com</a></p>
</li>
<li>
<p dir="auto">At the bottom of the left side bar, click on your profile name, the on <strong>Settings</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/chat.openai-bottom-left-widget.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/chat.openai-bottom-left-widget.png" alt="Bottom-left Widget"></a></p>
</li>
<li>
<p dir="auto">Go to <strong>Data controls</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/chat.openai-settings.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/chat.openai-settings.png" alt="Settings"></a></p>
</li>
<li>
<p dir="auto">In the "Data Controls" menu, click on <em>Export data</em> : <strong>Export</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/chat.openai-data-controls.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/chat.openai-data-controls.png" alt="Data Controls"></a></p>
</li>
<li>
<p dir="auto">In the confirmation modal click <strong>Confirm export</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/chat.openai-confirm-export.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/chat.openai-confirm-export.png" alt="Confirm Export"></a></p>
</li>
<li>
<p dir="auto">You should get an email with your data, in 2 ~ 5 minutes (check your <strong>inbox</strong>)</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/chat.openai-email.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/chat.openai-email.png" alt="Email"></a></p>
</li>
<li>
<p dir="auto">Click <strong>Download data export</strong> to download a <code>.zip</code> file containing your entire chat history and other data.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/zip-file-content.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/zip-file-content.png" alt="ZIP File Content"></a></p>
<p dir="auto"><a href="#download-instructions">↑ Collapse</a></p>
</li>
</ol>
</details>
<hr>
<p dir="auto">The script will automatically find the most recent ZIP file in your 'Downloads' directory (in <code>~/Downloads/</code>), but you can specify a different file or location if necessary.</p>
<h3 tabindex="-1" id="user-content-step-3-running-the-script-️" dir="auto"><a href="#step-3-running-the-script-️">Step 3: Running the Script 🏃‍♂️</a></h3>
<p dir="auto">In the terminal or command prompt, run the script with this command:</p>

<p dir="auto">The default output location for the Markdown files is : <code>~/Documents/ChatGPT-Conversations/MD/</code>. The script will automatically create the directories if they didn't exist. Feel free to <a href="#optional-customize-the-scripts-behavior-%F0%9F%8C%9F">customize</a> the script's behavior.</p>
<h3 tabindex="-1" id="user-content-step-4-check-the-output-" dir="auto"><a href="#step-4-check-the-output-">Step 4: Check the Output 🎉</a></h3>
<p dir="auto">And that's it! After running the script, check the output folder for your neatly formatted Markdown files.</p>
<h3 tabindex="-1" id="user-content-optional-customize-the-scripts-behavior-" dir="auto"><a href="#optional-customize-the-scripts-behavior-">Optional: Customize the Script's behavior 🌟</a></h3>
<h4 tabindex="-1" id="user-content-command-line-parameters" dir="auto"><a href="#command-line-parameters">command line parameters</a></h4>
<p dir="auto">Feel free to customize the script's behavior using additional parameters:</p>
<ul dir="auto">
<li><code>--out_folder</code>: Specify the output folder where the MD files will be saved.</li>
<li><code>--zip_file</code>: Specify the ZIP file containing the ChatGPT conversations to be converted.</li>
</ul>
<p dir="auto">Here is an example command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python main.py --out_folder &quot;Obsidian_Vault/Chats&quot; --zip_file &quot;My downloads/my_chat.zip&quot;"><pre>python main.py --out_folder <span><span>"</span>Obsidian_Vault/Chats<span>"</span></span> --zip_file <span><span>"</span>My downloads/my_chat.zip<span>"</span></span></pre></div>
<p dir="auto">This will extract and look for the <code>conversations.json</code> file in <code>~/My downloads/my_chat.zip</code>, and create the MD files in <code>~/Obsidian_Vault/Chats</code>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/obsidian-logo.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/obsidian-logo.png" alt="Obsidian Logo" width="50"></a></p>
<p dir="auto">(on <strong>Windows</strong>, <code>~/</code> refers to <code>C:/Users/{your_username}/</code>).</p>
<h4 tabindex="-1" id="user-content-configjson" dir="auto"><a href="#configjson"><code>config.json</code></a></h4>
<p dir="auto">You can also modify the <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/config.json">config.json</a> file, to customize the output :</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;system_title&quot;: &quot;System&quot;,
  &quot;user_title&quot;: &quot;YOUR NAME&quot;,
  &quot;assistant_title&quot;: &quot;My AI&quot;,
  &quot;tool_title&quot;: &quot;Code output (or plugin name)&quot;,
  &quot;delimiters_default&quot;: true
}"><pre>{
  <span>"system_title"</span>: <span><span>"</span>System<span>"</span></span>,
  <span>"user_title"</span>: <span><span>"</span>YOUR NAME<span>"</span></span>,
  <span>"assistant_title"</span>: <span><span>"</span>My AI<span>"</span></span>,
  <span>"tool_title"</span>: <span><span>"</span>Code output (or plugin name)<span>"</span></span>,
  <span>"delimiters_default"</span>: <span>true</span>
}</pre></div>
<p dir="auto">Change <code>"delimiters_default"</code> to <code>false</code> to replace all <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="5c6e851ddaaad342ec5182a560ef6d5f">$\LaTeX$</math-renderer> bracket delimiters : <code>\(...\)</code> and <code>\[...\]</code>, with dollar sign ones : <code>$...$</code> and <code>$$...$$</code>, if you'd like your math to render beautifully in Markdown readers that support <strong>MathJax</strong> (like Obsidian).</p>
<p dir="auto">You can also configure the YAML header in the <code>config.json</code> to add or remove fields.</p>
<h3 tabindex="-1" id="user-content-issues-and-contributions-" dir="auto"><a href="#issues-and-contributions-">Issues and contributions 🆘</a></h3>
<blockquote>
<p dir="auto">See <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>
</blockquote>
<p dir="auto">Feel free to fork this repository and make your enhancements or improvements. ALL contributions are welcome !</p>
<p dir="auto">If you encounter any issues or have questions, feel free to open an <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/issues">issue</a> / <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/discussions">discussion</a>.
See also : <a href="https://news.ycombinator.com/item?id=37636701" rel="nofollow">HN post</a>.</p>
<h3 tabindex="-1" id="user-content-enjoy-your-conversations-in-markdown-" dir="auto"><a href="#enjoy-your-conversations-in-markdown-">Enjoy Your Conversations in Markdown! 🎈</a></h3>
<p dir="auto">Hopefully, you find value in this tool. If you do, giving it a star ⭐ on the repository would mean a lot. Thank you!</p>
<h3 tabindex="-1" id="user-content-prerequisites" dir="auto"><a href="#prerequisites">Prerequisites</a></h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/python-logo.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/python-logo.png" alt="Python Logo" width="70"></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/images/git-logo.png"><img src="https://github.com/mohamed-chs/chatgpt-history-export-to-md/raw/main/images/git-logo.png" alt="Git Logo" width="70"></a></p>
<p dir="auto">Make sure you have <strong>Python</strong> (version &gt;= 3.10), and <strong>Git</strong> installed.
You can download them from :</p>
<ul dir="auto">
<li><a href="https://www.python.org/downloads/" rel="nofollow">Official Python website</a></li>
<li><a href="https://git-scm.com/downloads" rel="nofollow">Official Git website</a></li>
</ul>
<p dir="auto">Yep, no external dependencies needed.</p>
<h3 tabindex="-1" id="user-content-todo" dir="auto"><a href="#todo">TODO</a></h3>
<p dir="auto">Doing what needs to be done.</p>
<p dir="auto">Feel free to add or check items.</p>
<p dir="auto"><strong>general</strong></p>
<ul>
<li> keep external dependencies to a minimum (0 so far)</li>
<li> Javascript to download more conversations, see <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/javascript">Javascript</a></li>
<li> Add new downloaded conversations to the MD folder</li>
<li> Update past conversations if changed</li>
<li> More robust testing setup</li>
<li> Data visualizations : chat times, frequency, models, word clouds, etc...</li>
<li> Data analysis : categories and more classifications based on topics, concepts, programming tools, etc ...</li>
<li> Integration with Obsidian (folders and subfolders, tags, ...)</li>
<li> Add HTML as an output option</li>
<li> Format more content data, for example : plugin use</li>
<li> Support different response selections in a chat</li>
<li> Extract more data from the JSON files, like user feedback per message</li>
<li> Option to add metadata for each individual message</li>
<li> more todos ...</li>
</ul>
<p dir="auto"><strong>command line</strong></p>
<ul>
<li> Nicer command line output formatting</li>
<li> More configs from the command line (overwrite the config.json)</li>
<li> Link to submit issues or feedback</li>
<li> more todos ...</li>
</ul>
<p dir="auto"><strong>configs.json</strong></p>
<ul>
<li> change user, assistant, and system names</li>
<li> yaml header elements</li>
<li> specific configs for each individual conversation / conversation type</li>
<li> output folder (currently set by default or via command line arguments)</li>
<li> more configs ...</li>
</ul>
<blockquote>
<p dir="auto">See also : <a href="https://github.com/mohamed-chs/chatgpt-history-export-to-md/blob/main/javascript/how_to_use.md#still-working-on">JavaScript Todo</a></p>
</blockquote>
<h3 tabindex="-1" id="user-content-notes" dir="auto"><a href="#notes">Notes</a></h3>
<p dir="auto">This is just a small thing I coded to help me see my convos in beautiful markdown, in <a href="https://obsidian.md/" rel="nofollow">Obsidian</a> (my note-taking app).</p>
<p dir="auto">I wasn't a fan of the clunky, and sometimes paid, chrome extensions.</p>
<p dir="auto">I'm working on automating it to add new conversations and updating old ones. Had some luck with a JavaScript bookmarklet, still ironing it out tho. Shouldn't take long.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There's a new map style on OpenStreetMap.org (396 pts)]]></title>
            <link>https://en.osm.town/@openstreetmap/111120663721969898</link>
            <guid>37636551</guid>
            <pubDate>Sun, 24 Sep 2023 19:51:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.osm.town/@openstreetmap/111120663721969898">https://en.osm.town/@openstreetmap/111120663721969898</a>, See on <a href="https://news.ycombinator.com/item?id=37636551">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Unpacking Elixir: Resilience (197 pts)]]></title>
            <link>https://underjord.io/unpacking-elixir-resilience.html</link>
            <guid>37636529</guid>
            <pubDate>Sun, 24 Sep 2023 19:48:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://underjord.io/unpacking-elixir-resilience.html">https://underjord.io/unpacking-elixir-resilience.html</a>, See on <a href="https://news.ycombinator.com/item?id=37636529">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        
        <small>2023-09-24</small>
        <p>The nine nines. 99.9999999% of uptime. Whether the AXD301 actually deserves to be held up as a system of nine nines seems debatable. I am not particularly interested in that debate. Erlang has a strong record for reliability and a design intended to help you as a developer and operator achieve your nines. Maybe just five of them. Up to you really.</p>
<p>Previous episodes of this article series has unpacked <a href="https://underjord.io/unpacking-elixir-concurrency.html">Concurrency</a>, <a href="https://underjord.io/unpacking-elixir-realtime-latency.html">Real-time &amp; Latency</a> and <a href="https://underjord.io/unpacking-elixir-syntax.html">the syntax</a>. In this one we talk about how Elixir and Erlang achieve reliability.</p>
<p>There are agressive, defensive and rigorous practices you can adopt in a variety of ways to achieve reliability and resilience. Testing, profiling, specifications, design, observability, culture, operations and so on. This is not about most of those. This is about software abstractions that serve you in making your system more resilient and allow you to construct resilient designs.</p>
<p>Erlang implements the Actor model, the typical actor in Erlang and Elixir terminology is the GenServer. The generic server. It is a process that has some nice facilities for receiving calls (“synchronous” messages, expecting a response within a timeout) and casts (asynchronous messages, with no expectation of reply). A GenServer is a bunch of API wrapped around the basic Erlang process. A process can receive and send messages. A GenServer (also other related types, gen_event, gen_statem) implements capturing errors that occur and the subsequent exit and passing information about the problems to the parental process as a message.</p>
<p>So what is the parental process. Well it is usually a special type of Erlang process called a Supervisor. A Supervisor can run multiple child processes that implement the necessary API for being a child. The Supervisor then handle problems with the children falling over by applying a strategy.</p>
<p>The strategies are normally <code>one_for_one</code>, <code>one_for_all</code> and <code>one_for_rest</code>. One for one indicates that if a child crashes it, it and only it should be considered when restarting. Leave the others alone. One for all means that the supervisor should restart all children if one child fails. This is often useful if the children are sharing a workload in some important way where restarting one would cause trouble with the others. One for rest is kind of nuanced in that the Supervisor will restart any child defined in the starting order after the crashing one. This can be used to kill a supporting process if the main one dies for example.</p>
<p>So a Supervisor supervises a set of child processes. This set can be dynamic, growing and shrinking as the system operates. In Elixir that would be a DynamicSupervisor. If a single crash happens within a child it will apply the strategy. If the new child crashes immediately it will try again. If there are enough failures within a given threshold the Supervisor will consider itself failing at the job and crash.</p>
<p>This crashing is a feature, not a bug. By crashing it will propagate a signal to whatever Supervisor started this Supervisor that there is an issue. This Supervisor can in turn apply strategies to try and recover the Supervisor through the tried and true practice of turning it off and on again. Or via custom logic if you are feeling spicy.</p>
<p>How many restarts, how often, how intense it is allowed to get. That’s all configurable. You might be fine with the defaults but if you have something particular in mind you have a pretty solid set of knobs to twiddle.</p>
<p>By having Supervisors supervise Supervisors all the way back to the root Supervisor which sits on top of your particular Erlang application we have defined a supervision tree. The idea being that any issue out in a nice leaf node of a tree is probably addressable there and should not affect the rest of your nice stateful actor-packed system. But if it isn’t, it is probably addressable at a branch closer to the tree.</p>
<p>A typical use-case for a Supervisor is a connection pool. And it might be the case that if any of the connections crash that indicates a problem with the server and you know from experience that you might as well re-establish every connection in the pool. Cool. Your Supervisor should do <code>one_for_all</code>. While if a phone-call crashes you probably don’t want to dump out every call in the system just because one had a weird issue. <code>one_for_one</code> should do it.</p>
<p>This is where the Erlang “Let it Crash” idea comes from. It is a bit of a meme (often repeated, poorly examined, often misunderstood, sometimes with funny pictures). Fundamentally, if there is nothing useful your code can do on a failure, no mitigation, no meaningful fallback, then you might as well have it blow up and rely on the underlying tree to make whatever is most useful out of it. You should probably handle the usual suspects “oh, data is missing, let’s 404”. That is an expected failure mode. “oh, hard drive has imploded and disk can’t be read” is a very different error and a 500 Internal Server Error is probably fine.</p>
<p>I don’t think I’ve seen an up-and-running Elixir application go down due to exhausting the Supervision tree with erroring out. I have seen it many times as a failure mode for a misconfigured deploy, typically missing an env variable, where starting the initial supervision tree fails.</p>
<p>Supervision is the fundamental building block in Erlang’s resilience story.</p>
<p>How is it used in Elixir? Not much. As in, we don’t typically need to think about it. Phoenix ships a practical and helpful Supervision tree. Ecto ships a good Supervision tree for your database connections and all that. These Supervision trees live a peaceful secretive life under the guise of library code and you get all the advantage with none of the work. And the moment you start coloring outside the lines and building your own GenServers the facilities are there for you.</p>
<p>With your regular generated Phoenix web application all you see is that your <code>application.ex</code> file contains a few entries for different purposes. These are the first branches of your supervision tree and all that you really see.</p>
<p>You get <code>MyApp.Repo</code> for your Ecto Repo which is the abstraction for all your database connectivity, hiding your connection pools and whatnot. You get <code>MyApp.Endpoint</code> which wraps up your HTTP server (Cowboy or Bandit) in Plug and Phoenix abstractions to respond. Under this you will build up a subtree with a variety of jobs. For HTTP requests you have processes that respond. I believe Cowboy uses a pool and Bandit spawns more ad-hoc. There are also the WebSockets and the specific Phoenix Channels or LiveView processes that belong to the state of your application. This all branches out from your Endpoint as it is all related to your web serving.</p>
<p>You can hear more about <a href="https://www.beamrad.io/53">how Bandit operates</a> on the BEAM Radio episode we did with Mat Trudel. We got into the process usage a decent bit there.</p>
<p>Separately you’ll have <code>MyApp.PubSub</code> which starts the Process Groups (pg2) or Redis adapter for doing cool PubSub stuff. This is not strictly web-related, so it has a separate sub-tree. Someone did a thinking.</p>
<p>I appreciate that Phoenix doesn’t try to hide this stuff from you any more than abstracting away the details. If you want to run your app without the web part you can quickly get to the idea of dropping the Endpoint from the list. You simply don’t start it. Same with the DB, just cut out the Repo. Likewise if you need multiple DBs or multiple web services. You can make more Repos and Endpoints. It is explicit. The code is right there. It uses the standard Erlang and Elixir way of starting things.</p>
<p>Anyway, that’s a detour from resilience and reliability. Fundamentally you have these supervisors, strategies as a structure to contain the blast radius of errors. The places this approach falls down is if you build a native implemented function (NIF) in C or similar. A crash in that brings down the whole VM. This is why doing work in properly managed BEAM code is preferred in most cases and why you’ll often see attempts to re-implement things in Elixir/Erlang rather than just binding to an existing C library. Rust and Rustler, Zig and Zigler both offer NIF implementations with some additional safety. Of course they don’t entirely remove the risks of native code though.</p>
<p>Rustler uses <a href="https://medium.com/@jlouis666/erlang-dirty-scheduler-overhead-6e1219dcc7">dirty schedulers</a> and I expect Zigler does something similar or at least supports the old and the new options for building NIFs. So they should play nice-ish with Erlang scheduling. But fundamentally native code doesn’t quite offer the same safety or same behavior.</p>
<p>Beyond Supervision trees there are more aspects of Erlang that are resilient. Scheduling and pre-empting was intended to produce <a href="https://underjord.io/unpacking-elixir-realtime-latency.html">consistently low latencies</a> but it also protects you from heavy workloads bogging things down, it prevents infinitely looping bugs from slowing the system to a crawl and in general makes things resilient to things not being ideal all the time.</p>
<p>Another thing is the Erlang heart. That’s a module that can be used to detect the Erlang application itself going down and being able to start it again. An almost-supervisor for your entire application. The IoT <a href="https://nerves-project.org/">Nerves project</a> also uses a variant of this to help ensure a resilient device.</p>
<p>Having built in other web frameworks and languages this is all a bit foreign. It is more reminiscent of building a microservice architecture than building a single application. But it does occur at the application level. It gives you tools to think about bringing up your system, bringing down your system, handling failure in your system. Those concerns all exist in other languages but the control-mechanisms tend to be quite coarse. Erlang and Elixir helps you think about how you design your application.</p>
<hr>
<p>Do you have lessons learned that you’d like to share about building for resiliency? Does the Erlang way of doing it resonate with you? Let me know over email at <a href="mailto:lars@underjord.io">lars@underjord.io</a> or via <a href="https://twitter.com/lawik">@lawik</a>.</p>

        <p>Note: If you like my writing you might appreciate my videos. Give them a go over on <a href="https://youtube.com/c/underjord">the YouTube
                channel</a>.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Two photographers captured the same millisecond in time (2018) (475 pts)]]></title>
            <link>https://www.dpreview.com/articles/7338941576/how-two-photographers-captured-the-same-millisecond-in-time</link>
            <guid>37636124</guid>
            <pubDate>Sun, 24 Sep 2023 19:01:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dpreview.com/articles/7338941576/how-two-photographers-captured-the-same-millisecond-in-time">https://www.dpreview.com/articles/7338941576/how-two-photographers-captured-the-same-millisecond-in-time</a>, See on <a href="https://news.ycombinator.com/item?id=37636124">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p><iframe allowfullscreen="" frameborder="0" height="326" src="https://player.vimeo.com/video/258671812?title=0&amp;byline=0&amp;portrait=0&amp;color=44BBDD" width="580" sandbox="allow-scripts allow-same-origin"></iframe></p>
<p>On March 3<sup>rd</sup>, during a large East Coast winter storm, I headed to the ocean to capture some wave action. My travels eventually took me to Great Island Commons in New Castle, NH where Whaleback Lighthouse is prominently featured 0.8 miles offshore. I was hoping to capture big waves crashing around the lighthouse, and Mother Nature didn’t disappoint.</p>
<p>Great Island Common is a wide open park where people come to picnic during the summer and to watch the ocean during the winter. After arriving, I set up my tripod and my Canon 5D Mark IV with Sigma 150-600mm lens on a tripod and positioned myself just to the right of a tree in order to help reduce the pummeling Northerly winds. As many of you know, it’s a challenge keeping 600mm stable in high winds, even on a tripod.</p>
<p>I set the camera up and then waited until I saw a wave starting to hit the lighthouse. I then kept firing until the splash ended, not knowing ahead of time the action of the wave. Most shots never panned out, but about three of them over the course of about 45 minutes were pretty decent.</p>
<p>Once back at home, I culled through the images and choose one to edit and upload to Instagram, replacing an earlier upload that was done in haste while still in the parking lot.</p>
<p>When a local TV station shared the photo to their Facebook page (with permission) it started to receive a large amount of shares, comments, and likes; however, there was one comment that mentioned that I had stolen the image from another New England photographer, <a href="https://www.facebook.com/ericgendronphotography/">Eric Gendon</a>. After letting the commenter know that it was indeed my image and that I possess the original RAW file, I headed over to the other photographers page and was blown away.</p>
<p>We had what looked like the exact same image, taken at the exact millisecond in time, from what looked like the same exact location and perspective.</p>
<p><a href="https://www.dpreview.com/files/p/articles/7338941576/Eric_Ron_sidebyside.jpeg" target="article-7338941576"><img data-thumbnail-height="0" data-thumbnail-width="590" height="282" src="https://4.img-dpreview.com/files/p/E~TS590x0~articles/7338941576/Eric_Ron_sidebyside.jpeg" width="590" data-filename="Eric_Ron_sidebyside.jpeg" srcset="https://4.img-dpreview.com/files/p/E~TS1180x0~articles/7338941576/Eric_Ron_sidebyside.jpeg 2x"></a></p>
<p>Aside from choices made in Lightroom, the photos at first glance look virtually identical aside from water in front and some of the white caps being in different position. Even then, the white caps were identical in size and shape—and I know those things are easily moved using the clone stamp in Photoshop—so I was concerned that maybe MY image was stolen and altered a bit.</p>
<p>Initially, I only had access to his shared, low-resolution, image so I wasn’t able to make out some of the very fine details that ultimately helped to convince me that we both had originals. After overlaying and aligning the images in Photoshop I was blown away that the lighthouse and waves were carbon copies, almost to the pixel. As mentioned already, there were many differences in the foreground water and the white caps on the horizon, and it was these differences that held me back from claiming he stole my image.</p>
<p>It wasn’t until another local photographer started comparing my photo to a higher resolution version of Eric’s image that he noticed that the iron gating around the top of the lighthouse had slightly different spacing between the vertical bars compared to my image. This would indicate that the other photographer was likely standing just a little bit left of where I was standing.</p>
<p>Since the 60D uses an APS-C sensor he would have also likely been back a little further to compensate for the 1.6x “zoom” / crop of the sensor or using a shorter focal length to compensate. This would also explain the white caps being in different positions.</p>
<p><a href="https://www.dpreview.com/files/p/articles/7338941576/Compare_with_circles.jpeg" target="article-7338941576"><img data-thumbnail-height="0" data-thumbnail-width="590" height="306" src="https://3.img-dpreview.com/files/p/E~TS590x0~articles/7338941576/Compare_with_circles.jpeg" width="507" data-filename="Compare_with_circles.jpeg"></a></p>
<p>However, the fact that the lighthouse doesn’t really show any rotational changes—and the crashing wave is an exact match—makes this all the more remarkable that these were captured randomly from two different photographers.</p>
<p>The next morning, Eric woke up to a flood of messages from me as well as other photographers, and immediately contacted me to share his EXIF data, and to agree that it was astounding that we both captured the exact same image of water motion at the exact millisecond in time. What makes this even more amazing is that this wasn’t a planned event (aka. sporting event, shuttle launch, etc.).</p>
<p>I also didn’t know Eric—we each chose this location randomly, and we both shot with different cameras (60D and 5D Mark IV) with different size sensors.</p>
<p>The 60D has a burst mode of 5.3fps, the 5DMKIV is 7fps; we both used a 600mm focal length; our exposures and depth-of-field were almost the same as well (F8 aperture, ISO 400, 1/1600<sup>th</sup> shutter vs. F8, ISO 320, 1/1000<sup>th</sup> shutter); and, ultimately, we both selected the same photo from that day to promote. Come to find out we were only <em>28 meters away from each other</em>. He was hunkered down under a picnic enclosure to help block some of the wind and I was up against a tree to help reduce the wind.</p>
<p><a href="https://www.dpreview.com/files/p/articles/7338941576/Photographers_Position.jpeg" target="article-7338941576"><img data-thumbnail-height="0" data-thumbnail-width="590" height="507" src="https://3.img-dpreview.com/files/p/E~TS590x0~articles/7338941576/Photographers_Position.jpeg" width="590" data-filename="Photographers_Position.jpeg"></a></p>
<p>I did a Google search to see how often this happens and could only find one article from 2011 where two photographers filming a surf competition on Huntington Beach ended up catching a virtually identical image of a surfer and its wave action.</p>
<p>If you shoot water in burst mode you know how different each exposure is even when the difference in time is just 1/7<sup>th</sup> of a second between shots. And I have been leading night-sky photography workshops for five years and have had well over 200 photographers who are often aiming at the same subject, shooting with similar cameras and lenses, and capturing at the same moment in time, even doing continuous shooting for time lapse, and until now I have never seen two images that were so close as to be virtual clones of each other.</p>
<p>While this is a rare occurrence, I believe that with cameras getting faster and photographers taking more time to prepare for their shots, I have to imagine that these situations will happen more frequently. It happens every day with stationary or slow motion objects (buildings, sun/moon rise) but almost never with water movement.</p>
<p>One commenter on my FB post mentioned how this mistake brings to light the importance that post-processing plays in making your images your own. Here we had two essentially identical images—one edited to preserve a more natural feel, while the other image was edited to enhance the drama and emotion of the scene.</p>
<h3>Photographer Information</h3>
<p><strong>Ron Risman<br> </strong>Website: <a href="http://www.timelapseworkshops.com/">http://www.timelapseworkshops.com</a><br> Instagram: <a href="https://www.instagram.com/Timeographer/">Timeographer</a><br> Facebook: <a href="https://www.facebook.com/risman">risman</a></p>
<p><strong>Eric Gendron</strong> <br> Website: <a href="http://www.ericgendronphotography.com/">http://www.ericgendronphotography.com/</a><br> Instagram: <a href="https://www.instagram.com/ericgendronphotography/">ericgendronphotography</a><br> Facebook: <a href="https://www.facebook.com/ericgendronphotography">ericgendronphotography</a></p>
<hr>
<p><em><strong>Ron Risman</strong> is a New England-based photographer, cinematographer, and time-lapse specialist with over 30 years of experience behind the camera. You can find more of his work on <a href="https://www.timelapseworkshops.com/">his website</a>, <a href="https://www.instagram.com/Timeographer/">Instagram</a>, and <a href="https://www.facebook.com/risman">Facebook page</a>.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[μMon: Stupid simple monitoring (2022) (245 pts)]]></title>
            <link>https://tomscii.sig7.se/2022/07/uMon-stupid-simple-monitoring</link>
            <guid>37636013</guid>
            <pubDate>Sun, 24 Sep 2023 18:50:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tomscii.sig7.se/2022/07/uMon-stupid-simple-monitoring">https://tomscii.sig7.se/2022/07/uMon-stupid-simple-monitoring</a>, See on <a href="https://news.ycombinator.com/item?id=37636013">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">
  
  <div itemprop="articleBody">
    <p>Let me introduce you to <a href="https://tomscii.sig7.se/umon">μMon</a>, my
personal, minimalist, opinionated take on host monitoring based on
<a href="https://oss.oetiker.ch/rrdtool/">RRDtool</a>, SNMP, some lightweight
shell scripting, and a small FastCGI server written using a modest
subset of modern C++.</p>

<p>Migrating my monitoring setup to <em>μMon</em> also serves as a case study
in <em>complexity reduction,</em> which is the broader theme of this post.</p>

<!--more-->

<p>Here is an example of how <em>μMon</em> might look like:</p>

<p><a href="https://tomscii.sig7.se/images/umon/aurora_main.png"><img src="https://tomscii.sig7.se/images/umon/aurora_main_thumb.jpg" alt=""></a><br>
<em>Main view of my Pinebook Pro (click to enlarge)</em></p>

<p>The above view covers the better part of my Pinebook Pro upgrading
itself to OpenBSD 7.1, compiling the whole system from source. The
vertical gaps are due to the machine being off.<sup><a href="#f1">1</a></sup></p>

<p>Here is a second example with a different view on another host:</p>

<p><a href="https://tomscii.sig7.se/images/umon/hq_ups.png"><img src="https://tomscii.sig7.se/images/umon/hq_ups_thumb.jpg" alt=""></a><br>
<em>Upsc view of the server that brought you this webpage (click to enlarge)</em></p>

<p>This view captures a short planned test of my UPS (visible in the
middle).  Data is sourced directly from the output of the <code>upsc</code>
command, as opposed to
<a href="https://github.com/tomscii/upsc-snmp-agent">SNMP</a>.
(Yeah, I know. Time for a new UPS battery.)</p>

<h2 id="why-μmon">Why μMon?</h2>

<p>I created <em>μMon</em> due to my love of minimalism and how short
existing solutions fall from that ideal. Specifically, I migrated my
stack of Prometheus + Grafana that I have been running at home for the
last couple years to <em>μMon</em>. By doing so, I managed to finally get
rid of:</p>

<ul>
  <li>
    <p>A full-blown time-series database (with gigabytes
of rolling on-disk data).</p>
  </li>
  <li>
    <p>Several Go binaries dozens of megabytes each, also consuming runtime
resources. (One of them got habitually stuck in an endless loop, so
I put in a crontab entry to restart it daily. I do not appreciate
black boxes like that.)</p>
  </li>
  <li>
    <p>Lengthy configuration files and lengthy argument lists to said
binaries.</p>
  </li>
  <li>
    <p>Systems continuously talking to each other over the network (even
when nobody is looking at any dashboard), periodically pulling
metrics from nodes into Prometheus, which in turn runs all sorts of
consolidation routines on that data. A constant source of noise in
otherwise idling systems.</p>
  </li>
  <li>
    <p>A mind-boggingly complex web front-end (Grafana) with its own
database, tons of JavaScript running in my browser, and role-based
access control over multiple users.</p>
  </li>
  <li>
    <p>A bespoke query language to pull metrics into dashboards, and lots
of specialized knowledge in how to build useful dashboards.  It is
all meant to be intuitive, but man, is it complicated!  (People
write whole books on how to operate and use this!)</p>
  </li>
  <li>
    <p>Tons of eye candy I did not really mind, but did not really
appreciate either.</p>
  </li>
</ul>

<p>No doubt this complex (and to me, opaque) stack would inevitably get
obsolete, necessitating migrations prone to failure, or demand my
attention in other, even less predictable ways. In short: keeping up
with the state of the art requires an ongoing investment.</p>

<p>I have a general inclination towards minimalism, and a preference for
long-term durable solutions that do not need continuous attention and
care. Having spent many years as a student of complexity (commonly
referred to as a career in IT), I have come to hate the kind of
surprises that complex (clever, if you will) systems are so prone to.
Nowadays, when I provision something, I ask: would this run for 10
years if I forgot about it? How long before it would break, or need to
be redeployed with a new (incompatible) major version? Or, if nothing
else, go hopelessly out of fashion (hello docker!)?</p>

<p>So I substituted all the above with an extremely lightweight stack
based on very well understood, several decades old concepts and
programs. I now have a system that is comprehensible in its scope and
size, and trivially understandable in its simplicity. I did this in
the hope that it will serve me for decades to come, without any undue
need of caring for it. In fact, my ambition was to solve the problem
of server monitoring <em>once and for all</em>, at least for all systems in
my care. This fits neatly into my overall strategy of establishing
fully autonomous, sustainable personal computing. Less bells and
whistles, less overhead and less <em>churn</em> equals less to worry about,
while keeping all the features actually needed.</p>

<p>By the way, I am not meaning to pick on Prometheus and Grafana in
particular. If you have used Cacti, Collectd, Graphite, InfluxDB,
Nagios, OpenNMS, Zabbix, or anything similar, then you will probably
agree that setting up and using any of these tools is anything but
simple. In fact, any monitoring stack will be similar to what I
described above in terms of its complexity.<sup><a href="#f2">2</a></sup>
Granted, if you get paid as a <del>sysadmin</del> <del><em>DevOps</em></del> <strong>Site
Reliability Engineer</strong>, you probably need to master some locally
useful combination of these comprehensive tools. If that is not your
job, and you want something <a href="https://en.wikipedia.org/wiki/KISS_principle">simple and
stupid</a>, you might find
<em>μMon</em> interesting.</p>

<p>Keeping it simple and stupid is such a priority that as an all-time
reminder, I decided to include the word <em>simplicity</em> right in the
<em>μMon</em> logo I “designed”:</p>

<p><img src="https://tomscii.sig7.se/images/umon/umon_logo_black.png" alt=""></p>

<p>In total, I estimate that I spent the equivalent of <em>at most</em> one week
of full-time engineering work (scattered over about a month of
evenings and weekends) on creating <em>μMon</em>. Including the logo!</p>

<p>Granted, <em>μMon</em> does not cater to every need, only my very own —
and those are definitely modest. I do not run anything that could be
considered modern or fashionable; I only run a bunch of Unix boxes (a
mixture of Linux and BSD). No Docker (or podman), no ProxMox, no
Kubernetes. Anywhere I get to decide, I use stable, proven, old
technology. In addition, my monitoring needs are fairly modest: I only
want basic metrics. Most importantly, I do not use any fancy alerting
functionality.<sup><a href="#f3">3</a></sup> That could be added on top of what
exists in <em>μMon</em>, but it stands for a sizable chunk of complexity
in the “real” monitoring systems mentioned above; getting it right is
very non-trivial, and not just from a technical
perspective.<sup><a href="#f4">4</a></sup> Since the small-scale servers I run
work pretty much unattended year in and year out, this is fine — I
only want to be able to look at metrics to spot trends and interesting
times to investigate by looking at event logs, etc.</p>

<p>That said, <em>μMon</em> gives me everything I have ever gotten from my
old setup (mostly the “interesting subset” of the output of
<code>node_exporter</code>, plus the metrics of a custom <code>upsc</code> feeder I hacked
together). And there are distinct advantages to <em>μMon</em>:</p>

<ul>
  <li>
    <p>A well understood, constant-space storage model thanks to RRDtool. I
know exactly how much disk space the aggregated data takes, and more
importantly, I know it will never grow beyond that extent.</p>
  </li>
  <li>
    <p>A well understood model of data consolidation and retention, built
on RRDtool’s consolidation functions. I can look back at anywhere
between the last one hour and the last two years, with the right
temporal resolution.</p>
  </li>
  <li>
    <p>Independent nodes. Each host runs <em>μMon</em> on its own, both to
collect metrics and to serve the webpage. There is no single point
of collection, storage, or access to the system, nor a single point
of failure. (Arguably, this can be a disadvantage depending on your
perspective, but it matches my preference.)</p>
  </li>
  <li>
    <p>Very lightweight data collection. Each host collects its own metrics
in locally stored round-robin archives; data collection does not
incur any network activity. Configuration of metrics collection
equals listing the probes you want (but you can use all the power of
shell scripting, if you wish).</p>
  </li>
  <li>
    <p>Very simple server setup. I use <code>(x)inetd</code> to serve the FastCGI of
<em>μMon</em> via a TCP socket to whatever web server I have on the host
(or a different host). The <em>μMon</em> collector script is run by cron.
Everything that belongs to <em>μMon</em> resides and runs under an
unprivileged user.</p>
  </li>
  <li>
    <p>Extremely minimal dependencies. To install <em>μMon</em>, all I need is a
Unix system with a POSIX shell (<code>/bin/sh</code>), a modern C++ compiler,
and the ability to install <code>rrdtool</code>. No PHP (or other web toolkit),
no Python, no NodeJs. No database (time-series or relational). A
local webserver (with FastCGI support) is optional; a remote
webserver can act as the proxy as well.</p>
  </li>
  <li>
    <p>Graphs (plots of certain groups of metrics) and views (collections
of graphs) can be created or modified any time, by editing simple,
small shell scripts. They can even be edited in place for immediate
effect (nothing to restart). Of course, knowledge of RRDtool and the
POSIX shell is mandatory, but then again, <em>μMon</em> is for hardcore
Unix sysadmins with modest needs.  Anything you need to know above
what is already etched into your brain you will find in the <code>rrd*</code>
man pages. But you can get started without changing anything.</p>
  </li>
</ul>

<h2 id="not-invented-here">Not invented here?</h2>

<p>You could argue that I am exhibiting <a href="https://en.wikipedia.org/wiki/Not_invented_here">NIH
syndrome</a> by
inventing my own (inferior) solution to a problem space well
understood and explored by many, many others. You would perhaps not be
very wrong.</p>

<p>To my defense, let me state that I am not forcing (not even
encouraging) anyone to adopt and use <em>μMon</em>. Rather, I am showing
it here as a case study in the noble pursuit of complexity reduction,
something that I feel is getting more and more important.  Especially
when focusing on one’s own personal computing affairs.</p>

<h2 id="reduction-in-complexity">Reduction in complexity</h2>

<p>Here is a table to recap the transition from all-in to minimal
complexity. Note that this is <em>not</em> a moral stance against higher
complexity, which you might need for fully legitimate reasons (such as
requiring complex alerting over metrics aggregated from different
hosts) that <em>μMon</em> does not support.</p>

<table>
  <thead>
    <tr>
      <th>Aspect</th>
      <th>Prometheus + Grafana</th>
      <th>μMon</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>look and feel</td>
      <td>shiny, modern</td>
      <td>old-school</td>
    </tr>
    <tr>
      <td>development</td>
      <td>probably several man-decades</td>
      <td>one man-week (tops)</td>
    </tr>
    <tr>
      <td>system model</td>
      <td>central servers, distributed feeders</td>
      <td>one independent node per host</td>
    </tr>
    <tr>
      <td>technologies</td>
      <td>Go, HTTP, JavaScript, TSDB, …</td>
      <td>/bin/sh, RRDtool, SNMP</td>
    </tr>
    <tr>
      <td>daemons</td>
      <td>collectors, prometheus, grafana</td>
      <td>umon_fcgi invoked by (x)inetd</td>
    </tr>
    <tr>
      <td>database</td>
      <td>bespoke TSDB with WAL, etc.</td>
      <td>RRDtool</td>
    </tr>
    <tr>
      <td>db size</td>
      <td>dynamic; gigabytes</td>
      <td>constant; a couple megabytes</td>
    </tr>
    <tr>
      <td>db activity</td>
      <td>has its own inner life, runs GC, etc.</td>
      <td>static (in-place RRA overwrites)</td>
    </tr>
    <tr>
      <td>frontend</td>
      <td>complete web stack</td>
      <td>FastCGI server invoking hooks</td>
    </tr>
    <tr>
      <td>configuration</td>
      <td>point-and-click, stored in opaque db</td>
      <td>small shell scripts</td>
    </tr>
    <tr>
      <td>plugins</td>
      <td>bespoke (large) binaries</td>
      <td>SNMP and simple shell scripts</td>
    </tr>
    <tr>
      <td>collection</td>
      <td>over the network</td>
      <td>local (works offline) via cron</td>
    </tr>
    <tr>
      <td>alerting</td>
      <td>complex conditions, several channels</td>
      <td>no support at all</td>
    </tr>
    <tr>
      <td>maintenance</td>
      <td>ongoing upgrades &amp; migrations</td>
      <td>minimal, if any</td>
    </tr>
  </tbody>
</table>



<h2 id="conclusion">Conclusion</h2>

<p>I am not saying that “big solutions” are necessarily bad or wrong. But
I do want to argue that there is a place for small, perhaps even
bespoke, site-only solutions that can serve the common 80% of needs
just as well, at several orders of magnitude less complexity. All the
while retaining nimbleness to be extended to cover the remaining 20%,
when prompted by actual need. There is something to be said for a
(figurative) napkin’s worth of code hacked together in a man-week that
is capable of bringing the same ultimate value as a full-fledged stack
that was no doubt developed in what is probably several man-decades
(if not centuries) of engineering work.  Sometimes a simple, dumb
solution can be fairly robust and complete. I believe <em>μMon</em> is a
good illustration of this general idea.</p>

<p>At the same time, I feel this is ultimately less of a surprise than it
might first seem. Let us not forget that running Unix-descended or
Unix-like systems means we are standing on the shoulders of giants: we
have time-proven architectural tenets, open standards and systems
programming APIs, plus free development tools at our disposal. On top
of that, the venerable RRDtool embeds some pretty sophisticated,
time-honed data sampling and graph rendering logic.  Granted, it takes
an educated sysadmin to make use of it all (being a competent systems
programmer as well is a big plus), but that is pretty much the
original intended audience of these operating systems.</p>

<p><a href="https://github.com/tomscii/umon">μMon</a> is released to the public
under the BSD license (the same zero-clause flavour that OpenBSD
uses).  If you feel inclined to try it yourself, please recall that it
is not my goal to supply you (or the world) with a toolkit that works
out of the box and suits everyone. I am specifically not advocating
<em>μMon</em> as a direct substitute to any of the well-known monitoring
stacks.<sup><a href="#f5">5</a></sup> In the spirit of the BSD license, it is
simply my gift to the world. What you do with it (whether or not you
find it useful) is up to you.  At any rate, you are expected to read
your way through some simple shell scripts and adapt them to your
needs. That said, if you have educated questions or constructive
feedback (positive or negative) about it, feel free to <a href="https://tomscii.sig7.se/id/">contact
me</a>.</p>

<hr>

<p><b id="f1">1</b> The machine froze Friday night, which I did not
notice for over an hour. Apparently building the OpenBSD base system
with <code>-j 6</code> was too much to ask from the hardware, so I resumed with
my usual <code>-j 4</code>.</p>

<p><b id="f2">2</b> What looks like the closest existing solution to
<em>μMon</em> is a stack of programs called
<a href="https://wpd.home.xs4all.nl/symon/index.html">symon</a>, consisting of
(at least) <code>symon</code>, <code>symux</code> and <code>syweb</code>. This is also largely
RRDtool-based. But… the user needs to configure listeners with port
numbers just to get some data collection going; needs to install
RRDtool into a webserver chroot; needs a webserver with PHP enabled,
etc.</p>

<p><b id="f3">3</b> I do have my personal collection of cron-driven
scripts that check essentials (such as expired SSL certificates) and
email me if there is anything that needs my attention. I just prefer
to keep these things separate from monitoring data rates and disk
usage percentages.</p>

<p><b id="f4">4</b> I could rant about the incessant floods of useless
email/pager alerts coming from everywhere, seemingly so inseparable
from Big Tech Company Culture, complete with the inevitable result of
people ignoring/filtering them out, for a net result of precisely zero
business value achieved at a tremendous cost. But that is another post
patiently waiting to be written.</p>

<p><b id="f5">5</b> Let’s be real: <em>μMon</em> absolutely <em>does not</em>
support many of the important use cases of the more complicated
stacks. Do I care about any of it? Absolutely not. The point of this
exercise was not to create a rewrite of Prometheus + Grafana (they are
fine as is), but rather create something that is at least three orders
of magnitude smaller, while providing all the functionality I need.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minecraft Wiki has decided to leave Fandom (128 pts)]]></title>
            <link>https://twitter.com/MinecraftWikiEN/status/1706004078206103965</link>
            <guid>37635939</guid>
            <pubDate>Sun, 24 Sep 2023 18:41:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/MinecraftWikiEN/status/1706004078206103965">https://twitter.com/MinecraftWikiEN/status/1706004078206103965</a>, See on <a href="https://news.ycombinator.com/item?id=37635939">Hacker News</a></p>
Couldn't get https://twitter.com/MinecraftWikiEN/status/1706004078206103965: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
    </channel>
</rss>