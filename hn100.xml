<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 12 Aug 2023 05:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Our fight is far from over (140 pts)]]></title>
            <link>https://blog.archive.org/2023/08/11/our-fight-is-far-from-over/</link>
            <guid>37096149</guid>
            <pubDate>Sat, 12 Aug 2023 01:46:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.archive.org/2023/08/11/our-fight-is-far-from-over/">https://blog.archive.org/2023/08/11/our-fight-is-far-from-over/</a>, See on <a href="https://news.ycombinator.com/item?id=37096149">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-26250">
				<!-- .entry-header -->

				<div>
			
<figure><a href="http://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1.png"><img decoding="async" width="1024" height="575" src="http://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1-1024x575.png" alt="" srcset="https://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1-1024x575.png 1024w, https://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1-300x168.png 300w, https://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1-768x431.png 768w, https://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1-1536x862.png 1536w, https://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1-624x350.png 624w, https://blog.archive.org/wp-content/uploads/2023/03/16_9-logo-white-letters-on-black-1.png 1850w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Four months after the disappointing decision on summary judgment in <em>Hachette v. Internet Archive</em>, a number of <a href="https://www.courtlistener.com/docket/17211300/hachette-book-group-inc-v-internet-archive/?order_by=desc" target="_blank" rel="noreferrer noopener">papers were filed today</a> in the district court,&nbsp;and then the judge is expected to make his final judgment. We expect that, at least while the appeal is pending, there will be changes to our lending program, but the full scope of those changes is a question pending with the district court. We will provide an update on those changes once the district court decision is final.</p>



<p><strong>Our fight is far from over—</strong>We remain steadfast in our belief that libraries should be able to own, preserve, and lend digital books outside of the confines of temporary licensed access. We believe that the judge made errors of law and fact in the decision, and we will appeal.</p>



<p><strong>Statement from Internet Archive founder, Brewster Kahle:</strong><br>“Libraries are under attack at unprecedented scale today, from book bans to defunding to overzealous lawsuits like the one brought against our library. These efforts are cutting off the public’s access to truth at a key time in our democracy. We must have strong libraries, which is why we are appealing this decision.”</p>



<h2><strong>How to Take Action:</strong></h2>



<p><strong>Stand up for libraries</strong><br>Stand up for the digital rights of all libraries! Join the Battle for Libraries: <a href="https://www.battleforlibraries.com/">https://www.battleforlibraries.com/</a>&nbsp;</p>



<p><strong>Support the Internet Archive&nbsp;</strong><br><a href="https://archive.org/donate">Support the Internet Archive</a> to continue fighting for libraries in court!</p>



<p><strong>Stay connected</strong><br>Sign up for the <a href="https://empoweringlibraries.org/get-involved/">Empowering Libraries newsletter</a> for ongoing updates about the lawsuit and our library.</p>
					</div><!-- .entry-content -->
		
		<!-- .entry-meta -->
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Police stage ‘chilling’ raid on Marion County newspaper (193 pts)]]></title>
            <link>https://kansasreflector.com/2023/08/11/police-stage-chilling-raid-on-marion-county-newspaper-seizing-computers-records-and-cellphones/</link>
            <guid>37096015</guid>
            <pubDate>Sat, 12 Aug 2023 01:27:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kansasreflector.com/2023/08/11/police-stage-chilling-raid-on-marion-county-newspaper-seizing-computers-records-and-cellphones/">https://kansasreflector.com/2023/08/11/police-stage-chilling-raid-on-marion-county-newspaper-seizing-computers-records-and-cellphones/</a>, See on <a href="https://news.ycombinator.com/item?id=37096015">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="dataContent">
                                    <p>MARION — In an unprecedented raid Friday, local law enforcement seized computers, cellphones and reporting materials from the <a target="_blank" href="http://marionrecord.com/">Marion County Record</a> office, the newspaper’s reporters, and the publisher’s home.</p>
<p>Eric Meyer, owner and publisher of the newspaper, said police were motivated by a confidential source who leaked sensitive documents to the newspaper, and the message was clear: “Mind your own business or we’re going to step on you.”</p>
<p>The city’s entire five-officer police force and two sheriff’s deputies took “everything we have,” Meyer said, and it wasn’t clear how the newspaper staff would take the weekly publication to press Tuesday night.</p>
<p>The raid followed news stories about a restaurant owner who kicked reporters out of a meeting last week with U.S. Rep. Jake LaTurner, and revelations about the restaurant owner’s lack of a driver’s license and conviction for drunken driving.</p>
<p>Meyer said he had never heard of police raiding a newspaper office during his 20 years at the Milwaukee Journal or 26 years teaching journalism at the University of Illinois.</p>
<p>“It’s going to have a chilling effect on us even tackling issues,” Meyer said, as well as “a chilling effect on people giving us information.”</p>
<p>The search warrant, signed by Marion County District Court Magistrate Judge Laura Viar, appears to violate <a target="_blank" href="https://www.law.cornell.edu/uscode/text/42/2000aa">federal law</a> that provides protections against searching and seizing materials from journalists. The law requires law enforcement to <a target="_blank" href="https://www.mcguirewoods.com/news-resources/publications/media.0101.pdf">subpoena materials instead</a>. Viar didn’t respond to a request to comment for this story or explain why she would authorize a potentially illegal raid.</p>
<p>Emily Bradbury, executive director of the Kansas Press Association, said the police raid is unprecedented in Kansas.</p>
<p>“An attack on a newspaper office through an illegal search is not just an infringement on the rights of journalists but an assault on the very foundation of democracy and the public’s right to know,” Bradbury said. “This cannot be allowed to stand.”</p>
<p>Meyer reported last week that Marion restaurant owner Kari Newell had kicked newspaper staff out of a public forum with LaTurner, whose staff was apologetic. Newell responded to Meyer’s reporting with hostile comments on her personal Facebook page.</p>
<p>A confidential source contacted the newspaper, Meyer said, and provided evidence that Newell had been convicted of drunken driving and continued to use her vehicle without a driver’s license. The criminal record could jeopardize her efforts to obtain a liquor license for her catering business.</p>
<p>A reporter with the Marion Record used a state website to verify the information provided by the source. But Meyer suspected the source was relaying information from Newell’s husband, who had filed for divorce. Meyer decided not to publish a story about the information, and he alerted police to the situation.</p>
<p>“We thought we were being set up,” Meyer said.</p>
<p>Police notified Newell, who then complained at a city council meeting that the newspaper had illegally obtained and disseminated sensitive documents, which isn’t true. Her public comments prompted the newspaper to set the record straight in a story published Thursday.</p>
<figure id="attachment_38546"><a href="https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2.jpg" target="_blank" data-slb-active="1" data-slb-asset="189978159" data-slb-internal="0" data-slb-group="38540"><img loading="lazy" src="https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2.jpg" alt="Marion County District Court Magistrate Judge Laura Viar signed a search warrant authorizing the police raid of the newspaper office." width="2400" height="1350" srcset="https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2.jpg 2400w, https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2-300x169.jpg 300w, https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2-1024x576.jpg 1024w, https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2-150x84.jpg 150w, https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2-768x432.jpg 768w, https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2-1536x864.jpg 1536w, https://kansasreflector.com/wp-content/uploads/2023/08/SearchWarrant2-2048x1152.jpg 2048w" sizes="(max-width: 2400px) 100vw, 2400px"></a><figcaption><i></i>  Marion County District Court Magistrate Judge Laura Viar signed a search warrant authorizing the police raid of the newspaper office. (Sam Bailey/Kansas Reflector)</figcaption></figure>
<p>Sometime before 11 a.m. Friday, officers showed up simultaneously at Meyer’s home and the newspaper office. They presented a search warrant that alleges identity theft and unlawful use of a computer.</p>
<p>The search warrant identifies two pages worth of items that law enforcement officers were allowed to seize, including computer software and hardware, digital communications, cellular networks, servers and hard drives, items with passwords, utility records, and all documents and records pertaining to Newell. The warrant specifically targeted ownership of computers capable of being used to “participate in the identity theft of Kari Newell.”</p>
<p>Officers injured a reporter’s finger by grabbing her cellphone out of her hand, Meyer said. Officers at his home took photos of his bank account information.</p>
<p>He said officers told him the computers, cellphones and other devices would be sent to a lab.</p>
<p>“I don’t know when they’ll get it back to us,” Meyer said. “They won’t tell us.”</p>
<p>The seized computers, server and backup hard drive include advertisements and legal notices that were supposed to appear in the next edition of the newspaper.</p>
<p>“I don’t know what we’re going to do,” he said. “We will publish something.”</p>
<p>Newell, writing Friday under a changed name on her personal Facebook account, said she “foolishly” received a DUI in 2008 and “knowingly operated a vehicle without a license out of necessity.”</p>
<p>“Journalists have become the dirty politicians of today, twisting narrative for bias agendas, full of muddied half-truths,” Newell wrote. “We rarely get facts that aren’t baited with misleading insinuations.”</p>
<p>She said the “entire debacle was brought forth in an attempt to smear my name, jeopardize my licensing through ABC (state Alcoholic Beverage Control Division), harm my business, seek retaliation, and for personal leverage in an ongoing domestic court battle.”</p>
<p>At the law enforcement center in Marion, a staff member said only Police Chief Gideon Cody could answer questions for this story, and that Cody had gone home for the day and could not be reached by phone. The office of Attorney General Kris Kobach wasn’t available to comment on the legal controversy in Marion, which is north of Wichita in central Kansas.</p>
<p>Melissa Underwood, communications director of the Kansas Bureau of Investigation, replied by email to a question about whether the KBI was involved in the case.</p>
<p>“At the request of the Marion Police Department, on Tuesday, Aug. 8, we began an investigation into allegations of criminal wrongdoing in Marion, Kansas. The investigation is ongoing,” Underwood said.</p>
<p>Meyer, whose father worked at the newspaper from 1948 until he retired, bought the Marion County Record in 1998, preventing a sale to a corporate newspaper chain.</p>
<p>As a journalism professor in Illinois, Meyer said, he had graduate students from Egypt who talked about how people would come into the newspaper office and seize everything so they couldn’t publish. Those students presented a scholarly paper at a conference in Toronto about what it has done to journalism there.</p>
<p>“That’s basically what they’re trying to do here,” Meyer said. “The intervention is just like that repressive government of Egypt. I didn’t think it could happen in America.”</p>
                                </div><div>
                                        
                                        <p>Our stories may be republished online or in print under Creative Commons license CC BY-NC-ND 4.0. We ask that you edit only for style or to shorten, provide proper attribution and link to our web site. Please see our republishing guidelines for use of photos and graphics.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pijul: Version-Control Post-Git • Goto 2023 (109 pts)]]></title>
            <link>https://www.youtube.com/watch?v=7MpdZkGj5AI</link>
            <guid>37094599</guid>
            <pubDate>Fri, 11 Aug 2023 22:02:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=7MpdZkGj5AI">https://www.youtube.com/watch?v=7MpdZkGj5AI</a>, See on <a href="https://news.ycombinator.com/item?id=37094599">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[An Introduction to Graph Theory (147 pts)]]></title>
            <link>https://arxiv.org/abs/2308.04512</link>
            <guid>37094111</guid>
            <pubDate>Fri, 11 Aug 2023 21:13:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2308.04512">https://arxiv.org/abs/2308.04512</a>, See on <a href="https://news.ycombinator.com/item?id=37094111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="labstabs"><p>
    <label for="tabone">Bibliographic Tools</label></p><div>
      <h2>Bibliographic and Citation Tools</h2>
      <div>
          <p><label>
              
              <span></span>
              <span>Bibliographic Explorer Toggle</span>
            </label>
          </p>
          
        </div>
        
        
        
    </div>


    <p>
    <label for="tabtwo">Code, Data, Media</label></p><div>
      <h2>Code, Data and Media Associated with this Article</h2>
      
      
      
      
      
      
    </div>


      <p>
      <label for="labstabs-demos-input" id="labstabs-demos-label">Demos</label></p><div>
        <h2>Demos</h2>
        
        
        
      </div>
      <p>
      <label for="tabfour">Related Papers</label></p><div>
        <h2>Recommenders and Search Tools</h2>
        
        
        
        
        
        
      </div>

      <p>
      <label for="tabfive">
        About arXivLabs
      </label></p><div>
            <h2>arXivLabs: experimental projects with community collaborators</h2>
            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
            <p>Have an idea for a project that will add value for arXiv's community? <a href="https://info.arxiv.org/labs/index.html"><strong>Learn more about arXivLabs</strong></a>.</p>
          </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[80% of bosses say they regret earlier return-to-office plans (281 pts)]]></title>
            <link>https://www.cnbc.com/2023/08/11/80percent-of-bosses-say-they-regret-earlier-return-to-office-plans.html</link>
            <guid>37093854</guid>
            <pubDate>Fri, 11 Aug 2023 20:52:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/08/11/80percent-of-bosses-say-they-regret-earlier-return-to-office-plans.html">https://www.cnbc.com/2023/08/11/80percent-of-bosses-say-they-regret-earlier-return-to-office-plans.html</a>, See on <a href="https://news.ycombinator.com/item?id=37093854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="MakeItRegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-1" data-analytics="MakeItRegularArticle-articleBody-5-1"><div><p>After three years of haphazard plans for getting workers back at their desks, the return-to-office movement has entered a phase of remorse.&nbsp;</p><p>A whopping 80% of bosses regret their initial return-to-office decisions and say they would have approached their plans differently if they had a better understanding of what their employees wanted, according to <a href="https://envoy.com/content/datareport/" target="_blank">new research</a> from Envoy.&nbsp;</p><p>"Many companies are realizing they could have been a lot more measured in their approach, rather than making big, bold, very controversial decisions based on executives' opinions rather than employee data," Larry Gadea, Envoy's CEO and founder, tells <a href="https://www.cnbc.com/make-it/">CNBC Make It</a>.&nbsp;</p><p>Envoy interviewed more than 1,000 U.S. company executives and workplace managers who work in-person at least one day per week.&nbsp;</p><p>Some leaders lamented the challenge of measuring the success of in-office policies, while others said it's been hard to make long-term real estate investments without knowing how employees might feel about being in the office weeks, or even months, from now.&nbsp;</p><p>Kathy Kacher, a consultant who advises corporate executives on their return-to-office plans, is surprised the percentage isn't higher.&nbsp;</p><p>"Many organizations that attempted to force a return to the office have had to retract or change their plans because of employee pushback, and now, they don't look strong," says Kacher, the president of Career/Life Alliance Services. "A lot of executives have egg on their faces and they're sad about that."</p></div><h2><a id="headline0"></a>The 'great resignation' to the 'great regret'</h2><div><p>As some business leaders accept hybrid work as a permanent reality, others are <a href="https://www.cnbc.com/2023/03/30/more-companies-could-increase-rto-requirements-soon.html">backtracking on earlier pledges</a> to let employees work from home on a full or part-time basis.&nbsp;</p><p>As of July, 59% of full-time employees are back to being 100% on-site, while 29% are in a hybrid arrangement and 12% are completely remote, according to <a href="https://wfhresearch.com/wp-content/uploads/2023/08/WFHResearch_updates_August2023.pdf" target="_blank">new data</a> from WFH Research. Offices are still only <a href="https://www.kastle.com/safety-wellness/getting-america-back-to-work/" target="_blank">half full </a>compared to their pre-pandemic occupancy.</p><p>Across industries, major corporations including <a href="https://www.cnbc.com/2023/01/09/disney-ceo-bob-iger-tells-employees-to-return-to-the-office-four-days-a-week.html">Disney</a>, <a href="https://www.cnbc.com/2023/01/11/starbucks-orders-return-to-office.html">Starbucks</a> and <a href="https://www.cnbc.com/2023/06/08/belief-in-person-workers-will-advance-more-in-careers-keeps-rising.html">BlackRock</a> are requiring employees to spend more time at the office, with executives<strong> </strong>often citing the need for more in-person collaboration.</p><p>Zoom is the<a href="https://www.cnbc.com/video/2023/08/08/the-death-of-remote-work-zoom-orders-workers-to-return-to-office-at-least-twice-a-week.html"> latest to reverse course</a>, telling employees who live within a 50-mile radius of a Zoom office that they need to come in at least twice a week.</p><p>It's an abrupt shift from the company's previous policy, which allowed employees to choose between hybrid, in-person or permanent remote work.&nbsp;</p><p>"We believe that a structured hybrid approach — meaning employees that live near an office need to be onsite two days a week to interact with their teams — is most effective for Zoom," a company spokesperson said in a statement to CNBC Make It, adding that the company will "continue to leverage the entire Zoom platform to keep our employees and dispersed teams connected and working efficiently" and&nbsp; "hire the best talent, regardless of location."</p><p>The sunk cost of unused office space has been a major factor in companies' decisions to change their RTO approach, says Kacher.&nbsp;</p><p>Even six months ago, companies were willing to eat these costs in a tight labor market to recruit and retain talent. But now, "Some companies are getting impatient, and want to recoup these large investments," Kacher explains.</p><p>In New York City, office space costs, on average, about $16,000 a year per employee, <a href="https://www.nytimes.com/2022/11/17/business/office-buildings-real-estate-vacancy.html" target="_blank">the New York Times </a>reports.</p><p>Yet the constant risk of losing top talent has been enough to make companies reconsider their strict RTO mandates. Research has shown that companies that put pressure on employees to return to the office are more likely to experience turnover issues than those that don't.&nbsp;</p><p>Companies that have mandated a strict return to the office three days a week without first seeking employee input are experiencing the most angst, Kacher adds.</p><p>"They're the ones struggling with retention and recruitment," she says. "Some of the companies I work with have even scaled back the number of in-office days they're requiring in response to employee backlash."</p></div><h2><a id="headline1"></a>Who's winning the return-to-office fight&nbsp;</h2><div><p>The companies that are seeing the most success with returning to the office appear to be the ones that are making decisions with their employees, rather than for them.&nbsp;</p><p>Take Ernst &amp; Young, for example.&nbsp;</p><p>The global accounting and consulting firm weathered some employee criticism for its initial return-to-office announcement in June 2021, when the firm told employees that they would be encouraged to spend 40-60% of their time in the office.&nbsp;</p><p>Their plan was put on pause through the end of the year as Covid-19 cases ticked up once again throughout the U.S., so EY leaders used that time to ask employees about their reluctance to come into the office.&nbsp;</p><p>Common threads stood out to Frank Giampietro, EY's chief wellbeing officer for the Americas: Employees weren't sure what to do about pet care or child care.</p><p>In response, EY announced a fund in February 2022 to reimburse up to $800 per year for commuting, pet care and dependent care costs for each of its 55,000-plus U.S. employees.</p><p>The fund, which is ongoing, had an immediate positive impact on employees' in-office attendance, Giampietro adds. Since EY first rolled out this benefit in February 2022, EY has seen a 150% uptick in office attendance across the U.S.</p><p>"It didn't take a complete rehaul of our return-to-office policies to make employees happy," he says. "We just needed to listen to our people and understand what, specifically, was problematic for them, and offer resources to address that."</p><p>Kacher anticipates that it will take at least another year or two before companies settle into an office routine that employees are content with and bosses don't regret.&nbsp;</p><p>"Some organizations are still in denial that people aren't coming back to the office, and some have moved into the acceptance phase, where they're ready to think more creatively or differently," she says. "But it'll take time for all of us to get there together."</p><p><em><strong>Want to be smarter and more successful with your money, work &amp; life?&nbsp;</strong></em><a href="https://www.cnbc.com/makeitnewsletter/"><em><strong>Sign up for our newsletter</strong></em></a><em><strong>!</strong></em></p><p><em>Get CNBC's free&nbsp;</em><a href="https://www.cnbc.com/buffett-whitepaper/">Warren Buffett Guide to Investing</a><em>, which distills the billionaire's No. 1 best piece of advice for regular investors, do's and don'ts, and three key investing principles into a clear and simple guidebook.</em></p><p><em><strong>Check out:</strong></em></p><p><a href="https://www.cnbc.com/2023/08/09/forget-quiet-quitting-loud-laborers-are-killing-workplace-morale.html"><em><strong>Forget 'quiet quitting' — 'loud laborers' are killing workplace morale. Here's how to spot them</strong></em></a></p></div><div id="Placeholder-ArticleBody-Video-107277424" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000311414" aria-labelledby="Placeholder-ArticleBody-Video-107277424"><p><img src="https://image.cnbcfm.com/api/v1/image/107283421-Van-Leeuwen-still-01.png?v=1691682181&amp;w=750&amp;h=422&amp;vtcrop=y" alt="How I built Van Leeuwen into a multi-million dollar ice cream empire"><span></span><span><span data-test="PlayButton"></span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Environment Integrity has no standing at W3C; understanding new W3C work (203 pts)]]></title>
            <link>https://www.w3.org/blog/2023/web-environment-integrity-has-no-standing-at-w3c/</link>
            <guid>37093632</guid>
            <pubDate>Fri, 11 Aug 2023 20:30:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.w3.org/blog/2023/web-environment-integrity-has-no-standing-at-w3c/">https://www.w3.org/blog/2023/web-environment-integrity-has-no-standing-at-w3c/</a>, See on <a href="https://news.ycombinator.com/item?id=37093632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
		<article>
			
							
			
			
							<section>
					
					<dl>
													<dt>By:
</dt>
							<dd>
								<ul role="presentation">
																		<li>
										<p>
											<span>
																									<img alt="" src="https://www.w3.org/avatars/9910666fe2f7cca4c4567165eefef556/?s=48" loading="lazy">
																							</span>
											Philippe Le Hégaret
										</p>
									</li>
																	</ul>
							</dd>
																			<dt>Published:
</dt>
																					<dd>
								<time datetime="2023-08-11T19:54:00+00:00" title="11 August 2023 at 19:54:00">
									11 August 2023
								</time>
							</dd>
											</dl>
									</section>
																					    <div>
                <p>For a few weeks now we have been hearing concern in the Web community in regard to <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity">Web Environment Integrity</a>, and are asked more and more about it. Our silence is due to the fact that the Web Environment Integrity API is not being worked on in W3C, nor has there been any submission to W3C for <a href="https://www.w3.org/groups/other/tag/">W3C Technical Architecture Group</a> (TAG) review.</p><p>In the rest of this article, I want to take the opportunity to explain generally <a href="https://www.w3.org/standards/about/#funnel">how new work is brought</a> to the World Wide Web Consortium, and how several W3C work groups coordinate what we call "<a href="https://www.w3.org/Guide/documentreview/#how_to_get_horizontal_review">horizontal review</a>". This review and other safeguards we have in place, transcends a particular technology by focusing on aspects that impact people and the Web: Web accessibility, architecture, internationalization, privacy, and security.</p><h2>Bringing new work to W3C</h2><p>Candidate W3C work arises from <a href="https://www.w3.org/Consortium/Process/#GAEvents">W3C Workshops</a> or <a href="https://www.w3.org/Submission/">Member Submissions</a>, or tracking the activity in public <a href="https://www.w3.org/community/groups/">W3C Community Groups</a>. New work starts at W3C by <a href="https://www.w3.org/Consortium/Process/#WGCharterDevelopment">initiating new working groups</a> based on interest from W3C Members and Team, or landing in <a href="https://www.w3.org/groups/">existing working groups</a> (in which case, the groups' charters are updated.) New charters and revised charters both require Member consensus.</p><h2>Passing W3C "horizontal review"</h2><p>The W3C Process Document enshrines <a href="https://www.w3.org/Consortium/Process/#doc-reviews">"horizontal review" as a requirement</a>. For a new working group, the review is done internally before any proposed charter is brought to W3C Members for approval. For new technology or specifications, the review must be done as part of publication on the W3C Recommendation track (i.e., the progression stages from an idea to a Web Standard.)</p>
        </div>

											    <figure>
    <blockquote>
        <p>
                        "The objective is to ensure that the entire set of stakeholders of the Web community, including the general public, have had adequate notice of the progress of the Working Group and were able to actually perform reviews of and provide comments on the specification. A second objective is to encourage groups to request reviews early enough that comments and suggested changes can still be reasonably incorporated in response to the review."
                </p>
    </blockquote>
            <figcaption>Excerpt from the requirement for wide review (Section 6.2.2.1, W3C Process)</figcaption>
    </figure>

											    <div>
                <h2>Self-review for Web platform designers</h2><p>As a starting point and as part of web developer advocacy, most W3C horizontal review groups have created guides and self-review documents so that key aspects can be resolved autonomously:</p><ul><li>The Technical Architecture Group exists to help ensure that the Web makes sense as a platform, and that the design is coherent. Among the criteria of any<a href="https://tag.w3.org/workmode/"> TAG review</a> is evaluation against the <a href="https://www.w3.org/TR/design-principles/">Design Principles</a> (which includes the priority of constituencies), the <a href="https://www.w3.org/TR/privacy-principles/">Privacy Principles</a>, and the <a href="https://www.w3.org/TR/ethical-web-principles/">Ethical Web Principles</a>.</li><li>The Framework for Accessibility in the Specification of Technologies (<a href="https://w3c.github.io/apa/fast/checklist.html">FAST</a>) explains by types of features how to ensure that a technology is accessible to users with disabilities.</li><li>A <a href="https://w3c.github.io/i18n-drafts/techniques/shortchecklist">short i18n review</a> flags areas to pay particular attention to in the Internationalization (i18n) quality approach taken early to avoid costly and sometimes prohibitive obstacles when rolling out products or a technology to meet the needs of people in different cultures, or who use different languages or writing systems.</li><li>The <a href="https://www.w3.org/TR/security-privacy-questionnaire/">Security and Privacy self-review questionnaire</a> helps specification authors as they think through the security and privacy implications of their work designing new features for the Web platform.</li></ul><h2>From an idea to a Web standard</h2><p>If there is interest in describing more the various steps new work takes at W3C, we can start a series of articles. In the meantime, I thought I would leave you with a final note on how any specification becomes a "standard" in W3C: it needs to show multiple, interoperable <a href="https://www.w3.org/Consortium/Process/#implementation-experience">implementations</a>.</p><p>Let us know if you have questions or what you would like to hear more about.</p>
        </div>

																												</article>
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Bankman-Fried Sent Back to Jail After Leaking Diary of Ex-Lover (243 pts)]]></title>
            <link>https://themessenger.com/business/sbf-thrown-in-jail-for-tampering-with-star-witness-in-upcoming-fraud-trial</link>
            <guid>37093163</guid>
            <pubDate>Fri, 11 Aug 2023 19:50:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://themessenger.com/business/sbf-thrown-in-jail-for-tampering-with-star-witness-in-upcoming-fraud-trial">https://themessenger.com/business/sbf-thrown-in-jail-for-tampering-with-star-witness-in-upcoming-fraud-trial</a>, See on <a href="https://news.ycombinator.com/item?id=37093163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>FTX founder Sam Bankman-Fried is <a href="https://cms.themessenger.com/news/feds-seek-to-revoke-sam-bankman-frieds-bond-after-prosecutors-say-he-leaked-ex-girlfriends-letters" target="_blank" rel="noreferrer noopener">being thrown in jail</a> pending his upcoming trial on fraud charges after a federal judge concluded Friday his <a href="https://themessenger.com/news/sam-bankman-fried-faces-federal-judge-over-allegations-he-leaked-his-ex-girlfriends-letters" target="_blank" rel="noreferrer noopener">airing of private musings </a>from a key prosecution cooperator amounted to witness intimidation and jury tampering.</p><p>"Witness tampering and obstruction poses a danger to community and risk of such activities would support pretrial detention," U.S. District Judge Lewis Kaplan said at the bail violation hearing. While Bankman-Fried had a First Amendment right to proclaim his innocence, the judge said, free speech protections do not cover communications intended to intimidate or tamper with witnesses, a felony.</p><div><p>Bankman-Fried was immediately taken into custody in the courtroom by U.S. marshals following the ruling. He removed his shoelaces, tie and jacket and handed them to his defense lawyer before being escorted from the courtroom. His lawyers asked the judge to suspend the ruling pending appeal,  but their request was denied. They declined comment as they left court. </p><p>The one-time Crypto King, Bankman-Fried had previously been allowed to remain free pending trial, confined to home detention at his parents' house in Palo Alto, California on $250 million bond. The trial is scheduled to begin in October and expected to last at least a month.</p><p><a href="https://themessenger.com/news/feds-seek-to-revoke-sam-bankman-frieds-bond-after-prosecutors-say-he-leaked-ex-girlfriends-letters" target="_blank" rel="noreferrer noopener">The personal notes by Caroline Ellison</a>, his ex-girlfriend and the chief executive of Alameda Research, a hedge fund affiliated with FTX that traded on the crypto exchange, were written in the months before it collapsed last fall. They described how her fizzled romantic relationship with Bankman-Fried left her unhappy and disengaged from her job. They were featured in an article in July in The New York Times. </p><p>Kaplan said he found the writings "extremely personal and intimate" and that they  "portrayed Ms. Ellison in an unfavorable light." By leaking them, he concluded, Bankman-Fried "intended at least in part to harass Ellison and influence her testimony."</p></div><p>Ellison pleaded guilty in December to charges stemming from her role in FTX’s collapse. She has agreed to testify against Bankman-Fried during his trial in a bid for a more lenient sentence, and prosecutors have said in court filings that she is an important witness for their case.</p><figure><p><span><img alt="Caroline Ellison, former CEO of Alameda Research" sizes="100vw" srcset="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=640&amp;q=75 640w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=750&amp;q=75 750w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=828&amp;q=75 828w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=1080&amp;q=75 1080w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=1200&amp;q=75 1200w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=1920&amp;q=75 1920w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=2048&amp;q=75 2048w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=3840&amp;q=75 3840w" src="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><span>Caroline Ellison, former CEO of Alameda Research and the star witness at the U.S. trial against Sam Bankman-Fried.</span><span>Caroline Ellison/Twitter/X</span></figcaption></figure><div><p>Lawyers for Bankman-Fried did not deny that he shared the writings with the Times, but maintain he had a right to do so and that the article was already in progress and informed by other sources. Mark Cohen, Bankman-Fried's attorney, said during the hearing that prosecutors lacked evidence of intent to   intimidate Ellison, and said their claim was based on a "thin record with a lot of spin." </p><p>After the writings appeared in the Times, Kaplan signed a gag order barring Bankman-Fried from speaking to the news media. But prosecutors sought the additional step of having Bankman-Fried jailed pending his trial, saying his sharing of Ellison’s musings amounted to intimidating a witness and tampering with the jury pool. Prosecutor Danielle Sassoon said his actions amounted to a "deliberate evasion of his bail conditions." </p><p>In court filings, prosecutors have noted Bankman-Fried was already warned by the judge for contacting a different prosecution witness on an encrypted messaging service early in the case and saying he hoped they could have a “constructive relationship.” During the hearing, Kaplan also concluded that the earlier contact amounted to an attempt to influence a witness. </p><p>FTX imploded amid disclosures that Alameda had borrowed $10 billion in customer funds on deposit at FTX and used the money to back high-risk trading positions that ultimately turned against it. FTX filed for bankruptcy in November and Bankman-Fried resigned as chief executive.</p><p>Prosecutors accuse Bankman-Fried, 31, of cheating investors and stealing deposits from customers of FTX, one of the world’s largest cryptocurrency exchanges before its collapse in November. He is accused of squandering the money backing the risky trades placed by Alameda, as well as on political contributions and a lavish lifestyle.</p><p>Bankman-Fried has been in prolific contact with journalists covering the collapse of FTX and his criminal case, according to court filings. Over a period of serval months, he logged more than 1,000 calls with reporters, and has also been in frequent contact with the author Michael Lewis, who is writing a book about the matter.</p><p>It was not immediately clear where Bankman-Fried would be held in custody pending trial. Prosecutors said they had looked into arrangements with the Putnam County jail in upstate New York where he would have better access to trial preparation materials via computer, but Judge Kaplan said he believed there would be similar access at the federal jail in Brooklyn. The issue was not resolved during the hearing. Kaplan noted the Brooklyn lock-up is "not on anybody's list of five-star facilities."</p></div><figure><p><span><img alt="Sam Bankman-Fried, Caroline Ellison" sizes="100vw" srcset="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=640&amp;q=75 640w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=750&amp;q=75 750w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=828&amp;q=75 828w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=1080&amp;q=75 1080w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=1200&amp;q=75 1200w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=1920&amp;q=75 1920w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=2048&amp;q=75 2048w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=3840&amp;q=75 3840w" src="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><span>Sam Bankman-Fried is going back to jail after leaking former girlfriend Caroline Ellison's personal diary pages to the New York Times.</span><span>Michael M. Santiago/Getty Images; Caroline Ellison/Twitter</span></figcaption></figure></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge to revoke bail for FTX founder Sam Bankman-Fried over witness tampering (411 pts)]]></title>
            <link>https://www.cnbc.com/2023/08/11/judge-to-revoke-bail-for-ftx-founder-sam-bankman-fried-over-witness-tampering.html</link>
            <guid>37092861</guid>
            <pubDate>Fri, 11 Aug 2023 19:28:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/08/11/judge-to-revoke-bail-for-ftx-founder-sam-bankman-fried-over-witness-tampering.html">https://www.cnbc.com/2023/08/11/judge-to-revoke-bail-for-ftx-founder-sam-bankman-fried-over-witness-tampering.html</a>, See on <a href="https://news.ycombinator.com/item?id=37092861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Sam Bankman-Fried will head to jail on Friday after a judge sided with a request by federal prosecutors to revoke the FTX founder's bail over alleged witness tampering. Bankman-Fried was remanded to custody directly from a court hearing in New York. </p><p>Judge Lewis Kaplan denied Bankman-Fried's request for delayed detention pending an appeal. Unless the appeal is successful, he is expected to remain in custody until his criminal trial, which is due to begin on Oct. 2.</p><p>"My conclusion is there is probable cause to believe the defendant tried to tamper with witnesses at least twice," said Judge Kaplan during his ruling.</p><p>As the court marshals took Bankman-Fried into custody at the end of the hearing, the defendant took off his blazer, tie, emptied his pockets, and appeared to remove his shoes. Bankman-Fried's parents were both in the gallery. His mother had her face buried in her hands for much of Judge Kaplan's lengthy ruling.</p><p>The government requested that Bankman-Fried be remanded to a jail in Putnam, New York, where he'd have access to a laptop with internet access for defense preparation, as opposed to sending him to Brooklyn's Metropolitan Detention Center, the facility closest to the courthouse that has limited internet access for prisoners. </p><p>Since his <a href="https://www.cnbc.com/2022/12/12/ftx-founder-sam-bankman-fried-arrested-in-the-bahamas-after-us-files-criminal-charges.html">arrest in December</a>, Bankman-Fried had been out on a <a href="https://www.cnbc.com/2022/12/22/ftx-founder-sam-bankman-fried-to-be-released-on-250-million-bail.html">$250 million bail package</a> which requires him to remain at his parents' Palo Alto, California house.</p><p>Bankman-Fried's court appearance on Friday is the latest in a series of pre-trial hearings related to the ex-billionaire's continued dealings with the press – exchanges which the Justice Department characterizes as a "pattern of witness tampering and evading his bail conditions."&nbsp;</p><p>Judge Kaplan previously issued a direct and stern warning to Bankman-Fried in July over his conversations with the media.</p><p>Members of the press, including counsel for The New York Times and the Reporters Committee for Freedom of the Press, had filed letters objecting to Bankman-Fried's detention, citing free speech concerns. Defense attorneys had similarly argued that Bankman-Fried was asserting his first amendment right and did not violate any terms of his bail conditions by speaking with journalists.</p><p>The defense had also been hoping that the discovery process would help Bankman-Fried's case.</p><p>Lawyers representing the former FTX chief stipulated that with Bankman-Fried jailed, he would not be able to properly prepare for his trial due to the mountainous amounts of discovery documents only accessible via a computer with internet access.</p><p>In the motion requesting Bankman-Fried's detention, the government said that, over the last several months, the defendant had sent over 100 emails to the media and had made over 1,000 phone calls to members of the press. The final straw, according to prosecutors, was Bankman-Fried leaking private diary entries of his ex-girlfriend, Caroline Ellison, to the New York Times.&nbsp;<a href="https://www.cnbc.com/2022/12/22/ftxs-gary-wang-alamedas-caroline-ellison-plead-guilty-to-federal-charges-cooperating-with-prosecutors.html">Ellison pleaded guilty</a> to federal charges in Dec. 2022.</p><p>Ellison, who is also the former chief executive of Bankman-Fried's failed crypto hedge fund, Alameda Research, has been cooperating with the government since December and is expected to be a star witness for the prosecution.&nbsp;</p><p>During his 33-minute ruling, Judge Kaplan walked through his rationale as to why probable cause for witness tampering had been met by the prosecution, adding that Bankman-Fried's contribution to the Ellison story was designed to "hurt" and "discredit" a witness.</p><p>"Faced with a series of conditions meant to limit the defendant's use of the internet and the phone, the defendant pivoted to in-person machinations," the prosecution said of Bankman-Fried, whose revised bail conditions include restricted internet access and a ban from smartphone use.&nbsp;</p><p>The government added that Bankman-Fried had over 100 phone calls with one of the authors of the Times story prior to publication – many of which lasted for approximately 20 minutes.&nbsp;</p><p>The prosecution described the effort by Bankman-Fried – who faces several wire and securities fraud charges related to the alleged multibillion-dollar FTX fraud – as an attempt to discredit Ellison, characterizing it as a "means of indirect witness intimidation through the press."&nbsp;</p><p>It is an argument that proved sufficient to convince Judge Kaplan to send Bankman-Fried to jail ahead of his trial.</p><p><a href="https://www.cnbc.com/2023/07/27/prosecutors-drop-another-charge-against-ftxs-sam-bankman-fried.html">The prosecution has had to cull charges twice</a> to comply with an extradition agreement inked with The Bahamas – where Bankman-Fried was previously held in custody. The government told the Judge in a letter that next week it plans to file a new superseding indictment.</p><p><em><strong>This story is developing. Please check back for updates.</strong></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wendelstein 7-X: Gigajoule energy turnover generated for eight minutes (387 pts)]]></title>
            <link>https://www.ipp.mpg.de/5322229/01_23</link>
            <guid>37092212</guid>
            <pubDate>Fri, 11 Aug 2023 18:36:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ipp.mpg.de/5322229/01_23">https://www.ipp.mpg.de/5322229/01_23</a>, See on <a href="https://news.ycombinator.com/item?id=37092212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  
  
  <p>After successful recommissioning in autumn 2022, the Greifswald nuclear fusion experiment has surpassed an important target.</p>
  

  

  <p><em>In 2023, an energy turnover of 1 gigajoule was targeted. Now the researchers have even achieved 1.3 gigajoules and a new record for discharge time on Wendelstein 7-X: the hot plasma could be maintained for eight minutes.</em></p>
  
  
<figure data-description="<em>Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world.</em>" data-picture="base64;<picture class="" data-iesrc="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--b0247d6c23f223b06f3aa20c0639626e3e49b5da" data-alt="Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world." data-class=""><source media="(max-width: 767px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--833b362de076d38ef744d026930908ba8f6b9df7 414w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--21a9553670cc621e6f6c955a6a10224d8433a189 375w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--42f026cc8ddbb4b28070b2b9e4519914ac68716a 320w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--6b5a92f7780bf49811ac40a746c08bc18d205ac9 411w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--b112792b348543ab5a71df61f43a9a705fe802ed 480w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--9deda45ffcce0563811fb15a830b5cafdff119f9 360w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--3f63153b9156f71644d4fe9af773cbf0e48a3f07 828w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--9f77c287612452bc53e2369b134ef8a6f06a843c 750w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--eb0e323986e3afe14247750b01861d6d1feb4398 640w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--51544e8cc80e8b270ccfd0eb1cc0d15b7cd152bc 822w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--ea2b2d353aef8059b450f955b16099d6bfa5a1a1 960w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--31ef326529acf99383b1465626d6a840330b2572 720w" sizes="100vw" type="image/webp" /><source media="(max-width: 767px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--0c88268b1ba34a6ec7ac230b37a73d2ebae83ca5 414w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--2e09626286e215ccad3f7358ca6a6d53143537df 375w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--4d566f90bedff8d19f9957103ebfaec944a97e11 320w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--b165242f0e35cc405e6a31ae7acfec01ce746864 411w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--b863c098cc9dac243aa2a1b39b17f0d36d7e7ecb 480w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--278d77702d45da284772344b32be9fad62b4e1bd 360w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--af81490a3e49a1290d65b4a6e3959ac85f34d29f 828w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--527fac808e98d2f911820aab93189c65f5370174 750w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--ae5945ec6fefb574515c9a42cbb2edffd6043c39 640w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--d9d354ede1d12e4b3326fb277974396dd5e26bf5 822w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--f46033176fd61d502403147a4326f409a428fa0b 960w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--62122e4c9bd0d7cd880b66abacdd316a82b2854e 720w" sizes="100vw" type="image/jpeg" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--99255bfb2a6cf75876d95df1465aba247ba5a30a 900w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIyMTM5fQ%3D%3D--ad579a615cf1b31e4c6f5b83fa23f7b3e51baf70 1800w" sizes="900px" type="image/webp" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--8ab0f04077bbd1ea17639b5863728b1f42473e21 900w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--3a7be48997eb365d04b6edf485fa80bb8709b144 1800w" sizes="900px" type="image/jpeg" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMjEzOX0%3D--8bb18d72c4acbd9a269c43acde086b273b1b3b0f 1200w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIyMTM5fQ%3D%3D--bb43354f86e920dbad6a0650045742e43e2ec3c8 2400w" sizes="1200px" type="image/webp" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--bbecc64a7630d0a01e975cb8ea07aaaccef4189d 1200w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--4c05b1f5fdbbff38b5b7c7da244f16159d70db6b 2400w" sizes="1200px" type="image/jpeg" /><source media="(min-width: 1200px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMjEzOX0%3D--2e34224009713570c6763c13d33488e6302f94cf 1400w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIyMTM5fQ%3D%3D--bc8fa37afd1888b3ed7fd5d85b71822ef1880835 2800w" sizes="1400px" type="image/webp" /><source media="(min-width: 1200px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--b0247d6c23f223b06f3aa20c0639626e3e49b5da 1400w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--0b42d792eb5ee6354b3a4c8be4407eedc73622df 2800w" sizes="1400px" type="image/jpeg" /><img alt="Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world." class="" title="Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world." src="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--b0247d6c23f223b06f3aa20c0639626e3e49b5da" /></picture>">
      
      

    
</figure>

<p>During the three-year completion work that ended last summer, Wendelstein 7-X was primarily equipped with water cooling for the wall elements and an upgraded heating system. The latter can now couple twice as much power into the plasma as before. Since then, the nuclear fusion experiment can be operated in new parameter ranges. "We are now exploring our way towards ever higher energy values," explained Prof. Dr. Thomas Klinger, head of the Stellarator Transport and Dynamics Division at the Max Planck Institute for Plasma Physics (IPP) in Greifswald. "In doing so, we have to proceed step by step so as not to overload and damage the facility."</p><p>On 15 February 2023, the researchers reached a new milestone: for the first time, they were able to achieve an energy turnover of 1.3 gigajoules in this device. This was 17 times higher than the best value achieved before the conversion (75 megajoules). The energy turnover results from the coupled heating power multiplied by the duration of the discharge. Only if it is possible to couple large amounts of energy continuously into the plasma and also remove the resulting heat, a power plant operation is possible.</p>
<figure data-description="<em>Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius.</em>" data-picture="base64;<picture class="" data-iesrc="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c0bc07b445deab3742505837d26da3d00e024d62" data-alt="Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius." data-class=""><source media="(max-width: 767px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--11f2e06fd9a085fe2aefe781627b42aa76c10f07 414w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--f3d29d934d79b8a370fa47d91a6056dd4da40dc4 375w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--557e81f93ea47c1c4403a32f0737d390b12505ad 320w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--d2a3c28a74403cab515d8557c0cc1d6bbf77ae5a 411w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--52b4f2cc362eb72823f26d139e930644d5ceb5f8 480w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--7eef544d9263ae64c64645af101c53fb5ee3c227 360w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--3068217804b9061157424dcf3b1111aea5464f83 828w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--d801fafb99755b440c62fbadca03cf4e65383dd9 750w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--632c5d0c720159fbc558f5b4cb74dc8fa7eb23e1 640w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--02d8ceea94e2e51e65ba2ceaaa004ffb79071243 822w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--f993bddb58a1cfec29b948bb305a6717f2313a7b 960w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--fb06e9af5ae197b83781fd5132943f688b7abe41 720w" sizes="100vw" type="image/webp" /><source media="(max-width: 767px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--9b50aed8c8b831b6514c1ce4a4e6dee89b8a660e 414w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--ce360e45b2a9b6dcc7378ca943def962975da94d 375w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--fee4b7854529d4bf6a0b2bceab4e44d1440b99e2 320w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--61e87750903b5a1e85511a850c3ac2c4135abcc6 411w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--07f1a24c7d3e459017fce2c670592d1e57ec4678 480w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--3f72497b9c3dd152de831979129d4311dd450a3a 360w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--f99b9436477eeaa8e8c86479ee11b2238f25e46e 828w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--a46a64e2b67059b6a1bdb51f9899162fcf3611b2 750w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--c3fea48347b9518f89b37aba8e644ecc125ee3ad 640w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--75ee5c0a058ea0ee6fa83c5487b6918dac57a7e9 822w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--1ca8abb813b68f93eb2dd7d63df42a8bfcb0cd92 960w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--2e77b89c30b6652271a70d574efd8e578457084d 720w" sizes="100vw" type="image/jpeg" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--33b448b21da5ce24459699cc5665affa2ba49c7d 900w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIzMTUzfQ%3D%3D--25ffa139b6b1f6ed7c0ab1a3e40545666d41583e 1800w" sizes="900px" type="image/webp" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--55def98633d17e2f3cc8b003c9496030fe47981e 900w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--dc59f175373535e2f2ff5bab14ac5d1d6392a00c 1800w" sizes="900px" type="image/jpeg" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMzE1M30%3D--bf85bf540587ba20be56e104367cfb575b34425f 1200w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIzMTUzfQ%3D%3D--8e4da926c339cb2b1580b2ebd9903e124af99741 2400w" sizes="1200px" type="image/webp" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--6d82a2bc2ce8706ab983b139d15a6bd74f550fd7 1200w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--4ee520281e1f92906f77e503d3fcebd90f4b5242 2400w" sizes="1200px" type="image/jpeg" /><source media="(min-width: 1200px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMzE1M30%3D--7875e667dfd2d7da0226fb641cd30af46f3d76c6 1400w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIzMTUzfQ%3D%3D--f83ac6afe616bb79e9a7c9d862e16a34dd820905 2800w" sizes="1400px" type="image/webp" /><source media="(min-width: 1200px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c0bc07b445deab3742505837d26da3d00e024d62 1400w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c887e5330c861c004a63a582c4dab16b1bf32f1c 2800w" sizes="1400px" type="image/jpeg" /><img alt="Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius." class="" title="Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius." src="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c0bc07b445deab3742505837d26da3d00e024d62" /></picture>">
      
      

    
</figure>

<p><strong>The plasma discharge lasted eight minutes</strong><br>Particularly heat-resistant divertor baffle plates are used to dissipate the largest heat flows at Wendelstein 7-X. They are part of the inner wall, which is now cooled by a system of 6.8 kilometres of water pipes since the completion of the device. No other fusion facility in the world currently has such a comprehensively cooled inner wall. The plasma heating consists of three components: the newly installed ion heating, the heating by neutral particle injection and electron microwave heating. For the current record, the electron microwave heating system was particularly important because it delivers large amounts of power over periods of several minutes. The energy turnover of 1.3 gigajoule was achieved with an average heating power of 2.7 megawatts, whereby the discharge lasted 480 seconds. This is also a new record for Wendelstein 7-X and one of the best values worldwide. Before the completion works, Wendelstein 7-X achieved maximum plasma times of 100 seconds at much lower heating power.</p><p>Within a few years, the plan is to increase the energy turnover at Wendelstein 7-X to 18 gigajoules, with the plasma then being kept stable for half an hour.</p><p>&nbsp;<strong>Background to nuclear fusion</strong><br>The goal of fusion research is to develop a climate and environmentally friendly power plant. Similar to the sun, it is to generate energy from the fusion of atomic nuclei. The Max Planck Institute for Plasma Physics is pursuing the path of magnetic fusion. Because the fusion fire only ignites at temperatures above 100 million degrees, the fuel – a thin hydrogen plasma – must not come into contact with cold vessel walls. Held by magnetic fields, it floats almost contact-free inside a vacuum chamber. The magnetic cage of Wendelstein 7-X is created by a ring of 50 superconducting magnetic coils. It is a stellarator-type facility in which the special shapes of the coils are the result of sophisticated optimisation calculations. With the help of these coils, the quality of plasma confinement in a stellarator should reach the level of competing tokamak-type facilities<strong>.</strong></p>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RFC 9446 Reflections on Ten Years Past the Snowden Revelations (205 pts)]]></title>
            <link>https://www.rfc-editor.org/rfc/rfc9446.html</link>
            <guid>37091989</guid>
            <pubDate>Fri, 11 Aug 2023 18:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rfc-editor.org/rfc/rfc9446.html">https://www.rfc-editor.org/rfc/rfc9446.html</a>, See on <a href="https://news.ycombinator.com/item?id=37091989">Hacker News</a></p>
<div id="readability-page-1" class="page">

<table>
<thead><tr>
<td>RFC 9446</td>
<td>Ten Years After</td>
<td>July 2023</td>
</tr></thead>
<tfoot><tr>
<td>Farrell, et al.</td>
<td>Informational</td>
<td>[Page]</td>
</tr></tfoot>
</table>


<h2 id="rfcnum">RFC 9446</h2>

<section id="section-abstract">
      <h2 id="abstract"><a href="#abstract">Abstract</a></h2>
<p id="section-abstract-1">This memo contains the thoughts and recountings of events that
transpired during and after the release of information about the United States National Security Agency (NSA)
by Edward Snowden in 2013.  There are four perspectives: that of someone 
who was involved with sifting through the information to responsibly 
inform the public, that of a security area director of the IETF, that of a human 
rights expert, and that of a computer science and affiliate law professor. The purpose 
of this memo is to provide some historical perspective, while at the 
same time offering a view as to what security and privacy challenges 
the technical community should consider.  These essays do not represent a consensus view, but that of the individual authors.<a href="#section-abstract-1">¶</a></p>
</section>
<section id="status-of-memo">
        <h2 id="name-status-of-this-memo">
<a href="#name-status-of-this-memo">Status of This Memo</a>
        </h2>
<p id="section-boilerplate.1-1">
            This document is not an Internet Standards Track specification; it is
            published for informational purposes.<a href="#section-boilerplate.1-1">¶</a></p>
<p id="section-boilerplate.1-2">
            This is a contribution to the RFC Series, independently of any
            other RFC stream.  The RFC Editor has chosen to publish this
            document at its discretion and makes no statement about its value
            for implementation or deployment.  Documents approved for
            publication by the RFC Editor are not candidates for any level of
            Internet Standard; see Section 2 of RFC 7841.<a href="#section-boilerplate.1-2">¶</a></p>
<p id="section-boilerplate.1-3">
            Information about the current status of this document, any
            errata, and how to provide feedback on it may be obtained at
            <span><a href="https://www.rfc-editor.org/info/rfc9446">https://www.rfc-editor.org/info/rfc9446</a></span>.<a href="#section-boilerplate.1-3">¶</a></p>
</section>
<section id="copyright">
        <h2 id="name-copyright-notice">
<a href="#name-copyright-notice">Copyright Notice</a>
        </h2>
<p id="section-boilerplate.2-1">
            Copyright (c) 2023 IETF Trust and the persons identified as the
            document authors. All rights reserved.<a href="#section-boilerplate.2-1">¶</a></p>
<p id="section-boilerplate.2-2">
            This document is subject to BCP 78 and the IETF Trust's Legal
            Provisions Relating to IETF Documents
            (<span><a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a></span>) in effect on the date of
            publication of this document. Please review these documents
            carefully, as they describe your rights and restrictions with
            respect to this document.<a href="#section-boilerplate.2-2">¶</a></p>
</section>
<section id="toc">
        <a href="#" onclick="scroll(0,0)">▲</a><h2 id="name-table-of-contents">
<a href="#name-table-of-contents">Table of Contents</a>
        </h2>
<nav><ul>
<li id="section-toc.1-1.1">
            <p id="section-toc.1-1.1.1"><a href="#section-1">1</a>.&nbsp;&nbsp;<a href="#name-introduction">Introduction</a></p>
</li>
          <li id="section-toc.1-1.2">
            <p id="section-toc.1-1.2.1"><a href="#section-2">2</a>.&nbsp;&nbsp;<a href="#name-bruce-schneier-snowden-ten-">Bruce Schneier: Snowden Ten Years Later</a></p>
</li>
          <li id="section-toc.1-1.3">
            <p id="section-toc.1-1.3.1"><a href="#section-3">3</a>.&nbsp;&nbsp;<a href="#name-stephen-farrell-ietf-and-in">Stephen Farrell: IETF and Internet Technical Community Reaction</a></p>
</li>
          <li id="section-toc.1-1.4">
            <p id="section-toc.1-1.4.1"><a href="#section-4">4</a>.&nbsp;&nbsp;<a href="#name-farzaneh-badii-did-snowdens">Farzaneh Badii: Did Snowden's Revelations Help with Protecting Human Rights on the Internet?</a></p>
</li>
          <li id="section-toc.1-1.5">
            <p id="section-toc.1-1.5.1"><a href="#section-5">5</a>.&nbsp;&nbsp;<a href="#name-steven-m-bellovin-governmen">Steven M. Bellovin: Governments and Cryptography: The Crypto Wars</a></p>
<ul>
<li id="section-toc.1-1.5.2.1">
                <p id="section-toc.1-1.5.2.1.1"><a href="#section-5.1">5.1</a>.&nbsp;&nbsp;<a href="#name-historical-background">Historical Background</a></p>
</li>
              <li id="section-toc.1-1.5.2.2">
                <p id="section-toc.1-1.5.2.2.1"><a href="#section-5.2">5.2</a>.&nbsp;&nbsp;<a href="#name-the-crypto-wars-begin">The Crypto Wars Begin</a></p>
</li>
              <li id="section-toc.1-1.5.2.3">
                <p id="section-toc.1-1.5.2.3.1"><a href="#section-5.3">5.3</a>.&nbsp;&nbsp;<a href="#name-the-battle-is-joined">The Battle Is Joined</a></p>
</li>
              <li id="section-toc.1-1.5.2.4">
                <p id="section-toc.1-1.5.2.4.1"><a href="#section-5.4">5.4</a>.&nbsp;&nbsp;<a href="#name-the-hidden-battle">The Hidden Battle</a></p>
</li>
              <li id="section-toc.1-1.5.2.5">
                <p id="section-toc.1-1.5.2.5.1"><a href="#section-5.5">5.5</a>.&nbsp;&nbsp;<a href="#name-whither-the-ietf">Whither the IETF?</a></p>
</li>
            </ul>
</li>
          <li id="section-toc.1-1.6">
            <p id="section-toc.1-1.6.1"><a href="#section-6">6</a>.&nbsp;&nbsp;<a href="#name-security-considerations">Security Considerations</a></p>
</li>
          <li id="section-toc.1-1.7">
            <p id="section-toc.1-1.7.1"><a href="#section-7">7</a>.&nbsp;&nbsp;<a href="#name-iana-considerations">IANA Considerations</a></p>
</li>
          <li id="section-toc.1-1.8">
            <p id="section-toc.1-1.8.1"><a href="#section-8">8</a>.&nbsp;&nbsp;<a href="#name-informative-references">Informative References</a></p>
</li>
          <li id="section-toc.1-1.9">
            <p id="section-toc.1-1.9.1"><a href="#appendix-A"></a><a href="#name-acknowledgments">Acknowledgments</a></p>
</li>
          <li id="section-toc.1-1.10">
            <p id="section-toc.1-1.10.1"><a href="#appendix-B"></a><a href="#name-authors-addresses">Authors' Addresses</a></p>
</li>
        </ul>
</nav>
</section>
<section id="introduction">
      <h2 id="name-introduction">
<a href="#section-1">1. </a><a href="#name-introduction">Introduction</a>
      </h2>
<p id="section-1-1">On June 6th, 2013, an article appeared in <em>The Guardian</em> <span>[<a href="#Guard2013">Guard2013</a>]</span>
that was the beginning of a series of what have come to be known as
the Snowden revelations, describing certain activities of the United
States National Security Agency (NSA).  These activities included,
amongst others: secret court orders; secret agreements for the receipt
of so-called "meta-information" that includes source, destination, and
timing of communications; and tapping of communications lines.  The
breathtaking scope of the operations shocked the Internet technical
community and resulted in a sea change within the IETF, IAB,
and other standards organizations.<a href="#section-1-1">¶</a></p>
<p id="section-1-2">Now that some years have passed, it seems appropriate to reflect on that
period of time and to consider what effect the community's actions had,
where security has improved, how the threat surface has evolved, what
areas haven't improved, and where the community might invest future
efforts.<a href="#section-1-2">¶</a></p>
<p id="section-1-3">Bruce Schneier begins this compendium of individual essays by bringing
us back to 2013, recalling how it was for him and others to report
what was happening, and the mindset of those involved.  Next, Stephen
Farrell reviews the technical community's reactions and in particular
the reactions of the IETF community, technical advances, and where
threats remain.  Then Farzaneh Badii discusses the impact of those
advances -- or lack thereof -- on human rights.  Finally Steven
M. Bellovin puts the Snowden revelations into an ever-evolving
historical context of secrets and secret stealing that spans
centuries, closing with some suggestions for IETF.<a href="#section-1-3">¶</a></p>
<p id="section-1-4">Readers are invited to consider what impact we as a community have
had, what challenges remain, and what positive contribution the
technical community can and should make to address security and
privacy of citizens of the world.<a href="#section-1-4">¶</a></p>
<p id="section-1-5">-- Eliot Lear, Independent Submissions Editor for the RFC Series<a href="#section-1-5">¶</a></p>
</section>
<section id="bruce-schneier-snowden-ten-years-later">
      <h2 id="name-bruce-schneier-snowden-ten-">
<a href="#section-2">2. </a><a href="#name-bruce-schneier-snowden-ten-">Bruce Schneier: Snowden Ten Years Later</a>
      </h2>
<p id="section-2-1">In 2013 and 2014, I wrote extensively about new revelations regarding
NSA surveillance based on the documents provided by Edward
Snowden. But I had a more personal involvement as well.<a href="#section-2-1">¶</a></p>
<p id="section-2-2">I wrote the essay below in September 2013. <em>The New Yorker</em> agreed to
publish it, but <em>The Guardian</em> asked me not to. It was
scared of UK law enforcement and worried that this essay would
reflect badly on it. And given that the UK police would raid its
offices in July 2014, it had legitimate cause to be worried.<a href="#section-2-2">¶</a></p>
<p id="section-2-3">Now, ten years later, I offer this as a time capsule of what those
early months of Snowden were like.<a href="#section-2-3">¶</a></p>
<blockquote id="section-2-4">
        <p id="section-2-4.1">It's a surreal experience, paging through hundreds of top-secret NSA
documents. You're peering into a forbidden world: strange, confusing,
and fascinating all at the same time.<a href="#section-2-4.1">¶</a></p>
<p id="section-2-4.2">I had flown down to Rio de Janeiro in late August at the request of
Glenn Greenwald. He had been working on the Edward Snowden archive for
a couple of months, and had a pile of more technical documents that he
wanted help interpreting. According to Greenwald, Snowden also thought
that bringing me down was a good idea.<a href="#section-2-4.2">¶</a></p>
<p id="section-2-4.3">It made sense. I didn't know either of them, but I have been writing
about cryptography, security, and privacy for decades. I could
decipher some of the technical language that Greenwald had difficulty
with, and understand the context and importance of various
document. And I have long been publicly critical of the NSA's
eavesdropping capabilities. My knowledge and expertise could help
figure out which stories needed to be reported.<a href="#section-2-4.3">¶</a></p>
<p id="section-2-4.4">I thought about it a lot before agreeing. This was before David
Miranda, Greenwald's partner, was detained at Heathrow airport by the
UK authorities; but even without that, I knew there was a risk. I fly
a lot -- a quarter of a million miles per year -- and being put on a TSA
list, or being detained at the US border and having my electronics
confiscated, would be a major problem. So would the FBI breaking into my
home and seizing my personal electronics. But in the end, that made me
more determined to do it.<a href="#section-2-4.4">¶</a></p>
<p id="section-2-4.5">I did spend some time on the phone with the attorneys recommended to
me by the ACLU and the EFF. And I talked about it with my partner,
especially when Miranda was detained three days before my departure.
Both Greenwald and his employer, <em>The Guardian</em>, are careful about whom
they show the documents to. They publish only those portions essential
to getting the story out. It was important to them that I be a
co-author, not a source. I didn't follow the legal reasoning, but the
point is that <em>The Guardian</em> doesn't want to leak the documents to
random people. It will, however, write stories in the public interest,
and I would be allowed to review the documents as part of that
process. So after a Skype conversation with someone at <em>The Guardian</em>, I
signed a letter of engagement.<a href="#section-2-4.5">¶</a></p>
<p id="section-2-4.6">And then I flew to Brazil.<a href="#section-2-4.6">¶</a></p>
<p id="section-2-4.7">I saw only a tiny slice of the documents, and most of what I saw was
surprisingly banal. The concerns of the top-secret world are largely
tactical: system upgrades, operational problems owing to weather,
delays because of work backlogs, and so on. I paged through weekly
reports, presentation slides from status meetings, and general
briefings to educate visitors. Management is management, even inside
the NSA. Reading the documents, I felt as though I were sitting through
some of those endless meetings.<a href="#section-2-4.7">¶</a></p>
<p id="section-2-4.8">The meeting presenters try to spice things up. Presentations regularly
include intelligence success stories. There were details -- what had been
found, and how, and where it helped -- and sometimes there were attaboys
from "customers" who used the intelligence. I'm sure these are
intended to remind NSA employees that they're doing good. It
definitely had an effect on me. Those were all things I want the NSA
to be doing.<a href="#section-2-4.8">¶</a></p>
<p id="section-2-4.9">There were so many code names. Everything has one: every program,
every piece of equipment, every piece of software. Sometimes code
names had their own code names. The biggest secrets seem to be the
underlying real-world information: which particular company
MONEYROCKET is; what software vulnerability EGOTISTICALGIRAFFE -- really,
I am not making that one up -- is; how TURBINE works. Those secrets
collectively have a code name -- ECI, for exceptionally compartmented
information -- and almost never appear in the documents. Chatting with
Snowden on an encrypted IM connection, I joked that the NSA cafeteria
menu probably has code names for menu items. His response: "Trust me
when I say you have no idea."<a href="#section-2-4.9">¶</a></p>
<p id="section-2-4.10">Those code names all come with logos, most of them amateurish and a
lot of them dumb. Note to the NSA: take some of that more than
ten-billion-dollar annual budget and hire yourself a design
firm. Really; it'll pay off in morale.<a href="#section-2-4.10">¶</a></p>
<p id="section-2-4.11">Once in a while, though, I would see something that made me stop,
stand up, and pace around in circles. It wasn't that what I read was
particularly exciting, or important. It was just that it was
startling. It changed -- ever so slightly -- how I thought about the world.<a href="#section-2-4.11">¶</a></p>
<p id="section-2-4.12">Greenwald said that that reaction was normal when people started
reading through the documents.<a href="#section-2-4.12">¶</a></p>
<p id="section-2-4.13">Intelligence professionals talk about how disorienting it is living on
the inside. You read so much classified information about the world's
geopolitical events that you start seeing the world differently. You
become convinced that only the insiders know what's really going on,
because the news media is so often wrong. Your family is
ignorant. Your friends are ignorant. The world is ignorant. The only
thing keeping you from ignorance is that constant stream of classified
knowledge. It's hard not to feel superior, not to say things like "If
you only knew what we know" all the time. I can understand how General
Keith Alexander, the director of the NSA, comes across as so
supercilious; I only saw a minute fraction of that secret world, and I
started feeling it.<a href="#section-2-4.13">¶</a></p>
<p id="section-2-4.14">It turned out to be a terrible week to visit Greenwald, as he was
still dealing with the fallout from Miranda's detention. Two other
journalists, one from <em>The Nation</em> and the other from <em>The Hindu</em>, were
also in town working with him. A lot of my week involved Greenwald
rushing into my hotel room, giving me a thumb drive of new stuff to
look through, and rushing out again.<a href="#section-2-4.14">¶</a></p>
<p id="section-2-4.15">A technician from <em>The Guardian</em> got a search capability working while I
was there, and I spent some time with it. Question: when you're given
the capability to search through a database of NSA secrets, what's the
first thing you look for? Answer: your name.<a href="#section-2-4.15">¶</a></p>
<p id="section-2-4.16">It wasn't there. Neither were any of the algorithm names I knew, not
even algorithms I knew that the US government used.<a href="#section-2-4.16">¶</a></p>
<p id="section-2-4.17">I tried to talk to Greenwald about his own operational security. It
had been incredibly stupid for Miranda to be traveling with NSA
documents on the thumb drive. Transferring files electronically is
what encryption is for. I told Greenwald that he and Laura Poitras
should be sending large encrypted files of dummy documents back and
forth every day.<a href="#section-2-4.17">¶</a></p>
<p id="section-2-4.18">Once, at Greenwald's home, I walked into the backyard and looked for
TEMPEST receivers hiding in the trees. I didn't find any, but that
doesn't mean they weren't there. Greenwald has a lot of dogs, but I
don't think that would hinder professionals. I'm sure that a bunch of
major governments have a complete copy of everything Greenwald
has. Maybe the black bag teams bumped into each other in those early
weeks.<a href="#section-2-4.18">¶</a></p>
<p id="section-2-4.19">I started doubting my own security procedures. Reading about the NSA's
hacking abilities will do that to you. Can it break the encryption on
my hard drive? Probably not. Has the company that makes my encryption
software deliberately weakened the implementation for it?
Probably. Are NSA agents listening in on my calls back to the US? Very
probably. Could agents take control of my computer over the Internet
if they wanted to? Definitely. In the end, I decided to do my best and
stop worrying about it. It was the agency's documents, after all. And
what I was working on would become public in a few weeks.<a href="#section-2-4.19">¶</a></p>
<p id="section-2-4.20">I wasn't sleeping well, either. A lot of it was the sheer magnitude of
what I saw. It's not that any of it was a real surprise. Those of us
in the information security community had long assumed that the NSA
was doing things like this. But we never really sat down and figured
out the details, and to have the details confirmed made a big
difference. Maybe I can make it clearer with an analogy. Everyone
knows that death is inevitable; there's absolutely no surprise about
that. Yet it arrives as a surprise, because we spend most of our lives
refusing to think about it. The NSA documents were a bit like
that. Knowing that it is surely true that the NSA is eavesdropping on
the world, and doing it in such a methodical and robust manner, is
very different from coming face-to-face with the reality that it is
and the details of how it is doing it.<a href="#section-2-4.20">¶</a></p>
<p id="section-2-4.21">I also found it incredibly difficult to keep the secrets.
<em>The Guardian</em>'s process is slow and methodical. I move much faster. I
drafted stories based on what I found. Then I wrote essays about those
stories, and essays about the essays. Writing was therapy; I would
wake up in the wee hours of the morning, and write an essay. But that
put me at least three levels beyond what was published.<a href="#section-2-4.21">¶</a></p>
<p id="section-2-4.22">Now that my involvement is out, and my first essays are out, I feel a
lot better. I'm sure it will get worse again when I find another
monumental revelation; there are still more documents to go through.<a href="#section-2-4.22">¶</a></p>
<p id="section-2-4.23">I've heard it said that Snowden wants to damage America. I can say
with certainty that he does not. So far, everyone involved in this
incident has been incredibly careful about what is released to the
public. There are many documents that could be immensely harmful to
the US, and no one has any intention of releasing them. The documents
the reporters release are carefully redacted. Greenwald and I
repeatedly debated with <em>The Guardian</em> editors the newsworthiness of story
ideas, stressing that we would not expose government secrets simply
because they're interesting.<a href="#section-2-4.23">¶</a></p>
<p id="section-2-4.24">The NSA got incredibly lucky; this could have ended with a massive
public dump like Chelsea Manning's State Department cables. I suppose
it still could. Despite that, I can imagine how this feels to the NSA.
It's used to keeping this stuff behind multiple levels of security:
gates with alarms, armed guards, safe doors, and military-grade
cryptography. It's not supposed to be on a bunch of thumb drives in
Brazil, Germany, the UK, the US, and who knows where else, protected
largely by some random people's opinions about what should or should
not remain secret. This is easily the greatest intelligence failure in
the history of ever. It's amazing that one person could have had so
much access with so little accountability, and could sneak all of this
data out without raising any alarms. The odds are close to zero that
Snowden is the first person to do this; he's just the first person to
make public that he did. It's a testament to General Alexander's power
that he hasn't been forced to resign.<a href="#section-2-4.24">¶</a></p>
<p id="section-2-4.25">It's not that we weren't being careful about security, it's that our
standards of care are so different. From the NSA's point of view,
we're all major security risks, myself included. I was taking notes
about classified material, crumpling them up, and throwing them into
the wastebasket. I was printing documents marked "TOP
SECRET/COMINT/NOFORN" in a hotel lobby. And once, I took the wrong
thumb drive with me to dinner, accidentally leaving the unencrypted
one filled with top-secret documents in my hotel room. It was an
honest mistake; they were both blue.<a href="#section-2-4.25">¶</a></p>
<p id="section-2-4.26">If I were an NSA employee, the policy would be to fire me for that alone.<a href="#section-2-4.26">¶</a></p>
<p id="section-2-4.27">Many have written about how being under constant surveillance changes
a person. When you know you're being watched, you censor yourself. You
become less open, less spontaneous. You look at what you write on your
computer and dwell on what you've said on the telephone, wonder how it
would sound taken out of context, from the perspective of a
hypothetical observer. You're more likely to conform. You suppress
your individuality. Even though I have worked in privacy for decades,
and already knew a lot about the NSA and what it does, the change was
palpable. That feeling hasn't faded. I am now more careful about what
I say and write. I am less trusting of communications technology. I am
less trusting of the computer industry.<a href="#section-2-4.27">¶</a></p>
<p id="section-2-4.28">After much discussion, Greenwald and I agreed to write three stories
together to start. All of those are still in progress. In addition, I
wrote two commentaries on the Snowden documents that were recently
made public. There's a lot more to come; even Greenwald hasn't looked
through everything.<a href="#section-2-4.28">¶</a></p>
<p id="section-2-4.29">Since my trip to Brazil (one month before), I've flown back to the US
once and domestically seven times -- all without incident. I'm not on any
list yet. At least, none that I know about.<a href="#section-2-4.29">¶</a></p>
</blockquote>
<p id="section-2-5">As it happened, I didn't write much more with Greenwald or 
<em>The Guardian</em>. Those two had a falling out, and by the time everything
settled and both began writing about the documents
independently -- Greenwald at the newly formed website <em>The Intercept</em> -- I
got cut out of the process somehow. I remember hearing that Greenwald
was annoyed with me, but I never learned the reason. We haven't spoken
since.<a href="#section-2-5">¶</a></p>
<p id="section-2-6">Still, I was happy with the one story I was part of: how the NSA hacks
Tor. I consider it a personal success that I pushed <em>The Guardian</em> to
publish NSA documents detailing QUANTUM. I don't think that would have
gotten out any other way. And I still use those pages today when I
teach cybersecurity to policymakers at the Harvard Kennedy School.<a href="#section-2-6">¶</a></p>
<p id="section-2-7">Other people wrote about the Snowden files, and wrote a lot. It was a
slow trickle at first, and then a more consistent flow. Between
Greenwald, Bart Gellman, and <em>The Guardian</em> reporters, there ended up
being steady stream of news. (Bart brought in Ashkan Soltani to help
him with the technical aspects, which was a great move on his part,
even if it cost Ashkan a government job later.) More stories were
covered by other publications.<a href="#section-2-7">¶</a></p>
<p id="section-2-8">It started getting weird. Both Greenwald and Gellman held documents
back so they could publish them in their books. Jake Appelbaum, who
had not yet been accused of sexual assault by multiple women, was
working with Poitras. He partnered with <em>Der Spiegel</em> to release an implant
catalog from the NSA's Tailored Access Operations group. To this day,
I am convinced that the document was not in the Snowden archives:
that Jake got it somehow, and it was released with the implication
that it was from Edward Snowden. I thought it was important enough
that I started writing about each item in that document in my blog:
"NSA Exploit of the Week." That got my website blocked by the DoD: I
keep a framed print of the censor's message on my wall.<a href="#section-2-8">¶</a></p>
<p id="section-2-9">Perhaps the most surreal document disclosures were when artists
started writing fiction based on the documents. This was in 2016, when
Laura Poitras built a secure room in New York to house the
documents. By then, the documents were years out of date.  And now
they're over a decade out of date. (They were leaked in 2013, but most
of them were from 2012 or before.)<a href="#section-2-9">¶</a></p>
<p id="section-2-10">I ended up being something of a public ambassador for the
documents. When I got back from Rio, I gave talks at a private
conference in Woods Hole, the Berkman Center at Harvard, something
called the Congress on Privacy and Surveillance in Geneva, events at
both CATO and New America in DC, an event at the University of
Pennsylvania, an event at EPIC, a "Stop Watching Us" rally in DC,
the RISCS conference in London, the ISF in Paris, and...then...at the
IETF meeting in Vancouver in November 2013. (I remember little of
this; I am reconstructing it all from my calendar.)<a href="#section-2-10">¶</a></p>
<p id="section-2-11">What struck me at the IETF was the indignation in the room, and the
calls to action. And there was action, across many fronts. We
technologists did a lot to help secure the Internet, for example.<a href="#section-2-11">¶</a></p>
<p id="section-2-12">The government didn't do its part, though. Despite the public outcry,
investigations by Congress, pronouncements by President Obama, and
federal court rulings, I don't think much has changed. The NSA
canceled a program here and a program there, and it is now more public
about defense. But I don't think it is any less aggressive about
either bulk or targeted surveillance. Certainly its government
authorities haven't been restricted in any way. And surveillance
capitalism is still the business model of the Internet.<a href="#section-2-12">¶</a></p>
<p id="section-2-13">And Edward Snowden? We were in contact for a while on Signal. I
visited him once in Moscow, in 2016. And I had him do a guest
lecture to my class at Harvard for a few years, remotely by
Jitsi. Afterwards, I would hold a session where I promised to answer
every question he would evade or not answer, explain every response he
did give, and be candid in a way that someone with an outstanding
arrest warrant simply cannot. Sometimes I thought I could channel
Snowden better than he could.<a href="#section-2-13">¶</a></p>
<p id="section-2-14">But now it's been a decade. Everything he knows is old and out of
date. Everything we know is old and out of date. The NSA suffered an
even worse leak of its secrets by the Russians, under the guise of the
Shadow Brokers, in 2016 and 2017. The NSA has rebuilt. It again has
capabilities we can only surmise.<a href="#section-2-14">¶</a></p>
</section>
<section id="stephen-farrell-ietf-and-internet-technical-community-reaction">
      <h2 id="name-stephen-farrell-ietf-and-in">
<a href="#section-3">3. </a><a href="#name-stephen-farrell-ietf-and-in">Stephen Farrell: IETF and Internet Technical Community Reaction</a>
      </h2>
<p id="section-3-1">In 2013, the IETF and, more broadly, the Internet technical, security, and
privacy research communities, were surprised by the surveillance and attack
efforts exposed by the Snowden revelations <span>[<a href="#Timeline">Timeline</a>]</span>. While the
potential for such was known, it was the scale and pervasiveness of the
activities disclosed that was alarming and, I think it fair to say, quite
annoying, for very many Internet engineers.<a href="#section-3-1">¶</a></p>
<p id="section-3-2">As for the IETF's reaction, informal meetings during the July 2013 IETF meeting
in Berlin indicated that IETF participants considered that these revelations
showed that we needed to do more to improve the security and privacy properties
of IETF protocols, and to help ensure deployments made better use of the
security and privacy mechanisms that already existed. In August, the IETF set up
a new mailing list <span>[<a href="#Perpass">Perpass</a>]</span>, which became a useful venue for triaging
proposals for work on these topics. At the November 2013 IETF meeting, there
was a lively and very well attended plenary session <span>[<a href="#Plenary-video">Plenary-video</a>]</span> on
"hardening the Internet" against such attacks, followed by a "birds of a
feather" session <span>[<a href="#Perpass-BoF">Perpass-BoF</a>]</span> devoted to more detailed discussion of possible
actions in terms of new working groups, protocols, and Best Current Practice
(BCP) documents that could help improve matters.  This was followed in
February/March 2014 by a joint IAB/W3C workshop on "strengthening the Internet
against pervasive monitoring" <span>[<a href="#STRINT">STRINT</a>]</span> held in London and attended by 150
engineers (still the only IAB workshop in my experience where we needed a
waiting list for people after capacity for the venue was reached!). The STRINT
workshop report was eventually published as <span>[<a href="#RFC7687">RFC7687</a>]</span> in 2015, but in the
meantime, work proceeded on a BCP document codifying
that the IETF community considered that "pervasive monitoring is an attack"
<span>[<a href="#RFC7258">RFC7258</a>]</span> (aka BCP 188). The IETF Last Call discussion for that short
document included more than 1000 emails -- while there was broad agreement on
the overall message, a number of IETF participants considered enshrining that
message in the RFC Series and IETF processes controversial. In any case, the
BCP was published in May 2014. The key statement on which rough consensus was
reached is in the abstract of RFC 7258 and says "Pervasive monitoring is a
technical attack that should be mitigated in the design of IETF protocols,
where possible." That document has since been referenced <span>[<a href="#Refs-to-7258">Refs-to-7258</a>]</span> by
many IETF working groups and RFCs as justifying additional work on security and
privacy. Throughout that period and beyond, the repercussions of the Snowden
revelations remained a major and ongoing agenda item for both of the IETF's
main technical management bodies, the IAB and the IESG (on which I served at
the time).<a href="#section-3-2">¶</a></p>
<p id="section-3-3">So far, I've only described the processes with which the IETF dealt with
the attacks, but there was, of course, also much technical work started by IETF
participants that was at least partly motivated by the Snowden revelations.<a href="#section-3-3">¶</a></p>
<p id="section-3-4">In November 2013, a working group was established to document better practices
for using TLS in applications <span>[<a href="#UTA">UTA</a>]</span> so that deployments would be less at risk
in the face of some of the attacks related to stripping TLS or having
applications misuse TLS APIs or parameters.  Similar work was done later to update
recommendations for use of cryptography in other protocols in the CURDLE 
Working Group <span>[<a href="#CURDLE">CURDLE</a>]</span>.  The CURDLE Working Group was, to an extent, created to
enable use of a set of new elliptic curves that had been documented by the IRTF
Crypto Forum Research Group <span>[<a href="#CFRG">CFRG</a>]</span>. That work in turn had been partly
motivated by (perhaps ultimately unfounded) concerns about elliptic curves
defined in NIST standards, following the DUAL_EC_DRBG debacle <span>[<a href="#Dual-EC">Dual-EC</a>]</span> 
(described further below) where a
NIST random number generator had been deliberately engineered to produce output
that could be vulnerable to NSA attack.<a href="#section-3-4">¶</a></p>
<p id="section-3-5">Work to develop a new version of TLS was started in 2014, mainly due to
concerns that TLS 1.2 and earlier version implementations had been shown to be
vulnerable to a range of attacks over the years. The work to develop TLS 1.3
<span>[<a href="#RFC8446">RFC8446</a>]</span> also aimed to encrypt more of the handshake so as to
expose less information to network observers -- a fairly direct result of the
Snowden revelations.  Work to further improve TLS in this respect continues
today using the so-called Encrypted Client Hello (ECH) mechanism <span>[<a href="#I-D.ietf-tls-esni">TLS-ECH</a>]</span>
to remove one of the last privacy leaks present in current TLS.<a href="#section-3-5">¶</a></p>
<p id="section-3-6">Work on ECH was enabled by significant developments to encrypt DNS traffic,
using DNS over TLS (DoT) <span>[<a href="#RFC7858">RFC7858</a>]</span> or DNS Queries over HTTPS (DoH) <span>[<a href="#RFC8484">RFC8484</a>]</span>, which also started as a result of
the Snowden revelations. Prior to that, privacy hadn't really been considered
when it came to DNS data or (more importantly) the act of accessing DNS data.
The trend towards encrypting DNS traffic represents a significant change for
the Internet, both in terms of reducing cleartext, but also in terms of moving
points-of-control. The latter aspect was, and remains, controversial, but the
IETF did its job of defining new protocols that can enable better DNS privacy.
Work on HTTP version 2 <span>[<a href="#RFC9113">RFC9113</a>]</span> and QUIC <span>[<a href="#RFC9000">RFC9000</a>]</span> further demonstrates
the trend in the IETF towards always encrypting protocols as the new norm, at
least at and above the transport layer.<a href="#section-3-6">¶</a></p>
<p id="section-3-7">Of course, not all such initiatives bore fruit; for example, attempts to define
a new MPLS encryption mechanism <span>[<a href="#I-D.ietf-mpls-opportunistic-encrypt">MPLS-OPPORTUNISTIC-ENCRYPT</a>]</span>
foundered due to a lack of interest and the existence of the already deployed
IEEE Media Access Control Security (MACsec) scheme. But there has been a fairly clear trend towards trying to
remove cleartext from the Internet as a precursor to provide improved privacy
when considering network observers as attackers.<a href="#section-3-7">¶</a></p>
<p id="section-3-8">The IETF, of course, forms only one part of the broader Internet technical
community, and there were many non-IETF activities triggered by the Snowden
revelations, a number of which also eventually resulted in new IETF work to
standardise better security and privacy mechanisms developed elsewhere.<a href="#section-3-8">¶</a></p>
<p id="section-3-9">In 2013, the web was largely unencrypted despite HTTPS being relatively
usable, and that was partly due to problems using the Web PKI at scale. The
Let's Encrypt initiative <span>[<a href="#LE">LE</a>]</span> issued its first certificates in 2015 as
part of its aim to try to move the web
towards being fully encrypted, and it has been extremely successful in helping
achieve that goal.  Subsequently, the automation protocols developed for
Let's Encrypt were standardised in the IETF's ACME Working Group <span>[<a href="#ACME">ACME</a>]</span>.<a href="#section-3-9">¶</a></p>
<p id="section-3-10">In 2013, most email transport between mail servers was cleartext,
directly enabling some of the attacks documented in the Snowden documents.
Significant effort by major mail services and MTA software developers since
then have resulted in more than 90% of email being encrypted between mail
servers, and various IETF protocols have been defined in order to improve that
situation, e.g., SMTP MTA Strict Transport Security (MTA-STS) <span>[<a href="#RFC8461">RFC8461</a>]</span>.<a href="#section-3-10">¶</a></p>
<p id="section-3-11">Lastly, MAC addresses have historically been long-term fixed values visible to
local networks (and beyond), which enabled some tracking attacks that were
documented in the Snowden documents <span>[<a href="#Toronto">Toronto</a>]</span>. 
Implementers, vendors, and the IEEE 802
standards group recognised this weakness and started work on MAC address
randomisation that in turn led to the IETF's MADINAS Working Group <span>[<a href="#MADINAS">MADINAS</a>]</span>, which
aims to ensure randomised MAC addresses can be used on the Internet without
causing unintentional harm.
There is also a history of IETF work on deprecating MAC-address-based IPv6 interface identifiers
and advocating pseudorandom identifiers and temporary addresses, some of
which pre-dates Snowden <span>[<a href="#RFC7217">RFC7217</a>]</span> <span>[<a href="#RFC8064">RFC8064</a>]</span> <span>[<a href="#RFC8981">RFC8981</a>]</span>.<a href="#section-3-11">¶</a></p>
<p id="section-3-12">In summary, the significantly large volume of technical work pursued in the
IETF and elsewhere as a result of the Snowden revelations has focussed on two
main things: decreasing the amount of plaintext that remains visible to network
observers and secondly reducing the number of long-term identifiers that enable
unexpected identification or re-identification of devices or users. This work
is not by any means complete, nor is deployment universal, but significant
progress has been made, and the work continues even if the level of annoyance
at the attack has faded somewhat over time.<a href="#section-3-12">¶</a></p>
<p id="section-3-13">One should also note that there has been pushback against these improvements
in security and privacy and the changes they cause for deployments. That has
come from more or less two camps: those on whom these improvements force
change tend to react badly, but later figure out how to adjust, and 
those who seemingly prefer not to strengthen security so as to, for
example, continue to achieve what they call "visibility" even in the face of the
many engineers who correctly argue that such an anti-encryption approach
inevitably leads to worse security overall. The recurring nature of this kind
of pushback is nicely illustrated by <span>[<a href="#RFC1984">RFC1984</a>]</span>. That informational document
was published in 1996 as an IETF response to an early iteration of the
perennial "encryption is bad" argument. In 2015, the unmodified 1996 text was
upgraded to a BCP (BCP 200) as the underlying arguments have
not changed, and will not change.<a href="#section-3-13">¶</a></p>
<p id="section-3-14">Looking back on all the above from a 2023 vantage point, I think that, as a
community of Internet engineers, we got a lot right, but that today there's way
more that needs to be done to better protect the security and privacy of people
who use the Internet. In particular, we (the technical community) haven't done
nearly as good a job at countering surveillance capitalism <span>[<a href="#Zubhoff2019">Zubhoff2019</a>]</span>, which has exploded
in the last decade. In part, that's because many of the problems are outside of
the scope of bodies such as the IETF. For example, intrusive backend sharing
of people's data for advertising purposes can't really be mitigated via
Internet protocols.<a href="#section-3-14">¶</a></p>
<p id="section-3-15">However, I also think that the real annoyance felt with respect to the Snowden
revelations is (in general) not felt nearly as much when it comes to the legal
but hugely privacy-invasive activities of major employers of Internet
engineers.<a href="#section-3-15">¶</a></p>
<p id="section-3-16">It's noteworthy that RFC 7258 doesn't consider that bad actors are limited to
governments, and personally, I think many advertising industry schemes for
collecting data are egregious examples of pervasive monitoring and hence ought
also be considered an attack on the Internet that ought be mitigated where
possible.  However, the Internet technical community clearly hasn't acted in
that way over the last decade.<a href="#section-3-16">¶</a></p>
<p id="section-3-17">Perhaps that indicates that Internet engineers and the bodies in which they
congregate need to place much more emphasis on standards for ethical behaviour
than has been the case for the first half-century of the Internet.  And while
it would be good to see the current leaders of Internet bodies work to make
progress in that regard, at the time of writing, it sadly seems more likely that
government regulators will be the ones to try force better behaviour. That of
course comes with a significant risk of having regulations that stymie the kind
of permissionless innovation that characterised many earlier Internet
successes.<a href="#section-3-17">¶</a></p>
<p id="section-3-18">So while we got a lot right in our reaction to Snowden's revelations,
currently, we have a "worse" Internet.  Nonetheless, I do still hope to see a
sea change there, as the importance of real Internet security and privacy for
people becomes utterly obvious to all, even the most hard-core capitalists and
government signals intelligence agencies.  That may seem naive, but I remain
optimistic that, as a fact-based community, we (and eventually our employers)
will recognise that the lesser risk is to honestly aim to provide the best
security and privacy practically possible.<a href="#section-3-18">¶</a></p>
</section>
<section id="farzaneh-badii-did-snowdens-revelations-help-with-protecting-human-rights-on-the-internet">
      <h2 id="name-farzaneh-badii-did-snowdens">
<a href="#section-4">4. </a><a href="#name-farzaneh-badii-did-snowdens">Farzaneh Badii: Did Snowden's Revelations Help with Protecting Human Rights on the Internet?</a>
      </h2>
<p id="section-4-1">It is very difficult to empirically measure the effect of Snowden's
revelations on human rights and the Internet. Anecdotally, we have
been witnessing dominant regulatory and policy approaches that impact
technologies and services that are at the core of protecting human
rights on the Internet. (A range of European Union laws aims to
address online safety or concentration of data. There are many more
regulations that have an impact on the Internet <span>[<a href="#Masnick2023">Masnick2023</a>]</span>.) There
has been little progress in fixing technical and policy issues that
help enable human rights. The Snowden revelations did not
revolutionize the Internet governance and
technical approaches to support human rights such as freedom
of expression, freedom of association and assembly, and privacy. It did not decrease the number of 
Internet shutdowns nor the eagerness of authoritarian (and even to some extent democratic) countries to territorialize the Internet. 
In some cases, the governments argued that they should have more data sovereignty or Internet sovereignty. Perhaps the revelations helped with the evolution of some technical and policy aspects.<a href="#section-4-1">¶</a></p>
<p id="section-4-2">After Snowden's revelations 10 years ago, engineers and advocates at
the IETF responded in a few
ways. One prominent response was the issuance of a BCP 
document, "Pervasive Monitoring Is an Attack" <span>[<a href="#RFC7258">RFC7258</a>]</span> by
Farrell and Tschofenig. The responses to the Snowden revelations did not
mean that IETF had lost sight of issues such as privacy and
surveillance. There were instances of resistance to surveillance in
the past by engineers (we do not delve into how successful that was in
protecting human rights). However, historically, many engineers believed
that widespread and habitual surveillance was too expensive to be
practical. The revelations proved them wrong.<a href="#section-4-2">¶</a></p>
<p id="section-4-3">Rights-centered activists were also involved with the IETF before the
revelations. For example, staff from Center for Democracy and
Technology (CDT) was undertaking work at the IETF (and was a member of
the Internet Architecture Board) and held workshops about the
challenges of creating privacy-protective protocols and systems. The
technical shortcomings that were exploited by the National Security
Agency to carry out mass-scale surveillance were recognized by the
IETF before the Snowden revelations <span>[<a href="#Garfinkel1995">Garfinkel1995</a>]</span> <span>[<a href="#RFC6462">RFC6462</a>]</span>. In
2012, Joy Liddicoat and Avri Doria wrote a report for the Internet Society
that extensively discussed the processes and principles of human
rights and Internet protocols <span>[<a href="#Doria2012">Doria2012</a>]</span>.<a href="#section-4-3">¶</a></p>
<p id="section-4-4">Perhaps the Snowden revelations brought more attention to the IETF and
its work as it related to important issues, such as privacy and
freedom of expression. It might have also expedited and helped with
more easily convening the Human Rights Protocol Considerations
Research Group (HRPC) in the Internet Research Task Force (IRTF) in July 2015. The HRPC RG was originally co-chaired
by Niels ten Oever (who worked at Article 19 at the time) and Internet
governance activist Avri Doria.
The charter of the HRPC RG states that
the group was established: "to research whether standards and
protocols can enable, strengthen or threaten human rights, as defined
in the Universal Declaration of Human Rights (UDHR) and the International Covenant on Civil and Political
Rights (ICCPR)."<a href="#section-4-4">¶</a></p>
<p id="section-4-5">During the past decade, a few successful strides were made to create
protocols that, when and if implemented, aim at protecting privacy of
the users, as well as help with reducing pervasive surveillance. These
efforts were in keeping with the consensus of the IETF found in RFC
7258.  Sometimes these protocols have anti-censorship qualities as
well. A few examples immediately come to mind: 1) the encryption of DNS
queries (for example, DNS over HTTPS), 2) ACME protocol underpinning
the Let's Encrypt initiative, and 3) Registration Data Access Protocol
(RDAP) <span>[<a href="#RFC7480">RFC7480</a>]</span> <span>[<a href="#RFC7481">RFC7481</a>]</span> <span>[<a href="#RFC8056">RFC8056</a>]</span> <span>[<a href="#RFC9082">RFC9082</a>]</span> <span>[<a href="#RFC9083">RFC9083</a>]</span> <span>[<a href="#RFC9224">RFC9224</a>]</span>. (It is debatable that RDAP had anything to do with
the Snowden revelations, but it is still a good example and is finally
being implemented.)<a href="#section-4-5">¶</a></p>
<p id="section-4-6">The DNS Queries over HTTPS protocol aimed to encrypt DNS queries. Four
years after RFC 7258, DoH was developed to tackle both active and
passive monitoring of DNS queries. It is also a tool that can help
with combatting censorship. Before the revelations, DNS query privacy
would have been controversial due to being expensive or unnecessary, but the 
Snowden revelations made it more plausible. 
Let's Encrypt was not an Internet protocol, but it was an initiative that aimed to encrypt the web, and later on
some of the automation protocols were standardized in the IETF ACME
Working Group. RDAP could solve a
long-term problem: redacting the domain name registrants' (and IP
address holders') sensitive, personal data but at the same time
enabling legitimate access to the information. As to the work of HRPC
Research Group, it has so far issued <span>[<a href="#RFC8280">RFC8280</a>]</span> by ten Oever and
Cath and a number of informational Internet-Drafts.<a href="#section-4-6">¶</a></p>
<p id="section-4-7">While we cannot really argue that all the movements and privacy-preserving 
protocols and initiatives that enable protecting human
rights at the infrastructure layer solely or directly result from the Snowden
revelations, I think it is safe to say that the revelations helped
with expediting the resolution of some of the "technical" hesitations
that had an effect on fixing Internet protocols that enabled
protection of human rights.<a href="#section-4-7">¶</a></p>
<p id="section-4-8">Unfortunately, the Snowden revelations have not yet helped us
meaningfully with adopting a human rights approach. We can't agree on
prioritizing human rights in our Internet communities for a host of
reasons. This could be due to: 1) human rights are sometimes in
conflict with each other; 2) it is simply not possible to mitigate the
human right violation through the Internet protocol; 3) it is not
obvious for the engineers in advance how the Internet protocol
contributes to enabling human rights protections, or precisely what they ought to do; 
 4) the protocol is already there, but market, law, and a
host of other societal and political issues do not allow for
widespread implementation.<a href="#section-4-8">¶</a></p>
<p id="section-4-9">IETF did not purposefully take a long time to adopt and implement protocols that
enabled human rights. There were technical and political issues that
created barriers. For example, as WHOIS was not capable of accommodating a tiered-access option, 
the IETF community attempted a few times before to create a protocol that would disclose the necessary
information of IP holders and domain name registrants while at the
same time protecting their data (Cross Registry Internet Service Protocol (CRISP) and later on Internet Registry Information Service (IRIS) are the
examples). However, IRIS was technically very difficult to implement. It was not until RDAP was developed and the
General Data Protection Regulation (GDPR) was enacted that Internet
Corporation for Assigned Names and Numbers had to consider instructing
registries and registrars to implement RDAP and its community had to
come up with a privacy-compliant policy.  Overall, a host of
regulatory and market incentives can halt or slow down the
implementation of human-rights-enabling protocols and implementation
could depend on other organizations with their own political and
stakeholder conflicts. Sometimes the protocol is available, but the regulatory framework and
the market do not allow for implementation. 
Sometimes the surrounding context includes 
practical dimensions that are easy to overlook in a purely engineering-focused argument.<a href="#section-4-9">¶</a></p>
<p id="section-4-10">
A curious example of this is sanctions regimes that target transactions involving
economically valuable assets.  As a result, sanctions might limit
sanctioned nations' and entities' access to IPv4 resources (because the existence of
a resale market for these addresses causes acquiring them to be
interpreted as buying something of value), though the same consideration
may not apply to IPv6 address resources.  But IPv6 adoption itself
depends on a host of complex factors that are by no means limited to
technical comparisons of the properties of IPv4 and IPv6.  Someone
focused only on technical features of protocols may devise an elegant
solution but be surprised both by deployment challenges and unintended
downstream effects.
Sometimes there are arguments over implementation of a protocol
because as it is perceived, while it can protect freedom of expression
and reduce surveillance, it can hamper other human rights. For
instance, the technical community and some network operators still have doubts about the implementation of DNS over HTTPS,
despite its potential to circumvent 
censorship and its ability to encrypt DNS queries. The arguments against
implementation of DoH include protection of children online and lack
of law enforcement access to data.<a href="#section-4-10">¶</a></p>
<p id="section-4-11">We must acknowledge that sometimes the technical solutions that we use
that protect one right (for example, encryption to protect the right to
privacy or to prevent surveillance) could potentially affect technical
and policy solutions that try to protect other human rights (for
example, encryption could prevent financial institutions from
monitoring employees' network activities to detect fraudulent
behavior). Acknowledging and identifying these conflicts can help us
come up with alternative techniques that could protect human rights
while not hampering other technical solutions such as
encryption. Where such alternative techniques are not possible,
acknowledging the shortcoming could clarify and bring to light the
trade-offs that we have accepted in our Internet system.<a href="#section-4-11">¶</a></p>
<p id="section-4-12">Ironically, we advocate for connectivity and believe expressing
oneself on the Internet is a human right, but when a war erupts, we
resort to tools that impact that very concept. For example, some
believe that, by imposing sanctions on critical properties of the Internet,
we can punish the perpetrators of a war. The Regional Internet
Registries that are in charge of registration of IP addresses have
shown resilience to these requests.  However, some tech companies (for
example, Cogent <span>[<a href="#Roth2022">Roth2022</a>]</span>) decided not to serve sanctioned countries
and overcomplied with sanctions. Overcompliance with sanctions could
hamper ordinary people's access to the Internet <span>[<a href="#Badii2023">Badii2023</a>]</span>.<a href="#section-4-12">¶</a></p>
<p id="section-4-13">Perhaps we can solve some of these problems by undertaking a thorough
impact assessment and contextualization to reveal how and why Internet
protocols affect human rights (something Fidler and I argued
for <span>[<a href="#Badii2021">Badii2021</a>]</span>). Contextualization and
impact assessment can reveal how each Internet protocol or each line
of code, in which systems, have an impact on which and whose human
rights.<a href="#section-4-13">¶</a></p>
<p id="section-4-14">The HRPC RG (which I am a part of) and the larger human rights and
policy analyst communities are still struggling to analyze legal,
social, and market factors alongside the protocols to have a good
understanding of what has an impact and what has to be changed. It is
hard, but it is not impossible. If we thoroughly document and research
the lifecycle of an Internet protocol and contextualize it, we might
have a better understanding of which
parts of the protocol to fix and how to fix them in order to protect human rights.<a href="#section-4-14">¶</a></p>
<p id="section-4-15">Overall, the revelations did, to some extent, contribute to the
evolution of our ideas and perspectives. Our next step should be to
undertake research on the impact of Internet systems (including
Internet protocols) on human rights, promote the implementation of
protocols good for human rights through policy and advocacy, and focus
on which technical parts we can standardize to help with more
widespread implementation of human-rights-enabling Internet protocols.<a href="#section-4-15">¶</a></p>
</section>
<section id="steven-m-bellovin-governments-and-cryptography-the-crypto-wars">
      <h2 id="name-steven-m-bellovin-governmen">
<a href="#section-5">5. </a><a href="#name-steven-m-bellovin-governmen">Steven M. Bellovin: Governments and Cryptography: The Crypto Wars</a>
      </h2>
<section id="historical-background">
        <h3 id="name-historical-background">
<a href="#section-5.1">5.1. </a><a href="#name-historical-background">Historical Background</a>
        </h3>
<p id="section-5.1-1">It's not a secret: many governments in the world don't like it when
people encrypt their traffic. More precisely, they like strong
cryptography for themselves but not for others, whether those others
are private citizens or other countries. But the history is longer and
more complex than that.<a href="#section-5.1-1">¶</a></p>
<p id="section-5.1-2">For much of written history, both governments and individuals used
cryptography to protect their messages. To cite just one famous
example, Julius Caesar is said to have encrypted messages by shifting
letters in the alphabet by 3 <span>[<a href="#Kahn1996">Kahn1996</a>]</span>. In modern parlance, 3 was
the key, and each letter was encrypted with<a href="#section-5.1-2">¶</a></p>
<p id="section-5.1-3">
            C[i] = (P[i] + 3) mod 23<a href="#section-5.1-3">¶</a></p>
<p id="section-5.1-4">(The Latin alphabet of his time had only 23 letters.)
Known
Arabic writings on cryptanalysis go back to at least the 8th century;
their sophistication shows that encryption was reasonably commonly
used. In the 9th century, Abū Yūsuf Yaʻqūb ibn ʼIsḥāq aṣ-Ṣabbāḥ 
al-Kindī developed and wrote about frequency analysis as a way to
crack ciphers <span>[<a href="#Borda2011">Borda2011</a>]</span> <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-4">¶</a></p>
<p id="section-5.1-5">In an era of minimal literacy, though, there wasn't that much use of
encryption, simply because most people could neither read nor
write. Governments used encryption for diplomatic messages, and
cryptanalysts followed close behind. The famed Black Chambers of the
Renaissance era read messages from many different governments, while
early cryptographers devised stronger and stronger ciphers
<span>[<a href="#Kahn1996">Kahn1996</a>]</span>. In Elizabethan times in England, Sir Francis Walsingham's
intelligence agency intercepted and decrypted messages from Mary,
Queen of Scots; these messages formed some of the strongest evidence
against her and eventually led to her execution <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-5">¶</a></p>
<p id="section-5.1-6">This pattern continued for centuries. In the United States, Thomas
Jefferson invented the so-called wheel cipher in the late 18th
century; it was reinvented about 100 years later by Étienne Bazeries
and used as a standard American military cipher well into World War II
<span>[<a href="#Kahn1996">Kahn1996</a>]</span>. Jefferson and other statesmen of the late 18th and early 19th centuries regularly used
cryptography when communicating with each other. An encrypted message
was even part of the evidence introduced in Aaron Burr's 1807 trial
for treason <span>[<a href="#Kerr2020">Kerr2020</a>]</span> <span>[<a href="#Kahn1996">Kahn1996</a>]</span>. Edgar Allan Poe claimed that he
could cryptanalyze any message sent to him <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-6">¶</a></p>
<p id="section-5.1-7">The telegraph era upped the ante. In the US, just a year after
Samuel Morse deployed his first telegraph line between Baltimore and
Washington, his business partner, Francis Smith, published a codebook
to help customers protect their traffic from prying eyes
<span>[<a href="#Smith1845">Smith1845</a>]</span>.  In 1870, Britain nationalized its domestic telegraph network;
in response, Robert Slater published a more sophisticated codebook
<span>[<a href="#Slater1870">Slater1870</a>]</span>. On the government side, Britain took advantage of its
position as the central node in the world's international telegraphic
networks to read a great deal of traffic passing through the country
<span>[<a href="#Headrick1991">Headrick1991</a>]</span> <span>[<a href="#Kennedy1971">Kennedy1971</a>]</span>. They used this ability strategically,
too -- when war broke out in 1914, the British Navy cut Germany's
undersea telegraph cables, forcing them to use radio; an intercept of
the so-called Zimmermann telegram, when cryptanalyzed, arguably led to
American entry into the war and thence to Germany's defeat. Once the
US entered the war, it required users of international telegraph
lines to deposit copies of the codebooks they used for compression, so
that censors could check messages for prohibited content <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-7">¶</a></p>
<p id="section-5.1-8">In Victorian Britain, private citizens, often lovers, used encryption
in newspapers' personal columns to communicate without their parents'
knowledge. Charles Wheatstone and Charles Babbage used to solve these
elementary ciphers routinely for their own amusement <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-8">¶</a></p>
<p id="section-5.1-9">This pattern continued for many years. Governments regularly used
ciphers and codes, while other countries tried to break them; private
individuals would sometimes use encryption but not often, and rarely
well. But the two World Wars marked a sea change, one that would soon
reverberate into the civilian world.<a href="#section-5.1-9">¶</a></p>
<p id="section-5.1-10">The first World War featured vast troop movements by all parties; this
in turn required a lot of encrypted communications, often by telegraph
or radio. These messages were often easily intercepted in
bulk. Furthermore, the difficulty of encrypting large volumes of
plaintext led to the development of a variety of mechanical encryption
devices, including Germany's famed Enigma machine. World War II
amplified both trends. It also gave rise to machine-assisted
cryptanalysis, such as the United Kingdom's bombes (derived from an
earlier Polish design) and Colossus machine, and the American's device
for cracking Japan's PURPLE system. The US also used punch
card-based tabulators to assist in breaking other Japanese codes, such
as the Japanese Imperial Navy's JN-25 <span>[<a href="#Kahn1996">Kahn1996</a>]</span> <span>[<a href="#Rowlett1998">Rowlett1998</a>]</span>.<a href="#section-5.1-10">¶</a></p>
<p id="section-5.1-11">These developments set the stage for the postwar SIGINT (Signals
Intelligence) environment. Many intragovernmental messages were sent by
radio, making them easy to intercept; advanced cryptanalytic machines
made cryptanalysis easier. Ciphers were getting stronger, though, and
government SIGINT agencies did not want to give up their access to
data. While there were undoubtedly many developments, two are well
known.<a href="#section-5.1-11">¶</a></p>
<p id="section-5.1-12">The first involved CryptoAG, a Swedish (and later Swiss) manufacturer
of encryption devices. The head of that company, Boris Hagelin, was a
friend of William F. Friedman, a pioneering American
cryptologist. During the 1950s, CryptoAG sold its devices to other
governments; apparently at Friedman's behest, Hagelin weakened the
encryption in a way that let the NSA read the traffic <span>[<a href="#Miller2020">Miller2020</a>]</span>.<a href="#section-5.1-12">¶</a></p>
<p id="section-5.1-13">The story involving the British is less well-documented and less
clear. When some of Britain's former colonies gained their
independence, the British government gave them captured, war-surplus
Enigma machines to protect their own traffic. Some authors contend
that this was deceptive, in that these former colonies did not realize
that the British could read Enigma-protected traffic; others claim
that this was obvious but that these countries didn't care: Britain
was no longer their enemy; it was neighboring countries they were
worried about. Again, though, this concerned governmental use of
encryption <span>[<a href="#Kahn1996">Kahn1996</a>]</span> <span>[<a href="#Baldwin2022">Baldwin2022</a>]</span>. There was still little private
use.<a href="#section-5.1-13">¶</a></p>
</section>
<section id="the-crypto-wars-begin">
        <h3 id="name-the-crypto-wars-begin">
<a href="#section-5.2">5.2. </a><a href="#name-the-crypto-wars-begin">The Crypto Wars Begin</a>
        </h3>
<p id="section-5.2-1">The modern era of conflict between an individual's desire for privacy and
the government desires to read traffic began around 1972. The grain
harvest in the USSR had failed; since relations between the Soviet
Union and the United States were temporarily comparatively warm, the
Soviet grain company -- an arm of the Soviet government, of
course -- entered into negotiations with private American
companies. Unknown to Americans at the time, Soviet intelligence was
intercepting the phone calls of the American negotiating teams. In
other words, private companies had to deal with state actors as a
threat. Eventually, US intelligence learned of this and came to a
realization: the private sector needed strong cryptography, too, to
protect American national interests <span>[<a href="#Broad1982">Broad1982</a>]</span> <span>[<a href="#Johnson1998">Johnson1998</a>]</span>. This
underscored the need for strong cryptography to protect American
civilian traffic -- but the SIGINT people were unhappy at the thought of
more encryption that they couldn't break.<a href="#section-5.2-1">¶</a></p>
<p id="section-5.2-2">Meanwhile, the US was concerned about protecting 
unclassified data <span>[<a href="#Landau2014">Landau2014</a>]</span>. In 1973 and again in 1974, the
National Bureau of Standards (NBS) put out a call for a strong, modern
encryption algorithm. IBM submitted Lucifer, an internally developed
algorithm based on what has become known as a 16-round Feistel network. The
original version used a long key.
It seemed quite strong, so NBS sent it off to the NSA to
get their take. The eventual design, which was adopted in 1976 as the
Data Encryption Standard (DES), differed in some important ways from
Lucifer. 
First, the so-called S-boxes, the source of the cryptologic
strength of DES, were changed, and were now demonstrably not composed of
random integers. Many researchers alleged that the S-boxes contained
an NSA back door. It took nearly 20 years for the truth to come out: the
S-boxes were in fact strengthened, not weakened. Most likely, IBM
independently discovered the attack now known as differential
cryptanalysis, though some scholars suspect that the NSA told them
about it. The nonrandom S-boxes protected against this attack. The
second change, though, was clearly insisted on by the NSA: the key size
was shortened, from Lucifer's 112 bits to DES's 56 bits. We now know
that the NSA wanted a 48-bit key size, while IBM wanted 64 bits; they
compromised at 56 bits.<a href="#section-5.2-2">¶</a></p>
<p id="section-5.2-3">Whitfield Diffie and Martin Hellman, at Stanford University, wondered
about the 56-bit keys. In 1979, they published a paper demonstrating
that the US government, but few others, could afford to build a
brute-force cracking machine, one that could try all 2<sup>56</sup> possible
keys to crack a message. NSA denied tampering with the design; a
Senate investigating committee found that assertion to be correct, but did
not discuss the shortened key length issue.<a href="#section-5.2-3">¶</a></p>
<p id="section-5.2-4">This, however, was not Diffie and Hellman's greatest contribution to
cryptology. A few years earlier, they had published a paper inventing what
is now known as public key cryptography.
(In fact, public key encryption had been invented a few years earlier
at UK Government Communications Headquarters (GCHQ), but they kept their discovery classified until 1997.)
In 1978, Ronald Rivest, Adi
Shamir, and Leonard Adleman devised the RSA algorithm, which made it
usable. (An NSA employee, acting on his own, sent a letter warning
that academic conferences on cryptology might violate US export
laws.)<a href="#section-5.2-4">¶</a></p>
<p id="section-5.2-5">Around the same time, George Davida at the University of Wisconsin
applied for a patent on a stream cipher; the NSA slapped a secrecy
order on the application. This barred him from even talking about his
invention. The publicity was devastating; the NSA had to back down.<a href="#section-5.2-5">¶</a></p>
<p id="section-5.2-6">The Crypto Wars had thus begun: civilians were inventing strong
encryption systems, and the NSA was tampering with them or trying to
suppress them. Bobby Inman, the then-director of the NSA, tried
creating a voluntary review process for academic papers, but very few
researchers were interested in participating <span>[<a href="#Landau1988">Landau1988</a>]</span>.<a href="#section-5.2-6">¶</a></p>
<p id="section-5.2-7">There were few major public battles during the 1980s because there
were few new major use cases for civilian cryptography during that
time. There was one notable incident, though: Shamir, Amos Fiat, and
Uriel Feige invented zero-knowledge proofs and applied for a US
patent. In response, the US Army slapped a secrecy order on the
patent. After a great deal of public outrage and intervention by, of
all organizations, the NSA, the order was lifted on very narrow
grounds: the inventors were not American, and they had been discussing
their work all over the world <span>[<a href="#Landau1988">Landau1988</a>]</span>.<a href="#section-5.2-7">¶</a></p>
<p id="section-5.2-8">In the 1990s, though, everything changed.<a href="#section-5.2-8">¶</a></p>
</section>
<section id="the-battle-is-joined">
        <h3 id="name-the-battle-is-joined">
<a href="#section-5.3">5.3. </a><a href="#name-the-battle-is-joined">The Battle Is Joined</a>
        </h3>
<p id="section-5.3-1">There were three major developments in cryptography in the early
1990s. First, Phil Zimmermann released PGP (Pretty Good Privacy), a
package to encrypt email messages. In 1993, AT&amp;T planned to release
the TSD-3600, an easy-to-use phone encryptor aimed at business
travelers. Shortly after that, the Netscape Communications Corporation released SSL
(Secure Socket Layer) as a way to enable web-based commerce using
their browser and web server. All of these were seen as threats by the
NSA and the FBI.<a href="#section-5.3-1">¶</a></p>
<p id="section-5.3-2">PGP was, at least arguably, covered by what was known as ITAR, the
International Trafficking in Arms Regulations -- under American law,
encryption software was regarded as a weapon, so exports required a
license. It was also alleged to infringe the patents on the RSA
algorithm. Needless to say, both issues were problematic for what was
intended to be open source software. Eventually, the criminal
investigation into Zimmermann's role in the spread of PGP overseas was
dropped, but the threat of such investigations remained to deter
others <span>[<a href="#Levy2001">Levy2001</a>]</span>.<a href="#section-5.3-2">¶</a></p>
<p id="section-5.3-3">The TSD-3600 was another matter. AT&amp;T was a major corporation that did
not want to pick a fight with the US government, but international
business travelers were seen as a major market for the device. At the
government's "request", the DES chip was replaced with what was known
as the Clipper chip. The Clipper chip used Skipjack, a cipher with
80-bit keys; it was thus much stronger against brute-force attacks
than DES. However, it provided "key escrow". Without going into any
details, the key escrow mechanism allowed US government
eavesdroppers to consult a pair of (presumably secure) internal
databases and decrypt all communications protected by the chip. The
Clipper chip proved to be extremely unpopular with industry; that AT&amp;T
Bell Labs' Matt Blaze found a weakness in the design <span>[<a href="#Blaze1994">Blaze1994</a>]</span>, one
that let you use Skipjack without the key escrow feature, didn't help
its reputation.<a href="#section-5.3-3">¶</a></p>
<p id="section-5.3-4">The third major development, SSL, was even trickier. SSL was aimed at
e-commerce, and of course Netscape wanted to be able to sell its
products outside the US. That would require an export license, so they
made a deal with the government: non-American users would receive a
version that used 40-bit keys, a key length far shorter than what the
NSA had agreed to 20 years earlier. (To get ahead of the story: there
was a compromise mode of operation, wherein an export-grade browser
could use strong encryption when talking to a financial
institution. This hybrid mode led to cryptographic weaknesses
discovered some 20 years later <span>[<a href="#Adrian2015">Adrian2015</a>]</span>.)<a href="#section-5.3-4">¶</a></p>
<p id="section-5.3-5">Technologists and American industry pushed back. The IETF adopted the
Danvers Doctrine, described in <span>[<a href="#RFC3365">RFC3365</a>]</span>:<a href="#section-5.3-5">¶</a></p>
<blockquote id="section-5.3-6">
          <p id="section-5.3-6.1">At the 32cd [sic] IETF held in Danvers, Massachusetts during April of 1995
the IESG asked the plenary for a consensus on the strength of security
that should be provided by IETF standards.  Although the immediate
issue before the IETF was whether or not to support "export" grade
security (which is to say weak security) in standards the question
raised the generic issue of security in general.<a href="#section-5.3-6.1">¶</a></p>
<p id="section-5.3-6.2">The overwhelming consensus was that the IETF should standardize on the
use of the best security available, regardless of national policies.
This consensus is often referred to as the "Danvers Doctrine".<a href="#section-5.3-6.2">¶</a></p>
</blockquote>
<p id="section-5.3-7">Then American companies started losing business to their overseas
competitors, who did not have to comply with US export laws. All of
this led to what seemed like a happy conclusion: the US government
drastically loosened its export rules for cryptographic software. All
was well -- or so it seemed...<a href="#section-5.3-7">¶</a></p>
</section>

<section id="whither-the-ietf">
        <h3 id="name-whither-the-ietf">
<a href="#section-5.5">5.5. </a><a href="#name-whither-the-ietf">Whither the IETF?</a>
        </h3>
<p id="section-5.5-1">Signal intelligence agencies, not just the NSA, but its peers around
the globe -- most major countries have their own -- are not going to go
away. The challenges that have beset the NSA are common to all such
agencies, and their solutions are likely the same. The question is
what should be done to protect individual privacy. A number of strong
democracies, such as Australia and the United Kingdom, are, in
a resumption of the Crypto Wars,
moving to restrict encryption. Spurred on by complaints from the FBI
and other law enforcement agencies, the US Congress frequently
considers bills to do the same.<a href="#section-5.5-1">¶</a></p>
<p id="section-5.5-2">The IETF has long had a commitment to strong, ubiquitous
encryption. This is a good thing. It needs to continue, with
cryptography and other security features designed into protocols from
the beginning. But there is also a need for maintenance. Parameters
such as key lengths and modulus sizes age; a value that is acceptable
today may not be 10 years hence. (We've already seen apparent problems
from 1024-bit moduli specified in an RFC, an RFC that was not modified
when technology improved enough that attacking encryption based on
them had become feasible <span>[<a href="#Adrian2015">Adrian2015</a>]</span>.) The IETF can do nothing about
the code that vendors ship or that sites use, but it can alert the
world that it thinks things have changed.<a href="#section-5.5-2">¶</a></p>
<p id="section-5.5-3">Cryptoagility is of increasing importance. In the next very few years,
we will have so-called post-quantum algorithms. Both protocols and key
lengths will need to change, perhaps drastically. Is the IETF ready?
What will happen to, say, DNSSEC if key lengths become drastically
longer? Backwards compatibility will remain important, but that, of
course, opens the door to other attacks. We've long thought about
them; we need to be sure that our mechanisms work -- we've
been surprised in the past <span>[<a href="#BellovinRescorla2006">BellovinRescorla2006</a>]</span>.<a href="#section-5.5-3">¶</a></p>
<p id="section-5.5-4">We also need to worry more about metadata. General Michael Hayden,
former director of both the NSA and the CIA, once remarked, "We kill
people based on metadata" <span>[<a href="#Ferran2014">Ferran2014</a>]</span>. But caution is necessary;
attempts to hide metadata can have side effects. To give a trivial
example, Tor is quite strong, but if your exit node is in a different
country than you are in, web sites that use IP geolocation may present
their content in a language foreign to you.
Some sites even block connections from known Tor exit nodes.
More generally, many
attempts to hide metadata involve trusting a different party; that
party may turn out to be untrustworthy or it may itself become a
target of attack. As another prominent IETFer has remarked,
"Insecurity is like entropy; you can't destroy it, but you can move it
around." The IETF has done a lot; it needs to do more. And remember
that the risk here is not just governments acting directly, it's also
private companies that collect the data and sell it to all comers.<a href="#section-5.5-4">¶</a></p>
<p id="section-5.5-5">Finally, the IETF must remember that its middle name is
"Engineering". To me, one of the attributes of engineering is the art
of picking the right solution in an over-constrained
environment. Intelligence agencies won't go away, nor will national
restrictions on cryptography. We have to pick the right path while
staying true to our principles.<a href="#section-5.5-5">¶</a></p>
</section>
</section>
<section id="security-considerations">
      <h2 id="name-security-considerations">
<a href="#section-6">6. </a><a href="#name-security-considerations">Security Considerations</a>
      </h2>
<p id="section-6-1">Each or any of the authors may have forgotten or omitted things
or gotten things wrong. We're sorry if that's the case, but that's
in the nature of a look-back such as this. Such flaws almost 
certainly won't worsen security or privacy, though.<a href="#section-6-1">¶</a></p>
</section>
<section id="iana-considerations">
      <h2 id="name-iana-considerations">
<a href="#section-7">7. </a><a href="#name-iana-considerations">IANA Considerations</a>
      </h2>
<p id="section-7-1">This document has no IANA actions.<a href="#section-7-1">¶</a></p>
</section>
<section id="section-8">
      <h2 id="name-informative-references">
<a href="#section-8">8. </a><a href="#name-informative-references">Informative References</a>
      </h2>
<dl>
<dt id="ACME">[ACME]</dt>
      <dd>
<span>IETF</span>, <span>"Automated Certificate Management Environment (acme)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/acme/about/">https://datatracker.ietf.org/wg/acme/about/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Adrian2015">[Adrian2015]</dt>
      <dd>
<span>Adrian, D.</span>, <span>Bhargavan, K.</span>, <span>Durumeric, Z.</span>, <span>Gaudry, P.</span>, <span>Green, M.</span>, <span>Halderman, J. A.</span>, <span>Heninger, N.</span>, <span>Springhall, D.</span>, <span>Thomé, E.</span>, <span>Valenta, L.</span>, <span>VanderSloot, B.</span>, <span>Wustrow, E.</span>, <span>Zanella-Béguelin, S.</span>, and <span>P. Zimmermann</span>, <span>"Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice"</span>, <span>CCS '15: Proceedings of the 22th ACM Conference on Computer and Communications Security</span>, <time datetime="2015-10">October 2015</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/2810103.2813707">https://dl.acm.org/doi/10.1145/2810103.2813707</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Badii2021">[Badii2021]</dt>
      <dd>
<span>Badiei, F.</span>, <span>Fidler, B.</span>, and <span>The Pennsylvania State University Press</span>, <span>"The Would-Be Technocracy: Evaluating Efforts to Direct and Control Social Change with Internet Protocol Design"</span>, <span>Journal of Information Policy, vol. 11, pp. 376-402</span>, <span>DOI 10.5325/jinfopoli.11.2021.0376</span>, <time datetime="2021-12">December 2021</time>, <span>&lt;<a href="https://doi.org/10.5325/jinfopoli.11.2021.0376">https://doi.org/10.5325/jinfopoli.11.2021.0376</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Badii2023">[Badii2023]</dt>
      <dd>
<span>Badiei, F.</span>, <span>"Sanctions and the Internet"</span>, <span>Digital Medusa</span>, <time datetime="2023">2023</time>, <span>&lt;<a href="https://digitalmedusa.org/wp-content/uploads/2023/05/SanctionsandtheInternet-DigitalMedusa.pdf">https://digitalmedusa.org/wp-content/uploads/2023/05/SanctionsandtheInternet-DigitalMedusa.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Baldwin2022">[Baldwin2022]</dt>
      <dd>
<span>Baldwin, M.</span>, <span>"Did Britain sell Enigmas postwar?"</span>, <span>Dr. Enigma</span>, <time datetime="2022-03">March 2022</time>, <span>&lt;<a href="https://drenigma.org/2022/03/02/did-britain-sell-enigmas-postwar/">https://drenigma.org/2022/03/02/did-britain-sell-enigmas-postwar/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="BellovinRescorla2006">[BellovinRescorla2006]</dt>
      <dd>
<span>Bellovin, S. M.</span> and <span>E. K. Rescorla</span>, <span>"Deploying a New Hash Algorithm"</span>, <span>Proceedings of NDSS '06</span>, <time datetime="2006-02">February 2006</time>, <span>&lt;<a href="https://www.cs.columbia.edu/~smb/papers/new-hash.pdf">https://www.cs.columbia.edu/~smb/papers/new-hash.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Blaze1994">[Blaze1994]</dt>
      <dd>
<span>Blaze, M.</span>, <span>"Protocol Failure in the Escrowed Encryption Standard"</span>, <span>CCS '94: Proceedings of Second ACM Conference on Computer and Communications Security</span>, <time datetime="1994">1994</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/191177.191193">https://dl.acm.org/doi/10.1145/191177.191193</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Borda2011">[Borda2011]</dt>
      <dd>
<span>Borda, M.</span>, <span>"Fundamentals in Information Theory and Coding"</span>, <span>Springer-Berlin</span>, <time datetime="2011-05">May 2011</time>. </dd>
<dd></dd>
<dt id="Broad1982">[Broad1982]</dt>
      <dd>
<span>Broad, W. J.</span>, <span>"Evading the Soviet Ear at Glen Cove"</span>, <span>Science, 217:4563, pp. 910-911</span>, <time datetime="1982-09">September 1982</time>, <span>&lt;<a href="https://www.science.org/doi/abs/10.1126/science.217.4563.910">https://www.science.org/doi/abs/10.1126/science.217.4563.910</a>&gt;</span>. </dd>
<dd></dd>
<dt id="CFRG">[CFRG]</dt>
      <dd>
<span>IRTF</span>, <span>"Crypto Forum (cfrg)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/rg/cfrg/about/">https://datatracker.ietf.org/rg/cfrg/about/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Checkoway2016">[Checkoway2016]</dt>
      <dd>
<span>Checkoway, S.</span>, <span>Maskiewicz, J.</span>, <span>Garman, C.</span>, <span>Fried, J.</span>, <span>Cohney, S.</span>, <span>Green, M.</span>, <span>Heninger, N.</span>, <span>Weinmann, R. P.</span>, <span>Rescorla, E.</span>, and <span>Hovav Shacham</span>, <span>"A Systematic Analysis of the Juniper Dual EC Incident"</span>, <span>CCS '16: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 468-479</span>, <time datetime="2016-10">October 2016</time>, <span>&lt;<a href="https://dl.acm.org/citation.cfm?id=2978395">https://dl.acm.org/citation.cfm?id=2978395</a>&gt;</span>. </dd>
<dd></dd>
<dt id="CURDLE">[CURDLE]</dt>
      <dd>
<span>IETF</span>, <span>"CURves, Deprecating and a Little more Encryption (curdle)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/curdle/about/">https://datatracker.ietf.org/wg/curdle/about/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Curtiz">[Curtiz]</dt>
      <dd>
<span>Curtiz, M.</span>, <span>Epstein, J. J.</span>, <span>Epstein, P. G.</span>, and <span>H. Koch</span>, <span>"Casablanca"</span>, <span>Warner Bros. Pictures</span>, <time datetime="1942-11">November 1942</time>. </dd>
<dd></dd>
<dt id="Doria2012">[Doria2012]</dt>
      <dd>
<span>Liddicoat, J.</span> and <span>A. Doria</span>, <span>"Human Rights and Internet Protocols: Comparing Processes and Principles"</span>, <span>The Internet Society</span>, <time datetime="2012-12">December 2012</time>, <span>&lt;<a href="https://www.internetsociety.org/resources/doc/2012/human-rights-and-internet-protocols-comparing-processes-and-principles/">https://www.internetsociety.org/resources/doc/2012/human-rights-and-internet-protocols-comparing-processes-and-principles/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Dual-EC">[Dual-EC]</dt>
      <dd>
<span>Bernstein, D.</span>, <span>Lange, T.</span>, and <span>R. Niederhagen</span>, <span>"Dual EC: A Standardized Back Door"</span>, <time datetime="2016-07">July 2016</time>, <span>&lt;<a href="https://eprint.iacr.org/2015/767.pdf">https://eprint.iacr.org/2015/767.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Ferran2014">[Ferran2014]</dt>
      <dd>
<span>Ferran, L.</span>, <span>"Ex-NSA Chief: "We Kill People Based on Metadata""</span>, <span>ABC News</span>, <time datetime="2014-05">May 2014</time>, <span>&lt;<a href="https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata">https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Garfinkel1995">[Garfinkel1995]</dt>
      <dd>
<span>Garfinkel, S.</span>, <span>"PGP: Pretty Good Privacy"</span>, <span>O'Reilly and Associates</span>, <time datetime="1995-01">January 1995</time>. </dd>
<dd></dd>
<dt id="Guard2013">[Guard2013]</dt>
      <dd>
<span>Greenwald, G.</span>, <span>"NSA collecting phone records of millions of Verizon customers daily"</span>, <span>The Guardian</span>, <time datetime="2013-06">June 2013</time>. </dd>
<dd></dd>
<dt id="Headrick1991">[Headrick1991]</dt>
      <dd>
<span>Headrick, D. R.</span>, <span>"The Invisible Weapon: Telecommunications and International Politics, 1851-1945"</span>, <span>Oxford University Press</span>, <time datetime="1991">1991</time>. </dd>
<dd></dd>
<dt id="Johnson1998">[Johnson1998]</dt>
      <dd>
<span>Johnson, T. R.</span>, <span>"American Cryptology During the Cold War, 1945-1989; Book III: Retrenchment and Reform, 1972-1980"</span>, <span>Center for Cryptologic History, NSA</span>, <time datetime="1998">1998</time>, <span>&lt;<a href="https://www.nsa.gov/portals/75/documents/news-features/declassified-documents/cryptologic-histories/cold_war_iii.pdf">https://www.nsa.gov/portals/75/documents/news-features/declassified-documents/cryptologic-histories/cold_war_iii.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Kahn1996">[Kahn1996]</dt>
      <dd>
<span>Kahn, D.</span>, <span>"The Codebreakers: The Comprehensive History of Secret Communication from Ancient Times to the Internet"</span>, <span>2nd Edition</span>, <span>Scribner</span>, <time datetime="1996">1996</time>. </dd>
<dd></dd>
<dt id="Kennedy1971">[Kennedy1971]</dt>
      <dd>
<span>Kennedy, P. M.</span>, <span>"Imperial cable communications and strategy, 1870-1914"</span>, <span>English Historical Review, 86:341, pp. 728-752</span>, <span>Oxford University Press</span>, <time datetime="1971-10">October 1971</time>, <span>&lt;<a href="https://www.jstor.org/stable/563928">https://www.jstor.org/stable/563928</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Kerr2020">[Kerr2020]</dt>
      <dd>
<span>Kerr, O. S.</span>, <span>"Decryption Originalism: The Lessons of Burr"</span>, <span>Harvard Law Review, 134:905</span>, <time datetime="2021-01">January 2021</time>, <span>&lt;<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3533069">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3533069</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Kostyuk2022">[Kostyuk2022]</dt>
      <dd>
<span>Kostyuk, N.</span> and <span>S. Landau</span>, <span>"Dueling over DUAL_EC_DRBG: The Consequences of Corrupting a Cryptographic Standardization Process"</span>, <span>Harvard National Security Journal, 13:2, pp. 224-284</span>, <time datetime="2022-06">June 2022</time>, <span>&lt;<a href="https://www.harvardnsj.org/wp-content/uploads/sites/13/2022/06/Vol13Iss2_Kostyuk-Landau_Dual-EC-DRGB.pdf">https://www.harvardnsj.org/wp-content/uploads/sites/13/2022/06/Vol13Iss2_Kostyuk-Landau_Dual-EC-DRGB.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Landau1988">[Landau1988]</dt>
      <dd>
<span>Landau, S.</span>, <span>"Zero Knowledge and the Department of Defense"</span>, <span>Notices of the American Mathematical Society, 35:1, pp. 5-12</span>, <time datetime="1988-01">January 1988</time>, <span>&lt;<a href="https://privacyink.org/pdf/Zero_Knowledge.pdf">https://privacyink.org/pdf/Zero_Knowledge.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Landau2014">[Landau2014]</dt>
      <dd>
<span>Landau, S.</span>, <span>"Under the Radar: NSA's Efforts to Secure Private-Sector Telecommunications Infrastructure"</span>, <span>Journal of National Security Law &amp; Policy, 7:3</span>, <time datetime="2014-09">September 2014</time>, <span>&lt;<a href="https://jnslp.com/wp-content/uploads/2015/03/NSA%E2%80%99s-Efforts-to-Secure-Private-Sector-Telecommunications-Infrastructure_2.pdf">https://jnslp.com/wp-content/uploads/2015/03/NSA%E2%80%99s-Efforts-to-Secure-Private-Sector-Telecommunications-Infrastructure_2.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="LE">[LE]</dt>
      <dd>
<span>Aas, J.</span>, <span>Barnes, R.</span>, <span>Case, B.</span>, <span>Durumeric, Z.</span>, <span>Eckersley, P.</span>, <span>Flores-López, A.</span>, <span>Halderman, A.</span>, <span>Hoffman-Andrews, J.</span>, <span>Kasten, J.</span>, <span>Rescorla, E.</span>, <span>Schoen, S. D.</span>, and <span>B. Warren</span>, <span>"Let's Encrypt: An Automated Certificate Authority to Encrypt the Entire Web"</span>, <span>CCS '19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security</span>, <time datetime="2019-11">November 2019</time>, <span>&lt;<a href="https://dl.acm.org/doi/pdf/10.1145/3319535.3363192">https://dl.acm.org/doi/pdf/10.1145/3319535.3363192</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Levy2001">[Levy2001]</dt>
      <dd>
<span>Levy, S.</span>, <span>"Crypto: How the Code Rebels Beat the Government-Saving Privacy in the Digital Age"</span>, <span>Penguin Publishing Group</span>, <time datetime="2001-01">January 2001</time>. </dd>
<dd></dd>
<dt id="MADINAS">[MADINAS]</dt>
      <dd>
<span>IETF</span>, <span>"MAC Address Device Identification for Network and Application Services (madinas)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/madinas/about">https://datatracker.ietf.org/wg/madinas/about</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Masnick2023">[Masnick2023]</dt>
      <dd>
<span>Masnick, M.</span>, <span>"The Unintended Consequences of Internet Regulation"</span>, <span>Copia</span>, <time datetime="2023-04">April 2023</time>, <span>&lt;<a href="https://copia.is/library/unintended-consequences/">https://copia.is/library/unintended-consequences/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Miller2020">[Miller2020]</dt>
      <dd>
<span>Miller, G.</span>, <span>"The intelligence coup of the century"</span>, <span>The Washington Post</span>, <time datetime="2020-02">February 2020</time>, <span>&lt;<a href="https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/">https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Moore2015">[Moore2015]</dt>
      <dd>
<span>Moore, H. D.</span>, <span>"CVE-2015-7755: Juniper ScreenOS Authentication Backdoor"</span>, <span>Rapid7</span>, <time datetime="2015-12">December 2015</time>, <span>&lt;<a href="https://www.rapid7.com/blog/post/2015/12/20/cve-2015-7755-juniper-screenos-authentication-backdoor/">https://www.rapid7.com/blog/post/2015/12/20/cve-2015-7755-juniper-screenos-authentication-backdoor/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="I-D.ietf-mpls-opportunistic-encrypt">[MPLS-OPPORTUNISTIC-ENCRYPT]</dt>
      <dd>
<span>Farrel, A.</span> and <span>S. Farrell</span>, <span>"Opportunistic Security in MPLS Networks"</span>, <span>Work in Progress</span>, <span>Internet-Draft, draft-ietf-mpls-opportunistic-encrypt-03</span>, <time datetime="2017-03-28">28 March 2017</time>, <span>&lt;<a href="https://datatracker.ietf.org/doc/html/draft-ietf-mpls-opportunistic-encrypt-03">https://datatracker.ietf.org/doc/html/draft-ietf-mpls-opportunistic-encrypt-03</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Perpass">[Perpass]</dt>
      <dd>
<span>IETF</span>, <span>"perpass mailing list"</span>, <span>&lt;<a href="https://mailarchive.ietf.org/arch/browse/perpass/">https://mailarchive.ietf.org/arch/browse/perpass/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Perpass-BoF">[Perpass-BoF]</dt>
      <dd>
<span>IETF</span>, <span>"perpass BoF -- Handling Pervasive Monitoring in the IETF"</span>, <span>IETF 88 Proceedings</span>, <time datetime="2013-11">November 2013</time>, <span>&lt;<a href="https://www.ietf.org/proceedings/88/perpass.html">https://www.ietf.org/proceedings/88/perpass.html</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Plenary-video">[Plenary-video]</dt>
      <dd>
<span>"IETF 88 Technical Plenary: Hardening The Internet"</span>, <span>YouTube video, 2:37:28, posted by "IETF - Internet Engineering Task Force"</span>, <time datetime="2013-11">November 2013</time>, <span>&lt;<a href="https://www.youtube.com/watch?v=oV71hhEpQ20&amp;pp=ygUQaWV0ZiA4OCBwbGVuYXJ5IA%3D%3D">https://www.youtube.com/watch?v=oV71hhEpQ20&amp;pp=ygUQaWV0ZiA4OCBwbGVuYXJ5IA%3D%3D</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Refs-to-7258">[Refs-to-7258]</dt>
      <dd>
<span>IETF</span>, <span>"References to RFC7258"</span>, <span>&lt;<a href="https://datatracker.ietf.org/doc/rfc7258/referencedby/">https://datatracker.ietf.org/doc/rfc7258/referencedby/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC1984">[RFC1984]</dt>
      <dd>
<span>IAB</span> and <span>IESG</span>, <span>"IAB and IESG Statement on Cryptographic Technology and the Internet"</span>, <span>BCP 200</span>, <span>RFC 1984</span>, <span>DOI 10.17487/RFC1984</span>, <time datetime="1996-08">August 1996</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc1984">https://www.rfc-editor.org/info/rfc1984</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC3365">[RFC3365]</dt>
      <dd>
<span>Schiller, J.</span>, <span>"Strong Security Requirements for Internet Engineering Task Force Standard Protocols"</span>, <span>BCP 61</span>, <span>RFC 3365</span>, <span>DOI 10.17487/RFC3365</span>, <time datetime="2002-08">August 2002</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc3365">https://www.rfc-editor.org/info/rfc3365</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC6462">[RFC6462]</dt>
      <dd>
<span>Cooper, A.</span>, <span>"Report from the Internet Privacy Workshop"</span>, <span>RFC 6462</span>, <span>DOI 10.17487/RFC6462</span>, <time datetime="2012-01">January 2012</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc6462">https://www.rfc-editor.org/info/rfc6462</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7217">[RFC7217]</dt>
      <dd>
<span>Gont, F.</span>, <span>"A Method for Generating Semantically Opaque Interface Identifiers with IPv6 Stateless Address Autoconfiguration (SLAAC)"</span>, <span>RFC 7217</span>, <span>DOI 10.17487/RFC7217</span>, <time datetime="2014-04">April 2014</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7217">https://www.rfc-editor.org/info/rfc7217</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7258">[RFC7258]</dt>
      <dd>
<span>Farrell, S.</span> and <span>H. Tschofenig</span>, <span>"Pervasive Monitoring Is an Attack"</span>, <span>BCP 188</span>, <span>RFC 7258</span>, <span>DOI 10.17487/RFC7258</span>, <time datetime="2014-05">May 2014</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7258">https://www.rfc-editor.org/info/rfc7258</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7480">[RFC7480]</dt>
      <dd>
<span>Newton, A.</span>, <span>Ellacott, B.</span>, and <span>N. Kong</span>, <span>"HTTP Usage in the Registration Data Access Protocol (RDAP)"</span>, <span>STD 95</span>, <span>RFC 7480</span>, <span>DOI 10.17487/RFC7480</span>, <time datetime="2015-03">March 2015</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7480">https://www.rfc-editor.org/info/rfc7480</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7481">[RFC7481]</dt>
      <dd>
<span>Hollenbeck, S.</span> and <span>N. Kong</span>, <span>"Security Services for the Registration Data Access Protocol (RDAP)"</span>, <span>STD 95</span>, <span>RFC 7481</span>, <span>DOI 10.17487/RFC7481</span>, <time datetime="2015-03">March 2015</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7481">https://www.rfc-editor.org/info/rfc7481</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7687">[RFC7687]</dt>
      <dd>
<span>Farrell, S.</span>, <span>Wenning, R.</span>, <span>Bos, B.</span>, <span>Blanchet, M.</span>, and <span>H. Tschofenig</span>, <span>"Report from the Strengthening the Internet (STRINT) Workshop"</span>, <span>RFC 7687</span>, <span>DOI 10.17487/RFC7687</span>, <time datetime="2015-12">December 2015</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7687">https://www.rfc-editor.org/info/rfc7687</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7858">[RFC7858]</dt>
      <dd>
<span>Hu, Z.</span>, <span>Zhu, L.</span>, <span>Heidemann, J.</span>, <span>Mankin, A.</span>, <span>Wessels, D.</span>, and <span>P. Hoffman</span>, <span>"Specification for DNS over Transport Layer Security (TLS)"</span>, <span>RFC 7858</span>, <span>DOI 10.17487/RFC7858</span>, <time datetime="2016-05">May 2016</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7858">https://www.rfc-editor.org/info/rfc7858</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8056">[RFC8056]</dt>
      <dd>
<span>Gould, J.</span>, <span>"Extensible Provisioning Protocol (EPP) and Registration Data Access Protocol (RDAP) Status Mapping"</span>, <span>RFC 8056</span>, <span>DOI 10.17487/RFC8056</span>, <time datetime="2017-01">January 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8056">https://www.rfc-editor.org/info/rfc8056</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8064">[RFC8064]</dt>
      <dd>
<span>Gont, F.</span>, <span>Cooper, A.</span>, <span>Thaler, D.</span>, and <span>W. Liu</span>, <span>"Recommendation on Stable IPv6 Interface Identifiers"</span>, <span>RFC 8064</span>, <span>DOI 10.17487/RFC8064</span>, <time datetime="2017-02">February 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8064">https://www.rfc-editor.org/info/rfc8064</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8280">[RFC8280]</dt>
      <dd>
<span>ten Oever, N.</span> and <span>C. Cath</span>, <span>"Research into Human Rights Protocol Considerations"</span>, <span>RFC 8280</span>, <span>DOI 10.17487/RFC8280</span>, <time datetime="2017-10">October 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8280">https://www.rfc-editor.org/info/rfc8280</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8446">[RFC8446]</dt>
      <dd>
<span>Rescorla, E.</span>, <span>"The Transport Layer Security (TLS) Protocol Version 1.3"</span>, <span>RFC 8446</span>, <span>DOI 10.17487/RFC8446</span>, <time datetime="2018-08">August 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8446">https://www.rfc-editor.org/info/rfc8446</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8461">[RFC8461]</dt>
      <dd>
<span>Margolis, D.</span>, <span>Risher, M.</span>, <span>Ramakrishnan, B.</span>, <span>Brotman, A.</span>, and <span>J. Jones</span>, <span>"SMTP MTA Strict Transport Security (MTA-STS)"</span>, <span>RFC 8461</span>, <span>DOI 10.17487/RFC8461</span>, <time datetime="2018-09">September 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8461">https://www.rfc-editor.org/info/rfc8461</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8484">[RFC8484]</dt>
      <dd>
<span>Hoffman, P.</span> and <span>P. McManus</span>, <span>"DNS Queries over HTTPS (DoH)"</span>, <span>RFC 8484</span>, <span>DOI 10.17487/RFC8484</span>, <time datetime="2018-10">October 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8484">https://www.rfc-editor.org/info/rfc8484</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8981">[RFC8981]</dt>
      <dd>
<span>Gont, F.</span>, <span>Krishnan, S.</span>, <span>Narten, T.</span>, and <span>R. Draves</span>, <span>"Temporary Address Extensions for Stateless Address Autoconfiguration in IPv6"</span>, <span>RFC 8981</span>, <span>DOI 10.17487/RFC8981</span>, <time datetime="2021-02">February 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8981">https://www.rfc-editor.org/info/rfc8981</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9000">[RFC9000]</dt>
      <dd>
<span>Iyengar, J., Ed.</span> and <span>M. Thomson, Ed.</span>, <span>"QUIC: A UDP-Based Multiplexed and Secure Transport"</span>, <span>RFC 9000</span>, <span>DOI 10.17487/RFC9000</span>, <time datetime="2021-05">May 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9000">https://www.rfc-editor.org/info/rfc9000</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9082">[RFC9082]</dt>
      <dd>
<span>Hollenbeck, S.</span> and <span>A. Newton</span>, <span>"Registration Data Access Protocol (RDAP) Query Format"</span>, <span>STD 95</span>, <span>RFC 9082</span>, <span>DOI 10.17487/RFC9082</span>, <time datetime="2021-06">June 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9082">https://www.rfc-editor.org/info/rfc9082</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9083">[RFC9083]</dt>
      <dd>
<span>Hollenbeck, S.</span> and <span>A. Newton</span>, <span>"JSON Responses for the Registration Data Access Protocol (RDAP)"</span>, <span>STD 95</span>, <span>RFC 9083</span>, <span>DOI 10.17487/RFC9083</span>, <time datetime="2021-06">June 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9083">https://www.rfc-editor.org/info/rfc9083</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9113">[RFC9113]</dt>
      <dd>
<span>Thomson, M., Ed.</span> and <span>C. Benfield, Ed.</span>, <span>"HTTP/2"</span>, <span>RFC 9113</span>, <span>DOI 10.17487/RFC9113</span>, <time datetime="2022-06">June 2022</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9113">https://www.rfc-editor.org/info/rfc9113</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9224">[RFC9224]</dt>
      <dd>
<span>Blanchet, M.</span>, <span>"Finding the Authoritative Registration Data Access Protocol (RDAP) Service"</span>, <span>STD 95</span>, <span>RFC 9224</span>, <span>DOI 10.17487/RFC9224</span>, <time datetime="2022-03">March 2022</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9224">https://www.rfc-editor.org/info/rfc9224</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Roth2022">[Roth2022]</dt>
      <dd>
<span>Roth, E.</span>, <span>"Internet backbone provider shuts off service in Russia"</span>, <span>The Verge</span>, <time datetime="2022-03">March 2022</time>, <span>&lt;<a href="https://www.theverge.com/2022/3/5/22962822/internet-backbone-provider-cogent-shuts-off-service-russia">https://www.theverge.com/2022/3/5/22962822/internet-backbone-provider-cogent-shuts-off-service-russia</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Rowlett1998">[Rowlett1998]</dt>
      <dd>
<span>Rowlett, F. B.</span>, <span>"The Story of Magic, Memoirs of an American Cryptologic Pioneer"</span>, <span>Aegean Park Press</span>, <time datetime="1998">1998</time>. </dd>
<dd></dd>
<dt id="Slater1870">[Slater1870]</dt>
      <dd>
<span>Slater, R.</span>, <span>"Telegraphic Code, to Ensure Secresy in the Transmission of Telegrams"</span>, <span>First Edition</span>, <span>W.R. Gray</span>, <time datetime="1870">1870</time>, <span>&lt;<a href="https://books.google.com/books?id=MJYBAAAAQAAJ">https://books.google.com/books?id=MJYBAAAAQAAJ</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Smith1845">[Smith1845]</dt>
      <dd>
<span>Smith, F. O.</span>, <span>"The Secret Corresponding Vocabulary: Adapted for Use to Morse's Electro-Magnetic Telegraph, and Also in Conducting Written Correspondence, Transmitted by the Mails, or Otherwise"</span>, <span>Thurston, Isley &amp; Company</span>, <time datetime="1845">1845</time>, <span>&lt;<a href="https://books.google.com/books?id=Z45clCxsF7EC">https://books.google.com/books?id=Z45clCxsF7EC</a>&gt;</span>. </dd>
<dd></dd>
<dt id="STRINT">[STRINT]</dt>
      <dd>
<span>W3C</span> and <span>IAB</span>, <span>"A W3C/IAB workshop on Strengthening the Internet Against Pervasive Monitoring (STRINT)"</span>, <time datetime="2014-03">March 2014</time>, <span>&lt;<a href="https://www.w3.org/2014/strint/">https://www.w3.org/2014/strint/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Timeline">[Timeline]</dt>
      <dd>
<span>Wikipedia</span>, <span>"Global surveillance disclosures (2013-present)"</span>, <time datetime="2023-07">July 2023</time>, <span>&lt;<a href="https://en.wikipedia.org/w/index.php?title=Global_surveillance_disclosures_(2013%E2%80%93present)&amp;oldid=1161557819">https://en.wikipedia.org/w/index.php?title=Global_surveillance_disclosures_(2013%E2%80%93present)&amp;oldid=1161557819</a>&gt;</span>. </dd>
<dd></dd>
<dt id="I-D.ietf-tls-esni">[TLS-ECH]</dt>
      <dd>
<span>Rescorla, E.</span>, <span>Oku, K.</span>, <span>Sullivan, N.</span>, and <span>C. A. Wood</span>, <span>"TLS Encrypted Client Hello"</span>, <span>Work in Progress</span>, <span>Internet-Draft, draft-ietf-tls-esni-16</span>, <time datetime="2023-04-06">6 April 2023</time>, <span>&lt;<a href="https://datatracker.ietf.org/doc/html/draft-ietf-tls-esni-16">https://datatracker.ietf.org/doc/html/draft-ietf-tls-esni-16</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Toronto">[Toronto]</dt>
      <dd>
<span>Memmott, M.</span>, <span>"Canada Used Airport Wi-Fi To Track Travelers, Snowden Leak Alleges"</span>, <span>NPR</span>, <time datetime="2014-01">January 2014</time>, <span>&lt;<a href="https://www.npr.org/sections/thetwo-way/2014/01/31/269418375/airport-wi-fi-used-to-track-travelers-snowden-leak-alleges">https://www.npr.org/sections/thetwo-way/2014/01/31/269418375/airport-wi-fi-used-to-track-travelers-snowden-leak-alleges</a>&gt;</span>. </dd>
<dd></dd>
<dt id="UTA">[UTA]</dt>
      <dd>
<span>IETF</span>, <span>"Using TLS in Applications (uta)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/uta/about">https://datatracker.ietf.org/wg/uta/about</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Zubhoff2019">[Zubhoff2019]</dt>
    <dd>
<span>Zuboff, S.</span>, <span>"The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power"</span>, <span>PublicAffairs</span>, <span>ISBN 9781781256855</span>, <time datetime="2019-01">January 2019</time>. </dd>
<dd></dd>
</dl>
</section>
<section id="acknowledgments">
      <h2 id="name-acknowledgments">
<a href="#name-acknowledgments">Acknowledgments</a>
      </h2>
<p id="appendix-A-1"><span>Susan Landau</span> added many valuable comments to <span>Steve Bellovin</span>'s essay.<a href="#appendix-A-1">¶</a></p>
<p id="appendix-A-2">We thank <span>Carsten Bormann</span>, <span>Brian Carpenter</span>, <span>Wendy Grossman</span>, <span>Kathleen Moriarty</span>,
<span>Jan Schaumann</span>, <span>Seth David Schoen</span>, and <span>Paul Wouters</span> for comments and review of this text, though
that of course doesn't mean that they necessarily agree with the text.<a href="#appendix-A-2">¶</a></p>
<p id="appendix-A-3">This document was created at the behest of <span>Eliot Lear</span>, who also 
cat herded and did some editing.<a href="#appendix-A-3">¶</a></p>
</section>
<section id="authors-addresses">
      <h2 id="name-authors-addresses">
<a href="#name-authors-addresses">Authors' Addresses</a>
      </h2>
<address>
        <p><span>Stephen Farrell</span></p>
<p><span>Trinity College, Dublin</span></p>
<p><span>Ireland</span></p>

</address>
<address>
        <p><span>Farzaneh Badii</span></p>
<p><span>Digital Medusa</span></p>

</address>
<address>
        <p><span>Bruce Schneier</span></p>
<p><span>Harvard University</span></p>
<p><span>United States of America</span></p>

</address>
<address>
        <p><span>Steven M. Bellovin</span></p>
<p><span>Columbia University</span></p>
<p><span>United States of America</span></p>

</address>
</section>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Squeeze the hell out of the system you have (455 pts)]]></title>
            <link>https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/#like-2777</link>
            <guid>37091983</guid>
            <pubDate>Fri, 11 Aug 2023 18:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/#like-2777">https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/#like-2777</a>, See on <a href="https://news.ycombinator.com/item?id=37091983">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2777">
	<div>
			
<p>About a year ago, I raised a red flag with colleagues and managers about Postgres performance. Our database was struggling to keep up with the load generated by our monolithic SaaS application. CPU utilization was riding between 60 and 80%, and at least once it spiked to 100%, causing a brief outage.</p>



<p>Now, we had been kicking the can down the road with respect to Postgres capacity for a long time. When the database looked too busy, we’d replace it with a bigger instance and move on. This saved us a lot of time and allowed us to focus on other things, like building features, which was great.</p>



<p>But this time, it wasn’t possible to scale the DB server vertically: we were already on the biggest instance. And we were about to overload that instance.</p>



<p>Lots of schemes were floated. Foremost among them:</p>



<ul>
<li><strong>Shard writes.</strong> Spin up a cluster of independent databases, and write data to one or the other according to some partitioning strategy.</li>



<li><strong>Do micro-services.</strong> Split up the monolith into multiple interconnected services, each with its own data store that could be scaled on its own terms.</li>
</ul>



<p>Both of these options are cool! A strong case can be made for either one on its merits. With write sharding, we could potentially increase our capacity by 2 or even 3 orders of magnitude. With micro-services, we’d be free to use “the right tool for the job,” picking data stores optimized to the requirements of each service workload. Either branch of the skill tree would offer exciting options for fault tolerance and operational resilience.</p>



<p>Either way, everyone had to agree: we’d outgrown our old, naïve implementation. Onward and upward! We can do hard things!</p>



<p>In situations like this, presented with a dazzling array of next-generation architecture options that can be built to last us through the decade, it’s easy to forget what our goal was: to get database performance under control.</p>



<h2>Complexity costs attention.</h2>



<p>Sometimes, leaps in complexity must be made. It’s generally a good problem to have. If enough demand is being placed on your system to render obsolete your existing technology, then even more growth is probably on the horizon! If you can just put in the investment and build the more advanced architecture now, then you’ll be looking at a bright future of unconstrained year-over-year success.</p>



<p>But don’t just consider the implementation cost. The real cost of increased complexity – often the much larger cost – is attention.</p>



<p>If you decide to shard across databases, then not only must you pay the money-, time-, and opportunity cost of building out the new architecture: <em>you must also take the new complexity into account in every subsequent technical decision</em>. Want to shard writes? Fine, but this complicates every future decision about backups, monitoring, migrations, the ORM, and network topology (just to name a few). And don’t get me started on micro-services.</p>



<p>Just think about how massive these costs are. How much feature delivery will have to be delayed or foregone to support the additional architectural complexity?</p>



<h2>Always squeeze first</h2>



<p>We should always put off significant complexity increases as long as possible.</p>



<p>When complexity leaps are on the table, there’s usually also an opportunity to <strong>squeeze</strong> some extra juice out of the system you have. By tweaking the workload, tuning performance, or supplementing the system in some way, you may be able to add months or even years of runway. When viable, these options are always preferable to building out a next-gen system.</p>



<p>Let’s return to the example of the overloaded Postgres instance. In that case, what we ended up doing was twofold:</p>



<ol>
<li>Two engineers (me and my colleague Ted – but mostly Ted) spent about 3 months working primarily on database performance issues. There was no silver bullet. We used our telemetry to identify heavy queries, dug into the (Rails) codebase to understand where they were coming from, and optimized or eliminated them. We also tuned a lot of Postgres settings.</li>



<li>Two more engineers cut a path through the codebase to run certain expensive read-only queries on a replica DB. This effort bore fruit around the same time as (1), when we offloaded our single most frequent query (a <code>SELECT</code> triggered by polling web clients).</li>
</ol>



<p>These two efforts together reduced the maximum weekly CPU usage on the database from 90% to 30%.</p>



<p>Now we can sleep at night. We have a huge amount of room to grow, both in terms of CPU headroom and our ability to shed load from the primary. And furthermore, since our work touched many parts of the codebase and demanded collaboration with lots of different devs, we now have a strong distributed knowledge base about the existing system. We’re well positioned to squeeze it even more if need be.</p>



<h2>This doesn’t mean complexity is bad</h2>



<p>Of course, I’m not saying complexity is bad. It’s necessary. Some day we’ll reach a fundamental limit of our database architecture, and before that day arrives, we’ll need to make a jump in complexity.</p>



<p>But until then, because we <strong>squeezed first</strong>, we get to keep working with the most boring system possible. This is by far the cheaper and more practical option.</p>
					</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infisical – open-source HashiCorp Vault alternative (226 pts)]]></title>
            <link>https://github.com/Infisical/infisical</link>
            <guid>37090754</guid>
            <pubDate>Fri, 11 Aug 2023 16:44:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Infisical/infisical">https://github.com/Infisical/infisical</a>, See on <a href="https://news.ycombinator.com/item?id=37090754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Infisical/infisical/blob/main/img/logoname-black.svg#gh-light-mode-only"><img width="300" src="https://github.com/Infisical/infisical/raw/main/img/logoname-black.svg#gh-light-mode-only" alt="infisical"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Infisical/infisical/blob/main/img/logoname-white.svg#gh-dark-mode-only"><img width="300" src="https://github.com/Infisical/infisical/raw/main/img/logoname-white.svg#gh-dark-mode-only" alt="infisical"></a>
</h2>
<p dir="auto"><b>Open-source, end-to-end encrypted secret management platform</b>: distribute secrets/configs across your team/infrastructure and prevent secret leaks.</p>

<h4 tabindex="-1" dir="auto">
  <a href="https://infisical.com/slack" rel="nofollow">Slack</a> |
  <a href="https://infisical.com/" rel="nofollow">Infisical Cloud</a> |
  <a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow">Self-Hosting</a> |
  <a href="https://infisical.com/docs/documentation/getting-started/introduction" rel="nofollow">Docs</a> |
  <a href="https://www.infisical.com/" rel="nofollow">Website</a>
</h4>
<p dir="auto">
  <a href="https://infisical.com/docs/self-hosting/deployment-options/aws-ec2" rel="nofollow">
    <img src="https://github.com/Infisical/infisical/raw/main/.github/images/deploy-to-aws.png" width="137">
  </a>
  <a href="https://infisical.com/docs/self-hosting/deployment-options/digital-ocean-marketplace" alt="Deploy to DigitalOcean" rel="nofollow">
     <img width="200" alt="Deploy to DO" src="https://camo.githubusercontent.com/df21703b4229f8d44f76c2d56073657a4ab450ca4566ba5d24d05bf528c298f8/68747470733a2f2f7777772e6465706c6f79746f646f2e636f6d2f646f2d62746e2d626c75652e737667" data-canonical-src="https://www.deploytodo.com/do-btn-blue.svg">
  </a>
</p>
<h4 tabindex="-1" dir="auto">
  <a href="https://github.com/Infisical/infisical/blob/main/LICENSE">
    <img src="https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667" alt="Infisical is released under the MIT license." data-canonical-src="https://img.shields.io/badge/license-MIT-blue.svg">
  </a>
  <a href="https://github.com/infisical/infisical/blob/main/CONTRIBUTING.md">
    <img src="https://camo.githubusercontent.com/f9c5499f3a5e5a9516b9c40e700535d96426dd0dc32b3f4ba64164d87807ba2a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d57656c636f6d652d627269676874677265656e" alt="PRs welcome!" data-canonical-src="https://img.shields.io/badge/PRs-Welcome-brightgreen">
  </a>
  <a href="https://github.com/Infisical/infisical/issues">
    <img src="https://camo.githubusercontent.com/bbadcfc720476057ff7a528009bffd6245d516f7f6df853244b001deae6d1149/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f696e6669736963616c2f696e6669736963616c" alt="git commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/m/infisical/infisical">
  </a>
  <a href="https://cloudsmith.io/~infisical/repos/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/b990261c2dc971d42e655715009b43ee925f6836e4387cd2dd89cc6bdcdc918f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f776e6c6f6164732d3832312e386b2d6f72616e6765" alt="Cloudsmith downloads" data-canonical-src="https://img.shields.io/badge/Downloads-821.8k-orange">
  </a>
  <a href="https://infisical.com/slack" rel="nofollow">
    <img src="https://camo.githubusercontent.com/7b4b98387d228c64f516f16aed0674b7b9c3a32eb46e12504c51ab2777d6ab76/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230536c61636b2d626c756576696f6c6574" alt="Slack community channel" data-canonical-src="https://img.shields.io/badge/chat-on%20Slack-blueviolet">
  </a>
  <a href="https://twitter.com/infisical" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6ac3a29a944d2e32a8e0b0017a8d0b9365d9c4a32417380a105147165ab8d6b2/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f696e6669736963616c3f6c6162656c3d466f6c6c6f77" alt="Infisical Twitter" data-canonical-src="https://img.shields.io/twitter/follow/infisical?label=Follow">
  </a>
</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Infisical/infisical/blob/main/img/infisical_github_repo.png"><img src="https://github.com/Infisical/infisical/raw/main/img/infisical_github_repo.png" width="100%" alt="Dashboard"></a></p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto"><strong><a href="https://infisical.com/" rel="nofollow">Infisical</a></strong> is an open source, end-to-end encrypted secret management platform that teams use to centralize their secrets like API keys, database credentials, and configurations.</p>
<p dir="auto">We're on a mission to make secret management more accessible to everyone, not just security teams, and that means redesigning the entire developer experience from ground up.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li><strong><a href="https://infisical.com/docs/documentation/platform/project" rel="nofollow">User-friendly dashboard</a></strong> to manage secrets across projects and environments (e.g. development, production, etc.)</li>
<li><strong><a href="https://infisical.com/docs/sdks/overview" rel="nofollow">Client SDKs</a></strong> to fetch secrets for your apps and infrastructure on demand</li>
<li><strong><a href="https://infisical.com/docs/cli/overview" rel="nofollow">Infisical CLI</a></strong> to fetch and inject secrets into any framework in local development</li>
<li><strong><a href="https://infisical.com/docs/integrations/overview" rel="nofollow">Native integrations</a></strong> with platforms like GitHub, Vercel, Netlify, and more</li>
<li><a href="https://infisical.com/docs/documentation/getting-started/kubernetes" rel="nofollow"><strong>Automatic Kubernetes deployment secret reloads</strong></a></li>
<li><strong><a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow">Complete control over your data</a></strong> - host it yourself on any infrastructure</li>
<li><strong><a href="https://infisical.com/docs/documentation/platform/secret-versioning" rel="nofollow">Secret versioning</a></strong> and <strong><a href="https://github.com/Infisical/infisical/blob/main">Point-in-Time Recovery</a></strong> to version every secret and project state</li>
<li><strong><a href="https://infisical.com/docs/documentation/platform/audit-logs" rel="nofollow">Audit logs</a></strong> to record every action taken in a project</li>
<li><strong>Role-based Access Controls</strong> per environment</li>
<li><a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow"><strong>Simple on-premise deployments</strong> to AWS, Digital Ocean, and more</a></li>
<li><a href="https://infisical.com/docs/cli/scanning-overview" rel="nofollow"><strong>Secret Scanning and Leak Prevention</strong></a></li>
</ul>
<p dir="auto">And much more.</p>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">Check out the <a href="https://infisical.com/docs/getting-started/introduction" rel="nofollow">Quickstart Guides</a></p>
<table>
<thead>
<tr>
<th>Use Infisical Cloud</th>
<th>Deploy Infisical on premise</th>
</tr>
</thead>
<tbody>
<tr>
<td>The fastest and most reliable way to <br> get started with Infisical is signing up <br> for free to <a href="https://app.infisical.com/login" rel="nofollow">Infisical Cloud</a>.</td>
<td><a href="https://infisical.com/docs/self-hosting/deployment-options/aws-ec2" rel="nofollow"><img src="https://github.com/Infisical/infisical/raw/main/.github/images/deploy-to-aws.png" width="150"></a> <a href="https://infisical.com/docs/self-hosting/deployment-options/digital-ocean-marketplace" alt="Deploy to DigitalOcean" rel="nofollow"> <img width="217" alt="Deploy to DO" src="https://camo.githubusercontent.com/df21703b4229f8d44f76c2d56073657a4ab450ca4566ba5d24d05bf528c298f8/68747470733a2f2f7777772e6465706c6f79746f646f2e636f6d2f646f2d62746e2d626c75652e737667" data-canonical-src="https://www.deploytodo.com/do-btn-blue.svg"> </a> <br> View all <a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow">deployment options</a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">Run Infisical locally</h3>
<p dir="auto">To set up and run Infisical locally, make sure you have Git and Docker installed on your system. Then run the command for your system:</p>
<p dir="auto">Linux/macOS:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Infisical/infisical &amp;&amp; cd &quot;$(basename $_ .git)&quot; &amp;&amp; cp .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up"><pre><span>git clone https://github.com/Infisical/infisical &amp;&amp; cd "$(basename $_ .git)" &amp;&amp; cp .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up</span></pre></div>
<p dir="auto">Windows Command Prompt:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Infisical/infisical &amp;&amp; cd infisical &amp;&amp; copy .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up"><pre><span>git clone https://github.com/Infisical/infisical &amp;&amp; cd infisical &amp;&amp; copy .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up</span></pre></div>
<p dir="auto">Create an account at <code>http://localhost:80</code></p>
<h3 tabindex="-1" dir="auto">Scan and prevent secret leaks</h3>
<p dir="auto">On top managing secrets with Infisical, you can also <a href="https://github.com/Infisical/infisical/blob/main">scan for over 140+ secret types</a> in your files, directories and git repositories.</p>
<p dir="auto">To scan your full git history, run:</p>

<p dir="auto">Install pre commit hook to scan each commit before you push to your repository</p>
<div data-snippet-clipboard-copy-content="infisical scan install --pre-commit-hook"><pre><code>infisical scan install --pre-commit-hook
</code></pre></div>
<p dir="auto">Lean about Infisical's code scanning feature <a href="https://infisical.com/docs/cli/scanning-overview" rel="nofollow">here</a></p>
<h2 tabindex="-1" dir="auto">Open-source vs. paid</h2>
<p dir="auto">This repo available under the <a href="https://github.com/Infisical/infisical/blob/main/LICENSE">MIT expat license</a>, with the exception of the <code>ee</code> directory which will contain premium enterprise features requiring a Infisical license.</p>
<p dir="auto">If you are interested in managed Infisical Cloud of self-hosted Enterprise Offering, take a look at <a href="https://infisical.com/" rel="nofollow">our webiste</a> or <a href="https://cal.com/vmatsiiako/infisical-demo" rel="nofollow">book a meeting with us</a>:</p>
<p dir="auto"><a href="https://cal.com/vmatsiiako/infisical-demo" rel="nofollow"><img alt="Schedule a meeting" src="https://camo.githubusercontent.com/6bea259f3d52a136dc4c575ef7f30191ca3b508688c170e6a4363410324fce05/68747470733a2f2f63616c2e636f6d2f626f6f6b2d776974682d63616c2d6461726b2e737667" data-canonical-src="https://cal.com/book-with-cal-dark.svg"></a></p>
<h2 tabindex="-1" dir="auto">Security</h2>
<p dir="auto">Please do not file GitHub issues or post on our public forum for security vulnerabilities, as they are public!</p>
<p dir="auto">Infisical takes security issues very seriously. If you have any concerns about Infisical or believe you have uncovered a vulnerability, please get in touch via the e-mail address <a href="mailto:security@infisical.com">security@infisical.com</a>. In the message, try to provide a description of the issue and ideally a way of reproducing it. The security team will get back to you as soon as possible.</p>
<p dir="auto">Note that this security address should be used only for undisclosed vulnerabilities. Please report any security problems to us before disclosing it publicly.</p>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">Whether it's big or small, we love contributions. Check out our guide to see how to <a href="https://infisical.com/docs/contributing/overview" rel="nofollow">get started</a>.</p>
<p dir="auto">Not sure where to get started? You can:</p>
<ul dir="auto">
<li><a href="https://cal.com/tony-infisical/30-min-meeting-contributing" rel="nofollow">Book a free, non-pressure pairing session / code walkthrough with one of our teammates</a>!</li>
<li>Join our <a href="https://infisical.com/slack" rel="nofollow">Slack</a>, and ask us any questions there.</li>
<li>Join our <a href="https://us06web.zoom.us/j/82623506356" rel="nofollow">community calls</a> every Wednesday at 11am EST to ask any questions, provide feedback, hangout and more.</li>
</ul>
<h2 tabindex="-1" dir="auto">Resources</h2>
<ul dir="auto">
<li><a href="https://infisical.com/docs/documentation/getting-started/introduction" rel="nofollow">Docs</a> for comprehensive documentation and guides</li>
<li><a href="https://infisical.com/slack" rel="nofollow">Slack</a> for discussion with the community and Infisical team.</li>
<li><a href="https://github.com/Infisical/infisical">GitHub</a> for code, issues, and pull requests</li>
<li><a href="https://twitter.com/infisical" rel="nofollow">Twitter</a> for fast news</li>
<li><a href="https://www.youtube.com/@infisical_os" rel="nofollow">YouTube</a> for videos on secret management</li>
<li><a href="https://infisical.com/blog" rel="nofollow">Blog</a> for secret management insights, articles, tutorials, and updates</li>
<li><a href="https://www.notion.so/infisical/be2d2585a6694e40889b03aef96ea36b?v=5b19a8127d1a4060b54769567a8785fa" rel="nofollow">Roadmap</a> for planned features</li>
</ul>
<h2 tabindex="-1" dir="auto">Acknowledgements</h2>



<p dir="auto"><a href="https://github.com/dangtony98"><img src="https://avatars.githubusercontent.com/u/25857006?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/maidul98"><img src="https://avatars.githubusercontent.com/u/9300960?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/akhilmhdh"><img src="https://avatars.githubusercontent.com/u/31166322?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/reginaldbondoc"><img src="https://avatars.githubusercontent.com/u/7693108?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/mv-turtle"><img src="https://avatars.githubusercontent.com/u/78047717?s=96&amp;v=4" width="50" height="50" alt=""></a> <a href="https://github.com/gangjun06"><img src="https://avatars.githubusercontent.com/u/50910815?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/asheliahut"><img src="https://avatars.githubusercontent.com/u/945619?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/SH5H"><img src="https://avatars.githubusercontent.com/u/25437192?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/gmgale"><img src="https://avatars.githubusercontent.com/u/62303146?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/asharonbaltazar"><img src="https://avatars.githubusercontent.com/u/58940073?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/JoaoVictor6"><img src="https://avatars.githubusercontent.com/u/68869379?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/mocherfaoui"><img src="https://avatars.githubusercontent.com/u/37941426?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/cerrussell"><img src="https://avatars.githubusercontent.com/u/80227828?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/jon4hz"><img src="https://avatars.githubusercontent.com/u/26183582?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/edgarrmondragon"><img src="https://avatars.githubusercontent.com/u/16805946?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/arjunyel"><img src="https://avatars.githubusercontent.com/u/11153289?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/LemmyMwaura"><img src="https://avatars.githubusercontent.com/u/20738858?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Zamion101"><img src="https://avatars.githubusercontent.com/u/8071263?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Grraahaam"><img src="https://avatars.githubusercontent.com/u/72856427?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Neeraj138"><img src="https://avatars.githubusercontent.com/u/58552561?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/esau-morais"><img src="https://avatars.githubusercontent.com/u/55207584?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/animeshdas2000"><img src="https://avatars.githubusercontent.com/u/40542456?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/umrak11"><img src="https://avatars.githubusercontent.com/u/20104948?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/KunalSin9h"><img src="https://avatars.githubusercontent.com/u/82411321?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/ImBIOS"><img src="https://avatars.githubusercontent.com/u/41441643?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/sanyamjain04"><img src="https://avatars.githubusercontent.com/u/107163858?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Gabriellopes232"><img src="https://avatars.githubusercontent.com/u/74881862?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/naorpeled"><img src="https://avatars.githubusercontent.com/u/6171622?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Aashish-Upadhyay-101"><img src="https://avatars.githubusercontent.com/u/81024263?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/jonerrr"><img src="https://avatars.githubusercontent.com/u/73760377?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/kmlgkcy"><img src="https://avatars.githubusercontent.com/u/102428035?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/samsbg"><img src="https://avatars.githubusercontent.com/u/70488844?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/imakecodes"><img src="https://avatars.githubusercontent.com/u/35536648?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/bngmnn"><img src="https://avatars.githubusercontent.com/u/88746983?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/kimcore"><img src="https://avatars.githubusercontent.com/u/36142378?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/caioluis"><img src="https://avatars.githubusercontent.com/u/30005368?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/alisson-acioli"><img src="https://avatars.githubusercontent.com/u/12742051?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/adrianmarinwork"><img src="https://avatars.githubusercontent.com/u/118568289?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/arthurzenika"><img src="https://avatars.githubusercontent.com/u/445200?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/franky47"><img src="https://avatars.githubusercontent.com/u/1174092?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/hanywang2"><img src="https://avatars.githubusercontent.com/u/44352119?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/tobias-mintlify"><img src="https://avatars.githubusercontent.com/u/110702161?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/wjhurley"><img src="https://avatars.githubusercontent.com/u/15939055?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/alexdanilowicz"><img src="https://avatars.githubusercontent.com/u/29822597?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/0xflotus"><img src="https://avatars.githubusercontent.com/u/26602940?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/wanjohiryan"><img src="https://avatars.githubusercontent.com/u/71614375?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/nirga"><img src="https://avatars.githubusercontent.com/u/4224692?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/RashidUjang"><img src="https://avatars.githubusercontent.com/u/11313829?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/kanhaiya38"><img src="https://avatars.githubusercontent.com/u/54778773?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/HasanMansoor4"><img src="https://avatars.githubusercontent.com/u/68682354?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/jerriclynsjohn"><img src="https://avatars.githubusercontent.com/u/3236669?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/eltociear"><img src="https://avatars.githubusercontent.com/u/22633385?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/MatthewJohn"><img src="https://avatars.githubusercontent.com/u/1266262?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/sheensantoscapadngan"><img src="https://avatars.githubusercontent.com/u/65645666?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/yoobato"><img src="https://avatars.githubusercontent.com/u/1592319?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/xinity"><img src="https://avatars.githubusercontent.com/u/1799009?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/simonemargio"><img src="https://avatars.githubusercontent.com/u/22590804?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Aqib-Rime"><img src="https://avatars.githubusercontent.com/u/116422706?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/ha-sante"><img src="https://avatars.githubusercontent.com/u/90225652?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/5h4k4r"><img src="https://avatars.githubusercontent.com/u/56171149?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/quinton11"><img src="https://avatars.githubusercontent.com/u/70300837?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/afrieirham"><img src="https://avatars.githubusercontent.com/u/32460534?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/Stijn-Kuijper"><img src="https://avatars.githubusercontent.com/u/25306980?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/atimapreandrew"><img src="https://avatars.githubusercontent.com/u/60506711?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/satyamgupta1495"><img src="https://avatars.githubusercontent.com/u/51158766?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/RezaRahemtola"><img src="https://avatars.githubusercontent.com/u/49811529?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/JunedKhan101"><img src="https://avatars.githubusercontent.com/u/47941768?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/unkletayo"><img src="https://avatars.githubusercontent.com/u/48031746?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/agoodman1999"><img src="https://avatars.githubusercontent.com/u/113685729?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/Spelchure"><img src="https://avatars.githubusercontent.com/u/20704539?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/piyushchhabra"><img src="https://avatars.githubusercontent.com/u/12864227?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/PylotLight"><img src="https://avatars.githubusercontent.com/u/7006124?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/jorgeteixe"><img src="https://avatars.githubusercontent.com/u/45232371?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/chisom5"><img src="https://avatars.githubusercontent.com/u/22566806?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/zwkee"><img src="https://avatars.githubusercontent.com/u/109659187?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/raykeating"><img src="https://avatars.githubusercontent.com/u/29098307?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/khoa165"><img src="https://avatars.githubusercontent.com/u/46258781?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/pgaijin66"><img src="https://avatars.githubusercontent.com/u/8869096?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/Budhathoki356"><img src="https://avatars.githubusercontent.com/u/53488484?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/mswider"><img src="https://avatars.githubusercontent.com/u/37093293?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/parthvnp"><img src="https://avatars.githubusercontent.com/u/41171860?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/seonggwonyoon"><img src="https://avatars.githubusercontent.com/u/37574822?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/ChukwunonsoFrank"><img src="https://avatars.githubusercontent.com/u/62689166?v=4" width="50" height="50" alt=""></a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine-Tuning Llama-2: A Comprehensive Case Study for Tailoring Custom Models (244 pts)]]></title>
            <link>https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications</link>
            <guid>37090632</guid>
            <pubDate>Fri, 11 Aug 2023 16:34:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications">https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications</a>, See on <a href="https://news.ycombinator.com/item?id=37090632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><i>In this blog, we provide a thorough analysis and a practical guide for fine-tuning. We examine the Llama-2 models under three real-world use cases, and show that fine-tuning yields significant accuracy improvements across the board (in some niche cases, better than GPT-4). Experiments were carried out with this </i><a href="https://github.com/ray-project/ray/tree/master/doc/source/templates/04_finetuning_llms_with_deepspeed"><i><u>script</u></i></a><i>.</i></p><p>Large open language models have made significant progress in recent months, paving the way for commercially viable solutions that are suitable for enterprise applications. Notable among these are the Llama-2 and Falcon models. While powerful generalist language models like GPT-4 and Claude-2 provide quick access and rapid turnaround for projects, they often end up being an overkill for the requirements of many applications.</p><p>As an example, if the goal is to summarize support tickets and categorize issues into predetermined buckets, there's no need for a model capable of generating prose in the style of Shakespeare. Setting security concerns aside, employing GPT-4 for such tasks is akin to using a space shuttle for a cross-town commute. To support this claim, we study fine-tuning the Llama-2 model of various sizes on three tasks:&nbsp;</p><ul><li><p>Functional representations extracted from unstructured text (<a href="https://huggingface.co/datasets/GEM/viggo"><u>ViGGO</u></a>)</p></li><li><p>SQL generation (<a href="https://huggingface.co/datasets/b-mc2/sql-create-context"><u>SQL-create-context</u></a>)</p></li><li><p>Grade-school math question-answering (<a href="https://huggingface.co/datasets/gsm8k"><u>GSM8k</u></a>)</p></li></ul><p>We specifically show how on some tasks (e.g. SQL Gen or Functional Representation) we can fine-tune small Llama-2 models to become even better than GPT-4. At the same time, there are tasks like math reasoning and understanding that OSS models are just behind even after significant gains obtained by fine-tuning.</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/6jANVvQ0XG2OBFaJ82A4Rb/530191ff406a0bfae0aac04907348e97/Llama_2_models_performance_chart.png" alt="Llama 2 performance"></p></div><p><i>The performance gain of Llama-2 models obtained via fine-tuning on each task. The darker shade for each of the colors indicate the performance of the Llama-2-chat models with a baseline prompt. The purple shows the performance of GPT-4 with the same prompt. The stacked bar plots show the performance gain from fine-tuning the Llama-2 base models. In Functional representation and SQL gen tasks with fine-tuning we can achieve better performance than GPT-4 while on some other task like math reasoning, fine-tuned models, while improving over the base models, are still not able to reach GPT-4’s performance levels.</i></p><p>In particular we show that with the Llama-13b variant we observed an increase in accuracy from, 58% to 98% on functional representations, 42% to 89% on SQL generation, and 28% to 47% on GSM. All of these experiments are done using Anyscale fine-tuning and serving platforms as offered as part of <a href="https://app.endpoints.anyscale.com/"><u>Anyscale Endpoints</u></a>.&nbsp;</p><p>In addition to providing more quantitative results, this blog post will present a technical deep-dive into how you can leverage Llama-2 models for specialized tasks. We will discuss the correct problem formulation, the setup of evaluation pipelines, and much more. We will compare methods such as prompt-engineering &amp; few-shot prompting with fine-tuning, providing concrete pros and cons of each method along the way.</p><p>Fine-tuning these models is not a straightforward task. However, <a href="http://github.com/ray-project/ray"><u>Ray</u></a> and <a href="https://anyscale.com/"><u>Anyscale</u></a> offer unique capabilities that make this process faster, cheaper, and more manageable. Our mission is to enable enterprises to harness the latest advancements in AI as swiftly as possible.</p><p>We hope that the details covered in this post can help others elicit more value from their LLMs through an emphasis on data quality and evaluation procedures.&nbsp;</p><h2>Fine-Tuning Basics</h2><p>For all three tasks, we use standard full parameter fine-tuning techniques. Models are fine-tuned for next-token prediction, and all parameters in the model are subject to gradient updates. While there certainly are other techniques to train LLMs, such as freezing select transformer blocks and LoRA, to keep a narrow scope we keep the training technique itself constant from task to task.&nbsp;</p><p>Performing full parameter fine-tuning on models of this scale is no easy task. However, our lives can be made easier if we use the right combination of libraries. The script we used to produce the results in this blog post can be found <a href="https://github.com/ray-project/ray/tree/workspace_templates_2.6.1/doc/source/templates/04_finetuning_llms_with_deepspeed"><u>here</u></a>. Built on top of <a href="https://docs.ray.io/en/latest/train/train.html"><u>Ray Train</u></a>, <a href="https://github.com/microsoft/DeepSpeed"><u>Deepspeed</u></a>, and <a href="https://github.com/huggingface/accelerate"><u>Accelerate</u></a>, this script allows you to easily run any of the Llama-2 7B, 13B, or 70B models. We will go over a couple high-level details about the script in the following subsections, but we suggest you checkout the script itself for details on how to run it.&nbsp;&nbsp;</p><h3>General Training Flow</h3><p>Training these large scale models is very difficult without scaling your workload across multiple nodes. Our script centers around a singular training function in which gradient updates on the model actually occur:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span></code><span><span>def</span><span> </span><span>training_function</span><span>(</span><span>kwargs: </span><span>dict</span><span>):</span><span>
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>print</span><span>(</span><span>"training_function called"</span><span>)
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;…
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> epoch </span><span>in</span><span> </span><span>range</span><span>(num_epochs):
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.train()
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…
</span><span>
</span></code></pre></div><p>The key here is that this training function is run on each of the individual worker processes, possibly distributed across multiple machines. Within Ray Train, we use the <a href="https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html"><u>TorchTrainer</u></a> class which acts as a process dispatcher and scales this&nbsp; training loop across our cluster. We can let TorchTrainer know how many worker processes we want to use and how many resources would each process need:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code><span><span>scaling_config=air.ScalingConfig(
</span></span><span>&nbsp;&nbsp;&nbsp;...
</span><span>&nbsp;&nbsp;&nbsp;num_workers=args.num_devices,
</span><span><span>&nbsp;&nbsp;&nbsp;use_gpu=</span><span>True</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;resources_per_worker={</span><span>"GPU"</span><span>: </span><span>1</span><span>},
</span></span><span>),
</span><span>
</span></code></pre></div><p>From here, the main challenge is figuring out how to split the work across our individual training functions. Intuitively, there are two ways to "split"  the work when training a model: one could shard the model, gradients, and optimizer states across workers, and also shard the data across them. On the data side, Ray Train helps us manage the data ingestion and dataset sharding across the training loops. At the top of training loop, a worker can access the shard of the dataset delegated to it via:</p><div><pre><code><code><span>1
</span><span>2
</span></code><span><span>train_ds = session.get_dataset_shard(</span><span>"train"</span><span>)
</span></span><span><span>valid_ds = session.get_dataset_shard(</span><span>"valid"</span><span>)
</span></span><span>
</span></code></pre></div><p>Model sharding is done through DeepSpeed. DeepSpeed defines a strategy for how to split the model across nodes and when to offload compute and memory from GPU to CPU (we use ZeRO stage 3 with optimizer state offloading). Note that because different chunks of the model are delegated to different workers, if we want to access the model in its entirety on any one node (for example, if we want to checkpoint it), we would need to “unwrap” the model:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code><span><span>unwrapped_model = accelerator.unwrap_model(model)
</span></span><span>unwrapped_model.save_pretrained(
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;ckpt_path_epoch,
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;is_main_process=accelerator.is_main_process,
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;save_function=accelerator.save,
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;safe_serialization=</span><span>True</span><span>,
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;state_dict=accelerator.get_state_dict(model),
</span><span>)
</span><span>
</span></code></pre></div><h3>Special Tokens</h3><p>To perform fine-tuning effectively,&nbsp; data needs to be structured appropriately. Rather than having to prompt a task by describing it as instructions to the LLM, we can simply encode this in plain text by utilizing “special tokens”:</p><p>Before:</p><div><pre><code><code><span>1
</span><span>2
</span></code><span><span>{</span><span>"text"</span><span>: </span><span>"You are to solve the following math question. Please write 
</span></span><span><span>out your reasoning ... etc ... {question}\n{answer}"</span><span>}
</span></span><span>
</span></code></pre></div><p>After:</p><div><pre><code><code><span>1
</span></code><span><span>{</span><span>"text"</span><span>: </span><span>"&lt;START_Q&gt;{question}&lt;END_Q&gt;&lt;START_A&gt;{answer}&lt;END_A&gt;}
</span></span><span>
</span></code></pre></div><p>The special tokens allow us to easily encode the structure of our task, as well as providing a signal for when a model should stop producing output. With the example above, we can define “&lt;END_A&gt;” to be the stopping token. This will guarantee that the model will stop producing output when it is done with the task as opposed to waiting for it to output an end-of-sentence token.&nbsp;</p><p>The Llama tokenizer by default outputs 32000 unique token IDs. After adding the four special tokens above to the tokenizer, it will instead output 32004 unique IDs – “&lt;START_Q&gt;” will have an ID of 32000, “&lt;END_Q&gt;” will have an ID of 32001, and so forth. In our script, these special tokens are added like so:&nbsp;</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code><span><span>tokenizer = AutoTokenizer.from_pretrained(pretrained_path, ...)
</span></span><span><span>tokenizer.add_tokens(special_tokens, special_tokens=</span><span>True</span><span>)
</span></span><span><span></span><span># this will make new learnable parameters for specialized tokens</span><span>
</span></span><span><span>model.resize_token_embeddings(</span><span>len</span><span>(tokenizer))
</span></span><span>
</span></code></pre></div><h3>Compute Details</h3><p>For the 7B and 13B models, we used 16xA10Gs, and for the 70B model, we used 32xA10Gs (across 4x g5.48xlarge instances). When using Ray, there's no need to secure A100s to perform full-parameter fine-tuning on these models! The process is simply repeated for each task. Figures below show an example run based on a context length of 512, with a total of 3.7M effective tokens per epoch on GSM8k dataset.&nbsp;</p><p>We ran the training for a maximum of 10 epochs and selected the best checkpoint according to the minimum perplexity score on the validation set.</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1NHkYacCqQEDmHOx3fGJyt/f86fc3eff57937c027ae17f45bee2b9a/Llama_2_learning_curve.png" alt="Llama 2 learning curve"></p></div><p><i>The learning curves obtained from a full-parameter fine-tuning Llama-2 model of different sizes. From these plots you can clearly see when the training starts to overfit the data. Perplexity graphs are good indicators of when to stop the training.&nbsp;</i></p><h2>Functional Representation of Unstructured Text (ViGGO)</h2><p>The first task we examine is based on the <a href="https://huggingface.co/datasets/GEM/viggo"><u>ViGGO</u></a> dataset. It is an English data-to-text generation dataset with the data centering around video game opinions. The original task involves converting a “functional representation” (a set of attribute-values) into coherent text that incorporates those attributes. However, we will reverse this task: transforming unstructured text into a structured and parsable “functional representation”. This representation condenses the information present in the text and can be used for indexing and other downstream applications. While the domain is just video games, this general problem is one that many enterprises are keen to solve.&nbsp;</p><h3>Example Data Point</h3><p>Let's examine an example from this task to understand the level of difficulty it can present for an LLM:</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1Lu1XYpXDyFy6YjHxnBw8r/6b7a7f867a0ee0347fe8d519e63467d7/Text_and_Representation_Table.png" alt="Text and Representation Table"></p></div><p>Given a target sentence the model has to construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values. This function should describe the target string accurately and must be one of the following:</p><div><pre><code><code><span>1
</span><span>2
</span></code><span><span>[</span><span>'inform</span><span>', </span><span>'request</span><span>', </span><span>'give_opinion</span><span>', </span><span>'confirm</span><span>', </span><span>'verify_attribute</span><span>',
</span></span><span><span> </span><span>'suggest</span><span>', </span><span>'request_explanation</span><span>', </span><span>'recommend</span><span>', </span><span>'request_attribute</span><span>']
</span></span><span>
</span></code></pre></div><p>The attributes must be one of the following:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span></code><span><span>[</span><span>'name</span><span>', </span><span>'release_year</span><span>', </span><span>'esrb</span><span>', </span><span>'genres</span><span>', </span><span>'platforms</span><span>', </span><span>'available_on_steam</span><span>',
</span></span><span><span></span><span>'has_linux_release</span><span>', </span><span>'has_mac_release</span><span>', </span><span>'specifier</span><span>', </span><span>'rating</span><span>', </span><span>'player_perspective</span><span>',
</span></span><span><span></span><span>'has_multiplayer</span><span>', </span><span>'developer</span><span>', </span><span>'exp_release_date</span><span>']
</span></span><span>
</span></code></pre></div><p>Let's prompt a few models to see if they can get anywhere close to our intention. Here is the prompt we used:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span><span>66
</span><span>67
</span><span>68
</span><span>69
</span><span>70
</span><span>71
</span><span>72
</span></code><span><span>Given a target sentence construct the underlying meaning representation
</span></span><span>of the input sentence as a single function with attributes and attribute
</span><span>values. This function should describe the target string accurately and the
</span><span><span>function must be one of the following [</span><span>'inform</span><span>', </span><span>'request</span><span>', </span><span>'give_opinion</span><span>',
</span></span><span><span></span><span>'confirm</span><span>', </span><span>'verify_attribute</span><span>', </span><span>'suggest</span><span>', </span><span>'request_explanation</span><span>',
</span></span><span><span></span><span>'recommend</span><span>', </span><span>'request_attribute</span><span>'] .
</span></span><span>
</span><span>The attributes must be one of the following:
</span><span><span>[</span><span>'name</span><span>', </span><span>'exp_release_date</span><span>', </span><span>'release_year</span><span>', </span><span>'developer</span><span>', </span><span>'esrb</span><span>', </span><span>'rating</span><span>',
</span></span><span><span></span><span>'genres</span><span>', </span><span>'player_perspective</span><span>', </span><span>'has_multiplayer</span><span>', </span><span>'platforms</span><span>',
</span></span><span><span></span><span>'available_on_steam</span><span>', </span><span>'has_linux_release</span><span>', </span><span>'has_mac_release</span><span>', </span><span>'specifier</span><span>']
</span></span><span>The order your list the attributes within the function must follow the
</span><span><span>order listed above. For example the </span><span>'name</span><span>' attribute must always come 
</span></span><span><span>before the </span><span>'exp_release_date</span><span>' attribute, and so forth.
</span></span><span>
</span><span>For each attribute, fill in the corresponding value of the attribute 
</span><span>within brackets. A couple of examples are below. Note: you are to output
</span><span><span>the string after </span><span>"Output: "</span><span>. Do not include </span><span>"Output: "</span><span> in your answer.
</span></span><span>
</span><span><span>Example </span><span>1</span><span>)
</span></span><span><span>Sentence: Dirt: Showdown from </span><span>2012</span><span> is a sport racing game for the
</span></span><span><span>PlayStation, Xbox, PC rated E </span><span>10</span><span>+ (</span><span>for</span><span> Everyone </span><span>10</span><span> and Older). 
</span></span><span><span>It</span><span>'s</span><span> not available on Steam, Linux, or Mac.
</span></span><span><span>Output: inform(</span><span>name</span><span>[</span><span>Dirt:</span><span> Showdown], release_year[</span><span>2012</span><span>], 
</span></span><span><span>esrb[</span><span>E</span><span> </span><span>10</span><span>+ (</span><span>for</span><span> Everyone </span><span>10</span><span> and Older)], genres[</span><span>driving/racing</span><span>, sport],
</span></span><span><span>platforms[</span><span>PlayStation</span><span>, Xbox, PC], available_on_steam[</span><span>no</span><span>], 
</span></span><span><span>has_linux_release[</span><span>no</span><span>], has_mac_release[</span><span>no</span><span>])
</span></span><span>
</span><span><span>Example </span><span>2</span><span>)&nbsp;
</span></span><span><span>Sentence: Were there even any terrible games in </span><span>2014</span><span>?
</span></span><span><span>Output: request(</span><span>release_year</span><span>[</span><span>2014</span><span>], specifier[</span><span>terrible</span><span>])
</span></span><span>
</span><span><span>Example </span><span>3</span><span>)
</span></span><span>Sentence: Adventure games that combine platforming and puzzles 
</span><span>can be frustrating to play, but the side view perspective is 
</span><span><span>perfect for them. That</span><span>'s</span><span> why I enjoyed playing Little Nightmares.
</span></span><span><span>Output: give_opinion(</span><span>name</span><span>[</span><span>Little</span><span> Nightmares], rating[</span><span>good</span><span>],
</span></span><span><span>genres[</span><span>adventure</span><span>, platformer, puzzle], player_perspective[</span><span>side</span><span> view])
</span></span><span>
</span><span><span>Example </span><span>4</span><span>)
</span></span><span><span>Sentence: Since we</span><span>'re</span><span> on the subject of games developed by Telltale 
</span></span><span><span>Games, I</span><span>'m</span><span> wondering, have you played The Wolf Among Us?
</span></span><span><span>Output: recommend(</span><span>name</span><span>[</span><span>The</span><span> Wolf Among Us], developer[</span><span>Telltale</span><span> Games])
</span></span><span>
</span><span><span>Example </span><span>5</span><span>)&nbsp;
</span></span><span>Sentence: Layers of Fear, the indie first person point-and-click adventure game?
</span><span><span>Output: confirm(</span><span>name</span><span>[</span><span>Layers</span><span> of Fear], genres[</span><span>adventure</span><span>, indie,
</span></span><span><span>point-and-click], player_perspective[</span><span>first</span><span> person])	
</span></span><span>
</span><span><span>Example </span><span>6</span><span>)&nbsp;
</span></span><span>Sentence: I bet you like it when you can play games on Steam, like 
</span><span>Worms: Reloaded, right?	
</span><span><span>Output: suggest(</span><span>name</span><span>[</span><span>Worms:</span><span> Reloaded], available_on_steam[</span><span>yes</span><span>])
</span></span><span>
</span><span><span>Example </span><span>7</span><span>)
</span></span><span>Sentence: I recall you saying that you really enjoyed The Legend 
</span><span>of Zelda: Ocarina of Time. Are you typically a big fan of games
</span><span><span>on Nintendo rated E (</span><span>for</span><span> Everyone)?	
</span></span><span><span>Output: verify_attribute(</span><span>name</span><span>[</span><span>The</span><span> Legend of Zelda: Ocarina of Time],
</span></span><span><span>esrb[</span><span>E</span><span> (</span><span>for</span><span> Everyone)], rating[</span><span>excellent</span><span>], platforms[</span><span>Nintendo</span><span>])
</span></span><span>
</span><span><span>Example </span><span>8</span><span>)
</span></span><span><span>Sentence: So what is it about the games that were released in </span><span>2005</span><span> 
</span></span><span>that you find so excellent?	
</span><span><span>Output: request_explanation(</span><span>release_year</span><span>[</span><span>2005</span><span>], rating[</span><span>excellent</span><span>])
</span></span><span>
</span><span><span>Example </span><span>9</span><span>)
</span></span><span>Sentence: Do you think Mac is a better gaming platform than others?
</span><span><span>Output: request_attribute(</span><span>has_mac_release</span><span>[])
</span></span><span>
</span><span>Give the output for the following sentence:
</span><span>{input}
</span><span>
</span></code></pre></div><p><b>Input Query:</b> What's a really fast-paced game with multiplayer that you like to play?&nbsp;</p><p><b>Expected Output:</b> request(has_multiplayer[yes], specifier[fast-paced])</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/jJUBXq14oK7euDi1EnP0g/4ce0cac85dd079e70d1e3b0412090f90/Llama_2_models.png" alt="Llama 2 Models"></p></div><p>As observed, these models do not align well with our intended output. This particular task is not one that can be easily accomplished through prompt-engineering alone. Also notice the length of the input context being passed in for these models – this large input makes inference time for producing an output significantly longer than the input text itself. With all this in mind, we are interested in exploring how far we can push the limits of fine-tuning on this task.</p><h3>Why Might Fine-Tuning Be Promising?</h3><p>In one of our previous blog posts, we discussed the idea that "<a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts"><u>fine-tuning is for form, not facts</u></a>". So, does it make sense to expect fine-tuned models to outperform other methods such as prompt engineering or few-shot prompting on this particular task?</p><p>The answer to this question isn't straightforward and requires experimentation. However, there are a couple of key insightful questions that can guide you in formulating a hypothesis on whether fine-tuning could add substantial value for your specific use case:</p><ol><li><p><b>New Concepts:</b> Can we assume that the base model has encountered the concepts within this task (concepts related to video games, etc)&nbsp; in its pre-training data, or is this an entirely new concept? If it is a completely new concept (or fact), the chances of the model learning it through small-scale fine-tuning are quite low.</p></li><li><p><b>Promising few-shot:</b> Do you observe improvements when you employ few-shot prompting? This technique involves showing the model a few examples of inputs and outputs, then asking it to complete the answer following the same pattern. If you notice significant improvements, fine-tuning could potentially offer even better results. This is because fine-tuning allows you to incorporate far more examples into the model's internal neural network weights, rather than being constrained by context length and consuming tokens for the prompt prefix.</p></li><li><p><b>Token budget:</b> Even if prompt-engineering is working for you, you must provide the usually lengthy prompts as input for <b>every</b> request. This approach can quickly consume your token budget. In the long run, it might be more cost-effective to fine-tune a niche model specifically for that task, thereby saving money.</p></li></ol><p>This particular task revolves around pattern recognition, necessitating a basic grasp of language and underlying concepts but not demanding intricate logical reasoning.&nbsp; More importantly, this task is grounded, meaning all required "facts" for its output are already embedded in the input. It is&nbsp; evident that a lengthier input prompt incorporating examples aids the model's comprehension of our intent, and that's a good indicator that even fine-tuning smaller Llama-2 models could significantly enhance performance in addressing this task.</p><h3>Evaluation</h3><p>Evaluating this task can be done from a few angles. While this task is deterministic enough to warrant checking for an exact character match, this would not be a fair metric for the non-fine-tuned models. Instead, we first check if the output function is predicted correctly. From there, we also check if the attribute types are correct. The attribute types within the function follow a strict precedence and so we check that the model output adheres to this ordering. This is mentioned in the prompt for instruction-following models (i.e. GPT, llama-2-chat), so these models are expected to output attributes following this rule. This is a hard guideline to pick up from just a few examples and the model has to pay attention to the specific rule and understand the meaning behind it.&nbsp;</p><p>To speed up evaluation, we utilized Ray's <a href="https://docs.ray.io/en/latest/data/batch_inference.html">batch inference API</a> for scaling up inference in conjunction with Anyscale's <a href="https://github.com/ray-project/aviary">Aviary</a> for serving our customized LLMs. Utilizing these two components allowed us to chain LLM generation with postprocessing and distribute it across many machines. Investing time in a robust evaluation framework is extremely important, as it forms the foundation of any model development process.</p><h3>Results</h3><div><p><img src="https://images.ctfassets.net/xjan103pcp94/4iu1UgY7SBuPiuEYgPa7gr/1eac9c5dec1fe63bfe8e18b8194d7faf/Viggo_dataset.png" alt="Viggo Dataset"></p></div><p><i>Dark colors present chat model performance using the mentioned prompt. For GPT-4, we report both evaluations numbers: with and without attribute order importance. Fine-tuned models consistently achieve &gt;90% success rate in both evaluations methods, never diverging from the precedence rule.</i></p><p>Both the 7b and 13b models significantly improve in accuracy with fine-tuning. While GPT-4’s accuracy significantly drops when attribute precedence is considered, the outputs of the fine-tuned models always follow precedence and accuracy remains unchanged with this added evaluation constraint.</p><h3>Takeaways</h3><p>The ViGGO dataset highlights the strongest aspects of fine-tuning, and the results clearly back it up. When requiring structured form, fine-tuning can provide reliable and efficient means to accomplish your task. This task also shows that requiring a “structured form” does not just mean matching a simple regex or JSON format, tasks that perhaps can be accomplished with libraries like <a href="https://github.com/microsoft/guidance"><u>guidance</u></a>. With ViGGO, an LLM needs to determine whether an argument should be included or not, as well as ensuring that the order of the included arguments follows precedence.&nbsp;</p><p>There is also the argument of efficiency. Besides the fact that significantly more input tokens were required for the general models, the fine-tuned results were achieved with only the 7b &amp; 13b models. Serving a Llama 7b model is significantly cheaper than footing the bill for GPT-4 endpoint calls, especially as your service grows.&nbsp;</p><h2>SQL Generation with Llama-2 fine-tuned models</h2><p>The next task we examine is SQL generation. The goal is to convert natural language queries to a functional SQL query that can then be executed on your database. For this task we examine the <a href="https://huggingface.co/datasets/b-mc2/sql-create-context"><u>b-mc2/sql-create-context</u></a> dataset from Hugging Face, which is a combination of the <a href="https://huggingface.co/datasets/wikisql"><u>WikiSQL</u></a> and <a href="https://huggingface.co/datasets/spider"><u>Spider</u></a> datasets.&nbsp;</p><p>Each of the 78,577 data points consists of a natural language query, corresponding SQL CREATE TABLE statements, and then the SQL query corresponding to the natural language question. The goal of the LLM is to take in the natural language query and SQL CREATE TABLE statements as context, and produce a SQL output that can query the given SQL tables and produce an output that answers the natural language query.&nbsp;</p><h3>Example Data Point</h3><p>One issue specific to this dataset was incorrect ground truth SQL outputs that had to be filtered out. In many data points, attributes that were integers were labeled as VARCHARs in the CREATE TABLE statements:</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/cYFm1c3wBaJ3nxfifdF4U/3f5a5ada5b5238959a5387a80bbb6060/Example_Datapoint_Chart.png" alt="Example Datapoint Chart"></p></div><p>Note that the attribute “week” is defined as a string in the CREATE TABLE statement, however, is treated like an integer in the SQL query. To avoid resulting issues when testing, we filtered out all SQL queries that assumed an attribute was an integer, cutting the dataset from 70k data points to 45k data points. While this is a strong constraint on the dataset, the python SQL engine we were using did not have an easy way to type check between the CREATE TABLE and SQL query statements – unless we wanted to write an algorithm to parse through the AST and type check ourselves. Nonetheless, the resulting dataset was still challenging with plenty of tricky data points like the following:&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/47XvvreSp5HVtn3jMGclOm/3c72f0ce67abfebdd60331876eef4111/Another_Example_Datapoint_Chart.png" alt="Another Example Datapoint Chart"></p></div><h3>Why Might Fine-Tuning Be Promising?</h3><p>This task shares some similarities to ViGGO – the LLM is trying to output a structured representation of natural language, which in this case is SQL. Unlike ViGGO, this task is slightly more ambiguous as there can be several SQL queries that could output the correct answer when executed on a data table. Nonetheless, this task is a great fit for fine-tuning as success hinges on an LLM’s ability to learn the “structure” of SQL and convert natural language to this structure.&nbsp;&nbsp;</p><h3>Evaluation</h3><p>A major challenge with a SQL task like this is evaluation. Once the model has outputted a SQL query, how do we check if it is correct? One naive way would be to check character by character equivalence between the generated SQL code and the ground truth query provided by the dataset. This approach is sensitive to a lot of factors that can raise the number of false negatives. Another way is to check the equivalence of the abstract syntax tree (AST) of the two queries. However, this is also susceptible to things like order of variable names, etc. The last approach that would be the most reliable is to run the code on a fake dataset and check the equivalence of the outputs.</p><p>What we decided to do for this task is to use OpenAI's GPT-3.5 endpoint to generate unit tests for a few hundreds of these examples. GPT-3.5 is prompted to look at the question, the table schema, and the answer and generate a fake table with ten data points. This small data table can be used to compare and test the validity of an SQL query:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span></code><span><span>from</span><span> sqlglot.executor </span><span>import</span><span> execute
</span></span><span>
</span><span>gpt_data_table = {
</span><span><span>&nbsp;&nbsp;</span><span>"table_name_64"</span><span>: [
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;{
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"position"</span><span>: </span><span>"mayor"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"first_election"</span><span>: </span><span>"1988 as vice mayor 2009"</span><span>
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;...
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;{
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"position"</span><span>: </span><span>"mayor"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"first_election"</span><span>: </span><span>"2007 as councilor 2014"</span><span>
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;}
</span><span>&nbsp;&nbsp;]
</span><span>}
</span><span>
</span><span><span>&nbsp;model_sql = get_llama_response(sql_prompt.</span><span>format</span><span>(create_table=..., query=...))
</span></span><span><span>&nbsp;model_sql = model_sql[model_sql.find(</span><span>"&lt;SQL&gt;"</span><span>)+</span><span>len</span><span>(</span><span>"&lt;SQL&gt;"</span><span>):model_sql.find(</span><span>"&lt;/SQL&gt;"</span><span>)]
</span></span><span>&nbsp;model_sql = model_sql.lower()
</span><span>
</span><span><span></span><span>try</span><span>:
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;queryresult = execute(sql_query, tables=table)
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;modelresult = execute(model_sql, tables=table)
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>str</span><span>(queryresult) == </span><span>str</span><span>(modelresult):
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	</span><span># output is correct&nbsp;</span><span>
</span></span><span><span></span><span>except</span><span> Exception </span><span>as</span><span> e:&nbsp;
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>print</span><span>(e)
</span></span><span>
</span></code></pre></div><p>To ensure the quality of the GPT-3.5 generated data tables, we first executed the ground truth SQL query against it. If the resulting table was either empty, or the same length as the initial table, the example was discarded. This resulted in filtering out roughly 50% of the GPT produced data tables.&nbsp;</p><h3>Results</h3><p>Both the Llama-7b and 13b fine-tuned models outperform the 70b-chat and GPT-4 models. One common source of error for the Llama chat models was that it would not consistently put its output SQL within &lt;SQL&gt; tags as instructed by the prompt – this was more common in the 7b and 13b chat models than the 70b one.&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/3mqT3cT0OTVbB57Udt5U5x/1df7d2df8ba08b7fc78701df9bfe72c3/Various_models.png" alt="Various Models"></p></div><p><i>Dark colors present chat model performance. Fine-tuned models achieve ~90% success rate.</i></p><p>Note that some of the natural language queries in that SQL dataset were not perfect English. This noise from the dataset is likely to have slightly affected the GPT-4 results. It nonetheless highlights an important point about fine-tuning – that these models will quickly adapt to the quirks of&nbsp; a dataset, whatever those quirks may be.&nbsp;</p><h3>Takeaways</h3><p>In this example, both the 7b and 13b fine-tuned models outperformed GPT-4 as well as the 70b chat model. Also keep in mind that for every call to GPT and the Llama base chat models, a lengthy prompt needed to be fed in. Additionally, while this wasn’t an issue for GPT, the Llama chat models would often output hundreds of miscellaneous tokens that were unnecessary for the task, further slowing down their inference time (e.g. “Sure! Happy to help…”).</p><h2>Grade School Math reasoning (GSM8k)</h2><p>The final task we consider is GSM8k. This task is a standard academic benchmark for evaluating LLMs on math reasoning and understanding. The challenge of fine-tuning on this dataset differs from the previous two. As opposed to just learning structure, we wanted to see how much an LLM could improve its ability to reason on math problems.</p><h3>Example data point</h3><table><tbody><tr><td><p><b>Question</b></p></td><td><p><b>Answer</b></p></td></tr><tr><td><p>Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?</p></td><td><p>Natalia sold 48/2 = 24 clips in May. \n Natalia sold 48+24 = 72 clips altogether in April and May. \n#### 72</p></td></tr></tbody></table><p>While it would be impressive for an LLM to immediately produce the answer of 72, current LLMs are incapable of internalizing their "thought" process leading to the final answer. Instead, they must generate their "thought" process as part of the output, ensuring that the generation of each subsequent word is based on a solid reasoning process. The target answers in this dataset are formatted to outline the thought process, concluding with the final answer in the #### {answer} format for easy parsing.</p><p>This task necessitates that the language models not only understand simple calculations, but also know how to progress from the given assumptions to intermediate conclusions, and ultimately to a final answer. Thus, LLMs need a solid grasp of language (including the understanding of concepts and their interrelationships), as well as the ability to lay out a logical chain of thought. The interesting question here is how well do the chat-tuned models do on this task and how much can we gain with fine-tuning?&nbsp;</p><h3>Evaluation</h3><p>To effectively evaluate an LLM on this task, you need a reliable method to extract the final answer generated by the language model and compare it to the ground truth. While this isn’t an issue with fine-tuned models, a common challenge with general language models is their inability to consistently adhere to a desired output format, making it tricky to evaluate. There are various proposed solutions for constrained generation, such as <a href="https://github.com/microsoft/guidance"><u>guidance</u></a>, hinting at the constraints in the prompt, or providing few-shot examples. However, for the sake of simplicity and to ensure a specific output format for automating the evaluation process, we utilized <a href="https://openai.com/blog/function-calling-and-other-api-updates"><u>OpenAI's function calling API</u></a>.</p><p>The idea is to employ a gpt-4 or gpt-3.5-turbo model to process the generated response for LLMs that lack a predetermined output structure. Given the question, these models can extract the final answer without correcting it (if there are any errors). The following code demonstrates the extraction procedure:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span></code><span><span>def extract_number_from_text(question: str, text: str) -&gt; int:
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;## Use GPT</span><span>-3.5</span><span>-turbo's functional API to extract the number from the text
</span></span><span>
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;functions = [
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"name"</span><span>: </span><span>"report_answer"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"description"</span><span>: </span><span>"Reports the final answer from the text."</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"parameters"</span><span>: {
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"type"</span><span>: </span><span>"object"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"properties"</span><span>: {
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"number"</span><span>: {
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"type"</span><span>: </span><span>"integer"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"description"</span><span>: ...
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"required"</span><span>: [</span><span>"number"</span><span>],
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;]
</span><span>
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;resp = openai.ChatCompletion.create(
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model=</span><span>"gpt-3.5-turbo-0613"</span><span>,
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messages=[...],
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functions=functions,
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;function_call={</span><span>"name"</span><span>: </span><span>"report_answer"</span><span>},
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;)
</span><span>
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;resp_msg = resp[</span><span>"choices"</span><span>][</span><span>0</span><span>][</span><span>"message"</span><span>]
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;function_args = json.loads(resp_msg[</span><span>"function_call"</span><span>][</span><span>"arguments"</span><span>])
</span></span><span>
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;return function_args[</span><span>"number"</span><span>]
</span></span><span>
</span></code></pre></div><p>We instruct the gpt-3.5 model to read the question and utilize a function named report_answer, which accepts an integer number as its input. This approach ensures that the model will consistently output the final integer number found within the content generated by another model. For example if the model answers that “The answer is four” we can still parse the answer as answer = 4. We've tested this on the provided answers in the dataset to confirm its efficacy and ensure that it doesn't present any edge cases. The downside of this approach is that we need to pay for OpenAI tokens for evaluation.&nbsp;</p><p>It's worth noting that the fine-tuned models quickly learn to adhere to the pattern exhibited in the target answers and rarely deviate from it – even if the answer itself is incorrect, the output structure is very predictable. Therefore, when evaluating fine-tuned models, we simply apply the regex pattern of #### {answer} to the output generated by these models, eliminating the need for post processing with OpenAI endpoints saving money during evaluation.&nbsp;</p><h3>Why Might Fine-Tuning Be Promising?</h3><p>For this task, we believe that the model has been exposed to sufficient mathematical concepts during its pre-training phase. As such, it should be able to generalize from there, and fine-tuning should help in activating the appropriate mode of its internal knowledge. Additionally, if we examine the published benchmarks on Llama-2, it performs notably well on the GSM8k dataset with 8 few-shot examples, outperforming other models. This underscores the importance of extensive pre-training data. The question then becomes: Can we further improve these numbers through fine-tuning?<br></p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/7po1LGLgt5LzPCb3SFxH2h/b9aac7af2dc3eecd89318e31d60cb567/benchmark_compare_table.png" alt="Benchmark Llama 2 Table"></p></div><h3>Baselines</h3><p>Establishing the correct baselines is crucial for methodically measuring progress and the effectiveness of different approaches. For this test, we considered the following baselines:</p><ol><li><p>The reported 8-shot prompting approach using the base pre-trained models (note that we did not re-run these experiments ourselves; we are simply quoting the published results).</p></li><li><p>Several prompt-engineered templates for the chat-tuned Llama variants. These “chat-tuned” models were trained by Meta using <a href="https://huyenchip.com/2023/05/02/rlhf.html">RLHF</a> to function as general-purpose assistant models. If the RLHF training is conducted as rigorously as OpenAI's approach, we should expect high-quality results from these models as well. The following table presents a view of the prompt templates we used and illustrates how they differ from each other.</p></li></ol><div><p><img src="https://images.ctfassets.net/xjan103pcp94/13GoCLY3pAe2gVCIRUDaqB/b01dc6a842dda90c46b3a6d4b5cc7ee1/Comparison_with_Baseline.png" alt="Comparison with Baseline"></p></div><h3><br>Results</h3><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1YaJFzh4W1HwCxeTLSIf75/f6603679a8f04c0d3a292c3980e856ef/GSM8k_Results_Across_Llama.png" alt="GSM8k Results Across Llama"></p></div><p><i>The fine-tuned 7b and 13b models have an improved accuracy by 10% when compared to their base counterparts. The margin is less when compared to the chat-tuned baselines, as these were likely trained with math examples in the chat-tuning process.&nbsp;</i></p><p>There a couple takeaways from these results:</p><ol><li><p><b>Fine-tuning the base model consistently enhances its performance on this specific task. </b>However, it may not necessarily yield results significantly better than those of the chat-tuned models. Keep in mind that the chat models were fine-tuned to be versatile, so determining whether they are sufficient for your task requires experimenting with different prompts.&nbsp;</p></li><li><p><b>Prompting the fine-tuned model does not always lead to better performance than the base model.</b> For instance, Llama-2-70B-chat could actually underperform relative to the base model with an 8-shot example prompt, while the fine-tuned model consistently does better than the 8-shot prompted base model.&nbsp;</p></li><li><p><b>Fine-tuned models for this task demonstrate superior performance across all model sizes</b>, while potentially costing significantly less than the other baselines during serving. For this task, you will be charged for all the tokens in the prompt for each request, but for fine-tuned models, you would effectively only pay for the number of tokens in the question. Depending on the serving traffic you are targeting, your overall cost could be lower while using a more performant, customized model.</p></li><li><p><b>Chat-tuned models performed better than the non-fine-tuned base model.</b> It is important to make the distinction between the chat-tuned model and the base pre-trained model. The chat-tuned models were likely trained with math examples in the chat-tuning process, resulting in better accuracy than the base model.&nbsp;</p></li></ol><h3>Further Improving Fine-Tuning Results</h3><p>While we do see improvements from fine-tuning across the board, we wanted to focus on Llama-13b and see if results could be further improved with standard fine-tuning techniques. The GSM8k training dataset is relatively small, with only 8k data points. Since learning to solve math problems is less straightforward than just learning to output answers in a specific format, we figured it was unlikely that just 8k data points would be sufficient in unlocking the full-potential of a Llama-13b model on this dataset.&nbsp;</p><p>With this in mind, we took the base Llama-13b model and first fine-tuned it on the MathQA dataset, before subsequently fine-tuning the model on the original GSM8k dataset. This extra round of fine-tuning resulted in a further 10% increase from the initial fine-tuned model results, adding up to a 20% increase from the base model.&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/35f5hYWemM3xoVftEH2GkP/be028fe2dc39707af59d238192875be5/Llama-13b_GSM8k_Accuracy.png" alt="Llama-13b GSM8k Accuracy."></p></div><p><i>Fine-tuning with just the GSM8k data yields a 10% improvement. Fine-tuning in two stages with both the MathQA and GSM8k datasets result in a cumulative 10% improvement.</i></p><p>While one might expect this to align with the classic “more data, better model” paradigm within machine learning, we found these results to be surprising given the nature of the MathQA dataset. MathQA is a collection of 30,000 question/answer pairs that are much noisier and of different structure than the GSM8K dataset. The answers are of poorer quality, and unlike GSM8k, the final answers in MathQA are multiple choice. As an example:</p><table><tbody><tr><td><p><b>Question</b></p></td><td><p><b>Answer Options</b></p></td><td><p><b>Answer</b></p></td></tr><tr><td><p>the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?</p></td><td><p>a ) rs . 400 , b ) rs . 300 , c ) rs . 500 , d ) rs . 350 , e ) none of these</p></td><td><p>explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = rs . 400 answer : option a</p></td></tr></tbody></table><p>Notice the odd spacing and compare the quality of this datapoint to the GSM8k question/answer pair from earlier:</p><table><tbody><tr><td><p><b>Question</b></p></td><td><p><b>Answer</b></p></td></tr><tr><td><p>Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?</p></td><td><p>Natalia sold 48/2 = 24 clips in May. \n Natalia sold 48+24 = 72 clips altogether in April and May. \n#### 72</p></td></tr></tbody></table><p>Stratifying the fine-tuning into two rounds was an effective way to leverage this MathQA dataset and yield a much better final result for the GSM8k dataset.</p><h3>Conclusion</h3><p>Hopefully going through these three examples should have convinced you that while closed-source models like GPT-4, Claude-2, etc. are strong enablers for prototyping and proving the initial value, they are not sufficient for running performant LLM apps in production. Fine-tuning LLMs for niche tasks is one of the promising solutions to elicit value out of LLMs for your business, not just because of privacy, but also latency, cost, and sometimes quality (e.g. in ViGGO and SQL examples). For fine-tuning your focus should be on collecting data and setting up evaluation pipelines that help you understand trade-offs between different solutions tied to your business, and not think about the infrastructure and intricacies of fine-tuning. At Anyscale we have built the best fine-tuning and serving solutions on top of Ray, so you can start repeating the same process outlined here on your own data and on your own cloud. Checkout <a href="https://app.endpoints.anyscale.com/"><u>Anyscale Endpoints</u></a> to learn more.<br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GSMA considers giving away mobile device locations through API (130 pts)]]></title>
            <link>https://www.gsma.com/futurenetworks/gsma-open-gateway-api-descriptions/</link>
            <guid>37090063</guid>
            <pubDate>Fri, 11 Aug 2023 15:49:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gsma.com/futurenetworks/gsma-open-gateway-api-descriptions/">https://www.gsma.com/futurenetworks/gsma-open-gateway-api-descriptions/</a>, See on <a href="https://news.ycombinator.com/item?id=37090063">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="wrapper" role="main">
    <article id="post-35494" class="page">
    


    <section>
    <p><img decoding="async" src="https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1.jpg" alt="Open Gateway APIs" width="858" height="288" srcset="https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1.jpg 858w, https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1-500x168.jpg 500w, https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1-768x258.jpg 768w" sizes="(max-width: 858px) 100vw, 858px"><br>
<a href="https://www.gsma.com/futurenetworks/gsma-open-gateway/">← Back to GSMA Open Gateway Home</a></p>
<p>The GSMA Open Gateway initiative launches with eight network APIs, including SIM Swap, Quality on Demand, Device Status, Number Verification, Simple Edge Discovery, One Time Password SMS, Carrier Billing – Check Out and Device Location. The initiative plans to launch further APIs throughout 2023.</p>
<p>They can be found in the CAMARA repository here&nbsp;<a href="https://github.com/camaraproject" target="_blank" rel="noopener">https://github.com/camaraproject</a></p>

<h3><b>SIM swap</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2">The API checks the last time that the SIM card associated with a mobile number (MSISDN) has changed. The response may be a timestamp or a yes/no for a defined period (e.g. last 24h).</td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><strong>Fraud prevention in banking:</strong> a bank may query the API when a transaction appears suspicious. The SIM swap information feeds into the bank risk decision engine and security measures are applied accordingly by the bank</li>
<li><strong>Fraud prevention for password reset (various sectors):</strong> password reset is often protected via a mobile verification e.g. SMS One Time Password. The online service provider may query the API to secure the mobile verification. A recent SIM swap may indicate a risk of account takeover fraud and the service provider can adapt the security measures accordingly.</li>
</ul>
</td>
<td>Increased security without additional friction for the user</td>
</tr>
</tbody>
</table>
<h3><b>Quality On Demand</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>The API allows an application developer to request stable latency (reduced jitter) or throughput for specified application data flows between application clients&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>and application servers. The developer chooses from a predefined set of&nbsp;</span><span>Quality of Service</span><span>&nbsp;Profiles (</span><span>i.e.</span><span>&nbsp;stable latency or different levels of throughput). The&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>API response confirms whether the network can fulfill the request.</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Remote control of machines and vehicles (e.g.&nbsp;Automated Guided Vehicles, drones,&nbsp;</b><b>robotic arm, factory production&nbsp;line</b><b>): </b><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>applications requiring remote control of&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>machines or vehicles require stable data throughput and low latency. The requirements&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>may change dynamically (</span><span>e.g.</span><span>&nbsp;piloting a drone vs drone transmitting video data) or&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>not&nbsp;(</span><span>e.g.</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>specialised</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>&nbsp;robotic arm or remote maintenance). The application requests the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>required Quality On Demand from the mobile network via the API each time the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>requirements change. The API can&nbsp;also apply over private networks and network slices.</span></span></li>
<li><b>Real-time media and entertainment (e.g. gaming, real-time streaming): </b>online gamers and viewers of real-time streaming media require a guaranteed level of quality to ensure good user experience. The application requests the required Quality on Demand from the mobile network via the API.</li>
</ul>
</td>
<td>Improved performance for applications.
<p>Minimised production line downtime. Factory floor flexibility.</p>
<p>Guaranteed quality may be critical for safety reasons (moving objects or vehicles).</p>
<p>Enhanced end-user experience.</p></td>
</tr>
</tbody>
</table>
<h3><b>Device status</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API checks connectivity status for a user equipment. In its current version, the API only checks the roaming status of a device. The response confirms&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>whether the device is roaming and the country it is in.&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li data-charcodes="8226" data-font="Arial,Sans-Serif" data-buautonum="8" data-margin="540" data-aria-posinset="1" data-aria-level="1"><b><span data-usefontface="false" data-contrast="none">Service delivery:&nbsp;</span></b><span data-usefontface="false" data-contrast="none">a content provider may need to enforce territory restrictions for their&nbsp;</span><span data-usefontface="false" data-contrast="none">content. For&nbsp;instance&nbsp;a broadcaster or streaming service may only have rights to&nbsp;</span><span data-usefontface="false" data-contrast="none">broadcast a piece of content in their domestic market. Through the Device status API,&nbsp;</span><span data-usefontface="false" data-contrast="none">the content provider can check that the end-user&nbsp;is located in&nbsp;the content provider&nbsp;</span><span data-usefontface="false" data-contrast="none">domestic&nbsp;market.&nbsp;</span>​</li>
<li data-charcodes="8226" data-font="Arial,Sans-Serif" data-buautonum="8" data-margin="540" data-aria-posinset="2" data-aria-level="1"><b><span data-usefontface="false" data-contrast="none">Fraud prevention (e.g.&nbsp;banking, payments, commerce):&nbsp;</span></b><span data-usefontface="false" data-contrast="none">a bank may query the API&nbsp;</span><span data-usefontface="false" data-contrast="none">upon detecting a transaction from an unexpected country. The roaming information feeds&nbsp;</span><span data-usefontface="false" data-contrast="none">into the bank risk decision engine and security measures are applied accordingly by the&nbsp;</span><span data-usefontface="false" data-contrast="none">bank.&nbsp;</span>​</li>
<li data-charcodes="8226" data-font="Arial,Sans-Serif" data-buautonum="8" data-margin="540" data-aria-posinset="3" data-aria-level="1"><b><i><span data-usefontface="false" data-contrast="none">Regulatory compliance:&nbsp;</span></i></b><i><span data-usefontface="false" data-contrast="none">a customer may need to be within a certain jurisdiction, or&nbsp;</span></i><i><span data-usefontface="false" data-contrast="none">outwith</span></i><i><span data-usefontface="false" data-contrast="none">&nbsp;others,&nbsp;in order for&nbsp;transactions to be&nbsp;</span></i><i><span data-usefontface="false" data-contrast="none">authorised</span></i>​</li>
</ul>
</td>
<td>Remote monitoring of IoT devices enables device management and performance.
<p>Decreased fraud risk without additional friction for the user.</p></td>
</tr>
</tbody>
</table>
<h3><b>Number Verification</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>The API enables the seamless authentication of the mobile device by the mobile network. The developer requests a check of the phone number of the device&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>being used to access its service. The API either confirms the comparison result (</span><span>i.e.</span><span>&nbsp;whether the user is using a device with the same&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>mobile phone</span><span>&nbsp;number&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>as&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>is declared</span><span>), or</span><span>&nbsp;returns the phone number.&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>App onboarding (banking app, social media, ride share, mobile wallet, …): </b>SMS One Time Password is widely used to prove that the user is in possession of the mobile device associated with the mobile number used for registration. However it adds friction to the user journey. The application can instead request a seamless authentication of the mobile device via the API.</li>
<li><b>App login: </b>in place of username/password, the application can request seamless authentication of the mobile device.</li>
<li><b>Application password reset: </b>the user journey often relies on SMS One Time Password. As in the app onboarding use case, the application can instead request a seamless authentication of the mobile device via the API.</li>
</ul>
</td>
<td>Improved seamless and faster user experience, hence improved conversion rates &amp; customer satisfaction
<p>Lower risk of compromise (by social engineering or interception)</p></td>
</tr>
</tbody>
</table>
<h3><b>Simple Edge Discovery</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API allows an application to discover the nearest Edge-Cloud node for it to connect to (may be telco edge cloud or&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>hyperscaler</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>&nbsp;edge cloud, whichever is&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>required).&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>All edge cloud use cases e.g. automotive, mixed/augmented reality, high resolution video streaming, cloud gaming, remote control of moving objects or vehicles</b>: for an application deployed in telco edge cloud or hyperscaler edge cloud, the device needs to be informed of the Edge-Cloud node to access. The application queries the API and is informed of the nearest Edge-Cloud node to connect to. It can then perform a DNS lookup to route traffic to this node.</li>
</ul>
</td>
<td>
<p data-ccp-props="{&quot;335551550&quot;:1,&quot;335551620&quot;:1,&quot;335559683&quot;:0,&quot;335559685&quot;:0,&quot;335559731&quot;:0,&quot;335559737&quot;:0,&quot;335562764&quot;:2,&quot;335562765&quot;:1,&quot;335562766&quot;:4,&quot;335562767&quot;:0,&quot;335562768&quot;:4,&quot;335562769&quot;:0}"><span data-scheme-color="@000000,," data-usefontface="true" data-contrast="none">Enables selection of and routing towards the nearest edge cloud&nbsp;</span><span data-scheme-color="@000000,," data-usefontface="true" data-contrast="none">node, generally&nbsp;</span><span data-usefontface="false" data-contrast="none">optimising network performance by minimising&nbsp;</span><span data-usefontface="false" data-contrast="none">propagation delay.&nbsp;</span>​</p>
<p data-ccp-props="{&quot;335551550&quot;:1,&quot;335551620&quot;:1,&quot;335559683&quot;:0,&quot;335559685&quot;:0,&quot;335559731&quot;:0,&quot;335559737&quot;:0,&quot;335562764&quot;:2,&quot;335562765&quot;:1,&quot;335562766&quot;:4,&quot;335562767&quot;:0,&quot;335562768&quot;:4,&quot;335562769&quot;:0}">​<span data-usefontface="false" data-contrast="none">More accurate selection based on Operator network topology&nbsp;</span><span data-usefontface="false" data-contrast="none">rather than geolocation.&nbsp;</span></p>
</td>
</tr>
</tbody>
</table>
<h3>One Time Password SMS</h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API delivers a short-lived&nbsp;</span><span>one time</span><span>&nbsp;password to&nbsp;</span><span>a mobile phone</span><span>&nbsp;number via SMS. The API then validates the code as input by the end-user into the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>service,&nbsp;</span><span>in order to</span><span>&nbsp;provide a proof of possession of the phone number.&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Onboarding to digital service (banking, social media, gig economy, retail, …):</b> SMS One Time Password is used to prove that the user is in possession of the mobile device associated with the mobile number used for onboarding. This increases confidence for future uses of the mobile number and reduces instances of fake accounts creation.</li>
<li><b>High-value transactions: </b>in order to reduce payment fraud, the user may be asked to enter the OTP code sent to their registered mobile number.</li>
<li><b>Account management e.g. password reset: </b>to protect against account takeover, sensitive account management actions can be protected by requesting a second factor authentication by the end-user.</li>
</ul>
</td>
<td>End user familiarity.
<p>Increased security over single-factor authentication (username/password) or in card-not-present scenarios.</p>
<p>Prevent fake accounts creation (bots).</p></td>
</tr>
</tbody>
</table>
<h3><b>Carrier Billing – Check Out</b>​</h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API allows an online merchant to enable the purchase of third-party digital goods and to request payment against the user’s Operator carrier billing&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>system. The API enables several related operations to the purchase (triggering purchase and consulting information to follow up on fulfilment); and to the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>payment, in one step by requesting carrier billing payment or with additional steps to prepare the payment before confirming or cancelling it. The Operator&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>takes care of the billing.&nbsp;</span><span>Usually</span><span>&nbsp;the payment amount is added to the user’s phone bill or deducted from their prepaid balance and funds are paid to the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>merchant by the Operator.&nbsp;</span></span><span>​</span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Mobile payments across media, gaming, mobile services, ticketing, content, and other digital services: </b>when reaching checkout online, the user gets the option to pay by mobile. If chosen, the merchant requests payment via the Carrier Billing API. The payment amount is added to the user’s phone bill or deducted from their prepaid balance. The settlement from the mobile operator to the merchant takes place to cover all users’ payments over a defined period.</li>
</ul>
</td>
<td>Convenient and secure online payment solution for unbanked / underbanked users who cannot pay by credit card

<p>Increased conversion for merchants</p></td>
</tr>
</tbody>
</table>
<h3><b>Device Location</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API allows an application to check if a mobile device is in proximity of a given location. The API request contains the location to be checked and an&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>accuracy range in km (between 2km and 200km). The API response indicates whether the location is within the accuracy range of the last known location of&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>the MSISDN</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>.&nbsp;</span></span><span>​</span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Fraud prevention (banking, payments): </b>a bank may query the API upon detecting a cash withdrawal or credit card use attempt from an unexpected location. The location verification feeds into the bank risk decision engine and security measures are applied accordingly by the bank.</li>
<li><b>Traffic management of drones: </b>the Uncrewed Aircraft System Traffic Management or the drone operator can obtain drone location information from its GPS data, however this is vulnerable to jamming or spoofing. They can query the API to verify the drone location, e.g. for law enforcement purposes or to check compliance with approved flight plan.</li>
<li><b>Retail marketing:</b> a retailer Edge Application may query the API to verify that a user is close enough to a physical location before pushing a notification to them.</li>
<li><b>Protection of assets e.g. logistics, indoors factory tools (depending on available accuracy)</b>: the fleet manager can check if assets are in their expected location.</li>
</ul>
</td>
<td>Decreased fraud risk without additional friction for the user.
<p>Independent and reliable verification of the location reported by a drone GPS.</p>
<p>Geotargeted marketing</p></td>
</tr>
</tbody>
</table>
<span><a href="https://www.gsma.com/aboutus/legal/anti-trust-policy-statement/" target="_self">GSMA privacy policy&nbsp;<i></i></a></span>

    
    </section>
  </article>
  
	
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mpire: A Python package for easier and faster multiprocessing (140 pts)]]></title>
            <link>https://github.com/sybrenjansen/mpire</link>
            <guid>37089817</guid>
            <pubDate>Fri, 11 Aug 2023 15:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sybrenjansen/mpire">https://github.com/sybrenjansen/mpire</a>, See on <a href="https://news.ycombinator.com/item?id=37089817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">MPIRE (MultiProcessing Is Really Easy)</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sybrenjansen/mpire/workflows/Build/badge.svg?branch=master"><img alt="Build status" src="https://github.com/sybrenjansen/mpire/workflows/Build/badge.svg?branch=master"></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/sybrenjansen/mpire/workflows/Docs/badge.svg?branch=master"><img alt="Docs status" src="https://github.com/sybrenjansen/mpire/workflows/Docs/badge.svg?branch=master"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1033fea2d63358ff14ce80b822c956506b2ba36b8fe97f83ed9750c2792a7de2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d70697265"><img alt="Pypi status" src="https://camo.githubusercontent.com/1033fea2d63358ff14ce80b822c956506b2ba36b8fe97f83ed9750c2792a7de2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d70697265" data-canonical-src="https://img.shields.io/pypi/v/mpire"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4faf85fddc1f6489895661d067a66fa3923e06ce64ab4c11d12129c3c4cf27f0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6d70697265"><img alt="Python versions" src="https://camo.githubusercontent.com/4faf85fddc1f6489895661d067a66fa3923e06ce64ab4c11d12129c3c4cf27f0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6d70697265" data-canonical-src="https://img.shields.io/pypi/pyversions/mpire"></a></p>
<p dir="auto"><code>MPIRE</code>, short for MultiProcessing Is Really Easy, is a Python package for multiprocessing. <code>MPIRE</code> is faster in
most scenarios, packs more features, and is generally more user-friendly than the default multiprocessing package. It
combines the convenient map like functions of <code>multiprocessing.Pool</code> with the benefits of using copy-on-write shared
objects of <code>multiprocessing.Process</code>, together with easy-to-use worker state, worker insights, worker init and exit
functions, timeouts, and progress bar functionality.</p>
<p dir="auto">Full documentation is available at <a href="https://sybrenjansen.github.io/mpire/" rel="nofollow">https://sybrenjansen.github.io/mpire/</a>.</p>
<a name="user-content-features"></a>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Faster execution than other multiprocessing libraries. See <a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9" rel="nofollow">benchmarks</a>.</li>
<li>Intuitive, Pythonic syntax</li>
<li>Multiprocessing with <code>map</code>/<code>map_unordered</code>/<code>imap</code>/<code>imap_unordered</code>/<code>apply</code>/<code>apply_async</code> functions</li>
<li>Easy use of copy-on-write shared objects with a pool of workers (copy-on-write is only available for start method
<code>fork</code>)</li>
<li>Each worker can have its own state and with convenient worker init and exit functionality this state can be easily
manipulated (e.g., to load a memory-intensive model only once for each worker without the need of sending it through a
queue)</li>
<li>Progress bar support using <a href="https://tqdm.github.io/" rel="nofollow">tqdm</a></li>
<li>Progress dashboard support</li>
<li>Worker insights to provide insight into your multiprocessing efficiency</li>
<li>Graceful and user-friendly exception handling</li>
<li>Timeouts, including for worker init and exit functions</li>
<li>Automatic task chunking for all available map functions to speed up processing of small task queues (including numpy
arrays)</li>
<li>Adjustable maximum number of active tasks to avoid memory problems</li>
<li>Automatic restarting of workers after a specified number of tasks to reduce memory footprint</li>
<li>Nested pool of workers are allowed when setting the <code>daemon</code> option</li>
<li>Child processes can be pinned to specific or a range of CPUs</li>
<li>Optionally utilizes <a href="https://pypi.org/project/dill/" rel="nofollow">dill</a> as serialization backend through <a href="https://github.com/uqfoundation/multiprocess">multiprocess</a>, enabling parallelizing more exotic objects,
lambdas, and functions in iPython and Jupyter notebooks.</li>
</ul>
<p dir="auto">MPIRE has been tested on both Linux and Windows. There are a few minor known caveats for Windows users, which can be
found <a href="https://sybrenjansen.github.io/mpire/troubleshooting.html#windows" rel="nofollow">here</a>.</p>
<a name="user-content-installation"></a>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">Through pip (PyPi):</p>

<p dir="auto">MPIRE is also available through conda-forge:</p>
<div dir="auto" data-snippet-clipboard-copy-content="conda install -c conda-forge mpire"><pre>conda install -c conda-forge mpire</pre></div>
<a name="user-content-getting-started"></a>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">Suppose you have a time consuming function that receives some input and returns its results. Simple functions like these
are known as <a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel" rel="nofollow">embarrassingly parallel</a> problems, functions that require little to no effort to turn into a parallel
task. Parallelizing a simple function as this can be as easy as importing <code>multiprocessing</code> and using the
<code>multiprocessing.Pool</code> class:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import time
from multiprocessing import Pool

def time_consuming_function(x):
    time.sleep(1)  # Simulate that this function takes long to complete
    return ...

with Pool(processes=5) as pool:
    results = pool.map(time_consuming_function, range(10))"><pre><span>import</span> <span>time</span>
<span>from</span> <span>multiprocessing</span> <span>import</span> <span>Pool</span>

<span>def</span> <span>time_consuming_function</span>(<span>x</span>):
    <span>time</span>.<span>sleep</span>(<span>1</span>)  <span># Simulate that this function takes long to complete</span>
    <span>return</span> ...

<span>with</span> <span>Pool</span>(<span>processes</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>))</pre></div>
<p dir="auto">MPIRE can be used almost as a drop-in replacement to <code>multiprocessing</code>. We use the <code>mpire.WorkerPool</code> class and
call one of the available <code>map</code> functions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from mpire import WorkerPool

with WorkerPool(n_jobs=5) as pool:
    results = pool.map(time_consuming_function, range(10))"><pre><span>from</span> <span>mpire</span> <span>import</span> <span>WorkerPool</span>

<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>))</pre></div>
<p dir="auto">The differences in code are small: there's no need to learn a completely new multiprocessing syntax, if you're used to
vanilla <code>multiprocessing</code>. The additional available functionality, though, is what sets MPIRE apart.</p>
<a name="user-content-progress-bar"></a>
<h3 tabindex="-1" dir="auto">Progress bar</h3>
<p dir="auto">Suppose we want to know the status of the current task: how many tasks are completed, how long before the work is ready?
It's as simple as setting the <code>progress_bar</code> parameter to <code>True</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="with WorkerPool(n_jobs=5) as pool:
    results = pool.map(time_consuming_function, range(10), progress_bar=True)"><pre><span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>progress_bar</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">And it will output a nicely formatted <a href="https://tqdm.github.io/" rel="nofollow">tqdm</a> progress bar.</p>
<p dir="auto">MPIRE also offers a dashboard, for which you need to install additional <a href="https://sybrenjansen.github.io/mpire/install.html#dashboard" rel="nofollow">dependencies</a>. See <a href="https://sybrenjansen.github.io/mpire/usage/dashboard.html" rel="nofollow">Dashboard</a> for more
information.</p>
<a name="user-content-shared-objects"></a>
<h3 tabindex="-1" dir="auto">Shared objects</h3>
<p dir="auto">Note: Copy-on-write shared objects is only available for start method <code>fork</code>. For <code>threading</code> the objects are shared
as-is. For other start methods the shared objects are copied once for each worker, which can still be better than once
per task.</p>
<p dir="auto">If you have one or more objects that you want to share between all workers you can make use of the copy-on-write
<code>shared_objects</code> option of MPIRE.  MPIRE will pass on these objects only once for each worker without
copying/serialization. Only when you alter the object in the worker function it will start copying it for that worker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="def time_consuming_function(some_object, x):
    time.sleep(1)  # Simulate that this function takes long to complete
    return ...

def main():
    some_object = ...
    with WorkerPool(n_jobs=5, shared_objects=some_object) as pool:
        results = pool.map(time_consuming_function, range(10), progress_bar=True)"><pre><span>def</span> <span>time_consuming_function</span>(<span>some_object</span>, <span>x</span>):
    <span>time</span>.<span>sleep</span>(<span>1</span>)  <span># Simulate that this function takes long to complete</span>
    <span>return</span> ...

<span>def</span> <span>main</span>():
    <span>some_object</span> <span>=</span> ...
    <span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>, <span>shared_objects</span><span>=</span><span>some_object</span>) <span>as</span> <span>pool</span>:
        <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>progress_bar</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">See <a href="https://sybrenjansen.github.io/mpire/usage/workerpool/shared_objects.html" rel="nofollow">shared_objects</a> for more details.</p>
<a name="user-content-worker-initialization"></a>
<h3 tabindex="-1" dir="auto">Worker initialization</h3>
<p dir="auto">Workers can be initialized using the <code>worker_init</code> feature. Together with <code>worker_state</code> you can load a model, or
set up a database connection, etc.:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def init(worker_state):
    # Load a big dataset or model and store it in a worker specific worker_state
    worker_state['dataset'] = ...
    worker_state['model'] = ...

def task(worker_state, idx):
    # Let the model predict a specific instance of the dataset
    return worker_state['model'].predict(worker_state['dataset'][idx])

with WorkerPool(n_jobs=5, use_worker_state=True) as pool:
    results = pool.map(task, range(10), worker_init=init)"><pre><span>def</span> <span>init</span>(<span>worker_state</span>):
    <span># Load a big dataset or model and store it in a worker specific worker_state</span>
    <span>worker_state</span>[<span>'dataset'</span>] <span>=</span> ...
    <span>worker_state</span>[<span>'model'</span>] <span>=</span> ...

<span>def</span> <span>task</span>(<span>worker_state</span>, <span>idx</span>):
    <span># Let the model predict a specific instance of the dataset</span>
    <span>return</span> <span>worker_state</span>[<span>'model'</span>].<span>predict</span>(<span>worker_state</span>[<span>'dataset'</span>][<span>idx</span>])

<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>, <span>use_worker_state</span><span>=</span><span>True</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>task</span>, <span>range</span>(<span>10</span>), <span>worker_init</span><span>=</span><span>init</span>)</pre></div>
<p dir="auto">Similarly, you can use the <code>worker_exit</code> feature to let MPIRE call a function whenever a worker terminates. You can
even let this exit function return results, which can be obtained later on. See the <a href="https://sybrenjansen.github.io/mpire/usage/map/worker_init_exit.html" rel="nofollow">worker_init and worker_exit</a>
section for more information.</p>
<a name="user-content-worker-insights"></a>
<h3 tabindex="-1" dir="auto">Worker insights</h3>
<p dir="auto">When your multiprocessing setup isn't performing as you want it to and you have no clue what's causing it, there's the
worker insights functionality. This will give you insight in your setup, but it will not profile the function you're
running (there are other libraries for that). Instead, it profiles the worker start up time, waiting time and
working time. When worker init and exit functions are provided it will time those as well.</p>
<p dir="auto">Perhaps you're sending a lot of data over the task queue, which makes the waiting time go up. Whatever the case, you
can enable and grab the insights using the <code>enable_insights</code> flag and <code>mpire.WorkerPool.get_insights</code> function,
respectively:</p>
<div dir="auto" data-snippet-clipboard-copy-content="with WorkerPool(n_jobs=5, enable_insights=True) as pool:
    results = pool.map(time_consuming_function, range(10))
    insights = pool.get_insights()"><pre><span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>, <span>enable_insights</span><span>=</span><span>True</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>))
    <span>insights</span> <span>=</span> <span>pool</span>.<span>get_insights</span>()</pre></div>
<p dir="auto">See <a href="https://sybrenjansen.github.io/mpire/usage/workerpool/worker_insights.html" rel="nofollow">worker insights</a> for a more detailed example and expected output.</p>
<a name="user-content-timeouts"></a>
<h3 tabindex="-1" dir="auto">Timeouts</h3>
<p dir="auto">Timeouts can be set separately for the target, <code>worker_init</code> and <code>worker_exit</code> functions. When a timeout has been
set and reached, it will throw a <code>TimeoutError</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def init():
    ...

def exit_():
    ...

# Will raise TimeoutError, provided that the target function takes longer
# than half a second to complete
with WorkerPool(n_jobs=5) as pool:
    pool.map(time_consuming_function, range(10), task_timeout=0.5)

# Will raise TimeoutError, provided that the worker_init function takes longer
# than 3 seconds to complete or the worker_exit function takes longer than
# 150.5 seconds to complete
with WorkerPool(n_jobs=5) as pool:
    pool.map(time_consuming_function, range(10), worker_init=init, worker_exit=exit_,
             worker_init_timeout=3.0, worker_exit_timeout=150.5)"><pre><span>def</span> <span>init</span>():
    ...

<span>def</span> <span>exit_</span>():
    ...

<span># Will raise TimeoutError, provided that the target function takes longer</span>
<span># than half a second to complete</span>
<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>task_timeout</span><span>=</span><span>0.5</span>)

<span># Will raise TimeoutError, provided that the worker_init function takes longer</span>
<span># than 3 seconds to complete or the worker_exit function takes longer than</span>
<span># 150.5 seconds to complete</span>
<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>worker_init</span><span>=</span><span>init</span>, <span>worker_exit</span><span>=</span><span>exit_</span>,
             <span>worker_init_timeout</span><span>=</span><span>3.0</span>, <span>worker_exit_timeout</span><span>=</span><span>150.5</span>)</pre></div>
<p dir="auto">When using <code>threading</code> as start method MPIRE won't be able to interrupt certain functions, like <code>time.sleep</code>.</p>
<p dir="auto">See <a href="https://sybrenjansen.github.io/mpire/usage/map/timeouts.html" rel="nofollow">timeouts</a> for more details.</p>
<a name="user-content-id4"></a>
<h2 tabindex="-1" dir="auto">Benchmarks</h2>
<p dir="auto">MPIRE has been benchmarked on three different benchmarks: numerical computation, stateful computation, and expensive
initialization. More details on these benchmarks can be found in this <a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9" rel="nofollow">blog post</a>. All code for these benchmarks can
be found in this <a href="https://github.com/sybrenjansen/multiprocessing_benchmarks">project</a>.</p>
<p dir="auto">In short, the main reasons why MPIRE is faster are:</p>
<ul dir="auto">
<li>When <code>fork</code> is available we can make use of copy-on-write shared objects, which reduces the need to copy objects
that need to be shared over child processes</li>
<li>Workers can hold state over multiple tasks. Therefore you can choose to load a big file or send resources over only
once per worker</li>
<li>Automatic task chunking</li>
</ul>
<p dir="auto">The following graph shows the average normalized results of all three benchmarks. Results for individual benchmarks
can be found in the <a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9" rel="nofollow">blog post</a>. The benchmarks were run on a Linux machine with 20 cores, with disabled hyperthreading
and 200GB of RAM. For each task, experiments were run with different numbers of processes/workers and results were
averaged over 5 runs.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sybrenjansen/mpire/blob/master/images/benchmarks_averaged.png"><img alt="Average normalized bechmark results" src="https://github.com/sybrenjansen/mpire/raw/master/images/benchmarks_averaged.png"></a></p>
<a name="user-content-documentation"></a>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">See the full documentation at <a href="https://sybrenjansen.github.io/mpire/" rel="nofollow">https://sybrenjansen.github.io/mpire/</a> for information on all the other features of MPIRE.</p>
<p dir="auto">If you want to build the documentation yourself, please install the documentation dependencies by executing:</p>

<p dir="auto">or</p>

<p dir="auto">Documentation can then be build by using Python &lt;= 3.9 and executing:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python setup.py build_docs"><pre>python setup.py build_docs</pre></div>
<p dir="auto">Documentation can also be build from the <code>docs</code> folder directly. In that case <code>MPIRE</code> should be installed and
available in your current working environment. Then execute:</p>

<p dir="auto">in the <code>docs</code> folder.</p>

</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tailscale vs. Narrowlink (308 pts)]]></title>
            <link>https://narrowlink.com/docs/comparisons/tailscale</link>
            <guid>37089739</guid>
            <pubDate>Fri, 11 Aug 2023 15:24:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://narrowlink.com/docs/comparisons/tailscale">https://narrowlink.com/docs/comparisons/tailscale</a>, See on <a href="https://news.ycombinator.com/item?id=37089739">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Narrowlink and Tailscale are two open-source solutions with different architectures that enable secure remote access and connectivity across networks. They share some similarities but also have key differences in their architectures, features, and use cases.</p><h2 id="overview">Overview<a href="#overview" aria-label="Direct link to Overview" title="Direct link to Overview">​</a></h2><p><strong>Tailscale</strong> is a Software-as-a-Service (SaaS) platform that provides a zero-config VPN using the WireGuard protocol. It is partially open source and uses a peer-to-peer mesh architecture that connects devices through the Tailscale cloud services. Tailscale aims to be easy to use out of the box.</p><p><strong>Narrowlink</strong> is a self-hosted platform that consists of a gateway, agents, and clients acting as a proxy server. It uses a client-agent-gateway model to facilitate connectivity across restricted networks. Narrowlink is fully open source and designed to be flexible, transparent, and secure, and it can be deployed on your infrastructure.</p><p>Tailscale and Narrowlink are both excellent solutions for remote access and connectivity. However, Tailscale focuses on enabling access between different devices, while Narrowlink focuses on accessing services through agents as proxies.</p><h2 id="architecture">Architecture<a href="#architecture" aria-label="Direct link to Architecture" title="Direct link to Architecture">​</a></h2><p><strong>Narrowlink</strong> uses a centralized gateway to which clients and agents connect over HTTP/S protocols. The gateway handles routing and connections between agents behind firewalls/NAT and clients. Narrowlink does not have centralized configuration management to define agents, clients, access control policies, etc. The gateway is configured dynamically based on the tokens that agents and clients use, making it easy to scale and deploy.</p><p><strong>Tailscale</strong> devices connect directly to each other over WireGuard in a mesh architecture in a peer-to-peer fashion. Tailscale uses a centralized configuration management system to define devices, access control policies, etc. Traffic is routed through the Tailscale cloud services to facilitate connections between devices.</p><h2 id="open-source">Open Source<a href="#open-source" aria-label="Direct link to Open Source" title="Direct link to Open Source">​</a></h2><p><strong>Narrowlink</strong> is completely open source. All components, including the gateway, agents, and clients, are open source.</p><p><strong>Tailscale</strong> uses the open source WireGuard protocol, and its client apps are open source, but the coordination services are proprietary.</p><h2 id="security-and-privacy">Security and Privacy<a href="#security-and-privacy" aria-label="Direct link to Security and Privacy" title="Direct link to Security and Privacy">​</a></h2><p>Both Tailscale and Narrowlink are considered secure and private. Tailscale uses the WireGuard protocol and provides end-to-end encryption between devices by default. Narrowlink uses the HTTP/S protocol to transfer data between agents and clients to the gateway, which is encrypted by default. Since the data is transferred through the gateway, the gateway has access to the data. However, Narrowlink has implemented optional end-to-end encryption between agents and clients using the XChaCha20-Poly1305 cipher, adding an extra layer of security and privacy.</p><p>Due to the nature of the peer-to-peer architecture, the connection between Tailscale devices can be observed by the ISP and the Tailscale cloud services. However, the data itself is encrypted and cannot be read by the ISP or Tailscale cloud services. In Narrowlink, the ISP only observes the connections between agents or clients and the gateway, which are covered by the HTTPS protocol, appearing as normal web traffic, and the gateway has access to the connection data and info. However, if end-to-end encryption is enabled, the gateway cannot read the data.</p><p>Tailscale requires special permissions such as root/admin access to install and run the client app. It sometimes requires changing the OS and firewall configuration to enable IP forwarding. Narrowlink does not require any special permissions to install and run the agent and client for any of the functionalities.</p><h2 id="internet-sharing">Internet Sharing<a href="#internet-sharing" aria-label="Direct link to Internet Sharing" title="Direct link to Internet Sharing">​</a></h2><p>Both Tailscale and Narrowlink can be used to share internet access between devices. This concept is known as "exit node" in the Tailscale architecture. Tailscale needs to enable IP forwarding on the exit node device, which can lead to security issues as other computers within the same VLAN may use your computer as a gateway. In contrast, Narrowlink does not need to enable any sort of IP forwarding feature or change your firewall configurations, as it acts as a proxy. Additionally, you can apply ACLs to restrict access to the internet.</p><h2 id="access-control">Access Control<a href="#access-control" aria-label="Direct link to Access Control" title="Direct link to Access Control">​</a></h2><p>Both tools use ACLs to control access to devices and services. However, access control in Tailscale is limited in comparison to Narrowlink. Tailscale only supports IP-based ACLs. Narrowlink supports more granular ACLs, including IP, domain, port, and time-based whitelist and blacklist ACLs. Since Narrowlink accesses services through the agent, the ACLs can be applied to the external network that the agent is going to connect to. For example, you can share your network access with your friend while restricting access to specific services on your network or limiting them to access one of the services on the agent's network.</p><h2 id="self-hosted">Self-Hosted<a href="#self-hosted" aria-label="Direct link to Self-Hosted" title="Direct link to Self-Hosted">​</a></h2><p>Narrowlink is designed to be self-hosted on your infrastructure, providing more control and transparency over the data and traffic. Tailscale is a closed SaaS platform that must be used over the internet through their cloud coordination service.</p><h2 id="cdn-compatibility">CDN Compatibility<a href="#cdn-compatibility" aria-label="Direct link to CDN Compatibility" title="Direct link to CDN Compatibility">​</a></h2><p>Since Narrowlink uses HTTP/S protocols as a transport channel, it can be deployed behind a content delivery network (CDN) such as Cloudflare to improve performance. In other words, agents or clients can connect to the gateway through the CDN. Tailscale uses the WireGuard protocol, which is not compatible with CDNs.</p><h2 id="publishing-services">Publishing Services<a href="#publishing-services" aria-label="Direct link to Publishing Services" title="Direct link to Publishing Services">​</a></h2><p>Both Narrowlink and Tailscale can publish your local web services on the internet and automatically issue certificates for them. Tailscale calls this feature "Funnel," but this feature only works for HTTPS connections, and users must use Tailscale's infrastructure to publish their services, using Tailscale's domain (custom domains are not supported). Tailscale issues the certificate on the client machines, preventing the Tailscale infrastructure from decrypting your traffic and using an SNI proxy to route the traffic to the correct client. Narrowlink is more flexible in this case, offering three modes of operation for publishing web services on the internet:</p><ol><li>HTTP/S transparent proxy mode: In this mode, Narrowlink automatically issues and manages the certificates on the gateway, publishing your services on both HTTP and HTTPS protocols. In this mode, the gateway decrypts the TLS traffic and routes it to the correct agent. This mode is perfect for use behind CDNs and is useful for users who prioritize caching and performance over security.</li><li>SNI proxy mode: In this mode, Narrowlink relies on the SNI extension in the TLS protocol, similar to Tailscale, and does not decrypt the traffic. Certificate management should be performed by the users, and they can even use their custom certificate. This mode is useful for users who prioritize security over performance.</li><li>Mixed mode: In this mode, users can define that HTTP connections use the transparent proxy mode, and for TLS connections, it acts as SNI mode.</li></ol><p>Since Narrowlink is a self-hosted platform, you can use your custom domain and publish your web services on any port and protocol.</p><h2 id="network-performance">Network Performance<a href="#network-performance" aria-label="Direct link to Network Performance" title="Direct link to Network Performance">​</a></h2><p>Tailscale technically offers better network performance than Narrowlink due to its peer-to-peer architecture. However, the performance of Narrowlink is still good enough for most use cases. Narrowlink's performance depends on the bandwidth of the gateway and devices, while Tailscale's performance depends on the bandwidth of the devices. Narrowlink can also be deployed behind a CDN to utilize caching and enhance performance for publishing services.</p><h2 id="efficiency">Efficiency<a href="#efficiency" aria-label="Direct link to Efficiency" title="Direct link to Efficiency">​</a></h2><p>Narrowlink has better efficiency in terms of binary size, memory usage, and CPU usage. Narrowlink is written in Rust, while Tailscale is written in Go and C++ for most of its functionality. For example, the Tailscale client binary size is 46MB (tailscale 18MB, tailscale 28MB), while Narrowlink with libc and TLS library static linking is 3.5MB (Ubuntu x64).</p><h2 id="bottom-line">Bottom Line<a href="#bottom-line" aria-label="Direct link to Bottom Line" title="Direct link to Bottom Line">​</a></h2><p>When evaluating Narrowlink vs Tailscale, there are some key differences to consider that are important to understand. This bottom-line summary outlines the major distinctions between the two solutions:</p><ul><li>Tailscale focuses on direct peer-to-peer encrypted connections between devices, while Narrowlink focuses on accessing services through agent proxies.</li><li>Tailscale uses a SaaS model relying on its cloud coordination service, while Narrowlink is self-hosted for more customization and control.</li><li>Tailscale uses WireGuard for better raw throughput performance between devices, while Narrowlink has adequate performance for most use cases.</li><li>Narrowlink supports advanced ACLs, access to external networks, and custom proxy behaviors, while Tailscale has basic IP-based ACLs.</li><li>Narrowlink can be deployed behind CDNs, while Tailscale does not integrate with CDNs.</li><li>Narrowlink offers more flexibility in publishing and exposing services, while Tailscale is more limited.</li><li>Tailscale aims for easy out-of-the-box device connectivity, while Narrowlink offers more options and customizability.</li><li>Narrowlink has smaller binary sizes, lower resource usage, and avoids large dependencies.</li><li>Narrowlink provides additional security by tunneling all traffic through HTTPS to the gateway, while Tailscale uses WireGuard, which exposes some metadata.</li><li>Narrowlink is fully open source, while Tailscale is partially open source.</li></ul><p>In summary, Tailscale prioritizes peer-to-peer device connections with its architecture and SaaS model, while Narrowlink prioritizes self-hosted proxy access, ACL flexibility, customizability, and HTTP/S security at the potential cost of some performance depending on the gateway. Evaluate your specific needs to choose the right tool.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube-Dl Site Goes Offline as Hosting Provider Enforces Court-Ordered Ban (401 pts)]]></title>
            <link>https://torrentfreak.com/youtube-dl-site-goes-offline-as-hosting-provider-enforces-court-ordered-ban-230809/</link>
            <guid>37089545</guid>
            <pubDate>Fri, 11 Aug 2023 15:07:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/youtube-dl-site-goes-offline-as-hosting-provider-enforces-court-ordered-ban-230809/">https://torrentfreak.com/youtube-dl-site-goes-offline-as-hosting-provider-enforces-court-ordered-ban-230809/</a>, See on <a href="https://news.ycombinator.com/item?id=37089545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>

<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Lawsuits category archives." href="https://torrentfreak.com/category/lawsuits/"><span property="name">Lawsuits</span></a><meta property="position" content="2"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Apps and Sites category archives." href="https://torrentfreak.com/category/lawsuits/apps-and-sites/"><span property="name">Apps and Sites</span></a><meta property="position" content="3"></span> &gt; <span></span>
</p>
<p>
<span> </span>
Hosting provider Uberspace has taken down the website of YouTube-ripping software, youtube-dl. The removal is the result of a German court order in a copyright infringement lawsuit, filed by Sony, Warner and Universal. While Uberspace didn't host the open source software, it was held responsible for the website linking to the software hosted on developer platform GitHub.
</p>
</div><div>
<p><img decoding="async" src="https://torrentfreak.com/images/censored-300x220.png" alt="censortube" width="300" height="220" srcset="https://torrentfreak.com/images/censored-300x220.png 300w, https://torrentfreak.com/images/censored.png 960w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20220'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/censored-300x220.png 300w, https://torrentfreak.com/images/censored.png 960w" data-lazy-src="https://torrentfreak.com/images/censored-300x220.png">In 2020, the RIAA <a href="https://torrentfreak.com/riaas-youtube-dl-takedown-ticks-of-developers-and-githubs-ceo-201027/">infuriated</a> many players in the open source community by targeting YouTube-ripping tool, youtube-dl.</p>
<p>The RIAA sent a takedown notice to GitHub, claiming that the software bypassed technological protection measures, in violation of the DMCA. </p>
<p>GitHub initially complied but later changed course. After consulting legal experts, including those at the EFF, it <a href="https://github.com/ytdl-org/youtube-dl">restored</a> the <a href="https://youtube-dl.org/">youtube-dl</a> repository and launched a million-dollar defense fund to assist developers in similar disputes.</p>
<h2>Targeting youtube-dl’s Host</h2>
<p>This episode was a massive setback for the music industry, which had been fighting stream-ripping tools for years. However, instead of laying down their arms, Sony, Warner and Universal went after <a href="https://uberspace.de/en/">Uberspace</a>, youtube-dl’s website hosting company in Germany. </p>
<p>A German court previously ruled that stream-ripping software bypasses YouTube’s ‘rolling cipher’ download protection. This is seen as a circumvention of technical protection measures, a violation of intellectual property law in Europe. </p>
<p>Earlier this year this line of reasoning was also adopted by the district court of Hamburg. While the open source youtube-dl software is hosted on GitHub, Uberspace was <a href="https://torrentfreak.com/music-labels-win-legal-battle-against-youtube-dls-hosting-provider-230404/">held liable</a> as the host of the youtube-dl.org website because it linked to the developer platform. </p>
<p>In its defense, Uberspace argued that the protection can be circumvented using any regular web browser and in any case, the youtube-dl software has plenty of legal uses. These arguments failed to sway the court.</p>
<p>The court recognized that YouTube’s rolling cipher protection is far from perfect but concluded that it’s good enough to signal to average users that downloading content from YouTube is not permitted.</p>
<p>“[T]he average user must recognize that YouTube content, unlike media content on other websites, cannot be downloaded with a simple right-click and must be aware that this is achieved using technology on YouTube and that youtube-dl ‘overrides’ this protection. It is therefore to be assumed that the average user acts in bad faith,” the Hamburg Court <a href="https://openjur.de/u/2466945.html">wrote</a>.</p>
<h2>Ban Enforced</h2>
<p>The ruling was published in March but Uberspace wasn’t required to take action right away. The hosting company decided to appeal, which meant that the youtube-dl.org site remained online, unless the music companies posted a €20,000 bond.</p>
<p>Initially, it didn’t appear that the labels would enforce the order, but that changed a few days ago. The plaintiffs informed Uberspace that they had posted the security, leaving the company no other choice than to take the site offline. </p>
<p>Speaking with TorrentFreak, Uberspace owner Jonas Pasche says that his hands are tied. Failure to comply with the order would either result in a massive fine, or worse, a prison sentence.</p>
<p>“I received that information from the plaintiff’s side on July 27, with proof that they did the security deposit at a bank. So I no longer have a choice but to follow the judgment. Otherwise, I would face a fine of €250,000 or jail time,” Pasche notes.</p>
<center><img decoding="async" src="https://torrentfreak.com/images/youtube-host-block.jpg" alt="youtube-dl" width="600" height="282" srcset="https://torrentfreak.com/images/youtube-host-block.jpg 906w, https://torrentfreak.com/images/youtube-host-block-300x141.jpg 300w" sizes="(max-width: 600px) 100vw, 600px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20600%20282'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/youtube-host-block.jpg 906w, https://torrentfreak.com/images/youtube-host-block-300x141.jpg 300w" data-lazy-src="https://torrentfreak.com/images/youtube-host-block.jpg"></center>
<p>For several days, people who visited youtube-dl’s website saw a blocking notice instead, which is shown above. At the time of writing, the website doesn’t load at all. </p>
<h2>Appeal ‘Censorship’ Order</h2>
<p>Uberspace will continue the legal battle and is prepared to fight the order up to the highest court possible. If the appeal is successful, Pasche will gladly unblock the site.</p>
<p>“We are confident that a higher court will overturn the judgment of the Hamburg Regional Court, so we will be able to unblock the site as soon as this happens,” he says. </p>
<p>Uberspace is not the website’s domain registrar, so youtube-dl may yet decide to point its domain elsewhere. For now, that hasn’t happened. The software remains available <a href="https://github.com/ytdl-org/youtube-dl">on GitHub</a> where it also has a <a href="http://ytdl-org.github.io/youtube-dl/">dedicated website</a>.</p>
<p>The hosting company previously <a href="https://torrentfreak.com/youtube-dl-hosting-ban-paves-the-way-to-privatized-censorship-230411/">told us</a> that the Hamburg court’s ‘devastating’ order opens the door to privatized censorship, citing this threat as one of the main reasons to fight back.</p>
<p>“The consequences of this will be that hosting providers receiving complaints will most likely kick out their customers without a court ruling, for things that might be perfectly legal,” Pasche said at the time.</p>
<p>“This is a shameful day for the freedom of speech. It’s paving the way for privatized censorship. Do we as a society really want this? We strongly believe we’re on the right side of history here.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The crash of Air France flight 447 (2021) (164 pts)]]></title>
            <link>https://admiralcloudberg.medium.com/the-long-way-down-the-crash-of-air-france-flight-447-8a7678c37982</link>
            <guid>37089363</guid>
            <pubDate>Fri, 11 Aug 2023 14:53:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admiralcloudberg.medium.com/the-long-way-down-the-crash-of-air-france-flight-447-8a7678c37982">https://admiralcloudberg.medium.com/the-long-way-down-the-crash-of-air-france-flight-447-8a7678c37982</a>, See on <a href="https://news.ycombinator.com/item?id=37089363">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://admiralcloudberg.medium.com/?source=post_page-----8a7678c37982--------------------------------"><div aria-hidden="false"><p><img alt="Admiral Cloudberg" src="https://miro.medium.com/v2/resize:fill:88:88/2*pZPMtIONqtJYi2xHYD_Ivg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="f955"><em>Note: this accident was previously featured in episode 10 of the plane crash series on November 11th, 2017, prior to the series’ arrival on Medium. This article is written without reference to and supersedes the original.</em></p><figure><figcaption>Searchers recover the tail section of Air France flight 447 from the Atlantic on June 7th, 2009. (The Guardian)</figcaption></figure><p id="1d4b">In the early hours of the first of June 2009, Air France flight 447 from Rio de Janeiro to Paris disappeared in a radar dead zone over the mid-Atlantic. The Airbus A330 with 228 people on board had vanished into the night without a distress call, leaving behind little to explain its sudden and dramatic end. What could have brought down a modern passenger jet, flying for a world class airline, during what should have been the safest part of the flight? For two years, the world could only speculate, as search teams scoured a vast area of the ocean floor in search of the elusive black boxes.</p><p id="5a31">When the recorders were finally found in May 2011, they revealed a story at once more prosaic and more inexplicable than anyone had imagined. A brief interruption to their airspeed indications, lasting less than a minute, had thrown two trained Air France pilots into a state of paralyzed agitation. Through a series of increasingly misguided control inputs, they sent flight 447 plummeting towards the ocean, all the while trying desperately to understand what was wrong, only grasping too late that they themselves were the problem. How could such a thing happen? To this day, most people still struggle to understand it. But there is a reason, written between the lines of the cockpit voice recorder transcript, hidden away within the mysterious code that governs human behavior, a key to the secrets of the profoundly irrational. Its lessons could not be more important, even for those who believe themselves above the doomed crew of flight 447, as the boundary between the responsibilities of man and machine grows ever dimmer.</p><p id="fdfb">◊◊◊</p><figure><figcaption>A CGI image of flight 447 in its final hours. (PBS Nova)</figcaption></figure><p id="5f46">It’s 1:00 a.m., the middle of the Atlantic Ocean. 35,000 feet above the night-dark waves, dim overhead lights illuminate the cockpit of Air France flight 447. Captain Marc Dubois has headphones on, listening to opera. The pilot flying, First Officer Pierre-Cédric Bonin, stares dully at the instrument panel.</p><p id="cd58">Dubois hands Bonin his headset, and for a few moments they listen together. “All that’s missing is the whiskey!” Bonin eventually says, handing the headset back to his captain, one might imagine with a smile. Flight 447 flies on into the night. Red and green lights steady, white lights blinking. No one knows it, but they are passing into that strange realm between life and death, hurtling onward into the void, unaware that they have already walked for the last time among the living.</p><figure><figcaption>The pilots of flight 447, probably pictured in their license photos. (Original source unknown)</figcaption></figure><p id="8a2e">Three hours earlier in Rio de Janeiro, Brazil, 216 passengers and 12 crew boarded Air France flight 447 for an overnight flight to Paris. The plane was an Airbus A330, a fully fly-by-wire wide body jet with an impeccable safety record; since its introduction in 1994, the type had never had a fatal accident in passenger service. The flight crew consisted of 58-year-old Captain Marc Dubois, a veteran pilot with nearly 11,000 hours; 32-year-old First Officer Pierre-Cédric Bonin, an inexperienced copilot with 2,000 hours who had recently come up through Air France’s in-house training program; and 37-year-old Relief First Officer David Robert, who would fill in during the middle of the flight so that Captain Dubois could get his legally mandated rest. Robert had also learned to fly at Air France, but had since graduated to an executive position, and had joined the crew of flight 447 in order to keep his type rating. His landing in Rio de Janeiro during the inbound trip was his first in three months.</p><figure><figcaption>The route of flight 447. (Google + own work)</figcaption></figure><p id="0e24">For Air France pilots, the Rio de Janeiro rotation was a coveted trip, complete with a three-day layover at a beachside hotel in Copacabana. Pilots often spent their rest days partying, sightseeing, and restaurant-hopping. First Officer Bonin had brought his wife along for the ride, leaving their kids at home in France; Captain Dubois had also brought his girlfriend, an off-duty flight attendant and opera singer, with whom he had been seen out on the town the night before the flight. Dubois was said to have gotten just one hour of sleep before boarding flight 447.</p><p id="66c9">Although none of the pilots were well-rested, they also knew that their advanced plane could bail them out. Unlike older generations of jets, the A330 was designed to minimize the consequences of crew errors, incorporating flight envelope protections that would make it impossible for the pilots to pitch too steeply up or down, fly too fast or too slow, bank too far to one side, or generate G-loads that could overstress the airframe. Furthermore, thanks to the plane’s advanced flight management system, they could enter the entire flight plan before departure, and the plane would all but fly itself from just after takeoff until right before landing. The pilots’ job primarily consisted of tactical decision-making and monitoring the instruments.</p><figure><figcaption>F-GZCP, the aircraft involved in the accident. (Hansueli Krapf)</figcaption></figure><p id="f270">Flight 447 took off from Rio de Janeiro at 22:29 UTC, climbed to its cruising altitude of 35,000 feet, and proceeded northeast up the coast of Brazil. Bonin was the pilot flying, although he had little reason to touch the controls, and Dubois monitored the instruments. David Robert hung back in the crew quarters, trying to get some sleep before going on duty.</p><p id="c62d">As the flight passed off Natal and headed out into the Atlantic, the pilots mostly kept to themselves. Dubois pointed out the equator, and Bonin joked about “feeling the bump” as they passed over it. An hour passed. Everything seemed to be going smoothly.</p><p id="691f">At around 1:30 a.m. UTC, the Brazilian oceanic control center, Atlantico, contacted the crew and instructed them to remain at flight level 350–35,000 feet. “Eh, well there you are,” said Captain Dubois. Keying his mic, he replied to the controller, “Okay, will do.” It would be flight 447’s last communication with the outside world.</p><p id="7959">First Officer Bonin had been using the cockpit weather radar to observe a growing band of thunderstorms in their path, a region known as the Intertropical Convergence Zone, where thunderstorms are practically a permanent fixture. All the pilots on flight 447 had flown through it many times before, crossing over it twice on every trip to South America. But tonight Bonin seemed more nervous than usual. “We’ll soon ask to climb, surely,” he said, expressing his dissatisfaction with the controller’s order to stay at 35,000 feet, and his desire to get above the worst of the weather.</p><figure><figcaption>Satellite weather data from the Intertropical Convergence Zone at around midnight on the night of the accident, with flight 447’s designated airway overlaid. (BEA)</figcaption></figure><p id="a697">But Captain Dubois knew that there was no need to change altitude. In his judgment the weather was unlikely to be any better at 37,000 feet, the highest they could fly at their current weight, nor was it likely to be dangerous at any flight level. At most they could expect some mild turbulence or icing. And if they really needed to, then they could divert around it.</p><p id="3fba">“So we’ve got a… thing straight ahead,” Bonin said, sounding nervous.</p><p id="b6f3">“Yes, I saw that,” said Dubois.</p><p id="e82b">Eleven minutes later, Bonin said, “It looks like we’re entering the cloud cover.”</p><p id="37d2">Dubois had no comment.</p><p id="1128">“It would have been good to climb now, eh?” Bonin said.</p><p id="03ae">“Yeah, if it’s turbulence,” Dubois said, without the slightest hint of worry.</p><p id="9eba">Now deep in the oceanic sector, the plane was outside the radar range of any airport. Out here, planes were kept apart by keeping northbound traffic on odd flight levels and southbound traffic on even flight levels. But the next highest odd level, 37,000 feet, was close to their maximum altitude — maybe too close. Bonin suggested that they request a non-standard altitude of 36,000 feet.</p><p id="3aae">“We’ll wait a little, see if it goes that way,” Dubois replied.</p><p id="851e">Bright flashes of light streaked across the windscreen, the eerie glow of St. Elmo’s fire. The sound of ice crystals hitting the plane rose to a dull roar in the background.</p><figure><figcaption>St. Elmo’s Fire in an aircraft cockpit. (Beyond Clouds)</figcaption></figure><p id="66d7">At this point Captain Dubois decided it was time to turn in for the night. He rang the call button to summon First Officer Robert from the bunk room. To Bonin, he said, “Er, who’s doing the landing, is it you? Well, he’s going to take my place. You’re a PL, right?”</p><p id="211c">“Yeah,” said Bonin.</p><p id="36e8">This was the closest Dubois ever came to deciding who would be in command after he left the flight deck.</p><p id="d0da">Two minutes later, Robert entered the cockpit. “Did you sleep?” Bonin asked.</p><p id="3c09">“So-so,” Robert replied.</p><p id="f4e5">“You didn’t sleep?” Dubois interjected.</p><p id="7109">“He said so-so, so-so,” said Bonin.</p><p id="cf81">“Well, then I’m out of here,” said Dubois.</p><p id="ebd6">Bonin briefed Robert on the situation: they were cruising at 35,000 feet, there was a storm ahead but they couldn’t climb to 37,000. Their attempt to log on with the oceanic control system in Dakar, Senegal had failed, but this was not an uncommon occurrence and Bonin knew it. All around, nothing terribly unusual. Robert settled in for the next leg of the flight.</p><p id="07b4">About six minutes later, noting the storm cell in their path, Robert said, “Don’t you maybe want to go to the left a bit?”</p><p id="67ea">“Excuse me?”</p><p id="21a9">“You can possibly go a bit to the left,” Robert repeated.</p><p id="1b96">With two first officers in the cockpit, and the less experienced one at the controls, it was unclear who was in charge. Decisions seemed to be taken by mutual agreement. Bonin never replied to Robert’s suggestion, so nothing was done.</p><p id="c110">Now a smell of ozone started to seep into the cockpit, a not unusual phenomenon when flying through highly charged thunder clouds. But Bonin didn’t seem to recognize it, and it was making him nervous. The ozone, the Saint Elmo’s fire, the storms — none of it was out of the ordinary for a transatlantic crossing, but for some reason it was starting to get to him.</p><figure><figcaption>How ice blocks a pitot tube and affects airspeed readings. (boldmethod)</figcaption></figure><p id="7820">For the past several minutes, they had been flying through a cloud of high-altitude ice crystals within the upper reaches of the thundercloud. Normally this would not be a problem, but if the concentration of crystals is high enough, they can clog the pitot tubes — the airspeed sensors — faster than the built-in heaters can melt them. This is what occurred on flight 447.</p><p id="9cd1">The A330 has three pitot tubes, one each for the captain, the first officer, and the standby instruments. Each pitot tube measures the pressure of the oncoming air, which is then compared to the static pressure to derive the plane’s airspeed. This data in turn is used to calculate a number of other parameters, including Mach number, vertical speed, and altitude, which are all displayed instantaneously to the pilots. But if ice crystals clog the pitot tubes, air cannot enter them, causing the measured pressure to drop, which in turn causes a decrease in indicated airspeed.</p><p id="db2a">On flight 447, as all three pitot tubes filled up with ice, the airspeed readings quickly became invalid. Sensing a growing discrepancy between the three sources of airspeed data, at 2:10 a.m. and four seconds the autopilot disconnected with a sudden cavalry charge warning. The auto thrust shut off a split second later. Taken completely by surprise, First Officer Bonin announced, “I have the controls!” and reached for his side stick.</p><figure><figcaption>The principle of the “flight envelope.” (Philippe Goupil)</figcaption></figure><p id="2f79">Behind the scenes, the loss of valid airspeed data had triggered a shift in the Airbus’s complex flight control laws. In “normal law,” computers interpret pilots’ side stick inputs and move the control surfaces in accordance with what is reasonable at that altitude, speed, and configuration. This improves the handling of the airplane to such an extent that no particular skill is required to fly it gracefully. Normal law also comes with full flight envelope protections in roll, pitch, speed, and load factor.</p><p id="60d2">If sensor failures occur, the controls drop down a level to “alternate law.” This law contains several sub-laws with slightly different configurations, but in general, alternate law means that some or all computer moderation of control inputs remains, but flight envelope protections are removed. The autopilot and auto thrust cease to function.</p><p id="9209">In the event of further failures, the controls can enter direct law, in which there are no flight envelope protections and side stick inputs correspond directly to the position of the control surfaces, with no adjustment by the computer. This makes the airplane fly rather like a classic airliner, similar to most older Boeing models.</p><p id="1f51">When the airspeed readings became invalid on flight 447, the control law changed to “alternate 2B,” which is specific to loss of speed data. In this law, load factor protection remains, but there is no autopilot, no auto thrust, and no high or low speed protection; furthermore, lateral (roll) control functions as it does in direct law. All of this happened near instantaneously, leaving the pilots completely in control of the airplane with little advance warning.</p><p id="1809">As soon as the autopilot disconnected, turbulence caused the plane to roll eight degrees to the right; Bonin immediately grabbed the side stick and rolled it back to the left, his inputs rough and jerky. At the same time, he pulled back on the stick, putting the plane into a climb. The A330 began to ascend rapidly from its cruise altitude of 35,000 feet, zooming upward through the impenetrable blackness, as multiple alarms blared over the cockpit speakers.</p><figure><figcaption>How a stall works. (NASA)</figcaption></figure><p id="b9b7">Climbing while at high altitudes above 30,000 feet is something that requires care and consideration. At these altitudes, a plane’s maximum safe speed and minimum safe speed are quite close together (and at a certain height they will in fact meet, a zone that pilots call the “coffin corner”). Fundamentally, as angle of attack — the angle of the plane into the airstream — increases, lift increases, until it reaches the critical point and drops off rapidly, causing the plane to stall. Because the air is thin at high altitude and provides little lift, a higher speed is necessary to keep the plane airborne, and the critical angle of attack is very low. Pitching up even a few degrees could place the plane on the edge of a stall. And in fact, as Bonin pulled back on his stick, the plane’s stall warning activated for three seconds, informing him that the angle of attack, for a moment anyway, was dangerously high.</p><figure><figcaption>Flight data from the first 20 seconds after the start of the event. (BEA)</figcaption></figure><p id="7375">But the warning proved transient, and neither pilot recognized it. Robert asked, “What was that?”</p><p id="45b1">Bonin did not directly address the question. “We haven’t got a good… we haven’t got a good display of speed,” he said. A continuous C-chord pinged away in the background, warning that they had left their assigned altitude.</p><p id="134f">A number of warning messages had appeared on the computer screen, and Robert began to read them off in a disjointed, confused manner. None of them explicitly stated the cause of the failure, only the symptoms, including the disconnection of the autoflight systems and the switch to alternate law. By now, flight 447 was climbing through 37,000 feet, still going up, but decelerating alarmingly.</p><p id="49fb">Robert must have noticed their high pitch angle, because he said to Bonin, “Watch your speed, watch your speed!” But neither pilot had a valid airspeed reading.</p><p id="6272">“Okay, okay, okay, I’m going back down,” said Bonin, lowering the nose. But he didn’t lower it enough to stop climbing, and he reduced engine thrust, exacerbating the loss of airspeed even further.</p><p id="d7ca">“Go back down! According to that we’re going up,” Robert said, presumably pointing at their altitude readout. “According to all three you’re going up, so go back down.”</p><p id="8b43">“Okay.”</p><p id="a5bd">“You’re at… go back down!”</p><p id="908c">“It’s going, we’re going back down,” Bonin insisted, restoring engine thrust to maximum. But the plane kept climbing.</p><p id="1f90">Robert started switching Bonin’s instruments to alternate sources, but in a wholesale manner, indicating that he had not identified what instruments were actually faulty. Having done this, he started trying to summon Captain Dubois, ringing the call button with almost frenetic urgency. Clearly both pilots were in over their heads; only Dubois, it seemed, could help them. By now the airspeed indications had returned to normal, but the pilots had already set in motion a sequence of events which could not be undone.</p><figure><figcaption>Flight data from 46 seconds after the start of the event to 106 seconds after the start of the event. (BEA)</figcaption></figure><p id="c472">At that moment the plane’s angle of attack, now rising through ten degrees, again triggered the stall warning, and this time it didn’t go away. Accompanied by continuous clicking, an automated voice began to call out, “STALL! STALL!”</p><p id="96a3">Flight 447 reached a peak altitude of 38,000 feet, stalled, and began to descend. Nose high, engines straining, the plane started to accelerate downward, following a long descending arc that grew steeper with every passing second.</p><p id="b180">“STALL! STALL!”</p><p id="058c">Bonin was frantically trying to keep the wings level, but the disrupted airflow and his own jerky control inputs made this all but impossible. The plane swayed wildly from side to side, reaching bank angles of up to forty degrees. “Above all, try to touch the lateral controls as little as possible, eh?” Robert suggested.</p><p id="858f">“STALL! STALL!”</p><p id="9335">“I’m in TOGA, eh?” Bonin said, referring to takeoff/go around, the highest normal thrust setting. He didn’t seem to understand why, if he had engine power set to TOGA, they were descending.</p><p id="e87e">“Is he coming or not!?” Robert said, searching for some sign of the captain.</p><p id="545b">“STALL! STALL!”</p><p id="f8ba">“But we’ve got the engines, what’s happening?” Robert exclaimed. “Do you understand what’s happening or not?”</p><p id="faf9">“STALL! STALL!”</p><p id="c0cc">“I don’t have control of the airplane anymore now!” said Bonin. “I don’t have control of the airplane at all!” With the nose pitched up and the engines at max thrust, he simply couldn’t fathom why they weren’t climbing. Overwhelmed by the noise of the warnings, the terrifying vibrations, and the wildly fluctuating instrument readings, his brain seemed to shut down, paralyzed by confusion and fear.</p><figure><figcaption>A very basic diagram like this would have probably helped the pilots understand what the plane was doing. (Flying Magazine)</figcaption></figure><p id="d6ef">By now the plane was falling toward the ocean at a rate of 10,000 feet per minute, and accelerating. The angle of attack was more than forty degrees. The only way to recover was to push the nose down, regain airspeed, and then pull out at a lower altitude. But Bonin just kept pulling his side stick back, forcing the nose up.</p><p id="a0ee">“Controls to the left,” Robert said, still worried about their bank angle. Pressing the priority button on his side stick, he took control and locked out Bonin, but Bonin immediately pressed his own priority button and assumed control again.</p><p id="e752">“STALL! STALL!”</p><p id="36ba">Bonin said something which might be best translated as, “I have the impression that we’re going crazy fast.” His impression couldn’t have been further from the truth.</p><p id="b233">At that moment, Captain Dubois returned to the cockpit to find a scene of chaos. “Er, what are you doing?” he said, glancing around in an attempt to figure out what was going on.</p><p id="1d82">“What’s happening?” Robert asked. “I don’t know, I don’t know what’s happening!”</p><p id="cb00">“We’re losing control of the airplane,” said Bonin.</p><p id="6738">“We lost all control of the airplane, we don’t understand anything, we’ve tried everything!” Robert said, desperation in his voice. But in fact they had tried nothing at all.</p><p id="fdc3">“STALL! STALL!”</p><p id="ce0e">“I have a problem, it’s that I don’t have vertical speed indication,” said Bonin. His vertical speed indicator was working perfectly; he just didn’t believe what it said. “I have no more displays!” he opined, although again, all indications were correct and all his instruments were working.</p><p id="dc63">“We have no more displays!” Robert repeated.</p><p id="39a4">“I have the impression that we have some crazy speed, no?” Bonin said. “What do you think?”</p><p id="3913">“STALL! STALL!”</p><p id="7cbe">“So we’re still going down,” Bonin said.</p><p id="c627">“We’re pulling,” said Robert. “What do you think about it, what do you think — what do we need to do?”</p><p id="dba7">“There — I don’t know, it’s going down!” said Dubois. He had made no effort to assume control, continuing to look over his first officers’ shoulders instead.</p><p id="ed5c">As the plane plummeted toward the Atlantic Ocean, the pilots only became more confused and agitated. Recovery was already impossible; the fates of all on board were carved in stone. All that followed was a final, terrible fight to the death.</p><p id="e9ea">“The wings to flat horizon, the standby horizon!”</p><p id="bd2e">“The horizon!”</p><p id="eabb">“Speed?”</p><p id="00e3">“You’re climbing!”</p><p id="6d1e">“You’re going down, down, down!”</p><p id="2161">“Am I going down now?”</p><p id="fb74">“Go down!”</p><p id="2bcd">“No, you’re climbing!”</p><p id="1668">“I’m climbing, okay, so we’re going down!”</p><p id="7b1b">“STALL! STALL!”</p><p id="24cb">“Okay what are we here? On altitude, what do we have here?”</p><p id="f522">“…It’s impossible,” Captain Dubois said, completely baffled.</p><p id="bfb6">“STALL! STALL!”</p><p id="5bff">“What do you mean, on altitude?</p><p id="0a90">“Yeah yeah yeah, I’m going down no?”</p><p id="1954">“You’re going down, yes!”</p><p id="ba24">“Hey you, you’re in — get the wings horizontal!”</p><p id="b604">“Get the wings horizontal!”</p><p id="3ad0">“That’s what I’m trying to do! I’m at the limit with the roll!”</p><p id="9601">“We lost it all! I’ve got nothing here!”</p><p id="5f6b">“We’re there, we’re passing level 100!” Flight 447 was falling through 10,000 feet, still deeply stalled, headed straight into the jaws of oblivion.</p><p id="8381">“Wait, me — I have the controls!” Robert said. But Bonin didn’t stop pulling up.</p><p id="e18a">“What is… how come we’re continuing to go down right now?” Bonin asked.</p><p id="2435">“STALL! STALL!”</p><p id="4601">“Nine thousand feet!” Bonin cried out.</p><p id="e45d">“Climb, climb, climb, climb…” Robert said, as though trying to will the plane to stop falling.</p><p id="4d76">“But I’ve been at maximum nose up for a while!” said Bonin.</p><p id="c7ba">It was at that point that Captain Dubois finally understood what was happening. “No no no, don’t climb!” he shouted. But it was already much too late to intervene. Not even the most skilled pilot on earth could have saved them.</p><figure><figcaption>CGI animation of the stall and crash. (Mayday)</figcaption></figure><p id="c7cb">These final moments of Air France flight 447 would go down in aviation history as some of the most tragic and the most baffling.</p><p id="36cb">“So go down!” said Robert. “So give me the controls, the controls to me, controls to me!”</p><p id="47e5">“Go ahead, you have the controls!” said Bonin.</p><p id="a3b7">“STALL! STALL!”</p><p id="34eb">“Watch out, you’re pitching up there!” said Dubois. Incredibly, both Bonin and Robert were still hauling back on their side sticks.</p><p id="082a">“I’m pitching up,” said Robert.</p><p id="8003">“You’re pitching up!” Dubois shouted.</p><p id="e1b3">“Well we need to, we are at four thousand feet!” said Bonin. It was true, it was far too late to recover by pitching down. Not that it would matter anyway.</p><p id="a943">“PULL UP,” said the ground proximity warning system. “PULL UP! PULL UP!”</p><p id="4e23">“Go on, pull,” Dubois said. Was this comment a sardonic resignation to fate?</p><p id="1120">“PULL UP! PULL UP!”</p><p id="dcf5">“We’re going to crash!” Bonin cried out. “This can’t be true! But what’s happening?”</p><p id="d8af">“PULL UP! PULL UP!”</p><p id="c667">“Ten degrees pitch attitude,” Dubois drily commented. His would be the last words on the cockpit voice recording. Less than two seconds later, with a forward airspeed of just 107 knots and a descent rate of 11,000 feet per minute, Air France flight 447 slammed belly-first into the Atlantic Ocean. In a fraction of a second, like so many candles, 228 lives flickered and went out.</p><p id="0351">◊◊◊</p><figure><figcaption>A map from early in the search on the day of the crash. (BBC News)</figcaption></figure><p id="83a9">It would not be until 4:00 a.m. UTC, nearly two hours after the crash, that controllers in Senegal began to realize that they should have heard from Air France 447, but had not. They tried everything — contacting nearby control centers, asking other planes, asking Air France — but no one had spoken to flight 447 since shortly before 2:00 in the morning. At 4:59, having tried and failed to establish contact with flight 447 via satellite, an Air France dispatcher told the Dakar control center that something must be seriously wrong. 24 minutes later, fearing that the plane had gone down in the Atlantic, Brazil and Senegal issued an alert to rescue services, and the search for the plane began.</p><p id="cec1">The problem was that Air France flight 447 had apparently vanished within an area that had no radar coverage, no possibility of witnesses, and only spotty radio contact. No one knew exactly when or where the plane went down, and with each passing hour, any floating debris would drift farther from its point of origin. By the time the first search planes actually departed, more than ten hours had passed since the crash, and the debris was already scattering.</p><figure><figcaption>A Brazilian newspaper front page shows the faces of some of the missing. (Vanderlei Almeida)</figcaption></figure><p id="3b98">Meanwhile, investigators with France’s Bureau of Inquiry and Analysis (BEA) set up an elite team to investigate what promised to be the most complicated and most important accident in the history of French aviation. Although they didn’t have the airplane, they didn’t start with nothing: like all modern aircraft, the Airbus A330 regularly broadcasts data to the airline for diagnostic purposes. This system, known as ACARS, sent a burst of data approximately every ten minutes, with additional messages if certain warning conditions were met. The last regular message, sent at 2:10, indicated that there was a problem with the pitot-static system, the autopilot had disengaged, and the controls were in alternate law. Several additional messages sent between 2:10 and 2:14 indicated faults with the Air Data Reference units, the computers which process airspeed, and an abnormally high rate of descent. It was just enough to prompt speculation, but not enough to explain what had happened, or why.</p><figure><figcaption>A map of the surface search and its discoveries. (The New York Times)</figcaption></figure><p id="4123">One thing that investigators suspected from the very beginning was a problem with the pitot tubes. At the time of its disappearance, flight 447 was flying through storms in the intertropical convergence zone, the perfect conditions for pitot tube icing. This particular model of pitot tube had been shown on several occasions to experience ice accumulation greater than the heaters could remove, leading to a loss of airspeed data. In fact, Air France, Airbus, and the pitot tube manufacturer had been holding meetings on the matter since 2008, and earlier in 2009 a study had shown that a newer model of Thales pitot tube could significantly reduce the frequency of such incidents. Air France quickly ordered the new pitot tubes for all of its Airbus A330s, and the first airplane was retrofitted on May 30th, just hours before Air France flight 447 left Rio de Janeiro. Although the airline had been proactive, their efforts came ever so slightly too late for the 228 passengers and crew now presumed lost at sea.</p><figure><figcaption>Searchers recover the tail section of Air France flight 447 from the Atlantic on June 7th, 2009. (The Guardian)</figcaption></figure><p id="6baf">But to know how exactly frozen pitot tubes, a relatively minor malfunction, could have led to the catastrophic crash of a wide body jet with a flawless record, investigators needed the black boxes. Everyone knew that they would be hard to find — but few could have guessed just how difficult it would turn out to be.</p><p id="490d">By the afternoon of June 1st, French officials had already acknowledged that there was “no hope for survivors,” but the scope of the sea search only continued to increase. On June 2nd, a Brazilian plane spotted an apparent oil slick and light floating debris; on the 6th of June, two bodies were found, along with personal effects, and the plane’s vertical stabilizer was located on the 7th. In all, by the end of June searchers had found over 600 pieces of the airplane and the bodies of 50 victims, including Captain Dubois. Engineering analysis of the debris and autopsies of the victims revealed that the plane had impacted the water in a nearly flat pitch attitude with a high rate of descent, but again, investigators couldn’t say why. The answers, as ever, lay with the flight recorders.</p><figure><figcaption>Another view of the recovery of the tail section. (France24)</figcaption></figure><p id="1148">The A330’s two black boxes were equipped with pingers that could be detected by specialized equipment, but the batteries which powered the pingers were only rated to last 30 days. Although authorities moved quickly to bring in search ships capable of detecting the pingers, their chances of finding the black boxes inside the 30-day window were slim. With the plane likely resting at a depth of up to 4,000 meters, surface vessels would need to get very close to the site of the wreckage in order to pick up the signal, and with no radar record, it was impossible to know with any specificity where the plane had actually entered the water. It was unfortunately no surprise that the 30-day period went by with no sign of the black boxes.</p><p id="24d3">At that point, the search entered its third phase: a methodical sonar examination of an area extending 75 kilometers in all directions from the plane’s last known position, as reported by ACARS. Carried out between April and May 2010, this search failed to turn up any sign of the plane. All data indicated that the plane should have been within the search area, but covering every square kilometer in detail was difficult, and a more precise search would be needed.</p><p id="6695">The fourth phase began in the spring of 2011, focusing on areas not covered by the previous search within a limited 37-kilometer radius around the last known position. This search began on the 25 of March, and had been in progress for just seven days when sonar imagery detected the presence of a large debris field on the ocean floor. On the 3rd of April, a submarine equipped with a camera reached the debris field, returning images that left investigators speechless: after nearly two long years, there lay Air France flight 447, shattered on the barren floor of the abyssal plain, four kilometers beneath the Atlantic.</p><figure><figcaption>(BEA)</figcaption></figure><p id="93be">Examining the debris field inch by inch, searchers managed to find the flight recorders by the beginning of May, followed soon after by several substantial chunks of wreckage and the bodies of a further 104 passengers and crew. Another 74 bodies were never found, having apparently been lost to the sea.</p><p id="d481">The much-anticipated readout of the black boxes occurred at the BEA headquarters in Paris in May 2011. At long last, investigators listened, transfixed, to the voices of the doomed crew on that fateful night in 2009 — voices that some had doubted they would ever hear. But as those haunting conversations played out over the two hour tape, it became clear that the black boxes would raise just as many questions as they answered.</p><figure><figcaption>Photos of various parts of the airplane as they were found on the ocean floor. (BEA)</figcaption></figure><p id="4e88">By integrating the cockpit voice recorder and the flight data recorder, investigators were able to show that at the moment the airspeeds became invalid and the autopilot disconnected, First Officer Pierre-Cédric Bonin began to pull back on his side stick, raising the nose, and that he maintained this input almost continuously until impact. The data was indisputable; Bonin had stalled the airplane, sending it to its doom. But this explanation in fact explained very little. Every airline pilot should know that such inputs will lead to a stall, so why did Bonin seem to be oblivious to the danger?</p><figure><figcaption>The tail section of flight 447 is hauled aboard a salvage ship. (NBC News)</figcaption></figure><p id="01b8">Answering this question proved to be by far the most complicated part of the entire investigation. Understanding what went through the minds of the pilots requires a second-by-second analysis of the final four minutes of the flight, considering all of the disparate cues which each pilot was trying to assimilate.</p><p id="db4b">But first, it is critical to understand who Pierre-Cédric Bonin was as a pilot. In the popular consciousness, a pilot is a semi-heroic figure who flies a plane by hand, guiding it through all manner of dangers. Bonin was perhaps living proof that this type of pilot has not existed for decades.</p><p id="9e70">In fact, the job of a modern pilot on a plane like the A330 is far more abstract. The average A330 pilot will hand-fly an airplane for maybe four minutes out of every flight, and will pilot only two or three flights a week, sometimes fewer. The vast majority of their time is spent programming automation, monitoring computer activity, and making broad, tactical decisions about the flight. Physical skill is far less important than emotional intelligence, good memory, and an ability to communicate. And on a highly automated plane like the A330, it’s all but impossible to discover who possesses such physical skill in the first place.</p><figure><figcaption>Investigators lay out the recovered debris on the floor of a hangar for identification and analysis. (Der Spiegel)</figcaption></figure><p id="e26c">Physical, or traditional, piloting skills are typically developed through extensive experience flying small aircraft which have little or no automation. These aircraft force a pilot to develop an intuitive understanding of how airplanes behave in various regimes of flight, and anyone who cannot develop these skills will wash out at an early stage. Captain Marc Dubois no doubt had these skills: between 1977 and 1987, he obtained type ratings on no less than 17 different light aircraft and accrued thousands of hours flying them. If he had been in the pilot’s seat when the airspeed indicators failed on flight 447, there is little doubt that he would have reacted correctly: he surely had an intuitive understanding that, in the absence of any configuration changes, the plane will continue to fly on its previously established trajectory, even if all the instruments are lost — a sort of airman’s object permanence. He would have known that all he needed to do was nothing.</p><figure><figcaption>The tail section is loaded onto a truck in port for transportation to the evidence hangar. (CNN)</figcaption></figure><p id="5af4">Bonin, on the other hand, had a completely different background. He had followed a fast-track trajectory to the right seat of the Airbus A330, flying small planes just long enough to get his private and air transport pilot’s licenses before being inducted into Air France with just a couple hundred flight hours. He was immediately trained to fly the advanced fly-by-wire Airbus A320, before upgrading to the Airbus A340 and finally the A330, all of which were heavily automated. Any rudimentary “traditional” skills which he had gained during his brief time flying light aircraft would have quickly degraded. Although Bonin would have learned about the principles of aircraft dynamics in a classroom setting, such instruction is an order of magnitude less valuable than getting to feel the principles in action while at the controls of a fully mechanical airplane. Instead, he spent the next 2,000 flight hours watching as computers flew the jet on his behalf. His total time actually hand-flying an airliner couldn’t have been more than a couple dozen hours, all of them within the bounds of the flight envelope protections, which he knew made it impossible for him to lose control. If you asked him, Bonin probably could have told you what a stall is and how it works, but could he have identified one in real life?</p><figure><figcaption>A floating galley section was found, complete with intact drawers. (Reuters)</figcaption></figure><p id="2579">The extent of his stall-related training leaves room for doubt. Air France did not train its pilots on prevention or recovery from high altitude stalls, even though these have several fundamental differences from low-altitude stalls. If the stall warning activates during the initial climb away from an airport, a scenario which Bonin practiced many times in the A330 simulator, it is possible to avert the stall by applying maximum thrust and maintaining a nose up attitude of about twelve degrees. The denser air closer to sea level ensures that the plane is stable in such a configuration. But at 35,000 feet, this will not work: pitch angles as low as four or five degrees will be sufficient to activate the stall warning, and an actual stall will follow soon after.</p><p id="b21a">However, all of that is hypothetical, because nearly all of the time, Airbus aircraft cannot stall. The flight envelope protections simply will not allow any inputs which raise the angle of attack above the critical point, and with these protections in place, there isn’t even a stall warning, because a stall will not and cannot occur. A pilot can haul back on the side stick with all their might, and the plane will rear up to whatever angle the algorithms determine is safe. Nothing the pilot can do will make it pitch up more.</p><p id="3bf0">With these facts in mind, consider the scenario actually faced by the crew of flight 447. They were at high altitude where even a mild nose up input could quickly escalate into a stall. Bonin and Robert were probably only vaguely aware of this fact, which was rather esoteric in an environment where the flight envelope was clearly limited (although it was their duty to know it). And then suddenly all the protections vanish, as the loss of airspeed data forces the controls to slip into alternate law. After all, the computer can’t protect against a stall if it doesn’t know how fast the plane is going. Does Bonin know that the plane is in alternate law? And if he does, does he understand what that means? In theory it’s his job to know, but he doesn’t.</p><figure><figcaption>The complex interrelationship between measured and calculated flight parameters. (BEA)</figcaption></figure><p id="0355">At the moment that the airspeed data became invalid, a curious quirk of the plane’s internal calculations might have set the whole sequence of events in motion. Because of the location of the A330’s static ports, which measure the basic outside air pressure, the reading is somewhat affected by the plane’s airspeed, due to leakage of rushing air into the ports. Generally this results in a slightly elevated static pressure reading. Because static pressure increases as altitude decreases, this design quirk would cause the sensor to continually underestimate the plane’s altitude. To account for this, an algorithm applies a small correction to the static pressure reading based on the airspeed reported by the pitot tubes, in the process correcting the altitude to its true, higher value. But if the pitot tubes suddenly start reporting an erroneously low airspeed — say they’re blocked by ice — the size of the applied correction will be smaller, and the plane’s indicated altitude will decrease, even though it is in fact flying straight and level.</p><figure><figcaption>A recovery worker prepares the galley section for salvage. (The Guardian)</figcaption></figure><p id="9004">Consequently, at the moment the pitot tubes froze on Air France flight 447, the indicated altitude dropped by about 350 feet, and the vertical speed indicator briefly displayed a descent rate of 600 feet per minute. Bonin didn’t comment on these figures, so we can’t prove that he saw them. But if he did, it would explain his initial decision to pull the nose up: he probably thought the airplane was descending. And what did he think would happen if he pulled the nose up? Most likely, that the plane would climb at a protected angle, safely below the stall margin, no matter how hard he pulled back on the stick or how long he held it there. There was no need for such an extreme input, but it seems he was caught by the startle effect, feeling compelled to take drastic action, but without understanding what form that action should take, and believing that the computer would bail him out if he did something wrong.</p><p id="5538">It is somewhat more difficult to explain why Bonin kept pulling on the stick even after his instruments showed the plane passing back through its initial cruise altitude and continuing toward 37,000 feet. But his comments earlier in the flight, in which he repeatedly expressed a desire to climb above the weather, provide a possible reason. If he thought the plane would be out of the clouds at around 37,000 feet, and if he was concerned about the possibility of turbulence or other severe conditions inside the storm, his first instinct upon seeing the cascade of warnings might have been to try to escape from the area of bad weather. Perhaps he wanted to climb as high as the plane would let him, not knowing that all such protections had been withdrawn.</p><figure><figcaption>Another part of the galley was used to prove that the plane hit the water in a flat attitude. (BEA)</figcaption></figure><p id="6a2e">At the same time, there is considerable evidence that Bonin was more concerned about flying too fast than he was about flying too slow. Pilots in general were aware, to an almost superstitious extent, that exceeding the maximum operating speed could lead to the breakup of the airplane in flight, and that at high altitudes this maximum speed was not that much faster than the normal cruising speed. In fact, on an Airbus operating in normal law, the airspeed indicator in front of each pilot displays markers representing the maximum and minimum allowable speeds (as defined by the flight envelope protections), and the actual speed in cruise is usually much closer to the former than the latter. Many pilots, including Bonin, had probably developed a false belief that overspeed was a more pressing danger than stalling. In fact, it’s the other way around: in the 20 years leading up to the crash of flight 447, there had been considerably more crashes involving high-altitude stalls than crashes involving overspeed-related breakup.</p><p id="1e5a">In light of these assumptions, when Bonin saw the plane appearing to descend in the first seconds after the failure, his instinctive reaction may have been to protect the plane against entering an overspeed condition. Furthermore, when the max/min speed markers disappeared during the transition to alternate law, his sense of where these boundaries lay became uncertain. This uncertainty, and the irrational fear of flying too fast, may have pre-conditioned him to ignore cues which indicated that he was actually flying too slowly.</p><p id="4af9">It is also worth noting that Bonin and Robert had both undergone training on unreliable airspeed events, during which pilots were instructed to adopt a known power setting and pitch angle which would result in a stable flight path. However, much like the stall training, it was assumed that the most critical unreliable airspeed scenario is one which occurs at low altitude during initial climb. Although procedures for other phases of flight could be found in the manual, the training conditioned pilots to expect unreliable airspeed events during climb, to which they would respond with a steady nose-up pitch and high power setting that would ensure a shallow ascent. Such a response would be completely inappropriate in cruise.</p><figure><figcaption>A reconstruction of the warning messages the pilots would have seen during the event. (BEA)</figcaption></figure><p id="2f91">Investigators found that because of this conditioning, in a dozen or so previous cases of unreliable airspeed in cruise on the Airbus A330 and the similar A340, not a single crew had correctly identified the anomaly and applied the stabilization procedure. In one case, the pilot even applied nose-up inputs which triggered a stall warning, although deviation from the flight path was ultimately minimal. Therefore Bonin and Robert were not the exception in failing to initially identify the cause of the malfunctions and apply the known solution. In all of these cases, part of the problem was that in the actual events, the loss of speed data was accompanied by a series of alarms and warning messages which were not present in the simulator scenarios, and none of these messages explicitly stated that there was a problem with the pitot tubes, contributing to pilots’ difficulty identifying the root cause.</p><figure><figcaption>Debris lies of the floor of the hangar following recovery from the sea surface. (CNN)</figcaption></figure><p id="c7bf">Having pitched their plane up to the very brink of a stall, Bonin and Robert could have saved the day by reacting correctly to the stall warning which began to sound as the plane approached 38,000 feet. There are however several possible reasons why they ignored it. One is that their minds were already so saturated with information that they simply never heard it. Instrument indications were seemingly going haywire, nobody knew what instruments they could trust, the pilots were desperately trying to figure out what the plane was doing, the computer screen was covered in warning messages, and a continuous C-chord chime was running in the background. Scientific studies have shown that in such situations, the capacity of the human brain to tune out seemingly obvious auditory cues is considerable.</p><p id="ac72">Another possible reason is that the stall warning had previously activated for three seconds shortly after the disconnection of the autopilot, when Bonin initially pitched up. At that time the stall warning was unexpected and difficult for the pilots to rationalize. Crews involved in similar incidents reported that they assumed the brief stall warnings were generated by the erroneous airspeed readings, a not unreasonable interpretation which breaks down only when one learns that the stall warning calculations are based on angle of attack and do not incorporate any airspeed data. Thus, the stall warnings in all such cases were real. But in a situation where they were not expecting a stall warning, and in which they might have believed the plane could not stall, it’s not hard to imagine that Bonin and Robert heard the stall warning but simply didn’t believe it.</p><figure><figcaption>The tail section lies on the deck of a Brazilian navy ship following its recovery from the sea. (Der Spiegel)</figcaption></figure><p id="0f6b">At this point, Robert, despite his greater experience, failed to stop Bonin from stalling the airplane, even though he appeared to recognize that his fellow pilot was pitching up too steeply. Investigators noted that during most of the period between the onset of the event and the stall, Robert was trying to interpret the warning messages and was not directly paying attention to the flight path. Although he did tell Bonin to “go down,” Bonin’s halfhearted response was apparently enough to satisfy him, as he went right back to analyzing the problem. It is also worth noting that Robert had the same non-traditional piloting background as Bonin; he was likely operating on little sleep; and he had barely flown since being promoted into airline management. All things considered he was just as unprepared for the situation as Bonin was.</p><p id="ebb4">Once the airplane actually stalled, the crew of flight 447 found themselves beyond the scope of anything they had learned in training. Training scenarios never allowed the stall to fully develop, in part because the simulators in use at Air France could not faithfully simulate the behavior of the aircraft after exiting the normal flight envelope. The scenarios thus focused on preventing stalls, not recovering from them, and while the pilots likely knew in principle that they would need to pitch down to recover from a fully developed stall, this knowledge would have been purely academic in nature. Neither Bonin nor Robert had ever attempted such a maneuver, not in a simulator and definitely not in real life.</p><figure><figcaption>What the flight directors would have displayed during the periods when they were active during initial climb and stall. (BEA)</figcaption></figure><p id="5b05">This lack of practical knowledge combined with several conflicting cues to cement Bonin’s pre-established desire to pull up and climb. One of these cues came from the flight director, an overlay on the pilot’s attitude indicator which provides command bars that the pilot can follow in order to achieve a desired flight path. Normally the flight directors will disappear if the airspeed data becomes unreliable, and at first they did. But if the pilots don’t turn them off, they will come back as soon as two of the three Air Data Reference computers provide it with airspeed readings that are consistent with one another. On flight 447, the pilots never attempted to turn off the flight directors, and they came back as soon as the pitot tubes unfroze and the airspeed data became valid again, which occurred just before the onset of the stall. Not knowing the intentions of the crew, when the flight directors come online, they automatically instruct the pilot to maintain the current trajectory, until the pilot programs them to do otherwise. The result was that the flight directors re-engaged not in cruise mode, but in vertical speed mode with a target climb rate of 1,400 feet per minute — the exact rate at which flight 447 was climbing at that particular moment. From then on the flight directors, whenever they had valid data, instructed the pilots to attain an approximately 12-degree nose up attitude in order to reach this target vertical speed. Flight data indicates that at several points during the stall, Bonin may have been attempting to follow this erroneous flight director instruction.</p><figure><figcaption>A BEA investigator sorts wreckage in the hangar. (Eric Cabanis)</figcaption></figure><p id="d1cc">In fact, by coincidence the target pitch angle displayed by the flight director was almost exactly equal to the target pitch angle Bonin had learned to use while powering out of a low-altitude stall. This finding raises the question of whether Bonin thought that following the flight director would lead to the stabilization of the flight path. This interpretation is supported by Bonin’s comments to the effect that high power and a high pitch angle should cause them to climb. It seems likely that he not only thought he was flying the stall avoidance procedure, but that he believed the flight director was instructing him to do so as well. He apparently never recognized that the plane was already in a fully developed stall, and that this procedure was completely irrelevant to their actual situation.</p><p id="8ffe">During flight 447’s plunge toward the sea, the flight directors disappeared every time the forward airspeed dropped below 60 knots. This was because an airspeed below 60 knots while in flight is so anomalous that the computers are programmed to reject such a reading as false. Furthermore, at an angle of attack threshold which corresponded quite closely to 60 knots, the stall warning would cease for exactly the same reason. This created an unfortunate correlation, wherein Bonin would pitch up, the angle of attack and airspeed would exceed the rejection thresholds, the flight director would stop telling him to fly up, and the stall warning would cease; then if he attempted to pitch down, the angle of attack data would become valid again, the flight director would tell him to pitch up, and the stall warning would return. This perverse Pavlovian relationship could have subconsciously conditioned Bonin to believe that pitching down was causing the plane to approach the stall envelope, and that by pitching up he was actually protecting the plane against stalling. This violated basic aeronautical common sense, but by this point Bonin and common sense might as well have been on different planets.</p><figure><figcaption>BEA investigators present the black boxes. (CNN)</figcaption></figure><p id="ed6d">David Robert, had he taken decisive action, could perhaps have saved the plane if he had recognized that Bonin was causing the stall. At times he seemed aware that Bonin was pulling up, at times not; but many experts believe that the very design of the Airbus made it harder for him to understand his copilot’s actions. Unlike most other airliners, the control sticks on Airbus models are not mechanically linked and the pilots cannot directly feel what the other pilot is doing. Although this usually doesn’t present a problem — in the course of normal flight, pilots rarely touch the side stick —this can become a liability in an emergency situation involving a breakdown in communication. The design of the side stick assumes that the pilots are well-trained in crew resource management and are communicating their actions to one another, but this ideal appears dangerously naive in light of the confusion on the flight deck of Air France 447. Airbus has stuck to its guns, and no change of the side stick design appears imminent, but the debate rages on, and it is widely believed that a linked side stick could have allowed Robert to recognize and correct the situation well before Dubois arrived to bail him out.</p><p id="b70c">Unfortunately, by the time Captain Dubois entered the cockpit, the stall was already well advanced and their chances of survival were slim. Had he immediately recognized the problem, kicked Robert out of his seat, locked out Bonin from the controls, and executed a flawless stall recovery maneuver he might have saved the plane. But despite his expertise, he only seemed to realize what was happening shortly before impact. His difficulty understanding the situation could be explained by the first officers’ panic, the large number of extraneous indications and alarms, and the fact that he was operating on one hour of sleep. In theory, he should have seen that they were pitched up with the engines at high power and descending rapidly, a configuration that could only mean they were in a stall; there was no other explanation. But for whatever reason, he didn’t make the connection. In the fog of confusion, it took him too long to put two and two together, and by the time he did, he already knew there was no hope of recovery.</p><figure><figcaption>A BEA investigator presents the findings of the investigation. (Mehdi Fedouach)</figcaption></figure><p id="6a8d">In the end, there is no single interpretation of the situation which fully explains why Bonin did what he did. In all likelihood, his actions were the result of a confused mixture of conflicting ideas, which caused him to make decisions which were based on completely contradictory scenarios. Did he think they were in overspeed, or did he think he was applying a stall recovery procedure? The answer may not be either-or; in such a state of mind, rational thought tends to break down, and moment-by-moment instincts take over. It’s entirely possible that he held both opinions during the fatal descent, maybe even at the same time.</p><figure><figcaption>Flight attendants mourn their colleagues at a memorial service at the Notre Dame. (The Guardian)</figcaption></figure><p id="784d">Looking back on this bewildering body of evidence, the loss of Air France flight 447 kind of starts to make sense, in a distorted sort of way, like real life reflected in a funhouse mirror. We can start to see how a pilot who fundamentally does not understand his aircraft could fall into this trap, grasping wildly at trees without seeing the forest. What Bonin and Robert needed was aeronautical common sense, and they didn’t have it. It is so easy for those of us who have read about Air France flight 447 and similar accidents to point the finger and say the accident was Bonin’s fault, that he alone killed 227 other people. But such an accusation ignores the fact that Bonin was systematically underprepared for the situation in which he found himself. It is easy, from the vantage point of 2021, living in a world where Air France flight 447 has become one of the most studied accidents of all time, to say that he should have known better. And indeed he should have, but that’s not the point: the point is that Bonin was only a symptom of a deeper problem.</p><figure><figcaption>French Prime Minister Francois Fillion meets with Air France crews at a ceremony for the victims. (Antonio Scorza)</figcaption></figure><p id="d377">In fact, Air France flight 447 represented a turning point in how the global aviation industry approaches the subject of automation. There is no denying that automation has made flying much safer; the data supporting this conclusion is irrefutable. But amid the swift march of progress, it is important not to lose sight of the foundations on which that progress is built. Just like Alternate Law always lurks beneath Normal Law, underneath a layer of automation there lies the same need for traditional piloting skill that has always existed, and will continue to exist for the foreseeable future. We catch fewer glimpses into that realm than we used to, but it is still there, visible whenever something goes wrong with the automation. The fundamental paradox, one outlined by famed aviation author William Langewiesche, is this: the rarer such moments become, the harder it is to ensure that pilots are ready for them; and yet at the same time, their readiness becomes all the more important. After the crash of flight 447, solving this paradox became the foremost priority of aviation safety experts around the world, and the fruits of their efforts are only now becoming apparent.</p><figure><figcaption>A memorial to the victims of flight 447 evokes 228 transparent birds in flight. (Bertrand Langlois)</figcaption></figure><p id="dd0a">Today, flying is not the same as it was in 2009, when Dubois, Robert, and Bonin boarded their Airbus A330 for the last time. Training again emphasizes basic piloting skills and aeronautical common sense; high altitude stalls are a major training topic; and increased simulator fidelity has allowed the widespread introduction of Upset and Recovery Training, now mandatory in the United States and Europe, which confronts pilots with extreme situations and forces them to fly their way out. There are some pilots out there who still lack these skills, but there are surely fewer of them now than there were ten or fifteen years ago. A marked decline in the number of major airline accidents in the second half of the 2010s has testified to this fact. But it would be a mistake to believe that the problem is, or even can be, fully solved. As long as humans fly airplanes, some amount of information will always be lost while translating between man and machine, and from these imperfections spring the seeds of catastrophe. The next major crash of a large airliner, wherever it may occur, will almost certainly have something to do with the interaction between pilots and the automation that they oversee. In the meantime, it would be beneficial, even for those of us who are not pilots, to look on the events of Air France flight 447 and accept that we are human, that our capacity to err is unbound by reason, and that the best way to avoid disaster is to learn from the mistakes of others.</p><p id="0190">_______________________________________________________________</p><p id="c809"><a href="https://www.reddit.com/r/CatastrophicFailure/comments/q4ohcj/2009_the_crash_of_air_france_flight_447_analysis/?" rel="noopener ugc nofollow" target="_blank">Join the discussion of this article on Reddit!</a></p><p id="312a">Visit <a href="https://www.reddit.com/r/AdmiralCloudberg/" rel="noopener ugc nofollow" target="_blank">r/admiralcloudberg</a> to read and discuss over 200 similar articles.</p><p id="b17f">You can also <a href="https://www.patreon.com/Admiral_Cloudberg" rel="noopener ugc nofollow" target="_blank">support me on Patreon.</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Want to pwn a satellite? Turns out it's surprisingly easy (116 pts)]]></title>
            <link>https://www.theregister.com/2023/08/11/satellite_hacking_black_hat/</link>
            <guid>37088716</guid>
            <pubDate>Fri, 11 Aug 2023 13:56:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/08/11/satellite_hacking_black_hat/">https://www.theregister.com/2023/08/11/satellite_hacking_black_hat/</a>, See on <a href="https://news.ycombinator.com/item?id=37088716">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Black Hat</span> A study into the feasibility of hacking low-Earth orbit satellites has revealed that it's worryingly easy to do.</p>
<p>In a presentation at the <a target="_blank" href="https://www.theregister.com/special_features/blackhat_and_defcon">Black Hat security conference</a> in Las Vegas, Johannes Willbold, a PhD student at Germany's Ruhr University Bochum, <a target="_blank" rel="nofollow" href="https://www.blackhat.com/us-23/briefings/schedule/#houston-we-have-a-problem-analyzing-the-security-of-low-earth-orbit-satellites-32468">explained</a> he had been investigating the security of satellites. He studied three types of orbital machinery and found that many were utterly defenseless against remote takeover because they lack the most basic security systems.</p>
<p>"People think that satellites are secure," he said. "Those are expensive assets and they should have encryption and authentication. I assume that criminals think the same and they are too hard to target and you need to be some kind of cryptography genius. Maybe it wasn't a good idea to give this talk."</p>

    

<p>Satellite operators have been lucky so far. The prevailing wisdom is that hacking this kit would be prohibitively expensive due to the high cost of ground stations that communicate with the orbital birds, and that such hardware benefited from security by obscurity – that getting hold of the details of the firmware would be too difficult. Neither is true, the research indicates.</p>
<blockquote>

<p>Those are expensive assets and they should have encryption and authentication. I assume that criminals think the same and they are too hard to target</p>
</blockquote>
<p>For example, both AWS and Microsoft's Azure now offer Ground Station as a Service (GSaaS) to communicate with LEO satellites, so communication is simply a matter of plonking down a credit card. As for getting details on firmware, the commercial space industry has flourished in recent years and many of the components used on multiple platforms are easy to buy and study – Willbold estimated a hacker could build their own ground station for around $10,000 in parts.</p>
<p>As an academic, Willbold took a more direct approach. He just asked satellite operators for the relevant details for <a href="https://jwillbold.com/paper/willbold2023spaceodyssey.pdf" rel="nofollow">his paper</a> [PDF]. Some of them agreed (although he did have to sign an NDA in one case) and the results somewhat mirrored the early computing days, when security was sidelined because of the lack of computing power and memory.</p>

        


        

<p>He studied three different types of satellite: an ESTCube-1, a tiny CubeSat 2013 running an Arm Cortex-M3 processor, a larger CubeSat OPS-SAT operated by the European Space Agency as an orbital research platform, and the so-called Flying Laptop – a larger and more advanced satellite run by the Institute of Space Systems at the University of Stuttgart.</p>
<ul>

<li><a href="https://www.theregister.com/2023/08/10/viasat_reports_revenue_up_but/">Viasat probe into ailing $700M satellite casts shadow over Q1 results</a></li>

<li><a href="https://www.theregister.com/2023/04/26/kemba_walden_cybersecurity_space/">US National Cyber Director: Fending off cyber threats in space is 'urgent,' needs 'high level attention'</a></li>

<li><a href="https://www.theregister.com/2023/08/09/black_hat_def_con/">It's that time of the year again: The trinity of infosec conferences</a></li>
</ul>
<p>The results were depressing. Both the CubeSats failed at a most basic level, with no authentication protocols, and they were broadcasting signals without encryption. With some code Willbold would have been able to take over the satellites' basic control functions and lock out the legitimate owner, which he demonstrated during the talk with a simulation.</p>
<p>The Flying Laptop was a different case, however. It had basic security systems in place and tried to isolate core functions from interference. However, with some skill, code, and standard techniques, this satellite too proved vulnerable.</p>
<h3>Low priority</h3>
<p>Intrigued by the results, Willbold decided to dig deeper. He contacted developers working on sat systems to check the data, and got nine responses from devs who worked on a total of 132 satellites over their careers. This wasn't easy – it took four months to garner those responses.</p>
<p>The results showed that security systems were way down on the list of priorities when it comes to satellite design. Only two of the respondents had tried any kind of penetration testing. The problem, he opined, was that space science is such a rarefied field that the developers just didn't have the security skills to do a rigorous shakedown of a satellite in the first place.</p>
<div><p><img src="https://regmedia.co.uk/2023/06/03/comp_earth_moonlighter_satellite.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Composition of the Moonlighter satellite orbiting Earth"></p><h2 title="'World's first and only' orbiting infosec playpen due to blast off Sunday">Uncle Sam wants DEF CON hackers to pwn this Moonlighter satellite in space</h2>
<p><a href="https://www.theregister.com/2023/06/03/moonlighter_satellite_hacking/"><span>READ MORE</span></a></p></div>
<p>One surprising result was that the larger the satellite (and thus more expensive to build and launch), the more vulnerable it was. Larger machinery typically used more commercial off-the-shelf components and was thus more vulnerable since the code base was public, whereas smaller CubeSats tended to use custom code.</p>
<p>As for what would happen if a satellite was hijacked, Willbold suggested a number of alternatives. They could be used to transmit malicious information or code to targets on the ground, or to talk to other satellites in a constellation and subvert those too. In a worst-case scenario, a satellite could be moved to crash into another one, spewing debris all over orbit and potentially knocking out more systems.</p>
<p>When asked by <em>The Register</em> if it would be possible to retrofit security systems to satellites, Willbold wasn't hopeful.</p>

        

<p>"From a very technical perspective it would be possible. But realistically these systems are built on very tight margins," he said.</p>
<p>"They have planned these systems for every milliwatt of power that is used to run the satellite, so there is not the power budget on existing systems to run encryption or authentication. It's not practical." ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenTerraform – an MPL fork of Terraform after HashiCorp's license change (131 pts)]]></title>
            <link>https://github.com/diggerhq/open-terraform</link>
            <guid>37088591</guid>
            <pubDate>Fri, 11 Aug 2023 13:41:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/diggerhq/open-terraform">https://github.com/diggerhq/open-terraform</a>, See on <a href="https://news.ycombinator.com/item?id=37088591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Open Terraform</h2>
<p dir="auto">An open-source (MPL) fork of Hashicorp's Terraform following their <a href="https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license" rel="nofollow">change of license</a></p>
<p dir="auto">Created and maintained by <a href="https://github.com/diggerhq/digger">Digger.dev</a>, an open-source CI runner for infrastructure-as-code</p>
<blockquote>
<p dir="auto">The license change is not retroactive. This means all source code and releases prior to the change remain under the MPL 2.0 license. You may continue to use those versions indefinitely under the original license. (from <a href="https://www.hashicorp.com/license-faq#What-did-HashiCorp-announce-today-(Aug-10)" rel="nofollow">Hashicorp's blog</a>)</p>
</blockquote>
<ul dir="auto">
<li>HashiCorp's Website: <a href="https://www.terraform.io/" rel="nofollow">https://www.terraform.io</a></li>
<li>Forums: <a href="https://discuss.hashicorp.com/c/terraform-core" rel="nofollow">HashiCorp Discuss</a></li>
<li>Documentation: <a href="https://www.terraform.io/docs/" rel="nofollow">https://www.terraform.io/docs/</a></li>
<li>Tutorials: <a href="https://learn.hashicorp.com/terraform" rel="nofollow">HashiCorp's Learn Platform</a></li>
<li>Certification Exam: <a href="https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate" rel="nofollow">HashiCorp Certified: Terraform Associate</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1a4ed08978379480a9b1ca95d7f4cc8eb80b45ad47c056a7cfb5c597e9315ae5/68747470733a2f2f7777772e6461746f636d732d6173736574732e636f6d2f323838352f313632393934313234322d6c6f676f2d7465727261666f726d2d6d61696e2e737667"><img alt="Terraform" src="https://camo.githubusercontent.com/1a4ed08978379480a9b1ca95d7f4cc8eb80b45ad47c056a7cfb5c597e9315ae5/68747470733a2f2f7777772e6461746f636d732d6173736574732e636f6d2f323838352f313632393934313234322d6c6f676f2d7465727261666f726d2d6d61696e2e737667" width="600px" data-canonical-src="https://www.datocms-assets.com/2885/1629941242-logo-terraform-main.svg"></a></p>
<p dir="auto">Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.</p>
<p dir="auto">The key features of Terraform are:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Infrastructure as Code</strong>: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.</p>
</li>
<li>
<p dir="auto"><strong>Execution Plans</strong>: Terraform has a "planning" step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.</p>
</li>
<li>
<p dir="auto"><strong>Resource Graph</strong>: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.</p>
</li>
<li>
<p dir="auto"><strong>Change Automation</strong>: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.</p>
</li>
</ul>
<p dir="auto">For more information, refer to the <a href="https://www.terraform.io/intro" rel="nofollow">What is Terraform?</a> page on the Terraform website.</p>
<h2 tabindex="-1" dir="auto">Getting Started &amp; Documentation</h2>
<p dir="auto">Documentation is available on the <a href="https://www.terraform.io/" rel="nofollow">Terraform website</a>:</p>
<ul dir="auto">
<li><a href="https://www.terraform.io/intro" rel="nofollow">Introduction</a></li>
<li><a href="https://www.terraform.io/docs" rel="nofollow">Documentation</a></li>
</ul>
<p dir="auto">If you're new to Terraform and want to get started creating infrastructure, please check out our <a href="https://learn.hashicorp.com/terraform#getting-started" rel="nofollow">Getting Started guides</a> on HashiCorp's learning platform. There are also <a href="https://learn.hashicorp.com/terraform#operations-and-development" rel="nofollow">additional guides</a> to continue your learning.</p>
<p dir="auto">Show off your Terraform knowledge by passing a certification exam. Visit the <a href="https://www.hashicorp.com/certification/" rel="nofollow">certification page</a> for information about exams and find <a href="https://learn.hashicorp.com/terraform/certification/terraform-associate" rel="nofollow">study materials</a> on HashiCorp's learning platform.</p>
<h2 tabindex="-1" dir="auto">Developing Terraform</h2>
<p dir="auto">This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on <a href="https://registry.terraform.io/" rel="nofollow">the Terraform Registry</a>. HashiCorp develops some providers, and others are developed by other organizations. For more information, see <a href="https://www.terraform.io/docs/extend/index.html" rel="nofollow">Extending Terraform</a>.</p>
<ul dir="auto">
<li>
<p dir="auto">To learn more about compiling Terraform and contributing suggested changes, refer to <a href="https://github.com/diggerhq/open-terraform/blob/main/.github/CONTRIBUTING.md">the contributing guide</a>.</p>
</li>
<li>
<p dir="auto">To learn more about how we handle bug reports, refer to the <a href="https://github.com/diggerhq/open-terraform/blob/main/BUGPROCESS.md">bug triage guide</a>.</p>
</li>
<li>
<p dir="auto">To learn how to contribute to the Terraform documentation in this repository, refer to the <a href="https://github.com/diggerhq/open-terraform/blob/main/website/README.md">Terraform Documentation README</a>.</p>
</li>
</ul>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto"><a href="https://github.com/hashicorp/terraform/blob/main/LICENSE">Mozilla Public License v2.0</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What HashiCorp’s license change means for our customers (214 pts)]]></title>
            <link>https://spacelift.io/blog/hashicorps-license-change</link>
            <guid>37088548</guid>
            <pubDate>Fri, 11 Aug 2023 13:37:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spacelift.io/blog/hashicorps-license-change">https://spacelift.io/blog/hashicorps-license-change</a>, See on <a href="https://news.ycombinator.com/item?id=37088548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>On August 10, </span><a href="https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license" target="_blank" rel="nofollow noopener"><span>HashiCorp announced</span></a><span> that they are changing the license on all their products to exclude use by direct competitors.</span></p></div><div><h2>What does it mean in practice?</h2>
<p><span>Beyond Terraform 1.5.5, direct HashiCorp competitors will be unable to incorporate the source code or embed or distribute newer versions of Terraform.</span></p>
</div><div><h2>How does it impact us?</h2>
<p><span>What we know for sure is that current versions of Terraform are, and will remain, unaffected, so there is no concern for your usage today. We are working with lawyers and experts to ensure we remain compliant going forward. We will provide updates soon.</span></p>
</div><div><h2>Can they do it?</h2>
<p><span>Yes, they can. They required every contributor to Terraform to sign a CLA that allowed this. Being legal does not make the move ethical or consistent with the ideals of open source software.</span></p>
</div><div><h2>They claim that we’re taking advantage of what they’re building. Are they right?</h2>
<p><span>Software is normally built in layers, and it’s not unusual to have commercial layers running on top of open source layers. Nobody is accusing GitHub of exploiting the Git ecosystem. In fact, much of the success of Git is due to the emergence of higher-level platforms like GitHub, Bitbucket, GitLab, and others. Competition in services on top of Terraform has recently driven much innovation as many of our own concepts eventually found their way to Terraform Cloud. It’s also worth remembering that Terraform itself is built on top of multiple open source libraries and an open source ecosystem. Without the volunteer work of hundreds of unpaid individuals, HashiCorp products would not be successful, there would be no ecosystem, and the company would not exist.</span></p>
</div></div><div><div><p><span><span></span><img alt="avatar_image_marcinw" srcset="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2Fb9ba5de8e05bd6d85824eb156694b0e1%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=64&amp;q=75 1x, https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2Fb9ba5de8e05bd6d85824eb156694b0e1%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75 2x" src="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2Fb9ba5de8e05bd6d85824eb156694b0e1%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><div><h3>Marcin Wyszynski</h3><p>Marcin is the co-founder and Chief Product Officer at Spacelift. Prior to founding Spacelift, he was an SRE and Production Engineer at Google and Facebook. He also consulted for European scaleups such as Deliveroo and Tier Mobility. He is the creator of geopoiesis.</p></div></div><div><p><span><span></span><img alt="avatar_image_pawel" srcset="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F8382b12eb2fa4be4e8510e7e6c3bf2f6%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=64&amp;q=75 1x, https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F8382b12eb2fa4be4e8510e7e6c3bf2f6%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75 2x" src="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F8382b12eb2fa4be4e8510e7e6c3bf2f6%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><div><h3>Pawel Hytry</h3><p>Pawel is the CEO &amp; Co-Founder at Spacelift. Previously, he was the Co-Founder and Managing Director at FitPass Group. Pawel holds a degree in Operations &amp; Information Management from the University of Pennsylvania.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Wondercraft (YC S22) – Use text-to-speech to create podcasts easily (110 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37088087</link>
            <guid>37088087</guid>
            <pubDate>Fri, 11 Aug 2023 12:46:33 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37088087">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37088087">
      <td><span></span></td>      <td><center><a id="up_37088087" href="https://news.ycombinator.com/vote?id=37088087&amp;how=up&amp;goto=item%3Fid%3D37088087"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37088087">Launch HN: Wondercraft (YC S22) – Use text-to-speech to create podcasts easily</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37088087">101 points</span> by <a href="https://news.ycombinator.com/user?id=diminikolaou">diminikolaou</a> <span title="2023-08-11T12:46:33"><a href="https://news.ycombinator.com/item?id=37088087">10 hours ago</a></span> <span id="unv_37088087"></span> | <a href="https://news.ycombinator.com/hide?id=37088087&amp;goto=item%3Fid%3D37088087">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Wondercraft%20(YC%20S22)%20%E2%80%93%20Use%20text-to-speech%20to%20create%20podcasts%20easily&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37088087&amp;auth=b6210a461151c5ce4f18224af3b937eedc7e7d74">favorite</a> | <a href="https://news.ycombinator.com/item?id=37088087">76&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Hi HN! We’re Dimitris and Youssef, founders of Wondercraft (<a href="https://www.wondercraft.ai/">https://www.wondercraft.ai/</a>), a platform that leverages AI voices to make podcast creation simple. This video shows how it works: <a href="https://www.loom.com/share/fa8ac8eba8b9440dbe0321ccb8ba9426?sid=fef9c08a-1003-4377-9d79-8d8a7bf14eb0" rel="nofollow noreferrer">https://www.loom.com/share/fa8ac8eba8b9440dbe0321ccb8ba9426?...</a>.</p><p>“Hacker News Recap” (<a href="https://www.wondercraft.ai/podcasts/hacker-news-recap">https://www.wondercraft.ai/podcasts/hacker-news-recap</a>) a podcast produced using our platform, has been running for 4 months and currently gets close to 23k listens per month. We’ve made its analytics publicly available: <a href="https://op3.dev/show/f77aea62-97e5-5cce-92c6-9464e51c30c6" rel="nofollow noreferrer">https://op3.dev/show/f77aea62-97e5-5cce-92c6-9464e51c30c6</a>.</p><p>Having previously attempted to start a podcast, we were well aware of the difficulties. Figuring out what equipment and software you need to buy is a daunting start. Editing is a lengthy and tedious process, technical difficulties often occur during recording, and planning logistics around recording is a hassle. As a result, content release is infrequent, which leads to lackluster growth.</p><p>At the same time, podcast consumption is experiencing exponential growth. There are 500M podcast listeners around the world, double in size compared to 5 years ago. Apart from the growth in listeners, podcasts are the medium that is most likely to influence behavior, which is the reason why the number of businesses having podcasts has grown 5x over the past 5 years. Finally, the last piece that led to the creation of Wondercraft is that text-to-speech models saw a big improvement about 6 months ago, with ElevenLabs releasing models with an output that is almost indistinguishable to humans (see HN thread here: <a href="https://news.ycombinator.com/item?id=34361651">https://news.ycombinator.com/item?id=34361651</a>).</p><p>Wondercraft integrates realistic text-to-speech with an infrastructure that simplifies podcast creation. For example, you can integrate music, publish your podcast / create an RSS feed, generate a video for your episode,  get assistance in the script generation, auto generate show notes and transcript and translate your podcast all together. All text based tasks (e.g. script assistance, show note generation, etc) are completed using a chain of custom prompts to LLM models. All text-to-speech is done through custom voices that are either synthetically generated or professionally cloned from Voice Actors, using the ElevenLabs platform. Tasks such as episode translation involve the use of both LLMs and ElevenLabs. Video generation runs using Remotion and the RSS feed is an XML creation and updating routine.</p><p>Since launching, we’ve had more than 13k users sign up to create their podcast. Use cases that we’re seeing include: businesses repurposing their blogs and generating video content for their socials; writers/bloggers/newsletters reaching audience through another medium; news outlets and publications adding a news rundown podcast in their lineup; businesses creating internal educational/cultural material; and podcast studios using Wondercraft to serve client needs faster.</p><p>Wondercraft is not a tool for fully AI generated content. Rather, we save people time by transferring content they’ve created (e.g. an article they’ve written) to another medium. This technology is best suited for news rundowns and narrational format podcasts (often used by businesses talking about a niche topic). And while interview and conversational formats will sound better person-to-person, the logistical and (often) sound quality issues remain, so we’re testing out an “Async Podcasts” feature, where an interviewee can respond to questions async in writing, share a photo and (optionally) a clip of their voice, and a podcast will be created out of it.</p><p>We’d love to hear any thoughts, comments or experiences you may have had in relation to leveraging text to speech for podcast creation. Thank you for taking the time to read!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feral desert donkeys are digging wells, giving water to parched wildlife (184 pts)]]></title>
            <link>https://theconversation.com/feral-desert-donkeys-are-digging-wells-giving-water-to-parched-wildlife-159909</link>
            <guid>37087303</guid>
            <pubDate>Fri, 11 Aug 2023 11:06:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/feral-desert-donkeys-are-digging-wells-giving-water-to-parched-wildlife-159909">https://theconversation.com/feral-desert-donkeys-are-digging-wells-giving-water-to-parched-wildlife-159909</a>, See on <a href="https://news.ycombinator.com/item?id=37087303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In the heart of the world’s deserts – some of the most expansive wild places left on Earth – roam herds of feral donkeys and horses. These are the descendants of a once-essential but now-obsolete labour force. </p>

<p>These wild animals are generally considered <a href="https://nt.gov.au/environment/animals/feral-animals/feral-donkey">a threat to the natural environment</a>, and have been the target of mass eradication and lethal control programs in Australia. However, as we show in a <a href="https://science.sciencemag.org/cgi/doi/10.1126/science.abd6775">new research paper in Science</a>, these animals do something amazing that has long been overlooked: they dig wells — or “ass holes”. </p>

<p>In fact, we found that ass holes in North America — where feral donkeys and horses are widespread — dramatically increased water availability in desert streams, particularly during the height of summer when temperatures reached near 50℃. At some sites, the wells were the only sources of water. </p>

<figure>
            <a href="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Feral donkeys and horses dig wells to desert groundwater.</span>
              <span><span>Erick Lundgren</span></span>
            </figcaption>
          </figure>

<p>The wells didn’t just provide water for the donkeys and horses, but were also used by more than 57 other species, including numerous birds, other herbivores such as mule deer, and even mountain lions. (The lions are also predators of feral donkeys and <a href="https://www.nytimes.com/2018/05/12/sunday-review/let-mountain-lions-eat-horses.html">horses</a>.) </p>

<p>Incredibly, once the wells dried up some became nurseries for the germination and establishment of wetland trees.</p>

<figure>
            <a href="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=675&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=675&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=675&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=848&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=848&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=848&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Numerous species use equid wells. This includes mule deer (top left), scrub jays (middle left), javelina (bottom left), cottonwood trees (top right), and bobcats (bottom right).</span>
              <span><span>Erick Lundgren</span></span>
            </figcaption>
          </figure>

<h2>Ass holes in Australia</h2>

<p>Our research didn’t evaluate the impact of donkey-dug wells in arid Australia. But <a href="https://conbio.onlinelibrary.wiley.com/doi/10.1111/cobi.13447">Australia is home</a>  to most of the world’s feral donkeys, and it’s likely their wells support wildlife in similar ways.    </p>

<p>Across the Kimberley in Western Australia, helicopter pilots regularly saw strings of wells in dry streambeds. However, these all but disappeared as mass shootings since the late 1970s have driven donkeys <a href="https://www.abc.net.au/news/rural/2020-01-20/cost-benefit-analysis-of-culling-feral-donkeys-in-the-kimberley/11874064">near local extinction</a>. Only on <a href="https://www.kachana-station.com/projects/wild-donkey-project/">Kachana Station</a>, where the last of the Kimberley’s feral donkeys are protected, are these wells still to be found. </p>

<p>In Queensland, <a href="https://www.goodreads.com/book/show/2599093-they-all-ran-wild">brumbies</a> (feral horses) have been observed digging wells deeper than their own height to reach groundwater.</p>

<figure>
            <a href="https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="https://www.kachana-station.com/projects/wild-donkey-project/" data-src="https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=444&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=444&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=444&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=559&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=559&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=559&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>Some of the last feral donkeys of the Kimberley.</span>
              <span><span>Arian Wallach</span></span>
            </figcaption>
          </figure>

<p>Feral horses and donkeys are not alone in this ability to maintain water availability through well digging. </p>

<p>Other equids — including mountain zebras, Grevy’s zebras and the kulan — dig wells. African and Asian elephants dig wells, too. These wells provide resources for other animal species, including the near-threatened <a href="https://www.goviinkhulan.com/english/our-projects/research/">argali</a> and the <a href="https://books.google.com/books/about/Tracking_Gobi_Grizzlies.html?id=paBHjgEACAAJ">mysterious Gobi desert grizzly bear</a> in Mongolia. </p>

<p>These animals, like most of the world’s remaining megafauna, <a href="https://advances.sciencemag.org/content/1/4/e1400103">are threatened</a> by human hunting and habitat loss.</p>

<figure>
            <a href="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Other megafauna dig wells, too, including kulans in central Asia, and African elephants.</span>
              <span><span>Petra Kaczensky, Richard Ruggiero</span></span>
            </figcaption>
          </figure>

<h2>Digging wells has ancient origins</h2>

<p>These declines are the modern continuation of an ancient pattern visible since humans left Africa during the late Pleistocene, beginning around 100,000 years ago. As our ancestors stepped foot on new lands, the largest animals <a href="https://theconversation.com/did-people-or-climate-kill-off-the-megafauna-actually-it-was-both-127803">disappeared</a>, most likely from human hunting, with contributions from climate change. </p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/giant-marsupials-once-migrated-across-an-australian-ice-age-landscape-84762">Giant marsupials once migrated across an Australian  Ice Age landscape</a>
    </strong>
  </em>
</p>
<hr>


<p>If their modern relatives dig wells, we presume many of these extinct megafauna may have also dug wells. In Australia, for example, a pair of <a href="https://www.abc.net.au/news/2020-02-07/water-diviner-wombats-bring-animals-to-water-hole/11937990">common wombats</a> were recently documented digging a 4m-deep well, which was used by numerous species, such as wallabies, emus, goannas and various birds, during a severe drought. This means ancient giant wombats (<em>Phascolonus gigas</em>) may have dug wells across the arid interior, too. </p>

<p>Likewise, a diversity of equids and elephant-like proboscideans that once roamed other parts of world, may have dug wells like their surviving relatives. </p>

<p>Indeed, these animals have left riddles in the soils of the Earth, such as the preserved remnants of a 13,500-year-old, 2m-deep well in western North America, perhaps dug by a mammoth during an ancient drought, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169555X1100314X">as a 2012 research paper proposes</a>.</p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/from-feral-camels-to-cocaine-hippos-large-animals-are-rewilding-the-world-83301">From feral camels to 'cocaine hippos', large animals are rewilding the world</a>
    </strong>
  </em>
</p>
<hr>


<h2>Acting like long-lost megafauna</h2>

<p>Feral equids are resurrecting this ancient way of life. While donkeys and horses were introduced to places like Australia, it’s clear they hold some curious resemblances to some of its great lost beasts. </p>

<p><a href="https://www.pnas.org/content/117/14/7871.short">Our previous research published in PNAS</a> showed introduced megafauna actually make Australia overall more functionally similar to the ancient past, prior to widespread human-caused extinctions. </p>

<figure>
            <p><img alt="" data-src="https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=258&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=258&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=258&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=324&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=324&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=324&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p>
            <figcaption>
              <span>Donkeys share many similar traits with extinct giant wombats, who once may have dug wells in Australian drylands.</span>
              <span><span>Illustration by Oscar Sanisidro</span></span>
            </figcaption>
          </figure>

<p>For example, donkeys and feral horses have trait combinations (including diet, body mass, and digestive systems) that mirror those of the giant wombat. This suggests — in addition to potentially restoring well-digging capacities to arid Australia — they may also influence vegetation in similar ways. </p>

<p>Water is a limited resource, made even scarcer by farming, mining, climate change, and other human activities. With deserts predicted to spread, feral animals may provide unexpected gifts of life in drying lands.</p>

<figure>
            <a href="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=337&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=337&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=337&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Feral donkeys, horses (mapped in blue), and other existing megafauna (mapped in red) may restore digging capacities to many drylands. Non-dryland areas are mapped in grey, and the projected expansion of drylands from climate change in yellow.</span>
              <span><span>Erick Lundgren/Science</span>, <span>Author provided</span></span>
            </figcaption>
          </figure>

<p>Despite these ecological benefits in desert environments, feral animals have long been denied the <a href="https://ro.uow.edu.au/asj/vol8/iss2/14/">care</a>, curiosity and <a href="https://theconversation.com/non-native-species-should-count-in-conservation-even-in-australia-127926">respect</a> native species deservedly receive. Instead, these animals are targeted by <a href="https://www.abc.net.au/religion/this-treatment-of-donkeys-makes-brutes-out-of-us/10101372">culling</a> programs for conservation and the meat industry. </p>

<p>However, there are signs of change. New fields such as <a href="https://www.uts.edu.au/research-and-teaching/our-research/centre-compassionate-conservation">compassionate conservation</a> and <a href="https://www.sydney.edu.au/arts/our-research/futurefix/multispecies-justice.html">multispecies justice</a> are expanding conservation’s <a href="https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/cobi.13126">moral world</a>, and challenging the idea that only native species matter.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shamir Secret Sharing (223 pts)]]></title>
            <link>https://max.levch.in/post/724289457144070144/shamir-secret-sharing-its-3am-paul-the-head-of</link>
            <guid>37087136</guid>
            <pubDate>Fri, 11 Aug 2023 10:38:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://max.levch.in/post/724289457144070144/shamir-secret-sharing-its-3am-paul-the-head-of">https://max.levch.in/post/724289457144070144/shamir-secret-sharing-its-3am-paul-the-head-of</a>, See on <a href="https://news.ycombinator.com/item?id=37087136">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Fastest Branchless Binary Search (284 pts)]]></title>
            <link>https://mhdm.dev/posts/sb_lower_bound/</link>
            <guid>37086796</guid>
            <pubDate>Fri, 11 Aug 2023 09:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mhdm.dev/posts/sb_lower_bound/">https://mhdm.dev/posts/sb_lower_bound/</a>, See on <a href="https://news.ycombinator.com/item?id=37086796">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You’re a busy person so I’ll first jump right to it. Here it is, the fastest general (and simple) binary search C++ implementation:</p><div><pre><code data-lang="C++"><span>template</span> <span>&lt;</span><span>class</span> <span>ForwardIt</span>, <span>class</span> <span>T</span>, <span>class</span> <span>Compare</span><span>&gt;</span>
<span>constexpr</span> ForwardIt sb_lower_bound(
      ForwardIt first, ForwardIt last, <span>const</span> T<span>&amp;</span> value, Compare comp) {
   <span>auto</span> length <span>=</span> last <span>-</span> first;
   <span>while</span> (length <span>&gt;</span> <span>0</span>) {
      <span>auto</span> rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      <span>if</span> (comp(first[length], value)) {
         first <span>+=</span> length <span>+</span> rem;
      }
   }
   <span>return</span> first;
}
</code></pre></div><p>Same function interface as <code>std::lower_bound</code>, but <strong>2x</strong> faster, and shorter. “branchless” because the <code>if</code> compiles down to a conditional move instruction rather than a branch/conditional jump. We will explore compiler options, even faster versions, fully branchless, and caveats towards the end of the article. There’s a significant <strong>update</strong> too. Oh and I’m sorry about just thrusting C++ code on you. Rude, I know. You don’t really need to know C++ to understand this article, just iterators (<code>first</code> and <code>last</code>), basically pointers to elements in an array, though note they can point one past the last array entry. Ignore <code>template</code>, <code>class</code>, <code>constexpr</code> and <code>&amp;</code>. If only there was a clean fast bare-metal language to write all this in.. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><h2 id="binary-search-intro">Binary search intro</h2><p>You have a sorted list and want to find where a <code>value</code> would fit. In C++ you’d use <code>std::lower_bound</code> which returns the first position (iterator) for which the comparison (usually <code>&lt;</code>) fails, or <code>last</code> if the comparison is true for all elements. Let’s write that, so surprise coding interview question! (In C++. Good luck.)</p><p>The <code>binary</code> in binary search comes from splitting up the list into two at some middle item and doing a comparison of the middle against the given <code>value</code>. Based on the comparison result we pick which of the two lists to keep looking in. We start with a list of some <code>length = last - first</code> that starts at the given iterator <code>first</code>. We need to have some loop that keeps going until the list is empty, i.e. <code>while (length &gt; 0)</code>. Pick the/a middle, at <code>length / 2</code> do a comparison and update the current list, which we’ll do by updating <code>first</code> and <code>length</code>. Here goes:</p><div><pre><code data-lang="C++"><span>// std_lower_bound()
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>if</span> (comp(first[half], value)) {
      first <span>+=</span> half <span>+</span> <span>1</span>;
      length <span>-=</span> half <span>+</span> <span>1</span>;
   } <span>else</span> {
      length <span>=</span> half;
   }
}
<span>return</span> first;
</code></pre></div><p>That was straight-forward. What we got was a slightly refactored version of <a href="https://github.com/gcc-mirror/gcc/blob/releases/gcc-13/libstdc%2B%2B-v3/include/bits/stl_algobase.h#L1467">what gcc/libstdc++ uses</a> or <a href="https://github.com/llvm/llvm-project/blob/release/16.x/libcxx/include/__algorithm/lower_bound.h#L36">what llvm/libc++ uses</a>. Roughly the same speed, even (sometimes) compiles down to the same assembly in the loop.</p><h2 id="branch-prediction">Branch prediction</h2><p>“What’s slow about this?” Not much but glad you asked, great question. Processors have gotten faster and faster over the years, and part of the reason why is <em>branch prediction</em>. Short explanation: for speed, the CPU attempts to execute instructions in parallel by dividing each instruction execution into multiple stages, say F-D-E-W (fetch, decode, execute, writeback). With a careful design it can make progress on multiple stages of different instructions (Example: instruction 5 in stage F, 6 in D, 7E, 8F) at the same time. The complication comes from branches in the code, i.e. conditional jump instructions, where depending on some result the next instruction is either X or Y. The CPU <em>predicts</em> one option, X, and starts running through the stages, eventually including the stages of say X+1 and X+2. When the result becomes available and it turns out it should have been Y, all the work on X, X+1 and X+2 is thrown away. Branch mispredictions are expensive because the CPU could have already made progress on Y, Y+1 and Y+2 instead.</p><p>Branch prediction is great, but not for binary search. It’s a search, and you only search for something if you don’t know exactly where it is, otherwise you’d just get it. Which means that <code>if (comp(first[half], value))</code> is unpredictable in common use of <code>std::lower_bound</code>.</p><p><img src="https://mhdm.dev/posts/sb_lower_bound/predictions.png" alt="A happy-go-lucky processor saying “my predictions fail only half the time!" "="">
Credit <a href="https://www.instagram.com/practicemakespink">@practicemakespink</a></p><p>Let’s help the processor.</p><p>-We:</p><div><pre><code data-lang="C++"><span>// bstd_lower_bound()
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>bool</span> compare <span>=</span> comp(first[half], value);
   <span>// No more ifs
</span><span></span>   first <span>=</span> compare <span>?</span> first <span>+</span> half <span>+</span> <span>1</span> <span>:</span> first;
   length <span>=</span> compare <span>?</span> length <span>-</span> half <span>-</span> <span>1</span> <span>:</span> half;
}
<span>return</span> first;
</code></pre></div><p>-Clang compiler: “That’s not how this works!”</p><p>-We: <code>-mllvm -x86-cmov-converter=false</code></p><p>-Clang compiler: “Yes, boss."<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><p>The result is 25% faster as it uses 2 conditional move instructions. Not bad. But turns out that <code>-mllvm -x86-cmov-converter=false</code>, which we’ll shorten to <code>-cmov</code>, speeds up <code>std::lower_bound</code> just as much because clang is smart enough to figure out how to convert the <code>if</code>/<code>else</code> to conditional moves. gcc doesn’t have such an option and generally just doesn’t care about what you want.</p><p>Overall, there’s currently no good way to tell either clang<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> or gcc<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> to use a conditional move in just a certain situation.I’m trying to not make this article about finicky compilers, so let’s move on.</p><h2 id="what-started-this">What started this</h2><p>Why are we even talking about speeding up binary searches anyway? Why am I roping you into this? Cause someone else roped me into this.</p><p><video muted="" autoplay="" loop="" src="https://mhdm.dev/posts/sb_lower_bound/rope.mp4" width="100%" title="Meeseeks blaming one another for being roped in | Rick and Morty" onclick="this.paused?this.play():this.pause()"></video>
<a href="https://www.adultswim.com/videos/rick-and-morty/meeseeks-and-destroy">Rick and Morty - Meeseeks and Destroy</a></p><p>I saw Malte Skarupke’s translation of “Shar’s algorithm” into a C++ binary search (<code>branchless_lower_bound</code>) and I couldn’t help but think “it’s not optimal”. Malte’s version sometimes compares <code>value</code> against the same element multiple times. So I wondered, what is the optimal ‘branchless’ binary search? That led to <code>sb_lower_bound</code> which is ~20% faster than <a href="https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/">Malte’s version of lower_bound that he tested as 2x faster than GCC</a>.</p><p>“What’s an ‘optimal’ binary search anyway?” Good question. I think a binary search is ‘optimal’ if it completes by doing the minimum number of comparisons. This is very useful when you have a (relatively) slow comparison function. Malte noted his version is slower than <code>std::lower_bound</code> for binary searching a large number of strings.</p><p>Looking at <code>std::lower_bound</code> it returns an iterator, which can point to any of the list elements but also one past the end. For a list of size <code>n</code> there are <code>n+1</code> possible options. Thus for a list of size <code>2<sup>k</sup>-1</code> there are <code>2<sup>k</sup></code> possible options. In this case the optimal number of comparisons is <code>k</code>. Provably so as being able to distinguish between all <code>2<sup>k</sup></code> options requires <code>k</code> bits of information, and each comparison gives us 1 bit of information (true vs false). Translating this case into code, we get:</p><div><pre><code data-lang="C++"><span>// Really fast but only works when length is a power of 2 minus 1
</span><span>// When not, it can result in out of bounds accesses like for
</span><span>// array [0, 1, 2, 3, 4, 5] and value 4
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   length <span>/=</span> <span>2</span>;
   <span>if</span> (comp(first[length], value)) {
      first <span>+=</span> length <span>+</span> <span>1</span>;
   }
}
<span>return</span> first;
</code></pre></div><p>With clang <code>-cmov</code> the loop compiles down to 6 instructions, one of which is <code>cmov</code>. The reason this (and Malte’s code) is so fast is that only updating <code>first</code> depends on the comparison result.</p><h2 id="sb_lower_bound"><code>sb_lower_bound</code></h2><p>Now let’s look at <code>sb_lower_bound</code> (named after <em>simple branchless</em>). It actually took me longer to stumble upon than faster versions (yet to be presented) as it’s not ‘optimal’.</p><div><pre><code data-lang="C++"><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> rem <span>=</span> length <span>%</span> <span>2</span>;
   length <span>/=</span> <span>2</span>;
   <span>if</span> (comp(first[length], value)) {
      first <span>+=</span> length <span>+</span> rem;
   }
}
<span>return</span> first;
</code></pre></div><p>Every time we split the list, the number of elements happens to be even, and comp returns true then we don’t skip over enough elements. For <code>n</code> elements, where <code>2<sup>k</sup> &lt;= n &lt; 2<sup>k+1</sup></code>, <code>sb_lower_bound</code> will always make <code>k+1</code> comparisons while <code>std::lower_bound</code> will either make <code>k</code> or <code>k+1</code> comparisons. On average <code>std::lower_bound</code> will make about <code>log2(n+1)</code> comparisons. Overall <code>sb_lower_bound</code> is faster as it has significantly fewer instructions in the loop. The comparison function has to be really slow for the difference between <code>k+1</code> and <code>log2(n+1)</code> number of comparisons to matter.</p><p>Second caveat is that currently, gcc does not emit branchless code for <code>sb_lower_bound</code> regardless of optimization level. It doesn’t emit branchless code for <code>std::lower_bound</code> either so they end up about as fast. We can try to write some inline assembly to force gcc to use <code>cmov</code> but there’s a tradeoff. The simple way results in more instructions than necessary. The alternative requires writing different assembly code for every possible type of <code>value</code> (int, float, etc.).</p><div><pre><code data-lang="C++"><span>// asm_lower_bound, works for x86 only
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> rem <span>=</span> length <span>%</span> <span>2</span>;
   length <span>/=</span> <span>2</span>;
   <span>auto</span> firstplus <span>=</span> first <span>+</span> length <span>+</span> rem;
   <span>// Does a comparison which sets some x86 FLAGS like CF or ZF
</span><span></span>   <span>bool</span> compare <span>=</span> comp(first[length], value);
   <span>// Inline assembly doesn't support passing bools straight into FLAGS
</span><span></span>   <span>// so we ask the compiler to copy it from FLAGS into a register
</span><span></span>   __asm__(
         <span>// Then we test the register, which sets ZF=!compare and CF=0
</span><span></span>         <span>// Reference: https://www.felixcloutier.com/x86/test
</span><span></span>         <span>"test %[compare],%[compare]</span><span>\n</span><span>"</span>
         <span>// cmova copies firstplus into first if ZF=0 and CF=0
</span><span></span>         <span>// Reference: https://www.felixcloutier.com/x86/cmovv
</span><span></span>         <span>"cmova %[firstplus],%[first]</span><span>\n</span><span>"</span>
         <span>:</span> [first] <span>"+r"</span>(first)
         <span>:</span> [firstplus] <span>"r"</span>(firstplus), [compare]<span>"r"</span>(compare)
   );
}
<span>return</span> first;
</code></pre></div><p>2x faster than the gcc version of <code>std::lower_bound</code>, but slightly slower than <code>sb_lower_bound</code> with clang <code>-cmov</code>. Presented just for demonstration purposes.</p><h2 id="more-optimal">More optimal</h2><p>I promised an even faster version in the intro. Here it is:</p><div><pre><code data-lang="C++"><span>// bb_lower_bound
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>// while length isn't a power of 2 minus 1
</span><span></span><span>while</span> (length <span>&amp;</span> (length <span>+</span> <span>1</span>)) {
   <span>auto</span> step <span>=</span> length <span>/</span> <span>8</span> <span>*</span> <span>6</span> <span>+</span> <span>1</span>; <span>// MAGIC
</span><span></span>   <span>if</span> (comp(first[step], value)) {
      first <span>+=</span> step <span>+</span> <span>1</span>;
      length <span>-=</span> step <span>+</span> <span>1</span>;
   } <span>else</span> {
      length <span>=</span> step;
      <span>break</span>;
   }
}
<span>while</span> (length <span>!=</span> <span>0</span>) {
   length <span>/=</span> <span>2</span>;
   <span>if</span> (comp(first[length], value)) {
      first <span>+=</span> length <span>+</span> <span>1</span>;
   }
}
<span>return</span> first;
</code></pre></div><p>Let’s quickly go over <code>length &amp; (length + 1)</code>. Example: <code>length</code> is <code>110011</code>, <code>length+1</code> is <code>110100</code>, <code>length &amp; (length+1)</code> is <code>110000</code>. Note how they always share their most significant <code>1</code> except for when <code>length+1</code> carries over all set bits. That case is when <code>length</code> is of the form <code>11..1</code>, i.e. power of 2 minus 1, in which case <code>length &amp; (length + 1)</code> will be 0. Slightly adapted from one of the bit twiddling tricks I remembered and there’s a (warning!) <a href="https://graphics.stanford.edu/~seander/bithacks.html">rabbit hole full of awesome tricks here</a>.</p><p>Let us call lengths ‘nice’ if they are powers of 2 minus 1. Earlier we found that for nice lengths we can have optimal searching. The original idea was that for non-nice length we split the search list not in half but in a way that we’ll quickly end up only searching sub-lists of nice lengths. This idea was not quite fast enough as it meant spending significant time just splitting up the list. The first compromise is that early <code>break</code>, which means the second <code>while</code> loop may (non-optimally) search past its original length; no out of bounds accesses though as this sub-list isn’t at the end of the full list. This compromise leads to a second compromise, that bit of MAGIC in selecting the <code>step</code> size. To be fast we want a large <code>step</code>, definitely <code>&gt;= length/2</code>, so we more often break out to the faster <code>while</code> loop. But not so large a <code>step</code> that almost equals <code>length</code> because we lose on what makes a binary search fast. We’d also prefer that the <code>step</code> is nice or has many <code>1</code>s in its binary representation, which makes the second <code>while</code> loop more optimal. The many <code>1</code>s is why the <code>step</code> is forced to be odd. Last but not least, we’d want <code>length - step - 1</code> to be nice.</p><p>I’ve tried quite a few variations. The most bitter sweet was <code>auto step = length &gt;&gt; 1; step |= step &gt;&gt; 1;</code> which I thought to be a good fast heuristic that balances the listed compromises, is very close to optimal but ultimately ended up slightly slower than MAGIC. Another issue is the ‘break’ makes it branchy.</p><p>One unexplored avenue is exhaustively searching for the fastest (yet still optimal) <code>step</code> for every length and storing that into a precomputed table. Then either deriving a good heuristic from said table or using it outright. With <code>sb_lower_bound</code> I’ve reached my good-enough point but you’re welcome to explore further :).</p><div><pre><code data-lang="C++"><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&amp;</span> (length <span>+</span> <span>1</span>)) {
   <span>auto</span> step <span>=</span> precomputed[length];
   <span>if</span> (comp(first[step], value)) {
      first <span>+=</span> step <span>+</span> <span>1</span>;
      length <span>-=</span> step <span>+</span> <span>1</span>;
   } <span>else</span> {
      length <span>=</span> step;
   }
}
<span>// ...
</span></code></pre></div><h2 id="more-branchless-more-better">More branchless, more better?</h2><p>Short answer: no. This section can be skipped but here’s the long answer: For <code>n</code> elements where <code>2<sup>k</sup> &lt;= n &lt; 2<sup>k+1</sup></code> <code>sb_lower_bound</code> will always do <code>k+1</code> comparisons. On a 64-bit machine that means at most 64 iterations of the <code>while (length &gt; 0)</code> loop. So it’s possible to write a “fully branchless” version that doesn’t have the <code>length</code> check by using a <code>switch</code> with intentional fall-through.</p><div><pre><code data-lang="C++">size_t length <span>=</span> last <span>-</span> first;
size_t rem;
<span>switch</span>(std<span>::</span>bit_width(length)) {
   <span>case</span> <span>64</span><span>:</span>
      rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      first <span>+=</span> comp(first[length], value) <span>*</span> (length <span>+</span> rem);
   <span>case</span> <span>63</span><span>:</span>
      rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      first <span>+=</span> comp(first[length], value) <span>*</span> (length <span>+</span> rem);
   <span>// ...
</span><span></span>   <span>case</span> <span>1</span><span>:</span>
      rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      first <span>+=</span> comp(first[length], value) <span>*</span> (length <span>+</span> rem);
}
<span>return</span> first;
</code></pre></div><p>If you’re not familiar with <code>switch</code>, think of it as a jump into code. In our case to the exact place from which there are exactly the right number of comparisons left to do.</p><p>“Is it any faster?” No. Modern x86 processors handle loop conditions well as they’re predictable; we’re very likely to remain in the loop. And that’s good especially because it saves us from writing templates or macros or copy-paste-edit the 64 cases.</p><h2 id="spotlight-on-performance">Spotlight on Performance</h2><p><img src="https://mhdm.dev/posts/sb_lower_bound/performance.png" alt="Sketch of processor’s performance" title="Spotlight on Performance">
Credit <a href="https://www.instagram.com/practicemakespink">@practicemakespink</a></p><p>Average run time (ns):</p><table><thead><tr><th></th><th><code>std::lower_</code></th><th><code>branchless_lower_</code></th><th><code>asm_lower_</code></th><th><code>sb_lower_</code></th><th><code>sbm_lower_</code></th><th><code>bb_lower_</code></th></tr></thead><tbody><tr><td>gcc</td><td>80.68</td><td>43.65</td><td>54.92</td><td>77.22</td><td>34.19</td><td>75.64</td></tr><tr><td>clang</td><td>78.66</td><td>90.97</td><td>51.83</td><td>80.06</td><td>83.95</td><td>74.44</td></tr><tr><td>clang -cmov</td><td>61.30</td><td>43.43</td><td>54.32</td><td><strong>33.24</strong></td><td>35.54</td><td><strong>32.73</strong></td></tr></tbody></table><p>Geometric mean run time (ns):</p><table><thead><tr><th></th><th><code>std::lower_</code></th><th><code>branchless_lower_</code></th><th><code>asm_lower_</code></th><th><code>sb_lower_</code></th><th><code>sbm_lower_</code></th><th><code>bb_lower_</code></th></tr></thead><tbody><tr><td>gcc</td><td>62.44</td><td>25.55</td><td>32.35</td><td>59.67</td><td>20.62</td><td>57.93</td></tr><tr><td>clang</td><td>61.24</td><td>65.72</td><td>30.67</td><td>63.59</td><td>66.91</td><td>58.19</td></tr><tr><td>clang -cmov</td><td>39.17</td><td>25.14</td><td>31.21</td><td><strong>19.81</strong></td><td>20.91</td><td>21.33</td></tr></tbody></table><p>Runtimes in line chart form:</p><p><a href="https://mhdm.dev/posts/sb_lower_bound/runtimes.png"><img src="https://mhdm.dev/posts/sb_lower_bound/runtimes.png" alt="Runtimes"></a></p><p>“What’s <code>sbm_lower_bound</code>?” It’s basically <code>sb_lower_bound</code> but modified to trick gcc into generating a conditional move. The difference is switching from the <code>if</code> statement to <code>first += comp(first[length], value) * (length + rem)</code>. Use with comments and caution as the next version of gcc may undo this optimization.</p><p>Benchmarking commands showing compiler options:</p><div><pre><code data-lang="sh">g++-10 -std<span>=</span>c++20 -Wall -O2 -march<span>=</span>haswell test.cpp -o test <span>&amp;&amp;</span> ./test
clang++-10 -std<span>=</span>c++20 -Wall -O2 -march<span>=</span>haswell test.cpp -o test <span>&amp;&amp;</span> ./test
clang++-10 -std<span>=</span>c++20 -Wall -O2 -march<span>=</span>haswell -mllvm -x86-cmov-converter<span>=</span>false test.cpp -o test <span>&amp;&amp;</span> ./test
</code></pre></div><p><code>-march=native</code> or no <code>-march</code> did not significantly influence the rankings. Benchmarked on an intel i7 kaby lake.</p><h3 id="branch-mispredictions">Branch mispredictions</h3><p>We can look at branch mispredictions/misses using <code>perf</code>:</p><div><pre><code data-lang="sh"><span># clang</span>
perf stat ./test
<span># [..]</span>
         16,599.95 msec task-clock:u     <span>#    1.000 CPUs utilized</span>
<span># [..]</span>
    30,309,755,516      instructions:u   <span>#    0.53  insn per cycle</span>
     6,941,783,502      branches:u       <span>#  418.181 M/sec</span>
     1,203,569,540      branch-misses:u  <span>#   17.34% of all branches</span>
<span># clang -cmov</span>
perf stat ./test
<span># [..]</span>
         10,982.97 msec task-clock:u     <span>#    1.000 CPUs utilized</span>
<span># [..]</span>
    32,603,123,521      instructions:u   <span>#    0.90  insn per cycle</span>
     4,070,883,093      branches:u       <span>#  370.654 M/sec</span>
        35,954,999      branch-misses:u  <span>#    0.88% of all branches</span>
</code></pre></div><p><code>-cmov</code> removes ~2.9B branches and ~1.2B branch misses, so it removes branches that were mispredicted ~41% of the time. It’s close to the 50% we’d expect for purely unpredictable branches, if we had perfect randomness and benchmarking. In which case <code>-cmov</code> would result in an even higher improvement.</p><h3 id="performance-with-slower-comp">Performance with slower <code>comp()</code></h3><p>For somewhat realistic scenarios of binary searching with a slower <code>comp()</code> function I’ve thought of searching through ids, phone numbers, accounts and keywords. I’ve thus settled on testing searching 8-byte strings.</p><p>Average run time (ns):</p><table><thead><tr><th></th><th><code>std::lower_</code></th><th><code>branchless_lower_</code></th><th><code>sb_lower_</code></th><th><code>sbm_lower_</code></th><th><code>bb_lower_</code></th></tr></thead><tbody><tr><td>gcc</td><td><strong>160.01</strong></td><td>205.24</td><td>165.66</td><td>193.96</td><td>163.91</td></tr><tr><td>clang</td><td><strong>157.71</strong></td><td>178.77</td><td>162.68</td><td>166.00</td><td><strong>157.22</strong></td></tr><tr><td>clang -cmov</td><td><strong>156.06</strong></td><td>193.70</td><td>164.71</td><td>181.57</td><td>157.48</td></tr></tbody></table><p>In this case <code>std::lower_bound</code> is very slightly but consistently faster than <code>sb_lower_bound</code>. To always get the best performance it is possible for libraries to use <code>sb_lower_bound</code> whenever directly working on primitive types and <code>std::lower_bound</code> otherwise.</p><h2 id="assembly">Assembly</h2><p>No bare-metal code performance optimization is complete without looking at the generated assembly. However, feel free to skip this section.</p><div><pre><code data-lang="js"><span>Time</span><span>%</span> <span>|</span>      <span>instructions</span>

<span>// std::lower_bound, clang -cmov, hottest loop assembly
</span><span></span> <span>1.68</span> <span>│</span><span>20</span><span>:</span>   <span>mov</span>      <span>%</span><span>rsi</span>,<span>%</span><span>rcx</span>             <span>// rcx = length
</span><span></span> <span>3.20</span> <span>│</span>      <span>shr</span>      <span>%</span><span>rcx</span>                  <span>// rcx = length / 2
</span><span></span> <span>1.08</span> <span>│</span>      <span>mov</span>      <span>%</span><span>rcx</span>,<span>%</span><span>rdx</span>             <span>// rdx = length / 2
</span><span></span> <span>4.42</span> <span>│</span>      <span>not</span>      <span>%</span><span>rdx</span>                  <span>// rdx = binary_not(rdx) = -length / 2 - 1
</span><span></span> <span>2.85</span> <span>│</span>      <span>add</span>      <span>%</span><span>rsi</span>,<span>%</span><span>rdx</span>             <span>// rdx = length - length / 2 - 1
</span><span></span><span>63.41</span> <span>│</span>      <span>vucomiss</span> (<span>%</span><span>rax</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>xmm0</span>   <span>// Compare first[rcx] with value, sets FLAGS
</span><span></span> <span>0.21</span> <span>│</span>      <span>lea</span>      <span>0x4</span>(<span>%</span><span>rax</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>rsi</span> <span>// rsi = first + length / 2 + 1
</span><span></span><span>10.14</span> <span>│</span>      <span>cmova</span>    <span>%</span><span>rsi</span>,<span>%</span><span>rax</span>             <span>// first = compare_res ? first : rsi
</span><span></span> <span>4.87</span> <span>│</span>      <span>cmovbe</span>   <span>%</span><span>rcx</span>,<span>%</span><span>rdx</span>             <span>// rdx = not compare_res ? length / 2 : rdx
</span><span></span> <span>0.88</span> <span>│</span>      <span>mov</span>      <span>%</span><span>rdx</span>,<span>%</span><span>rsi</span>             <span>// rsi = rdx (new length)
</span><span></span> <span>0.33</span> <span>│</span>      <span>test</span>     <span>%</span><span>rdx</span>,<span>%</span><span>rdx</span>             <span>// Set FLAGS based on rdx
</span><span></span> <span>3.90</span> <span>│</span>    <span>↑</span> <span>jg</span>       <span>20</span>                    <span>// Jump to instruction 20 if rdx not zero
</span><span></span>
<span>// sb_lower_bound, clang -cmov, hottest loop assembly
</span><span></span> <span>4.21</span> <span>│</span><span>20</span><span>:</span>   <span>shr</span>      <span>%</span><span>rcx</span>                  <span>// rcx = length / 2
</span><span></span> <span>4.70</span> <span>│</span>      <span>and</span>      <span>$0x1</span>,<span>%</span><span>esi</span>             <span>// esi = length % 2
</span><span></span> <span>5.00</span> <span>│</span>      <span>add</span>      <span>%</span><span>rcx</span>,<span>%</span><span>rsi</span>             <span>// rsi = length / 2 + length % 2
</span><span></span><span>68.86</span> <span>│</span>      <span>vucomiss</span> (<span>%</span><span>rax</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>xmm0</span>   <span>// Compare first[rcx] with value, sets FLAGS
</span><span></span> <span>0.01</span> <span>│</span>      <span>lea</span>      (<span>%</span><span>rax</span>,<span>%</span><span>rsi</span>,<span>4</span>),<span>%</span><span>rdx</span>    <span>// rdx = first + length / 2 + length % 2
</span><span></span><span>11.69</span> <span>│</span>      <span>cmova</span>    <span>%</span><span>rdx</span>,<span>%</span><span>rax</span>             <span>// first = compare_res ? first : rdx
</span><span></span> <span>3.71</span> <span>│</span>      <span>mov</span>      <span>%</span><span>rcx</span>,<span>%</span><span>rsi</span>             <span>// rsi = length / 2
</span><span></span>      <span>│</span>      <span>test</span>     <span>%</span><span>rcx</span>,<span>%</span><span>rcx</span>             <span>// Set FLAGS based on rcx
</span><span></span> <span>0.02</span> <span>│</span>    <span>↑</span> <span>jne</span>      <span>20</span>                    <span>// Jump to instruction 20 if rcx not zero
</span><span></span>
<span>// branchless_lower_bound, clang -cmov, hottest loop assembly
</span><span></span> <span>3.04</span> <span>│</span><span>70</span><span>:</span>   <span>lea</span>      (<span>%</span><span>rdi</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>rax</span>    <span>// rax = first + length
</span><span></span><span>71.22</span> <span>│</span>      <span>vucomiss</span> (<span>%</span><span>rdi</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>xmm0</span>   <span>// Compare first[rcx] with value, sets FLAGS
</span><span></span><span>12.26</span> <span>│</span>      <span>cmova</span>    <span>%</span><span>rax</span>,<span>%</span><span>rdi</span>             <span>// first = compare_res ? first : rax
</span><span></span> <span>1.03</span> <span>│</span><span>7</span><span>d</span><span>:</span>   <span>shr</span>      <span>%</span><span>rcx</span>                  <span>// length /= 2, but note it also sets FLAGS
</span><span></span> <span>1.64</span> <span>│</span>    <span>↑</span> <span>jne</span>      <span>70</span>                    <span>// Jump to instruction 20 if length not zero
</span></code></pre></div><p>The <code>branchless_lower_bound</code> assembly is really short and clean. While that’s a good indicator of speed, <code>sb_lower_bound</code> wins out in the performance tests due to low overhead.</p><h2 id="conclusion">Conclusion</h2><p>If the slowest part of your program involves searching and/or comparisons that a processor would not be able to predict then try clang with <code>-mllvm -x86-cmov-converter=false</code> (if your processor is x86).</p><p>If you’d benefit from a faster binary search, try <code>sb_lower_bound</code> (or for gcc you could also try <a href="https://github.com/mh-dm/sb_lower_bound/blob/master/sbm_lower_bound.h"><code>sbm_lower_bound</code></a>). I’ve made it open source, MIT license.</p><p>If you want more articles like this, follow me <a href="https://twitter.com/_mhdm">@_mhdm</a> on Twitter (I don’t post often). Alternatively, you can <a href="https://mhdm.dev/index.xml">use RSS</a>.</p><p>Code, including benchmarking, is available at <a href="https://github.com/mh-dm/sb_lower_bound/">github.com/mh-dm/sb_lower_bound/</a>.</p><p>If you have ideas, thoughts, or something to add you can <a href="https://www.reddit.com/r/cpp/comments/14okto7/fastest_branchless_binary_search/">leave a comment here</a>.</p><h2 id="update">Update</h2><p>Following a fruitful comment by <a href="https://orlp.net/">orlp.net author</a>, <code>sb_lower_bound</code> can be refactored slightly to reduce the number of assembly instructions in the hot loop from 9 to 8.</p><div><pre><code data-lang="C++"><span>// sb_lower_bound refactored
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>if</span> (comp(first[half], value)) {
      <span>// length - half equals half + length % 2
</span><span></span>      first <span>+=</span> length <span>-</span> half;
   }
   length <span>=</span> half;
}
<span>return</span> first;
</code></pre></div><p>With <code>clang -cmov</code> there’s a slight speed up from ~33ns to ~32ns for the average run time.</p><h3 id="prefetching">Prefetching</h3><p>From comments there was a recommended method for a further speed-up, namely prefetching. Prefetching pulls particular parts of memory into cache (usually L1/L2) so that when prefetched data is actually needed the load only incurs L1/L2 cache latency (~4/12 cycles) vs slower cache (L3, ~40 cycles) or memory latency (~200 cycles). <a href="https://www.7-cpu.com/cpu/Skylake.html">Example timings</a>. For this there’s <code>__builtin_prefetch()</code> supported in both gcc and clang.</p><p>Say we’re going to check against the element at <code>length / 2</code>. We could prefetch at <code>length / 4</code> and <code>length * 3 / 4</code>. Or we could also prefetch at <code>length / 8</code> divisions, which is an extra 4 memory locations. For <code>length / 4</code> divisions, 1 out of every 2 prefetches will be wasted, doubling cache pressure. If also <code>length / 8</code> divisions, 5 out of every 6 prefetches will be wasted. There’s overhead in computing the locations and prefetching, overhead that will be significant in the hot loop we worked hard to make short.</p><p>Finally, if we’ve already made a few full searches the initial divisions are likely to be in the cache as many elements should fit in modern 256KB+ L2 caches.</p><p>When trying various prefetching strategies, none helped for under 256KB arrays, which is about what we expect. Long story short, here’s <code>sb_lower_bound</code> but with prefetching added in for 256KB+:</p><div><pre><code data-lang="C++"><span>// sbp_lower_bound
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>// Sized to roughly fit in L2 cache
</span><span></span><span>constexpr</span> <span>int</span> entries_per_256KB <span>=</span> <span>256</span> <span>*</span> <span>1024</span> <span>/</span> <span>sizeof</span>(T);
<span>if</span> (length <span>&gt;=</span> entries_per_256KB) {
   <span>constexpr</span> <span>int</span> num_per_cache_line <span>=</span> std<span>::</span>max(<span>64</span> <span>/</span> <span>int</span>(<span>sizeof</span>(T)), <span>1</span>);
   <span>while</span> (length <span>&gt;=</span> <span>3</span> <span>*</span> num_per_cache_line) {
      <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
      __builtin_prefetch(<span>&amp;</span>first[half <span>/</span> <span>2</span>]);
      <span>// length - half equals half + length % 2
</span><span></span>      <span>auto</span> first_half1 <span>=</span> first <span>+</span> (length <span>-</span> half);
      __builtin_prefetch(<span>&amp;</span>first_half1[half <span>/</span> <span>2</span>]);
      first <span>=</span> comp(first[half], value) <span>?</span> first_half1 : first;
      length <span>=</span> half;
   }
}
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>auto</span> first_half1 <span>=</span> first <span>+</span> (length <span>-</span> half);
   first <span>=</span> comp(first[half], value) <span>?</span> first_half1 : first;
   length <span>=</span> half;
}
<span>return</span> first;
</code></pre></div><p>Tested in the same way as before, for sizes ranging up to ~4 million entries (or 16MB), there’s a further speed up from ~32ns to ~26ns average run time. At this point I should acknowledge that my original size stopping point happened to be too small. A case of a quick ‘should be larger than L3 cache size’ and a mistake in not following up. So let’s go much higher, now to ~128 million entries (or 512MB). We’re way past L3 but still in reasonable data set size.</p><p>Runtimes in line chart form:</p><p><a href="https://mhdm.dev/posts/sb_lower_bound/runtimes2.png"><img src="https://mhdm.dev/posts/sb_lower_bound/runtimes2.png" alt="Runtimes 2"></a></p><p>There’s some interesting stuff going on.</p><ul><li>Branchless <code>std::lower_bound</code> that’s generated with <code>clang -cmov</code> is slower than the branchy version at massive sizes. Modern cpus follow predicted branches including loading from memory (basically a prefetch) and speculatively executing on said data (basically a <a href="https://en.wikipedia.org/wiki/Transient_execution_CPU_vulnerability">security nightmare</a>).</li><li><code>sbpm_lower_bound</code> is the prefetching version of <code>sbm_lower_bound</code> which does a multiply with a boolean to trick gcc into generating branchless code.</li><li>We’re at ~2.3x faster average time comparing <code>std::lower_bound</code> (~161ns) to prefetched version (~71ns).</li></ul><h3 id="faster">Faster?</h3><h4 id="drop-in-replacement-for-stdlower_bound">Drop in replacement for <code>std::lower_bound</code></h4><p>There’s a performance graph bump/weirdness between 1-10 million elements so faster is possible in theory. In practice the prefetching code is getting messy and gaining magic constants. An exciting part for me in writing this post was the (small) probability of contributing back to <a href="https://gcc.gnu.org/contribute.html">gcc/libstdc++</a> and/or <a href="https://libcxx.llvm.org/Contributing.html">llvm/libc++</a>. I’ll stop here as that probability gets even smaller with added complexity.</p><h4 id="breaking-stdlower_bound-constraints">Breaking <code>std::lower_bound</code> constraints</h4><p>Comments also noted the interesting <a href="https://algorithmica.org/en/eytzinger">Eytzinger Binary Search</a> variant where the input array is reshaped (into a binary med-“heap”) for lookups to be cache friendly. I could ponder how fast a SIMD optimized K-ary tree could be, but no need to ponder: 7x to 15x faster than <code>std::lower_bound</code> (for 16-ary tree of ints) as presented by <a href="https://www.youtube.com/watch?v=1RIPMQQRBWk">Sergey Slotin at CppCon 2022</a>.</p><h4 id="footnotes">Footnotes</h4><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>BUT RUST.. Rust is fast but do you really want my first post to be <a href="https://doc.rust-lang.org/src/core/slice/mod.rs.html#2520">about unsafe code</a>? <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p>BUT ZIG.. There’s no binary search implementation in Zig that I could find, rather it calls to C++. <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>There’s always a <a href="https://m.xkcd.com/149/">relevant XKCD</a>. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li><li id="fn:4" role="doc-endnote"><p>With clang we could do <a href="https://clang.llvm.org/docs/LanguageExtensions.html#builtin-unpredictable"><code>__builtin_unpredictable</code></a><code>(comp(first[half], value))</code> but it does nothing (tested v10-13). <a href="#fnref:4" role="doc-backlink">↩︎</a></p></li><li id="fn:5" role="doc-endnote"><p>gcc has <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html#index-_005f_005fbuiltin_005fexpect_005fwith_005fprobability"><code>__builtin_expect_with_probability</code></a><code>(cond, 0, 0.5)</code> but it does nothing (tested v10). <a href="#fnref:5" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There is no hard takeoff (142 pts)]]></title>
            <link>https://geohot.github.io//blog/jekyll/update/2023/08/10/there-is-no-hard-takeoff.html</link>
            <guid>37086779</guid>
            <pubDate>Fri, 11 Aug 2023 09:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geohot.github.io//blog/jekyll/update/2023/08/10/there-is-no-hard-takeoff.html">https://geohot.github.io//blog/jekyll/update/2023/08/10/there-is-no-hard-takeoff.html</a>, See on <a href="https://news.ycombinator.com/item?id=37086779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Back in 2014, Elon Musk referred to AI as <a href="https://www.washingtonpost.com/news/innovations/wp/2014/10/24/elon-musk-with-artificial-intelligence-we-are-summoning-the-demon/">summoning the demon</a>. And it wasn’t hard to see that view. Soon, <a href="https://en.wikipedia.org/wiki/AlphaGo">Go agents</a> would beat top humans learning from self play. By the end of 2017, the <a href="https://arxiv.org/abs/1712.01815">same algorithm</a> mastered Chess and Shogi. By 2020, it didn’t even need tons of calls to the simulator, and could <a href="https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules">play Atari too</a>.</p>

<p>AI looked scary. It looked like it was one FOOM away from self playing and becoming superhuman at the universe. And yet, here we are in 2023 and self driving cars still don’t work.</p>

<p>Does becoming superhuman at the universe make any practical sense? The universe has so many orders of magnitude more states than any Go game. And I don’t even need math to illustrate this point, just imagine tiling the universe with as many very tiny Go boards as you can fit.</p>

<p>That’s a lot of Go boards. So many that the difference in complexity between Go and the Universe is not a matter of number, it’s a matter of kind. Every Go program operates at the stone level. Almost nothing predicting the world operates at the atom level.</p>

<hr>


<p>These modern self play systems like <a href="https://arxiv.org/pdf/1911.08265.pdf">MuZero</a> have some form of dynamics model, a function that given the current state of the world and an action, it predicts the next state. We also use these dynamics models <a href="https://twitter.com/comma_ai/status/1681491118536691712">at comma</a>. They are world models, and contain all the knowledge of how the world works inside of them.</p>

<p>GPT-4 is a dynamics model also, conditioned on the prior of the action space. And there’s an even simpler way to think about it. The loss function for dynamics is compression.</p>

<p><a href="http://www.hutter1.net/ai/">Compression is prediction is intelligence, intelligence is prediction is compression.</a> One of the coolest facts I ever learned. So, feed in the whole internet, build a compressive model, make it really really big, and you just won the universe?</p>

<hr>


<p>Not so fast. This approach can lead to <a href="https://chat.openai.com/">very neat applications</a>, but does it take over the world?</p>

<p>You want to get rich? Here’s an idea. Download all the historical stock market data. Get lots and lots of GPUs to train a huge model. Boom, predictor for the stock market. I look at prediction, I know which stocks go up! I buy the stocks that go up, I short the stocks that go down. With mega leverage, I am a billionaire by the end of the week! I can reinvest my billions in more GPUs for recursive self improvement. Nobody will stop me, I will take over the whole economy. How is nobody doing this?!?</p>

<p>Oh wait…every hedge fund bro is already doing this. And most of them aren’t billionaires. The problem is your model needs to include all the computers playing the market, and it also needs to include the other hedge fund bros themselves. This strategy only dominates if you have more compute than the whole market itself, which you don’t.</p>

<hr>


<p>In Go, your model doesn’t need to include other computers. Yes, you are playing against a computer that you are modeling, but the game itself is way too small to contain a Go playing computer. The other computer you are playing against is outside the universe. The rules of Go don’t include computers. The rules of Go are fixed in complexity.</p>

<p>On the other hand, your dynamics model of the universe must include computers. You’ll have to spend a lot of effort modeling them. Unless you have an absolutely staggering advantage, you aren’t going to figure them out from self play. The computers are active players, and they have a lot of compute. They might even be using it to try to model you!</p>

<p>Assuming <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">no untoward market intervention</a>, why would any one system ever have a large majority of the compute? Compute will be distributed in a <a href="https://en.wikipedia.org/wiki/Power_law">power law</a>.</p>

<p>The smart regulation isn’t capping the FLOPS in training runs. That’s creating a powder keg. If the FLOPS are artificially restricted, and one person breaks the restriction, you could end up with a single dominant system.</p>

<p>If you don’t want FOOM, you just need to prevent a 51% attack on compute.</p>

<hr>


<p>Now, if there’s one weird trick to 1e20x your efficiency, and only one group gets it, all bets are off. But this is never how things happen. Nobody has a 1e20x more efficient steam engine, it isn’t even possible.</p>

<p>Nobody has a 1e20x more efficient Bitcoin miner either, and I also doubt that’s possible, we just <a href="https://en.wikipedia.org/wiki/Thermodynamics">understand</a> steam engines a lot better, so for steam engines we <em>know</em>. More intelligence leads to more new tricks, but the tricks get harder and harder to find.</p>

<p>There’s low hanging fruit, you pick it, then you build tools to get the higher hanging fruit. You spend money on ladders, electric crane thingies, more and more money to get less and less fruit. Oil <a href="https://en.wikipedia.org/wiki/Petroleum_seep">used to be</a> just pouring out of the ground, now we go <a href="https://www.indelac.com/blog/introduction-to-oil-gas-offshore-drilling">to the bottom</a> of the ocean.</p>

<hr>


<p>A revolution is coming. The information revolution will do for intelligence what the industrial revolution did for energy. Most work (force*distance) used to be done by muscles, now it’s not. Most thinking used to be done by brains, soon it won’t be.</p>

<p>But it’s not going to happen overnight. It’ll happen on a nice exponential, like it already is. The universe is an unfathomable number of orders of magnitude more complex than the Go game. The universe includes the player. The universe includes the other players. Games don’t.</p>

<p><img src="https://geohot.github.io/blog/assets/images/trolley.jpg" height="250"></p>

<p>Unless we build a terrifying powder keg, there is no FOOM. Let the markets cook.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Artificial General Intelligence – A gentle introduction (240 pts)]]></title>
            <link>https://cis.temple.edu/~pwang/AGI-Intro.html</link>
            <guid>37086308</guid>
            <pubDate>Fri, 11 Aug 2023 08:15:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cis.temple.edu/~pwang/AGI-Intro.html">https://cis.temple.edu/~pwang/AGI-Intro.html</a>, See on <a href="https://news.ycombinator.com/item?id=37086308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="ltr" id="sites-canvas-main"><center><span size="5"><b><br>
</b></span></center>
<center>
<span size="5"><b>Artificial General Intelligence</b></span></center>
<center>
<span size="4">— A gentle introduction</span></center>
<center><span size="4"><br>
</span></center>
<center>
<i><a href="http://www.cis.temple.edu/%7Epwang/" rel="nofollow">Pei Wang</a></i>
</center>
<p><span><span size="2">[This page contains up-to-date information about the field of Artificial General Intelligence (AGI), collected and organized according to my judgment, though efforts are made to avoid personal biases.] </span></span></p>
<div><p><span size="2"><div><p>Contents</p><ol><li><a href="#TOC-From-AI-to-AGI"><strong>1 </strong>From AI to AGI</a><ol><li><a href="#TOC-AI:-in-different-directions-and-through-seasonal-cycles"><strong>1.1 </strong>AI: in different directions, and through seasonal cycles</a></li><li><a href="#TOC-A-new-spring"><strong>1.2 </strong>A new spring</a></li><li><a href="#TOC-It-s-summer-again"><strong>1.3 </strong>It's summer again</a></li></ol></li><li><a href="#TOC-AGI-Basics"><strong>2 </strong>AGI Basics</a><ol><li><a href="#TOC-What-is-AGI"><strong>2.1 </strong>What is AGI</a></li><li><a href="#TOC-Limitations-and-objections"><strong>2.2 </strong>Limitations and objections</a></li><li><a href="#TOC-Strategies-and-techniques"><strong>2.3 </strong>Strategies and techniques</a></li><li><a href="#TOC-The-ethics-of-AGI"><strong>2.4 </strong>The ethics of AGI</a></li></ol></li><li><a href="#TOC-Representative-AGI-Projects"><strong>3 </strong>Representative AGI Projects</a></li><li><a href="#TOC-AGI-Literatures-and-Resources"><strong>4 </strong>AGI Literatures and Resources</a></li></ol></div></span></p></div>
<h2><a name="TOC-From-AI-to-AGI"></a>From AI to AGI</h2>
<h3><a name="TOC-AI:-in-different-directions-and-through-seasonal-cycles"></a>AI: in different directions, and through seasonal cycles</h3><p>
    Artificial Intelligence (AI) started with "thinking machine" or
    "human-comparable intelligence" as the ultimate goal, as documented by
    the following literature:
    
</p><ul>
<li><a href="http://cogprints.org/499/1/turing.html" rel="nofollow">Computing
          machinery and intelligence</a>, 1950</li>
<li><a href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html" rel="nofollow">Proposal of the Dartmouth Meeting</a>, 1956</li>
<li><a href="https://mitpress.mit.edu/books/computers-and-thought-1" rel="nofollow">Computers and Thought</a>, 1963</li>
</ul><p>
    In the past, there were some ambitious projects aiming at this goal,
    though they all failed. The best-known examples include the
    following ones:
</p><ul>
<li><a href="https://en.wikipedia.org/wiki/General_Problem_Solver" rel="nofollow">General Problem Solver</a> </li>
<li><a href="http://en.wikipedia.org/wiki/Fifth_generation_computer" rel="nofollow">Fifth
          Generation Computer Systems</a> </li>
<li><a href="https://en.wikipedia.org/wiki/Strategic_Computing_Initiative" rel="nofollow">DARPA's Strategic Computing Initiative</a></li>
</ul><p>
    Partly due to the recognized difficulty of the problem, in the
    1970s-1980s mainstream AI gradually moved away from general-purpose
    intelligent systems, and turned to domain-specific problems and
    special-purpose solutions, though there are opposite attitudes
    toward this change:
</p><ul>
<li>"<a href="https://www.americanscientist.org/article/the-manifest-destiny-of-artificial-intelligence" rel="nofollow">AI adopts
          the scientific method (1987-present): ... It is now more
        common to build on existing theories than to propose brand new
        ones, to base claims on rigorous theorems or hard experimental
        evidence rather than on intuition, and to show relevance to
        real-world applications rather than toy examples.</a>"</li>
<li>"<a href="https://www.wired.com/2003/08/why-a-i-is-brain-dead/" rel="nofollow">Only a small community has concentrated on general intelligence ... AI has been brain-dead since the 1970s.</a>" </li>
</ul><p>
    Consequently, the field currently called "AI" consists of many
    loosely related subfields without a common foundation or framework,
    and suffers from an identity crisis:
</p><ul>
<li><a href="http://en.wikipedia.org/wiki/AI_effect" rel="nofollow">External
          recognition</a>: As soon as a problem is solved, it is no
        longer considered as requiring "intelligence" anymore, so the AI community rarely gets credit. </li>
<li><a href="http://www.aaai.org/Library/President/Brachman.pdf" rel="nofollow">Internal
          fragmentation</a>: The subfields of AI become less and less
        associated to one another, even though their problems are closely
        related. </li>
</ul>
<h3><a name="TOC-A-new-spring"></a>A new spring</h3><p>
    Roughly in the period of 2004 to 2007, calls for research on
    general-purpose systems returned, both inside and outside mainstream
    AI.
    
</p><p> Anniversaries are good time to review the big picture of the
      field. In the following collections and events, many
      well-established AI researchers raised the topic of
      general-purpose and human-level intelligence: </p>
<ul>
<li><a href="http://www.aaai.org/ojs/index.php/aimagazine/issue/view/161/showToc" rel="nofollow">AI
          Magazine 26(4), Winter 2005</a>: for the 25th Anniversary of
        AAAI and AI Magazine </li>
<li><a href="http://www.aaai.org/ojs/index.php/aimagazine/issue/view/165/showToc" rel="nofollow">AI
          Magazine 27(4), Winter 2006</a>: for the 50th Anniversary of
        AI </li>
<li><a href="https://en.wikipedia.org/wiki/AI@50" rel="nofollow">AI@50</a>:
        2006 Dartmouth Artificial Intelligence Conference: The Next
        Fifty Years </li>
</ul><p>
    More or less coincidentally, from outside mainstream AI, there were several books with bold titles and novel technical approaches to produce
    intelligence as a whole in computers:
</p><ul>
<li>Eric Baum, <a href="http://www.whatisthought.com/" rel="nofollow">What is
          Thought?</a>, 2004 </li>
<li>Jeff Hawkins, <a href="https://numenta.com/resources/papers-videos-and-more/on-intelligence/" rel="nofollow">On Intelligence</a>, 2004 </li>
<li>Marcus Hutter, <a href="http://www.hutter1.net/ai/uaibook.htm" rel="nofollow">Universal
          Artificial Intelligence</a>, 2005 </li>
<li>Pei Wang, <a href="http://www.springer.com/west/home/computer/artificial?SGWID=4-147-22-173659733-0" rel="nofollow">Rigid
Flexibility:
          The Logic of Intelligence</a>, 2006 [The manuscript was finished in 2003.]</li>
<li>Ben Goertzel &amp; Cassio Pennachin (Editors), <a href="http://www.springer.com/sgw/cda/frontpage/0,11855,4-147-22-43950079-0,00.html" rel="nofollow">Artificial General Intelligence</a>, 2007 [The manuscript was finished in 2003.] </li>
</ul><p>
    There were also several less technical but more influential books,
    with the same optimism on the possibility of building
    general-purpose AI:
    
</p><ul>
<li>Ray Kurzweil, <a href="http://www.singularity.com/aboutthebook.html" rel="nofollow">The
          Singularity Is Near: When Humans Transcend Biology</a>, 2005 </li>
<li>Marvin Minsky, <a href="http://en.wikipedia.org/wiki/The_Emotion_Machine" rel="nofollow">The
          Emotion Machine: Commonsense Thinking, Artificial
          Intelligence, and the Future of the Human Mind</a>, 2006 </li>
<li>Ben Goertzel, <a href="http://www.brownwalker.com/book.php?method=ISBN&amp;book=1581129890" rel="nofollow">The
          Hidden Pattern: A Patternist Philosophy of Mind</a>, 2006 </li>
<li>J. Storrs Hall, <a href="https://www.google.com/books/edition/Beyond_AI/j6ofAQAAIAAJ?hl=en" rel="nofollow">Beyond AI: Creating the Conscience of the Machine</a>, 2007 </li>
</ul><p>
    So after several decades, "general-purpose system", "integrated AI",
    and "human-level AI" become less taboo (though still far from popular)
    topics, as shown by several related meetings:
    
</p><ul>
<li><a href="http://www.aaai.org/Library/Symposia/Fall/fs04-01.php" rel="nofollow">Achieving Human-Level Intelligence through Integrated Systems and Research, AAAI Fall Symposium (2004)</a>
</li>
<li><a href="http://www-cs.stanford.edu/groups/nips05-AI-Workshop/" rel="nofollow">Towards Human-Level AI?, NIPS Workshop (2005)</a>
</li>
<li><a href="http://www.aaai.org/Conferences/AAAI/2006/aaai06iictrack.php" rel="nofollow">AAAI conferences special track on Integrated Intelligent
        Capabilities (2006)</a>
</li>
<li><a href="http://www.iospress.nl/book/advances-in-artificial-general-intelligence-concepts-architectures-and-algorithms/" rel="nofollow">Artificial General Intelligence Workshop (2006)</a></li>
</ul>
<h3><a name="TOC-It-s-summer-again"></a>It's summer again</h3><p>

Since 2008, several research communities have emerged, with similar focuses and overlapping participants:
</p><ul>
<li>Artificial General Intelligence: <a href="http://www.agi-conf.org/" rel="nofollow">conferences</a>, <a href="https://sciendo.com/journal/JAGI" rel="nofollow">journal</a>, <a href="http://www.agi-society.org/" rel="nofollow">society</a> </li>
<li>Biologically Inspired Cognitive Architectures: <a href="https://bica.ai/" rel="nofollow">conferences</a>, <a href="http://www.sciencedirect.com/science/journal/2212683X" rel="nofollow">journal</a>,
        <a href="http://www.bicasociety.org/" rel="nofollow">society</a> </li>
<li>Advances in Cognitive Systems: <a href="http://www.cogsys.org/journal" rel="nofollow">journal</a>, <a href="http://www.cogsys.org/" rel="nofollow">conferences</a></li>
<li>IEEE Task Force on Towards Human-like Intelligence: <a href="http://www.mini.pw.edu.pl/%7Emandziuk/cis_tf_thli/" rel="nofollow">website</a>, <a href="http://www.mini.pw.edu.pl/~mandziuk/cis_tf_thli/?page=activities" rel="nofollow">conferences</a></li>
</ul><p>
More research books have been published:
</p><ul>
<li>Joscha Bach, <a href="https://global.oup.com/academic/product/principles-of-synthetic-intelligence-psi-an-architecture-of-motivated-cognition-9780195370676" rel="nofollow">Principles of Synthetic Intelligence PSI: An Architecture of Motivated Cognition</a>, 2009</li>
<li>John Laird, <a href="http://mitpress.mit.edu/books/soar-cognitive-architecture" rel="nofollow">The Soar Cognitive Architecture</a>, 2012</li>
<li>Pei Wang and Ben Goertzel (Editors), <a href="http://www.springer.com/computer/ai/book/978-94-91216-61-9" rel="nofollow">Theoretical
          Foundations of Artificial General Intelligence</a>, 2012</li>
<li>Pei Wang, <a href="http://www.worldscientific.com/worldscibooks/10.1142/8665" rel="nofollow">Non-Axiomatic
Logic: A Model of Intelligent Reasoning</a>, 2013</li>
<li>Ben Goertzel <i>et al.</i>, Engineering General Intelligence, <a href="http://www.springer.com/computer/ai/book/978-94-6239-026-3" rel="nofollow">Part 1</a> and <a href="http://www.springer.com/computer/ai/book/978-94-6239-029-4" rel="nofollow">Part 2</a>, 2014</li>
</ul>
<p>In mainstream AI, <a href="https://en.wikipedia.org/wiki/Deep_learning" rel="nofollow">deep learning</a> has made impressive progress in recent years, which raises many people's hope on "human-level" AI once again. The claim <a href="https://www.telegraph.co.uk/technology/news/10884839/Computer-passes-Turing-Test-for-the-first-time-after-convincing-users-it-is-human.html" rel="nofollow">"The Turing Test has been passed"</a> and the success of <a href="https://en.wikipedia.org/wiki/AlphaGo" rel="nofollow">AlphaGo</a> in the board game Go renewed the discussion on what "artificial intelligence" is really about, and how to reach it. There is still no consensus, and the <a href="https://content.sciendo.com/view/journals/jagi/11/2/article-p1.xml" rel="nofollow">opinions</a> are not even converging. Several large companies have labeled their results as "steps towards AGI", and their approaches are either extensions of deep learning or integrations of the existing AI techniques. This approach is exemplified by <a href="https://openai.com/research/gpt-4">GPT-4</a>, which is claimed by its creator as "a significant step towards AGI".
</p>
<p>
Partly triggered by the recent progresses, more and more people consider AGI, or whatever it is called, as really possible. As a consequence, the risk and safety of it becomes a hot topic:
</p><ul>
<li><a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies" rel="nofollow">Superintelligence: Paths, Dangers, Strategies</a> by Nick Bostrom, 2014</li>
<li><a href="hhttps://futureoflife.org/open-letter/pause-giant-ai-experiments/" rel="nofollow">Pause Giant AI Experiments: An Open Letter</a> from the Future of Life Institute, 2023</li>
</ul>

<h2><a name="TOC-AGI-Basics"></a>AGI Basics</h2>
<div><p>The most general questions every AGI researcher needs to answer include:
  </p><ol><li>What is AGI, accurately specified?</li>
<li>Is it possible to build the AGI as specified?</li>
<li>If AGI is possible, what is the most plausible way to achieve it?</li>
<li>Even if we know how to achieve AGI, should we really do it?</li>
</ol><p>
[My own answers to these questions are <a href="http://www.iiim.is/2010/05/questions-about-artificial-intelligence/" rel="nofollow">here</a>.]</p></div>
<p>In the following the major answers in the field of AGI are summarized.</p>
<h3><a name="TOC-What-is-AGI"></a>What is AGI</h3><p>
Roughly speaking, Artificial General Intelligence (AGI) research has the following features:
</p><ul>
<li>Stressing on the <i>general-purpose</i> nature of intelligence,</li>
<li>Taking a <i>holistic or integrative</i> viewpoint on intelligence,</li>
<li>Believing the time has come to build an AI that is comparable to human intelligence.</li></ul><p>
Therefore, "AGI" is closer to the original meaning "AI", while very different from the current mainstream "AI research", which focuses on domain-specific and problem-specific methods. "AGI" is similar or related to notions like "<a href="http://en.wikipedia.org/wiki/Strong_AI" rel="nofollow">strong AI</a>", "<a href="http://www-formal.stanford.edu/jmc/human/human.html" rel="nofollow">human-level AI</a>", "<a href="http://en.wikipedia.org/wiki/AI-complete" rel="nofollow">complete AI</a>", "<a href="http://cogprints.org/499/1/turing.html" rel="nofollow">thinking machine</a>", "<a href="http://en.wikipedia.org/wiki/Cognitive_computing" rel="nofollow">cognitive computing</a>", and some others. <a href="https://goertzel.org/who-coined-the-term-agi/">Here</a> is an explanation about the selection of the term "AGI".
</p><p>
Even though there is a vague consensus on the objective of reproducing "intelligence" as a whole in computers, the current AGI projects are not aimed at exactly the same goal. Though every AGI approach gets its inspiration from the same source, that is, human intelligence, here "intelligence" is understood in several senses. Consequently, AGI projects attempt to duplicate human intelligence at different levels of abstraction:
</p><ul>
<li><b>Structure</b><br>
            Rationale: Intelligence is produced by the human brain. Therefore, to build an intelligent computer means to simulate the brain structure as faithfully as possible.<br>
            Background: Neuroscience, biology, etc.<br>
            Examples:&nbsp; <a href="http://en.wikipedia.org/wiki/Hierarchical_Temporal_Memory" rel="nofollow">HTM</a>,&nbsp;<a href="https://www.vicarious.com/" rel="nofollow">Vicarious</a><br>
            Challenge: There may be biological details that are neither
            possible nor necessary to be reproduced in AI systems.
      </li>
<li><b>Behavior</b><br>
            Rationale: Intelligence is displayed in how the human beings
            behave. Therefore, the goal should be to make a computer to behave exactly like a human.<br>
            Background: Psychology, linguistics, etc.<br>
            Examples: <a href="http://en.wikipedia.org/wiki/Turing_test" rel="nofollow">Turing
              Test</a>, <a href="https://openai.com/blog/chatgpt/" rel="nofollow">ChatGPT</a><br>
            Challenge: There may be psychological or social factors that are
            neither possible nor necessary to be reproduced in AI
            systems.
      </li>
<li><b>Capability</b><br>
            Rationale: Intelligence is evaluated by problem-solving capability. Therefore, an intelligent system should be able to solve certain practical problem that is currently solvable by humans only.<br>
            Background: Computer application guided by domain knowledge<br>
            Examples: <a href="https://en.wikipedia.org/wiki/IBM_Watson" rel="nofollow">IBM Watson</a>, <a href="https://en.wikipedia.org/wiki/AlphaGo" rel="nofollow">AlphaGo</a><br>
            Challenge: There is no defining problems of intelligence, and the
            special-purpose solutions lack generality and flexibility.
      </li>
<li><b>Function</b><br>
            Rationale: Intelligence is associated to a collection of cognitive
            functionality, such as perceiving, reasoning, learning, acting, communicating, problem solving, etc. Therefore the goal is to reproduce these functions in computers.<br>
            Background: Computer science<br>
            Examples: <a href="http://aima.cs.berkeley.edu/chapters.html" rel="nofollow">Mainstream
              AI textbooks</a>, <a href="http://soar.eecs.umich.edu/" rel="nofollow">Soar</a><br>
            Challenge: The AI techniques developed so far are highly
            fragmented and rigid, and it is hard for them to work together.
      </li>
<li><b>Principle</b><br>
            Rationale: Intelligence is a form of rationality or
            optimality. Therefore, an intelligent system should always "do the right thing" according to certain general principles.<br>
            Background: Logic, mathematics, etc.<br>
            Examples: <a href="http://www.hutter1.net/ai/uaibook.htm" rel="nofollow">AIXI</a>, <a href="https://cis.temple.edu/~pwang/NARS-Intro.html">NARS</a>
<br>
            Challenge: There are too many aspects in intelligence and cognition to be explained and reproduced by a
            simple theory.</li></ul>
<p>
From top to bottom, they correspond to descriptions of human intelligence in more and more general level, and to reproduce that description in computer systems. Since different descriptions have different granularity and scope, the above objectives are related, but still very different, and do not subsume each other. The best way to achieve one is usually not a good choice for the others. [A more detailed discussion of this issue can be found <a href="https://content.sciendo.com/view/journals/jagi/10/2/article-p1.xml" rel="nofollow">here</a>.]
</p><p>
The "general purpose" nature of AGI has also obtained different interpretations over the years, as meaning
</p>
<p><i><ol>
<li>Can solve all problems,</li>
<li>Can solve all human-solvable problems,</li>
<li>Can solve all computable problems,</li>
<li>Can try to solve all representable problems.</li>
</ol></i></p><p>
Because of this diversity in research goal, in AGI currently there is no commonly accepted evaluation criteria (such as milestones and benchmarks).

</p>
<h3><a name="TOC-Limitations-and-objections"></a>Limitations and objections</h3><p>

Since the idea of AI or "thinking machine" appeared, there have been various objections against its possibility. Some people claimed that they have proved that AGI, or whatever it is called, is theoretically impossible, due to certain fundamental limitations of computers.
</p><p>
Many researchers have argued against these objections. Classical arguments can be found in the following works:
</p>
<ul>
<li><a href="http://cogprints.org/499/1/turing.html" rel="nofollow">Computing machinery and
    intelligence</a>, Alan M. Turing</li>
<li><a href="http://en.wikipedia.org/wiki/G%C3%B6del%2C_Escher%2C_Bach" rel="nofollow">G<span color="#6a6a6a" face="Arial">ö</span>del, Escher, Bach: An Eternal Golden Braid</a>, Douglas R. Hofstadter</li>
</ul><p>
Obviously, all AGI researchers believe that AGI can be achieved (though they have different interpretations to the term). In the <a href="http://www.cis.temple.edu/~pwang/Publication/AGI_Aspects.pdf" rel="nofollow">introductory chapter of the AGI 2006 Workshop Proceedings</a>, I and Ben Goertzel responded to the following common doubts and objections of this research:
</p><ul><i>
<li>AGI is impossible.</li>
<li>There is no such a thing as general intelligence.</li>
<li>General-purpose systems are not as good as special-purpose ones.</li>
<li>AGI is already included in the current AI.</li>
<li>It is too early to work on AGI.</li>
<li>AGI is nothing but hype.</li>
<li>AGI research is not fruitful.</li>
<li>AGI is dangerous.</li>
</i></ul>
<p>Some of the doubts about the possibility of AGI come from misconceptions on what AGI attempts to achieve or what computers can do. The previous subsection has clarified the former issue, while an analysis of the latter issue can be found <a href="http://www.cis.temple.edu/~pwang/Publication/AI_Misconceptions.pdf" rel="nofollow">here</a>.</p>
<h3><a name="TOC-Strategies-and-techniques"></a>Strategies and techniques</h3><p>

On one hand, the ultimate goal of AGI is to reproduce intelligence as a whole, while on the other hand, engineering practice must be step-by-step. To resolve this dilemma, three overall strategies have been proposed:
    
</p><ul>
<li><b>Hybrid</b><br>
            Approach: To develop individual functions first (using
            different theories and techniques), then to connect them
            together.<br>
            Argument: <a href="http://www.aaai.org/Library/President/Brachman.pdf" rel="nofollow">(AA)AI:
              More than the Sum of Its Parts</a>, Ronald Brachman<br>
            Difficulty: Compatibility of the theories and techniques
      </li>
<li><b>Integrated</b><br>
            Approach: To design an architecture first, then to design
            its modules (using various techniques) accordingly.<br>
            Argument: <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.233.1596" rel="nofollow">Cognitive
              Synergy: A Universal Principle for Feasible General
              Intelligence?</a>, Ben Goertzel<br>
            Difficulty: Isolation, specification, and coordination of
            the functions
      </li>
<li><b>Unified</b><br>
            Approach: Using a single technique to start from a core
            system, then to extend and augment it incrementally.<br>
            Argument: <a href="http://www.cis.temple.edu/%7Epwang/Publication/unifiedAI.pdf" rel="nofollow">Toward
              a Unified Artificial Intelligence</a>, Pei Wang<br>
            Difficulty: Versatility and extensibility of the core technique
      </li>
</ul><p>
Obviously, the selection of development strategy partially depends on the selection of the research objective.
</p>
<div><p>At the current time, the major techniques used in AGI projects include, though are not limited to:
</p><ul><li>logic</li>
<li>probability theory</li>
<li>production system</li>
<li>graph theory</li>
<li>knowledge base</li>
<li>learning algorithm</li>
<li>neural network</li>
<li>evolutionary computation</li>
<li>robotics</li>
<li>multi-agent system</li></ul><p>
Though each of these techniques is also explored in mainstream AI, to use it in a general-purpose system leads to very different design decisions in technical details.</p><h3><a name="TOC-The-ethics-of-AGI"></a>The ethics of AGI</h3>
<p>Even if we have found out how to achieve AGI, it does not necessarily mean we really want to do it. Like all major scientific discoveries and technical breakthroughs, AGI has the potential to revolutionize our life and even the fate of the human species, either in a desired way or an undesired way — or, as things usually go, a mixture of the two.
</p>
<p>AGI researchers are aware of their responsibility on this topic, though most of them think that, according to the currently available evidence, progress in AGI research will benefit the human species, rather than to destroy it. Discussions on how to make AGI "safe" have existed in AGI meetings since the very beginning. Sample discussions include</p>
<ul>
<li><a href="http://agi-conf.org/2008/" rel="nofollow">AGI-08</a> had a workshop on <a href="http://agi-conf.org/2008/workshop/" rel="nofollow">The Sociocultural, Ethical and Futurological Implications of Artificial General Intelligence</a></li>
<li><a href="http://agi-conf.org/2012/" rel="nofollow">AGI-12</a> was jointly sponsored by Oxford's <a href="https://www.fhi.ox.ac.uk/" rel="nofollow">Future of Humanity Institute</a>. In this conference, many papers address ethical and moral issues</li>
</ul>
<p>Of course, many crucial problems remain open, but to find their solutions, the research of AGI should be speed up, rather than slowed down. Once again, some wide-spreading concerns and fears about AGI are based on misconceptions about the nature of AGI.</p>
	
<h2><a name="TOC-Representative-AGI-Projects"></a>Representative AGI Projects</h2><p>

The following projects are selected to represent the current AGI research, as for each of them, it can be said that</p></div>
<div>
<ol><li>It is clearly oriented to AGI (that is why IBM's Watson and DeepMind's AlphaGo are not included)</li>
<li>It is still very active (that is why Pollock's OSCAR and Brooks' Cog are no longer included)</li>
<li>It has ample publications on technical details (that is why many recent AGI projects are not included yet, except GPT-4 that is used to represent various deep learning projects toward AGI)</li>
</ol>
<p>The projects are listed in alphabetical order. Each project name is linked to the project website, where the following quotations are extracted. The focus of the quotations is on the research goal (the 1st question) and technical path (the 3rd question). Two publications on the project are selected, usually one brief introduction and one detailed description.</p>
<blockquote><i>
</i></blockquote>
<p><b><a href="http://act-r.psy.cmu.edu/" rel="nofollow">ACT-R</a></b>
[<a href="http://act-r.psy.cmu.edu/wordpress/wp-content/uploads/2012/12/526FSQUERY.pdf" rel="nofollow">An Integrated Theory of the Mind</a>; <a href="http://act-r.psy.cmu.edu/book/" rel="nofollow">The Atomic Components of Thought</a>]
    <i>
<blockquote>
    ACT-R is a cognitive architecture: a theory for simulating and
          understanding human cognition. Researchers working on ACT-R
          strive to understand how people organize knowledge and produce
          intelligent behavior. As the research continues, ACT-R evolves
          ever closer into a system which can perform the full range of
          human cognitive tasks: capturing in great detail the way we
          perceive, think about, and act on the world. 
<p>
On the exterior, ACT-R looks like a programming language;
          however, its constructs reflect assumptions about human
          cognition. These assumptions are based on numerous facts
          derived from psychology experiments. Like a programming
          language, ACT-R is a framework: for different tasks (e.g.,
          Tower of Hanoi, memory for text or for list of words, language
          comprehension, communication, aircraft controlling),
          researchers create models (aka programs) that are written in
          ACT-R and that, beside incorporating the ACT-R's view of
          cognition, add their own assumptions about the particular
          task. These assumptions can be tested by comparing the results
          of the model with the results of people doing the same tasks.
     </p>
<p>
     ACT-R is a hybrid cognitive
          architecture. Its symbolic structure is a production system;
          the subsymbolic structure is represented by a set of massively
          parallel processes that can be summarized by a number of
          mathematical equations. The subsymbolic equations control many
          of the symbolic processes. For instance, if several
          productions match the state of the buffers, a subsymbolic
          utility equation estimates the relative cost and benefit
          associated with each production and decides to select for
          execution the production with the highest utility. Similarly,
          whether (or how fast) a fact can be retrieved from declarative
          memory depends on subsymbolic retrieval equations, which take
          into account the context and the history of usage of that
          fact. Subsymbolic mechanisms are also responsible for most
          learning processes in ACT-R.
        </p>
</blockquote>
</i>
<b><a href="https://openaera.org/" rel="nofollow">AERA</a></b>
[<a href="https://alumni.media.mit.edu/~kris/ftp/AnytimeBoundedRationalityagi15_nivelEtAl.pdf" rel="nofollow">Anytime Bounded Rationality</a>; <a href="https://alumni.media.mit.edu/~kris/ftp/AERA-RUTR-SCS13002.pdf" rel="nofollow">Autocatalytic Endogenous Reflective Architecture</a>]
    <i>
<blockquote>
    AERA is a cognitive architecture - and a blueprint - for constructing agents with high levels of operational autonomy, starting from only a small amount of designer-specified code – a seed. Using a value-driven dynamic priority scheduling to control the parallel execution of a vast number of lines of reasoning, the system accumulates increasingly useful models of its experience, resulting in recursive self-improvement that can be autonomously sustained after the machine leaves the lab, within the boundaries imposed by its designers. 
<p>
AERA demonstrates domain-independent self-supervised cumulative learning of complex tasks. Unlike contemporary AI systems, AERA-based agents excel at handling novelty - situations, information, data, tasks - that their programmers could not anticipate. It is the only implementable / implemented system in existence for achieving bounded recursive self-improvement.
     </p>
<p>
     AERA-based agents learn cumulatively from experience by interacting with the world and generating compositional causal-relational micro-models of its experience. Using non-axiomatic abduction and deduction, it constantly predicts how to achieve its active goals and what the future may hold, generating a flexible opportunistically-interruptable plan for action.
        </p>
</blockquote>
</i>
<b><a href="http://www.hutter1.net/ai/index.htm" rel="nofollow">AIXI</a></b>  [<a href="http://www.hutter1.net/ai/aixigentle.htm" rel="nofollow">Universal Algorithmic Intelligence: A mathematical top-&gt;down approach</a>; <a href="http://www.hutter1.net/ai/uaibook.htm" rel="nofollow">Universal Artificial Intelligence</a><span>]</span><i>
<blockquote>An important observation is that most, if not all known facets of intelligence can be formulated as goal driven or, more precisely, as maximizing some utility function.
<p>Sequential decision theory formally solves the problem of rational agents in uncertain worlds if the true environmental prior probability distribution is known. Solomonoff's theory of universal induction formally solves the problem of sequence prediction for unknown prior distribution. We combine both ideas and get a parameter-free theory of universal Artificial Intelligence. We give strong arguments that the resulting AIXI model is the most intelligent unbiased agent possible.</p>
<p>The major drawback of the AIXI model is that it is uncomputable, ... which makes an implementation impossible. To overcome this problem, we constructed a modified model AIXItl, which is still effectively more intelligent than any other time t and length l bounded algorithm.</p>
</blockquote>
</i>
<b><a href="http://www.cyc.com/" rel="nofollow">Cyc</a></b> [<a href="http://www.csee.umbc.edu/courses/471/papers/cyc95.pdf" rel="nofollow">Cyc: A Large-Scale Investment in Knowledge Infrastructure</a>; <a href="https://www.researchgate.net/publication/220545983_D_B_Lenat_and_R_V_Guha_Building_Large_Knowledge-Based_Systems_Representation_and_Inference_in_the_Cyc_Project" rel="nofollow">Building Large Knowledge-Based Systems</a>]<i>
<blockquote>Vast amounts of commonsense knowledge, representing human consensus reality, would need to be encoded to produce a general AI system. In order to mimic human reasoning, Cyc would require background knowledge regarding science, society and culture, climate and weather, money and financial systems, health care, history, politics, and many other domains of human experience. The Cyc Project team expected to encode at least a million facts spanning these and many other topic areas.
<p>The Cyc knowledge base (KB) is a formalized representation of a vast quantity of fundamental human knowledge: facts, rules of thumb, and heuristics for reasoning about the objects and events of everyday life. The medium of representation is the formal language CycL. The KB consists of terms -- which constitute the vocabulary of CycL -- and assertions which relate those terms. These assertions include both simple ground assertions and rules.</p>
</blockquote>
</i>
<b><a href="https://openai.com/research/gpt-4" rel="nofollow">GPT-4</a></b> [<a href="https://cdn.openai.com/papers/gpt-4.pdf" rel="nofollow">GPT-4 Technical Report</a>; <a href="https://arxiv.org/abs/2303.12712">Sparks of Artificial General Intelligence</a>]<i>
<blockquote>
We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks. <p>
The combination of the generality of GPT-4's capabilities, with numerous abilities spanning a broad swath of domains, and its performance on a wide spectrum of tasks at or beyond human-level, makes us comfortable with saying that GPT-4 is a significant step towards AGI.</p>
</blockquote>
</i>
<b><a href="http://en.wikipedia.org/wiki/Hierarchical_Temporal_Memory" rel="nofollow">HTM</a></b> [<a href="http://numenta.com/assets/pdf/whitepapers/hierarchical-temporal-memory-cortical-learning-algorithm-0.2.1-en.pdf" rel="nofollow">Hierarchical Temporal Memory</a>; <a href="http://www.onintelligence.org/" rel="nofollow">On Intelligence</a>]<i>
<blockquote>At the core of every Grok model is the Cortical Learning Algorithm (CLA), a detailed and realistic model of a layer of cells in the neocortex. Contrary to popular belief, the neocortex is not a computing system, it is a memory system. When you are born, the neocortex has structure but virtually no knowledge. You learn about the world by building models of the world from streams of sensory input. From these models, we make predictions, detect anomalies, and take actions.
<p>In other words, the brain can best be described as a predictive modeling system that turns predictions into actions. Three key operating principles of the neocortex are described below: sparse distributed representations, sequence memory, and on-line learning.</p>
</blockquote>
</i><b><a href="http://ccrg.cs.memphis.edu/projects.html" rel="nofollow">LIDA</a></b>
[<a href="http://ccrg.cs.memphis.edu/assets/papers/zo-1010-lida-060403.pdf" rel="nofollow">The LIDA Architecture</a>;
<a href="http://ccrg.cs.memphis.edu/tutorial/tutorial.html" rel="nofollow">LIDA Tutorial</a>]
  <i>
  <blockquote>
Implementing and fleshing out
          a number of psychological and neuroscience theories of
          cognition, the LIDA conceptual model aims at being a cognitive
          "theory of everything." With modules or processes for
          perception, working memory, episodic memories,
          "consciousness," procedural memory, action selection,
          perceptual learning, episodic learning, deliberation,
          volition, and non-routine problem solving, the LIDA model is
          ideally suited to provide a working ontology that would allow
          for the discussion, design, and comparison of AGI systems. The
          LIDA technology is based on the LIDA cognitive cycle, a sort
          of "cognitive atom." The more elementary cognitive modules
          play a role in each cognitive cycle. Higher-level processes
          are performed over multiple cycles.
    
<p>
     The LIDA architecture
          represents perceptual entities, objects, categories,
          relations, etc., using nodes and links .... These serve as
          perceptual symbols acting as the common currency for
          information throughout the various modules of the LIDA
          architecture.</p>
</blockquote>
</i><b><a href="http://cognitive-ai.com/" rel="nofollow">MicroPsi</a></b><span>  [</span><a href="http://cognitive-ai.com/publications/assets/MicroPsiArchitectureICCM03.pdf" rel="nofollow">The MicroPsi Agent Architecture</a><span>;  </span><a href="https://global.oup.com/academic/product/principles-of-synthetic-intelligence-psi-an-architecture-of-motivated-cognition-9780195370676?cc=us&amp;lang=en&amp;" rel="nofollow">Principles of Synthetic Intelligence</a><span>]</span><i>
<blockquote>The MicroPsi agent architecture describes the interaction of emotion, 
motivation and cognition of situated agents, mainly based on the Psi 
theory of Dietrich Dorner. 
The Psi theory addresses emotion, perception, representation and bounded
 rationality, but being formulated within psychology, has had relatively
 little impact on the discussion of agents within computer science. 
MicroPsi is a formulation of the original theory in a more abstract and 
formal way, at the same time enhancing it with additional concepts for 
memory, building of ontological categories and attention.
<p>The agent framework uses semantic networks, called node nets, that are a
 unified representation for control structures, plans, sensory and 
action schemas, Bayesian networks and neural nets. Thus it is possible 
to set up different kinds of agents on the same framework.</p>
</blockquote>
</i><b><a href="http://opennars.org/">NARS</a></b><span>  [</span><a href="https://proceedings.mlr.press/v192/wang22a/wang22a.pdf">Intelligence: From Definition to Design</a><span>;  </span><a href="http://www.springer.com/west/home/computer/artificial?SGWID=4-147-22-173659733-0" rel="nofollow">Rigid Flexibility: The Logic of Intelligence</a><span>]</span><i>
<blockquote>What makes NARS different from conventional reasoning systems is its ability to learn from its experience and to work with insufficient knowledge and resources. NARS attempts to uniformly explain and reproduce many cognitive facilities, including reasoning, learning, planning, etc, so as to provide a unified theory, model, and system for AI as a whole. The ultimate goal of this research is to build a thinking machine.
<p>The development of NARS takes an incremental approach consisting four major stages. At each stage, the logic is extended to give the system a more expressive language, a richer semantics, and a larger set of inference rules; the memory and control mechanism are then adjusted accordingly to support the new logic.</p>
<p>In NARS the notion of "reasoning" is extended to represent a system's ability to predict the future according to the past, and to satisfy the unlimited resources demands using the limited resources supply, by flexibly combining justifiable micro steps into macro behaviors in a domain-independent manner.</p>
</blockquote>
</i><b><a href="http://opencog.org/" rel="nofollow">OpenCog</a> </b><span>[</span><a href="https://arxiv.org/abs/2103.15100v3" rel="nofollow">The General Theory of General Intelligence: A Pragmatic Patternist Perspective</a><span>; Engineering General Intelligence, </span><a href="http://www.springer.com/computer/ai/book/978-94-6239-026-3" rel="nofollow">Part 1</a><span> and </span><a href="http://www.springer.com/computer/ai/book/978-94-6239-029-4" rel="nofollow">Part 2</a><span>]</span><i>
<blockquote>OpenCog, as a software framework, aims to provide research scientists and software developers with a common platform to build and share artificial intelligence programs. The long-term goal of OpenCog is acceleration of the development of beneficial AGI.
<p>OpenCogPrime is a specific AGI design being constructed within the OpenCog framework. It comes with a fairly detailed, comprehensive design covering all aspects of intelligence. The hypothesis is that if this design is fully implemented and tested on a reasonably-sized distributed network, the result will be an AGI system with general intelligence at the human level and ultimately beyond.</p>
<p>While an OpenCogPrime based AGI system could do a lot of things, we are initially focusing on using OpenCogPrime to control simple virtual agents in virtual worlds. We are also experimenting with using it to control a Nao humanoid robot. See http://novamente.net/example for some illustrative videos.</p>
</blockquote>
</i><b><a href="http://cogarch.ict.usc.edu/" rel="nofollow">Sigma</a></b><span> [</span><a href="https://www.dropbox.com/s/bsfsyot89xl28zo/SM%20Symp%20Sigma%202017%20Revised%20D.pdf" rel="nofollow">Lessons from Mapping Sigma onto the Standard Model of the Mind</a><span>; </span><a href="https://sciendo.com/article/10.1515/jagi-2016-0001" rel="nofollow">The Sigma Cognitive Architecture and System</a><span>]</span><i>
<blockquote>The goal of this effort is to develop a sufficiently efficient, 
functionally elegant, generically cognitive, grand unified, cognitive 
architecture in support of virtual humans (and hopefully intelligent 
agents/robots – and even a new form of unified theory of human cognition
 – as well).<p>

Our focus is on the development of the <em>Sigma</em> (∑) architecture, which explores the <em>graphical architecture hypothesis</em>
 that progress at this point depends on blending what has been learned 
from over three decades worth of independent development of cognitive 
architectures and <em>graphical models</em>, a broadly applicable state-of-the-art formalism for constructing intelligent mechanisms.  The result is a <em>hybrid</em> (discrete+continuous) <em>mixed</em>
 (symbolic+probabilistic) approach that has yielded initial results 
across memory and learning, problem solving and decision making, mental 
imagery and perception, speech and natural language, and emotion and 
attention.</p></blockquote>
</i><b><a href="http://www.cse.buffalo.edu/sneps/" rel="nofollow">SNePS</a></b>
[<a href="http://www.cse.buffalo.edu/%7Eshapiro/Papers/shabon09a.pdf" rel="nofollow">The
GLAIR Cognitive Architecture</a>; <a href="http://www.cse.buffalo.edu/sneps/Tutorial/" rel="nofollow">SNePS Tutorial</a>]
<i>
<blockquote>
The long term goal of the SNePS Research Group is to understand the
          nature of intelligent cognitive processes by developing and
          experimenting with computational cognitive agents that are
          able to use and understand natural language, reason, act, and
          solve problems in a wide variety of domains.
          
<p>
          The SNePS knowledge representation, reasoning, and
          acting system has several features that facilitate
          metacognition in SNePS-based agents. The most prominent is the
          fact that propositions are represented in SNePS as terms
          rather than as logical sentences. The effect is that
          propositions can occur as arguments of propositions, acts, and
          policies without limit, and without leaving first-order logic.</p>
</blockquote>
</i></p><p><b><a href="http://soar.eecs.umich.edu/" rel="nofollow">Soar</a></b> [<a href="http://www.cse.msu.edu/~cse841/papers/Soar.pdf" rel="nofollow">A Gentle Introduction to Soar</a>; <a href="http://mitpress.mit.edu/books/soar-cognitive-architecture" rel="nofollow">The Soar Cognitive Architecture</a>]</p>
<blockquote><i>The ultimate in intelligence would be complete rationality which would imply the ability to use all available knowledge for every task that the system encounters. Unfortunately, the complexity of retrieving relevant knowledge puts this goal out of reach as the body of knowledge increases, the tasks are made more diverse, and the requirements in system response time more stringent. The best that can be obtained currently is an approximation of complete rationality. The design of Soar can be seen as an investigation of one such approximation.
<p>For many years, a secondary principle has been that the number of distinct architectural mechanisms should be minimized. Through Soar 8, there has been a single framework for all tasks and subtasks (problem spaces), a single representation of permanent knowledge (productions), a single representation of temporary knowledge (objects with attributes and values), a single mechanism for generating goals (automatic subgoaling), and a single learning mechanism (chunking). We have revisited this assumption as we attempt to ensure that all available knowledge can be captured at runtime without disrupting task performance. This is leading to multiple learning mechanisms (chunking, reinforcement learning, episodic learning, and semantic learning), and multiple representations of long-term knowledge (productions for procedural knowledge, semantic memory, and episodic memory).</p>
<p>Two additional principles that guide the design of Soar are functionality and performance. Functionality involves ensuring that Soar has all of the primitive capabilities necessary to realize the complete suite of cognitive capabilities used by humans, including, but not limited to reactive decision making, situational awareness, deliberate reasoning and comprehension, planning, and all forms of learning. Performance involves ensuring that there are computationally efficient algorithms for performing the primitive operations in Soar, from retrieving knowledge from long-term memories, to making decisions, to acquiring and storing new knowledge.</p>
</i></blockquote>
<p><b>A rough classification</b></p><p>
The above AGI projects are roughly classified in the following
        table, according to the type of their answers to the previously
        listed 1st question (on research goal) and 3rd question (on
        technical path).
</p>

<center>
<table>
<tbody>
<tr>
<td><i>goal  \  path</i></td>
<td><b>hybrid</b></td>
<td><b>integrated</b></td>
<td><b>unified</b></td>
</tr>
<tr>
<td><b>principle</b></td>
<td> </td>
<td><br>
</td>
<td>AERA, AIXI, NARS</td>
</tr>
<tr>
<td><b>function</b></td>
<td><br>
</td>
<td>OpenCog, Sigma, Soar</td>
<td>SNePS</td>
</tr>
<tr>
<td><b>capability</b></td>
<td><br>
</td>
<td><br>
</td>
<td>Cyc</td>
</tr>
<tr>
<td><b>behavior</b></td>
<td><br>
</td>
<td>ACT-R, LIDA, MicroPsi</td>
<td>GPT-4</td>
</tr>
<tr>
<td><b>structure</b></td>
<td><br>
</td>
<td><br>
</td>
<td>HTM</td>
</tr>
</tbody>
</table>
</center>
<p>
Since this classification is made at a high level, projects in the same entry of the table are still quite different in the details of their research goals and technical paths.
 </p>
<p>
In summary, the current AGI projects are based on very different theories and techniques.</p>
<h2><a name="TOC-AGI-Literatures-and-Resources"></a>AGI Literatures and Resources</h2>
<p>AGI collections:</p>
<div>
<ul><li>The earliest collection of AGI works is <a href="https://link.springer.com/book/10.1007/978-3-540-68677-4" rel="nofollow">Artificial General Intelligence</a>. Though this book was published in 2007, 
the manuscript was finished in 2003.</li>
<li><a href="https://www.iospress.com/catalog/books/advances-in-artificial-general-intelligence-concepts-architectures-and-algorithms" rel="nofollow">Advances in Artificial General Intelligence: Concepts, Architectures and Algorithms</a> is a post-conference proceedings of the 2006 AGI Workshop. The introductory chapter "<a href="https://cis.temple.edu/~pwang/Publication/AGI_Aspects.pdf" rel="nofollow">Aspects of Artificial General Intelligence</a>" clarified the notion of AGI and summarized the other chapters.</li>
<li><a href="http://www.springer.com/computer/ai/book/978-94-91216-61-9" rel="nofollow">Theoretical Foundations of Artificial General Intelligence</a> is a collection co-authored by active AGI researchers. Each chapter address a theoretical topic in AGI, and is written in a non-technical style, so as to provide information for readers who are not AGI researchers.</li>
<li><a href="https://www.amazon.com/Between-Ape-Artilect-Conversations-Transformative/dp/1496138171" rel="nofollow">Between Ape and Artilect: Conversations with Pioneers of Artificial General Intelligence and Other Transformative Technologies</a> contains some interviews of AGI researchers.</li></ul>
<p>
The <a href="http://agi-conf.org/" rel="nofollow">annual AGI international conference series</a> was started in 2008. The conference websites link to all accepted papers, plus additional materials like presentation files and video records.
</p>
<p>
<a href="https://sciendo.com/journal/JAGI" rel="nofollow">Journal of Artificial General Intelligence</a> (JAGI) is a peer-reviewed journal with open access, started in 2009.</p>
<p>The AGI conference and journal are managed by the <a href="http://www.agi-society.org/" rel="nofollow">Artificial General Intelligence Society</a> (AGIS). Everyone interested in AGI can become a member.
</p><p>
Communication venues and social media dedicated to AGI or related research:
</p><ul>
<li>AGI groups in Facebook: <a href="https://www.facebook.com/groups/propBitDev/" rel="nofollow">Artificial General Intelligence (AGI)</a>, <a href="https://www.facebook.com/groups/RealAGI/" rel="nofollow">Real AGI</a>,
<a href="https://www.facebook.com/groups/396475193810786/" rel="nofollow">Artificial General Intelligence</a>, <a href="https://www.facebook.com/groups/722892624534381/" rel="nofollow">Artificial Cognition</a></li>
<li><a href="https://www.linkedin.com/groups/1084997" rel="nofollow">AGI group</a> in LinkedIn</li>
<li><a href="http://groups.google.com/group/artificial-general-intelligence">AGI group</a> in Google Group</li>
<li><a href="https://agi.topicbox.com/" rel="nofollow">AGI mailing list</a> in Listbox</li>
</ul>
<p>Educational materials for students:</p>
<ul>
<li><a href="https://cis.temple.edu/~pwang/AGI-Curriculum.html">
Suggested Education for Future AGI Researchers</a>, by Pei Wang</li>
<li><a href="http://goertzel.org/agi-curriculum/" rel="nofollow">Sketch of an AGI Curriculum</a>, by Ben Goertzel</li>
<li><a href="http://www.hutter1.net/ai/introref.htm" rel="nofollow">AI Recommendations</a>, by Marcus Hutter</li>
<li><a href="http://www.agi-society.org/resources/" rel="nofollow">Videos of the past AGI Summer School lectures</a></li>
</ul>
<p>Other AGI resources:</p>
<div>
<ul><li>AGIS <a href="http://www.agi-society.org/resources/" rel="nofollow">resources page</a></li>
<li><a href="http://en.wikipedia.org/wiki/Artificial_General_Intelligence" rel="nofollow">Artificial general intelligence page</a> in Wikipedia</li>
<li><a href="http://www.scholarpedia.org/article/Artificial_General_Intelligence" rel="nofollow">Artificial general intelligence page</a> in Scholarpedia</li></ul>
</div>
</div>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Bipolar Lisp Programmer (2007) (142 pts)]]></title>
            <link>https://www.marktarver.com/bipolar.html</link>
            <guid>37086301</guid>
            <pubDate>Fri, 11 Aug 2023 08:13:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marktarver.com/bipolar.html">https://www.marktarver.com/bipolar.html</a>, See on <a href="https://news.ycombinator.com/item?id=37086301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <td><span color="#FFFFFF" size="4" face="Nyala"><br>
        &nbsp;</span><div>
			<p>
			<span color="#000000" size="4" face="Nyala">Any lecturer who serves 
			his time will probably graduate hundreds, if not thousands of 
			students. &nbsp;Mostly they merge into a blur; like those paintings of 
			crowd scenes where the leading faces are clearly picked out and the 
			rest just have iconic representations. &nbsp; This anonymity can be 
			embarrassing when some past student hails you by name and you really 
			haven't got the foggiest idea of who he or she is. &nbsp;It's both nice 
			to be remembered and also toe curlingly embarrassing to admit that 
			you cannot recognise who you are talking to.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But some faces you do 
			remember; students who did a project under you. &nbsp;Also two other 
			categories - the very good and the very bad. &nbsp; Brilliance and abject 
			failure both stick in the mind. And one of the oddest things, and 
			really why I'm writing this short essay, is that there are some 
			students who actually fall into both camps. &nbsp;Here's another 
			confession. &nbsp;I've always liked these students and had a strong 
			sympathy for them.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now abject failure is 
			nothing new in life. &nbsp;Quite often I've had students who have failed 
			miserably for no other reason than they had very little ability. &nbsp; 
			&nbsp;This is nothing new. What is new is that in the UK, we now graduate 
			a lot of students like that. &nbsp;But, hey, that's a different story and 
			I'm not going down that route.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">No I want to look at the 
			brilliant failures. &nbsp; Because brilliance amd failure are so often 
			mixed together and our initial reaction is it shouldn't be. &nbsp; But it 
			happens and it happens a lot. &nbsp;Why?</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Well, to understand 
			that, we have to go back before university. Let's go back to high 
			school and look at a brilliant failure in the making. &nbsp;Those of you 
			who have seen the film "Donnie Darko" will know exactly the kind of 
			student I'm talking about. &nbsp;But if you haven't, don't worry, because 
			you'll soon recognise the kind of person I'm talking about. &nbsp;Almost 
			every high school has one every other year or so.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Generally what we're 
			talking about here is a student of outstanding brilliance. &nbsp;Someone 
			who is used to acing most of his assignments; of doing things at the 
			last minute but still doing pretty well at them. &nbsp; &nbsp;At some level he 
			doesn't take the whole shebang all that seriously; because, when you 
			get down to it, a lot of the rules at school are pretty damned 
			stupid. &nbsp;In fact a lot of the things in our world don't make a lot 
			of sense, if you really look at them with a fresh mind. &nbsp;</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">So we have two aspects 
			to this guy; intellectual acuteness and not taking things seriously. 
			&nbsp;The not taking things seriously goes with finding it all pretty 
			easy and a bit dull. &nbsp;But also it goes with realising that a lot of 
			human activity is really pretty pointless, and when you realise that 
			and internalise it then you become cynical and also a bit sad - 
			because you yourself are caught up in this machine and you have to 
			play along if you want to get on. &nbsp;Teenagers are really good at 
			spotting this kind of phony nonsense. &nbsp;Its also the seed of an 
			illness; a melancholia that can deepen in later life into full blown 
			depression.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Another feature about 
			this guy is his low threshold of boredom. He'll pick up on a task 
			and work frantically at it, accomplishing wonders in a short time 
			and then get bored and drop it before its properly finished. &nbsp;He'll 
			do nothing but strum his guitar and lie around in bed for several 
			days after. That's also part of the pattern too; periods of frenetic 
			activity followed by periods of melancholia, withdrawal and 
			inactivity. &nbsp; This is a bipolar personality.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Alright so far? &nbsp;OK, 
			well lets graduate this guy and see him go to university. &nbsp;What 
			happens to him then?</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Here we have two 
			stories; a light story and a dark one.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">The light story is that 
			he's really turned on by what he chooses and he goes on to graduate&nbsp;<em>summa 
			cum laude</em>, vindicating his natural brilliance.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But that's not the story 
			I want to look at. &nbsp;I want to look at the dark story. &nbsp;The one where 
			brilliance and failure get mixed together.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">This is where this 
			student begins by recognising that university, like school, is also 
			fairly phony in many ways. What saves university is generally the 
			beauty of the subject as built by great minds. &nbsp;But if you just look 
			at the professors and don't see past their narrow obsession with 
			their pointless and largely unread (and unreadable) publications to 
			the great invisible university of the mind, you will probably 
			conclude its as phony as anything else. &nbsp;Which it is.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But lets stick to this 
			guy's story.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now the big difference 
			between school and university for the fresher is FREEDOM. &nbsp;Freedom 
			from mom and dad, freedom to do your own thing. &nbsp; Freedom in fact to 
			screw up in a major way. &nbsp; So our hero begins a new life and finds 
			he can do all he wants. &nbsp;Get drunk, stumble in at 3.00 AM. So he 
			goes to town and he relies on his natural brilliance to carry him 
			through because, hey, it worked at school. &nbsp;And it does work for a 
			time.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But brilliance is not 
			enough. &nbsp;You need application too, because the material is harder at 
			university. &nbsp; So pretty soon our man is getting B+, then Bs and then 
			Cs for his assignments. &nbsp; He experiences alternating feelings of 
			failure cutting through his usual self assurance. &nbsp;He can still stay 
			up to 5.00AM and hand in his assignment before the 9.00AM deadline, 
			but what he hands in is not so great. &nbsp;Or perhaps he doesn't get 
			into beer, but into some mental digression from his official studies 
			that takes him too far away from the main syllabus.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">This sort of student 
			used to pass my way every now and then, riding on the bottom of the 
			class. &nbsp; One of them had&nbsp;<strong>Bored&gt;</strong>&nbsp;as his UNIX prompt. 
			If I spotted one I used to connect well with them. &nbsp;(In fact I 
			rescued one and now he's a professor and miserable because he's 
			surrounded by phonies - but hey, what can you do?). &nbsp; Generally he 
			would come alive in the final year project when he could do his own 
			thing and hand in something really really good. &nbsp; Something that 
			would show (shock, horror) originality. &nbsp;And a lot of professors 
			wouldn't give it a fair mark for that very reason - and because the 
			student was known to be scraping along the bottom.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Often this kind of 
			student never makes it to the end. &nbsp;He flunks himself by dropping 
			out. &nbsp; He ends on a soda fountain or doing yard work, but all the 
			time reading and studying because a good mind is always hungry.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now one of the things 
			about Lisp, and I've seen it before, is that Lisp is a real magnet 
			for this kind of mind. &nbsp; Once you understand that, and see that it 
			is this kind of mind that has contributed a lot to the culture of 
			Lisp, you begin to see why Lisp is, like many of its proponents, a 
			brilliant failure. &nbsp;It shares the peculiar strengths and weaknesses 
			of the brilliant bipolar mind (BBM).</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Why is this? &nbsp;Well, its 
			partly to do with vision. &nbsp; The 'vision thing' as George Bush Snr. 
			once described it, is really one of the strengths of the BBM. &nbsp;He 
			can see far; further than in fact his strength allows him to travel. 
			&nbsp;He conceives of brilliant ambitious projects requiring great 
			resources, and he embarks on them only to run out of steam. &nbsp;It's 
			not that he's lazy; its just that his resources are insufficient.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And this is where Lisp 
			comes in. &nbsp;Because Lisp, as a tool, is to the mind as the lever is 
			to the arm. &nbsp;It amplifies your power and enables you to embark on 
			projects beyond the scope of lesser languages like C. &nbsp; Writing in C 
			is like building a mosaic out of lentils using a tweezer and glue. &nbsp; 
			Lisp is like wielding an air gun with power and precision. &nbsp; It 
			opens out whole kingdoms shut to other programmers.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">So BBMs love Lisp. &nbsp;And 
			the stunning originality of Lisp is reflective of the creativity of 
			the BBM; so we have a long list of ideas that originated with 
			Lispers - garbage collection, list handling, personal computing, 
			windowing and areas in which Lisp people were amongst the earliest 
			pioneers. &nbsp;So we would think, off the cuff, that Lisp should be well 
			established, the premiere programming language because hey - its 
			great and we were the first guys to do this stuff.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But it isn't and the 
			reasons why not are not in the language, but in the community 
			itself, which contains not just the strengths but also the 
			weaknesses of the BBM.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">One of these is the 
			inability to finish things off properly. &nbsp;The phrase 'throw-away 
			design' is absolutely made for the BBM and it comes from the Lisp 
			community. &nbsp; Lisp allows you to just chuck things off so easily, and 
			it is easy to take this for granted. &nbsp;I saw this 10 years ago when 
			looking for a GUI to my Lisp (Garnet had just gone West then). &nbsp;No 
			problem, there were 9 different offerings. &nbsp;The trouble was that 
			none of the 9 were properly documented and none were bug free. 
			Basically each person had implemented his own solution and it worked 
			for him so that was fine. &nbsp; This is a BBM attitude; it works for me 
			and I understand it. &nbsp; It is also the product of not needing or 
			wanting anybody else's help to do something.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now in contrast, the 
			C/C++ approach is quite different. &nbsp;It's so damn hard to do anything 
			with tweezers and glue that anything significant you do will be a 
			real achievement. &nbsp;You want to document it. &nbsp;Also you're liable to 
			need help in any C project of significant size; so you're liable to 
			be social and work with others. &nbsp; You need to, just to get 
			somewhere.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And all that, from the 
			point of view of an employer, is attractive. Ten people who 
			communicate, document things properly and work together are 
			preferable to one BBM hacking Lisp who can only be replaced by 
			another BBM (if you can find one) in the not unlikely event that he 
			will, at some time, go down without being rebootable.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now the other aspect of 
			the BBM that I remarked on is his sensitivity to artifice. &nbsp;To put 
			it in plain American, he knows bullshit when he smells it. &nbsp; Most of 
			us do. &nbsp;However the BBM has much lower tolerance of it than others. 
			&nbsp;He can often see the absurdity of the way things are, and has the 
			intelligence to see how they should be. &nbsp;And he is, unlike the rank 
			and file, unprepared to compromise. &nbsp;And this leads to many things.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">The Lisp machines were a 
			product of this kind of vision. It was, as Gabriel once said, the 
			Right Thing. &nbsp;Except of course it wasn't. &nbsp;Here the refusal to 
			compromise with the market, and to use the platforms that the C 
			bashers were using proved in the long run to be a fatal mistake.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And this brings me to 
			the last feature of the BBM. &nbsp;The flip side of all that energy and 
			intelligence - the sadness, melancholia and loss of self during a 
			down phase. &nbsp; &nbsp;If you read many posts discussing Lisp (including one 
			in comp.lang.lisp called&nbsp;<strong>Common Lisp Sucks</strong>) you see 
			it writ large. &nbsp; Veteran programmers of many years with obvious 
			ability and talent go down with a fit of the blues. &nbsp;The 
			intelligence is directed inwards in mournful contemplation of the 
			inadequacies of their favourite programming language. &nbsp; The problems 
			are soluble (Qi is a proof of that for God's sake), but when you're 
			down everything seems insoluble. &nbsp;Lisp is doomed and we're all going 
			to hell.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Actually one paper that 
			exemplifies that more than any other is the classic&nbsp;<strong>Lisp: 
			Good News, Bad News, How to Win Big</strong>. If you read that 
			paper, you feel and see nature of the BBM. &nbsp;Its unique because 
			Gabriel actually displays both aspects at the same time. &nbsp; The 
			positive side, the intellectual pride and belief in Lisp is there. 
			&nbsp;But also in there is the depressive 'but its all going to go to 
			hell' aspect is there too. &nbsp;This is contained in the message that 
			Worse is Better.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">So what's the message in 
			all of this? Basically, that there are two problems. The problem 
			with the Lisp mindset and the problem with Lisp. The problem of the 
			Lisp mindset is the problem of the mindset characteristic of the BBM.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And the problem with 
			Lisp? &nbsp;The answer is tailor made for the minds who program it. It is 
			the koan of Lisp.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">The answer is that there 
			is no problem with Lisp, because Lisp is, like life, what you make 
			of it.&nbsp;</span></p></div>
		</td>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Browsers barely care what HTTP status code your web pages are served with (131 pts)]]></title>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/BrowsersAndHTTPStatusCodes</link>
            <guid>37085449</guid>
            <pubDate>Fri, 11 Aug 2023 05:37:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://utcc.utoronto.ca/~cks/space/blog/web/BrowsersAndHTTPStatusCodes">https://utcc.utoronto.ca/~cks/space/blog/web/BrowsersAndHTTPStatusCodes</a>, See on <a href="https://news.ycombinator.com/item?id=37085449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Browsers barely care what HTTP status code your web pages are served with</h2>

	<p><small>August 10, 2023</small></p>
</div><div><p>Back when I wrote an entry on <a href="https://utcc.utoronto.ca/~cks/space/blog/web/WebServerDefaultNotThere">issues around the HTTP status code
for a web server's default front page</a>,
I said in passing that <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">the HTTP status code</a> mostly
doesn't matter to browsers. More exactly, the status code for a web
page mostly doesn't matter to people looking at web pages in a
browser (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/PragmaticHTTPErrorCodes">this has come up before</a>). This
is well known in some circles and probably surprising in others.</p>

<p>Certain HTTP status codes cause web browsers to do specific things;
there are the HTTP 3xx redirections, <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401">HTTP 401 Unauthorized</a>, and
some others. However, in general if you respond to a request for a
web page with a HTTP 200, 4xx, or 5xx code outside of these specific
ones and some HTML, almost all browsers will display the HTML to
the user and not expose the actual HTTP status code to them in any
obvious way. If the HTML says 'HTTP 500 internal failure', they'll
assume one thing; if the HTML says 'welcome to the default server
page', they'll assume another thing.</p>

<p>(I'm not sure there's any way to find the HTTP status code in a
modern Firefox environment short of using web developer tools.
It's not in places like 'Page Info' as far as I can see.)</p>

<p>This is not so true in other browser contexts. If a web page is
trying to fetch CSS, JavaScript, or images as sub-resources, I
believe that browsers will react very differently to <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200">a HTTP 200</a>
response than to the exact same content with the exact same
Content-Type but with a HTTP 4xx or 5xx status code; only the
successful HTTP 200 response will work. Similarly if there's
JavaScript running to fetch HTML chunks and stuff them into the
page, it's likely to care (and not work) if you return the same
HTML with a HTTP 404 instead of a HTTP 200.</p>

<p>It's a convention (and a useful one) that the HTML served for a web
server's error pages will include the HTTP status code in the text
(and often the &lt;title&gt; as well). But it's only a convention and it
can be violated, both accidentally and deliberately (both in omitting
the status code and listing the wrong one). If it is violated, you
probably won't notice for a while (if ever).</p>

<p>PS: It turns out that <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">our Django based web application</a> doesn't actually list
the HTTP status codes on its various custom error pages, although
it does have appropriate text that says you've hit a nonexistent
page or an internal error. I probably should at least add a footer
saying '(This is a HTTP status 404 error)' (with the correct code
for the specific error page).</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>