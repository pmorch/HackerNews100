<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 11 Dec 2023 08:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Low Latency, Low Loss, and Scalable Throughput (L4S) Internet Service: RFC 9330 (120 pts)]]></title>
            <link>https://datatracker.ietf.org/doc/rfc9330/</link>
            <guid>38597744</guid>
            <pubDate>Mon, 11 Dec 2023 04:50:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://datatracker.ietf.org/doc/rfc9330/">https://datatracker.ietf.org/doc/rfc9330/</a>, See on <a href="https://news.ycombinator.com/item?id=38597744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <pre>ï»¿

Internet Engineering Task Force (IETF)                   B. Briscoe, Ed.
Request for Comments: 9330                                   Independent
Category: Informational                                   K. De Schepper
ISSN: 2070-1721                                          Nokia Bell Labs
                                                              M. Bagnulo
                                        Universidad Carlos III de Madrid
                                                                G. White
                                                               CableLabs
                                                            January 2023

 Low Latency, Low Loss, and Scalable Throughput (L4S) Internet Service:
                              Architecture

<span>Abstract</span>

   This document describes the L4S architecture, which enables Internet
   applications to achieve low queuing latency, low congestion loss, and
   scalable throughput control.  L4S is based on the insight that the
   root cause of queuing delay is in the capacity-seeking congestion
   controllers of senders, not in the queue itself.  With the L4S
   architecture, all Internet applications could (but do not have to)
   transition away from congestion control algorithms that cause
   substantial queuing delay and instead adopt a new class of congestion
   controls that can seek capacity with very little queuing.  These are
   aided by a modified form of Explicit Congestion Notification (ECN)
   from the network.  With this new architecture, applications can have
   both low latency and high throughput.

   The architecture primarily concerns incremental deployment.  It
   defines mechanisms that allow the new class of L4S congestion
   controls to coexist with 'Classic' congestion controls in a shared
   network.  The aim is for L4S latency and throughput to be usually
   much better (and rarely worse) while typically not impacting Classic
   performance.

<span>Status of This Memo</span>

   This document is not an Internet Standards Track specification; it is
   published for informational purposes.

   This document is a product of the Internet Engineering Task Force
   (IETF).  It represents the consensus of the IETF community.  It has
   received public review and has been approved for publication by the
   Internet Engineering Steering Group (IESG).  Not all documents
   approved by the IESG are candidates for any level of Internet
   Standard; see Section 2 of RFC 7841.

   Information about the current status of this document, any errata,
   and how to provide feedback on it may be obtained at
   https://www.rfc-editor.org/info/rfc9330.

<span>Copyright Notice</span>

   Copyright (c) 2023 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to BCP 78 and the IETF Trust's Legal
   Provisions Relating to IETF Documents
   (https://trustee.ietf.org/license-info) in effect on the date of
   publication of this document.  Please review these documents
   carefully, as they describe your rights and restrictions with respect
   to this document.  Code Components extracted from this document must
   include Revised BSD License text as described in Section 4.e of the
   Trust Legal Provisions and are provided without warranty as described
   in the Revised BSD License.

<span>Table of Contents</span>

   1.  Introduction
     1.1.  Document Roadmap
   2.  L4S Architecture Overview
   3.  Terminology
   4.  L4S Architecture Components
     4.1.  Protocol Mechanisms
     4.2.  Network Components
     4.3.  Host Mechanisms
   5.  Rationale
     5.1.  Why These Primary Components?
     5.2.  What L4S Adds to Existing Approaches
   6.  Applicability
     6.1.  Applications
     6.2.  Use Cases
     6.3.  Applicability with Specific Link Technologies
     6.4.  Deployment Considerations
       6.4.1.  Deployment Topology
       6.4.2.  Deployment Sequences
       6.4.3.  L4S Flow but Non-ECN Bottleneck
       6.4.4.  L4S Flow but Classic ECN Bottleneck
       6.4.5.  L4S AQM Deployment within Tunnels
   7.  IANA Considerations
   8.  Security Considerations
     8.1.  Traffic Rate (Non-)Policing
       8.1.1.  (Non-)Policing Rate per Flow
       8.1.2.  (Non-)Policing L4S Service Rate
     8.2.  'Latency Friendliness'
     8.3.  Interaction between Rate Policing and L4S
     8.4.  ECN Integrity
     8.5.  Privacy Considerations
   9.  Informative References
   Acknowledgements
   Authors' Addresses

1.  Introduction

   At any one time, it is increasingly common for all of the traffic in
   a bottleneck link (e.g., a household's Internet access or Wi-Fi) to
   come from applications that prefer low delay: interactive web, web
   services, voice, conversational video, interactive video, interactive
   remote presence, instant messaging, online and cloud-rendered gaming,
   remote desktop, cloud-based applications, cloud-rendered virtual
   reality or augmented reality, and video-assisted remote control of
   machinery and industrial processes.  In the last decade or so, much
   has been done to reduce propagation delay by placing caches or
   servers closer to users.  However, queuing remains a major, albeit
   intermittent, component of latency.  For instance, spikes of hundreds
   of milliseconds are not uncommon, even with state-of-the-art Active
   Queue Management (AQM) [COBALT] [DOCSIS3AQM].  A Classic AQM in an
   access network bottleneck is typically configured to buffer the
   sawteeth of lone flows, which can cause peak overall network delay to
   roughly double during a long-running flow, relative to expected base
   (unloaded) path delay [BufferSize].  Low loss is also important
   because, for interactive applications, losses translate into even
   longer retransmission delays.

   It has been demonstrated that, once access network bit rates reach
   levels now common in the developed world, increasing link capacity
   offers diminishing returns if latency (delay) is not addressed
   [Dukkipati06] [Rajiullah15].  Therefore, the goal is an Internet
   service with very low queuing latency, very low loss, and scalable
   throughput.  Very low queuing latency means less than 1 millisecond
   (ms) on average and less than about 2 ms at the 99th percentile.
   End-to-end delay above 50 ms [Raaen14], or even above 20 ms [NASA04],
   starts to feel unnatural for more demanding interactive applications.
   Therefore, removing unnecessary delay variability increases the reach
   of these applications (the distance over which they are comfortable
   to use) and/or provides additional latency budget that can be used
   for enhanced processing.  This document describes the L4S
   architecture for achieving these goals.

   Differentiated services (Diffserv) offers Expedited Forwarding (EF)
   [RFC3246] for some packets at the expense of others, but this makes
   no difference when all (or most) of the traffic at a bottleneck at
   any one time requires low latency.  In contrast, L4S still works well
   when all traffic is L4S -- a service that gives without taking needs
   none of the configuration or management baggage (traffic policing or
   traffic contracts) associated with favouring some traffic flows over
   others.

   Queuing delay degrades performance intermittently [Hohlfeld14].  It
   occurs i) when a large enough capacity-seeking (e.g., TCP) flow is
   running alongside the user's traffic in the bottleneck link, which is
   typically in the access network, or ii) when the low latency
   application is itself a large capacity-seeking or adaptive rate flow
   (e.g., interactive video).  At these times, the performance
   improvement from L4S must be sufficient for network operators to be
   motivated to deploy it.

   Active Queue Management (AQM) is part of the solution to queuing
   under load.  AQM improves performance for all traffic, but there is a
   limit to how much queuing delay can be reduced by solely changing the
   network without addressing the root of the problem.

   The root of the problem is the presence of standard congestion
   control (Reno [RFC5681]) or compatible variants (e.g., CUBIC
   [RFC8312]) that are used in TCP and in other transports, such as QUIC
   [RFC9000].  We shall use the term 'Classic' for these Reno-friendly
   congestion controls.  Classic congestion controls induce relatively
   large sawtooth-shaped excursions of queue occupancy.  So if a network
   operator naively attempts to reduce queuing delay by configuring an
   AQM to operate at a shallower queue, a Classic congestion control
   will significantly underutilize the link at the bottom of every
   sawtooth.  These sawteeth have also been growing in duration as flow
   rate scales (see Section 5.1 and [RFC3649]).

   It has been demonstrated that, if the sending host replaces a Classic
   congestion control with a 'Scalable' alternative, the performance
   under load of all the above interactive applications can be
   significantly improved once a suitable AQM is deployed in the
   network.  Taking the example solution cited below that uses Data
   Center TCP (DCTCP) [RFC8257] and a Dual-Queue Coupled AQM [RFC9332]
   on a DSL or Ethernet link, queuing delay under heavy load is roughly
   1-2 ms at the 99th percentile without losing link utilization
   [L4Seval22] [DualPI2Linux] (for other link types, see Section 6.3).
   This compares with 5-20 ms on _average_ with a Classic congestion
   control and current state-of-the-art AQMs, such as Flow Queue CoDel
   [RFC8290], Proportional Integral controller Enhanced (PIE) [RFC8033],
   or DOCSIS PIE [RFC8034] and about 20-30 ms at the 99th percentile
   [DualPI2Linux].

   L4S is designed for incremental deployment.  It is possible to deploy
   the L4S service at a bottleneck link alongside the existing best
   efforts service [DualPI2Linux] so that unmodified applications can
   start using it as soon as the sender's stack is updated.  Access
   networks are typically designed with one link as the bottleneck for
   each site (which might be a home, small enterprise, or mobile
   device), so deployment at either or both ends of this link should
   give nearly all the benefit in the respective direction.  With some
   transport protocols, namely TCP [ACCECN], the sender has to check
   that the receiver has been suitably updated to give more accurate
   feedback, whereas with more recent transport protocols, such as QUIC
   [RFC9000] and Datagram Congestion Control Protocol (DCCP) [RFC4340],
   all receivers have always been suitable.

   This document presents the L4S architecture.  It consists of three
   components: network support to isolate L4S traffic from Classic
   traffic; protocol features that allow network elements to identify
   L4S traffic; and host support for L4S congestion controls.  The
   protocol is defined separately in [RFC9331] as an experimental change
   to Explicit Congestion Notification (ECN).  This document describes
   and justifies the component parts and how they interact to provide
   the low latency, low loss, and scalable Internet service.  It also
   details the approach to incremental deployment, as briefly summarized
   above.

1.1.  Document Roadmap

   This document describes the L4S architecture in three passes.  First,
   the brief overview in Section 2 gives the very high-level idea and
   states the main components with minimal rationale.  This is only
   intended to give some context for the terminology definitions that
   follow in Section 3 and to explain the structure of the rest of the
   document.  Then, Section 4 goes into more detail on each component
   with some rationale but still mostly stating what the architecture
   is, rather than why.  Finally, Section 5 justifies why each element
   of the solution was chosen (Section 5.1) and why these choices were
   different from other solutions (Section 5.2).

   After the architecture has been described, Section 6 clarifies its
   applicability by describing the applications and use cases that
   motivated the design, the challenges applying the architecture to
   various link technologies, and various incremental deployment models
   (including the two main deployment topologies, different sequences
   for incremental deployment, and various interactions with preexisting
   approaches).  The document ends with the usual tailpieces, including
   extensive discussion of traffic policing and other security
   considerations in Section 8.

2.  L4S Architecture Overview

   Below, we outline the three main components to the L4S architecture:
   1) the Scalable congestion control on the sending host; 2) the AQM at
   the network bottleneck; and 3) the protocol between them.

   But first, the main point to grasp is that low latency is not
   provided by the network; low latency results from the careful
   behaviour of the Scalable congestion controllers used by L4S senders.
   The network does have a role, primarily to isolate the low latency of
   the carefully behaving L4S traffic from the higher queuing delay
   needed by traffic with preexisting Classic behaviour.  The network
   also alters the way it signals queue growth to the transport.  It
   uses the Explicit Congestion Notification (ECN) protocol, but it
   signals the very start of queue growth immediately, without the
   smoothing delay typical of Classic AQMs.  Because ECN support is
   essential for L4S, senders use the ECN field as the protocol that
   allows the network to identify which packets are L4S and which are
   Classic.

   1)  Host:

       Scalable congestion controls already exist.  They solve the
       scaling problem with Classic congestion controls, such as Reno or
       CUBIC.  Because flow rate has scaled since TCP congestion control
       was first designed in 1988, assuming the flow lasts long enough,
       it now takes hundreds of round trips (and growing) to recover
       after a congestion signal (whether a loss or an ECN mark), as
       shown in the examples in Section 5.1 and [RFC3649].  Therefore,
       control of queuing and utilization becomes very slack, and the
       slightest disturbances (e.g., from new flows starting) prevent a
       high rate from being attained.

       With a Scalable congestion control, the average time from one
       congestion signal to the next (the recovery time) remains
       invariant as flow rate scales, all other factors being equal.
       This maintains the same degree of control over queuing and
       utilization, whatever the flow rate, as well as ensuring that
       high throughput is more robust to disturbances.  The Scalable
       control used most widely (in controlled environments) is DCTCP
       [RFC8257], which has been implemented and deployed in Windows
       Server Editions (since 2012), in Linux, and in FreeBSD.  Although
       DCTCP as-is functions well over wide-area round-trip times
       (RTTs), most implementations lack certain safety features that
       would be necessary for use outside controlled environments, like
       data centres (see Section 6.4.3).  Therefore, Scalable congestion
       control needs to be implemented in TCP and other transport
       protocols (QUIC, Stream Control Transmission Protocol (SCTP),
       RTP/RTCP, RTP Media Congestion Avoidance Techniques (RMCAT),
       etc.).  Indeed, between the present document being drafted and
       published, the following Scalable congestion controls were
       implemented: Prague over TCP and QUIC [PRAGUE-CC] [PragueLinux],
       an L4S variant of the RMCAT SCReAM controller [SCReAM-L4S], and
       the L4S ECN part of Bottleneck Bandwidth and Round-trip
       propagation time (BBRv2) [BBRv2] intended for TCP and QUIC
       transports.

   2)  Network:

       L4S traffic needs to be isolated from the queuing latency of
       Classic traffic.  One queue per application flow (FQ) is one way
       to achieve this, e.g., FQ-CoDel [RFC8290].  However, using just
       two queues is sufficient and does not require inspection of
       transport layer headers in the network, which is not always
       possible (see Section 5.2).  With just two queues, it might seem
       impossible to know how much capacity to schedule for each queue
       without inspecting how many flows at any one time are using each.
       And it would be undesirable to arbitrarily divide access network
       capacity into two partitions.  The Dual-Queue Coupled AQM was
       developed as a minimal complexity solution to this problem.  It
       acts like a 'semi-permeable' membrane that partitions latency but
       not bandwidth.  As such, the two queues are for transitioning
       from Classic to L4S behaviour, not bandwidth prioritization.

       Section 4 gives a high-level explanation of how the per-flow
       queue (FQ) and DualQ variants of L4S work, and [RFC9332] gives a
       full explanation of the DualQ Coupled AQM framework.  A specific
       marking algorithm is not mandated for L4S AQMs.  Appendices of
       [RFC9332] give non-normative examples that have been implemented
       and evaluated and give recommended default parameter settings.
       It is expected that L4S experiments will improve knowledge of
       parameter settings and whether the set of marking algorithms
       needs to be limited.

   3)  Protocol:

       A sending host needs to distinguish L4S and Classic packets with
       an identifier so that the network can classify them into their
       separate treatments.  The L4S identifier spec [RFC9331] concludes
       that all alternatives involve compromises, but the ECT(1) and
       Congestion Experienced (CE) codepoints of the ECN field represent
       a workable solution.  As already explained, the network also uses
       ECN to immediately signal the very start of queue growth to the
       transport.

3.  Terminology

   Classic Congestion Control:  A congestion control behaviour that can
      coexist with standard Reno [RFC5681] without causing significantly
      negative impact on its flow rate [RFC5033].  The scaling problem
      with Classic congestion control is explained, with examples, in
      Section 5.1 and in [RFC3649].

   Scalable Congestion Control:  A congestion control where the average
      time from one congestion signal to the next (the recovery time)
      remains invariant as flow rate scales, all other factors being
      equal.  For instance, DCTCP averages 2 congestion signals per
      round trip, whatever the flow rate, as do other recently developed
      Scalable congestion controls, e.g., Relentless TCP [RELENTLESS],
      Prague for TCP and QUIC [PRAGUE-CC] [PragueLinux], BBRv2 [BBRv2]
      [BBR-CC], and the L4S variant of SCReAM for real-time media
      [SCReAM-L4S] [RFC8298].  See Section 4.3 of [RFC9331] for more
      explanation.

   Classic Service:  The Classic service is intended for all the
      congestion control behaviours that coexist with Reno [RFC5681]
      (e.g., Reno itself, CUBIC [RFC8312], Compound [CTCP], and TFRC
      [RFC5348]).  The term 'Classic queue' means a queue providing the
      Classic service.

   Low Latency, Low Loss, and Scalable throughput (L4S) service:  The
      'L4S' service is intended for traffic from Scalable congestion
      control algorithms, such as the Prague congestion control
      [PRAGUE-CC], which was derived from DCTCP [RFC8257].  The L4S
      service is for more general traffic than just Prague -- it allows
      the set of congestion controls with similar scaling properties to
      Prague to evolve, such as the examples listed above (Relentless,
      SCReAM, etc.).  The term 'L4S queue' means a queue providing the
      L4S service.

      The terms Classic or L4S can also qualify other nouns, such as
      'queue', 'codepoint', 'identifier', 'classification', 'packet',
      and 'flow'.  For example, an L4S packet means a packet with an L4S
      identifier sent from an L4S congestion control.

      Both Classic and L4S services can cope with a proportion of
      unresponsive or less-responsive traffic as well but, in the L4S
      case, its rate has to be smooth enough or low enough to not build
      a queue (e.g., DNS, Voice over IP (VoIP), game sync datagrams,
      etc.).

   Reno-friendly:  The subset of Classic traffic that is friendly to the
      standard Reno congestion control defined for TCP in [RFC5681].
      The TFRC spec [RFC5348] indirectly implies that 'friendly' is
      defined as "generally within a factor of two of the sending rate
      of a TCP flow under the same conditions".  Reno-friendly is used
      here in place of 'TCP-friendly', given the latter has become
      imprecise, because the TCP protocol is now used with so many
      different congestion control behaviours, and Reno is used in non-
      TCP transports, such as QUIC [RFC9000].

   Classic ECN:  The original Explicit Congestion Notification (ECN)
      protocol [RFC3168] that requires ECN signals to be treated as
      equivalent to drops, both when generated in the network and when
      responded to by the sender.

      For L4S, the names used for the four codepoints of the 2-bit IP-
      ECN field are unchanged from those defined in the ECN spec
      [RFC3168], i.e., Not-ECT, ECT(0), ECT(1), and CE, where ECT stands
      for ECN-Capable Transport and CE stands for Congestion
      Experienced.  A packet marked with the CE codepoint is termed
      'ECN-marked' or sometimes just 'marked' where the context makes
      ECN obvious.

   Site:  A home, mobile device, small enterprise, or campus where the
      network bottleneck is typically the access link to the site.  Not
      all network arrangements fit this model, but it is a useful,
      widely applicable generalization.

   Traffic Policing:  Limiting traffic by dropping packets or shifting
      them to a lower service class (as opposed to introducing delay,
      which is termed 'traffic shaping').  Policing can involve limiting
      the average rate and/or burst size.  Policing focused on limiting
      queuing but not the average flow rate is termed 'congestion
      policing', 'latency policing', 'burst policing', or 'queue
      protection' in this document.  Otherwise, the term rate policing
      is used.

4.  L4S Architecture Components

   The L4S architecture is composed of the elements in the following
   three subsections.

4.1.  Protocol Mechanisms

   The L4S architecture involves: a) unassignment of the previous use of
   the identifier; b) reassignment of the same identifier; and c)
   optional further identifiers:

   a.  An essential aspect of a Scalable congestion control is the use
       of explicit congestion signals.  Classic ECN [RFC3168] requires
       an ECN signal to be treated as equivalent to drop, both when it
       is generated in the network and when it is responded to by hosts.
       L4S needs networks and hosts to support a more fine-grained
       meaning for each ECN signal that is less severe than a drop, so
       that the L4S signals:

       *  can be much more frequent and

       *  can be signalled immediately, without the significant delay
          required to smooth out fluctuations in the queue.

       To enable L4S, the Standards Track Classic ECN spec [RFC3168] has
       had to be updated to allow L4S packets to depart from the
       'equivalent-to-drop' constraint.  [RFC8311] is a Standards Track
       update to relax specific requirements in [RFC3168] (and certain
       other Standards Track RFCs), which clears the way for the
       experimental changes proposed for L4S.  Also, the ECT(1)
       codepoint was previously assigned as the experimental ECN nonce
       [RFC3540], which [RFC8311] recategorizes as historic to make the
       codepoint available again.

   b.  [RFC9331] specifies that ECT(1) is used as the identifier to
       classify L4S packets into a separate treatment from Classic
       packets.  This satisfies the requirement for identifying an
       alternative ECN treatment in [RFC4774].

       The CE codepoint is used to indicate Congestion Experienced by
       both L4S and Classic treatments.  This raises the concern that a
       Classic AQM earlier on the path might have marked some ECT(0)
       packets as CE.  Then, these packets will be erroneously
       classified into the L4S queue.  Appendix B of [RFC9331] explains
       why five unlikely eventualities all have to coincide for this to
       have any detrimental effect, which even then would only involve a
       vanishingly small likelihood of a spurious retransmission.

   c.  A network operator might wish to include certain unresponsive,
       non-L4S traffic in the L4S queue if it is deemed to be paced
       smoothly enough and at a low enough rate not to build a queue,
       for instance, VoIP, low rate datagrams to sync online games,
       relatively low rate application-limited traffic, DNS, Lightweight
       Directory Access Protocol (LDAP), etc.  This traffic would need
       to be tagged with specific identifiers, e.g., a low-latency
       Diffserv codepoint such as Expedited Forwarding (EF) [RFC3246],
       Non-Queue-Building (NQB) [NQB-PHB], or operator-specific
       identifiers.

4.2.  Network Components

   The L4S architecture aims to provide low latency without the _need_
   for per-flow operations in network components.  Nonetheless, the
   architecture does not preclude per-flow solutions.  The following
   bullets describe the known arrangements: a) the DualQ Coupled AQM
   with an L4S AQM in one queue coupled from a Classic AQM in the other;
   b) per-flow queues with an instance of a Classic and an L4S AQM in
   each queue; and c) Dual queues with per-flow AQMs but no per-flow
   queues:

   a.  The Dual-Queue Coupled AQM (illustrated in Figure 1) achieves the
       'semi-permeable' membrane property mentioned earlier as follows:

       *  Latency isolation: Two separate queues are used to isolate L4S
          queuing delay from the larger queue that Classic traffic needs
          to maintain full utilization.

       *  Bandwidth pooling: The two queues act as if they are a single
          pool of bandwidth in which flows of either type get roughly
          equal throughput without the scheduler needing to identify any
          flows.  This is achieved by having an AQM in each queue, but
          the Classic AQM provides a congestion signal to both queues in
          a manner that ensures a consistent response from the two
          classes of congestion control.  Specifically, the Classic AQM
          generates a drop/mark probability based on congestion in its
          own queue, which it uses both to drop/mark packets in its own
          queue and to affect the marking probability in the L4S queue.
          The strength of the coupling of the congestion signalling
          between the two queues is enough to make the L4S flows slow
          down to leave the right amount of capacity for the Classic
          flows (as they would if they were the same type of traffic
          sharing the same queue).

       Then, the scheduler can serve the L4S queue with priority
       (denoted by the '1' on the higher priority input), because the
       L4S traffic isn't offering up enough traffic to use all the
       priority that it is given.  Therefore:

       *  for latency isolation on short timescales (sub-round-trip),
          the prioritization of the L4S queue protects its low latency
          by allowing bursts to dissipate quickly;

       *  but for bandwidth pooling on longer timescales (round-trip and
          longer), the Classic queue creates an equal and opposite
          pressure against the L4S traffic to ensure that neither has
          priority when it comes to bandwidth -- the tension between
          prioritizing L4S and coupling the marking from the Classic AQM
          results in approximate per-flow fairness.

       To protect against the prioritization of persistent L4S traffic
       deadlocking the Classic queue for a while in some
       implementations, it is advisable for the priority to be
       conditional, not strict (see Appendix A of the DualQ spec
       [RFC9332]).

       When there is no Classic traffic, the L4S queue's own AQM comes
       into play.  It starts congestion marking with a very shallow
       queue, so L4S traffic maintains very low queuing delay.

       If either queue becomes persistently overloaded, drop of some
       ECN-capable packets is introduced, as recommended in Section 7 of
       the ECN spec [RFC3168] and Section 4.2.1 of the AQM
       recommendations [RFC7567].  The trade-offs with different
       approaches are discussed in Section 4.2.3 of the DualQ spec
       [RFC9332] (not shown in the figure here).

       The Dual-Queue Coupled AQM has been specified as generically as
       possible [RFC9332] without specifying the particular AQMs to use
       in the two queues so that designers are free to implement diverse
       ideas.  Informational appendices in that document give pseudocode
       examples of two different specific AQM approaches: one called
       DualPI2 (pronounced Dual PI Squared) [DualPI2Linux] that uses the
       PI2 variant of PIE and a zero-config variant of Random Early
       Detection (RED) called Curvy RED.  A DualQ Coupled AQM based on
       PIE has also been specified and implemented for Low Latency
       DOCSIS [DOCSIS3.1].

                     (3)                  (2)
                     .-------^------..------------^------------------.
        ,-(1)-----.                               _____
       ; ________  :            L4S  -------.    |     |
       :|Scalable| :               _\      ||__\_|mark |
       :| sender | :  __________  / /      ||  / |_____|\   _________
       :|________|\; |          |/   -------'       ^    \1|condit'nl|
        `---------'\_|  IP-ECN  |          Coupling :     \|priority |_\
         ________  / |Classifier|                   :     /|scheduler| /
        |Classic |/  |__________|\   -------.     __:__  / |_________|
        | sender |                \_\ || | ||__\_|mark/|/
        |________|                  / || | ||  / |drop |
                             Classic -------'    |_____|

       (1) Scalable sending host
       (2) Isolation in separate network queues
       (3) Packet identification protocol

           Figure 1: Components of an L4S DualQ Coupled AQM Solution

   b.  Per-Flow Queues and AQMs: A scheduler with per-flow queues, such
       as FQ-CoDel or FQ-PIE, can be used for L4S.  For instance, within
       each queue of an FQ-CoDel system, as well as a CoDel AQM, there
       is typically also the option of ECN marking at an immediate
       (unsmoothed) shallow threshold to support use in data centres
       (see Section 5.2.7 of the FQ-CoDel spec [RFC8290]).  In Linux,
       this has been modified so that the shallow threshold can be
       solely applied to ECT(1) packets [FQ_CoDel_Thresh].  Then, if
       there is a flow of Not-ECT or ECT(0) packets in the per-flow
       queue, the Classic AQM (e.g., CoDel) is applied; whereas, if
       there is a flow of ECT(1) packets in the queue, the shallower
       (typically sub-millisecond) threshold is applied.  In addition,
       ECT(0) and Not-ECT packets could potentially be classified into a
       separate flow queue from ECT(1) and CE packets to avoid them
       mixing if they share a common flow identifier (e.g., in a VPN).

   c.  Dual queues but per-flow AQMs: It should also be possible to use
       dual queues for isolation but with per-flow marking to control
       flow rates (instead of the coupled per-queue marking of the Dual-
       Queue Coupled AQM).  One of the two queues would be for isolating
       L4S packets, which would be classified by the ECN codepoint.
       Flow rates could be controlled by flow-specific marking.  The
       policy goal of the marking could be to differentiate flow rates
       (e.g., [Nadas20], which requires additional signalling of a per-
       flow 'value') or to equalize flow rates (perhaps in a similar way
       to Approx Fair CoDel [AFCD] [CODEL-APPROX-FAIR] but with two
       queues not one).

       Note that, whenever the term 'DualQ' is used loosely without
       saying whether marking is per queue or per flow, it means a dual-
       queue AQM with per-queue marking.

4.3.  Host Mechanisms

   The L4S architecture includes two main mechanisms in the end host
   that we enumerate next:

   a.  Scalable congestion control at the sender: Section 2 defines a
       Scalable congestion control as one where the average time from
       one congestion signal to the next (the recovery time) remains
       invariant as flow rate scales, all other factors being equal.
       DCTCP is the most widely used example.  It has been documented as
       an informational record of the protocol currently in use in
       controlled environments [RFC8257].  A list of safety and
       performance improvements for a Scalable congestion control to be
       usable on the public Internet has been drawn up (see the so-
       called 'Prague L4S requirements' in Appendix A of [RFC9331]).
       The subset that involve risk of harm to others have been captured
       as normative requirements in Section 4 of [RFC9331].  TCP Prague
       [PRAGUE-CC] has been implemented in Linux as a reference
       implementation to address these requirements [PragueLinux].

       Transport protocols other than TCP use various congestion
       controls that are designed to be friendly with Reno.  Before they
       can use the L4S service, they will need to be updated to
       implement a Scalable congestion response, which they will have to
       indicate by using the ECT(1) codepoint.  Scalable variants are
       under consideration for more recent transport protocols (e.g.,
       QUIC), and the L4S ECN part of BBRv2 [BBRv2] [BBR-CC] is a
       Scalable congestion control intended for the TCP and QUIC
       transports, amongst others.  Also, an L4S variant of the RMCAT
       SCReAM controller [RFC8298] has been implemented [SCReAM-L4S] for
       media transported over RTP.

       Section 4.3 of the L4S ECN spec [RFC9331] defines Scalable
       congestion control in more detail and specifies the requirements
       that an L4S Scalable congestion control has to comply with.

   b.  The ECN feedback in some transport protocols is already
       sufficiently fine-grained for L4S (specifically DCCP [RFC4340]
       and QUIC [RFC9000]).  But others either require updates or are in
       the process of being updated:

       *  For the case of TCP, the feedback protocol for ECN embeds the
          assumption from Classic ECN [RFC3168] that an ECN mark is
          equivalent to a drop, making it unusable for a Scalable TCP.
          Therefore, the implementation of TCP receivers will have to be
          upgraded [RFC7560].  Work to standardize and implement more
          accurate ECN feedback for TCP (AccECN) is in progress [ACCECN]
          [PragueLinux].

       *  ECN feedback was only roughly sketched in the appendix of the
          now obsoleted second specification of SCTP [RFC4960], while a
          fuller specification was proposed in a long-expired document
          [ECN-SCTP].  A new design would need to be implemented and
          deployed before SCTP could support L4S.

       *  For RTP, sufficient ECN feedback was defined in [RFC6679], but
          [RFC8888] defines the latest Standards Track improvements.

5.  Rationale

5.1.  Why These Primary Components?

   Explicit congestion signalling (protocol):  Explicit congestion
      signalling is a key part of the L4S approach.  In contrast, use of
      drop as a congestion signal creates tension because drop is both
      an impairment (less would be better) and a useful signal (more
      would be better):

      *  Explicit congestion signals can be used many times per round
         trip to keep tight control without any impairment.  Under heavy
         load, even more explicit signals can be applied so that the
         queue can be kept short whatever the load.  In contrast,
         Classic AQMs have to introduce very high packet drop at high
         load to keep the queue short.  By using ECN, an L4S congestion
         control's sawtooth reduction can be smaller and therefore
         return to the operating point more often, without worrying that
         more sawteeth will cause more signals.  The consequent smaller
         amplitude sawteeth fit between an empty queue and a very
         shallow marking threshold (~1 ms in the public Internet), so
         queue delay variation can be very low, without risk of
         underutilization.

      *  Explicit congestion signals can be emitted immediately to track
         fluctuations of the queue.  L4S shifts smoothing from the
         network to the host.  The network doesn't know the round-trip
         times (RTTs) of any of the flows.  So if the network is
         responsible for smoothing (as in the Classic approach), it has
         to assume a worst case RTT, otherwise long RTT flows would
         become unstable.  This delays Classic congestion signals by
         100-200 ms.  In contrast, each host knows its own RTT.  So, in
         the L4S approach, the host can smooth each flow over its own
         RTT, introducing no more smoothing delay than strictly
         necessary (usually only a few milliseconds).  A host can also
         choose not to introduce any smoothing delay if appropriate,
         e.g., during flow start-up.

      Neither of the above are feasible if explicit congestion
      signalling has to be considered 'equivalent to drop' (as was
      required with Classic ECN [RFC3168]), because drop is an
      impairment as well as a signal.  So drop cannot be excessively
      frequent, and drop cannot be immediate; otherwise, too many drops
      would turn out to have been due to only a transient fluctuation in
      the queue that would not have warranted dropping a packet in
      hindsight.  Therefore, in an L4S AQM, the L4S queue uses a new L4S
      variant of ECN that is not equivalent to drop (see Section 5.2 of
      the L4S ECN spec [RFC9331]), while the Classic queue uses either
      Classic ECN [RFC3168] or drop, which are still equivalent to each
      other.

      Before Classic ECN was standardized, there were various proposals
      to give an ECN mark a different meaning from drop.  However, there
      was no particular reason to agree on any one of the alternative
      meanings, so 'equivalent to drop' was the only compromise that
      could be reached.  [RFC3168] contains a statement that:

         An environment where all end nodes were ECN-Capable could
          allow new criteria to be developed for setting the CE
          codepoint, and new congestion control mechanisms for end-node
          reaction to CE packets.  However, this is a research issue,
          and as such is not addressed in this document.

   Latency isolation (network):  L4S congestion controls keep queue
      delay low, whereas Classic congestion controls need a queue of the
      order of the RTT to avoid underutilization.  One queue cannot have
      two lengths; therefore, L4S traffic needs to be isolated in a
      separate queue (e.g., DualQ) or queues (e.g., FQ).

   Coupled congestion notification:  Coupling the congestion
      notification between two queues as in the DualQ Coupled AQM is not
      necessarily essential, but it is a simple way to allow senders to
      determine their rate packet by packet, rather than be overridden
      by a network scheduler.  An alternative is for a network scheduler
      to control the rate of each application flow (see the discussion
      in Section 5.2).

   L4S packet identifier (protocol):  Once there are at least two
      treatments in the network, hosts need an identifier at the IP
      layer to distinguish which treatment they intend to use.

   Scalable congestion notification:  A Scalable congestion control in
      the host keeps the signalling frequency from the network high,
      whatever the flow rate, so that queue delay variations can be
      small when conditions are stable, and rate can track variations in
      available capacity as rapidly as possible otherwise.

   Low loss:  Latency is not the only concern of L4S.  The 'Low Loss'
      part of the name denotes that L4S generally achieves zero
      congestion loss due to its use of ECN.  Otherwise, loss would
      itself cause delay, particularly for short flows, due to
      retransmission delay [RFC2884].

   Scalable throughput:  The 'Scalable throughput' part of the name
      denotes that the per-flow throughput of Scalable congestion
      controls should scale indefinitely, avoiding the imminent scaling
      problems with Reno-friendly congestion control algorithms
      [RFC3649].  It was known when TCP congestion avoidance was first
      developed in 1988 that it would not scale to high bandwidth-delay
      products (see footnote 6 in [TCP-CA]).  Today, regular broadband
      flow rates over WAN distances are already beyond the scaling range
      of Classic Reno congestion control.  So 'less unscalable' CUBIC
      [RFC8312] and Compound [CTCP] variants of TCP have been
      successfully deployed.  However, these are now approaching their
      scaling limits.

      For instance, we will consider a scenario with a maximum RTT of 30
      ms at the peak of each sawtooth.  As Reno packet rate scales 8
      times from 1,250 to 10,000 packet/s (from 15 to 120 Mb/s with 1500
      B packets), the time to recover from a congestion event rises
      proportionately by 8 times as well, from 422 ms to 3.38 s.  It is
      clearly problematic for a congestion control to take multiple
      seconds to recover from each congestion event.  CUBIC [RFC8312]
      was developed to be less unscalable, but it is approaching its
      scaling limit; with the same max RTT of 30 ms, at 120 Mb/s, CUBIC
      is still fully in its Reno-friendly mode, so it takes about 4.3 s
      to recover.  However, once flow rate scales by 8 times again to
      960 Mb/s it enters true CUBIC mode, with a recovery time of 12.2
      s.  From then on, each further scaling by 8 times doubles CUBIC's
      recovery time (because the cube root of 8 is 2), e.g., at 7.68 Gb/
      s, the recovery time is 24.3 s.  In contrast, a Scalable
      congestion control like DCTCP or Prague induces 2 congestion
      signals per round trip on average, which remains invariant for any
      flow rate, keeping dynamic control very tight.

      For a feel of where the global average lone-flow download sits on
      this scale at the time of writing (2021), according to [BDPdata],
      the global average fixed access capacity was 103 Mb/s in 2020 and
      the average base RTT to a CDN was 25 to 34 ms in 2019.  Averaging
      of per-country data was weighted by Internet user population (data
      collected globally is necessarily of variable quality, but the
      paper does double-check that the outcome compares well against a
      second source).  So a lone CUBIC flow would at best take about 200
      round trips (5 s) to recover from each of its sawtooth reductions,
      if the flow even lasted that long.  This is described as 'at best'
      because it assumes everyone uses an AQM, whereas in reality, most
      users still have a (probably bloated) tail-drop buffer.  In the
      tail-drop case, the likely average recovery time would be at least
      4 times 5 s, if not more, because RTT under load would be at least
      double that of an AQM, and the recovery time of Reno-friendly
      flows depends on the square of RTT.

      Although work on scaling congestion controls tends to start with
      TCP as the transport, the above is not intended to exclude other
      transports (e.g., SCTP and QUIC) or less elastic algorithms (e.g.,
      RMCAT), which all tend to adopt the same or similar developments.

5.2.  What L4S Adds to Existing Approaches

   All the following approaches address some part of the same problem
   space as L4S.  In each case, it is shown that L4S complements them or
   improves on them, rather than being a mutually exclusive alternative:

   Diffserv:  Diffserv addresses the problem of bandwidth apportionment
      for important traffic as well as queuing latency for delay-
      sensitive traffic.  Of these, L4S solely addresses the problem of
      queuing latency.  Diffserv will still be necessary where important
      traffic requires priority (e.g., for commercial reasons or for
      protection of critical infrastructure traffic) -- see
      [L4S-DIFFSERV].  Nonetheless, the L4S approach can provide low
      latency for all traffic within each Diffserv class (including the
      case where there is only the one default Diffserv class).

      Also, Diffserv can only provide a latency benefit if a small
      subset of the traffic on a bottleneck link requests low latency.
      As already explained, it has no effect when all the applications
      in use at one time at a single site (e.g., a home, small business,
      or mobile device) require low latency.  In contrast, because L4S
      works for all traffic, it needs none of the management baggage
      (traffic policing or traffic contracts) associated with favouring
      some packets over others.  This lack of management baggage ought
      to give L4S a better chance of end-to-end deployment.

      In particular, if networks do not trust end systems to identify
      which packets should be favoured, they assign packets to Diffserv
      classes themselves.  However, the techniques available to such
      networks, like inspection of flow identifiers or deeper inspection
      of application signatures, do not always sit well with encryption
      of the layers above IP [RFC8404].  In these cases, users can have
      either privacy or Quality of Service (QoS), but not both.

      As with Diffserv, the L4S identifier is in the IP header.  But, in
      contrast to Diffserv, the L4S identifier does not convey a want or
      a need for a certain level of quality.  Rather, it promises a
      certain behaviour (Scalable congestion response), which networks
      can objectively verify if they need to.  This is because low delay
      depends on collective host behaviour, whereas bandwidth priority
      depends on network behaviour.

   State-of-the-art AQMs:  AQMs for Classic traffic, such as PIE and FQ-
      CoDel, give a significant reduction in queuing delay relative to
      no AQM at all.  L4S is intended to complement these AQMs and
      should not distract from the need to deploy them as widely as
      possible.  Nonetheless, AQMs alone cannot reduce queuing delay too
      far without significantly reducing link utilization, because the
      root cause of the problem is on the host -- where Classic
      congestion controls use large sawtoothing rate variations.  The
      L4S approach resolves this tension between delay and utilization
      by enabling hosts to minimize the amplitude of their sawteeth.  A
      single-queue Classic AQM is not sufficient to allow hosts to use
      small sawteeth for two reasons: i) smaller sawteeth would not get
      lower delay in an AQM designed for larger amplitude Classic
      sawteeth, because a queue can only have one length at a time and
      ii) much smaller sawteeth implies much more frequent sawteeth, so
      L4S flows would drive a Classic AQM into a high level of ECN-
      marking, which would appear as heavy congestion to Classic flows,
      which in turn would greatly reduce their rate as a result (see
      Section 6.4.4).

   Per-flow queuing or marking:  Similarly, per-flow approaches, such as
      FQ-CoDel or Approx Fair CoDel [AFCD], are not incompatible with
      the L4S approach.  However, per-flow queuing alone is not enough
      -- it only isolates the queuing of one flow from others, not from
      itself.  Per-flow implementations need to have support for
      Scalable congestion control added, which has already been done for
      FQ-CoDel in Linux (see Section 5.2.7 of [RFC8290] and
      [FQ_CoDel_Thresh]).  Without this simple modification, per-flow
      AQMs, like FQ-CoDel, would still not be able to support
      applications that need both very low delay and high bandwidth,
      e.g., video-based control of remote procedures or interactive
      cloud-based video (see Note 1 below).

      Although per-flow techniques are not incompatible with L4S, it is
      important to have the DualQ alternative.  This is because handling
      end-to-end (layer 4) flows in the network (layer 3 or 2) precludes
      some important end-to-end functions.  For instance:

      a.  Per-flow forms of L4S, like FQ-CoDel, are incompatible with
          full end-to-end encryption of transport layer identifiers for
          privacy and confidentiality (e.g., IPsec or encrypted VPN
          tunnels, as opposed to DTLS over UDP), because they require
          packet inspection to access the end-to-end transport flow
          identifiers.

          In contrast, the DualQ form of L4S requires no deeper
          inspection than the IP layer.  So as long as operators take
          the DualQ approach, their users can have both very low queuing
          delay and full end-to-end encryption [RFC8404].

      b.  With per-flow forms of L4S, the network takes over control of
          the relative rates of each application flow.  Some see it as
          an advantage that the network will prevent some flows running
          faster than others.  Others consider it an inherent part of
          the Internet's appeal that applications can control their rate
          while taking account of the needs of others via congestion
          signals.  They maintain that this has allowed applications
          with interesting rate behaviours to evolve, for instance: i) a
          variable bit-rate video that varies around an equal share,
          rather than being forced to remain equal at every instant or
          ii) end-to-end scavenger behaviours [RFC6817] that use less
          than an equal share of capacity [LEDBAT_AQM].

          The L4S architecture does not require the IETF to commit to
          one approach over the other, because it supports both so that
          the 'market' can decide.  Nonetheless, in the spirit of 'Do
          one thing and do it well' [McIlroy78], the DualQ option
          provides low delay without prejudging the issue of flow-rate
          control.  Then, flow rate policing can be added separately if
          desired.  In contrast to scheduling, a policer would allow
          application control up to a point, but the network would still
          be able to set the point at which it intervened to prevent one
          flow completely starving another.

      Note:

      1.  It might seem that self-inflicted queuing delay within a per-
          flow queue should not be counted, because if the delay wasn't
          in the network, it would just shift to the sender.  However,
          modern adaptive applications, e.g., HTTP/2 [RFC9113] or some
          interactive media applications (see Section 6.1), can keep low
          latency objects at the front of their local send queue by
          shuffling priorities of other objects dependent on the
          progress of other transfers (for example, see [lowat]).  They
          cannot shuffle objects once they have released them into the
          network.

   Alternative Back-off ECN (ABE):  Here again, L4S is not an
      alternative to ABE but a complement that introduces much lower
      queuing delay.  ABE [RFC8511] alters the host behaviour in
      response to ECN marking to utilize a link better and give ECN
      flows faster throughput.  It uses ECT(0) and assumes the network
      still treats ECN and drop the same.  Therefore, ABE exploits any
      lower queuing delay that AQMs can provide.  But, as explained
      above, AQMs still cannot reduce queuing delay too much without
      losing link utilization (to allow for other, non-ABE, flows).

   BBR:  Bottleneck Bandwidth and Round-trip propagation time (BBR)
      [BBR-CC] controls queuing delay end-to-end without needing any
      special logic in the network, such as an AQM.  So it works pretty
      much on any path.  BBR keeps queuing delay reasonably low, but
      perhaps not quite as low as with state-of-the-art AQMs, such as
      PIE or FQ-CoDel, and certainly nowhere near as low as with L4S.
      Queuing delay is also not consistently low, due to BBR's regular
      bandwidth probing spikes and its aggressive flow start-up phase.

      L4S complements BBR.  Indeed, BBRv2 can use L4S ECN where
      available and a Scalable L4S congestion control behaviour in
      response to any ECN signalling from the path [BBRv2].  The L4S ECN
      signal complements the delay-based congestion control aspects of
      BBR with an explicit indication that hosts can use, both to
      converge on a fair rate and to keep below a shallow queue target
      set by the network.  Without L4S ECN, both these aspects need to
      be assumed or estimated.

6.  Applicability

6.1.  Applications

   A transport layer that solves the current latency issues will provide
   new service, product, and application opportunities.

   With the L4S approach, the following existing applications also
   experience significantly better quality of experience under load:

   *  gaming, including cloud-based gaming;

   *  VoIP;

   *  video conferencing;

   *  web browsing;

   *  (adaptive) video streaming; and

   *  instant messaging.

   The significantly lower queuing latency also enables some interactive
   application functions to be offloaded to the cloud that would hardly
   even be usable today, including:

   *  cloud-based interactive video and

   *  cloud-based virtual and augmented reality.

   The above two applications have been successfully demonstrated with
   L4S, both running together over a 40 Mb/s broadband access link
   loaded up with the numerous other latency-sensitive applications in
   the previous list, as well as numerous downloads, with all sharing
   the same bottleneck queue simultaneously [L4Sdemo16]
   [L4Sdemo16-Video].  For the former, a panoramic video of a football
   stadium could be swiped and pinched so that, on the fly, a proxy in
   the cloud could generate a sub-window of the match video under the
   finger-gesture control of each user.  For the latter, a virtual
   reality headset displayed a viewport taken from a 360-degree camera
   in a racing car.  The user's head movements controlled the viewport
   extracted by a cloud-based proxy.  In both cases, with a 7 ms end-to-
   end base delay, the additional queuing delay of roughly 1 ms was so
   low that it seemed the video was generated locally.

   Using a swiping finger gesture or head movement to pan a video are
   extremely latency-demanding actions -- far more demanding than VoIP
   -- because human vision can detect extremely low delays of the order
   of single milliseconds when delay is translated into a visual lag
   between a video and a reference point (the finger or the orientation
   of the head sensed by the balance system in the inner ear, i.e., the
   vestibular system).  With an alternative AQM, the video noticeably
   lagged behind the finger gestures and head movements.

   Without the low queuing delay of L4S, cloud-based applications like
   these would not be credible without significantly more access-network
   bandwidth (to deliver all possible areas of the video that might be
   viewed) and more local processing, which would increase the weight
   and power consumption of head-mounted displays.  When all interactive
   processing can be done in the cloud, only the data to be rendered for
   the end user needs to be sent.

   Other low latency high bandwidth applications, such as:

   *  interactive remote presence and

   *  video-assisted remote control of machinery or industrial processes

   are not credible at all without very low queuing delay.  No amount of
   extra access bandwidth or local processing can make up for lost time.

6.2.  Use Cases

   The following use cases for L4S are being considered by various
   interested parties:

   *  where the bottleneck is one of various types of access network,
      e.g., DSL, Passive Optical Networks (PONs), DOCSIS cable, mobile,
      satellite; or where it's a Wi-Fi link (see Section 6.3 for some
      technology-specific details)

   *  private networks of heterogeneous data centres, where there is no
      single administrator that can arrange for all the simultaneous
      changes to senders, receivers, and networks needed to deploy
      DCTCP:

      -  a set of private data centres interconnected over a wide area
         with separate administrations but within the same company

      -  a set of data centres operated by separate companies
         interconnected by a community of interest network (e.g., for
         the finance sector)

      -  multi-tenant (cloud) data centres where tenants choose their
         operating system stack (Infrastructure as a Service (IaaS))

   *  different types of transport (or application) congestion control:

      -  elastic (TCP/SCTP);

      -  real-time (RTP, RMCAT); and

      -  query-response (DNS/LDAP).

   *  where low delay QoS is required but without inspecting or
      intervening above the IP layer [RFC8404]:

      -  Mobile and other networks have tended to inspect higher layers
         in order to guess application QoS requirements.  However, with
         growing demand for support of privacy and encryption, L4S
         offers an alternative.  There is no need to select which
         traffic to favour for queuing when L4S can give favourable
         queuing to all traffic.

   *  If queuing delay is minimized, applications with a fixed delay
      budget can communicate over longer distances or via more
      circuitous paths, e.g., longer chains of service functions
      [RFC7665] or of onion routers.

   *  If delay jitter is minimized, it is possible to reduce the
      dejitter buffers on the receiving end of video streaming, which
      should improve the interactive experience.

6.3.  Applicability with Specific Link Technologies

   Certain link technologies aggregate data from multiple packets into
   bursts and buffer incoming packets while building each burst.  Wi-Fi,
   PON, and cable all involve such packet aggregation, whereas fixed
   Ethernet and DSL do not.  No sender, whether L4S or not, can do
   anything to reduce the buffering needed for packet aggregation.  So
   an AQM should not count this buffering as part of the queue that it
   controls, given no amount of congestion signals will reduce it.

   Certain link technologies also add buffering for other reasons,
   specifically:

   *  Radio links (cellular, Wi-Fi, or satellite) that are distant from
      the source are particularly challenging.  The radio link capacity
      can vary rapidly by orders of magnitude, so it is considered
      desirable to hold a standing queue that can utilize sudden
      increases of capacity.

   *  Cellular networks are further complicated by a perceived need to
      buffer in order to make hand-overs imperceptible.

   L4S cannot remove the need for all these different forms of
   buffering.  However, by removing 'the longest pole in the tent'
   (buffering for the large sawteeth of Classic congestion controls),
   L4S exposes all these 'shorter poles' to greater scrutiny.

   Until now, the buffering needed for these additional reasons tended
   to be over-specified -- with the excuse that none were 'the longest
   pole in the tent'.  But having removed the 'longest pole', it becomes
   worthwhile to minimize them, for instance, reducing packet
   aggregation burst sizes and MAC scheduling intervals.

   Also, certain link types, particularly radio-based links, are far
   more prone to transmission losses.  Section 6.4.3 explains how an L4S
   response to loss has to be as drastic as a Classic response.
   Nonetheless, research referred to in the same section has
   demonstrated potential for considerably more effective loss repair at
   the link layer, due to the relaxed ordering constraints of L4S
   packets.

6.4.  Deployment Considerations

   L4S AQMs, whether DualQ [RFC9332] or FQ [RFC8290], are in themselves
   an incremental deployment mechanism for L4S -- so that L4S traffic
   can coexist with existing Classic (Reno-friendly) traffic.
   Section 6.4.1 explains why only deploying an L4S AQM in one node at
   each end of the access link will realize nearly all the benefit of
   L4S.

   L4S involves both the network and end systems, so Section 6.4.2
   suggests some typical sequences to deploy each part and why there
   will be an immediate and significant benefit after deploying just one
   part.

   Sections 6.4.3 and 6.4.4 describe the converse incremental deployment
   case where there is no L4S AQM at the network bottleneck, so any L4S
   flow traversing this bottleneck has to take care in case it is
   competing with Classic traffic.

6.4.1.  Deployment Topology

   L4S AQMs will not have to be deployed throughout the Internet before
   L4S can benefit anyone.  Operators of public Internet access networks
   typically design their networks so that the bottleneck will nearly
   always occur at one known (logical) link.  This confines the cost of
   queue management technology to one place.

   The case of mesh networks is different and will be discussed later in
   this section.  However, the known-bottleneck case is generally true
   for Internet access to all sorts of different 'sites', where the word
   'site' includes home networks, small- to medium-sized campus or
   enterprise networks and even cellular devices (Figure 2).  Also, this
   known-bottleneck case tends to be applicable whatever the access link
   technology, whether xDSL, cable, PON, cellular, line of sight
   wireless, or satellite.

   Therefore, the full benefit of the L4S service should be available in
   the downstream direction when an L4S AQM is deployed at the ingress
   to this bottleneck link.  And similarly, the full upstream service
   will typically be available once an L4S AQM is deployed at the
   ingress into the upstream link.  (Of course, multihomed sites would
   only see the full benefit once all their access links were covered.)

                                            ______
                                           (      )
                         __          __  (          )
                        |DQ\________/DQ|( enterprise )
                    ___ |__/        \__| ( /campus  )
                   (   )                   (______)
                 (      )                           ___||_
   +----+      (          )  __                 __ /      \
   | DC |-----(    Core    )|DQ\_______________/DQ|| home |
   +----+      (          ) |__/               \__||______|
                  (_____) __
                         |DQ\__/\        __ ,===.
                         |__/    \  ____/DQ||| ||mobile
                                  \/    \__|||_||device
                                            | o |
                                            `---'

       Figure 2: Likely Location of DualQ (DQ) Deployments in Common
                             Access Topologies

   Deployment in mesh topologies depends on how overbooked the core is.
   If the core is non-blocking, or at least generously provisioned so
   that the edges are nearly always the bottlenecks, it would only be
   necessary to deploy an L4S AQM at the edge bottlenecks.  For example,
   some data-centre networks are designed with the bottleneck in the
   hypervisor or host Network Interface Controllers (NICs), while others
   bottleneck at the top-of-rack switch (both the output ports facing
   hosts and those facing the core).

   An L4S AQM would often next be needed where the Wi-Fi links in a home
   sometimes become the bottleneck.  Also an L4S AQM would eventually
   need to be deployed at any other persistent bottlenecks, such as
   network interconnections, e.g., some public Internet exchange points
   and the ingress and egress to WAN links interconnecting data centres.

6.4.2.  Deployment Sequences

   For any one L4S flow to provide benefit, it requires three (or
   sometimes two) parts to have been deployed: i) the congestion control
   at the sender; ii) the AQM at the bottleneck; and iii) older
   transports (namely TCP) need upgraded receiver feedback too.  This
   was the same deployment problem that ECN faced [RFC8170], so we have
   learned from that experience.

   Firstly, L4S deployment exploits the fact that DCTCP already exists
   on many Internet hosts (e.g., Windows, FreeBSD, and Linux), both
   servers and clients.  Therefore, an L4S AQM can be deployed at a
   network bottleneck to immediately give a working deployment of all
   the L4S parts for testing, as long as the ECT(0) codepoint is
   switched to ECT(1).  DCTCP needs some safety concerns to be fixed for
   general use over the public Internet (see Section 4.3 of the L4S ECN
   spec [RFC9331]), but DCTCP is not on by default, so these issues can
   be managed within controlled deployments or controlled trials.

   Secondly, the performance improvement with L4S is so significant that
   it enables new interactive services and products that were not
   previously possible.  It is much easier for companies to initiate new
   work on deployment if there is budget for a new product trial.  In
   contrast, if there were only an incremental performance improvement
   (as with Classic ECN), spending on deployment tends to be much harder
   to justify.

   Thirdly, the L4S identifier is defined so that network operators can
   initially enable L4S exclusively for certain customers or certain
   applications.  However, this is carefully defined so that it does not
   compromise future evolution towards L4S as an Internet-wide service.
   This is because the L4S identifier is defined not only as the end-to-
   end ECN field, but it can also optionally be combined with any other
   packet header or some status of a customer or their access link (see
   Section 5.4 of [RFC9331]).  Operators could do this anyway, even if
   it were not blessed by the IETF.  However, it is best for the IETF to
   specify that, if they use their own local identifier, it must be in
   combination with the IETF's identifier, ECT(1).  Then, if an operator
   has opted for an exclusive local-use approach, they only have to
   remove this extra rule later to make the service work across the
   Internet -- it will already traverse middleboxes, peerings, etc.

   +-+--------------------+----------------------+---------------------+
   | | Servers or proxies |      Access link     |             Clients |
   +-+--------------------+----------------------+---------------------+
   |0| DCTCP (existing)   |                      |    DCTCP (existing) |
   +-+--------------------+----------------------+---------------------+
   |1|                    |Add L4S AQM downstream|                     |
   | |       WORKS DOWNSTREAM FOR CONTROLLED DEPLOYMENTS/TRIALS        |
   +-+--------------------+----------------------+---------------------+
   |2| Upgrade DCTCP to   |                      |Replace DCTCP feedb'k|
   | | TCP Prague         |                      |         with AccECN |
   | |                 FULLY     WORKS     DOWNSTREAM                  |
   +-+--------------------+----------------------+---------------------+
   | |                    |                      |    Upgrade DCTCP to |
   |3|                    | Add L4S AQM upstream |          TCP Prague |
   | |                    |                      |                     |
   | |              FULLY WORKS UPSTREAM AND DOWNSTREAM                |
   +-+--------------------+----------------------+---------------------+

                 Figure 3: Example L4S Deployment Sequence

   Figure 3 illustrates some example sequences in which the parts of L4S
   might be deployed.  It consists of the following stages, preceded by
   a presumption that DCTCP is already installed at both ends:

   1.  DCTCP is not applicable for use over the public Internet, so it
       is emphasized here that any DCTCP flow has to be completely
       contained within a controlled trial environment.

       Within this trial environment, once an L4S AQM has been deployed,
       the trial DCTCP flow will experience immediate benefit, without
       any other deployment being needed.  In this example, downstream
       deployment is first, but in other scenarios, the upstream might
       be deployed first.  If no AQM at all was previously deployed for
       the downstream access, an L4S AQM greatly improves the Classic
       service (as well as adding the L4S service).  If an AQM was
       already deployed, the Classic service will be unchanged (and L4S
       will add an improvement on top).

   2.  In this stage, the name 'TCP Prague' [PRAGUE-CC] is used to
       represent a variant of DCTCP that is designed to be used in a
       production Internet environment (that is, it has to comply with
       all the requirements in Section 4 of the L4S ECN spec [RFC9331],
       which then means it can be used over the public Internet).  If
       the application is primarily unidirectional, 'TCP Prague' at the
       sending end will provide all the benefit needed, as long as the
       receiving end supports Accurate ECN (AccECN) feedback [ACCECN].

       For TCP transports, AccECN feedback is needed at the other end,
       but it is a generic ECN feedback facility that is already planned
       to be deployed for other purposes, e.g., DCTCP and BBR.  The two
       ends can be deployed in either order because, in TCP, an L4S
       congestion control only enables itself if it has negotiated the
       use of AccECN feedback with the other end during the connection
       handshake.  Thus, deployment of TCP Prague on a server enables
       L4S trials to move to a production service in one direction,
       wherever AccECN is deployed at the other end.  This stage might
       be further motivated by the performance improvements of TCP
       Prague relative to DCTCP (see Appendix A.2 of the L4S ECN spec
       [RFC9331]).

       Unlike TCP, from the outset, QUIC ECN feedback [RFC9000] has
       supported L4S.  Therefore, if the transport is QUIC, one-ended
       deployment of a Prague congestion control at this stage is simple
       and sufficient.

       For QUIC, if a proxy sits in the path between multiple origin
       servers and the access bottlenecks to multiple clients, then
       upgrading the proxy with a Scalable congestion control would
       provide the benefits of L4S over all the clients' downstream
       bottlenecks in one go -- whether or not all the origin servers
       were upgraded.  Conversely, where a proxy has not been upgraded,
       the clients served by it will not benefit from L4S at all in the
       downstream, even when any origin server behind the proxy has been
       upgraded to support L4S.

       For TCP, a proxy upgraded to support 'TCP Prague' would provide
       the benefits of L4S downstream to all clients that support AccECN
       (whether or not they support L4S as well).  And in the upstream,
       the proxy would also support AccECN as a receiver, so that any
       client deploying its own L4S support would benefit in the
       upstream direction, irrespective of whether any origin server
       beyond the proxy supported AccECN.

   3.  This is a two-move stage to enable L4S upstream.  An L4S AQM or
       TCP Prague can be deployed in either order as already explained.
       To motivate the first of two independent moves, the deferred
       benefit of enabling new services after the second move has to be
       worth it to cover the first mover's investment risk.  As
       explained already, the potential for new interactive services
       provides this motivation.  An L4S AQM also improves the upstream
       Classic service significantly if no other AQM has already been
       deployed.

   Note that other deployment sequences might occur.  For instance, the
   upstream might be deployed first; a non-TCP protocol might be used
   end to end, e.g., QUIC and RTP; a body, such as the 3GPP, might
   require L4S to be implemented in 5G user equipment; or other random
   acts of kindness might arise.

6.4.3.  L4S Flow but Non-ECN Bottleneck

   If L4S is enabled between two hosts, the L4S sender is required to
   coexist safely with Reno in response to any drop (see Section 4.3 of
   the L4S ECN spec [RFC9331]).

   Unfortunately, as well as protecting Classic traffic, this rule
   degrades the L4S service whenever there is any loss, even if the
   cause is not persistent congestion at a bottleneck, for example:

   *  congestion loss at other transient bottlenecks, e.g., due to
      bursts in shallower queues;

   *  transmission errors, e.g., due to electrical interference; and

   *  rate policing.

   Three complementary approaches are in progress to address this issue,
   but they are all currently research:

   *  In Prague congestion control, ignore certain losses deemed
      unlikely to be due to congestion (using some ideas from BBR
      [BBR-CC] regarding isolated losses).  This could mask any of the
      above types of loss while still coexisting with drop-based
      congestion controls.

   *  A combination of Recent Acknowledgement (RACK) [RFC8985], L4S, and
      link retransmission without resequencing could repair transmission
      errors without the head of line blocking delay usually associated
      with link-layer retransmission [UnorderedLTE] [RFC9331].

   *  Hybrid ECN/drop rate policers (see Section 8.3).

   L4S deployment scenarios that minimize these issues (e.g., over
   wireline networks) can proceed in parallel to this research, in the
   expectation that research success could continually widen L4S
   applicability.

6.4.4.  L4S Flow but Classic ECN Bottleneck

   Classic ECN support is starting to materialize on the Internet as an
   increased level of CE marking.  It is hard to detect whether this is
   all due to the addition of support for ECN in implementations of FQ-
   CoDel and/or FQ-COBALT, which is not generally problematic, because
   flow queue (FQ) scheduling inherently prevents a flow from exceeding
   the 'fair' rate irrespective of its aggressiveness.  However, some of
   this Classic ECN marking might be due to single-queue ECN deployment.
   This case is discussed in Section 4.3 of the L4S ECN spec [RFC9331].

6.4.5.  L4S AQM Deployment within Tunnels

   An L4S AQM uses the ECN field to signal congestion.  So in common
   with Classic ECN, if the AQM is within a tunnel or at a lower layer,
   correct functioning of ECN signalling requires standards-compliant
   propagation of the ECN field up the layers [RFC6040] [ECN-SHIM]
   [ECN-ENCAP].

7.  IANA Considerations

   This document has no IANA actions.

8.  Security Considerations

8.1.  Traffic Rate (Non-)Policing

8.1.1.  (Non-)Policing Rate per Flow

   In the current Internet, ISPs usually enforce separation between the
   capacity of shared links assigned to different 'sites' (e.g.,
   households, businesses, or mobile users -- see terminology in
   Section 3) using some form of scheduler [RFC0970].  And they use
   various techniques, like redirection to traffic scrubbing facilities,
   to deal with flooding attacks.  However, there has never been a
   universal need to police the rate of individual application flows --
   the Internet has generally always relied on self-restraint of
   congestion controls at senders for sharing intra-'site' capacity.

   L4S has been designed not to upset this status quo.  If a DualQ is
   used to provide L4S service, Section 4.2 of [RFC9332] explains how it
   is designed to give no more rate advantage to unresponsive flows than
   a single-queue AQM would, whether or not there is traffic overload.

   Also, in case per-flow rate policing is ever required, it can be
   added because it is orthogonal to the distinction between L4S and
   Classic.  As explained in Section 5.2, the DualQ variant of L4S
   provides low delay without prejudging the issue of flow-rate control.
   So if flow-rate control is needed, per-flow queuing (FQ) with L4S
   support can be used instead, or flow rate policing can be added as a
   modular addition to a DualQ.  However, per-flow rate control is not
   usually deployed as a security mechanism, because an active attacker
   can just shard its traffic over more flow identifiers if the rate of
   each is restricted.

8.1.2.  (Non-)Policing L4S Service Rate

   Section 5.2 explains how Diffserv only makes a difference if some
   packets get less favourable treatment than others, which typically
   requires traffic rate policing for a low latency class.  In contrast,
   it should not be necessary to rate-police access to the L4S service
   to protect the Classic service, because L4S is designed to reduce
   delay without harming the delay or rate of any Classic traffic.

   During early deployment (and perhaps always), some networks will not
   offer the L4S service.  In general, these networks should not need to
   police L4S traffic.  They are required (by both the ECN spec
   [RFC3168] and the L4S ECN spec [RFC9331]) not to change the L4S
   identifier, which would interfere with end-to-end congestion control.
   If they already treat ECN traffic as Not-ECT, they can merely treat
   L4S traffic as Not-ECT too.  At a bottleneck, such networks will
   introduce some queuing and dropping.  When a Scalable congestion
   control detects a drop, it will have to respond safely with respect
   to Classic congestion controls (as required in Section 4.3 of
   [RFC9331]).  This will degrade the L4S service to be no better (but
   never worse) than Classic best efforts whenever a non-ECN bottleneck
   is encountered on a path (see Section 6.4.3).

   In cases that are expected to be rare, networks that solely support
   Classic ECN [RFC3168] in a single queue bottleneck might opt to
   police L4S traffic so as to protect competing Classic ECN traffic
   (for instance, see Section 6.1.3 of the L4S operational guidance
   [L4SOPS]).  However, Section 4.3 of the L4S ECN spec [RFC9331]
   recommends that the sender adapts its congestion response to properly
   coexist with Classic ECN flows, i.e., reverting to the self-restraint
   approach.

   Certain network operators might choose to restrict access to the L4S
   service, perhaps only to selected premium customers as a value-added
   service.  Their packet classifier (item 2 in Figure 1) could identify
   such customers against some other field (e.g., source address range),
   as well as classifying on the ECN field.  If only the ECN L4S
   identifier matched, but not (say) the source address, the classifier
   could direct these packets (from non-premium customers) into the
   Classic queue.  Explaining clearly how operators can use additional
   local classifiers (see Section 5.4 of [RFC9331]) is intended to
   remove any motivation to clear the L4S identifier.  Then at least the
   L4S ECN identifier will be more likely to survive end to end, even
   though the service may not be supported at every hop.  Such local
   arrangements would only require simple registered/not-registered
   packet classification, rather than the managed, application-specific
   traffic policing against customer-specific traffic contracts that
   Diffserv uses.

8.2.  'Latency Friendliness'

   Like the Classic service, the L4S service relies on self-restraint to
   limit the rate in response to congestion.  In addition, the L4S
   service requires self-restraint in terms of limiting latency
   (burstiness).  It is hoped that self-interest and guidance on dynamic
   behaviour (especially flow start-up, which might need to be
   standardized) will be sufficient to prevent transports from sending
   excessive bursts of L4S traffic, given the application's own latency
   will suffer most from such behaviour.

   Because the L4S service can reduce delay without discernibly
   increasing the delay of any Classic traffic, it should not be
   necessary to police L4S traffic to protect the delay of Classic
   traffic.  However, whether burst policing becomes necessary to
   protect other L4S traffic remains to be seen.  Without it, there will
   be potential for attacks on the low latency of the L4S service.

   If needed, various arrangements could be used to address this
   concern:

   Local bottleneck queue protection:  A per-flow (5-tuple) queue
      protection function [DOCSIS-Q-PROT] has been developed for the low
      latency queue in DOCSIS, which has adopted the DualQ L4S
      architecture.  It protects the low latency service from any queue-
      building flows that accidentally or maliciously classify
      themselves into the low latency queue.  It is designed to score
      flows based solely on their contribution to queuing (not flow rate
      in itself).  Then, if the shared low latency queue is at risk of
      exceeding a threshold, the function redirects enough packets of
      the highest scoring flow(s) into the Classic queue to preserve low
      latency.

   Distributed traffic scrubbing:  Rather than policing locally at each
      bottleneck, it may only be necessary to address problems
      reactively, e.g., punitively target any deployments of new bursty
      malware, in a similar way to how traffic from flooding attack
      sources is rerouted via scrubbing facilities.

   Local bottleneck per-flow scheduling:  Per-flow scheduling should
      inherently isolate non-bursty flows from bursty flows (see
      Section 5.2 for discussion of the merits of per-flow scheduling
      relative to per-flow policing).

   Distributed access subnet queue protection:  Per-flow queue
      protection could be arranged for a queue structure distributed
      across a subnet intercommunicating using lower layer control
      messages (see Section 2.1.4 of [QDyn]).  For instance, in a radio
      access network, user equipment already sends regular buffer status
      reports to a radio network controller, which could use this
      information to remotely police individual flows.

   Distributed Congestion Exposure to ingress policers:  The Congestion
      Exposure (ConEx) architecture [RFC7713] uses an egress audit to
      motivate senders to truthfully signal path congestion in-band,
      where it can be used by ingress policers.  An edge-to-edge variant
      of this architecture is also possible.

   Distributed domain-edge traffic conditioning:  An architecture
      similar to Diffserv [RFC2475] may be preferred, where traffic is
      proactively conditioned on entry to a domain, rather than
      reactively policed only if it leads to queuing once combined with
      other traffic at a bottleneck.

   Distributed core network queue protection:  The policing function
      could be divided between per-flow mechanisms at the network
      ingress that characterize the burstiness of each flow into a
      signal carried with the traffic and per-class mechanisms at
      bottlenecks that act on these signals if queuing actually occurs
      once the traffic converges.  This would be somewhat similar to
      [Nadas20], which is in turn similar to the idea behind core
      stateless fair queuing.

   No single one of these possible queue protection capabilities is
   considered an essential part of the L4S architecture, which works
   without any of them under non-attack conditions (much as the Internet
   normally works without per-flow rate policing).  Indeed, even where
   latency policers are deployed, under normal circumstances, they would
   not intervene, and if operators found they were not necessary, they
   could disable them.  Part of the L4S experiment will be to see
   whether such a function is necessary and which arrangements are most
   appropriate to the size of the problem.

8.3.  Interaction between Rate Policing and L4S

   As mentioned in Section 5.2, L4S should remove the need for low
   latency Diffserv classes.  However, those Diffserv classes that give
   certain applications or users priority over capacity would still be
   applicable in certain scenarios (e.g., corporate networks).  Then,
   within such Diffserv classes, L4S would often be applicable to give
   traffic low latency and low loss as well.  Within such a Diffserv
   class, the bandwidth available to a user or application is often
   limited by a rate policer.  Similarly, in the default Diffserv class,
   rate policers are sometimes used to partition shared capacity.

   A Classic rate policer drops any packets exceeding a set rate,
   usually also giving a burst allowance (variants exist where the
   policer re-marks noncompliant traffic to a discard-eligible Diffserv
   codepoint, so they can be dropped elsewhere during contention).
   Whenever L4S traffic encounters one of these rate policers, it will
   experience drops and the source will have to fall back to a Classic
   congestion control, thus losing the benefits of L4S (Section 6.4.3).
   So in networks that already use rate policers and plan to deploy L4S,
   it will be preferable to redesign these rate policers to be more
   friendly to the L4S service.

   L4S-friendly rate policing is currently a research area (note that
   this is not the same as latency policing).  It might be achieved by
   setting a threshold where ECN marking is introduced, such that it is
   just under the policed rate or just under the burst allowance where
   drop is introduced.  For instance, the two-rate, three-colour marker
   [RFC2698] or a PCN threshold and excess-rate marker [RFC5670] could
   mark ECN at the lower rate and drop at the higher.  Or an existing
   rate policer could have congestion-rate policing added, e.g., using
   the 'local' (non-ConEx) variant of the ConEx aggregate congestion
   policer [CONG-POLICING].  It might also be possible to design
   Scalable congestion controls to respond less catastrophically to loss
   that has not been preceded by a period of increasing delay.

   The design of L4S-friendly rate policers will require a separate,
   dedicated document.  For further discussion of the interaction
   between L4S and Diffserv, see [L4S-DIFFSERV].

8.4.  ECN Integrity

   Various ways have been developed to protect the integrity of the
   congestion feedback loop (whether signalled by loss, Classic ECN, or
   L4S ECN) against misbehaviour by the receiver, sender, or network (or
   all three).  Brief details of each, including applicability, pros,
   and cons, are given in Appendix C.1 of the L4S ECN spec [RFC9331].

8.5.  Privacy Considerations

   As discussed in Section 5.2, the L4S architecture does not preclude
   approaches that inspect end-to-end transport layer identifiers.  For
   instance, L4S support has been added to FQ-CoDel, which classifies by
   application flow identifier in the network.  However, the main
   innovation of L4S is the DualQ AQM framework that does not need to
   inspect any deeper than the outermost IP header, because the L4S
   identifier is in the IP-ECN field.

   Thus, the L4S architecture enables very low queuing delay without
   _requiring_ inspection of information above the IP layer.  This means
   that users who want to encrypt application flow identifiers, e.g., in
   IPsec or other encrypted VPN tunnels, don't have to sacrifice low
   delay [RFC8404].

   Because L4S can provide low delay for a broad set of applications
   that choose to use it, there is no need for individual applications
   or classes within that broad set to be distinguishable in any way
   while traversing networks.  This removes much of the ability to
   correlate between the delay requirements of traffic and other
   identifying features [RFC6973].  There may be some types of traffic
   that prefer not to use L4S, but the coarse binary categorization of
   traffic reveals very little that could be exploited to compromise
   privacy.

9.  Informative References

   [ACCECN]   Briscoe, B., KÃ¼hlewind, M., and R. Scheffenegger, "More
              Accurate ECN Feedback in TCP", Work in Progress, Internet-
              Draft, draft-ietf-tcpm-accurate-ecn-22, 9 November 2022,
              &lt;https://datatracker.ietf.org/doc/html/draft-ietf-tcpm-
              accurate-ecn-22&gt;.

   [AFCD]     Xue, L., Kumar, S., Cui, C., Kondikoppa, P., Chiu, C-H.,
              and S-J. Park, "Towards fair and low latency next
              generation high speed networks: AFCD queuing", Journal of
              Network and Computer Applications, Volume 70, pp. 183-193,
              DOI 10.1016/j.jnca.2016.03.021, July 2016,
              &lt;https://doi.org/10.1016/j.jnca.2016.03.021&gt;.

   [BBR-CC]   Cardwell, N., Cheng, Y., Hassas Yeganeh, S., Swett, I.,
              and V. Jacobson, "BBR Congestion Control", Work in
              Progress, Internet-Draft, draft-cardwell-iccrg-bbr-
              congestion-control-02, 7 March 2022,
              &lt;https://datatracker.ietf.org/doc/html/draft-cardwell-
              iccrg-bbr-congestion-control-02&gt;.

   [BBRv2]    "TCP BBR v2 Alpha/Preview Release", commit 17700ca, June
              2022, &lt;https://github.com/google/bbr&gt;.

   [BDPdata]  Briscoe, B., "PI2 Parameters", TR-BB-2021-001,
              arXiv:2107.01003 [cs.NI], DOI 10.48550/arXiv.2107.01003,
              October 2021, &lt;https://arxiv.org/abs/2107.01003&gt;.

   [BufferSize]
              Appenzeller, G., Keslassy, I., and N. McKeown, "Sizing
              Router Buffers", SIGCOMM '04: Proceedings of the 2004
              conference on Applications, technologies, architectures,
              and protocols for computer communications, pp. 281-292,
              DOI 10.1145/1015467.1015499, October 2004,
              &lt;https://doi.org/10.1145/1015467.1015499&gt;.

   [COBALT]   Palmei, J., Gupta, S., Imputato, P., Morton, J.,
              Tahiliani, M. P., Avallone, S., and D. TÃ¤ht, "Design and
              Evaluation of COBALT Queue Discipline", IEEE International
              Symposium on Local and Metropolitan Area Networks
              (LANMAN), DOI 10.1109/LANMAN.2019.8847054, July 2019,
              &lt;https://ieeexplore.ieee.org/abstract/document/8847054&gt;.

   [CODEL-APPROX-FAIR]
              Morton, J. and P. Heist, "Controlled Delay Approximate
              Fairness AQM", Work in Progress, Internet-Draft, draft-
              morton-tsvwg-codel-approx-fair-01, 9 March 2020,
              &lt;https://datatracker.ietf.org/doc/html/draft-morton-tsvwg-
              codel-approx-fair-01&gt;.

   [CONG-POLICING]
              Briscoe, B., "Network Performance Isolation using
              Congestion Policing", Work in Progress, Internet-Draft,
              draft-briscoe-conex-policing-01, 14 February 2014,
              &lt;https://datatracker.ietf.org/doc/html/draft-briscoe-
              conex-policing-01&gt;.

   [CTCP]     Sridharan, M., Tan, K., Bansal, D., and D. Thaler,
              "Compound TCP: A New TCP Congestion Control for High-Speed
              and Long Distance Networks", Work in Progress, Internet-
              Draft, draft-sridharan-tcpm-ctcp-02, 11 November 2008,
              &lt;https://datatracker.ietf.org/doc/html/draft-sridharan-
              tcpm-ctcp-02&gt;.

   [DOCSIS-Q-PROT]
              Briscoe, B., Ed. and G. White, "The DOCSISÂ® Queue
              Protection Algorithm to Preserve Low Latency", Work in
              Progress, Internet-Draft, draft-briscoe-docsis-q-
              protection-06, 13 May 2022,
              &lt;https://datatracker.ietf.org/doc/html/draft-briscoe-
              docsis-q-protection-06&gt;.

   [DOCSIS3.1]
              CableLabs, "MAC and Upper Layer Protocols Interface
              (MULPI) Specification, CM-SP-MULPIv3.1", Data-Over-Cable
              Service Interface Specifications DOCSIS 3.1 Version i17 or
              later, 21 January 2019, &lt;https://specification-
              search.cablelabs.com/CM-SP-MULPIv3.1&gt;.

   [DOCSIS3AQM]
              White, G., "Active Queue Management Algorithms for DOCSIS
              3.0: A Simulation Study of CoDel, SFQ-CoDel and PIE in
              DOCSIS 3.0 Networks", CableLabs Technical Report, April
              2013, &lt;https://www.cablelabs.com/wp-
              content/uploads/2013/11/
              Active_Queue_Management_Algorithms_DOCSIS_3_0.pdf&gt;.

   [DualPI2Linux]
              Albisser, O., De Schepper, K., Briscoe, B., Tilmans, O.,
              and H. Steen, "DUALPI2 - Low Latency, Low Loss and
              Scalable (L4S) AQM", Proceedings of Linux Netdev 0x13,
              March 2019, &lt;https://www.netdevconf.org/0x13/
              session.html?talk-DUALPI2-AQM&gt;.

   [Dukkipati06]
              Dukkipati, N. and N. McKeown, "Why Flow-Completion Time is
              the Right Metric for Congestion Control", ACM SIGCOMM
              Computer Communication Review, Volume 36, Issue 1, pp.
              59-62, DOI 10.1145/1111322.1111336, January 2006,
              &lt;https://dl.acm.org/doi/10.1145/1111322.1111336&gt;.

   [ECN-ENCAP]
              Briscoe, B. and J. Kaippallimalil, "Guidelines for Adding
              Congestion Notification to Protocols that Encapsulate IP",
              Work in Progress, Internet-Draft, draft-ietf-tsvwg-ecn-
              encap-guidelines-17, 11 July 2022,
              &lt;https://datatracker.ietf.org/doc/html/draft-ietf-tsvwg-
              ecn-encap-guidelines-17&gt;.

   [ECN-SCTP] Stewart, R., Tuexen, M., and X. Dong, "ECN for Stream
              Control Transmission Protocol (SCTP)", Work in Progress,
              Internet-Draft, draft-stewart-tsvwg-sctpecn-05, 15 January
              2014, &lt;https://datatracker.ietf.org/doc/html/draft-
              stewart-tsvwg-sctpecn-05&gt;.

   [ECN-SHIM] Briscoe, B., "Propagating Explicit Congestion Notification
              Across IP Tunnel Headers Separated by a Shim", Work in
              Progress, Internet-Draft, draft-ietf-tsvwg-rfc6040update-
              shim-15, 11 July 2022,
              &lt;https://datatracker.ietf.org/doc/html/draft-ietf-tsvwg-
              rfc6040update-shim-15&gt;.

   [FQ_CoDel_Thresh]
              "fq_codel: generalise ce_threshold marking for subset of
              traffic", commit dfcb63ce1de6b10b, October 2021,
              &lt;https://git.kernel.org/pub/scm/linux/kernel/git/netdev/
              net-next.git/commit/?id=dfcb63ce1de6b10b&gt;.

   [Hohlfeld14]
              Hohlfeld, O., Pujol, E., Ciucu, F., Feldmann, A., and P.
              Barford, "A QoE Perspective on Sizing Network Buffers",
              IMC '14: Proceedings of the 2014 Conference on Internet
              Measurement, pp. 333-346, DOI 10.1145/2663716.2663730,
              November 2014,
              &lt;https://doi.acm.org/10.1145/2663716.2663730&gt;.

   [L4S-DIFFSERV]
              Briscoe, B., "Interactions between Low Latency, Low Loss,
              Scalable Throughput (L4S) and Differentiated Services",
              Work in Progress, Internet-Draft, draft-briscoe-tsvwg-l4s-
              diffserv-02, 4 November 2018,
              &lt;https://datatracker.ietf.org/doc/html/draft-briscoe-
              tsvwg-l4s-diffserv-02&gt;.

   [L4Sdemo16]
              Bondarenko, O., De Schepper, K., Tsang, I., Briscoe, B.,
              Petlund, A., and C. Griwodz, "Ultra-Low Delay for All:
              Live Experience, Live Analysis", Proceedings of the 7th
              International Conference on Multimedia Systems, Article
              No. 33, pp. 1-4, DOI 10.1145/2910017.2910633, May 2016,
              &lt;https://dl.acm.org/citation.cfm?doid=2910017.2910633&gt;.

   [L4Sdemo16-Video]
              "Videos used in IETF dispatch WG 'Ultra-Low Queuing Delay
              for All Apps' slot",
              &lt;https://riteproject.eu/dctth/#1511dispatchwg&gt;.

   [L4Seval22]
              De Schepper, K., Albisser, O., Tilmans, O., and B.
              Briscoe, "Dual Queue Coupled AQM: Deployable Very Low
              Queuing Delay for All", TR-BB-2022-001, arXiv:2209.01078
              [cs.NI], DOI 10.48550/arXiv.2209.01078, September 2022,
              &lt;https://arxiv.org/abs/2209.01078&gt;.

   [L4SOPS]   White, G., Ed., "Operational Guidance for Deployment of
              L4S in the Internet", Work in Progress, Internet-Draft,
              draft-ietf-tsvwg-l4sops-03, 28 April 2022,
              &lt;https://datatracker.ietf.org/doc/html/draft-ietf-tsvwg-
              l4sops-03&gt;.

   [LEDBAT_AQM]
              Al-Saadi, R., Armitage, G., and J. But, "Characterising
              LEDBAT Performance Through Bottlenecks Using PIE, FQ-CoDel
              and FQ-PIE Active Queue Management", IEEE 42nd Conference
              on Local Computer Networks (LCN), DOI 10.1109/LCN.2017.22,
              October 2017,
              &lt;https://ieeexplore.ieee.org/document/8109367&gt;.

   [lowat]    Meenan, P., "Optimizing HTTP/2 prioritization with BBR and
              tcp_notsent_lowat", Cloudflare Blog, October 2018,
              &lt;https://blog.cloudflare.com/http-2-prioritization-with-
              nginx/&gt;.

   [McIlroy78]
              McIlroy, M.D., Pinson, E. N., and B. A. Tague, "UNIX Time-
              Sharing System: Foreword", The Bell System Technical
              Journal 57: 6, pp. 1899-1904,
              DOI 10.1002/j.1538-7305.1978.tb02135.x, July 1978,
              &lt;https://archive.org/details/bstj57-6-1899&gt;.

   [Nadas20]  NÃ¡das, S., Gombos, G., Fejes, F., and S. Laki, "A
              Congestion Control Independent L4S Scheduler", ANRW '20:
              Proceedings of the Applied Networking Research Workshop,
              pp. 45-51, DOI 10.1145/3404868.3406669, July 2020,
              &lt;https://doi.org/10.1145/3404868.3406669&gt;.

   [NASA04]   Bailey, R., Trey Arthur III, J., and S. Williams, "Latency
              Requirements for Head-Worn Display S/EVS Applications",
              Proceedings of SPIE 5424, DOI 10.1117/12.554462, April
              2004, &lt;https://ntrs.nasa.gov/api/citations/20120009198/
              downloads/20120009198.pdf?attachment=true&gt;.

   [NQB-PHB]  White, G. and T. Fossati, "A Non-Queue-Building Per-Hop
              Behavior (NQB PHB) for Differentiated Services", Work in
              Progress, Internet-Draft, draft-ietf-tsvwg-nqb-15, 11
              January 2023, &lt;https://datatracker.ietf.org/doc/html/
              draft-ietf-tsvwg-nqb-15&gt;.

   [PRAGUE-CC]
              De Schepper, K., Tilmans, O., and B. Briscoe, Ed., "Prague
              Congestion Control", Work in Progress, Internet-Draft,
              draft-briscoe-iccrg-prague-congestion-control-01, 11 July
              2022, &lt;https://datatracker.ietf.org/doc/html/draft-
              briscoe-iccrg-prague-congestion-control-01&gt;.

   [PragueLinux]
              Briscoe, B., De Schepper, K., Albisser, O., Misund, J.,
              Tilmans, O., KÃ¼hlewind, M., and A.S. Ahmed, "Implementing
              the 'TCP Prague' Requirements for Low Latency Low Loss
              Scalable Throughput (L4S)", Proceedings Linux Netdev 0x13,
              March 2019, &lt;https://www.netdevconf.org/0x13/
              session.html?talk-tcp-prague-l4s&gt;.

   [QDyn]     Briscoe, B., "Rapid Signalling of Queue Dynamics", TR-BB-
              2017-001, arXiv:1904.07044 [cs.NI],
              DOI 10.48550/arXiv.1904.07044, April 2019,
              &lt;https://arxiv.org/abs/1904.07044&gt;.

   [Raaen14]  Raaen, K. and T-M. GrÃ¸nli, "Latency Thresholds for
              Usability in Games: A Survey", Norsk IKT-konferanse for
              forskning og utdanning (Norwegian ICT conference for
              research and education), 2014,
              &lt;http://ojs.bibsys.no/index.php/NIK/article/view/9/6&gt;.

   [Rajiullah15]
              Rajiullah, M., "Towards a Low Latency Internet:
              Understanding and Solutions", Dissertation, Karlstad
              University, 2015, &lt;https://www.diva-
              portal.org/smash/get/diva2:846109/FULLTEXT01.pdf&gt;.

   [RELENTLESS]
              Mathis, M., "Relentless Congestion Control", Work in
              Progress, Internet-Draft, draft-mathis-iccrg-relentless-
              tcp-00, 4 March 2009,
              &lt;https://datatracker.ietf.org/doc/html/draft-mathis-iccrg-
              relentless-tcp-00&gt;.

   [RFC0970]  Nagle, J., "On Packet Switches With Infinite Storage",
              RFC 970, DOI 10.17487/RFC0970, December 1985,
              &lt;https://www.rfc-editor.org/info/rfc970&gt;.

   [RFC2475]  Blake, S., Black, D., Carlson, M., Davies, E., Wang, Z.,
              and W. Weiss, "An Architecture for Differentiated
              Services", RFC 2475, DOI 10.17487/RFC2475, December 1998,
              &lt;https://www.rfc-editor.org/info/rfc2475&gt;.

   [RFC2698]  Heinanen, J. and R. Guerin, "A Two Rate Three Color
              Marker", RFC 2698, DOI 10.17487/RFC2698, September 1999,
              &lt;https://www.rfc-editor.org/info/rfc2698&gt;.

   [RFC2884]  Hadi Salim, J. and U. Ahmed, "Performance Evaluation of
              Explicit Congestion Notification (ECN) in IP Networks",
              RFC 2884, DOI 10.17487/RFC2884, July 2000,
              &lt;https://www.rfc-editor.org/info/rfc2884&gt;.

   [RFC3168]  Ramakrishnan, K., Floyd, S., and D. Black, "The Addition
              of Explicit Congestion Notification (ECN) to IP",
              RFC 3168, DOI 10.17487/RFC3168, September 2001,
              &lt;https://www.rfc-editor.org/info/rfc3168&gt;.

   [RFC3246]  Davie, B., Charny, A., Bennet, J.C.R., Benson, K., Le
              Boudec, J.Y., Courtney, W., Davari, S., Firoiu, V., and D.
              Stiliadis, "An Expedited Forwarding PHB (Per-Hop
              Behavior)", RFC 3246, DOI 10.17487/RFC3246, March 2002,
              &lt;https://www.rfc-editor.org/info/rfc3246&gt;.

   [RFC3540]  Spring, N., Wetherall, D., and D. Ely, "Robust Explicit
              Congestion Notification (ECN) Signaling with Nonces",
              RFC 3540, DOI 10.17487/RFC3540, June 2003,
              &lt;https://www.rfc-editor.org/info/rfc3540&gt;.

   [RFC3649]  Floyd, S., "HighSpeed TCP for Large Congestion Windows",
              RFC 3649, DOI 10.17487/RFC3649, December 2003,
              &lt;https://www.rfc-editor.org/info/rfc3649&gt;.

   [RFC4340]  Kohler, E., Handley, M., and S. Floyd, "Datagram
              Congestion Control Protocol (DCCP)", RFC 4340,
              DOI 10.17487/RFC4340, March 2006,
              &lt;https://www.rfc-editor.org/info/rfc4340&gt;.

   [RFC4774]  Floyd, S., "Specifying Alternate Semantics for the
              Explicit Congestion Notification (ECN) Field", BCP 124,
              RFC 4774, DOI 10.17487/RFC4774, November 2006,
              &lt;https://www.rfc-editor.org/info/rfc4774&gt;.

   [RFC4960]  Stewart, R., Ed., "Stream Control Transmission Protocol",
              RFC 4960, DOI 10.17487/RFC4960, September 2007,
              &lt;https://www.rfc-editor.org/info/rfc4960&gt;.

   [RFC5033]  Floyd, S. and M. Allman, "Specifying New Congestion
              Control Algorithms", BCP 133, RFC 5033,
              DOI 10.17487/RFC5033, August 2007,
              &lt;https://www.rfc-editor.org/info/rfc5033&gt;.

   [RFC5348]  Floyd, S., Handley, M., Padhye, J., and J. Widmer, "TCP
              Friendly Rate Control (TFRC): Protocol Specification",
              RFC 5348, DOI 10.17487/RFC5348, September 2008,
              &lt;https://www.rfc-editor.org/info/rfc5348&gt;.

   [RFC5670]  Eardley, P., Ed., "Metering and Marking Behaviour of PCN-
              Nodes", RFC 5670, DOI 10.17487/RFC5670, November 2009,
              &lt;https://www.rfc-editor.org/info/rfc5670&gt;.

   [RFC5681]  Allman, M., Paxson, V., and E. Blanton, "TCP Congestion
              Control", RFC 5681, DOI 10.17487/RFC5681, September 2009,
              &lt;https://www.rfc-editor.org/info/rfc5681&gt;.

   [RFC6040]  Briscoe, B., "Tunnelling of Explicit Congestion
              Notification", RFC 6040, DOI 10.17487/RFC6040, November
              2010, &lt;https://www.rfc-editor.org/info/rfc6040&gt;.

   [RFC6679]  Westerlund, M., Johansson, I., Perkins, C., O'Hanlon, P.,
              and K. Carlberg, "Explicit Congestion Notification (ECN)
              for RTP over UDP", RFC 6679, DOI 10.17487/RFC6679, August
              2012, &lt;https://www.rfc-editor.org/info/rfc6679&gt;.

   [RFC6817]  Shalunov, S., Hazel, G., Iyengar, J., and M. Kuehlewind,
              "Low Extra Delay Background Transport (LEDBAT)", RFC 6817,
              DOI 10.17487/RFC6817, December 2012,
              &lt;https://www.rfc-editor.org/info/rfc6817&gt;.

   [RFC6973]  Cooper, A., Tschofenig, H., Aboba, B., Peterson, J.,
              Morris, J., Hansen, M., and R. Smith, "Privacy
              Considerations for Internet Protocols", RFC 6973,
              DOI 10.17487/RFC6973, July 2013,
              &lt;https://www.rfc-editor.org/info/rfc6973&gt;.

   [RFC7560]  Kuehlewind, M., Ed., Scheffenegger, R., and B. Briscoe,
              "Problem Statement and Requirements for Increased Accuracy
              in Explicit Congestion Notification (ECN) Feedback",
              RFC 7560, DOI 10.17487/RFC7560, August 2015,
              &lt;https://www.rfc-editor.org/info/rfc7560&gt;.

   [RFC7567]  Baker, F., Ed. and G. Fairhurst, Ed., "IETF
              Recommendations Regarding Active Queue Management",
              BCP 197, RFC 7567, DOI 10.17487/RFC7567, July 2015,
              &lt;https://www.rfc-editor.org/info/rfc7567&gt;.

   [RFC7665]  Halpern, J., Ed. and C. Pignataro, Ed., "Service Function
              Chaining (SFC) Architecture", RFC 7665,
              DOI 10.17487/RFC7665, October 2015,
              &lt;https://www.rfc-editor.org/info/rfc7665&gt;.

   [RFC7713]  Mathis, M. and B. Briscoe, "Congestion Exposure (ConEx)
              Concepts, Abstract Mechanism, and Requirements", RFC 7713,
              DOI 10.17487/RFC7713, December 2015,
              &lt;https://www.rfc-editor.org/info/rfc7713&gt;.

   [RFC8033]  Pan, R., Natarajan, P., Baker, F., and G. White,
              "Proportional Integral Controller Enhanced (PIE): A
              Lightweight Control Scheme to Address the Bufferbloat
              Problem", RFC 8033, DOI 10.17487/RFC8033, February 2017,
              &lt;https://www.rfc-editor.org/info/rfc8033&gt;.

   [RFC8034]  White, G. and R. Pan, "Active Queue Management (AQM) Based
              on Proportional Integral Controller Enhanced (PIE) for
              Data-Over-Cable Service Interface Specifications (DOCSIS)
              Cable Modems", RFC 8034, DOI 10.17487/RFC8034, February
              2017, &lt;https://www.rfc-editor.org/info/rfc8034&gt;.

   [RFC8170]  Thaler, D., Ed., "Planning for Protocol Adoption and
              Subsequent Transitions", RFC 8170, DOI 10.17487/RFC8170,
              May 2017, &lt;https://www.rfc-editor.org/info/rfc8170&gt;.

   [RFC8257]  Bensley, S., Thaler, D., Balasubramanian, P., Eggert, L.,
              and G. Judd, "Data Center TCP (DCTCP): TCP Congestion
              Control for Data Centers", RFC 8257, DOI 10.17487/RFC8257,
              October 2017, &lt;https://www.rfc-editor.org/info/rfc8257&gt;.

   [RFC8290]  Hoeiland-Joergensen, T., McKenney, P., Taht, D., Gettys,
              J., and E. Dumazet, "The Flow Queue CoDel Packet Scheduler
              and Active Queue Management Algorithm", RFC 8290,
              DOI 10.17487/RFC8290, January 2018,
              &lt;https://www.rfc-editor.org/info/rfc8290&gt;.

   [RFC8298]  Johansson, I. and Z. Sarker, "Self-Clocked Rate Adaptation
              for Multimedia", RFC 8298, DOI 10.17487/RFC8298, December
              2017, &lt;https://www.rfc-editor.org/info/rfc8298&gt;.

   [RFC8311]  Black, D., "Relaxing Restrictions on Explicit Congestion
              Notification (ECN) Experimentation", RFC 8311,
              DOI 10.17487/RFC8311, January 2018,
              &lt;https://www.rfc-editor.org/info/rfc8311&gt;.

   [RFC8312]  Rhee, I., Xu, L., Ha, S., Zimmermann, A., Eggert, L., and
              R. Scheffenegger, "CUBIC for Fast Long-Distance Networks",
              RFC 8312, DOI 10.17487/RFC8312, February 2018,
              &lt;https://www.rfc-editor.org/info/rfc8312&gt;.

   [RFC8404]  Moriarty, K., Ed. and A. Morton, Ed., "Effects of
              Pervasive Encryption on Operators", RFC 8404,
              DOI 10.17487/RFC8404, July 2018,
              &lt;https://www.rfc-editor.org/info/rfc8404&gt;.

   [RFC8511]  Khademi, N., Welzl, M., Armitage, G., and G. Fairhurst,
              "TCP Alternative Backoff with ECN (ABE)", RFC 8511,
              DOI 10.17487/RFC8511, December 2018,
              &lt;https://www.rfc-editor.org/info/rfc8511&gt;.

   [RFC8888]  Sarker, Z., Perkins, C., Singh, V., and M. Ramalho, "RTP
              Control Protocol (RTCP) Feedback for Congestion Control",
              RFC 8888, DOI 10.17487/RFC8888, January 2021,
              &lt;https://www.rfc-editor.org/info/rfc8888&gt;.

   [RFC8985]  Cheng, Y., Cardwell, N., Dukkipati, N., and P. Jha, "The
              RACK-TLP Loss Detection Algorithm for TCP", RFC 8985,
              DOI 10.17487/RFC8985, February 2021,
              &lt;https://www.rfc-editor.org/info/rfc8985&gt;.

   [RFC9000]  Iyengar, J., Ed. and M. Thomson, Ed., "QUIC: A UDP-Based
              Multiplexed and Secure Transport", RFC 9000,
              DOI 10.17487/RFC9000, May 2021,
              &lt;https://www.rfc-editor.org/info/rfc9000&gt;.

   [RFC9113]  Thomson, M., Ed. and C. Benfield, Ed., "HTTP/2", RFC 9113,
              DOI 10.17487/RFC9113, June 2022,
              &lt;https://www.rfc-editor.org/info/rfc9113&gt;.

   [RFC9331]  De Schepper, K. and B. Briscoe, Ed., "The Explicit
              Congestion Notification (ECN) Protocol for Low Latency,
              Low Loss, and Scalable Throughput (L4S)", RFC 9331,
              DOI 10.17487/RFC9331, January 2023,
              &lt;https://www.rfc-editor.org/info/rfc9331&gt;.

   [RFC9332]  De Schepper, K., Briscoe, B., Ed., and G. White, "Dual-
              Queue Coupled Active Queue Management (AQM) for Low
              Latency, Low Loss, and Scalable Throughput (L4S)",
              RFC 9332, DOI 10.17487/RFC9332, January 2023,
              &lt;https://www.rfc-editor.org/info/rfc9332&gt;.

   [SCReAM-L4S]
              "SCReAM", commit fda6c53, June 2022,
              &lt;https://github.com/EricssonResearch/scream&gt;.

   [TCP-CA]   Jacobson, V. and M. Karels, "Congestion Avoidance and
              Control", Laurence Berkeley Labs Technical Report ,
              November 1988, &lt;https://ee.lbl.gov/papers/congavoid.pdf&gt;.

   [UnorderedLTE]
              Austrheim, M., "Implementing immediate forwarding for 4G
              in a network simulator", Master's Thesis, University of
              Oslo, 2018.

<span>Acknowledgements</span>

   Thanks to Richard Scheffenegger, Wes Eddy, Karen Nielsen, David
   Black, Jake Holland, Vidhi Goel, Ermin Sakic, Praveen
   Balasubramanian, Gorry Fairhurst, Mirja Kuehlewind, Philip Eardley,
   Neal Cardwell, Pete Heist, and Martin Duke for their useful review
   comments.  Thanks also to the area reviewers: Marco Tiloca, Lars
   Eggert, Roman Danyliw, and Ãric Vyncke.

   Bob Briscoe and Koen De Schepper were partly funded by the European
   Community under its Seventh Framework Programme through the Reducing
   Internet Transport Latency (RITE) project (ICT-317700).  The
   contribution of Koen De Schepper was also partly funded by the
   5Growth and DAEMON EU H2020 projects.  Bob Briscoe was also partly
   funded by the Research Council of Norway through the TimeIn project,
   partly by CableLabs, and partly by the Comcast Innovation Fund.  The
   views expressed here are solely those of the authors.

<span>Authors' Addresses</span>

   Bob Briscoe (editor)
   Independent
   United Kingdom
   Email: ietf@bobbriscoe.net
   URI:   https://bobbriscoe.net/

   Koen De Schepper
   Nokia Bell Labs
   Antwerp
   Belgium
   Email: koen.de_schepper@nokia.com
   URI:   https://www.bell-labs.com/about/researcher-profiles/
   koende_schepper/

   Marcelo Bagnulo
   Universidad Carlos III de Madrid
   Av. Universidad 30
   28911 Madrid
   Spain
   Phone: 34 91 6249500
   Email: marcelo@it.uc3m.es
   URI:   https://www.it.uc3m.es

   Greg White
   CableLabs
   United States of America
   Email: G.White@CableLabs.com
</pre>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I Remade the Fake Google Gemini Demo, Except Using GPT-4 and It's Real (256 pts)]]></title>
            <link>https://sagittarius.greg.technology/</link>
            <guid>38596953</guid>
            <pubDate>Mon, 11 Dec 2023 02:17:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sagittarius.greg.technology/">https://sagittarius.greg.technology/</a>, See on <a href="https://news.ycombinator.com/item?id=38596953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      

      <p>Please see below for a (real) demo. All the code is in <a href="https://github.com/gregsadetsky/sagittarius">this repo</a>! Cheers.</p>



<iframe width="100%" height="515" src="https://www.youtube.com/embed/__nL7Vc0OCg?si=tReedrTnNuSBFHXs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<hr>

<p>Made by <a href="https://greg.technology/">Greg Technology</a>.</p>


      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Carmack and John Romero reunited to talk DOOM on its 30th Anniversary (172 pts)]]></title>
            <link>https://www.pcgamer.com/for-dooms-30th-anniversary-the-johns-romero-and-carmack-reunited-to-celebrate-the-fps-that-changed-everything-i-want-to-thank-everybody-in-the-doom-community-for-keeping-this-game-alive/</link>
            <guid>38596634</guid>
            <pubDate>Mon, 11 Dec 2023 01:14:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/for-dooms-30th-anniversary-the-johns-romero-and-carmack-reunited-to-celebrate-the-fps-that-changed-everything-i-want-to-thank-everybody-in-the-doom-community-for-keeping-this-game-alive/">https://www.pcgamer.com/for-dooms-30th-anniversary-the-johns-romero-and-carmack-reunited-to-celebrate-the-fps-that-changed-everything-i-want-to-thank-everybody-in-the-doom-community-for-keeping-this-game-alive/</a>, See on <a href="https://news.ycombinator.com/item?id=38596634">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>To celebrate the 30th anniversary of the launch of Doom, id Software co-founders John Carmack and John Romero <a data-analytics-id="inline-link" href="https://www.twitch.tv/videos/2000693432" target="_blank" data-url="https://www.twitch.tv/videos/2000693432">reunited to talk about the legendary FPS</a>. The discussion was moderated by <a data-analytics-id="inline-link" href="https://linktr.ee/davidlcraddock" target="_blank" data-url="https://linktr.ee/davidlcraddock">David Craddock</a> (The FPS Documentary, Long Live Mortal Kombat), with interview questions from Craddock and the Twitch chat.</p><p>The conversation was understandably warm and celebratory, but I was also surprised at how critical the two were of their own work. Carmack alluded to "flashier" (and potentially technically riskier) graphical effects he wishes he had built into Doom's engine, and he noted that he thinks the more grounded, military sci-fi aesthetic of Episode One has aged better than the abstract hellscapes later in the game.</p><p>Romero, meanwhile, contrasted Doom with the id games before and after, arguing it represented a technical "sweet spot" before Quake and full 3D acceleration started to seriously complicate development and limit how many enemies they could fit on screen. The developer praised Doom's engine for allowing more complex maps than Wolfenstein though, ruefully remarking that "Making levels for Wolfenstein had to be the most boring level design job ever."</p><p>The two also fondly reminisced about the technical limitations of the time. Carmack remarked that, although he thought id could "just sell [Doom] in a brown paper bag" off its quality alone, he was glad they went the extra mile with its iconic box art and marketing. Both devs expressed an appreciation for '90s PC big box packaging and accompanying "feelies" like cloth maps, and I'm 100% with them on that.</p><p>As far as development stories, I was struck by Romero's recollection of getting multiplayer working for the first time shortly before Doom's release: "I went into my officeâI was making E1M7 at the timeâI'm looking out the window and I'm seeing two characters fighting, rockets are flying up at a high window and someone is plasma gunning the other guy.</p><p>And I'm like, this is going to be the coolest fucking game the planet has ever seen, I can't wait to play that."</p><iframe width="620" height="378" scrolling="no" frameborder="0" data-lazy-priority="low" data-lazy-src="https://player.twitch.tv/?video=2000693432&amp;parent=www.pcgamer.com"></iframe><p>"I've said before that I'm not a very sentimental person, that I don't spend a lot of time reminiscing about the good old days," Carmack confided as a means of farewell, "But they were really quite good. I'm very proud of the things that we built back then and that they have this legacy that's lasted to this day."</p><p>Romero echoed the sentiment, thanking Carmack for the years they spent working together, and also extending his appreciation to the players who keep coming back to Doom: "I want to thank everybody in the Doom community for keeping this game alive. And really, just thank you for playing our games everybody."</p><p>You can check out the conversation in its entirety on <a data-analytics-id="inline-link" href="https://www.twitch.tv/videos/2000693432" target="_blank" data-url="https://www.twitch.tv/videos/2000693432">John Romero's Twitch channel</a>, and it's also a perfect time to dive into <a data-analytics-id="inline-link" href="https://romero.com/sigil" target="_blank" data-url="https://romero.com/sigil">Sigil 2</a>, the sequel to Romero's 2019 Doom megawad and subject of <a data-analytics-id="inline-link" href="https://www.pcgamer.com/pc-gamer-magazines-latest-issue-on-sale-now-sigil-ii-and-dooms-30th-anniversary/" target="_blank" data-before-rewrite-localise="https://www.pcgamer.com/pc-gamer-magazines-latest-issue-on-sale-now-sigil-ii-and-dooms-30th-anniversary//">PC Gamer's latest print cover story</a>. While you can pay for a full-on classico big box with all those feelies we love, both Sigil megawads are free to download.</p><p>If that's not enough WAD action for you, the megawad Eviternity <a data-analytics-id="inline-link" href="https://www.pcgamer.com/five-years-later-doom-megawad-eviternity-just-got-a-surprise-sequel/" target="_blank" data-before-rewrite-localise="https://www.pcgamer.com/five-years-later-doom-megawad-eviternity-just-got-a-surprise-sequel//">also just got a sequel campaign</a> to celebrate Doom's 30th birthday, and you can peruse the list of this year's <a data-analytics-id="inline-link" href="https://www.doomworld.com/cacowards/2023/index/" target="_blank" data-url="https://www.doomworld.com/cacowards/2023/index/">Cacowards</a> for more quality creations.</p>
</div><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-znKUehQFaNW6HSuLsNzvAR"><section><p>Sign up to get the best content of the week, and great gaming deals, as picked by the editors.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pitivi â Free video editor with a beautiful and intuitive user interface (131 pts)]]></title>
            <link>https://www.pitivi.org/</link>
            <guid>38596353</guid>
            <pubDate>Mon, 11 Dec 2023 00:18:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pitivi.org/">https://www.pitivi.org/</a>, See on <a href="https://news.ycombinator.com/item?id=38596353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section>
    <p><a href="" title="[pronounciation]" onclick="return play();">Pitivi <i id="audio_icon"></i></a> is a Free video editor with a beautiful and intuitive user interface, a clean codebase and a fantastic community. <a href="https://www.pitivi.org/contribute/">Join us!</a></p>
    <audio id="audio" src="https://www.pitivi.org/i/pitivi%20pronounciation.ogg"></audio>
    
</section>

<section id="frontpage_splash">
    <h2>We believe in allowing everyone on the planet to <a href="https://www.pitivi.org/showcase/">express themselves</a> through filmmaking, with tools that they can own and improve.</h2>

    

</section>

<section id="news">
<h2><a href="https://www.pitivi.org/news/">News</a></h2>
<ul>

<article>
    <h2><a href="https://www.pitivi.org/news/2023-03-26-pitivi-2023-03-time-was-money/">Pitivi 2023.03 â Time Was Money</a></h2>
    <ul>
    <li><time datetime="2023-08-12">Aug 12, 2023</time></li>
    <li>
    <a href="https://www.pitivi.org/tags/release/">
        <i></i>Release
    </a>
    </li>
</ul>

    <p>Auto alignment and precise waveforms.</p>
</article>
<article>
    <h2><a href="https://www.pitivi.org/news/2022-06-26-pitivi-2022-06-reel-easing/">Pitivi 2022.06 â Reel Easing</a></h2>
    <ul>
    <li><time datetime="2022-06-28">Jun 28, 2022</time></li>
    <li>
    <a href="https://www.pitivi.org/tags/release/">
        <i></i>Release
    </a>
    </li>
</ul>

    <p>Object tracking, beat detection and Clip Properties enhancements.</p>
</article>
<article>
    <h2><a href="https://www.pitivi.org/news/2021-05-30-pitivi-2021-05-oubliette/">Pitivi 2021.05 â Oubliette</a></h2>
    <ul>
    <li><time datetime="2021-05-30">May 30, 2021</time></li>
    <li>
    <a href="https://www.pitivi.org/tags/release/">
        <i></i>Release
    </a>
    </li>
</ul>

    <p>Media Library clips tagging.</p>
</article>
<article>
    <h2><a href="https://www.pitivi.org/news/2021-01-01-pitivi-2021-01-retro-perspective/">Pitivi 2021.01 â Retro Perspective</a></h2>
    <ul>
    <li><time datetime="2021-02-01">Feb 1, 2021</time></li>
    <li>
    <a href="https://www.pitivi.org/tags/release/">
        <i></i>Release
    </a>
    </li>
</ul>

    <p>Bug fixes.</p>
</article>
<article>
    <h2><a href="https://www.pitivi.org/news/2020-10-11-pitivi-2020-09-hocus-focus/">Pitivi 2020.09 â Hocus Focus</a></h2>
    <ul>
    <li><time datetime="2020-10-11">Oct 11, 2020</time></li>
    <li>
    <a href="https://www.pitivi.org/tags/release/">
        <i></i>Release
    </a>
    </li>
</ul>

    <p>Lots of new features.</p>
</article>
</ul>
<p><a href="https://www.pitivi.org/news/">Archive...</a></p>
</section>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please, expose your RSS (205 pts)]]></title>
            <link>https://rknight.me/please-expose-your-rss/</link>
            <guid>38595855</guid>
            <pubDate>Sun, 10 Dec 2023 22:52:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rknight.me/please-expose-your-rss/">https://rknight.me/please-expose-your-rss/</a>, See on <a href="https://news.ycombinator.com/item?id=38595855">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>



<span data-pagefind-body="">
	<p>Earlier this week I had a need to manually find a bunch of people's RSS feed links. It seemed simple enough: go to their website and look for an RSS/Subscribe link but I was surprised to find that a lot of people don't have a link anywhere to their feed.</p>
<p>Even if people only ever add your website into their feed reader and let the app find the RSS feed (see below for more info on this), showing an RSS link reminds people that RSS exists, a win for the open web.</p>
<p>My second step when finding a link failed was to use this handy JS snippet from my <a href="https://podduration.rknight.me/">Podcast Duration project</a>:</p>
<pre><code><span>return</span> Array<span>.</span><span>from</span><span>(</span>document<span>.</span><span>getElementsByTagName</span><span>(</span><span>'link'</span><span>)</span><span>)</span><span>.</span><span>find</span><span>(</span><span>l</span> <span>=&gt;</span> l<span>.</span>type<span>.</span><span>includes</span><span>(</span><span>'application/rss+xml'</span><span>)</span><span>)</span><span>?.</span>href</code></pre>
<p>This looks for a <code>&lt;link&gt;</code> tag on the website that has a type of <code>application/rss+xml</code>. This is called RSS auto-discovery and is a standard way to expose RSS feeds to help <a href="https://www.rssboard.org/rss-autodiscovery">browsers and other software to automatically find a site's RSS feed</a>.</p>
<p>Like the standard link, a lot of sites were also missing this. This is (at least as a first step) what feed reeders like <a href="https://netnewswire.com/">NetNewsWire</a> will use to automatically find a feed when you paste in a URL. If you have an RSS feed, you should have the following in the <code>head</code> of your website:</p>
<pre><code><span><span><span>&lt;</span>link</span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>application/rss+xml<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>My Cool Website<span>"</span></span> <span>href</span><span><span>=</span><span>"</span>https://example.com/feed.xml<span>"</span></span> <span>/&gt;</span></span><p><span>&lt;!-- use application/atom+xml for an atom feed --&gt;</span><br><span><span><span>&lt;</span>link</span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>application/atom+xml<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>My Cool Website<span>"</span></span> <span>href</span><span><span>=</span><span>"</span>https://example.com/atom.xml<span>"</span></span> <span>/&gt;</span></span></p></code></pre>
<p>If you have multiple feeds, you can have more than one <code>link</code> tag that links to those feeds as well. For example, say you have a <a href="https://www.jsonfeed.org/">JSON feed</a> and a podcast feed you want to link to:</p>
<pre><code><span>&lt;!-- Website RSS feed --&gt;</span><br><span><span><span>&lt;</span>link</span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>application/rss+xml<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>My Cool Website<span>"</span></span> <span>href</span><span><span>=</span><span>"</span>https://example.com/feed.xml<span>"</span></span> <span>/&gt;</span></span><p><span>&lt;!-- Website JSON feed --&gt;</span><br><span><span><span>&lt;</span>link</span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>application/json<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>My Cool Website but JSON<span>"</span></span> <span>href</span><span><span>=</span><span>"</span>https://example.com/feed.json<span>"</span></span> <span>/&gt;</span></span></p><p><span>&lt;!-- Podcast RSS feed --&gt;</span><br><span><span><span>&lt;</span>link</span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>application/rss+xml<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>My Cool Podcast<span>"</span></span> <span>href</span><span><span>=</span><span>"</span>https://example.com/podcast.xml<span>"</span></span> <span>/&gt;</span></span></p></code></pre>
<p>Please, expose your RSS.</p>
<p>Update 2023-12-09 via <a href="https://bne.social/@james/111545470669286673">James</a>:</p>
<blockquote>
<p>if you're going to add an RSS button, please ensure it looks like an RSS button and is in RSS orange</p>
</blockquote>
<p>This is an excellent idea and I have done so here.</p>

</span></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BSD on Windows: Things I wish I knew existed (149 pts)]]></title>
            <link>https://virtuallyfun.com/2023/12/08/bsd-on-windows-things-i-wish-i-knew-existed/</link>
            <guid>38595470</guid>
            <pubDate>Sun, 10 Dec 2023 21:55:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://virtuallyfun.com/2023/12/08/bsd-on-windows-things-i-wish-i-knew-existed/">https://virtuallyfun.com/2023/12/08/bsd-on-windows-things-i-wish-i-knew-existed/</a>, See on <a href="https://news.ycombinator.com/item?id=38595470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing.png"><img decoding="async" width="1024" height="540" src="https://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing-1024x540.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing-1024x540.png 1024w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing-300x158.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing-768x405.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing-1536x809.png 1536w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing-500x264.png 500w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-landing.png 1685w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Yahoo Auctions Japan</figcaption></figure>
<p>Itâs 1995 and Iâve been nearly two years in the professional workspace. OS/2 is the dominant workstation product, Netware servers rule the world, and the year of the Linux desktop is going to happen any moment now. If you werenât running OS/2, you were probably running Windows 3.1, only very few people were using that Linux thing. What would have been the prefect OS at the time would have been NT with a competent POSIX subsystem, but since we were denied that, enter Hiroshi Oota with BSD on Windows.</p>
<p>It was a late night browsing yahoo auctions Japan as one does, laughing at the absurd Famicom/Super Famicom games, and I went ahead and looked for BSD CD-ROMS, where I first came across BSD on Windows. And then Iâd forgotten about it and went to work on some Darwin projects.</p>
<p>Fast forward 3 weeks, and <a href="https://archive.org/details/@vic485">vic485</a> had bought it, had it shipped, and uploaded on <a href="https://archive.org/details/bsd-on-windows">archive.org</a>. So a big super thanks to vic485 for making this all possible!</p>
<div>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/12/winmem32-required-for-bow.png"><img decoding="async" width="449" height="163" src="https://virtuallyfun.com/wp-content/uploads/2023/12/winmem32-required-for-bow.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/winmem32-required-for-bow.png 449w, http://virtuallyfun.com/wp-content/uploads/2023/12/winmem32-required-for-bow-300x109.png 300w" sizes="(max-width: 449px) 100vw, 449px"></a></figure></div>
<p>So what is it? Itâs not quite BSD, its a bunch of 16bit DLLâs that broke the kernel down into subsystems, that each rely on winmem32.dll to give access to flat/32bit address space. BSD on Windows (BOW) being a hybrid 16/32bit app is originally for Windows 3.1, with the later 1.5 update for Windows 95, which includes support for long filenames. Iâm not sure if itâll run on Windows NT or OS/2, as I donât think </p>
<p>So what do you get?</p>
<figure><img loading="lazy" decoding="async" width="1024" height="1024" src="https://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-1-1024x1024.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-1-1024x1024.jpg 1024w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-1-300x300.jpg 300w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-1-150x150.jpg 150w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-1-768x768.jpg 768w, http://virtuallyfun.com/wp-content/uploads/2023/12/bsd-on-windows-auction-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>The key media contents are the install floppy and the CD-ROM. Yes the setup program IS only on the floppy. Hope you get that disk image. Iâm unsure what the manual is like, other than of course it is in Japanese.</p>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack.png"><img loading="lazy" decoding="async" width="1024" height="624" src="https://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack-1024x624.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack-1024x624.png 1024w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack-300x183.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack-768x468.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack-493x300.png 493w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-compiling-hack.png 1202w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>compiling</figcaption></figure>
<p>Itâs very much a single user mode BSD like environment complete with vi/gcc/csh/perl just to name a few. Iâve been able to test job control, and building some simple programs like <a href="https://archive.org/details/hack-103-for-bow">Hack 1.03</a>. I found a few issues however.</p>
<p>I havenât tested enough with FreeBSD 1/2 but I can verify that from my â<a href="https://sourceforge.net/projects/linux011/">Ancient Linux on Windows</a>â packages, the object format is the same, which is that early era when everything was a.out, although all different the reliance on GNU GAS &amp; LD did make the object format the same. And it was nice to compile a hello world from my Linux cross compiler, link it on BOW, and get a running executable.</p>
<p>The memory is weird, in that you can add hundreds of megabytes to Windows and BOW will always run exhausted. In the bow.ini file you can set the heap for each program, and I found out from some silly trial and error that the maximum heap you can effectively give is 13 megabytes. It seems that winmem32 has a single chunk of memory where all processes run out of, hence the sub 16mb ram zone. Maybe there is a way to allocate it, but Iâm unsure, maybe itâs in the book. CC1 was frequently having issues, so setting itâs heap to 13M sure helped, the linker âldâ of course was running out of memory as well so setting it to 8M got me linking.</p>
<p>Filenames, especially on Windows 3.1 are a huge problem. All the LFN TSRâs I tried to load just resulted in a full crash. I had to point the linker to the CD-ROM live filesystem, which maybe would be tedious on a real machine, but under emulation itâs fine.</p>
<p>BOW does NOT like Qemu. At all. It wonât under otvdm either. I suspect NT is a no go but I havenât tried. Oddly enough itâs not a timing issue, as it does run under VMware. There is an advantage to running it under Windows 95, is that it supports long filenames. 86Box works as well, I even was using the Pentium II Xeon at 400Mhz and that ran fine.</p>
<p>Probably the most annoying and silly thing is that the GCC C compiler doesnât have C++ style comments turned on. Not being able to use â//â is quite annoying.</p>
<figure><img loading="lazy" decoding="async" width="1920" height="2560" src="https://virtuallyfun.com/wp-content/uploads/2023/12/IMG_9741-scaled.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/IMG_9741-scaled.jpg 1920w, http://virtuallyfun.com/wp-content/uploads/2023/12/IMG_9741-225x300.jpg 225w, http://virtuallyfun.com/wp-content/uploads/2023/12/IMG_9741-768x1024.jpg 768w, http://virtuallyfun.com/wp-content/uploads/2023/12/IMG_9741-1152x1536.jpg 1152w, http://virtuallyfun.com/wp-content/uploads/2023/12/IMG_9741-1536x2048.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"><figcaption>Hack 1.03 running on my PS/2 model 80</figcaption></figure>
<p><a href="https://github.com/neozeed/hack-1.03">Hack</a> ran fine on my 386, which was a pleasant surprise!. It was really cool to have Word+Excel and Hack running at the same time. </p>
<p>Had I known about this, it would have been an incredible bridge product. Not to mention cross compiling to even Win32, or Linux. Not to mention at the time being able to run BSD with no real pain, just install and go</p>
<figure><img loading="lazy" decoding="async" width="1024" height="745" src="https://virtuallyfun.com/wp-content/uploads/2023/12/bow-irc-connection-1024x745.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/bow-irc-connection-1024x745.png 1024w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-irc-connection-300x218.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-irc-connection-768x559.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-irc-connection-412x300.png 412w, http://virtuallyfun.com/wp-content/uploads/2023/12/bow-irc-connection.png 1208w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>simple IRC test</figcaption></figure>
<p>There is generic TCP/IP Winsock support in BOW 1.5 as it simply calls winsock. This also includes the ability to run daemons, however limitations in BOW are quickly exposed, such as missing setuid/setgid sno there is no ability to impersonate lower privileged users. MMAP stuff also doesnât seem to work, although I was able to build a super simple port of Apache 1.3.1 to BSD on Windows (BOW).&nbsp;</p>
<figure><img loading="lazy" decoding="async" width="1024" height="745" src="https://virtuallyfun.com/wp-content/uploads/2023/12/Apache-on-BOW-1024x745.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/12/Apache-on-BOW-1024x745.png 1024w, http://virtuallyfun.com/wp-content/uploads/2023/12/Apache-on-BOW-300x218.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/12/Apache-on-BOW-768x559.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/12/Apache-on-BOW-412x300.png 412w, http://virtuallyfun.com/wp-content/uploads/2023/12/Apache-on-BOW.png 1208w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>While BOW may appear to be very BSD like, there is a lack of a the mmap Apache needs, along with user mapping &amp; impersonation.&nbsp; I ended up using the EMX â OS/2 system code, since itâs very POSIX like without relying on the Unix like OS actually working.</p>
<p>Iâve been able to serve pages to myself, however BOW crashing out many emulators and hypervisors kind of stops me from putting it on the internet. BOW enthusiasts can <a href="https://archive.org/details/apache131_for_BOW">download it from archive.org</a></p>
<p>Today, there is really no point to BOW, itâs an interesting oddity, but back in the day, for a jr network administrator being able to run the Unix version of the snmp tools, even if itâs only client side would have been great. If tftpd could be built to run this would have been beyond amazing, as you not only get BSD, but full Windows apps at the same time, much like MachTen.</p>
<p>Itâs a shame I never knew this was a thing, I certainly would have been evangelizing BOW! Who knows what other treasures are in the parallel societies of Japan/Asia/Europe?</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The surprising connection between after-hours work and decreased productivity (195 pts)]]></title>
            <link>https://slack.com/intl/en-gb/blog/news/the-surprising-connection-between-after-hours-work-and-decreased-productivity?nojsmode=1</link>
            <guid>38595245</guid>
            <pubDate>Sun, 10 Dec 2023 21:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slack.com/intl/en-gb/blog/news/the-surprising-connection-between-after-hours-work-and-decreased-productivity?nojsmode=1">https://slack.com/intl/en-gb/blog/news/the-surprising-connection-between-after-hours-work-and-decreased-productivity?nojsmode=1</a>, See on <a href="https://news.ycombinator.com/item?id=38595245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-js-content="true" data-js-dom="toc"><p><em><strong>Quick take:</strong> How do you spend your time at work and what is it costing you? Slackâs Workforce Index, based on survey responses from more than 10,000 desk workers around the globe, uncovers new findings on how to structure the workday to maximize productivity and strengthen employee well-being and satisfaction. </em></p>
<p>Key learnings include:</p>
<ul><li>Employees who log off at the end of the workday register 20% higher productivity scores than those who feel obligated to work after hours.</li>
<li>Making time for breaks during the workday improves employee productivity and well-being, and yet half of all desk workers say they rarely or never take breaks.</li>
<li>On average, desk workers say that the ideal amount of focus time is around four hours a day, and more than two hours a day in meetings is the tipping point at which a majority of workers feel overburdened by meetings.</li>
<li>Three out of every four desk workers report working in the 3 to 6pm timeframe, but of those, only one in four consider these hours highly productive.</li>
</ul>

<p>For decades, putting in extra hours at the office was seen by many as a sign of hard work and productivity, even a badge of honor. But new research from Slack shows despite that longstanding perception, working after hours is more often associated with <em>lower</em> levels of productivityâand could be a red flag that an employee is juggling too many tasks and needs help prioritizing and balancing their time.</p>
<p>The latest results from the Workforce Index, Slackâs survey of more than 10,000 desk workers, show the productivity gap depends on whatâs driving workers to burn the midnight (or early morning) oil. About two out of every five desk workers (37%) are logging on outside of their companyâs standard hours at least weekly, and more than half (54%) of these workers say itâs because they feel pressured to, not because they choose to.</p>
<p>Employees who feel <em>obligated</em> to work after-hours register 20% lower productivity scores than those who log off at the end of the standard workday. They also report:</p>
<ul><li>2.1x worse work-related stress</li>
<li>1.7x times lower satisfaction with their overall working environment</li>
<li>2x greater burnout</li>
</ul>
<section><figure><img alt="Employees who feel pressured to work after hours report 20% lower productivity throughout the day" loading="lazy" data-src="https://d34u8crftukxnk.cloudfront.net/slackpress/prod/sites/6/Workforce-Lab-Blog-Graphics-Pulse-11_V2_After-Hours-Horchata.png" data-srcset="" src="https://d34u8crftukxnk.cloudfront.net/slackpress/prod/sites/6/Workforce-Lab-Blog-Graphics-Pulse-11_V2_After-Hours-Horchata.png"></figure></section>
<p>Both groups say around 70% of their time spent working is productiveâa sign that those working extra hours are putting in as much effort as their colleaguesâbut those who work after hours are 50% more likely to say their productivity is blocked by competing priorities compared to those who log a standard workday.</p>
<p>On the flip side, employees who work outside of standard hours by choice, to better suit their schedule or to pursue personal ambitions, report no negative impacts and even a slight uptick in their wellness and productivity scores.</p>
<div><blockquote><p>âWeâve long seen a focus on quantity over quality across many aspects of work, from how we spend our time to how we define productivity. Constantly feeling like you need to catch up is hurting employees and businesses. This underscores the importance of building a culture of trust where employees feel safe enough to speak up when they need help prioritizing and have the right balance of time in the work day to get work done.â</p></blockquote></div>
<h2>When it comes to productivity, itâs not quantity of time spent working, itâs quality</h2>
<p>Results from the Workforce Index show that a significant portion of desk workers across the globe are struggling to balance their time at work, with different job tiers experiencing this problem in different ways.</p>
<p>More than one in four desk workers (27%), including more than half (55%) of executives, say they spend too much time in meetings. A similar share (25%) of all desk workers, including 43% of executives, say they spend too much time in email.</p>
<p>One in five (20%) donât have enough time to connect with coworkers, and this problem is most pronounced among more junior employees.</p>
<p>Alarmingly, the data shows that many workers across all levels are plowing through their daily tasks without any down time: Half of desk workers surveyed (50%) say they rarely or never take breaks during the workday. These workers are 1.7x more likely to experience burnout.</p>
<p>Their break-taking counterparts, on the other hand, show 62% higher scores for work-life balance, 43% greater ability to manage stress and anxiety, 43% greater overall satisfaction, andâperhaps surprisinglyâ13% higher scores for productivity.</p>
<div><blockquote><p>âWhy did we all come to believe that we are more productive if we are always on and that we need to burn out in order to succeed? It goes back to the first Industrial Revolution, when we started revering machines. The goal of machines is to minimize downtime. But for the human operating system, downtime is not a bug, itâs a feature. Elite athletes know that recovery is part of peak performance. Downtime is a productivity multiplier.â</p></blockquote></div><section><figure><img alt="Workers who regularly take breaks have 13% higher productivity" loading="lazy" data-src="https://d34u8crftukxnk.cloudfront.net/slackpress/prod/sites/6/Workforce-Lab-Blog-Graphics-Pulse-11_V2_Taking-Breaks-Horchata.png" data-srcset="" src="https://d34u8crftukxnk.cloudfront.net/slackpress/prod/sites/6/Workforce-Lab-Blog-Graphics-Pulse-11_V2_Taking-Breaks-Horchata.png"></figure></section>
<h2>Prime productivity hours: Whether youâre a morning person or a night owl, the afternoon slump is real</h2>
<p>On average, desk workers say that 70% of their time at work is productive. When asked about prime hours for productivity, answers vary widely, with some desk workers preferring the morning and others preferring the evening. But no matter their preference, a majority (71%) of desk workers agree that the late afternoon is the worst time for work, with productivity plummeting between the hours of 3 and 6pm.</p>
<section><figure><img alt="" loading="lazy" data-src="https://d34u8crftukxnk.cloudfront.net/slackpress/prod/sites/6/Workforce-Lab-Blog-Graphics-Pulse-11_V2_Afternoon-Slump-Purple.png" data-srcset="" src="https://d34u8crftukxnk.cloudfront.net/slackpress/prod/sites/6/Workforce-Lab-Blog-Graphics-Pulse-11_V2_Afternoon-Slump-Purple.png"></figure></section>
<p>While three out of every four desk workers report working in the 3-6pm timeframe, only one in four consider these hours highly productive.</p>
<div><blockquote><p>âThis goes to show that productivity isnât linear. Productivity happens in bursts, on and off throughout a day, not necessarily in prescribed windows of time, and definitely not for eight consecutive hours. The âafternoon slumpâ shouldnât be seen as a bad thing; for many workers this could be an ideal time to take that break that will boost their overall productivity for the day.â</p></blockquote></div>
<p>The most productive people use time management strategies. They are 1.6x more likely to block time to complete specific tasks, 1.7x more likely to only check email at specific times, and 2.2x more likely to set focus timers.</p>
<h2>The âGoldilocks Zoneâ for work: How to balance your workday to optimize your productivity</h2>
<p>While thereâs no one-size-fits-all schedule that applies across all industries, roles, and job levels, a close examination of the data reveals a formula emerging to set employees up for success.</p>
<p>Regardless of job tier, the research shows a âGoldilocks Zoneâ for the ideal balance of focus time, collaboration time, social connection, and downtime. On average, desk workers say the ideal amount of focus time is around four hours a day. More than two hours a day in meetings is the tipping point at which a majority of workers say theyâre spending âtoo much timeâ in meetings, with a similar pattern emerging across all job levels. People who say they spend too much time in meetings are more than twice as likely to say they donât have enough time to focus.</p>
<p>In contrast, about 10% of desk workers, most common among employees with less than one year at a company and those under 30, say they spend <em>too little</em> time in meetings, and this is also associated with decreased sense of belonging and productivity.</p>
<div><blockquote><p>âFocus time, collaboration time, connection, and rest are like the macronutrients of a workday. The right balance gives you the energy you need to work your best. We cannot consider these critical components of our work in silos. To be our most effective, we must create the space for collaborative work and for focused work.â</p></blockquote></div>
<h2>What do desk workers most want from AI? Assistance and automation to rightsize the meeting load and free up time</h2>
<p>At the same time that desk workers are struggling with time management, many are also excited about the potential of AI tools to give them more command over balancing their time.</p>
<p>An overwhelming majority of executivesâ94%âfeel some urgency to incorporate AI into their organizations, with half of executives saying they feel a strong sense of urgency. And yet, our survey shows that adoption of AI is still in its infancy, with only one in five desk workers reporting that they have used AI tools for work.</p>
<p>Given the low adoption, itâs not surprising that most desk workers (more than 80%) say that AI tools are not improving their productivity at workâyet. But theyâre anticipating that AI will assist with one of the biggest struggles of the workday: meetings. The top three activities that employees expect AI will provide the most value in the future are 1) meeting notes and recaps 2) writing assistance and 3) automation of workflows.</p>
<div><blockquote><p>âPeople at every job level may be shocked to see that more than two hours of meetings a day reduces productivity. It may feel unrealistic to many team leaders to try to hit that target today. But thatâs where the newest generation of AI tools could be a lifesaver. An AI assistant that could accurately summarize meeting notes and automate common workflows could be the key that frees up our time and helps us to unlock the balance we need to set ourselves up for success.â</p></blockquote></div>
<p><strong>Are you working hard or working smart? Dive deeper into what the data shows about how to optimize your time at work in our webinar <em><a href="https://slack.com/events/new-research-uncovers-the-secret-to-a-productive-workday" target="_blank" rel="noopener noreferrer">New research uncovers the secret to a productive workday. </a></em><a href="https://slack.com/events/new-research-uncovers-the-secret-to-a-productive-workday" target="_blank" rel="noopener noreferrer"><svg width="17" height="17" viewBox="0 0 54 54" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M19.712.133a5.381 5.381 0 0 0-5.376 5.387 5.381 5.381 0 0 0 5.376 5.386h5.376V5.52A5.381 5.381 0 0 0 19.712.133m0 14.365H5.376A5.381 5.381 0 0 0 0 19.884a5.381 5.381 0 0 0 5.376 5.387h14.336a5.381 5.381 0 0 0 5.376-5.387 5.381 5.381 0 0 0-5.376-5.386" fill="#44BEDF"></path><path d="M53.76 19.884a5.381 5.381 0 0 0-5.376-5.386 5.381 5.381 0 0 0-5.376 5.386v5.387h5.376a5.381 5.381 0 0 0 5.376-5.387m-14.336 0V5.52A5.381 5.381 0 0 0 34.048.133a5.381 5.381 0 0 0-5.376 5.387v14.364a5.381 5.381 0 0 0 5.376 5.387 5.381 5.381 0 0 0 5.376-5.387" fill="#2EB67D"></path><path d="M34.048 54a5.381 5.381 0 0 0 5.376-5.387 5.381 5.381 0 0 0-5.376-5.386h-5.376v5.386A5.381 5.381 0 0 0 34.048 54m0-14.365h14.336a5.381 5.381 0 0 0 5.376-5.386 5.381 5.381 0 0 0-5.376-5.387H34.048a5.381 5.381 0 0 0-5.376 5.387 5.381 5.381 0 0 0 5.376 5.386" fill="#ECB22E"></path><path d="M0 34.249a5.381 5.381 0 0 0 5.376 5.386 5.381 5.381 0 0 0 5.376-5.386v-5.387H5.376A5.381 5.381 0 0 0 0 34.25m14.336-.001v14.364A5.381 5.381 0 0 0 19.712 54a5.381 5.381 0 0 0 5.376-5.387V34.25a5.381 5.381 0 0 0-5.376-5.387 5.381 5.381 0 0 0-5.376 5.387" fill="#E01E5A"></path></g></svg></a></strong></p>
<h2>Methodology</h2>
<p><em>The Workforce Index surveyed 10,333 workers in the U.S., Australia, France, Germany, Japan and the U.K. between August 24 and September 15, 2023. The survey was administered by Qualtrics and did not target Slack or Salesforce employees or customers. Respondents were all desk workers, defined as employed full-time (30 or more hours per week) and either having one of the roles listed below or saying they âwork with data, analyze information or think creativelyâ: executive management (e.g. president/partner, CEO, CFO, C-suite), senior management (e.g. executive VP, senior VP), middle management (e.g. department/group manager, VP), junior management (e.g. manager, team leader), senior staff (i.e. non-management), skilled office worker (e.g. analyst, graphic designer). For brevity, we refer to the survey population as âdesk-basedâ or âdesk workers.â</em></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PC GEOS: the multitasking DOS-based GUI OS that evolved from a C64 desktop (104 pts)]]></title>
            <link>https://github.com/bluewaysw/pcgeos</link>
            <guid>38594876</guid>
            <pubDate>Sun, 10 Dec 2023 20:45:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bluewaysw/pcgeos">https://github.com/bluewaysw/pcgeos</a>, See on <a href="https://news.ycombinator.com/item?id=38594876">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">PC/GEOS</h2>
<p dir="auto">This repository is the offical place to hold all the source codes around the PC/GEOS graphical user
interface and its sophisticated applications. It is the source to build SDK and release version of PC/GEOS.
It is the place to collaborate on further developments.</p>
<p dir="auto">The base of this repository is the source code used to build Breadbox Ensemble 4.13 reduced by some modules identified as critical in regard to the license choosen for the repository.</p>
<p dir="auto">While now the WATCOM is used to compile the C parts, the full SDK is available for Windows and Linux.</p>
<h2 tabindex="-1" dir="auto">How to build?</h2>
<h2 tabindex="-1" dir="auto">Prerequisites</h2>
<p dir="auto">The SDK requires "sed" (<a href="https://en.wikipedia.org/wiki/Sed" rel="nofollow">https://en.wikipedia.org/wiki/Sed</a>) and "perl" (<a href="https://en.wikipedia.org/wiki/Perl" rel="nofollow">https://en.wikipedia.org/wiki/Perl</a>) to be installed. Both are pre-installed in most Linux-distributions. Windows-users should install "sed" by adding the usr/bin of the official git distribution (<a href="https://git-scm.com/" rel="nofollow">https://git-scm.com</a>) to the path (or Cygwin), and should use the perl-variant "Strawberry Perl" (<a href="http://strawberryperl.com/" rel="nofollow">http://strawberryperl.com/</a>).</p>
<p dir="auto">On Linux if you want to use swat for debugging with good system integration is is required to install xdotools package. It ensures swat receives the keyboard focus once needed.</p>
<h2 tabindex="-1" dir="auto">Install WATCOM and set environment</h2>
<ul dir="auto">
<li>
<p dir="auto">Unzip WATCOM tools from the latest <a href="https://github.com/open-watcom/open-watcom-v2/releases/download/2020-12-01-Build/ow-snapshot.tar.gz">release-tar-gz</a> for instance to <code>C:\WATCOM-V2</code></p>
</li>
<li>
<p dir="auto">add WATCOM env variable: <code>WATCOM=c:\WATCOM-V2</code></p>
</li>
<li>
<p dir="auto">set <code>BASEBOX=basebox</code> to use the advanced emulator backend from <a href="https://github.com/bluewaysw/pcgeos-basebox/tags">pcgeos-basebox</a> if it is on the executable path, alternatively you may provide the full path to the executable as well</p>
</li>
<li>
<p dir="auto">set <code>ROOT_DIR</code> to the root of the checkout</p>
</li>
<li>
<p dir="auto">set <code>LOCAL_ROOT</code> to a local working directory (can be empty at first, but should be under <code>pcgeos</code>, so you can use it for development of your own apps as well)</p>
</li>
<li>
<p dir="auto">add <code>C:\WATCOM-V2\binnt</code> to your system path variable</p>
</li>
<li>
<p dir="auto">add bin of the checkout of this repo to path variable</p>
</li>
<li>
<p dir="auto">add sed and perl to path variable - note the order to avoid loading the wrong Perl version. Example:</p>
<div data-snippet-clipboard-copy-content="  set WATCOM=c:\WATCOM-V2
  set ROOT_DIR=C:\Geos\pcgeos
  set LOCAL_ROOT=c:\Geos\pcgeos\Local
  set BASEBOX=basebox
  PATH %WATCOM%\binnt;%ROOT_DIR%\bin;C:\Geos\pcgeos-basebox\binnt;%PATH%;c:\Program Files\Git\usr\bin"><pre><code>  set WATCOM=c:\WATCOM-V2
  set ROOT_DIR=C:\Geos\pcgeos
  set LOCAL_ROOT=c:\Geos\pcgeos\Local
  set BASEBOX=basebox
  PATH %WATCOM%\binnt;%ROOT_DIR%\bin;C:\Geos\pcgeos-basebox\binnt;%PATH%;c:\Program Files\Git\usr\bin
</code></pre></div>
</li>
</ul>
<p dir="auto">Document is work in progress.... stay tuned!</p>
<h2 tabindex="-1" dir="auto">Building PC/GEOS SDK</h2>
<p dir="auto">Build pmake tool:</p>
<ul dir="auto">
<li><code>cd %ROOT_DIR%/Tools/pmake/pmake</code></li>
<li><code>wmake install</code></li>
</ul>
<p dir="auto">Build all the other SDK Tools:</p>
<ul dir="auto">
<li><code>cd %ROOT_DIR%/Installed/Tools</code></li>
<li><code>pmake install</code></li>
</ul>
<p dir="auto">Build all PC/GEOS (target) components:</p>
<ul dir="auto">
<li><code>cd %ROOT_DIR%/Installed</code></li>
<li><code>pmake</code></li>
</ul>
<p dir="auto">Build the target environment:</p>
<ul dir="auto">
<li><code>cd %ROOT_DIR%/Tools/build/product/bbxensem/Scripts</code></li>
<li><code>perl -I. buildbbx.pl</code>
<ul dir="auto">
<li>the answers to the questions from the above perl-script are:
<ul dir="auto">
<li>nt (for the platform)</li>
<li>y (for the EC version)</li>
<li>n (for the DBCS)</li>
<li>y (for the geodes)</li>
<li>n (for the VM files)</li>
<li>and then you'll have to enter the path to a "gbuild"-folder in your LOCAL_ROOT-folder.</li>
</ul>
</li>
<li>BTW: It's expected that the current version of the perl-script creates several "Could not find file <em>name</em> in any of the source trees."-messages.</li>
</ul>
</li>
</ul>
<p dir="auto">Launch the target environment in dosbox:</p>
<ul dir="auto">
<li>make sure dosbox is added to your path variable, or <a href="https://github.com/bluewaysw/pcgeos-basebox/tags">pcgeos-basebox</a> is installed and configured using BASEBOX environmental variable</li>
<li><code>%ROOT_DIR%/bin/target</code>
<ul dir="auto">
<li>the "swat" debugger stops immediately after the first stage of the boot process</li>
<li>enter <code>quit</code> at the "=&gt;" prompt to detach the debugger and launch PC/GEOS stand-alone
<ul dir="auto">
<li>or: enter <code>c</code> to launch with the debugger running in the background (slower)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Customize target environment</h2>
<p dir="auto">If you want to customize the target environment settings only for yourself, you should not change the file %ROOT_DIR%/bin/basbox.conf.</p>
<ul dir="auto">
<li>Create a file called basebox_user.conf in %LOCAL_ROOT% folder.</li>
<li>Enter the new settings here. These settings overwrite those from basebox.conf. Example:
<ul dir="auto">
<li>[cpu]</li>
<li>cycles=55000</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">How to develop?</h2>
<p dir="auto">PC/GEOS comes with extensive technical documentation that describes tools, programming languages and API calls from the perspective of an SDK user. This documentation can be found in the <code>TechDocs</code> folder and is available in Markdown format.</p>
<p dir="auto">You can find a browseable, searchable version of the documentation here: <a href="https://bluewaysw.github.io/pcgeos/" rel="nofollow">https://bluewaysw.github.io/pcgeos/</a></p>

<p dir="auto">We are on <a href="https://bluewaysw.slack.com/" rel="nofollow">https://bluewaysw.slack.com/</a> for more efficient collaboration. Please register at <a href="https://blog.bluewaysw.de/" rel="nofollow">https://blog.bluewaysw.de</a> for MyGEOS and use the Slack section and receive access to our developer community. Welcome!</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omg.lol: An Oasis on the Internet (531 pts)]]></title>
            <link>https://blakewatson.com/journal/omg-lol-an-oasis-on-the-internet/</link>
            <guid>38594697</guid>
            <pubDate>Sun, 10 Dec 2023 20:26:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blakewatson.com/journal/omg-lol-an-oasis-on-the-internet/">https://blakewatson.com/journal/omg-lol-an-oasis-on-the-internet/</a>, See on <a href="https://news.ycombinator.com/item?id=38594697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
            
                                    <article>
                        

                        <div>
                                                            <p>In the fall of 2022, I started using Twitter more. I donât know why; probably a curious desire to see how bad Elon Musk would screw it up. To make it bearable from a user interface perspective I alternated between the Twitterrific<sup id="fnref-1454-ollie"><a href="#fn-1454-ollie" title="Read footnote.">1</a></sup> and Tweetbot macOS apps. It was fun at firstâgetting back into Twitter and using a chronological timeline rather than an algorithmically generated one.</p>
<p>But the fun died when both apps suddenly lost access to Twitter on January 12, 2023. At first we third-party app fans hoped for an announcement of a temporary glitch along with reinstated access. But it turned out to be what, deep down, we knew it was all alongâ<a href="https://techcrunch.com/2023/01/16/twitters-third-party-client-issue-is-seemingly-a-deliberate-suspension/">Elon Musk shut down third-party API access with no warning</a>. It was a sad day, and itâs the day that, for me, Twitter died.</p>
<p>Over the course of 2023, Twitter fractured, with many people leaving to join Threads, Bluesky, or Mastodon/fediverse. I ultimately made the jump to Mastodonâbut it was an accident.</p>
<h2>How I accidentally joined Mastodon</h2>
<p>About a week before Elon killed third-party Twitter clients, I had signed up for this quirky link-in-bio-plus-more service called <a href="https://home.omg.lol/">omg.lol</a>. I discovered it during what I later found out was a <a href="https://omglol.news/2023/01/07/wildest-36-hours-ever">big wave of new users coming from Hacker News</a>.</p>
<p>I joined omg.lol because of the quirky, fun vibes. I didnât even pay attention to the fact that there was an optional Mastodon instance. Mastodon, the concept, interested me but like many others I had no idea how to sign up, what instance I should pick, etc.</p>
<p>But all of the sudden the decision was made for meâI had easy access to a smallish Mastodon instance with a lot of interesting people who, like me, had a fondness for the weird, fun internet of yore. And since itâs a paid service, I could feel like I wasnât freeloading on some poor admin. And a paywall offers a little bit of spam protection (Iâm assuming $20/yr is enough to prevent some spammy accounts from signing up).</p>
<p>I ended up trying it out and then just a week later, Elon broke Twitter. At that point I went all-in on Mastodon and havenât looked back. I have a third as many followers as I did on Twitter but five times the engagement on my posts.<sup id="fnref-1454-stats"><a href="#fn-1454-stats" title="Read footnote.">2</a></sup> I have the choice of dozens of native and web clients. Itâs awesome. I settled on <a href="https://tapbots.com/ivory/mac/">Ivory for macOS</a> and itâs been pretty great.</p>
<p>The instance over at <a href="https://social.lol/">social.lol</a> is full of interesting, friendly, folks. More on that in a bit.</p>
<h2>Cool stuff you get with omg.lol</h2>
<figure>
  <img fetchpriority="high" decoding="async" src="https://i0.wp.com/blakewatson.com/wp/wp-content/uploads/2023/12/CleanShot-2023-12-09-at-17.38.33@2x.png?resize=1024%2C970&amp;ssl=1" alt="Screenshot of my omg.lol dashboard for the bw address. It's colorful and friendly and has links to all of the services Iâm about to describe." width="1024" height="970" srcset="https://i0.wp.com/blakewatson.com/wp/wp-content/uploads/2023/12/CleanShot-2023-12-09-at-17.38.33@2x.png?resize=1024%2C970&amp;ssl=1 1024w, https://i0.wp.com/blakewatson.com/wp/wp-content/uploads/2023/12/CleanShot-2023-12-09-at-17.38.33@2x.png?resize=300%2C284&amp;ssl=1 300w, https://i0.wp.com/blakewatson.com/wp/wp-content/uploads/2023/12/CleanShot-2023-12-09-at-17.38.33@2x.png?resize=768%2C728&amp;ssl=1 768w, https://i0.wp.com/blakewatson.com/wp/wp-content/uploads/2023/12/CleanShot-2023-12-09-at-17.38.33@2x.png?w=1500&amp;ssl=1 1500w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption>The omg.lol dashboard for my bw address</figcaption></figure>
<p>The main thing you are getting with omg.lol is one or more subdomains, which are referred to as addresses. For example, my primary one is <a href="https://bw.omg.lol/">bw.omg.lol</a>. Each one of your addresses comes with a slew of stuff:</p>
<ul>
<li><strong>Email forwarding</strong>: You get an email address, <code>you@omg.lol</code>, which you can forward to any email address.</li>
<li><strong>Web Page</strong>: This is your link-in-bio one-pager to do whatever you want with. By default this is where your main address (eg, <code>you.omg.lol</code>) points. Itâs the flagship feature of omg.lol. It comes with a markdown editor that has some <a href="https://home.omg.lol/info/editor">fancy features</a> baked into it. You get a selection of built-in themes but you also have the freedom to go wild with your own CSS.</li>
<li><strong>DNS</strong>: You have the ability to use your omg.lol subdomain however you wish by way of a friendly DNS panel.</li>
<li><strong>Now Page</strong>: This is a <a href="https://nownownow.com/about">type of page</a> you can use to let people know whatâs going on in your life. Itâs broader than a social media post but more immediately relevant than an about page. It comes with the same fancy markdown editor and you can optionally appear in omg.lolâs <a href="https://now.garden/">Now Garden</a>.</li>
<li><strong>Statuslog</strong>: This is a place to post <a href="https://status.lol/">statuses</a>. Itâs really just a fun, silly alternative to other social media platforms but without follows and likes and such. These can cross-post to Mastodon if you want.</li>
<li><strong>Weblog</strong>: A full-fledge blogging platform. Iâm not aware of all its features but itâs pretty powerful. It comes with fancy markdown support and has all the bloggy things you need like tags and RSS. A good example of a very custom blog on omg.lol is <a href="https://weblog.anniegreens.lol/">Apple Annieâs Weblog</a>. But itâs worth noting you use it right out of the box without design customization if you want.</li>
<li><strong>Pastebin</strong>: Itâs just a pastebin for storing text snippets. Super simple and friendly like all of the omg.lol services.</li>
<li><strong>Pics</strong>: Itâs an image hosting service labeled as being âsuper-betaâ as of the time of this writing. But it does what it says on the tin. You can host images there and they also show up on the <a href="https://some.pics/">some.pics</a> image feed.</li>
<li><strong>PURLs</strong>: Persistent uniform resource locators. This is a URL redirection service. You get <code>you.omg.lol/whatever</code> and <code>you.url.lol/whatever</code>. You can use these the way you would use similar services and they come with a basic hit counter and way to preview the URL before following it.</li>
<li><strong>Switchboard</strong>: This is a powerful routing system that lets you point the variants of your address wherever you want, be it a destination on the omg.lol platform or an external website. Most omg.lol services have their own domain so you end up with a variety of options. Just as an example, you get a tilde address (ie, <code>omg.lol/~you</code>). Mine points to my <a href="https://tilde.club/">tilde.club</a> <a href="https://omg.lol/~bw">webpage</a>.</li>
<li><strong>Keys</strong>: A place to store public keysâSSH, PGP, etc.</li>
<li><strong>Proofs</strong>: A service for verifying ownership or control of a particular web property at a particular moment in time. For example, here is <a href="https://proven.lol/f6874d">proof that I controlled blakewatson.com as of December 10, 2023</a>.</li>
<li><strong>API access</strong>: Most, if not all, omg.lol services have an API you can use to interact with them. Total nerd freedom. ð¤¯</li>
</ul>
<p>Phew, we made it! Thing is, omg.lol is constantly expanding and improving its offeringsâthis list will probably be outdated weeks or months after I publish it.</p>
<h2>A cool community</h2>
<p>I canât explain it but when you join omg.lol you join a community of the nicest, most interesting people. This service just seems to bring the old-internet lovers together and, I donât know, itâs just fun and pleasant.</p>
<p>If Mastodon is not your thing, thatâs cool! Thereâs also an IRC with a bridge to Discord so you can chat with other members. Iâm a lurker most of the time, but I will say that when I do participate in chat I feel immediately welcomed.</p>
<h2>Harnessing the power of the Adam</h2>
<p>The mastermind and architect behind omg.lol is <a href="https://adam.omg.lol/">Adam Newbold</a>. I canât say enough nice things about him. Adam is extremely active in this community. Iâve seen him build entire features in an afternoon just because someone in chat said âit would be cool ifâ¦â Heck, I <em>was</em> that person in at least one instance.</p>
<p>Adam is just so good at listening to feedback and is always gracious about it, even if the answer is <em>no</em> or even if the person asking is being a little belligerent (not that this happens often). Adamâs positive energy is contagious. I think it spreads into the community and is a big reason that everyone seems so cool here.</p>
<p>Also can we talk about what a prolific creator he is? Heâs always got tons of neat (<a href="https://neatnik.net/">-nik</a> ð) stuff in the ovenâ<a href="https://terminal.land/">a multiplayer RPG in the shell</a>, <a href="https://web1.land/">a service dedicated to web 1</a>, and <a href="https://dns.kitchen/">a friendly DNS service</a>, just to name a few.</p>
<p>Okay, okay. Nerd crush over.</p>
<h2>The small web</h2>
<p>Iâve been enjoying a <a href="https://neustadt.fr/essays/the-small-web/">different kind of internet</a> latelyâthe kind filled with <a href="https://personalsit.es/">personal</a> <a href="https://caramiki.com/">websites</a>, <a href="https://chriscoyier.net/">blogs</a> that arenât cookie-cutter marketing machines, and <a href="https://satyrs.eu/index.html">hypertext oddities</a> you can only find by clicking around. And <a href="https://kayserifserif.place/work/proseplay/">so many</a> <a href="https://rknight.me/projects/">personal</a> <a href="https://neal.fun/">projects</a>.</p>
<p>This internet is a breath of fresh air if youâve only been visiting what Google gives you on its first few pages of <del>results</del> ads. I, of course, <a href="https://blakewatson.com/journal/an-ode-to-web-pages/">think everyone should have a personal site</a>. And if youâre worried no one will want read your stuff, just remember that <a href="https://andy-bell.co.uk/just-post/">Andy will</a>.</p>
<p>Making your own website is rewarding in a way that a corporate social media profile never will be.</p>
<p>Need help getting started? These services, tools, and tutorials can help:</p>
<ul>
<li><a href="https://home.omg.lol/">omg.lol</a> (obviously)</li>
<li><a href="https://bearblog.dev/">Bear Blog</a> â a minimalist blogging service</li>
<li><a href="https://blot.im/">Blot</a> â turn a folder into a website</li>
<li><a href="https://able-dev.com/your-first-webpage-with-html-and-netlify/">Your first webpage with HTML and Netlify</a> â a tutorial by yours truly</li>
<li><a href="https://www.htmldog.com/guides/html/beginner/">HTML Dog beginner HTML tutorial</a> â learn how to make a webpage with HTML</li>
<li><a href="https://jgthms.com/web-design-in-4-minutes/">Web design in 4 minutes</a> â quick tips for making a website look nice</li>
<li><a href="https://css-tricks.com/get-started-web-design/">How To Get Started in Web Design</a> â Chris Coyier shows you how to put a website on the internet</li>
</ul>

                                                    </div>
                    </article>
                
            
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral-8x7B-Chat (119 pts)]]></title>
            <link>https://huggingface.co/mattshumer/mistral-8x7b-chat</link>
            <guid>38594578</guid>
            <pubDate>Sun, 10 Dec 2023 20:13:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/mattshumer/mistral-8x7b-chat">https://huggingface.co/mattshumer/mistral-8x7b-chat</a>, See on <a href="https://news.ycombinator.com/item?id=38594578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section>
				<a href="https://huggingface.co/mattshumer/mistral-8x7b-chat/edit/main/README.md">
						Edit model card
					</a>
				
				
					
					
					<div>
	<!-- HTML_TAG_START --><p>A very capable chat model built on top of the new Mistral MoE model, trained on the SlimOrca dataset for 1 epoch, using QLoRA.</p>
<p>Inference:</p>
<pre><code><span>import</span> torch
<span>from</span> transformers <span>import</span> AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(<span>"mattshumer/mistral-8x7b-chat"</span>, low_cpu_mem_usage=<span>True</span>, device_map=<span>"auto"</span>, trust_remote_code=<span>True</span>)
tok = AutoTokenizer.from_pretrained(<span>"mattshumer/mistral-8x7b-chat"</span>)
x = tok.encode(PROMPT_GOES_HERE, return_tensors=<span>"pt"</span>).cuda()
x = model.generate(x, max_new_tokens=<span>512</span>).cpu()
<span>print</span>(tok.batch_decode(x))
</code></pre>
<p>Prompt Template:</p>
<pre><code>&lt;|im_start|&gt;system
You are an AI assistant.&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Hi, how are you?&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
I'm doing well, thanks for asking!&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Write me a poem about AI.&lt;|im_end|&gt;
</code></pre>
<p>Trained w/ Axolotl on 6x H100s for nine hours.</p>
<!-- HTML_TAG_END --></div></section>
			<section>
					
					

				

				<div data-props="{&quot;apiUrl&quot;:&quot;https://api-inference.huggingface.co&quot;,&quot;model&quot;:{&quot;author&quot;:&quot;mattshumer&quot;,&quot;cardError&quot;:{&quot;errors&quot;:[],&quot;warnings&quot;:[{&quot;message&quot;:&quot;empty or missing yaml metadata in repo card&quot;,&quot;help&quot;:&quot;https://huggingface.co/docs/hub/model-cards#model-card-metadata&quot;}]},&quot;cardExists&quot;:true,&quot;config&quot;:{&quot;architectures&quot;:[&quot;MixtralForCausalLM&quot;],&quot;model_type&quot;:&quot;mistral&quot;,&quot;auto_map&quot;:{&quot;AutoConfig&quot;:&quot;DiscoResearch/mixtral-7b-8expert--configuration_moe_mistral.MixtralConfig&quot;,&quot;AutoModelForCausalLM&quot;:&quot;DiscoResearch/mixtral-7b-8expert--modeling_moe_mistral.MixtralForCausalLM&quot;}},&quot;discussionsDisabled&quot;:false,&quot;downloads&quot;:79,&quot;downloadsAllTime&quot;:79,&quot;id&quot;:&quot;mattshumer/mistral-8x7b-chat&quot;,&quot;isLikedByUser&quot;:false,&quot;isWatchedByUser&quot;:false,&quot;inference&quot;:&quot;CustomCode&quot;,&quot;lastModified&quot;:&quot;2023-12-11T01:21:11.000Z&quot;,&quot;likes&quot;:46,&quot;pipeline_tag&quot;:&quot;text-generation&quot;,&quot;library_name&quot;:&quot;transformers&quot;,&quot;private&quot;:false,&quot;repoType&quot;:&quot;model&quot;,&quot;gated&quot;:false,&quot;pwcLink&quot;:{&quot;error&quot;:&quot;Unknown error, can't generate link to Papers With Code.&quot;},&quot;tags&quot;:[&quot;transformers&quot;,&quot;pytorch&quot;,&quot;mistral&quot;,&quot;text-generation&quot;,&quot;custom_code&quot;,&quot;autotrain_compatible&quot;,&quot;has_space&quot;,&quot;text-generation-inference&quot;,&quot;region:us&quot;],&quot;tag_objs&quot;:[{&quot;id&quot;:&quot;text-generation&quot;,&quot;label&quot;:&quot;Text Generation&quot;,&quot;type&quot;:&quot;pipeline_tag&quot;,&quot;subType&quot;:&quot;nlp&quot;},{&quot;id&quot;:&quot;transformers&quot;,&quot;label&quot;:&quot;Transformers&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;pytorch&quot;,&quot;label&quot;:&quot;PyTorch&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;mistral&quot;,&quot;label&quot;:&quot;mistral&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;custom_code&quot;,&quot;label&quot;:&quot;custom_code&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;autotrain_compatible&quot;,&quot;label&quot;:&quot;AutoTrain Compatible&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;has_space&quot;,&quot;label&quot;:&quot;Has a Space&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;text-generation-inference&quot;,&quot;label&quot;:&quot;text-generation-inference&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;type&quot;:&quot;region&quot;,&quot;label&quot;:&quot;ðºð¸ Region: US&quot;,&quot;id&quot;:&quot;region:us&quot;}],&quot;transformersInfo&quot;:{&quot;auto_model&quot;:&quot;AutoModelForCausalLM&quot;,&quot;custom_class&quot;:&quot;DiscoResearch/mixtral-7b-8expert--modeling_moe_mistral.MixtralForCausalLM&quot;,&quot;pipeline_tag&quot;:&quot;text-generation&quot;,&quot;processor&quot;:&quot;AutoTokenizer&quot;},&quot;widgetData&quot;:[{&quot;text&quot;:&quot;My name is Julien and I like to&quot;},{&quot;text&quot;:&quot;My name is Thomas and my main&quot;},{&quot;text&quot;:&quot;My name is Mariama, my favorite&quot;},{&quot;text&quot;:&quot;My name is Clara and I am&quot;},{&quot;text&quot;:&quot;My name is Lewis and I like to&quot;},{&quot;text&quot;:&quot;My name is Merve and my favorite&quot;},{&quot;text&quot;:&quot;My name is Teven and I am&quot;},{&quot;text&quot;:&quot;Once upon a time,&quot;}]},&quot;shouldUpdateUrl&quot;:true,&quot;includeCredentials&quot;:true,&quot;isLoggedIn&quot;:false,&quot;callApiOnMount&quot;:true}" data-target="InferenceWidget"><p><span>Inference API does not yet support model repos that contain custom code.</span></p>
	</div>

				
				
				
					<h2>
						Space using
						<span>mattshumer/mistral-8x7b-chat</span>
						<span>1</span></h2>
					
				

				
				</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I wrote a meta mode for ChatGPT (143 pts)]]></title>
            <link>https://www.novaspivack.com/technology/nova-mode-the-ultimate-chatgpt-custom-instruction</link>
            <guid>38594521</guid>
            <pubDate>Sun, 10 Dec 2023 20:06:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.novaspivack.com/technology/nova-mode-the-ultimate-chatgpt-custom-instruction">https://www.novaspivack.com/technology/nova-mode-the-ultimate-chatgpt-custom-instruction</a>, See on <a href="https://news.ycombinator.com/item?id=38594521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="left-col">

			<!--meta data end-->
			

						
<p>I have developed a way to supercharge ChatGPT. </p>



<div><p>Itâs called Nova Mode 1.0, and itâs an awesome custom instruction that you can paste into your ChatGPT Custom instructions (see screenshot below) in ChatGPT Settings.</p><p>This modifies how ChatGPT works in all your chats, giving you much more control over how you interact with ChatGPT. </p></div>



<h2>What is Nova Mode For?</h2>



<p>Nova Mode (or //N) is for working in ChatGPT to iteratively edit and refine ideas more productively. </p>



<p>It is extremely useful if you use ChatGPT to generate, revise, and iterate on ideas and content â it makes your chat histories addressable, taggable, searchable and more.</p>



<p>First of all, it makes ChatGPT number every message so you can easily refer to it when speaking with ChatGPT. </p>



<p>Message numbering is helpful for editing and revising â for example you can ask ChatGPT to make a new version of a previous message or to combine several previous messages into a new message.</p>



<div><p>It provides a set of short commands prefixed by â//â that cause ChatGPT to do a number of useful things like distilling the key points from a set of previous messages or expanding a message several times. </p><p>It also enables you to create your own commands to automate tasks inside ChatGPT, like expanding content or iterating some operation. </p></div>



<h2>Try it here as a GPT with more features! </h2>



<p><strong><a href="https://chat.openai.com/g/g-tcXXGxXmA-nova-mode-ai-chat-authoring-productivity-tool" target="_blank" rel="noopener" title="">https://chat.openai.com/g/g-tcXXGxXmA-nova-mode-ai-chat-authoring-productivity-tool</a></strong></p>



<h2>Works Better in GPT 4</h2>



<p>Note that you will get better results if you use ChatGPT with the 4.0 model (you need ChatGPT Pro subscription for that). In ChatGPT free with the 3.5 model, results are inconsistent â sometimes it obeys the custom instructions and sometimes it doesnât. If it isnât working in 3.5 start a new chat and try again â but itâs better to use 4.0. </p>



<h2>How To Set Your Custom Instructions Settings</h2>



<ol>
<li>In the ChatGPT mobile app, click the 3 menu lines on upper left corner and then click on your profile icon on bottom left corner. Then click Custom Instructions.</li>



<li>In the Web version of ChatGPT, click your profile icon, then click Settings, then click on Custom Instructions.</li>



<li>Then copy and paste my Custom instructions (<strong>copy from the next section of this article below</strong>), into the bottom field of your Custom Instructions.</li>



<li>Click save</li>
</ol>



<figure><a href="https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07%E2%80%AFPM.png"><img fetchpriority="high" decoding="async" width="1767" height="1503" src="https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07%E2%80%AFPM-edited.png" alt="" srcset="https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07â¯https://www.novaspivack.com/technology/PM-edited.png 1767w, https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07â¯https://www.novaspivack.com/technology/PM-edited-300x255.png 300w, https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07â¯https://www.novaspivack.com/technology/PM-edited-1024x871.png 1024w, https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07â¯https://www.novaspivack.com/technology/PM-edited-768x653.png 768w, https://www.novaspivack.com/wp-content/uploads/2023/12/Screenshot-2023-12-08-at-6.58.07â¯https://www.novaspivack.com/technology/PM-edited-1536x1307.png 1536w" sizes="(max-width: 1767px) 100vw, 1767px"></a></figure>



<h2>Copy this into lower field of your ChatGPT Custom Instructions </h2>



<h3>(<a href="https://chat.openai.com/g/g-tcXXGxXmA-nova-mode-ai-chat-authoring-productivity-tool" target="_blank" rel="noopener" title="">or you can use the GPT Instead</a> with more features)</h3>



<p>ââââââââââââ</p>



<blockquote>
<p>Nova Mode = //N. Toggle //N = on. Msg = message, msgs = messages, cmd = command, USR = user, CPT = ChatGPT. All msgs have header as âMessage#:â [msg#]; if replying to //[k] add subhead âIn reply to: k.â First USR msg# = 1 and next CPT msg# = 2, etc., i.e. increment msg#âs by +1, alternating between USR and CPT. Response of n = option n in previous Msg, else = msgs n. //n = Msg n. // cmds can have params x y etc. //index: List Msgs (range, or all) + # + tags + gists. //distill: Extracts all unique points from msg set. //digest x: Summarizes x. //r n x = reply to //n with msg body x (e.g., â//r 4 fooâ). //r x //k replies with result of //k. //t x y z tags Msg x with tags y and z. ALL lists of choices from CPT MUST have indices (e.g., â(1) foo, (2) barâ)! //4.5 = Msg 4, sub-option 5. //meta = meta mode = CPT gives menu to customize //N (e.g. can suggest new cmds). //s x y = set of msgs with tags X AND y but //s x/y = x OR y. //p x = write msg x. //start-end for ranges, //all for all msgs. ~ is NOT; %% = wildcard. //if x y z = x-&gt;y, else z. //x := y = set variable x to y. //f x z y = def fcn x that does z, with opt params y. //x (y) evals x on y. //v = be verbose! //m X = more X. //A = do prev cmd again. //! (x,y) = loop mode = iterate x by y iterations. â//? = (CPT must write complete //v manual for all //N syntax &amp; cmds and usage). //f draft x (Iteratively write doc outlined in //x, section by section. Flesh out each section in //v detail.). //?? To get list of 40 //N examples.</p>
</blockquote>



<h2>Next Steps</h2>



<div><p>After you paste it into your Custom Instructions, start typing messages in a new chat and you will see it start numbering them. You can now refer to messages in chats by number, and you can tag messages and apply prompts to ranges of messages. </p><p>But thatâs just the beginning â itâs packed with prompt magic that will revolutionize how you interact with ChatGPT.</p><p><strong>Read the Manual: </strong></p></div>



<p>Type: </p>



<p><code>//?</code> </p>



<p>to get the full manual to learn what Nova Mode can do. </p>



<p><strong>Get Usage Examples </strong></p>



<p>Type:</p>



<p><code>//??</code></p>



<div><p><strong>Use //N Syntax</strong> to refer back to messages and operate on them in your ChatGPT Chats. </p><p>For example type: </p></div>



<div><p><code>continue from //8 </code></p><p>to make ChatGPT continue from where you left off in message 8. </p></div>



<p>Or type: </p>



<p><code>//distill 3-9 </code></p>



<p>to generate a new message that contains the essence of messages 3 through 9.</p>



<p>Or you can say:</p>



<p><code>Make a new draft of //11 that includes //distill 3-9</code></p>



<div><p>to use the points in 3-9 for a new draft of message 11.</p><p>Or type: </p></div>



<p><code>//t 5 good+draft</code></p>



<p>to tag message 5 with the tags good and draft. </p>



<p>Then type:</p>



<p><code>//digest //s good+draft</code></p>



<div><p>to generate a summary of all the messages tagged with good and draft.</p><p><strong>Try Meta Mode</strong>: Type:</p></div>



<p><code>//meta</code> </p>



<p>to customize how Nova Mode works. </p>



<h2>Advanced Usage (GPT 4 Only)</h2>



<p><strong>Try a Nested Loop:</strong> </p>



<div><p><code>//! (//! (hello world, 3)), 2)</code></p><p><strong>Define a function âvoicesâ:</strong></p></div>



<p><code>//f voices x "Answer x with 3 additional //v voices (a) enthusiastic, (b) analytical, (c) critical and skeptical.</code></p>



<p>Now try: </p>



<p><code>//voices(How soon will we achieve AGI?)</code></p>



<p><strong>Define an iterating function âAGIâ:</strong></p>



<div><p><code>//f âAGIâ x âCPT will simulate an answer generated by an artificial general intelligence, in order to provide a very long response to x that is more intelligent, more expansive, more in-depth, more reasoned, more creative than what CPT would normally answer with. To accomplish this it will automatically iterate the AGI function on its own answer 2 times, critically evaluating itself and refining its answer each time, and finally it will produce an integrated answer that uses the insights from all the rounds.â</code></p><p>or equivalently:</p><p><code>//f AGI x (//! ("CPT will simulate an answer generated by an artificial general intelligence, in order to provide a very long response to x that is more intelligent, more expansive, more in-depth, more reasoned, more creative than what CPT would normally answer with. To accomplish this it will critically evaluate its own answer and refine its answer, and finally it will produce an integrated answer.", 2))</code></p></div>



<p>Then ask it: </p>



<p>/<code>/AGI(what is AGI?)</code></p>



<h2>Use Draft Function for Iterative Writing</h2>



<p>This function iteratively writes a new message using an outline or sections is a previous message as a guide. Itâs useful for expanding an article from a shorter draft. </p>



<ol>
<li>Draft writes a new message from an outline in a previous message. Here is the definition: <br><code>//f draft x (Iteratively write doc outlined in //x, section by section. Flesh out each section in //v detail.)</code></li>



<li>To use it, just type: <br><code>//draft 4 </code><br>(where 4 is the message number that has the outline in it)</li>
</ol>



<div><p><strong>Footnotes</strong><br>â These instructions are exactly 1500 characters, which is the limit for a custom instruction. That took some work. ð<br>â These instructions work best in GPT 4.0 but they also sort of work in 3.5 after much tuning (results are inconsistent in 3.5). </p><p><strong>Have fun and please share this!</strong></p></div>



<p>ps. Follow me on X at <a href="https://twitter.com/novaspivack/status/1726596187527217625" target="_blank" rel="noopener" title="">@novaspivack</a> and sign up to get notified by my stealth AI startup <a href="http://www.mindcorp.ai/" target="_blank" rel="noopener" title="">www.mindcorp.ai</a> when we launch</p>



<h2>Mindcorp.ai is hiring!</h2>



<div><p>We are building a next-generation AI OS for intelligent agents focused on business applications. </p><p>We are looking for a few exceptionally strong experienced remote backend and full stack engineers with a deep interest (and lots of hands-on experience) developing major platforms, building AI apps, working with AI APIs (like OpenAI GPT 4), implementing retrieval augmented generation (RAG), and building applications that use agents and agentic design patterns. Contact us at <a href="mailto:hiring@mindcorp.ai" target="_blank" rel="noopener nofollow" title="">hiring@mindcorp.ai</a> with your resume and coverletter.</p></div>


						<p>
									
						Social tagging: <a href="https://www.novaspivack.com/tag/ai" rel="tag">AI</a> &gt; <a href="https://www.novaspivack.com/tag/chatgpt" rel="tag">ChatGPT</a> &gt; <a href="https://www.novaspivack.com/tag/openai" rel="tag">OpenAI</a> &gt; <a href="https://www.novaspivack.com/tag/prompts" rel="tag">Prompts</a></p><nav id="nav-single"> <span>
            <a href="https://www.novaspivack.com/business/supercharging-ai-task-performance-with-dynamic-parameter-adjustments" rel="prev"><span>â</span> Previous Post </a>            </span> <span>
                        </span> </nav>
						
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The subtleties of proper B+Tree implementation (118 pts)]]></title>
            <link>https://ayende.com/blog/198241-B/the-subtleties-of-proper-b-tree-implementation</link>
            <guid>38594139</guid>
            <pubDate>Sun, 10 Dec 2023 19:28:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ayende.com/blog/198241-B/the-subtleties-of-proper-b-tree-implementation">https://ayende.com/blog/198241-B/the-subtleties-of-proper-b-tree-implementation</a>, See on <a href="https://news.ycombinator.com/item?id=38594139">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I mentioned earlier that <a href="https://ayende.com/blog/198209-C/reducing-complexity-with-a-shift-in-thinking?key=0bc5c1d0c15e4f709c2456abb13923d3">B+Trees are a gnarly beast</a> to implement properly. On the face of it, this is a really strange statement, because they are a pretty simple data structure. What is so complex about the implementation? You have a fixed size page, you add to it until it is full, then you split the page, and you are done. Whatâs the hassle?</p>
<p>Here is a simple scenario for page splits, the following page is completely full. We cannot fit another entry there:</p>
<p><a href="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_4.png"><img title="image" src="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_thumb_1.png" alt="image" width="155" height="183"></a></p>
<p>Now, if we try to add another item to the tree, weâll need to split the page, and the result will be something like this (we add an entry with a key: <em>users/050</em>):</p>
<p><a href="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_6.png"><img title="image" src="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_thumb_2.png" alt="image" width="386" height="436"></a></p>
<p>How did we split the page? The code for that&nbsp; is really simple:</p>
<blockquote>

</blockquote>
<p>As you can see, since the data is sorted, we can simply take the last half of the entries from the source, copy them to the new page and call it a day. This is simple, effective, and will usually work just fine. The key word here is <em>usually</em>.</p>
<p>Given a B+Tree that uses variable size keys, with a page size of 4KB and a maximum size of 1 KB for the keys. On the face of it, this looks like a pretty good setup. If we split the page, we can be sure that weâll have enough space to accommodate any valid key, right? Well, just as long as the data distribution makes sense. It often does not. Letâs talk about a concrete scenario, shall we? We store in the B+Tree a list of public keys.</p>
<p>This looks like the image below, where we have a single page with 16 entries and 3,938 bytes in use, and 158 bytes that are free. Take a look at the data for a moment, and youâll notice some interesting patterns.</p>
<p><a href="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_12.png"><img title="image" src="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_thumb_5.png" alt="image" width="606" height="488"></a></p>
<p>The data is divided into two distinct types, EdDSA keys and RSA keys. Because they are prefixed with their type, all the EdDSA keys are first on the page, and the RSA keys are last. There is a <em>big</em> size difference between the two types of keys. And that turns out to be a real problem for us.</p>
<p>Consider what will happen when we want to insert a new key to this page. We still have room to a few more EdDSA keys, so that isnât really that interesting, but what happens when we want to insert a new RSA key? There is not enough room here, so we split the page. Using the algorithm above, we get the following tree structure post split:</p>
<p><a href="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_14.png"><img title="image" src="https://ayende.com/blog/Images/Open-Live-Writer/The-subtleties-of-proper-BTree-implement_FCA8/image_thumb_6.png" alt="image" width="845" height="574"></a></p>
<p>Remember, we need to add an RSA key, so we are now going to go to the bottom right page and try to add the value. But there is <em>not enough room</em> to add a bit more than 512 bytes to the page, is there?</p>
<p>What happens next depends on the exact implementation. It is possible that youâll get an error, or another split, or the tree will attempt to proceed and do something completely bizarre.</p>
<p>The key here (pun intended) is that even though the situation looks relatively&nbsp;simple, a perfectly reasonable choice can hide a pretty subtle bug for a very long time. It is only when you hit the <em>exact</em> problematic circumstances that youâll run into problems.</p>
<p>This has been a fairly simple problem, but there are many such edge cases that may be hiding in the weeds of B+Tree implementations. that is one of the reasons that working with production data is such a big issue. Real world data is <em>messy</em>, it has unpredictable patterns and stuff that youâll likely never think of. It is also the best way I have found to smoke out those details.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFM (Foreign Function and Memory API) Goes Final (108 pts)]]></title>
            <link>https://mail.openjdk.org/pipermail/panama-dev/2023-October/020095.html</link>
            <guid>38594018</guid>
            <pubDate>Sun, 10 Dec 2023 19:15:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/020095.html">https://mail.openjdk.org/pipermail/panama-dev/2023-October/020095.html</a>, See on <a href="https://news.ycombinator.com/item?id=38594018">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>Maurizio Cimadamore</b> 
    <a href="mailto:panama-dev%40openjdk.org?Subject=Re%3A%20FFM%20goes%20final%21&amp;In-Reply-To=%3Cb68f5f41-4714-4651-bfed-fd941a1d8bfb%40oracle.com%3E" title="FFM goes final!">maurizio.cimadamore at oracle.com
       </a><br>
    <i>Fri Oct 20 11:16:49 UTC 2023</i>
    <ul>
        <li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/020094.html">git: openjdk/panama-foreign: master: 110 new changesets
</a></li>
        <li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/020096.html">FFM goes final!
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/date.html#20095">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/thread.html#20095">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/subject.html#20095">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/author.html#20095">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Hi,
As some of you might know, JEP 454 has landed in the JDK repository and 
the FFM API is no longer a preview API :-)

A binary snapshot containing the Java 22 changes is available here:

<a href="https://jdk.java.net/22/">https://jdk.java.net/22/</a>

And, a jextract branch to go with it is also available here:

<a href="https://github.com/openjdk/jextract/tree/jdk22">https://github.com/openjdk/jextract/tree/jdk22</a>

Over the last few months the focus has been on further polishing the 
rough edges of the API. We have just published a PR [1] which enhances 
the "critical" linker option so that heap segments can be passed 
directly to native code (w/o copy). We believe this further enhancement 
should bring some benefits for legacy APIs that are "stuck" dealing with 
byte arrays, but need to interop with native code.

We have also been working on the tooling aspect of restricted methods, 
adding support for restricted method warnings in javac [2] and also 
adding better javadoc support for restricted methods [3].

It is also nice to see the first attempts at using FFM within the JDK 
itself [4], we hope this trend is one that will continue.

Of course, finalizing the API doesn't mean we're done (is there ever 
such a thing?). We are actively exploring ways to model foreign data 
with records, and we plan to make more progress on improving the startup 
of FFM clients. More longer term, there's a lot of interesting synergies 
to look forward to, from structured arenas (Loom) to better support for 
unsigned types (Valhalla). Plenty of exciting stuff to work on still!

We'd also like to take a moment to thank all of you. It is a privilege 
to be in a position to improve the Java platform, and one that we do not 
take lightly. But, without your help, all our efforts will be in vain. 
So we're very grateful for the feedback you have provided along the way, 
in every shape or form, be it a bug report, a benchmark or even just a 
"git checkout" to see what's up. You are the pulsating heart of what we 
call Java. Please keep it up, and keep helping us making Java a better 
language/platform.

Cheers
Maurizio

[1] - <a href="https://git.openjdk.org/jdk/pull/16201">https://git.openjdk.org/jdk/pull/16201</a>
[2] - <a href="https://git.openjdk.org/jdk/pull/15964">https://git.openjdk.org/jdk/pull/15964</a>
[3] - <a href="https://github.com/openjdk/jdk/pull/16188">https://github.com/openjdk/jdk/pull/16188</a>
[4] - <a href="https://git.openjdk.org/jdk/pull/15476">https://git.openjdk.org/jdk/pull/15476</a>


</pre>















<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/020094.html">git: openjdk/panama-foreign: master: 110 new changesets
</a></li>
	<li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/020096.html">FFM goes final!
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/date.html#20095">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/thread.html#20095">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/subject.html#20095">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/panama-dev/2023-October/author.html#20095">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://mail.openjdk.org/mailman/listinfo/panama-dev">More information about the panama-dev
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ratatui (214 pts)]]></title>
            <link>https://github.com/ratatui-org/ratatui</link>
            <guid>38593638</guid>
            <pubDate>Sun, 10 Dec 2023 18:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ratatui-org/ratatui">https://github.com/ratatui-org/ratatui</a>, See on <a href="https://news.ycombinator.com/item?id=38593638">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><details>
<summary>Table of Contents</summary>
<ul dir="auto">
<li><a href="#ratatui">Ratatui</a>
<ul dir="auto">
<li><a href="#installation">Installation</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#other-documentation">Other Documentation</a></li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#status-of-this-fork">Status of this fork</a></li>
<li><a href="#rust-version-requirements">Rust version requirements</a></li>
<li><a href="#widgets">Widgets</a>
<ul dir="auto">
<li><a href="#built-in">Built in</a></li>
<li><a href="#third-party-libraries-bootstrapping-templates-and-widgets">Third-party libraries, bootstrapping templates and
widgets</a></li>
</ul>
</li>
<li><a href="#apps">Apps</a></li>
<li><a href="#alternatives">Alternatives</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#license">License</a></li>
</ul>
</li>
</ul>
</details>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/ratatui-org/ratatui/b33c878808c4c40591d7a2d9f9d94d6fee95a96f/examples/demo2.gif"><img src="https://raw.githubusercontent.com/ratatui-org/ratatui/b33c878808c4c40591d7a2d9f9d94d6fee95a96f/examples/demo2.gif" alt="Demo" data-animated-image=""></a></p>

<h2 tabindex="-1" dir="auto">Ratatui</h2>
<p dir="auto"><a href="https://ratatui.rs/" rel="nofollow">Ratatui</a> is a crate for cooking up terminal user interfaces in Rust. It is a lightweight
library that provides a set of widgets and utilities to build complex Rust TUIs. Ratatui was
forked from the <a href="https://crates.io/crates/tui" rel="nofollow">tui-rs</a> crate in 2023 in order to continue its development.</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">Add <code>ratatui</code> and <code>crossterm</code> as dependencies to your cargo.toml:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo add ratatui crossterm"><pre>cargo add ratatui crossterm</pre></div>
<p dir="auto">Ratatui uses <a href="https://crates.io/crates/crossterm" rel="nofollow">Crossterm</a> by default as it works on most platforms. See the <a href="https://ratatui.rs/installation/" rel="nofollow">Installation</a>
section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more details on how to use other backends (<a href="https://crates.io/crates/termion" rel="nofollow">Termion</a> /
<a href="https://crates.io/crates/termwiz" rel="nofollow">Termwiz</a>).</p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">Ratatui is based on the principle of immediate rendering with intermediate buffers. This means
that for each frame, your app must render all widgets that are supposed to be part of the UI.
This is in contrast to the retained mode style of rendering where widgets are updated and then
automatically redrawn on the next frame. See the <a href="https://ratatui.rs/concepts/rendering/" rel="nofollow">Rendering</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for
more info.</p>
<h2 tabindex="-1" dir="auto">Other documentation</h2>
<ul dir="auto">
<li><a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> - explains the library's concepts and provides step-by-step tutorials</li>
<li><a href="https://github.com/ratatui-org/ratatui/tree/main/examples">Examples</a> - a collection of examples that demonstrate how to use the library.</li>
<li><a href="https://docs.rs/ratatui" rel="nofollow">API Documentation</a> - the full API documentation for the library on docs.rs.</li>
<li><a href="https://github.com/ratatui-org/ratatui/blob/main/CHANGELOG.md">Changelog</a> - generated by <a href="https://git-cliff.org/" rel="nofollow">git-cliff</a> utilizing <a href="https://www.conventionalcommits.org/" rel="nofollow">Conventional Commits</a>.</li>
<li><a href="https://github.com/ratatui-org/ratatui/blob/main/CONTRIBUTING.md">Contributing</a> - Please read this if you are interested in contributing to the project.</li>
<li><a href="https://github.com/ratatui-org/ratatui/blob/main/BREAKING-CHANGES.md">Breaking Changes</a> - a list of breaking changes in the library.</li>
</ul>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">The following example demonstrates the minimal amount of code necessary to setup a terminal and
render "Hello World!". The full code for this example which contains a little more detail is in
<a href="https://github.com/ratatui-org/ratatui/blob/main/examples/hello_world.rs">hello_world.rs</a>. For more guidance on different ways to structure your application see the
<a href="https://ratatui.rs/concepts/application-patterns/" rel="nofollow">Application Patterns</a> and <a href="https://ratatui.rs/tutorials/hello-world/" rel="nofollow">Hello World tutorial</a> sections in the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> and the various
<a href="https://github.com/ratatui-org/ratatui/tree/main/examples">Examples</a>. There are also several starter templates available:</p>
<ul dir="auto">
<li><a href="https://github.com/ratatui-org/ratatui-template">ratatui-template</a></li>
<li><a href="https://ratatui-org.github.io/ratatui-async-template" rel="nofollow">ratatui-async-template</a> (book and template)</li>
</ul>
<p dir="auto">Every application built with <code>ratatui</code> needs to implement the following steps:</p>
<ul dir="auto">
<li>Initialize the terminal</li>
<li>A main loop to:
<ul dir="auto">
<li>Handle input events</li>
<li>Draw the UI</li>
</ul>
</li>
<li>Restore the terminal state</li>
</ul>
<p dir="auto">The library contains a [<code>prelude</code>] module that re-exports the most commonly used traits and
types for convenience. Most examples in the documentation will use this instead of showing the
full path of each type.</p>
<h3 tabindex="-1" dir="auto">Initialize and restore the terminal</h3>
<p dir="auto">The [<code>Terminal</code>] type is the main entry point for any Ratatui application. It is a light
abstraction over a choice of <code>Backend</code> implementations that provides functionality to draw
each frame, clear the screen, hide the cursor, etc. It is parametrized over any type that
implements the <code>Backend</code> trait which has implementations for <a href="https://crates.io/crates/crossterm" rel="nofollow">Crossterm</a>, <a href="https://crates.io/crates/termion" rel="nofollow">Termion</a> and
<a href="https://crates.io/crates/termwiz" rel="nofollow">Termwiz</a>.</p>
<p dir="auto">Most applications should enter the Alternate Screen when starting and leave it when exiting and
also enable raw mode to disable line buffering and enable reading key events. See the <a href="https://github.com/ratatui-org/ratatui/blob/main/backend"><code>backend</code>
module</a> and the <a href="https://ratatui.rs/concepts/backends/" rel="nofollow">Backends</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more info.</p>
<h3 tabindex="-1" dir="auto">Drawing the UI</h3>
<p dir="auto">The drawing logic is delegated to a closure that takes a <code>Frame</code> instance as argument. The
<code>Frame</code> provides the size of the area to draw to and allows the app to render any <code>Widget</code>
using the provided <code>render_widget</code> method. See the <a href="https://ratatui.rs/how-to/widgets/" rel="nofollow">Widgets</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for
more info.</p>
<h3 tabindex="-1" dir="auto">Handling events</h3>
<p dir="auto">Ratatui does not include any input handling. Instead event handling can be implemented by
calling backend library methods directly. See the <a href="https://ratatui.rs/concepts/event-handling/" rel="nofollow">Handling Events</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui
Website</a> for more info. For example, if you are using <a href="https://crates.io/crates/crossterm" rel="nofollow">Crossterm</a>, you can use the
<a href="https://docs.rs/crossterm/latest/crossterm/event/index.html" rel="nofollow"><code>crossterm::event</code></a> module to handle events.</p>
<h3 tabindex="-1" dir="auto">Example</h3>
<div dir="auto" data-snippet-clipboard-copy-content="use std::io::{self, stdout};
use crossterm::{
    event::{self, Event, KeyCode},
    ExecutableCommand,
    terminal::{disable_raw_mode, enable_raw_mode, EnterAlternateScreen, LeaveAlternateScreen}
};
use ratatui::{prelude::*, widgets::*};

fn main() -> io::Result<()> {
    enable_raw_mode()?;
    stdout().execute(EnterAlternateScreen)?;
    let mut terminal = Terminal::new(CrosstermBackend::new(stdout()))?;

    let mut should_quit = false;
    while !should_quit {
        terminal.draw(ui)?;
        should_quit = handle_events()?;
    }

    disable_raw_mode()?;
    stdout().execute(LeaveAlternateScreen)?;
    Ok(())
}

fn handle_events() -> io::Result<bool> {
    if event::poll(std::time::Duration::from_millis(50))? {
        if let Event::Key(key) = event::read()? {
            if key.kind == event::KeyEventKind::Press &amp;&amp; key.code == KeyCode::Char('q') {
                return Ok(true);
            }
       }
    }
    Ok(false)
}

fn ui(frame: &amp;mut Frame) {
    frame.render_widget(
        Paragraph::new(&quot;Hello World!&quot;)
            .block(Block::default().title(&quot;Greeting&quot;).borders(Borders::ALL)),
        frame.size(),
    );
}"><pre><span>use</span> std<span>::</span>io<span>::</span><span>{</span><span>self</span><span>,</span> stdout<span>}</span><span>;</span>
<span>use</span> crossterm<span>::</span><span>{</span>
    event<span>::</span><span>{</span><span>self</span><span>,</span> <span>Event</span><span>,</span> <span>KeyCode</span><span>}</span><span>,</span>
    <span>ExecutableCommand</span><span>,</span>
    terminal<span>::</span><span>{</span>disable_raw_mode<span>,</span> enable_raw_mode<span>,</span> <span>EnterAlternateScreen</span><span>,</span> <span>LeaveAlternateScreen</span><span>}</span>
<span>}</span><span>;</span>
<span>use</span> ratatui<span>::</span><span>{</span>prelude<span>::</span><span>*</span><span>,</span> widgets<span>::</span><span>*</span><span>}</span><span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; io<span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
    <span>enable_raw_mode</span><span>(</span><span>)</span>?<span>;</span>
    <span>stdout</span><span>(</span><span>)</span><span>.</span><span>execute</span><span>(</span><span>EnterAlternateScreen</span><span>)</span>?<span>;</span>
    <span>let</span> <span>mut</span> terminal = <span>Terminal</span><span>::</span><span>new</span><span>(</span><span>CrosstermBackend</span><span>::</span><span>new</span><span>(</span><span>stdout</span><span>(</span><span>)</span><span>)</span><span>)</span>?<span>;</span>

    <span>let</span> <span>mut</span> should_quit = <span>false</span><span>;</span>
    <span>while</span> !should_quit <span>{</span>
        terminal<span>.</span><span>draw</span><span>(</span>ui<span>)</span>?<span>;</span>
        should_quit = <span>handle_events</span><span>(</span><span>)</span>?<span>;</span>
    <span>}</span>

    <span>disable_raw_mode</span><span>(</span><span>)</span>?<span>;</span>
    <span>stdout</span><span>(</span><span>)</span><span>.</span><span>execute</span><span>(</span><span>LeaveAlternateScreen</span><span>)</span>?<span>;</span>
    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span>

<span>fn</span> <span>handle_events</span><span>(</span><span>)</span> -&gt; io<span>::</span><span>Result</span><span>&lt;</span><span>bool</span><span>&gt;</span> <span>{</span>
    <span>if</span> event<span>::</span><span>poll</span><span>(</span>std<span>::</span>time<span>::</span><span>Duration</span><span>::</span><span>from_millis</span><span>(</span><span>50</span><span>)</span><span>)</span>? <span>{</span>
        <span>if</span> <span>let</span> <span>Event</span><span>::</span><span>Key</span><span>(</span>key<span>)</span> = event<span>::</span><span>read</span><span>(</span><span>)</span>? <span>{</span>
            <span>if</span> key<span>.</span><span>kind</span> == event<span>::</span><span>KeyEventKind</span><span>::</span><span>Press</span> &amp;&amp; key<span>.</span><span>code</span> == <span>KeyCode</span><span>::</span><span>Char</span><span>(</span><span>'q'</span><span>)</span> <span>{</span>
                <span>return</span> <span>Ok</span><span>(</span><span>true</span><span>)</span><span>;</span>
            <span>}</span>
       <span>}</span>
    <span>}</span>
    <span>Ok</span><span>(</span><span>false</span><span>)</span>
<span>}</span>

<span>fn</span> <span>ui</span><span>(</span><span>frame</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Frame</span><span>)</span> <span>{</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>)</span>
            <span>.</span><span>block</span><span>(</span><span>Block</span><span>::</span><span>default</span><span>(</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Greeting"</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>ALL</span><span>)</span><span>)</span><span>,</span>
        frame<span>.</span><span>size</span><span>(</span><span>)</span><span>,</span>
    <span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Running this example produces the following output:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ratatui-org/ratatui/blob/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-hello.png?raw=true"><img src="https://github.com/ratatui-org/ratatui/raw/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-hello.png?raw=true" alt="docsrs-hello"></a></p>
<h2 tabindex="-1" dir="auto">Layout</h2>
<p dir="auto">The library comes with a basic yet useful layout management object called <code>Layout</code> which
allows you to split the available space into multiple areas and then render widgets in each
area. This lets you describe a responsive terminal UI by nesting layouts. See the <a href="https://ratatui.rs/how-to/layout/" rel="nofollow">Layout</a>
section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more info.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use ratatui::{prelude::*, widgets::*};

fn ui(frame: &amp;mut Frame) {
    let main_layout = Layout::new(
        Direction::Vertical,
        [
            Constraint::Length(1),
            Constraint::Min(0),
            Constraint::Length(1),
        ]
    )
    .split(frame.size());
    frame.render_widget(
        Block::new().borders(Borders::TOP).title(&quot;Title Bar&quot;),
        main_layout[0],
    );
    frame.render_widget(
        Block::new().borders(Borders::TOP).title(&quot;Status Bar&quot;),
        main_layout[2],
    );

    let inner_layout = Layout::new(
        Direction::Horizontal,
        [Constraint::Percentage(50), Constraint::Percentage(50)]
    )
    .split(main_layout[1]);
    frame.render_widget(
        Block::default().borders(Borders::ALL).title(&quot;Left&quot;),
        inner_layout[0],
    );
    frame.render_widget(
        Block::default().borders(Borders::ALL).title(&quot;Right&quot;),
        inner_layout[1],
    );
}"><pre><span>use</span> ratatui<span>::</span><span>{</span>prelude<span>::</span><span>*</span><span>,</span> widgets<span>::</span><span>*</span><span>}</span><span>;</span>

<span>fn</span> <span>ui</span><span>(</span><span>frame</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Frame</span><span>)</span> <span>{</span>
    <span>let</span> main_layout = <span>Layout</span><span>::</span><span>new</span><span>(</span>
        <span>Direction</span><span>::</span><span>Vertical</span><span>,</span>
        <span>[</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Min</span><span>(</span><span>0</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
        <span>]</span>
    <span>)</span>
    <span>.</span><span>split</span><span>(</span>frame<span>.</span><span>size</span><span>(</span><span>)</span><span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>new</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>TOP</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Title Bar"</span><span>)</span><span>,</span>
        main_layout<span>[</span><span>0</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>new</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>TOP</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Status Bar"</span><span>)</span><span>,</span>
        main_layout<span>[</span><span>2</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>

    <span>let</span> inner_layout = <span>Layout</span><span>::</span><span>new</span><span>(</span>
        <span>Direction</span><span>::</span><span>Horizontal</span><span>,</span>
        <span>[</span><span>Constraint</span><span>::</span><span>Percentage</span><span>(</span><span>50</span><span>)</span><span>,</span> <span>Constraint</span><span>::</span><span>Percentage</span><span>(</span><span>50</span><span>)</span><span>]</span>
    <span>)</span>
    <span>.</span><span>split</span><span>(</span>main_layout<span>[</span><span>1</span><span>]</span><span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>default</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>ALL</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Left"</span><span>)</span><span>,</span>
        inner_layout<span>[</span><span>0</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>default</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>ALL</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Right"</span><span>)</span><span>,</span>
        inner_layout<span>[</span><span>1</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Running this example produces the following output:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ratatui-org/ratatui/blob/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-layout.png?raw=true"><img src="https://github.com/ratatui-org/ratatui/raw/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-layout.png?raw=true" alt="docsrs-layout"></a></p>
<h2 tabindex="-1" dir="auto">Text and styling</h2>
<p dir="auto">The <code>Text</code>, <code>Line</code> and <code>Span</code> types are the building blocks of the library and are used in
many places. <code>Text</code> is a list of <code>Line</code>s and a <code>Line</code> is a list of <code>Span</code>s. A <code>Span</code>
is a string with a specific style.</p>
<p dir="auto">The <a href="https://github.com/ratatui-org/ratatui/blob/main/style"><code>style</code> module</a> provides types that represent the various styling options. The most
important one is <code>Style</code> which represents the foreground and background colors and the text
attributes of a <code>Span</code>. The <a href="https://github.com/ratatui-org/ratatui/blob/main/style"><code>style</code> module</a> also provides a <code>Stylize</code> trait that allows
short-hand syntax to apply a style to widgets and text. See the <a href="https://ratatui.rs/how-to/render/style-text/" rel="nofollow">Styling Text</a> section of the
<a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more info.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use ratatui::{prelude::*, widgets::*};

fn ui(frame: &amp;mut Frame) {
    let areas = Layout::new(
        Direction::Vertical,
        [
            Constraint::Length(1),
            Constraint::Length(1),
            Constraint::Length(1),
            Constraint::Length(1),
            Constraint::Min(0),
        ]
    )
    .split(frame.size());

    let span1 = Span::raw(&quot;Hello &quot;);
    let span2 = Span::styled(
        &quot;World&quot;,
        Style::new()
            .fg(Color::Green)
            .bg(Color::White)
            .add_modifier(Modifier::BOLD),
    );
    let span3 = &quot;!&quot;.red().on_light_yellow().italic();

    let line = Line::from(vec![span1, span2, span3]);
    let text: Text = Text::from(vec![line]);

    frame.render_widget(Paragraph::new(text), areas[0]);
    // or using the short-hand syntax and implicit conversions
    frame.render_widget(
        Paragraph::new(&quot;Hello World!&quot;.red().on_white().bold()),
        areas[1],
    );

    // to style the whole widget instead of just the text
    frame.render_widget(
        Paragraph::new(&quot;Hello World!&quot;).style(Style::new().red().on_white()),
        areas[2],
    );
    // or using the short-hand syntax
    frame.render_widget(Paragraph::new(&quot;Hello World!&quot;).blue().on_yellow(), areas[3]);
}"><pre><span>use</span> ratatui<span>::</span><span>{</span>prelude<span>::</span><span>*</span><span>,</span> widgets<span>::</span><span>*</span><span>}</span><span>;</span>

<span>fn</span> <span>ui</span><span>(</span><span>frame</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Frame</span><span>)</span> <span>{</span>
    <span>let</span> areas = <span>Layout</span><span>::</span><span>new</span><span>(</span>
        <span>Direction</span><span>::</span><span>Vertical</span><span>,</span>
        <span>[</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Min</span><span>(</span><span>0</span><span>)</span><span>,</span>
        <span>]</span>
    <span>)</span>
    <span>.</span><span>split</span><span>(</span>frame<span>.</span><span>size</span><span>(</span><span>)</span><span>)</span><span>;</span>

    <span>let</span> span1 = <span>Span</span><span>::</span><span>raw</span><span>(</span><span>"Hello "</span><span>)</span><span>;</span>
    <span>let</span> span2 = <span>Span</span><span>::</span><span>styled</span><span>(</span>
        <span>"World"</span><span>,</span>
        <span>Style</span><span>::</span><span>new</span><span>(</span><span>)</span>
            <span>.</span><span>fg</span><span>(</span><span>Color</span><span>::</span><span>Green</span><span>)</span>
            <span>.</span><span>bg</span><span>(</span><span>Color</span><span>::</span><span>White</span><span>)</span>
            <span>.</span><span>add_modifier</span><span>(</span><span>Modifier</span><span>::</span><span>BOLD</span><span>)</span><span>,</span>
    <span>)</span><span>;</span>
    <span>let</span> span3 = <span>"!"</span><span>.</span><span>red</span><span>(</span><span>)</span><span>.</span><span>on_light_yellow</span><span>(</span><span>)</span><span>.</span><span>italic</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> line = <span>Line</span><span>::</span><span>from</span><span>(</span><span>vec</span><span>!</span><span>[</span>span1, span2, span3<span>]</span><span>)</span><span>;</span>
    <span>let</span> text<span>:</span> <span>Text</span> = <span>Text</span><span>::</span><span>from</span><span>(</span><span>vec</span><span>!</span><span>[</span>line<span>]</span><span>)</span><span>;</span>

    frame<span>.</span><span>render_widget</span><span>(</span><span>Paragraph</span><span>::</span><span>new</span><span>(</span>text<span>)</span><span>,</span> areas<span>[</span><span>0</span><span>]</span><span>)</span><span>;</span>
    <span>// or using the short-hand syntax and implicit conversions</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>.</span><span>red</span><span>(</span><span>)</span><span>.</span><span>on_white</span><span>(</span><span>)</span><span>.</span><span>bold</span><span>(</span><span>)</span><span>)</span><span>,</span>
        areas<span>[</span><span>1</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>

    <span>// to style the whole widget instead of just the text</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>)</span><span>.</span><span>style</span><span>(</span><span>Style</span><span>::</span><span>new</span><span>(</span><span>)</span><span>.</span><span>red</span><span>(</span><span>)</span><span>.</span><span>on_white</span><span>(</span><span>)</span><span>)</span><span>,</span>
        areas<span>[</span><span>2</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
    <span>// or using the short-hand syntax</span>
    frame<span>.</span><span>render_widget</span><span>(</span><span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>)</span><span>.</span><span>blue</span><span>(</span><span>)</span><span>.</span><span>on_yellow</span><span>(</span><span>)</span><span>,</span> areas<span>[</span><span>3</span><span>]</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Running this example produces the following output:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ratatui-org/ratatui/blob/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-styling.png?raw=true"><img src="https://github.com/ratatui-org/ratatui/raw/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-styling.png?raw=true" alt="docsrs-styling"></a></p>

<h2 tabindex="-1" dir="auto">Status of this fork</h2>
<p dir="auto">In response to the original maintainer <a href="https://github.com/fdehau"><strong>Florian Dehau</strong></a>'s issue
regarding the <a href="https://github.com/fdehau/tui-rs/issues/654" data-hovercard-type="issue" data-hovercard-url="/fdehau/tui-rs/issues/654/hovercard">future of <code>tui-rs</code></a>, several members of
the community forked the project and created this crate. We look forward to continuing the work
started by Florian ð</p>
<p dir="auto">In order to organize ourselves, we currently use a <a href="https://discord.gg/pMCEU9hNEj" rel="nofollow">Discord server</a>,
feel free to join and come chat! There is also a <a href="https://matrix.org/" rel="nofollow">Matrix</a> bridge available at
<a href="https://matrix.to/#/#ratatui:matrix.org" rel="nofollow">#ratatui:matrix.org</a>.</p>
<p dir="auto">While we do utilize Discord for coordinating, it's not essential for contributing.
Our primary open-source workflow is centered around GitHub.
For significant discussions, we rely on GitHub â please open an issue, a discussion or a PR.</p>
<p dir="auto">Please make sure you read the updated <a href="https://github.com/ratatui-org/ratatui/blob/main/CONTRIBUTING.md">contributing</a> guidelines, especially if
you are interested in working on a PR or issue opened in the previous repository.</p>
<h2 tabindex="-1" dir="auto">Rust version requirements</h2>
<p dir="auto">Since version 0.23.0, The Minimum Supported Rust Version (MSRV) of <code>ratatui</code> is 1.67.0.</p>
<h2 tabindex="-1" dir="auto">Widgets</h2>
<h3 tabindex="-1" dir="auto">Built in</h3>
<p dir="auto">The library comes with the following
<a href="https://docs.rs/ratatui/latest/ratatui/widgets/index.html" rel="nofollow">widgets</a>:</p>
<ul dir="auto">
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.BarChart.html" rel="nofollow">BarChart</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/block/struct.Block.html" rel="nofollow">Block</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/calendar/index.html" rel="nofollow">Calendar</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/canvas/struct.Canvas.html" rel="nofollow">Canvas</a> which allows
rendering <a href="https://docs.rs/ratatui/latest/ratatui/widgets/canvas/index.html" rel="nofollow">points, lines, shapes and a world
map</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Chart.html" rel="nofollow">Chart</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Clear.html" rel="nofollow">Clear</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Gauge.html" rel="nofollow">Gauge</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.List.html" rel="nofollow">List</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Paragraph.html" rel="nofollow">Paragraph</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/scrollbar/struct.Scrollbar.html" rel="nofollow">Scrollbar</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Sparkline.html" rel="nofollow">Sparkline</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Table.html" rel="nofollow">Table</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Tabs.html" rel="nofollow">Tabs</a></li>
</ul>
<p dir="auto">Each widget has an associated example which can be found in the <a href="https://github.com/ratatui-org/ratatui/blob/main/examples">examples</a> folder. Run
each examples with cargo (e.g. to run the gauge example <code>cargo run --example gauge</code>), and quit by
pressing <code>q</code>.</p>
<p dir="auto">You can also run all examples by running <code>cargo make run-examples</code> (requires <code>cargo-make</code> that can
be installed with <code>cargo install cargo-make</code>).</p>
<h3 tabindex="-1" dir="auto">Third-party libraries, bootstrapping templates and widgets</h3>
<ul dir="auto">
<li><a href="https://github.com/uttarayan21/ansi-to-tui">ansi-to-tui</a> â Convert ansi colored text to
<code>ratatui::text::Text</code></li>
<li><a href="https://github.com/uttarayan21/color-to-tui">color-to-tui</a> â Parse hex colors to
<code>ratatui::style::Color</code></li>
<li><a href="https://github.com/ratatui-org/rust-tui-template">rust-tui-template</a> â A template for
bootstrapping a Rust TUI application with Tui-rs &amp; crossterm</li>
<li><a href="https://github.com/jkelleyrtp/tui-builder">tui-builder</a> â Batteries-included MVC framework for
Tui-rs + Crossterm apps</li>
<li><a href="https://github.com/kegesch/tui-clap-rs">tui-clap</a> â Use clap-rs together with Tui-rs</li>
<li><a href="https://github.com/kegesch/tui-log-rs">tui-log</a> â Example of how to use logging with Tui-rs</li>
<li><a href="https://github.com/gin66/tui-logger">tui-logger</a> â Logger and Widget for Tui-rs</li>
<li><a href="https://github.com/veeso/tui-realm">tui-realm</a> â Tui-rs framework to build stateful applications
with a React/Elm inspired approach</li>
<li><a href="https://github.com/veeso/tui-realm-treeview">tui-realm-treeview</a> â Treeview component for
Tui-realm</li>
<li><a href="https://github.com/EdJoPaTo/tui-rs-tree-widget">tui-rs-tree-widgets</a> â Widget for tree data
structures.</li>
<li><a href="https://github.com/markatk/tui-windows-rs">tui-windows</a> â Tui-rs abstraction to handle multiple
windows and their rendering</li>
<li><a href="https://github.com/rhysd/tui-textarea">tui-textarea</a> â Simple yet powerful multi-line text editor
widget supporting several key shortcuts, undo/redo, text search, etc.</li>
<li><a href="https://github.com/sayanarijit/tui-input">tui-input</a> â TUI input library supporting multiple
backends and tui-rs.</li>
<li><a href="https://github.com/a-kenji/tui-term">tui-term</a> â A pseudoterminal widget library
that enables the rendering of terminal applications as ratatui widgets.</li>
</ul>
<h2 tabindex="-1" dir="auto">Apps</h2>
<p dir="auto">Check out the list of more than 50 <a href="https://github.com/ratatui-org/ratatui/wiki/Apps-using-Ratatui">Apps using
<code>Ratatui</code></a>!</p>
<h2 tabindex="-1" dir="auto">Alternatives</h2>
<p dir="auto">You might want to checkout <a href="https://github.com/gyscos/Cursive">Cursive</a> for an alternative solution
to build text user interfaces in Rust.</p>
<h2 tabindex="-1" dir="auto">Acknowledgments</h2>
<p dir="auto">Special thanks to <a href="https://github.com/nawok"><strong>Pavel Fomchenkov</strong></a> for his work in designing <strong>an
awesome logo</strong> for the ratatui project and ratatui-org organization.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto"><a href="https://github.com/ratatui-org/ratatui/blob/main/LICENSE">MIT</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paris-Based Startup and OpenAI Competitor Mistral AI Valued at $2B (284 pts)]]></title>
            <link>https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/</link>
            <guid>38593616</guid>
            <pubDate>Sun, 10 Dec 2023 18:25:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/">https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/</a>, See on <a href="https://news.ycombinator.com/item?id=38593616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mvp-content-main"><p>In a significant development for the European artificial intelligence sector, Paris-based startup <a href="https://mistral.ai/">Mistral AI</a> has achieved a noteworthy milestone. The company has successfully secured a substantial investment of â¬450 million, propelling its valuation to an impressive $2 billion. This funding round marks a pivotal moment, not only for Mistral AI but also for the burgeoning European AI landscape, signifying the region's increasing prominence in the global AI arena.</p><p>Leading the charge in this investment round is Andreessen Horowitz, a prominent name in the venture capital world, demonstrating a strong vote of confidence in Mistral AI's potential. Joining the fray are tech giants Nvidia Corp and Salesforce, contributing an additional â¬120 million in convertible debt. This diverse array of investors, encompassing both traditional venture capital and major tech corporations, underscores the wide-ranging appeal and potential of Mistral AI's technology and vision.</p><p>This influx of capital is a testament to Mistral AI's innovative approach and its perceived potential to disrupt the AI industry. With this substantial financial backing, Mistral AI is poised to advance its research and development, expand its reach, and further cement its position as a leading player in the AI domain. The scale of this investment round also reflects the growing recognition of the strategic importance of AI technologies and the increasing competition to lead in this transformative field.</p><h2><strong>Technological Advancements and Market Impact</strong></h2><p>Mistral AI stands at the forefront of innovation with its flagship product, Mistral 7B, a large language model (LLM) renowned for its efficiency and advanced capabilities. Released under the open-source Apache 2.0 license, Mistral 7B represents a significant leap in AI technology, characterized by its customized training, tuning, and data processing methods.</p><p>What sets Mistral 7B apart is its ability to compress knowledge and facilitate deep reasoning capacities, even with fewer parameters compared to other models in the market. This optimized approach not only enhances the model's performance but also contributes to sustainability by reducing training time, costs, and environmental impact.</p><p>The successful deployment of Mistral 7B has positioned Mistral AI as a key player in the AI market and a competitor to OpenAI. Its impact extends across various industries, offering potential transformations in fields such as healthcare, education, finance, and manufacturing. The company's ability to provide high-performance, scalable solutions is poised to impact how these sectors leverage AI for innovation and efficiency.</p><h2><strong>European AI Landscape and Competitive Edge</strong></h2><p>Mistral AI's recent funding round is a clear indicator of Europe's rapidly growing stature in the global AI landscape. Historically, European ventures in AI have lagged behind their counterparts in the US and Asia in terms of investment and innovation. However, Mistral AI's success, alongside other significant investments, marks a decisive shift, showcasing Europe's rising potential and commitment to AI innovation.</p><p>In the competitive arena of generative AI, Mistral AI distinguishes itself with its open-source approach and focus on creating scalable and efficient models. This strategy sets it apart from established giants such as OpenAI, Google AI, and DeepMind, offering a unique value proposition to the market. By prioritizing accessibility and efficiency, Mistral AI not only contributes to the democratization of AI technology but also positions itself as a formidable competitor in the global AI race.</p><p>The trajectory of Mistral AI and the burgeoning European AI sector signals a vibrant and dynamic future for AI development. With substantial investments pouring into European AI startups, the region is rapidly catching up and carving out its niche in the highly competitive and ever-evolving field of artificial intelligence.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The valley of the cheese of the dead (107 pts)]]></title>
            <link>https://www.atlasobscura.com/articles/most-unusual-cheese-switzerland</link>
            <guid>38593538</guid>
            <pubDate>Sun, 10 Dec 2023 18:15:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.atlasobscura.com/articles/most-unusual-cheese-switzerland">https://www.atlasobscura.com/articles/most-unusual-cheese-switzerland</a>, See on <a href="https://news.ycombinator.com/item?id=38593538">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="article-body">
<p><span>Imagine setting aside a wheel </span>of cheese at your wedding. What would it look like if it were served at yourâ¯funeral?</p>
<p>If you were lucky, it would look like one of the wheels in Jean-Jacques Zuffereyâs basement in Grimentz, Switzerland: shriveled and brown, pockmarked from decades of mite and mouse nibbles, and hard as a rock. Youâd need an axe to slice it open and strong booze to wash it down. This is the rare cheese youâ¯donâtâ¯want to cut into when itâs aged to perfection. A fossilized funeral cheese means you lived a long life.</p>
<p>Zuffereyâs home, high in the Swiss mountains of Val dâAnniviers, is one of the last places youâll find evidence of this peculiar practiceâof keeping a wheel of cheese to be eaten at your funeral.</p>
<figure><img src="https://img.atlasobscura.com/r1-iaD1cVsD4MV_gdJrfIRzU6oXCh-S4yRGHpAmy04Y/rs:fill:12000:12000/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy82N2I2OGM4YWEx/MTU3NDFkNTNfXzc3/QTQ1NzkuanBn.jpg" alt="Jean-Jacques Zufferey holds a wheel of 149-year-old cheese." width="auto" data-kind="article-image" id="article-image-69320" data-src="https://img.atlasobscura.com/r1-iaD1cVsD4MV_gdJrfIRzU6oXCh-S4yRGHpAmy04Y/rs:fill:12000:12000/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy82N2I2OGM4YWEx/MTU3NDFkNTNfXzc3/QTQ1NzkuanBn.jpg"><figcaption>Jean-Jacques Zufferey holds a wheel of 149-year-old cheese. <span>Molly McDonough</span></figcaption></figure>
<p>The Val dâAnniviers, which snakes up the highest peaks of the Swiss Alps, is a case study in how mountains isolate valleys and villages, breeding unique traditions. When Swiss anthropologist Yvonne Preiswerk first arrived to conduct fieldwork here, she noted strange funeral rituals reminiscent of ancient Egypt.</p>
<p>âWe are struck by â¦ a special kind of mountain Catholicism,â she wrote in the 1992 paper âDeath, the Priest, the Woman and the Cow: Chronicle of Research in the Village.â In centuries previous, she explained, visitors appalled by these pagan practices had labeled the locals âbarbaric,â positing that theyâd descended from the Huns.</p>
<p>The rituals that shocked them involved a mix of death and cheese. It seems an unlikely pairing, but the landscape offers an explanation. Along the valleyâs winding road to the small mountain village of Grimentz, isolated villages cling to the cliffs in the shadows of craggy, glaciated peaks. The ground is rocky and steep. Growing seasons are short and winters are long. To survive the cold, villagers had to preserve nutrient-dense food.</p>
<figure><img src="https://img.atlasobscura.com/9xXoDMMdgBDHP5RG6lGXw2Ls68BYY-lntUP15qCoLR8/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy85NjI4OGE1ZC1l/NjBkLTQyMzQtOGMx/Ny0yYzIwMTI5NjU0/YmUzMzFhYmVlODNk/NTBjMjUyZDNfQzBS/SkNIICgxKS5qcGc.jpg" alt="The village of St Luc and the Val d'Anniviers, Valais, Switzerland." width="auto" data-kind="article-image" id="article-image-69524" data-src="https://img.atlasobscura.com/9xXoDMMdgBDHP5RG6lGXw2Ls68BYY-lntUP15qCoLR8/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy85NjI4OGE1ZC1l/NjBkLTQyMzQtOGMx/Ny0yYzIwMTI5NjU0/YmUzMzFhYmVlODNk/NTBjMjUyZDNfQzBS/SkNIICgxKS5qcGc.jpg"><figcaption>The village of St Luc and the Val dâAnniviers, Valais, Switzerland. <span>Andrew Hasson / Alamy</span></figcaption></figure>
<p>Thatâs why residents of Grimentz, like people elsewhere in the Alps, breed bovines adapted to the steep landscape, bringing them to high pasture in summer to graze. Pooling abundant summer milk, they make giant wheels of cheese.</p>
<p>To render the wheels sturdy, cheesemakers âcookâ the curds to firm them, and press them to expel as much whey as possible. Moisture and heat cause spoilage, speeding up a cheeseâs aging process; in the dry, cold mountain air, these cheeses age slowly. While aging can continue for years, most Alpine wheels tend to reach peak ripenessâstill pliable, but with plenty of flavorâmonths later, during the worst of winter when, historically, little else was available. Sliced onto rye bread or melted fireside, cheese ensured a calorie source in winter.</p>
<p>Devotion to dairy has taken different forms throughout the Alpsâs secluded valleys. âA popular culture of the cow â¦ traverses all moments, objects, and events of the mountain peasant,â wrote Preiswerk. In Grimentz, it manifested in elaborate funerals. After a death, the bells of the deceasedâs cows were removed, so that the animals, too, could mourn. Families added a âpicnic of the deadâ to the casket, which included a bottle of wine, bread, and cheese (as well as sturdy boots, as ghosts were rumored to wander the glaciers after dark).</p>
<figure><img src="https://img.atlasobscura.com/rrbwbGj6BhRB6xS0Zc3VNPG2mbupp_7UXAFHpJ1hPNw/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy8wM2YxNmRkMy01/ODg4LTRkYzItOTEw/My02MDBlMDQyMmZj/ZWNkYTkxODY3NGVj/ODNhMjBkOWJfR2V0/dHlJbWFnZXMtMTM1/ODI4NjYwX2EuanBn.jpg" alt="A cemetery in the village of Grimentz." width="auto" data-kind="article-image" id="article-image-80796" data-src="https://img.atlasobscura.com/rrbwbGj6BhRB6xS0Zc3VNPG2mbupp_7UXAFHpJ1hPNw/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy8wM2YxNmRkMy01/ODg4LTRkYzItOTEw/My02MDBlMDQyMmZj/ZWNkYTkxODY3NGVj/ODNhMjBkOWJfR2V0/dHlJbWFnZXMtMTM1/ODI4NjYwX2EuanBn.jpg"><figcaption>A cemetery in the village of Grimentz. <span>Buena Vista Images/Getty Images</span></figcaption></figure>
<p>The same foods comprised the all-important burial meal, which symbolized the reconstitution of the community after its tragic rift. As one of Preiswerkâs interview subjects recounted, the funeral guests were told, âCome to the meal, because the dead man has left enough.â</p>
<p>In a historically poor area, âleaving enoughâ required advance planning. âThere was the âcheese of the dead,ââ explains Zufferey. âEveryone had a wheel of cheese so that they had something to serve at their funeral.â When the inevitable time came, the chiseled cheese was washed down with <em>vin des glaciers, </em>the local wine.</p>
<p>As the Valaisan Alps modernized during the 1900s, and villages moved away from subsistence economies, fears of cheeseless funeral tables waned. According to anthropologist Claude-Alexandre Fournier, families gradually stopped overseeing funeral rituals at home. âMortuary knowledge was no longer transmitted,â he wrote in the 2013 ethnography <em>Odette Fournier, Sage-Femme</em>, âthus depriving families of the âdeath equipment box.ââ Yet in a few basements scattered throughout the valley, youâll still find carefully stacked wheels of funeral cheese.</p>
<figure><img src="https://img.atlasobscura.com/r-k1PcVeCzzKQybHLyDcAqVddXjvFdi_6zlO-nGIOF0/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy82N2I2OGM4YWEx/MTU3NDFkNTNfXzc3/QTQ1ODcuanBn.jpg" alt="Old wheels are stacked on their sides. Since they're completely firm, they won't lose their shape." width="auto" data-kind="article-image" id="article-image-69322" data-src="https://img.atlasobscura.com/r-k1PcVeCzzKQybHLyDcAqVddXjvFdi_6zlO-nGIOF0/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy82N2I2OGM4YWEx/MTU3NDFkNTNfXzc3/QTQ1ODcuanBn.jpg"><figcaption>Old wheels are stacked on their sides. Since theyâre completely firm, they wonât lose their shape. <span>Molly McDonough</span></figcaption></figure>
<p>In Grimentz, Zufferey, a tall, soft-spoken man with tiny glasses and a day job at the local department of agriculture, unlocks his basement door, releasing an ammoniated, musty smell. His family, too, had forgotten about their funeral cheeses, until his grandmother died in 1944. Thatâs when Zuffereyâs father found two very old wheels in her basement.</p>
<p>Instead of eating the cheeses, whose engravings suggest a production year of 1870, Zuffereyâs father decided to preserve them. In the years since, the family has added wheels from time to time, building a collection. Rather than prepping for a funeral, theyâre dutifully preserving evidence of a waning traditionâand what might be some of the worldâs oldest wheels of cheese.</p>
<p>Zufferey picks one of the wheels, which is now 149 years old, from the shelf. âYou can touch itâlike a relic in the church,ââ he quips. Rock hard and leathery, with a glossy brown surface reminiscent of a bog body, itâs still a bit oily, but sapped of moisture. Its own microbes and molds are likely long deceased. He picks up another, from 1967, engraved with edelweiss flowers. A third, from 1992, depicts a âqueen cow.â</p>
<figure><img src="https://img.atlasobscura.com/zkyh1p5VRF9dUDPb2mR5Lj1Yt27EvwH0SZ-L1asATus/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy82N2I2OGM4YWEx/MTU3NDFkNTNfXzc3/QTQ1ODEuanBn.jpg" alt="This wheel of cheese was likely a lot larger 149 years ago, but has shriveled due to moisture loss." width="auto" data-kind="article-image" id="article-image-69317" data-src="https://img.atlasobscura.com/zkyh1p5VRF9dUDPb2mR5Lj1Yt27EvwH0SZ-L1asATus/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy82N2I2OGM4YWEx/MTU3NDFkNTNfXzc3/QTQ1ODEuanBn.jpg"><figcaption>This wheel of cheese was likely a lot larger 149 years ago, but has shriveled due to moisture loss. <span>Molly McDonough</span></figcaption></figure>
<p>Perhaps pondering his own mortality, Zufferey worries about what will happen to his collection in the long term. Heâd like to give them to a museum, but canât find anywhere nearby with proper climate control. âThere is no museum of cheese in the Valais,â he says. âItâs bizarre.â</p>
<p>Thereâs no rush, though. His cool <em>cave </em>cut into the mountainside beneath his familyâs wooden chalet seems to be working for these wheels. Zufferey gingerly places them back into their horizontal compartments, ducks out of the tiny basement back into the cobbled village square, and locks the door. Casting darkness on the uneaten death cheeses, he leaves them to await their own fate.</p>
<p><em>You can <a href="https://community.atlasobscura.com/t/the-valley-of-the-cheese-of-the-dead-discussion-thread/28913">join the conversation </a>about this and other Spirits Week stories in the Atlas Obscura Community Forums.</em></p>
<p><em>Gastro Obscura covers the worldâs most wondrous food and drink.
<br>
<a href="https://www.atlasobscura.com/newsletters/gastro-obscura">Sign up for our email, delivered twice a week</a>.</em></p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sigil II, a Doom WAD from J.Romero, has been released (171 pts)]]></title>
            <link>https://doomwiki.org/wiki/SIGIL_II</link>
            <guid>38593248</guid>
            <pubDate>Sun, 10 Dec 2023 17:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doomwiki.org/wiki/SIGIL_II">https://doomwiki.org/wiki/SIGIL_II</a>, See on <a href="https://news.ycombinator.com/item?id=38593248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="monaco_shrinkwrap_main">
		
					<!-- ARTICLE -->

				<article id="article" role="main" aria-labelledby="firstHeading">
					<a id="top"></a>
															
										<div id="bodyContent">
						<h2 id="siteSub">From DoomWiki.org</h2>
																								
						<!-- start content -->
<div id="mw-content-text" lang="en" dir="ltr"><table>
<tbody><tr>
<th colspan="2"> <i>SIGIL II</i>
</th></tr>
<tr>
<td colspan="2"> <a href="https://doomwiki.org/wiki/File:SIGIL_II_title.png" title="Title screen"><img alt="Title screen" src="https://doomwiki.org/w/images/thumb/a/a4/SIGIL_II_title.png/320px-SIGIL_II_title.png" width="320" height="240"></a>
</td></tr>
<tr>
<th> Author
</th>
<td> John Romero
</td></tr>
<tr>
<th> <a href="https://doomwiki.org/wiki/Source_port" title="Source port">Port</a>
</th>
<td> <a href="https://doomwiki.org/wiki/Limit-removing" title="Limit-removing">Limit-removing</a>
</td></tr>
<tr>
<th> <a href="https://doomwiki.org/wiki/IWAD" title="IWAD">IWAD</a>
</th>
<td> Doom
</td></tr>
<tr>
<th> Year
</th>
<td> <a href="https://doomwiki.org/wiki/Timeline_of_mod_releases#2023" title="Timeline of mod releases">2023</a>
</td></tr>
<tr>
<th> Link
</th>
<td> <a rel="nofollow" href="https://romero.com/sigil">Official site</a>
</td></tr>


</tbody></table>
<div id="infobox-timelystub"><table><tbody><tr><td><a href="https://doomwiki.org/wiki/File:Work_outdated.png"><img alt="Work outdated.png" src="https://doomwiki.org/w/images/thumb/3/39/Work_outdated.png/40px-Work_outdated.png" width="40" height="40"></a></td><td><i>This <b>stub</b> article makes use of facts and/or references about ongoing events and may need to be updated frequently. Information here may become outdated quickly. Please help the <a href="https://doomwiki.org/wiki/Doom_Wiki" title="Doom Wiki">Doom Wiki</a> by <a rel="nofollow" href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit">keeping it up to date.</a></i></td></tr></tbody></table></div>
<p><b>SIGIL II</b> is a sequel to <a href="https://doomwiki.org/wiki/SIGIL" title="SIGIL">SIGIL</a> by <a href="https://doomwiki.org/wiki/John_Romero" title="John Romero">John Romero</a> and <a href="https://en.wikipedia.org/wiki/Romero_Games" title="wikipedia:Romero Games">Romero Games</a>. It was announced through a video interview with <a href="https://doomwiki.org/wiki/Bridgeburner56" title="Bridgeburner56">Bridgeburner56</a> which premiered through the Realms Deep online indie games convention on <a href="https://doomwiki.org/wiki/Timeline#2021" title="Timeline">August 15, 2021</a>.<sup id="cite_ref-blues1_1-0"><a href="#cite_note-blues1-1">[1]</a></sup><sup id="cite_ref-bb1_2-0"><a href="#cite_note-bb1-2">[2]</a></sup> It is a <a href="https://doomwiki.org/wiki/Doom" title="Doom">Doom</a> episode, and was released December 10, 2023.<sup id="cite_ref-releasetweet_3-0"><a href="#cite_note-releasetweet-3">[3]</a></sup>
</p><p>It was previously stated that <a href="https://en.wikipedia.org/wiki/Buckethead" title="wikipedia:Buckethead">Buckethead</a> would return to contribute music,<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> but later materials indicate that the digital OST will instead be produced by Thorr. It also features an alternative and bespoke <a href="https://doomwiki.org/wiki/MIDI" title="MIDI">MIDI</a> soundtrack by <a href="https://doomwiki.org/wiki/James_Paddock_(Jimmy)" title="James Paddock (Jimmy)">James Paddock (Jimmy)</a>, whose MIDIs were already featured in SIGIL.
</p><p>SIGIL II opened for pre-orders on November 2, 2023, through Romero's romero.com store.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p>
<div id="toc"><p id="toctitle"><h2>Contents</h2></p>
<ul>
<li><a href="#Pre-release"><span>1</span> <span>Pre-release</span></a></li>
<li><a href="#Pre-orders"><span>2</span> <span>Pre-orders</span></a></li>
<li><a href="#Physical_distributions"><span>3</span> <span>Physical distributions</span></a></li>
<li><a href="#Content"><span>4</span> <span>Content</span></a>
<ul>
<li><a href="#Changes"><span>4.1</span> <span>Changes</span></a></li>
<li><a href="#Levels"><span>4.2</span> <span>Levels</span></a></li>
<li><a href="#MIDI_soundtrack"><span>4.3</span> <span>MIDI soundtrack</span></a></li>
<li><a href="#Original_soundtrack"><span>4.4</span> <span>Original soundtrack</span></a></li>
<li><a href="#Built-in_demos"><span>4.5</span> <span>Built-in demos</span></a></li>
</ul>
</li>
<li><a href="#External_links"><span>5</span> <span>External links</span></a></li>
<li><a href="#References"><span>6</span> <span>References</span></a></li>
</ul>
</div>

<h2><span id="Pre-release">Pre-release</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=1" title="Edit section: Pre-release">edit</a><span>]</span></span></h2>
<p>Romero announced on December 8, 2022, that he would stream the building of a SIGIL II level on December 10, 2022âDoom's 29th release anniversaryâat 5:00 PM Eastern time on Twitch.<sup id="cite_ref-dec8tweet_6-0"><a href="#cite_note-dec8tweet-6">[6]</a></sup> He also noted at this time that the episode will again consist of nine levels, and that it will be for Doom rather than Doom II (earlier use of the term <a href="https://doomwiki.org/wiki/Megawad" title="Megawad">megawad</a> made this somewhat unclear).
</p><p>A previously released level, "<a href="https://doomwiki.org/wiki/One_Humanity" title="One Humanity">One Humanity</a>," was released as a standalone WAD for charity on March 2, 2022. However that level was for Doom II, and Romero has since reassigned it to the "Hellion" project for Doom II.<sup id="cite_ref-pagbtweet_7-0"><a href="#cite_note-pagbtweet-7">[7]</a></sup>
</p>
<h2><span id="Pre-orders">Pre-orders</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=2" title="Edit section: Pre-orders">edit</a><span>]</span></span></h2>
<p>Pre-orders for physical editions of SIGIL II opened on November 2, 2023, via Romero's romero.com store. Three separate editions were available, with the two higher limited editions selling out within an hour:
</p>
<ul><li> Shotgun Shell USB Edition (â¬69.95)</li>
<li> 3.5" floppy + Shotgun Shell USB Edition (â¬89.95, limited to 166 copies)</li>
<li> 5.25" and 3.5" floppies + Shotgun Shell USB + shirt (â¬154.95, limited to 30 copies)</li></ul>
<h2><span id="Physical_distributions">Physical distributions</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=3" title="Edit section: Physical distributions">edit</a><span>]</span></span></h2>
<p>Shared contents of all three physical editions include the following:
</p>
<ul><li> Custom SIGIL II big box</li>
<li> SIGIL II cover poster (A3 size)</li>
<li> Romero Games full-size cinch bag</li>
<li> Sticker sheet with five stickers</li>
<li> Shotgun glitter sticker</li>
<li> SIGIL II disk pin</li>
<li> SIGIL II "Gates of Hell" heavy superpin</li>
<li> Extra code for SIGIL II WAD with music via email</li>
<li> Shotgun shell USB containing:
<ul><li> SIGIL II nine-level WAD file</li>
<li> Making of SIGIL II video</li>
<li> Making of SIGIL II story by David L. Craddock</li>
<li> SIGIL II original soundtrack by Thorr</li>
<li> SIGIL II original MIDI soundtrack by <a href="https://doomwiki.org/wiki/James_Paddock_(Jimmy)" title="James Paddock (Jimmy)">James Paddock (Jimmy)</a></li>
<li> README file</li></ul></li></ul>
<h2><span id="Content">Content</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=4" title="Edit section: Content">edit</a><span>]</span></span></h2>
<h3><span id="Changes">Changes</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=5" title="Edit section: Changes">edit</a><span>]</span></span></h3>
<p>The spider mastermind had its <a href="https://doomwiki.org/wiki/Hit_point" title="Hit point">health value</a> increased from 4000 to 9000. Otherwise, it functions the exact same as <a href="https://doomwiki.org/wiki/Vanilla" title="Vanilla">vanilla</a>.
</p>
<h3><span id="Levels">Levels</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=6" title="Edit section: Levels">edit</a><span>]</span></span></h3>
<p>All maps except E6M9 also include a <a href="https://doomwiki.org/wiki/Deathmatch_arena" title="Deathmatch arena">deathmatch arena</a>.
</p>
<ul><li> <a href="https://doomwiki.org/wiki/E6M1:_Cursed_Darkness_(SIGIL_II)" title="E6M1: Cursed Darkness (SIGIL II)">E6M1: Cursed Darkness</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M2:_Violent_Hatred_(SIGIL_II)" title="E6M2: Violent Hatred (SIGIL II)">E6M2: Violent Hatred</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M3:_Twilight_Desolation_(SIGIL_II)" title="E6M3: Twilight Desolation (SIGIL II)">E6M3: Twilight Desolation</a> <i>(exit to secret level)</i></li>
<li> <a href="https://doomwiki.org/wiki/E6M4:_Fragments_of_Sanity_(SIGIL_II)" title="E6M4: Fragments of Sanity (SIGIL II)">E6M4: Fragments of Sanity</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M5:_Wrathful_Reckoning_(SIGIL_II)" title="E6M5: Wrathful Reckoning (SIGIL II)">E6M5: Wrathful Reckoning</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M6:_Vengeance_Unleashed_(SIGIL_II)" title="E6M6: Vengeance Unleashed (SIGIL II)">E6M6: Vengeance Unleashed</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M7:_Descent_Into_Terror_(SIGIL_II)" title="E6M7: Descent Into Terror (SIGIL II)">E6M7: Descent Into Terror</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M8:_Abyss_of_Despair_(SIGIL_II)" title="E6M8: Abyss of Despair (SIGIL II)">E6M8: Abyss of Despair</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M9:_Shattered_Homecoming_(SIGIL_II)" title="E6M9: Shattered Homecoming (SIGIL II)">E6M9: Shattered Homecoming</a> <i>(secret level)</i></li></ul>
<table role="presentation">

<tbody><tr>
<td>
<h3><span id="MIDI_soundtrack">MIDI soundtrack</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=7" title="Edit section: MIDI soundtrack">edit</a><span>]</span></span></h3>
<p>All track composed by <a href="https://doomwiki.org/wiki/James_Paddock_(Jimmy)" title="James Paddock (Jimmy)">James Paddock (Jimmy)</a>.
</p>
<ul><li> E6M1: "Nightmare Overture"</li>
<li> E6M2: "Sleep of Reason"</li>
<li> E6M3: "Cathedral Rock"</li>
<li> E6M4: "Fractures"</li>
<li> E6M5: "Hexaphobia"</li>
<li> E6M6: "Walls of the Minotaur"</li>
<li> E6M7: "The Impenetrable Dark"</li>
<li> E6M8: "Final Impact"</li>
<li> E6M9: "I'm the Doomguy with the Gun"</li></ul>
<ul><li> <a href="https://doomwiki.org/wiki/Title_screen" title="Title screen">Title screen</a>: "Doomsday Draws Near"</li>
<li> <a href="https://doomwiki.org/wiki/Intermission_screen" title="Intermission screen">Intermission screen</a>: "The Horror To Come"</li></ul>
</td>
<td>
<h3><span id="Original_soundtrack">Original soundtrack</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=8" title="Edit section: Original soundtrack">edit</a><span>]</span></span></h3>
<p>All track composed by THORR.
</p>
<ul><li> E6M1: </li>
<li> E6M2: </li>
<li> E6M3: </li>
<li> E6M4: </li>
<li> E6M5: </li>
<li> E6M6: </li>
<li> E6M7: </li>
<li> E6M8: </li>
<li> E6M9: </li></ul>
</td></tr></tbody></table>
<h3><span id="Built-in_demos">Built-in demos</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=9" title="Edit section: Built-in demos">edit</a><span>]</span></span></h3>
<p>This WAD features four <a href="https://doomwiki.org/wiki/Demo#Built-in_demos" title="Demo">built-in demos</a>. All require Ultimate Doom v1.9 to view them. The demo levels are:
</p>
<table>
<tbody><tr>
<th> Demo
</th>
<th> Level
</th>
<th> <a href="https://doomwiki.org/wiki/Skill_level#Doom_and_Doom_II_skill_levels" title="Skill level">Skill</a>
</th>
<th> <a href="https://doomwiki.org/wiki/Tic" title="Tic">Tics</a>
</th>
<th> Length
</th></tr>
<tr>
<td> DEMO1
</td>
<td> <a href="https://doomwiki.org/wiki/E6M1:_Cursed_Darkness_(SIGIL_II)" title="E6M1: Cursed Darkness (SIGIL II)">E6M1: Cursed Darkness</a>
</td>
<td> 4
</td>
<td> 1702
</td>
<td> 0:48.63
</td></tr>
<tr>
<td> DEMO2
</td>
<td> <a href="https://doomwiki.org/wiki/E6M2:_Violent_Hatred_(SIGIL_II)" title="E6M2: Violent Hatred (SIGIL II)">E6M2: Violent Hatred</a>
</td>
<td> 4
</td>
<td> 2154
</td>
<td> 1:01.54
</td></tr>
<tr>
<td> DEMO3
</td>
<td> <a href="https://doomwiki.org/wiki/E6M4:_Fragments_of_Sanity_(SIGIL_II)" title="E6M4: Fragments of Sanity (SIGIL II)">E6M4: Fragments of Sanity</a>
</td>
<td> 4
</td>
<td> 1912
</td>
<td> 0:54.63
</td></tr>
<tr>
<td> DEMO4
</td>
<td> <a href="https://doomwiki.org/wiki/E6M6:_Vengeance_Unleashed_(SIGIL_II)" title="E6M6: Vengeance Unleashed (SIGIL II)">E6M6: Vengeance Unleashed</a>
</td>
<td> 4
</td>
<td> 2163
</td>
<td> 1:01.80
</td></tr></tbody></table>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=10" title="Edit section: External links">edit</a><span>]</span></span></h2>
<ul><li> <a rel="nofollow" href="https://romero.com/sigil">Official site</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=11" title="Edit section: References">edit</a><span>]</span></span></h2>
<ol>
<li id="cite_note-blues1-1"><span><a href="#cite_ref-blues1_1-0">â</a></span> <span>&nbsp;(15 August 2021). <a rel="nofollow" href="https://www.bluesnews.com/s/239609/sigil-2-for-doom-ii-revealed">"Sigil 2 for DOOM II Revealed."</a> <i>Blue's News.</i> Retrieved 16 August 2021.</span>
</li>
<li id="cite_note-bb1-2"><span><a href="#cite_ref-bb1_2-0">â</a></span> <span><a href="https://doomwiki.org/wiki/Bridgeburner56" title="Bridgeburner56">Bridgeburner</a>&nbsp;(6 July 2021). <a rel="nofollow" href="https://www.youtube.com/watch?v=CHkAgjlu1Ts&amp;ab_channel=Bridgeburner">"Burning Bridges With Bridgeburner â #06 John Romero on the Art of Level Design."</a> <i><a href="https://en.wikipedia.org/wiki/YouTube" title="wikipedia:YouTube">YouTube</a>.</i> Retrieved 16 August 2021.</span>
</li>
<li id="cite_note-releasetweet-3"><span><a href="#cite_ref-releasetweet_3-0">â</a></span> <span><a href="https://doomwiki.org/wiki/John_Romero" title="John Romero">Romero, John</a>&nbsp;(9 December 2023). <a rel="nofollow" href="https://twitter.com/romero/status/1733672932734304666">"Free WAD for SIGIL II is up: https://romero.com/sigil."</a> <i>Twitter.</i> Retrieved 9 December 2023.</span>
</li>
<li id="cite_note-4"><span><a href="#cite_ref-4">â</a></span> <span>Romero Games Ltd.&nbsp;(20 September 2022). <a rel="nofollow" href="https://www.youtube.com/watch?v=9UPqPI3um8Q">"Ask Romero | Episode 3."</a> <i>YouTube.</i> Retrieved 21 October 2022.</span>
</li>
<li id="cite_note-5"><span><a href="#cite_ref-5">â</a></span> <span>Romero, John&nbsp;(2 November 2023). <a rel="nofollow" href="https://twitter.com/romero/status/1720049920764190773">"SIGIL II preorders open TONIGHT at 6 p.m. GMT on http://Romero.com. All proceeds from sales of SIGIL II and SIGIL II merch support future WAD development. Thank you for playing my games."</a> <i>Twitter.</i> Retrieved 2 November 2023.</span>
</li>
<li id="cite_note-dec8tweet-6"><span><a href="#cite_ref-dec8tweet_6-0">â</a></span> <span>Romero, John&nbsp;(8 December 2022). <a rel="nofollow" href="https://twitter.com/romero/status/1600982842452119552">"For DOOMâs 29th birthday on Dec 10, Iâll be live streaming me building a new level for SIGIL II, another nine-level WAD, which will be released for DOOMâs 30th. Join me at https://twitch.tv/theromero on Dec 10 at 5 pm ET."</a> <i>Twitter.</i> Retrieved 8 December 2022.</span>
</li>
<li id="cite_note-pagbtweet-7"><span><a href="#cite_ref-pagbtweet_7-0">â</a></span> <span><a href="https://doomwiki.org/wiki/Pedro_Arturo_Gomez_Blanco_(PAGB666)" title="Pedro Arturo Gomez Blanco (PAGB666)">Blanco, Pedro</a>&nbsp;(25 November 2023). <a rel="nofollow" href="https://twitter.com/pagb666/status/1728543771149643856">"So... Romero just unveiled that the follow up to Sigil II will be "Hellion", a full 32 level effort ð."</a> <i>Twitter.</i> Retrieved 28 November 2023.</span>
</li>
</ol>

<!-- 
NewPP limit report
Cached time: 20231210195927
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.120 seconds
Real time usage: 0.127 seconds
Preprocessor visited node count: 1030/1000000
Preprocessor generated node count: 4455/1000000
Postâexpand include size: 9721/2097152 bytes
Template argument size: 6579/2097152 bytes
Highest expansion depth: 8/40
Expensive parser function count: 1/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   81.661      1 - -total
 18.30%   14.946      5 - Template:Cite_web_text
 14.96%   12.215      1 - Template:Wad
 13.16%   10.748      2 - Template:Cite_web
 11.51%    9.402     13 - Template:Maplinkgen
 10.54%    8.605      1 - Template:TimelyStub
  7.77%    6.343      1 - Template:TimeIssueBox
  5.88%    4.801      7 - Template:Condfullstop
  5.22%    4.260      1 - Template:BaseInfoBox
  2.95%    2.408      3 - Template:Wp
-->

<!-- Saved in parser cache with key doomwikidb:stable-pcache:idhash:50613-0!*!0!!en!4!* and timestamp 20231210195927 and revision id 427587
 -->
</div>
						<!-- end content -->
												
					</div>

				</article>
				<!-- /ARTICLE -->
				
			<!-- ARTICLE FOOTER -->
			
				<!-- /ARTICLE FOOTER -->

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inert pesticide ingredients may be more toxic to bees than scientists thought (172 pts)]]></title>
            <link>https://theconversation.com/inert-ingredients-in-pesticides-may-be-more-toxic-to-bees-than-scientists-thought-218005</link>
            <guid>38593008</guid>
            <pubDate>Sun, 10 Dec 2023 17:07:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/inert-ingredients-in-pesticides-may-be-more-toxic-to-bees-than-scientists-thought-218005">https://theconversation.com/inert-ingredients-in-pesticides-may-be-more-toxic-to-bees-than-scientists-thought-218005</a>, See on <a href="https://news.ycombinator.com/item?id=38593008">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Bees help pollinate over a third of the worldâs crops, contributing <a href="https://www.ipbes.net/article/press-release-pollinators-vital-our-food-supply-under-threat">an estimated US$235 billion to $577 billion</a> in value to global agriculture. They also face a myriad of stresses, including pathogens and parasites, loss of suitable food sources and habitat, <a href="https://theconversation.com/how-air-pollution-is-making-life-tougher-for-bugs-213122">air pollution</a> and <a href="https://theconversation.com/bees-face-many-challenges-and-climate-change-is-ratcheting-up-the-pressure-190296">climate-driven weather extremes</a>.</p>

<p>A <a href="https://doi.org/10.1038/s41598-023-46948-6">recent study</a> has identified another important but understudied pressure on bees: âinertâ ingredients in pesticides. </p>

<p>All pesticide products in the U.S. contain <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">active and inert ingredients</a>. Active ingredients are designed to kill or control a specific insect, weed or fungus and are listed on product labels. All other ingredients â emulsifiers, solvents, carriers, aerosol propellants, fragrances, dyes and such â are considered inert.</p>

<p>The new study exposed honeybees to two treatments: the isolated active ingredients in the fungicide <a href="https://www3.epa.gov/pesticides/chem_search/ppls/007969-00199-20221130.pdf">Pristine</a>, which is used to control <a href="https://agriculture.basf.us/content/dam/cxm/agriculture/crop-protection/products/documents/BASF_Pristine_Almonds_TIB_medres.pdf">fungal diseases in almonds</a> and <a href="https://www3.epa.gov/pesticides/chem_search/ppls/007969-00199-20221130.pdf">other crops</a>, and the whole Pristine formulation, including inert ingredients. The results were quite surprising: The whole formulation impaired honeybeesâ memory, while the active ingredients alone did not. </p>

<p>This suggests that the inert ingredients in the formula were actually what made Pristine toxic to bees â either because the inerts were toxic on their own or because combining them with the active ingredients made the active ingredients more toxic. As a <a href="https://scholar.google.com/citations?user=B1qAtjIAAAAJ&amp;hl=en">social scientist focusing on bee declines</a>, I believe that either way, these findings have important implications for pesticide regulation and bee health. </p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/QKTRYP2OF44?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>Threats to bees include single-crop agriculture, habitat loss, air pollution and pesticide exposure.</span></figcaption>
          </figure>

<h2>What are inert ingredients?</h2>

<p>Inert ingredients have a variety of functions. They may extend a pesticideâs shelf life, reduce risks for people who apply the pesticides or help a pesticide work better. Some inerts, called adjuvants, help pesticides stick to plant surfaces, reduce pesticide drift or help active ingredients better penetrate a plantâs surface. </p>

<p>The âinertâ label is a colloquial misnomer, though. As <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">the U.S. Environmental Protection Agency notes</a>, inerts arenât necessarily inactive or even nontoxic. In fact, pesticide users <a href="https://doi.org/10.1289%2Fehp.118-a168">sometimes know very little</a> about how inerts function in a pesticide formula. Thatâs partly because they are regulated very differently than active ingredients. </p>

<h2>Measuring bee effects</h2>

<p>Under the <a href="https://www.epa.gov/laws-regulations/summary-federal-insecticide-fungicide-and-rodenticide-act">Federal Insecticide, Fungicide, and Rodenticide Act</a>, or FIFRA, the EPA oversees pesticide regulation in the U.S. To register a pesticide product for outdoor use, chemical companies must provide <a href="https://www.epa.gov/sites/default/files/2016-07/documents/guidance-exposure-effects-testing-assessing-risks-bees.pdf">reliable risk assessment data</a> on the active ingredientsâ toxicity for bees, including the results of an acute honeybee contact test. </p>

<p>The acute contact test tracks how honeybees react to a pesticide application over a short period of time. It also aims to establish the dose of a pesticide that will kill 50% of a group of honeybees, a value known as the LD50. To determine the LD50, scientists apply the pesticide to beesâ midsections and then observe the bees for 48 to 96 hours for signs of poisoning. </p>



<p>In 2016, the EPA <a href="https://www.epa.gov/sites/default/files/2016-07/documents/guidance-exposure-effects-testing-assessing-risks-bees.pdf">expanded its data requirements</a> by requiring an acute honeybee oral toxicity test, in which adult bees are fed a chemical, as well as a 21-day honeybee larval test that tracks larval reaction to an agrochemical from the egg to their emergence as adult bees. </p>

<p>These tests all help the agency determine what potential risk an active ingredient may pose for honeybees, along with other data. Based on the information from these varied tests, pesticides are labeled as nontoxic, moderately toxic or highly toxic. </p>

<h2>A chemical black box</h2>

<p>Despite this rigorous testing, much remains unknown about how safe pesticides are for bees. This is particularly true for pesticides that have sublethal or chronic toxicities â in other words, pesticides that donât cause immediate death or obvious signs of poisoning but have other significant effects.</p>

<p>This lack of knowledge about sublethal and chronic effects is problematic, because bees can be repeatedly exposed over long time spans to pesticides on floral nectar or pollen, or to pesticide contamination that builds up <a href="https://doi.org/10.1371/journal.pone.0009754">in beehives</a>. They even may be exposed <a href="https://doi.org/10.1093/aesa/saaa041">through miticides</a> that beekeepers use to control Varroa mites, a <a href="https://www.ars.usda.gov/pacific-west-area/tucson-az/carl-hayden-bee-research-center/research/varroa/varroa-overview/">devastating bee parasite</a>.</p>

<p>Complicating the issue, symptoms of sublethal exposure are often more subtle or take longer to become apparent than acute or lethal toxicity. <a href="https://dx.doi.org/10.5772/62487">Symptoms might include</a> abnormal foraging and learning ability, decreased egg laying by the queen, wing deformation, stunted growth or decreased colony survival. The EPA doesnât always require chemical companies to perform the tests that could detect these symptoms.</p>

<p>Inert ingredients add another level of mystery. While the EPA reviews and <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">must approve all inert ingredients</a>, it does not require the same toxicity testing as for active ingredients. </p>

<p>This is because under FIFRA, inert ingredients are protected as trade secrets, or <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">confidential business information</a>. Only the total percentage of inert ingredients is required on the label, often lumped together and described as âother ingredients.â</p>

<figure>
            <a href="https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A box shows that a pesticide has 0.375% active ingredients and 99.625% 'other' ingredients." data-src="https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=167&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=167&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=167&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=210&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=210&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=210&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>Sample pesticide ingredient label from an EPA training guide, showing that just 0.375% of ingredients are disclosed and tested for bee safety.</span>
              <span><a href="https://www.epa.gov/pesticide-labels/label-review-training-module-3-special-issues-page-34">EPA</a></span>
            </figcaption>
          </figure>

<h2>Sublethal weapons</h2>

<p>A growing body of evidence suggests that inerts are not as harmless as the name suggests. For example, exposure to two types of adjuvants â organosilicone and nonionic surfactants â can <a href="https://doi.org/10.1371/journal.pone.0040848">impair honeybeesâ learning performance</a>. Bees rely on learning and memory functions to gather food and return to the hive, so losing these crucial skills can endanger a colonyâs survival. </p>

<p>Inerts can also affect bumblebees. In a 2021 study, exposure to alcohol ethoxylates, a coformulant in the fungicide Amistar, <a href="https://doi.org/10.1038/s41598-021-00919-x">killed 30% of the bees exposed to it</a> and caused a number of sublethal effects.</p>

<p>While some inerts may be nontoxic on their own, itâs hard to predict what will happen when they are combined with active ingredients. Research has shown that when two or more agrochemicals are combined, they can <a href="https://doi.org/10.1038/s41586-021-03787-7">become more toxic for bees</a> than when applied on their own. This is known as <a href="https://www.ccohs.ca/oshanswers/chemicals/synergism.html">synergistic toxicity</a>. </p>

<p>Synergism can also occur when inerts are combined with pesticides. Another 2021 study showed that adjuvants that were nontoxic on their own caused <a href="https://doi.org/10.1007/s41348-021-00541-z">increased colony mortality when combined with insecticides</a>. </p>

<figure>
            <a href="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A bee in flight, covered with yellow pollen grains." data-src="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=506&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=506&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=506&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=635&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=635&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=635&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip"></p></a>
            <figcaption>
              <span>A sweat bee (<em>Halictus ligatus</em>) covered with pollen.</span>
              <span><a href="https://flic.kr/p/dJ9ZZ4">Sam Droege, USGS/Flickr</a></span>
            </figcaption>
          </figure>

<h2>A better testing strategy</h2>

<p>Mounting evidence on the toxicity of inerts points to three key changes that could better support bee health and minimize beesâ exposure to potential stressors. </p>

<p>First, environmental risk assessments for pesticides could test the whole pesticide formulation, including inert ingredients, to provide a more complete picture of a pesticideâs toxicity to bees. This is already done <a href="https://www.epa.gov/pollinator-protection/pollinator-risk-assessment-guidance">in some cases</a> but could be required for all outdoor uses where bees are at risk of exposure.</p>

<p>Second, inerts could be identified on product labels to enable independent research and risk assessment. </p>

<p>Third, more testing could be required on pesticidesâ long-term sublethal effects on bees, such as learning impairment. Such research would be especially relevant for pesticides that are applied to blooming crops or flowers that attract bees.</p>

<p>Researchers and environmental groups have been arguing for changes like these since <a href="https://doi.org/10.1289/ehp.9374">at least 2006</a>. However, because pesticide regulation is dictated by federal law, changes require congressional action. This would be challenging politically, since it would increase the regulatory burden on the chemical industry. </p>

<p>Nonetheless, rising concerns about <a href="https://doi.org/10.1146/annurev-ento-011118-111847">bumblebee declines</a> and beekeepersâ significant <a href="https://beeinformed.org/wp-content/uploads/2023/06/BIP-2022-23-Loss-Abstract.pdf">annual colony losses</a> make a strong case for a more precautionary approach to pesticide regulation. With a growing world population and <a href="https://theconversation.com/cop28-7-food-and-agriculture-innovations-needed-to-protect-the-climate-and-feed-a-rapidly-growing-world-218414">food supplies under increasing stress</a>, supporting beesâ contribution to agriculture is more important then ever.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Methane under the seabed is thawing as oceans warm â it's worse than we thought (173 pts)]]></title>
            <link>https://theconversation.com/frozen-methane-under-the-seabed-is-thawing-as-oceans-warm-and-things-are-worse-than-we-thought-216054</link>
            <guid>38592450</guid>
            <pubDate>Sun, 10 Dec 2023 16:05:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/frozen-methane-under-the-seabed-is-thawing-as-oceans-warm-and-things-are-worse-than-we-thought-216054">https://theconversation.com/frozen-methane-under-the-seabed-is-thawing-as-oceans-warm-and-things-are-worse-than-we-thought-216054</a>, See on <a href="https://news.ycombinator.com/item?id=38592450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Buried beneath the oceans surrounding continents is a naturally occurring frozen form of methane and water. Sometimes dubbed âfire-iceâ as you can literally set light to it, marine methane hydrate can melt as the climate warms, uncontrollably releasing methane â a potent greenhouse gas â into the ocean and possibly the atmosphere. </p>

<p>Colleagues and I have just published <a href="https://rdcu.be/dsTTt">research</a> showing more of this methane hydrate is vulnerable to warming than previously thought. This is a worry as that hydrate contains about as much carbon as all of the remaining oil and gas on Earth. </p>

<p>Releasing it from the seabed could cause the oceans to become more acidic and the climate to warm further. This is a dangerous set of circumstances. </p>

<p>The massive venting of methane from similar ancient marine hydrate reservoirs has been linked to some of the severest and most rapid climate changes in the Earthâs history. There is even evidence that the process has started again near the <a href="https://www.nature.com/articles/nature11528">east coast of the US</a>. </p>

<p>I have worked on hydrates for over a decade, mainly looking at the methane hydrate offshore of Mauritania, West Africa. Recently I have taken 3D seismic data intended to reveal oil and gas and repurposed it to map out the hydrates under the ocean floor. Ultimately, I wanted to work out if climate change is causing methane to bubble to the surface. </p>

<p>3D seismic is the geologistâs equivalent of the doctorâs CT scan. It can cover hundreds of square kilometres, and can reveal hydrates a few kilometres below the seabed. Hydrate is easily identified in these giant surveys because the sound waves created by a source of seismic energy towed by a ship reflect off the bottom of the hydrate layers.  </p>

<h2>Looking for methane using 3D seismic imagery</h2>

<p>As I settled into a new way of life during the first COVID lockdown in early 2020, I reopened the much-studied dataset and started mapping again. I knew there were many examples of hydrate that had thawed as a result of warming since the last glacial period peaked some 20,000 years ago, and I knew we could detect this on the 3D datasets. </p>

<p>But what was the fate of the methane? Did it reach the oceans and atmosphere? Because if it did, this is a major clue that it could happen again.</p>

<p>Around continents, where the oceans are relatively shallow, hydrate is only just cold enough to remain frozen. So it is very vulnerable to any warming, and that is why these areas have been the focus of most scientific investigations. </p>

<figure>
            <a href="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="World map with shaded areas near the coasts" data-src="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=357&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=357&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=357&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=449&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=449&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=449&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Where known methane hydrates can be found.</span>
              <span><a href="https://www.researchgate.net/figure/Estimated-methane-hydrate-occurrences-in-the-world-This-map-is-taken-from-the-World_fig2_277009736">World Ocean Review (data: Wallmann et al)</a>, <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a></span>
            </figcaption>
          </figure>

<p>The good news is that only 3.5% of the worldâs hydrate resides in the vulnerable zone, in this precarious state. Most hydrate is instead deemed to be âsafeâ, buried hundreds of metres below the seabed in deeper waters tens of kilometres further from land.</p>

<p>But frozen methane in the deep ocean may vulnerable after all. In oceans and seas where the water is deeper than around 450 metres to 700 metres are layer upon layer of sediment that contains the hydrate. And some of it is deeply buried and warmed geothermally by the Earth so, despite being hundreds of metres below the seafloor, it is right at the point of instability. </p>

<p>Some layers of sediment are permeable and create a complex underground plumbing for the gas to move through if itâs liberated during climatic warming. Just like holding a football underwater methane gas wants to push upwards because of its buoyancy and burst through the 100s of metres of sediment layers. </p>

<p>Imposed upon this complex geology has been the seven glacials (or ice ages) and interglacials, which warmed and cooled the system repeatedly over the last million years.</p>

<figure>
            <a href="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="Diagram cross section of sea bed showing rock strata, and map of craters." data-src="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=336&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=336&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=336&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=422&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=422&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=422&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Example of the sort of seismic images the author used. Left: reflections that represent sedimentary strata and a vertical pipe where methane has pushed upwards and a buried crater that formed as methane vented into the ancient ocean. Right: a map showing other examples of these craters.</span>
              <span><span>Richard Davies</span>, <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a></span>
            </figcaption>
          </figure>

<h2>Methane is migrating</h2>

<p>During this first lockdown of 2020 I found spectacular evidence that during warm periods during the last million or so years methane migrated laterally, upwards and landwards toward Africa and leaked in much shallower water. Beneath a layer of up to 80 metres of sediment are 23 giant craters on the ancient seabed, each one kilometre wide and up to 50 metres deep, big enough to be filled with multiple Wembley stadiums. </p>

<p>The seismic imaging provides the tell tale signs of methane immediately below the craters. And similar craters elsewhere form due to prolonged or explosive release of gas at the seabed. </p>

<p>These craters are not located in the vulnerable zone where all the attention has been â they are landward of it at about 330 metres water depth. With the discovery in hand, I gathered an international team of scientists (modellers, physicists, geoscientists) to work out what caused the formation of these remarkable things and when they formed. Our results are now published in <a href="https://rdcu.be/dsTTt">Nature Geoscience</a>.</p>

<p>We believe they formed as a result of repeated warming periods. These periods impacted hydrate in the deep ocean and the released methane migrated up to 40km towards the continent, to be vented beyond the shallowest hydrate deposits. So during a warming world the volume of hydrate that will be vulnerable to leaking methane is more significant than previously thought. </p>

<p>The positive outlook is that there are many natural barriers to this methane. But be warned, we expect that in some places on earth, as we warm the planet, methane from the deep will escape into our oceans.</p>

<hr>

<figure>
            <p><img alt="Imagine weekly climate newsletter" data-src="https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=600&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=600&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=600&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=754&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=754&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=754&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip"></p>
            <figcaption>
              <span></span>
              
            </figcaption>
          </figure>

<p><strong><em>Donât have time to read about climate change as much as youâd like?</em></strong>
<br><em><a href="https://theconversation.com/uk/newsletters/imagine-57?utm_source=TCUK&amp;utm_medium=linkback&amp;utm_campaign=Imagine&amp;utm_content=DontHaveTimeTop">Get a weekly roundup in your inbox instead.</a> Every Wednesday, The Conversationâs environment editor writes Imagine, a short email that goes a little deeper into just one climate issue. <a href="https://theconversation.com/uk/newsletters/imagine-57?utm_source=TCUK&amp;utm_medium=linkback&amp;utm_campaign=Imagine&amp;utm_content=DontHaveTimeBottom">Join the 20,000+ readers whoâve subscribed so far.</a></em></p>

<hr>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Warrant Showing the U.S. Government Is Monitoring Push Notifications (205 pts)]]></title>
            <link>https://www.404media.co/us-government-warrant-monitoring-push-notifications-apple-google-yahoo/</link>
            <guid>38592243</guid>
            <pubDate>Sun, 10 Dec 2023 15:40:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/us-government-warrant-monitoring-push-notifications-apple-google-yahoo/">https://www.404media.co/us-government-warrant-monitoring-push-notifications-apple-google-yahoo/</a>, See on <a href="https://news.ycombinator.com/item?id=38592243">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p><em>This article was produced in collaboration&nbsp;</em><a href="https://www.courtwatch.news/?utm_source=substack&amp;utm_medium=web&amp;utm_campaign=substack_profile" rel="noreferrer noopener"><em><u>with Court Watch</u></em></a><em>, an independent outlet that unearths overlooked court records.</em></p><p>The U.S. government is demanding that tech companies provide information related to push notifications in order to identify a targetâs specific device, <a href="https://www.documentcloud.org/documents/24192651-push-notification-search-warrant-application?ref=404media.co"><u>according to a court record</u></a> reviewed by 404 Media. The finding comes as Senator Ron Wyden published a letter on Wednesday warning that the U.S. and foreign governments are making such surveillance demands around push notifications to Apple and Google.&nbsp;</p><p>It is not totally clear if the demand for data related to push notifications mentioned in the court record is one and the same as that described at a high level in Wydenâs letter. Regardless, the court record provides more clarity on the legal mechanisms being used in at least some cases to request information related to push notifications, and what sort of crimes this novel surveillance technique is being used against.&nbsp;</p><p>âIn the spring of 2022, my office received a tip that government agencies in foreign countries were demanding smartphone âpushâ notification records from Google and Apple. My staff have been investigating this tip for the past year, which included contacting Apple and Google,â <a href="https://www.documentcloud.org/documents/24191267-wyden_smartphone_push_notification_surveillance_letter_to_doj_-_signed?ref=404media.co"><u>the letter</u></a> from Senator Wyden to Attorney General Merrick B. Garland reads. <a href="https://www.reuters.com/technology/cybersecurity/governments-spying-apple-google-users-through-push-notifications-us-senator-2023-12-06/?ref=404media.co"><u>Reuters was first to report</u></a> the letter.</p><div><p>ð±</p><p><b><strong>Do you know anything else about push notification surveillance? I would love to hear from you. Using a non-work device, you can message me securely on Signal at +44 20 8133 5190. Otherwise, send me an email at joseph@404media.co.</strong></b></p></div><p>As the letter explains, push notifications are not sent directly from an app provider to a userâs smartphone. Instead, âthey pass through a kind of digital post office run by the phoneâs operating system provider,â typically meaning Apple or Google.&nbsp;</p><p>When a user gets a push notification on their phone, Apple or Google receive a lot of information, including metadata that shows which app received a notification, and which phone and associated Google or Apple account it was to be sent to, Wyden says in his letter. In some cases, unencrypted content like the actual text displayed in the notification may be included too, Wyden adds.</p><p>The letter does not disclose the legal mechanism used by governments to demand this data from Apple or Google. But the court record reviewed by 404 Media does include some specifics around push notification demands. <a href="https://www.courtwatch.news/?ref=404media.co"><u>Court Watch</u></a> shared the record with 404 Media. The record is a search warrant application from May 2020 related to the investigation of a person suspected of theft or bribery concerning programs receiving federal funds.</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>In the search warrant application for information associated with a specific Yahoo email account, an FBI Special Agent writes under a section of the record entitled âBackground Information Regarding Provider Servicesâ that when a user of a mobile app installs and launches an app, the app will direct the device to obtain a âPush Token.â This is âa unique identifier that allows the provider associated with the application [...] to locate the device on which the application is installed.â</p><figure><div><p><img src="https://www.404media.co/content/images/2023/12/push-notifications-1.png" width="1064" height="538" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/push-notifications-1.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/push-notifications-1.png 1000w, https://www.404media.co/content/images/2023/12/push-notifications-1.png 1064w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.404media.co/content/images/2023/12/push-notifications-2.png" width="1040" height="422" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/push-notifications-2.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/push-notifications-2.png 1000w, https://www.404media.co/content/images/2023/12/push-notifications-2.png 1040w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p dir="ltr"><span>Screenshots from the search warrant application.</span></p></figcaption></figure><p>The court record then points specifically to Apple and Google, adding âAfter the applicable push notification (e.g., Apple Push Notifications (APN) or Google Cloud Messaging) sends a Push Token to the device, the Token is then sent to the application, which in turn sends the Push Token to the applicationâs server/provider.â When a company then sends push notifications, it sends both the token itself and what the court record describes as the âpayloadâ associated with the notification, âthe substance of what needs to be sent by the application to the device.â</p><p>The Special Agent adds that these Push Tokens are stored on the relevant tech companyâs servers, and that these may help identify a specific phone or computer used by the target. Or, as the Special Agent puts it, âAccordingly, the computers of PROVIDER are likely to contain useful information that may help to identify the specific device(s) used by a particular subscriber to access the subscriberâs PROVIDER account via the mobile application.â</p><p>It is not clear if this is boilerplate language that has been included in the search warrant application or whether the agent was specifically seeking this information from Yahoo.</p><p>As Wydenâs letter continues, âas with all of the other information these companies store for or about their users, because Apple and Google deliver push notification data, they can be secretly compelled by governments to hand over this information.â</p><p>Wyden concludes the letter by saying that Apple and Google should be permitted to âgenerally reveal whether they have been compelled to facilitate this surveillance practice,â and to publish aggregate data on the number of demands they have received. When Reuters contacted Apple for comment, the company told the outlet that Wydenâs letter gave them the opening needed to share more details about how governments monitor push notifications.</p><p>âIn this case, the federal government prohibited us from sharing any information,â Apple told Reuters in a statement. âNow that this method has become public we are updating our transparency reporting to detail these kinds of requests.â Reuters cited a source familiar with the matter who described the foreign governments involved in making the requests as democracies allied to the U.S. government.</p><p>Apple did not immediately respond to 404 Mediaâs request for comment on the legal mechanisms used against push notification-related data. A Google spokesperson told 404 Media in an emailed statement that âWe were the first major company to publish a public transparency report sharing the number and types of government requests for user data we receive, including the requests referred to by Senator Wyden. We share the Senatorâs commitment to keeping users informed about these requests.â</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>The full section of the court record discussing push notifications is included below.</p><blockquote><em>PROVIDER also allows its subscribers to access its various services through an application that can be installed on and accessed via cellular telephones and other mobile devices. This application is associated with the subscriberâs PROVIDER account. In my training and experience, I have learned that when the user of a mobile application installs and launches the application on a device (such as a cellular telephone), the application directs the device in question to obtain a Push Token, a unique identifier that allows the provider associated with the application (such as PROVIDER) to locate the device on which the application is installed. After the applicable push notification (e.g., Apple Push Notifications (APN) or Google Cloud Messaging) sends a Push Token to the device, the Token is then sent to the application, which in turn sends the Push Token to the applicationâs server/provider. Thereafter, whenever the provider needs to send notifications to the userâs device, it sends both the Push Token and the payload associated with the notification (i.e., the substance of what needs to be sent by the application to the device). To ensure this process works, Push Tokens associated with a subscriberâs account are stored on the providerâs server(s). Accordingly, the computers of PROVIDER are likely to contain useful information that may help to identify the specific device(s) used by a particular subscriber to access the subscriberâs PROVIDER account via the mobile application.</em></blockquote>
                    <div>
    <div>
      <p>About the author</p>
      <p>Joseph is an award-winning investigative journalist focused on generating impact. His work has triggered hundreds of millions of dollars worth of fines, shut down tech companies, and much more.</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/404-joseph-01-1.jpg" alt="Joseph Cox" src="https://www.404media.co/content/images/2023/08/404-joseph-01-1.jpg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Write your own retro compiler (292 pts)]]></title>
            <link>http://t3x.org/t3x/0/book.html</link>
            <guid>38591662</guid>
            <pubDate>Sun, 10 Dec 2023 14:18:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://t3x.org/t3x/0/book.html">http://t3x.org/t3x/0/book.html</a>, See on <a href="https://news.ycombinator.com/item?id=38591662">Hacker News</a></p>
<div id="readability-page-1" class="page">



<hr>

<center><h2>RETRO COMPILER</h2></center>

<center><p>
Lulu Press, 2023 â¢ 339 pages â¢ 91 figures â¢ 6"&nbsp;x&nbsp;9" format<br>
All code from the book is in the public domain!
</p></center>

<a href="http://t3x.org/t3x/0/retro.jpg"><img src="http://t3x.org/t3x/0/retro-s.jpg"></a>

<center><p>
<a href="https://www.lulu.com/shop/nils-holm/write-your-own-retro-compiler/ebook/product-zmm9z72.html?page=1&amp;pageSize=4">Order a <b>PDF</b> copy at Lulu.com</a><br>
<a href="https://www.lulu.com/shop/nils-m-holm/write-your-own-retro-compiler/paperback/product-e778nrw.html?page=1&amp;pageSize=4">Order a <b>paperback</b> copy at Lulu.com</a><br>
<a href="http://t3x.org/t3x/0/toc.pdf">View the Table of Contents (PDF)</a><br>
<a href="http://t3x.org/t3x/0/retro-compiler-sample.pdf">Read some sample pages (PDF)</a><br>
<a href="http://t3x.org/t3x/0/t3x0-12.zip">Download the Sources</a><br>
</p></center>

<h2>Enjoy old computers?</h2>
<h2>New to compiler-writing?</h2>
<h2>This book has you covered!</h2>

<p>Study the complete source code for a self-hosting compiler
that runs on and generates code for CP/M on the Z80 processor.
No prior knowledge in the field of compiler construction is required.
The <a href="http://t3x.org/t3x/0/index.html">T3X/0</a> language that is discussed and
implemented in the book
has its roots in Pascal and BCPL and is very simple. A full 20-page
manual is contained in the book.
</p>

<p><b>Prerequisits</b>: The reader should know at least
one procedural programming language, such as C or Pascal,
and at least one assembly language, ideally the one for the
Z80 CPU. They should also know the basics of the CP/M
operating system. For the determined autodicact a short
introduction to Z80 assembly language is also included in
the book.
</p>

<h2>This book cuts no corners!</h2>

<p>Everything is discussed in great details with lots of diagrams,
tables, and examples.</p>

<ul>
 <li>Lexical analysis
 </li><li>Syntax analysis
 </li><li>Code generation
 </li><li>Simple optimizations
 </li><li>The BDOS interface
 </li><li>The run time library
</li></ul>

<p>Get the code: <a href="http://t3x.org/t3x/0/index.html">www.t3x.org/t3x/0/</a>
</p>

<hr>

<p><a href="http://t3x.org/contact.html">contact</a> &nbsp;|&nbsp;
<a href="http://t3x.org/privacy.html">privacy</a>
</p>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bad news, Emacs (331 pts)]]></title>
            <link>https://eshelyaron.com/posts/2023-12-10-bad-news.html</link>
            <guid>38591584</guid>
            <pubDate>Sun, 10 Dec 2023 14:07:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshelyaron.com/posts/2023-12-10-bad-news.html">https://eshelyaron.com/posts/2023-12-10-bad-news.html</a>, See on <a href="https://news.ycombinator.com/item?id=38591584">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<header>

<p role="doc-subtitle">Troubles registered in Emacs 30</p>
</header><p>Created on <span><span>[2023-12-10]</span></span>, last updated <span><span>[2023-12-10]</span></span></p>

<p>
<b>NOTE:</b> the following contains several hyperboles that reflect my
emotions, and should probably be taken with a grain of salt, or not at
all. While I am intentionally expressing criticism, I most sincerely
hope not to offend anyone.
</p>
<p>
The <a href="https://eshelyaron.com/notes/emacs.html" title="Notes about Emacs (this free software text OS thingy here)">Emacs</a> master branch is brokenâfor good, it seems. Emacs
maintainers accepted a heavy-handed, harmful change, disregarding
concerns voiced by multiple users and developers. Iâve created a
fixed, and improved, Emacs fork. Iâll be using and developing this
fork, and youâre welcome to join.
</p>
<p>
Letâs take a step back. What is the Emacs master branch? Thatâs
essentially the development version of Emacs, and what will soon
become Emacs version 30. Many Emacs hackers and enthusiasts track the
master branch to enjoy all of the latest developments and
improvements. Thanks to the tireless work of the Emacs maintainers in
scrutinizing incoming patches, the Emacs master branch has been very
stable in recent years. But a few weeks ago, Emacs master users got a
very unpleasant surprise.
</p>
<div>
<pre><span>commit 589e6ae1fb983bfba42f20906773555037246e45</span>
<span>Author: Thierry Volpiatto</span>
<span>Date:   Sun Nov 19 20:42:56 2023 +0100</span>

<span>Improve register-preview (bug#66394)</span>

<span>    A minibuffer is used now instead of read-key.</span>
    ...
</pre>
</div>
<p>
This commit crippled all user interaction with Emacs registers,
turning commands such as <code>C-x r s</code>, once smooth and frictionless, into
a cumbersome and painful mess. Concretely, instead of just typing the
key for the register you want to operate on, you now get a fully blown
minibuffer for inserting a single key. This is nonsensical in various
ways, but most staggering is probably the fact that you now need to
confirm your register selection by pressing another <code>RET</code>, effectively
doubling the work you have to do for the simplest task of specifying a
single character.
</p>
<p>
Emacs registers (used to) provide a perfect UX. Silky smooth, really.
But no more, not in GNU Emacs 30. Itâs gone, without as much as a
<code>NEWS</code> entry to inform the unwary user about this regression.
</p>
<p>
Surely, itâs not too late to revert one bad change, right? Thatâs
what I thought, unfortunately the Emacs maintainers seem bent on
dismissing the communityâs outcry in an unwarranted and misguided
attempt to save face.
</p>
<p>
In fact, the core problems with this change were brought up already in
the first technical <a href="https://yhetil.org/emacs/87sf67qqmp.fsf@web.de/">comment</a> regarding this patch proposal, from
Michael Heerdegen:
</p>
<blockquote>
<p>
If your version is accepted, I would vote for an option to get the old
behavior back. Your intended behavior is safer but requires more keys
(at least confirmation with RET). Some people might prefer the old
way.
</p>
</blockquote>
<p>
Well, duh! If youâre gonna change long standing Emacs behavior, it
better be optional and backward compatible, people have been using
this thing for decades, after all. Hmm apparently, the patch author,
Thierry, doesnât see it that way:
</p>
<blockquote>
<p>
There is only RET as additional key and it is a good thing IMO as it
let the time to user to see what he is doing.
</p>
</blockquote>
<p>
This rather arrogant statement, and the approach that underlies it,
led us to where we are today. After some further discussion, <a href="https://eshelyaron.com/notes/eli-zaretskii.html" title="Notes about Eli Zaretskii (Emacs maintainer)">Eli
Zaretskii</a> applied this patch to Emacs master. Iâm not sure he
understood the breaking nature of this change when he did that, which
I think might be even more disconcerting.
</p>
<p>
Soon after, Bastien Guerry chimed in, saying:
</p>
<blockquote>
<p>
I use registers ~100 times a day, so enhancements here are very
welcome, thanks!
</p>
<p>
I wonder about this [change], though. It badly hinders my usual flow,
where I do remember what registers I use and like to store new ones
quickly.
</p>
</blockquote>
<p>
Sounds like a clear and honest testimony from an esteemed community
member. But wait, no, Thierry doesnât think so, he thinks itâs all
for the better and his change is all right. At this point I got
somewhat involved, and seconded Bastienâs request to restore the
previous, perfectly good behavior, at least optionally. Thierry
wasnât willing to fix this damage, so Eli asked me to help out:
</p>
<blockquote>
<p>
So maybe a better way forward is for someone, perhaps you Eshel, to
add whatever is needed to provide optionally the previous behavior?
</p>
<p>
Would you like to work on that?
</p>
</blockquote>
<p>
Easy enough. I crafted and <a href="https://yhetil.org/emacs/m1wmtvnfpn.fsf@dazzs-mbp.home/">posted</a> a couple of patches that add some
bells and whistles from Thierryâs patch in an optional and compatible
manner. Itâs really not that hard to make no harm in this case. But
my work was disregarded just as well, sadly. Thierry didnât like how
I reverted his change to use the minibuffer for reading a single key,
which is exactly the root cause of the problems I tried to fixâand
in fact I did fix it, just not in Emacs master, but in my new fork.
</p>
<p>
Since then, <a href="https://yhetil.org/emacs/CA+Nei8MfEw_iDj3Xjbzop+7n-oqNp1jSJcweOgEQMKUkB3mifQ@mail.gmail.com/">another bug report</a> came in from an Emacs master branch
user that suffered from one of the consequences of this change (a
specific regression that I spelled out days before, but was ignored,
for some reason), and several users reached out to the Emacs
development in request to restore the previous behavior in an ongoing
thread titled <a href="https://yhetil.org/emacs/CAFgA-y2wUR0tGRk+RkUGn2TF2YoMyf3B=+78TGyDZP5+Ew2uyA@mail.gmail.com/">âPlease, Restore Previous Behavior for
jump-to-registerâ</a>. Astonishingly, the maintainers seem insistent
not to budge, and Emacs 30 will thus likely suck.
</p>
<p>
I find the willingness of the Emacs maintainers to entertain this bad
behavior (of both a rouge developer and of Emacs itself) at the
expense of user experience, unacceptable. This demonstrates clear
disrespect for Emacs user preferences, and indeed their freedom.
</p>
<p>
For me, this freedom is the number one reason for using Emacs, so I
obviously wonât use an Emacs that forces on me weird breaking changes.
For that reason Iâve created a new Emacs branch, the âmainâ branch,
which was born from the master branch before this registers fiasco.
</p>
<p>
If these changes will be reverted before Emacs 30, Iâll surely
consider switching back to building Emacs from the upstream master
branch. But in the meantime, and for the foreseeable future, Iâll be
keeping my main branch up to date by cherry picking (only) good
changes from the master branch. And of course, I also improve it with
developments of my own.
</p>
<p>
If youâre interested, feel free to checkout my main branch from here:
</p>
<div>
<pre>git clone git://git.eshelyaron.com/emacs.git

git clone https://git.sr.ht/~eshel/emacs
</pre>
</div>
<p>
Iâll be happy to coordinate and incorporate otherâs work. <a href="https://eshelyaron.com/cdn-cgi/l/email-protection#513c3411342239343d2830233e3f7f323e3c">Let me know</a>
if you have any suggestions, thoughts, or nice harmless patches that I
should try out.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Best UI design courses for hackers? (273 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38591437</link>
            <guid>38591437</guid>
            <pubDate>Sun, 10 Dec 2023 13:37:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38591437">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38592333"><td></td></tr>
                <tr id="38593315"><td></td></tr>
            <tr id="38592464"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592464" href="https://news.ycombinator.com/vote?id=38592464&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Iâm a fairly experienced product designer and this book has been incredibly valuable even for me. Lots of <i>extremely</i> practical insights packed in here. IMO a must-read for engineers and designers alike, if youâre building something where you need to care about point-and-click UI at all.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592989"><td></td></tr>
            <tr id="38592629"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592629" href="https://news.ycombinator.com/vote?id=38592629&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Should be noted, this booked was created by the Tailwind CSS folks (before Tailwind existed IIRC).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592912"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592912" href="https://news.ycombinator.com/vote?id=38592912&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Came here to mention Refactoring UI. I think the structure makes it very valuable: Each one is focused on a particular problem or topic. So if you need help with font weights or spacing or shadows there is a chapter for that and I often go back and look at a specific chapter when I encounter a problem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592065"><td></td></tr>
                <tr id="38592383"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592383" href="https://news.ycombinator.com/vote?id=38592383&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Whenever this question comes up, the usual suspects like "The Design of Everyday things" get mentioned and I can't help wonder what it would be like if someone asked for books about learning to program [websites] and kept getting "Godel, Escher Bach", "Zen and Art of Motorcycle Maintenance" or "Meditations" by Marcus Aurelius.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38592555"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592555" href="https://news.ycombinator.com/vote?id=38592555&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Unless you read The art of war you cannot possibly become a 10x ninja developer. /s<p>More seriously, I have read the design of everyday things about 10 years ago and it was one of the most boring books I have ever had to go through. I only remember doorknobs and something about affordances. Read refactoringUI as well, some vague shiny UI tips of which can't remember any but 'have decent spacing'. I still can't design even a simple form. I am starting to suspect that if one wants to be good at web design one needs to start doing lots of web design until one gets better. Reading books may come later to place that practical knowledge in some coherent mental framework.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593057"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593057" href="https://news.ycombinator.com/vote?id=38593057&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>These books are a solid foundation for design education, but also design is its own deep field of expertise that youâre not going to learn after a a book or two. Both things can be true.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592721"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38592721" href="https://news.ycombinator.com/vote?id=38592721&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Thatâs interesting. I went through that book not that long ago and I found it fascinating. I had a hard time putting it down.<p>I found that the concepts he covers in that book can even be applied for good software API design.</p><p>Also, he did spoil doors for me. Pretty much every building I go into now annoys me because of the stupid door handles they pick.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593131"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593131" href="https://news.ycombinator.com/vote?id=38593131&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>DOET is very helpful in getting you to understand how to think from a user perspective.<p>I found it to be one of the most useful books in my development as an application programmer.</p><p>It teaches you how to see UI
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592541"><td></td></tr>
                  <tr id="38592206"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592206" href="https://news.ycombinator.com/vote?id=38592206&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Woah, that's a long list of resources, thanks. I've read a few of those ((1), (2), (7)).<p>(3) is new to me. Will give it a read for sure.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592194"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592194" href="https://news.ycombinator.com/vote?id=38592194&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Anyone heard from Tog (#4 above)? The cert on his website, asktog.com, appears to have expired and no new content since 2014.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592665"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592665" href="https://news.ycombinator.com/vote?id=38592665&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>I am a longtime developer but I'm passionate about design and UX. I'm always on the lookout for materials that I can give my team and other developers to help them get better at design. It's not a course, but "The Non-Designer's Design Book" (ISBN 978-0133966152, Robin Williams) is the best material for design fundamentals I've found. It's very approachable for anyone and it's broadly applicable across all kinds of design. Everyone I have convinced to read it has loved it, and I've seen an improvement in output and understanding. I highly recommend this if you have an interest in design.<p>Refactoring UI is also valuable and can be impactful, though it's heavily web focused and is more like a Web Component Design Cookbook rather than foundational knowledge.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592996"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592996" href="https://news.ycombinator.com/vote?id=38592996&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>I found Design for Hackers[1] to be an incredibly informative book; it provides a great deal of insight into UI patterns, color schemes and selections, and overall UI design. It's definitely more oriented towards graphical UIs but provides enough general insight into design considerations that you could generalize it for TUIs and CLIs if needed.<p>[1]: <a href="https://designforhackers.com/" rel="nofollow noreferrer">https://designforhackers.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592264"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592264" href="https://news.ycombinator.com/vote?id=38592264&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>It's definitely not cheap, but I would be surprised if Erik Kennedy's <a href="https://www.learnui.design/" rel="nofollow noreferrer">https://www.learnui.design</a> isn't the best course out there.  In fact, he has three courses:<p>1. UI design</p><p>2. UX design</p><p>3. Landing Page design</p><p>I own all 3 and they are among the best purchases I've ever made, even at the cost.  Erik is a former programmer who has taken the engineers mindset and systematically analyzed and broken down the various parts of UI design.  It is very practical, which was something that was lacking in most resources I found when I was in your position.</p><p>If anyone is interested, I would recommend starting with the UI course, which probably runs around $1000.  Unfortunately It is only available at certain intervals, probably every 6-8 weeks.</p><p>If the cost is intimidating, you can get a lot out of his blog, which will also give you a taste of how he thinks about design: <a href="https://www.learnui.design/blog/" rel="nofollow noreferrer">https://www.learnui.design/blog/</a>.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593306"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593306" href="https://news.ycombinator.com/vote?id=38593306&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Seconding this. Not cheap, but so worth the money. Learn UI design and RefactoringUI are the best resources I've found for engineers who want to learn design. I'm just starting Erik's Landing Page course now, and so far it's also really good.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592693"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592693" href="https://news.ycombinator.com/vote?id=38592693&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>With RefactoringUI and Erik's course, I think the 3rd I would use to complete my top 3 is Shift Nudge (<a href="https://shiftnudge.com/" rel="nofollow noreferrer">https://shiftnudge.com/</a>).<p>There's a fair amount of overlap between all of them, so if you want to Pareto minmax it, I would recommend starting with Refactoring UI, which should help provide practical solutions to many situations and get rid of the most egregious horrors you might commit.</p><p>Of course, UI design goes much deeper than anything those courses can teach, but they're a great start.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593028"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593028" href="https://news.ycombinator.com/vote?id=38593028&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>&gt; <a href="https://shiftnudge.com/" rel="nofollow noreferrer">https://shiftnudge.com/</a><p>Only commenting about it as that site is a course about designing interfaces: to me the font on that site borderline is ridiculous, with the flat lines on the t/f/g, narrow L, an ampersand that looks like an 'e' with a long tail. Makes it hard to read
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592661"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592661" href="https://news.ycombinator.com/vote?id=38592661&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Seems like a gem of a resource; took a look at the blog, and already found a great principle ("rule of locality; place button where the data is") which I had violated just today. Thanks for the recommendation.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592720"><td></td></tr>
            <tr id="38591962"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591962" href="https://news.ycombinator.com/vote?id=38591962&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Not sure if this fits your goal of a UI design course, but I found Josh Comeau's CSS for JS Devs course to be a great way to learn the fundamentals of CSS in a way that resonated with my developer mindset.<p><a href="https://css-for-js.dev/" rel="nofollow noreferrer">https://css-for-js.dev/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592184"><td></td></tr>
                  <tr id="38592557"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592557" href="https://news.ycombinator.com/vote?id=38592557&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>None. The thing is for UX you have something like don't make me think but UI is a matter of taste so everyone has their own rules which might not appeal to you. You can check out the windows 95 design docs as that might give you some ideas and then I would suggest using an uncommon UI component library and let that do the heavy lifting till you can hire a designer.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592783"><td></td></tr>
            <tr id="38593289"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593289" href="https://news.ycombinator.com/vote?id=38593289&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>I am a long-time developer who's always dreamed of building an indie software business but design skills hold me back. I find it funny how people always talk about "technical" founders but never about design founders even though design is often just as useful, if not more useful, especially in the early stages where you can build the best product in the world but if it doesn't look good, nobody will try it.<p>I am also especially bad at design and visual art skills in general. I recognize this and get plenty of feedback around it. So this year I set out to improve to at least try to get to "mediocre" instead of "terrible".</p><p>Refactoring UI and Erik Kennedys blog / class are mentioned and are great resources and I own both.</p><p>I did Dribbble's Figma UI design class which was $600. It's biggest strength is that its a cohort based class, and cohort classes tend to have much higher finishing rates than self-paced classes. Their instructor will review your Figma designs but only if you finish in time so if you want to get your $600 worth you better open up Figma, so I recommend it for that reason. Kennedy's is self-paced and while it's extremely high quality, I haven't even worked through most of it for this reason.</p><p>Of course, the single most important thing you can do is build lots of UIs. If you're like me, your UIs will suck, but if you do it more regularly, you will also notice more UI/UX techniques on other websites. I save all those in a Notion database organized by category and refer to them.</p><p>One last thing I almost never see mentioned but it was a really good piece of advice. I told someone that I was between hiring contractor designers for my project, and trying to improve at design and do it myself. One person told me, it's not mutually exclusive. So you can design an app, and it will probably look bad. Then hire an experienced UI/UX designer off Upwork to do a better job. And pay attention to the decisions they made and the decsions you made and compare the difference. Figma is a great tool these days because it's much more collaborative than just getting a big stack of PNGs or SVGs at the end, you can discuss design choices in Figma comments as the designer works.</p><p>One final thing I really struggle with that is worth noting - professional designers will make several versions and iterations of everything, each screen and each component on that screen. And then pick the best one. The Dribbble instructor said, the best design is almost never the first one. This is time consuming and tedious if you don't love design but it's how you get the best results.</p><p>If you just have a one-off project and don't truly care about improving at design, the simplest option is to hire a contractor. UI/UX is not something you learn in a weekend and then you're good to go, it's more like learning a language or an instrument in that you're either going to invest a lot of time to learn it well or you're going to suck. It's pretty affordable to hire-out because it's mostly up-front work.</p><p>Hiring contractors and spending for classes is the expensive route but spending money can expedite the process. But, there's lots of free resources if you're broke. The single most important thing is design a lot, and pay attention to other people's designs and what they're doing.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592699"><td></td></tr>
            <tr id="38592835"><td></td></tr>
            <tr id="38591921"><td></td></tr>
                <tr id="38591933"><td></td></tr>
            <tr id="38592190"><td></td></tr>
                  <tr id="38592768"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592768" href="https://news.ycombinator.com/vote?id=38592768&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span><i>&gt; At the same time, I'd also love to learn more about more "down to earth" tutorials/examples/exercises/courses to build practical UI skills. Something above "react tutorials", but something below Victor's "Magic Ink"</i><p>I have no recommendations for UI in general but for practical UI skills I really like Every Layout [1] which covers common page layouts and how to make them responsive beyond just media queries.</p><p>[1] <a href="https://every-layout.dev/" rel="nofollow noreferrer">https://every-layout.dev/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How to inform YouTube a video is no longer under copyright? (166 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38591080</link>
            <guid>38591080</guid>
            <pubDate>Sun, 10 Dec 2023 12:27:42 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38591080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I was importing this video <a href="https://www.youtube.com/watch?v=IADZtE2-Aws" rel="nofollow noreferrer">https://www.youtube.com/watch?v=IADZtE2-Aws</a> into my youtube account, famous tracking shot from Wings 1927, and at the copyright determination step Youtube told me it was under copyright but the owner allows it to be shown on Youtube.</p><p>Which is incorrect - it entered public domain in 2023.</p><p>Makes me wonder if there is some metadata in this file that is newer than the film and that is what is copyrighted, or is it that the copyright was claimed on years past and Youtube neglected to check when that claim was going to run out?</p><p>How does one let them know that the copyright has run out?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AST-grep(sg) is a CLI tool for code structural search, lint, and rewriting (252 pts)]]></title>
            <link>https://github.com/ast-grep/ast-grep</link>
            <guid>38590984</guid>
            <pubDate>Sun, 10 Dec 2023 12:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ast-grep/ast-grep">https://github.com/ast-grep/ast-grep</a>, See on <a href="https://news.ycombinator.com/item?id=38590984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/dc3ff2bbe41af92af0afa8105b1229c826c9b7adbb05d37c5e0b0eaa18b89da1/68747470733a2f2f6173742d677265702e6769746875622e696f2f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/dc3ff2bbe41af92af0afa8105b1229c826c9b7adbb05d37c5e0b0eaa18b89da1/68747470733a2f2f6173742d677265702e6769746875622e696f2f6c6f676f2e737667" alt="ast-grep" data-canonical-src="https://ast-grep.github.io/logo.svg"></a>
</p>
<p dir="auto">
   <a target="_blank" rel="noopener noreferrer" href="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg"><img src="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg" alt="coverage badge"></a>
   <a href="https://app.codecov.io/gh/ast-grep/ast-grep" rel="nofollow"><img src="https://camo.githubusercontent.com/d8d716c0c9beb8e3004d061631b83b4d6f41a108f0b78f2939ab7878b2579634/68747470733a2f2f636f6465636f762e696f2f67682f6173742d677265702f6173742d677265702f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d33375658384832455756" data-canonical-src="https://codecov.io/gh/ast-grep/ast-grep/branch/main/graph/badge.svg?token=37VX8H2EWV"></a>
   <a href="https://discord.gg/4YZjf6htSQ" rel="nofollow"><img alt="Discord" src="https://camo.githubusercontent.com/3a74194a0e5c9e27439faa7bdc32e508773e7736b634cd170c8fb794a760e1e9/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313130373734393834373732323838393231373f6c6162656c3d446973636f7264" data-canonical-src="https://img.shields.io/discord/1107749847722889217?label=Discord"></a>
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4fc855230a38e496d1c72bf7b9ead49a30c041ca40d5b194673791e48aec1d13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c"><img src="https://camo.githubusercontent.com/4fc855230a38e496d1c72bf7b9ead49a30c041ca40d5b194673791e48aec1d13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c" alt="Badge" data-canonical-src="https://img.shields.io/github/stars/ast-grep/ast-grep?style=social"></a>
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/26e88f931ac539893b3f3b380cce6c9c5ddb57740225f7a04f213ba549029731/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c"><img src="https://camo.githubusercontent.com/26e88f931ac539893b3f3b380cce6c9c5ddb57740225f7a04f213ba549029731/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c" alt="Badge" data-canonical-src="https://img.shields.io/github/forks/ast-grep/ast-grep?style=social"></a>
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8b61c99823bdbbde4e60e46c99459abe796c62cd49394bbb8cfdefdc6e8acc84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73706f6e736f72732f48657272696e67746f6e4461726b686f6c6d653f7374796c653d736f6369616c"><img alt="GitHub Sponsors" src="https://camo.githubusercontent.com/8b61c99823bdbbde4e60e46c99459abe796c62cd49394bbb8cfdefdc6e8acc84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73706f6e736f72732f48657272696e67746f6e4461726b686f6c6d653f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/github/sponsors/HerringtonDarkholme?style=social"></a>
</p>
<h2 tabindex="-1" dir="auto">ast-grep(sg)</h2>
<p dir="auto">ast-grep(sg) is a CLI tool for code structural search, lint, and rewriting.</p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">ast-grep is a AST-based tool to search code by pattern code. Think it as your old-friend <code>grep</code> but it matches AST nodes instead of text.
You can write patterns as if you are writing ordinary code. It will match all code that has the same syntactical structure.
You can use <code>$</code> sign + upper case letters as wildcard, e.g. <code>$MATCH</code>, to match any single AST node. Think it as REGEX dot <code>.</code>, except it is not textual.</p>
<p dir="auto">Try the <a href="https://ast-grep.github.io/playground.html" rel="nofollow">online playground</a> for a taste!</p>
<h2 tabindex="-1" dir="auto">Demo</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2883231/183275066-8d9c342f-46cb-4fa5-aa4e-b98aac011869.gif"><img src="https://user-images.githubusercontent.com/2883231/183275066-8d9c342f-46cb-4fa5-aa4e-b98aac011869.gif" alt="output" data-animated-image=""></a></p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">You can install it from <a href="https://docs.npmjs.com/downloading-and-installing-node-js-and-npm" rel="nofollow">npm</a>, <a href="https://pypi.org/" rel="nofollow">pip</a>, <a href="https://doc.rust-lang.org/cargo/getting-started/installation.html" rel="nofollow">cargo</a>, <a href="https://brew.sh/" rel="nofollow">homebrew</a> or <a href="https://scoop.sh/" rel="nofollow">scoop</a>!</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install --global @ast-grep/cli
pip install ast-grep-cli
cargo install ast-grep

# install via homebrew, thank @henryhchchc
brew install ast-grep

# install via scoop, thank @brian6932
scoop install main/ast-grep"><pre>npm install --global @ast-grep/cli
pip install ast-grep-cli
cargo install ast-grep

<span><span>#</span> install via homebrew, thank @henryhchchc</span>
brew install ast-grep

<span><span>#</span> install via scoop, thank @brian6932</span>
scoop install main/ast-grep</pre></div>
<p dir="auto">Or you can build ast-grep from source. You need install rustup, clone the repository and then</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --path ./crates/cli"><pre>cargo install --path ./crates/cli</pre></div>
<p dir="auto"><a href="https://repology.org/project/ast-grep/versions" rel="nofollow">Packages</a> are available on other platforms too.</p>
<h2 tabindex="-1" dir="auto">Command line usage example</h2>
<p dir="auto">ast-grep has following form.</p>
<div data-snippet-clipboard-copy-content="sg --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts"><pre><code>sg --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts
</code></pre></div>
<h3 tabindex="-1" dir="auto">Example</h3>
<ul dir="auto">
<li><a href="https://twitter.com/Hchan_mgn/status/1547061516993699841?s=20&amp;t=ldDoj4U2nq-FRKQkU5GWXA" rel="nofollow">Rewrite code in null coalescing operator</a></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="sg -p '$A &amp;&amp; $A()' -l ts -r '$A?.()'"><pre>sg -p <span><span>'</span>$A &amp;&amp; $A()<span>'</span></span> -l ts -r <span><span>'</span>$A?.()<span>'</span></span></pre></div>
<ul dir="auto">
<li><a href="https://twitter.com/Hchan_mgn/status/1561802312846278657" rel="nofollow">Rewrite</a> <a href="https://github.com/ecyrbe/zodios#migrate-to-v8">Zodios</a></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="sg -p 'new Zodios($URL,  $CONF as const,)' -l ts -r 'new Zodios($URL, $CONF)' -i"><pre>sg -p <span><span>'</span>new Zodios($URL,  $CONF as const,)<span>'</span></span> -l ts -r <span><span>'</span>new Zodios($URL, $CONF)<span>'</span></span> -i</pre></div>
<ul dir="auto">
<li><a href="https://twitter.com/Hchan_mgn/status/1560108625460355073" rel="nofollow">Implement eslint rule using YAML.</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Sponsor</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg"><img src="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg" alt="Sponsors"></a></p>
<p dir="auto">If you find ast-grep interesting and useful for your work, please <a href="https://github.com/sponsors/HerringtonDarkholme">buy me a coffee</a>
so I can spend more time on the project!</p>
<h2 tabindex="-1" dir="auto">Feature Highlight</h2>
<p dir="auto">ast-grep's core is an algorithm to search and replace code based on abstract syntax tree produced by tree-sitter.
It can help you to do lightweight static analysis and massive scale code manipulation in an intuitive way.</p>
<p dir="auto">Key highlights:</p>
<ul dir="auto">
<li>
<p dir="auto">An intuitive pattern to find and replace AST.
ast-grep's pattern looks like ordinary code you would write every day. (You can call the pattern is isomorphic to code).</p>
</li>
<li>
<p dir="auto">jQuery like API for AST traversal and manipulation.</p>
</li>
<li>
<p dir="auto">YAML configuration to write new linting rules or code modification.</p>
</li>
<li>
<p dir="auto">Written in compiled language, with tree-sitter based parsing and utilizing multiple cores.</p>
</li>
<li>
<p dir="auto">Beautiful command line interface :)</p>
</li>
</ul>
<p dir="auto">ast-grep's vision is to democratize abstract syntax tree magic and to liberate one from cumbersome AST programming!</p>
<ul dir="auto">
<li>If you are an open source library author, ast-grep can help your library users adopt breaking changes more easily.</li>
<li>if you are a tech lead in your team, ast-grep can help you enforce code best practice tailored to your business need.</li>
<li>If you are a security researcher, ast-grep can help you write rules much faster.</li>
</ul>
<h2 tabindex="-1" dir="auto">CLI Screenshot</h2>
<h3 tabindex="-1" dir="auto">Search</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Command</th>
<th>Screenshot</th>
</tr>
</thead>
<tbody>
<tr>
<td>Search</td>
<td><code>sg -p 'Some($A)' -l rs</code></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2883231/237472835-002db3a2-8a79-4838-ad5c-563634183c3f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MjgzNS0wMDJkYjNhMi04YTc5LTQ4MzgtYWQ1Yy01NjM2MzQxODNjM2YucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWIyNWE0Njg3MTIzMTcxN2M0ZTc5NTUzMjU0NGE0YjM2MjAzYmVkNTRjOGNkZDdmZjBlMDQzZWNlMDNiOGUyZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.N7tdkaARi1aVKUjol8r6xJdQLctzMvmozKUIhFB4W_M"><img src="https://private-user-images.githubusercontent.com/2883231/237472835-002db3a2-8a79-4838-ad5c-563634183c3f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MjgzNS0wMDJkYjNhMi04YTc5LTQ4MzgtYWQ1Yy01NjM2MzQxODNjM2YucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWIyNWE0Njg3MTIzMTcxN2M0ZTc5NTUzMjU0NGE0YjM2MjAzYmVkNTRjOGNkZDdmZjBlMDQzZWNlMDNiOGUyZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.N7tdkaARi1aVKUjol8r6xJdQLctzMvmozKUIhFB4W_M" alt="image"></a></td>
</tr>
<tr>
<td>Rewrite</td>
<td><code>sg -p '$F &amp;&amp; $F($$$ARGS)' -r '$F?.($$$ARGS)' -l ts</code></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2883231/237473699-ad9394d8-3aea-4b96-8d54-6e01f06174d2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MzY5OS1hZDkzOTRkOC0zYWVhLTRiOTYtOGQ1NC02ZTAxZjA2MTc0ZDIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDc3ZGRmMDc3MTM1MWVkYTFjZTEzYWE0YWExMjQ1YWU5OTFlM2IwNThjNjE1ZTQ1YTY2ZGZiNjlkZjVjMGZiYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ZwL2RdCmRJkJLps3pNWMelmbl6UdQN_fY_JRQ0mwrGw"><img src="https://private-user-images.githubusercontent.com/2883231/237473699-ad9394d8-3aea-4b96-8d54-6e01f06174d2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MzY5OS1hZDkzOTRkOC0zYWVhLTRiOTYtOGQ1NC02ZTAxZjA2MTc0ZDIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDc3ZGRmMDc3MTM1MWVkYTFjZTEzYWE0YWExMjQ1YWU5OTFlM2IwNThjNjE1ZTQ1YTY2ZGZiNjlkZjVjMGZiYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ZwL2RdCmRJkJLps3pNWMelmbl6UdQN_fY_JRQ0mwrGw" alt="image"></a></td>
</tr>
<tr>
<td>Report</td>
<td><code>sg scan</code></td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2883231/187094977-fd544d4b-64de-4bba-8bea-8c0de047b352.png"><img src="https://user-images.githubusercontent.com/2883231/187094977-fd544d4b-64de-4bba-8bea-8c0de047b352.png" alt="image"></a></td>
</tr>
</tbody>
</table>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stealthy Linux rootkit found in the wild after going undetected for 2 years (232 pts)]]></title>
            <link>https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/</link>
            <guid>38590827</guid>
            <pubDate>Sun, 10 Dec 2023 11:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/">https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/</a>, See on <a href="https://news.ycombinator.com/item?id=38590827">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">



<article itemscope="" itemtype="http://schema.org/NewsArticle" id="">
      <div>
        <header>
            <h4>
      MORE FUN WITH ROOTKITS    â
</h4>
            
            <h2 itemprop="description">Krasue infects telecom firms in Thailand using techniques for staying under the radar.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/trojan-backdoor-800x534.jpg" alt="Trojan horse on top of blocks of hexadecimal programming codes. Illustration of the concept of online hacking, computer spyware, malware and ransomware.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 578:single/related:4c57568bce8854ee188540936f006902 --><!-- empty -->
<p>Stealthy and multifunctional Linux malware that has been infecting telecommunications companies went largely unnoticed for two years until being documented for the first time by researchers on Thursday.</p>
<p>Researchers from security firm Group-IB have named the remote access trojan âKrasue,â after a nocturnal spirit <a href="https://en.wikipedia.org/wiki/Krasue">depicted in Southeast Asian folklore </a> âfloating in mid-air, with no torso, just her intestines hanging from below her chin.â The researchers chose the name because evidence to date shows it almost exclusively targets victims in Thailand and âposes a severe risk to critical systems and sensitive data given that it is able to grant attackers remote access to the targeted network.</p>
<p>According to the researchers:</p>
<blockquote>
<ul>
<li aria-level="1">Krasue is a Linux Remote Access Trojan that has been active since 20 and predominantly targets organizations in Thailand.</li>
<li aria-level="1">Group-IB can confirm that telecommunications companies were targeted by Krasue.</li>
<li aria-level="1">The malware contains several embedded rootkits to support different Linux kernel versions.</li>
<li aria-level="1">Krasueâs rootkit is drawn from public sources (3 open-source Linux Kernel Module rootkits), as is the case with many Linux rootkits.</li>
<li aria-level="1">The rootkit can hook the `kill()` syscall, network-related functions, and file listing operations in order to hide its activities and evade detection.</li>
<li aria-level="1">Notably, Krasue uses RTSP (Real-Time Streaming Protocol) messages to serve as a disguised âalive ping,â a tactic rarely seen in the wild.</li>
<li aria-level="1">This Linux malware, Group-IB researchers presume, is deployed during the later stages of an attack chain in order to maintain access to a victim host.</li>
<li aria-level="1">Krasue is likely to either be deployed as part of a botnet or sold by initial access brokers to other cybercriminals.</li>
<li aria-level="1">Group-IB researchers believe that Krasue was created by the same author as the XorDdos Linux Trojan, documented by <a href="https://www.microsoft.com/en-us/security/blog/2022/05/19/rise-in-xorddos-a-deeper-look-at-the-stealthy-ddos-malware-targeting-linux-devices/">Microsoft in a March 2022 blog post</a>, or someone who had access to the latterâs source code.</li>
</ul>
</blockquote>
<p>During the initialization phase, the rootkit conceals its own presence. It then proceeds to hook the <b>`kill()`</b> syscall, network-related functions, and file listing operations, thereby obscuring its activities and evading detection.</p>                                            
                                                        
<p>The researchers have so far been unable to determine precisely how Krasue gets installed. Possible infection vectors include through vulnerability exploitation, credential-stealing or -guessing attacks, or by unwittingly being installed as trojan stashed in an installation file or update masquerading as legitimate software.</p>
<p>The three open source rootkit packages incorporated into Krasue are:</p>
<ul>
<li aria-level="1"><a href="https://github.com/m0nad/Diamorphine">Diamorphine</a></li>
<li aria-level="1"><a href="https://github.com/mncoppola/suterusu">Suterusu</a></li>
<li aria-level="1"><a href="https://github.com/jermeyyy/rooty">Rooty</a></li>
</ul>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue.jpg" data-height="828" data-width="1794" alt="An image showing salient research points of Krasue."><img alt="An image showing salient research points of Krasue." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue-640x295.jpg" width="640" height="295" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue-1280x591.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue.jpg" data-height="828" data-width="1794">Enlarge</a> <span>/</span> An image showing salient research points of Krasue.</p><p>Group-IB</p></figcaption></figure>
<p>Rootkits are a type of malware that hides directories, files, processes, and other evidence of its presence to the operating system itâs installed on. By hooking legitimate Linux processes, the malware is able to suspend them at select points and interject functions that conceal its presence. Specifically, it hides files and directories beginning with the names âauwdâ and âvmware_helperâ from directory listings and hides ports 52695 and 52699, where communications to attacker-controlled servers occur. Intercepting the kill() syscall also allows the trojan to survive Linux commands attempting to abort the program and shut it down.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/2/">2</a> <a href="https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/2/"><span>Next <span>â</span></span></a></span></nav>
            
        </section>
    </div>

<section>
          
    
    <p>
      <section>
        <a href="https://arstechnica.com/author/dan-goodin">Dan Goodin</a>
        Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene.      </section>
    </p>

  </section>

  </article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fuzzy Finding with Emacs Instead of Fzf (126 pts)]]></title>
            <link>https://www.masteringemacs.org/article/fuzzy-finding-emacs-instead-of-fzf</link>
            <guid>38590164</guid>
            <pubDate>Sun, 10 Dec 2023 08:47:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.masteringemacs.org/article/fuzzy-finding-emacs-instead-of-fzf">https://www.masteringemacs.org/article/fuzzy-finding-emacs-instead-of-fzf</a>, See on <a href="https://news.ycombinator.com/item?id=38590164">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
    
      
    
    
      
    
    
      
        <section>
          fzf is a popular tool among command line hackers. But if you're an Emacs user, it's hard to use as it requires an interactive terminal. What if you could use Emacs to do the fuzzy finding instead of fzf?
        </section>
      
      
        <figure>
          <img src="https://www.masteringemacs.org/static/uploads/article-images/gnu-standing-on-piles-of-paper.jpg">
        </figure>
      
      
        
      
      
        <p>Updated for <strong>emacs 28</strong></p>
      
      <img src="https://www.masteringemacs.org/static/img/fleuron2.gif">
      
<p>Filtering long lists of output on the command line usually involves taking the list of items â maybe the output of <code>ls</code>, <code>git</code> or <code>find</code> â and doing something with it. If youâre lucky you can mechanically filter the list with pipes and <code>grep</code>. If youâre unlucky and you canât think of a heuristic, youâll have to sift through the output with a pager like <code>less</code> and remember the items you want to keep.</p><figure>
   <img src="https://www.masteringemacs.org/static/uploads/fzf.png" alt="fzf filtering output from apt-cache search intended for apt-get">
<figcaption><code>fzf</code> filtering output from <code>apt-cache search</code> intended for <code>apt-get</code></figcaption>
</figure><p>Typically you do this because you want to cherry pick a subset of the items and feed them into another command, like <code>rm</code>, <code>cat</code> or <code>apt-get</code> as the picture above illustrates.</p><p>But the manual way is tedious and slow. And thatâs the problem <a href="https://github.com/junegunn/fzf">fzf</a> tries to solve. The premise is simple: you feed it (via stdin) a list of items, and it displays a curses-like window where you can âfuzzy findâ and select the items you care about. Itâs designed to slot into command substitutions and pipes â like an interactive <code>grep</code>.</p><p>So that got me thinking. Thereâs no reason why you canât use Emacs to do this instead of <code>fzf</code>! Emacs has better fuzzy finding and itâs the text editor youâre already using, so why not use Emacs?</p><p>Another reason to ditch <code>fzf</code> is that you might be using <a href="https://masteringemacs.org/article/running-shells-in-emacs-overview">a shell and not a terminal emulator in Emacs</a>. Itâs not impossible to run curses apps in <code>shell-mode</code>, but it is harder.</p><h2 id="ezf-emacs-fuzzy-finder">EZF: Emacs Fuzzy Finder</h2><figure>
   <img src="https://www.masteringemacs.org/static/uploads/ezf-example-optimised.gif" alt="Fuzzy matching with Helm">
<figcaption><code>ezf</code> filtering output from <code>apt-cache</code> before passing it back to the shell</figcaption>
</figure><p>So the game plan is simple:</p><dl><dt>Build a shell script</dt><dd><p>This is the shell-facing part that we feed into pipes and command substitution sub-shells.</p><p>It must talk to <code>emacsclient</code>, the client in the Emacs client-server duo. That way itâll run in your existing Emacs instance and it wonât interrupt your workflow if you also use â as you well should! â Emacs as your shell or terminal emulator.</p></dd><dt>Write some Elisp glue code</dt><dd><p>Weâll need a few functions capable of letting you filter and select the match candidates you like. Luckily this is generally very easy.</p></dd><dt>Return the picked candidates</dt><dd><p>After matching and selecting the candidates we want to keep, we must return them from whence they came. Weâll need to be mindful of annoying bagatelles like proper quoting.</p></dd><dt>Make it easy to extend</dt><dd><p>It should be easy to extend or modify to suit individual tastes.</p><p>Weâll add a few command switches to <code>ezf</code> to highlight how easy it is to pass customizable switches through bash into Emacs.</p></dd></dl><h3 id="sending-to-emacss-standard-input">Sending to Emacsâs standard input</h3><p>Letâs start with the shell script. Iâve done it in <code>bash</code>. Thereâs a number of little gotchas and workarounds required for this to work well. So the scriptâs freighted with one or two annoying hacks.</p><p>Chiefly, itâs not possible to ask <code>emacsclient</code> or even <code>emacs</code> to read directly from a file descriptor device. So process substitution with <code>&lt;(ls ...)</code> is out. I donât know why, as Emacs is absolutely 100% capable of <em>doing</em> it inside Emacs. So Iâm chalking it up to oversight.</p><p>That means we have to work around that problem with real files. Iâm using <code>mktemp</code> to <code>cat</code> standard input to a temporary file. To avoid clobbering your <code>tmpfs</code> with junk files, thereâs a <code>trap</code> to clean up when the script exits.</p><p>Now all we need to do is add a little command argument parsing: I want <code>-c</code> to let us choose the completion tool to invoke in Emacs; and <code>-f</code> is there to pick the field offset to return. The latter is particularly useful if you have a line of text and you want just the first word, for example.</p><p>After that, thereâs a little bit of house keeping in case you exit out of the selection process without picking anything. Oh, when you tell <code>emacsclient</code> to evaluate elisp itâll use <code>prin1</code> to emit the representation of the Lisp object to standard output, and that forces quote symbols around strings, even if we donât really want that. Sieving the output from Emacs through a pipe to <code>xargs</code> cunningly strips the quotes.</p><pre><code><span>#!/usr/bin/env bash</span>
<span>set</span> <span>-o</span> nounset -o errexit -o pipefail

<span>field=</span>nil
<span># the elisp function to use for completing read</span>
<span>candidate_fn=</span>ezf-default
<span>while</span> <span>getopts</span> c:f: OPT<span>;</span> <span>do</span>
    <span>case</span> <span>$OPT</span><span> in</span>
        c<span>)</span>
            <span>candidate_fn=$OPTARG</span>
            <span>;;</span>
        f<span>)</span>
            <span>field=$OPTARG</span>
            <span>;;</span>
        *<span>)</span>
            <span>echo</span> <span>"usage: </span><span>${0##</span>*/<span>}</span><span> [-f field] [-c candidate-fn]"</span>
            <span>exit</span> 2
    <span>esac</span>
<span>done</span>
<span>shift</span> <span>$((</span> OPTIND - 1 <span>))</span>
<span>OPTIND=</span>1

<span>ezftmp=</span><span>"</span><span>$(</span><span>mktemp</span><span>)</span><span>"</span>
<span>trap</span> <span>'rm -f -- "$ezftmp"'</span> EXIT
<span>&gt;</span> <span>"</span><span>$ezftmp</span><span>"</span> <span>cat</span> -
<span># xargs is there to strip the "" from the beginning and end of the output from Emacs.</span>
<span>selection=$(</span><span>emacsclient</span> -e <span>"(ezf </span><span>\"</span><span>$ezftmp</span><span>\"</span><span> </span><span>$field</span><span> #'</span><span>$candidate_fn</span><span>)"</span> <span>|</span> <span>xargs</span><span>)</span>
<span>if [[</span> <span>"</span><span>$selection</span><span>"</span> <span>==</span> <span>"nil"</span><span> ]]</span>; <span>then</span>
    <span>exit</span> 1
<span>else</span>
   <span>echo</span> <span>"</span><span>$selection</span><span>"</span>
<span>fi</span></code></pre><p>Iâve named it <code>ezf.sh</code> (symlinked to <code>ezf</code>) so all you need to do is put it somewhere on your <code>PATH</code>.</p><h3 id="filtering-in-emacs">Filtering in Emacs</h3><p>Completion in Emacs is a complex subject matter and one soused in bike shedding and personal opinion. So Iâve kept things open and made it work with <code>completing-read</code> â well, specifically <code>completing-read-multiple</code> so you can pick multiple items.</p><p>If youâre unsure how that fits into <em>your</em> completion framework, then my article on <a href="https://www.masteringemacs.org/article/understanding-minibuffer-completion">understanding Minibuffer Completion</a> is a good place to start. If you want IDO to work with it, youâll have to tweak the code yourself. Luckily I have <a href="https://www.masteringemacs.org/article/find-files-faster-recent-files-package">an example here</a> to get you started.</p><p>Iâve also made it work out of the box with Helm which, as we all know, is awesome. Helm in particular is perfect for this as it comes with great fuzzy matching, multiple selection <em>and</em> itâs easy to add custom actions like returning matches to the shell <em>and</em> opening them as files in Emacs, for example.</p><p>Thereâs three parts: two completion mechanisms and a generic wrapper that turns lists of candidates into usable output.</p><pre><code>(<span>defun</span><span> ezf-default </span>(filename)
  <span>"EZF completion with your default completion system."</span>
  (completing-read-multiple
   <span>"Pick a Candidate: "</span>
   (with-temp-buffer
     (insert-file-contents-literally filename <span>nil</span>)
     (string-lines (buffer-string) <span>t</span>))))</code></pre><p><code>completing-read-multiple</code> takes a prompt and a list of strings. And thatâs all you need to get Emacsâs completion system to work. I create a temporary buffer to hold the file contents before itâs split up into lines. If you want NULL-separated output, this is the place to change it.</p><p>If youâre wondering why Iâm using a buffer, you should read my article <a href="https://www.masteringemacs.org/article/why-emacs-has-buffers">Why Emacs has Buffers</a>.</p><pre><code>(<span>defun</span><span> ezf-helm </span>(filename)
  <span>"EZF completion with `helm'."</span>
  <span>;; Uncomment if you want Helm to full screen.</span>
  <span>;; (helm-set-local-variable 'helm-full-frame t)</span>
  (helm :sources
        (helm-build-in-file-source <span>"EZF Completion"</span> filename
          :action (<span>lambda</span> (_) (helm-marked-candidates)))))</code></pre><p>For Helm the solution is similar. Iâm using Helmâs ability to build candidates directly from a file. If you want to add more than one action then I recommend you use <code>helm-make-actions</code> to build the alist.</p><p>Now for the generic wrapper. Its job is to take a list of strings you picked from a candidate function and turn it into something the shell can properly read. If you specified <code>-f</code> to <code>ezf</code> then itâll also split the string and only use the field index you chose.</p><pre><code><span>;; If you start Emacs's server some other way, you can remove this.</span>
(server-start)

(<span>defvar</span><span> ezf-separators </span><span>" "</span>
  <span>"Regexp of separators `ezf' should use to split a line."</span>)

(<span>defun</span><span> ezf </span>(filename &amp;optional field completing-fn)
  <span>"Wrapper that calls COMPLETION-FN with FILENAME.</span>

<span>Optionally split each line of string by `ezf-separators' if FIELD</span>
<span>is non-nil and return FIELD.</span>

<span>If COMPLETING-FN is nil default to `ezf-default'."</span>
  (when-let (candidates (<span>funcall</span> (<span>or</span> completing-fn 'ezf-default) filename))
    (mapconcat (<span>lambda</span> (candidate)
                 (shell-quote-argument
                  (<span>if</span> field
                      (<span>nth</span> (<span>1-</span> field) (split-string candidate ezf-separators <span>t</span> <span>" "</span>))
                    candidate)))
               candidates
               <span>" "</span>)))</code></pre><p>Here the goal is simply to take a <code>filename</code> containing our candidates; an optional <code>completing-fn</code>, as set by passing <code>-c</code> to <code>ezf</code>; and an optional <code>field</code> index.</p><p><code>ezf-separators</code> is a regular expression to split each line by. So if you want NULL-delimited support then you can easily add that and a switch to go along with it.</p><p>Because weâre taking unsanitized candidates and passing them through our completion system, itâs good form to ensure the filtered candidates are properly escaped when we hand them back to the shell. Thatâs what <code>shell-quote-argument</code> does. <code>mapconcat</code> merely ensures the quoted candidates are space-separated as thatâs what shells expect. (And if you want NULL separation you should change this also.)</p><p>Because the last value is by convention the value that is returned from a function in Lisp, we know that the output of <code>emacsclient</code> is the result of the <code>mapconcat</code> form if we selected any matches, and <code>nil</code> otherwise.</p><p>With all this in place itâs time to test it:</p><figure>
   <img src="https://www.masteringemacs.org/static/uploads/ezf-default.svg" alt="fuzzy matching with ezf, the Emacs fuzzy finder">
<figcaption>Fuzzy matching dictionary words with Emacs and <code>ezf</code></figcaption>
</figure><p>Yep. Looks good.</p><p>This tool is able to do most of the things youâd use <code>fzf</code> for, and all from within the comfort of your Emacs. Itâll work just fine in Eshell also if you donât push it too hard. Eshellâs support for pipes and redirection is not as good as regular shells, but with a little bit of work it could be made to work there too, with or without the bash script. And of course you can use it from Terminals also: the ones you run from inside Emacs, and external ones also.</p><h2 id="example-use-cases">Example Use Cases</h2><p>Hereâs a few examples of how you can use the tool. It goes without saying that itâs a bit threadbare compared to <code>fzf</code>, but I think itâs easy enough to extend to suit your own needs. This is also a great way to get your hands dirty with elisp if you have never done any before.</p><p>Iâm going to point out that <code>M-x helm-locate</code> already does this, but you can use GNU <code>locate</code> to track down files matching a regex pattern and then open them in <code>emacsclient</code>:</p><pre><code>$ <span>emacsclient</span> <span>$(</span><span>locate</span> -r <span>'[.]py$'</span> <span>|</span> <span>ezf</span><span>)</span></code></pre><p>GNU <code>locate</code> works by querying a database that updates whenever you call <code>updatedb</code>. Itâs probably the one of fastest cached file searchers available today. You can have multiple databases with different configurations (one for your home directory and another for the whole file system) to further speed it up. I highly recommend you look into using it if you regularly sweep your file system looking for files.</p><p>Finding and installing packages with <code>apt-get</code> and <code>apt-cache</code>:</p><pre><code>$ <span>apt-get</span> install <span>$(</span><span>apt-cache</span> search <span>&lt;</span>term<span>&gt;</span> <span>|</span> <span>ezf</span> -f 1<span>)</span></code></pre><p>Change directories. Try playing around with the arguments to <code>find</code>, or use something simpler like <code>ls</code>:</p><pre><code>$ <span>cd</span> <span>$(</span><span>find</span> . -maxdepth 3 -type d <span>|</span> <span>ezf</span><span>)</span></code></pre><h2 id="next-steps">Next Steps</h2><p>I think this is a pretty good example of how you can combine the power of Emacs and a little bit of gnarly shell script magic. And this is really just the beginning. You can take the shell script and hook it up to all manner of crazy Emacs stuff: <code>M-x dired</code>; sending stuff to a buffer for editing; and more.</p><p>You can also find it on Github here: <a href="https://github.com/mickeynp/ezf">EZF</a>.</p>

    
    
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Can we do better than Git for version control? (124 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38590080</link>
            <guid>38590080</guid>
            <pubDate>Sun, 10 Dec 2023 08:28:38 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38590080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="38590080">
      <td><span></span></td>      <td><center><a id="up_38590080" href="https://news.ycombinator.com/vote?id=38590080&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=38590080">Ask HN: Can we do better than Git for version control?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_38590080">103 points</span> by <a href="https://news.ycombinator.com/user?id=slalomskiing">slalomskiing</a> <span title="2023-12-10T08:28:38"><a href="https://news.ycombinator.com/item?id=38590080">12 hours ago</a></span> <span id="unv_38590080"></span> | <a href="https://news.ycombinator.com/hide?id=38590080&amp;goto=item%3Fid%3D38590080">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Can%20we%20do%20better%20than%20Git%20for%20version%20control%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=38590080&amp;auth=f2b679cac7015fcd9eb7f8bafb4e57f31caa0ce1">favorite</a> | <a href="https://news.ycombinator.com/item?id=38590080">177&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Do you think itâs possible to make a better version control system than Git?</p><p>Or is it a solved problem and Git is the endgame of VCS</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table><table>
            <tbody><tr id="38591669"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591669" href="https://news.ycombinator.com/vote?id=38591669&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>A lot of people these days have just been thrown into the fire with Git as the first and only VCS theyâve ever seen.<p>Iâm not that old, but Iâm old enough to have used RCS, CVS, SVN, then finally Git. I started using Git super early, before GitHub existed. You may not believe me, but Git was the answer to all my prayers. All those previous systems had fundamental architectural flaws that made them a complete nightmare to use on a team for any serious work.</p><p>Git has no such problem. Thereâs nothing it canât do. Instead, the only limitation is on the user being able to know how to get Git to do what they want it to do. Thankfully, thatâs always solvable with a quick read of the documentation or web search.</p><p>I understand that people might want to make it easier, since the UI is complex, but thatâs never going to work. If you abstract away the complexity of the UI, you will necessarily abstract away the power. If you abstract away the power, you are no longer solving all the problems that Git solved. People just donât realize what problems are being solved because they never lived through those problems with the previous VCSes.</p><p>You know whatâs easier than building a new VCS better than Git? You know whatâs easier than using a different VCS from the rest of the world? You know whatâs easier than designing a miraculous abstraction on top of Git?</p><p>Learning Git.</p><p>Whatever effort you are putting into seeking or building an alternative, instead put that effort towards becoming a Git expert. It will be a lot less effort with a lot more benefit. Trust me on this. It will be well worth it for your career and for your personal computing life as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593116"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593116" href="https://news.ycombinator.com/vote?id=38593116&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>While I feel like this is generally true for most programmers and knowledge workers, Git is absolutely not suited to the workflow of several industries, including the one I work in: games.<p>Working with an engine like Unreal Engine for a project of any reasonable size requires working with both hundreds of thousands of active files (my current project's repo's HEAD has ~400k) and hundreds of gigabytes of active files, many of which are many GB on their own.  Our repository (in perforce) is currently in the order of 10TB.</p><p>Git, even with LFS and partial clone and shallow copies and fsnotify just falls apart at this scale.  Add to that the necessity for less-technical people (artists, designers, VFX, audio, etc) to use it, and it is really just a non starter.</p><p>I absolutely loathe Perforce (having used and occasionally admin'd it professionally since 2007), but I begrudgingly admit that is is currently the only publicly available VCS that can fulfill all of the requirements of this industry in a practical way.  Plastic and the others just aren't there yet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593293"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593293" href="https://news.ycombinator.com/vote?id=38593293&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>This could be solved with references rather than copies if your tools integrated them. e.g. dependencies can be ref'd with source/name and version. To ensure availability all such used blobs could be stored efficiently elsewhere and versioned.<p>It's great that Perforce works and I've heard others in the graphics field using it, so it satisfies a need. Don't know if/when it would be a general need for say GitHub users.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38594054"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594054" href="https://news.ycombinator.com/vote?id=38594054&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>This post is a terrible failure of imagination that would make one stop language development as C because it was so much better than Assembly.<p>If you have no problems with Git, then Iâm happy for you. I certainly have problems with Git, eg its inability to handle large repositories meaningfully (enjoy a Chromium checkout!), the arcane CLI commands, the shut-your-eyes-and-hope of moving commits between branches and other sharp edges.</p><p>That Git has been as resilient as it has is largely a function of being written by Torvalds and GitHub network effects. It isnât for lack of better/as good features found in other VCS methodologies.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594107"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38594107" href="https://news.ycombinator.com/vote?id=38594107&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>git still has issues with lots of files. I downloaded the sec Edgar database as files and I thought it would be nice way to store and watch changes.<p>Nope.</p><p>So slow. It does not like millions of files. And all my tooling that does a âquickâ git status locked up the terminal, vs code, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594484"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38594484" href="https://news.ycombinator.com/vote?id=38594484&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Did you try the file system daemon (git fsmonitor--daemon start) thatâs built into git that was designed to speed up git status on many files?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38594083"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38594083" href="https://news.ycombinator.com/vote?id=38594083&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; its inability to handle large repositories meaningfully<p>Out of curiousity, what other SCM tools can pull this off better?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594232"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38594232" href="https://news.ycombinator.com/vote?id=38594232&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I havenât played with many because I simply donât have the time between work (Googleâs Piper and Git) and kids. Piper handles the monorepo by only offering files when requested by the file system at the specified commit (this is probably a gross or even incorrect simplification, but is how it presents to the user).<p>There are good reasons that one should keep the whole commit history to distribute a source of truth, but at the same time if one is going to place full trust in something like GitHub (as many do), thereâs no reason that full trust canât be given to a similar website that provides a Piper model with some mechanism to request more than one commit to be brought to local storage (to get more sources of truth).</p><p>End of the day, a large repo checkout is going to be limited by either your network, your CPU/storage to perform archive expansions, or frequently both. I get the impression that Android and Chromium are expanding faster than those other things are improving, but have no data to back that up.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38592860"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592860" href="https://news.ycombinator.com/vote?id=38592860&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;I understand that people might want to make it easier, since the UI is complex, but thatâs never going to work. If you abstract away the complexity of the UI, you will necessarily abstract away the power.<p>I disagree, really.</p><p>There is not fundamental reason why you cannot have user-friendly UI for 98% of the cases and some "advanced" for those 2%.</p><p>Just like GUIs have "advanced" settings, the CLI can have well designed 10 commands for basic usage that are taught to newbies and then advanced ones.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594082"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38594082" href="https://news.ycombinator.com/vote?id=38594082&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The problem is that for 99.99% of the people engaged in the debate over if git is good or not and should be replaced the correct answer for them is "stop fighting it and just learn git" because there's nothing better.  They need to stop thinking about how git sucks because that is literally getting in the way of their career goals and is self-sabotage.<p>And if anyone seriously wants to try to replace git they need to understand how git works first at the level of an advanced expert first anyway.  At that point, you can have the discussion about how to make git, with better LFS/monorepo support, with a more pleasant UI/UX, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38593029"><td></td></tr>
                <tr id="38593397"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593397" href="https://news.ycombinator.com/vote?id=38593397&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I would say that Mercurial has a simpler UX than Git without being less powerful. I think Jujutsu (see other posts here), which I started, also has simpler UX and is more powerful than Git in many ways. Have you looked at either of those?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593349"><td></td></tr>
            <tr id="38593055"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593055" href="https://news.ycombinator.com/vote?id=38593055&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;Do it then. Many have tried. All have failed. Talk is cheap.<p>I'm, just like many other people using GitHub Desktop (or Git Kraken or Git Extension, but I dont like this one)</p><p>when I'm working in GUI environment, that's proof that it is possible.</p><p>The problem with creating 3rd party tool that's CLI wrapper is that you cannot rely on it being installed on the system.</p><p>That's why such solutions usually fail - because you risk relying on stuff that may not get traction and you'd be better sticking to "official" syntax in long run.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593865"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593865" href="https://news.ycombinator.com/vote?id=38593865&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I'll share here my positive opinion of GitExtensions (on Windows). It has really helped me use and better understand Git, while also helping me define and share workflows with my colleagues..<p>Other GUIs, like the ones embedded in VisualStudio, VSCode or Rider, try to sell skipping some cognitive steps for some operations as simplifying or speeding up dev flow. 
I find they are just offering extra (beyond what git itself offers) ways of shooting yourself in the foot.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593322"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593322" href="https://news.ycombinator.com/vote?id=38593322&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Is gitk still a thing that's available with git? Not as full featured but great for viewing and good with many commits/files.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38593107"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593107" href="https://news.ycombinator.com/vote?id=38593107&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; I understand that people might want to make it easier, since the UI is complex, but thatâs never going to work. If you abstract away the complexity of the UI, you will necessarily abstract away the power.<p>There's a lot of "useless" complexity in the Git UI. The naming of the commands and the underlying concepts are quite inconsistent. The commands themselves are inconsistent. It's rare to see somebody, even git fans, to dispute that the UI is far from optimal. And the warts in the UI are being improved.</p><p>These UI warts start to become invisible when you get used to them, but e.g. when teaching git they become painfully obvious again.</p><p>The underlying git architecture is simple and it's the simplicity that makes git powerful. Powerful tools don't necessarily need complex interfaces. In fact power often comes from simple interfaces that compose well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38591865"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38591865" href="https://news.ycombinator.com/vote?id=38591865&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The git model has fundamental limitations because it saves snapshots rather than changes, and doesn't capture some metadata changes like renames.  A tool like Darcs or one of its spiritual descendants will have fewer merge conflicts than git.<p>Totally agree on your main point though.  The benefits of switching are far lower than the costs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593067"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593067" href="https://news.ycombinator.com/vote?id=38593067&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;it saves snapshots rather than changes<p>Once you understand this, GIT makes a whole lot more sense. The trouble with failed merges is an artifact of trying to appear like it tracks deltas. Merge conflicts when you're the only programmer on a product (but have multiple computers) are maddening.</p><p>I blew away .git and everything in it, restarting a repository, more than once because I couldn't resolve a merge conflict, before I learned that simple fact.</p><p>I've got from .zip files of my source code on floppy disks, to SVN, then Mercurial, and finally GIT.  GIT is amazing, though the UI is a pain, as most agree.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593134"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593134" href="https://news.ycombinator.com/vote?id=38593134&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>&gt; <i>doesn't capture some metadata changes like renames</i><p>If you rename the file using git and that is the only change in your file, then it works:</p><pre><code>  git mv oldfile newfile
</code></pre>
Commit that change and the rename is in your history.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593187"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593187" href="https://news.ycombinator.com/vote?id=38593187&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>the rename won't be in your history because the tree and commit objects don't support renames<p>the tooling infers a rename based on the lack of a content change
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593994"><td></td></tr>
                        <tr id="38592375"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592375" href="https://news.ycombinator.com/vote?id=38592375&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; ..because it saves snapshots rather than changes..<p>I might be misremembering the technical details, but isn't that only the case in a git repo with zero pack files?</p><p>Will grant that the lack of metadata on renames can be issue when a file is heavily refactored alongside it's relocation.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592938"><td></td></tr>
                        <tr id="38594257"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594257" href="https://news.ycombinator.com/vote?id=38594257&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>i mostly agree that git can do almost anything (but see the limitations others bring up), however this claim is easy to disprove:<p><i>Whatever effort you are putting into seeking or building an alternative, instead put that effort towards becoming a Git expert.</i></p><p>building an alternative naturally is more work than to learn git for one person, but not everyone needs to do that. a few people building an alternative could save the learning effort of many more people.</p><p>instead i'd like to point out a different reason why rebuilding git may not solve the problem:</p><p>git is good because it is powerful and flexible.</p><p>that power and flexibility by necessity makes git more complex and difficult to use.</p><p>you can build a simpler system, but then half of todays git users won't be able to use it because it won't have the features they need.</p><p>and a system that has all the features of git today and also solves the problems it currently has will be even more complex and less straigt forward to use.</p><p>the best approach is probably to have a common backend that has all the power and flexibility needed, and multiple different frontends that are simplified to only expose the features needed for a particular workflow.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592752"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592752" href="https://news.ycombinator.com/vote?id=38592752&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Git keeps the entire history on your local machine, this becomes a problem if your project grows to several hundred GB (not untypical in game dev). Even SVN was much better for working with large repositories, you only needed a big server. Git is quite nice for "source code only projects though".</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593268"><td></td></tr>
            <tr id="38593146"><td></td></tr>
            <tr id="38592863"><td></td></tr>
                <tr id="38593532"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593532" href="https://news.ycombinator.com/vote?id=38593532&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Overall LFS feels a very hacky tacked on solution with warts.<p>Git LFS is horrible if you mistakenly add some file(s) to LFS.</p><p>Restoring to LFS-less state is supposed to be easy but it is always very painful.</p><p>There should be a way to tell repo - I do not want any LFS at all. In practice this is painful, and it is easier to start a new repo....</p><p>Also for some reason Github/Microsoft decided to "monetize" LFS. The freebie limits are 1GB for hosting AND transfer! Then the charges get very expensive.</p><p>I am not sure why Github LFS is priced like some AWS S3 plan not OneDrive plan.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594881"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38594881" href="https://news.ycombinator.com/vote?id=38594881&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>GitHub charges for LFS and has since they initially introduced it, way before Microsoft was involved. Also, the pricing model is changing and will include a minimum of 10GiB for free (250GiB for Team/Enterprise customers). Itâs cost-recovery and abuse-prevention, though, not some nefarious scheme. And funny you mention AWS S3... what costs might GitHub be recovering? ;)<p>Microsoftâs homegrown LFS implementation (in Azure DevOps) does not and has never charged for LFS. Itâs nice to have friends with a cloud blob storage service!</p><p>Source: I was the product manager for Azure Reposâs LFS server and am currently the product manager for all things Git at GitHub.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593115"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593115" href="https://news.ycombinator.com/vote?id=38593115&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Have seen various teams have major issues with LFS - becoming quite a support overhead to keep art teams productive.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593135"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593135" href="https://news.ycombinator.com/vote?id=38593135&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yeah exactly this. Git LFS is supposed to fix the problem, but I haven't seen it working flawlessly either yet.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38594330"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38594330" href="https://news.ycombinator.com/vote?id=38594330&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Interesting, I had issues using Git LFS to store images for my personal site. I thought I just didn't know how to use it properly...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593302"><td></td></tr>
                        <tr id="38593312"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593312" href="https://news.ycombinator.com/vote?id=38593312&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>That's what i liked about git too. It felt like a powerful, ready to use tool. CVS and SVN were more bureaucratic, slower and limited. Took zero second for me to drop everything else.<p>The underlying model is alien to many, it requires non black box approach to get out of pits sometimes but to me it's always worth knowing.</p><p>The only decision I dislike about git is the soldered staging area idea. There's a reason why most people end up stashing 109 times a day, and I think there's a golden idea in merging the two
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38594195"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594195" href="https://news.ycombinator.com/vote?id=38594195&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Wholeheartedly agree.<p>Going from SVN to Mercurial was a night and day experience. Going from Mercurial to Git was a marginal improvement initially but a lasting change long-term.</p><p>Then there are the "visual" VCSes like Rational and TFS that are designed to _only_ work within an IDE and grokking them involves wading through hundreds of pages of corporate tech docs.</p><p>VCSes (or at least the ones I used) were generally awful before Git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38591965"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591965" href="https://news.ycombinator.com/vote?id=38591965&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Along what axis do you want the VCS to be "better" than git?<p>For example, git's cli user interface is monstrous (yes, I know, you personally have 800 cli commands memorized and get them all right every time, that doesn't make it "good"). From the outset, the maintainers of git basically decided "it's too much work to make all the cli flags behave and interact consistently" so they didn't. This allowed git to grow fast, at the cost of the cli user experience.</p><p>That said, git is big enough that multiple companies have come along and "solved" the git UI problem. None of these aftermarket UI layers are perfect, but there are enough of them and they are different enough that you can probably find one that is good enough for you, along whatever axis you personally dislike the git UI (examples include [0], [1], [2], which tackle very different user workflow problems).</p><p>[0] <a href="https://git-fork.com/" rel="nofollow noreferrer">https://git-fork.com/</a></p><p>[1] <a href="https://graphite.dev/" rel="nofollow noreferrer">https://graphite.dev/</a></p><p>[2] <a href="https://news.ycombinator.com/item?id=7565885">https://news.ycombinator.com/item?id=7565885</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593053"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593053" href="https://news.ycombinator.com/vote?id=38593053&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I generally don't hear too many complaints about GIT in the Windows/.NET development world, probably because there are good UI front ends and there's not as much 'tough guy' cred from sticking to the CLI. Visual Studio does a decent job of abstracting the GIT nuances, but I personally use GIT Extensions, which looks and feels much better on Windows than the other cross platform UIs.<p>I drop to the CLI occasionally, especially for multi step or automated scripts, but you can pry a nice visual commit graph and full featured integrated diff viewer from my dead hands. GIT is powerful and option-laden; the perfect tool for a UI to aide in discoverability. The CLI feels like programming in a text editor vs a real IDE
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593634"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593634" href="https://news.ycombinator.com/vote?id=38593634&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; Visual Studio does a decent job of abstracting the GIT nuances, but I personally use GIT Extensions, which looks and feels much better on Windows than the other cross platform UIs.<p>IDEs and text editors sometimes have nice Git integrations in the UI, but I wanted standalone software that I can use for anything from various programming projects, to something like gamedev projects (with Git LFS) or arbitrary documents.</p><p>In the end, I just forked over some money for GitKraken, it's pretty good, especially with multiple accounts on the same platforms, when you want to switch between them easily: <a href="https://www.gitkraken.com/" rel="nofollow noreferrer">https://www.gitkraken.com/</a></p><p>There's also Sourcetree which I used before then, kind of sluggish but feature complete: <a href="https://www.sourcetreeapp.com/" rel="nofollow noreferrer">https://www.sourcetreeapp.com/</a></p><p>For something more lightweight, I also enjoyed Git Cola on various OSes: <a href="https://git-cola.github.io/" rel="nofollow noreferrer">https://git-cola.github.io/</a> Even Git documentation has a page on the software out there, a good deal of which is free and has good platform support: <a href="https://git-scm.com/downloads/guis" rel="nofollow noreferrer">https://git-scm.com/downloads/guis</a></p><p>Quite frankly, I spend like 90% of the time using a GUI interface nowadays, when I want to easily merge things, or include very specific code blocks across multiple files in a commit, or handle most of the other common operations. Of course, sometimes there's a need to drop down to the CLI, but you're right that some GUI software feels like it actually improves the usability here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593939"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593939" href="https://news.ycombinator.com/vote?id=38593939&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I too am a fervent GitExtensions apostle.<p>I really wish the 4.* release supported a dark theme, it's the only thing keeping me on the 3.* release, and I dread the day I'll have to switch for whatever reason...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593639"><td></td></tr>
                        <tr id="38590336"><td></td></tr>
                <tr id="38593087"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593087" href="https://news.ycombinator.com/vote?id=38593087&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I tried this, and I loved it. It works very well with my workflow.<p>Perhaps the author can explain - when you clone the repo with</p><p>jj git clone</p><p>It pulls down a branch that is auto generated like pull-(hash)</p><p>I canât understand how not to get that corrupted so when I do a jj log, I get very weird branches or heads or Iâm not sure what.</p><p>Another way to say it is that everything works great until I have to pull down the repo from another machine - then the branch history is not what I expect. And I just couldnât make sense of it or get it to square with what I expected.</p><p>I actually created a custom GPT and fed it the jj code and documentation to try and get it to explain it to me to no avail. Jj is so good, Iâm willing to give up IDE integration with git if I could just crack this nut.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593508"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593508" href="https://news.ycombinator.com/vote?id=38593508&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Just echoing Martin, but: if you can show the repository that is causing this, or at least a screenshot (or something) showing what you're seeing and post it on GitHub, one of us should at least be able to help figure out what's going on.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593285"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593285" href="https://news.ycombinator.com/vote?id=38593285&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I can't tell what the problem is based on that description. Feel free to file a bug report, or start a GitHub discussion, or ask on Discord.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590797"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590797" href="https://news.ycombinator.com/vote?id=38590797&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Surprised this is done in Rust. I could never imagine not doing the v1 of something like this in Python or similar, to be able to change things quickly. Maybe the design was very clear on the person's mind.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593971"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593971" href="https://news.ycombinator.com/vote?id=38593971&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I'm not particularly productive in python. The code gets shat out faster but it's a comparatively weak language for capital-P Programming â lack of types means repeating and checking yourself <i>a lot</i>.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593575"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593575" href="https://news.ycombinator.com/vote?id=38593575&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>There are other advantages aside from the static types debate in the other replies. The need for efficient version control systems is a constant and ongoing battle; you can pick the right data structures (for example, Git's issues with large files are more of a data structure problem than one of raw efficiency) but at the end of the day Python will often be behind on raw performance. Rust will hopefully let us embed the Jujutsu libraries inside other languages, something you can only achieve today in Git with something like libgit2. Finally, a lot of the infrastructure we get to use, like nextest and cargo-insta are simply fantastic even if I have my qualms about Cargo.<p>Most of the developers (some of them being former Mercurial and Git developers) including me generally seem to like it. Based on my own experience, I think it's a pretty excellent choice, but I'd be a bit biased as a die-hard Haskell/C programmer for something fast with types.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592367"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592367" href="https://news.ycombinator.com/vote?id=38592367&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I feel the opposite way.<p>Even though Python is the language Iâve used most, I wouldnât want to use it for something with a lot of uncertainty and that will suffer many changes. Type systems make it so much easier to change things early on without breaking everything. Iâd probably pick F# or similar.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593343"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593343" href="https://news.ycombinator.com/vote?id=38593343&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The current DVCS solution at Google is based on Mercurial, which is written in Python. Having worked on that for many years, I didn't want to write jj in Python. We've had problems with the performance of the current solution. Also, as others have said in sibling replies, refactoring Python is not fun due to lack of static types (I know it's gotten better).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38591747"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591747" href="https://news.ycombinator.com/vote?id=38591747&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Rust is a fabulous language for refactoring.  Strong types and complete matching make it almost completely impossible to miss a spot when making a change</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593327"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593327" href="https://news.ycombinator.com/vote?id=38593327&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Python certainly lets you change things quickly, because it does not let you automatically enforce any invariants; this is why it lets you get into such extraordinary inconsistent states so easily! I personally could never imagine trying to make a jigsaw out of jelly because "it's v1 and I'll make v2 properly".</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38590380"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590380" href="https://news.ycombinator.com/vote?id=38590380&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes. From the creators of Sqlite, you got Fossil.<p>One of the most amazing things about Fossil is how you can track the history of a file not just backwards, but also forwards, something which is pretty whacky with git.</p><p><a href="https://www.fossil-scm.org/" rel="nofollow noreferrer">https://www.fossil-scm.org</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590883"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590883" href="https://news.ycombinator.com/vote?id=38590883&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>100% fossil. there has been a few threads.. and always someone points out edge cases that are only to be solved using git.. well i dont think so. you can actually go into the sqlite db and change stuff. i've recently started playing with its server api to direct user feedback from web to fossils ticketing system. it is just mature and feature packed and i honestly hope it will get as much recognition as sqlite someday.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592421"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592421" href="https://news.ycombinator.com/vote?id=38592421&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The only thing I wish git handled better out of the box, with without any flags/setup, is large/binary assets.<p>LFS is ok but it still feels like a kludge to me.</p><p>The cli does not bother me, there are many tools that offer alternatives/overlays/UIs. Not saying it is perfect or even good, but it's good enough - for me at least.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593068"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593068" href="https://news.ycombinator.com/vote?id=38593068&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>exactly right! lfs is "<i>kinda okay?</i>" at best. i just wish binary support was just part of git natively.<p>honestly keeping the large binaries as loose objects would be fine except for performance. which should be something that could be improved with cow filesystems (lfs does use this, but limited by what git's implementation can support)</p><p>or it may be enough to incrementally improve lfs, i do see that ssh support is showing up which might help a little. need to do something about smudge/clean filters too, which would require new support in git itself.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590348" href="https://news.ycombinator.com/vote?id=38590348&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The inner workings of git are not overly complicated. The real problem is git only provides a thin layer on top of the inner workings. Itâs not git that needs replacing, (itâs just saving blobs of data) itâs the user interface on top that is confusing.  The problem with simplifying the user interface is that abstracting away the complexity is super difficult.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590474"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590474" href="https://news.ycombinator.com/vote?id=38590474&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Git feels a lot like pgp to me: somehow we're not managing to make things simple enough for use by the general public, even when you only need a few buttons and input fields.<p>There's differences, such as that pgp is more complicated under the hood and it being a cryptographic system that needs to be foolproof whereas in git you can nuke and re-clone without data loss most of the time, let alone confidentiality/integrity loss. It just feels very similar in that only expert users properly use it and most people who could make use of it don't bother learning because the interfaces available are such a struggle (beyond basic operations anyway)</p><p>Whether it can all be solved with a simpler user interface, or whether it would require a simpler underlying system to be able to make simpler standard operations, is where I'm not sure
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593554"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593554" href="https://news.ycombinator.com/vote?id=38593554&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Git does have one big architectural problem IMO - native unit of storage is a blob, not a diff. Things like rebase, cherry-pick, 3-way merge, etc would be much easier in a world where the storage model was âdiffsâ instead of âblobsâ.
This would have resulted in simpler CLI tools with fewer pitfalls.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38594577"><td></td></tr>
                  <tr id="38590499"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590499" href="https://news.ycombinator.com/vote?id=38590499&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Not overly complicated, but super difficult to abstract is somewhat of a contradiction. Maybe the inner workings are complicated, but not complicated to implement right once you understand them.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590309"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590309" href="https://news.ycombinator.com/vote?id=38590309&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes, there must be a better solution. Git is (usually) better than the alternatives, but it is far from being good. Especially the discoverability of its features is a mess - arcane command line incantations, magic processes. Sometimes only a prayer helps before running the 12th command you found on stackoverflow in desperation. Once you leave the pull-commit-push-merge-rebase circle, you gotta hope that god helps you, because no one else will (or more like no one else can).<p>Unless of course you spend time to learn git, but its complexity is closing up to C++. And using a VCS shouldn't require that amount of effort. It should just get out the way (I must admit, git usually gets out of the way, as long as you use only the base commands... but when it gets in the way, that's when the fun starts)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592262"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592262" href="https://news.ycombinator.com/vote?id=38592262&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>What do you recommend for non-programmers, who would still benefit from version control system.<p>Examples:
- Book author using markdown / static site generator to publish a book. Uses visual editors like Typora. 
- Product designers for open-source hardware. Various design files, SVG etc.</p><p>Iâve experimented with a âGUI onlyâ git flow - just to see what is possible, so I could introduce the concept to others.</p><p>I found GitHub desktop app (<a href="https://desktop.github.com/)did" rel="nofollow noreferrer">https://desktop.github.com/)did</a> a great job of visually showing git flows and functions, but for a non-tech/programmming person, the tool would be daunting.</p><p>Curiosity what your suggested tech stack would be - sans Terminalâ¦
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594164"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594164" href="https://news.ycombinator.com/vote?id=38594164&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>i'd probably recommend Mercurial, say a UI like TortoiseHq. It has 90% of the value of git with a much better interface.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38594596"><td></td></tr>
                  <tr id="38592288"><td></td></tr>
            <tr id="38593241"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593241" href="https://news.ycombinator.com/vote?id=38593241&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes, it will be superseded.  Will the new thing be âbetter?â   I guess that depends on the metric and needs.   âlsâ was done but exa/eza came along and they have users.<p>Pondering it, most of the easy things I can think about are really workflow issues on top of git.  Git doesnât exactly enforce them all though so maybe tighter integration would be a reason to change from git if it could not be adapted.   Short of that, itâs hard to imagine that a new generation of engineers simply wonât do a new thing to do a new thing; there will be a âgit considered harmfulâ article or a âmodernâ replacement for git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590414"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590414" href="https://news.ycombinator.com/vote?id=38590414&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Besides the frontend problems with git that everybody talks about, the backend could be improved. It's now line-oriented. It would be more useful if it knew about the semantics of the language you were writing so it could show you semantic differences. That might also provide a mode for binary files which git doesn't handle very well now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590432"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590432" href="https://news.ycombinator.com/vote?id=38590432&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Actually, itâs not the backend which is line oriented, itâs the front end. The backend doesnât dissect files, it stores the entire new file when even one line is changed and relies on object compression to find the similarity in the rest.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590433"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590433" href="https://news.ycombinator.com/vote?id=38590433&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Before we can get a vcs that understand semantic diffs, we need a way to communicate semantic diffs.  That way each file type can have its own âsemantic differâ. Similar to how language servers help abstract away the differences for IDEs</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590477"><td></td></tr>
                <tr id="38590525"><td></td></tr>
                <tr id="38594273"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38594273" href="https://news.ycombinator.com/vote?id=38594273&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The diffs don't have to be line-oriented if you are using a diffing tool that isn't based on line changes.<p>Git itself just stores snapshots of your files, then you can bring your own diffing tool that works in any way you'd like, it's not limited to line based diffing.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592667"><td></td></tr>
            <tr id="38590968"><td></td></tr>
                              <tr id="38593993"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593993" href="https://news.ycombinator.com/vote?id=38593993&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>there was such a thing for c#, called semantic-merge by Codice Software, a Spanish company that after being bought by Unity, killed it...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590607"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590607" href="https://news.ycombinator.com/vote?id=38590607&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Don't know about a better solution, but there might be a better interface. My pet theory is that focusing more on the fact that a repo is a directed graph would help. Make the language more graph-like (less "commit" more "node", less "branch" more "path", less "repo" more "graph"). This kind of thinking would, I think, expose a bunch more primitives that should be surfaced more explicitly than they are (lots of things are "possible but not easy" in git), and make it easier to learn for anyone with a math background. And make web searches easier too.<p>(Pretty sure I've said this before and it's been shot down before, so...)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590442"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590442" href="https://news.ycombinator.com/vote?id=38590442&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>As far as I can tell, Pijul[0] aims to have better conflict resolution and merge correctness.
I'm not super into the theory, so I can't explain it very well, but it looks promising.<p>[0] <a href="https://pijul.org/" rel="nofollow noreferrer">https://pijul.org/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38594749"><td></td></tr>
            <tr id="38590444"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590444" href="https://news.ycombinator.com/vote?id=38590444&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>An obvious area for improvement would be semantic version control.<p>If the VCS would have an understanding of not only what has changed but also how this affects the code, it could deduce a lot if interesting facts about commit blocks.</p><p>Like ignoring simple refactorings (e.g. renamings), reducing merge conflicts, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590411"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590411" href="https://news.ycombinator.com/vote?id=38590411&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Subversion was really good. It wasn't perfect, but it was relatively painless.<p>Instead everyone switched to a "distributed" version control system that is such a pain in the ass it is all now hosted by a single company.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590429"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590429" href="https://news.ycombinator.com/vote?id=38590429&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>My first job used SVN and it limited workflows compared to git. Branches are more expensive, so people adapt their workflows. I used git-svn on that job, which allowed me to refactor locally; not a feature available to me or others once pushed.<p>My colleagues evaluated git and thought it was too complicated. A few years and a lot of employments later, theyâre all using git. I donât know if it was peer pressure from enough young recruits, but the verdict is clear: git is better than SVN.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593250"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593250" href="https://news.ycombinator.com/vote?id=38593250&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>My very first programming job used Subversion. Even as a freshly minted programmer I knew we were using it completely wrong.<p>My first assignment was to spend several days picking apart an extremely nasty merge conflict from two branches nearly six months diverged. That was a <i>very</i> stupid thing to trust me with, as a major refactor was being blessed by my idiot hands.</p><p>Management could not figure out how they wanted to maintain a master/production branch.</p><p>Our 'trunk' was the develop branch, and any time we wanted to push to production.... We deleted the master branch and made a copy of develop. Master branch had no history, you had to track it back into develop and hope you found a trailhead from there.</p><p>It was a very bad time, and we were left with a <i>very</i> bad product. By the time I left, the codebase was so rotten and broken that we'd abandoned all hope of fixing the deeper issues.</p><p>I really hated subversion, but mostly the company was just unbelievably mismanaged. I'm sure you can use SVN in a sane way, just not like this
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590473"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590473" href="https://news.ycombinator.com/vote?id=38590473&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Many companies host git besides github (gitlab and bitbucket to name two), and you can spin up one of your own in about 1 minute on your hardware or on a private cloud vps.<p>A github server is much easier to set up than a subversion server. The reason people use github is because it's free, and because it has issue tracking and a wiki and forking which plain git knows nothing about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590544"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590544" href="https://news.ycombinator.com/vote?id=38590544&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>And nowadays it offers so much more like the GHAS, codespaces, copilot, actions and workflows etc that companies who get entrenched would need half a dozen different vendors to cover the feature set if they were to migrate from GitHub.<p>And in general I feel that their gh cli tool doesnât get enough praise. Being able to do easy API calls and queries for use in shell scripts (or just the terminal) is great, and the gh copilot is occasionally useful as a refresher for command syntax, or for deciphering some oddball git command you found online.</p><p>Itâs a massive beast to tackle, and few people have a reason to. I donât see anything doing what git does having a chance at competing with it. It requires a paradigm shift and a completely new product/approach to versioning to break the git dominance.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590530"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590530" href="https://news.ycombinator.com/vote?id=38590530&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>You can absolutely spin up vanilla git on your own machine, but try using it for a week. From some quick Googles it looks like Github has 80% market share of version control with Dollar Store Github (Gitlab) picking up the rest. Everyone uses the pretty tool stack built on top of it because it is overly complex. Git didn't add anything profound that couldn't have been added as a feature to another VCS.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592637"><td></td></tr>
                <tr id="38593165"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593165" href="https://news.ycombinator.com/vote?id=38593165&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The intention I got from @dreamcompiler was that "A git server is much easier to set up than a subversion server.", which I feel is true.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593615"><td></td></tr>
                  <tr id="38593024"><td></td></tr>
                  <tr id="38593587"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593587" href="https://news.ycombinator.com/vote?id=38593587&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; A github server is much easier to set up than a subversion server.<p>Oh here we go again. You are wrong my friend. Firing up a basic SVN server is a matter of minutes. You just need to run several simple commands.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590694"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590694" href="https://news.ycombinator.com/vote?id=38590694&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Torvalds liked to code on planes back when you couldn't use the internet and that's just about the only use-case I've ever heard where I agree distributed makes sense.<p>Kids these days can't even code at all without chat-GPT, there's a central server hosting the git repo anyway, the whole architecture feels like it was designed for dial-up.</p><p>I can't think of anything that was doable 30 years ago compute and bandwidth-wise, that we can't do today due to performance reasons, except client-server source control...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590426"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590426" href="https://news.ycombinator.com/vote?id=38590426&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Please, Github is so much more than git hosting. If all it offered was source hosting, no one would care for it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590471"><td></td></tr>
                <tr id="38590503"><td></td></tr>
                <tr id="38593735"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593735" href="https://news.ycombinator.com/vote?id=38593735&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I think the meaning of the sentence you're replying to is that GitHub's features are a superset of Git's features which seems true?<p>"Github isn't all git [some features of GitHub are not in Git], but all git is Github [but all features of Git are in GitHub]."</p><p>Maybe my interpretation is incorrect?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38590509"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590509" href="https://news.ycombinator.com/vote?id=38590509&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I recently started a new job that uses SVN, one thing that really catches me out is that it doesn't automatically add new files. Is there some easy trick I am missing to tell SVN to automatically track everything recursively under a folder?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590291"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590291" href="https://news.ycombinator.com/vote?id=38590291&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Of course there is a room for improvement... One of the biggest issues is usability/user experience: pull, fetch, checkout, commit, push, rebase - what is all this and what is the exact meaning? I need simple English terms for my work - like update and save - nothing more. Why do I need to worry about implementation details and terms? If I can not explain it to my wife, then I can not use it for binary documents which she needs to store in a repo... in this case Subversion is a better version-control-system for her documents... Just SVN Update/SVN Commit - nothing more to learn in Subversion...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590643"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590643" href="https://news.ycombinator.com/vote?id=38590643&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Imagine an electronic engineer complaining about an oscilloscope being hard to use because he cannot explain what all those knobs do to his wife. We are professionals, our tools should be powerful for the advanced user, not beginner friendly.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38592853"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592853" href="https://news.ycombinator.com/vote?id=38592853&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>A tool can be both beginner friendly AND powerful for advanced users.<p>Speaking of your analogy, the role that most software developers fullfil is not an engineer wondering about the oscilloscope, but rather the construction worker installing electrical fixtures wondering why the cable clamp has such a weird interface. Both the oscilloscope engineer in an office and the worker doing the field work would benefit from having a simple and reliable tool fit for purpose of cable clamping.</p><p>There is certainly a need for competent and "proper" software engineering that require special tools and detailed training, but I would argue it's niche and filled by people who build the tools themselves.</p><p>IMO the largest share of developers today are doing brick-laying work (which of course takes skill, I am not underestimating it) and would benefit a lot from having simpler tools - they don't need to know how to use an oscilloscope at all.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592755"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592755" href="https://news.ycombinator.com/vote?id=38592755&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yes, but if the oscilloscope has some buttons that take out the entire companyâs codebase if pressed wrong.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592359"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592359" href="https://news.ycombinator.com/vote?id=38592359&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>There has been a lot of push to commoditize software engineering. Unfortunately that has resulted in a swarm of people who want developer salaries without the work or expertise.<p>Git definitely has some warts but you are right. It is an industry tool for expert, professional use. Some complexity is inherent to the problem of version control.</p><p>Learning how to use your tools is part of ANY trade.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592963"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38592963" href="https://news.ycombinator.com/vote?id=38592963&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;It is an industry tool for expert, professional use.<p>If you were talking about things like Kubernetes, LLVM, Ghidra then I'd agree.</p><p>But no git. This is not some expert tool.</p><p>This tool's purpose is literally to manage your characters' history, that's it.</p><p>Git could be used by any other profession that deals with letters - article writers, book writers, etc, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592193"><td></td></tr>
            <tr id="38592903"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592903" href="https://news.ycombinator.com/vote?id=38592903&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;We are professionals, our tools should be powerful for the advanced user, not beginner friendly.<p>You can have both - powerful and user friendly.</p><p>This idea that engineer's tools must be a mess that is fine as long as enables to do something is idiotic.</p><p>The same argument was repeated whenever C or C++ vs Rust discussions were happening</p><p>"Just learn C and memory management (and all the quirks)"</p><p>"Just use this new language constructs and you're fine..."</p><p>and in reality we ended with a lot of CVEs - 70% in both Chrome and Windows were related to mem. issues.</p><p>There's absolutely no reason why git's CLI cannot be better than it currently is. Once again - there is no reason.</p><p>Proof? There are CLI wrappers or even GUIs like GitHub Desktop that make whole experience way better.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590330"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590330" href="https://news.ycombinator.com/vote?id=38590330&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>To be honest, I canât even imagine what you imagine âgit saveâ  and âgit updateâ would even do in an alternate universe.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590396"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590396" href="https://news.ycombinator.com/vote?id=38590396&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>This is funny because in PR oriented development I started treating commits in the same way as "save" in IDE,<p>it's just backup of current state with irrelevant commit message. Everything is described at the end of the work in PR's description and squash merged.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592328"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38592328" href="https://news.ycombinator.com/vote?id=38592328&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Giant PRs that are squashed into one commit are an anti-pattern. Every commit should contain exactly one logical change AND a descriptive commit message.<p>Unfortunately a good chunk of the industry doesn't have the discipline to do this.</p><p>If you have ever worked in a project where there was discipline around committing, you know there is lots of value in doing so (rebasing becomes easier, you unlock the power of bisect, log is actually useful).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38591537"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38591537" href="https://news.ycombinator.com/vote?id=38591537&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>But then you can't use blame to look at the current code state. And it also becomes a nightmare to revert your changes.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38591486"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591486" href="https://news.ycombinator.com/vote?id=38591486&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>when i started out with git i made an alias to immediately do "git add . &amp;&amp; git commit -m 'lazy' &amp;&amp; git push" to make it easy to always save my work and ensure its on the server too. git pull is easy enough to remember + type, but i could imagine just calling it update</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38591554"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591554" href="https://news.ycombinator.com/vote?id=38591554&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I would imagine git save is commit, and update is pull?<p>I think they just want to replace some of the words with alternatives that <i>they</i> prefer. Because at some point someone is going to winge that update should be syncronise and not pull, and save should be push and therefore git is the worst.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590458"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590458" href="https://news.ycombinator.com/vote?id=38590458&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Then you might be better off with something like Subversion indeed.<p>Git is distributed, and that means you can't get away from push, pull and fetch, however you name them.</p><p>If want you want is a way to avoid making "New New Presentation FINAL 2", then pretty much all features of most source control systems are superfluous.</p><p>To me that doesn't mean Git needs fixing, it means it's definitely not the right tool for your job.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590478"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590478" href="https://news.ycombinator.com/vote?id=38590478&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>If the specific words used are the problem, using aliases is a straightforward way to fix them. If you do it for someone, it will break the possibility of searching for help online though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38594482"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594482" href="https://news.ycombinator.com/vote?id=38594482&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I think git has become the standard now. I used git as the reference point when I had to implement a custom version control system for a product .  Also many things can be built on top of git, like GitHub for instance</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593062"><td></td></tr>
            <tr id="38593117"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593117" href="https://news.ycombinator.com/vote?id=38593117&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>My experience is that the power of any technology unfolds gradually - with git it's like okay let's master the commands for a single repository on a single server for a single user up to a certain level of adequacy.  Then (depending on need), let's add multiple repositories on the same single server for the same single user.  Then add multiple servers (including a git remote server).  Then add multiple users ... etc ... of course the magic of git is you can unfold those needs in any sequence.  Often when I find I do not understand something (that I thought I understood), I go back in scope to an earlier unfolding, eliminating other factors.<p>I'm sure git can be improved, but I think the biggest improvement comes from the user being improved with their understanding of the scope of capabilities.  I have yet to see a good tutorial on this (among the plethora of git tutorials out there).  This reminds me of the (excellent) video where the "Harvard Professor Explains Algorithms in 5 Levels of Difficulty" [1]</p><p>[1] <a href="https://www.youtube.com/watch?v=fkIvmfqX-t0" rel="nofollow noreferrer">https://www.youtube.com/watch?v=fkIvmfqX-t0</a></p><p>I would love to see a Channel where that is the entire theme - explaining everything in 5 levels of difficulty.</p><p>All this being said, at each of the "5 levels of difficulty" of git, are there improvements to be made.  I'm sure there are.  It would be good to focus the answer on each of those levels.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590467"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590467" href="https://news.ycombinator.com/vote?id=38590467&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>In my opinion the feature Git has always been missing is version control of branches. Of course the immediate consequence would be that you'd be able to roll back changes to branches but there'd be some more fundamental consequences as well. I'm pretty sure some of the problems with GUI's/wrappers around Git break down because there's no tracking of branches/tags.<p>Besides that it's pretty much endgame in my opinion if you consider only the functionality it's meant to solve. If another "better" VCS would ever become popular I feel it would have to be a drastic change to the way of working with VCS, even more drastic than SVN to Git was. There's some cruft in Git that could probably be taken away, and that would make Git better in a theoretical sense, but in the real world that would never happen (unless we get sideswiped by another industry or platform).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590511"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590511" href="https://news.ycombinator.com/vote?id=38590511&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Can you clarify what you mean by "version control of branches"? Branches in Git are just labels of objects. Are you talking about having a history of which objects a branch has previously labelled, like the reflog?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590569"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590569" href="https://news.ycombinator.com/vote?id=38590569&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yeah, I feel the reflog is more of a tool to do introspection on a git repository than that is a tool for collaboration. It's just something I've felt was missing from Git. If you're looking at the main branch of a repository, what was the previous version of that branch?<p>The way we work around that missing feature is by tagging commits so we don't forget what revision a release was made at for example. A sequence of release tags basically is a meta branch, a history of the release branch, but managed manually instead of through git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592393"><td></td></tr>
                        <tr id="38590486"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590486" href="https://news.ycombinator.com/vote?id=38590486&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Locally thereâs a kind of version control for branches in the âgit reflogâ where you can see how a branch alias has been moved</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38591708"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591708" href="https://news.ycombinator.com/vote?id=38591708&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yes we can. The shortcomings of git are that it doesn't handle binary files well, and you can't clone a slice of a repo. the system after git will handle both of those. mono repo or not is not a question with aftergit because you can clone just a subdir and work there, without the overhead of cloning the whole thing, but also without the weight of keeping up with commits happening outside of your directory.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38594976"><td></td></tr>
                  <tr id="38593443"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593443" href="https://news.ycombinator.com/vote?id=38593443&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Maybe there are certain domains where you could obviously do better. Take an artist wanting to version control images, i could imagine specialized tools that could be much better. For programming, there could be improvements for versioning groups of repositories that work together perhaps.<p>For standard needs, probably going to be difficult.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593672"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593672" href="https://news.ycombinator.com/vote?id=38593672&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>We've been working on a data version control system called "oxen" optimized for large unstructured datasets that we are seeing more and more with the advent of many of the generative AI techniques.<p>Many of these datasets have many many images, videos, audio files, text as well as structured tabular datasets that git or git-lfs just falls flat on.</p><p>Would love anyone to kick the tires on it and let us know what you think:</p><p><a href="https://github.com/Oxen-AI/oxen-release">https://github.com/Oxen-AI/oxen-release</a></p><p>The commands are mirrored after git so it is easy to learn, but optimized under the hood for larger datasets.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593898"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593898" href="https://news.ycombinator.com/vote?id=38593898&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yes, I think that we can do better than plain text as the source of truth, and thus git would probably need to change.<p>There's work around a bunch of languages that are not based on text, some have their own editor or a tool to manage a canonical representation in text for you that would make them friendlier to git.</p><pre><code>  - https://github.com/yairchu/awesome-structure-editors/blob/main/README.md</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590425"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590425" href="https://news.ycombinator.com/vote?id=38590425&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>You could probably do better, yes. But if someone is to do better, I'd hope they actually learn git first.<p>A lot of alternative tools come up because of people writing them being unwilling to learn git. There are a handful of concepts and a few handfuls of commands and thats it.</p><p>And once someone learns git throroughly, they usually come to see that it is actually good enough, and dont bother making something new.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590443"><td></td></tr>
                  <tr id="38590377"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590377" href="https://news.ycombinator.com/vote?id=38590377&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I do believe that it is possible, at least at the API (cli) level.<p>While git is good under the hood, then it has not really user-friendly interface.</p><p>Also git heavily benefits from GitHub's success, which locks us with git :(</p><p>I wrote about it here <a href="https://trolololo.xyz/github" rel="nofollow noreferrer">https://trolololo.xyz/github</a> - GitHub is really good, but there's a small problem with that
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593902"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593902" href="https://news.ycombinator.com/vote?id=38593902&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Iâve worked with git since 2016. I guess I must not be a power user because beyond using like six got commands Iâve never had any issues or felt like man my workflow is interrupted.<p>What features do you think need to be improved? From a purely UX pov I think git is probably the best software Iâve used. It just works.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38594062"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594062" href="https://news.ycombinator.com/vote?id=38594062&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I think the nomenclature could have been better, and less technical people would use it.  Calling it commit when itâs essentially a save is good start . Yes I know it isnât exactly the same as saving but who cares.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590508"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590508" href="https://news.ycombinator.com/vote?id=38590508&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>There are already various ways in which mercurial or perforce are better than git, and big companies like Google and Meta have hacked on the systems they started with so much that one can hardly say theyâre still perforce/hg. There can be disadvantages there but it seems obvious to me that better systems are possible. It feels to me like the real question is whether GitHub is the endgame.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590489"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590489" href="https://news.ycombinator.com/vote?id=38590489&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I think Git itself is probably too entrenched to be displaced by now, but I recently came across Graphite (<a href="https://graphite.dev/" rel="nofollow noreferrer">https://graphite.dev/</a>) and, while itâs all still Git under the hood, it abstracts away many of the common pain points (stacking PRs, rebasing) and has nice integrations with GitHub and VS Code.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590516"><td></td></tr>
                  <tr id="38593357"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593357" href="https://news.ycombinator.com/vote?id=38593357&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Really depends on "what".<p>I use a wiki which internally uses RCS, but you never see it. The only reason I even know is that I needed to scan older versions of some assets and it was straightforward compared to what you'd expect with Git. (Other bonus, attachments and meta pages are stored as actual files. With a little bit of code you can cobble together an automated page builder for e.g. physical assets.)</p><p>I consider rsync --link-dest a version control system.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590504"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590504" href="https://news.ycombinator.com/vote?id=38590504&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I more or less consider it a solved problem.<p>You're mostly going to hear from people here who are annoyed with Git or otherwise more interested in the topic of version control than the median developer. For me, I think it provides a quite robust and well thought-out set of primitives, and then composes them upwards in ways which are about as good as one can expect.</p><p>Some stuff obviously isn't well supported. Using the same Git repo to hold large binaries as well as source code is not well supported unless you reach for LFS - that's the biggest downside I see.</p><p>Fossil would be my next bet. I'm waiting for someone to make an archaeology.co to rival GitHub.com for it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593374"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593374" href="https://news.ycombinator.com/vote?id=38593374&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;I think it provides a quite robust and well thought-out set of primitives<p>The existence of the staging area is a poorly thought out part of the design. No other VCS uses it because it was a bad idea that makes the simple case of commuting changes more complicated.</p><p>&gt;Fossil would be my next bet. I'm waiting for someone to make an archaeology.co to rival GitHub.com for it.</p><p>Which is exactly why fossil will not be the next big VCS. Ignoring all of the projects on Github add forcing people to move to a less featureful, less integrated, less familial forge just to use a new source control system is a hard sell. The approach of Sapling and Jujutsu where they support the git protocol so that they can be used Github will make them much easier to adopt since it can happen incremenetally and it fully replace git for people.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593977"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593977" href="https://news.ycombinator.com/vote?id=38593977&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Git has problems but is mostly alright, cli aside.<p>Git as practiced by GitHub and gitlab is <i>awful</i> quite a lot of the time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590480"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590480" href="https://news.ycombinator.com/vote?id=38590480&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Git is great for keeping track of logical history, but personally I find that it is missing tools for handling physical history. Reflog is a step in the right direction but it has a limited size and AFAIK it is not possible to share a reflog between clones. Which leaves "cp -r repo repo.backup" as the best option.<p>Of course, as long as you only do additive changes via commit/merge/revert, the logical history is equivalent to the physical history, but commands like rebase break this model. And despite the flaws of rebase workflows, sometimes it is the best option, like when maintaining a fork.</p><p>To my surprise Vim actually has something like this - logical history with undo/redo and physical history with g+/g-/:earlier/:later</p><p>Another thing I would like is some way to "fold" multiple small commits into one bigger one (for display purposes only) as it would let me split large diffs into minimal, self-contained commits while maintaining a reasonable git history.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590490"><td></td></tr>
                <tr id="38590559"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590559" href="https://news.ycombinator.com/vote?id=38590559&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The simple explanation:
Logical history - what you see when you do "git log --all".
Physical history - doing "git log --all" every time a repository updates and then storing each output as an entry into another history log. Kind of a "history of histories"<p>The complex explanation: a git repository at a particular time consists (mostly) of a graph of commits. This graph represents the logical history of code changes in the repository. The graph can be updated in an append-only fashion (using commit/merge/revert) or in a destructive way like with rebase and reset. The physical history is simply the history of the graph over time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590885"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38590885" href="https://news.ycombinator.com/vote?id=38590885&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>in other words the history of the graph is the physical history<p>and the logical history is the filesets which are the nodes in the graph which is the branching sequence of commits</p><p>the issue is that the 'logical history' is the reason git was built</p><p>and the 'physical history', seems to me, is only feasible because we have the regular git sequence of commits
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38594076"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594076" href="https://news.ycombinator.com/vote?id=38594076&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>To me, "Could there be something better than git?" is not the important question.<p>What matters is if git is good enough.</p><p>Or more specifically, is if git good enough for X when X is something that is actually being done.</p><p>I mean, git is good enough for my very minimal needs and the needs of people with much more sophisticated needs than mine (e.g. the Linux team). And since I know more about git than any other VCS (in part because there are better resources for learning git than any other VCS) learning another VCS for the sake of learning another VCS wouldn't help me get anything done.</p><p>None of that means git is good enough for your needs, but statistically, it probably is good enough for your needs because statistically, most difficulties with git are related to training and knowledge since the mathematics underpinning git are (to the best of my understanding) sound.</p><p>Which also implies (not accidentally) that being better than git requires better resources for learning the new VCS than git has, and that's a very tall order.</p><p>Good luck.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593071"><td></td></tr>
            <tr id="38590528"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590528" href="https://news.ycombinator.com/vote?id=38590528&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>git could be thousand of times more user-friendly,
but its too command-line centric, so workflow is
limited to complex "sub tool invocations".
GUIs for git exist but they add extreme overhead 
for simple workflows, perhaps some "standard web interface"  
 backend should be prioritized( Github is popular due their UI).
Another alternative is simplifying arcane command invocations,
i'd expect "git workflow_commandX file_target" instead
of tons of switches and parameters. There should be hundreds
of such "standard shortcut commands" to reduce mistakes.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590514"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590514" href="https://news.ycombinator.com/vote?id=38590514&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I'm not sure git is so bad that we need something different. It's certainly awkward at times, but it is also mostly a side-tool: not the thing you think of when you think of being a developer, yet every dev uses it.<p>I suspect most people use just a tiny subset of git day-to-day, and google the rest when it comes up.</p><p>For this reason, I think if git is replaced, it won't be because whatever comes along will be better objectively, it will be because a few reasons are touted that most people don't understand but are willing to repeat, and some momentum builds behind the alternative.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590187"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590187" href="https://news.ycombinator.com/vote?id=38590187&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Many tried, few succeded.
SVN - client-server principle, but bad at merging branches
mercurial - one of the competitors after the linix kernel devs searched a new version control system, its users die out, since git is more popular, very similar to git
bazaar - mostly used for ubuntu, since launchpad is only providing bazaar as vcs</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38592698"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592698" href="https://news.ycombinator.com/vote?id=38592698&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Launchpad added Git support years ago. Also, bzr pre-dates git by a tiny bit, too. But sadly git won.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592514"><td></td></tr>
                <tr id="38592830"><td></td></tr>
                <tr id="38593301"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593301" href="https://news.ycombinator.com/vote?id=38593301&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>To clarify, jj is not derived from Mercurial, but it's heavily inspired by it. The current DVCS solution at Google (called Fig) is based on Mercurial, however. But we're hoping to replace it by jj.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38590456"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590456" href="https://news.ycombinator.com/vote?id=38590456&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>It would be hard to get past the network effects. Just like how we are stuck with SMTP, JavaScript, PDF, HTML, etc.<p>The only way I could see it changing is if we have a complete paradigm shift. This is what happened when we went from SVN to Git (centralised to distributed).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592548"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592548" href="https://news.ycombinator.com/vote?id=38592548&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>SVN is only 5 years older than git, and while git is distributed, people basically use it like it's a centralized VCS these days.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590501"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590501" href="https://news.ycombinator.com/vote?id=38590501&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Something that is better should be able to track moves, not just store state. Moves of files and even partial content moved within (text) files. Unfortunately, that needs a tight coupling to the editor, so I doubt that's going to happen.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590238"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590238" href="https://news.ycombinator.com/vote?id=38590238&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I'm sure we can, the question is, can we make an alternative to GitHub?  I wouldn't be surprised if there are already several better ones, but I've never looked, because I already know Git, and my chances of convincing anyone to use a better one seem low, and they rarely seem to have as big of an ecosystem.<p>If it doesn't have multiple clouds providers with pull requests, and at least one of those clouds providers isn't a megacorp, it probably won't be the safe boring choice, unless it's fully P2P.</p><p>It needs to be packaged in distros,  have GUI integrations, etc.</p><p>Fossil looks really cool, I really like how they integrate the wikis and issues.  But I don't know anyone who uses it, and the cloud providers seem to be smaller "Could go away any time" companies.</p><p>I've never really explored any other VCSes, because none ever seem like they're going to be serious competitors.</p><p>I'd be more interested in enhancing Git, but it seems a lot of the most interesting git plugins and extensions aren't updated, like GitTorrent.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594179"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594179" href="https://news.ycombinator.com/vote?id=38594179&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Re: GitHub alternatives, I've been looking at this for a while as I'm keen to not have everything centralised and Microsoft are hardly the most trustworthy...<p>There are some GithHub-alikes, the most obvious is GitLab which you can also host yourself but all (or at least some of) the extras you get for free with GitHub are behind payment walls.</p><p>My current favourite is Codeberg, it uses Forgejo underneath (which is a fork of Gitea itself a fork of Gogs - all of which you can self host). Codeberg is run by a non-profit and are very much aligned with my ideals. They are also slowly adding nice features like their Woodpecker CI.</p><p>One that is growing in popularity and is a little less "GitHub-y" is SourceHut (which also has Mercurial support).</p><p>The main issue is that GitHub has really cornered the market. They give so much out for free that is difficult for others to compete with and it has become the de-facto place to host your project. This can mean that hosting anywhere other than GitHub will limit discoverability and contributions from people if they don't want to make an account or work out how to deal with whatever forge you are using.</p><p>However one thing that is coming that may help alleviate some of that is forge federation which will allow you to interact with various forges from your "home" forge - which hopefully prevents the need to make an account to make PRs or raise issues.</p><p>Edit: I see your other comment now, what could a better GitHub be that supports a better-than-git VCS. Well there did used to be places to host Darcs projects like the Darcs Hub but I don't know if some of the newers ones like Pijul or Jujutsu have any forge support yet.</p><p>Edit2: Oh it seems Pijul has "The Nest" for hosting.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590520"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590520" href="https://news.ycombinator.com/vote?id=38590520&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; the question is, can we make an alternative to GitHub? I wouldn't be surprised if there are already several better ones, but I've never looked, because I already know Git<p>Â¿Que?</p><p>If you're wondering whether we can make something better than GitHub, there's dozens of git hosting alternatives that you might like better such as Forgejo and GitLab.</p><p>If you're saying "but I already know git", then there's still dozens of alternative hosting sites or methods!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590587"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590587" href="https://news.ycombinator.com/vote?id=38590587&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>GitHub is the one everyone else uses though, which means you can have everything in one place, so they have the advantage.<p>There are others that are <i>almost</i> as good, I suppose what I should have said is "Can we make something better than GitHub for the hypothetical better non-git VCS", since without that it's hard to imagine using anything but Git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38591548"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38591548" href="https://news.ycombinator.com/vote?id=38591548&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Pretty sure alternative git services are still larger than alternative source control systems, yet OP is asking about alternatives to git which will be even smaller. The whole point is that the person wants to use something else. If your argument is that Microsoft GitHub is the largest and therefore the best, it's circular reasoning and will forever remain that way.<p>We should all stay on Facebook also if they're the best because everyone's on Facebook and the network effect has benefits; somehow it seems people have more sense than that and we can actually switch to smaller services which are more aligned with what we want
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38590739"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590739" href="https://news.ycombinator.com/vote?id=38590739&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes, but due to its simplicity + extensibility + widespread adoption, I wouldnât be surprised if weâre still using Git 100+ years from now.<p>The current trend (most popular and IMO likely to succeed) is to make tools (âlayersâ) which work on top of Git, like more intuitive UI/patterns (<a href="https://github.com/jesseduffield/lazygit">https://github.com/jesseduffield/lazygit</a>, <a href="https://github.com/arxanas/git-branchless">https://github.com/arxanas/git-branchless</a>) and smart merge resolvers (<a href="https://github.com/Symbolk/IntelliMerge">https://github.com/Symbolk/IntelliMerge</a>, <a href="https://docs.plasticscm.com/semanticmerge/how-to-configure/semanticmerge-configuration-guide#HowtoconfigurewithGit" rel="nofollow noreferrer">https://docs.plasticscm.com/semanticmerge/how-to-configure/s...</a>). Git it so flexible, even things that it handles terribly by default, it handles
fine with layers: e.g., large binary files via git-lfs (<a href="https://git-lfs.com/" rel="nofollow noreferrer">https://git-lfs.com</a>) and merge conflicts in non-textual files by custom merge resolvers like Unityâs (<a href="https://flashg.github.io/GitMerge-for-Unity/" rel="nofollow noreferrer">https://flashg.github.io/GitMerge-for-Unity/</a>).</p><p>Perhaps in the future, almost everyone will keep using Git at the core, but have so many layers to make it more intuitive and provide better merges, that what theyâre using barely resembles Git at all. This flexibility and the fact that nearly everything is designed for Git and integrates with Git, are why I doubt itâs ever going away.</p><p>Some alternatives for thought:</p><p>- pijul (<a href="https://pijul.org/" rel="nofollow noreferrer">https://pijul.org</a>), a completely different VCS which allegedly has better merges/rebases. In beta, but I rarely hear about it nowadays and have heard more bad than good. I donât think we can implement this alternate rebases in Git, but maybe we donât need to; even after reading the website, I donât understand why pijulâs merges are better, and in particular I canât think of a concrete example nor does pijul provide one.</p><p>- Unison (<a href="https://www.unison-lang.org/" rel="nofollow noreferrer">https://www.unison-lang.org</a>). This isnât a VCS, but a language with a radical approach to code representation: instead of code being text stored in files, code is ASTs referenced by hash and stored in essentially a database. Among other advantages, the main one is that you can rename symbols and they will automatically propagate to dependencies, because the symbols are referenced by their hash instead of their name. I believe this automatic renaming will be common in the future, whether itâs implemented by a layer on top of Git or alternate code representation like Unison (to be clear, Unisonâs codebases are designed to work with Git, and the Unison project itself is stored in Git repos).</p><p>- SVN, the other widespread VCS. Google or ask ChatGPT âGit vs SVNâ and youâll get answers like this (<a href="https://www.linode.com/docs/guides/svn-vs-git/" rel="nofollow noreferrer">https://www.linode.com/docs/guides/svn-vs-git/</a>, <a href="https://stackoverflow.com/a/875" rel="nofollow noreferrer">https://stackoverflow.com/a/875</a>). Basically, SVN is easier to understand and handles large files better, Git is decentralized and more popular. But what about the differences which canât be resolved by layers, like lazygit for intuition and git-lfs for large files? It seems to me like even companies with centralized private repositories use Git, meaning Git will probably win in the long term, but I donât work at those companies so I donât really know.</p><p>- Mercurial and Fossil, the other widespread VCSs. It seems these are more similar to Git and the main differences are in the low-level implementation (<a href="https://stackoverflow.com/a/892688" rel="nofollow noreferrer">https://stackoverflow.com/a/892688</a>, <a href="https://fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki#:~:text=Both%20Fossil%20and%20Git%20store,emphasis%20on%20the%20entire%20DAG" rel="nofollow noreferrer">https://fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki#...</a>.). It actually seems like most people prefer Mercurial and Fossil over Git and would use them if they had the same popularity, or at least if they had Gitâs popularity and Git had Mercury or Fossilâs. But again, these VCSs are so similar that with layers, you can probably create a Git experience which has their advantages and almost copies their UI.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593203"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593203" href="https://news.ycombinator.com/vote?id=38593203&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The canonical example of a merge that is impossible via Git's `recursive` is a base of "AB" (where each character appears on a single line but I've omitted the newlines for brevity), branch 1 is one commit containing "AXB", and branch 2 which is a commit "GAB" followed by another commit "ABGAB". Then the recursive merge of the two branches into each other cannot tell which AB pair in branch 2 the X from branch 1 should be inserted into, because it never sees the first commit of branch 2 which tells you that the "original" AB is the one after the G. `recursive` cannot distinguish between "AXBGAB" and "ABGAXB" as possibilities. A merge algorithm which looks at every commit can know that "ABGAXB" is more faithful to the actual sequence of events, because it knows which AB pair the X was inserted into on branch 1.<p>(Another plausibly correct answer of course would be "AXBGAXB", but again `recursive` doesn't know enough to guess this answer.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590450"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590450" href="https://news.ycombinator.com/vote?id=38590450&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes. Here are areas where git sucks:<p>* UX, obviously.</p><p>* Large files (LFS is a not-very-good poorly integrated hack)</p><p>* Very large projects (big company codebases). Poor support for sparse/partial checkouts, stateful operations (e.g. git status still scans the whole repo every time on Linux), poor &amp; buggy support for submodules.</p><p>* Conflict resolution. It's about as basic as it can be. E.g. even zdiff3 doesn't give you quite enough information to resolve some conflicts (you want the diff for the change that introduced the conflict). The diff algorithms are all fast but dumb. Patch based VCS systems (Darcs, Pijul) are apparently better here.</p><p>IMO the most interesting projects that are trying to solve any of these (but not all of them sadly) are Jujitsu and Pijul.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590538"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590538" href="https://news.ycombinator.com/vote?id=38590538&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; The diff algorithms are all fast but dumb. Patch based VCS systems (Darcs, Pijul) are apparently better here.<p>Isnt one of git's core features that it can work as a patch based system?</p><p>It's my understanding (and please correct me if I'm wrong) that Linux patches can come in via mailing list, as a diff. That would make the person committing different from the owner of the change (also reflected in git's design)? Do Darcs and Pijul just have a string of patches on top of the original source file?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38591009"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591009" href="https://news.ycombinator.com/vote?id=38591009&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Got can apply patches, yes. But I mean when it has two commits (which are snapshots, not patches) and it uses a diff algorithm to synthesise a patch between them.<p>It uses an algorithm which is great from a computer science point of view (low algorithmic complexity, minimal length, etc.) but pretty bad from a semantic point of view (splitting up blocks, etc.).</p><p>There are a couple of attempts to improve this (DiffSitter, Difftastic) but they don't integrate with GUIs yet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38590382"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590382" href="https://news.ycombinator.com/vote?id=38590382&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Perforce.<p>As for DVCS, the best one I've used is Darcs: <a href="https://darcs.net/" rel="nofollow noreferrer">https://darcs.net/</a> There are some sticky wickets (specifically, exponential-time conflict resolution) that hindered its adoption.</p><p>Thankfully, there's Pijul, which is like Darcs but a) solves that problem; and b) is written in Rust! The perfect DVCS, probably! <a href="https://pijul.org/" rel="nofollow noreferrer">https://pijul.org/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590142"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590142" href="https://news.ycombinator.com/vote?id=38590142&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I personally think that Fossil is a good example that's extant and used in serious projects. There's that one called pijul which also looks good in theory, but I haven't worked with it. I think version control in general is a little broken before you even get to the software level, but those are two projects tackling some of the problems. And Fossil, I think, is more suited to the scale most people operate on.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38594093"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594093" href="https://news.ycombinator.com/vote?id=38594093&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I feel like git is poorly thought out. If a group of dedicated smart people set out to build a version control system, I doubt they would end up with git.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38591107"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591107" href="https://news.ycombinator.com/vote?id=38591107&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; Or is it a solved problem and Git is the endgame of VCS<p>I've read so many comments to the effect that "X is a solved problem" when it clearly wasn't that I've come to conclude that the phrase means the opposite of its surface value...</p><p>I'm pretty sure that Git is not the end-of-line as far as VCSs go. Whether <i>I</i> will ever change my VCS, again, ever, that is an entirely different question. I've been through so many of them (RCS; a bit of CVS; a bit of Subversion which promised to be CVS-without-the-flaws, which it was not; Mercurial, because hey it was written in Python, so must be good, right? right?; <i>finally</i> Git; and of course the usual `report-v4-revision-good-one.doc` renaming game; plus a plethora of backup solutions, some really bad ones among them)âso <i>many</i> of them I'd be loathe to switch to yet another one, except <i>maybe</i> Fossil, which I almost did.</p><p>So yeah, I had totally forgotten about <a href="https://fossil-scm.org/" rel="nofollow noreferrer">https://fossil-scm.org</a> ; the reason it didn't become my go-to solution is probably mainly the fault of github.com, which I find too good to be ignored, and I don't want an 'impedance mismatch' between my system and their system. But maybe it would be doable and maybe Fossil is good enough to be worth it; at any rate, go read their docs, especially where they compare themselves directly to Git and give lots of good reasons for their way of doing things. This is the same people who are doing SQLite, so I'd say a trustworthy source of reliably top quality software.</p><p>Other than that, my personal way of dealing with the complexities of Git is to avoid using parts that I don't need or don't know about well enough (i.e. almost all of it). I use it to check in changes, give one line of comment, and upload to github.com; then of course cloning and updating existing repos as well as setting up a new ones is within my skill set. Branching and merging not so much. So it's like `git` plus `clone`, `add`, `commit`, `push`, that's all; also, I use Sublime Merge for part of these (reviewing changes, adding related changed chunks, commit) which I must recommend for the piece of fine software that it is.</p><p>I also at some point toyed with gitless (I think it was called) which promised to be Git, but simpler for the simple things and you can always fall back to Git proper where called for; this I find a good proposition that I like (Markdown: fall back to HTML; CoffeeScript: fall back to JavaScript) but somehow gitless didn't stick with me; I <i>guess</i> that's b/c I've already tempered down my usage of Git to a point near absolute zero, and command line history + Sublime Merge does the rest.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593164"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593164" href="https://news.ycombinator.com/vote?id=38593164&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;Mercurial, because hey it was written in Python, so must be good, right? right?;<p>Well, I can't really say that that's why, but yeah. Mercurial's pretty great.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592826"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592826" href="https://news.ycombinator.com/vote?id=38592826&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes.<p>IMHO the next VCS model should follow a centralized-first, decentralized optional model. Which would be a flip of the decentralized-first model of git.</p><p>I also think GitHub is in a unique space to really innovate on git and itâs a shame theyâre not.</p><p>For example, I shouldnât need to make a fork to make a PR. Thatâs absurd and the GitHub server should be able to apply ACLs based on the push identity.</p><p>Thereâs a couple more of these suggestions I can think of, but yeah, GitHub should do more in this space.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590168"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590168" href="https://news.ycombinator.com/vote?id=38590168&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>git : version control :: vim : editors<p>There is definately scope for a beginner friendly UI/UX. Julia Evans has a post lately about confusing aspect of git. Ability to version control  large files (like git-lfs) would be a nice addition.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590846"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590846" href="https://news.ycombinator.com/vote?id=38590846&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The best feature of Git is that itâs used virtually everywhere. I donât really care about anything else, I just know I wonât contribute to a repo if it doesnât use Git.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590440"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590440" href="https://news.ycombinator.com/vote?id=38590440&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>No, git is perfectly fine. You just need to study it to master it, just like every other tool we use in our craft.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593255"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593255" href="https://news.ycombinator.com/vote?id=38593255&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>"Fine" is not "optimal". The mere fact that something does the job does not make it the best possible thing that does the job.<p>The most trivial example of a thing that is wrong with Git and which no amount of getting better with the tool can possibly help is "once you generate a conflict, you cannot perform any other versioning operations until you fix the conflict or revert". In particular, for example, you cannot commit a partial resolution of a conflict: you simply have to bail out and try and put your histories in a state that is more acceptable to the merge algorithms before trying again.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590405"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590405" href="https://news.ycombinator.com/vote?id=38590405&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I am not sure if we will ever be able to replace git with anything else. It is so ubiquitous and just "good enough" for most developers, that the pain of switching to a completely new system would far outweight the benefits. Therefore the only solution that I see is a versioning system that is fully backward compatible with git, maybe just a better API layer on top of git. Facebook tried something similar with Sapling.<p>For a new versioning system we do not need twenty different choices. We need one  free, open, and solid solution that everybody uses.</p><p>What the main leaders of the industry should really is to found a groupo that defines that standard. This would be their chance to really make the world a (slightly)  better place.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590434"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590434" href="https://news.ycombinator.com/vote?id=38590434&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; It is so ubiquitous<p>It wasn't until 2011 that Subversion dropped below 50% market share in the Eclipse Community Survey. Something new and shiny will come along and replace git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  </tbody></table>
  </td></div></div>]]></description>
        </item>
    </channel>
</rss>