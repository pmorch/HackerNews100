<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 21 Dec 2024 08:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[US judge finds Israel's NSO Group liable for hacking journalists via WhatsApp (146 pts)]]></title>
            <link>https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/</link>
            <guid>42476828</guid>
            <pubDate>Sat, 21 Dec 2024 01:38:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/">https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/</a>, See on <a href="https://news.ycombinator.com/item?id=42476828">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Compiling C to Safe Rust, Formalized (164 pts)]]></title>
            <link>https://arxiv.org/abs/2412.15042</link>
            <guid>42476192</guid>
            <pubDate>Fri, 20 Dec 2024 23:30:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2412.15042">https://arxiv.org/abs/2412.15042</a>, See on <a href="https://news.ycombinator.com/item?id=42476192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2412.15042">View PDF</a></p><blockquote>
            <span>Abstract:</span>The popularity of the Rust language continues to explode; yet, many critical codebases remain authored in C, and cannot be realistically rewritten by hand. Automatically translating C to Rust is thus an appealing course of action. Several works have gone down this path, handling an ever-increasing subset of C through a variety of Rust features, such as unsafe. While the prospect of automation is appealing, producing code that relies on unsafe negates the memory safety guarantees offered by Rust, and therefore the main advantages of porting existing codebases to memory-safe languages.
<br>We instead explore a different path, and explore what it would take to translate C to safe Rust; that is, to produce code that is trivially memory safe, because it abides by Rust's type system without caveats. Our work sports several original contributions: a type-directed translation from (a subset of) C to safe Rust; a novel static analysis based on "split trees" that allows expressing C's pointer arithmetic using Rust's slices and splitting operations; an analysis that infers exactly which borrows need to be mutable; and a compilation strategy for C's struct types that is compatible with Rust's distinction between non-owned and owned allocations.
<br>We apply our methodology to existing formally verified C codebases: the HACL* cryptographic library, and binary parsers and serializers from EverParse, and show that the subset of C we support is sufficient to translate both applications to safe Rust. Our evaluation shows that for the few places that do violate Rust's aliasing discipline, automated, surgical rewrites suffice; and that the few strategic copies we insert have a negligible performance impact. Of particular note, the application of our approach to HACL* results in a 80,000 line verified cryptographic library, written in pure Rust, that implements all modern algorithms - the first of its kind.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Aymeric Fromherz [<a href="https://arxiv.org/show-email/8fe3c653/2412.15042" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 19 Dec 2024 16:51:29 UTC (92 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Raycaster in Bash (134 pts)]]></title>
            <link>https://github.com/izabera/pseudo3d</link>
            <guid>42475703</guid>
            <pubDate>Fri, 20 Dec 2024 22:25:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/izabera/pseudo3d">https://github.com/izabera/pseudo3d</a>, See on <a href="https://news.ycombinator.com/item?id=42475703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">a raycaster in bash</h2><a id="user-content-a-raycaster-in-bash" aria-label="Permalink: a raycaster in bash" href="#a-raycaster-in-bash"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description wolfenstein-in-bash.mp4">wolfenstein-in-bash.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1572859/397868206-addb77f3-f309-48ab-8609-a8ea3082c952.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ3NTU3MDMsIm5iZiI6MTczNDc1NTQwMywicGF0aCI6Ii8xNTcyODU5LzM5Nzg2ODIwNi1hZGRiNzdmMy1mMzA5LTQ4YWItODYwOS1hOGVhMzA4MmM5NTIubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIyMSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMjFUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9Nzg0YTY2YmM0MzhhNzliZmUxYTU3ODAzMzRiODQzMTJhZDkyMGVkYzI4YWM3NWJiOGEzMWFlZjY2Zjc5ZjIzMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.6c7Jq5sz0dH0ZkjiCzBpIi5gj9WWwB73p7Ac9DdJS0I" data-canonical-src="https://private-user-images.githubusercontent.com/1572859/397868206-addb77f3-f309-48ab-8609-a8ea3082c952.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ3NTU3MDMsIm5iZiI6MTczNDc1NTQwMywicGF0aCI6Ii8xNTcyODU5LzM5Nzg2ODIwNi1hZGRiNzdmMy1mMzA5LTQ4YWItODYwOS1hOGVhMzA4MmM5NTIubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIyMSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMjFUMDQzMDAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9Nzg0YTY2YmM0MzhhNzliZmUxYTU3ODAzMzRiODQzMTJhZDkyMGVkYzI4YWM3NWJiOGEzMWFlZjY2Zjc5ZjIzMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.6c7Jq5sz0dH0ZkjiCzBpIi5gj9WWwB73p7Ac9DdJS0I" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">more screenshots/vidoes at <a href="https://imgur.com/a/izas-wolfenstein-bash-journey-bAy5zhp" rel="nofollow">https://imgur.com/a/izas-wolfenstein-bash-journey-bAy5zhp</a></p>
<p dir="auto">largely a port of <a href="https://lodev.org/cgtutor/raycasting.html" rel="nofollow">https://lodev.org/cgtutor/raycasting.html</a></p>
<p dir="auto">use the arrow keys to rotate and move around, and q to quit</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">why this was a bit hard:</h3><a id="user-content-why-this-was-a-bit-hard" aria-label="Permalink: why this was a bit hard:" href="#why-this-was-a-bit-hard"></a></p>
<ul dir="auto">
<li>
<p dir="auto">bash is slow.  this is by far the biggest issue.  it's so slow that you
cannot possibly achieve an acceptable frame rate if you have to execute even
a single command per pixel.  this implies that you also cannot keep the state
of the screen in memory, neither as an array of colours (did you know that
accessing a random element in an array takes linear time?) nor as a single
long string (did you know that accessing the nth character in a string takes
linear time even in LANG=C?), because literally just reading this
representation to dump it to the screen will take longer than a frame</p>
</li>
<li>
<p dir="auto">bash has no floating point support nor access to a library of maths
functions. all the maths is done on integers, scaled up by 100000</p>
</li>
<li>
<p dir="auto">terminals are ugly if you use a full character to represent each pixel, so
this uses unicode half blocks with different foreground and background
colours, which effectively doubles the vertical resolution.  there is
unfortunately no way to update only one of the two colours in a cell, nor any
way to query the current colours of a cell (besides, it would be too slow for
bash), so every time we write a pixel we need to know the colour of an
adjacent pixel.  it would be really convenient if bash could store the state
somehow but alas it cannot</p>
</li>
<li>
<p dir="auto">various misc annoyances:</p>
<ul dir="auto">
<li>
<p dir="auto">making sure all the terminal is updated at once is not trivial with a
slow language like bash</p>
</li>
<li>
<p dir="auto">most terminals are not designed to play video games in (shockingly), so
you cannot test if a key is currently pressed.  instead you can only get
a single key that's being held down, usually really slowly debounced and
with a low limit for continued presses, so you probably get like 5-6
characters a second.  you cannot even get multiple keys pressed at the
same time unless some are modifiers.  the kitty keyboard protocol 100%
fixes all this, and i'm sure it will become a widely implemented standard
by the year 2100</p>
</li>
<li>
<p dir="auto">turns out that filling a terminal with colours takes a lot of data.  at
my normal font size this does ~10mb of i/o per second, which isn't very
much in the grand scheme of things, but, you know, it's bash</p>
</li>
<li>
<p dir="auto">bash will never use a single syscall to print a string with more than one
newline, regardless of the type of file you're writing to.  this is
pointless and dumb, and it's the reason why this never prints \n and
always moves the cursor in other ways.  ultimately this ended up printing
more data than the size your terminal is likely getting in each read, so
it might not matter too much, but it still bothered me</p>
</li>
<li>
<p dir="auto">ecma48/vt100/vt200/xterm... were all designed by insane people who hated
me specifically</p>
</li>
<li>
<p dir="auto">holy shit i'm bad at maths, i went to uni for this what the fuck</p>
</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">faq:</h3><a id="user-content-faq" aria-label="Permalink: faq:" href="#faq"></a></p>
<ul dir="auto">
<li>
<p dir="auto">q: it fucks things up when i resize the window/it's a flickery mess/it
generally looks like shite on my terminal</p>
</li>
<li>
<p dir="auto">a: open an issue please</p>
</li>
<li>
<p dir="auto">q: my cpu heats up like crazy/my computer from 2005 slows down to a crawl</p>
</li>
<li>
<p dir="auto">a: try to set the env variable FPS to something less than 30</p>
</li>
<li>
<p dir="auto">q: it doesn't work on my bash &lt; 5</p>
</li>
<li>
<p dir="auto">a: yep</p>
</li>
<li>
<p dir="auto">q: is this code all pure bash?</p>
</li>
<li>
<p dir="auto">a: no.  it also calls stty once at startup to disable echo, and once at exit
to re enable it</p>
</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qualcomm wins licensing fight with Arm over chip designs (177 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-20/qualcomm-wins-licensing-fight-with-arm-over-chip-designs</link>
            <guid>42475228</guid>
            <pubDate>Fri, 20 Dec 2024 21:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-20/qualcomm-wins-licensing-fight-with-arm-over-chip-designs">https://www.bloomberg.com/news/articles/2024-12-20/qualcomm-wins-licensing-fight-with-arm-over-chip-designs</a>, See on <a href="https://news.ycombinator.com/item?id=42475228">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI O3 breakthrough high score on ARC-AGI-PUB (1188 pts)]]></title>
            <link>https://arcprize.org/blog/oai-o3-pub-breakthrough</link>
            <guid>42473321</guid>
            <pubDate>Fri, 20 Dec 2024 18:11:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arcprize.org/blog/oai-o3-pub-breakthrough">https://arcprize.org/blog/oai-o3-pub-breakthrough</a>, See on <a href="https://news.ycombinator.com/item?id=42473321">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            <h2>ARC Prize remains undefeated.<br>New ideas still needed<span>.</span></h2>
        </p><div>


<p>OpenAI's new o3 system - trained on the ARC-AGI-1 Public Training set - has scored a breakthrough <strong>75.7%</strong> on the Semi-Private Evaluation set at our stated public leaderboard $10k compute limit. A high-compute (172x) o3 configuration scored <strong>87.5%</strong>.</p>

<p><img src="https://arcprize.org/media/images/blog/o-series-performance.jpg" alt="o Series Performance"></p>

<p>This is a surprising and important step-function increase in AI capabilities, showing novel task adaptation ability never seen before in the GPT-family models. For context, ARC-AGI-1 took 4 years to go from 0% with GPT-3 in 2020 to 5% in 2024 with GPT-4o. All intuition about AI capabilities will need to get updated for o3.</p>

<p>The mission of ARC Prize goes beyond our first benchmark: to be a North Star towards AGI. And we're excited to be working with the OpenAI team and others next year to continue to design next-gen, enduring AGI benchmarks.</p>

<p>ARC-AGI-2 (same format - verified easy for humans, harder for AI) will launch alongside ARC Prize 2025. We're committed to running the Grand Prize competition until a high-efficiency, open-source solution scoring 85% is created.</p>

<p>Read on for the full testing report.</p>

<hr>

<h2 id="openai-o3-arc-agi-results">OpenAI o3 ARC-AGI Results</h2>

<p>We tested o3 against two ARC-AGI datasets:</p>

<ul>
  <li><strong>Semi-Private Eval</strong>: 100 private tasks used to assess overfitting</li>
  <li><strong>Public Eval</strong>: 400 public tasks</li>
</ul>

<p>At OpenAI's direction, we tested at two levels of compute with variable sample sizes: 6 (high-efficiency) and 1024 (low-efficiency, 172x compute).</p>

<p>Here are the results.</p>

<div>
    <table>
    <thead>
        <tr>
        <th>Set</th>
        <th>Tasks</th>
        <th>Efficiency</th>
        <th>Score</th>
        <th>Retail Cost</th>
        <th>Samples</th>
        <th>Tokens</th>
        <th>Cost/Task</th>
        <th>Time/Task (mins)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
        <td>Semi-Private</td>
        <td>100</td>
        <td>High</td>
        <td>75.7%</td>
        <td>$2,012</td>
        <td>6</td>
        <td>33M</td>
        <td>$20</td>
        <td>1.3</td>
        </tr>
        <tr>
        <td>Semi-Private</td>
        <td>100</td>
        <td>Low</td>
        <td>87.5%</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        </tr>
        <tr>
        <td>Public</td>
        <td>400</td>
        <td>High</td>
        <td>82.8%</td>
        <td>$6,677</td>
        <td>6</td>
        <td>111M</td>
        <td>$17</td>
        <td>N/A</td>
        </tr>
        <tr>
        <td>Public</td>
        <td>400</td>
        <td>Low</td>
        <td>91.5%</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>--</td>
        </tr>
    </tbody>
    </table>
</div>

<ul>
  <li>Note: OpenAI has requested that we not publish the high-compute costs. The amount of compute was roughly 172x the low-compute configuration.</li>
</ul>

<p>Due to variable inference budget, efficiency (e.g., compute cost) is now a required metric when reporting performance. We've documented both the total costs and the cost per task as an initial proxy for efficiency. As an industry, we'll need to figure out <a href="https://x.com/mikeknoop/status/1868760635716386864" target="_blank">what metric best tracks efficiency</a>, but directionally, cost is a solid starting point.</p>

<p>The high-efficiency score of 75.7% is within the budget rules of ARC-AGI-Pub (costs &lt;$10k) and therefore qualifies as 1st place on the public leaderboard!</p>

<p>The low-efficiency score of 87.5% is quite expensive, but still shows that performance on novel tasks does improve with increased compute (at least up to this level.)</p>

<p>Despite the significant cost per task, these numbers aren't just the result of applying brute force compute to the benchmark. OpenAI's new o3 model represents a significant leap forward in AI's ability to adapt to novel tasks. This is not merely incremental improvement, but a genuine breakthrough, marking a qualitative shift in AI capabilities compared to the prior limitations of LLMs. o3 is a system capable of adapting to tasks it has never encountered before, arguably approaching human-level performance in the ARC-AGI domain.</p>

<p>Of course, such generality comes at a steep cost, and wouldn't quite be economical yet: you could pay a human to solve ARC-AGI tasks for roughly $5 per task (we know, we did that), while consuming mere cents in energy. Meanwhile o3 requires $17-20 per task in the low-compute mode. But cost-performance will likely improve quite dramatically over the next few months and years, so you should plan for these capabilities to become competitive with human work within a fairly short timeline.</p>

<p>o3's improvement over the GPT series proves that architecture is everything. You couldn't throw more compute at GPT-4 and get these results. Simply scaling up the things we were doing from 2019 to 2023 – take the same architecture, train a bigger version on more data – is not enough. Further progress is about new ideas.</p>

<hr>

<h3 id="so-is-it-agi">So is it AGI?</h3>

<p>ARC-AGI serves as a critical benchmark for detecting such breakthroughs, highlighting generalization power in a way that saturated or less demanding benchmarks cannot. However, it is important to note that ARC-AGI is not an acid test for AGI – as we've repeated dozens of times this year. It's a research tool designed to focus attention on the most challenging unsolved problems in AI, a role it has fulfilled well over the past five years.</p>

<p>Passing ARC-AGI does not equate to achieving AGI, and, as a matter of fact, I don't think o3 is AGI yet. o3 still fails on some very easy tasks, indicating fundamental differences with human intelligence.</p>

<p>Furthermore, early data points suggest that the upcoming ARC-AGI-2 benchmark will still pose a significant challenge to o3, potentially reducing its score to under 30% even at high compute (while a smart human would still be able to score over 95% with no training). This demonstrates the continued possibility of creating challenging, unsaturated benchmarks without having to rely on expert domain knowledge. You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.</p>

<h3 id="whats-different-about-o3-compared-to-older-models">What's different about o3 compared to older models?</h3>

<p>Why does o3 score so much higher than o1? And why did o1 score so much higher than GPT-4o in the first place? I think this series of results provides invaluable data points for the ongoing pursuit of AGI.</p>

<p>My mental model for LLMs is that they work as <a href="https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering" target="_blank">a repository of vector programs</a>. When prompted, they will fetch the program that your prompt maps to and "execute" it on the input at hand. LLMs are a way to store and operationalize millions of useful mini-programs via passive exposure to human-generated content.</p>

<p>This "memorize, fetch, apply" paradigm can achieve arbitrary levels of skills at arbitrary tasks given appropriate training data, but it cannot adapt to novelty or pick up new skills on the fly (which is to say that there is no fluid intelligence at play here.) This has been exemplified by the low performance of LLMs on ARC-AGI, the only benchmark specifically designed to measure adaptability to novelty – GPT-3 scored 0, GPT-4 scored near 0, GPT-4o got to 5%. Scaling up these models to the limits of what's possible wasn't getting ARC-AGI numbers anywhere near what basic brute enumeration could achieve years ago (up to 50%).</p>

<p>To adapt to novelty, you need two things. First, you need knowledge – a set of reusable functions or programs to draw upon. LLMs have more than enough of that. Second, you need the ability to recombine these functions into a brand new program when facing a new task – a program that models the task at hand. Program synthesis. LLMs have long lacked this feature. The o series of models fixes that.</p>

<p>For now, we can only speculate about the exact specifics of how o3 works. But o3's core mechanism appears to be natural language program search and execution within token space – at test time, the model searches over the space of possible Chains of Thought (CoTs) describing the steps required to solve the task, in a fashion perhaps not too dissimilar to AlphaZero-style Monte-Carlo tree search. In the case of o3, the search is presumably guided by some kind of evaluator model. To note, Demis Hassabis hinted back in <a href="https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/" target="_blank">a June 2023 interview</a> that DeepMind had been researching this very idea – this line of work has been a long time coming.</p>

<p>So while single-generation LLMs struggle with novelty, o3 overcomes this by generating and executing its own programs, where the program itself (the CoT) becomes the artifact of knowledge recombination. Although this is not the only viable approach to test-time knowledge recombination (you could also do test-time training, or search in latent space), it represents the current state-of-the-art as per these new ARC-AGI numbers.</p>

<p>Effectively, o3 represents a form of <em>deep learning-guided program search</em>. The model does test-time search over a space of "programs" (in this case, natural language programs – the space of CoTs that describe the steps to solve the task at hand), guided by a deep learning prior (the base LLM). The reason why solving a single ARC-AGI task can end up taking up tens of millions of tokens and cost thousands of dollars is because this search process has to explore an enormous number of paths through program space – including backtracking.</p>

<p>There are however two significant differences between what's happening here and what I meant when I previously described "deep learning-guided program search" as the best path to get to AGI. Crucially, the programs generated by o3 are <em>natural language instructions</em> (to be "executed" by a LLM) rather than <em>executable symbolic programs</em>. This means two things. First, that they cannot make contact with reality via execution and direct evaluation on the task – instead, they must be evaluated for fitness via another model, and the evaluation, lacking such grounding, might go wrong when operating out of distribution. Second, the system cannot autonomously acquire the ability to generate and evaluate these programs (the way a system like AlphaZero can learn to play a board game on its own.) Instead, it is reliant on expert-labeled, human-generated CoT data.</p>

<p>It's not yet clear what the exact limitations of the new system are and how far it might scale. We'll need further testing to find out. Regardless, the current performance represents a remarkable achievement, and a clear confirmation that intuition-guided test-time search over program space is a powerful paradigm to build AI systems that can adapt to arbitrary tasks.</p>

<h3 id="what-comes-next">What comes next?</h3>

<p>First of all, open-source replication of o3, facilitated by the ARC Prize competition in 2025, will be crucial to move the research community forward. A thorough analysis of o3's strengths and limitations is necessary to understand its scaling behavior, the nature of its potential bottlenecks, and anticipate what abilities further developments might unlock.</p>

<p>Moreover, ARC-AGI-1 is now saturating – besides o3's new score, the fact is that a large ensemble of low-compute Kaggle solutions can now score 81% on the private eval.</p>

<p>We're going to be raising the bar with a new version – ARC-AGI-2 - which has been in the works since 2022. It promises a major reset of the state-of-the-art. We want it to push the boundaries of AGI research with hard, high-signal evals that highlight current AI limitations.</p>

<p>Our early ARC-AGI-2 testing suggests it will be useful and extremely challenging, even for o3. And, of course, ARC Prize's objective is to produce a <em>high-efficiency</em> and <em>open-source</em> solution in order to win the Grand Prize. We currently intend to launch ARC-AGI-2 alongside ARC Prize 2025 (estimated launch: late Q1).</p>

<p>Going forward, the ARC Prize Foundation will continue to create new benchmarks to focus the attention of researchers on the hardest unsolved problems on the way to AGI. We've started work on a third-generation benchmark which departs completely from the 2019 ARC-AGI format and incorporates some exciting new ideas.</p>

<hr>

<h2 id="get-involved-open-source-analysis">Get Involved: Open-Source Analysis</h2>

<p>Today, we're also releasing high-compute, o3-labeled tasks and would like your help to analyze them. In particular, we are very curious about the ~9% set of Public Eval tasks o3 was unable to solve, even with lots of compute, yet are straightforward for humans.</p>

<p>We invite the community to help us assess the characteristics of both solved and unsolved tasks.</p>

<p>To get your ideas flowing, here are 3 examples of tasks unsolved by high-compute o3.</p>

<figure>
  <img src="https://arcprize.org/media/images/blog/arc-agi-task-c6e1b8da.png" alt="ARC-AGI Task Id: c6e1b8da">
  <figcaption>ARC-AGI Task ID: c6e1b8da</figcaption>
</figure>

<figure>
  <img src="https://arcprize.org/media/images/blog/arc-agi-task-0d87d2a6.png" alt="ARC-AGI Task Id: 0d87d2a6">
  <figcaption>ARC-AGI Task ID: 0d87d2a6</figcaption>
</figure>

<figure>
  <img src="https://arcprize.org/media/images/blog/arc-agi-task-b457fec5.png" alt="ARC-AGI Task Id: b457fec5">
  <figcaption>ARC-AGI Task ID: b457fec5</figcaption>
</figure>

<p><a href="https://github.com/arcprizeorg/model_baseline/tree/main/results" target="_blank">See our full set of o3 testing data.</a></p>

<p>We've also created a new channel in our Discord named <code>oai-analysis</code> and we'd love to hear your analysis and insights there. Or tag us on X/Twitter <a href="https://x.com/arcprize" target="_blank">@arcprize</a>.</p>

<hr>

<h2 id="conclusions">Conclusions</h2>

<p>To sum up – o3 represents a significant leap forward. Its performance on ARC-AGI highlights a genuine breakthrough in adaptability and generalization, in a way that no other benchmark could have made as explicit.</p>

<p>o3 fixes the fundamental limitation of the LLM paradigm – the inability to recombine knowledge at test time – and it does so via a form of LLM-guided natural language program search. This is not just incremental progress; it is new territory, and it demands serious scientific attention.</p>

<p><span></span> <a href="#" data-modal-id="newsletter">Sign up to get updates</a></p>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grayjay Desktop App (366 pts)]]></title>
            <link>https://grayjay.app/desktop/</link>
            <guid>42473032</guid>
            <pubDate>Fri, 20 Dec 2024 17:33:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grayjay.app/desktop/">https://grayjay.app/desktop/</a>, See on <a href="https://news.ycombinator.com/item?id=42473032">Hacker News</a></p>
Couldn't get https://grayjay.app/desktop/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why are UK electricity bills so expensive? (172 pts)]]></title>
            <link>https://climate.benjames.io/uk-electricity-bills/</link>
            <guid>42472247</guid>
            <pubDate>Fri, 20 Dec 2024 16:05:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://climate.benjames.io/uk-electricity-bills/">https://climate.benjames.io/uk-electricity-bills/</a>, See on <a href="https://news.ycombinator.com/item?id=42472247">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>I recently built a website that breaks down the cost of a UK electricity bill.</p><figure><a href="https://electricitybills.uk/?ref=climate.benjames.io"><img src="https://climate.benjames.io/content/images/2024/12/image.png" alt="" loading="lazy" width="2000" height="1121" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/image.png 600w, https://climate.benjames.io/content/images/size/w1000/2024/12/image.png 1000w, https://climate.benjames.io/content/images/size/w1600/2024/12/image.png 1600w, https://climate.benjames.io/content/images/2024/12/image.png 2124w" sizes="(min-width: 720px) 720px"></a><figcaption><a href="http://electricitybills.uk/?ref=climate.benjames.io">electricitybills.uk</a></figcaption></figure><p>It's interactive, and I'd recommend visiting it before reading this post. Check it out here: <a href="http://electricitybills.uk/?ref=climate.benjames.io">electricitybills.uk</a></p><p>Here are three interesting things about the data.</p><h3 id="1-the-wholesale-power-cost-is-only-one-third-of-an-electricity-bill">#1: The wholesale power cost is only one third of an electricity bill.</h3><p>The wholesale price is the actual cost of buying electricity on the open market. But the average bill is <strong>triple</strong> that amount.</p><figure><img src="https://climate.benjames.io/content/images/2024/12/bill_breakdown_full_manual--1-.png" alt="" loading="lazy" width="1204" height="1107" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/bill_breakdown_full_manual--1-.png 600w, https://climate.benjames.io/content/images/size/w1000/2024/12/bill_breakdown_full_manual--1-.png 1000w, https://climate.benjames.io/content/images/2024/12/bill_breakdown_full_manual--1-.png 1204w" sizes="(min-width: 720px) 720px"></figure><p>The remaining 2/3 of the bill is made up of three parts:</p><ul><li><strong>Network costs:</strong> paying for the wires and substations of the power grid</li><li><strong>Generation costs:</strong> subsidising strategically important generation, like offshore wind, household solar, and firm gas.</li><li><strong>Miscellaneous: </strong>running a utility company customer service department, various taxes, etc.</li></ul><h3 id="2-these-charges-are-about-to-rise-a-lot">#2: These charges are about to rise, a lot.</h3><p><strong>Network costs </strong>are about to skyrocket. Investment in the UK power grid has been stagnant for 20 years, because UK power demand has been flat for 20 years. But now, the UK urgently needs to expand the grid. Energy that used to flow through pipelines will need to flow through wires.</p><p><strong>Contracts for Difference </strong>are the UK's flagship scheme for supporting renewables, and they will add an increasing cost to electricity bills. More than half of the contracts already allocated have yet to be activated, and the next contract allocation round is expected to be the biggest yet.</p><p><em>Note: CfDs do insulate consumers from high wholesale prices (during the energy crisis, CfDs reduced consumer bills), but on average they add cost.</em></p><figure><img src="https://climate.benjames.io/content/images/2024/12/cfd_svg--2-.png" alt="" loading="lazy" width="1087" height="514" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/cfd_svg--2-.png 600w, https://climate.benjames.io/content/images/size/w1000/2024/12/cfd_svg--2-.png 1000w, https://climate.benjames.io/content/images/2024/12/cfd_svg--2-.png 1087w" sizes="(min-width: 720px) 720px"></figure><p>The <strong>Capacity Market</strong> pays firm generation &amp; demand response to be on standby, to prevent blackouts. Contracts are mostly allocated four years in advance, and the cost will ~<em>triple</em><strong> </strong>to 2028.</p><figure><img src="https://climate.benjames.io/content/images/2024/12/CM-clearing-prices--1-.png" alt="" loading="lazy" width="942" height="427" srcset="https://climate.benjames.io/content/images/size/w600/2024/12/CM-clearing-prices--1-.png 600w, https://climate.benjames.io/content/images/2024/12/CM-clearing-prices--1-.png 942w" sizes="(min-width: 720px) 720px"></figure><h3 id="3-existing-costs-are-locked-in-for-a-long-time">#3: Existing costs are locked in for a long time.</h3><p>The UK ran two pretty expensive green subsidies in the 2010s.</p><p>The <strong>Renewables Obligation</strong> mandates utilities to buy credits from wind and solar farms. It closed to new projects in 2017, but payments to existing projects will continue until 2037. It makes up around 10% of an average bill.</p><div><p>The Renewables Obligation is, in my opinion, wild. Renewable generators who got accredited before 2017 essentially get paid an ever-rising inflation-linked price until 2037, regardless of the market price of electricity.&nbsp;</p></div><p>The <strong>Feed in Tariff</strong> pays households with solar panels a very tasty rate for exported energy. It closed to new applications in 2019, but payments will continue up to 2044 for some projects.</p><p>Being an early adopter of renewables has been expensive for the UK. You might argue that we should have waited an extra decade, since renewables would now be <a href="https://climate.benjames.io/solar-off-grid">much cheaper</a>. But the reality of learning curves means that renewables only got cheap because people built them. If everyone waits for someone else to decarbonise first, we won't get very far.</p><p>But we can learn from policy mistakes in the past. Schemes like the Feed in Tariff did not correct quickly enough when solar prices fell, leading to spiralling policy costs that were completely decoupled from market dynamics.</p><h2 id="the-future-of-cheap-clean-power">The future of cheap, clean power.</h2><p>Let's say that we want electricity to be radically cheap in future - say £50 / MWh.</p><p>Well, network costs are already ~£70 / MWh and will increase steadily. We've missed our target, before we've even paid to generate electricity. There are only two solutions here:</p><ul><li>Ditch the power grid. Use local solar generation, and a lot of batteries. This works well in most of the world, but less so in northern Europe (it's not very sunny).</li><li>Utilise the existing power grid better. Instead of expanding the grid just to service peak demand, improve our grid utilisation by "filling in the rectangle" throughout the day. (This is part of what we're working on at <a href="https://axle.energy/?ref=climate.benjames.io">Axle</a>)</li></ul><p>The UK has achieved the fastest rate of grid decarbonisation among advanced economies. A lot of this progress occurred when renewables were still expensive, so we are stuck with a cost hangover. Luckily, renewables are getting <em>much</em> cheaper, so the tradeoffs in future policy are very different.</p><hr><p>Thanks for reading, I'd love to hear your thoughts on the site. <a href="https://climate.benjames.io/uk-electricity-bills/electricitybills.uk">electricitybills.uk</a></p><p>Warmly,</p><p>Ben</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A bestiary of exotic hadrons (133 pts)]]></title>
            <link>https://cerncourier.com/a-bestiary-of-exotic-hadrons/</link>
            <guid>42471927</guid>
            <pubDate>Fri, 20 Dec 2024 15:29:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cerncourier.com/a-bestiary-of-exotic-hadrons/">https://cerncourier.com/a-bestiary-of-exotic-hadrons/</a>, See on <a href="https://news.ycombinator.com/item?id=42471927">Hacker News</a></p>
Couldn't get https://cerncourier.com/a-bestiary-of-exotic-hadrons/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Artemis, a Calm Web Reader (240 pts)]]></title>
            <link>https://artemis.jamesg.blog/</link>
            <guid>42471913</guid>
            <pubDate>Fri, 20 Dec 2024 15:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://artemis.jamesg.blog/">https://artemis.jamesg.blog/</a>, See on <a href="https://news.ycombinator.com/item?id=42471913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            
            

            
            
<article>
    <h2>Artemis</h2>
    <p>Artemis is a calm web reader.</p>
    <p>You can use Artemis to follow your favorite websites.</p>
    <p>Artemis updates once per day, at approximately 12am in your timezone.</p>
    <p><a href="https://artemis.jamesg.blog/features" target="_blank">See a list of features.</a></p>
    <figure>
        <img src="https://artemis.jamesg.blog/assets/demo.png" alt="The Artemis dashboard, showing the titles and domains from for two posts from feeds." height="243" width="543">
        <figcaption>The Artemis dashboard.</figcaption>
    </figure>
    <h2>Design</h2>
    <p>Artemis is designed to be slow and minimal. It's a calm place to see what's new on your favorite websites, with no urgency.</p>
    <p><a href="https://jamesg.blog/2024/11/30/designing-a-calm-web-reader/">Read more about the project design philosophy.</a></p>
    <h3>Data Storage</h3>
    <p><a href="https://artemis.jamesg.blog/data">Read how we store your data.</a></p>
    <h3>Accessibility</h3>
    <p>I have tried my best to make this service accessible. If you notice any issues, please feel free to contact me.</p>
    <p><a href="https://artemis.jamesg.blog/accessibility">Read our accessibility statement.</a></p>
    <h2>Pricing</h2>
    <p>Artemis is free to use, although <a href="https://github.com/sponsors/capjamesg/">donations are appreciated</a>!</p>
    <h2>About</h2>
    <p>Artemis is made by <a href="https://jamesg.blog/">capjamesg</a>.</p>
    <p>Need tech support? Contact <a href="mailto:readers@jamesg.blog">jamesg@jamesg.blog</a></p>
</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building Effective "Agents" (305 pts)]]></title>
            <link>https://www.anthropic.com/research/building-effective-agents</link>
            <guid>42470541</guid>
            <pubDate>Fri, 20 Dec 2024 12:29:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/research/building-effective-agents">https://www.anthropic.com/research/building-effective-agents</a>, See on <a href="https://news.ycombinator.com/item?id=42470541">Hacker News</a></p>
Couldn't get https://www.anthropic.com/research/building-effective-agents: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[We're about to fly a spacecraft into the Sun for the first time (128 pts)]]></title>
            <link>https://arstechnica.com/space/2024/12/were-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time/</link>
            <guid>42470202</guid>
            <pubDate>Fri, 20 Dec 2024 11:23:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/space/2024/12/were-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time/">https://arstechnica.com/space/2024/12/were-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time/</a>, See on <a href="https://news.ycombinator.com/item?id=42470202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                          <div>
  <p><em>Twas the night before Christmas, when all through the Solar cycle,</em></p>
<p><em>Not a sunspot was stirring, not even a burst;</em></p>
<p><em>The stockings were all hung by the corona with care,</em></p>
<p><em>In hopes that the Parker Solar Probe would soon be there.&nbsp;</em></p>

</div>
                      
          
<p>Almost no one ever writes about the Parker Solar Probe anymore.</p>
<p>Sure, the spacecraft got some attention when it launched.&nbsp; It is, after all, the fastest moving object that humans have ever built. At its maximum speed, goosed by the gravitational pull of the Sun, the probe reaches a velocity of 430,000 miles per hour, or more than one-sixth of 1 percent the speed of light. That kind of speed would get you from New York City to Tokyo in less than a minute.</p>
<p>And the Parker Solar Probe also has the distinction of being the first NASA spacecraft named after a living person. At the time of its launch, in August 2018, physicist Eugene Parker was 91 years old.</p>
<p>But in the six years since the probe has been zipping through outer space and flying by the Sun? Not so much. Let's face it, the astrophysical properties of the Sun and its complicated structure are not something that most people think about on a daily basis.</p>
<p>However, the smallish probe—it masses less than a metric ton, and its scientific payload is only about 110 pounds (50 kg)—is about to make its star turn. Quite literally. On Christmas Eve, the Parker Solar Probe will make its closest approach yet to the Sun. It will come within just 3.8 million miles (6.1 million km) of the solar surface, flying into the solar atmosphere for the first time.</p>
<p>Yeah, it's going to get pretty hot. Scientists estimate that the probe's heat shield will endure temperatures in excess of 2,500° Fahrenheit (1,371° C) on Christmas Eve, which is pretty much the polar opposite of the North Pole.</p>
<h2>Going straight to the source</h2>
<p>I spoke with the chief of science at NASA, Nicky Fox, to understand why the probe is being tortured so. Before moving to NASA headquarters, Fox was the project scientist for the Parker Solar Probe, and she explained that scientists really want to understand the origins of the solar wind.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matt Mullenweg temporarily shuts down some Wordpress.org functions (126 pts)]]></title>
            <link>https://wordpress.org/news/2024/12/holiday-break/</link>
            <guid>42469708</guid>
            <pubDate>Fri, 20 Dec 2024 10:07:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.org/news/2024/12/holiday-break/">https://wordpress.org/news/2024/12/holiday-break/</a>, See on <a href="https://news.ycombinator.com/item?id=42469708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>In order to give myself and the many tired volunteers around WordPress.org a break for the holidays, we’re going to be pausing a few of the free services currently offered:</p>



<ul>
<li>New account registrations on WordPress.org (clarifying so press doesn’t confuse this: people can still make their own WordPress installs and accounts)</li>



<li>New <a href="https://wordpress.org/plugins/">plugin directory</a> submissions</li>



<li>New plugin reviews</li>



<li>New <a href="https://wordpress.org/themes/">theme directory</a> submissions</li>



<li>New <a href="https://wordpress.org/photos/">photo directory</a> submissions</li>
</ul>



<p>We’re going to leave things like localization and the forums open because these don’t require much moderation.</p>



<p>As you may have heard, <a href="https://www.theverge.com/2024/12/10/24318350/automattic-restore-wp-engine-access-wordpress">I’m legally compelled to provide free labor and services to WP Engine thanks to the success of their expensive lawyers</a>, so in order to avoid bothering the court I will say that none of the above applies to WP Engine, so if they need to bypass any of the above please just have your high-priced attorneys talk to my high-priced attorneys and we’ll arrange access, or just reach out directly to me on Slack and I’ll fix things for you.</p>



<p>I hope to find the time, energy, and money to reopen all of this sometime in the new year. Right now much of the time I would spend making WordPress better is being taken up defending against WP Engine’s legal attacks. Their attacks are against Automattic, but also me individually as the owner of WordPress.org, which means if they win I can be personally liable for millions of dollars of damages.</p>



<p>If you would like to fund legal attacks against me, I would encourage you to sign up for WP Engine services, <a href="https://wpengine.com/plans/">they have great plans and pricing starting at $50/mo and scaling all the way up to $2,000/mo</a>. If not, you can use <a href="https://wordpress.org/news/2024/10/wp-engine-promotions/">literally any other web host in the world that isn’t suing me and is offering promotions and discounts for switching away from WP Engine</a>.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>