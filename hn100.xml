<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 21 Oct 2025 02:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Today is when the Amazon brain drain sent AWS down the spout (360 pts)]]></title>
            <link>https://www.theregister.com/2025/10/20/aws_outage_amazon_brain_drain_corey_quinn/</link>
            <guid>45649178</guid>
            <pubDate>Mon, 20 Oct 2025 20:50:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/20/aws_outage_amazon_brain_drain_corey_quinn/">https://www.theregister.com/2025/10/20/aws_outage_amazon_brain_drain_corey_quinn/</a>, See on <a href="https://news.ycombinator.com/item?id=45649178">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>column</span> "It's always DNS" is a long-standing sysadmin saw, and with good reason: a disproportionate number of outages are at their heart DNS issues. And so today, as AWS is still repairing its downed cloud as this article goes to press, it becomes clear that the culprit is once again DNS. But if you or I know this, AWS certainly does.</p>
<p>And so, a quiet suspicion starts to circulate: where have the senior AWS engineers who've been to this dance before gone? And the answer increasingly is that they've left the building — taking decades of hard-won institutional knowledge about how AWS's systems work at scale right along with them.</p>
<h3>What happened?</h3>
<p>AWS reports that on October 20, at 12:11 AM PDT, it began investigating “increased error rates and latencies for multiple AWS services in the US-EAST-1 Region.” About an hour later, at 1:26 AM, the company confirmed “significant error rates for requests made to the DynamoDB endpoint” in that region. By 2:01 AM, engineers had identified <a target="_blank" href="https://www.theregister.com/2025/10/20/aws_outage_chaos/">DNS resolution of the DynamoDB API endpoint</a> for US-EAST-1 as the likely root cause, which led to cascading failures for most other things in that region. DynamoDB is a "foundational service" upon which a whole mess of other AWS services rely, so the blast radius for an outage touching this thing can be huge.</p>
<p>As a result, <a target="_blank" href="https://www.theregister.com/2025/10/20/amazon_aws_outage/">much of the internet stopped working</a>: banking, gaming, social media, government services, buying things I don't need on Amazon.com itself, etc.</p>
<p>AWS has given increasing levels of detail, as is their tradition, when outages strike, and as new information comes to light. Reading through it, one really gets the sense that it took them 75 minutes to go from "things are breaking" to "we've narrowed it down to a single service endpoint, but are still researching," which is something of a bitter pill to swallow. To be clear: I've seen zero signs that this stems from a lack of transparency, and every indication that they legitimately did not know what was breaking for a patently absurd length of time.</p>

    

<p>Note that for those 75 minutes, visitors to the AWS status page (reasonably wondering why their websites and other workloads had just burned down and crashed into the sea) were met with an "all is well!" default response. Ah well, it's not as if AWS had <a target="_blank" href="https://aws.amazon.com/message/12721/" rel="nofollow">previously called out slow outage notification times</a> as an area for improvement. <a target="_blank" href="https://aws.amazon.com/message/11201/" rel="nofollow">Multiple times</a> even. We can <a target="_blank" href="https://aws.amazon.com/message/41926/" rel="nofollow">keep doing this</a> if you'd like.</p>
<h3>The prophecy</h3>
<p>AWS is very, very good at infrastructure. You can tell this is a true statement by the fact that a single one of their 38 regions going down (albeit a very important region!) causes this kind of attention, as opposed to it being "just another Monday outage." At AWS's scale, all of their issues are complex; this isn't going to be a simple issue that someone should have caught, just because they've already hit similar issues years ago and ironed out the kinks in their resilience story.</p>
<p>Once you reach a certain point of scale, there are no simple problems left. What's more concerning to me is the way it seems AWS has been flailing all day trying to run this one to ground. Suddenly, I'm reminded of something I had tried very hard to forget.</p>

        


        

<p>At the end of 2023, Justin Garrison left AWS and <a target="_blank" href="https://justingarrison.com/blog/2023-12-30-amazons-silent-sacking/" rel="nofollow">roasted them on his way out the door</a>. He stated that AWS had seen an increase in Large Scale Events (or LSEs), and predicted significant outages in 2024. It would seem that he discounted the power of inertia, but the pace of senior AWS departures certainly hasn't slowed — and now, with an outage like this, one is forced to wonder whether those departures are themselves a contributing factor.</p>
<p>You can hire a bunch of very smart people who will explain how DNS works at a deep technical level (or you can hire me, who will incorrect you by explaining that it's a database), but the one thing you can't hire for is the person who remembers that when DNS starts getting wonky, check that seemingly unrelated system in the corner, because it's historically played a contributing role to some outages of yesteryear.</p>

        

<p>When that tribal knowledge departs, you're left having to reinvent an awful lot of in-house expertise that didn't want to participate in your RTO games, or play Layoff Roulette yet again this cycle. This doesn't impact your service reliability — until one day it very much does, in spectacular fashion. I suspect that day is today.</p>
<ul>

<li><a href="https://www.theregister.com/2025/10/20/aws_outage_chaos/">AWS outage exposes Achilles heel: central control plane</a></li>

<li><a href="https://www.theregister.com/2025/10/20/amazon_aws_outage/">Major AWS outage across US-East region breaks half the internet</a></li>

<li><a href="https://www.theregister.com/2025/10/17/amazon_nuke_washington/">Amazon spills plan to nuke Washington...with X-Energy mini-reactors</a></li>

<li><a href="https://www.theregister.com/2025/10/06/amazon_007_without_golden_gun/">Amazon turns James Bond into the Man Without the Golden Gun</a></li>
</ul>
<h3>The talent drain evidence</h3>
<p>This is <em>The Register</em>, a respected journalistic outlet. As a result, I know that if I publish this piece as it stands now, an AWS PR flak will appear as if by magic, waving their hands, insisting that "there is no talent exodus at AWS," a la Baghdad Bob. Therefore, let me forestall that time-wasting enterprise with some data.</p>
<ul>
<li>It is a fact that there have been <a target="_blank" href="https://www.cnbc.com/2025/07/17/amazon-web-services-has-some-layoffs.html" rel="nofollow">27,000+ Amazonians impacted by layoffs</a> between 2022 and 2024, continuing into 2025. It's hard to know how many of these were AWS versus other parts of its Amazon parent, because the company is notoriously tight-lipped about staffing issues.</li>

<li>Internal documents reportedly say that Amazon <a target="_blank" href="https://www.engadget.com/amazon-attrition-leadership-ctsmd-201800110-201800100.html" rel="nofollow">suffers from 69 percent to 81 percent regretted attrition</a> across all employment levels. In other words, "people quitting who we wish didn't."</li>

<li>The internet is full of anecdata of senior Amazonians lamenting the hamfisted approach of their Return to Office initiative; <a target="_blank" href="https://finance.yahoo.com/news/amazon-back-office-crusade-could-090200105.html/" rel="nofollow">experts have weighed in</a> citing similar concerns.</li>
</ul>
<p>If you were one of the early employees who built these systems, the world is your oyster. There's little reason to remain at a company that increasingly demonstrates apparent disdain for your expertise.</p>
<h3>My take</h3>
<p>This is a tipping point moment. Increasingly, it seems that the talent who understood the deep failure modes is gone. The new, leaner, presumably less expensive teams lack the institutional knowledge needed to, if not prevent these outages in the first place, significantly reduce the time to detection and recovery. Remember, there was a time when Amazon's "Frugality" leadership principle meant doing more with less, not doing everything with basically nothing. AWS's operational strength was built on redundant, experienced people, and when you cut to the bone, basic things start breaking.</p>
<p>I want to be very clear on one last point. This isn't about the technology being old. It's about the people maintaining it being new. If I had to guess what happens next, the market will forgive AWS this time, but the pattern will continue.</p>
<p>AWS will almost certainly say this was an "isolated incident," but when you've hollowed out your engineering ranks, every incident becomes more likely. The next outage is already brewing. It's just a matter of which understaffed team trips over which edge case first, because the chickens are coming home to roost. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iOS 26.1 lets users control Liquid Glass transparency (152 pts)]]></title>
            <link>https://www.macrumors.com/2025/10/20/ios-26-1-liquid-glass-toggle/</link>
            <guid>45648266</guid>
            <pubDate>Mon, 20 Oct 2025 19:39:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrumors.com/2025/10/20/ios-26-1-liquid-glass-toggle/">https://www.macrumors.com/2025/10/20/ios-26-1-liquid-glass-toggle/</a>, See on <a href="https://news.ycombinator.com/item?id=45648266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="maincontent"><article expanded="true"><div data-io-article-url="/2025/10/20/ios-26-1-liquid-glass-toggle/"><p>With the fourth betas of iOS 26.1, iPadOS 26.1, and macOS 26.1, Apple has introduced a new setting that's designed to allow users to customize the look of Liquid Glass.</p>
<p><img src="https://images.macrumors.com/t/OCRA_6Z8V4J8hTc_cWfWK-zkX9w=/400x0/article-new/2025/10/ios-26-1-liquid-glass-opaque.jpg?lossy" srcset="https://images.macrumors.com/t/OCRA_6Z8V4J8hTc_cWfWK-zkX9w=/400x0/article-new/2025/10/ios-26-1-liquid-glass-opaque.jpg?lossy 400w,https://images.macrumors.com/t/tj3V79n2YvpR0tslbBIv6K1qcvY=/800x0/article-new/2025/10/ios-26-1-liquid-glass-opaque.jpg?lossy 800w,https://images.macrumors.com/t/Nawho-r4OQp6pTe_7_FIPthUu2A=/1600x0/article-new/2025/10/ios-26-1-liquid-glass-opaque.jpg 1600w,https://images.macrumors.com/t/6PpVz-MHL6Gyx_oDr4Hqtac40xA=/2500x0/filters:no_upscale()/article-new/2025/10/ios-26-1-liquid-glass-opaque.jpg 2500w" sizes="(max-width: 900px) 100vw, 697px" alt="ios 26 1 liquid glass opaque" width="2000" height="1125"><br>The toggle lets users select from a clear look for Liquid Glass, or a tinted look. Clear is the current Liquid Glass design, which is more transparent and shows the background underneath buttons, bars, and menus, while tinted increases the opacity of Liquid Glass and adds more contrast.</p>
<p>The new setting can be found on iOS and iPadOS by going to Settings &gt; Display and Brightness, or System Settings &gt; Appearance on the Mac.</p>
<p>Apple says that the new toggle was added because during the beta testing period over the summer, user feedback suggested that some people would prefer to have a more opaque option for Liquid Glass. The added setting provides additional customization in iOS 26.1, iPadOS 26.1, and macOS Tahoe 26.1. </p>
<p>Increasing opacity and adding contrast applies to Liquid Glass throughout the operating system, including in apps and Lock Screen notifications.</p>
<p>There are multiple other new features in iOS 26.1, including a new slide to stop feature for alarms and timers, new <a href="https://www.macrumors.com/guide/apple-intelligence/">Apple Intelligence</a> languages, a redesigned <a href="https://www.macrumors.com/roundup/apple-tv/">Apple TV</a> app icon, changes to the Settings app, and more, with a full list of features <a href="https://www.macrumors.com/guide/ios-26-1-beta-features/">available in our iOS 26.1 feature guide</a>.</p>
</div></article><p><h2>Popular Stories</h2></p><div><h3><a href="https://www.macrumors.com/2025/10/17/iphone-air-production-to-be-cut-amid-lower-sales/">Apple Said to Cut iPhone Air Production Amid Underwhelming Sales</a></h3><p>Apple plans to cut production of the iPhone Air amid underwhelming sales performance, Japan's Mizuho Securities believes (via The Elec).
The Japanese investment banking and securities firm claims that the iPhone 17 Pro and iPhone 17 Pro Max are seeing higher sales than their predecessors during the same period last year, while the standard iPhone 17 is a major success, performing...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/18/ios-26-1-to-ios-26-4-expected-features/">iOS 26.1 to iOS 26.4 Will Add These New Features to Your iPhone</a></h3><p>Saturday October 18, 2025 11:00 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>iOS 26 was released last month, but the software train never stops, and iOS 26.1 beta testing is already underway. So far, iOS 26.1 makes both Apple Intelligence and Live Translation on compatible AirPods available in additional languages, and it includes some other minor changes across the Apple Music, Calendar, Photos, Clock, and Safari apps.
More features and changes will follow in future ...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/17/ios-26-0-2-coming-soon/">iOS 26.0.2 Update for iPhones Coming Soon</a></h3><p>Apple's software engineers continue to internally test iOS 26.0.2, according to MacRumors logs, which have been a reliable indicator of upcoming iOS versions.
iOS 26.0.2 will be a minor update that addresses bugs and/or security vulnerabilities, but we do not know any specific details yet.
The update will likely be released by the end of next week.
Last month, Apple released iOS 26.0.1,...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/16/heres-whats-coming-next-from-apple/">Apple's Next Rumored Products: New HomePod Mini, Apple TV, and More</a></h3><p>Thursday October 16, 2025 9:13 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple on Wednesday updated the 14-inch MacBook Pro, iPad Pro, and Vision Pro with its next-generation M5 chip, but previous rumors have indicated that the company still plans to announce at least a few additional products before the end of the year.
The following Apple products have at one point been rumored to be updated in 2025, although it is unclear if the timeframe for any of them has...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/19/ios-26-4-revamped-siri-concerns/">Some Apple Employees Have 'Concerns' About iOS 26.4's Revamped Siri</a></h3><p>iOS 26.4 is expected to introduce a revamped version of Siri powered by Apple Intelligence, but not everyone is satisfied with how well it works.
In his Power On newsletter today, Bloomberg's Mark Gurman said some of Apple's software engineers have "concerns" about the overhauled Siri's performance. However, he did not provide any specific details about the shortcomings.
iOS 26.4 will...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/18/new-ipad-pro-six-key-upgrades/">New iPad Pro Has Six Key Upgrades Beyond M5 Chip</a></h3><p>Saturday October 18, 2025 10:57 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>While the new iPad Pro's headline feature is the M5 chip, the device has some other changes, including N1 and C1X chips, faster storage speeds, and more.
With the M5 chip, the new iPad Pro has up to a 20% faster CPU and up to a 40% faster GPU compared to the previous model with the M4 chip, according to Geekbench 6 results. Keep in mind that 256GB and 512GB configurations have a 9-core CPU,...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/20/ios-26-1-liquid-glass-toggle/">iOS 26.1 Beta 4 Lets Users Control Liquid Glass Transparency with New Toggle</a></h3><p>Monday October 20, 2025 10:57 am PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>With the fourth betas of iOS 26.1, iPadOS 26.1, and macOS 26.1, Apple has introduced a new setting that's designed to allow users to customize the look of Liquid Glass.
The toggle lets users select from a clear look for Liquid Glass, or a tinted look. Clear is the current Liquid Glass design, which is more transparent and shows the background underneath buttons, bars, and menus, while tinted ...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/16/new-14-inch-macbook-pro-two-key-upgrades/">New 14-Inch MacBook Pro Has Two Key Upgrades Beyond the M5 Chip</a></h3><p>Thursday October 16, 2025 8:31 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple on Wednesday updated the 14-inch MacBook Pro base model with an M5 chip, and there are two key storage-related upgrades beyond that chip bump.
First, Apple says the new 14-inch MacBook Pro offers up to 2× faster SSD performance than the equivalent previous-generation model, so read and write speeds should get a significant boost. Apple says it is using "the latest storage technology," ...</p></div><div><h3><a href="https://www.macrumors.com/2025/10/16/m5-macbook-air-spring/">M5 MacBook Air Coming Spring 2026 With M5 Mac Studio and Mac Mini in Development</a></h3><p>Thursday October 16, 2025 3:57 pm PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>Apple plans to launch MacBook Air models equipped with the new M5 chip in spring 2026, according to Bloomberg's Mark Gurman. Apple is also working on M5 Pro and M5 Max MacBook Pro models that will come early in the year.
Neither the MacBook Pro models nor the MacBook Air models are expected to get design changes, with Apple focusing on simple chip upgrades. In the case of the MacBook Pro, a m...</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[J.P. Morgan's OpenAI loan is strange (209 pts)]]></title>
            <link>https://marketunpack.com/j-p-morgans-openai-loan-is-strange/</link>
            <guid>45648258</guid>
            <pubDate>Mon, 20 Oct 2025 19:38:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marketunpack.com/j-p-morgans-openai-loan-is-strange/">https://marketunpack.com/j-p-morgans-openai-loan-is-strange/</a>, See on <a href="https://news.ycombinator.com/item?id=45648258">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
             
            <p>In October, <a href="https://openai.com/index/new-credit-facility-enhances-financial-flexibility/" rel="noreferrer">OpenAI secured a 4 billion dollar revolving credit facility from J.P. Morgan and several other banks</a>.  I was surprised when I heard this because OpenAI is a young company with no earnings.  Shouldn't all their capital come from investors?  Let's run some numbers.</p><h2 id="from-first-principles">From first principles</h2><p>Let's do an <a href="https://www.investopedia.com/terms/e/expected-value.asp" rel="noreferrer">Expected Value (EV)</a> calculation, first from the perspective of an investor and then from the perspective of a lender.  We'll pick some arbitrary parameters first, then refine.</p><p>Putting our investor hat on, the possible returns for investing $1,000 into OpenAI look like this:</p><ul><li>Cost: $1,000</li><li>Case 1 (90%): OpenAI goes bankrupt. Return: $0</li><li>Case 2 (9%): OpenAI becomes a big successful company and goes 10x.  Return: $10,000</li><li>Case 3 (1%): OpenAI becomes the big new thing and goes 100x.  Return: $100,000</li></ul><p>Our expected value is:</p>
<!--kg-card-begin: html--><p>
\[\begin{align}
  EV &amp;= -1000 + 0.9 \times 0 + 0.09 \times 10000 + 0.01 \times 100000\\
  EV &amp;= -1000 + 0 + 900 + 1000\\
  EV &amp;= 900
\end{align}\]
</p><!--kg-card-end: html-->
<p>The EV is positive, so this is a good investment.  Obviously, there's a 90% chance of it going to zero, so if this were our only investment, it would be an insanely risky one.  But provided we can do many investments like this and provided their failure cases aren't correlated, this would be a profitable strategy.</p><p>What happens if we instead put our lender hat on?  Using the same probabilities as above, the possible returns for lending $1,000 to OpenAI at 5% interest look like this:</p><ul><li>Cost: $1,000</li><li>Case 1 (90%): OpenAI goes bankrupt. Return: $0</li><li>Case 2 (9%): OpenAI becomes a big successful company and goes 10x.  Return: $1,000 + 5% interest = $1,050</li><li>Case 3 (1%): OpenAI becomes the big new thing and goes 100x.  Return: $1,000 + 5% interest = $1,050</li></ul><p>Lenders don't benefit directly from the success of the company.  Whether it barely scrapes by but manages to repay the loan or becomes the greatest company ever and easily repays the loan, it's all the same to a lender.  So, we can merge cases 2 and 3 into:</p><ul><li>Case 2+3 (10%): OpenAI doesn't go bankrupt.  Return: $1,000 + 5% interest = $1,050</li></ul><p>This makes our EV in the lending case:</p>
<!--kg-card-begin: html--><p>
\[\begin{align}
  EV &amp;= -1000 + 0.9 \times 0 + 0.1 \times 1050\\
  EV &amp;= -1000 + 0 + 105\\
  EV &amp;= -895
\end{align}\]
</p><!--kg-card-end: html-->
<p>The EV is negative, so we'd end up losing most of our money on average.  Lending on these terms doesn't make sense.</p><p>There are two numbers we made up in the above calculation: the probability of bankruptcy and the interest rate.  Let's leave the interest rate fixed at 5% and see what the probability \(p\) would have to be for us to break even.</p>
<!--kg-card-begin: html--><p>
\[\begin{align}
  EV &amp;= -1000 + p \times 0 + (1 - p) \times 1050\\
  EV &amp;= -1000 + 1050 - p \times 1050 \\
  EV &amp;= 50 - p \times 1050 \\[0.5cm]
  &amp; \text{Set EV to 0} \\[0.5cm]
  0 &amp;= 50 - p \times 1050 \\
  p &amp;= \frac{50}{1050} \\
  p &amp;= 0.0476
\end{align}\]
</p><!--kg-card-end: html-->
<p>So, we'd break even if the probability of OpenAI going bankrupt was only about 5%.  In practice, we'd want it to be lower than that so that we made a profit and so that we had a margin of safety in case our assumptions were wrong.</p><p>This 5% failure rate seems very optimistic to me, but this scenario is basically the one the consortium of banks got into.  Concrete details on the deal are sparse, but this <a href="https://thecioleaders.com/openai-locks-down-4-billion-revolving-credit-putting-liquidity-over-10-billion/" rel="noreferrer">CIO Leaders article</a> claims the interest rate was "SOFR + 100 basis points".  The <a href="https://www.newyorkfed.org/markets/reference-rates/sofr" rel="noreferrer">overnight SOFR rate</a> is about 4.1% in October, so this puts OpenAI's interest at about 5%.</p><h2 id="from-market-data">From market data</h2><p>The problem with the above expected value calculation is that it's very idealized.  The shape of it is correct, but the real world is too messy to be accurately represented by just a couple of parameters.  I think it would be very difficult to build a model with enough predictive accuracy to be useful and I suspect there just isn't enough publicly available data to plug into it to make it work.</p><p>Luckily for us, banks exist!  We know the banks have the better model and the non-public data and we know they came up with about 5% interest.  So, let's work back from that and see what we can learn.</p><p>We're talking about a loan here and that's very similar to issuing bonds.  So, we should be able to look at the bond market and find companies in similar financial health (from the perspective of a creditor).  One problem is that we only know the overnight rate for OpenAI of about 5%, but bonds on the market will have longer maturities.  We need to calculate what what yield a longer maturity loan would require and we can do that by looking at US treasuries.</p><p>According to <a href="https://www.bloomberg.com/markets/rates-bonds/government-bonds/us" rel="noreferrer">Bloomberg</a>, the three month treasuries have a yield of 3.94%.  One year ones have a yield of 3.58%.</p><figure><img src="https://marketunpack.com/content/images/2025/10/image.png" alt="" loading="lazy" width="856" height="436" srcset="https://marketunpack.com/content/images/size/w600/2025/10/image.png 600w, https://marketunpack.com/content/images/2025/10/image.png 856w" sizes="(min-width: 720px) 720px"><figcaption><b><strong>Figure 1.</strong></b><span> Treasury Yields for US government bonds. The table shows the following yields: 3 months is 3.94%, 6 month is 3.81%, 12 month is 3.58%, 2 year is 3.50%, 5 year is 3.62%, 10 year is 4.03%, 30 year is 4.62%. This describes a smile that initially goes down, goes back up to starting level at 10 years, then continues upwards.</span></figcaption></figure><p>One way of thinking about corporate bonds is that they're basically treasury bonds plus some premium to account for the risk of default.  This <em>default spread</em> seems to be about \(5\% - 3.94\% \approx 1\%\) in OpenAI's case.  By this logic, OpenAI's one year debt would have a yield of about 4.6%.</p><p>Can we find some one year bonds with a yield of 4.6%?</p><figure><img src="https://marketunpack.com/content/images/2025/10/image-3.png" alt="" loading="lazy" width="1133" height="685" srcset="https://marketunpack.com/content/images/size/w600/2025/10/image-3.png 600w, https://marketunpack.com/content/images/size/w1000/2025/10/image-3.png 1000w, https://marketunpack.com/content/images/2025/10/image-3.png 1133w" sizes="(min-width: 720px) 720px"><figcaption><b><strong>Figure 2.</strong></b><span> A sample of corporate USD bonds expiring in one year or less, sorted by their mid-yield to maturity. (Source: Saxo Bank)</span></figcaption></figure><p>Some bonds in the vicinity of what we're looking for are:</p><ul><li>4.99%: HCA Inc. (US healthcare provider with credit rating BBB),</li><li>4.73%: Ziraat Katilim (Turkish bank with credit rating B+), and</li><li>4.24%: Citigroup (US bank with credit rating A).</li></ul><p>In fact, scanning the sample above, it's mostly banks with BBB and A ratings.  So, the consortium of big banks seems to have lent money to OpenAI at the kind of rates they themselves are borrowing at.</p><p>Looking at just a few bonds is interesting, but anecdotal.  It would be better if we had some statistics across the whole bond market.  Helpfully, Prof Damodaran goes through the exercise of calculating just <a href="https://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/ratings.html" rel="noreferrer">such statistics</a> (<a href="https://web.archive.org/web/20250827084311/https://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/ratings.html" rel="noreferrer">archive link</a>) every year, most recently this January.</p><figure><img src="https://marketunpack.com/content/images/2025/10/image-1.png" alt="" loading="lazy" width="417" height="458"><figcaption><b><strong>Figure 3.</strong></b><span> To quote the author: "This is a table that relates the interest coverage ratio of a firm to a 'synthetic' rating and a default spread that goes with that rating. The link between interest coverage ratios and ratings was developed by looking at all rated companies in the United States. The default spreads are obtained from traded bonds. Adding that number to a riskfree rate should yield the pre-tax cost of borrowing for a firm."</span></figcaption></figure><p>Looking up OpenAI's default spread of 1% in that table, we see it's at the level we'd expect for an A- or BBB firm (same as with the anecdotal search earlier).  This normally corresponds to an interest coverage ratio of 3.00-4.24.  However, OpenAI's actual interest coverage ratio is negative because their earnings before interest are negative.</p><p>This doesn't make sense: any way we look at it, OpenAI is getting the kind of interest rates only much more established and profitable firms would be getting.  So, my initial surprise at hearing about this is justified, but there must be an explanation because the big banks wouldn't make such an obvious mistake.</p><h2 id="making-this-make-sense">Making this make sense</h2><p>OpenAI is not a profitable company.  It's also a private company, so we don't get to see audited financials, but we still know some things.  This <a href="https://www.reuters.com/technology/artificial-intelligence/openai-establishes-4-bln-credit-facility-2024-10-03/" rel="noreferrer">Reuters article</a> claims OpenAI is going to generate $3.6 billion in revenue this year, but the costs will lead to a loss of more than $5 billion.</p><p>There's also speculation that their revenue next year will jump to $11.6 billion.  However, there's no speculation about what their earnings will be because they're currently selling their services below cost and there isn't really any story as to how they'll turn this profitable.</p><p>The banks are lenders in this scenario, so they don't really care about how many users OpenAI gets or how huge their revenue becomes.  As lenders, all they care about is getting paid back and it really doesn't seem like OpenAI will have the earnings to do that.  But maybe earnings aren't what matters here.</p><p>If OpenAI can't pay its debts, it goes bankrupt and the creditors seize the company.  Importantly, they seize it from the equity holders.  Who are these equity holders?  According to <a href="https://www.digitalinformationworld.com/2025/09/who-really-owns-openai-billion-dollar.html" rel="noreferrer">this Digital Information World article</a>, the owners are Microsoft (28%), OpenAI non-profit and employees (52%), and other investors (20%).</p><p>So, the hypothetical is OpenAI runs out of money.  They have revenue, but since their costs are higher, they don't actually have anything left over.  They can't make interest payments on their debt, so they go bankrupt, and the banks seize the company from Microsoft.  I don't think Microsoft will allow this to happen.  <a href="https://www.microsoft.com/en-us/investor/earnings/fy-2024-q4/press-release-webcast" rel="noreferrer">Microsoft's earnings for last year were $88 billion</a>, so I think Microsoft will just pay off OpenAI's $4 billion debt in this scenario.  And I think the banks know all this.</p><p>So, the banks loaning money to OpenAI at an A- interest rate doesn't make sense, but effectively loaning the same to <a href="https://www.spglobal.com/ratings/en/regulatory/article/-/view/sourceId/37291" rel="noreferrer">Microsoft with its AAA rating</a> does, and that's what's actually happening here.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When a stadium adds AI to everything, it's worse experience for everyone (119 pts)]]></title>
            <link>https://a.wholelottanothing.org/bmo-stadium-in-la-added-ai-to-everything-and-what-they-got-was-a-worse-experience-for-everyone/</link>
            <guid>45648249</guid>
            <pubDate>Mon, 20 Oct 2025 19:38:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://a.wholelottanothing.org/bmo-stadium-in-la-added-ai-to-everything-and-what-they-got-was-a-worse-experience-for-everyone/">https://a.wholelottanothing.org/bmo-stadium-in-la-added-ai-to-everything-and-what-they-got-was-a-worse-experience-for-everyone/</a>, See on <a href="https://news.ycombinator.com/item?id=45648249">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I just got back from a 24hr trip to Los Angeles to catch my favorite Portland Thorns team, watching them clinch their playoff spot in a match at BMO stadium in downtown Los Angeles.</p><p>In May of 2024, I did the same trip to catch a match on Mother's Day, but I accidentally chose bad seats in the sun and it was hot and uncomfortable. Ultimately, it partially inspired <a href="https://unofficialnwsl.stadium.guide/the-book-is-out/?ref=a.wholelottanothing.org" rel="noreferrer">my wife and I's book reviewing every NWSL soccer stadium</a> so other fans wouldn't suffer the same fate when flying across the country to catch their favorite team.</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_2952.JPG" alt="" loading="lazy" width="2000" height="1541" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_2952.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_2952.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_2952.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_2952.JPG 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Me and my pal Greg yesterday</span></figcaption></figure><p>This year, I got better seats in the shade and enjoyed the game. But overall? The experience of being in the stadium was worse a year later. After thinking about it on the flight home, I think the reason was the stadium's rush to automation and AI in several places. </p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/SF-20Giants-2004.webp" alt="" loading="lazy" width="2000" height="1500" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/SF-20Giants-2004.webp 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/SF-20Giants-2004.webp 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/SF-20Giants-2004.webp 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/SF-20Giants-2004.webp 2400w" sizes="(min-width: 1200px) 1200px"></figure><h2 id="spoiler-alert-deploying-cameraai-recognition-for-everything-isnt-great">Spoiler alert: deploying camera/AI recognition for everything isn't great</h2><p>Every concession stand, including the ones that didn't even serve hot food, used the apparatus in the photo above to control all checkouts. I assume these are expensive units, because most places that used to have several checkout lanes only had one of them, requiring everyone to checkout through a single location.</p><p>Here's how they worked in the stadium yesterday: You place all your items on the white shelf with some space between them. Although they were clearly designed to be a self-checkout experience, the stadium had a staff member rearrange your items, then for about 30 seconds the kiosk would be thinking. After, it would pop up all items on the menu, and the staff member would have to tap to confirm what each item was. Then another 30 seconds to calculate and move the purchase to a point of sale/tap on the side, then you'd pay. </p><p>Overall, this added at least one, if not two full minutes to every transaction that didn't normally have those delays. Lines were unbearably long, and it was a hot day in LA yesterday, at 87ºF/30ºC. I bought food and drinks several times over the the course of the day and had to endure the process multiple times.</p><h2 id="when-you-add-object-recognition-youre-incentivized-to-reduce-choices">When you add object recognition, you're incentivized to reduce choices</h2><p>Here's an unintended consequence of moving all your concession stand checkouts to computer vision: it's easier if you have less things on offer.</p><p>Case in point: Let's talk about my favorite concession stand at BMO last year, a place that served rotisserie chicken with waffle fries and chicken sandwiches. Here's our meal from 2024, it was well-seasoned, came with great sauces, and was one of the best meals I had at a stadium in my entire nationwide tour, which is why I remembered it.</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_5563.JPG" alt="" loading="lazy" width="2000" height="1974" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_5563.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_5563.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_5563.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_5563.JPG 2400w" sizes="(min-width: 720px) 720px"></figure><p>I returned to the same concession stand yesterday and here's their new menu:</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_2925.JPG" alt="" loading="lazy" width="2000" height="1380" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_2925.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_2925.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_2925.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_2925.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>When your checkout stand relies on computer vision, it's probably confusing to have half a dozen different menu items that fans can enjoy. But if you could condense it to just chicken tenders, fries, a hot dog, and boxes of candy, your computer vision-based checkout system will probably work faster since it has to do less work with the obvious shapes of each of those items.</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_5571.JPG" alt="" loading="lazy" width="2000" height="1983" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_5571.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_5571.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_5571.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_5571.JPG 2400w" sizes="(min-width: 720px) 720px"></figure><p>Looking through my photos from my 2024 visit, I saw a variety of food options including smashburgers and a Korean BBQ rice bowl I also tried, pictured above. </p><p>If foods are difficult for computer vision to decipher, why not get rid of most options? Walking around the stadium yesterday, the menus were basically all hot dogs, pizza, nachos, and chicken tenders.</p><h2 id="even-quick-service-options-sucked">Even quick service options sucked</h2><p>As I said, it was a hot day, I was constantly parched, and I ended up drinking four bottles of water over the course of three hours. Each time, I had to go through the automated checkout gauntlet, and each time it required a long wait in a line, while I missed bits of the match.</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_2984.JPG" alt="" loading="lazy" width="2000" height="2667" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_2984.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_2984.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_2984.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_2984.JPG 2400w" sizes="(min-width: 720px) 720px"></figure><p>Late in the game, I wanted to get water quickly and they had these "vending kiosks" that were fully automated. You'd tap your phone on the locked door, it would unlock, you'd grab items, then close the door. Next, you had to stand there for about 2 minutes while it said "calculating checkout" before showing you a receipt on the screen.</p><p>What was supposed to be fast was very slow. The person in front of me bought two items and saw she got charged for three. Since there were no paper receipts, she took a photo of the machine before going to the guest services to complain. I missed ten minutes of the game getting water.</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_2983.JPG" alt="" loading="lazy" width="2000" height="1265" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_2983.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_2983.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_2983.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_2983.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>This was a quick service "market" style place and last year, you'd just grab stuff off a shelf, and checkout quickly from staff at multiple registers. This year, it had a long line snaking all over because of the slow AI/camera checkout kiosks.</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_2980.JPG" alt="" loading="lazy" width="2000" height="1500" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_2980.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_2980.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_2980.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_2980.JPG 2400w"></figure><p>It was a busy game, being the last home match for the fans and I would guess there were around 17,000-18,000 people in attendance. When it's nearly 90ºF/30ºC, heat exhaustion becomes a problem for crowds. When it takes people ten minutes to buy a bottle of water (I didn't see automated water fillers at the restrooms), the embrace of slow AI/Camera-based checkout systems starts to become a health and safety issue for the crowd.</p><h2 id="but-mrs-lincoln%E2%80%94besides-the-obvious%E2%80%94how-was-the-play">But Mrs. Lincoln—besides the obvious—how was the play?</h2><p>A year later visiting the same stadium, I got worse food, slower service, and a worse overall experience. On the bright side, the billionaire stadium owners probably got to reduce their staff in the process while maybe increasing profits.</p><p>The company behind the kiosks <a href="https://blog.mashgin.com/ai-retail/mashgin-expands-footprint-at-bmo-stadium?ref=a.wholelottanothing.org" rel="noreferrer">claims they are 400% faster than human checkers and result in a 25% increase in profits</a>. After experiencing it in person yesterday, I think those numbers are bullshit. Human checkers are clearly faster and smoother, and I bet they sold more food and drinks when people could get them quickly.</p><p>And the portions? They were so small!</p><figure><img src="https://a.wholelottanothing.org/content/images/2025/10/IMG_2977.JPG" alt="" loading="lazy" width="2000" height="2354" srcset="https://a.wholelottanothing.org/content/images/size/w600/2025/10/IMG_2977.JPG 600w, https://a.wholelottanothing.org/content/images/size/w1000/2025/10/IMG_2977.JPG 1000w, https://a.wholelottanothing.org/content/images/size/w1600/2025/10/IMG_2977.JPG 1600w, https://a.wholelottanothing.org/content/images/size/w2400/2025/10/IMG_2977.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure>
    </div><div>
                        <h3>
                                Subscribe to get new posts in your inbox
                        </h3>
                        

                            
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code on the Web (378 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-code-on-the-web</link>
            <guid>45647166</guid>
            <pubDate>Mon, 20 Oct 2025 18:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-code-on-the-web">https://www.anthropic.com/news/claude-code-on-the-web</a>, See on <a href="https://news.ycombinator.com/item?id=45647166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>Today, we're introducing Claude Code on the web, a new way to delegate coding tasks directly from your browser.</p><p>Now in beta as a research preview, you can assign multiple coding tasks to Claude that run on Anthropic-managed cloud infrastructure, perfect for tackling bug backlogs, routine fixes, or parallel development work.</p><h2 id="run-coding-tasks-in-parallel">Run coding tasks in parallel</h2><p>Claude Code on the web lets you kick off coding sessions without opening your terminal. Connect your GitHub repositories, describe what you need, and Claude handles the implementation. </p><p>Each session runs in its own isolated environment with real-time progress tracking, and you can actively steer Claude to adjust course as it’s working through tasks.</p><p>With Claude Code running in the cloud, you can now <strong>run multiple tasks in parallel</strong> across different repositories from a single interface and <strong>ship faster</strong> with automatic PR creation and clear change summaries.</p><h2 id="flexible-for-every-workflow">Flexible for every workflow</h2><p>The web interface complements your existing Claude Code workflow. Running tasks in the cloud is especially effective for:</p><ul><li>Answering questions about how projects work and how repositories are mapped</li><li>Bugfixes and routine, well-defined tasks</li><li>Backend changes, where Claude Code can use test-driven development to verify changes</li></ul><p>You can also use Claude Code on mobile. As part of this research preview, we’re making Claude Code available on our iOS app so developers can explore coding with Claude on the go. It’s an early preview, and we hope to quickly refine the mobile experience based on your feedback.<br></p><h2 id="security-first-cloud-execution">Security-first cloud execution</h2><p>Every Claude Code task runs in an isolated sandbox environment with network and filesystem restrictions. Git interactions are handled through a secure proxy service that ensures Claude can only access authorized repositories—helping keep your code and credentials protected throughout the entire workflow.</p><p>You can also add custom network configuration to choose what domains Claude Code can connect to from its sandbox. For example, you can allow Claude to download npm packages over the internet so that it can run tests and validate changes.</p><p>Read our <a href="https://www.anthropic.com/engineering/claude-code-sandboxing">engineering blog</a> and <a href="https://docs.claude.com/en/docs/claude-code/sandboxing">documentation</a> for a deep dive on Claude Code’s sandboxing approach.</p><h2 id="getting-started">Getting started</h2><p>Claude Code on the web is available now in research preview for Pro and Max users. Visit <a href="http://claude.com/code">claude.com/code</a> to connect your first repository and start delegating tasks.</p><p>Cloud-based sessions share rate limits with all other Claude Code usage. <a href="https://docs.claude.com/en/docs/claude-code/claude-code-on-the-web">Explore our documentation</a> to learn more.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peanut allergies have plummeted in children (107 pts)]]></title>
            <link>https://www.nytimes.com/2025/10/20/well/peanut-allergy-drop.html</link>
            <guid>45647133</guid>
            <pubDate>Mon, 20 Oct 2025 18:09:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/10/20/well/peanut-allergy-drop.html">https://www.nytimes.com/2025/10/20/well/peanut-allergy-drop.html</a>, See on <a href="https://news.ycombinator.com/item?id=45647133">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/10/20/well/peanut-allergy-drop.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[x86-64 Playground – An online assembly editor and GDB-like debugger (110 pts)]]></title>
            <link>https://x64.halb.it/</link>
            <guid>45646958</guid>
            <pubDate>Mon, 20 Oct 2025 17:55:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://x64.halb.it/">https://x64.halb.it/</a>, See on <a href="https://news.ycombinator.com/item?id=45646958">Hacker News</a></p>
<div id="readability-page-1" class="page"> <header>  </header> <section>   <h2>An online assembly editor and GDB-like debugger</h2>  </section> <section> <div> <picture> <source srcset="https://x64.halb.it/_astro/app_desktop_3.Bcfcbg3r.webp" type="image/webp"> <img src="https://x64.halb.it/_astro/app_desktop_3.CISWVIUM.jpg" alt="Screenshot of the Playground web app, in the desktop layout size." width="2880" height="1800" loading="lazy" decoding="async"> </picture> </div> <span></span> </section> <section> <h3 id="introduction">Features</h3> <p>x86-64 Playground is a web app for experimenting and learning 
          x86-64 assembly.
</p> <p>
The Playground web app provides an online code editor where you
        can write, compile, and share assembly code for a wide
        range of popular assemblers such as GNU As, Fasm and Nasm.
</p> <p>
Unlike traditional onlide editors, this playground
          allows you to follow the execution of your program step by step,
        inspecting memory and registers of the running process from a GDB-like interface.
</p> <p>
You can bring your own programs!
        Drag and drop into the app any x86-64-Linux static executable to run and 
        debug it in the same sandboxed environment, without having to install anything.
</p> </section> <section> <h3>Who is this for?</h3> <p>The app is for anyone that wants to run amd64 assembly snippets or
          inspect the inner workings of simple Linux ELF files.</p> <p>It has been designed with the academic world of binary exploitation in mind;
            The debugger interface offers visualizations similar to the GDB+PwnGDB debugger plugin,
            and all the controls are labelled with the respective GDB commands.
</p> <p>Combined with <a href="https://godbolt.org/">Compiler Explorer</a>, this app provides
            a noise-free environment to learn the basics behind the inner workings of a Linux process.
            When you are ready, it includes the guides and resources necessary to keep experimenting
            on your own linux environment, with the actual GDB debugger.
</p> </section> <div> <div> <h3>Designed for the web </h3> <p>Have you ever seen a responsive debugger?
        The app places the mobile experience at the center of its design,
        and can be embedded in any web page
        to add interactivity to technical tutorials or documentations.
</p> <p>
Follow the guide to <a href="https://x64.halb.it/"> embed in your website </a> both the asm editor and debugger.
</p> </div> <p><img src="https://x64.halb.it/_astro/app_mobile_art.nN-X8L8r_1Q1Cl8.webp" alt="Screenshot of the Playground web app, showing the layout on mobile devices." width="581" height="815" loading="lazy" decoding="async"> </p> </div> <section> <h3>Offline-first and open-source</h3> <p>
The app is open-source, and <a href="https://github.com/robalb/x86-64-playground">available on Github</a>.
  It's powered by the <a href="https://github.com/jart/blink/">Blink Emulator</a>,
  which emulates an x86-64-Linux environment entirely client side in your browser.
  This means that all the code you write, or the excutables you debug are never sent to the server.
</p> <p>
everything runs in your browser, and once the Web App loads it will work 
  without an internet connection.
</p> </section>     </div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS outage shows internet users 'at mercy' of too few providers, experts say (240 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/oct/20/amazon-web-services-aws-outage-hits-dozens-websites-apps</link>
            <guid>45646649</guid>
            <pubDate>Mon, 20 Oct 2025 17:32:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/oct/20/amazon-web-services-aws-outage-hits-dozens-websites-apps">https://www.theguardian.com/technology/2025/oct/20/amazon-web-services-aws-outage-hits-dozens-websites-apps</a>, See on <a href="https://news.ycombinator.com/item?id=45646649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Experts have warned of the perils of relying on a small number of companies for operating the global internet after a glitch at Amazon’s cloud computing service brought down apps and websites around the world.</p><p>The affected platforms included <a href="https://www.theguardian.com/technology/snapchat" data-link-name="in body link" data-component="auto-linked-tag">Snapchat</a>, Roblox, Signal and Duolingo as well as a host of Amazon-owned operations including its main retail site and the Ring doorbell company.</p><p>More than 2,000 companies worldwide have been affected, according to Downdetector, a site that monitors internet outages, with 8.1m reports of problems from users including 1.9m reports in the US, 1m in the UK and 418,000 in Australia.</p><p>In the UK, Lloyds bank was affected, as well as its subsidiaries Halifax and Bank of Scotland, while there were also problems accessing the HM Revenue and Customs website on Monday morning. Also in the UK, Ring users complained on social media that their doorbells were not working.</p><p>In the UK alone, reports of problems on individual apps ran into the tens of thousands for each platform. Other affected platforms around the world included Wordle, Coinbase, Duolingo, Slack, Pokémon Go, Epic Games, PlayStation Network and Peloton.</p><p>By 10.30am UK time, Amazon was reporting that the problem, which first emerged at about 8am, was being resolved as AWS was “seeing significant signs of recovery”.</p><p>However, after reporting further positive progress by late morning in the UK, Amazon still appeared to be struggling to overcome the glitch this afternoon as it acknowledged it was still experiencing elevated errors.</p><p>“We can confirm significant API errors and connectivity issues across multiple services … We are investigating,” AWS said in an update around 7am Pacific time and 3pm UK time.</p><p>To aid the recovery, AWS said it was putting in place limits on the number of requests that could be made on its platform.</p><p>Experts said the outage underlined the dangers of the internet’s reliance on a small number of tech companies, with Amazon, Microsoft and Google playing a key role in the cloud market.</p><p>Dr Corinne Cath-Speth, the head of digital at human rights organisation Article 19, said: “We urgently need diversification in cloud computing. The infrastructure underpinning democratic discourse, independent journalism and secure communications cannot be dependent on a handful of companies.”</p><p>Cori Crider, the executive director of the Future of Technology<em> </em>Institute, a thinktank that supports a sovereign technology framework for Europe, said: “The UK can’t keep leaving its critical infrastructure at the mercy of US tech giants. With Amazon Web Services down, we’ve seen the lights go out across the modern economy – from banking to communications.”</p><p>Madeline Carr, professor of global politics and cybersecurity at University College London, said it was “hard to disagree” with warnings about the over-reliance of the global internet on a small number of companies.</p><p>“The counter-argument is that it’s these large hyper-scaling companies that have the financial resources to provide a secure, global and resilient service. But most people outside those companies would argue that is a risky position for the world to be in.”</p><p>Last year, airports, healthcare services and businesses worldwide were hit by the “largest outage in history”, caused by a botched software upgrade from cybersecurity company CrowdStrike that <a href="https://www.theguardian.com/australia-news/article/2024/jul/19/microsoft-windows-pcs-outage-blue-screen-of-death" data-link-name="in body link">hit Microsoft’s Windows operating system</a>.</p><p>Amazon reported that the problem on Monday originated in the east coast of the US at Amazon Web Services, a unit that provides vital web infrastructure for a host of companies, which rent out space on Amazon servers. AWS is the world’s largest cloud computing platform.</p><p>Shortly after midnight (PDT) in the US (8am BST) on Monday, Amazon confirmed “increased error rates and latencies” for AWS services in a region on the east coast of the US. The ripple effect hit services around the world, with Downdetector reporting problems with the same sites in multiple continents.</p><p>Cisco’s Thousand Eyes, a service that <a href="https://www.thousandeyes.com/outages/" data-link-name="in body link">tracks internet outages</a>, also reported a surge in problems on Monday morning, with many of them located in Virginia, the location of Amazon’s US-East-1 region, where AWS said the problems began and where AWS has a number of datacentres.</p><p>Experts said the outage appeared to be an IT issue rather than a cyber-attack. AWS’s online health dashboard referred to DynamoDB, its database system where AWS customers store their data. Amazon appeared to rule out foul play, saying the root cause was an internal subsystem responsible for monitoring its load balancers, which prevent traffic from overloading its servers.</p><p>“The incident appears to have been caused by some accident within AWS, rather than being the result of any malicious intent,” said Steven Murdoch, a professor of security engineering at University College London.</p><p>The UK government has said it is in contact with Amazon over the outage.</p><p>A spokesperson said:<em> </em>“We are aware of an incident affecting Amazon Web Services, and several online services which rely on their infrastructure. Through our established incident response arrangements, we are in contact with the company, who are working to restore services as quickly as possible.”</p><p>The House of Commons’ treasury committee in the UK has written to the economic secretary to the Treasury, Lucy Rigby, to ask why the government had not yet designated Amazon a “critical third party” to the UK’s financial services sector – which would expose the tech firm to financial regulatory oversight.</p><p>The committee chair, Meg Hillier, pointed out that Amazon had recently told the committee that financial services customers were using AWS to support their “resilience” and that AWS offered “multiple layers of protection”.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dutch spy services have restricted intelligence-sharing with the United States (251 pts)]]></title>
            <link>https://intelnews.org/2025/10/20/01-3416/</link>
            <guid>45646572</guid>
            <pubDate>Mon, 20 Oct 2025 17:25:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://intelnews.org/2025/10/20/01-3416/">https://intelnews.org/2025/10/20/01-3416/</a>, See on <a href="https://news.ycombinator.com/item?id=45646572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrap">

					

					

					<p><img data-attachment-id="23271" data-permalink="https://intelnews.org/2025/10/20/01-3416/first-post-h-889/" data-orig-file="https://intelnews.org/wp-content/uploads/2025/10/first-post-h-1.jpg" data-orig-size="629,291" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Mark Rutte NATO Trump" data-image-description="<p>Mark Rutte NATO Trump</p>
" data-image-caption="" data-medium-file="https://intelnews.org/wp-content/uploads/2025/10/first-post-h-1.jpg?w=300" data-large-file="https://intelnews.org/wp-content/uploads/2025/10/first-post-h-1.jpg?w=629" src="https://intelnews.org/wp-content/uploads/2025/10/first-post-h-1.jpg" alt="Mark Rutte NATO Trump" width="629" height="291">INTELLIGENCE SERVICES IN THE Netherlands have restricted intelligence-sharing with their United States counterparts due to political developments in Washington, according to two leading Dutch intelligence officials. This development—which may typify Europe’s current approach to transatlantic intelligence-sharing—was confirmed last week by the heads of the Netherlands’ two largest intelligence agencies in a joint <a title="H. MODDERKOLK &quot;Nederlandse diensten delen minder informatie met de VS - ‘Soms vertellen we dingen niet meer’&quot; De Volkskrant [18oct2025]" href="https://www.volkskrant.nl/binnenland/nederlandse-diensten-delen-minder-informatie-met-de-vs-soms-vertellen-we-dingen-niet-meer~b4882f19/">interview</a> with <em>De Volkskrant</em> newspaper.</p>
<p>The joint interview was given to <em>De Volkskrant</em> by Erik Akerboom, director of the General Intelligence and Security Service (AIVD), and Peter Reesink , director of the General Intelligence and Security Service (MIVD)—AIVD’s civilian counterpart.</p>
<p>Both men stressed that inter-agency relations between Dutch and American intelligence organizations remain “excellent”. However, they added that the Netherlands has grown more selective about what it chooses to share with American intelligence agencies—particularly the Central Intelligence Agency and the National Security Agency. “That we sometimes don’t share things anymore, that’s true,” Reesink said, referring to sharing information with American intelligence agencies. Akerboom added: “sometimes you have to think case by case.” He went on to say: “We can’t say what we will or won’t share. But we can say that we are more critical.”</p>
<p>According to the two senior officials, Dutch spies have been intensifying intelligence cooperation and sharing with their European counterparts. This is particularly applicable to a collection of central and northern European intelligence services from countries like Scandinavia, France, Germany, the United Kingdom, and Poland, according to <em>De Volkskrant</em>.</p>
<p>► <strong>Author</strong>: Ian Allen | <strong>Date</strong>: 20 October 2025 | <a href="https://intelnews.org/2025/10/20/01-3416/">Permalink</a></p>

					
					<!--
					<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://intelnews.org/2025/10/20/01-3416/"
    dc:identifier="https://intelnews.org/2025/10/20/01-3416/"
    dc:title="Dutch spy services have restricted intelligence-sharing with the United States:&nbsp;report"
    trackback:ping="https://intelnews.org/2025/10/20/01-3416/trackback/" />
</rdf:RDF>					-->

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chess grandmaster Daniel Naroditsky has passed away (304 pts)]]></title>
            <link>https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/</link>
            <guid>45646561</guid>
            <pubDate>Mon, 20 Oct 2025 17:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/">https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/</a>, See on <a href="https://news.ycombinator.com/item?id=45646561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="siteTable_t3_1obnbmu"><div id="thing_t1_nkh9edt" onclick="click_thing(this)" data-fullname="t1_nkh9edt" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="TheStarfrost" data-author-fullname="t2_1v11zz43qp" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkh9edt/"><p>[–]<a href="https://old.reddit.com/user/TheStarfrost">TheStarfrost</a><span></span> <span title="348">348 points</span><span title="349">349 points</span><span title="350">350 points</span> <time title="Mon Oct 20 16:56:00 2025 UTC" datetime="2025-10-20T16:56:00+00:00">2 hours ago</time><time title="last edited 1 hour ago" datetime="2025-10-20T17:37:08+00:00">*</time>&nbsp;(1 child)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkh9edt1my"><div><p>Heartbreaking. </p>

<p>Danya was an incredible, positive influence, not only on Chess, but on the world around him. </p>

<p>He brought so much joy to so many people, from his speedruns to his commentary to his chess itself. </p>

<p>I cannot believe he's gone. We are all lesser for it.</p>

<p>He will be sorely missed.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkh9edt/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nkhaozo" onclick="click_thing(this)" data-fullname="t1_nkhaozo" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="KnightFlorianGeyer" data-author-fullname="t2_ezcujy04s" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhaozo/"><p>[–]<a href="https://old.reddit.com/user/Solid_Crab_4748">Solid_Crab_4748</a><span></span> <span title="6">6 points</span><span title="7">7 points</span><span title="8">8 points</span> <time title="Mon Oct 20 19:10:34 2025 UTC" datetime="2025-10-20T19:10:34+00:00">19 minutes ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkhij1i599"><div><p>Nobody goes to check on someone after they haven't said something in a day</p>

<p>There are also signs in some of how he spoke more recently and for those who really payed attention you could tell he was struggling.</p>

<p>I sure do hope so. And I don't think speculating helps tbf but there's a lot more to suggest one way than the other :(</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhij1i/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nkhhqfi" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nkh96ir" onclick="click_thing(this)" data-fullname="t1_nkh96ir" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="__Jimmy__" data-author-fullname="t2_z9rec" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkh96ir/"><p>[–]<a href="https://old.reddit.com/user/ChaoticBoltzmann">ChaoticBoltzmann</a><span></span> <span title="47">47 points</span><span title="48">48 points</span><span title="49">49 points</span> <time title="Mon Oct 20 17:32:21 2025 UTC" datetime="2025-10-20T17:32:21+00:00">1 hour ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkhan31nzv"><div><p>He was easily the most passionate, deliberate, masterful teacher of Chess.</p>

<p>With Danya, you could believe that if you had spent the time and given the effort, you, too, could reach the levels of mastery that he effortlessly displayed.</p>

<p>He was a gentlemen of the highest caliber, an ambassador for the game, and he will forever be remembered as such.</p>

<p>Life is fragile folks, ...</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhan31/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#nkh9qno" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nkhb0nd" onclick="click_thing(this)" data-fullname="t1_nkhb0nd" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="daynighttrade" data-author-fullname="t2_b5v0spvp" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhb0nd/"><p>[–]<a href="https://old.reddit.com/user/daynighttrade">daynighttrade</a><span></span> <span title="23">23 points</span><span title="24">24 points</span><span title="25">25 points</span> <time title="Mon Oct 20 17:42:31 2025 UTC" datetime="2025-10-20T17:42:31+00:00">1 hour ago</time>&nbsp;(3 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkhb0nd9ax"><div><p>I'm shattered. I can't imagine the pain his loved ones, friends and family would be feeling. Such a bright person passing away, and living his last days of his life under mental agony. I wanted him to bounce back so much, that I'm having difficulty processing this news.  </p>

<p>I hope people take some lesson from this. It's very easy to be a keyboard warrior behind anonymity cloak, but there's a real person at the other end.</p>

<p>I also hope Kramnik realizes what he's done and stops his baseless allegations.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhb0nd/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nkhbkpw" onclick="click_thing(this)" data-fullname="t1_nkhbkpw" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="01_vampyr" data-author-fullname="t2_1zwg66hpu4" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhbkpw/"><p>[–]<a href="https://old.reddit.com/user/01_vampyr">01_vampyr</a><span></span> <span title="16">16 points</span><span title="17">17 points</span><span title="18">18 points</span> <time title="Mon Oct 20 17:57:54 2025 UTC" datetime="2025-10-20T17:57:54+00:00">1 hour ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkhbkpwz8v"><div><p>Danya was THE "everyday person" to be able to compete at the absolute highest level (if not above). He would regularly destroy the top of the crop in online chess, and would do so while showing emotion, entertaining viewers, and making humble content for beginners.</p>

<p>To be completely honest, I was first attracted to his streams by his fits of rage on stream... partly because they were funny, but partly also because it was relatable, and "normalized" a chess GM. Once he said he got control of it, his content got even better, and I noticed that he quickly became not just the biggest Chess streamer (I'm certain he was for several years), but one of the biggest streamers on Twitch. Like, he went from a "uni kid" raging for slipping pieces etc during games in between uni-classes, to netting $100k+/month streaming and being positive. And on top of displaying the highest level of chess on streams, he would, like I said, make beginner content, commentate tournaments, etc.</p>

<p>Never did he shill any crappy products (or far below that, like unregulated gamba, like some of the other top GM's like Hikaru), and never did it seem like any of his success got to his head. He didn't "minmax" his streams by only focusing on drama or whatever would from time to time boost Chess interest. He always did what originally got people interested in him, and what he actually wanted to do.</p>

<p>I don't know the details, but I'd be shocked if this <em>wasn't</em> suicide. Something just tells me that it was, everything into consideration. It's just so sad. The world has truly lost out on a great person, a great influencer (if you can even believe those can exist in today's world), and for chess, an irreplicable asset.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhbkpw/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nkhac78" onclick="click_thing(this)" data-fullname="t1_nkhac78" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="Particular_Text17" data-author-fullname="t2_1ljmklf18n" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhac78/"><p>[–]<a href="https://old.reddit.com/user/Particular_Text17">Particular_Text17</a><span></span> <span title="5">5 points</span><span title="6">6 points</span><span title="7">7 points</span> <time title="Mon Oct 20 17:23:58 2025 UTC" datetime="2025-10-20T17:23:58+00:00">2 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkhac78qk4"><div><p>Shocking. Had a shiver down my spine reading this.</p>

<p>I've been watching Danya ever since his days at Stanford streaming from his dorm and classrooms. Very bright, had every door open back then.</p>

<p>He always had some minor mental health issues (e.g. destroying objects, raging really hard) and was staying up super late every night, but nothing unusual for other gamers too, to be fair. People found his antics funny, his chat was memeing mostly.</p>

<p>Really hard to tell what happened. Something must've derailed really badly. Probably something personal, not even connected to chess or his career.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhac78/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_nkhed7l" onclick="click_thing(this)" data-fullname="t1_nkhed7l" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="youwin10" data-author-fullname="t2_6iw43kjn" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhed7l/"><p>[–]<a href="https://old.reddit.com/user/youwin10">youwin10</a><span></span> <span title="7">7 points</span><span title="8">8 points</span><span title="9">9 points</span> <time title="Mon Oct 20 18:43:50 2025 UTC" datetime="2025-10-20T18:43:50+00:00">46 minutes ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkhed7luby"><div><p>His family should destroy Kramnik now.   </p>

<p>They should lawsuit the shit out of him and destroy whatever is left of his reputation.</p>

<p>They should take everything, it's still not gonna be enough.</p>

<p>This is one of the most disgusting, evil, unholy things I've even seen in my life.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkhed7l/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="siteTable_deleted" onclick="click_thing(this)" data-fullname="t1_nkh9m1q" data-type="comment" data-gildings="0" data-subreddit="chess" data-subreddit-prefixed="r/chess" data-subreddit-fullname="t5_2qhr7" data-subreddit-type="public" data-author="JustinSlick" data-author-fullname="t2_6qwv2" data-replies="0" data-permalink="/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkh9cmp/"><p>[–]<a href="https://old.reddit.com/user/JustinSlick">JustinSlick</a><span></span> <span title="12">12 points</span><span title="13">13 points</span><span title="14">14 points</span> <time title="Mon Oct 20 17:02:22 2025 UTC" datetime="2025-10-20T17:02:22+00:00">2 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkh9m1qrk7"><div><p>Post was from @charlottechesscenter - as far as I know nobody else has reported it. </p>

<blockquote>
<p>It is with great sadness that we share the unexpected passing of Daniel Naroditsky. Daniel was a talented chess player, educator, and cherished member of the chess community. He was also a loving son, brother, and loyal friend. </p>

<p>We ask for privacy for Daniel’s family during this extremely difficult time. Let us honor Daniel by remembering his passion for chess and the inspiration he brought to us all.</p>
</blockquote>
</div></form><ul><li><a href="https://old.reddit.com/r/chess/comments/1obnbmu/grandmaster_daniel_naroditsky_has_passed_away/nkh9m1q/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Production RAG: what I learned from processing 5M+ documents (305 pts)]]></title>
            <link>https://blog.abdellatif.io/production-rag-processing-5m-documents</link>
            <guid>45645349</guid>
            <pubDate>Mon, 20 Oct 2025 15:55:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.abdellatif.io/production-rag-processing-5m-documents">https://blog.abdellatif.io/production-rag-processing-5m-documents</a>, See on <a href="https://news.ycombinator.com/item?id=45645349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><p>October 20, 2025<!-- --> • <!-- -->3 min read</p><article><p>I've spent the last 8 months in the RAG trenches, I want to share what actually worked vs. wasted our time. We built RAG for Usul AI (9M pages) and an unnamed legal AI enterprise (4M pages).</p>
<h2 id="langchain-llamaindex"><a href="#langchain-llamaindex"></a>Langchain + Llamaindex</h2>
<p>We started out with youtube tutorials. First Langchain → Llamaindex. Got to a working prototype in a couple of days and were optimistic with the progress. We run tests on subset of the data (100 documents) and the results looked great. We spent the next few days running the pipeline on the production dataset and got everything working in a week — incredible.</p>
<p>Except it wasn't, the results were subpar and only the end users could tell. We spent the following few months rewriting pieces of the system, one at a time, until the performance was at the level we wanted. Here are things we did ranked by ROI.</p>
<h2 id="what-moved-the-needle"><a href="#what-moved-the-needle"></a>What moved the needle</h2>
<ol>
<li><strong>Query Generation</strong>: not all context can be captured by the user's last query. We had an LLM review the thread and generate a number of semantic + keyword queries. We processed all of those queries in parallel, and passed them to a reranker. This made us cover a larger surface area and not be dependent on a computed score for hybrid search.</li>
<li><strong>Reranking</strong>: the highest value 5 lines of code you'll add. The chunk ranking shifted <em>a lot</em>. More than you'd expect. Reranking can many times make up for a bad setup if you pass in enough chunks. We found the ideal reranker set-up to be 50 chunk input -&gt; 15 output.</li>
<li><strong>Chunking Strategy</strong>: this takes a lot of effort, you'll probably be spending most of your time on it. We built a custom flow for both enterprises, make sure to understand the data, review the chunks, and check that a) chunks are not getting cut mid-word or sentence b) ~each chunk is a logical unit and captures information on its own</li>
<li><strong>Metadata to LLM</strong>: we started by passing the chunk text to the LLM, we ran an experiment and found that injecting relevant metadata as well (title, author, etc.) improves context and answers by a lot.</li>
<li><strong>Query routing</strong>: many users asked questions that can't be answered by RAG (e.g. summarize the article, who wrote this). We created a small router that detects these questions and answers them using an API call + LLM instead of the full-blown RAG set-ups.</li>
</ol>
<h2 id="our-stack"><a href="#our-stack"></a>Our stack</h2>
<ul>
<li><strong>Vector database</strong>: Azure -&gt; Pinecone -&gt; Turbopuffer (cheap, supports keyword search natively)</li>
<li><strong>Document Extraction</strong>: Custom</li>
<li><strong>Chunking</strong>: Unstructured.io by default, custom for enterprises (heard that Chonkie is good)</li>
<li><strong>Embedding</strong>: text-embedding-large-3, haven't tested others</li>
<li><strong>Reranker</strong>: None -&gt; Cohere 3.5 -&gt; Zerank (less known but actually good)</li>
<li><strong>LLM</strong>: GPT 4.1 -&gt; GPT 5 -&gt; GPT 4.1, covered by Azure credits</li>
</ul>
<h2 id="going-open-source"><a href="#going-open-source"></a>Going Open-source</h2>
<p>We put all our learning into an open-source project: <a target="_blank" rel="noopener noreferrer" href="https://github.com/agentset-ai/agentset">agentset-ai/agentset</a> under an MIT license. Feel free to <a target="_blank" rel="noopener noreferrer" href="mailto:abdellatif@agentset.ai">reach out</a> if you have any questions.</p></article></section><!--$--><!--/$--><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Postman which I thought worked locally on my computer, is down (245 pts)]]></title>
            <link>https://status.postman.com</link>
            <guid>45645172</guid>
            <pubDate>Mon, 20 Oct 2025 15:40:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://status.postman.com">https://status.postman.com</a>, See on <a href="https://news.ycombinator.com/item?id=45645172">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div>
                  <p><strong>Update</strong> - <span>We have seen significant recovery of the features. We are continuing to monitor for any further issues.</span>
                    <br>
                      <small><span data-datetime-unix="1760973602000"></span>Oct <var data-var="date">20</var>, <var data-var="year">2025</var> - <var data-var="time">08:20</var> PDT</small>
                  </p>
                  <p><strong>Monitoring</strong> - <span>Majority of the services have recovered. We are continuing to monitor.</span>
                    <br>
                      <small><span data-datetime-unix="1760966473000"></span>Oct <var data-var="date">20</var>, <var data-var="year">2025</var> - <var data-var="time">06:21</var> PDT</small>
                  </p>
                  <p><strong>Update</strong> - <span>We are seeing significant recovery and are continuing to monitor.</span>
                    <br>
                      <small><span data-datetime-unix="1760965004000"></span>Oct <var data-var="date">20</var>, <var data-var="year">2025</var> - <var data-var="time">05:56</var> PDT</small>
                  </p>
                  <p><strong>Update</strong> - <span>We are seeing significant recovery and are continuing to monitor.</span>
                    <br>
                      <small><span data-datetime-unix="1760964720000"></span>Oct <var data-var="date">20</var>, <var data-var="year">2025</var> - <var data-var="time">05:52</var> PDT</small>
                  </p>
                  <p><strong>Identified</strong> - <span>We are currently experiencing significantly increased error rates which is impacting functionality on Postman. There is a major issue with our underlying cloud provider and we are working with them to restore full access as quickly as possible.</span>
                    <br>
                      <small><span data-datetime-unix="1760963977000"></span>Oct <var data-var="date">20</var>, <var data-var="year">2025</var> - <var data-var="time">05:39</var> PDT</small>
                  </p>
              </div>



        <div>
      
    <div>
          <div>
      
<div data-component-id="myy1xf2243k7" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Platform on Desktop
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Desktop application for Windows, Mac &amp;amp; Linux to help you build, test &amp;amp; manage your APIs." data-original-title="Desktop application for Windows, Mac &amp;amp; Linux to help you build, test &amp;amp; manage your APIs." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="yd763bkzgtgp" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Platform on Browser
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Postman experience on the web such as working within a workspace, sending requests, etc" data-original-title="Postman experience on the web such as working within a workspace, sending requests, etc" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="6p1fq1q27p48" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Login
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Signing up, signing in to your Postman Account on your browser or when using the desktop applications." data-original-title="Signing up, signing in to your Postman Account on your browser or when using the desktop applications." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="2qwj5yj4dd1p" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Monitors
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Run your collections &amp;amp; environments in the Postman Cloud to monitor your API uptime, health &amp;amp; response." data-original-title="Run your collections &amp;amp; environments in the Postman Cloud to monitor your API uptime, health &amp;amp; response." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="4rvnts3yqmcr" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Mocks
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="API mocking service using your collections as a backing store." data-original-title="API mocking service using your collections as a backing store." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="zgyq9tfp50r8" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman API
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="api.getpostman.com service that lets you programmatically access all your data stored on Postman Cloud" data-original-title="api.getpostman.com service that lets you programmatically access all your data stored on Postman Cloud" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="k14n5hnrpqss" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman API Network (API Explore)
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Platform for the distribution of collections, allowing for easy &amp;amp; quick access to your APIs." data-original-title="Platform for the distribution of collections, allowing for easy &amp;amp; quick access to your APIs." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      


      
<div data-component-id="pb0wgwm8s804" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Search
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="This component serves search results on Postman Application." data-original-title="This component serves search results on Postman Application." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="z20p2dbm7l9c" data-component-status="operational" data-js-hook="">

   <p><span>
      Public Collection Documentation
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Published documentation served from documenter.getpostman.com or your own custom domain." data-original-title="Published documentation served from documenter.getpostman.com or your own custom domain." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      


      
<div data-component-id="xbbdyty488ls" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Learning Center and Documentation
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Sub-parts of postman.com domain that deals with documentation and pages around the Postman product along with wiki and knowledge-base on https://learning.postman.com" data-original-title="Sub-parts of postman.com domain that deals with documentation and pages around the Postman product along with wiki and knowledge-base on https://learning.postman.com" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="8gbj8vqp6q0v" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Support and  Community Forum
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Postman support subsystem at https://support.postman.com/ and https://community.postman.com" data-original-title="Postman support subsystem at https://support.postman.com/ and https://community.postman.com" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="1v2l8kpl7blf" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Integrations
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="All integrations outlined at https://www.postman.com/integrations/" data-original-title="All integrations outlined at https://www.postman.com/integrations/" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="8rvcdymgz9dr" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Interceptor
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="4h2f09y1y6gw" data-component-status="operational" data-js-hook="">

   <p><span>
      Marketing Website
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Static content that is marketing related and served via www.postman.com.  This includes www.postman.com/downloads/, https://www.postman.com/release-notes/, and www.postman.com/pricing/." data-original-title="Static content that is marketing related and served via www.postman.com.  This includes www.postman.com/downloads/, https://www.postman.com/release-notes/, and www.postman.com/pricing/." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      


      
<div data-component-id="mbqgc0cwjyf4" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman VS Code extension
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="The Postman VS Code extension enables you to develop and test your APIs in Postman directly from Visual Studio Code." data-original-title="The Postman VS Code extension enables you to develop and test your APIs in Postman directly from Visual Studio Code." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="tpym246hbkmn" data-component-status="operational" data-js-hook="">

   <p><span>
      API Builder
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Create and manage APIs within your workspace" data-original-title="Create and manage APIs within your workspace" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="1wj634bs58jp" data-component-status="operational" data-js-hook="">

   <p><span>
      API Specifications
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Create and manage Specifications within a workspace, generating collections from specification" data-original-title="Create and manage Specifications within a workspace, generating collections from specification" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="x08ythhdpfvx" data-component-status="operational" data-js-hook="">

   <p><span>
      Collection Runner
   </span>


  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      


  </div>

          <div>
      
<div data-component-id="gtytnqfzhhq1" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Platform on Desktop
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Desktop application for Windows, Mac &amp;amp; Linux to help you build, test &amp;amp; manage your APIs." data-original-title="Desktop application for Windows, Mac &amp;amp; Linux to help you build, test &amp;amp; manage your APIs." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="ry1cld662pcm" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Platform on Browser
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Postman experience on the web such as working within a workspace, sending requests, etc" data-original-title="Postman experience on the web such as working within a workspace, sending requests, etc" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="2tqmljfrlmhx" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Login
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="Signing up, signing in to your Postman Account on your browser or when using the desktop applications." data-original-title="Signing up, signing in to your Postman Account on your browser or when using the desktop applications." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="s6f85vsfgs0d" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Mocks
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="API mocking service using your collections as a backing store." data-original-title="API mocking service using your collections as a backing store." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="3vjknn1q8nsm" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman API
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="api.getpostman.com service that lets you programmatically access all your data stored on Postman Cloud" data-original-title="api.getpostman.com service that lets you programmatically access all your data stored on Postman Cloud" role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

      
<div data-component-id="bv6g2w5c9bvy" data-component-status="operational" data-js-hook="">

   <p><span>
      Postman Search
   </span>

    <span data-js-hook="tooltip" tabindex="0" aria-label="This component serves search results on Postman Application." data-original-title="This component serves search results on Postman Application." role="tooltip">?</span>

  <span title="">

    Operational

  </span>

  <span title="Operational"></span></p>

</div>

  </div>

    </div>
    <div>
  <p><span></span>
    Operational
  </p>
  <p><span></span>
    Degraded Performance
  </p>
  <p><span></span>
    Partial Outage
  </p>
  
  <p><span></span>
    Major Outage
  </p>
  <p><span></span>
    Maintenance
  </p>
</div>

  </div>

    

    








        


      <div>
        <h2 id="past-incidents">Past Incidents</h2>
          
  <div>
    <p>Oct <var data-var="date">20</var>, <var data-var="year">2025</var></p>
      <p>Unresolved incident: Users may encounter issues with accessing or using Postman.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">19</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">18</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">17</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">16</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">15</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">14</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">13</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">12</var>, <var data-var="year">2025</var></p>
          <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <p><strong>Completed</strong> -
      	<span>The scheduled maintenance has been completed.</span>

        <br>

        <small>
            Oct <var data-var="date">12</var>, <var data-var="time">08:52</var> PDT
        </small>
      </p>
      <p><strong>Verifying</strong> -
      	<span>Verification is currently underway for the maintenance items.</span>

        <br>

        <small>
            Oct <var data-var="date">12</var>, <var data-var="time">08:49</var> PDT
        </small>
      </p>
      <p><strong>In progress</strong> -
      	<span>Scheduled maintenance is currently in progress. We will provide updates as necessary.</span>

        <br>

        <small>
            Oct <var data-var="date">12</var>, <var data-var="time">08:00</var> PDT
        </small>
      </p>
      <p><strong>Scheduled</strong> -
      	<span>We will be performing a planned database upgrade in the US data centre to ensure the latest version and security patches are applied. During this time, users with data in US region may experience temporary service disruptions while using Postman across all platforms.<p>Maintenance is expected to last approximately 2 hours and we will provide regular updates on the progress. Please note, this downtime only affects users with data in US region. Services for users in our EU data centre will remain unaffected.</p><p>If you have any questions, please don't hesitate to reach out to our support team at <a target="_blank" href="mailto:support@postman.com">support@postman.com</a>. <br>We appreciate your patience and understanding during this maintenance window.</p></span>

        <br>

        <small>
            Oct <var data-var="date"> 9</var>, <var data-var="time">06:30</var> PDT
        </small>
      </p>
  </div>

  </div>

          
  <div>
    <p>Oct <var data-var="date">11</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date">10</var>, <var data-var="year">2025</var></p>
          <div>
    <!-- postmortem -->

    <!-- incident updates -->
      <p><strong>Completed</strong> -
      	<span>Scheduled database maintenance has been successfully completed.</span>

        <br>

        <small>
            Oct <var data-var="date">10</var>, <var data-var="time">21:40</var> PDT
        </small>
      </p>
      <p><strong>Verifying</strong> -
      	<span>We are in the process of verifying the maintenance items.</span>

        <br>

        <small>
            Oct <var data-var="date">10</var>, <var data-var="time">21:23</var> PDT
        </small>
      </p>
      <p><strong>In progress</strong> -
      	<span>Scheduled maintenance is currently in progress. We will provide updates as necessary.</span>

        <br>

        <small>
            Oct <var data-var="date">10</var>, <var data-var="time">20:30</var> PDT
        </small>
      </p>
      <p><strong>Scheduled</strong> -
      	<span>We have a scheduled database maintenance coming up to enable upgrades to the service. Users may experience intermittent service disruptions when doing collection runs via Collection Runner or Postman CLI. Postman Monitors and Scheduled Collections will remain unaffected. We expect to complete maintenance within two hours and will provide frequent updates throughout the process.<p>Contact our support team at <a target="_blank" href="mailto:support@postman.com">support@postman.com</a> with any questions.<br>We appreciate your patience during this maintenance window.</p></span>

        <br>

        <small>
            Oct <var data-var="date"> 7</var>, <var data-var="time">09:15</var> PDT
        </small>
      </p>
  </div>

  </div>

          
  <div>
    <p>Oct <var data-var="date"> 9</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date"> 8</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date"> 7</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

          
  <div>
    <p>Oct <var data-var="date"> 6</var>, <var data-var="year">2025</var></p>
        <p>No incidents reported.</p>
  </div>

      </div>


      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How much Anthropic and Cursor spend on Amazon Web Services (146 pts)]]></title>
            <link>https://www.wheresyoured.at/costs/</link>
            <guid>45644777</guid>
            <pubDate>Mon, 20 Oct 2025 15:05:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/costs/">https://www.wheresyoured.at/costs/</a>, See on <a href="https://news.ycombinator.com/item?id=45644777">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
          <p>So, I originally planned for this to be on my premium newsletter, but decided it was better to publish on my free one so that you could all enjoy it. If you liked it, please consider subscribing to support my work. <a href="https://edzitronswheresyouredatghostio.outpost.pub/public/promo-subscription/28fs01k51c?ref=wheresyoured.at"><u>Here’s $10 off the first year of annual</u></a>.</p><p>I’ve also recorded an episode about this on my podcast Better Offline (<a href="https://www.omnycontent.com/d/playlist/e73c998e-6e60-432f-8610-ae210140c5b1/cf0c25ad-cf01-4da5-ae1c-b0fc015f790e/53ed270b-7147-4f70-81c2-b0fc015fe4ed/podcast.rss?ref=wheresyoured.at"><u>RSS feed</u></a>, <a href="https://podcasts.apple.com/us/podcast/better-offline/id1730587238?i=1000732667889&amp;ref=wheresyoured.at" rel="noreferrer">Apple</a>, <a href="https://open.spotify.com/episode/5Tyqfmo2EIIj2IzzQl9z1Z?ref=wheresyoured.at" rel="noreferrer">Spotify</a>, <a href="https://podcasts.apple.com/us/podcast/better-offline/id1730587238?i=1000732667889&amp;ref=wheresyoured.at" rel="noreferrer">iHeartRadio</a>), it’s a little different but both handle the same information, just subscribe and it'll pop up.&nbsp;</p><hr><p>Over the last two years I have written <a href="https://www.wheresyoured.at/the-haters-gui/#companies-built-on-top-of-large-language-models-dont-make-much-money-in-fact-theyre-likely-all-deeply-unprofitable"><u>again</u></a> and <a href="https://www.wheresyoured.at/why-everybody-is-losing-money-on-ai/"><u>again</u></a> about the ruinous costs of running generative AI services, and today I’m coming to you with real proof.</p><p>Based on discussions with sources with direct knowledge of their AWS billing, I am able to disclose the amounts that AI firms are spending, specifically Anthropic and AI coding company Cursor, <a href="https://www.vincentschmalbach.com/cursor-is-anthropics-largest-customer-and-maxing-out-their-gpus/?ref=wheresyoured.at"><u>its largest customer</u></a>.</p><p>I can exclusively reveal today Anthropic’s spending on Amazon Web Services for the entirety of 2024, and for every month in 2025 up until September, and that that Anthropic’s spend on compute far exceeds that previously reported.&nbsp;</p><p>Furthermore, I can confirm that <strong>through September, Anthropic has spent more than 100% of its estimated revenue (based on reporting in the last year) on Amazon Web Services, spending $2.66 billion on compute on an estimated $2.55 billion in revenue.</strong></p><p>Additionally, Cursor’s Amazon Web Services bills more than doubled from $6.2 million in May 2025 to $12.6 million in June 2025, exacerbating a cash crunch that began when Anthropic introduced Priority Service Tiers, <a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>an aggressive rent-seeking measure that begun what I call the Subprime AI Crisis</u></a>, where model providers begin jacking up the prices on their previously subsidized rates.</p><p>Although Cursor obtains the majority of its compute from Anthropic — with AWS contributing a relatively small amount, and likely also taking care of other parts of its business — the data seen reveals an overall direction of travel, where the costs of compute <em>only keep on going up</em>.&nbsp;</p><p>Let’s get to it.</p><h2 id="some-initial-important-details">Some Initial Important Details</h2><ul><li><strong>I do not have all the answers!</strong> I am going to do my best to go through the information I’ve obtained and give you a thorough review and analysis. This information provides a revealing — though incomplete — insight into the costs of running Anthropic and Cursor, but does not include other costs, like salaries and compute obtained from other providers. I cannot tell you (and do not have insight into) Anthropic’s actual private moves. Any conclusions or speculation I make in this article will be based on my interpretations of the information I’ve received, as well as other publicly-available information.</li><li>I have used estimates of Anthropic’s revenue based on reporting across the last ten months. Any estimates I make are detailed and they are brief.&nbsp;</li><li><strong>These costs are inclusive of every product bought on Amazon Web Services, including EC2, storage and database services (as well as literally everything else they pay for).</strong></li><li>Anthropic works with both Amazon Web Services and Google Cloud for compute. I do not have any information about its Google Cloud spend.<ul><li>The reason I bring this up is that Anthropic’s revenue is already being eaten up by its AWS spend. It’s likely billions <em>more</em> in the hole from Google Cloud and other operational expenses.</li></ul></li><li>I have confirmed with sources that every single number I give around Anthropic and Cursor’s AWS spend is <strong>the final cash paid to Amazon after any discounts or credits.</strong></li><li>While I cannot disclose the identity of my source, I am 100% confident in these numbers, and have verified their veracity with other sources. </li></ul><h2 id="anthropic%E2%80%99s-compute-costs-are-likely-much-higher-than-reported-%E2%80%94-135-billion-in-2024-on-aws-alone">Anthropic’s Compute Costs Are Likely Much Higher Than Reported — $1.35 Billion in 2024 on AWS Alone</h2><p>In February of this year, <a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The information reported</u></a> that Anthropic burned $5.6 billion in 2024, and made somewhere between $400 million and $600 million in revenue:</p><blockquote>It’s not publicly known how much revenue Anthropic generated in 2024, although its monthly revenue rose to about $80 million by the end of the year, compared to around $8 million at the start. That suggests full-year revenue in the $400 million to $600 million range.<p>…Anthropic told investors it expects to burn $3 billion this year, substantially less than last year, when it burned $5.6 billion. Last year’s cash burn was nearly $3 billion more than Anthropic had previously projected. That’s likely due to the fact that more than half of the cash burn came from a one-off payment to access the data centers that power its technology, according to one of the people who viewed the pitch.</p></blockquote><p>While I don’t know about prepayment for services, I can confirm from a source with direct knowledge of billing that Anthropic spent $1.35 billion on Amazon Web Services in 2024, and has already spent $2.66 billion on Amazon Web Services through the end of September.</p><p>Assuming that Anthropic made $600 million in revenue, this means that Anthropic spent $6.2 billion in 2024, leaving $4.85 billion in costs unaccounted for.&nbsp;</p><p>The Information’s piece also brings up another point:</p><blockquote>The costs to develop AI models accounted for a major portion of Anthropic’s expenses last year. The company spent $1.5 billion on servers for training AI models. OpenAI was on track to spend as much as $3 billion on training costs last year, though that figure includes additional expenses like paying for data.</blockquote><p>Before I go any further, I want to be clear that The Information’s reporting is sound, and I trust that their source (I have no idea who they are or what information was provided) was operating in good faith with good data. </p><p>However, Anthropic is telling people it spent $1.5 billion on <em>just</em> training when it has an Amazon Web Services bill of $1.35 billion, which heavily suggests that its actual compute costs are significantly higher than we thought, because, to quote SemiAnalysis, “<a href="https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion?ref=wheresyoured.at#:~:text=A%20large%20share%20of%20Anthropic%E2%80%99s%20spending%20is%20going%20to%20Google%20Cloud%20%E2%80%93%20one%20of%20Anthropic%E2%80%99s%20first%20major%20investors%20(%24300M%20round%20late%2D2022)%20and%20preferred%20cloud%20partner%20in%202023%20and%202024%2C%20before%20the%20expanded%20AWS%20deal."><u>a large share of Anthropic’s spending is going to Google Cloud</u></a>.”&nbsp;</p><p>I am guessing, because I do not know, but with $4.85 billion of other expenses to account for, it’s reasonable to believe Anthropic spent an amount similar to its AWS spend on Google Cloud. I do not have any information to confirm this, but given the discrepancies mentioned above, this is an explanation that makes sense.</p><p>I also will add that there is some sort of undisclosed cut that Amazon gets of Anthropic’s revenue, though it’s unclear how much. <a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>According to The Information</u></a>, “Anthropic previously told some investors it paid a substantially higher percentage to Amazon [than OpenAI’s 20% revenue share with Microsoft] when companies purchase Anthropic models through Amazon.”</p><p>I cannot confirm whether a similar revenue share agreement exists between Anthropic and Google.</p><p>This also makes me wonder exactly where Anthropic’s money is going.</p><h2 id="where-is-anthropic%E2%80%99s-money-going">Where Is Anthropic’s Money Going?</h2><p>Anthropic has, based on what I can find, raised $32 billion in the last two years, starting out&nbsp;2023 with <a href="https://www.aboutamazon.com/news/company-news/amazon-aws-anthropic-ai?ref=wheresyoured.at"><u>a $4 billion investment from Amazon from September 2023</u></a> (bringing the total to $37.5 billion), where Amazon was named its “primary cloud provider” nearly eight months after <a href="https://www.cnbc.com/2025/01/22/google-agrees-to-new-1-billion-investment-in-anthropic.html?ref=wheresyoured.at"><u>Anthropic announced Google was Anthropic’s “cloud provider.,”</u></a> which <a href="https://www.cnbc.com/2023/10/27/google-commits-to-invest-2-billion-in-openai-competitor-anthropic.html?ref=wheresyoured.at"><u>Google responded to a month later by investing another $2 billion on October 27 2023</u></a>, “involving a $500 million upfront investment and an additional $1.5 billion to be invested over time,” bringing its total funding from 2023 to $6 billion.</p><p>In 2024, it would raise several more rounds — one in January for $750 million, another in March for $884.1 million, another in May for $452.3 million, and <a href="https://www.anthropic.com/news/anthropic-amazon-trainium?ref=wheresyoured.at"><u>another $4 billion from Amazon in November 2024</u></a>, which also saw it name AWS as Anthropic’s “primary cloud and training partner,” bringing its 2024 funding total to $6 billion.</p><p>In 2025 so far, it’s raised <a href="https://www.cnbc.com/2025/01/22/google-agrees-to-new-1-billion-investment-in-anthropic.html?ref=wheresyoured.at"><u>a $1 billion round from Google</u></a>, <a href="https://techcrunch.com/2025/03/03/anthropic-raises-3-5b-to-fuel-its-ai-ambitions/?ref=wheresyoured.at"><u>a $3.5 billion venture round</u></a> in March, opened <a href="https://www.cnbc.com/2025/05/16/anthropic-ai-credit-facility.html?ref=wheresyoured.at"><u>a $2.5 billion credit facility</u></a> in May, and completed <a href="https://www.cnbc.com/2025/09/02/anthropic-raises-13-billion-at-18-billion-valuation.html?ref=wheresyoured.at"><u>a $13 billion venture round in September, valuing the company at $183 billion</u></a>. This brings its total 2025 funding to $20 billion.&nbsp;</p><p>While I do not have Anthropic’s 2023 numbers, its spend on AWS in 2024 — around $1.35 billion — leaves (as I’ve mentioned) $4.85 billion in costs that are unaccounted for. The Information reports that <a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>costs for Anthropic’s 521 research and development staff reached $160 million in 2024</u></a>, leaving 394 other employees unaccounted for (for 915 employees total), and also adding that Anthropic expects its headcount to increase to 1900 people by the end of 2025.</p><p>The Information also adds that Anthropic “expects to stop burning cash in 2027.”</p><p>This leaves two unanswered questions:</p><ul><li>Where is the rest of Anthropic’s money going?</li><li>How will it “stop burning cash” when its operational costs explode as its revenue increases?</li></ul><p>An optimist might argue that Anthropic is just growing its pile of cash so it’s got a warchest to burn through in the future, but I have my doubts. <a href="https://www.wired.com/story/anthropic-dario-amodei-gulf-state-leaked-memo/?ref=wheresyoured.at"><u>In a memo revealed by WIRED</u></a>, Anthropic CEO Dario Amodei stated that “if [Anthropic wanted] to stay on the frontier, [it would] gain a very large benefit from having access to this capital,” with “this capital” referring to money from the Middle East.&nbsp;</p><p>Anthropic and Amodei’s sudden willingness to take large swaths of capital from the Gulf States does not suggest that it’s not at least a <em>little</em> desperate for capital, especially given Anthropic has, <a href="https://archive.ph/t2HiF?ref=wheresyoured.at"><u>according to Bloomberg</u></a>, “recently held early funding talks with Abu Dhabi-based investment firm MGX” <a href="https://www.cnbc.com/2025/09/02/anthropic-raises-13-billion-at-18-billion-valuation.html?ref=wheresyoured.at"><u>a month after raising $13 billion</u></a>.</p><p>In my opinion — and this is just my gut instinct — I believe that it is either significantly more expensive to run Anthropic than we know, or Anthropic’s leaked (and stated) revenue numbers are worse than we believe. I do not know one way or another, and will only report what I know.</p><h2 id="how-much-did-anthropic-and-cursor-spend-on-amazon-web-services-in-2025">How Much Did Anthropic and Cursor Spend On Amazon Web Services In 2025?</h2><p>So, I’m going to do this a little differently than you’d expect, in that I’m going to lay out how much these companies spent, and draw throughlines from that spend to its reported revenue numbers and product announcements or events that may have caused its compute costs to increase.</p><p>I’ve only got Cursor’s numbers from January through September 2025, but I have Anthropic’s AWS spend for both the entirety of 2024 and through September 2025.</p><h2 id="what-does-%E2%80%9Cannualized%E2%80%9D-mean">What Does “Annualized” Mean?</h2><p>So, this term is one of the most abused terms in the world of software, <em>but in this case</em>, I am sticking to the idea that it means “month times 12.” So, if a company made $10m in January, you would say that its annualized revenue is $120m. Obviously, there’s a lot of (when you think about it, really obvious) problems with this kind of reporting — and thus, you only ever see it when it comes to pre-IPO firms — but that’s besides the point.</p><p>I give you this explanation because, when contrasting Anthropic’s AWS spend with its revenues, I’ve had to work back from whatever annualized revenues were reported for that month.&nbsp;</p><h2 id="anthropic%E2%80%99s-amazon-web-services-spend-in-20241359-billionestimated-revenue-400-million-to-600-million">Anthropic’s Amazon Web Services Spend In 2024 - $1.359 Billion - Estimated Revenue $400 Million to $600 Million</h2><p>Anthropic’s 2024 revenues are a little bit of a mystery, but, as mentioned above, <a href="https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?ref=wheresyoured.at"><u>The Information</u></a> says it might be between $400 million and $600 million.</p><p>Here’s its monthly AWS spend.&nbsp;</p><ul><li>January 2024 - $52.9 million</li><li>February 2024 - $60.9 million</li><li>March 2024 - $74.3 million</li><li>April 2024 - $101.1 million</li><li>May 2024 - $100.1 million</li><li>June 2024 - $101.8 million</li><li>July 2024 - $118.9 million</li><li>August 2024 - $128.8 million</li><li>September 2024 - $127.8 million</li><li>October 2024 - $169.6 million</li><li>November 2024 - $146.5 million</li><li>December 2024 - $176.1 million</li></ul><h2 id="analysis-anthropic-spent-at-least-200-of-its-2024-revenue-on-amazon-web-services-in-2024">Analysis: Anthropic Spent At Least 200% of Its 2024 Revenue On Amazon Web Services In 2024</h2><p>I’m gonna be <em>nice</em> here and say that Anthropic made $600 million in 2024 — the higher end of The Information’s reporting — meaning that it spent around 226% of its revenue ($1.359 billion) on Amazon Web Services.</p><p><strong>[Editor's note:</strong> this copy originally had incorrect maths on the %. Fixed now.]<strong> </strong></p><h2 id="anthropic%E2%80%99s-amazon-web-services-spend-in-2025-through-september-2025266-billionestimated-revenue-through-september-255-billion104-of-revenue-spent-on-aws">Anthropic’s Amazon Web Services Spend In 2025 Through September 2025 - $2.66 Billion - Estimated Revenue Through September $2.55 Billion - 104% Of Revenue Spent on AWS</h2><p><a href="https://www.wheresyoured.at/howmuchmoney/#anthropic-has-made-around-15-billion-through-july-in-2025-so-far-and-could-hit-9-billion-annualized-by-end-of-2025"><u>Thanks to my own analysis</u></a> and reporting from outlets like The Information and Reuters, we have a pretty good idea of Anthropic’s revenues for much of the year. That said, July, August, and September get a little weirder, because we’re relying on “almosts” and “approachings,” as I’ll explain as we go.</p><p>I’m also gonna do an analysis on a month-by-month basis, because it’s necessary to evaluate these numbers in context.&nbsp;</p><h3 id="january-20251885-million-in-aws-spend-7291-or-83-million-in-revenue227-of-revenue-spent-on-aws">January 2025 - $188.5 million In AWS Spend, $72.91 or $83 Million In Revenue - 227% Of Revenue Spent on AWS</h3><p>In this month, Anthropic’s reported revenue was somewhere from <a href="https://www.theinformation.com/articles/lightspeed-pays-a-pretty-penny-for-anthropic?ref=wheresyoured.at&amp;rc=kz8jh3"><u>$875 million</u></a> to <a href="https://www.cnbc.com/2025/03/03/amazon-backed-ai-firm-anthropic-valued-at-61point5-billion-after-latest-round.html?ref=wheresyoured.at"><u>$1 billion annualized</u></a>, meaning either $72.91 million or $83 million for the month of January.</p><h3 id="february-20251812-million-in-aws-spend-116-million-in-revenue156-of-revenue-spent-on-aws181-of-revenue-spent-on-aws">February 2025 - $181.2 million in AWS Spend, $116 Million In Revenue - 156% Of Revenue Spent On AWS - 181% Of Revenue Spent On AWS</h3><p>In February, <a href="https://www.theinformation.com/articles/anthropics-claude-drives-strong-revenue-growth-while-powering-manus-sensation?offer=exp-ann-25&amp;utm_campaign=Expansion%3A+AI+Agenda&amp;utm_content=7427&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=5088&amp;rc=kz8jh3"><u>as reported by The Information</u></a>, Anthropic hit $1.4 billion annualized revenue, or around $116 million each month.</p><h3 id="march-20252403-million-in-aws-spend166-million-in-revenue144-of-revenue-spent-on-awslaunch-of-claude-sonnet-37-claude-code-research-preview-february-24">March 2025 - $240.3 million in AWS Spend - $166 Million In Revenue - 144% Of Revenue Spent On AWS - Launch of Claude Sonnet 3.7 &amp; Claude Code Research Preview (February 24)</h3><p>In March, <a href="https://www.reuters.com/business/anthropic-hits-3-billion-annualized-revenue-business-demand-ai-2025-05-30/?ref=wheresyoured.at"><u>as reported by Reuters</u></a>, Anthropic hit $2 billion in annualized revenue, or $166 million in revenue.</p><p>Because February is a short month, and the launch took place on February 24 2025, I’m considering the <a href="https://www.anthropic.com/news/claude-3-7-sonnet?ref=wheresyoured.at"><u>launches of Claude 3.7 Sonnet and Claude Code’s research preview</u></a> to be a cost burden in the month of March.</p><p>And man, what a burden! Costs increased by $59.1 million, primarily across compute categories, but with a large ($2 million since January) increase in monthly costs for S3 storage.</p><h3 id="april-20252216-million-in-aws-spend204-million-in-revenue108-of-revenue-spent-on-aws">April 2025 - $221.6 million in AWS Spend - $204 Million In Revenue - 108% Of Revenue Spent On AWS</h3><p>I estimate, based on a 22.4% compound growth rate, that Anthropic hit around $2.44 billion in annualized revenue in April, or $204 million in revenue.</p><p>Interestingly, <a href="https://www.anthropic.com/news/max-plan?ref=wheresyoured.at"><u>this was the month where Anthropic launched its $100 and $200 dollar a month “Max” plan</u></a>s, and it doesn’t seem to have dramatically increased its costs. Then again, Max is also the gateway to things like Claude Code, which I’ll get to shortly.</p><h3 id="may-20252867-million-in-aws-spend250-million-in-revenue114-of-revenue-spent-on-awssonnet-4-opus-4-general-availability-of-claude-code-may-22-service-tiers-may-30">May 2025 - $286.7 million in AWS Spend - $250 Million In Revenue - 114% Of Revenue Spent On AWS - Sonnet 4, Opus 4, General Availability Of Claude Code (May 22) Service Tiers (May 30)</h3><p>In May, <a href="https://www.cnbc.com/2025/05/30/anthropic-hits-3-billion-in-annualized-revenue-on-business-demand-for-ai.html?ref=wheresyoured.at"><u>as reported by CNBC</u></a>, Anthropic hit $3 billion in annualized revenue, or $250 million in monthly average revenue.</p><p>This was a <em>big month</em> for Anthropic, with <a href="https://www.anthropic.com/news/claude-4?ref=wheresyoured.at"><u>two huge launches on May 22 2025</u></a> — its new, “more powerful” models Claude Sonnet and Opus 4, as well as the general availability of its AI coding environment Claude Code.</p><p>Eight days later, on May 30 2025, a page on Anthropic's API documentation appeared for the first time: "<a href="https://web.archive.org/web/20250530132140/https://docs.anthropic.com/en/api/service-tiers"><u>Service Tiers</u></a>":</p><blockquote>Different tiers of service allow you to balance availability, performance, and predictable costs based on your application’s needs.<p>We offer three service tiers:</p><p>- Priority Tier: Best for workflows deployed in production where time, availability, and predictable pricing are important</p><p>Standard: Best for bursty traffic, or for when you’re trying a new idea</p><p>Batch: Best for asynchronous workflows which can wait or benefit from being outside your normal capacity</p></blockquote><p><a href="https://web.archive.org/web/20250530132140/https://docs.anthropic.com/en/api/service-tiers#get-started-with-priority-tier"><u>Accessing the priority tier requires you to make an up-front commitment to Anthropic</u></a>, and said commitment is based on a number of months (1, 3, 6 or 12) and the number of input and output tokens you estimate you will use each minute.&nbsp;</p><h4 id="what%E2%80%99s-a-priority-tier-why-is-it-significant">What’s a Priority Tier? Why Is It Significant?</h4><p>As I’ll get into in my June analysis, Anthropic’s Service Tiers exist specifically for it to “guarantee” your company won’t face rate limits or any other service interruptions, requiring a minimum spend, minimum token throughput, and for you to pay higher rates when writing to the cache — which is, as I’ll explain, a big part of running an AI coding product like Cursor.</p><p>Now, the jump in costs — $65.1 million or so between April and May — likely comes as a result of the final training for Sonnet and Opus 4, as well as, I imagine, some sort of testing to make sure Claude Code was ready to go.</p><h3 id="june-20253214-million-in-aws-spend333-million-in-revenue965-of-revenue-spent-on-awsanthropic-cashes-in-on-service-tier-tolls-that-add-an-increased-charge-for-prompt-caching-directly-targeting-companies-like-cursor">June 2025 - $321.4 million in AWS Spend - $333 Million In Revenue - 96.5% Of Revenue Spent On AWS - Anthropic Cashes In On Service Tier Tolls That Add An Increased Charge For Prompt Caching, Directly Targeting Companies Like Cursor</h3><p>In June, as reported by The Information, Anthropic hit $4 billion in annualized revenue, or $333 million.</p><p>Anthropic’s revenue spiked by $83 million this month, and so did its costs by $34.7 million.&nbsp;</p><h3 id="anthropic-started-the-subprime-ai-crisis-in-june-2025-increasing-costs-on-its-largest-customer-doubling-its-aws-spend-in-a-month">Anthropic Started The Subprime AI Crisis In June 2025, Increasing Costs On Its Largest Customer, Doubling Its AWS Spend In A Month</h3><p>I have, for a while, talked about <a href="https://www.wheresyoured.at/subprimeai/#:~:text=I%20hypothesize%20a%20kind,to%20justify%20the%20expense."><u>the Subprime AI Crisis</u></a>, where big tech and companies like Anthropic, after offering subsidized pricing to entice in customers, raise the rates on their customers to start covering more of their costs, leading to a cascade where businesses are forced to raise their prices to handle their new, exploding costs.</p><p>And I was god damn <em>right. </em>Or, at least, it sure looks like I am. I’m hedging, forgive me. I cannot say for certain, but I see a pattern.&nbsp;</p><p>It’s likely the June 2025 spike in revenue came from the introduction of service tiers, which specifically target prompt caching, increasing the amount of tokens you’re charged for as an enterprise customer based on the term of the contract, and your forecast usage. </p><p><a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/#how-anthropics-tiered-service-may-have-harmed-its-largest-customer-cursor:~:text=a%20minimum%20spend.-,Furthermore,-%2C%20the%20way%20that"><u>Per my reporting in July</u></a>:&nbsp;</p><blockquote>You see, Anthropic specifically notes on its "service tiers" page that requests at the priority tier are "prioritized over all other requests to Anthropic," a rent-seeking measure that effectively means a company must either:<p>-	Commit to at least a month, though likely 3-12 months of specific levels of input and output tokens a minute, based on what they believe they will use in the future, regardless of whether they do.</p><p>-	Accept that access to Anthropic models will be slower at some point, in some way that Anthropic can't guarantee.Furthermore, the way that Anthropic is charging almost feels intentionally built to fuck over any coding startup that would use its service. Per the service tier page, Anthropic charges 1.25 for every time you write a token to the cache with a 5 minute TTL — or 2 tokens if you have a 1 hour TTL — and a longer cache is effectively essential for any background task where an agent will be working for more than 5 minutes, such as restructuring a particularly complex series of code, you know, the exact things that Cursor is well-known and marketed to do. </p><p>Furthermore, the longer something is in the cache, the better autocomplete suggestions for your code will be. It's also important to remember you're, at some point, caching the prompts themselves — so the instructions of what you want Cursor to do, meaning that the more complex the operation, the more expensive it'll now be for Cursor to provide the service with reasonable uptime.</p></blockquote><p>Cursor, as Anthropic’s largest client (the second largest being Github Copilot), represents a material part of its revenue, and its surging popularity meant it was sending more and more revenue Anthropic’s way.&nbsp; Anysphere, the company that develops Cursor, <a href="https://techcrunch.com/2025/06/05/cursors-anysphere-nabs-9-9b-valuation-soars-past-500m-arr/?ref=wheresyoured.at"><u>hit $500 million annualized revenue ($41.6 million) by the end of May</u></a>, which Anthropic chose to celebrate by increasing its costs.</p><p>On June 16 2025, <a href="https://web.archive.org/web/20250619080155/https://www.cursor.com/en/blog/new-tier"><u>Cursor launched a $200-a-month “Ultra” plan</u></a>, <a href="https://cursor.com/blog/new-tier?ref=wheresyoured.at"><u>as well as dramatic changes to its $20-a-month Pro pricing</u></a> that, instead of offering 500 “fast” responses using models from Anthropic and OpenAI, now effectively provided you with “at least” whatever you paid a month (so $20-a-month got at least $20 of credit), <a href="https://techcrunch.com/2025/07/07/cursor-apologizes-for-unclear-pricing-changes-that-upset-users/?ref=wheresyoured.at"><u>massively increasing the costs for users</u></a>, with one calling the changes a “rug pull” <a href="https://x.com/0ni_x4/status/1940885976127283342?ref=wheresyoured.at"><u>after spending $71 in a single day</u></a>.</p><p>As I’ll get to later in the piece, Cursor’s costs exploded from $6.19 million in May 2025 to $12.67 million in June 2025, and I believe this is a direct result of Anthropic’s sudden and aggressive cost increases.&nbsp;</p><p>Similarly, Replit, <a href="https://blog.replit.com/effort-based-pricing?ref=wheresyoured.at"><u>another AI coding startup, moved to “Effort-Based Pricing” on June 18 2025</u></a>. I have not got any information around its AWS spend.</p><p>I’ll get into this a bit later, but I find this whole situation disgusting.</p><h3 id="july-2025-3232-million-in-aws-spend416-million-in-revenue777-of-revenue-spent-on-aws">July 2025 $323.2 million in AWS Spend - $416 Million In Revenue - 77.7% Of Revenue Spent On AWS</h3><p>In July, <a href="https://archive.ph/KWhkD?ref=wheresyoured.at"><u>as reported by Bloomberg</u></a>, Anthropic hit $5 billion in annualized revenue, or $416 million.</p><p>While July wasn’t a huge month for announcements, it was allegedly the month that Claude Code was generating “nearly $400 million in annualized revenue,” or $33.3 million (<a href="https://www.theinformation.com/articles/anthropic-revenue-pace-nears-5-billion-run-mega-round?ref=wheresyoured.at&amp;rc=kz8jh3"><u>according to The Information</u></a>, who says Anthropic was “approaching” $5 billion in annualized revenue - which likely means LESS than that - but I’m going to go with the full $5 billion annualized for sake of fairness.&nbsp;</p><p>There’s roughly an $83 million bump in Anthropic’s revenue between June and July 2025, and I think Claude Code and its new rates are a big part of it. What’s <em>fascinating</em> is that cloud costs didn’t increase too much — by only $1.8 million, to be specific.</p><h3 id="august-20253837-million-in-aws-spend416-million-in-revenue92-of-revenue-spent-on-aws">August 2025 - $383.7 million in AWS Spend - $416 Million In Revenue - 92% Of Revenue Spent On AWS</h3><p>In August, according to Anthropic, its run-rate “<a href="https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation?ref=wheresyoured.at"><u>reached over $5 billion</u></a>,” or in or around $416 million. I am not giving it anything more than $5 billion, especially considering in July Bloomberg’s reporting said “about $5 billion.”</p><p>Costs grew by $60.5 this month, potentially due to the <a href="https://www.anthropic.com/news/claude-opus-4-1?ref=wheresyoured.at"><u>launch of Claude Opus 4.1</u></a>, Anthropic’s more aggressively expensive model, though revenues do not appear to have grown much along the way.</p><p>Yet what’s <em>very</em> interesting is that Anthropic — <a href="https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/?ref=wheresyoured.at"><u>starting August 28</u></a> — launched weekly rate limits on its Claude Pro and Max plans. I wonder why?</p><h3 id="september-20255189-million-in-aws-spend583-million-in-revenue889-of-revenue-spent-on-aws">September 2025 - $518.9 million in AWS Spend - $583 Million In Revenue - 88.9% Of Revenue Spent On AWS</h3><p>Oh fuck! Look at that massive cost explosion!</p><p>Anyway, according to Reuters, <a href="https://archive.ph/EjLeA?ref=wheresyoured.at"><u>Anthropic’s run rate is “approaching $7 billion” in October</u></a>, and for the sake of <em>fairness</em>, I am going to just say it has $7 billion annualized, <strong>though I believe this number to be lower. </strong>“Approaching” can mean a lot of different things — $6.1 billion, $6.5 billion — and because I already anticipate a lot of accusations of “FUD,” I’m going to err on the side of <em>generosity.</em></p><p>If we assume a $6.5 billion annualized rate, that would make this month’s revenue $541.6 million, or 95.8% of its AWS spend.&nbsp;&nbsp;</p><p>Nevertheless, Anthropic’s costs exploded in the space of a month by $135.2 million (35%) - likely due to the fact that users, <a href="https://www.wheresyoured.at/anthropic-is-bleeding-out/"><u>as I reported in mid-July, were costing it thousands or tens of thousands of dollars in compute</u></a>, a problem it still faces to this day, with <a href="https://www.viberank.app/?ref=wheresyoured.at"><u>VibeRank showing a user currently spending $51,291 in a calendar month on a $200-a-month subscription</u></a>.</p><p>If there were other costs, they likely had something to do with the training runs for <a href="https://www.anthropic.com/news/claude-sonnet-4-5?ref=wheresyoured.at"><u>the launches of Sonnet 4.5</u></a> on September 29 2025 and <a href="https://www.anthropic.com/claude/haiku?ref=wheresyoured.at"><u>Haiku 4.5 in October 2025</u></a>.</p><h2 id="anthropic%E2%80%99s-monthly-aws-costs-have-increased-by-174-since-januaryand-with-its-potential-google-cloud-spend-and-massive-staff-anthropic-is-burning-billions-in-2025">Anthropic’s Monthly AWS Costs Have Increased By 174% Since January - And With Its Potential Google Cloud Spend and Massive Staff, Anthropic Is Burning Billions In 2025</h2><p>While these costs only speak to one part of its cloud stack — Anthropic has an unknowable amount of cloud spend on Google Cloud, and the data I have only covers AWS — it is simply remarkable how much this company spends on AWS, and how rapidly its costs seem to escalate as it grows.</p><p>Though things improved slightly over time — in that Anthropic is no longer burning over 200% of its revenue on AWS alone — these costs have still dramatically escalated, and done so in an aggressive and arbitrary manner.&nbsp;</p><h2 id="anthropic%E2%80%99s-aws-costs-increase-linearly-with-revenue-consuming-the-majority-of-each-dollar-anthropic-makesas-a-reminder-it-also-spends-hundreds-of-millions-or-billions-on-google-cloud-too">Anthropic’s AWS Costs Increase Linearly With Revenue, Consuming The Majority Of Each Dollar Anthropic Makes - <strong>As A Reminder, It Also Spends Hundreds Of Millions Or Billions On Google Cloud Too</strong></h2><p>So, I wanted to visualize this part of the story, because I think it’s important to see the various different scenarios.</p><h2 id="an-estimate-of-anthropic%E2%80%99s-potential-cloud-compute-spend-through-september">An Estimate of Anthropic’s Potential Cloud Compute Spend Through September</h2><p><strong><em><u>THE NUMBERS I AM USING ARE ESTIMATES CALCULATED BASED ON 25%, 50% and 100% OF THE AMOUNTS THAT ANTHROPIC HAS SPENT ON AMAZON WEB SERVICES THROUGH SEPTEMBER.&nbsp;</u></em></strong></p><p>I apologize for all the noise, I just want it to be crystal clear what you see next.&nbsp;&nbsp;</p><figure><img src="https://www.wheresyoured.at/content/images/2025/10/data-src-image-a18dda28-2ac7-494a-8aad-1e3124ebda42.png" alt="" loading="lazy" title="Chart" width="1600" height="960" srcset="https://www.wheresyoured.at/content/images/size/w600/2025/10/data-src-image-a18dda28-2ac7-494a-8aad-1e3124ebda42.png 600w, https://www.wheresyoured.at/content/images/size/w1000/2025/10/data-src-image-a18dda28-2ac7-494a-8aad-1e3124ebda42.png 1000w, https://www.wheresyoured.at/content/images/2025/10/data-src-image-a18dda28-2ac7-494a-8aad-1e3124ebda42.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>As you can see, all it takes is for Anthropic to spend (I am estimating) around 25% of its Amazon Web Services bills (for a total of around $3.33 billion in compute costs through the end of September) to savage any and all revenue ($2.55 billion) it’s making.&nbsp;</p><p>Assuming Anthropic spends half of its&nbsp; AWS spend on Google Cloud, this number climbs to $3.99 billion, and if you assume - and to be clear, this is <em><strong>an estimate </strong></em>- that it spends around the same on <em>both</em> Google Cloud and AWS, Anthropic has spent $5.3 billion on compute through the end of September.</p><p>I can’t tell you which it is, just that we know for certain that Anthropic is spending money on Google Cloud, and because Google <a href="https://www.nytimes.com/2025/03/11/technology/google-investment-anthropic.html?ref=wheresyoured.at"><u>owns 14% of the company</u></a> — rivalling <a href="https://www.morningstar.com/news/marketwatch/20250903243/why-anthropics-fresh-183-billion-valuation-is-good-news-for-amazon?ref=wheresyoured.at"><u>estimates saying Amazon owns around 15-19%</u></a> — it’s fair to assume that there’s a significant spend.</p><h2 id="anthropic%E2%80%99s-costs-are-out-of-control-consistently-and-aggressively-outpacing-revenueand-amazon%E2%80%99s-revenue-from-anthropic-of-266-billion-is-25-of-its-2025-capex">Anthropic’s Costs Are Out Of Control, Consistently And Aggressively Outpacing Revenue - And Amazon’s Revenue from Anthropic Of $2.66 Billion Is 2.5% Of Its 2025 Capex</h2><p>I have sat with these numbers for a great deal of time, and I can’t find any evidence that Anthropic has any path to profitability outside of aggressively increasing the prices on their customers to the point that its services will become untenable for consumers and enterprise customers alike.</p><p>As you can see from these estimated and reported revenues, Anthropic’s AWS costs appear to increase in a near-linear fashion with its revenues, meaning that the current pricing — including rent-seeking measures like Priority Service Tiers — isn’t working to meet the burden of its costs.</p><p>We do not know its Google Cloud spend, but I’d be shocked if it was anything less than 50% of its AWS bill. If that’s the case, Anthropic is in real trouble - the cost of the services underlying its business increase the more money they make.</p><p>It’s becoming increasingly apparent that Large Language Models are not a profitable business. While I cannot speak to Amazon Web Services’ actual costs, it’s making $2.66 billion from Anthropic, which is the <em>second largest foundation model company in the world.&nbsp;</em></p><p>Is that really worth <a href="https://www.barrons.com/articles/amazon-stock-ai-aws-207f82d8?gaa_at=eafs&amp;gaa_n=AWEtsqdB5ei2Pp549YWJtX_F8ImxHOmK8IsGY7lELJ-noRSvlrNczjmyppY2gbP5KHk%3D&amp;gaa_ts=68f2c6ea&amp;gaa_sig=fWk4e5ZMICsxF_Jico93PSq67-vn6xdcEFxzgEYijc2HE7uEipCfxyojd9hqbSDlTD_JG-85XbK4EyckM3NKhQ%3D%3D&amp;ref=wheresyoured.at"><u>$105 billion in capital expenditures</u></a>? Is that really worth building <a href="https://futurism.com/the-byte/amazon-anthropic-ai-data-center?ref=wheresyoured.at"><u>a giant 1200 acre data center in Indiana</u></a> with 2.2GW of electricity?</p><p>What’s the plan, exactly? Let Anthropic burn money for the foreseeable future until it dies, and then pick up the pieces? Wait until Wall Street gets mad at you and then pull the plug?</p><p>Who knows.&nbsp;</p><p>But let’s change gears and talk about Cursor — Anthropic’s largest client and, at this point, a victim of circumstance.</p><h2 id="cursor%E2%80%99s-amazon-web-services-spend-in-2025-through-september-20256999-million">Cursor’s Amazon Web Services Spend In 2025 Through September 2025 - $69.99 Million</h2><h3 id="an-important-note-about-cursor%E2%80%99s-compute-spend">An Important Note About Cursor’s Compute Spend</h3><p><a href="https://aws.amazon.com/bedrock/anthropic/?ref=wheresyoured.at"><u>Amazon sells Anthropic’s models through Amazon Bedrock</u></a>, <strong>and I believe that AI startups are compelled to spend some of their AI model compute costs through Amazon Web Services.</strong> Cursor <em>also sends money directly to Anthropic and OpenAI, meaning that these costs are only one piece of its overall compute costs. </em><strong>In any case, it’s very clear that Cursor buys some degree of its Anthropic model spend through Amazon.</strong></p><p>I’ll also add that <a href="https://www.newcomer.co/p/cursors-popularity-has-come-at-a?ref=wheresyoured.at"><u>Tom Dotan of Newcomer reported</u></a> a few months ago that an investor told him that “Cursor is spending 100% of its revenue on Anthropic.”</p><p>Unlike Anthropic, we lack thorough reporting of the month-by-month breakdown of Cursor’s revenues. I will, however, mention them in the month I have them.</p><p>For the sake of readability — and because we really don’t have much information on Cursor’s revenues beyond a few months — I’m going to stick to a bullet point list.&nbsp;</p><h2 id="another-note-about-cursor%E2%80%99s-aws-spendit-likely-funnels-some-model-spend-through-aws-but-the-majority-goes-directly-to-providers-like-anthropic">Another Note About Cursor’s AWS Spend - It Likely Funnels Some Model Spend Through AWS, But The Majority Goes Directly To Providers Like Anthropic</h2><p>As discussed above, <a href="https://web.archive.org/web/20250619080155/https://www.cursor.com/en/blog/new-tier"><u>Cursor announced (along with their price change and $200-a-month plan) several multi-year partnerships</u></a> with xAI, Anthropic, OpenAI and Google, suggesting that it has direct agreements with Anthropic itself versus one with AWS to guarantee “this volume of compute at a predictable price.”&nbsp;</p><p>Based on its spend with AWS, I do not see a strong “minimum” spend that would suggest that they have a similar deal with Amazon — likely because Amazon handles more than its infrastructure than <em>just</em> compute, but incentivizes it to spend on Anthropic’s models through AWS by offering discounts, something I’ve confirmed with a source.&nbsp;</p><p>In any case, here’s what Cursor spent on AWS.</p><ul><li>January 2025 - $1.459 million<ul><li>This, apparently, is the month <a href="https://x.com/AnjneyMidha/status/1879306784525222193?ref=wheresyoured.at"><u>that Cursor hit $100 million annualized revenue</u></a> — or $8.3 million, meaning it spent 17.5% of its revenue on AWS.</li></ul></li><li>February 2025 - $2.47 million</li><li>March 2025 - $4.39 million</li><li>April 2025 - $4.74 million<ul><li><a href="https://www.theinformation.com/briefings/cursor-hits-200-million-annual-recurring-revenue?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Cursor hit $200 million annualized ($16.6 million) at the end of March 2025</u></a>, according to The Information, working out to spending 28% of its revenue on AWS.&nbsp;&nbsp;</li></ul></li><li>May 2025 - $6.19 million</li><li>June 2025 - $12.67 million<ul><li>So, <a href="https://archive.ph/GnzEC?ref=wheresyoured.at"><u>Bloomberg reported that Cursor hit $500 million on June 5 2025</u></a>, along with raising a $900 million funding round. Great news! Turns out it’d need to start handing a lot of that to Anthropic.</li><li>This was, as I’ve discussed above, the month when Anthropic forced it to adopt “Service Tiers”.<a href="https://www.wheresyoured.at/ai-is-a-money-trap/#cursor-is-a-systemic-risk-to-the-ai-industry"><u> I go into detail about the situation here</u></a>, but the long and short of it is that Anthropic increased the amount of tokens you burned by writing stuff to the cache (think of it like RAM in a computer), and AI coding startups are very cache heavy, meaning that Cursor immediately took on what I believed would be massive new costs. As I discuss in what I just linked, this led Cursor to aggressively change its product, thereby vastly increasing its customers’ costs if they wanted to use the same service.</li><li>That same month, Cursor’s AWS costs — which I believe are the <em>minority</em> of its cloud compute costs — exploded by 104% (or by $6.48 million), and never returned to their previous levels.</li><li>It’s conceivable that this surge is due to the compute-heavy nature of the latest Claude 4 models released that month — or, perhaps, Cursor sending more of its users to other models that it runs on Bedrock.&nbsp;</li></ul></li><li>July 2025 - $15.5 million<ul><li>As you can see, Cursor’s costs continue to balloon in July, and I am guessing it’s because of the Service Tiers situation — which, I believe, indirectly resulted in Cursor pushing more users to models that it runs on Amazon’s infrastructure.</li></ul></li><li>August 2025 - $9.67 million<ul><li>So, I can only guess as to why there was a drop here. User churn? It could be <a href="https://cursor.com/blog/gpt-5?ref=wheresyoured.at"><u>the launch of GPT-5 on Cursor</u></a>, which gave users a week of free access to OpenAI’s new models.</li><li>What’s also interesting is that this was the month when <a href="https://cursor.com/blog/aug-2025-pricing?ref=wheresyoured.at"><u>Cursor announced</u></a> that its previously free “auto” model (where Cursor would select the best available premium model or its own model) would now bill at “<a href="https://cursor.com/docs/account/pricing?ref=wheresyoured.at#auto"><u>competitive token rates</u></a>,” by which I mean it went from charging nothing to $1.25 per million input and $6 per million output tokens. This change would take effect on September 15 2025.</li><li><a href="http://newcomer.co/p/cursors-popularity-has-come-at-a?ref=wheresyoured.at"><u>On August 10 2025</u></a>, Tom Dotan of Newcomer reported that Cursor was “well above” $500 million in annualized revenue based on commentary from two sources.</li></ul></li><li>September 2025 - $12.91 million<ul><li>Per the above, this is the month when Cursor started charging for its “auto” model.</li></ul></li></ul><h2 id="what-anthropic-may-have-done-to-cursor-is-disgustingand-is-a-preview-of-what%E2%80%99s-to-come-for-ai-startups">What Anthropic May Have Done To Cursor Is Disgusting - And Is A Preview Of What’s To Come For AI Startups</h2><p>When I wrote that <a href="https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/"><u>Anthropic and OpenAI had begun the Subprime AI Crisis</u></a> back in July, I assumed that the increase in costs was <em>burdensome,</em> but having the information from its AWS bills, it seems that Anthropic’s actions directly caused Cursor’s costs to explode by over 100%.&nbsp;</p><p>While I can’t definitively say “this is exactly what did it,” the timelines match up exactly, the costs have never come down, Amazon offers <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html?ref=wheresyoured.at"><u>provisioned throughput</u></a>, and, more than likely, Cursor needs to keep a standard of uptime similar to that of Anthropic’s own direct API access.</p><p>If this is what happened, it’s deeply shameful.&nbsp;</p><p>Cursor, <a href="https://www.vincentschmalbach.com/cursor-is-anthropics-largest-customer-and-maxing-out-their-gpus/?ref=wheresyoured.at"><u>Anthropic’s largest customer</u></a>, in the very same month it hit $500 million in annualized revenue, immediately had its AWS and Anthropic-related costs explode to the point that it had to dramatically reduce the value of its product just as it hit the apex of its revenue growth.&nbsp;</p><h2 id="anthropic-timed-its-rent-seeking-service-tier-price-increases-on-cursor-with-the-launch-of-a-competitive-productwhich-is-what%E2%80%99s-coming-to-any-ai-startup-that-builds-on-top-of-its-products">Anthropic Timed Its Rent-Seeking Service Tier Price Increases on Cursor With The Launch Of A Competitive Product - Which Is What’s Coming To Any AI Startup That Builds On Top Of Its Products</h2><p>It’s very difficult to see Service Tiers as anything other than an aggressive rent-seeking maneuver.</p><p>Yet another undiscussed part of the story is that the launch of Claude 4 Opus and Sonnet — and the subsequent launch of Service Tiers — <a href="https://www.anthropic.com/news/claude-4?ref=wheresyoured.at"><u>coincided with the launch of Claude Code</u></a>, a product that directly competes with Cursor, without the burden of having to pay itself for the cost of models or, indeed, having to deal with its own “Service Tiers.”</p><p>Anthropic may have increased the prices on its largest client at the time it was launching a competitor, <strong>and I believe that this is what awaits any product built on top of OpenAI or Anthropic’s models.&nbsp;</strong></p><h2 id="the-subprime-ai-crisis-is-real-and-it-can-hurt-you">The Subprime AI Crisis Is Real, And It Can Hurt You</h2><p>I realize this has been a long, number-stuffed article, but the long-and-short of it is simple: Anthropic is burning all of its revenue on compute, and Anthropic will willingly increase the prices on its customers if it’ll help it burn less money, even though that doesn’t seem to be working.</p><p>What I believe happened to Cursor will likely happen to every AI-native company, because in a very real sense, Anthropic’s products are a wrapper for its own models, except it only has to pay the (unprofitable) costs of running them on Amazon Web Services and Google Cloud.</p><p>As a result, both OpenAI and Anthropic can (and may very well!) devour the market of any company that builds on top of their models.&nbsp;</p><p>OpenAI may have given Cursor free access to its GPT-5 models in August, but a month later <a href="https://openai.com/index/introducing-upgrades-to-codex/?ref=wheresyoured.at"><u>on September 15 2025</u></a> it debuted massive upgrades to its competitive “Codex” platform.&nbsp;</p><p>Any product built on top of an AI model that shows any kind of success can be cloned immediately by OpenAI and Anthropic, and I believe that we’re going to see multiple price increases on AI-native companies in the next few months. After all, <a href="https://openai.com/api-priority-processing/?ref=wheresyoured.at"><u>OpenAI already has its own priority processing product, which it launched shortly after Anthropic’s in June</u></a>.</p><p>The ultimate problem is that there really are no<em> winners</em> in this situation. If Anthropic kills Cursor through aggressive rent-seeking, that directly eats into its own revenues. If Anthropic lets Cursor succeed, that’s <em>revenue</em>, but it’s also clearly <em>unprofitable revenue</em>. Everybody loses, but nobody loses more than Cursor’s (and other AI companies’) customers.&nbsp;</p><h2 id="anthropic-is-in-real-troubleand-the-current-cost-of-doing-business-is-unsustainable-meaning-prices-must-increase">Anthropic Is In Real Trouble - And The Current Cost Of Doing Business Is Unsustainable, Meaning Prices Must Increase</h2><p>I’ve come away from this piece with a feeling of dread.</p><p>Anthropic’s costs are out of control, and as things get more desperate, it appears to be lashing out at its customers, both companies like Cursor and <a href="https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/?ref=wheresyoured.at"><u>Claude Code customers facing weekly rate limits on their more-powerful models</u></a> who are chided for using a product they pay for. Again, I cannot say for certain, but the spike in costs is clear, and it feels like more than a coincidence to me.&nbsp;</p><p>There is no period of time that I can see in the just under two years of data I’ve been party to that suggests that Anthropic has any means of — or any success doing — cost-cutting, and the only thing this company seems capable of doing is increasing the amount of money it burns on a monthly basis.&nbsp;</p><p>Based on what I have been party to, the more successful Anthropic becomes, the more its services cost. <a href="https://www.wheresyoured.at/how-to-argue-with-an-ai-booster/#if-you-plotted-the-curve-of-how-the-cost-of-inference-has-been-falling-over-time-%E2%80%94-false-the-cost-of-inference-has-gone-up-over-time"><u>The cost of inference is clearly increasing for customers</u></a>, but based on its escalating monthly costs, the cost of inference appears to be high for Anthropic too, though it’s impossible to tell how much of its compute is based on training versus running inference.</p><p>In any case, these costs seem to increase with the amount of money Anthropic makes, meaning that the current pricing of both subscriptions and API access seems unprofitable, and must increase dramatically — from my calculations, a 100% price increase might work, but good luck retaining every single customer and their customers too! — for this company to ever become sustainable.&nbsp;</p><p>I don’t think that people would pay those prices. If anything, I think what we’re seeing in these numbers is a company bleeding out from costs that escalate the more that its user base grows. This is just my opinion, of course.&nbsp;</p><p>I’m tired of watching these companies burn billions of dollars to destroy our environment and steal from everybody. I’m tired that so many people have tried to pretend there’s a justification for burning billions of dollars every year, clinging to empty tropes about how <a href="https://www.wheresyoured.at/how-to-argue-with-an-ai-booster/#ultimate-booster-quip-openai-and-anthropic-are-%E2%80%9Cjust-like-uber%E2%80%9D-because-uber-burned-25-billion-over-the-course-of-15-or-so-years-and-is-now-profitable-this-proves-that-openai-a-totally-different-company-with-different-economics-will-be-fine"><u>this is just like Uber</u></a> or <a href="https://www.wheresyoured.at/the-haters-gui/#ed-amazon-web-services-took-years-to-become-profitable-people-said-amazon-would-fail"><u>Amazon Web Services</u></a>, when Anthropic has built something far more mediocre.&nbsp;</p><p>Mr. Amodei, I am sure you will read this piece, and I can make time to chat in person on my show Better Offline. Perhaps this Friday? I even have some studio time on the books.&nbsp;</p>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Commodore 64 Ultimate (131 pts)]]></title>
            <link>https://www.commodore.net/product-page/commodore-64-ultimate-basic-beige-batch1</link>
            <guid>45644654</guid>
            <pubDate>Mon, 20 Oct 2025 14:55:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.commodore.net/product-page/commodore-64-ultimate-basic-beige-batch1">https://www.commodore.net/product-page/commodore-64-ultimate-basic-beige-batch1</a>, See on <a href="https://news.ycombinator.com/item?id=45644654">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span><span>ex. tax</span></span></p><div id="comp-mcpbk490" data-testid="richTextElement"><h4>Preorder FAQ</h4>

<h3>Is this a Kickstarter?</h3>
<p>Not quite - this is an official Commodore® preorder with a money-back guarantee. Similar to crowdfunding, every penny goes into manufacturing first, and then to the mission to reboot Commodore itself. By skipping Kickstarter, we avoid big platform fees and pass the savings on to you - just like our founder Jack Tramiel would’ve wanted.&nbsp;</p>

<h3>Am I charged now or at shipping, and what currency?</h3>
<p>You’re charged now, in USD (your local currency shows until checkout). Like Kickstarter and others, your preorder funds production at the factory. The rest helps reboot the Commodore brand.</p>

<h3>Can I get a refund?</h3>
<p>Absolutely. You’re in control. Cancel anytime before shipping with our <strong>no quibble money-back guarantee</strong> for a full refund - no questions asked. Have an account? <a href="https://www.commodore.net/my-orders" target="_blank"><u>Cancel there</u></a> with one click. No account? Use our <a href="https://www.commodore.net/contact-us" target="_blank"><u>support form</u></a> and we’ll sort it fast.</p>

<h3>How does shipping work?</h3>
<p>We deliver from Commodore &amp; Commodore partner hubs in the USA, UK, and EU (including our original 1980s Corby building). If you’re farther out, we ship via trusted couriers like DHL, FedEx, UPS, or Chickenlips Express.</p>

<h3>Will I pay sales tax?</h3>
<p>USA: Sales tax is added at checkout where required.</p>
<p>UK &amp; Europe: VAT/IVA/MwSt is added at checkout.</p>

<h3>What about tariffs?</h3>
<p>If your country charges import tariffs (e.g. the USA), you’ll see a “Tariff Tax” at checkout. This covers everything upfront, so there’s nothing more to pay later. We don’t control these fees, but we avoid surprises. If tariffs drop after you pay, we’ll refund you at shipping. If they rise a lot before shipping, we may adjust- but only if truly needed to protect Commodore’s future.&nbsp;</p>

<h3>What about customs duties?</h3>
<p>We aim to prepay duties (DDP) where possible. In some places (e.g. Norway, Australia, New Zealand, Singapore), you might get a tax refund before shipping. Some countries may still charge customs fees on arrival - these aren’t included and as is commonplace, these are your responsibility.</p>

<h3>Isn't this just an emulator or rebadged something-or-other?</h3>
<p>The Commodore 64 Ultimate from the only original Commodore® brand (est. 1958) is brand new hardware-based Commodore 64 technology. It features SID chip-reactive LEDs (case, keyboard, power light*), the world's first transparent keyboard PCB*, original and modern creators’ autographs etched in copper, and an updated FPGA that replicates the original C64 motherboard (not emulation). All customisable via a new, easy main menu. It’s a fully authentic new build from Commodore - who else?</p>
<p><em>*except beige version</em></p>

<h3>Will Commodore 64 Ultimate units still ship if the acquisition doesn’t complete?</h3>
<p>Good news - as of 31st July 2025 we paid the sellers in full, ahead of schedule, and signed the final contracts to complete the acquisition. Even before that, we had a contract guaranteeing these machines would be made no matter what.</p>

<h3>So what are the risks?</h3>
<p>All launches have some risk, whether you're Apple or Commodore. But this preorder is unusually safe. Most parts are already in production. The motherboard is a proven design. Cases shipped in January 2025. Keycaps shipped in 2024. Just a few parts remain, like the keyboard base, made by a trusted partner since the Apple II era. All components are pro-designed to fit together. Add the box, manual, and power supply, and we’re set.</p>

<h3>Is there a warranty?</h3>
<p>Yes. Our products include a 1-year limited warranty covering defects in materials and workmanship. For customers in the EU or UK, your purchase also complies with local consumer protection laws, including the EU Consumer Rights Directive and UK Consumer Rights Act, which provide additional rights. You can also add an extended warranty <a href="https://www.commodore.net/product-page/commodore-warranty" target="_blank"><u>here</u></a>.</p>

<h3>Can I email/DM you to suggest a feature change?</h3>
<p>We’re not planning hardware changes right now. Chances are we already debated it over chickenlips snacks. We’re reviewing ideas from our launch form and will reach out if your Commodore 256 Ultra-Turbo-CD-Lightgun-Keyring makes the cut.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BERT Is Just a Single Text Diffusion Step (350 pts)]]></title>
            <link>https://nathan.rs/posts/roberta-diffusion/</link>
            <guid>45644328</guid>
            <pubDate>Mon, 20 Oct 2025 14:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nathan.rs/posts/roberta-diffusion/">https://nathan.rs/posts/roberta-diffusion/</a>, See on <a href="https://news.ycombinator.com/item?id=45644328">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img alt="Text Diffusion" src="https://nathan.rs/images/roberta-diffusion.gif"></p><p>A while back, Google DeepMind unveiled <a href="https://deepmind.google/models/gemini-diffusion/">Gemini Diffusion</a>, an experimental language model that generates text using diffusion. Unlike traditional GPT-style models that generate one word at a time, Gemini Diffusion creates whole blocks of text by refining random noise step-by-step.</p><p>I read the paper <a href="https://arxiv.org/abs/2502.09992">Large Language Diffusion Models</a> and was surprised to find that discrete language diffusion is just a generalization of masked language modeling (MLM), something we’ve been doing since <a href="https://arxiv.org/abs/1810.04805">2018</a>.
The first thought I had was, “can we finetune a BERT-like model to do text generation?” I decided to try a quick proof of concept out of curiosity.</p><blockquote><p>NOTE: After I wrote the article I stumbled upon the paper <a href="https://arxiv.org/abs/2211.15029">DiffusionBERT</a> which does essentially the same thing but with more rigorous testing! Check it out if this post interested you.</p></blockquote><h2 id="a-short-history-of-transformers">A Short History of Transformers<a href="#a-short-history-of-transformers">#</a></h2><hr><p>The original Transformer architecture, introduced in <a href="https://arxiv.org/abs/1706.03762">2017</a>, was an encoder-decoder model. In 2018, researchers realized that the encoder and decoder components of the model could be separated (with the advent of <a href="https://arxiv.org/abs/1810.04805">BERT</a> and <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>), and two distinct families of models were created:</p><ol><li><strong>Encoder-only models (BERT-style, bidirectional)</strong></li></ol><p>Encoder models used masked language modeling (MLM) as a training objective: randomly mask out a subset of tokens of each input and train the encoder to reconstruct the missing tokens (fill in the blanks).
The model sees the entire (partially masked) context at once and learns bidirectional representations.
This architecture excelled at tasks requiring a full‐sentence (or paragraph) representation (e.g., classification and retrieval).</p><ol start="2"><li><strong>Decoder-only models (GPT-style, autoregressive)</strong></li></ol><p>Decoder models used next‐token prediction as a training objective: at each position $t$, predict the token at position $t + 1$ given all tokens up to $t$ as context. Only the left context is used to predict future values (unidirectional).
This architecture excelled at generative tasks where you produce text one token at a time, such as open‐ended generation, summarization, and translation.</p><p>Originally, BERT saw immediate use in tasks such as classification, whereas GPT-style models didn’t become popular until later (due to initial limited capabilities). Eventually, the generation capabilities of autoregressive (decoder) transformers vastly improved. The general training objective of “next token prediction” means a much larger space of use cases when compared to encoder models.</p><h2 id="discrete-language-diffusion-models">Discrete Language Diffusion Models<a href="#discrete-language-diffusion-models">#</a></h2><hr><p>Diffusion models were first popularized in image generation. In image generation, diffusion models gradually add Gaussian noise to an image (forward process) and then train a neural network to iteratively denoise it (reverse process). A high‐level summary of continuous diffusion with images is:</p><ol><li><strong>Forward process</strong>: Start from a clean image <em>x₀</em>, then add small amounts of (usually Gaussian) noise at each timestep until you end up with near‐pure noise.</li><li><strong>Reverse process</strong>: Train a model (often a U‐Net) to predict the noise at each timestep, gradually recovering the original image in discrete denoising steps.</li></ol><p>Applying this idea to language means we need a way to add noise to text and then remove it in stages.
The simplest way to do this is a <strong>masking‐based noise process</strong>:</p><ol><li><p><strong>Forward (masking) process</strong>:</p><ul><li>At timestep <em>t = 0</em>, you have a fully uncorrupted text sequence.</li><li>At each subsequent timestep <em>t &gt; 0</em>, randomly replace a fraction of tokens with a special <code>&lt;MASK&gt;</code> token according to a pre‐defined schedule (e.g., gradually increasing the masked proportion from 0% to 100%).</li><li>By the final timestep <em>T</em>, the entire sequence may be masked (all tokens are <code>&lt;MASK&gt;</code>).</li></ul></li><li><p><strong>Reverse (denoising) process</strong>:</p><ul><li>Train a model (often a standard Transformer encoder) to predict the original token IDs given a partially masked sequence at timestep <em>t</em>.</li><li>This is akin to performing masked language modeling at varying mask rates: at early timesteps, only a few tokens are masked (easy to predict); at later timesteps, many tokens are masked (harder).</li><li>By chaining together predictions from high‐mask‐rate back down to zero, you can recover (or generate) a full sequence.</li></ul></li></ol><p>In this discrete text diffusion framework, the model learns a likelihood bound on the data distribution by optimizing a sum of denoising losses over all timesteps, rather than a single MLM objective at a fixed mask probability.</p><p>As we can see, BERT’s masked language modeling objective is the <strong>same training objective as text diffusion, but just for a subset of masking rates</strong>.
By introducing variable masking rates (from 0 to 1) and a scheduled sequence of denoising steps (inspired by diffusion theory), we can transform BERT’s masked language modeling objective into a full generative procedure.</p><h2 id="roberta-diffusion">RoBERTa Diffusion<a href="#roberta-diffusion">#</a></h2><hr><p>In 2019, <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> was released. It was essentially just an enhancement of the original BERT model, with better hyperparameters, data training size, and a more simple training objective (MLM only, removed next sentence prediction).</p><p>Here we use the HuggingFace <code>transformers</code> and <code>dataset</code> libraries to pull in the original RoBERTa weights, tokenizer, and the Trainer class to easily finetune the model on the WikiText dataset.
The main code (<a href="https://github.com/nathan-barry/RoBERTaDiffusion">full code here</a>) looks like this below:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># Load and tokenize dataset and instantiate the model</span>
</span></span><span><span>dataset <span>=</span> load_dataset(<span>"wikitext"</span>, <span>"wikitext-2-raw-v1"</span>)
</span></span><span><span>tokenizer <span>=</span> RobertaTokenizerFast<span>.</span>from_pretrained(<span>"roberta-base"</span>)
</span></span><span><span>model <span>=</span> RobertaForMaskedLM<span>.</span>from_pretrained(<span>"roberta-base"</span>)
</span></span><span><span>
</span></span><span><span><span># Create the training args and Trainer instance</span>
</span></span><span><span>training_args <span>=</span> TrainingArguments(
</span></span><span><span>    output_dir<span>=</span><span>"finetuned-roberta-diffusion"</span>,
</span></span><span><span>    overwrite_output_dir<span>=</span><span>True</span>,
</span></span><span><span>    num_train_epochs<span>=</span>NUM_EPOCHS,
</span></span><span><span>    per_device_train_batch_size<span>=</span>BATCH_SIZE,
</span></span><span><span>    save_strategy<span>=</span><span>"epoch"</span>,
</span></span><span><span>    save_total_limit<span>=</span><span>1</span>,
</span></span><span><span>    logging_steps<span>=</span><span>200</span>,
</span></span><span><span>)
</span></span><span><span>
</span></span><span><span>trainer <span>=</span> Trainer(
</span></span><span><span>    model<span>=</span>model,
</span></span><span><span>    args<span>=</span>training_args,
</span></span><span><span>    train_dataset<span>=</span>tokenized[<span>"train"</span>],
</span></span><span><span>    eval_dataset<span>=</span>tokenized[<span>"validation"</span>],
</span></span><span><span>    data_collator<span>=</span>diffusion_collator, <span># custom implementation</span>
</span></span><span><span>    tokenizer<span>=</span>tokenizer,
</span></span><span><span>)
</span></span><span><span>
</span></span><span><span><span># Train &amp; save</span>
</span></span><span><span>trainer<span>.</span>train()
</span></span><span><span>trainer<span>.</span>save_model(<span>"finetuned-roberta-diffusion"</span>)</span></span></code></pre></div><p>Currently we have 10 diffusion steps, so we randomly sample a percentage $p$ out of <code>mask_probs</code> (1.0, 0.9, 0.9, …, 0.1) and mask that percent of the tokens each batch.
The custom <code>diffusion_collator</code> function (<a href="https://github.com/nathan-barry/RoBERTaDiffusion/blob/main/finetune.py#L77">see code here</a>) samples one mask-probability <code>p</code> from <code>mask_probs</code> per batch and sets each token to <code>&lt;MASK&gt;</code> with <code>p</code> probability.</p><p>To be able to condition the generation on a “prompt”, we currently never mask the first 16 tokens. That means that during training, each step will always have the first 16 tokens as context for generation.</p><p>Simplified code for the <code>diffusion_collator</code> looks like:</p><div><pre tabindex="0"><code data-lang="python"><span><span>  <span>def</span> <span>diffusion_collator</span>(examples):
</span></span><span><span>      batch <span>=</span> tokenizer<span>.</span>pad(examples, return_tensors<span>=</span><span>"pt"</span>)
</span></span><span><span>
</span></span><span><span>      <span># Randomly select masking probability for this batch</span>
</span></span><span><span>      mask_prob <span>=</span> random<span>.</span>choice([<span>1.0</span>, <span>0.9</span>, <span>0.8</span>, <span>0.7</span>, <span>0.6</span>, <span>0.5</span>, <span>0.4</span>, <span>0.3</span>, <span>0.2</span>, <span>0.1</span>])
</span></span><span><span>
</span></span><span><span>      <span># Never mask the first PREFIX_LEN tokens (preserved context)</span>
</span></span><span><span>      maskable_positions <span>=</span> batch<span>.</span>input_ids[:, PREFIX_LEN:]
</span></span><span><span>
</span></span><span><span>      <span># Create random mask for the chosen probability</span>
</span></span><span><span>      mask <span>=</span> torch<span>.</span>rand(maskable_positions<span>.</span>shape) <span>&lt;</span> mask_prob
</span></span><span><span>
</span></span><span><span>      <span># Apply masking</span>
</span></span><span><span>      batch<span>.</span>input_ids[:, PREFIX_LEN:][mask] <span>=</span> tokenizer<span>.</span>mask_token_id
</span></span><span><span>      batch<span>.</span>labels <span>=</span> batch<span>.</span>input_ids<span>.</span>clone()
</span></span><span><span>
</span></span><span><span>      <span>return</span> batch</span></span></code></pre></div><p>For inference, we start with an input which is a tensor of size 256 (since we are generating blocks of 256 tokens). The first 16 positions are the token ids that correspond to the prompt, and the last 240 are just <code>&lt;MASK&gt;</code> tokens. We iterate through the denoising schedule and each step, we generate a prediction and then remask the sequence again. The process looks like this:</p><pre tabindex="0"><code>Step 0: [PREFIX] &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; ...     (100% masked)
Step 1: [PREFIX] will &lt;mask&gt; over &lt;mask&gt; control ...        (90% masked)
Step 2: [PREFIX] will begin &lt;mask&gt; greater control ...      (80% masked)
...
Step 10: [PREFIX] will begin to assert greater control ...  (0% masked - DONE)</code></pre><p>Simplified code for generation looks like:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># Generate text through iterative denoising</span>
</span></span><span><span><span>for</span> step, mask_prob <span>in</span> <span>enumerate</span>(mask_probs):
</span></span><span><span>    <span># Forward pass: predict masked tokens</span>
</span></span><span><span>    <span>with</span> torch<span>.</span>no_grad():
</span></span><span><span>        outputs <span>=</span> model(input_ids<span>=</span>input_ids, attention_mask<span>=</span>attention_mask)
</span></span><span><span>        predictions <span>=</span> outputs<span>.</span>logits  <span># shape: (1, MAX_LEN, vocab_size)</span>
</span></span><span><span>
</span></span><span><span>    <span># For each masked position, sample from top-k/top-p filtered distribution</span>
</span></span><span><span>    <span>for</span> pos <span>in</span> <span>range</span>(PREFIX_LEN, MAX_LEN):
</span></span><span><span>        <span>if</span> input_ids[<span>0</span>, pos] <span>==</span> tokenizer<span>.</span>mask_token_id:
</span></span><span><span>            logits <span>=</span> predictions[<span>0</span>, pos, :]
</span></span><span><span>            <span># Apply top-k and top-p filtering</span>
</span></span><span><span>            filtered_logits <span>=</span> top_k_top_p_filtering(logits, top_k<span>=</span>TOP_K, top_p<span>=</span>TOP_P)
</span></span><span><span>            probs <span>=</span> F<span>.</span>softmax(filtered_logits, dim<span>=-</span><span>1</span>)
</span></span><span><span>            <span># Sample token</span>
</span></span><span><span>            sampled_token <span>=</span> torch<span>.</span>multinomial(probs, <span>1</span>)
</span></span><span><span>            input_ids[<span>0</span>, pos] <span>=</span> sampled_token
</span></span><span><span>
</span></span><span><span>    <span># Re-mask a portion of non-prefix tokens for next iteration</span>
</span></span><span><span>    <span>if</span> mask_prob <span>&gt;</span> <span>0</span>:
</span></span><span><span>        mask_indices <span>=</span> torch<span>.</span>rand(MAX_LEN <span>-</span> PREFIX_LEN) <span>&lt;</span> mask_prob
</span></span><span><span>        input_ids[<span>0</span>, PREFIX_LEN:][mask_indices] <span>=</span> tokenizer<span>.</span>mask_token_id</span></span></code></pre></div><p>Here is an example output generation of the fine-tuned model after training on an H200 for 30 minutes (the first line is the initial prompt):</p><pre tabindex="0"><code>Following their victory in the French and Indian War, Britain began to assert
greater...

...dominion over Europe beginning about the early 19th. There conflict took
place on the island, between British and Irish Ireland. British officials 
administered British Ireland, a Celtic empire under the control of the Irish 
nationalist authorities, defined as a dominion of Britain. As the newly Fortic 
states acquired independent and powerful status, many former English colonies
played their part in this new, British @-@ controlled colonial system. Following
this period the Non @-@ Parliamentaryist Party won its influence in Britain in 
1890, led by the support of settlers from the Irish colonies. Looking inwards, 
Sinclair, Lewis questioned, and debated the need to describe " The New Britain "</code></pre><p>The output looks surprisingly coherent! Most of the quirks present are actually just quirks from the formatting of WikiText (spaces around punctuation <code>"</code>, turning hyphens <code>-</code> into <code>@-@</code>).</p><p>Below is a comparison between our diffusion model and GPT-2:</p><p><img alt="RoBERTa Diffusion vs GPT" src="https://nathan.rs/images/roberta-diffusion-gpt.gif"></p><p>We see GPT-2’s output is more coherent and slightly faster (~9 seconds vs ~13) but I’m pleasantly surprised with how good my simple implementation was. It is a good proof of concept, and with new approaches like AR-Diffusion and Skip-Step Diffusion (and a more optimized implementation), the quality and speed can be drastically improved.</p><h2 id="conclusion">Conclusion<a href="#conclusion">#</a></h2><hr><p>We’ve seen that masked language models like RoBERTa, originally designed for fill-in-the-blank tasks, can be repurposed into fully generative engines by interpreting variable-rate masking as a discrete diffusion process. By gradually corrupting text with <code>&lt;MASK&gt;</code> tokens and training the model to iteratively denoise at increasing mask intensities, we effectively turn the standard MLM objective into a step-by-step generation procedure.</p><p>Even without architectural changes, a fine-tuned RoBERTa can generate coherent looking text after slightly modifying the training objective, validating the idea that BERT-style models are essentially just text diffusion models trained on one masking rate.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Servo v0.0.1 Released (472 pts)]]></title>
            <link>https://github.com/servo/servo</link>
            <guid>45643357</guid>
            <pubDate>Mon, 20 Oct 2025 12:55:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/servo/servo">https://github.com/servo/servo</a>, See on <a href="https://news.ycombinator.com/item?id=45643357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">The Servo Parallel Browser Engine Project</h2><a id="user-content-the-servo-parallel-browser-engine-project" aria-label="Permalink: The Servo Parallel Browser Engine Project" href="#the-servo-parallel-browser-engine-project"></a></p>
<p dir="auto">Servo is a prototype web browser engine written in the
<a href="https://github.com/rust-lang/rust">Rust</a> language. It is currently developed on
64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.</p>
<p dir="auto">Servo welcomes contribution from everyone. Check out:</p>
<ul dir="auto">
<li>The <a href="https://book.servo.org/" rel="nofollow">Servo Book</a> for documentation</li>
<li><a href="https://servo.org/" rel="nofollow">servo.org</a> for news and guides</li>
</ul>
<p dir="auto">Coordination of Servo development happens:</p>
<ul dir="auto">
<li>Here in the Github Issues</li>
<li>On the <a href="https://servo.zulipchat.com/" rel="nofollow">Servo Zulip</a></li>
<li>In video calls advertised in the <a href="https://github.com/servo/project/issues">Servo Project</a> repo.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">For more detailed build instructions, see the Servo book under <a href="https://book.servo.org/hacking/setting-up-your-environment.html" rel="nofollow">Setting up your environment</a>, <a href="https://book.servo.org/hacking/building-servo.html" rel="nofollow">Building Servo</a>, <a href="https://book.servo.org/hacking/building-for-android.html" rel="nofollow">Building for Android</a> and <a href="https://book.servo.org/hacking/building-for-openharmony.html" rel="nofollow">Building for OpenHarmony</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS</h3><a id="user-content-macos" aria-label="Permalink: macOS" href="#macos"></a></p>
<ul dir="auto">
<li>Download and install <a href="https://developer.apple.com/xcode/" rel="nofollow">Xcode</a> and <a href="https://brew.sh/" rel="nofollow"><code>brew</code></a>.</li>
<li>Install <code>uv</code>: <code>curl -LsSf https://astral.sh/uv/install.sh | sh</code></li>
<li>Install <code>rustup</code>: <code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh</code></li>
<li>Restart your shell to make sure <code>cargo</code> is available</li>
<li>Install the other dependencies: <code>./mach bootstrap</code></li>
<li>Build servoshell: <code>./mach build</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<ul dir="auto">
<li>Install <code>curl</code>:
<ul dir="auto">
<li>Arch: <code>sudo pacman -S --needed curl</code></li>
<li>Debian, Ubuntu: <code>sudo apt install curl</code></li>
<li>Fedora: <code>sudo dnf install curl</code></li>
<li>Gentoo: <code>sudo emerge net-misc/curl</code></li>
</ul>
</li>
<li>Install <code>uv</code>: <code>curl -LsSf https://astral.sh/uv/install.sh | sh</code></li>
<li>Install <code>rustup</code>: <code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh</code></li>
<li>Restart your shell to make sure <code>cargo</code> is available</li>
<li>Install the other dependencies: <code>./mach bootstrap</code></li>
<li>Build servoshell: <code>./mach build</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<ul dir="auto">
<li>Download <a href="https://docs.astral.sh/uv/getting-started/installation/#standalone-installer" rel="nofollow"><code>uv</code></a>, <a href="https://chocolatey.org/install#individual" rel="nofollow"><code>choco</code></a>, and <a href="https://win.rustup.rs/" rel="nofollow"><code>rustup</code></a>
<ul dir="auto">
<li>Be sure to select <em>Quick install via the Visual Studio Community installer</em></li>
</ul>
</li>
<li>In the Visual Studio Installer, ensure the following components are installed:
<ul dir="auto">
<li><strong>Windows 10/11 SDK (anything &gt;= 10.0.19041.0)</strong> (<code>Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&gt;=19041}</code>)</li>
<li><strong>MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)</strong> (<code>Microsoft.VisualStudio.Component.VC.Tools.x86.x64</code>)</li>
<li><strong>C++ ATL for latest v143 build tools (x86 &amp; x64)</strong> (<code>Microsoft.VisualStudio.Component.VC.ATL</code>)</li>
</ul>
</li>
<li>Restart your shell to make sure <code>cargo</code> is available</li>
<li>Install the other dependencies: <code>.\mach bootstrap</code></li>
<li>Build servoshell: <code>.\mach build</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Android</h3><a id="user-content-android" aria-label="Permalink: Android" href="#android"></a></p>
<ul dir="auto">
<li>Ensure that the following environment variables are set:
<ul dir="auto">
<li><code>ANDROID_SDK_ROOT</code></li>
<li><code>ANDROID_NDK_ROOT</code>: <code>$ANDROID_SDK_ROOT/ndk/28.2.13676358/</code>
<code>ANDROID_SDK_ROOT</code> can be any directory (such as <code>~/android-sdk</code>).
All of the Android build dependencies will be installed there.</li>
</ul>
</li>
<li>Install the latest version of the <a href="https://developer.android.com/studio#command-tools" rel="nofollow">Android command-line
tools</a> to
<code>$ANDROID_SDK_ROOT/cmdline-tools/latest</code>.</li>
<li>Run the following command to install the necessary components:
<div dir="auto" data-snippet-clipboard-copy-content="sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
 &quot;build-tools;34.0.0&quot; \
 &quot;emulator&quot; \
 &quot;ndk;28.2.13676358&quot; \
 &quot;platform-tools&quot; \
 &quot;platforms;android-33&quot; \
 &quot;system-images;android-33;google_apis;x86_64&quot;"><pre>sudo <span>$ANDROID_SDK_ROOT</span>/cmdline-tools/latest/bin/sdkmanager --install \
 <span><span>"</span>build-tools;34.0.0<span>"</span></span> \
 <span><span>"</span>emulator<span>"</span></span> \
 <span><span>"</span>ndk;28.2.13676358<span>"</span></span> \
 <span><span>"</span>platform-tools<span>"</span></span> \
 <span><span>"</span>platforms;android-33<span>"</span></span> \
 <span><span>"</span>system-images;android-33;google_apis;x86_64<span>"</span></span></pre></div>
</li>
<li>Follow the instructions above for the platform you are building on</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">OpenHarmony</h3><a id="user-content-openharmony" aria-label="Permalink: OpenHarmony" href="#openharmony"></a></p>
<ul dir="auto">
<li>Follow the instructions above for the platform you are building on to prepare the environment.</li>
<li>Depending on the target distribution (e.g. <code>HarmonyOS NEXT</code> vs pure <code>OpenHarmony</code>) the build configuration will differ slightly.</li>
<li>Ensure that the following environment variables are set
<ul dir="auto">
<li><code>DEVECO_SDK_HOME</code> (Required when targeting <code>HarmonyOS NEXT</code>)</li>
<li><code>OHOS_BASE_SDK_HOME</code> (Required when targeting <code>OpenHarmony</code>)</li>
<li><code>OHOS_SDK_NATIVE</code> (e.g. <code>${DEVECO_SDK_HOME}/default/openharmony/native</code> or <code>${OHOS_BASE_SDK_HOME}/${API_VERSION}/native</code>)</li>
<li><code>SERVO_OHOS_SIGNING_CONFIG</code>: Path to json file containing a valid signing configuration for the demo app.</li>
</ul>
</li>
<li>Review the detailed instructions at <a href="https://book.servo.org/hacking/building-for-openharmony.html" rel="nofollow">Building for OpenHarmony</a>.</li>
<li>The target distribution can be modified by passing <code>--flavor=&lt;default|harmonyos&gt;</code> to <code>mach &lt;build|package|install&gt;</code>.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alibaba Cloud says it cut Nvidia AI GPU use by 82% with new pooling system (349 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/semiconductors/alibaba-says-new-pooling-system-cut-nvidia-gpu-use-by-82-percent</link>
            <guid>45643163</guid>
            <pubDate>Mon, 20 Oct 2025 12:31:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/semiconductors/alibaba-says-new-pooling-system-cut-nvidia-gpu-use-by-82-percent">https://www.tomshardware.com/tech-industry/semiconductors/alibaba-says-new-pooling-system-cut-nvidia-gpu-use-by-82-percent</a>, See on <a href="https://news.ycombinator.com/item?id=45643163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN.jpg" alt="Alibaba Cloud" srcset="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Alibaba)</span>
</figcaption>
</div>

<div id="article-body">
<p id="caf228b5-5290-4a25-9b2c-43d6badcb8b3">Alibaba Cloud claims its new Aegaeon pooling system reduces the number of Nvidia GPUs required to serve large language models by 82% during a multi-month beta test inside its Model Studio marketplace. The result, published in a <a data-analytics-id="inline-link" href="https://ennanzhai.github.io/pub/sosp25-aegaeon.pdf" target="_blank">peer-reviewed paper</a> presented at the 2025 ACM Symposium on Operating Systems (SOSP) in Seoul, suggests that cloud providers may be able to extract significantly more inference capacity from existing silicon, especially in constrained markets like China, where the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/china-repurposes-used-nvidia-gpus" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/gpus/china-repurposes-used-nvidia-gpus">supply of Nvidia's latest H20s</a> remains limited.</p><p>Unlike training-time breakthroughs that chase model quality or speed, Aegaeon is an inference-time scheduler designed to maximize GPU utilization across many models with bursty or unpredictable demand. Instead of pinning one accelerator to one model, Aegaeon virtualizes GPU access at the token level, allowing it to schedule tiny slices of work across a shared pool. This means one H20 could serve several different models simultaneously, with system-wide “goodput” — a measure of effective output — rising by as much as nine times compared to older serverless systems.</p>

<p id="caf228b5-5290-4a25-9b2c-43d6badcb8b3-2">The system was tested in production over several months, according to the paper, which lists authors from both Peking University and Alibaba’s infrastructure division, including CTO Jingren Zhou. During that window, the number of GPUs needed to support dozens of different LLMs — ranging in size up to 72 billion parameters — fell from 1,192 to just 213.</p><p>While the paper does not break down which models contributed most to the savings, reporting by the <a data-analytics-id="inline-link" href="https://www.scmp.com/business/article/3329450/alibaba-cloud-claims-slash-nvidia-gpu-use-82-new-pooling-system?module=top_story&amp;pgtype=section"><em>South China Morning Post</em></a><em> </em>says the tests were conducted using Nvidia’s H20, one of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/jensen-huang-says-nvidia-china-market-share-has-fallen-to-zero" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/jensen-huang-says-nvidia-china-market-share-has-fallen-to-zero">few accelerators</a> still legally available to Chinese buyers under current U.S. export controls.</p><p>Whether those savings translate outside Alibaba’s stack remains to be seen. Alibaba Cloud’s paper does not specify the exact network fabric used in the beta test, but we know the company offers its own eRDMA elastic RDMA network and has a record of building highly‑integrated GPU serving stacks, suggesting the results may depend on an optimized, vertically integrated environment.</p>
<a href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" id="91c68ebe-b326-462c-8a81-636b58803280"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" alt="Google Preferred Source" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png">
</picture></p></div></figure></a>
<p id="de01fbb3-3508-4f25-a524-943c5df08f57"><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em> Tom's Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em> add us as a preferred source</em></a><em>, to get our latest news, analysis, &amp; reviews in your feeds.</em></p>
</div>



<!-- Drop in a standard article here maybe? -->



<div id="slice-container-authorBio-UfPxse5QFfEeNmgZisoaf5"><p>Luke James is a freelance writer and journalist.&nbsp; Although his background is in legal, he has a personal interest in all things tech, especially hardware and microelectronics, and anything regulatory.&nbsp;</p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI-generated 'poverty porn' fake images being used by aid agencies (168 pts)]]></title>
            <link>https://www.theguardian.com/global-development/2025/oct/20/ai-generated-poverty-porn-fake-images-being-used-by-aid-agencies</link>
            <guid>45643040</guid>
            <pubDate>Mon, 20 Oct 2025 12:17:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/global-development/2025/oct/20/ai-generated-poverty-porn-fake-images-being-used-by-aid-agencies">https://www.theguardian.com/global-development/2025/oct/20/ai-generated-poverty-porn-fake-images-being-used-by-aid-agencies</a>, See on <a href="https://news.ycombinator.com/item?id=45643040">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>AI-generated images of extreme poverty, children and sexual violence survivors are flooding stock photo sites and increasingly being used by leading health NGOs, according to global health professionals who have voiced concern over a new era of “poverty porn”.</p><p>“All over the place, people are using it,” said Noah Arnold, who works at Fairpicture, a Swiss-based organisation focused on promoting ethical imagery in global development. “Some are actively using AI imagery, and others, we know that they’re experimenting at least.”</p><p><a href="https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(23)00329-7/fulltext" data-link-name="in body link">Arsenii Alenichev, a researcher</a> at the Institute of Tropical Medicine in Antwerp studying the production of global health images, said: “The images replicate the visual grammar of poverty – children with empty plates, cracked earth, stereotypical visuals.”</p><p>Alenichev has collected more than 100 AI-generated images of extreme poverty used by individuals or NGOs as part of social media campaigns against hunger or sexual violence. Images he shared with the Guardian show exaggerated, stereotype-perpetuating scenes: children huddled together in muddy water; an African girl in a wedding dress with a tear staining her cheek. In a <a href="https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(25)00313-4/fulltext?rss=yes" data-link-name="in body link">comment piece published on Thursday</a> in the Lancet Global Health, he argues these images amount to “poverty porn 2.0”.</p><p>While it is hard to quantify the prevalence of the AI-generated images, Alenichev and others say their use is on the rise, driven by concerns over consent and cost. Arnold said that US funding cuts to NGO budgets had made matters worse.</p><p>“It is quite clear that various organisations are starting to consider synthetic images instead of real photography, because it’s cheap and you don’t need to bother with consent and everything,” said Alenichev.</p><p>AI-generated images of extreme poverty now appear in their dozens on popular stock photo sites, including <a href="https://stock.adobe.com/uk/search/images?filters%5Bcontent_type%3Aphoto%5D=1&amp;filters%5Bcontent_type%3Aillustration%5D=1&amp;filters%5Bcontent_type%3Azip_vector%5D=1&amp;filters%5Bcontent_type%3Avideo%5D=0&amp;filters%5Bcontent_type%3Atemplate%5D=0&amp;filters%5Bcontent_type%3A3d%5D=0&amp;filters%5Bcontent_type%3Aaudio%5D=0&amp;filters%5Binclude_stock_enterprise%5D=0&amp;filters%5Bis_editorial%5D=0&amp;filters%5Bfree_collection%5D=0&amp;filters%5Bcontent_type%3Aimage%5D=1&amp;filters%5Bgentech%5D=only&amp;k=poverty&amp;order=relevance&amp;price%5B%24%5D=1&amp;search_type=filter-select&amp;get_facets=1" data-link-name="in body link">Adobe Stock Photos</a> and <a href="https://www.freepik.com/search?ai=only&amp;format=search&amp;last_filter=ai&amp;last_value=only&amp;query=poverty" data-link-name="in body link">Freepik</a>, in response to queries such as “poverty”. Many bear captions such as “Photorealistic kid in refugee camp”; “Asian children swim in a river full of waste”; and “Caucasian white volunteer provides medical consultation to young black children in African village”. Adobe sells licences to the last two photos in that list for about £60.</p><p>“They are so racialised. They should never even let those be published because it’s like the worst stereotypes about Africa, or India, or you name it,” said Alenichev.</p><p>Joaquín Abela, CEO of Freepik, said the responsibility for using such extreme images lay with media consumers, and not with platforms such as his. The AI stock photos, he said, are generated by the platform’s global community of users, who can receive a licensing fee when Freepik’s customers choose to buy their images.</p><p>Freepik had attempted to curb biases it had found in other parts of its photo library, he said, by “injecting diversity” and trying to ensure gender balance into the photos of lawyers and CEOs hosted on the site.</p><p>But, he said, there was only so much his platform could do. “It’s like trying to dry the ocean. We make an effort, but in reality, if customers worldwide want images a certain way, there is absolutely nothing that anyone can do.”</p><figure id="f83a4bc0-27e2-4585-8c83-b8dd6140dbc1" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A series of photographs showing black and brown-skinned people living in poverty in what appear to be refugee camps" src="https://i.guim.co.uk/img/media/c4f9a6f4fa8474a2c2ac158c0745bdceab2c7ae0/5_0_2227_1211/master/2227.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="241.98248765154915" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A screen grab showing AI-generated images of ‘poverty’ on a stock photo site. Pictures such as these have raised concerns over biased imagery and stereotypes.</span> Illustration: Freepik</figcaption></figure><p>In the past, leading charities have used AI-generated images as part of their communications strategies on global health. In 2023, the Dutch arm of UK charity Plan International released a <a href="https://www.youtube.com/watch?v=wD_JjBWddq8" data-link-name="in body link">video campaign against child marriage</a> containing AI-generated images of a girl with a black eye, an older man and a pregnant teenager.</p><p>Last year, the <a href="https://www.youtube.com/watch?v=S38jbjC47oY" data-link-name="in body link">UN posted a video</a> on YouTube with AI-generated “re-enactments” of sexual violence in conflict, which included AI-generated testimony from a Burundian woman describing being raped by three men and left to die in 1993 during the country’s civil war. The video was removed after the Guardian contacted the UN for comment.</p><div><p>A UN Peacekeeping spokesperson said: “The video in question, which was produced over a year ago using a fast-evolving tool, has been taken down, as we believed it shows improper use of AI, and may pose risks regarding information integrity, blending real footage and near-real artificially generated content. </p><p>
 “The United Nations remains steadfast in its commitment to support victims of conflict-related sexual violence, including through innovation and creative advocacy.”</p></div><p>Arnold said the rising use of these AI images comes after years of debate in the sector around ethical imagery and dignified storytelling about poverty and violence. “Supposedly, it’s easier to take ready-made AI visuals that come without consent, because it’s not real people.”</p><figure id="dcc5b05b-a6e5-4e73-bab9-8671c357e49c" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:16,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;How AI monitoring is cutting stillbirths and neonatal deaths in a clinic in Malawi&quot;,&quot;elementId&quot;:&quot;dcc5b05b-a6e5-4e73-bab9-8671c357e49c&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/global-development/2024/dec/06/how-ai-monitoring-is-cutting-stillbirths-and-neonatal-deaths-in-a-clinic-in-malawi&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>Kate Kardol, an NGO communications consultant, said the images frightened her, and recalled earlier debates about the use of “poverty porn” in the sector.</p><p>“It saddens me that the fight for more ethical representation of people experiencing poverty now extends to the unreal,” she said.</p><p>Generative AI tools have long been found to replicate – and at times exaggerate – <a href="https://www.theguardian.com/technology/2024/mar/16/ai-racism-chatgpt-gemini-bias" data-link-name="in body link">broader societal biases</a>. The proliferation of biased images in global health communications may make the problem worse, said Alenichev, because the images could filter out into the wider internet and be used to train the next generation of AI models, a process which has been <a href="https://www.nytimes.com/interactive/2024/08/26/upshot/ai-synthetic-data.html" data-link-name="in body link">shown to amplify prejudice</a>.</p><p>A spokesperson for Plan International said the NGO had, as of this year: “adopted guidance advising against using AI to depict individual children”, and said the 2023 campaign had used AI-generated imagery to safeguard “the privacy and dignity of real girls”.</p><p>Adobe declined to comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS Outage: A Single Cloud Region Shouldn't Take Down the World. But It Did (297 pts)]]></title>
            <link>https://faun.dev/c/news/devopslinks/aws-outage-a-single-cloud-region-shouldnt-take-down-the-world-but-it-did/</link>
            <guid>45642951</guid>
            <pubDate>Mon, 20 Oct 2025 12:05:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://faun.dev/c/news/devopslinks/aws-outage-a-single-cloud-region-shouldnt-take-down-the-world-but-it-did/">https://faun.dev/c/news/devopslinks/aws-outage-a-single-cloud-region-shouldnt-take-down-the-world-but-it-did/</a>, See on <a href="https://news.ycombinator.com/item?id=45642951">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="markdown"><p>A significant outage of Amazon Web Services (AWS) disrupted numerous high-profile websites and services, including Amazon, Snapchat, Disney+, Reddit, and Canva. The outage was attributed to an "operational issue" affecting over 70 AWS services, causing widespread disruptions in cloud-based games and crypto exchanges like Coinbase. AWS reported signs of recovery shortly after the incident, but some services, such as Reddit, continued to experience issues.</p><p>The outage also impacted government websites like the UK's HMRC and various banking services, including Lloyds, Halifax, and the Bank of Scotland, leading to declined card transactions and inaccessible online banking. AWS identified the issue as related to DNS resolution in the US-EAST-1 region and worked on multiple paths to accelerate recovery. Despite significant recovery signs, some services faced delays due to a backlog of queued requests.</p><p>The incident highlighted the vulnerability of relying on a few major cloud service providers, as disruptions can have extensive ripple effects across numerous platforms.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matrix Conference 2025 Highlights (125 pts)]]></title>
            <link>https://element.io/blog/the-matrix-conference-a-seminal-moment-for-matrix/</link>
            <guid>45642923</guid>
            <pubDate>Mon, 20 Oct 2025 12:00:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://element.io/blog/the-matrix-conference-a-seminal-moment-for-matrix/">https://element.io/blog/the-matrix-conference-a-seminal-moment-for-matrix/</a>, See on <a href="https://news.ycombinator.com/item?id=45642923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://conference.matrix.org/?ref=element.io" rel="noreferrer">The Matrix Conference 2025</a> was a huge success; the energy and enthusiasm was just incredible!</p><p>We were delighted to be the anchor sponsor - thanks to The Matrix Foundation and everyone else that organised the conference, those who presented, the others sponsors and of course all those who attended!</p><p>The overriding vibe of the conference was one of incredible momentum - with so many governments presenting on their Matrix-based initiatives, there was a genuine realisation that Matrix is the future of government and inter-governmental communications.</p><h2 id="the-matrix-conference-on-demand">The Matrix Conference on-demand</h2><p>All the presentations given at The Matrix Conference are <a href="https://www.youtube.com/playlist?list=PLl5dnxRMP1hUgnYEbpEsEEhIqY_KlO3NG&amp;ref=element.io"><u>available here</u></a>. Each and every presentation is well worth watching.</p><h2 id="the-matrix-state-of-the-union">The Matrix State of the Union</h2><p>Matthew Hodgson gives an excellent overview of the entire Matrix universe. </p>
<!--kg-card-begin: html-->
<p>
<iframe src="https://www.youtube-nocookie.com/embed/2y8qtRLgalQ?si=V8Ie3LRn9Jaoi1Qf&amp;start=6" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p>
<!--kg-card-end: html-->
<p>For those interested in government and public sector adoption of Matrix, don’t miss Amandine Le Pape’s <a href="https://youtu.be/gHNSIiXyhdM?si=2zjD_dzpf7IzzlmD&amp;ref=element.io"><u>How Matrix is becoming the communication standard for the public sector</u></a>. </p><h2 id="elements-keynote">Element's keynote</h2><div><p>Neil Johnson’s talk includes a power-packed review of Element’s work over the last 12 months (and some sneak previews).</p><p>In particular, look out for </p><a href="https://element.io/server-suite/community?ref=element.io"><u>ESS Community</u></a><p> being installed in under a minute - and then, when the time is right, it being a seamless live-upgrade to </p><a href="https://element.io/server-suite/pro?ref=element.io"><u>ESS Pro</u></a><p>! The idea here is that ESS Community can be used, free of charge, for casual use (up to about 100 users) and also act as a way for organisations to run small scale evaluations. Those evaluations can then be easily upgraded to ESS Pro for increased scalability, performance, enterprise features and SLA-backed support.</p></div>
<!--kg-card-begin: html-->
<p>
<iframe src="https://www.youtube-nocookie.com/embed/TZgcdgv2NXk?si=DkpBp3qimfkXxlPt&amp;start=6" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p>
<!--kg-card-end: html-->
<h2 id="element-product-presentations">Element product presentations</h2><p><a href="https://youtu.be/BIYfFeFxcbc?si=qkzbcWNOU4n7EH_J&amp;ref=element.io"><u>ESS - Element’s distribution for Matrix deployments</u></a>, from Patrick Maier, gives more detail on Element Server Suite; covering ESS Community, ESS Pro and ESS for TI-Messenger. For those that want to get into the nitty-gritty, take a look at Gael Goinvic’s <a href="https://youtu.be/tApx4md-Cpk?si=7Bn43betJBBhAM_i&amp;ref=element.io"><u>Getting Started with ESS Community</u></a> workshop.&nbsp;</p><p><a href="https://element.io/pro-app?ref=element.io"><u>Element Pro</u></a>, our new app developed specifically for the workplace, created a huge buzz - particularly in-app colour theming, and the ability to now create a whitelabelled mobile app without the expense of maintaining a fork. Catch all the details from Andreas Sisask in his session; <a href="https://youtu.be/_cahXxr8d-4?si=xOFeWzlB-DQEmoTU&amp;ref=element.io"><u>Element X and Pro</u></a>. We’d also recommend the <a href="https://youtu.be/z0ULOptq2vk?si=gu-P0NikoKBmC4Br&amp;ref=element.io"><u>Element X Web</u></a> presentation and the session on <a href="https://youtu.be/Gjwz_7G1zdY?si=ndLrLKNIq_HVae5T&amp;ref=element.io"><u>Element Call</u></a>.</p><h2 id="the-real-stars-of-the-show">The real stars of the show!<br></h2><p>The best proof points, of course, are the deployments and initiatives that are already underway. The conference was packed with presentations from governments and public sector organisations, who are the real stars of the show!&nbsp;</p><p>Do take a look at the outstanding work being done across governments, NGOs and public sector organisations. </p>
<!--kg-card-begin: html-->


<div>
  <a href="https://www.youtube.com/watch?v=PqrQ1-dMrSA&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/PqrQ1-dMrSA/hqdefault.jpg" alt="">
    <p>Trialing Matrix within the European Commission for resilient and sovereign communications</p>
    <p>Nicolas Dubois, European Commission</p>
  </a>

  <a href="https://www.youtube.com/watch?v=4PoUmWadaQ0&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/4PoUmWadaQ0/hqdefault.jpg" alt="">
    <p>Matrix French gov deployment: opening a private federation securely</p>
    <p>Mathieu Velten, DINUM</p>
  </a>

  <a href="https://www.youtube.com/watch?v=S4iQBWnuSRM&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/S4iQBWnuSRM/hqdefault.jpg" alt="">
    <p>Consolidating Germany’s administrative communication: Towards a joint Matrix-based architecture</p>
    <p>Dominik Braun, FITKO</p>
  </a>

  <a href="https://youtu.be/dQeZLT0Rai8?ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/dQeZLT0Rai8/hqdefault.jpg" alt="">
    <p>Sweden’s Public Sector in Transition</p>
    <p>Anna Engström &amp; Kenneth Edwall, Försäkringskassan</p>
  </a>

  <a href="https://www.youtube.com/watch?v=xeRXFf4GDmw&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/xeRXFf4GDmw/hqdefault.jpg" alt="">
    <p>Luxchat(4gov)</p>
    <p>Patrick Weber, Luxembourg government</p>
  </a>

  <a href="https://youtu.be/2stYnXGUm0g?ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/2stYnXGUm0g/hqdefault.jpg" alt="">
    <p>Medical Care over Matrix with Delay during a Simulated Moonwalk</p>
    <p>Jan-Lukas Furmanek &amp; Aileen Rabsahl</p>
  </a>

  <a href="https://youtu.be/B9ghNwNjtFA?ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/B9ghNwNjtFA/hqdefault.jpg" alt="">
    <p>Matrix’s role in the German Healthcare System</p>
    <p>Marie Ruddeck, Gematik</p>
  </a>

  <a href="https://www.youtube.com/watch?v=HHxvYgei2_U&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/HHxvYgei2_U/hqdefault.jpg" alt="">
    <p>Nationwide Rollout of Matrix-Based Instant Messaging (TI-M) for 74 Million Statutorily Insured Citizens</p>
    <p>Jan Kohnert, Gematik</p>
  </a>

  <a href="https://www.youtube.com/watch?v=7LMxzIlpOuA&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/7LMxzIlpOuA/hqdefault.jpg" alt="">
    <p>Secure communication leveraging the Matrix protocol for UNICC and its partners</p>
    <p>Tima Soni, UNICC</p>
  </a>

  <a href="https://www.youtube.com/watch?v=Q0BBLeoRw9A&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/Q0BBLeoRw9A/hqdefault.jpg" alt="">
    <p>Supporting TF-X with Matrix: best practices and pitfalls</p>
    <p>Jeroen Franssen, NATO ACT</p>
  </a>

  <a href="https://www.youtube.com/watch?v=zY8qPe6aoxY&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/zY8qPe6aoxY/hqdefault.jpg" alt="">
    <p>The German BundesMessenger</p>
    <p>Kai A. Hiller, BWI</p>
  </a>

  <a href="https://www.youtube.com/watch?v=m3c2tPxFqXE&amp;ref=element.io" target="_blank">
    <img src="https://img.youtube.com/vi/m3c2tPxFqXE/hqdefault.jpg" alt="">
    <p>No Desk Is an Island: Enabling Cross-Border Workspace Communication</p>
    <p>Alexander Smolianitski, ZenDiS</p>
  </a>
</div>

<!--kg-card-end: html-->
<p>An open standard based on open source software, Matrix delivers the digital sovereignty, interoperability, resilience and security that governments need to transform the way they communicate; both within their own nation and across borders. These are the key benefits driving Matrix adoption.</p><p>The discussion between sessions, and in the evenings, had a consistent theme. Governments want communications that are:</p><p>1. <strong>Digitally sovereign</strong> - meaning end-user organisations have complete autonomy over their technology stack. Crucially, that means no vendor lock-in. That so many competing vendors sponsored and attended The Matrix Conference underlines the health of the Matrix ecosystem.</p><p>2. <strong>Interoperable</strong> - to both enable digital sovereignty and ensure that separate organisations can easily communicate with each other. The interoperability delivered by the Matrix open standard is absolutely crucial in enabling large-scale federated communications between multiple organisations.</p><p>3. <strong>Resilient</strong> - a decentralised communications network provides a far more robust communications architecture than a centralised network, which is paramount for government communications (as we write this blog post, Signal, Slack, Zoom and others are down due to their centralised design and a dependency on AWS).</p><p>4. <strong>Secure</strong> - end-to-end encryption is, of course, fundamental and viewed as ‘table stakes.’</p><p>European governments are rightly determined to control their own digital destiny, and are embracing Matrix as the foundation for real time communications. </p><p>Seeing the European Commission, France, FITKO, Germany, the German healthcare system, Luxembourg, NATO, Sweden, United Nations, ZenDiS and the European Space Agency all presenting on their Matrix deployments was just mindblowing! </p><p>Knowing how many other governments were also in attendance, soaking up insights and tips for their forthcoming Matrix projects, makes us really excited for a Matrix-based future that transforms cross-border collaboration and helps support a united, digitally sovereign Europe.</p><p>👋 See you all next year!</p><figure><img src="https://element.io/blog/content/images/2025/10/1760698709884-1.jpeg" alt="Element's keynote at The Matrix Conference 2025" loading="lazy" width="2000" height="1334" srcset="https://element.io/blog/content/images/size/w600/2025/10/1760698709884-1.jpeg 600w, https://element.io/blog/content/images/size/w1000/2025/10/1760698709884-1.jpeg 1000w, https://element.io/blog/content/images/size/w1600/2025/10/1760698709884-1.jpeg 1600w, https://element.io/blog/content/images/2025/10/1760698709884-1.jpeg 2048w" sizes="(min-width: 720px) 720px"><figcaption><span>Element's keynote at The Matrix Conference 2025</span></figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Playwright Skill for Claude Code – Less context than playwright-MCP (139 pts)]]></title>
            <link>https://github.com/lackeyjb/playwright-skill</link>
            <guid>45642911</guid>
            <pubDate>Mon, 20 Oct 2025 11:58:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lackeyjb/playwright-skill">https://github.com/lackeyjb/playwright-skill</a>, See on <a href="https://news.ycombinator.com/item?id=45642911">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Playwright Skill for Claude Code</h2><a id="user-content-playwright-skill-for-claude-code" aria-label="Permalink: Playwright Skill for Claude Code" href="#playwright-skill-for-claude-code"></a></p>
<p dir="auto"><strong>General-purpose browser automation as a Claude Skill</strong></p>
<p dir="auto">A <a href="https://www.anthropic.com/news/skills" rel="nofollow">Claude Skill</a> that enables Claude to write and execute any Playwright automation on-the-fly - from simple page tests to complex multi-step flows. Packaged as a <a href="https://docs.claude.com/en/docs/claude-code/plugins" rel="nofollow">Claude Code Plugin</a> for easy installation and distribution.</p>
<p dir="auto">Claude autonomously decides when to use this skill based on your browser automation needs, loading only the minimal information required for your specific task.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Any Automation Task</strong> - Claude writes custom code for your specific request, not limited to pre-built scripts</li>
<li><strong>Visible Browser by Default</strong> - See automation in real-time with <code>headless: false</code></li>
<li><strong>Zero Module Resolution Errors</strong> - Universal executor ensures proper module access</li>
<li><strong>Progressive Disclosure</strong> - Concise SKILL.md with full API reference loaded only when needed</li>
<li><strong>Safe Cleanup</strong> - Smart temp file management without race conditions</li>
<li><strong>Comprehensive Helpers</strong> - Optional utility functions for common tasks</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">This skill can be installed via the Claude Code plugin system or manually.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Via Plugin System (Recommended)</h3><a id="user-content-option-1-via-plugin-system-recommended" aria-label="Permalink: Option 1: Via Plugin System (Recommended)" href="#option-1-via-plugin-system-recommended"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add this repository as a marketplace
/plugin marketplace add lackeyjb/playwright-skill

# Install the plugin
/plugin install playwright-skill@playwright-skill

# Navigate to the skill directory and run setup
cd ~/.claude/plugins/marketplaces/playwright-skill/skills/playwright-skill
npm run setup"><pre><span><span>#</span> Add this repository as a marketplace</span>
/plugin marketplace add lackeyjb/playwright-skill

<span><span>#</span> Install the plugin</span>
/plugin install playwright-skill@playwright-skill

<span><span>#</span> Navigate to the skill directory and run setup</span>
<span>cd</span> <span>~</span>/.claude/plugins/marketplaces/playwright-skill/skills/playwright-skill
npm run setup</pre></div>
<p dir="auto">Verify installation by running <code>/help</code> to confirm the skill is available.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Manual Git Clone</h3><a id="user-content-option-2-manual-git-clone" aria-label="Permalink: Option 2: Manual Git Clone" href="#option-2-manual-git-clone"></a></p>
<p dir="auto">Install directly from GitHub to your skills directory:</p>
<p dir="auto"><strong>Global Installation (Available Everywhere):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Navigate to your Claude skills directory
cd ~/.claude/skills

# Clone the skill
git clone https://github.com/lackeyjb/playwright-skill.git

# Navigate into the skill directory (note the nested structure)
cd playwright-skill/skills/playwright-skill

# Install dependencies and Chromium browser
npm run setup"><pre><span><span>#</span> Navigate to your Claude skills directory</span>
<span>cd</span> <span>~</span>/.claude/skills

<span><span>#</span> Clone the skill</span>
git clone https://github.com/lackeyjb/playwright-skill.git

<span><span>#</span> Navigate into the skill directory (note the nested structure)</span>
<span>cd</span> playwright-skill/skills/playwright-skill

<span><span>#</span> Install dependencies and Chromium browser</span>
npm run setup</pre></div>
<p dir="auto"><strong>Project-Specific Installation:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install in a specific project
cd /path/to/your/project
mkdir -p .claude/skills
cd .claude/skills
git clone https://github.com/lackeyjb/playwright-skill.git
cd playwright-skill/skills/playwright-skill
npm run setup"><pre><span><span>#</span> Install in a specific project</span>
<span>cd</span> /path/to/your/project
mkdir -p .claude/skills
<span>cd</span> .claude/skills
git clone https://github.com/lackeyjb/playwright-skill.git
<span>cd</span> playwright-skill/skills/playwright-skill
npm run setup</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: Download Release</h3><a id="user-content-option-3-download-release" aria-label="Permalink: Option 3: Download Release" href="#option-3-download-release"></a></p>
<ol dir="auto">
<li>Download the latest release from <a href="https://github.com/lackeyjb/playwright-skill/releases">GitHub Releases</a></li>
<li>Extract to:
<ul dir="auto">
<li>Global: <code>~/.claude/skills/playwright-skill</code></li>
<li>Project: <code>/path/to/your/project/.claude/skills/playwright-skill</code></li>
</ul>
</li>
<li>Navigate to the skill directory and run setup:
<div dir="auto" data-snippet-clipboard-copy-content="cd playwright-skill/skills/playwright-skill
npm run setup"><pre><span>cd</span> playwright-skill/skills/playwright-skill
npm run setup</pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Verify Installation</h3><a id="user-content-verify-installation" aria-label="Permalink: Verify Installation" href="#verify-installation"></a></p>
<p dir="auto">Run <code>/help</code> to confirm the skill is loaded, then ask Claude to perform a simple browser task like "Test if google.com loads".</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto">After installation, simply ask Claude to test or automate any browser task. Claude will write custom Playwright code, execute it, and return results with screenshots and console output.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage Examples</h2><a id="user-content-usage-examples" aria-label="Permalink: Usage Examples" href="#usage-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test Any Page</h3><a id="user-content-test-any-page" aria-label="Permalink: Test Any Page" href="#test-any-page"></a></p>
<div data-snippet-clipboard-copy-content="&quot;Test the homepage&quot;
&quot;Check if the contact form works&quot;
&quot;Verify the signup flow&quot;"><pre><code>"Test the homepage"
"Check if the contact form works"
"Verify the signup flow"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Visual Testing</h3><a id="user-content-visual-testing" aria-label="Permalink: Visual Testing" href="#visual-testing"></a></p>
<div data-snippet-clipboard-copy-content="&quot;Take screenshots of the dashboard in mobile and desktop&quot;
&quot;Test responsive design across different viewports&quot;"><pre><code>"Take screenshots of the dashboard in mobile and desktop"
"Test responsive design across different viewports"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Interaction Testing</h3><a id="user-content-interaction-testing" aria-label="Permalink: Interaction Testing" href="#interaction-testing"></a></p>
<div data-snippet-clipboard-copy-content="&quot;Fill out the registration form and submit it&quot;
&quot;Click through the main navigation&quot;
&quot;Test the search functionality&quot;"><pre><code>"Fill out the registration form and submit it"
"Click through the main navigation"
"Test the search functionality"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Validation</h3><a id="user-content-validation" aria-label="Permalink: Validation" href="#validation"></a></p>
<div data-snippet-clipboard-copy-content="&quot;Check for broken links&quot;
&quot;Verify all images load&quot;
&quot;Test form validation&quot;"><pre><code>"Check for broken links"
"Verify all images load"
"Test form validation"
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How It Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How It Works" href="#how-it-works"></a></p>
<ol dir="auto">
<li>Describe what you want to test or automate</li>
<li>Claude writes custom Playwright code for the task</li>
<li>The universal executor (run.js) runs it with proper module resolution</li>
<li>Browser opens (visible by default) and automation executes</li>
<li>Results are displayed with console output and screenshots</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Default settings:</p>
<ul dir="auto">
<li><strong>Headless:</strong> <code>false</code> (browser visible unless explicitly requested otherwise)</li>
<li><strong>Slow Motion:</strong> <code>100ms</code> for visibility</li>
<li><strong>Timeout:</strong> <code>30s</code></li>
<li><strong>Screenshots:</strong> Saved to <code>/tmp/</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="playwright-skill/
├── .claude-plugin/
│   ├── plugin.json          # Plugin metadata for distribution
│   └── marketplace.json     # Marketplace configuration
├── skills/
│   └── playwright-skill/    # The actual skill (Claude discovers this)
│       ├── SKILL.md         # What Claude reads (314 lines)
│       ├── run.js           # Universal executor (proper module resolution)
│       ├── package.json     # Dependencies &amp; setup scripts
│       └── lib/
│           └── helpers.js   # Optional utility functions
├── API_REFERENCE.md         # Full Playwright API reference (630 lines)
├── README.md                # This file - user documentation
├── CONTRIBUTING.md          # Contribution guidelines
└── LICENSE                  # MIT License"><pre><code>playwright-skill/
├── .claude-plugin/
│   ├── plugin.json          # Plugin metadata for distribution
│   └── marketplace.json     # Marketplace configuration
├── skills/
│   └── playwright-skill/    # The actual skill (Claude discovers this)
│       ├── SKILL.md         # What Claude reads (314 lines)
│       ├── run.js           # Universal executor (proper module resolution)
│       ├── package.json     # Dependencies &amp; setup scripts
│       └── lib/
│           └── helpers.js   # Optional utility functions
├── API_REFERENCE.md         # Full Playwright API reference (630 lines)
├── README.md                # This file - user documentation
├── CONTRIBUTING.md          # Contribution guidelines
└── LICENSE                  # MIT License
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced Usage</h2><a id="user-content-advanced-usage" aria-label="Permalink: Advanced Usage" href="#advanced-usage"></a></p>
<p dir="auto">Claude will automatically load <code>API_REFERENCE.md</code> when needed for comprehensive documentation on selectors, network interception, authentication, visual regression testing, mobile emulation, performance testing, and debugging.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dependencies</h2><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<ul dir="auto">
<li>Node.js &gt;= 14.0.0</li>
<li>Playwright ^1.48.0 (installed via <code>npm run setup</code>)</li>
<li>Chromium (installed via <code>npm run setup</code>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto"><strong>Playwright not installed?</strong>
Navigate to the skill directory and run <code>npm run setup</code>.</p>
<p dir="auto"><strong>Module not found errors?</strong>
Ensure automation runs via <code>run.js</code>, which handles module resolution.</p>
<p dir="auto"><strong>Browser doesn't open?</strong>
Verify <code>headless: false</code> is set. The skill defaults to visible browser unless headless mode is requested.</p>
<p dir="auto"><strong>Install all browsers?</strong>
Run <code>npm run install-all-browsers</code> from the skill directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is a Claude Skill?</h2><a id="user-content-what-is-a-claude-skill" aria-label="Permalink: What is a Claude Skill?" href="#what-is-a-claude-skill"></a></p>
<p dir="auto"><a href="https://www.anthropic.com/news/skills" rel="nofollow">Skills</a> are modular capabilities that extend Claude's functionality. Unlike slash commands that you invoke manually, skills are model-invoked—Claude autonomously decides when to use them based on your request.</p>
<p dir="auto">When you ask Claude to test a webpage or automate browser interactions, Claude discovers this skill, loads the necessary instructions, executes custom Playwright code, and returns results with screenshots and console output.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome. Fork the repository, create a feature branch, make your changes, and submit a pull request. See <a href="https://github.com/lackeyjb/playwright-skill/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Learn More</h2><a id="user-content-learn-more" aria-label="Permalink: Learn More" href="#learn-more"></a></p>
<ul dir="auto">
<li><a href="https://www.anthropic.com/news/skills" rel="nofollow">Claude Skills</a> - Official announcement from Anthropic</li>
<li><a href="https://docs.claude.com/en/docs/claude-code/skills" rel="nofollow">Claude Code Skills Documentation</a></li>
<li><a href="https://docs.claude.com/en/docs/claude-code/plugins" rel="nofollow">Claude Code Plugins Documentation</a></li>
<li><a href="https://docs.claude.com/en/docs/claude-code/plugin-marketplaces" rel="nofollow">Plugin Marketplaces</a></li>
<li><a href="https://github.com/lackeyjb/playwright-skill/blob/main/API_REFERENCE.md">API_REFERENCE.md</a> - Full Playwright documentation</li>
<li><a href="https://github.com/lackeyjb/playwright-skill/issues">GitHub Issues</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License - see <a href="https://github.com/lackeyjb/playwright-skill/blob/main/LICENSE">LICENSE</a> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beaver-engineered dam in the Czech Republic (113 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Beaver-engineered_dam_in_the_Czech_Republic</link>
            <guid>45642562</guid>
            <pubDate>Mon, 20 Oct 2025 11:08:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Beaver-engineered_dam_in_the_Czech_Republic">https://en.wikipedia.org/wiki/Beaver-engineered_dam_in_the_Czech_Republic</a>, See on <a href="https://news.ycombinator.com/item?id=45642562">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Tayside_Beaver_mother_and_kit_June_5,_2010_Ray_Scott.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Tayside_Beaver_mother_and_kit_June_5%2C_2010_Ray_Scott.jpg/250px-Tayside_Beaver_mother_and_kit_June_5%2C_2010_Ray_Scott.jpg" decoding="async" width="250" height="189" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Tayside_Beaver_mother_and_kit_June_5%2C_2010_Ray_Scott.jpg/500px-Tayside_Beaver_mother_and_kit_June_5%2C_2010_Ray_Scott.jpg 1.5x" data-file-width="678" data-file-height="512"></a><figcaption>A Eurasian beaver with her kit along the <a href="https://en.wikipedia.org/wiki/River_Tay" title="River Tay">River Tay</a></figcaption></figure>
<p>In early 2025, <a href="https://en.wikipedia.org/wiki/Eurasian_beaver" title="Eurasian beaver">beaver</a> activity in the <a href="https://en.wikipedia.org/wiki/Brdy" title="Brdy">Brdy</a> Protected Landscape Area, <a href="https://en.wikipedia.org/wiki/Czech_Republic" title="Czech Republic">Czech Republic</a>, contributed to the restoration of a <a href="https://en.wikipedia.org/wiki/Wetland" title="Wetland">wetland</a> ecosystem. A family of beavers constructed a series of dams that accomplished environmental goals set by the Czech government, which had delayed its proposed project since 2018 for bureaucratic and financial reasons. The <a href="https://en.wikipedia.org/wiki/Beaver_dam" title="Beaver dam">beaver-built dams</a> saved the Czech government approximately US$1.2 million, providing <a href="https://en.wikipedia.org/wiki/Ecology" title="Ecology">ecological</a> benefits including improved water quality, enhanced <a href="https://en.wikipedia.org/wiki/Biodiversity" title="Biodiversity">biodiversity</a>, and better water retention.<sup id="cite_ref-:0_1-0"><a href="#cite_note-:0-1"><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-:1_2-0"><a href="#cite_note-:1-2"><span>[</span>2<span>]</span></a></sup><sup id="cite_ref-3"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup>
</p>
<meta property="mw:PageProp/toc">

<p>The Brdy region, located south of <a href="https://en.wikipedia.org/wiki/Prague" title="Prague">Prague</a>, had been affected by <a href="https://en.wikipedia.org/wiki/Artificial_drainage" title="Artificial drainage">artificial drainage</a> systems established by the <a href="https://en.wikipedia.org/w/index.php?title=Brdy_Military_District&amp;action=edit&amp;redlink=1" title="Brdy Military District (page does not exist)">Brdy Military District</a><span>&nbsp;[<a href="https://cs.wikipedia.org/wiki/Vojensk%C3%BD_%C3%BAjezd_Brdy" title="cs:Vojenský újezd Brdy">cs</a>]</span>, leading to <a href="https://en.wikipedia.org/wiki/Environmental_degradation" title="Environmental degradation">environmental degradation</a>. Decades earlier, soldiers had excavated bypass <a href="https://en.wikipedia.org/wiki/Gully" title="Gully">gullies</a> to drain water from the land, transforming the wetland into a <a href="https://en.wikipedia.org/wiki/Drylands" title="Drylands">dry terrain</a>.<sup id="cite_ref-:0_1-1"><a href="#cite_note-:0-1"><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-:1_2-1"><a href="#cite_note-:1-2"><span>[</span>2<span>]</span></a></sup> In 2016, the <a href="https://en.wikipedia.org/w/index.php?title=Brdy_Protected_Landscape_Area&amp;action=edit&amp;redlink=1" title="Brdy Protected Landscape Area (page does not exist)">Brdy Protected Landscape Area</a><span>&nbsp;[<a href="https://cs.wikipedia.org/wiki/Chr%C3%A1n%C4%9Bn%C3%A1_krajinn%C3%A1_oblast_Brdy" title="cs:Chráněná krajinná oblast Brdy">cs</a>]</span> was established in place of the abolished military district and some surrounding areas.<sup id="cite_ref-4"><a href="#cite_note-4"><span>[</span>4<span>]</span></a></sup><sup id="cite_ref-5"><a href="#cite_note-5"><span>[</span>5<span>]</span></a></sup> Recognizing the ecological damage, the administration of the Brdy protected landscape area drafted plans in 2018 to construct small dams to restore the wetland and protect the <a href="https://en.wikipedia.org/wiki/Klabava_(river)" title="Klabava (river)">Klabava river</a> from <a href="https://en.wikipedia.org/wiki/Sedimentation" title="Sedimentation">sedimentation</a> and acidic water pollution originating from nearby ponds.<sup id="cite_ref-:3_6-0"><a href="#cite_note-:3-6"><span>[</span>6<span>]</span></a></sup> However, bureaucratic obstacles, unresolved land ownership disputes, and financial constraints led to significant delays in implementing the project.<sup id="cite_ref-:2_7-0"><a href="#cite_note-:2-7"><span>[</span>7<span>]</span></a></sup>
</p>
<div><h2 id="Beaver_construction">Beaver construction</h2><p><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Beaver-engineered_dam_in_the_Czech_Republic&amp;action=edit&amp;section=2" title="Edit section: Beaver construction"><span>edit</span></a><span>]</span></span></p></div>
<table><tbody><tr><th colspan="2">External image</th></tr><tr><td colspan="2"><span typeof="mw:File"><span><img alt="image icon" src="https://upload.wikimedia.org/wikipedia/en/thumb/6/61/Searchtool.svg/20px-Searchtool.svg.png" decoding="async" width="16" height="16" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/6/61/Searchtool.svg/40px-Searchtool.svg.png 1.5x" data-file-width="512" data-file-height="512"></span></span> <a rel="nofollow" href="https://english.radio.cz/sites/default/files/styles/rcz_lightbox_v2/public/images/892a696677ea568f98a3fad53e4bb3ad.jpg?itok=QZ5VagkW&amp;timestamp=1740061110">Image of the natural dam created by beavers in Brdy</a> photographed for the Nature Conservation Agency of the Czech Republic</td></tr></tbody></table>
<p>In early 2025, a family of <a href="https://en.wikipedia.org/wiki/Eurasian_beaver" title="Eurasian beaver">Eurasian beavers</a> (<i>Castor fiber</i>) naturally built a series of dams in the same locations where the human-planned infrastructure was intended.<sup id="cite_ref-8"><a href="#cite_note-8"><span>[</span>8<span>]</span></a></sup> The beavers used wood, mud, and stones to create structures that slowed water drainage and restored the wetland environment. This spontaneous restoration effort resulted in a thriving ecosystem, benefiting local wildlife such as rare stone crayfish, frogs, aquatic insects, and bird species dependent on wetland habitats.<sup id="cite_ref-:3_6-1"><a href="#cite_note-:3-6"><span>[</span>6<span>]</span></a></sup>
</p><p>In 2013 a family of beavers also slowed the time it takes for water upstream to travel to <a href="https://en.wikipedia.org/wiki/Winzer" title="Winzer">Winzer</a>, Germany from around 45 minutes to 20 days, according to Gerhard Shwab, a local beaver specialist,<sup id="cite_ref-9"><a href="#cite_note-9"><span>[</span>9<span>]</span></a></sup> which was estimated to have saved the local government €<span><span data-sort-value="7004300000000000000♠"></span>30<span>000</span></span>. 
</p><p>Experts noted that beavers are instinctive engineers capable of altering landscapes to support water retention and biodiversity. Their activities help regulate water flow, mitigate soil erosion, and improve water filtration, making them vital contributors to wetland health. The beaver-made dams in Brdy not only recreated a functioning wetland but also provided long-term benefits by reducing <a href="https://en.wikipedia.org/wiki/Flood_risk" title="Flood risk">flood risks</a>, preventing drought effects, and maintaining a balanced ecosystem.<sup id="cite_ref-:0_1-2"><a href="#cite_note-:0-1"><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-10"><a href="#cite_note-10"><span>[</span>10<span>]</span></a></sup> 
</p>
<div><h2 id="Reaction_and_recognition">Reaction and recognition</h2><p><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Beaver-engineered_dam_in_the_Czech_Republic&amp;action=edit&amp;section=3" title="Edit section: Reaction and recognition"><span>edit</span></a><span>]</span></span></p></div>
<p>Czech conservation authorities praised the beavers for their unexpected yet effective environmental work. Bohumil Fišer, head of the Brdy Protected Landscape Area, stated that the beavers "built the dams without any project documentation and for free", and achieved the desired ecological outcomes "practically overnight".<sup id="cite_ref-:1_2-2"><a href="#cite_note-:1-2"><span>[</span>2<span>]</span></a></sup><sup id="cite_ref-:3_6-2"><a href="#cite_note-:3-6"><span>[</span>6<span>]</span></a></sup> The estimated cost savings for the Czech government amounted to 30 million <a href="https://en.wikipedia.org/wiki/Czech_koruna" title="Czech koruna">Czech koruna</a> (<a href="https://en.wikipedia.org/wiki/United_States_dollar" title="United States dollar">US$</a>1.2 million), as the project was completed without human labor or funding.<sup id="cite_ref-11"><a href="#cite_note-11"><span>[</span>11<span>]</span></a></sup>
</p><p>Zoologists and environmentalists emphasized the broader significance of the event, reinforcing the role of beavers as "ecosystem engineers".<sup id="cite_ref-12"><a href="#cite_note-12"><span>[</span>12<span>]</span></a></sup> This case contributed to growing discussions in Europe about the benefits of beaver <a href="https://en.wikipedia.org/wiki/Rewilding" title="Rewilding">rewilding</a> programs, particularly in regions where their activity supports <a href="https://en.wikipedia.org/wiki/Flood_management" title="Flood management">flood management</a>, water conservation, and habitat restoration.<sup id="cite_ref-:0_1-3"><a href="#cite_note-:0-1"><span>[</span>1<span>]</span></a></sup>
</p><p>The Brdy beaver colony is part of a larger resurgence of Eurasian beaver populations in the Czech Republic, with estimates indicating around 15,000 individuals across the country.<sup id="cite_ref-:2_7-1"><a href="#cite_note-:2-7"><span>[</span>7<span>]</span></a></sup> While beavers can sometimes create conflicts by felling trees or flooding agricultural lands, officials noted that the Brdy site is located far from farmland, making long-term coexistence with the beavers feasible.<sup id="cite_ref-13"><a href="#cite_note-13"><span>[</span>13<span>]</span></a></sup> Authorities anticipate no significant conflicts with the beaver colony for at least the next decade.<sup id="cite_ref-14"><a href="#cite_note-14"><span>[</span>14<span>]</span></a></sup>
</p>

<div><ol>
<li id="cite_note-:0-1"><span>^ <a href="#cite_ref-:0_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:0_1-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-:0_1-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFAndrei2025">Andrei, Mihai (2025-02-12). <a rel="nofollow" href="https://www.zmescience.com/science/news-science/beavers-in-the-czech-republic-built-dams-that-saved-authorities-1-25-million/">"Beavers Built a $1.2M Dam for Free — And Saved a Czech River"</a>. ZME Science<span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Beavers+Built+a+%241.2M+Dam+for+Free+%E2%80%94+And+Saved+a+Czech+River&amp;rft.pub=ZME+Science&amp;rft.date=2025-02-12&amp;rft.aulast=Andrei&amp;rft.aufirst=Mihai&amp;rft_id=https%3A%2F%2Fwww.zmescience.com%2Fscience%2Fnews-science%2Fbeavers-in-the-czech-republic-built-dams-that-saved-authorities-1-25-million%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-:1-2"><span>^ <a href="#cite_ref-:1_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:1_2-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFAlbeck-Ripka2025">Albeck-Ripka, Livia (2025-02-12). <a rel="nofollow" href="https://www.nytimes.com/2025/02/12/world/europe/beavers-prague-czech-republic-dam.html">"Czech Dam Project Was Stalled by Bureaucracy. Beavers Built Their Own"</a>. <i>The New York Times</i>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://search.worldcat.org/issn/0362-4331">0362-4331</a><span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Czech+Dam+Project+Was+Stalled+by+Bureaucracy.+Beavers+Built+Their+Own.&amp;rft.date=2025-02-12&amp;rft.issn=0362-4331&amp;rft.aulast=Albeck-Ripka&amp;rft.aufirst=Livia&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2025%2F02%2F12%2Fworld%2Feurope%2Fbeavers-prague-czech-republic-dam.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.nationalgeographic.com/animals/article/beaver-dam-czech-republic">"These eager beavers saved the Czech government $1.2 million"</a>. <i>National Geographic</i>. 2025-03-02<span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Geographic&amp;rft.atitle=These+eager+beavers+saved+the+Czech+government+%241.2+million&amp;rft.date=2025-03-02&amp;rft_id=https%3A%2F%2Fwww.nationalgeographic.com%2Fanimals%2Farticle%2Fbeaver-dam-czech-republic&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><a rel="nofollow" href="https://www.idnes.cz/praha/zpravy/chranena-oblast-v-brdech-bude-vetsi-nez-vojenska-obcim-vzniknou-potize.A110919_1653884_praha-zpravy_kol">Chráněná oblast v Brdech bude větší než vojenská, obce čekají potíže</a></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><a rel="nofollow" href="https://web.archive.org/web/20160304221458/http://brdy.ochranaprirody.cz/vyhlaseni-chranene-krajinne-oblast-brdy/">"Vyhlášení Chráněné krajinné oblasti Brdy"</a> ("Declaration of the Brdy Protected Landscape Area")</span>
</li>
<li id="cite_note-:3-6"><span>^ <a href="#cite_ref-:3_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:3_6-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:3_6-2"><sup><i><b>c</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://english.radio.cz/beavers-build-planned-dams-protected-landscape-area-while-local-officials-still-8841536">"Beavers build planned dams in protected landscape area, while local officials still seeking permits"</a>. <a href="https://en.wikipedia.org/wiki/Czech_Radio" title="Czech Radio">Czech Radio</a>. 2025-01-31<span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Beavers+build+planned+dams+in+protected+landscape+area%2C+while+local+officials+still+seeking+permits&amp;rft.pub=Czech+Radio&amp;rft.date=2025-01-31&amp;rft_id=https%3A%2F%2Fenglish.radio.cz%2Fbeavers-build-planned-dams-protected-landscape-area-while-local-officials-still-8841536&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-:2-7"><span>^ <a href="#cite_ref-:2_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:2_7-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://www.jpost.com/omg/viral-news-from-the-web/article-841454">"Beavers save Czech government €1.2 million by building planned dam"</a>. <i>The Jerusalem Post</i>. 2025-02-10<span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Jerusalem+Post&amp;rft.atitle=Beavers+save+Czech+government+%E2%82%AC1.2+million+by+building+planned+dam&amp;rft.date=2025-02-10&amp;rft_id=https%3A%2F%2Fwww.jpost.com%2Fomg%2Fviral-news-from-the-web%2Farticle-841454&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFTravers">Travers, Scott. <a rel="nofollow" href="https://www.forbes.com/sites/scotttravers/2025/02/27/3-surprising-stories-that-prove-beavers-are-natures-most-diligent-water-engineers/">"3 Surprising Stories That Prove Beavers Are Nature's Most Diligent Water Engineers"</a>. <i>Forbes</i><span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=3+Surprising+Stories+That+Prove+Beavers+Are+Nature%27s+Most+Diligent+Water+Engineers&amp;rft.aulast=Travers&amp;rft.aufirst=Scott&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fscotttravers%2F2025%2F02%2F27%2F3-surprising-stories-that-prove-beavers-are-natures-most-diligent-water-engineers%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.euronews.com/green/2025/03/01/czechias-1m-dam-built-for-free-by-beavers-heres-where-else-theyre-doing-good-work">"Czechia's €1m dam built for free by beavers: Here's where else they're doing good work"</a>. <i>euronews.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=euronews.com&amp;rft.atitle=Czechia%27s+%E2%82%AC1m+dam+built+for+free+by+beavers%3A+Here%27s+where+else+they%27re+doing+good+work&amp;rft_id=https%3A%2F%2Fwww.euronews.com%2Fgreen%2F2025%2F03%2F01%2Fczechias-1m-dam-built-for-free-by-beavers-heres-where-else-theyre-doing-good-work&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.huffpost.com/entry/beavers-dam-project-czech-republic_n_67a63a7be4b0d9a21f36c768">"Pricey Dam Project 7 Years In The Making Finished By Beavers For Free"</a>. <i>HuffPost</i>. 2025-02-08<span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=HuffPost&amp;rft.atitle=Pricey+Dam+Project+7+Years+In+The+Making+Finished+By+Beavers+For+Free&amp;rft.date=2025-02-08&amp;rft_id=https%3A%2F%2Fwww.huffpost.com%2Fentry%2Fbeavers-dam-project-czech-republic_n_67a63a7be4b0d9a21f36c768&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFMessenger2025">Messenger, Stephen (2025-02-07). <a rel="nofollow" href="https://www.thedodo.com/daily-dodo/government-scraps-construction-project-after-beavers-finish-the-job-themselves">"Government Scraps Construction Project After Beavers Finish the Job Themselves"</a>. <i>The Dodo</i><span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Dodo&amp;rft.atitle=Government+Scraps+Construction+Project+After+Beavers+Finish+the+Job+Themselves&amp;rft.date=2025-02-07&amp;rft.aulast=Messenger&amp;rft.aufirst=Stephen&amp;rft_id=https%3A%2F%2Fwww.thedodo.com%2Fdaily-dodo%2Fgovernment-scraps-construction-project-after-beavers-finish-the-job-themselves&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFBarber2025">Barber, Harriet (2025-02-09). <a rel="nofollow" href="https://www.telegraph.co.uk/world-news/2025/02/09/beavers-complete-stalled-dam-save-czech-government-money/">"Beavers finish seven-year dam project in two days"</a>. <i>The Telegraph</i>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://search.worldcat.org/issn/0307-1235">0307-1235</a><span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Telegraph&amp;rft.atitle=Beavers+finish+seven-year+dam+project+in+two+days&amp;rft.date=2025-02-09&amp;rft.issn=0307-1235&amp;rft.aulast=Barber&amp;rft.aufirst=Harriet&amp;rft_id=https%3A%2F%2Fwww.telegraph.co.uk%2Fworld-news%2F2025%2F02%2F09%2Fbeavers-complete-stalled-dam-save-czech-government-money%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.france24.com/en/live-news/20250211-dam-fine-beavers-save-czech-treasury-1-million">"Dam fine: beavers save Czech treasury $1 million"</a>. <i>France 24</i>. 2025-02-11<span>. Retrieved <span>2025-03-06</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=France+24&amp;rft.atitle=Dam+fine%3A+beavers+save+Czech+treasury+%241+million&amp;rft.date=2025-02-11&amp;rft_id=https%3A%2F%2Fwww.france24.com%2Fen%2Flive-news%2F20250211-dam-fine-beavers-save-czech-treasury-1-million&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite id="CITEREFFrance-Press2025">France-Press, Agence (2025-02-11). <a rel="nofollow" href="https://www.theguardian.com/world/2025/feb/11/beavers-save-czech-taxpayers-by-flooding-ex-army-training-site">"Eager beavers: rodents engineer Czech wetland project after years of human delay"</a>. <i>The Guardian</i>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://search.worldcat.org/issn/0261-3077">0261-3077</a><span>. Retrieved <span>2025-03-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Guardian&amp;rft.atitle=Eager+beavers%3A+rodents+engineer+Czech+wetland+project+after+years+of+human+delay&amp;rft.date=2025-02-11&amp;rft.issn=0261-3077&amp;rft.aulast=France-Press&amp;rft.aufirst=Agence&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Fworld%2F2025%2Ffeb%2F11%2Fbeavers-save-czech-taxpayers-by-flooding-ex-army-training-site&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABeaver-engineered+dam+in+the+Czech+Republic"></span></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Parsed by mw‐api‐ext.eqiad.main‐7685855cb9‐s2nwh
Cached time: 20251020141533
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.344 seconds
Real time usage: 0.426 seconds
Preprocessor visited node count: 1727/1000000
Revision size: 9053/2097152 bytes
Post‐expand include size: 27006/2097152 bytes
Template argument size: 2060/2097152 bytes
Highest expansion depth: 9/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 47462/5000000 bytes
Lua time usage: 0.208/10.000 seconds
Lua memory usage: 6875189/52428800 bytes
Number of Wikibase entities loaded: 0/500
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  387.203      1 -total
 45.62%  176.627      1 Template:Reflist
 34.81%  134.796      9 Template:Cite_web
 25.30%   97.949      1 Template:Short_description
 13.97%   54.080      2 Template:Pagetype
 10.72%   41.526      1 Template:External_media
  9.20%   35.628      1 Template:Infobox
  8.41%   32.578      1 Template:Val
  6.76%   26.169      2 Template:Ill
  5.93%   22.978      7 Template:Main_other
-->

<!-- Saved in parser cache with key enwiki:pcache:79362707:|#|:idhash:canonical and timestamp 20251020141533 and revision id 1317867240. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Major AWS outage takes down Fortnite, Alexa, Snapchat, and more (209 pts)]]></title>
            <link>https://www.theverge.com/news/802486/aws-outage-alexa-fortnite-snapchat-offline</link>
            <guid>45641143</guid>
            <pubDate>Mon, 20 Oct 2025 08:12:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/802486/aws-outage-alexa-fortnite-snapchat-offline">https://www.theverge.com/news/802486/aws-outage-alexa-fortnite-snapchat-offline</a>, See on <a href="https://news.ycombinator.com/item?id=45641143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>Amazon Web Services (AWS) is currently experiencing a major outage that has taken down online services, including Amazon, Alexa, Snapchat, <em>Fortnite</em>, <a href="https://status.openai.com/incidents/01K80CBJD5Z64DF82KGT3K3QE0">ChatGPT</a>, <a href="https://x.com/EOSStatus/status/1980194104115150858">Epic Games Store, Epic Online Services</a>, and more. The <a href="https://health.aws.amazon.com/health/status">AWS status checker</a> is reporting that multiple services in the US-EAST-1 Region are “impacted” by operational issues, though outages also affected services in other regions globally.</p><p>As of 6:35AM ET, Amazon says that “most AWS Service operations are succeeding normally now” and that it is working towards a full resolution.</p><p>The AWS dashboard first reported issues affecting the US-EAST-1 Region at 3:11AM ET. “We are actively engaged and working to both mitigate the issue and understand root cause. We will provide an update in 45 minutes, or sooner if we have additional information to share,” Amazon said in an update published at 3:51AM ET.</p><p><a href="https://www.reddit.com/r/alexa/comments/1obdalz/anybody_else_having_their_alexa_say_sorry_the/?share_id=fJoQ-Ru02X3moE99D2HkA&amp;utm_content=1&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_source=share&amp;utm_term=1">Users on Reddit</a> reported that the Alexa smart assistant was down and unable to respond to queries or complete requests, and in my own experience, I found that routines like pre-set alarms are not functioning. The AWS issue also appeared to be impacting platforms running on its cloud network, including Perplexity, Airtable, Canva, and the McDonalds app. The cause of the outage hasn’t been confirmed, and it’s unclear when regular service will be full restored.</p><p>“Perplexity is down right now,” Perplexity CEO <a href="https://x.com/aravsrinivas/status/1980172632600506579?s=46">Aravind Srinivas said on X</a>. “The root cause is an AWS issue. We’re working on resolving it.”</p><p>In a 5:27AM ET update, Amazon says “We are seeing significant signs of recovery. Most requests should now be succeeding. We continue to work through a backlog of queued requests.”</p><p>AWS outages in the US-East-1 region have created widespread disruptions in <a href="https://www.theverge.com/2023/6/13/23759857/amazon-aws-down-outage-taco-bell-mcdonalds-burger-king">2023</a>, <a href="https://www.theverge.com/2021/12/11/22829544/amazon-web-services-overwhelmed-network-outage">2021</a>, and <a href="https://www.theverge.com/2020/11/25/21719396/amazon-web-services-aws-outage-down-internet">2020</a>, forcing multiple websites and platforms offline for several hours before regular service was restored.</p><p><em><strong>Update, October 20th:</strong> added status updates from Amazon.</em></p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Jess Weatherbed</span></span></span></li><li></li><li></li><li></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Docker Systems Status: Full Service Disruption (318 pts)]]></title>
            <link>https://www.dockerstatus.com/pages/incident/533c6539221ae15e3f000031/68f5e1c741c825463df7486c</link>
            <guid>45640877</guid>
            <pubDate>Mon, 20 Oct 2025 07:31:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dockerstatus.com/pages/incident/533c6539221ae15e3f000031/68f5e1c741c825463df7486c">https://www.dockerstatus.com/pages/incident/533c6539221ae15e3f000031/68f5e1c741c825463df7486c</a>, See on <a href="https://news.ycombinator.com/item?id=45640877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h5>Issues accessing Registry, Hub, Scout, DBC, DHI<span>Full Service Disruption</span></h5></p></div><div><div><p>Components  </p><p>Docker Hub Registry, Docker Authentication, Docker Hub Web Services, Docker Billing, Docker Hub Automated Builds, Docker Hub Security Scanning, Docker Scout, Docker Build Cloud, Testcontainers Cloud, Docker Cloud, Docker Hardened Images</p></div><div><p>Locations  </p><p>Docker Web Services</p></div><br><div><p><strong>October 20, 2025 01:22 PDT<br>October 20, 2025 08:22 UTC</strong></p><p><strong>[Identified] </strong><span id="statusio_incident_message_68f5f13c1dee3648df635c5e">We have identified the underlying issue with one of our cloud service providers. We are monitoring the situation and prepare our systems for when the issues with our service provider resolve. </span></p></div><br><div><p><strong>October 20, 2025 00:16 PDT<br>October 20, 2025 07:16 UTC</strong></p><p><strong>[Investigating] </strong><span id="statusio_incident_message_68f5e1c741c825463df7487e">We are seeing issues accessing and using our services across many of our products. We are currently investigating and will report back as soon as possible..

</span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS Multiple Services Down in us-east-1 (1475 pts)]]></title>
            <link>https://health.aws.amazon.com/health/status?ts=20251020</link>
            <guid>45640838</guid>
            <pubDate>Mon, 20 Oct 2025 07:22:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://health.aws.amazon.com/health/status?ts=20251020">https://health.aws.amazon.com/health/status?ts=20251020</a>, See on <a href="https://news.ycombinator.com/item?id=45640838">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Major AWS Outage Happening (1069 pts)]]></title>
            <link>https://old.reddit.com/r/aws/comments/1obd3lx/dynamodb_down_useast1/</link>
            <guid>45640772</guid>
            <pubDate>Mon, 20 Oct 2025 07:11:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/aws/comments/1obd3lx/dynamodb_down_useast1/">https://old.reddit.com/r/aws/comments/1obd3lx/dynamodb_down_useast1/</a>, See on <a href="https://news.ycombinator.com/item?id=45640772">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>[–]<a href="https://old.reddit.com/user/Wilbo007">Wilbo007</a><span></span> <span title="1">1 point</span><span title="2">2 points</span><span title="3">3 points</span> <time title="Mon Oct 20 07:25:39 2025 UTC" datetime="2025-10-20T07:25:39+00:00">1 hour ago</time>&nbsp;(1 child)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_nkg0bp67ew"><div><p>Yeah looks like its DNS. The domain exists but there's no A or AAAA records for it right now</p>

<pre><code>nslookup -debug dynamodb.us-east-1.amazonaws.com 1.1.1.1
------------
Got answer:
    HEADER:
        opcode = QUERY, id = 1, rcode = NOERROR
        header flags:  response, want recursion, recursion avail.
        questions = 1,  answers = 1,  authority records = 0,  additional = 0

    QUESTIONS:
        1.1.1.1.in-addr.arpa, type = PTR, class = IN
    ANSWERS:
    -&gt;  1.1.1.1.in-addr.arpa
        name = one.one.one.one
        ttl = 1704 (28 mins 24 secs)

------------
Server:  one.one.one.one
Address:  1.1.1.1

------------
Got answer:
    HEADER:
        opcode = QUERY, id = 2, rcode = NOERROR
        header flags:  response, want recursion, recursion avail.
        questions = 1,  answers = 0,  authority records = 1,  additional = 0

    QUESTIONS:
        dynamodb.us-east-1.amazonaws.com, type = A, class = IN
    AUTHORITY RECORDS:
    -&gt;  dynamodb.us-east-1.amazonaws.com
        ttl = 545 (9 mins 5 secs)
        primary name server = ns-460.awsdns-57.com
        responsible mail addr = awsdns-hostmaster.amazon.com
        serial  = 1
        refresh = 7200 (2 hours)
        retry   = 900 (15 mins)
        expire  = 1209600 (14 days)
        default TTL = 86400 (1 day)

------------
------------
Got answer:
    HEADER:
        opcode = QUERY, id = 3, rcode = NOERROR
        header flags:  response, want recursion, recursion avail.
        questions = 1,  answers = 0,  authority records = 1,  additional = 0

    QUESTIONS:
        dynamodb.us-east-1.amazonaws.com, type = AAAA, class = IN
    AUTHORITY RECORDS:
    -&gt;  dynamodb.us-east-1.amazonaws.com
        ttl = 776 (12 mins 56 secs)
        primary name server = ns-460.awsdns-57.com
        responsible mail addr = awsdns-hostmaster.amazon.com
        serial  = 1
        refresh = 7200 (2 hours)
        retry   = 900 (15 mins)
        expire  = 1209600 (14 days)
        default TTL = 86400 (1 day)

------------
------------
Got answer:
    HEADER:
        opcode = QUERY, id = 4, rcode = NOERROR
        header flags:  response, want recursion, recursion avail.
        questions = 1,  answers = 0,  authority records = 1,  additional = 0

    QUESTIONS:
        dynamodb.us-east-1.amazonaws.com, type = A, class = IN
    AUTHORITY RECORDS:
    -&gt;  dynamodb.us-east-1.amazonaws.com
        ttl = 776 (12 mins 56 secs)
        primary name server = ns-460.awsdns-57.com
        responsible mail addr = awsdns-hostmaster.amazon.com
        serial  = 1
        refresh = 7200 (2 hours)
        retry   = 900 (15 mins)
        expire  = 1209600 (14 days)
        default TTL = 86400 (1 day)

------------
------------
Got answer:
    HEADER:
        opcode = QUERY, id = 5, rcode = NOERROR
        header flags:  response, want recursion, recursion avail.
        questions = 1,  answers = 0,  authority records = 1,  additional = 0

    QUESTIONS:
        dynamodb.us-east-1.amazonaws.com, type = AAAA, class = IN
    AUTHORITY RECORDS:
    -&gt;  dynamodb.us-east-1.amazonaws.com
        ttl = 545 (9 mins 5 secs)
        primary name server = ns-460.awsdns-57.com
        responsible mail addr = awsdns-hostmaster.amazon.com
        serial  = 1
        refresh = 7200 (2 hours)
        retry   = 900 (15 mins)
        expire  = 1209600 (14 days)
        default TTL = 86400 (1 day)

------------
Name:    dynamodb.us-east-1.amazonaws.com
</code></pre>
</div></form><ul><li><a href="https://old.reddit.com/r/aws/comments/1obd3lx/dynamodb_down_useast1/nkg0bp6/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: AWS us-east-1 services are down (337 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=45640754</link>
            <guid>45640754</guid>
            <pubDate>Mon, 20 Oct 2025 07:07:01 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=45640754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="45641031"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641031" href="https://news.ycombinator.com/vote?id=45641031&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Choosing us-east-1 as your primary region is good, because when you're down, everybody's down, too. You don't get this luxury with other US regions!</p></div></td></tr></tbody></table></td></tr><tr id="45641062"><td></td></tr><tr id="45641132"><td></td></tr><tr id="45641040"><td></td></tr><tr id="45641101"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45641101" href="https://news.ycombinator.com/vote?id=45641101&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Check the URL, we had an issue a couple of years ago with the Workspaces. US East was down but all of our stuff was in EU.</p><p>Turns out the default URL was hardcoded to use the us east interface and just by going to workspaces and then editing your URL to be the local region got everyone working again.</p><p>Unless you mean nothing is working for you at the moment.</p></div></td></tr></tbody></table></td></tr><tr id="45641212"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641212" href="https://news.ycombinator.com/vote?id=45641212&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>To everyone that got paged (like me), grab a coffee and ride it out, the week can only get better!</p></div></td></tr></tbody></table></td></tr><tr id="45640875"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45640875" href="https://news.ycombinator.com/vote?id=45640875&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Signal is down from several vantage points and accounts in Europe, I'd guess because of this dependence on Amazon overseas</p><p>We're having fun figuring out how to communicate amongst colleagues now! It's when it's gone when you realise your dependence</p></div></td></tr></tbody></table></td></tr><tr id="45641020"><td></td></tr><tr id="45640936"><td></td></tr><tr id="45641001"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45641001" href="https://news.ycombinator.com/vote?id=45641001&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Self hosting is golden. Sadly we already feel like we have too many services for our company's size, and the sensitivity of vulnerabilities in customer systems precludes unencrypted comms. IRC+TLS could be used but we also regularly send screenshots and such in self-destructing messages (not that an attacker couldn't disable that, but to avoid there being a giant archive when we do have some sort of compromise), so we'd rather fall back to something with a similar featureset</p><p>As a degraded-state fallback, email is what we're using now (we have our clients configured to encrypt with PGP by default, we use it for any internal email and also when the customer has PGP so everyone knows how to use that)</p></div></td></tr></tbody></table></td></tr><tr id="45641180"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45641180" href="https://news.ycombinator.com/vote?id=45641180&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>self-hosting isn't "golden", if you are serious about the reliability of complex systems, you can't afford to have your own outages impede your own engineers from fixing them.</p><p>if you seriously have no external low dep fallback, please at least document this fact now for the Big Postmortem.</p></div></td></tr></tbody></table></td></tr><tr id="45640965"><td></td></tr><tr id="45641186"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641186" href="https://news.ycombinator.com/vote?id=45641186&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>&gt; We're having fun figuring out how to communicate amongst colleagues now!</p><p>When Slack was down we used... google... google mail? chat. When you go to gmail there is actually a chat app on the left.</p></div></td></tr></tbody></table></td></tr><tr id="45640887"><td></td></tr><tr id="45641159"><td></td></tr><tr id="45641058"><td></td></tr><tr id="45640963"><td></td></tr><tr id="45641014"><td></td></tr><tr id="45640944"><td></td></tr><tr id="45641025"><td></td></tr><tr id="45641142"><td></td></tr><tr id="45641055"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641055" href="https://news.ycombinator.com/vote?id=45641055&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>I find it interesting that AWS services appear to be so tightly integrated that when there's an issue in a region, it affects most or all services. Kind of defeats the purported resiliency of cloud services.</p></div></td></tr></tbody></table></td></tr><tr id="45641085"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641085" href="https://news.ycombinator.com/vote?id=45641085&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>You know how people say X startup is ChatGPT wrapper? A significant chunk of AWS services are wrappers of main services (DynamoDB, EC2, S3 and etc).</p></div></td></tr></tbody></table></td></tr><tr id="45641164"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45641164" href="https://news.ycombinator.com/vote?id=45641164&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Yes, and that's exactly the problem. It's like choosing a microservice architecture for resiliency and building all the services on top of the same database or message queue without underlying redundancy.</p></div></td></tr></tbody></table></td></tr><tr id="45641211"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641211" href="https://news.ycombinator.com/vote?id=45641211&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Yeah I think there are a number of "hidden" dependencies on different regions, especially us-east-1. It's an artifact of it being AWS' largest region, etc.</p></div></td></tr></tbody></table></td></tr><tr id="45641196"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641196" href="https://news.ycombinator.com/vote?id=45641196&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>you can't possibly know that?</p><p>surely you mean:</p><p>&gt; I find it interesting that AWS services appear to be so tightly integrated that when there's an issue THAT BECOMES VISIBLE TO ME in a region, it affects most or all services.</p><p>AWS has stuff failing alllllllll the time, it's not very surprising that many of the outages that become <i>visible to you</i> involve multi-system failures - lots of other ones don't become visible!</p></div></td></tr></tbody></table></td></tr><tr id="45641077"><td></td></tr><tr id="45641227"><td></td></tr><tr id="45641131"><td></td></tr><tr id="45640967"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45640967" href="https://news.ycombinator.com/vote?id=45640967&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>docker hub or github cache internal maybe is affected:</p><p>Booting builder
  /usr/bin/docker buildx inspect --bootstrap --builder builder-1c223ad9-e21b-41c7-a28e-69eea59c8dac
  #1 [internal] booting buildkit
  #1 pulling image moby/buildkit:buildx-stable-1
  #1 pulling image moby/buildkit:buildx-stable-1 9.6s done
  #1 ERROR: received unexpected HTTP status: 500 Internal Server Error
  ------
   &gt; [internal] booting buildkit:
  ------
  ERROR: received unexpected HTTP status: 500 Internal Server Error</p></div></td></tr></tbody></table></td></tr><tr id="45640976"><td></td></tr><tr id="45641080"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641080" href="https://news.ycombinator.com/vote?id=45641080&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>I can't log in to my AWS account, in Germany, on top of that it is not possible to order anything or change payment options from amazon.de.</p><p>No landing page explaining services are down, just scary error pages. I thought account was compromised. Thanks HN for, as always, being the first to clarify what's happening.</p><p>Scary to see that in order to order from Amazon Germany, us-east1 must be up. Everything else works flawlessly but payments are a no go.</p></div></td></tr></tbody></table></td></tr><tr id="45641256"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641256" href="https://news.ycombinator.com/vote?id=45641256&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>I wanted to log into my Audible account after a long time on my phone, I couldn't, started getting annoyed, maybe my password is not saved correctly, maybe my account was banned, ... Then checking desktop, still errors, checking my Amazon.de, no profile info... That's when I started suspecting that <i>it's not me, it's you, Amazon!</i> Anyway, I guess, I'll listen to my book in a couple of hours, hopefully.</p><p>Btw, most parts of the amazon.de is working fine, but I can't load profiles, and can't login.</p></div></td></tr></tbody></table></td></tr><tr id="45641120"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641120" href="https://news.ycombinator.com/vote?id=45641120&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>I just ordered stuff from Amazon.de. And I highly any Amazon site can go down because of one region. Just like Netflix are rarely affected.</p></div></td></tr></tbody></table></td></tr><tr id="45641182"><td></td></tr><tr id="45641203"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45641203" href="https://news.ycombinator.com/vote?id=45641203&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>I'm on Amazon.de and I literally ordered stuff seconds before posting the comment. They took the money and everything. The order is in my order history list.</p></div></td></tr></tbody></table></td></tr><tr id="45641122"><td></td></tr><tr id="45640761"><td></td></tr><tr id="45641153"><td></td></tr><tr id="45641202"><td></td></tr><tr id="45640985"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45640985" href="https://news.ycombinator.com/vote?id=45640985&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>It's plausible that Amazon removes unhealthy servers from all round-robins including DNS. If all servers are unhealthy, no DNS.</p><p>Alternatively, perhaps their DNS service stopped responding to queries or even removed itself from BGP. It's possible for us mere mortals to tell which of these is the case.</p></div></td></tr></tbody></table></td></tr><tr id="45641015"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641015" href="https://news.ycombinator.com/vote?id=45641015&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Wasn't the point why AWS is so much premium that you will always get at least 6 nines if not more in availability?</p></div></td></tr></tbody></table></td></tr><tr id="45641038"><td></td></tr><tr id="45641045"><td></td></tr><tr id="45641144"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45641144" href="https://news.ycombinator.com/vote?id=45641144&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>The dashboard is the SLA.</p><p>IIRC it takes WAY too many managers to approve the dashboard being anything other than green.</p><p>It's not a reflection of reality nor is it automated.</p></div></td></tr></tbody></table></td></tr><tr id="45641193"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641193" href="https://news.ycombinator.com/vote?id=45641193&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>the highest availability service i think is S3 at 4 nines</p><p>you might be thinking of durability for s3 which is 11 nines, and i've never heard of anyone losing an object yet</p></div></td></tr></tbody></table></td></tr><tr id="45641069"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641069" href="https://news.ycombinator.com/vote?id=45641069&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>It's usually true if you arent in US-East-1 which is widely known to be the least reliable location. Theres no reason anyone should be deploying anything new to it these days.</p></div></td></tr></tbody></table></td></tr><tr id="45641035"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641035" href="https://news.ycombinator.com/vote?id=45641035&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Last time I checked the standard SLA is actually 99 % and the only compensation you get for downtime is a refund. Which is why I don't use AWS for anything mission critical.</p></div></td></tr></tbody></table></td></tr><tr id="45641066"><td></td></tr><tr id="45641126"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45641126" href="https://news.ycombinator.com/vote?id=45641126&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Depends on which service you're paying for. For pure hosting the answer is no, which is why it rarely makes sense to go AWS for uptime and stability because when it goes down there's nothing you can do. As opposed to bare metal hosting with redundancy across data centers, which can even cost less than AWS for a lot of common workloads.</p></div></td></tr></tbody></table></td></tr><tr id="45641049"><td></td></tr><tr id="45641094"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45641094" href="https://news.ycombinator.com/vote?id=45641094&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Been using AWS too, but for a critical service we mirrored across three Hetzner datacenters with master-master replication as well as two additional locations for cluster node voting.</p></div></td></tr></tbody></table></td></tr><tr id="45641119"><td></td></tr><tr id="45641034"><td></td></tr><tr id="45641130"><td></td></tr><tr id="45641041"><td></td></tr><tr id="45640955"><td></td></tr><tr id="45640834"><td></td></tr><tr id="45641064"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641064" href="https://news.ycombinator.com/vote?id=45641064&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>During the last us-east-1 apocalypse 14 years ago, I started awsdowntime.com - don't make me regsiter it again and revive the page.</p></div></td></tr></tbody></table></td></tr><tr id="45641224"><td></td></tr><tr id="45640886"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45640886" href="https://news.ycombinator.com/vote?id=45640886&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Couple of years ago us-east was considered the least stable region here on HN due to its age. Is that still a thing?</p></div></td></tr></tbody></table></td></tr><tr id="45641008"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641008" href="https://news.ycombinator.com/vote?id=45641008&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>When I was there at aws (left about a decade ago), us-east-1 was considered least stable, because it was the biggest.</p><p>I.e. some bottle-necks in new code appearing only _after_ you've deployed there, which is of course too late.</p><p>It didn't help that some services had their deploy trains (pipelines in amazon lingo) of ~3 weeks, with us-east-1 being the last one.</p><p>I bet the situation hasn't changed much since.</p></div></td></tr></tbody></table></td></tr><tr id="45641005"><td></td></tr><tr id="45640989"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45640989" href="https://news.ycombinator.com/vote?id=45640989&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Couple of weeks or months ago the front page was saying how us-east-1 instability was a thing of the past due to (whatever).</p></div></td></tr></tbody></table></td></tr><tr id="45640974"><td></td></tr><tr id="45641030"><td></td></tr><tr id="45641047"><td></td></tr><tr id="45640774"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45640774" href="https://news.ycombinator.com/vote?id=45640774&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>We're seeing issues with RDS proxy.  Wouldn't be surprised if a DNS issue was the cause, but who knows, will wait for the postmortem.</p></div></td></tr></tbody></table></td></tr><tr id="45640780"><td></td></tr><tr id="45640847"><td></td></tr><tr id="45640907"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45640907" href="https://news.ycombinator.com/vote?id=45640907&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Can confirm. I was trying to send the newsletter (with SES) and it didn't work. I was thinking my local boto3 was old, but I figured I should check HN just in case.</p></div></td></tr></tbody></table></td></tr><tr id="45640764"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45640764" href="https://news.ycombinator.com/vote?id=45640764&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Yes, we're seeing issues with Dynamo, and potentially other AWS services.</p><p>Appears to have happened within the last 10-15 minutes.</p></div></td></tr></tbody></table></td></tr><tr id="45640775"><td></td></tr><tr id="45641107"><td></td></tr><tr id="45641201"><td></td></tr><tr id="45640953"><td></td></tr><tr id="45640950"><td></td></tr><tr id="45640881"><td></td></tr><tr id="45640899"><td></td></tr><tr id="45640932"><td></td></tr><tr id="45641104"><td></td></tr><tr id="45640945"><td></td></tr><tr id="45640939"><td></td></tr><tr id="45640991"><td></td></tr><tr id="45640855"><td></td></tr><tr id="45640869"><td></td></tr><tr id="45640949"><td></td></tr><tr id="45640773"><td></td></tr><tr id="45640982"><td></td></tr><tr id="45641000"><td></td></tr><tr id="45641043"><td></td></tr><tr id="45641161"><td></td></tr><tr id="45641137"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45641137" href="https://news.ycombinator.com/vote?id=45641137&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Meanwhile my pair of 12 year old raspberry pi's hangling my home services like DNS survive their 3rd AWS us-east-1 outage.</p><p>"But you can't do webscale uptime on your own"</p><p>Sure. I suspect even a single pi with auto-updates on has less downtime.</p></div></td></tr></tbody></table></td></tr><tr id="45641039"><td></td></tr><tr id="45641082"><td></td></tr><tr id="45641154"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45641154" href="https://news.ycombinator.com/vote?id=45641154&amp;how=up&amp;goto=item%3Fid%3D45640754"></a></center></td><td><br>
<div><p>Never choose a single point of failure.</p><p>Or rather</p><p>Ensure your single point of failure risk is appropriate for your business. I don't have full resilience for my companies AS going down, but we do have limited DR capability. Same with the loss of a major city or two.</p><p>I'm not 100% confident in a Thames Barrier flood situation, as I suspect some of our providers don't have the resilience levels we do, but we'd still be able to provide some minimal capability.</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bat v0.26.0 (133 pts)]]></title>
            <link>https://github.com/sharkdp/bat/releases/tag/v0.26.0</link>
            <guid>45640678</guid>
            <pubDate>Mon, 20 Oct 2025 06:49:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sharkdp/bat/releases/tag/v0.26.0">https://github.com/sharkdp/bat/releases/tag/v0.26.0</a>, See on <a href="https://news.ycombinator.com/item?id=45640678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true" data-hpc=""><h2>v0.26.0</h2>
<h2>Features</h2>
<ul>
<li>Add build for windows/ARM64 platform. <a data-error-text="Failed to load title" data-id="2823318557" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3190" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3190/hovercard" href="https://github.com/sharkdp/bat/pull/3190">#3190</a> (<a data-hovercard-type="user" data-hovercard-url="/users/alcroito/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/alcroito">@alcroito</a>)</li>
<li>Add paging to <code>--list-themes</code>, see PR <a data-error-text="Failed to load title" data-id="2943537281" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3239" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3239/hovercard" href="https://github.com/sharkdp/bat/pull/3239">#3239</a> (<a data-hovercard-type="user" data-hovercard-url="/users/einfachIrgendwer0815/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/einfachIrgendwer0815">@einfachIrgendwer0815</a>)</li>
<li>Support negative relative line ranges, e.g. <code>bat -r :-10</code> / <code>bat -r='-10:'</code>, see <a data-error-text="Failed to load title" data-id="2459004322" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3068" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3068/hovercard" href="https://github.com/sharkdp/bat/pull/3068">#3068</a> (<a data-hovercard-type="user" data-hovercard-url="/users/ajesipow/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ajesipow">@ajesipow</a>)</li>
<li>Support context in line ranges, e.g. <code>bat -r 30::5</code> /  <code>bat -r 30:40:5</code>, see <a data-error-text="Failed to load title" data-id="3233945614" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3345" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3345/hovercard" href="https://github.com/sharkdp/bat/pull/3345">#3345</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cavanaug/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cavanaug">@cavanaug</a>)</li>
<li>Add built-in 'minus' pager, e.g. <code>bat --pager=builtin</code> see PR <a data-error-text="Failed to load title" data-id="3399766556" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3402" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3402/hovercard" href="https://github.com/sharkdp/bat/pull/3402">#3402</a> (<a data-hovercard-type="user" data-hovercard-url="/users/academician/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/academician">@academician</a>)</li>
</ul>
<h2>Bugfixes</h2>
<ul>
<li>Fix UTF-8 BOM not being stripped for syntax detection, see <a data-error-text="Failed to load title" data-id="3103771473" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3314" data-hovercard-type="issue" data-hovercard-url="/sharkdp/bat/issues/3314/hovercard" href="https://github.com/sharkdp/bat/issues/3314">#3314</a> (<a data-hovercard-type="user" data-hovercard-url="/users/krikera/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/krikera">@krikera</a>)</li>
<li>Fix <code>BAT_THEME_DARK</code> and <code>BAT_THEME_LIGHT</code> being ignored, see issue <a data-error-text="Failed to load title" data-id="2776708580" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3171" data-hovercard-type="issue" data-hovercard-url="/sharkdp/bat/issues/3171/hovercard" href="https://github.com/sharkdp/bat/issues/3171">#3171</a> and PR <a data-error-text="Failed to load title" data-id="2773798977" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3168" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3168/hovercard" href="https://github.com/sharkdp/bat/pull/3168">#3168</a> (<a data-hovercard-type="user" data-hovercard-url="/users/bash/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/bash">@bash</a>)</li>
<li>Prevent <code>--list-themes</code> from outputting default theme info to stdout when it is piped, see <a data-error-text="Failed to load title" data-id="2813464960" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3189" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3189/hovercard" href="https://github.com/sharkdp/bat/pull/3189">#3189</a> (<a data-hovercard-type="user" data-hovercard-url="/users/einfachIrgendwer0815/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/einfachIrgendwer0815">@einfachIrgendwer0815</a>)</li>
<li>Rename some submodules to fix Dependabot submodule updates, see issue <a data-error-text="Failed to load title" data-id="2826234600" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3198" data-hovercard-type="issue" data-hovercard-url="/sharkdp/bat/issues/3198/hovercard" href="https://github.com/sharkdp/bat/issues/3198">#3198</a> and PR <a data-error-text="Failed to load title" data-id="2828716746" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3201" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3201/hovercard" href="https://github.com/sharkdp/bat/pull/3201">#3201</a> (<a data-hovercard-type="user" data-hovercard-url="/users/victor-gp/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/victor-gp">@victor-gp</a>)</li>
<li>Make highlight tests fail when new syntaxes don't have fixtures PR <a data-error-text="Failed to load title" data-id="2964461642" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3255" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3255/hovercard" href="https://github.com/sharkdp/bat/pull/3255">#3255</a> (<a data-hovercard-type="user" data-hovercard-url="/users/dan-hipschman/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/dan-hipschman">@dan-hipschman</a>)</li>
<li>Fix crash for multibyte characters in file path, see issue <a data-error-text="Failed to load title" data-id="2905349506" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3230" data-hovercard-type="issue" data-hovercard-url="/sharkdp/bat/issues/3230/hovercard" href="https://github.com/sharkdp/bat/issues/3230">#3230</a> and PR <a data-error-text="Failed to load title" data-id="2961883699" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3245" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3245/hovercard" href="https://github.com/sharkdp/bat/pull/3245">#3245</a> (<a data-hovercard-type="user" data-hovercard-url="/users/HSM95/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/HSM95">@HSM95</a>)</li>
<li>Add missing mappings for various bash/zsh files, see PR <a data-error-text="Failed to load title" data-id="2978022854" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3262" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3262/hovercard" href="https://github.com/sharkdp/bat/pull/3262">#3262</a> (<a data-hovercard-type="user" data-hovercard-url="/users/AdamGaskins/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/AdamGaskins">@AdamGaskins</a>)</li>
<li>Send all bat errors to stderr by default, see <a data-error-text="Failed to load title" data-id="3208848495" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3336" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3336/hovercard" href="https://github.com/sharkdp/bat/pull/3336">#3336</a> (<a data-hovercard-type="user" data-hovercard-url="/users/JerryImMouse/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/JerryImMouse">@JerryImMouse</a>)</li>
<li>Make --map-syntax target case insensitive to match --language, see <a data-error-text="Failed to load title" data-id="2840889505" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3206" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3206/hovercard" href="https://github.com/sharkdp/bat/pull/3206">#3206</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Correctly determine the end of the line in UTF16LE/BE input <a data-error-text="Failed to load title" data-id="3301795093" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3369" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3369/hovercard" href="https://github.com/sharkdp/bat/pull/3369">#3369</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li><code>--style=changes</code> no longer prints a two-space indent when the file is unmodified, see issue <a data-error-text="Failed to load title" data-id="1940575016" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/2710" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/2710/hovercard" href="https://github.com/sharkdp/bat/pull/2710">#2710</a> and PR <a data-error-text="Failed to load title" data-id="3437471941" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3406" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3406/hovercard" href="https://github.com/sharkdp/bat/pull/3406">#3406</a> (<a data-hovercard-type="user" data-hovercard-url="/users/jyn514/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jyn514">@jyn514</a>)</li>
<li>Add missing shell completions, see <a data-error-text="Failed to load title" data-id="3460299040" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3411" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3411/hovercard" href="https://github.com/sharkdp/bat/pull/3411">#3411</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Execute help/version/diagnostic commands even with invalid config/arguments present, see <a data-error-text="Failed to load title" data-id="3460700052" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3414" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3414/hovercard" href="https://github.com/sharkdp/bat/pull/3414">#3414</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Fixed line numbers (<code>-n</code>) and style components not printing when piping output, see issue <a data-error-text="Failed to load title" data-id="2236944741" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/2935" data-hovercard-type="issue" data-hovercard-url="/sharkdp/bat/issues/2935/hovercard" href="https://github.com/sharkdp/bat/issues/2935">#2935</a> and PR <a data-error-text="Failed to load title" data-id="3521498174" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3438" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3438/hovercard" href="https://github.com/sharkdp/bat/pull/3438">#3438</a> (<a data-hovercard-type="user" data-hovercard-url="/users/lmmx/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/lmmx">@lmmx</a>)</li>
</ul>
<h2>Other</h2>
<ul>
<li>Update base16 README links to community driven base16 work <a data-error-text="Failed to load title" data-id="2152268636" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/2871" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/2871/hovercard" href="https://github.com/sharkdp/bat/pull/2871">#2871</a> (<a data-hovercard-type="user" data-hovercard-url="/users/JamyGolden/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/JamyGolden">@JamyGolden</a>)</li>
<li>Work around build failures when building <code>bat</code> from vendored sources <a data-error-text="Failed to load title" data-id="2796755531" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3179" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3179/hovercard" href="https://github.com/sharkdp/bat/pull/3179">#3179</a> (<a data-hovercard-type="user" data-hovercard-url="/users/dtolnay/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/dtolnay">@dtolnay</a>)</li>
<li>CICD: Stop building for x86_64-pc-windows-gnu which fails <a data-error-text="Failed to load title" data-id="2975586712" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3261" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3261/hovercard" href="https://github.com/sharkdp/bat/pull/3261">#3261</a> (Enselic)</li>
<li>CICD:  CICD: replace windows-2019 runners with windows-2025 <a data-error-text="Failed to load title" data-id="3211744894" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3339" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3339/hovercard" href="https://github.com/sharkdp/bat/pull/3339">#3339</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cyqsimon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cyqsimon">@cyqsimon</a>)</li>
<li>Build script: replace string-based codegen with quote-based codegen <a data-error-text="Failed to load title" data-id="3211983606" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3340" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3340/hovercard" href="https://github.com/sharkdp/bat/pull/3340">#3340</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cyqsimon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cyqsimon">@cyqsimon</a>)</li>
<li>Improve code coverage of <code>--list-languages</code> parameter <a data-error-text="Failed to load title" data-id="2255217108" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/2942" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/2942/hovercard" href="https://github.com/sharkdp/bat/pull/2942">#2942</a> (<a data-hovercard-type="user" data-hovercard-url="/users/sblondon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/sblondon">@sblondon</a>)</li>
<li>Only start offload worker thread when there's more than 1 core <a data-error-text="Failed to load title" data-id="2285059143" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/2956" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/2956/hovercard" href="https://github.com/sharkdp/bat/pull/2956">#2956</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cyqsimon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cyqsimon">@cyqsimon</a>)</li>
<li>Update terminal-colorsaurus (the library used for dark/light detection) to 1.0, see <a data-error-text="Failed to load title" data-id="3251109476" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3347" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3347/hovercard" href="https://github.com/sharkdp/bat/pull/3347">#3347</a> (<a data-hovercard-type="user" data-hovercard-url="/users/bash/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/bash">@bash</a>)</li>
<li>Update console dependency to 0.16, see <a data-error-text="Failed to load title" data-id="3256087183" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3351" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3351/hovercard" href="https://github.com/sharkdp/bat/pull/3351">#3351</a> (<a data-hovercard-type="user" data-hovercard-url="/users/musicinmybrain/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/musicinmybrain">@musicinmybrain</a>)</li>
<li>Fixed some typos <a data-error-text="Failed to load title" data-id="2960107545" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3244" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3244/hovercard" href="https://github.com/sharkdp/bat/pull/3244">#3244</a> (<a data-hovercard-type="user" data-hovercard-url="/users/ssbarnea/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ssbarnea">@ssbarnea</a>)</li>
<li>Update onig_sys dependency to 69.9.1 to fix a gcc build failure <a data-error-text="Failed to load title" data-id="3382266911" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3400" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3400/hovercard" href="https://github.com/sharkdp/bat/pull/3400">#3400</a> (<a data-hovercard-type="user" data-hovercard-url="/users/CosmicHorrorDev/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/CosmicHorrorDev">@CosmicHorrorDev</a>)</li>
<li>Add a cargo feature (<code>vendored-libgit2</code>) to build with vendored libgit2 version without depending on the system's one <a data-error-text="Failed to load title" data-id="3488497070" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3426" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3426/hovercard" href="https://github.com/sharkdp/bat/pull/3426">#3426</a> (<a data-hovercard-type="user" data-hovercard-url="/users/0x61nas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/0x61nas">@0x61nas</a>)</li>
<li>Update syntect dependency to v5.3.0 to fix a few minor bugs, see <a data-error-text="Failed to load title" data-id="3460290947" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3410" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3410/hovercard" href="https://github.com/sharkdp/bat/pull/3410">#3410</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
</ul>
<h2>Syntaxes</h2>
<ul>
<li>Add syntax mapping for <code>paru</code> configuration files <a data-error-text="Failed to load title" data-id="2798102869" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3182" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3182/hovercard" href="https://github.com/sharkdp/bat/pull/3182">#3182</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cyqsimon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cyqsimon">@cyqsimon</a>)</li>
<li>Add support for <a href="https://www.idris-lang.org/" rel="nofollow">Idris 2 programming language</a> <a data-error-text="Failed to load title" data-id="2758106895" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3150" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3150/hovercard" href="https://github.com/sharkdp/bat/pull/3150">#3150</a> (<a data-hovercard-type="user" data-hovercard-url="/users/buzden/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/buzden">@buzden</a>)</li>
<li>Add syntax mapping for <code>nix</code>'s '<code>flake.lock</code> lockfiles <a data-error-text="Failed to load title" data-id="2825723310" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3196" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3196/hovercard" href="https://github.com/sharkdp/bat/pull/3196">#3196</a> (<a data-hovercard-type="user" data-hovercard-url="/users/odilf/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/odilf">@odilf</a>)</li>
<li>Improvements to CSV/TSV highlighting, with autodetection of delimiter and support for TSV files, see <a data-error-text="Failed to load title" data-id="2810370100" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3186" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3186/hovercard" href="https://github.com/sharkdp/bat/pull/3186">#3186</a> (@keith-</li>
<li>Improve (Sys)log error highlighting, see <a data-error-text="Failed to load title" data-id="2840584050" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3205" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3205/hovercard" href="https://github.com/sharkdp/bat/pull/3205">#3205</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Map <code>ndjson</code> extension to JSON syntax, see <a data-error-text="Failed to load title" data-id="2855284742" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3209" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3209/hovercard" href="https://github.com/sharkdp/bat/pull/3209">#3209</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Map files with <code>csproj</code>, <code>vbproj</code>, <code>props</code> and <code>targets</code> extensions to XML syntax, see <a data-error-text="Failed to load title" data-id="2873379651" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3213" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3213/hovercard" href="https://github.com/sharkdp/bat/pull/3213">#3213</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Add debsources syntax to highlight <code>/etc/apt/sources.list</code> files, see <a data-error-text="Failed to load title" data-id="2879475662" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3215" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3215/hovercard" href="https://github.com/sharkdp/bat/pull/3215">#3215</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Add syntax definition and test file for GDScript highlighting, see <a data-error-text="Failed to load title" data-id="2941195861" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3236" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3236/hovercard" href="https://github.com/sharkdp/bat/pull/3236">#3236</a> (<a data-hovercard-type="user" data-hovercard-url="/users/chetanjangir0/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/chetanjangir0">@chetanjangir0</a>)</li>
<li>Add syntax test file for Odin highlighting, see <a data-error-text="Failed to load title" data-id="2956008671" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3241" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3241/hovercard" href="https://github.com/sharkdp/bat/pull/3241">#3241</a> (<a data-hovercard-type="user" data-hovercard-url="/users/chetanjangir0/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/chetanjangir0">@chetanjangir0</a>)</li>
<li>Update quadlet syntax mapping rules to cover quadlets in subdirectories <a data-error-text="Failed to load title" data-id="3075992934" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3299" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3299/hovercard" href="https://github.com/sharkdp/bat/pull/3299">#3299</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cyqsimon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cyqsimon">@cyqsimon</a>)</li>
<li>Add syntax Typst <a data-error-text="Failed to load title" data-id="3078076655" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3300" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3300/hovercard" href="https://github.com/sharkdp/bat/pull/3300">#3300</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cskeeters/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cskeeters">@cskeeters</a>)</li>
<li>Map <code>.mill</code> files to Scala syntax for Mill build tool configuration files <a data-error-text="Failed to load title" data-id="3100606917" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3311" data-hovercard-type="issue" data-hovercard-url="/sharkdp/bat/issues/3311/hovercard" href="https://github.com/sharkdp/bat/issues/3311">#3311</a> (<a data-hovercard-type="user" data-hovercard-url="/users/krikera/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/krikera">@krikera</a>)</li>
<li>Add syntax highlighting for VHDL, see <a data-error-text="Failed to load title" data-id="3209285421" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3337" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3337/hovercard" href="https://github.com/sharkdp/bat/pull/3337">#3337</a> (<a data-hovercard-type="user" data-hovercard-url="/users/JerryImMouse/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/JerryImMouse">@JerryImMouse</a>)</li>
<li>Add syntax mapping for certbot certificate configuration <a data-error-text="Failed to load title" data-id="3211065543" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3338" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3338/hovercard" href="https://github.com/sharkdp/bat/pull/3338">#3338</a> (<a data-hovercard-type="user" data-hovercard-url="/users/cyqsimon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/cyqsimon">@cyqsimon</a>)</li>
<li>Update Lean syntax from Lean 3 to Lean 4 <a data-error-text="Failed to load title" data-id="3132736460" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3322" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3322/hovercard" href="https://github.com/sharkdp/bat/pull/3322">#3322</a> (<a data-hovercard-type="user" data-hovercard-url="/users/YDX-2147483647/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/YDX-2147483647">@YDX-2147483647</a>)</li>
<li>Map <code>.flatpakref</code> and <code>.flatpakrepo</code> files to INI syntax <a data-error-text="Failed to load title" data-id="3280677453" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3353" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3353/hovercard" href="https://github.com/sharkdp/bat/pull/3353">#3353</a> (<a data-hovercard-type="user" data-hovercard-url="/users/Ferenc-/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Ferenc-">@Ferenc-</a>)</li>
<li>Update hosts syntax <a data-error-text="Failed to load title" data-id="3301680750" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3368" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3368/hovercard" href="https://github.com/sharkdp/bat/pull/3368">#3368</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Map <code>.kshrc</code> files to Bash syntax <a data-error-text="Failed to load title" data-id="3286574371" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3364" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3364/hovercard" href="https://github.com/sharkdp/bat/pull/3364">#3364</a> (<a data-hovercard-type="user" data-hovercard-url="/users/ritoban23/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ritoban23">@ritoban23</a>)</li>
<li>Map <code>/var/log/dmesg</code> files to Syslog syntax <a data-error-text="Failed to load title" data-id="3460655867" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3412" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3412/hovercard" href="https://github.com/sharkdp/bat/pull/3412">#3412</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
<li>Add syntax definition and test file for Go modules(<code>go.mod</code> and <code>go.sum</code>) highlighting, see <a data-error-text="Failed to load title" data-id="3480124155" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3424" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3424/hovercard" href="https://github.com/sharkdp/bat/pull/3424">#3424</a> (<a data-hovercard-type="user" data-hovercard-url="/users/DarkMatter-999/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/DarkMatter-999">@DarkMatter-999</a>)</li>
<li>Syntax highlighting for typescript code blocks within Markdown files, see <a data-error-text="Failed to load title" data-id="3509386497" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3435" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3435/hovercard" href="https://github.com/sharkdp/bat/pull/3435">#3435</a> (<a data-hovercard-type="user" data-hovercard-url="/users/MuntasirSZN/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/MuntasirSZN">@MuntasirSZN</a>)</li>
</ul>
<h2>Themes</h2>
<ul>
<li>Add Catppuccin, see <a data-error-text="Failed to load title" data-id="3105456087" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3317" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3317/hovercard" href="https://github.com/sharkdp/bat/pull/3317">#3317</a> (<a data-hovercard-type="user" data-hovercard-url="/users/SchweGELBin/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SchweGELBin">@SchweGELBin</a>)</li>
<li>Updated Catppuccin, see <a data-error-text="Failed to load title" data-id="3202214324" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3333" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3333/hovercard" href="https://github.com/sharkdp/bat/pull/3333">#3333</a> (<a data-hovercard-type="user" data-hovercard-url="/users/SchweGELBin/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SchweGELBin">@SchweGELBin</a>)</li>
<li>Updated gruvbox, see <a data-error-text="Failed to load title" data-id="3307702639" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3372" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3372/hovercard" href="https://github.com/sharkdp/bat/pull/3372">#3372</a> (<a data-hovercard-type="user" data-hovercard-url="/users/Nicholas42/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Nicholas42">@Nicholas42</a>)</li>
<li>Updated GitHub theme, see <a data-error-text="Failed to load title" data-id="3336456334" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3382" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3382/hovercard" href="https://github.com/sharkdp/bat/pull/3382">#3382</a> (<a data-hovercard-type="user" data-hovercard-url="/users/CosmicHorrorDev/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/CosmicHorrorDev">@CosmicHorrorDev</a>)</li>
<li>Updated ANSI theme to highlight JSON object keys differently from values, see <a data-error-text="Failed to load title" data-id="3460672564" data-permission-text="Title is private" data-url="https://github.com/sharkdp/bat/issues/3413" data-hovercard-type="pull_request" data-hovercard-url="/sharkdp/bat/pull/3413/hovercard" href="https://github.com/sharkdp/bat/pull/3413">#3413</a> (<a data-hovercard-type="user" data-hovercard-url="/users/keith-hall/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/keith-hall">@keith-hall</a>)</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek OCR (754 pts)]]></title>
            <link>https://github.com/deepseek-ai/DeepSeek-OCR</link>
            <guid>45640594</guid>
            <pubDate>Mon, 20 Oct 2025 06:26:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/DeepSeek-OCR">https://github.com/deepseek-ai/DeepSeek-OCR</a>, See on <a href="https://news.ycombinator.com/item?id=45640594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">


<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/assets/logo.svg"><img src="https://github.com/deepseek-ai/DeepSeek-OCR/raw/main/assets/logo.svg" width="60%" alt="DeepSeek AI"></a>
</p>
<hr>
<p><a href="https://www.deepseek.com/" rel="nofollow">
    <img alt="Homepage" src="https://github.com/deepseek-ai/DeepSeek-OCR/raw/main/assets/badge.svg">
  </a>
  <a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR" rel="nofollow">
    <img alt="Hugging Face" src="https://camo.githubusercontent.com/5e3115539d4583e22d65cb89eb1759e767cb9e1d70772923292fcfc80a654be4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e67253230466163652d446565705365656b25323041492d6666633130373f636f6c6f723d666663313037266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&amp;logoColor=white">
  </a>
</p>
<p><a href="https://discord.gg/Tc7c45Zzu5" rel="nofollow">
    <img alt="Discord" src="https://camo.githubusercontent.com/e227481a149714ed5187e4fd0b60b9f736099c2dd2083e6c091e29f1446cbb1a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d446565705365656b25323041492d3732383964613f6c6f676f3d646973636f7264266c6f676f436f6c6f723d776869746526636f6c6f723d373238396461" data-canonical-src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&amp;logoColor=white&amp;color=7289da">
  </a>
  <a href="https://twitter.com/deepseek_ai" rel="nofollow">
    <img alt="Twitter Follow" src="https://camo.githubusercontent.com/8272710ecd020c821b4f62c1c455efb89e0db4eb179c5f5f971c3c1f69452c54/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f547769747465722d646565707365656b5f61692d77686974653f6c6f676f3d78266c6f676f436f6c6f723d7768697465" data-canonical-src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&amp;logoColor=white">
  </a>
</p>
<p dir="auto">
  <a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR" rel="nofollow"><b>📥 Model Download</b></a> |
  <a href="https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf"><b>📄 Paper Link</b></a> |
  <a href="https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf"><b>📄 Arxiv Paper Link</b></a> |
</p>

<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/assets/fig1.png"><img src="https://github.com/deepseek-ai/DeepSeek-OCR/raw/main/assets/fig1.png"></a>
</p>
<p dir="auto">
<a href="https://github.com/deepseek-ai/DeepSeek-OCR/blob/main">Explore the boundaries of visual-text compression.</a>       
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Release</h2><a id="user-content-release" aria-label="Permalink: Release" href="#release"></a></p>
<ul dir="auto">
<li>[2025/x/x]🚀🚀🚀 We release DeepSeek-OCR, a model to investigate the role of vision encoders from an LLM-centric viewpoint.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ul dir="auto">
<li><a href="#install">Install</a></li>
<li><a href="#vllm-inference">vLLM Inference</a></li>
<li><a href="#transformers-inference">Transformers Inference</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<blockquote>
<p dir="auto">Our environment is cuda11.8+torch2.6.0.</p>
</blockquote>
<ol dir="auto">
<li>Clone this repository and navigate to the DeepSeek-OCR folder</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/deepseek-ai/DeepSeek-OCR.git"><pre>git clone https://github.com/deepseek-ai/DeepSeek-OCR.git</pre></div>
<ol start="2" dir="auto">
<li>Conda</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="conda create -n deepseek-ocr python=3.12.9 -y
conda activate deepseek-ocr"><pre>conda create -n deepseek-ocr python=3.12.9 -y
conda activate deepseek-ocr</pre></div>
<ol start="3" dir="auto">
<li>Packages</li>
</ol>
<ul dir="auto">
<li>download the vllm-0.8.5 <a href="https://github.com/vllm-project/vllm/releases/tag/v0.8.5">whl</a></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118
pip install vllm-0.8.5+cu118-cp38-abi3-manylinux1_x86_64.whl
pip install -r requirements.txt
pip install flash-attn==2.7.3 --no-build-isolation"><pre>pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118
pip install vllm-0.8.5+cu118-cp38-abi3-manylinux1_x86_64.whl
pip install -r requirements.txt
pip install flash-attn==2.7.3 --no-build-isolation</pre></div>
<p dir="auto"><strong>Note:</strong> if you want vLLM and transformers codes to run in the same environment, you don't need to worry about this installation error like: vllm 0.8.5+cu118 requires transformers&gt;=4.51.1</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">vLLM-Inference</h2><a id="user-content-vllm-inference" aria-label="Permalink: vLLM-Inference" href="#vllm-inference"></a></p>
<ul dir="auto">
<li>VLLM:</li>
</ul>
<blockquote>
<p dir="auto"><strong>Note:</strong> change the INPUT_PATH/OUTPUT_PATH and other settings in the DeepSeek-OCR-master/DeepSeek-OCR-vllm/config.py</p>
</blockquote>
<div dir="auto" data-snippet-clipboard-copy-content="cd DeepSeek-OCR-master/DeepSeek-OCR-vllm"><pre><span>cd</span> DeepSeek-OCR-master/DeepSeek-OCR-vllm</pre></div>
<ol dir="auto">
<li>image: streaming output</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python run_dpsk_ocr_image.py"><pre>python run_dpsk_ocr_image.py</pre></div>
<ol start="2" dir="auto">
<li>pdf: concurrency ~2500tokens/s(an A100-40G)</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python run_dpsk_ocr_pdf.py"><pre>python run_dpsk_ocr_pdf.py</pre></div>
<ol start="3" dir="auto">
<li>batch eval for benchmarks</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python run_dpsk_ocr_eval_batch.py"><pre>python run_dpsk_ocr_eval_batch.py</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Transformers-Inference</h2><a id="user-content-transformers-inference" aria-label="Permalink: Transformers-Inference" href="#transformers-inference"></a></p>
<ul dir="auto">
<li>Transformers</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="from transformers import AutoModel, AutoTokenizer
import torch
import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = '0'
model_name = 'deepseek-ai/DeepSeek-OCR'

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name, _attn_implementation='flash_attention_2', trust_remote_code=True, use_safetensors=True)
model = model.eval().cuda().to(torch.bfloat16)

# prompt = &quot;<image>\nFree OCR. &quot;
prompt = &quot;<image>\n<|grounding|>Convert the document to markdown. &quot;
image_file = 'your_image.jpg'
output_path = 'your/output/dir'

res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)"><pre><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModel</span>, <span>AutoTokenizer</span>
<span>import</span> <span>torch</span>
<span>import</span> <span>os</span>
<span>os</span>.<span>environ</span>[<span>"CUDA_VISIBLE_DEVICES"</span>] <span>=</span> <span>'0'</span>
<span>model_name</span> <span>=</span> <span>'deepseek-ai/DeepSeek-OCR'</span>

<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>model_name</span>, <span>trust_remote_code</span><span>=</span><span>True</span>)
<span>model</span> <span>=</span> <span>AutoModel</span>.<span>from_pretrained</span>(<span>model_name</span>, <span>_attn_implementation</span><span>=</span><span>'flash_attention_2'</span>, <span>trust_remote_code</span><span>=</span><span>True</span>, <span>use_safetensors</span><span>=</span><span>True</span>)
<span>model</span> <span>=</span> <span>model</span>.<span>eval</span>().<span>cuda</span>().<span>to</span>(<span>torch</span>.<span>bfloat16</span>)

<span># prompt = "&lt;image&gt;\nFree OCR. "</span>
<span>prompt</span> <span>=</span> <span>"&lt;image&gt;<span>\n</span>&lt;|grounding|&gt;Convert the document to markdown. "</span>
<span>image_file</span> <span>=</span> <span>'your_image.jpg'</span>
<span>output_path</span> <span>=</span> <span>'your/output/dir'</span>

<span>res</span> <span>=</span> <span>model</span>.<span>infer</span>(<span>tokenizer</span>, <span>prompt</span><span>=</span><span>prompt</span>, <span>image_file</span><span>=</span><span>image_file</span>, <span>output_path</span> <span>=</span> <span>output_path</span>, <span>base_size</span> <span>=</span> <span>1024</span>, <span>image_size</span> <span>=</span> <span>640</span>, <span>crop_mode</span><span>=</span><span>True</span>, <span>save_results</span> <span>=</span> <span>True</span>, <span>test_compress</span> <span>=</span> <span>True</span>)</pre></div>
<p dir="auto">or you can</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd DeepSeek-OCR-master/DeepSeek-OCR-hf
python run_dpsk_ocr.py"><pre><span>cd</span> DeepSeek-OCR-master/DeepSeek-OCR-hf
python run_dpsk_ocr.py</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support-Modes</h2><a id="user-content-support-modes" aria-label="Permalink: Support-Modes" href="#support-modes"></a></p>
<p dir="auto">The current open-source model supports the following modes:</p>
<ul dir="auto">
<li>Native resolution:
<ul dir="auto">
<li>Tiny: 512×512 （64 vision tokens）✅</li>
<li>Small: 640×640 （100 vision tokens）✅</li>
<li>Base: 1024×1024 （256 vision tokens）✅</li>
<li>Large: 1280×1280 （400 vision tokens）✅</li>
</ul>
</li>
<li>Dynamic resolution
<ul dir="auto">
<li>Gundam: n×640×640 + 1×1024×1024 ✅</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prompts examples</h2><a id="user-content-prompts-examples" aria-label="Permalink: Prompts examples" href="#prompts-examples"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# document: <image>\n<|grounding|>Convert the document to markdown.
# other image: <image>\n<|grounding|>OCR this image.
# without layouts: <image>\nFree OCR.
# figures in document: <image>\nParse the figure.
# general: <image>\nDescribe this image in detail.
# rec: <image>\nLocate <|ref|>xxxx<|/ref|> in the image.
# '先天下之忧而忧'"><pre><span># document: &lt;image&gt;\n&lt;|grounding|&gt;Convert the document to markdown.</span>
<span># other image: &lt;image&gt;\n&lt;|grounding|&gt;OCR this image.</span>
<span># without layouts: &lt;image&gt;\nFree OCR.</span>
<span># figures in document: &lt;image&gt;\nParse the figure.</span>
<span># general: &lt;image&gt;\nDescribe this image in detail.</span>
<span># rec: &lt;image&gt;\nLocate &lt;|ref|&gt;xxxx&lt;|/ref|&gt; in the image.</span>
<span># '先天下之忧而忧'</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Visualizations</h2><a id="user-content-visualizations" aria-label="Permalink: Visualizations" href="#visualizations"></a></p>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgement</h2><a id="user-content-acknowledgement" aria-label="Permalink: Acknowledgement" href="#acknowledgement"></a></p>
<p dir="auto">We would like to thank <a href="https://github.com/Ucas-HaoranWei/Vary/">Vary</a>, <a href="https://github.com/Ucas-HaoranWei/GOT-OCR2.0/">GOT-OCR2.0</a>, <a href="https://github.com/opendatalab/MinerU">MinerU</a>, <a href="https://github.com/PaddlePaddle/PaddleOCR">PaddleOCR</a>, <a href="https://github.com/LingyvKong/OneChart">OneChart</a>, <a href="https://github.com/Ucas-HaoranWei/Slow-Perception">Slow Perception</a> for their valuable models and ideas.</p>
<p dir="auto">We also appreciate the benchmarks: <a href="https://github.com/ucaslcl/Fox">Fox</a>, <a href="https://github.com/opendatalab/OmniDocBench">OminiDocBench</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">coming soon！</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Space Elevator (1227 pts)]]></title>
            <link>https://neal.fun/space-elevator/</link>
            <guid>45640226</guid>
            <pubDate>Mon, 20 Oct 2025 04:42:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neal.fun/space-elevator/">https://neal.fun/space-elevator/</a>, See on <a href="https://news.ycombinator.com/item?id=45640226">Hacker News</a></p>
Couldn't get https://neal.fun/space-elevator/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Entire Linux Network stack diagram (2024) (502 pts)]]></title>
            <link>https://zenodo.org/records/14179366</link>
            <guid>45639995</guid>
            <pubDate>Mon, 20 Oct 2025 03:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zenodo.org/records/14179366">https://zenodo.org/records/14179366</a>, See on <a href="https://news.ycombinator.com/item?id=45639995">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
          

              

              

              <div id="record-info" aria-label="Publication date and version number">
                    <p><span title="Publication date">
                        Published November 18, 2024
                      </span>
                      <span> | Version v7</span>
                    </p>
                    <p><span role="note" aria-label="Resource type">
                          Poster
                        </span>
                      

                      <span role="note" data-tooltip="The record and files are publicly accessible." data-inverted="" aria-label="Access status">
                        
                          
                        
                        <span aria-label="The record and files are publicly accessible.">
                          Open
                        </span>
                      </span>
                    </p>
                  </div>
              <section id="record-title-section" aria-label="Record title and creators">
  <ul>
    
    <li>
      1.

      

      Ericsson Nikola Tesla
    </li>
  

    </ul>
</section>



  <section id="description" aria-label="Record description">
    <h2 id="description-heading">Description</h2>
    
    <div>
      <p>Diagram of entire Linux Network Stack, including:</p>
<ul>
<li>Virtualization and Linux containers:
<ul>
<li>Emulation and Paravirtualization.</li>
</ul>
</li>
<li>Network sockets.</li>
<li>Network stack:
<ul>
<li>Upper layer of Network stack (TCP, UDP).</li>
<li>Low layer of Network stack with GRO, RPS, RFS and GSO.</li>
</ul>
</li>
<li>Network Scheduler.</li>
<li>NetFilter and traffic controll:
<ul>
<li>Bridge and Bond interfaces.</li>
<li>Tap interface, ...</li>
</ul>
</li>
<li>Device Driver:
<ul>
<li>Queue.</li>
<li>NAPI.</li>
<li>IRQ handler.</li>
</ul>
</li>
<li>Network functions accelerated by NIC:
<ul>
<li>Checksum offload, VLAN, VxLAN, GRE, TSO, LRO,&nbsp;RSS, ...</li>
</ul>
</li>
<li>Network card.</li>
</ul>
<p>All (above) sections (layers) include tips for optimizations and/or statistics.</p>

<p>This diagram is part of the book:&nbsp;</p>
<p><strong>Operativni sustavi i računalne mreže - Linux u primjeni</strong></p>
<p>https://doi.org/10.5281/zenodo.8119310</p>
    </div>
  </section>


<section id="record-files" aria-label="Files"><h2 id="files-heading">Files</h2>
            
  <div href="#files-preview-accordion-panel">
    <h3>
      <p><span id="preview-file-title">Linux Network Stack - EN.pdf</span>
        
      </p>
    </h3>
    
  </div>
  <div href="#files-list-accordion-panel">
    <h3>
      <p>
        Files
        <small> (5.4 MB)</small>
        
      </p>
    </h3>

    
  </div>

    </section>
              

  <section id="additional-details" aria-label="Additional record details">











  <h2 id="record-details-heading">Additional details</h2>

  

  

  

  
    
      
    
    
  

  

  

  

  



  

  </section>
    
    
  
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introduction to reverse-engineering vintage synth firmware (168 pts)]]></title>
            <link>https://ajxs.me/blog/Introduction_to_Reverse-Engineering_Vintage_Synth_Firmware.html</link>
            <guid>45639860</guid>
            <pubDate>Mon, 20 Oct 2025 02:56:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ajxs.me/blog/Introduction_to_Reverse-Engineering_Vintage_Synth_Firmware.html">https://ajxs.me/blog/Introduction_to_Reverse-Engineering_Vintage_Synth_Firmware.html</a>, See on <a href="https://news.ycombinator.com/item?id=45639860">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
          In this article we're going to take a look at how to reverse-engineer
          vintage synthesiser firmware. The synthesiser I've chosen for us to
          look at is the Yamaha DX7 (<i>See <a href="#why_the_dx7">Appendix: Why Choose This Synth?</a></i>). You don't need a DX7 to follow along at home, but you will need a
          copy of the DX7 V1.8 firmware (available
          <a href="https://dbwbp.com/index.php/9-misc/37-synth-eprom-dumps" target="_blank">here</a>) and the
          <a href="https://ghidra-sre.org/" target="_blank">Ghidra</a>
          disassembler.
        </p>
        <div>
          <p>
            <span>Who is this article for?</span>
            This article's intended audience is people from a technical
            background who are new to reverse-engineering, 8-bit architectures,
            or embedded development. If you come from an electrical-engineering
            or embedded-software background, you'll probably find the content
            here a little basic.
          </p>
          <p>
            You'll only need to know a little bit about low-level programming: A
            basic understanding of how binary and pointers work should be
            enough. You don't need to know assembly language, or understand any
            specific processor architecture.
          </p>
        </div>
        <p>
          A few years ago I decided to give myself a crash course on what goes
          on inside synthesisers. I ended up writing the article
          <a href="https://ajxs.me/blog/Yamaha_DX7_Technical_Analysis.html" target="_blank">Yamaha DX7 Technical Analysis</a>
          about what I'd learned. In order to tease out some more details about
          the DX7's inner-workings, I decided to
          <a href="https://github.com/ajxs/yamaha_dx7_rom_disassembly" target="_blank">disassemble the synth's firmware ROM</a>. I didn't have any experience with reverse-engineering binaries, so
          I had to figure it out as I went. I'm still by no means an expert (<i>if you see any mistakes in this article, please let me know!</i>), but I'd like to share what I've learned.
        </p>
        <p>
          All I had when I started was a copy of the firmware, a copy of the
          service manual, and a <i>can-do</i> attitude. I knew nothing about
          8-bit systems, and <em>absolutely nothing</em> about electronics, but
          I was willing to give anything a shot. If this sounds like you, read
          on, and I hope you find this article helpful!
        </p>

        <div>
          <p>Table of Contents</p>
          <ol>
            <li><a href="#address_decoding">Address Decoding</a></li>
            <li>
              <a href="#memory_map">Decoding the DX7's Memory Map</a>
              <ol>
                <li><a href="#rom_address_decoding">The Firmware ROM</a></li>
                <li><a href="#ram_address_decoding">RAM</a></li>
                <li><a href="#lcd_address_decoding">LCD Screen</a></li>
                <li><a href="#wrapping_up">Wrapping Up</a></li>
              </ol>
            </li>
            <li>
              <a href="#disassembling_the_firmware">Disassembling The Firmware</a>
              <ol>
                <li><a href="#reset_function">The Reset Function</a></li>
                <li><a href="#interrupts">Interrupts</a></li>
                <li><a href="#lcd_interface">LCD Interface</a></li>
              </ol>
            </li>
            <li>
              <a href="#going_further">Going Further</a>
              <ol>
                <li>
                  <a href="#midi_handling_routine">The MIDI Handling Routine</a>
                </li>
                <li>
                  <a href="#interrupts">Debugging the Firmware in an Emulator</a>
                </li>
                <li><a href="#final_words">Final Words</a></li>
              </ol>
            </li>
            <li><a href="#why_the_dx7">Appendix: Why Choose This Synth?</a></li>
            <li><a href="#documentation">Appendix: Documentation</a></li>
          </ol>
        </div>

        <p>
          Reverse-engineering vintage synthesisers is a great introduction to
          embedded systems, and can be a lot of fun. In a lot of ways
          reverse-engineering is a bit like putting together a big jigsaw
          puzzle. Sometimes putting a new piece in place unlocks a lot of new
          progress, and like a jigsaw puzzle, the best place to start is at the
          edges.
        </p>

        <h2 id="address_decoding">
          Address Decoding <a href="#address_decoding">#</a>
        </h2>
        <p>
          The peripheral devices attached to the DX7's CPU, such as its LCD
          screen and sound chips, are <i>memory-mapped</i>. This means that the
          device has been allocated a specific address range in the system's
          memory, and the system communicates with the device by reading and
          writing data from and to these addresses.
        </p>
        <p>
          Before we can start disassembling the firmware ROM, we need to know
          what peripheral device is mapped where. To do that we'll need to look
          at the DX7's <i>address decoding</i> logic. The first place to start
          is with the schematics.
        </p>
        <p>
          The best version of the schematics I've seen is
          <a href="https://yamahamusicians.com/forum/viewtopic.php?p=90769#p90769" target="_blank">this</a>
          version, created by the yamahamusicians.com user <i>Miks</i>. While
          you're at it, grab a copy of the
          <a href="https://homepages.abdn.ac.uk/d.j.benson/pages/dx7/manuals/dx7-9_service_manual_1.pdf" target="_blank">service manual</a>
          too. We won't be referencing it in this article, but it's a good
          resource to have. It explains certain details about the synth's
          architecture that aren't obvious from the schematics.
        </p>
        <p><span>Service Manuals:</span>
          Most consumer devices from the 80s and 90s have
          <i>service manuals</i> available. These are technical documents
          written by the manufacturer to assist in servicing the device. They
          typically include schematics, diagrams, and lists of electrical
          components. The first place to start when reverse-engineering a device
          is looking for its service manual.
        </p>
        <p>
          If you're new to electronics, device schematics can look very
          intimidating, but once you understand the basics they're not actually
          as scary as they look! You can find a good introductory guide to
          schematics
          <a href="https://learn.sparkfun.com/tutorials/how-to-read-a-schematic/all" target="_blank">here</a>.
        </p>

        <h3>Background</h3>
        <p>
          But first, what does <i>address decoding</i> actually mean?
          <a href="https://en.wikipedia.org/wiki/Address_decoder" target="_blank">Address decoding</a>
          refers to <em>how</em> a specific device is mapped to a specific
          address. In this section we'll figure out what peripheral is mapped to
          what address by tracing the address decoding logic in the synth's
          schematics.
        </p>
        <p>
          The total amount of memory addresses that a CPU can access is referred
          to as the CPU's <i>'address space'</i>. This is limited by the
          <i>width</i> of its <i>'address bus'</i>. The CPU's address bus is
          responsible for selecting addresses in attached memory devices, such
          as RAM, or peripheral devices with addressable registers. Each
          <i>line</i> in the address bus represents a single bit, with the total
          number of lines determining the address range the CPU can access. For
          example, a 16-bit address bus can address 2<sup>16</sup> unique memory
          locations, or 64KiB.
        </p>
        <p>
          When a CPU's address lines are exposed externally in the form of pins
          on the chip's package, this is called an <i>external</i> address
          bus<sup><a href="#footnote_1" id="footnote_1_link">1</a></sup>. These lines can be physically connected to external memory devices.
          Together with the CPU's <i>data bus</i>, this allow reading and
          writing binary data back and forth.
        </p>
        <p>
          When the CPU performs an instruction that reads or writes memory, like
          <code>LDB 0x2001</code>, several things happen:
        </p>
        <ul>
          <li>
            The CPU's external address pins are set to high and low
            <a href="https://en.wikipedia.org/wiki/Logic_level" target="_blank">logic levels</a>
            according to the specified address. For address
            <span>0x2001</span>
            (<code>0b0010_0000_0000_0001</code>), address pins 0 and 13 will be
            high, and all the others will be low.
          </li>
          <li>
            The CPU's <code>RW</code> pin will be set high to
            indicate that this is a <i>read</i> operation, and...
          </li>
          <li>
            The CPU will prepare to accept the incoming data at
            <span>0x2001</span> over the data bus into the
            <span>B</span> register.
          </li>
        </ul>

        <p>
          But wait... If the CPU only has one set of address and data bus lines,
          how do you connect multiple memory devices to the CPU? This is where
          the
          <a href="https://en.wikipedia.org/wiki/Chip_select" target="_blank"><i>'Chip Select'</i></a>
          interface comes in: Each device attached to the CPU's data/address
          buses has a 'Chip Select' pin, controlling whether the device responds
          to incoming signals.
        </p>
        <p>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/address_decoding_logic.png" target="_blank">
            <img alt="A schematic showing the address decoding logic of a hypothetical system." src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/address_decoding_logic_thumbnail.jpg">
          </a>
          Consider the above (incredibly simplified) diagram: Two 8KiB
          <a href="https://en.wikipedia.org/wiki/6264" target="_blank">6264</a>
          RAM chips (U3 and U4) are connected to shared address and data buses
          on a Z80 CPU. U3's <code>CE1</code> (Chip Enable)
          pin is connected to the CPU's A13 pin. The bar over the top of the
          label indicates that this pin is <i>'Active Low'</i>, meaning a low
          logic level will 'activate' its function. When the CPU selects an
          address between <span>0x0</span> and
          <span>0x1FFF</span>, the A13 pin will be low,
          activating the U3 chip. U4's <code>CE1</code> pin
          is attached to the CPU's A13 pin via a <code>NOT</code> gate, which
          inverts the signal coming from A13. When an address above
          <span>0x1FFF</span> is selected, A13 will be set
          high, selecting the U4 chip. This effectively maps U3 to the first
          8KiB of the system's memory, and U4 to the next.
        </p>
        <p>
          Can you spot the problem with this example? Since <em>any</em> address
          using A13 will 'select' U4, U4 is now mapped to <em>every</em> 8KiB
          block of memory above <span>0x1FFF</span>. In
          reality, more sophisticated logic is used to map memory devices. Let's
          examine the real world example of the DX7's address decoding
          circuitry.
        </p>

        <p><span>Logic Gates:</span>
          The DX7's <i>address decoding logic</i> is primarily implemented via
          the use of <i>logic gates</i>. If you're not familiar with logic
          gates, a good introduction to the topic can be found
          <a href="https://www.khanacademy.org/computing/computers-and-internet/xcae6f4a7ff015e7d:computers/xcae6f4a7ff015e7d:logic-gates-and-circuits/a/logic-gates" target="_blank">here</a>. Don't worry though, we're not going to be going too in-depth. A
          basic understanding of what <code>AND</code>, <code>OR</code>, and
          <code>NOT</code> gates do is all you need. One particular type of
          component you'll encounter a lot inside vintage synthesisers are
          <a href="https://en.wikipedia.org/wiki/7400-series_integrated_circuits" target="_blank">7400-series logic chips</a>.
        </p>

        <h2 id="memory_map">
          Decoding the DX7's Memory Map
          <a href="#memory_map">#</a>
        </h2>
        <p>
          Nearly all of the discrete electrical components that make up a DX7
          are commonly available products. They're mass-manufactured and sold by
          a variety of different manufacturers. The best way to understand these
          components is to read the <i>datasheets</i> made available by the
          manufacturer. I'll provide links to these as we go.
        </p>
        <p><span>Note:</span>
          The creator of the DX7 schematics used the <i>logic</i> symbols ·
          and + to denote <code>AND</code> and <code>OR</code> gates, rather
          than the more standard
          <a href="https://www.electrical-symbols.com/electrical-electronics-pdf/Logic_Gates_Symbols.pdf" target="_blank">
            ANSI, or IEC notations </a><sup>[pdf]</sup>. Other gates use the ANSI notation.
        </p>
        <h3 id="rom_address_decoding">
          The Firmware ROM
          <a href="#rom_address_decoding">#</a>
        </h3>
        <p>Let's start by taking a look at the firmware ROM, IC14.</p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/rom.png" target="_blank">
            <img alt="An excerpt from the Yamaha DX7's schematics, with the ROM address mapping logic highlighted" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/rom_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt from the Yamaha DX7's schematics, with the ROM address
            mapping logic highlighted.
          </figcaption>
        </figure>
        <p>
          In the schematic we can see that IC14's
          <code>CE1</code> pin is connected to the CPU's
          <code>A14/A15</code> lines via an <code>AND</code> gate, and a
          <code>NOT</code> gate. What's going on here?
        </p>
        <p>
          The <code>AND</code> gate ensures that the signal is only high when
          <em>both</em> address lines are active, and the <code>NOT</code> gate
          inverts the signal so that it activates the <em>active-low</em>
          <code>CE1</code> pin. If <code>A14</code> and
          <code>A15</code> being active on the CPU 'selects' the ROM chip, that
          means it's mapped to the address range
          <span>0xC000 - 0xFFFF</span><sup><a href="#footnote_2" id="footnote_2_link">2</a></sup>.
        </p>
        <p>
          Awesome! That wasn't so hard. Now we know where the ROM is mapped in
          memory. What's next?
        </p>

        <h3 id="ram_address_decoding">
          RAM <a href="#ram_address_decoding">#</a>
        </h3>
        <p>
          The address decoding logic for the RAM is a little more complicated.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/ram.png" target="_blank">
            <img alt="An excerpt from the Yamaha DX7's schematics, with the RAM address mapping logic highlighted" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/ram_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt from the Yamaha DX7's schematics, with the RAM address
            mapping logic highlighted.
          </figcaption>
        </figure>
        <p>
          The DX7 features three 4KiB
          <a href="https://www.allaboutcircuits.com/electronic-components/datasheet/M5M5118P--Mitsubishi/" target="_blank">5118P</a>
          RAM chips (IC19, 20, 21). These are connected to the CPU's address bus
          via a
          <a href="https://www.ti.com/product/SN74LS138" target="_blank">74LS138 demultiplexer</a>
          (IC23). This
          <a href="https://www.electronics-tutorials.ws/combination/comb_3.html" target="_blank">demultiplexing</a>
          circuit is used to select one of 8 individual output lines based on a
          3-bit input signal. These output lines are labeled as
          <code>Y<sub>0</sub></code> -
          <code>Y<sub>7</sub></code>, and the input lines as <code>D<sub>A</sub></code>, <code>D<sub>B</sub></code>, and <code>D<sub>C</sub></code>. The <code>OR</code> gates used here are wired to the system clock
          output pin. Presumably to ensure the timing of read and write
          operations are valid.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/74ls138_function_table.png" target="_blank">
            <img alt="The function table from the 74LS138P's datasheet" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/74ls138_function_table_thumbnail.jpg">
          </a>
          <figcaption>
            The 'Function Table' from the 74LS138P's datasheet, showing what
            combinations of input lines select which output line.
          </figcaption>
        </figure>
        <p>
          The first RAM chip (IC19)'s chip select terminal is connected to the
          demultiplexer's
          <code>Y<sub>2</sub></code> line. The 'Function
          Table' from the 74LS138P datasheet shows that
          <code>Y<sub>2</sub></code> will be set low when
          input <code>D<sub>B</sub></code> (connected to the CPU's
          <code>A12</code>) is high. Therefore, when the CPU selects address
          <span>0x1000</span>, the first RAM chip will be
          selected.
        </p>
        <p>
          <code>Y<sub>3</sub></code>
          (connected to the second RAM chip, IC20) will be set low when inputs
          <code>D<sub>A</sub></code> and <code>D<sub>B</sub></code> (<code>A11</code>
          and <code>A12</code>) are high, corresponding to an address of
          <span>0x1800</span>. Likewise,
          <code>Y<sub>4</sub></code>
          (connected to IC21) corresponds to an address of
          <span>0x2000</span>.
        </p>
        <p>
          By tracing this address decoding logic, we've successfully mapped the
          synth's RAM to
          <span>0x1000 - 0x2800</span>.
        </p>

        <h3 id="lcd_address_decoding">
          LCD Screen <a href="#lcd_address_decoding">#</a>
        </h3>
        <p>
          The last peripheral we're going to look at right now is the synth's
          LCD screen. When you take your first peek inside a binary you'll be
          staring at an intimidating jumble of machine code. One of the few
          things that will stand out at a glance is ASCII strings. A good way to
          get a quick overview of the binary is finding out how these strings
          are printed to the screen, and where.
        </p>
        <p>
          The best place to start doing that is understanding how the CPU
          interfaces with the LCD controller, and working your way backwards to
          the code responsible for sending string data to it. Once you've found
          <em>how</em> strings are printed to the screen, you can easily see
          <em>what's</em> printed <em>where</em> to get a better understanding
          of the code.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/lcd.png" target="_blank">
            <img alt="An excerpt from the Yamaha DX7's schematics, with the LCD address mapping logic highlighted" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/lcd_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt from the Yamaha DX7's schematics, with the LCD address
            mapping logic highlighted.
          </figcaption>
        </figure>
        <p>
          The LCD address mapping logic might look really complicated, but don't
          worry though. It's just more of the same logic as before.
        </p>
        <p>
          IC23's <code>Y<sub>5</sub></code> pin is connected
          to IC24, another 74LS138 demultiplexer. From the 74LS138 function
          table we know that <code>Y<sub>5</sub></code> goes
          low when inputs A, and C (<code>A11</code> and <code>A13</code>) are
          high. So it looks like IC24 is mapped to
          <span>0x2800</span>.
        </p>
        <p>
          Take a look at IC24: Inputs A, B and C are wired to
          <code>A1</code>, <code>A2</code> and <code>A3</code>. That means that
          IC24 only maps <em>8 bytes</em>.
        </p>
        <p>
          IC24's <code>Y<sub>0</sub></code> and
          <code>Y<sub>1</sub></code> pins are connected to an
          <code>AND</code> gate connected to the 'chip select' pin of IC12.
          What's happening here? This might seem a little confusing at first,
          but since the 74LS138P's outputs are <i>active-low</i>, this makes
          <code>LCDCS</code> active when either
          <code>Y<sub>0</sub></code> or
          <code>Y<sub>1</sub></code> are active. This maps
          IC12 to the four-byte range
          <span>0x2800 - 0x2803</span>. Awesome. But what's
          IC12 doing?
        </p>
        <p>
          IC12 is an
          <a href="https://en.wikipedia.org/wiki/Intel_8255" target="_blank">Intel 8255</a>
          <i>Programmable Peripheral Interface (PPI)</i>. It provides 24
          parallel, bidirectional IO lines<sup><a href="#footnote_3" id="footnote_3_link">3</a></sup>.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/8255_basic_operation.png" target="_blank">
            <img alt="An excerpt from the Intel 8255 datasheet showing its basic operations" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/8255_basic_operation_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt from the Intel 8255 datasheet showing its basic
            operations.
          </figcaption>
        </figure>
        <p>
          The schematics show the LCD's parallel interface (<code>DB0 - DB7</code>) is connected to the PPI's port A (<code>PA0 - PA7</code>), and its
          control pins (<code>E, RW</code> and <code>RS</code>) to the PPI's
          port B (<code>PB0 - PB2</code>).
        </p>
        <p>
          The Hitachi LM016 LCD screen used in the DX7 features the ubiquitous
          <i><a href="https://en.wikipedia.org/wiki/Hitachi_HD44780_LCD_controller" target="_blank">Hitachi HD44780 LCD Controller</a></i>. According to its datasheet (available
          <a href="https://www.sparkfun.com/datasheets/LCD/HD44780.pdf" target="_blank">here</a>) it has two registers. When its <code>RS</code> line (connected to
          the PPI's <code>PB0</code>) is low, the <i>instruction register</i> is
          selected. When high, the <i>data register</i> is selected.
        </p>
        <p>
          Based on the HD44780 datasheet, and the above table from the 8255's
          datasheet, we can tell that the LCD's data register must be mapped to
          <span>0x2800</span>, and its control register to
          <span>0x2801</span>. We'll go into more detail
          about the LCD controller itself later in the article.
        </p>

        <h3 id="wrapping_up">
          Wrapping Up <a href="#wrapping_up">#</a>
        </h3>
        <p>
          Now we've got a pretty good idea of what's going on where in the
          memory map, and how this is discovered. To save you the trouble of
          going through the whole schematic, here are all the memory-mapped
          peripheral addresses.
        </p>
        <table>
          <tbody><tr>
            <th>Address Range</th>
            <th>Peripheral</th>
          </tr>
          <tr>
            <td><span>0x1000 - 0x2800</span></td>
            <td>RAM (External)</td>
          </tr>
          <tr>
            <td><span>0x2800</span></td>
            <td>LCD Data</td>
          </tr>
          <tr>
            <td><span>0x2801</span></td>
            <td>LCD Control</td>
          </tr>
          <tr>
            <td><span>0x2802</span></td>
            <td>Sustain/Portamento Pedals, and LCD Busy Line</td>
          </tr>
          <tr>
            <td><span>0x2803</span></td>
            <td>8255 Peripheral Controller Control Register</td>
          </tr>
          <tr>
            <td><span>0x2804</span></td>
            <td>OPS Mode register</td>
          </tr>
          <tr>
            <td><span>0x2805</span></td>
            <td>OPS Algorithm/Feedback register</td>
          </tr>
          <tr>
            <td><span>0x280A</span></td>
            <td>DAC Volume</td>
          </tr>
          <tr>
            <td><span>0x280E</span></td>
            <td>LED1</td>
          </tr>
          <tr>
            <td><span>0x280F</span></td>
            <td>LED2</td>
          </tr>
          <tr>
            <td><span>0x3000 - 0x4000</span></td>
            <td>EGS</td>
          </tr>
          <tr>
            <td><span>0x4000 - 0x5000</span></td>
            <td>Cartridge Interface</td>
          </tr>
          <tr>
            <td><span>0xC000 - 0xFFFF</span></td>
            <td>ROM</td>
          </tr>
        </tbody></table>

        <p>
          These aren't the only peripherals attached to the system, the Hitachi
          6303 CPU also features 'IO Ports'. These are memory-mapped
          input/output lines with their own dedicated functionality. We'll touch
          on these later in the article.
        </p>

        <h2 id="disassembling_the_firmware">
          Disassembling The Firmware
          <a href="#disassembling_the_firmware">#</a>
        </h2>
        <p>
          Now that we know the memory map, we can start disassembling the
          firmware. To do this we'll use a graphical disassembler called
          <a href="https://ghidra-sre.org/" target="_blank">Ghidra</a><sup><a href="#footnote_4" id="footnote_4_link">4</a></sup>. It's a relatively new player on the scene, but it's free, open
          source, and very powerful. A great resource to keep handy while
          working with Ghidra is the
          <a href="https://ghidra-sre.org/CheatSheet.html" target="_blank">Ghidra Cheat Sheet</a>.
        </p>

        <p><span>Ghidra 6303 Support:</span>
          As of the time of writing, Ghidra doesn't yet support the HD6303
          architecture out of the box, so we'll need to install our own language
          specification.
          <a href="https://github.com/blackjetrock/ghidra-6303" target="_blank">This</a>
          repository contains a Ghidra language specification for the 6303
          architecture. To install it, download the repository and copy the
          <code>6303</code> directory to the
          <code>Ghidra/Processors</code> directory inside your Ghidra
          installation. You'll need to restart Ghidra to see the new processor
          in the list.
        </p>

        <p>
          Once you've installed the language definitions, open Ghidra and create
          a new project.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/new_project.png" target="_blank">
            <img alt="A screenshot of Ghidra showing the 'New Project' dialog" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/new_project_thumbnail.jpg">
          </a>

          The first thing we're going to need to do is to import the firmware
          ROM binary. Select the '6303' language, and click 'OK'.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/set_language.png" target="_blank">
            <img alt="A screenshot of Ghidra showing the 'Select Language' dialog" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/set_language_thumbnail.jpg">
          </a>
        </p>
        <p>
          Next, open up the <i>Codebrowser</i>. This is where all the action
          happens.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/codebrowser.png" target="_blank">
            <img alt="A screenshot of Ghidra showing the 'Codebrowser' button" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/codebrowser_thumbnail.jpg">
          </a>
        </p>
        <p>
          Once the initial disassembly loads, the first thing you'll be looking
          at is row after row of hexadecimal. This is the actual machine code as
          it would appear to the CPU. Don't bother with <i>analyzing</i> the
          file.
        </p>
        <p>
          The first thing we're going to do is set up the memory map. Remember
          that thing we just did all that hard work figuring out? That's going
          to come in handy now. Press the <b>'Display Memory Map'</b> icon in
          the top button bar, to open up the Memory Map dialog.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/display_memory_map.png" target="_blank">
            <img alt="A screenshot of Ghidra showing the 'Display Memory Map' button" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/display_memory_map_thumbnail.jpg">
          </a>

          By default there's only one memory block defined. This block consists
          of the binary we just imported, so go ahead and rename it to
          <i>'ROM'</i>. The next thing we need to do is move this block to the
          correct offset <span>0xC000</span>. Because all of
          the machine code instructions reference memory with absolute
          addresses, if we didn't map the ROM to the correct location none of
          the disassembly would work.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/move_block_button.png" target="_blank">
            <img alt="A screenshot of Ghidra showing the 'Move Memory Block' button" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/move_block_button_thumbnail.jpg">
          </a>

          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/move_block.png" target="_blank">
            <img alt="A screenshot of Ghidra showing the 'Move Memory Block' dialog" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/move_block_thumbnail.jpg">
          </a>
        </p>
        <p>
          Before we finish setting up the memory map, let's take a quick look at
          the code. When the Hitachi 6303 processor in the DX7 powers up, it
          knows where to begin executing code by fetching a pointer from a
          specific location in the <i>interrupt vector table</i>.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/interrupt_vectors.png" target="_blank">
            <img alt="An excerpt table from the 6301/6303 Handbook showing the 6303's interrupt vector table" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/interrupt_vectors_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt table from the 6301/6303 Handbook showing the 6303's
            interrupt vector table.
          </figcaption>
        </figure>
        <p>
          In this case the <i>'Reset vector'</i> is always located at the
          specific memory address <span>0xFFFE</span>, right
          at the end of the address space. Press the
          <span>
            <span>Ctrl</span><span>+</span><span>End</span>
          </span>
          combination on your keyboard to move to the end of the binary, and
          select the offset <span>0xFFFE</span> by clicking
          on it. Press the
          <span><span>P</span></span>
          key on your keyboard to convert the data at this address to a pointer.
          You should see something similar to the image below.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_vector_pointer.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the reset vector pointer" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_vector_pointer_thumbnail.jpg">
          </a>
        </p>
        <p>
          Double-click on this pointer to take you to the associated offset in
          the binary. Now we've found where the actual code is located, but it
          doesn't look like much just yet.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_handler_location.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the reset handler function" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_handler_location_thumbnail.jpg">
          </a>
        </p>
        <p>
          To begin disassembling the machine code into something we can work
          with, click on the label and press the
          <span><span>D</span></span>
          key on your keyboard, or right-click and select
          <i>'Disassemble'</i> in the context menu.
        </p>
        <p><span>The Reset Vector:</span>
          Different processor architectures will have different methods for
          locating the reset handler. Typically a pointer to the reset handler
          will be stored in an <i>interrupt vector table</i> (IVT) at a fixed
          location in memory. On an ARM Cortex-M processor the IVT is located at
          address <span>0x0</span>, and the reset vector at
          <span>0x4</span>. On the
          <a href="https://en.wikipedia.org/wiki/MCS-51" target="_blank">MCS-51</a>
          architecture —another popular 8-bit microcontroller commonly
          seen in synthesisers— the actual reset <em>handler</em> begins
          at <span>0x0</span>.
        </p>
        <p>
          The disassembly process will follow the flow of code through the
          binary, disassembling as it goes. An error will pop up here, but don't
          worry about it for now. This is just the disassembler mistaking a jump
          table for code.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/analyzer_error.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the expected 'analyzer error' message" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/analyzer_error_thumbnail.jpg">
          </a>
        </p>
        <p>
          Once the disassembly completes you should see something like the
          picture below.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_handler_disassembled.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the disassembled reset handler" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_handler_disassembled_thumbnail.jpg">
          </a>
        </p>
        <p>
          Now we're looking at real code! No need to panic though. If you don't
          understand what you're looking at, that's okay. Assembly can look
          pretty intimidating at first, but with a little bit of practice you'll
          get the hang of it!
        </p>
        <p>
          Each of the lines you're seeing here represents a single machine-code
          instruction translated into assembly code. The three letter
          <i>mnemonics</i> are the human-readable representation of the
          instructions.
          <span>LDA</span>
          for example, is the mnemonic for the
          <i>'Load value into register A'</i> instruction.
          <span>STA</span>
          is the mnemonic for the
          <i>'Store value in register A'</i> instruction. If you've never
          encountered assembly language before, that's okay!
          <a href="https://youtu.be/4gwYkEK0gOk?si=ZY9W2wwP2YZEtN7V" target="_blank">This</a>
          video will give a very quick and general introduction to assembly
          language.
        </p>
        <p>
          The HD63B03RP CPU used in the DX7 is a member of the
          <a href="https://www.cpushack.com/tag/6800/" target="_blank">6800</a>
          family of processors. Its instruction set (the full set of assembly
          <i>instructions</i>) is small and easy to understand. A great resource
          for understanding the 6303 CPU and its instruction set is the
          <i><a href="http://www.bitsavers.org/components/hitachi/_dataBooks/1989_U07_HD6301_HD6303_Series_Handbook_1989.pdf" target="_blank">
              HD6301/HD6303 Series Handbook
            </a></i>
          freely available on bitsavers.org.
        </p>
        <p>
          The <span>FUN_c5e5</span> text you're seeing
          here is a <i>label</i>. This is a symbol placed in the disassembler's
          <a href="https://en.wikipedia.org/wiki/Symbol_table" target="_blank">symbol table</a>, which can be referenced elsewhere in the assembly code, usually as
          the target for a branching instruction. Ghidra should already have set
          up the reset vector as a 'function'. Select this label with your
          cursor and press the
          <span><span>F</span></span>
          key on your keyboard to edit the function and give it a more
          meaningful label like
          <span>reset</span>.
        </p>
        <p>
          But what are all these red labels we're seeing, like
          <span>DAT_2575</span>?
          If you try to double click on it, Ghidra offers a helpful error
          message: <i>'Address not found in program memory: 2575'</i>. This is
          because we're missing our memory map! Let's go back to the 'Memory
          Map' dialog, and add the missing blocks.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/adding_ram_memory_map.png" target="_blank">
            <img alt="A screenshot showing adding the RAM memory map block in Ghidra" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/adding_ram_memory_map_thumbnail.jpg">
          </a>
        </p>
        <p>
          Fill in the memory map that we worked out in the last section. The
          completed map should look something like the screenshot below. You can
          choose to consolidate some of these blocks if you like. It's not super
          important how the blocks are divided. What matters is that the blocks
          cover all of the needed peripheral addresses.

          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/memory_map.png" target="_blank">
            <img alt="The completed memory map shown in Ghidra, with all peripheral address space allocated" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/memory_map_thumbnail.jpg">
          </a>

          Note that I added memory blocks for the HD6303 CPU's internal
          registers, and internal RAM.
        </p>
        <p>
          Now is a good time to go and fill in the individual peripheral
          addresses that we know. The
          <a href="http://www.bitsavers.org/components/hitachi/_dataBooks/1989_U07_HD6301_HD6303_Series_Handbook_1989.pdf" target="_blank">HD6301/HD6303 Series Handbook</a>
          provides a list of the HD6303RP's internal registers.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/internal_register_area.png" target="_blank">
            <img alt="An excerpt from the Hitachi HD6301/HD6303 Series Handbook showing the IO port addresses" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/internal_register_area_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt from the Hitachi HD6301/HD6303 Series Handbook showing
            the IO port addresses.
          </figcaption>
        </figure>
        <p>
          Press the
          <span>
            <span>Ctrl</span><span>+</span><span>Home</span>
          </span>
          keys on your keyboard to go to address
          <span>0x0</span>. Press the
          <span><span>B</span></span> key
          on your keyboard to declare that address
          <span>0x0</span> specifies a byte of data. You'll
          see the <code>??</code> change to <code>db</code>, which is the
          assembler <i>directive</i> to define a byte of memory. Press the
          <span><span>L</span></span>
          key on your keyboard to give this address a useful label like
          <span>io_port_1_dir</span>. Go ahead and fill
          in the rest of the peripherals. When you go back to the reset handler
          you'll notice that, even with only a few pieces of the jigsaw puzzle
          in place, things will start to make a lot more sense.
        </p>

        <h3 id="reset_function">
          The Reset Function <a href="#reset_function">#</a>
        </h3>
        <p>
          The main reset handler in the DX7 is responsible for initialising the
          firmware. It sets up the CPU's IO ports, ensures the firmware's
          important variables have valid values, and sets up the CPU's
          <i>timer interrupt</i>. More on this later.
        </p>
        <p><span>Registers:</span>
          The 6303 has three general-purpose
          <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)" target="_blank">accumulator</a>
          registers: <span>A</span>,
          <span>B</span>, and
          <span>D</span>.
          <span>A</span> and
          <span>B</span> are both 8-bits in size, and
          <span>D</span> provides a 16-bit view of both of
          them combined: <code>D == (A &lt;&lt; 8) | B</code>.
        </p>
        <p>
          A great way to visualise the <i>'control flow'</i> of the program is
          in the <i>'Function Graph'</i> view. This view shows a directed graph
          of the program's branching logic. You can open this view by selecting
          <b>Window → Function Graph</b> in the top window menu. You
          should see a view similar to the picture below.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_function_graph.png" target="_blank">
            <img alt="A screenshot of Ghidra's function graph of the reset handler" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/reset_function_graph_thumbnail.jpg">
          </a>
          At offset <span>0xC605</span> you'll see the
          following instructions:
        </p>
        <div>
          <pre><span></span><span>LDA</span><span>   </span><span>#</span><span>0</span><span>xd</span>
<span>CMPA</span><span>  </span><span>DAT_2328</span>
<span>BHI</span><span>   </span><span>LAB_c60f</span>
</pre>
        </div>
        <ol>
          <li>
            The <span>LDA</span> instruction loads
            the <i>immediate</i> value <code>0xD</code> into the
            <span>A</span> register.
          </li>
          <li>
            The <span>CMPA</span> instruction then
            compares the value in the <span>A</span>
            register with the value at the memory address
            <span>DAT_2328</span>.
          </li>
          <li>
            The <span>BHI</span> instruction tells
            the CPU to branch to the label
            <span>LAB_c60f</span>
            if the value in the <span>A</span>
            register is greater than the value at
            <span>DAT_2328</span>.
          </li>
        </ol>
        <p><span>Condition Codes:</span>
          What <em>actually</em> happens when you execute a
          <span>CMPA</span>
          instruction is that the CPU sets a series of fields in the
          <i>'condition code'</i> register based on the result of the
          comparison. These <i>'condition codes'</i> are used by the conditional
          branching instructions to determine whether or not to take the branch.
          In this case, the
          <span>BHI</span> instruction will take
          the branch if the <i>C(arry)</i> and <i>Z(ero)</i>
          condition codes are both clear.
        </p>
        <p>
          You can see in the function graph that if the memory at
          <span>DAT_2328</span>
          is greater than or equal to '13', it will not branch, and the value
          will be cleared. The program will then continue to execute the next
          instruction, which would have been the original branch target. In this
          case, the program is checking to see that the 'pitch bend range'
          variable (stored in memory at location
          <span>0x2328</span>) is within a valid range of
          0-12. If not, it's reset to 0.
        </p>
        <p>
          If you look down at the bottom of the graph, you'll notice something
          interesting: The program goes into an infinite loop. This is the
          firmware's <i>'main loop'</i>.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/main_loop.png" target="_blank">
            <img alt="The firmware's 'main loop'" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/main_loop_thumbnail.jpg">
          </a>
          Tasks that need to be performed continuously happen here. Such as
          updating the UI based on user input, and parsing incoming MIDI
          messages.
        </p>
        <p>
          When certain tasks not only need to be performed <i>continuously</i>,
          but also <i>periodically</i>, there's another way to make this happen:
          <i>interrupts</i>.
        </p>
        <h3 id="interrupts">
          Interrupts <a href="#interrupts">#</a>
        </h3>
        <p>
          <a href="https://en.wikipedia.org/wiki/Interrupt" target="_blank">Interrupts</a>
          are signals sent to the processor by hardware or software to
          <em>interrupt</em> the current code being executed, and handle a
          specific event. They're commonly used in embedded-software to handle
          external, time-critical, or asynchronous events.
        </p>
        <p>
          One of the most common types of interrupt you'll encounter is a
          <a href="https://www.visualmicro.com/page/Timer-Interrupts-Explained.aspx" target="_blank"><i>'timer interrupt'</i></a>. The HD6303's built-in timer interrupt consists of a 16-bit
          <i>'counter'</i> register, which is incremented every clock cycle, and
          a 16-bit <i>'output compare'</i> register. When the value in the
          counter register matches the value in the output compare register, a
          timer interrupt will be raised. This causes the processor to halt what
          it was doing, push the current state of the CPU onto the stack, and
          jump to the appropriate interrupt handler specified in the interrupt
          vector table. In the 6303 a pointer to this handler is located at
          offset <span>0xFFF4</span>. Once the firmware is
          done handling the interrupt, it executes the
          <span>RTI</span> instruction, which
          restores the CPU's state from the stack and continues executing the
          code from where it left off.
        </p>
        <p>
          The timer interrupt handler is where all the synth's
          <i>real-time</i> functionality happens. This is any code that needs to
          be executed in a time-critical manner. The DX7 uses the periodic timer
          interrupt to process portamento and modulation, update the individual
          voice frequencies, and send the updated voice data to the sound chips.
          Feel free to declare the pointer to the timer interrupt handler just
          like we did for the reset handler, disassemble the handler, and take a
          look at what's going on.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/ocf_handler.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the interrupt vector table and the OCF interrupt handler pointer" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/ocf_handler_thumbnail.jpg">
          </a>
        </p>
        <h3 id="lcd_interface">
          LCD Interface <a href="#lcd_interface">#</a>
        </h3>
        <p>
          One of the best places to start reverse-engineering a synth's firmware
          is to understand how it prints things to the LCD screen. We already
          know <em>where</em> the LCD controller is mapped in memory, let's work
          backwards from there and see if we can find that code.
        </p>
        <p>
          Press the
          <span><span>G</span></span> key
          on your keyboard to open the <i>'Go To...'</i> dialog, and go to
          address <span>0x2800</span>.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_registers.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the LCD registers" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_registers_thumbnail.jpg">
          </a>
          These are the two memory-mapped LCD registers. The list of
          <i>cross-references</i> on the right shows us where these addresses
          are referenced in the code. Click on the
          <span>FUN_fdef</span> label to take us to this
          function. This is the function called by the reset handler to
          initialise the LCD screen.
        </p>
        <p>
          Below the function we can see something that looks like ASCII data.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/welcome_message.png" target="_blank">
            <img alt="Screenshot from Ghidra showing ASCII data embedded in the code" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/welcome_message_thumbnail.jpg">
          </a>
          In fact, it looks a lot like the welcome message displayed when you
          boot up the DX7. Hmm. Click on offset
          <span>0xFE31</span>, and press the
          <span><span>'</span></span> key
          on the keyboard twice. Once to convert the data at this offset to
          character data, twice to convert it to a NULL-terminated string.
        </p>
        <p>
          Notice that the welcome message location is referenced in the code at
          offset
          <span>0xFE2B</span>:
        </p>
        <div>
          <pre><span></span><span>JSR</span><span>   </span><span>FUN_fe52</span>
<span>LDX</span><span>   </span><span>#</span><span>0</span><span>xfe31</span>
<span>JMP</span><span>   </span><span>FUN_fea4</span>
</pre>
        </div>
        <p>
          Select the operand <code>#0xFe31</code>, and press
          <span>
            <span>Alt</span><span>+</span><span>Ctrl</span><span>+</span><span>R</span>
          </span>
          on your keyboard to turn this into a
          <i>memory reference</i>. The default label looks a bit strange, so you
          might want to give it a better one like
          <span>str_welcome_message</span>
          by selecting the reference and pressing the
          <span><span>L</span></span> key.
        </p>
        <p>
          We can see here that a pointer to the welcome message string is loaded
          into the <span>X</span> register, and then the
          ROM jumps to the function
          <span>FUN_fea4</span>. Could this function have
          something to do with printing the string? Let's find out.
        </p>
        <p><span>The Index Register (X):</span>
          The Motorola 6800 family of processors has an interesting feature
          called an
          <a href="https://en.wikipedia.org/wiki/Index_register" target="_blank"><i>'index register'</i></a>. The index register (<span>X</span>) can be
          used as a 16-bit base address, to which an 8-bit relative offset can
          be applied. For example, the <code>LDA 4,x</code> instruction will
          load the byte into <span>A</span> that is 4
          bytes from the address stored in <span>X</span>.
          This is useful because it allows us to reference 16-bit addresses with
          only an 8-bit operand.
        </p>
        <p>
          Let's take a walk through <span>FUN_fea4</span>
          together and see if we can figure out what it's doing:
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_print_and_update.png" target="_blank">
            <img alt="Screenshot from Ghidra showing an unknown function that prints the welcome message to the LCD screen" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_print_and_update_thumbnail.jpg">
          </a>
        </p>
        <ol>
          <li>
            First, it pushes the address of the welcome message string in
            <span>X</span> to the stack.
          </li>
          <li>
            Then it loads a memory address (<span>0x261F</span>) into <span>X</span>, and saves that address
            to a pointer in memory.
          </li>
          <li>
            Then it restores the welcome message address from the stack into
            <span>X</span>.
          </li>
        </ol>
        <p>
          Not very helpful yet, unfortunately. Something I find that helps make
          sense of so many unknown labels is to give them names that describe
          how they're used. Double-click on the label
          <span>DAT_00fb</span> to go to its location.
          Since we know this variable stores memory addresses, press the
          <span><span>P</span></span> key
          to convert it to a pointer. Giving it a name like
          <span>unknown_lcd_pointer_00fb</span>
          can help identify it at a glance later.
        </p>
        <p>
          Use the
          <span>
            <span>Alt</span><span>+</span><span>←</span>
          </span>
          keyboard combination to navigate back to where we were before. Once
          you're there, click through to
          <span>FUN_fe8b</span>.

          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_strcpy.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the function located at 0xfe8b" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_strcpy_thumbnail.jpg">
          </a>

          We can see that lots of cross-references to this function have been
          found in the code already. Let's go through this function step by step
          and see what we can figure out:
        </p>
        <ol>
          <li>
            We already know that the
            <span>X</span> register contains a pointer to
            a string. So we can see that this function is loading an ASCII
            character into register <span>B</span> from
            the address stored in <span>X</span>.
          </li>
          <li>
            When the <span>LDB</span> instruction
            loads a new value into <span>B</span> it sets
            the <i>condition codes</i> according to its value. If the
            most-significant bit of this byte is 1, the
            <i>N(egative)</i> condition code will be set. This will cause the
            <span>BMI</span> (<i><b>B</b>ranch If <b>MI</b>nus</i>) instruction to branch. Valid
            <a href="https://www.asciitable.com/" target="_blank">ASCII</a>
            values fall within the range 0-127, so this code looks like it's
            checking for an invalid character, and will branch to the exit if
            this is the case.<br>
            <b>Note:</b> Different instructions treat integer values as either
            signed, or unsigned, with the most-significant bit treated as the
            <a href="https://en.wikipedia.org/wiki/Sign_bit" target="_blank">sign bit</a>.
          </li>
          <li>
            The value in <span>B</span> is then compared
            against <code>0x20</code> (ASCII space). As I mentioned earlier, the
            <span>CMP</span> instruction sets
            condition codes according to the value in the associated
            accumulator, and the operand. The
            <span>BCC</span> instruction (<i><b>B</b>ranch If <b>C</b>arry <b>C</b>lear</i>) will branch if the <i>C(arry)</i> condition code is
            <em>clear</em>. This means that the value in
            <span>B</span> must be <code>0x20</code> or
            above, otherwise the function exits.<br>

            You can read more about how the carry flag is used in computer
            arithmetic on
            <a href="https://en.wikipedia.org/wiki/Carry_flag" target="_blank">Wikipedia</a>.
          </li>
          <li>
            If the ASCII char is valid, it calls
            <span>BSR</span> to branch to the
            subroutine <span>FUN_fe9a</span>. In this
            subroutine we can immediately see something interesting: Remember
            that pointer we labeled earlier? This subroutine writes the ASCII
            character in <span>B</span>
            to the location in this pointer, increments the pointer, and saves
            it...
          </li>
          <li>
            After this, the address in <span>X</span> is
            incremented, and the function loops back to the start. Now the
            function repeats, with <span>X</span> pointing
            to the <em>next</em> character in the string.
          </li>
        </ol>
        <p>
          Are you thinking what I'm thinking? This is a
          <em>String Copy</em> function! It copies characters from a string into
          a buffer, until either a NULL-terminator, or other unprintable ASCII
          character is encountered.
        </p>
        <p>
          Go ahead and give this function a label like
          <span>lcd_strcpy</span>. If you like, you can
          apply local labels to <span>LAB_fe94</span>,
          and <span>LAB_fe99</span> like
          <span>.copy_character</span> and
          <span>.exit</span>. Maybe give that buffer
          address we saw earlier (<span>0x261F</span>) a
          temporary label too.
        </p>
        <p><span>Subroutines:</span>
          You might have noticed the instructions
          <span>BSR</span>
          (<i>'<b>B</b>ranch to <b>S</b>ub<b>R</b>outine'</i>), or
          <span>JSR</span> (<i>'<b>J</b>ump to <b>S</b>ub<b>R</b>outine'</i>). These instructions are used to call <i>subroutines</i>. When a
          subroutine is <i>called</i>, the address of the next instruction is
          pushed onto the stack, and the
          <a href="https://en.wikipedia.org/wiki/Program_counter" target="_blank"><i>'program counter'</i></a>
          jumps to the address of the subroutine. When the subroutine calls the
          <span>RTS</span> instruction to
          <i>return</i> to its caller, this address is popped from the stack
          into the <span>PC</span> (Program Counter)
          register, and the program continues from where it left off. Just like
          a function call in a higher-level language.
        </p>
        <p>
          This is where we're at so far:
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_function_partially_annotated.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the function located at 0xfea4 partially annotated" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_function_partially_annotated_thumbnail.jpg">
          </a>
        </p>
        <p>
          Let's move on to that last function
          <span>FUN_fe52</span> and see where that leads
          us. This function is a bit more complicated. Using the
          <i>Function Graph</i> window I showed you before might help visualise
          what's going on.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_update.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the function graph of the function located at 0xfe52" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_update_thumbnail.jpg">
          </a>
          Let's go through this function step-by-step like we did before:
        </p>
        <ol>
          <li>
            A new location in memory (<span>0x263F</span>)
            is being saved to that pointer we saw before, and the LCD buffer
            address we saw earlier (<span>0x261F</span>) is
            being saved to a new pointer. There's something interesting about
            those addresses. They're 32 bytes apart. That seems a bit
            conspicuous, doesn't it? Maybe this corresponds to the length of the
            LCD screen (2 lines of 16 characters)?
          </li>
          <li>
            A constant value is loaded into
            <span>B</span>.
          </li>
          <li>
            Inside the loop, we can see that
            <span>B</span> is saved to the stack. A byte
            is then loaded into <span>A</span> from the
            location in the pointer at <span>0xF9</span>. We
            know from seeing the welcome message string loaded into
            <span>X</span>
            that this byte is ASCII string data. The pointer is then incremented
            and saved.
          </li>
          <li>
            This byte is then compared against the byte pointed to by
            <span>unknown_lcd_pointer_00fb</span>.
          </li>
          <li>
            If the character in
            <span>unknown_lcd_pointer_00f9</span> and
            <span>unknown_lcd_pointer_00fb</span>
            <em>aren't</em> equal, then this character is used as an argument
            for a function call to <span>FUN_fec7</span>.
          </li>
        </ol>
        <p>
          The function at <span>FUN_fec7</span> is a bit
          more complicated, so I'll walk you through what's happening.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_write_instruction.png" target="_blank">
            <img alt="The firmware's 'main loop'" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_write_instruction_thumbnail.jpg">
          </a>
        </p>

        <ol>
          <li>
            The constant <code>0x89</code> is written to the 8255 PPI control
            register at <span>0x2803</span>. The PPI
            datasheet refers to this as <i>'Control Word #5'</i>. This sets the
            PPI's Port A, and B to outputs, allowing the CPU to send data to the
            LCD controller.
          </li>
          <li>
            A value of zero is written to the LCD control register. This sets
            the <code>RS</code> line low to select the
            <i>Instruction Register</i>, and the <code>RW</code> line low to
            select a <i>Write</i> operation.
          </li>
          <li>
            The <code>E</code> line of the LCD is then driven high to instruct
            it to be ready to receive data over the data bus.
          </li>
          <li>
            The byte in <span>A</span> is then written to
            the LCD instruction register. After this, the <code>E</code> line is
            driven low, and the <code>RW</code> line is driven high to signal
            the end of the data transfer.
          </li>
          <li>
            The 8255 <i>'Control Word #13'</i> is written to the PPI control
            register to revert port A and C to being inputs.
          </li>
          <li>
            Finally, it branches unconditionally to
            <span>FUN_ff08</span>.
          </li>
        </ol>

        <p><span>Note about unconditional branches:</span>
          Sometimes, rather than returning with an
          <span>RTS</span> instruction, a
          subroutine will just unconditionally branch to the next subroutine. As
          long as the stack is managed correctly, this is perfectly valid. The
          second subroutine's ending
          <span>RTS</span>
          instruction will just pop the original return value from the stack and
          return to the original caller. This technique saves a few bytes of
          code.
        </p>

        <p>
          Let's check out the subroutine at
          <span>FUN_ff08</span> that our function jumps
          to.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_wait_ready.png" target="_blank">
            <img alt="A screenshot from Ghidra showing the subroutine at 0xFF08." src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_wait_ready_thumbnail.jpg">
          </a>
        </p>
        <ol>
          <li>
            The <code>E</code> and <code>RW</code> lines of the LCD controller
            are set high. This sets the LCD controller to read mode.
          </li>
          <li>
            The PPI's port C is read into the
            <span>A</span> register, then the
            <code>E</code> line of the LCD controller is set low to indicate the
            read operation is complete.
          </li>
          <li>
            A bitwise <code>AND</code> is performed between value of the
            <span>A</span> register and
            <code>0b1000_0000</code>. This checks the status of the
            <code>PC7</code> line. If the <code>PC7</code> line is high, the
            function loops back to the start.
          </li>
        </ol>
        <p>
          It's easy to miss, but if you look closely in the schematics you'll
          see that the PPI's <code>PC7</code> line is connected to
          <code>PA7</code>, which is connected to the LCD controller's DB7 pin.
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/lcd_busy_line.png" target="_blank">
            <img alt="An excerpt from the Yamaha DX7's schematics showing the PPI's connection to the LCD controller's 'Busy Flag' line" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/schematics/lcd_busy_line_thumbnail.jpg">
          </a>
          The DB7 pin serves as the LCD controller's <i>'Busy Flag'</i>. This
          flag indicates whether the LCD controller is busy processing data.
          When it's clear, the LCD controller is ready to accept new data.
        </p>
        <p>
          It looks like the purpose of this function is to poll the LCD
          controller, waiting for it to be ready to accept new data. Awesome!
          Let's give it a label like
          <span>lcd_wait_ready</span>. Okay! So putting
          it all together, the function at
          <span>0xFEC7</span> writes an
          <em>instruction</em> to the LCD controller, and then waits for it to
          be ready to receive data again. Go ahead and give it a name like
          <span>lcd_write_instruction</span>.
        </p>
        <p>
          Reverse-engineering often involves going down a rabbit hole. Sometimes
          you need to fill in a few different pieces of the puzzle before you
          can start to see the whole picture. Let's return to the function at
          <span>FUN_fe52</span> and see what happens
          next.
        </p>
        <p>
          We now know the loop is writing an instruction to the LCD controller,
          but what did this instruction do? The original instruction value when
          the function started was <code>0x80</code>, and it's incremented by
          one with each iteration of the loop. The HD44780 datasheet tells us
          that <code>0x80</code> is the instruction to set the DDRAM (Display
          Data RAM) address in the LCD controller. This is the address in the
          LCD's memory where the next character will be written. A value of
          <code>0x80</code> indicates the start of the screen's first line.
        </p>
        <p>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_write_data.png" target="_blank">
            <img alt="The firmware's 'main loop'" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_write_data_thumbnail.jpg">
          </a>
          The next function call (<span>FUN_fee7</span>)
          looks almost identical to our
          <span>lcd_write_instruction</span> function.
          The only difference is that it writes to the LCD controller's
          <em>data</em> register, rather than the instruction register. This
          must be where the actual character data is written! You can give this
          function a label like
          <span>lcd_write_data</span>. Note that this
          function <i>'falls-through'</i> to the LCD controller polling function
          we saw earlier.
        </p>
        <p>
          Now we know what's going on here. This is our LCD printing function!
          Notice that after writing the character data to the LCD, at offset
          <span>0xFE77</span> the function writes it to the
          buffer at <span>0x263F</span>? The incoming
          characters are compared against the contents of this buffer to see if
          they're identical, if they are then it skips printing the character.
          Maybe these buffers represent the <i>'next'</i>, and
          <i>'current'</i> contents of the LCD screen?
        </p>
        <p>
          After writing the LCD character data, the function then checks whether
          the LCD instruction byte is equal to <code>0xD0</code>. Now we know
          that this is checking whether the LCD DDRAM position is at the end of
          the second line. If not, it checks whether we're at the end of the
          first line (<code>0x90</code>). If so, the instruction byte is set to
          <code>0xC0</code>, which sets the DDRAM address to the start of the
          second line.
        </p>
        <p><span>Note about HD44780 DDRAM addresses:</span>
          Each 'line' in the HD44780 LCD controller actually has a length of 64
          characters, even if the screen is only 16 characters wide. As a
          result, <code>0xC0</code> (<code>0x80 + 0x40</code>) is the correct
          DDRAM address for the start of the second line.
        </p>
        <p>
          Awesome! Now we've discovered the LCD printing function! Go ahead and
          give it a name like <span>lcd_print</span>.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_print.png" target="_blank">
            <img alt="The firmware's 'main loop'" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/disassembly/lcd_print_thumbnail.jpg">
          </a>
          <figcaption>
            The completed <code>lcd_print</code> function. Note that I went
            ahead and labelled all of the important variables.
          </figcaption>
        </figure>
        <p>
          If you've followed along, give yourself a huge pat on the back. This
          was no easy feat! You've now got a pretty good understanding of how
          vintage synth binaries are reverse-engineered. Everything else
          involved in disassembling a synth's firmware is just a matter of
          applying these same ideas.
        </p>

        <p><span>Bonus:</span>
          The HD44780 LCD controller has been a staple in consumer devices for
          <em>decades</em><sup><a href="#footnote_5" id="footnote_5_link">5</a></sup>. LCD controllers compatible with the HD44780 instruction set are
          still being manufactured, and are commonly used in commercial, and
          hobby projects alike. Because of this, lots of tutorial material is
          available online, and the knowledge gained in working with it is
          applicable elsewhere.
        </p>

        <h2 id="going_further">
          Going Further <a href="#going_further">#</a>
        </h2>

        <h3 id="midi_handling_routine">
          The MIDI Handling Routine
          <a href="#midi_handling_routine">#</a>
        </h3>
        <p>
          After disassembling the LCD printing function, the next best way to
          figure out what's going on inside a synth ROM is to disassemble the
          function that parses incoming MIDI data. This function is an entry
          point to nearly every aspect of a synth's functionality. Disassembling
          it will allow you to trace the path of a particular MIDI message to
          its associated functionality. You can trace <i>'NOTE ON'</i> and
          <i>'NOTE OFF'</i> messages to find the code that handles starting and
          stopping individual voices; Or you can trace
          <i>'CONTROL CHANGE'</i> messages to find the code that handles pitch
          bend or modulation.
        </p>
        <p>
          I decided not to tackle this function in this article, as the DX7's
          MIDI parsing code is huge, and requires a lot of explanation. Parsing
          MIDI messages is always implemented via a straightforward state
          machine, and the code is nearly identical across different synths.
          Once you've seen how it works in one synth, you've seen how it works
          in nearly all of them.
        </p>

        <h3 id="debugging_the_firmware">
          Debugging the Firmware in an Emulator
          <a href="#debugging_the_firmware">#</a>
        </h3>
        <p>
          One of the best ways to understand what's going on inside a synth's
          firmware is to run it in an emulator. The
          <a href="https://www.mamedev.org/" target="_blank">MAME</a>
          emulation framework is freely available, and already supports a wide
          variety of vintage synths. It features a built-in disassembler, and a
          debugger that can be used to step through the firmware instruction by
          instruction to see what's happening in detail. When I was working on
          my
          <a href="https://github.com/ajxs/yamaha_dx97" target="_blank">Yamaha DX9/7</a>
          project, I used MAME as a testing and development platform for the
          firmware.
        </p>

        <h3 id="final_words">
          Final Words <a href="#final_words">#</a>
        </h3>
        <p>
          The DX7, and its 8-bit CPU might be a bit primitive by today's
          standards, but the same principles apply to reverse-engineering modern
          devices. Instructions sets and
          <a href="https://en.wikipedia.org/wiki/Calling_convention" target="_blank">calling-conventions</a>
          might change, but whether it's a vintage 8-bit architecture like the
          6800, or a cutting-edge 32-bit ARM system, the principles of how to
          disassemble device firmware remain the same.
        </p>
        <p>
          If you have any questions about this article, please get in touch! If
          you have any corrections or suggestions, I'd love to hear from you.
          Thank you for reading!
        </p>

        <h2 id="why_the_dx7">
          Appendix: Why Choose This Synth?
          <a href="#why_the_dx7">#</a>
        </h2>
        <h3>It Can Be Disassembled With Free Software</h3>
        <p>
          6303 binaries can be disassembled by using free and open source tools,
          such as <a href="https://ghidra-sre.org/" target="_blank">Ghidra</a>,
          <a href="https://github.com/Arakula/f9dasm" target="_blank">F9DASM</a>, and MAME's
          <a href="https://www.mameworld.info/easyemu/mameguide/tools/unidasm.html" target="_blank">Universal Disassembler</a>.
        </p>

        <h3>It's Well Documented</h3>
        <p>
          40 years on, the DX7 continues to captivate people's imaginations. As
          a result, lots is known about what goes on inside a DX7. Yamaha's
          service manuals are comprehensive, and freely available online.
        </p>
        <p>
          Yamaha even released internal documentation on the DX7's architecture
          and sound chips, which is now
          <a href="https://ajxs.me/blog/Yamaha_DX7_Official_Technical_Analysis.html" target="_blank">available online</a>.
        </p>

        <h3>Only One ROM</h3>
        <p>
          One advantage of reverse-engineering the DX7 is that there's only one
          ROM you need worry about.
          <em>Technically</em> there's also the sub-CPU and its mask ROM, but in
          this case you don't <em>really</em> need to worry what's going on
          there.
        </p>
        <p>
          Some synths have important part of the firmware stored on the CPU's
          mask ROM, such as the Casio CZ-101. Other synths spread the synth's
          core functionality across multiple CPUs, each with their own ROMs,
          such as the Roland JX-8P. The DX7 is much simpler, having (nearly) all
          of its code in one place.
        </p>

        <h3>It Has an LCD Screen</h3>
        <p>
          Disassembling code for a system with a text-based user interface has a
          lot of advantages. I considered some of the early DCO-based Roland
          polysynths as candidates for this article, but without an LCD screen
          it's much harder to make headway into a ROM.
        </p>

        <h3>No Bank Switching</h3>
        <p>
          Unfortunately the various disassembler tools available don't handle
          <a href="https://en.wikipedia.org/wiki/Bank_switching" target="_blank"><i>bank switching</i></a>
          very well. In Ghidra you can use 'Overlay' memory blocks to set up the
          different banks, however it's still not very intuitive in my
          experience.
        </p>
        <p>
          I considered the Ensoniq ESQ-1 as a candidate for this article. It
          features a Motorola MC6809 processor, which is very well supported by
          lots of different debuggers. However it uses bank switching, which
          makes it a bit of a nuisance to disassemble.
        </p>

        <h4>What Is Bank Switching?</h4>
        <p>
          What happens if you need to squeeze 64KiB of firmware ROM, and 32KiB
          of RAM into your HD6303 chip's 16-bit address space? One solution to
          this problem is <i>bank switching</i>. Many vintage synths use
          bank-switching to fit their firmware into the CPU's address space.
        </p>
        <p>
          Bank switching breaks a memory device's address space up into multiple
          <i>'banks'</i>
          by latching one or more of its address lines to one of the CPU's I/O
          port lines. This allows the CPU to select which 'bank' is active by
          toggling the aforementioned I/O line in the software.
        </p>
        <figure>
          <a href="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/tx81z_schematics_excerpt.png" target="_blank">
            <img alt="Yamaha TX81Z schematics excerpt showing CPU, ROM, and RAM" src="https://ajxs.me/static/articles/reverse_engineering_vintage_synths/tx81z_schematics_excerpt_thumbnail.jpg">
          </a>
          <figcaption>
            An excerpt from the Yamaha TX81Z's schematics, showing the CPU, ROM,
            and RAM wiring.
          </figcaption>
        </figure>
        <p>
          The Yamaha TX81Z features a 64KiB 27C512 EPROM chip, mapped into the
          CPU's address space at
          <span>0x8000 - 0xFFFF</span>. The EPROM's A0-A14
          pins are wired to the CPU's A0-A14, and the EPROM's
          <code>CE1</code> pin is latched to the CPU's A15
          pin. The EPROM's A15 pin is wired to the CPU's I/O port 6 (pin
          <code>P63</code> in the schematics). If the <code>P63</code> I/O line
          is pulled <em>high</em>, the upper half of the EPROM's memory is
          selected, mapping addresses
          <span>0x8000 - 0xFFFF</span> into the CPU's
          address space. If it's pulled <em>low</em>, the EPROM's
          <span>0x0000 to 0x7FFF</span> memory is mapped to
          <span>0x8000 - 0xFFFF</span>.
        </p>
        <p>
          To allow branching from code in one bank to code in another, a common
          technique is to use a
          <i><a href="https://en.wikipedia.org/wiki/Trampoline_(computing)" target="_blank">'trampoline function'</a></i>
          located at the same address in both banks.
        </p>

        <h2 id="documentation">
          Appendix: Documentation
          <a href="#documentation">#</a>
        </h2>
        <p>
          Below is a list of all the important documentation referenced in the
          article.
        </p>
        <ul>
          <li>
            <a href="https://yamahamusicians.com/forum/viewtopic.php?p=90769#p90769" target="_blank">
              DX7 Schematic
            </a>
          </li>
          <li>
            <a href="https://homepages.abdn.ac.uk/d.j.benson/pages/dx7/manuals/dx7-9_service_manual_1.pdf" target="_blank">
              DX7 Service Manual
            </a>
          </li>
          <li>
            <a href="https://www.alldatasheet.com/datasheet-pdf/pdf/63667/HITACHI/HD6303R.html" target="_blank">
              Hitachi HD6303R Datasheet
            </a>
          </li>
          <li>
            <a href="http://www.bitsavers.org/components/hitachi/_dataBooks/1989_U07_HD6301_HD6303_Series_Handbook_1989.pdf" target="_blank">
              HD6301/HD6303 Series Handbook
            </a>
          </li>
          <li>
            <a href="https://www.sparkfun.com/datasheets/LCD/HD44780.pdf" target="_blank">
              Hitachi HD44780 Datasheet
            </a>
          </li>
          <li>
            <a href="https://www.alldatasheet.com/datasheet-pdf/pdf/66100/INTEL/8255A.html" target="_blank">
              Intel 8255 Datasheet
            </a>
          </li>
          <li>
            <a href="https://www.ti.com/product/SN74LS138#tech-docs" target="_blank">
              74LS138 Datasheet
            </a>
          </li>
        </ul>

        <hr>
        <ol>
          <li id="footnote_1">
            The Hitachi 6303 microcontroller used in the DX7 includes both an
            <i>internal</i>, and <i>external</i> memory bus. The first 256
            memory addresses in the 6303 point to the CPU's internal registers
            and on-board RAM. Many modern microcontrollers —such as the
            Atmel AVR, and Microchip PIC series— don't feature external
            address buses. It's more common for modern microcontrollers to
            communicate with peripheral devices over serial buses, using
            protocols such as SPI, or I<sup>2</sup>C.
            <a href="#footnote_1_link">↲</a>
          </li>
          <li id="footnote_2">
            On boot, the
            <a href="https://en.wikipedia.org/wiki/Motorola_6800" target="_blank">6800</a>
            CPU family fetches the <i>reset vector</i> from the fixed address of
            <span>0xFFFE</span>. Knowing this, we could have
            just made an educated guess that the whole ROM was mapped to the
            high addresses. Still, it's always good to check your assumptions!
            <a href="#footnote_2_link">↲</a>
          </li>
          <li id="footnote_3">
            If you're curious about why the 8255 PPI chip is used here, it's
            most likely because the LCD controller, cartridge, and
            portamento/sustain pedal interface don't feature a chip select
            interface.
            <a href="#footnote_3_link">↲</a>
          </li>
          <li id="footnote_4">
            There are a variety of disassemblers available for the HD6303
            architecture. The state-of-the-art graphical disassembler is
            arguably
            <a href="https://hex-rays.com/IDA-pro/" target="_blank">IDA Pro</a>,
            but it's closed source, and prohibitively expensive for hobbyists.
            Non-graphical disassemblers also exist, such as
            <a href="https://github.com/Arakula/f9dasm" target="_blank">F9DASM</a>. If you're new to reverse-engineering, I'd personally recommend
            starting with Ghidra. It's free, open source, and easy to learn.
            <a href="#footnote_4_link">↲</a>
          </li>
          <li id="footnote_5">
            I went down a bit of a rabbit-hole trying to find what year the
            LM016/HD44780 was first manufactured. The earliest reference I can
            find online is a
            <a href="https://archive.org/details/Hitachi-DotMarixLiquidCrystalDisplayControllerandDriverLCD-IIHD44780UsersManualOCR/page/n1/mode/2up" target="_blank">'preliminary' user's manual</a>, dated March 1981. It's a shame that there's so little background
            information available about one of the best-known ICs in history.
            <a href="#footnote_5_link">↲</a>
          </li>
        </ol>
      </div></div>]]></description>
        </item>
    </channel>
</rss>