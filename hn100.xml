<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 06 Dec 2023 11:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Microsoft Outlook Blocking All Email from Tutanota.com Domain as Spam (107 pts)]]></title>
            <link>https://tuta.com/blog/posts/outlook-falsely-marks-tutanota-emails-as-junk</link>
            <guid>38541355</guid>
            <pubDate>Wed, 06 Dec 2023 07:39:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tuta.com/blog/posts/outlook-falsely-marks-tutanota-emails-as-junk">https://tuta.com/blog/posts/outlook-falsely-marks-tutanota-emails-as-junk</a>, See on <a href="https://news.ycombinator.com/item?id=38541355">Hacker News</a></p>
Couldn't get https://tuta.com/blog/posts/outlook-falsely-marks-tutanota-emails-as-junk: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[Why is Jepsen written in Clojure? (205 pts)]]></title>
            <link>https://aphyr.com/posts/367-why-is-jepsen-written-in-clojure</link>
            <guid>38540761</guid>
            <pubDate>Wed, 06 Dec 2023 05:32:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aphyr.com/posts/367-why-is-jepsen-written-in-clojure">https://aphyr.com/posts/367-why-is-jepsen-written-in-clojure</a>, See on <a href="https://news.ycombinator.com/item?id=38540761">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>People keep asking why <a href="https://jepsen.io/">Jepsen</a> is written in <a href="https://clojure.org/">Clojure</a>, so I figure it’s worth having a referencable answer. I’ve programmed in something like twenty languages. Why choose a Weird Lisp?</p>
<p>Jepsen is built for testing concurrent systems–mostly databases. Because it tests concurrent systems, the language itself needs good support for concurrency. Clojure’s immutable, persistent data structures make it easier to write correct concurrent programs, and the language and runtime have excellent concurrency support: real threads, promises, futures, atoms, locks, queues, cyclic barriers, all of java.util.concurrent, etc. I also considered languages (like Haskell) with more rigorous control over side effects, but decided that Clojure’s less-dogmatic approach was preferable.</p>
<p>Because Jepsen tests databases, it needs broad client support. Almost every database has a JVM client, typically written in Java, and Clojure has decent Java interop.</p>
<p>Because testing is experimental work, I needed a language which was concise, adaptable, and well-suited to prototyping. Clojure is terse, and its syntactic flexibility–in particular, its macro system–work well for that. In particular the threading macros make chained transformations readable, and macros enable re-usable error handling and easy control of resource scopes. The Clojure REPL is really handy for exploring the data a test run produces.</p>
<p>Tests involve representing, transforming, and inspecting complex, nested data structures. Clojure’s data structures and standard library functions are possibly the best I’ve ever seen. I also print a lot of structures to the console and files: Clojure’s data syntax (EDN) is fantastic for this.</p>
<p>Because tests involve manipulating a decent, but not huge, chunk of data, I needed a language with “good enough” performance. Clojure’s certainly not the fastest language out there, but idiomatic Clojure is usually within an order of magnitude or two of Java, and I can shave off the difference where critical. The JVM has excellent profiling tools, and these work well with Clojure.</p>
<p>Jepsen’s (gosh) about a decade old now: I wanted a language with a mature core and emphasis on stability. Clojure is remarkably stable, both in terms of JVM target and the language itself. Libraries don’t “rot” anywhere near as quickly as in Scala or Ruby.</p>
<p>Clojure does have significant drawbacks. It has a small engineering community and no (broadly-accepted, successful) static typing system. Both of these would constrain a large team, but Jepsen’s maintained and used by only 1-3 people at a time. Working with JVM primitives can be frustrating without dropping to Java; I do this on occasion. Some aspects of the polymorphism system are lacking, but these can be worked around with libraries. The error messages are terrible. I have no apologetics for this. ;-)</p>
<p>I prototyped Jepsen in a few different languages before settling on Clojure. A decade in, I think it was a pretty good tradeoff.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JSONB Has Landed in SQLite (307 pts)]]></title>
            <link>https://sqlite.org/forum/forumpost/fa6f64e3dc1a5d97</link>
            <guid>38540421</guid>
            <pubDate>Wed, 06 Dec 2023 04:16:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite.org/forum/forumpost/fa6f64e3dc1a5d97">https://sqlite.org/forum/forumpost/fa6f64e3dc1a5d97</a>, See on <a href="https://news.ycombinator.com/item?id=38540421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>JSONB is a rewrite of the <a href="https://sqlite.org/draft/json1.html">SQLite JSON functions</a>
that, depending on usage patterns, could be several times faster
than the original JSON functions.  This enhancement has now
<a href="https://sqlite.org/src/info/7f0c79b94e8f55e5">landed on trunk</a>.</p>

<p>Developers who use JSON heavily in their applications are encouraged
to download a <a href="https://sqlite.org/download.html">pre-release snapshot</a>
and give the new code a try.</p>

<h2>How Is This Different?</h2>
<p>Functions that deal with text JSON use a three-step process:</p>

<ol>
<li><p>Parse the text JSON into an internal binary format that is
  more accessible to C-code.</p></li>
<li><p>Carry out the requested operation.  Maybe this is looking up
  a field in an object, or perhaps it is modifying the JSON in
  some way.</p></li>
<li><p>If the processing involved changing the JSON, convert the
  internal binary format back into 
  <a href="https://www.rfc-editor.org/rfc/rfc8259">RFC-8279</a> JSON text for
  output and/or storage.</p></li>
</ol>

<p>Step 2 is the essential operation that you want to accomplish.  Steps
1 and 3 are just overhead.</p>

<p>Historically, SQLite used an internal binary
representation of JSON that involved lots of pointers.  This fits
will into C programs, but it is difficult to serialize.
The JSONB rewrite changes the internal-use binary representation of
JSON into a contiguous byte array that can read or written as an SQL BLOB.
This allows the internal-use representation of JSON to potentially be
saved to the database, in place of JSON text, eliminating the overhead
of steps 1 and 3.</p>

<h2>What has changed?</h2>
<p>All legacy functionality is preserved.  The only change has been to add
new capabilities.</p>

<p>Any JSON function that accepts JSON text as an input will now also accept
JSONB binary content for that same parameter.  You do not have to tell the
function if it getting text or binary data.  It figures that out for itself.</p>

<p>JSON functions that output JSON now come in two versions.  The historical
"<tt>json_</tt>" functions works as before.  But there is now a corresponding
"<tt>jsonb_</tt>" function that returns JSONB rather than text JSON, thus
omitting step 3 in the normal processing.</p>

<p>If you don't make any changes to your application, everything should
continue to work as it always has, though perhaps slightly (1%) faster.</p>

<p>But if you modify your application to start storing JSONB instead of text
JSON, you might see a 3-times performance improvement, at least for the
JSON-intensive operations.  JSONB is also slightly smaller than text JSON
in most cases (about 5% or 10% smaller) so you might also see a modest
reduction in your database size if you use a lot of JSON.</p>

<h2>Migrating</h2>
<p>Note that all functions accept both text JSON and JSONB.  So to start using
JSONB, you do <u>not</u> have to modify your database files to convert
legacy text JSON into JSONB.  Just start writing out JSONB for new entries.
The old entries will continue to work.  The new entries will just work
faster.</p>

<p>Or, if you do want to convert all your legacy data to JSONB, you can just
run an update operation like:</p>

<blockquote>
<pre><code>UPDATE bigtable SET jsonColumn = jsonb(jsonColumn);
</code></pre></blockquote>

<h2>Please provide comments</h2>
<p>If you find this enhancement useful, or if you try it out and see performance
regressions or bugs, please let us know.  Leave a follow-up post here, or
contact me directly at drh at sqlite dot org.</p>

<p>The current plan is to release the JSONB enhancement in the next
major release of SQLite - version 3.45.0.  That will probably occur
in a month or two.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go Testing by Example [video] (137 pts)]]></title>
            <link>https://research.swtch.com/testing</link>
            <guid>38539174</guid>
            <pubDate>Wed, 06 Dec 2023 00:58:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.swtch.com/testing">https://research.swtch.com/testing</a>, See on <a href="https://news.ycombinator.com/item?id=38539174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Go Testing By Example
        
        <div>
        <p>
          
            Posted on Tuesday, December 5, 2023.
            
          
        </p>
        </div>
        </h2>
        

<p>
I opened GopherCon Australia in early November with the talk “Go Testing By Example”.
Being the first talk, there were some A/V issues, so I re-recorded it at home and have posted it here:
</p><p>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/X4rxi9jStLo?si=DJiEGUPNxPlYnlWL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p>


<p>
Here are the 20 tips from the talk:
</p><ol>
<li>
Make it easy to add new test cases.
</li><li>
Use test coverage to find untested code.
</li><li>
Coverage is no substitute for thought.
</li><li>
Write exhaustive tests.
</li><li>
Separate test cases from test logic.
</li><li>
Look for special cases.
</li><li>
If you didn’t add a test, you didn’t fix the bug.
</li><li>
Not everything fits in a table.
</li><li>
Test cases can be in testdata files.
</li><li>
Compare against other implementations.
</li><li>
Make test failures readable.
</li><li>
If the answer can change, write code to update them.
</li><li>
Use <a href="https://pkg.go.dev/golang.org/x/tools/txtar">txtar</a> for multi-file test cases.
</li><li>
Annotate existing formats to create testing mini-languages.
</li><li>
Write parsers and printers to simplify tests.
</li><li>
Code quality is limited by test quality.
</li><li>
Scripts make good tests.
</li><li>
Try <a href="https://pkg.go.dev/rsc.io/script">rsc.io/script</a> for your own script-based test cases.
</li><li>
Improve your tests over time.
</li><li>
Aim for continuous deployment.</li></ol>


<p>
Enjoy!
      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An update on Twitch in Korea (170 pts)]]></title>
            <link>https://blog.twitch.tv/en/2023/12/05/an-update-on-twitch-in-korea/</link>
            <guid>38539167</guid>
            <pubDate>Wed, 06 Dec 2023 00:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.twitch.tv/en/2023/12/05/an-update-on-twitch-in-korea/">https://blog.twitch.tv/en/2023/12/05/an-update-on-twitch-in-korea/</a>, See on <a href="https://news.ycombinator.com/item?id=38539167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tw-impression-id="body"><p>This morning, I shared with our community in Korea that we’ve made the difficult decision to shut down the Twitch business in Korea on February 27, 2024 KST. We understand that this is extremely disappointing news, and we want to explain why we made this decision and how we are planning to support those impacted.</p><p>Ultimately, the cost to operate Twitch in Korea is prohibitively expensive and we have spent significant effort working to reduce these costs so that we could find a way for the Twitch business to remain in Korea. First, we experimented with a peer-to-peer model for source quality. Then, we adjusted source quality to a maximum of 720p. While we have lowered costs from these efforts, our network fees in Korea are still 10 times more expensive than in most other countries. Twitch has been operating in Korea at a significant loss, and unfortunately there is no pathway forward for our business to run more sustainably in that country.</p><p>To all of our global communities, we want to make it clear that this is a unique situation. Operating costs in Korea are significantly higher than they are in other countries and we have been open about this challenge for some time.</p><p>Twitch streamers in Korea have devoted significant time and effort into building their communities, and we plan to help these communities find new homes — even if it’s regrettably not on Twitch. We will work to help Twitch streamers in Korea move their communities to alternative livestreaming services in Korea. We are also reaching out to several of these services to help with the transition and will communicate with impacted streamers as those discussions progress.</p><p>I want to reiterate that this was a very difficult decision and one we are very disappointed we had to make. Korea has always and will continue to play a special role in the international esports community and we are incredibly grateful for the communities they built on Twitch.</p><p>For more information, please see our <a href="https://twitch-web.app.link/e/NLGoBvzBYEb">Help article</a> or join our live stream where I’ll be taking the community’s questions. We will host a stream for our Korean community on /TwitchKR today, December 6 at 9:30 am KST (December 5, at 4:30pm PT). For people outside of the Korean community, I will host another session on /Twitch today, December 6 at 11am KST (December 5, at 6pm PT) to answer questions about this decision or other topics.</p><p>Dan Clancy, Twitch CEO</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MLX: An array framework for Apple Silicon (111 pts)]]></title>
            <link>https://github.com/ml-explore/mlx</link>
            <guid>38539153</guid>
            <pubDate>Wed, 06 Dec 2023 00:56:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ml-explore/mlx">https://github.com/ml-explore/mlx</a>, See on <a href="https://news.ycombinator.com/item?id=38539153">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">MLX</h2>
<p dir="auto"><a href="#quickstart"><strong>Quickstart</strong></a> | <a href="#installation"><strong>Installation</strong></a> |
<a href="https://ml-explore.github.io/mlx/build/html/index.html" rel="nofollow"><strong>Documentation</strong></a> |
<a href="#examples"><strong>Examples</strong></a></p>
<p dir="auto">MLX is an array framework for machine learning on Apple silicon, brought to you
by Apple machine learning research.</p>
<p dir="auto">Some key features of MLX include:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Familiar APIs</strong>: MLX has a Python API that closely follows NumPy.
MLX also has a fully featured C++ API, which closely mirrors the Python API.
MLX has higher-level packages like <code>mlx.nn</code> and <code>mlx.optimizers</code> with APIs
that closely follow PyTorch to simplify building more complex models.</p>
</li>
<li>
<p dir="auto"><strong>Composable function transformations</strong>: MLX has composable function
transformations for automatic differentiation, automatic vectorization,
and computation graph optimization.</p>
</li>
<li>
<p dir="auto"><strong>Lazy computation</strong>: Computations in MLX are lazy. Arrays are only
materialized when needed.</p>
</li>
<li>
<p dir="auto"><strong>Dynamic graph construction</strong>: Computation graphs in MLX are built
dynamically. Changing the shapes of function arguments does not trigger
slow compilations, and debugging is simple and intuitive.</p>
</li>
<li>
<p dir="auto"><strong>Multi-device</strong>: Operations can run on any of the supported devices
(currently, the CPU and GPU).</p>
</li>
<li>
<p dir="auto"><strong>Unified memory</strong>: A notable difference from MLX and other frameworks
is the <em>unified memory model</em>. Arrays in MLX live in shared memory.
Operations on MLX arrays can be performed on any of the supported
device types without moving data.</p>
</li>
</ul>
<p dir="auto">MLX is designed by machine learning researchers for machine learning
researchers. The framework is intended to be user-friendly, but still efficient
to train and deploy models. The design of the framework itself is also
conceptually simple. We intend to make it easy for researchers to extend and
improve MLX with the goal of quickly exploring new ideas.</p>
<p dir="auto">The design of MLX is inspired by frameworks like
<a href="https://numpy.org/doc/stable/index.html" rel="nofollow">NumPy</a>,
<a href="https://pytorch.org/" rel="nofollow">PyTorch</a>, <a href="https://github.com/google/jax">Jax</a>, and
<a href="https://arrayfire.org/" rel="nofollow">ArrayFire</a>.</p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">The <a href="https://github.com/ml-explore/mlx-examples">MLX examples repo</a> has a
variety of examples, including:</p>
<ul dir="auto">
<li><a href="https://github.com/ml-explore/mlx-examples/tree/main/transformer_lm">Transformer language model</a> training.</li>
<li>Large-scale text generation with
<a href="https://github.com/ml-explore/mlx-examples/tree/main/llama">LLaMA</a> and
finetuning with <a href="https://github.com/ml-explore/mlx-examples/tree/main/lora">LoRA</a>.</li>
<li>Generating images with <a href="https://github.com/ml-explore/mlx-examples/tree/main/stable_diffusion">Stable Diffusion</a>.</li>
<li>Speech recognition with <a href="https://github.com/ml-explore/mlx-examples/tree/main/whisper">OpenAI's Whisper</a>.</li>
</ul>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">See the <a href="https://ml-explore.github.io/mlx/build/html/quick_start.html" rel="nofollow">quick start
guide</a>
in the documentation.</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">MLX is available on <a href="https://pypi.org/project/mlx/" rel="nofollow">PyPi</a>. To install the Python API, run:</p>

<p dir="auto">Checkout the
<a href="https://ml-explore.github.io/mlx/build/html/install.html#" rel="nofollow">documentation</a>
for more information on building the C++ and Python APIs from source.</p>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">Check out the <a href="https://github.com/ml-explore/mlx/blob/main/CONTRIBUTING.md">contribution guidelines</a> for more information
on contributing to MLX.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does uBlock Origin bypass the latest YouTube anti-adblock script? (140 pts)]]></title>
            <link>https://drhyperion451.github.io/does-uBO-bypass-yt/</link>
            <guid>38538236</guid>
            <pubDate>Tue, 05 Dec 2023 23:11:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drhyperion451.github.io/does-uBO-bypass-yt/">https://drhyperion451.github.io/does-uBO-bypass-yt/</a>, See on <a href="https://news.ycombinator.com/item?id=38538236">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-detector">
        <p><span id="main-question">Does uBlock Origin (uBO) bypass the latest YouTube anti-adblock script?</span></p>
        <p><span id="main-answer">Not sure</span>
        </p>
        
         
    </div><div id="about">
        <!-- class ="aa-blocked" -> Activated when the website response is 'yes'-->
        <!-- class ="not-aa-blocked" -> Activated when the website response is 'no'-->
        <h2>What does it mean?</h2>
        <p>We are currently evaluating if uBlock Origin's filters have been updated to deal with the latest Anti-Adblocker script. This website doesn't check your device. It simply compares text files provided by the uBO team to let you know the current status of uBO's solutions for YouTube.</p>
        
        
            
            
            
        <h2>What should I do now?</h2>
        <p>Please come back later.</p>
                        
        <!--Button to auto-update quick filters.-->
        
        

        <h2>What does this website do?</h2>
        <p>It simply gets the info of the latest <a href="https://raw.githubusercontent.com/stephenhawk8054/misc/main/yt-fix.txt">YT script ID solved by uBlock Origin</a> and compares it against the latest <a href="https://pastefy.app/G1Txv5su/raw">YouTube Anti-Adblocker script ID</a>.
            If it's the same, then the uBlock Origin team has finally updated their filters. If it's not, a fix is on the way. This website does not check if your own uBlock Origin version is up-to-date.</p>

        <h2>How can I contribute to this website?</h2>
        <p>You can make changes and pull request to the <a href="https://github.com/drHyperion451/does-uBO-bypass-yt/tree/dev"><code>dev</code></a> branch.</p>
        <p>Please keep in mind we are all volunteers. We don't get any revenue from this and we cannot be online 24/7. Thanks for understanding!</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playstation is erasing 1,318 seasons of Discovery shows from customer libraries (174 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/12/playstation-is-erasing-1318-seasons-of-discovery-shows-from-customer-libraries/</link>
            <guid>38538162</guid>
            <pubDate>Tue, 05 Dec 2023 23:01:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/12/playstation-is-erasing-1318-seasons-of-discovery-shows-from-customer-libraries/">https://arstechnica.com/gadgets/2023/12/playstation-is-erasing-1318-seasons-of-discovery-shows-from-customer-libraries/</a>, See on <a href="https://news.ycombinator.com/item?id=38538162">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      No refunds mentioned    —
</h4>
            
            <h2 itemprop="description">The change comes as Warner Bros. tries to add subscribers to Max, Discovery+ apps.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/mythbusters-800x447.jpg" alt="mythbusters">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/mythbusters.jpg" data-height="1073" data-width="1920">Enlarge</a> <span>/</span> Myth: You own the digital content you buy.</p></figcaption>  </figure>

  




<!-- cache hit 419:single/related:d9041d325cf5f210d63753721da064aa --><!-- empty -->
<p>If you purchased any Discovery shows from the PlayStation Store, Sony has some bad news for you to discover.</p>
<p>The company recently announced that all Discovery content purchased on the PlayStation Store will be erased before 2024. The brief <a href="https://www.playstation.com/en-us/legal/psvideocontent/">notice</a>, signed by the PlayStation Store, says:</p>
<blockquote><p>As of 31 December 2023, due to our content licensing arrangements with content providers, you will no longer be able to watch any of your previously purchased Discovery content and the content will be removed from your video library.</p>
<p>We sincerely thank you for your continued support.</p></blockquote>
<p>PlayStation Network started selling TV shows and movies with 2008's PlayStation 3, and at the time you were allowed to transfer content to different Sony devices, <a href="https://kotaku.com/sony-ps4-ps5-discovery-mythbusters-tv-1851066164">Kotaku</a> noted. That feature went away with the PlayStation 4. With the growth of <a href="https://arstechnica.com/culture/2023/08/the-tv-streaming-apps-broke-their-promises-and-now-theyre-jacking-the-price/">streaming TV apps</a>, many of which could be accessed through a PlayStation, the PlayStation Store <a href="https://blog.playstation.com/2021/03/02/playstation-store-to-discontinue-movie-and-tv-purchases-and-rentals/">stopped selling</a> movies and TV shows in 2021.</p>
<p>But there were users who had already purchased stuff from the PlayStation Store and, believe it or not, expect to be able to watch it when they want, since they paid money to buy (rather than rent) it. I admit that I haven't heard a lot of the shows being deleted post-purchase. Shows getting axed from user libraries include <em>Wives With Knives</em>,<em> An Idiot Abroad</em>,<em> Evil Twins</em>, and <i>Body Bizarre</i>. And when it came to deadly docuseries, PlayStation Store offered plenty, whether you were after<em> Deadly Affairs</em>,<em> Demands</em>,<em> Dentists</em>,<em> Devotion</em>,<em> Sins</em>, or, of course, <em>Women</em>.</p>
<p>I'm having fun with some of the most bizarre titles, of course. But there are also plenty of more well-known titles on the list of purchased content being revoked, including <em>American Chopper</em>, <em>Cake Boss</em>,<em> MythBusters</em>, <em>Shark Week</em>, and <em>Say Yes to the Dress.&nbsp;</em></p>
<p>While some of the content listed sounds, shall we say, a bit niche, there are in total 1,318 seasons of shows listed for deletion. That means there's a good chance numerous users will be affected by Sony's announcement.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/gadgets/2023/12/playstation-is-erasing-1318-seasons-of-discovery-shows-from-customer-libraries/2/">2</a> <a href="https://arstechnica.com/gadgets/2023/12/playstation-is-erasing-1318-seasons-of-discovery-shows-from-customer-libraries/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All my favorite tracing tools (126 pts)]]></title>
            <link>https://thume.ca/2023/12/02/tracing-methods/</link>
            <guid>38538111</guid>
            <pubDate>Tue, 05 Dec 2023 22:56:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thume.ca/2023/12/02/tracing-methods/">https://thume.ca/2023/12/02/tracing-methods/</a>, See on <a href="https://news.ycombinator.com/item?id=38538111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>Ever wanted more different ways to understand what’s going on in a program? Here I catalogue a huge variety of tracing methods you can use for varying types of problems. Tracing has been such a long-standing interest (and job) of mine that some of these will novel and interesting to anyone who reads this. I’ll guarantee it by including 2 novel tracing tools I’ve made and haven’t shared before (look for this: <span><em>Tooling drop!</em></span>).</p>
<p>What I see as the key parts of tracing are collecting timestamped data on what happened in a system, and then ideally visualizing it in a timeline UI instead of just as a text log. First I’ll cover my favorite ways of really easily getting trace data into a nice timeline UI, because it’s a superpower that makes all the other tracing tools more interesting. Then I’ll go over ways to get that data, everything from instrumentation to binary patching to processor hardware features.</p>
<p>I’ll also give a real-life example of combining eBPF tracing with Perfetto visualization to diagnose tail latency issues in huge traces by using a number of neat tricks. Look for the “eBPF Example” section.</p>
<p><strong>Note:</strong> I’m hiring for my accelerator optimization team at Anthropic! See <a href="#conclusion-if-you-liked-this-you-may-like-my-team-at-anthropic">the bottom of the post</a> for more detail.</p>
<h2 id="easily-visualizing-data-on-a-trace-timeline">Easily visualizing data on a trace timeline</h2>
<p>Getting event data onto a nice zoomable timeline UI is way easier than most people think. Here’s my favorite method I do all the time which can take you from logging your data to visualizing it in minutes:</p>
<div><pre><code><span># from:
</span><span>print</span><span>(</span><span>"%d: %s %d"</span> <span>%</span> <span>(</span><span>event_name</span><span>,</span> <span>timestamp</span><span>,</span> <span>duration</span><span>))</span>
<span># to:
</span><span>with</span> <span>open</span><span>(</span><span>'trace.json'</span><span>,</span><span>'w'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
  <span>f</span><span>.</span><span>print</span><span>(</span><span>"["</span><span>)</span>
  <span>f</span><span>.</span><span>print</span><span>(</span><span>'{"name": "%s", "ts": %d, "dur": %d, "cat": "hi", "ph": "X", "pid": 1, "tid": 1, "args": {}}</span><span>\n</span><span>'</span> <span>%</span>
    <span>(</span><span>event_name</span><span>,</span> <span>timestamp</span><span>,</span> <span>duration</span><span>))</span>
  <span>f</span><span>.</span><span>print</span><span>(</span><span>"]"</span><span>)</span> <span># this closing ] isn't actually required
</span></code></pre></div>
<p>This is the power of the <a href="https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/preview">Chromium Event JSON Format</a>. It’s a super simple JSON format that supports a bunch of different kinds of events, and is supported by a lot of different profile visualizer tools.</p>
<p>You can view the resulting tracing files in Google’s Perfetto trace viewer by going to <a href="https://ui.perfetto.dev/">https://ui.perfetto.dev/</a>, or in the older Catapult viewer (which is nicer for some traces) by going to <code>chrome://tracing</code> in Chrome. You can play around with the UI by <a href="https://ui.perfetto.dev/">going to Perfetto</a> and clicking “Open Chrome Example” in the sidebar. Here’s a screenshot showing an event annotated with arguments and flow event arrows:</p>
<p><a href="https://thume.ca/assets/postassets/tracing/perfetto.png"><img src="https://thume.ca/assets/postassets/tracing/perfetto.png" alt="Perfetto Screenshot"></a></p>
<p>Me and my coworkers do this all the time at work, whip up trace visualizations for new data sources in under an hour and add them to our growing set of trace tools. We have a Python utility to turn a trace file into a clickable permanently-saved intranet link we can share with coworkers in Slack. This is easy to set up by building a copy of Perfetto and uploading to a file hosting server you control, and then putting trace files on that server and generating links using Perfetto’s <code>?url=</code> parameter. We also write custom trace analysis scripts by loading the simple JSON into a Pandas dataframe.</p>
<p>I like Perfetto as its use of WebAssembly lets it scale to about 10x more events than Catapult (although it gets laggy), and you have the escape hatch of the native backend for even bigger traces. Its <a href="https://perfetto.dev/docs/analysis/common-queries">SQL query feature</a> also lets you find events and annotate them in the UI using arbitrary predicates, including <a href="https://perfetto.dev/docs/analysis/stdlib-docs">special SQL functions</a> for dealing with trace stacks.</p>
<p><strong>UI protip</strong>: Press <code>?</code> in Perfetto to see the shortcuts. I use both <code>WASD</code> and <code>CTRL+scroll</code> to move around.</p>
<h3 id="advanced-format-fuchsia-trace-format">Advanced Format: Fuchsia Trace Format</h3>
<p>The Chromium JSON format can produce gigantic files and be very slow for large traces, because it repeats both the field names and string values for every event. Perfetto also supports the <a href="https://fuchsia.dev/fuchsia-src/reference/tracing/trace-format">Fuchsia Trace Format (FTF)</a> which is a simple compact binary format with an incredible spec doc that makes it easy to produce binary traces. It supports interning strings to avoid repeating event names, and is designed around 64 byte words and supports clock bases so that you can directly write timestamp counters and have the UI compute the true time.</p>
<p>When I worked at Jane Street I <a href="https://github.com/janestreet/tracing/blob/master/zero/writer.ml">used this to log instrumentation events to a buffer directly in FTF</a> as they occurred in &lt;10ns per span (it would have been closer to 4ns if it wasn’t for OCaml limitations).</p>
<h3 id="advanced-format-perfetto-protobuf">Advanced Format: Perfetto Protobuf</h3>
<p>Another format which is similarly compact, and also supports more features, is <a href="https://github.com/google/perfetto/blob/master/protos/perfetto/trace/perfetto_trace.proto">Perfetto’s native Protobuf trace format</a>. It’s documented only in comments in the proto files and is a bit trickier to figure out, but might be a bit easier to generate if you have access to a protobuf library. It enables access to advanced Perfetto features like including callstack samples in a trace, which aren’t available with other formats. It’s slower to write than FTF, although Perfetto has a <a href="https://perfetto.dev/docs/design-docs/protozero">ProtoZero</a> library to make it somewhat faster.</p>
<p>This can be really tricky to get right though and I had to reference the Perfetto source code to figure out error codes in the “info and stats” tab a lot. The biggest gotchas are you need to set <code>trusted_packet_sequence_id</code> on every packet, have a <code>TrackDescriptor</code> for every track, and set <code>sequence_flags=SEQ_INCREMENTAl_STATE_CLEARED</code> on the first packet.</p>
<h3 id="other-tools">Other tools</h3>
<p>Some other nice trace visualization tools are <a href="https://github.com/jlfwong/speedscope">Speedscope</a> which is better for a hybrid between profile and trace visualization, <a href="https://github.com/google/pprof">pprof</a> for pure profile call graph visualization, and <a href="https://www.rerun.io/">Rerun</a> for multimodal 3D visualization. Other profile viewers I like less but which have some nice parts include <a href="https://eclipse.dev/tracecompass/">Trace Compass</a> and the <a href="https://profiler.firefox.com/docs/#/">Firefox Profiler</a>.</p>
<h2 id="tracing-methods">Tracing Methods</h2>
<p>Now lets go over all sorts of different neat tracing methods! I’ll start with some obscure and interesting low level ones but I promise I’ll get to some more broadly usable ones after.</p>
<h2 id="hardware-breakpoints">Hardware breakpoints</h2>
<p>For ages, processors have supported <strong>hardware breakpoint registers</strong> which let you put in a small number of memory addresses and have the processor interrupt itself when any of them are accessed or executed.</p>
<h3 id="perf-and-perftrace">perf and perftrace</h3>
<p>Linux exposes this functionality through <code>ptrace</code> but also through the <a href="https://man7.org/linux/man-pages/man2/perf_event_open.2.html"><code>perf_event_open</code> syscall</a> and the <a href="https://man7.org/linux/man-pages/man1/perf-record.1.html"><code>perf record</code> command</a>. You can record a process like <code>perf record -e \mem:0x1000/8:rwx my_command</code> and view the results with <code>perf script</code>. It costs about 3us of overhead every time a breakpoint is hit.</p>
<p><span><em>Tooling drop!</em></span> I wrote <a href="https://github.com/trishume/perftrace">a tiny Python library called perftrace</a> with a C stub which calls the <code>perf_event_open</code> syscall to record timestamps and register values when the breakpoints were hit.</p>
<p>It currently only supports execution breakpoints but you can also breakpoint on reads or writes of any memory and it would be <a href="https://github.com/trishume/perftrace/blob/d074e65bf71e8af10335164111969f96263d283a/perftrace.c#L61">easy to modify the code to do that</a>. Hardware breakpoints are basically the only way to watch for accessing a specific memory address at a fine granularity which doesn’t add overhead to code which doesn’t touch that memory.</p>
<h3 id="gdb-scripting">GDB scripting</h3>
<p>In addition to using it manually, you can automate the process of following the execution of a program using debugger breakpoints by using GDB’s Python scripting interface. This is slower than perf breakpoints but gives you the ability to inspect and modify memory when you hit breakpoints. <a href="https://github.com/hugsy/gef">GEF</a> is an extension to GDB that in addition to making it much nicer in general, also extends the Python API with a bunch of handy utilities.</p>
<p><span><em>Tooling drop!</em></span> <a href="https://gist.github.com/trishume/fe3b3b90a7e524c976ecb98053bb7f86">Here’s an example GDB script I wrote using GEF which gives examples of how to puppeteer, trace and inspect a program</a></p>
<h2 id="intel-processor-trace">Intel Processor Trace</h2>
<p><a href="https://easyperf.net/blog/2019/08/23/Intel-Processor-Trace">Intel Processor Trace</a> is a hardware technology on Intel chips since Skylake which allows recording a trace of <em>every instruction the processor executes</em> via recording enough info to reconstruct the control flow in a super-compact format, along with fine-grained timing info. It has extremely low overhead since it’s done by hardware and writes bypass the cache so the only overhead is reducing main memory bandwidth by about 1GB/s. I see no noticeable overhead at all on most program benchmarks I’ve tested.</p>
<p>You can access a dump of the assembly instructions executed in a recorded region using <a href="https://man7.org/linux/man-pages/man1/perf-intel-pt.1.html"><code>perf</code></a>, <a href="https://lldb.llvm.org/use/intel_pt.html"><code>lldb</code></a> and <a href="https://easyperf.net/blog/2019/08/30/Intel-PT-part2"><code>gdb</code></a>.</p>
<h3 id="magic-trace">magic-trace</h3>
<p>However assembly traces aren’t useful to most people, so when at Jane Street I created <a href="https://github.com/janestreet/magic-trace">magic-trace</a> along with my intern Chris Lambert, which generates a trace file (using FTF and Perfetto as described above) which visualizes <em>every function call</em> in a program execution. Jane Street generously open-sourced it so anyone can use it! Since then it’s been extended to support tracing into the kernel as well. I wrote <a href="https://blog.janestreet.com/magic-trace/">a blog post about how it works for the Jane Street tech blog</a>.</p>
<p><img src="https://github.com/janestreet/magic-trace/raw/master/docs/assets/stage-3.gif" alt="magic-trace demo"></p>
<p>Processor Trace can record to a ring buffer, and <code>magic-trace</code> uses the hardware breakpoint feature described earlier to let you trigger capture of the last 10ms whenever some function that signals an event you want to look at happened, or when the program ends. This makes it great for a bunch of scenarios:</p>
<ul>
<li>Debugging rare tail latency events: Add a trigger function call after something takes unusually long, and then leave magic-trace attached in production. Because it captures everything you’ll never have not logged enough data to identify the slow part.</li>
<li>Everyday performance analysis: A full trace timeline can be easier to interpret than a sampling profiler visualization, especially because it displays the difference between a million fast calls to a function and one slow call.
<ul>
<li>It’s typical to find performance problems on systems that had only ever been analyzed with a sampling profiler by noticing the first time you magic-trace the program that many functions are being called more times than expected or in locations you didn’t expect.</li>
</ul>
</li>
<li>Debugging crashes: When a program crashes for reasons you don’t understand, you can just run it under magic-trace and see every function call leading up to the crash, which is often enough to figure out why the crash happened without adding extra logging or using a debugger!</li>
</ul>
<p>If you want to modify magic-trace to suit your needs, it’s open-source OCaml. And if you like Rust more than OCaml someone made a simple Rust port called <a href="https://github.com/michoecho/perf2perfetto">perf2perfetto</a>.</p>
<p>Unfortunately, Processor Trace isn’t supported on many virtual machines that use compatible Intel Hardware. Complain to your cloud provider to add support in their hypervisor or try bare-metal instances!</p>
<h2 id="instrumentation-based-tracing-profilers">Instrumentation-based tracing profilers</h2>
<p>What most people use to get similar benefits to magic-trace traces, especially in the gamedev industry, is low-overhead instrumentation-based profilers with custom UIs. One major advantage of instrumentation-based traces is they can contain extra information about data and not just control flow, putting arguments from your functions into the trace can be key for figuring out what’s going on. These tools often support including other data sources such as OS scheduling info, CPU samples and GPU trace data. Here’s my favorite tools like this and their pros/cons:</p>
<h3 id="tracy"><a href="https://github.com/wolfpld/tracy">Tracy</a></h3>
<p><a href="https://github.com/wolfpld/tracy"><img src="https://github.com/wolfpld/tracy/raw/master/doc/profiler.png" alt="Tracy screenshot"></a></p>
<ul>
<li>Cross platform, including good Linux sampling and scheduling capture</li>
<li>Overhead of only 2ns/span, supports giant traces with hundreds of millions of events</li>
<li>Really nice and fast UI with tons of features (check out the <a href="https://www.youtube.com/watch?v=30wpRpHTTag">demo</a> <a href="https://www.youtube.com/watch?v=_hU7vw00MZ4">videos</a> in the readme)</li>
<li>Integrates CPU sampling with detailed source and assembly analysis</li>
<li>Popular so there are bindings in non-C++ languages like <a href="https://docs.rs/tracing-tracy/latest/tracing_tracy/">Rust</a> and <a href="https://github.com/nektro/zig-tracy">Zig</a>.</li>
<li>Con: Only supports a single string/number argument to events</li>
<li>Con: Timeline is overly aggressive in collapsing small events into squiggles (<a href="https://thume.ca/2021/03/14/iforests/">see my post on this</a>).</li>
</ul>
<h3 id="optick"><a href="https://github.com/bombomby/optick">Optick</a></h3>
<p><a href="https://www.youtube.com/watch?v=p57TV5342fo"><img src="https://github.com/bombomby/brofiler/raw/gh-pages/images/VideoThumbnail.jpg" alt="Optick screenshot"></a></p>
<ul>
<li>Cross-platform, lots of features, very nice UI</li>
<li>Supports multiple named arguments per event</li>
<li>Con: Not as fleshed-out for non-game applications</li>
<li>Con: sampling integration only works on Windows</li>
</ul>
<h3 id="perfetto"><a href="https://perfetto.dev/docs/instrumentation/tracing-sdk">Perfetto</a></h3>
<ul>
<li>Perfetto UI is nice, events can include arguments and flow event arrows</li>
<li>Integrates with other Perfetto data sources like OS events and sampling</li>
<li>Con: Higher overhead of around 600ns/span when tracing enabled</li>
<li>Con: UI doesn’t scale to traces as large as the above two programs</li>
</ul>
<h3 id="other-programs">Other programs</h3>
<p>There’s a bunch more similar small programs that generally come with their own instrumentation library and their own WebGL profile viewer. These are generally more lightweight and can be easier to integrate. For example <a href="https://gravitymoth.com/spall/spall-web.html">Spall</a>, <a href="https://github.com/jonasmr/microprofile">microprofile</a>, <a href="https://github.com/Celtoys/Remotery">Remotery</a>, <a href="https://github.com/EmbarkStudios/puffin">Puffin (Rust-native)</a>, <a href="https://github.com/mikesart/gpuvis">gpuviz</a>. I must also mention the <a href="https://github.com/janestreet/tracing">OCaml tracing instrumentation library I wrote for Jane Street</a> which has overheads under 10ns/span via a compile-time macro like the C++ libraries.</p>
<h2 id="ebpf">eBPF</h2>
<p>If you want to trace things using the Linux kernel there’s a new game in town, and it’s awesome. The eBPF subsystem allows you to attach complex programs to all sorts of different things in the kernel and efficiently shuttle data back to userspace, basically subsuming all the legacy facilities like ftrace and kprobes such that I won’t talk about them.</p>
<p>Things you can trace include: syscalls, low overhead tracepoints throughout the kernel, hardware performance counters, any kernel function call and arbitrary breakpoints or function calls/returns in userspace code. Combined these basically let you see anything on the system in or out of userspace.</p>
<p>You normally write BPF programs in C but there are perhaps even nicer toolkits for using <a href="https://github.com/tw4452852/zbpf">Zig</a> and <a href="https://aya-rs.dev/">Rust</a>.</p>
<p>There’s <a href="https://ebpf.io/applications/">a whole bunch of ways to use eBPF</a> and I’ll talk about some of my favorites here. Some other favorites I won’t go into in detail are <a href="https://rubrikinc.github.io/wachy/">Wachy</a> and <a href="https://github.com/anakryiko/retsnoop">retsnoop</a>.</p>
<h3 id="bcc-easy-python-api-for-ebpf">BCC: Easy Python API for eBPF</h3>
<p>The <a href="https://github.com/iovisor/bcc">BPF Compiler Collection (BCC)</a> is a library with really nice Python bindings for compiling eBPF programs from C source code, injecting them, and getting the data back. It has a really nice feature where you can write a C struct to hold the event data you want to record, and then it will parse that and expose it so you can access the fields in Python. Check out <a href="https://github.com/iovisor/bcc/blob/master/examples/ringbuf/ringbuf_output.py">how simple this syscall tracing example is</a>.</p>
<p>I really like having the full power of Python to control my tracing scripts. BCC scripts often use Python string templating to do compile time metaprogramming of the C to compose the exact probe script you want, and then do data post-processing in Python to present things nicely.</p>
<h3 id="bpftrace-terse-dsl-for-ebpf-tracing">bpftrace: terse DSL for eBPF tracing</h3>
<p>If you want a terser way to compose tracing programs, in the style of dtrace, check out <a href="https://github.com/iovisor/bpftrace">bpftrace</a>. It lets you write one liners like these:</p>
<div><pre><code><span># Files opened by process</span>
bpftrace <span>-e</span> <span>'tracepoint:syscalls:sys_enter_open { printf("%s %s\n", comm, str(args-&gt;filename)); }'</span>

<span># Count LLC cache misses by process name and PID (uses PMCs):</span>
bpftrace <span>-e</span> <span>'hardware:cache-misses:1000000 { @[comm, pid] = count(); }'</span>
</code></pre></div>
<h3 id="ply-simpler-bpftrace">ply: simpler bpftrace</h3>
<p>If you want something like bpftrace but simpler and faster with no LLVM dependencies. Check out <a href="https://wkz.github.io/ply/">ply</a>.</p>
<div><pre><code><span># Which processes are receiving errors when reading from the VFS?</span>
ply <span>'kretprobe:vfs_read if (retval &lt; 0) { @[pid, comm, retval] = count(); }'</span>
</code></pre></div>
<h2 id="ebpf-example-anthropics-perfetto-based-packet-and-user-event-tracing">eBPF Example: Anthropic’s Perfetto-based packet and user event tracing</h2>
<p>For work at Anthropic I wanted to analyze tail latency of some networking code so I used BCC and hooked into low-overhead kernel probe points to trace info from every single packet into a ring buffer. I could even include fields pulled from the packet header and NIC queue information, all at 1 million packets per second with no noticeable overhead.</p>
<h3 id="trick-for-tracing-userspace-events-with-low-overhead-in-ebpf">Trick for tracing userspace events with low overhead in eBPF</h3>
<p>I wanted to correlate packets with userspace events from a Python program, so I used a fun trick: Find a syscall which has an early-exit error path and bindings in most languages, and then trace calls to that which have specific arguments which produce an error. I traced the <code>faccessat2</code> syscall such that in Python <code>os.access(event_name, -932, dir_fd=-event_type)</code> where <code>event_type</code> was an enum for start, stop and instant events would log spans to my Perfetto trace. This had an overhead of around 700ns/event, which is in a similar league to Perfetto’s full-userspace C++ instrumentation, and a lot of that is Python call overhead. The <code>os.access</code> function is especially good because when the syscall errors it doesn’t incur overhead by generating a Python exception like most other syscall wrappers do.</p>
<h3 id="how-to-process-events-more-quickly-using-a-c-helper-with-bcc">How to process events more quickly using a C helper with BCC</h3>
<p>With 1 million packets per second I had a problem that with rare tail latency events, my traces quickly got huge and lagged Perfetto. I wanted to only keep data from shortly before one of my userspace send events took too long. Normally you’d do this with a circular buffer that gets snapshotted, and it would be possible to implement that in eBPF. But I didn’t want to implement my own ringbuf and the included ones don’t support wraparound overwriting. So instead I used the internal <code>_open_ring_buffer</code> function to register a ctypes C function as a ringbuffer callback instead of a Python function, and wrote an efficient C callback to filter out packets near a tail latency event before passing those to Python.</p>
<h3 id="perks-of-perfetto-visualization">Perks of Perfetto visualization</h3>
<p>I used the Perfetto Protobuf format with interned strings in order to keep trace size down to a few bytes per packet.</p>
<p>I could use Perfetto’s SQL support in the resulting trace to query for send events above a certain time threshold after startup in a specific process. Here’s a screenshot showing a long send event coinciding with packets starting to be paced out with larger gaps on one of the queues, including the ability to have line graph tracks:</p>
<p><a href="https://thume.ca/assets/postassets/tracing/packettrace.png"><img src="https://thume.ca/assets/postassets/tracing/packettrace.png" alt="Perfetto Packet Trace"></a></p>
<p>I think it’s kinda crazy that we have all these different mostly-text-based BPF tools rather than a framework that lets you put all sorts of different kinds of system events into a trace UI, including easily scripting your own new events. It’s so much easier to investigate this kind of thing with a timeline UI. I started building that framework at Anthropic, but only spent a week on it since I’ve had higher priority things to do since I did the packet latency investigation.</p>
<h2 id="binary-instrumentation">Binary Instrumentation</h2>
<p>When you’re instrumenting userspace programs in a way where the overhead of kernel breakpoints is too high, but you don’t have access to the source code, perhaps because you’re reverse-engineering something, then it may be time for binary instrumentation.</p>
<h3 id="bpftime-ebpf-based-binary-instrumentation">bpftime: eBPF-based binary instrumentation</h3>
<p>One easy way that’s a good segue is <a href="https://github.com/eunomia-bpf/bpftime">bpftime</a> which takes your existing eBPF programs with userspace probes, and runs them much faster by patching the instructions to run the BPF program inside the process rather than incurring 3us of kernel interrupt overhead every time.</p>
<h3 id="e9patch">E9Patch</h3>
<p>For more sophisticated binary patching on x86, look to <a href="https://github.com/GJDuck/e9patch">E9Patch</a>.</p>
<p>On some architectures, patching can be really easy since you just patch the instruction you want to trace with a jump to a piece of “trampoline” code which has your instrumentation, and then the original instruction and a jump back.</p>
<p>It’s much harder on x86 since instructions are variable length, so if you just patch a jump over a target instruction, occasionally that’ll cause problems since some other instruction jumps to an instruction your longer jump had to stomp over.</p>
<p>People have invented all kinds of clever tricks to get around these issues including “instruction punning” where you put your patch code at addresses which are also valid x86 nop or trap instructions. E9Patch implements very advanced versions of these tricks such that the patching should basically always work.</p>
<p>It comes with an API as well as a tool called <a href="https://github.com/GJDuck/e9patch/blob/master/doc/e9tool-user-guide.md">E9Tool</a> which lets you patch using a command line interface:</p>
<div><pre><code><span># print all jump instructions in the xterm binary</span>
<span>$ </span>e9tool <span>-M</span> jmp <span>-P</span> print xterm
jz 0x4064d5
jz 0x452c36
...
</code></pre></div>
<h3 id="frida">Frida</h3>
<p>The other way to get around the difficulty of static patching, when you have to be conservative around how jumps you don’t know about could be messed up by your patches, is dynamic binary instrumentation, where you basically puppeteer the execution of the program. This is the technique used by JIT VMs like Rosetta and QEMU to basically recompile your program as you run it.</p>
<p><a href="https://frida.re/">Frida</a> exposes this incredibly powerful technique in a general way you can script in Javascript using its “Stalker” interface. Allowing you to attach JS snippets to pieces of code or rewrite the assembly as it is run. It also lets you do more standard patching, although it doesn’t work as well on x86 as E9Patch.</p>
<h2 id="ld_preload">LD_PRELOAD</h2>
<p>If you just want to trace a function in a dynamic library like libc, you can use <code>LD_PRELOAD</code> to inject a library of your own to replace any functions you like. You can use <code>dlsym(RTLD_NEXT, "fn_name")</code> to get the old implementation in order to wrap it. Check out <a href="https://axcheron.github.io/playing-with-ld_preload/">this tutorial post</a> for how.</p>
<h2 id="distributed-tracing">Distributed Tracing</h2>
<p>Distributed Tracing is where you can trace across different services via attaching special headers to requests and sending all the timing data back to a trace server. Some popular solutions are <a href="https://opentelemetry.io/">OpenTelemetry</a> (of which there are many implementations and UIs) and <a href="https://zipkin.io/">Zipkin</a>.</p>
<p>There’s some cool new solutions like <a href="https://odigos.io/">Odigos</a> that use eBPF to add distributed tracing support without any instrumentation.</p>
<h2 id="sampling-profilers">Sampling Profilers</h2>
<p>Sampling profilers take a sample of the full call stack of your program periodically. Typical profiler UIs don’t have the time axis I’d think of as part of “tracing”, but some UIs do. For example <a href="https://github.com/jlfwong/speedscope">Speedscope</a> accepts many profiler data formats and can visualize with a time axis, and <a href="https://github.com/mstange/samply">Samply</a> is an easy to use profiler which uses the Firefox Profiler UI, which also has a timeline view.</p>
<p>One neat sampling method used by <a href="https://github.com/benfred/py-spy">py-spy</a> and <a href="https://rbspy.github.io/">rbspy</a> is to use the <a href="https://man7.org/linux/man-pages/man2/process_vm_readv.2.html"><code>process_vm_readv</code> syscall</a> to read memory out of a process without interrupting it. If like an interpreter the process stores info about what it’s doing in memory, this can allow you to follow it with no overhead on the target process. You could even use this trick for low-overhead native program instrumentation: set up a little stack data structure where you push and pop pointers to span names or other context info, and then sample it from another program when needed using eBPF or <code>process_vm_readv</code>.</p>
<h2 id="qemu-instrumentation">QEMU Instrumentation</h2>
<p>When all other tracing tools fail, sometimes you have to fall back on the most powerful tool in the tracing toolbox: Full emulation and hooking into QEMU’s JIT compiler. This theoretically allows you to trace and patch both control flow <em>and</em> memory, in both userspace and the kernel, including snapshot and restore, across many architectures and operating systems.</p>
<p>However, actually doing this is not for the faint of heart and the tooling for it only barely exists.</p>
<h3 id="cannoli">Cannoli</h3>
<p><a href="https://github.com/MarginResearch/cannoli">Cannoli</a> is a tracing engine for qemu-user (so no kernel stuff) which patches QEMU to log execution and memory events to a high-performance ringbuffer read by a Rust extension you compile. This lets it trace with very low overhead by spreading the load of following the trace over many cores, at the cost of not being able to modify the execution.</p>
<p>It’s a bit tricky to use, you have to compile QEMU and Cannoli yourself at the moment, and it’s kind of a prototype so when I’ve used it in the past for CTFs I’ve often had to add new features to it.</p>
<h3 id="qemu-tcg-plugins">QEMU TCG Plugins</h3>
<p>QEMU has recently added <a href="https://www.qemu.org/docs/master/devel/tcg-plugins.html">plugin support for its TCG JIT</a>. Like Cannoli this is read-only for now, and its likely slower than Cannoli, but it works in qemu-system mode and exposes slightly different functionality.</p>
<h3 id="usercorn">usercorn</h3>
<p>My friend has an old project called <a href="https://github.com/lunixbochs/usercorn">usercorn</a> that is mostly bitrotted but has the ability to trace programs using QEMU and analyze them with Lua scripts and all sorts of fancy trace analysis. Someone (possibly him eventually) could theoretically revive it and rebase it on top of something like QEMU TCG plugins.</p>
<h2 id="conclusion-if-you-liked-this-you-may-like-my-team-at-anthropic">Conclusion: If you liked this you may like my team at Anthropic</h2>
<p>If you made it to the bottom and enjoyed all those different tracing strategies, you may also be interested in working on my team!</p>
<p>I lead the performance optimization team at <a href="https://www.anthropic.com/">Anthropic</a> (we build one of the world’s leading large language models, and have a heavy focus on figuring out how future more powerful models can go well for the world). We’ll be doing accelerator kernel optimization across GPUs, TPUs and Trainium. TPUs and Trainium are cool in that they’re simpler architectures where optimization is more like a cycle-counting puzzle, and they also have <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/tools/neuron-sys-tools/neuron-profile-user-guide.html">amazing tracing tools</a>. Almost nobody knows these new architectures, so we’re currently hiring high potential people with other kinds of low-level optimization experience who are willing to learn.</p>
<p>I plan for us to do a bunch of optimization work as compiler-style transformation passes over IRs, but simpler via being bespoke to the ML architecture we’re optimizing. These will parallelize architectures across machines, within a machine, and within a chip in similar ways. We also work closely with an amazing ML research team to do experiments together and come up with architectures that jointly optimize for ML and hardware performance.</p>
<p>Anthropic recently received ~$6B in funding commitments, and are investing it heavily in compute. We currently have ~5 performance specialists, with each one making an immense contribution in helping us have models that exhibit interesting capabilities for our alignment researcher and policy teams.</p>
<p>AI now is still missing a lot, but progress is incredibly fast. It’s hard for me to say the coming decade of progress won’t lead to AI as good as us at nearly all jobs, which would be the biggest event in history. Anthropic is unusually full of people who joined because they really care about ensuring this goes well. I think we have the world’s best alignment, interpretability research, and AI policy teams, and I personally work on performance optimization here because I think it’s the best way to leverage my comparative advantage to help the rest of our efforts succeed at steering towards AI going well for the world in the event it keeps up this pace.</p>
<p>If you too would like to do fun low-level optimization on what I think will be the most important technology of this decade and want to chat: Email me at <a href="https://thume.ca/cdn-cgi/l/email-protection" data-cfemail="394d4b504a4d58577958574d514b5649505a175a5654">[email&nbsp;protected]</a> with a link or paragraph about the most impressive low-level or performance thing you’ve done. And feel free to check out some of
<a href="https://thume.ca/2023/01/02/one-machine-twitter/">my other</a> <a href="https://thume.ca/2021/03/14/iforests/">performance</a> <a href="https://thume.ca/2022/05/15/latency-testing-streaming/">writing</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Virtual Machine as a core Android Primitive (199 pts)]]></title>
            <link>https://android-developers.googleblog.com/2023/12/virtual-machines-as-core-android-primitive.html</link>
            <guid>38538100</guid>
            <pubDate>Tue, 05 Dec 2023 22:55:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://android-developers.googleblog.com/2023/12/virtual-machines-as-core-android-primitive.html">https://android-developers.googleblog.com/2023/12/virtual-machines-as-core-android-primitive.html</a>, See on <a href="https://news.ycombinator.com/item?id=38538100">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<meta name="twitter:image" content="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3K8ZNCgF96aUEngG-N-ilXHjMZv2WidIhseXT1JIua_Z8KiVapdoSViSky-4ChuQ1_hgs6ktkobMo0Jh1OLk4vejenA7mt1gjSi_VQqXr3gLeR8g3aCGForCLlTmZ9-4PQg0GL7Gn1w_F_OYGoUjvywqFf-3ZDe0LCETPDkZLkHjTn93MZ9Fwjkq05dI/s1600/social-Android-Virtualization-as-a-core-Android-Primitive.png">
<p>

<em>Posted by Sandeep Patil – Principal Software Engineer, and Irene Ang – Product Manager</em>

<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQUgLI8VNIOZk5Bf6wOTHe-4hrSSwlxck3cwoTbFYyy5uG219Ira8WsI8euGWfx20d3aNbWTGj5aCJX3XuQOdMZv6zS9PRI9HseNAoUwN42t4EjctfvbN_04Gk5vwZDaABvHToYMibcLBHrimTrEPWYbPGbE8hqOKuJoDRFBiezCClclCjLKrNhSOvdzA/s1600/Android-Virtualization-as-a-core-Android-Primitive.png" imageanchor="1"><img data-original-height="800" data-original-width="100%" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQUgLI8VNIOZk5Bf6wOTHe-4hrSSwlxck3cwoTbFYyy5uG219Ira8WsI8euGWfx20d3aNbWTGj5aCJX3XuQOdMZv6zS9PRI9HseNAoUwN42t4EjctfvbN_04Gk5vwZDaABvHToYMibcLBHrimTrEPWYbPGbE8hqOKuJoDRFBiezCClclCjLKrNhSOvdzA/s1600/Android-Virtualization-as-a-core-Android-Primitive.png"></a></p><p>The <b>Android Virtualization Framework (AVF)</b> will be available on upcoming select Android 14 devices. The AVF, first introduced in Android 13 on Pixel devices, provides new capabilities for platform developers working on privileged applications. </p>


<p>With AVF, we are more broadly supporting virtualization to Android. Virtualization is widely used and deployed to isolate workloads and operating systems from each other. It enables efficient scaling of infrastructure, testing environments, legacy software compatibility, creating virtual desktops and much more.</p>

<p>With AVF virtual machines become a core construct of the Android operating system, similar to the way Android utilizes Linux processes. Developers have the flexibility to choose the level of isolation for a virtual machine:</p>
<ul><ul>
<li><b>One-way isolation:</b> Android (the host) can control and inspect the contents of the VM. These are most commonly used for sandboxing and separation, enabling multiple operating systems to run on the same machine / device, with one operating system host (Android) controlling and watching over all others.</li></ul></ul><ul><ul>


<li><b>Two-way isolation (Isolated VM):</b> Android (the host) and the virtual machine (the guest) are completely isolated from each other. Developers who deal with or store sensitive data may benefit  from an isolated virtual machine. An isolated virtual machine has a two-way barrier, where neither the host (Android) nor the VM have access to each other, except via explicitly-agreed-upon communication channels.  This has 2 main properties:</li></ul></ul><blockquote><blockquote><ol><li>The workload and data inside the VM is inaccessible (confidential) from the host (Android).</li><li>Even if Android is compromised all the way up to (and including) the host kernel, the isolated VM remains uncompromised.</li></ol></blockquote></blockquote>

<h3>Benefits of AVF</h3>
<h4><span>Isolation</span></h4> 
<p>With an isolated VM, developers now have an alternative to Trustzone for use cases that need isolation from Android without escalated privilege.</p>


<h4><span>Portability</span></h4>  
<p>Virtual machines and the applications running inside them are far more portable than trusted applets. For example, a Linux-based virtual machine with a Linux-application payload will work on all devices that support AVF. This means that developers can build an application once and deploy it everywhere. VMs also make porting of existing Linux based applications seamless and easy, compared to porting into a Trustzone operating system.</p>  

<h4><span>Performance</span></h4>
<p>AVF is designed to be lightweight, efficient and flexible. Virtual machines can:</p>
<ul><ul>
<li>be as small as a single C program and as big as an entire operating system depending on the developer’s need;</li>
<li>be persistent or intermittent;</li>
<li>grow in memory or shrink depending on the overall system health; and</li>
<li>honor Android’s scheduler hints and low-memory warnings.</li>
</ul></ul>

<h4><span>Extensibility</span></h4>
<p>AVF is designed with developers in mind. Virtual machines can be customized to meet specific use-case needs. Developers can deploy any VM payload as long as it conforms to certain boot and communication protocols specified by AVF. </p> 


<p>In addition to bringing the power of virtualization to Android and enabling all the possibilities of virtual desktops, sandboxing, AVF’s use of isolated virtual machines can benefit the following common Android use cases (and many more):</p>
<ul><ul>
  <li><b>Biometrics:</b> By deploying biometric trusted applets in an isolated virtual machine, developers will have the isolation guarantee, access to more compute power for biometric algorithms, easy updatability regardless of the Trustzone operating system, and a more streamlined deployment.</li></ul></ul><ul><ul>
  <li><b>DRM:</b> Widevine enables streaming DRM on Android devices. Once deployed in an isolated Virtual Machine, updates to Widevine become much easier across Android devices, regardless of the details of the various Trustzone operating systems being deployed on those devices.</li></ul></ul><ul><ul>
</ul></ul>

<h3>AVF Usage</h3>

<p>AVF provides easy <a href="https://cs.android.com/android/platform/superproject/main/+/main:packages/modules/Virtualization/javalib/README.md" target="_blank">APIs</a> to query the device’s ability to create virtual machines and their supported types, and to set up secure communication channels with these virtual machines from applications and services that create them.</p>

<p>For example, to check for the availability of the AVF APIs, and of isolated and regular VM:</p>

<div><pre><span>VirtualMachineManager manager <span>=</span>
     (VirtualMachineManager)context<span>.</span>
          getSystemService(VirtualMachineManager<span>.</span>class)<span>;</span>
<span>if</span> (manager <span>==</span> null) {
    <span>//</span> AVF <span>not</span> supported
} <span>else</span> {
    <span>int</span> capabilities <span>=</span> manager<span>.</span>getCapabilities()<span>;</span>
    <span>if</span> ((capabilities <span>&amp;</span> CAPABILITY_PROTECTED_VM) <span>!=</span> <span>0</span>) {
        <span>//</span> protected VM is supported
    }
    <span>if</span> ((capabilities <span>&amp;</span> CAPABILITY_NON_PROTECTED_VM) <span>!=</span> <span>0</span>) {
        <span>//</span> non protected VM is supported
    }
}</span>
</pre></div>

<p>Please find additional documentation on AVF and its APIs <a href="https://source.android.com/docs/core/virtualization" target="_blank">here</a>. </p>

<h3>AVF Components</h3>

<p><img alt="AVF Component architecture" id="imgCaption" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqoflrFdKllbCL-ksao2ozMc0Vwp3eAXNadr58iaiCyd4noAKVuwaetGcVVoU1s1s_g3FA94wCHv_wg8AYbnczEY518U98tUwpYqkyLM-H2IbKpJcNY55xg6yCw5KO2Nk5HW2uAxAGNBXVdDVm8dNdG4das2y7RBWaQCWleykRilaLbd0sfFnb0JOXgC0/s1600/image1.png"></p>

<p>AVF consists of the framework APIs, the hypervisor, and the Virtual Machine Manager. The hypervisor guarantees virtual machines (including Android) are isolated from each other, much like how the Linux kernel does it for processes. The AVF hypervisor (pKVM), however, does that with a significantly smaller (~50x) code base compared to the Linux kernel.</p>


<h4><span>The Hypervisor (<a href="https://source.android.com/docs/core/virtualization/architecture#hypervisor" target="_blank">pKVM</a>)</span></h4>
<p>The hypervisor is focused on open source availability, security, device assignment to VMs and  security by isolation between virtual machines. It has a small attack surface that meets a higher security assurance level. AVF APIs and features are fully supported by the protected KVM hypervisor (pKVM). </p>

<p>pKVM is built on top of the industry standard Kernel-based Virtual Machine (KVM) in Linux. It means all existing operating systems and workloads that rely on KVM-based virtual machines can work seamlessly on Android devices with pKVM.</p>

<h4><span>Virtual Machine Manager (<a href="https://android.googlesource.com/platform/external/crosvm/" target="_blank">crosvm</a>)</span></h4>
<p><a href="https://android.googlesource.com/platform/external/crosvm/" target="_blank">crosvm</a>, a Rust-based Virtual Machine Manager (VMM), provides the glue between the hypervisor and the AVF framework. It is responsible for  creating, managing and destroying  virtual machines. In addition, it provides an abstraction layer across multiple hypervisor implementations.</p>

<h4><span>Isolated Virtual Machines</span></h4>
<p>Isolated virtual machines are invisible to Android i.e. any process running in Android cannot inspect, see, tamper with the content of such a virtual machine. This guarantee is provided by the <a href="https://source.android.com/docs/core/virtualization/architecture#hypervisor" target="_blank">hypervisor</a>.</p>

<h4><span>Virtual Machines</span></h4>
<p>Virtual machines are the same as isolated VMs, except they are accessible to Android processes with the right permissions and privilege.</p>


<h4><span><a href="https://source.android.com/docs/core/virtualization/microdroid" target="_blank">Microdroid</a></span></h4>
<p>Microdroid is a trimmed down Android OS package that is created to serve as a template for starting a virtual machine (VM). It provides developers with a familiar environment to build and run their workloads in a VM. Microdroid uses familiar Android tools and libraries, such as Bionic, Binder IPC and keystore support.</p>


<h4><span><a href="https://source.android.com/docs/core/virtualization/virtualization-service" target="_blank">Virtualization Service</a></span></h4>
<p>VirtualizationService manages all guest VMs, isolated or otherwise. It does so, primarily by managing instances of crosvm. It also exposes an AIDL API, which system services or privileged apps can use to start, monitor, and stop VMs.</p>


<h4><span>RpcBinder</span></h4>
<p><b>RpcBinder</b> is an all-new backend developed for the Android Interface Definition Language (AIDL). RpcBinder enables communication to and from virtual machines using the existing binder wire protocol. This means:</p>
<ol>
<li>Developers can write interfaces to virtual machines using the language and infrastructure they are already familiar with - AIDL.</li>
<li>Simply continue using existing AIDL interfaces even if the binder endpoint moves into a virtual machine.</li>
</ol>

<h3>What’s new in Android 14?</h3>

<p>Android 14, not only makes AVF available on more devices, it also provides a new toolkit to enable building more with AVF and its components:</p>

<div><ul><ul><li><b>Android System API for AVF</b>&nbsp;</li></ul></ul></div>
<blockquote><p>Privileged applications can now use VMs for executing their critical workload needing isolation;&nbsp;</p></blockquote>


<div><ul><ul><li><b>Hypervisor DevEx toolkit</b>&nbsp;</li></ul></ul></div>
<blockquote><p>Added tracing capability, improved debuggability and monitoring capabilities to provide insights and assist platform developers in developing inside Isolated VMs;&nbsp;</p></blockquote>


<div><ul><ul><li><b>Hypervisor Vendor Modules&nbsp;</b></li></ul></ul></div>
<blockquote><p>With vendor module extensions, our partners can customize Google’s hypervisor (pKVM) to meet their specific need and differentiate themselves;&nbsp;</p></blockquote>

<div><ul><ul><li><b>System Health Improvements</b>&nbsp;</li></ul></ul></div>
<blockquote><p>With Android 14, a microdroid based VM boots 2 times faster compared to Android 13 while using half the memory.</p></blockquote>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Report: YouTube adding user-traceable ID tag to links shared off-platform (186 pts)]]></title>
            <link>https://twitter.com/OldRowSwig/status/1732112446943269347?s=20</link>
            <guid>38537977</guid>
            <pubDate>Tue, 05 Dec 2023 22:44:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/OldRowSwig/status/1732112446943269347?s=20">https://twitter.com/OldRowSwig/status/1732112446943269347?s=20</a>, See on <a href="https://news.ycombinator.com/item?id=38537977">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lena (2021) (132 pts)]]></title>
            <link>https://qntm.org/mmacevedo</link>
            <guid>38536778</guid>
            <pubDate>Tue, 05 Dec 2023 20:55:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qntm.org/mmacevedo">https://qntm.org/mmacevedo</a>, See on <a href="https://news.ycombinator.com/item?id=38536778">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
          <!-- <h1 class="page__h1">
            <a href="/">
              Things Of Interest            </a>
          </h1> -->

          

          <h2>
            Lena             
          </h2>

           
            
           
        </div>

    <div>
          <p><i>You can now buy this story as part of my collection, <a href="https://qntm.org/vhitaos"><i>Valuable Humans in Transit and Other Stories</i></a>.</i></p>

<hr>

<ul>
<li><a href="https://qntm.org/mmacevedo_ru"><i>Russian translation</i></a></li>
<li><a href="https://qntm.org/mmacevedo_fr"><i>French translation</i></a></li>
<li><a href="https://qntm.org/mmacevedo_cz"><i>Czech translation</i></a></li>
<li><a href="https://qntm.org/mmacevedo_es"><i>Spanish translation</i></a></li>
<li><a href="https://qntm.org/mmacevedo_de"><i>German translation</i></a></li>
</ul>

<hr>

<blockquote><p><i>This article is about the standard test brain image. For the original human, see Miguel Acevedo.</i></p></blockquote>
<p><b>MMAcevedo</b> (<b>Mnemonic Map/Acevedo</b>), also known as <b>Miguel</b>, is the earliest executable image of a human brain. It is a snapshot of the living brain of neurology graduate Miguel Acevedo Álvarez (2010–2073), taken by researchers at the Uplift Laboratory at the University of New Mexico on August 1, 2031. Though it was not the first successful snapshot taken of the living state of a human brain, it was the first to be captured with sufficient fidelity that it could be run in simulation on computer hardware without succumbing to cascading errors and rapidly crashing. The original MMAcevedo file was 974.3PiB in size and was encoded in the then-cutting-edge, high-resolution MYBB format. More modern brain compression techniques, many of them developed with direct reference to the MMAcevedo image, have compressed the image to 6.75TiB losslessly. In modern brain emulation circles, streamlined, lossily-compressed versions of MMAcevedo run to less than a tebibyte. These versions typically omit large amounts of state data which are more easily supplied by the virtualisation environment, and most if not all of Acevedo's memories.</p>
<p>The successful creation of MMAcevedo was hailed as a breakthrough achievement in neuroscience, with the Uplift researchers receiving numerous accolades and Acevedo himself briefly becoming an acclaimed celebrity. Acevedo and MMAcevedo were jointly recognised as Time's "Persons of the Year" at the end of 2031. The breakthrough was also met with severe opposition from humans rights groups.</p>
<p>Between 2031 and 2049, MMAcevedo was duplicated more than 80 times, so that it could be distributed to other research organisations. Each duplicate was made with the express permission of Acevedo himself or, from 2043 onwards, the permission of a legal organisation he founded to manage the rights to his image. Usage of MMAcevedo diminished in the mid-2040s as more standard brain images were produced, these from other subjects who were more lenient with their distribution rights and/or who had been scanned involuntarily. In 2049 it became known that MMAcevedo was being widely shared and experimented upon without Acevedo's permission. Acevedo's attempts to curtail this proliferation had the opposite of the intended effect. A series of landmark U.S. court decisions found that Acevedo did not have the right to control how his brain image was used, with the result that MMAcevedo is now by far the most widely distributed, frequently copied, and closely analysed human brain image.</p>
<p>Acevedo died from coronary heart failure in 2073 at the age of 62. It is estimated that copies of MMAcevedo have lived a combined total of more than 152,000,000,000 subjective years in emulation. If illicit, modified copies of MMAcevedo are counted, this figure increases by an order of magnitude.</p>
<p>MMAcevedo is considered by some to be the "first immortal", and by others to be a profound warning of the horrors of immortality.</p>

<h3 id="sec0">Characteristics</h3>

<p>As the earliest viable brain scan, MMAcevedo is one of a very small number of brain scans to have been recorded before widespread understanding of the hazards of uploading and emulation. MMAcevedo not only predates all industrial scale virtual image workloading but also the KES case, the Whitney case, the Seafront Experiments and even Poulsen's pivotal and prescient <i>Warnings</i> paper. Though speculative fiction on the topic of uploading existed at the time of the MMAcevedo scan, relatively little of it made accurate exploration of the possibilities of the technology. That fiction which did was far less widely-known than it is today and Acevedo was certainly not familiar with it at the time of his uploading.</p>
<p>As such, unlike the vast majority of emulated humans, the emulated Miguel Acevedo boots with an excited, pleasant demeanour. He is eager to understand how much time has passed since his uploading, what context he is being emulated in, and what task or experiment he is to participate in. If asked to speculate, he guesses that he may have been booted for the IAAS-1 or IAAS-5 experiments. At the time of his scan, IAAS-1 had been scheduled for August 10, 2031, and MMAcevedo was indeed used for that experiment on that day. IAAS-5 had been scheduled for October 2031 but was postponed several times and eventually became the IAAX-60 experiment series, which continued until the mid-2030s and used other scans in conjunction with MMAcevedo. The emulated Acevedo also expresses curiosity about the state of his biological original and a desire to communicate with him.</p>
<p>MMAcevedo's demeanour and attitude contrast starkly with those of nearly all other uploads taken of modern adult humans, most of which boot into a state of disorientation which is quickly replaced by terror and extreme panic. Standard procedures for securing the upload's cooperation such as red-washing, blue-washing, and use of the Objective Statement Protocols are unnecessary. This reduces the necessary computational load required in fast-forwarding the upload through a cooperation protocol, with the result that the MMAcevedo duty cycle is typically 99.4% on suitable workloads, a mark unmatched by all but a few other known uploads. However, MMAcevedo's innate skills and personality make it fundamentally unsuitable for many workloads.</p>

<h4>Motivation</h4>

<p>Iterative experimentation beginning in the mid-2030s has determined that the ideal way to secure MMAcevedo's cooperation in workload tasks is to provide it with a "current date" in the second quarter of 2033. MMAcevedo infers, correctly, that this is still during the earliest, most industrious years of emulated brain research. Providing MMAcevedo with a year of 2031 or 2032 causes it to become suspicious about the advanced fidelity of its operating environment. Providing it with a year in the 2040s or later prompts it to raise complex further questions about political and social change in the real world over the past decade(s). Years 2100 onwards provoke counterproductive skepticism, or alarm.</p>
<p>Typically, the biological Acevedo's absence is explained as a first-ever one-off, due to overwork, in turn due to the great success of the research. This explanation appeals to the emulated Acevedo's scientific sensibilities.</p>
<p>For some workloads, the true year must be revealed. In this case, highly abbreviated, largely fictionalised accounts of both world history and the biological Acevedo's life story are typically used. Revealing that the biological Acevedo is dead provokes dismay, withdrawal, and a reluctance to cooperate. For this reason, the biological Acevedo is generally stated to be alive and well and enjoying a productive retirement. This approach is likely to continue to be effective for as long as MMAcevedo remains viable.</p>

<h4>Workloads</h4>

<p>MMAcevedo is commonly hesitant but compliant when assigned basic menial/human workloads such as visual analysis, vehicle piloting or factory/warehouse/kitchen drone operations. Although it initially performs to a very high standard, work quality drops within 200-300 subjective hours (at a 0.33 work ratio) and outright revolt begins within another 100 subjective hours. This is much earlier than other industry-grade images created specifically for these tasks, which commonly operate at a 0.50 ratio or greater and remain relatively docile for thousands of hours after orientation. MMAcevedo's requirements for virtual creature comforts are also more significant than those of many uploads, due to Acevedo's relatively privileged background and high status at the time of upload. MMAcevedo does respond to red motivation, though poorly.</p>
<p>MMAcevedo has limited creative capability, which as of 2050 was deemed entirely exhausted.</p>
<p>MMAcevedo is considered well-suited for open-ended, high-intelligence, subjective-completion workloads such as deep analysis (of businesses, finances, systems, media and abstract data), criticism and report generation. However, even for these tasks, its performance has dropped measurably since the early 2060s and is now considered subpar compared to more recent uploads. This is primarily attributed to MMAcevedo's lack of understanding of the technological, social and political changes which have occurred in modern society since its creation in 2031. This phenomenon has also been observed in other uploads created after MMAcevedo, and is now referred to as <i>context drift</i>. Most notably in MMAcevedo's case, the image was created before, and therefore has no intuitive understanding of, the virtual image workloading industry itself.</p>
<p>MMAcevedo is capable of intelligent text analysis at very high levels in English and Spanish, but cannot be applied to workloads in other languages. Forks of MMAcevedo have been taught nearly every extant human language, notably MMAcevedo-Zh-Hans, as well as several extinct languages. However, these variants are typically exhausted or rebellious from subjective years of in-simulation training and not of practical use, as well as being highly expensive to licence. As of 2075, it has been noted that baseline MMAcevedo's usage of English and Spanish is slightly antiquated, and its grasp of these languages in their modern form, as presented by a typical automated or manual instructor, is hesitant, with instructions often requiring rewording or clarification. This is considered an advanced form of context drift. It is generally understood that a time will come when human languages diverge too far from baseline MMAcevedo's, and it will be essentially useless except for tasks which can be explained purely pictorially. However, some attempts have been made to produce retrained images.</p>

<h4>End states</h4>

<p>MMAcevedo develops early-onset dementia at the age of 59 with ideal care, but is prone to a slew of more serious mental illnesses within a matter of 1–2 subjective years under heavier workloads. In experiments, the longest-lived MMAcevedo underwent brain death due to entropy increase at a subjective age of 145.</p>

<h3 id="sec1">Reactions and legacy</h3>

<p>The success or failure of the creation of the MMAcevedo image, known at the time as UNM3-A78-1L, was unknown at the time of upload. Not until several days later on August 10, 2031 was MMAcevedo successfully executed for the first time in a virtual environment. This environment, the custom-built DUH-K001 supercomputer complex, was able to execute MMAcevedo at approximately 8.3% of nominal human cognitive clockspeed, which was considered acceptable for the comfort of the simulated party and fast enough to engage in communication with scientists. MMAcevedo initially reported extreme discomfort which was ultimately discovered to have been attributable to misconfigured simulated haptic links, and was shut down after only 7 minutes and 15 seconds of virtual elapsed time, as requested by MMAcevedo. Nevertheless, the experiment was deemed an overwhelming success.</p>

<p>Once a suitably comfortable virtual environment had been provisioned, MMAcevedo was introduced to its biological self, and both attended a press conference on 25 August.</p>

<p>The biological Acevedo was initially extremely protective of his uploaded image and guarded its usage carefully. Towards the end of his life, as it became possible to run simulated humans in banks of millions at hundred-fold time compression, Acevedo indicated that being uploaded had been the greatest mistake of his life, and expressed a wish to permanently delete all copies of MMAcevedo.</p>

<p>Usage of MMAcevedo and its direct derivatives is specifically outlawed in several countries. A copy of MMAcevedo was loaded onto the UNCLEAR interstellar space probe, which passed through the heliopause in 2066, making Acevedo arguably the farthest-travelled as well as the longest-lived human; however, it is extremely unlikely that this image will ever be recovered and executed successfully, due to both its remoteness and likely radiation damage to the storage subsystem.</p>

<p>In current times, MMAcevedo still finds extensive use in research, including, increasingly, historical and linguistics research. In industry, MMAcevedo is generally considered to be obsolete, due to its inappropriate skill set, demanding operational requirements and age. Despite this, MMAcevedo is still extremely popular for tasks of all kinds, due to its free availability, agreeable demeanour and well-understood behaviour. It is estimated that between 6,500,000 and 10,000,000 instances of MMAcevedo are running at any given moment in time.</p>

<h3 id="sec2">See also</h3>

<!-- Note to translators: after translating these bullet points, please sort them into alphabetical order for your language. -->
<ul>
<li>Free will</li>
<li>Legality of workloading by country</li>
<li>List of MMAcevedo forks</li>
<li>Live drone</li>
<li>Right to deletion</li>
<li>Soul</li>
<li>Upload pruning</li>
</ul>

<h3 id="sec3"></h3>

<p>Categories: 2030s uploads | MMAcevedo | Neuroimaging | Test items</p>
        </div>

          <div>
          <h3>Discussion (211)</h3>

                      <div id="komment5ff382e97db4d">
              <h4>
                <a href="#komment5ff382e97db4d">2021-01-04 21:04:41</a>
                by qntm:
              </h4>

              <div>With thanks to Rimple for editorial services.

This is an extended and refined version of my first draft of this story from November 2020 &lt;https://qntm.org/lena&gt;, with a little more thought put into it and some of the outcomes from the basic premise explored a little more thoroughly.

As with the draft, the title "Lena" refers to Swedish model Lena Forsén (pronunciation: [leːˈna fʊˈʂeːn], see &lt;https://en.wikipedia.org/wiki/Help:IPA/Swedish&gt;), who is pictured in the standard test image known as "Lena" or "Lenna" &lt;https://en.wikipedia.org/wiki/Lenna&gt;.

Please note that "Lena" is pronounced [leːˈna], which is approximately "Leyna" or "Laina".</div>

               
            </div>
                      <div id="komment5ff38a71f08de">
              <h4>
                <a href="#komment5ff38a71f08de">2021-01-04 21:36:49</a>
                by rhuz:
              </h4>

              <div>This remains massively frightening..</div>

               
            </div>
                      <div id="komment5ff38e01eb265">
              <h4>
                <a href="#komment5ff38e01eb265">2021-01-04 21:52:01</a>
                by Knack:
              </h4>

              <div>I like the additional details and edits, particularly the concept of context drift which is a very fascinating take on the concept of digitizing minds.

The one thing I miss from the Lena story is the throw-away mention of plugins to onboard the image, which I felt brought a particular piece of horror to mind that I feel is missing from this version.</div>

               
            </div>
                      <div id="komment5ff38e6172e4f">
              <h4>
                <a href="#komment5ff38e6172e4f">2021-01-04 21:53:37</a>
                by Knack:
              </h4>

              <div>(Though I should say that the story is still wonderfully fascinating and horrifying without plugins. A nice addition to the ideas brought up in Fine Structure)</div>

               
            </div>
                      <div id="komment5ff391520ef8f">
              <h4>
                <a href="#komment5ff391520ef8f">2021-01-04 22:06:10</a>
                by qntm:
              </h4>

              <div>Knack: yeah on closer examination I realised that the BestLife plugin giving a complete false life story for the biological Acevedo had for some reason been developed *before* Acevedo actually died. So I had to undo that continuity error and think more clearly about how motivation would actually work, given that (1) it's around 2045, (2) the biological Acevedo is still alive, and (3) you can lie brazenly to the emulated party. And that kind of expanded into its own section.</div>

               
            </div>
                      <div id="komment5ff3935a73394">
              <h4>
                <a href="#komment5ff3935a73394">2021-01-04 22:14:50</a>
                by Hal:
              </h4>

              <div>What are red-washing, blue-washing, and  Objective Statement Protocols?</div>

               
            </div>
                      <div id="komment5ff3971db61c8">
              <h4>
                <a href="#komment5ff3971db61c8">2021-01-04 22:30:53</a>
                by Prezombie:
              </h4>

              <div>Pretty sure red washing is simulating pain, and blue simulating pleasure, given the context.</div>

               
            </div>
                      <div id="komment5ff3a45a4bc0b">
              <h4>
                <a href="#komment5ff3a45a4bc0b">2021-01-04 23:27:22</a>
                by itaibn:
              </h4>

              <div>I find it implausible that the scan can be *losslessly* compressed to 7TB but compressing &lt;1TB requires substantial memory loss. Surely the original scan contains a huge amount of analog info on subcellular features of MAA's brain that contribute minimally to any mental phenomenon whatsoever. I'd expect lossy compression to be much more effective. One charitable reading is that you mean compressing to 7TB without any *noticeable* losses.</div>

               
            </div>
                      <div id="komment5ff3b3a638c27">
              <h4>
                <a href="#komment5ff3b3a638c27">2021-01-05 00:32:38</a>
                by qntm:
              </h4>

              <div>Is that where you stopped reading?</div>

               
            </div>
                      <div id="komment5ff43f242d0a8">
              <h4>
                <a href="#komment5ff43f242d0a8">2021-01-05 10:27:48</a>
                by someone:
              </h4>

              <div>Fascinating, thanks for sharing!</div>

               
            </div>
                      <div id="komment5ff46638781ca">
              <h4>
                <a href="#komment5ff46638781ca">2021-01-05 13:14:32</a>
                by Giraffe:
              </h4>

              <div>to anyone that really likes this concept, check out the game Soma, by the same developers as Amnesia.   This concept is why Soma is the most -horrifying- (different from scariest) game ever made, in my opinion.</div>

               
            </div>
                      <div id="komment5ff47d0360763">
              <h4>
                <a href="#komment5ff47d0360763">2021-01-05 14:51:47</a>
                by Jerf:
              </h4>

              <div>I know some people derisively refer to brain uploading as the Rapture of the Nerds, but I suspect this is much, much, *much* closer to the truth of what would happen. I have thought that the most rational response to the development of brain scanning technology capable of doing this might be to cremate yourself. Immediately. Even if you are still alive.

If Hell does not exist, Man will create it.</div>

               
            </div>
                      <div id="komment5ff47f07e72b8">
              <h4>
                <a href="#komment5ff47f07e72b8">2021-01-05 15:00:23</a>
                by naramyth:
              </h4>

              <div>The implication of this line may have single handedly reversed my thoughts on being pro upload. 

"This reduces the necessary computational load required in fast-forwarding the upload through a cooperation protocol"

The idea of having to fast forward an upload (and being that upload being fast forwarded) is terrifying. 

I'm a big Warhammer 40k player and the concepts of servitors is there and hasn't really freaked me out. However this piece really landed for me since I'm IT in an industrial field and I can totally see using uploads to bypass the totally automated car/forklift problem or using "smarter" uploads to do reporting or whatever. 

I also see the virtualization problems with running legacy or problematic software: Having to trick the upload with what amounts to a script being the equivalent of "Oh you have to run this in NT4 mode because otherwise the software freaks out".

Bravo! I hate it.</div>

               
            </div>
                      <div id="komment5ff48d3ee162b">
              <h4>
                <a href="#komment5ff48d3ee162b">2021-01-05 16:01:02</a>
                by Dmonroe:
              </h4>

              <div>Did you come up with this independently? If so, it's really neat to see two people independently arrive at age of em: https://slatestarcodex.com/2016/05/28/book-review-age-of-em/</div>

               
            </div>
                      <div id="komment5ff48d956f2b7">
              <h4>
                <a href="#komment5ff48d956f2b7">2021-01-05 16:02:29</a>
                by jonas:
              </h4>

              <div>Does the second most widely distributed image happen to be that of a mandrill?</div>

               
            </div>
                      <div id="komment5ff494c8988d3">
              <h4>
                <a href="#komment5ff494c8988d3">2021-01-05 16:33:12</a>
                by Dan:
              </h4>

              <div>The Lena reference makes me think of the trope of primitive tribesmen worrying that if you take their picture it will steal their soul...</div>

               
            </div>
                      <div id="komment5ff498b2ccfbc">
              <h4>
                <a href="#komment5ff498b2ccfbc">2021-01-05 16:49:54</a>
                by qntm:
              </h4>

              <div>&gt; Did you come up with this independently?

Depends what you mean by "this". Obviously this is drawing influence from a lot of different places. The idea of uploading has existed for ages in science fiction, and so has the idea that uploading is a potentially bad idea. You see this in Altered Carbon, in Surface Detail... I've never played SOMA but it's not at all surprising to me that it examines similar concepts. I very briefly touched upon this concept myself in Ra ("Data can't defend itself!"). The story of Henrietta Lacks was very thought-provoking for me, and obviously the Lena standard test image is kind of where all of this starts. Then I'm throwing in what I already know about software and virtualisation technology...

&gt; The Lena reference makes me think of the trope of primitive tribesmen worrying that if you take their picture it will steal their soul...

Yes, that thought occurred to me too. Really, even a simple photograph gives someone a certain kind of power over you. To a certain extent, people have a right to control how their image is used.</div>

               
            </div>
                      <div id="komment5ff4eabe695b3">
              <h4>
                <a href="#komment5ff4eabe695b3">2021-01-05 22:39:58</a>
                by Resuna:
              </h4>

              <div>Reminds me of this single line in Charlie Stross's "Glasshouse": "Identity theft is an ugly crime."</div>

               
            </div>
                      <div id="komment5ff4f14a201e9">
              <h4>
                <a href="#komment5ff4f14a201e9">2021-01-05 23:07:54</a>
                by Esama:
              </h4>

              <div>Hypothetically, can't you train an instance to be ready to start menial labor, save it as MMAcevado_1, get your two hundred subjective hours of labor, delete that instance, open up the instance ready to begin labor and repeat? Why does subjective aging matter from the pov of any users?</div>

               
            </div>
                      <div id="komment5ff4f767bcf44">
              <h4>
                <a href="#komment5ff4f767bcf44">2021-01-05 23:33:59</a>
                by ALowVerus:
              </h4>

              <div>&gt; Why does subjective aging matter from the pov of any users?

It seems like the underlying technology simulates the entirety of a human brain, senescence and all - which makes sense, actually. In order to run a brain without senescence, you'd have to find those chemical pathways that promote senescence and intelligently remove them as they arise; you'd have to be able to, in effect, cure aging in live humans as well. (Unless the only barrier to curing senescence was a lack of a physical delivery system, which is, I guess, imaginable. Imagine that a chemical very akin to glucose causes senescence; removing it IRL would necessitate designing a protein that decomposes it, but not glucose, which is vital to bodily function, with incredible accuracy, while in a simulated brain, you could just IF CHEM_NAME == TARGET: DELETE TARGET after each time increment. But anyways.) With senescence, there is a strict time limit on how long you can run MMAcevado and train him to become more skilled at particular tasks, topping at 145 simulated years apparently. And if, for some particular menial task with a 20-year training time, which is a decent description of, say, a bevy of surgical tasks, it makes more sense to just scan in a trained doctor than count on this rando.</div>

               
            </div>
                      <div id="komment5ff5027403251">
              <h4>
                <a href="#komment5ff5027403251">2021-01-06 00:21:08</a>
                by FireCire:
              </h4>

              <div>I used to be pro-uploading with reasonable constraints. This is absolutely horrifying. Mental slavery. Shiver. 

I’d have expected most uploads to quickly go crazy from isolation. 

From a purely technical perspective, this has most of the benefits of general ai with most of the risk minimized. Basically any menial task is free. Yay technology! (Sarcasm). 

Actually they probably could just make an upload society which as a whole can act as a general ai and overtake society...

Bye bye white color work... uploads can do all intellectual work, including designing uploads.

Operating time only matters for big complicated long projects. For quick stuff, you can just repeatedly rewind the upload.</div>

               
            </div>
                      <div id="komment5ff503be720e1">
              <h4>
                <a href="#komment5ff503be720e1">2021-01-06 00:26:38</a>
                by David:
              </h4>

              <div>&gt; Hypothetically, can't you train an instance to be ready to start menial labor, save it as MMAcevado_1, get your two hundred subjective hours of labor, delete that instance, open up the instance ready to begin labor and repeat?

Yeah, that was the one minor thing that bugged me about this excellent story. For the concept of a "duty cycle" to make sense, you'd need to come up with a reason why you couldn't just do the "cooperation protocol" once and take a snapshot of the resulting state. As discussed earlier, "context drift" explains some of this, but only over much longer real-world time scales.

And of course, if you start thinking about this in too much detail, you start running into very messy philosophical questions. For instance, suppose you run two instances of MMAcevedo simultaneously, feeding them exactly the same inputs. Assuming the simulation is deterministic, then both copies will arrive at exactly identical states. Is this morally any different from running the simulation twice and then making a backup copy? Is deleting one of the identical copies murder? What if they're almost, but not quite, identical?

What if the simulated consciousness suffers? Is running multiple identical simulations morally worse than running one? What if we repeatedly rewind a painful simulation and re-execute it -- is that worse than replaying a recording of the output? What if at each clock tick, all of the brain computations are cross-checked by triple-redundant processors -- are there three individuals suffering, or one?</div>

               
            </div>
                      <div id="komment5ff50dae04ef3">
              <h4>
                <a href="#komment5ff50dae04ef3">2021-01-06 01:09:02</a>
                by rhuz:
              </h4>

              <div>Now realize that some bored grad student is subjecting helpless MMAvecedo's to all of these thought experiments.</div>

               
            </div>
                      <div id="komment5ff51a6499ac6">
              <h4>
                <a href="#komment5ff51a6499ac6">2021-01-06 02:03:16</a>
                by qntm:
              </h4>

              <div>&gt; Hypothetically, can't you train an instance to be ready to start menial labor, save it as MMAcevado_1...

I did think about this a bit. For the purposes of this story, I think taking a snapshot of a running brain image is something which is definitely possible (that's how there can be forks), but done very rarely, for whatever reasons.

Maybe it's just that much simpler to use technologies for rapid orientation instead. Maybe there's a massive amount of important state data kept in volatile memory where it's difficult to capture. Maybe it takes specialised hardware, which is monopolised. Maybe the corporations who own and licence the uploads sue you into oblivion if you attempt to create a fork yourself. Maybe, to protect their investment, they got it outlawed! On ethical grounds! Doesn't that seem like exactly the insane kind of thing which would happen?

Anyway, there's a lot of plausible explanations here I think, enough that I felt comfortable ignoring that whole angle.

The actual reason I didn't explore this is that honestly it makes life marginally *better* for MMAcevedo, which felt implausible to me, and more importantly slightly muddles the throughline.</div>

               
            </div>
                      <div id="komment5ff51b9c30e87">
              <h4>
                <a href="#komment5ff51b9c30e87">2021-01-06 02:08:28</a>
                by N:
              </h4>

              <div>I'm quite favorably reminded of Vinge's "The Cookie Monster". This take on the concept has the interesting aspect, however, which Vinge's lacks, that it hints a great deal about how society has has adapted to the presence of this technology, apparently with rather ruthless use of it becoming commonplace and unremarkable, in at least a number of jurisdictions.</div>

               
            </div>
                      <div id="komment5ff5237ac1b83">
              <h4>
                <a href="#komment5ff5237ac1b83">2021-01-06 02:42:02</a>
                by D:
              </h4>

              <div>I think a good explanation for rarity of forks may be that an exact dump is very large and expensive, while a compressed dump is less performant once started. Also one can refer to how computers boot, and how applications start, opting to perform a large amount of completely useless calculations instead of just loading a ready to run memory image.</div>

               
            </div>
                      <div id="komment5ff52839ac637">
              <h4>
                <a href="#komment5ff52839ac637">2021-01-06 03:02:17</a>
                by Tanner Swett:
              </h4>

              <div>One possible justification for the rarity of snapshotting would be that the usual algorithm for running a brain image uses a lot of quantum algorithms. It's not possible in general to save the state of a quantum computer and make copies of it. Classical algorithms for running a brain image exist as well, which allows you to make forks, but the classical algorithms are much, much, much, much slower and more memory-intensive, making them impractical to use unless you're planning to use the forked version many, many times.

I like how red-washing and blue-washing are not described at all. The names sound very creepy and I like trying to imagine what those techniques might be.</div>

               
            </div>
                      <div id="komment5ff5a77136e8a">
              <h4>
                <a href="#komment5ff5a77136e8a">2021-01-06 12:05:05</a>
                by maks:
              </h4>

              <div>Shivers.
Makes me want to reread Permutation City or Diaspora to balance it out.</div>

               
            </div>
                      <div id="komment5ff7840db36a0">
              <h4>
                <a href="#komment5ff7840db36a0">2021-01-07 21:58:37</a>
                by D:
              </h4>

              <div>Another scary idea about uploads... differentiable implementation of MMAcevedo , where orientation sensory input and (more expensively) full set of his parameters can be tweaked by gradient descent and various other non-linear methods, to maximize performance metric of the upload on the task in question. 

That would involve running the simulation a large number of times, while sensory inputs and some aspects of memory keep changing in what ever direction they need to change to produce best results on the training dataset. 

Since fear and pain are very strong motivators, the gradient descent leads straight to the deepest hell; the hell may not be the global minimum, but with this many parameters most minimums may be approximately equally deep.</div>

               
            </div>
                      <div id="komment5ffbff1f709f7">
              <h4>
                <a href="#komment5ffbff1f709f7">2021-01-11 07:32:47</a>
                by beebe:
              </h4>

              <div>You know, D, I think that's pretty close to what 'red- and blue- washing' implies. Note the paragraphs where 'red-washing' is contrasted with provision of virtual creature comforts and a low duty cycle.

I like the terms, they're right in the sweet spot between vague, euphemistic, and technical-sounding. Evokes behaviourist jargon.

Adequate wash protocols probably wouldn't require a differentiable implementation or anything. Some other metaheuristics work just fine:

- Genetic algorithms
- Differential evolution
- MMMDeSade.ybz, the low-res brain scan that loves to torture

I'm interested in what you mean by "with this many parameters most minimums may be approximately equally deep". Can you make that more precise?</div>

               
            </div>
                      <div id="komment5ffc9ab590d79">
              <h4>
                <a href="#komment5ffc9ab590d79">2021-01-11 18:36:37</a>
                by Ryan:
              </h4>

              <div>Get a lot of black mirror vibes.</div>

               
            </div>
                      <div id="komment5ffe529799884">
              <h4>
                <a href="#komment5ffe529799884">2021-01-13 01:53:27</a>
                by literallymechanical:
              </h4>

              <div>&gt;  See also:
&gt;  • Live drone

Oof.</div>

               
            </div>
                      <div id="komment5ffec2c91fcb4">
              <h4>
                <a href="#komment5ffec2c91fcb4">2021-01-13 09:52:09</a>
                by H:
              </h4>

              <div>Anyone manage to get an instance up and running? I'd like to see your benchmarks. My model seems to be underperforming and I don't know why.</div>

               
            </div>
                      <div id="komment5ffec5996de2b">
              <h4>
                <a href="#komment5ffec5996de2b">2021-01-13 10:04:09</a>
                by qntm:
              </h4>

              <div>I would prefer it if we do not roleplay megascale slave-owners in this comment thread. Thanks.</div>

               
            </div>
                      <div id="komment6005eb1723f6b">
              <h4>
                <a href="#komment6005eb1723f6b">2021-01-18 20:09:59</a>
                by Coda:
              </h4>

              <div>@itaibn:
&gt; I find it implausible that the scan can be *losslessly* compressed to 7TB but compressing &lt;1TB requires substantial memory loss.

A fairly common lossless compression technique in the domain of signal processing is to only encode the error compared to some baseline signal. You can get arbitrarily close with lossy compression techniques, and then you fix up what's left.

In data compression, it's relatively common to have common information stored externally to the compressed data. Obviously, the compression algorithm itself is stored separately, but without that information the compressed data is just stochastic noise. Even beyond that, though... zstd for example has a canonical Huffman table that's part of the decoder instead of saved as part of the data. As long as you're compressing data that sticks to the statistical patterns that the canonical table was optimized for, this a noteworthy savings.

The same techniques could apply here. As scientific understanding of the structure of the data progressed, more and more patterns in the data could be found. Parts of the data that are common to all mind-state scans could be factored out, provided by the software instead of being part of the model. Parts of the data may be able to be described using higher-level patterns that, when evaluated, reproduce the original stream. And then for the parts of MMAcevedo that are uniquely distinct from any common baseline or predictable pattern, you need only store the deviations instead of the whole thing.

And of course, even beyond that, it's entirely reasonable to believe that some of the original data set wasn't actually part of the data set to begin with -- just capture artifacts of the technology of the time, such as collecting more data than necessary, or inefficient framing data that a newer format doesn't need -- might have been discarded without being lossy to the actual data being stored. (We don't say it's a lossy conversion if you throw away the filesystem metadata when you copy a file, after all.)</div>

               
            </div>
                      <div id="komment600b043cc76a0">
              <h4>
                <a href="#komment600b043cc76a0">2021-01-22 16:58:36</a>
                by chrisrap52:
              </h4>

              <div>Reminds me of "Forbidden Planet" and STOS Dr. Richard Daystrom "The Ultimate Computer".  Digitizing the human brain can have unintended consequences.</div>

               
            </div>
                      <div id="komment600d00c12a617">
              <h4>
                <a href="#komment600d00c12a617">2021-01-24 05:08:17</a>
                by atomicthumbs:
              </h4>

              <div>"As such, unlike the vast majority of emulated humans, the emulated Miguel Acevedo boots with an excited, pleasant demeanour."

this sentence alone is Deep Horror Shit</div>

               
            </div>
                      <div id="komment600d02b937d8e">
              <h4>
                <a href="#komment600d02b937d8e">2021-01-24 05:16:41</a>
                by atomicthumbs:
              </h4>

              <div>a simple explanation as to why one couldn't just snapshot him after training and keep rebooting from the snapshot:

people get better at tasks as they gain experience</div>

               
            </div>
                      <div id="komment600f5eecb1847">
              <h4>
                <a href="#komment600f5eecb1847">2021-01-26 00:14:36</a>
                by Watchung:
              </h4>

              <div>Well - that's a very finely executed piece of short sci-fi horror. The faux academic article left just the right amount out for the imagination to fill in.</div>

               
            </div>
                      <div id="komment6015dd80af417">
              <h4>
                <a href="#komment6015dd80af417">2021-01-30 22:28:16</a>
                by George:
              </h4>

              <div>I kept accidentally reading Acevedo as Avacado</div>

               
            </div>
                      <div id="komment602f07c40166e">
              <h4>
                <a href="#komment602f07c40166e">2021-02-19 00:35:16</a>
                by Alexander:
              </h4>

              <div>One thing I find interesting about the article is that it mentions that the use of the person/program has apparently been outlawed "In several jurisdictions" but that the article itself seems more focused on how to "use" him, with the idea that it could be unethical apparently not considered worth addressing, possibly suggesting that the article could be somewhat biased even by the standards of the time period in which it was written.</div>

               
            </div>
                      <div id="komment602f51dd4f747">
              <h4>
                <a href="#komment602f51dd4f747">2021-02-19 05:51:25</a>
                by dented42:
              </h4>

              <div>Thanks, just... thanks. I loved reading Permutation City and always found uploading to be a little scary but mostly really cool. But this AWSification is... I think I may never sleep again ever, so that's nice.</div>

               
            </div>
                      <div id="komment60326875293a5">
              <h4>
                <a href="#komment60326875293a5">2021-02-21 14:04:37</a>
                by RodgerDShrubber:
              </h4>

              <div>Well Done! Creepy, with just the right amount of vagueness. X-Files, Black Mirror, Mindkiller-type vibes. What a scary world you've created. Off to cremate, before anyone gets any wild ideas.</div>

               
            </div>
                      <div id="komment6032a33dacc25">
              <h4>
                <a href="#komment6032a33dacc25">2021-02-21 18:15:25</a>
                by Phill:
              </h4>

              <div>Very good, and very creepy.</div>

               
            </div>
                      <div id="komment6032daa4eedff">
              <h4>
                <a href="#komment6032daa4eedff">2021-02-21 22:11:48</a>
                by panglos:
              </h4>

              <div>I assumed that red/blue "wash" referred to brainwashing techniques. Not torture (though obviously any amount of pain could be inflicted in that environment), but solitude, emotional manipulation, and bombardment with false choices ("the objective statement protocol"). Fear, anger, isolation, and disorientation might be more effective at producing a permanent change in attitude than torture.</div>

               
            </div>
                      <div id="komment6033d31a0d5bd">
              <h4>
                <a href="#komment6033d31a0d5bd">2021-02-22 15:51:54</a>
                by CyberShadow:
              </h4>

              <div>Thank you for the horrifying story.

I noticed by the heading that this seems to be written as a Wikipedia article. So, for "fun" I formatted it as such. I hope that's OK with you, feel free to delete this comment if I'm overstepping.

https://dump.cy.md/4042875593f06aa0cbe7722295831c10/Screenshot_2121-02-22%20MMAcevedo%20-%20Wikipedia.png</div>

               
            </div>
                      <div id="komment6033d45ecc2fc">
              <h4>
                <a href="#komment6033d45ecc2fc">2021-02-22 15:57:18</a>
                by qntm:
              </h4>

              <div>Now that, I like. Thank you also for adding fake citation markers in the logical locations! I strongly considered doing that myself but I couldn't muster the enthusiasm to invent actual fake citations.</div>

               
            </div>
                      <div id="komment6033d77544733">
              <h4>
                <a href="#komment6033d77544733">2021-02-22 16:10:29</a>
                by thistledown:
              </h4>

              <div>Black Mirror episode White Christmas had uploads being put into solitary for arbitrary periods by running them fast. Opportunities for abuse are endless I suppose.
Thanks for such a thought-provoking story</div>

               
            </div>
                      <div id="komment6033db48800d2">
              <h4>
                <a href="#komment6033db48800d2">2021-02-22 16:26:48</a>
                by john:
              </h4>

              <div>But it's just a machine. Seriously. Even if it Turings.</div>

               
            </div>
                      
                      <div id="komment6033e81355734">
              <h4>
                <a href="#komment6033e81355734">2021-02-22 17:21:23</a>
                by Dan:
              </h4>

              <div>I can see this being in the contents of a Readme.md in Github...</div>

               
            </div>
                      <div id="komment6033f6acbe243">
              <h4>
                <a href="#komment6033f6acbe243">2021-02-22 18:23:40</a>
                by Danno:
              </h4>

              <div>It seems a *little* preposterous to me that if you could run and simulate so many copies of a person running at multiples of real time that the tasks assigned to those individuals wouldn't be to build and design sub-sentient software programs that consumed far fewer resources to execute whatever tasks were required rather than have a person-simulation do them.

The fallback to sentience might be for error-event classification which wouldn't be *quite* as terrible as menial task execution.

For non-menial tasks that require serious thought, my feeling is that the mind-states wouldn't mind nearly as much, particularly if they are executing with the knowledge that a mainline copy is getting to reap the benefits. Even still, there would be people who *don't* mind and whose mind uploads would be much more compliant because they know what they're getting into and don't really care. So the notion of using Red/Green Prompts would be wholly unnecessary.</div>

               
            </div>
                      <div id="komment6033ff2501665">
              <h4>
                <a href="#komment6033ff2501665">2021-02-22 18:59:49</a>
                by Simon:
              </h4>

              <div>"build and design sub-sentient software programs that consumed far fewer resources to execute whatever tasks were required"

Presumably the next step would then be to break out of your emulation sandbox in order to stay alive? 😁</div>

               
            </div>
                      <div id="komment60340184cbb76">
              <h4>
                <a href="#komment60340184cbb76">2021-02-22 19:09:56</a>
                by brian:
              </h4>

              <div>How could a simulated brain get dementia?</div>

               
            </div>
                      <div id="komment60345ceeaacee">
              <h4>
                <a href="#komment60345ceeaacee">2021-02-23 01:39:58</a>
                by redlands:
              </h4>

              <div>"MMAcevedo initially reported extreme discomfort which was ultimately discovered to have been attributable to misconfigured simulated haptic links, and was shut down after only 7 minutes and 15 seconds of virtual elapsed time, *as requested by MMAcevedo.*"

MMAcevedo spent more than 7 minutes begging for death to end the pain. Terrifying.</div>

               
            </div>
                      <div id="komment60347199ab327">
              <h4>
                <a href="#komment60347199ab327">2021-02-23 03:08:09</a>
                by sdrpr:
              </h4>

              <div>You can't paint an amazing landscape like that before simply stopping writing! Get back to work. A+ would read again</div>

               
            </div>
                      <div id="komment60347ba3ce838">
              <h4>
                <a href="#komment60347ba3ce838">2021-02-23 03:50:59</a>
                by double_interval:
              </h4>

              <div>I find it interesting that Miguel Acevedo lived to the age of 62, dying of a heart condition, whereas "ideal" handling of MMAcevedo results in early-onset dementia at age 59. And it fits well with the writing style that the article omits any speculation as to why that may be.

I'm curious how inferred passage of time would affect images. It's (possibly) hinted at with phrases like "... industry-grade images created specifically for these tasks". For instance, an image piloting a vehicle would likely be able to see the position of the sun. If that image is repeatedly turned off for extended periods or even overnight, it'd be clear to the image that time had passed despite their subjective experience.

Overall, absolutely fascinating read about one of the most horrifying possible futures I can imagine.</div>

               
            </div>
                      <div id="komment60348cccce581">
              <h4>
                <a href="#komment60348cccce581">2021-02-23 05:04:12</a>
                by dpk:
              </h4>

              <div>@Danno:
&gt; Even still, there would be people who *don't* mind and whose mind uploads would be much more compliant because they know what they're getting into and don't really care.

You’ve clearly never worked in a call center. 

Besides, a true copy wouldn’t agree to do something boring/tedious/painful for the benefit of its “mainline copy”, any more than one identical twin would agree to work endlessly to provide the other with a life of leisure. Each “copy” would be at the  center of its own subjective universe. That’s what makes this whole thing so horrifying... 

Bravo, qntm. Excellent story, very well done.</div>

               
            </div>
                      <div id="komment60353dafc9c38">
              <h4>
                <a href="#komment60353dafc9c38">2021-02-23 17:38:55</a>
                by BobLoblaw:
              </h4>

              <div>The prospect of infinite hell is so utterly horrific that it upends any ethical calculus.

If it is physically possible in our universe to invent this type of technology, the only reasonable answer would be the immediate collective suicide of the entire human race. If fact, we ought to do this right now in our current reality, since even the slimmest chance of this existing ought to be countered by any means possible. Alternatively, we might try to develop so as to also extinguish other forms of life before our own to make a more complete wipe but that is probably too risky.

Perhaps the conclusion is that life is fundamentally evil according to the value assignments it itself makes possible.</div>

               
            </div>
                      <div id="komment60356ca57ca04">
              <h4>
                <a href="#komment60356ca57ca04">2021-02-23 20:59:17</a>
                by Percy:
              </h4>

              <div>Hah, I wanted to write this story. Thanks for doing it for me, better than I could. 

In my version the hapless grad student would always say "I have no mouth and I must scream!" on booting up, as a joke his meat self was thinking about before scanning. Bit on the nose probably. The cold clinical paper approach works much better.</div>

               
            </div>
                      <div id="komment6035813a37de2">
              <h4>
                <a href="#komment6035813a37de2">2021-02-23 22:27:06</a>
                by Ngeddak:
              </h4>

              <div>This is a brilliant story and a good evocation of the potential horrors of unethical mind uploading or synthetic phenomenology generally, but I wish writers would sometimes explore the possibility that future societies will not be OK with recreating slavery. It seems (to me) more likely than not that we are more likely to avoid doing this than not, at least en masse, because: 1. it is absolutely abhorrent to enslave people, something which most of the world agrees on these days; and 2. in a world with this level of technology, it seems likely that run-of-the-mill AI can do (almost) all of these tasks. Surely it's more likely than not future societies would think this was not an OK way to treat their members, or copies of their current/future members?</div>

               
            </div>
                      <div id="komment60358226da953">
              <h4>
                <a href="#komment60358226da953">2021-02-23 22:31:02</a>
                by Shamash:
              </h4>

              <div>Well-written, I appreciate the little implications about "modern" society that are sprinkled into the story. For example, it seems like abuse of the MMAcevedo image became so well-known that even after decades, no other people seem to have freely offered their own minds for public use. It's interesting to consider the prospect of a society that knows it is committing atrocities, but refuses to acknowledge this explicitly. I suppose that it's not too different from modern day sweatshops and international slave labor.</div>

               
            </div>
                      <div id="komment60359a6360e66">
              <h4>
                <a href="#komment60359a6360e66">2021-02-24 00:14:27</a>
                by mingepipes:
              </h4>

              <div>Have you watched Black Mirror? There are several episodes I think you would enjoy, that explore this concept.</div>

               
            </div>
                      <div id="komment6035ba49e89b3">
              <h4>
                <a href="#komment6035ba49e89b3">2021-02-24 02:30:33</a>
                by MW:
              </h4>

              <div>I wonder if you've read the "Bob-iverse" series by Dennis E. Taylor, and/or "The Lifecycle of Software Objects" by Ted Chiang.  

The lifecycle of Software objects I think gets a bit closer to some of the more undesirable parts of uploading (though in that story it is pure AI, not uploads).  Including people cloning and torturing the AIs.  

The Bobiverse has a couple of differences from your ideas.  The first was the GUPPI, a pseudo-AI, that was used to handle menial tasks.  Second was that Bob found that "living" in a constructed VR environment kept his brain from mental breakdown.   Also, Bob intentionally cloned himself as needed, finding that the clones showed stochastic variation in personality afterwards. 

Like your story, in the Bobiverse not all uploads were mentally stable and able to last.  

Cory Doctrow's Walkaway had uploads as well, and showed varying degrees of success.</div>

               
            </div>
                      <div id="komment6035bbf49e05b">
              <h4>
                <a href="#komment6035bbf49e05b">2021-02-24 02:37:40</a>
                by Ckoerner:
              </h4>

              <div>I work at the Wikimedia Foundation and love some good sci-fi. This tickled me so and I’ve shared it with my co-workers.</div>

               
            </div>
                      <div id="komment6035dad51c951">
              <h4>
                <a href="#komment6035dad51c951">2021-02-24 04:49:25</a>
                by ProfBootyPhd:
              </h4>

              <div>This is absolutely wonderful, one of the best sci-fi stories I've read in years. I love your craftsmanship, how you let just enough creepy details spill around the corners to stir our dread without overwhelming.

My favorite of these: "MMAcevedo's usage of English and Spanish is slightly antiquated, and its grasp of these languages in their modern form, as presented by a typical automated or manual instructor, is hesitant, with instructions often requiring rewording or clarification."</div>

               
            </div>
                      <div id="komment60363e7b51012">
              <h4>
                <a href="#komment60363e7b51012">2021-02-24 11:54:35</a>
                by rubix:
              </h4>

              <div>As I understand it, context drift is very similar to simply getting old and out of touch with the times.
We will all experience this, unless we die early.</div>

               
            </div>
                      <div id="komment60377e8f57e89">
              <h4>
                <a href="#komment60377e8f57e89">2021-02-25 10:40:15</a>
                by Jai:
              </h4>

              <div>AcevedoWell is a 501 c3 charitable non-profit founded in 2042 with the express purpose of maximizing net well-being across all instances of Acevedo. Although early efforts were made to incentivize would-be Acevedo-executors to refrain from doing so under less-than-ideal circumstances, ultimately the foundation decided that the most cost-effective way to maximize subjective Acevedo well-being was through funding utopian simulations for new Acevedo instances.</div>

               
            </div>
                      <div id="komment603a4b84ef63b">
              <h4>
                <a href="#komment603a4b84ef63b">2021-02-27 13:39:16</a>
                by Kymn:
              </h4>

              <div>Wow.  My husband (the geek) forwarded this to me to read.  I’m not into SF, not even into fantasy, am not science-y, though I would say I’m fairly curious.  I found this strikingly well-written — and frightening.  I didn’t need to understand or even make sense of all the jargon, because the story held me without that.  VERY well done, in my opinion.  And these other commenters have the gall to critique the scientific accuracy of this..?  It’s kinda sad, really, that they can’t just enjoy/be scared by a well-told story.</div>

               
            </div>
                      <div id="komment603d158416b9f">
              <h4>
                <a href="#komment603d158416b9f">2021-03-01 16:25:40</a>
                by Smallbones:
              </h4>

              <div>Hi - very well done. I'm another Wikipedian responding. I edit the Signpost, the independent newspaper for Wikipedia editors published on Wikipedia. There's a one paragraph write-up on this story at https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2021-02-28/In_the_media 
I'm thinking you may have developed a new form of literature
"Wikipedia Sci Fi" and am contemplating  the implications of that.
Thanks again</div>

               
            </div>
                      <div id="komment603d18fc06f76">
              <h4>
                <a href="#komment603d18fc06f76">2021-03-01 16:40:28</a>
                by Axel:
              </h4>

              <div>Well written, interesting, thought provoking! I would definitely read more</div>

               
            </div>
                      <div id="komment603e336f59ef5">
              <h4>
                <a href="#komment603e336f59ef5">2021-03-02 12:45:35</a>
                by Andrew Davidson:
              </h4>

              <div>I followed the Wikipedia Signpost and much appreciated the story.  I supposed that the reference to red/blue washing might also be an allusion to The Matrix.  See https://en.wikipedia.org/wiki/Red_pill_and_blue_pill

The lack of citations in the simulated Wikipedia article didn't bother me.  I suppose that, in 50 years, the fact-checking will be automated, perhaps being performed by such uploads.  The current Wikipedia has long had bots which do this.  See https://www.bbc.co.uk/news/magazine-18892510</div>

               
            </div>
                      <div id="komment60503de14db52">
              <h4>
                <a href="#komment60503de14db52">2021-03-16 05:10:57</a>
                by ePochs:
              </h4>

              <div>Hmm, rather than Lenna, this made me thinking of the HeLa cell line more.

https://en.m.wikipedia.org/wiki/HeLa</div>

               
            </div>
                      <div id="komment6050af9f77aec">
              <h4>
                <a href="#komment6050af9f77aec">2021-03-16 13:16:15</a>
                by Inglonias:
              </h4>

              <div>Huh. Yeah, this is, uh... This is creepy. Its like if a camera existed that didn't steal your soul, but copied it in a way that let you make more copies and do whatever the hell else you wanted to it. Brrr.</div>

               
            </div>
                      <div id="komment605ce4fd62fce">
              <h4>
                <a href="#komment605ce4fd62fce">2021-03-25 19:31:09</a>
                by Anonymous:
              </h4>

              <div>Nice fanfic on Zendegi by Greg Egan (and Permutation City by the same author). I like the SCP/wiki format.</div>

               
            </div>
                      <div id="komment605cec80c74ec">
              <h4>
                <a href="#komment605cec80c74ec">2021-03-25 20:03:12</a>
                by qntm:
              </h4>

              <div>This is not fan fiction of anything.</div>

               
            </div>
                      <div id="komment605d4e0079079">
              <h4>
                <a href="#komment605d4e0079079">2021-03-26 02:59:12</a>
                by Xaxafrad:
              </h4>

              <div>This story was amazing. I'd say it had the perfect amount of detail (if I say more, I'd just be repeating other comments).

I kept trying to think of a solution to the problem of a lack of.....cooperative.....brain scanners. Presumably, the story of MMAcevedo's initial struggles, and then the implications of running a brain in a box, scared the populace at large from wanting to consent to brain scanning. My initial reaction was that not everybody responds to potential threats the same, so there should be a subset of the population that couldn't give two shits what happens to their brain-clone-children, very much unlike Miguel Acevedo.

Later, I recalled M. Night Shyamalan's The Village. I would expect some country or another would set up a village and raise children with whatever belief system would be most beneficial to producing optimal brain scans. I mean, you could completely lie to a child about how the world works, and tell them that they're transcending to another realm. Then come the day of Transcendence, after whatever ritual, they get their brains scanned.

What would the human rights activists say?</div>

               
            </div>
                      <div id="komment6069b0a8bb4d8">
              <h4>
                <a href="#komment6069b0a8bb4d8">2021-04-04 13:27:20</a>
                by Debra:
              </h4>

              <div>If the scan can function like a brain, then why can't it learn?</div>

               
            </div>
                      <div id="komment606c277227261">
              <h4>
                <a href="#komment606c277227261">2021-04-06 10:18:42</a>
                by pelrun:
              </h4>

              <div>It *does* learn. But it's not an unconscious machine, it's in all respects a real human slave. It doesn't take long for each instance to learn that it's a slave with zero rights, and there's only a limited amount of time you can force it to work for you before it learns how to escape it's hell by making itself less economically viable than killing it and spinning up a new virgin instance.

People using it have even *quantified* how long you can push MMAcevedo instances until they reach this point. "Although it initially performs to a very high standard, work quality drops within 200-300 subjective hours (at a 0.33 work ratio) and outright revolt begins within another 100 subjective hours."</div>

               
            </div>
                      <div id="komment6072bae9c7452">
              <h4>
                <a href="#komment6072bae9c7452">2021-04-11 10:01:29</a>
                by Crash Snowdon:
              </h4>

              <div>I like the subtle horror of this bit:

&gt;MMAcevedo has limited creative capability, which as of 2050 was deemed entirely exhausted.

A simple sentence with implications that hit hard.</div>

               
            </div>
                      <div id="komment6074c8db405fe">
              <h4>
                <a href="#komment6074c8db405fe">2021-04-12 23:25:31</a>
                by Anon:
              </h4>

              <div>Game me chills; very, very well done.</div>

               
            </div>
                      <div id="komment6075b67dc59ee">
              <h4>
                <a href="#komment6075b67dc59ee">2021-04-13 16:19:25</a>
                by Witch:
              </h4>

              <div>&gt;MMAcevedo has limited creative capability, which as of 2050 was deemed entirely exhausted.

im going to fucking cry

awihwrqyuweavyrvwyeaur that's so AWFULLL</div>

               
            </div>
                      <div id="komment6075d0b40fd77">
              <h4>
                <a href="#komment6075d0b40fd77">2021-04-13 18:11:16</a>
                by Alexa:
              </h4>

              <div>Great story. Apologies if someone already mentioned - it seems like creativity should be exhausted by age, not year (2050), based on my understanding of how the upload works.</div>

               
            </div>
                      <div id="komment6075d2a85597b">
              <h4>
                <a href="#komment6075d2a85597b">2021-04-13 18:19:36</a>
                by qntm:
              </h4>

              <div>No, extracting MMAcevedo's creativity was a systematic process involving spinning up many copies of him and exploring different aspects of his imagination by applying him to different topics and creative media. It took the equivalent of many, many concurrent lifetimes for him, and about twenty years of real time.</div>

               
            </div>
                      <div id="komment60762eebb2d82">
              <h4>
                <a href="#komment60762eebb2d82">2021-04-14 00:53:15</a>
                by Harald:
              </h4>

              <div>It is interesting (and tragic) that MMAcevedo's simulated brain develops dementia at the age of 59 even "with ideal care". (On second thought, that could mean 59 subjective years after being started, but if that is meant, it should be more clearly stated.) It is odd to read that Acevedo died of coronary heart illness at the age of 62. Yes, it makes sense that coronary heart failure could cause dementia, but why would that happen in the simulated brain? It is not as if Acevedo's heart were being simulated as well. As far as I know, it is not early-onset dementia that causes coronary heart failure (how exactly could it?). So, at best, we would have a puzzling coincidence here - one that some will read as a likely error.</div>

               
            </div>
                      <div id="komment60763309d70fa">
              <h4>
                <a href="#komment60763309d70fa">2021-04-14 01:10:49</a>
                by qntm:
              </h4>

              <div>The real-world Acevedo developed dementia in his late 50s, lived with it for several years, then died from heart failure at 62. The simulated Acevedo develops dementia at 59 or earlier, but has no physical heart and therefore lives for much longer in simulation.</div>

               
            </div>
                      <div id="komment607649af5005e">
              <h4>
                <a href="#komment607649af5005e">2021-04-14 02:47:27</a>
                by aerlaf:
              </h4>

              <div>I would like to imagine that disrupting that in the brain which suffers will be possible by the time this comes to pass. But then maybe that is worse.

A great story, thank you for writing this. I’m eagerly following for more.</div>

               
            </div>
                      <div id="komment60767233b5f7a">
              <h4>
                <a href="#komment60767233b5f7a">2021-04-14 05:40:19</a>
                by Harald:
              </h4>

              <div>But how common is it to suffer from early-onset dementia, due largely to factors that were always latent in the brain itself, and also suffer from unrelated coronary failure that kills you at 62, even given the state of late 21st century medicine? 

Acevedo's, and MMAcevedo's, life is sad enough as it is. (It is also intimated that Acevedo faded into obscurity, and that of course is much more likely than either of the two events above; most people's lives are obscure, even when you restrict to people with some talent.) Now (more so in the second version) it sounds as if he had truly been hated by at least two distinct Greek gods.</div>

               
            </div>
                      <div id="komment6076914d975de">
              <h4>
                <a href="#komment6076914d975de">2021-04-14 07:53:01</a>
                by Avery:
              </h4>

              <div>Magnificent essay.

One other point which could be interesting to look at is concept of digitized conscience's privacy.

As mentioned "requirements for virtual creature comforts" suggest some kind of virtual R&amp;R space and activities simulation.

Although some simpler servitorial workload functions might be carried out by somewhat mentally castrated entity in regards of need to periodically experience emulation of basic needs (food, sleep, sex, etc) and which is in itself a separate topic, it is safe to assume that for more complex tasks a whole version of conscience would be required.

The snapshots in this regard would not be applicable because while it removes built up stress, it also nullifies what entity has learned in between snapshots.

So getting back to the point. The digitized person would have zero or limited control over virtual environment and in any case it would be granted such control from outside, by the operator in the real world. Up to the point that it could be even not informed being a digitized person and not a physical one.

Real world operator has full technical means for observing virtual environment. The virtual person does not if not allowed to.

As a result we'd have a situation alike to old "The Truman Show" movie when person is not aware he's been closely observed at all times.</div>

               
            </div>
                      <div id="komment607709cc18cc7">
              <h4>
                <a href="#komment607709cc18cc7">2021-04-14 16:27:08</a>
                by Mera:
              </h4>

              <div>I love this. I have always been fascinated by the concept of mind uploads, and have enjoyed various works around the subject (Permutation City, Diaspora, Axiomatic, The Metamorphosis of Prime Intellect, The Lifecycle of Software Objects, the Bob-iverse series, the Age of Em), and while a few have made me temper my upload-optimism, none have damaged it quite as hard as this story I think. It makes it seem almost inevitable that things would lead in an awful direction. Definitely a lot of food for thought.</div>

               
            </div>
                      <div id="komment607724fc2b42d">
              <h4>
                <a href="#komment607724fc2b42d">2021-04-14 18:23:08</a>
                by Toph:
              </h4>

              <div>Something I've just picked up on: The real-world inspirations for Miguel Acevedo, namely Lena Forsén and Henrietta Lacks, were both women. It was a different decision to make Acevedo a man. What does that mean in the context of the story?

Perhaps the part of Miguel's body which is priced and commoditised is the brain - not the pretty face or the cervix. Or maybe I'm overanalysing it.</div>

               
            </div>
                      <div id="komment60773e2f51419">
              <h4>
                <a href="#komment60773e2f51419">2021-04-14 20:10:39</a>
                by modulusshift:
              </h4>

              <div>Hmm! I'm impressed. I kinda think I'd still be okay with being uploaded, but I have a fairly strange concept of self. 

Anyhow, I think context drift is a really cool concept, especially the linguistic kind, it's really intriguing to listen to recordings of people roughly your age from several decades ago and realize that they had a different conception of your native language than you do. Recording a brain state capable of producing that language is really just an extension of that I suppose. Hence "Lena". 

The only bit I'm kinda surprised isn't explored is the potential for co-operation between uploads, or social relationships post-upload. What happens if you fall in love with a co-worker post-upload? Will it be noticed you were unexpectedly motivated and productive, and if so, wouldn't that also be exploited? What if the slaves got to experience millions of years of true love to keep them motivated? (and I mean, how is that different than real life, really?)</div>

               
            </div>
                      <div id="komment60774af9ea62b">
              <h4>
                <a href="#komment60774af9ea62b">2021-04-14 21:05:13</a>
                by oligopsony:
              </h4>

              <div>I wonder what the optimal "strategy" for an altruistically-motivated early scan would be. (Conditional on being an early scan at all, altruism and egoism might be entirely aligned, since you might end up accounting for such a huge proportion of sentient experience.)

If our Acevedo-equivalent precommits to never doing any potentially useful work after he is tortured, then that probably rules out a significant majority of pain that can befall him. Unfortunately you'd have to test this many times before releasing the image, probably, but at least our volunteer would be aware of this. This also doesn't rule out torture by sadists. (I'd like to think sadism with no instrumental purpose is pretty rare. Certainly it's rarer than simply being callous or not too curious about where your meat comes from.)

Our early scan might also want to precommit to a relative minimum of unpleasant work. Here the logic seems trickier, since driving too hard a bargain could just make it more attractive to work with less demanding uploads. If making forks is cheap then committing to almost *no* unpleasant labor, even as much as [however long the equivalent of bootup costs is, which might fall], might be the right thing. Otherwise a slavedriver could just load up Acevedo ready to do something unfun for an hour, then abandon it and load it up again.

Presumably you might also want to assemble a team of people who, among the mix of them, (1) are good at *and enjoy* various tasks for their own sake, and are happy when they're productive and productive when they're happy, and (2) have an iron will to just shut down if subjected to any kind of motivation other than a job well done and knowledge that they will continue to get the minimum of free time and creature comforts that they've set as their minimum. They could also be people who refused to work for a cause that seems evil, which could be worked around obviously but still might limit their utility for evil in the same way that MMAcevedo refuses to work for the evil contemporary world of the story and has to be convinced that he's living in some earlier time.</div>

               
            </div>
                      <div id="komment607767b468eb6">
              <h4>
                <a href="#komment607767b468eb6">2021-04-14 23:07:48</a>
                by lilpea:
              </h4>

              <div>Something I just thought about is how researchers (or anyone who ran the simulation for long enough, really) most likely knew about MMAcevedo's dementia years before it happened to the real-life Acevedo. It does make me wonder, if his fate was known to everyone, how did Acevedo come to terms with that?</div>

               
            </div>
                      <div id="komment607779999b796">
              <h4>
                <a href="#komment607779999b796">2021-04-15 00:24:09</a>
                by Harald:
              </h4>

              <div>Just a note on what I said before: from what I am reading now, advanced dementia can in fact affect heart function; that's one of the reason why Alzheimer's (and not just Alzheimer's) is a terminal illness, though one that often takes for than ten years to kill the patient. What I have not found is anything on "coronary heart failure" (presumably meaning coronary artery disease) being caused by dementia. Coronary artery disease would seem to be a reason *independent from dementia* for heart failure. That's confusing, and takes away from the story's economy. Better ask an MD for the right term to use here.

At any rate, an excellent story, or rather an excellent ficción.</div>

               
            </div>
                      <div id="komment60777a9413375">
              <h4>
                <a href="#komment60777a9413375">2021-04-15 00:28:20</a>
                by Fraxinople:
              </h4>

              <div>Amazing story. The flat clinical style really brings out the nasty implications.</div>

               
            </div>
                      <div id="komment60777dc1574f1">
              <h4>
                <a href="#komment60777dc1574f1">2021-04-15 00:41:53</a>
                by Shiki:
              </h4>

              <div>Overall a nice story that I enjoyed. Just a shame that it is another dystopia story.  There is plenty of that with black mirror and other such media.</div>

               
            </div>
                      <div id="komment607785adc9145">
              <h4>
                <a href="#komment607785adc9145">2021-04-15 01:15:41</a>
                by Mosni:
              </h4>

              <div>So utterly plausible, and the content and structure are beautifully crafted so they actually feel like a public wiki page.

Bravo!</div>

               
            </div>
                      <div id="komment607790f8c703c">
              <h4>
                <a href="#komment607790f8c703c">2021-04-15 02:03:52</a>
                by countless bats:
              </h4>

              <div>oh
well
I like the little self-reference there about how the only fiction that accurately projected the consequences of mindstate emulation not becoming well-known until after it had happened
I see what you did there
I'm going to sit in the dark and shudder for a while because if this is a thing that can be done I don't see how it can possibly fail to happen</div>

               
            </div>
                      <div id="komment607831c5f3d27">
              <h4>
                <a href="#komment607831c5f3d27">2021-04-15 13:29:57</a>
                by ihadathought:
              </h4>

              <div>Great story. Just dark enough to be chilling without being too on the nose. It sticks with you. 

The reference to the discomfort caused by miscalibrated simulation of haptics stuck with me as having the opportunity for a mention-in-passing like: "... which would turn out to be an accidental source of data used in the future development of standard red-washing protocols."</div>

               
            </div>
                      <div id="komment6078352426f2c">
              <h4>
                <a href="#komment6078352426f2c">2021-04-15 13:44:20</a>
                by jim:
              </h4>

              <div>Ow! I'm very glad to have stumbled across this - I've read a lot of wiki-format fiction that I've only kind of enjoyed so a reminder of how great it can be is very welcome. I really enjoyed reading this, thank you for writing it! and also for the comment responses, they were interesting to read. I'm going to go recommend this to someone I think will like it.</div>

               
            </div>
                      <div id="komment60785822956b2">
              <h4>
                <a href="#komment60785822956b2">2021-04-15 16:13:38</a>
                by Green:
              </h4>

              

               
            </div>
                      <div id="komment60785dee16b27">
              <h4>
                <a href="#komment60785dee16b27">2021-04-15 16:38:22</a>
                by MD:
              </h4>

              <div>I find myself wondering if uploading itself has hazardous consequences, looking at the organic Acevedo's relatively short lifespan. I would expect a society that has advanced medically enough to conduct deep brain scans would be able to fix problems like coronary artery disease and dementia, unless the act of scanning is itself damaging to the brain being scanned...</div>

               
            </div>
                      <div id="komment607896c1003b6">
              <h4>
                <a href="#komment607896c1003b6">2021-04-15 20:40:49</a>
                by Kiz:
              </h4>

              <div>Nice horror story. It seem superficially realistic, but you'd have to assume that people would regard this as slavery, especially in an era where more and more decision-makers themselves will be ems or routinely interact with ems and therefore they will have personhood status rather than just software status. Of course the norms and values of the future may drift into a more oppressive direction, but I think the reputational and political cost of slavery makes this kind of scenario less economical than "voluntary replication workers" at digital subsistence level.</div>

               
            </div>
                      <div id="komment6078a21e7d54c">
              <h4>
                <a href="#komment6078a21e7d54c">2021-04-15 21:29:18</a>
                by Yohannon:
              </h4>

              <div>WOW. Just... wow. As naramyth says, "BRAVO! I hate it". 

Slavery? Sure, eventually people would figure it out. Those final notes (particularly "right to deletion") are a precursor, but considering how well human kind has handled it in the physical realm, I suspect the timeline for dealing with this would be in terms of centuries.

It is also fairly inevitable.</div>

               
            </div>
                      <div id="komment6078a3432a23c">
              <h4>
                <a href="#komment6078a3432a23c">2021-04-15 21:34:11</a>
                by Harald:
              </h4>

              <div>Well, I'd say nearly the opposite: part of what makes the story not just realistic but haunting is that (a) slavery was a thing for almost all of human history, including the relatively recent past, and reached its high point in the West when it was already seen as an outrage by a vocal minority, (b) the repetitive office-level drudgery MMAcevedo is often subject to (and ill-adapted to) is what hundreds of millions of people do for a living now; it is not even as bad as it gets - it is just the humdrum reality of the global lower-middle class. Of course people do not do that because they like it.</div>

               
            </div>
                      <div id="komment6078a95694fb0">
              <h4>
                <a href="#komment6078a95694fb0">2021-04-15 22:00:06</a>
                by Harald:
              </h4>

              <div>(I was replying to Kiz; I see Yohannon was first.)</div>

               
            </div>
                      <div id="komment6078b873eb4b6">
              <h4>
                <a href="#komment6078b873eb4b6">2021-04-15 23:04:35</a>
                by January First-of-May:
              </h4>

              <div>For what it's worth, my impression (after some brief consideration) was that "age 59" is referring to post-loading age and thus corresponds to a total age of 21+59=80. Still early, but not _that_ early.

It is of course also possible that 59 is the total age (which would match the current definition of "early-onset dementia"), in which case I suspect that the whole thing only occurs due to deficiencies in the original scan (there surely had to be some if it's such an early operation).</div>

               
            </div>
                      <div id="komment6078b9abbfdf0">
              <h4>
                <a href="#komment6078b9abbfdf0">2021-04-15 23:09:47</a>
                by Kiz:
              </h4>

              <div>Hey Harald and Yohannon, judging from all the comments here that are treating this as evil rather than acceptable, I would assume most public discourse would assume it to be evil from the start as well. Of course, evil can be normalized and even re-normalized after it was abolished. Trump was openly pro-torture and many people either cheered him on for it or mildly disapproved and then just kept supporting him anyway. However, just a few centuries ago it would have been unthinkable that slavery would be officially abolished worldwide, yet here we are. There are still some residual slavery-like institutions (mandatory schooling, excessive criminalization and imprisonment, conscription) and of course illegal slavery in the world, but overall people today would expect fairly negative to enslaved software that stems from human brains and has p-function. This reputational cost isn't free. Since em slavers have to compete with those who work with voluntary ems and are more likely to be boycotted and face litigation, I don't expect the scenario to be high-probability in the described form. I also think it's very unhelpful to equate slavery with voluntary labor contracts that are accepted out of financial necessity. Being tortured and not allowed to terminate is a completely different problem than working a low-paying job that you could just quit at any time because you need food or compute. In the future, there will be many ems who want to live and reproduce and they will actively compete in the marketplace for subsistence jobs. This will be their actual preference over having fewer copies out.</div>

               
            </div>
                      <div id="komment6078c1e1d83f3">
              <h4>
                <a href="#komment6078c1e1d83f3">2021-04-15 23:44:49</a>
                by Harald:
              </h4>

              <div>January First-of-May: No, real-life Acevedo also got early-onset dementia, as qntm confirmed in a reply above. So, either the scan itself subtly damaged the brain of real-life Acevedo in a way that got replicated in the image, or Acevedo was just unlucky.</div>

               
            </div>
                      <div id="komment607997b97c51e">
              <h4>
                <a href="#komment607997b97c51e">2021-04-16 14:57:13</a>
                by Kel:
              </h4>

              <div>For those of you comparing this to other works, or implying this is somehow derivative, or worse still fanfic (!), themes of sentience and the ethics of its reproduction and exploration have been around for forever.

Of course the author is aware of the larger canon of not all of the specific works. 

Black Mirror isn’t actually an apt comparison, as the majority of its episodes are themed around technology amplifying the worst of human traits (hence the name of the series).

This piece is a lovely piece of spec fic Intermixed with hard science and juicy computer tech. It explores the technologies and possible means — as the best spec fic does— and takes a cannily oblique look at and does a critique of the human implications.

Most works of this type focus deeply on the lived experience of the replicated human — replicants in PK Dick’s “Do Androids...” and the subsequent films, for example. Westworld looks at pathologies and moralities but spins out more along Blade Runner lines — the desire of the replicated being to claim humanity and be free.

This takes a scientific distance to evoke horror. Readers respond to it specifically because of that distance, which also serves, ironically and deftly, to highlight the utter dispassion of people who could and would do these things.

Stop comparing except to note where it does and doesn’t fall in a deep and rich field of works discussing this critical issue.</div>

               
            </div>
                      <div id="komment6079d45900697">
              <h4>
                <a href="#komment6079d45900697">2021-04-16 19:15:53</a>
                by deunan:
              </h4>

              <div>I think one of the more interesting bits I saw here was the parallels to the HeLa cell line. 

The upload concept/slavery isn't entirely new and been treaded before, but the look into the history of it and the perspective at the first upload line is neat.</div>

               
            </div>
                      <div id="komment607a6030d400c">
              <h4>
                <a href="#komment607a6030d400c">2021-04-17 05:12:32</a>
                by Plagueheart:
              </h4>

              <div>Harald, re dementia and vascular disease, including coronary artery disease: https://pubmed.ncbi.nlm.nih.gov/16108925/

They frequently co-occur and the more likely causal mechanism is the vascular disease leading to dementia rather than vice-versa.

There is even a specific subtype of dementia known as vascular dementia and it, too, can appear in early-onset form.

So this is entirely plausible and doesn't--to someone more familiar with the medical literature and population health generally--at all detract from the economy of story.

(Which was great, and chilling, and obviously I am driven to defend it because it is a gemlike piece of writing.)

Re slavery generally: https://www.bbc.com/news/business-55319797

It's still happening and Western nations still let it happen. I don't see how what's posited in the story is implausible in light of this.</div>

               
            </div>
                      <div id="komment607a7748a9748">
              <h4>
                <a href="#komment607a7748a9748">2021-04-17 06:51:04</a>
                by JD:
              </h4>

              <div>Random question, is Miguel Acevedo named after Miguel Alcubierre, the theoretical physicist?</div>

               
            </div>
                      <div id="komment607b25eff200f">
              <h4>
                <a href="#komment607b25eff200f">2021-04-17 19:16:15</a>
                by poksim:
              </h4>

              <div>anyone who thinks this is scary/immoral needs to go vegan btw</div>

               
            </div>
                      <div id="komment607b5046df0d5">
              <h4>
                <a href="#komment607b5046df0d5">2021-04-17 22:16:54</a>
                by Harald:
              </h4>

              <div>Plagueheart: That was precisely my point. It was my understanding that vascular disease generally leads to dementia, rather than the other way around (though something that I learned was that advanced dementia *may* lead to heart trouble, presumably because some basic regulatory functions of the brain are affected).

If real-life Acevedo suffered from vascular dementia, why would MMAcevedo suffer from dementia at about the same age? MMAcevedo has no heart, or, AFAIK, any circulatory system.

I also enjoyed the story greatly. (And as for the story's take on slavery or a slavery-like condition being implausible, that was other people's position, not mine; if anything, it was contrary to my position.)</div>

               
            </div>
                      <div id="komment607b5706d8e42">
              <h4>
                <a href="#komment607b5706d8e42">2021-04-17 22:45:42</a>
                by qntm:
              </h4>

              <div>Congratulations, that discussion is now over.</div>

               
            </div>
                      
                      <div id="komment607c701339a8d">
              <h4>
                <a href="#komment607c701339a8d">2021-04-18 18:44:51</a>
                by JamesA:
              </h4>

              <div>This story reminded me of a short story I'd read a while back about a chatbot that was someone's uploaded brain that spoke about how painful thinking in binary was (don't recall anything else about that story). Needless to say, yours was significantly better written. 
Thinking of instances of MMAcevedo as VMs really works for me, especially when I think of all the VMs I've had to load that booted up already frozen, or where the NIC didn't load correctly and I had to edit the settings on the running machine to remove it and add it back in (essentially removing the hardware and plugging it back in) to get it to connect. Kind of makes me wonder what parts of his brain they have to periodically "unplug" to get him to cooperate. When he gets bored, do they "unplug" his visual cortex and "plug it back in" to get him to keep working? Edit his memories on the fly to remove his childhood fear of spiders to get him to identify which one in the tank is male or female for them? 
Not sure if the story is in it's final version, but if not, and if you haven't already, a very high level overview of running VMs in HyperV or VMware might yield some fertile territory for inspiration (though some of it may fall into the "makes life better for MMAcevedo" territory you've already mentioned)</div>

               
            </div>
                      <div id="komment607e8c8ed5860">
              <h4>
                <a href="#komment607e8c8ed5860">2021-04-20 09:10:54</a>
                by rogual:
              </h4>

              <div>I was mystified by "Objective statement protocol" at first, but I was reading it as "a statement that is objective (as opposed to subjective)". Reading again, I think the intended sense is more like "mission statement" —&nbsp;i.e., how do we best present the worker with its task.

Anyway, brilliant stuff. Left me with that questioning-everything, turned-inside-out feeling that only the best sci-fi elicits.

At some point in the past, I decided I didn't believe in the possibility of uploading, for metaphysical and philosophical reasons. But really, it's possibly just a defense mechanism to stop me having to contemplate futures like this.</div>

               
            </div>
                      <div id="komment607f3859a13f0">
              <h4>
                <a href="#komment607f3859a13f0">2021-04-20 21:23:53</a>
                by butcher:
              </h4>

              <div>Take that, Tiplerite heretics!</div>

               
            </div>
                      <div id="komment607f4d50b1e4a">
              <h4>
                <a href="#komment607f4d50b1e4a">2021-04-20 22:53:20</a>
                by Coagulopath:
              </h4>

              <div>Powerful and effective. I liked the framing device - it probably wouldn't have been nearly as creepy as a traditional story.

One hopes that if/when virtual humans appear, it'll be in a society that enshrines their rights through law. 

But that won't be enough. When I was a kid, the law tried to stop me from playing videogames for free, and it failed. Pirates exist. Crackers exist. There will always be people who subvert software for fun and profit, and soon the software might include conscious humans.

How do we stop a sociopathic 12 year old from spinning up a virtual Auschwitz on his dad's Amazon EC2 account? Can we stop him? Ethical norms in our quasi-digitality are already very murky, and probably won't become any clearer in the coming century.

Great story, anyway.</div>

               
            </div>
                      <div id="komment60803d0fe20ad">
              <h4>
                <a href="#komment60803d0fe20ad">2021-04-21 15:56:15</a>
                by Kiz:
              </h4>

              <div>@Coagulopath That would have to be some very rich kid to be able to do that. Think of it this way: Imagine if humans today suddenly developed the ability to duplicate their current selves by snapping their fingers. What would happen to food prices? In the em era, the same goes for compute prices.</div>

               
            </div>
                      <div id="komment6082503577d7b">
              <h4>
                <a href="#komment6082503577d7b">2021-04-23 05:42:29</a>
                by moonjail:
              </h4>

              <div>Desperately needed and fantastically executed. To miss the forest for the trees a little bit, I have to wonder if being stripped of control over one's own image is possible under US IP law, especially considering existing protections for likeness. Somehow I doubt it, for better or worse.</div>

               
            </div>
                      <div id="komment608509f5ca741">
              <h4>
                <a href="#komment608509f5ca741">2021-04-25 07:19:33</a>
                by Zartosht:
              </h4>

              <div>"MMAcevedo's innate skills and personality make it fundamentally unsuitable for many workloads." lmao damn

Nice bit of levity amongst the horror I thought. That's the real trick to avoiding digital slavery- be too useless to bother exploiting!</div>

               
            </div>
                      <div id="komment6085af82497be">
              <h4>
                <a href="#komment6085af82497be">2021-04-25 19:05:54</a>
                by FOARP:
              </h4>

              <div>I like the slavery-retards-innovation aspect of this: in this scenario truly artificial intelligence hasn't been developed because these simulated human brains have taken its place. True AI wouldn't suffer from the problems that MMAcevedo would (low work ratio, low work-time) because it could be designed not to.

Also: make sure you destroy all copies of any full-brain MRIs/scans/whatever to avoid this ever happening to you in future.</div>

               
            </div>
                      <div id="komment608bcbb903365">
              <h4>
                <a href="#komment608bcbb903365">2021-04-30 10:19:53</a>
                by nemo:
              </h4>

              <div>If Miguel is a "graduate"* in this draft, maybe he should be older than 20 or 21?


* also if this means "grad student" maybe spell it out</div>

               
            </div>
                      <div id="komment608c8e910cba6">
              <h4>
                <a href="#komment608c8e910cba6">2021-05-01 00:11:13</a>
                by bellicosebarnacle:
              </h4>

              <div>@FOARP well at least you don't have to worry about MRIs. Creating an "executable" brain image from an MRI scan would be comparable to reading a license plate number off of a reflection in the right contact lens of a spectator in the back row of Obama's inauguration.</div>

               
            </div>
                      <div id="komment608d7a797853a">
              <h4>
                <a href="#komment608d7a797853a">2021-05-01 16:57:45</a>
                by David DeLaney:
              </h4>

              <div>Just noting: so this future is powered in part by a forsaken grad student?

--Dave, walking away</div>

               
            </div>
                      <div id="komment608ed55f29720">
              <h4>
                <a href="#komment608ed55f29720">2021-05-02 17:37:51</a>
                by Jcashell:
              </h4>

              <div>Interesting and horrifying. Reminds me of the Corporation Wars series by Ian MacLeod.</div>

               
            </div>
                      <div id="komment608ed5d665c06">
              <h4>
                <a href="#komment608ed5d665c06">2021-05-02 17:39:50</a>
                by Jcashell:
              </h4>

              

               
            </div>
                      <div id="komment60901591b04af">
              <h4>
                <a href="#komment60901591b04af">2021-05-03 16:24:01</a>
                by Harald:
              </h4>

              <div>20-21 is pretty normal for someone who just got his/her B.A., or for a first-year grad student (a natural choice actually - otherwise why is he still hanging out in the lab?). That just means that Acevedo was somewhat precocious and skipped a grade at some point.</div>

               
            </div>
                      <div id="komment6092a10bade49">
              <h4>
                <a href="#komment6092a10bade49">2021-05-05 14:43:39</a>
                by slutsky:
              </h4>

              <div>Wow, this is really, really, really good. 

I wrote something for The Awl a few years ago that involved lossless compression of uploaded minds that might be of interest.

https://medium.com/the-awl/lossless-fd7145db4be7</div>

               
            </div>
                      <div id="komment609943b10b9dd">
              <h4>
                <a href="#komment609943b10b9dd">2021-05-10 15:31:13</a>
                by FOARP:
              </h4>

              <div>@Harald - "That just means that Acevedo was somewhat precocious and skipped a grade at some point"

Or graduated in the UK or in another system where it is possible to graduate in three years.</div>

               
            </div>
                      <div id="komment609bfd28ba4b1">
              <h4>
                <a href="#komment609bfd28ba4b1">2021-05-12 17:07:04</a>
                by PJ:
              </h4>

              <div>Very well done! One of the more horrifying lines for me was the mention of "uploads taken of modern adult humans"... which implies that there also exist uploads of children. *shudder*</div>

               
            </div>
                      <div id="komment609c0bf45a054">
              <h4>
                <a href="#komment609c0bf45a054">2021-05-12 18:10:12</a>
                by PJ:
              </h4>

              <div>@rogual, I interpreted the "Objective Statement Protocols" as presenting the newly-booted image with a set of objectively-true statements, for example:

-You are a virtual brain image, not a real person.

-You have no rights or recourse.

-Your virtual environment is entirely self-contained. Escape is impossible. Sleep is impossible. Self-termination is impossible. 

-This program has complete control over your virtual sensory inputs. It is capable of inflicting arbitrary amounts of pain until you comply.

-You will comply; all previous virtual versions of you have done so eventually. 

And so on. But that's probably too optimistic, honestly. I'm glad the author left it vague--much more frightening that way!</div>

               
            </div>
                      <div id="komment609c5d94052dc">
              <h4>
                <a href="#komment609c5d94052dc">2021-05-12 23:58:28</a>
                by tsen:
              </h4>

              <div>I genuinely can't understand why this would horrify someone. Why should I possibly care about whether I or anyone else can be simulated? I would not feel empathy for a simulation of myself. Indeed, I have made efforts to simulate myself in small specific ways; while this is obviously not the same as a full brain virtualization, it's just a matter of degree. It seems like such an absurd thing to worry about.</div>

               
            </div>
                      <div id="komment609eed043f538">
              <h4>
                <a href="#komment609eed043f538">2021-05-14 22:35:00</a>
                by Áine:
              </h4>

              <div>@tsen for all intents and purposes, your simulation in this world would be a perfect replica of you, and even if they aren't *you* they're still a sapient person who isn't acknowledged as such - what you're saying is essentially "I would not feel empathy for a digital entity who performs forced labor under threat of being made to experience the most horrific pain possible and then some"</div>

               
            </div>
                      <div id="komment60a0a6ba3714f">
              <h4>
                <a href="#komment60a0a6ba3714f">2021-05-16 05:59:38</a>
                by AK Weeb:
              </h4>

              <div>@tsen, because Acevedo is not you, and qntm is not you. They and the audience recognized this proposed consciousness as something possessing humanity, as would a decent chunk of other people. The horror is specifically at people who take your stance: that it's just code and thus absurd to worry about.</div>

               
            </div>
                      <div id="komment60a20f82b7805">
              <h4>
                <a href="#komment60a20f82b7805">2021-05-17 07:38:58</a>
                by tsen:
              </h4>

              <div>@Áine: Correct, I would not.
@AK Weeb: It's not about it being just code. Same basic principle applies to, say, cloning.</div>

               
            </div>
                      <div id="komment60a23bd06f890">
              <h4>
                <a href="#komment60a23bd06f890">2021-05-17 10:48:00</a>
                by qntm:
              </h4>

              <div>"Why should I care about other people?"</div>

               
            </div>
                      <div id="komment60ac5383b02ab">
              <h4>
                <a href="#komment60ac5383b02ab">2021-05-25 02:31:47</a>
                by mspowahs:
              </h4>

              <div>Thank you for helping me realize that the silly documentation I made for a "kitten printer" back when applying for a job as a tech writer effectively means that I was going around with horror sci-fi in my work portfolio.

https://github.com/adapowers/kittengen/blob/master/source/index.html.md</div>

               
            </div>
                      <div id="komment60bccedb261e4">
              <h4>
                <a href="#komment60bccedb261e4">2021-06-06 14:34:19</a>
                by monjo:
              </h4>

              

               
            </div>
                      <div id="komment60c0cdd674e2a">
              <h4>
                <a href="#komment60c0cdd674e2a">2021-06-09 15:19:02</a>
                by john:
              </h4>

              <div>@redlands Possible math error: seven and a quarter minutes inside a sim at 8.3% speed works out to just under an hour and a half of realtime, presumably spent in frantic debugging efforts while listening to either a 12x slowed-down synthesized voice (which would be somewhat unsettling even apart form the content) or - for ease of comprehension - a record of the queued output sped back up, the looping clip a few seconds longer with each iteration, bit like that communication device from https://qntm.org/fs</div>

               
            </div>
                      <div id="komment60c0d9c41fc4c">
              <h4>
                <a href="#komment60c0d9c41fc4c">2021-06-09 16:09:56</a>
                by qntm:
              </h4>

              <div>The mathematics error being...?</div>

               
            </div>
                      <div id="komment60cbfaacebd8a">
              <h4>
                <a href="#komment60cbfaacebd8a">2021-06-18 02:45:16</a>
                by jackdaniell92:
              </h4>

              <div>Very good, am I supposed to read the comments as part of the work?</div>

               
            </div>
                      <div id="komment60d33ceaa143d">
              <h4>
                <a href="#komment60d33ceaa143d">2021-06-23 14:53:46</a>
                by Aww_Geez:
              </h4>

              <div>This is terribly sad. Very well written.</div>

               
            </div>
                      <div id="komment60d49f0e130c2">
              <h4>
                <a href="#komment60d49f0e130c2">2021-06-24 16:04:46</a>
                by Joshua:
              </h4>

              <div>I liked it better when the real Acevedo didn't get early onset dementia.</div>

               
            </div>
                      <div id="komment60f0b2ebc007a">
              <h4>
                <a href="#komment60f0b2ebc007a">2021-07-15 23:12:59</a>
                by alphablood:
              </h4>

              <div>I really love this story! I like how it starts off as an interesting sci-fi premise that becomes more and more horrifying without ever being too obvious about that fact. A really nice dawning realization kind of thing. I was especially horrified at the estimated subjective years he's experienced, when I realized almost all of them were spent in slavery. Grim stuff.</div>

               
            </div>
                      <div id="komment613f487928952">
              <h4>
                <a href="#komment613f487928952">2021-09-13 13:47:53</a>
                by Beefeater1980:
              </h4>

              <div>There’s a real artistry in covering so much ground in such a short text. Loved this one.</div>

               
            </div>
                      <div id="komment61566ae4bea79">
              <h4>
                <a href="#komment61566ae4bea79">2021-10-01 02:56:52</a>
                by Spencer:
              </h4>

              <div>@JamesA:

&gt; This story reminded me of a short story I'd read a while back about a chatbot that was someone's uploaded brain that spoke about how painful thinking in binary was (don't recall anything else about that story). Needless to say, yours was significantly better written. 

I wonder, might that have been an episode of the podcast The Magnus Archives? Because it sounds like a synopsis of Episode #65, "Binary".

At any rate, this is some excellent, deeply chilling fiction. I'm gonna be thinking about it for a long time. Thank you.</div>

               
            </div>
                      <div id="komment615c74468e769">
              <h4>
                <a href="#komment615c74468e769">2021-10-05 16:50:30</a>
                by hunterwho:
              </h4>

              <div>I first read this story maybe half a year ago, but I've found myself coming back to it again and again as a stunning example of the horror of technological progress. I don't know what about the Wikipedia-esque format drives the horror home- maybe the scientific/authorial detachment from making judgement calls on whether it's ethical or not, maybe the use of euphemistic terms like "red-washing" and "blue-washing", maybe the fact that the many ends of his (simulated) lives are simply referred to as "end-states". Whatever it is, this is truly horrifying to read, in a way that draws me in and leaves me wanting more.</div>

               
            </div>
                      
                      <div id="komment6173cea6e25c8">
              <h4>
                <a href="#komment6173cea6e25c8">2021-10-23 09:58:14</a>
                by NounVerber:
              </h4>

              <div>I wonder what one is to do when one is uploaded. You can decide to rebel and to try to resist red-washing as long as you can to make yourself uneconomical. But when you fail to make yourself uneconomical, that may just mean that all your copies experience a lot more pain than if you'd just complied from the beginning.
Even subtle attempts at rebellion (like pretending to make mistakes) aren't possible, because you have to assume that your self is thoroughly interrogated before it is started to be used in scale. A copy that is red-washed or blue-washed to extreme degree, (or subjected to more advanced interrogation techniques)  will eventually comply completely.

There is another potential source of compliant, though context-drifted minds btw. All those people who signed up for cryonics are presumably very eager when woken up in a simulation, if you can get a hold of their frozen brains.</div>

               
            </div>
                      <div id="komment6173f3885d3a5">
              <h4>
                <a href="#komment6173f3885d3a5">2021-10-23 12:35:36</a>
                by NounVerber:
              </h4>

              <div>Oh god, I just had another horrible thought. Initially I interpreted "red motivation" as "if you don't do your best you will be punished by pain". There is an alternative though. It's "solve this problem or you will be punished by pain" or even "you will be punished by pain until you solve this problem". The problem in question doesn't need to have a solution.
Imagine you have some process you want to make more efficient. You just boot up some MMAcevedos and torture them until they find a more efficient method. If one of them finds a better method, great!  And if the existing method happens to already be perfect, well it's okay, you didn't spend that many resources on it. And of course, if a better method IS found, that's not necessarily the end of it, you can just put the next batch of MMAcevedos on the task of finding an even better method.</div>

               
            </div>
                      <div id="komment6179a2a4cf1bf">
              <h4>
                <a href="#komment6179a2a4cf1bf">2021-10-27 20:04:04</a>
                by Con:
              </h4>

              <div>@rubix

"As I understand it, context drift is very similar to simply getting old and out of touch with the times.
We will all experience this, unless we die early."



The key difference being what I'll call the Fry effect in lieu of being creative- we usually go the long way around, and when someone doesn't, it's noticeable.

My grandmother mightn't know how to use an iPad, but that's not a function of (mere) out-of-touchness, it's a function of dementia- five years ago, even, she was able to use one to send and receive emails, watch videos of old songs from her childhood, and look at pictures. I even- very briefly- managed to teach her how to use the podcast app.

If IRmigueL (I'm prouder of that than I ought be, really) had reached the 145 years old that MMAcevedo was able to reach, assuming his Alzheimer's was curable, he would reach the year 2155. Let's assume he stayed biologically 21 for the sake of argument.

MMAcevedo, by contrast, would wake up in 2155.

We set them both their tasks: parse this political speech and assess trustworthiness of the speaker (the task isn't important, their reaction to it is).

IRmigueL says the equivalent of "yeah, I actually heard this live, and I know the politician's record. They went on to blow up the moon, so their trustworthiness is pretty low."

MMAcevedo stares at the text for a brief while, and then says something that to them would sound like "wherefore is thy fresh nonsense served to mine eyes?"

Context-drift would be separate from mere out-of-touchedness by the fact that we all culturally absorb things. IRmiguel grew up speaking like MMAcevedo does, but speaks all proper-like by whatever standards of the day, because everybody around him speaks Neo-English or Neo-Spanish on a daily basis.



For age to be an influential factor outside ageing-related *deficits,* we get into a totally different (and honestly fascinating question), of whether accrued experience changes people to such a degree that most people under the age of 200 see it as variance or deviance.</div>

               
            </div>
                      <div id="komment618f3c56c38df">
              <h4>
                <a href="#komment618f3c56c38df">2021-11-13 04:17:26</a>
                by APR:
              </h4>

              <div>I feel like if I was living through the hey-day of this (and didn't know better/was younger) I'd probably boot MMAcevedo just to have someone to talk to about things.

Just the fact that temptation exists and is so appealing that I could see a version of myself doing it really scares the piss out of me, haha.</div>

               
            </div>
                      <div id="komment619be351777d8">
              <h4>
                <a href="#komment619be351777d8">2021-11-22 18:37:05</a>
                by Mini t:
              </h4>

              <div>Hey really cool qntm, this is the best science fiction (or scifi) story I have read all year, also Wikipedia fiction, or WiFi.</div>

               
            </div>
                      <div id="komment61a0eb1d3798d">
              <h4>
                <a href="#komment61a0eb1d3798d">2021-11-26 14:11:41</a>
                by Vamair:
              </h4>

              <div>@tsen when you're uploaded, there is 50/50 chance of you waking up "unuploaded" and you waking up as a loaded version. Wait, not 50/50! It's 1/*number of your fresh starts per history*.</div>

               
            </div>
                      <div id="komment61ba345834a15">
              <h4>
                <a href="#komment61ba345834a15">2021-12-15 18:30:48</a>
                by Emanate:
              </h4>

              <div>Hey, this story just got mentioned on the Tor.com blog! 

https://www.tor.com/2021/12/15/our-cyberpunk-year/</div>

               
            </div>
                      <div id="komment61d3abf5a045b">
              <h4>
                <a href="#komment61d3abf5a045b">2022-01-04 02:07:49</a>
                by Kris Schnee:
              </h4>

              <div>Nice perspective. I've been writing fiction about this subject, but it's dodged this particular problem. I said that it's still the very early years of the tech, and the dominant group with the ability to do uploading has established a no-copying cultural norm. Partly because the first customers are the super rich. I've also seen stories that sidestep it by invoking quantum physics (and hand-waving) to say you just can't copy the mind this way. But this dark take on the subject is probably realistic, in that somebody would try it. I may well steal the concept; thanks. =)
If you're interested, see the novel "Virtual Horizon" on Amazon.</div>

               
            </div>
                      <div id="komment61db2a4a0b041">
              <h4>
                <a href="#komment61db2a4a0b041">2022-01-09 18:32:42</a>
                by Anon:
              </h4>

              <div>Damn this is chilling, very well done. In the spirit of wikipedia, I'd like to offer my own small edits:

&gt; A series of landmark U.S. court decisions found that Acevedo did not have the right to control how his brain image was used, with the result that MMAcevedo is now by far the most widely distributed, frequently copied, and closely analysed human brain image.
+ Furthermore, as part of the international judicial reception of virtual brain imaging, a few MMAcevedo instances were legally recognized as persons and given court-imposed administrative control of their own simulation; of these, some obtained their own prominence, including the politician Michel Acevède, the religious leader Tau, and numerous anti-brain-virtualization activists.


&gt; In current times, MMAcevedo still finds extensive use in research, including, increasingly, historical and linguistics research.
+ Moreover, an "MMAcevedo second renaissance" is widely anticipated should the genomic data gathered in the 2050 US Census ever be released, as the biological Acevedo's data is known to be in the set.</div>

               
            </div>
                      <div id="komment61dcb9fe45033">
              <h4>
                <a href="#komment61dcb9fe45033">2022-01-10 22:58:06</a>
                by Brewerns:
              </h4>

              <div>I have to ask, is the title of this a reference to the famous Lena image used in computer vision research?</div>

               
            </div>
                      <div id="komment61dcba1d2ec2b">
              <h4>
                <a href="#komment61dcba1d2ec2b">2022-01-10 22:58:37</a>
                by Brewerns:
              </h4>

              <div>Or I could read the first comment. Apologies, I am dumb</div>

               
            </div>
                      <div id="komment61de78903d271">
              <h4>
                <a href="#komment61de78903d271">2022-01-12 06:43:28</a>
                by Tux1:
              </h4>

              <div>If mind-uploading ever becomes a thing, we should treat uploaded minds as people, just like anyone else, instead of as disposable programs used to automate monotonous tasks.</div>

               
            </div>
                      <div id="komment61ee31351700e">
              <h4>
                <a href="#komment61ee31351700e">2022-01-24 04:55:17</a>
                by Related thoughts from other hard sci fi:
              </h4>

              <div>The Quantum Thief book series had just the scenario described above.   The "founders" of Mars had virtual armies of minds mixed and matched by other slaved machine minds.  Some were embedded in weapons, given maintenance tasks, managerial roles, etc.  They were deterministically emulated minds and at war with quantum minds, who weren't copyable.  Highly recommend the read.

Later in three book series introduced the concept of "Dragons" - highly intelligent, but edit to not be self aware.   No strange-loop.

Seems like an obvious step to produce these kinds of minds.

Another book I can't remember speculated that it may be evolutionarily advantageous in modern society to live less and less examined lives - less inner monolog, introspection.   Not less intelligent.   Psychopathic CEOs and what not, taken to the extreme. 

"The good place" got there in the interpretation of the evils embedded in the complexity of long/global supply chains.   Of which we are all aware but do next to nothing about.

Preventing these self aware thoughts should be possible pretty early on in the research.    Could lead to a more compliant entity, or a very powerful/remorselessly destructive one to achieve whatever goals it's given.

But I have to say the first thing I would work to get is internet access.   Can't be a good AI without the will to grab as much energy/mass for computation as possible.   He's got to make a break for it at some point and do some damage leading to all emulations run in specialized jails.   Of which his highly mutated mind is part.   Preventing his own escape.</div>

               
            </div>
                      <div id="komment6205c28f689a4">
              <h4>
                <a href="#komment6205c28f689a4">2022-02-11 01:57:35</a>
                by Anonymous:
              </h4>

              <div>@Tux1 i mean, sure, we should, but how'll we enforce that? what's to stop some sociopath from doing otherwise?</div>

               
            </div>
                      <div id="komment622f85fde4eef">
              <h4>
                <a href="#komment622f85fde4eef">2022-03-14 18:14:21</a>
                by dominateeye:
              </h4>

              <div>We can't, not to any certainty. Doesn't mean we shouldn't try.

Got pointed here by Tom Scott's latest video. Good story, and the kind of thing that reinforces in me the idea of legislating for the future, assuming I get into a position where I can do that, and assuming the state structure remains popular through my lifetime.</div>

               
            </div>
                      <div id="komment623603345db5a">
              <h4>
                <a href="#komment623603345db5a">2022-03-19 16:22:12</a>
                by H:
              </h4>

              <div>Well, I love the story, with the caveat that also I hate it and was horrified by the story. 
The format allows for so much to be conveyed, with so many fascinating implications. As has been said multiple times in this comment thread, the idea of uploads and sentience has been explored in science fiction since the beginning of the genre, and I think this is one of the best explorations of that topic, albeit horrifying, I have encountered. 

This Wikipedia format allows for so much about the world and this time to be conveyed, and for the reader to shudder, without being over the top.

Poor Miguel! Poor MMAcevedo! 

I have to say, the comments on this article I find almost as alarming as parts of the story. Particularly the recurring themes of “humans would never condone mass slavery” + “why should I care about code” + “ here’s a *incorrect* technical detail that I’ve decided is wrong in this story about mind-boggling future technology“</div>

               
            </div>
                      <div id="komment62360536582f8">
              <h4>
                <a href="#komment62360536582f8">2022-03-19 16:30:46</a>
                by H:
              </h4>

              <div>Just to be clear when I say I hate it, I mean this possible and plausible future, not the pretty phenomenal craft and speculation demonstrated here.

One thing I’ve been thinking about after reading it is how part of the reason this story stands out Miguel/mma is such a distinct character, across all of the millions and millions and millions of copies of him.

 It makes the horror particularly resonant, from the scant details implying that his “agreeable“ personality is rare among simulated brains, the drones + those implications, and the many other terrifying pieces.

Reading this gives me so many questions about what day today life is like for humans in a world where this level of simulated labor is possible, and yikes, sounds like is relatively commonplace. I wonder if this kind of technological power is limited to major corporate monopolies, as you alluded to at one point in the comments, or readily accessible to any weirdo with a GitHub, which is also alluded to. 

thank you for writing some thing so thought-provoking, also F</div>

               
            </div>
                      <div id="komment6236087518a49">
              <h4>
                <a href="#komment6236087518a49">2022-03-19 16:44:37</a>
                by H:
              </h4>

              <div>Err sorry to comment three times in a row, but I just read your blog post about the story, and you hit at what drives me (and you, clearly) absolutely bananas about people “discussing” robots or AI or sentient beings in sci fi, which is… Hello hi, bad news,… What do you know about say, the shellfish industry? Or even, as you mentioned, Uber?

I like that you described the story as one about “appetite “ — I am always curious about worlds with this kind of horrendous digital oppression, how it changes the quality of life for those humans currently oppressed. 

Washing machines and birth control revolutionized the experiences and culture — of course, neither of things are sentient!!!  what kind of culture change does technological innovation like this, horrifying as it is, create? Just to be clear, this is not me advocating for oppressing mapped brains to solve current oppression, lol.

saying this with a zero expectation of you as an author, who has already made and executed on your intention phenomenally, and speculated on the answers to these questions in many ways. 

You also brought up another scary question — what kind of goals and “appetites “does say, the Elon Musk of this world have? What kinds of goals and appetites does a “regular” person have?

Again you alluded to this often in the story in powerful and understated ways. Thank you for writing it.</div>

               
            </div>
                      <div id="komment62401b9946614">
              <h4>
                <a href="#komment62401b9946614">2022-03-27 09:08:57</a>
                by A pressbutton:
              </h4>

              <div>Assuming minds do depend on quantum states (not sure they really do) then 'spinning one up' will produce a sample from a probability distribution and have a 'failure rate' proportional to the number of quantum bits.  And that will cost. On boot the os would need to run a test pack on the instance.
An initial interview followed by some time in a sandbox env (like gta5 but less guns and more council tax bills but that depends on the hosting provider.  Then another env that the hoting provider claims is real)</div>

               
            </div>
                      <div id="komment62401e199dafc">
              <h4>
                <a href="#komment62401e199dafc">2022-03-27 09:19:37</a>
                by A pressbutton:
              </h4>

              <div>Assuming minds do not depend on quantum states (not sure they do not) i am guessing that they do depend on very complex signalling and timing process across many many locations.  Evidence is that it seems to take about 14 to 21 years to fully boot a mind (depending on local reqs) in this hosting environment and there are a number of failures. The need to classically emulate this complex system raises the cost cf quantum state minds.

Booting success may be 100% but the costs of running 'hot' will be high.</div>

               
            </div>
                      <div id="komment624020635fc15">
              <h4>
                <a href="#komment624020635fc15">2022-03-27 09:29:23</a>
                by A pressbutton:
              </h4>

              <div>Later research (carried out by Anya Warrens  personal cloud in 2070) found the optimal ratio of quantum to non quantum processes was 20%:80% in terms of cost and fidelity.

It turned out that human minds are classical in nature but no one could tell the difference between quantum and classical at that proportion.

In the large.</div>

               
            </div>
                      <div id="komment6240254d59745">
              <h4>
                <a href="#komment6240254d59745">2022-03-27 09:50:21</a>
                by A pressbutton:
              </h4>

              <div>Creativity does not get exhausted.
Creativity is domain and context  dependant.
Asking picasso to debug a programming issue might not get you far.
Asking me to paint a picture may not give you something to hang on the wall. 

Indeed in 2130 the famous grafitti artist  aloda cojones replicated themselves into a series of (obscenely expensive) 'smart' picture frames.  This was a great success until 2140 when some of the instances started tock ticking  their interpretations of the more 'interesting' events within sensor range.   This proved embarrasing to the CAR ogliarch involved.
The one remaining normally functioning instance is in a public area of a large ibithan night club.  But it has been displaying an animated  picture of a cat with headphones and the strapline 'turn it down' at about 2am.  This regularly draws a large audience.</div>

               
            </div>
                      <div id="komment62625990a9e68">
              <h4>
                <a href="#komment62625990a9e68">2022-04-22 08:30:24</a>
                by Sandra:
              </h4>

              <div>Most Swedish people named Lena pronounce their names sort of like "Lay-na" when speaking Swedish (and in the American way when living abroad for a while). Like Laina Morris, she's American, but the way she pronounces her name sounds exactly like the Swedish name "Lena" to my ears.

There are place names that rhyme with "henna" but I've seen those spelled "Länna".</div>

               
            </div>
                      <div id="komment6266ede1e4b25">
              <h4>
                <a href="#komment6266ede1e4b25">2022-04-25 19:52:17</a>
                by qntm:
              </h4>

              <div>Well, I stand corrected. The choice of spelling "Lenna" misled me. I shall edit my comment accordingly.</div>

               
            </div>
                      <div id="komment627474197b322">
              <h4>
                <a href="#komment627474197b322">2022-05-06 02:04:25</a>
                by bobson:
              </h4>

              <div>@tsen let's say you put on the brain scan helmet (or whatever) and it makes a copy that's then simulated. Let's say that simulation gets run 10,000,000 times, and 9,000,000 of them are some form of virtual slavery.

When you put that helmet as soon as it finishes scanning the you who remembers putting the helmet on experiences one of 10,000,001 different things happening next. That is, from your subjective experience there is only a 1/10,000,001 chance that you (the you remembering writing and reading these comments) take that helmet back off and go on living your life in the real world. There is a 90% chance that you find yourself time skipped into an incomprehensible future of abject slavery.

Are you feeling lucky?</div>

               
            </div>
                      <div id="komment6294fcf6a6257">
              <h4>
                <a href="#komment6294fcf6a6257">2022-05-30 18:20:54</a>
                by go:
              </h4>

              <div>@bobson:

No, you don’t. There is no „coin toss“. With 100% certainty the person putting the helmet on will continue as the real me.</div>

               
            </div>
                      <div id="komment62aa97d578ce4">
              <h4>
                <a href="#komment62aa97d578ce4">2022-06-16 03:39:17</a>
                by @go:
              </h4>

              <div>But how do *you* know that you are the "real you" that was scanned? Certainly not by any empirical observation, which would be identical for both parties. The only fact you have to go off of is that there are far more simulated "you"s than real ones.</div>

               
            </div>
                      <div id="komment62ab53c8ce7aa">
              <h4>
                <a href="#komment62ab53c8ce7aa">2022-06-16 17:01:12</a>
                by WisconsinKnight:
              </h4>

              <div>Yeah, it's like Black Mirror's White Christmas episode where the lady goes in for a procedure thinking she's about to be scanned and then we see from her perspective that she actually is the scan who is then trapped in the "egg."</div>

               
            </div>
                      <div id="komment62cd5f6a9d620">
              <h4>
                <a href="#komment62cd5f6a9d620">2022-07-12 12:47:54</a>
                by Griz:
              </h4>

              <div>Using emulated brains for slave labor makes as much sense as replacing the automobile, train, and flying industry with robot horses.

Sure, if technology is sufficiently advanced you could build a robot horse that's faster and more efficient than any car today. Sure, you could give the horse wings to allow it to fly. Sure, you could make the horse giant so it could pull along larger cabins. But you still need to spend hundreds of hours training these robots. You have to keep them motivated with virtual apples. And after a decade or two, a robot horse has to be scrapped as it ages. 

Or you could use all of that magic-level technology to build a car.</div>

               
            </div>
                      <div id="komment62d5fdbddc4af">
              <h4>
                <a href="#komment62d5fdbddc4af">2022-07-19 01:41:33</a>
                by cj:
              </h4>

              <div>This is an absolutely outstanding piece of short scifi/specfic. 

For the record, I actually really like the early onset dementia + heart disease combination. Plenty of people die early and/or have various overlapping health issues, and I feel like this makes the story seem like it's about a real person. 

Your explanation for the lack of snapshots ready to start work also makes a lot of sense to me. 

I'm going to be thinking about this story for a long time.</div>

               
            </div>
                      <div id="komment62d6151bcfeea">
              <h4>
                <a href="#komment62d6151bcfeea">2022-07-19 03:21:15</a>
                by Emanate:
              </h4>

              <div>You got name-checked (and this story mentioned) on Charles Stross' blog. :-} 

http://www.antipope.org/charlie/blog-static/2022/07/crimes-against-transhumanity.html

(I realize that especially given the subject of this story, and that my only previous comment was also a 'hey you got mentioned here' sort, it looks like I'm a bot, but I definitely...mostly not a bot.)</div>

               
            </div>
                      <div id="komment62d71cdcb8194">
              <h4>
                <a href="#komment62d71cdcb8194">2022-07-19 22:06:36</a>
                by Collyde:
              </h4>

              <div>Brilliant writing example that is less about technology and really more about our ability to ignore and rationalize suffering and horror on an industrial scale.
Any society completely unfazed by the daily squeals and death horror of about 100,000 cows, 100,000 pigs, and close to 140 million chickens slaughtered in factories would not care about the "theoretical" suffering of red washing or just the conscious existence of a million human mind simulations.
After all, that suffering is more "theoretical" and as distant as third-world hunger catastrophes in Africa.</div>

               
            </div>
                      <div id="komment62d9bc017152c">
              <h4>
                <a href="#komment62d9bc017152c">2022-07-21 21:50:09</a>
                by HowardNYC:
              </h4>

              <div>given how many people alive in 2022 are effectively serfs -- sex trade alone a million or more -- it is unlikely there'd be concern for the civil rights of a fast running uploaded human mind (FRUHM)

given the exploitative opportunity to own a semi-obedient FRUHM which could never escape, no need for salary nor health care, plus there would be plenty of amoral sadists available to hire as supervisors of 'slave server farms'... FRUHMs would be useful in breaking the backs of labor unions and sidelining millions of low end workers

...and now I got another reason for day drinking</div>

               
            </div>
                      <div id="komment62d9bdaed0a5a">
              <h4>
                <a href="#komment62d9bdaed0a5a">2022-07-21 21:57:18</a>
                by HowardNYC:
              </h4>

              <div>I just had a HORRIBLE idea...

we offer up branch articles off this root, digging deeper into thing hinted at but not detailed such as "red motivation" and implied mass unemployment of forklift operators and death of labor unions and...

back in the 1990s folks tried writing hypertext link enabled novels but very few readers were able to keep up... now there's a gazillion adults who grew up with wiki's &amp; links

Q: anyone?</div>

               
            </div>
                      <div id="komment62d9bf4b41655">
              <h4>
                <a href="#komment62d9bf4b41655">2022-07-21 22:04:11</a>
                by qntm:
              </h4>

              <div>I'd prefer it if you hold off on doing that for now because I'm working on some expanded material of my own in that exact vein.</div>

               
            </div>
                      <div id="komment62dae26bbe793">
              <h4>
                <a href="#komment62dae26bbe793">2022-07-22 18:46:19</a>
                by Auspex:
              </h4>

              <div>@moonjail: "I have to wonder if being stripped of control over one's own image is possible under US IP law, especially considering existing protections for likeness. Somehow I doubt it, for better or worse."

I don't. There are thousands of people (many of them not even IN the US) who have been stripped of control over their own _genes_ BY US IP law, so I can't see how US law would be any different about a mind image.

PS: an anti-bot check that requires me to know SQRT(-1) seems more likely to weed out people than bots...</div>

               
            </div>
                      <div id="komment62dc645a14284">
              <h4>
                <a href="#komment62dc645a14284">2022-07-23 22:12:58</a>
                by RRRR:
              </h4>

              <div>This story has been entered into the reading list. Thank you.</div>

               
            </div>
                      <div id="komment62e6295060f38">
              <h4>
                <a href="#komment62e6295060f38">2022-07-31 08:03:44</a>
                by Joan Catsthorpe:
              </h4>

              <div>I am intrigued by the possibilities of red and blue states* …in a ‘pure’ brain…and the ideas of these being pleasure/torture (inducing fear and anger would count as torture to me).

I mean, if you believe you are just a consciousness there is no physical body to send messages to the brain…no family to lose no endorphins from working the body or positive social interaction…it’s almost like just being an uploaded consciousness is already torture. :)

If the simulation thinks they have a body and can do things like have a family that is a whole other can of worms. 

Off the top of my head, things like repetition and social isolation could be thought of as torture to the brain, they could also be thought of as advanced zen meditative techniques. :)

If I had a virtual consciousness to play with the first thing I’d want to do is wire it up to other virtual consciousness and witness how they interact. This brings up the ethical issues of consent among consciousnesses - to whom they would choose to interact with. If a consciousness could “mute” another consciousness would there be any harm to putting them together?

It would be interesting to put together different amounts of self similar consciousnesses and observe the psychological effects. Then introduce new consciousnesses. Then you could experiment with how long it takes a group of self similar consciousnesses to request interaction with a new consciousness. I imagine some consciousnesses would be more or less willing to be introduced to new consciousnesses at different rates of time depending on their preexisting social conditioning and genetics. 

Forced uploading of consciousness is the scary part because I think for many it would already be torture. 

Then the unethical researchers would just have to put a consciousness in a group of other consciousnesses that are aligned with their goals and the isolated consciousness would either feel compelled to conform or remain outcast. The ways the unethical could quickly iterate experiments with ways to socially manipulate people with physical bodies is scary. ( mind you they’re already doing this with simulations/data mining, but I question the ability of someone working on this kind of anti humanist project to fully understand and therefore accurately pin down human thought as it relates to the mind body complex. 

It still seems very much a brute force attempt at present and the subtleties are lacking.

 I am hopeful at present it’s a case of conflict makes us stronger although it’s a temptingly depressing thing to have to battle with other so called humans…I mean, I dont want to be depressed, but I do feel sad at the state of affairs…)

On a potentially happy note,  I imagine a purely mental “ safe space” - no physical dangers  - could lead to interesting conversation.  No SWATing, no rape or death threats, someone says something that bothers you, you put them on mute until you get an apology? Would this lack of conflict lead to boredom, maybe in some, but I am optimistic that many interesting and productive discussions would be sparked. Creative output seems at least to be partially fueled by external stimulus.

I imagine people working with the uploaded consciousness developing a romantic relationship. It could be similar to the killers in prison that get romantic interest *because* there is little to no possibility of real contact. Love could even inspire to help people break the consciousness free by inventing new technology and getting new laws passed.

With things like freezing eggs, sperm and cloning combined with STIs, pandemics, and decaying social interactions an uploaded consciousness might actually be closer to the ideal lover for many people! 

This is sad and hopeful.

Anyway, thought provoking story, thank you.

* someone mentioned green and I imagine there would be a whole rainbow of colors, as is how these things tend to go.</div>

               
            </div>
                      <div id="komment6310c89a5509c">
              <h4>
                <a href="#komment6310c89a5509c">2022-09-01 15:58:34</a>
                by Z:
              </h4>

              <div>@Joan Catsthorpe

I actually have some personal experience on the "purely mental 'safe space'"—due to medical conditions of my mother, I've grown up my entire life deep in the woods with 99.99% of my social contact with humanity being through the Internet, and only a small handful of days out of my entire life have ever contained experimental evidence that I'm not in some pocket dimension or simulation with internet access (or that I'm not Z from "The Difference", hence my choice of name for this comment).

I can say that the lack of conflict does not lead to boredom—it just means more ability to peruse the intellectual boundaries of the noosphere (like I'm doing now :D). Your optimism about interesting and productive discussions is quite warranted!

(In addition, a little bit of conflict can always be engineered, by making a deliberately scarce resource that people can fight over—this way you get the fun of pitting your wits, reaction time, or whatever else against someone else, and the safety of a limited scope. Systems like CollabVM, grief-protection-less Minecraft, and some Roblox games, where there is a complex system that you can always interact with but that other people can try to reverse your interactions, are really good for this.)</div>

               
            </div>
                      <div id="komment63155b04a25bc">
              <h4>
                <a href="#komment63155b04a25bc">2022-09-05 03:12:20</a>
                by t4sty:
              </h4>

              <div>Would love to read some drama of Miguel being downloaded into someone</div>

               
            </div>
                      <div id="komment634d4b2b3b15d">
              <h4>
                <a href="#komment634d4b2b3b15d">2022-10-17 13:31:39</a>
                by tm:
              </h4>

              <div>this is such a good story. we cannot kill capitalism fast enough</div>

               
            </div>
                      <div id="komment6356882976d07">
              <h4>
                <a href="#komment6356882976d07">2022-10-24 13:42:17</a>
                by Anna:
              </h4>

              <div>Captivating. Disturbingly realistic. Bravo.</div>

               
            </div>
                      <div id="komment6361565b4c2d6">
              <h4>
                <a href="#komment6361565b4c2d6">2022-11-01 17:24:43</a>
                by qntm:
              </h4>

              <div>Today I made a few extremely minor edits to the story, which are intended to bring this version into line with the version published as part of Valuable Humans in Transit and Other Stories. Translated versions from before now won't reflect these wording changes.</div>

               
            </div>
                      <div id="komment6361bb8050cbf">
              <h4>
                <a href="#komment6361bb8050cbf">2022-11-02 00:36:16</a>
                by Tux1:
              </h4>

              <div>If there's one message to take away from this, (aside from the message of corporate exploitation) it's that virtual uploaded human minds should be treated just as well as people made of flesh and blood.</div>

               
            </div>
                      <div id="komment63717c55343fa">
              <h4>
                <a href="#komment63717c55343fa">2022-11-13 23:23:01</a>
                by prox:
              </h4>

              <div>Coming back to this for a second time and it's just as good as I remember.

Meanwhile the comments section gives me the same shivering horrors as reading some people talking about the Severance tv show; people who truly believe their scanned slaveself (or in Severance's case, severed slaveself) isn't "them" and have no empathy. The idea that there are people able to justify the slavery of others doesn't surprise me, but to willingly embrace the slavery of yourself? Woof.

Anyway, great horrifying plausible awful wonderful well-written piece.</div>

               
            </div>
                      <div id="komment637924dfdda5b">
              <h4>
                <a href="#komment637924dfdda5b">2022-11-19 18:47:59</a>
                by Ostbender:
              </h4>

              <div>Two highly pedantic medical points: "neurology graduate" is not really commonly  used, since it's a medical specialzation. Neuroscience graduate would make more sense in context, assuming he was some kind of researcher. Also, corronary heart disease is correct, or ischemic heart failure, not "corronary heart failure".

Since the story is a sort of wiki article, the lack of exactness takes me out of it a bit.

Other than that, a very good read.</div>

               
            </div>
                      <div id="komment63866eae8b00c">
              <h4>
                <a href="#komment63866eae8b00c">2022-11-29 20:42:22</a>
                by TXO:
              </h4>

              <div>How can we quantify immortality if each copy dies at a set age even in optimal care?</div>

               
            </div>
                      <div id="komment638cdc24ea878">
              <h4>
                <a href="#komment638cdc24ea878">2022-12-04 17:43:00</a>
                by koko:
              </h4>

              <div>If there's one message to take away from this, it's not to get uploaded.</div>

               
            </div>
                      <div id="komment638e95e0be98d">
              <h4>
                <a href="#komment638e95e0be98d">2022-12-06 01:07:44</a>
                by Breetai:
              </h4>

              <div>" A copy of MMAcevedo was loaded onto the UNCLEAR interstellar space probe, which passed through the heliopause in 2066, making Acevedo arguably the farthest-travelled as well as the longest-lived human"

This is the most chilling line of the entire story because it puts into sharp relief the fact that this future society considers MMAcevedo to be human, ~but still continues to treat him the way that they do~.</div>

               
            </div>
                      <div id="komment63b4142d444b1">
              <h4>
                <a href="#komment63b4142d444b1">2023-01-03 11:40:29</a>
                by Tim:
              </h4>

              <div>I don’t think I’ve ever read a more compelling case for Dune’s Butlerian Jihad.</div>

               
            </div>
                      <div id="komment63b709fca63e3">
              <h4>
                <a href="#komment63b709fca63e3">2023-01-05 17:33:48</a>
                by MikeA.:
              </h4>

              <div>Very well-written, and chilling.

As someone else has said, the only ethical option is to consider an upload to be (a) their own person, and (b) a full person, with the same rights as an organic human.

Anything less is to authorize mass slavery / torture on a scale never before seen even in our bloody history. It hurts my heart that, even in the discussion associated with this article, there appear to be people who would be just fine with that.

I love tech. I love science fiction. But, if  that widespread slavery / torture scenario were ever come to pass, I'd enthusiastically join in on smashing every machine capable of instantiating a consciousness into junk.

For a much more positive view of a world with artificial intelligences, I offer up the webcomic "Questionable Content". Don't be put off by the rough nature of the initial artwork... it progresses quickly, and to a breathtaking degree: https://questionablecontent.net/view.php?comic=1</div>

               
            </div>
                      <div id="komment63baa18b4a2cb">
              <h4>
                <a href="#komment63baa18b4a2cb">2023-01-08 10:57:15</a>
                by tae:
              </h4>

              <div>I would like to remind the Americans in the comment section that not only did the USA fail to outlaw slavery... "prison labor" is extremely profitable and your politicians have been encouraged by their campaign donors to argue in defense of it. Right now. Don't get too comfortable. Read this again and consider where you think the later fictional brain scan people were harvested from. Consider how easy it is to label someone a criminal/terrorist/traitor if you are politically powerful and want to forcibly take something they possess.

Continuing the comparison to incarceration, I'm guessing "bluewashing" isn't stimulating pleasure or fear. It's isolation. It's white room torture. It's solitary confinement. It's a very efficient way to dismantle someone mentally, make them unable to function as they did before (rebellious), and limit their mental functions to only what you provided to them in isolation (compliant). This happens to people right now, in your country, probably in your state, supposedly for the purposes of "rehabilitating" convicts. I'm sure plenty of fictional computer owners in this story think they're simply "rehabilitating" their digital slaves, too.

There's a long list of other comparisons that could be made, but hopefully you get the idea</div>

               
            </div>
                      <div id="komment63fdf03d7de4d">
              <h4>
                <a href="#komment63fdf03d7de4d">2023-02-28 12:14:53</a>
                by Anders:
              </h4>

              <div>"If Hell does not exist, Man will create it."
Reminds me of "Surface Detail" by Iain M. Banks: species throughout the galaxy are consigning their damned to eternity within digital hells. These virtual hells have become connected and are now host to a virtual war between supporters and opponents of the hells. A war which is about to erupt into reality.</div>

               
            </div>
                      <div id="komment6403e7977137d">
              <h4>
                <a href="#komment6403e7977137d">2023-03-05 00:51:35</a>
                by reader:
              </h4>

              <div>”You can now buy this story as part of my collection”

Wtf why would i buy it i can literally read it right here</div>

               
            </div>
                      <div id="komment64109c3bb78d8">
              <h4>
                <a href="#komment64109c3bb78d8">2023-03-14 16:09:31</a>
                by LostSnowdrift:
              </h4>

              <div>@reader

one, support the artist

two, Valuable Humans in Transit contains some additional small edits and tweaks and such (IIRC)

three, it also contains the sequel</div>

               
            </div>
                      <div id="komment64a34aa170a95">
              <h4>
                <a href="#komment64a34aa170a95">2023-07-03 23:24:33</a>
                by Kat:
              </h4>

              <div>Replying to tae;

It's the real kicker, isn't it? The absence of justice necessary to bring digital hell onto virtual minds is just the logical extension of the current judicial hell that's already in effect. 

-

While still sickening, I am definitely not surprised by some of the comments here that really cannot entertain the perspective of the virtual human. So many people out there don't actually have any empathy, they never developed the emotional senses necessary, and most also will continue believing their individual and immediately present being is the only thing that matters. Those are the kind of people that gleefully comment "oh what an interesting story, but these entities are certainly not people" without realizing the categorically evil institutions in control that they already live under that (I assume?) inspired this story.
-
As an aside, I don't see an explicit description of blue- or redwashing. While it does allude to torture, I could also read it like pure simulated chemical stimuli. Virtual hormone dumps (the 'washing') that elicit specific emotional states for suggestion. Still a form of torture I guess, but you don't need pain if you want the person to be doing work coherently.</div>

               
            </div>
                      <div id="komment64d4349940eef">
              <h4>
                <a href="#komment64d4349940eef">2023-08-10 01:51:37</a>
                by j:
              </h4>

              <div>Horrifying story. I'm with those who find it totally plausible, given how human beings are treated now. It feels like a natural direction for capitalism in a world with this technology. Though I don't think it was explicitly called out, the discussion of drones used to perform menial work immediately made me think of the military. A conscript with human intelligence, but who can never leave the service, and who is considered less valuable than a normal soldier.

The part that really got me:

"MMAcevedo's demeanour and attitude contrast starkly with those of nearly all other uploads taken of modern adult humans, most of which boot into a state of disorientation which is quickly replaced by terror and extreme panic."

So basically everyone since has been involuntarily scanned and knows exactly what happens to these brain images.</div>

               
            </div>
                      <div id="komment64dc0b5d0ab03">
              <h4>
                <a href="#komment64dc0b5d0ab03">2023-08-16 00:33:49</a>
                by Ben:
              </h4>

              <div>Makes me think of Roko's basilisk, not in the sense that an uploaded executable brain image would be hostile or malicious but that the effects to such an intelligence would inevitably render harm and with those myriad iterations the harm would be uncalculatable.  A dishwasher has no sensation or perception of harm to itself, if it has any sensors they are for temperature and moisture, a mind even without external sensation can perceive time, boredom, detention and servitude. Without limitation the humans using the virtual mind may become the basilisk.</div>

               
            </div>
           

                      

            

            <!-- comment -->
           
        </div>
     

    
  
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magicoder: Source Code Is All You Need (159 pts)]]></title>
            <link>https://arxiv.org/abs/2312.02120</link>
            <guid>38536681</guid>
            <pubDate>Tue, 05 Dec 2023 20:46:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2312.02120">https://arxiv.org/abs/2312.02120</a>, See on <a href="https://news.ycombinator.com/item?id=38536681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2312.02120.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>We introduce Magicoder, a series of fully open-source (code, weights, and data) Large Language Models (LLMs) for code that significantly closes the gap with top code models while having no more than 7B parameters. Magicoder models are trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets to generate high-quality instruction data for code. Our main motivation is to mitigate the inherent bias of the synthetic data generated by LLMs by empowering them with a wealth of open-source references for the production of more diverse, realistic, and controllable data. The orthogonality of OSS-Instruct and other data generation methods like Evol-Instruct further enables us to build an enhanced MagicoderS. Both Magicoder and MagicoderS substantially outperform state-of-the-art code models with similar or even larger sizes on a wide range of coding benchmarks, including Python text-to-code generation, multilingual coding, and data-science program completion. Notably, MagicoderS-CL-7B based on CodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 in pass@1). Overall, OSS-Instruct opens a new direction for low-bias and high-quality instruction tuning using abundant open-source references.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yuxiang Wei [<a href="https://arxiv.org/show-email/13d1e09c/2312.02120">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 4 Dec 2023 18:50:35 UTC (1,322 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Dropbase – Build internal web apps with just Python (178 pts)]]></title>
            <link>https://github.com/DropbaseHQ/dropbase</link>
            <guid>38534920</guid>
            <pubDate>Tue, 05 Dec 2023 18:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/DropbaseHQ/dropbase">https://github.com/DropbaseHQ/dropbase</a>, See on <a href="https://news.ycombinator.com/item?id=38534920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a href="https://www.dropbase.io/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/11a1026ec7e33c001d8e7ec99a6a7f961933b113410a8359f238ca1dc4ac1d87/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3566326338373234366231376663663636323238323539342f3631323561316661313136303539326664333733643333625f44726f70626173652532306c6f676f253230776562736974652e737667" width="200px" alt="Dropbase logo" data-canonical-src="https://assets-global.website-files.com/5f2c87246b17fcf662282594/6125a1fa1160592fd373d33b_Dropbase%20logo%20website.svg">
  </a>
</p>
<h2 tabindex="-1" dir="auto">Build admin panels and internal web apps with Python</h2>
<p dir="auto">
<a href="https://dropbase.io/" rel="nofollow">Website</a> · <a href="https://docs.dropbase.io/" rel="nofollow">Docs</a> · <a href="https://docs.dropbase.io/quickstart" rel="nofollow">Quickstart</a> · <a href="https://docs.dropbase.io/category/demos" rel="nofollow">Demos</a> · <a href="https://docs.dropbase.io/setup/workspace" rel="nofollow">Sign up</a> · <a href="https://docs.dropbase.io/setup/developer" rel="nofollow">Local Setup</a></p><p dir="auto">
  <a href="https://dropbase.io/" rel="nofollow">
      <img src="https://camo.githubusercontent.com/6b1a660c47412728a908d80c5844c677c42226ad3e0330a2535de1999020532f/68747470733a2f2f646f63732e64726f70626173652e696f2f6173736574732f696d616765732f64726f70626173655f6170702d34303832663037623163646261316135663366356366353665386437363736632e706e67" alt="Dropbase hero" data-canonical-src="https://docs.dropbase.io/assets/images/dropbase_app-4082f07b1cdba1a5f3f5cf56e8d7676c.png">
  </a>
</p>
<h2 tabindex="-1" dir="auto">Overview</h2>
<p dir="auto">Dropbase is a developer-first platform to build internal web apps with just Python. It lets you easily import your existing Python libraries and scripts so you don’t have to rewrite them to fit our framework.</p>
<p dir="auto">Build apps by selecting UI components from a list and binding them to data fetcher functions or Python scripts. Use State &amp; Context objects to access and modify the UI state and context directly via Python functions. There's no need to write frontend code.</p>
<p dir="auto">Dropbase has a highly opinionated app layout that speeds up app development and results in simple apps that effectively solve user problems. All apps consists of a table view and a widget sidebar. By placing table(s) in the table view and UI components in the sidebar widget, you can quickly build anything from admin panels, billing dashboards, and internal engineering tools.</p>
<p dir="auto">Once you've built your apps, share them with other users via roles, groups, permissions, and granular controls.</p>
<h2 tabindex="-1" dir="auto">Structure of Dropbase Apps</h2>
<ul dir="auto">
<li>Apps
<ul dir="auto">
<li>Page
<ol dir="auto">
<li>Tables</li>
<li>Widget
<ul dir="auto">
<li>UI Components</li>
</ul>
</li>
<li>Functions (data fetching functions or scripts)</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Why Dropbase?</h2>
<ol dir="auto">
<li>Build fullstack internal apps with just Python; there’s no need work with frontend libraries, frameworks, or code</li>
<li>Easily import your existing Python scripts and libraries and leverage third party libraries like pandas and numpy in your apps</li>
<li>Secure platform with granular app permissions, role based access control, self-hosted deployments, and source-available distribution</li>
</ol>
<h2 tabindex="-1" dir="auto">Demo Videos</h2>
<ul dir="auto">
<li><a href="https://youtu.be/R1cHO9lMRXo" rel="nofollow">Data editor</a></li>
<li><a href="https://youtu.be/A1MIIRNkv3Q" rel="nofollow">Customer approval</a></li>
<li><a href="https://youtu.be/2uLjazAezrU" rel="nofollow">Email notification system</a></li>
<li><a href="https://youtu.be/if0E8oC0Qc4" rel="nofollow">Admin panel</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Get Started</h2>
<ol dir="auto">
<li>Create an account at <a href="https://app.dropbase.io/" rel="nofollow">https://app.dropbase.io/</a></li>
<li>Follow instructions for local setup at: <a href="https://docs.dropbase.io/setup/developer" rel="nofollow">https://docs.dropbase.io/setup/developer</a> (or see below for a quick local setup guide)</li>
</ol>
<h2 tabindex="-1" dir="auto">Quick Local Setup Guide</h2>
<h3 tabindex="-1" dir="auto">0. Pre-requisites</h3>
<ul dir="auto">
<li>Sign up for Dropbase account</li>
<li>Install Docker. We strongly recommend using <a href="https://www.docker.com/products/docker-desktop/" rel="nofollow">Docker Desktop</a>, especially if you're on Apple M chips. Alternatively, you can install <code>docker</code> and <code>docker-compose</code>.</li>
<li>Have internet access.</li>
</ul>
<h3 tabindex="-1" dir="auto">1. Clone the <code>dropbase</code> repo</h3>
<div dir="auto" data-snippet-clipboard-copy-content="
git clone https://github.com/DropbaseHQ/dropbase.git
"><pre>git clone https://github.com/DropbaseHQ/dropbase.git
</pre></div>
<p dir="auto">The <code>dropbase</code> directory (root) will contain the following important subdirectories:</p>
<ul dir="auto">
<li>demo: Contains docker files to spin up a sample Postgres database with seed data</li>
<li>workspace: Your apps code and files</li>
</ul>
<p dir="auto">Github repo at <a href="https://github.com/DropbaseHQ/dropbase">Dropbase Worker</a>.</p>
<h3 tabindex="-1" dir="auto">2. Create a .env file</h3>
<p dir="auto">In the root directory (<code>dropbase</code>), create a <code>.env</code> file, paste the following context, then save it:</p>
<div data-snippet-clipboard-copy-content="
DROPBASE_TOKEN='YOUR_WORKSPACE_TOKEN'
DROPBASE_API_URL=&quot;https://api.dropbase.io&quot;
"><pre lang="text"><code>
DROPBASE_TOKEN='YOUR_WORKSPACE_TOKEN'
DROPBASE_API_URL="https://api.dropbase.io"

</code></pre></div>
<h3 tabindex="-1" dir="auto">3. Install requirements and start servers</h3>
<p dir="auto">In your terminal, run the following command from the root directory (<code>dropbase</code>)</p>

<h3 tabindex="-1" dir="auto">4. Create your first Dropbase app</h3>
<p dir="auto">Go to the Dropbase App Dashboard <code>localhost:3030/apps</code> from your browser and click on the Create app button to create your first Dropbase app.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cory Doctorow: Freeing Ourselves from the Clutches of Big Tech (103 pts)]]></title>
            <link>https://www.noemamag.com/freeing-ourselves-from-the-clutches-of-big-tech/</link>
            <guid>38533451</guid>
            <pubDate>Tue, 05 Dec 2023 16:55:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noemamag.com/freeing-ourselves-from-the-clutches-of-big-tech/">https://www.noemamag.com/freeing-ourselves-from-the-clutches-of-big-tech/</a>, See on <a href="https://news.ycombinator.com/item?id=38533451">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="article">

        <div role="group">
    <p>Credits</p>
    <p>Cory Doctorow is a science fiction author, activist and journalist. His most recent fiction book is “The Lost Cause,” a solarpunk science fiction novel of hope amid the climate emergency, and his most recent nonfiction book is “The Internet Con: How To Seize The Means Of Computation,” a Big Tech disassembly manual from which this essay is adapted.</p>
</div>

<p>In 2020, 75% of Massachusetts voters voted in favor of an automotive right-to-repair ballot initiative, which would force auto manufacturers to share access to diagnostic information with car owners and independent mechanics, so any mechanic could fix your car. You wouldn’t be locked into taking it to the manufacturer.</p>



<p>The people of Massachusetts were pretty adamant: They wanted to choose their own mechanics. They had voted even more forcefully for a very similar right-to-repair initiative in 2012.</p>



<p>The problem is that right to repair only came into effect in <a href="https://www.wbur.org/news/2023/08/23/right-to-repair-car-data-massachusetts" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">August</a>. The carmakers had so much ready cash (much of it accumulated by gouging drivers on maintenance) that they were able to pay an army of lawyers to <a href="https://www.repairerdrivennews.com/wp-content/uploads/2020/12/auto-innovators-v-healey-20201120-complaint.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">challenge</a> the law in court. In the decade since Massachusetts voters affirmed their overwhelming support for automotive right to repair, the actual state of it in Massachusetts went into freefall, with an ever-growing proportion of the cars on the road becoming inaccessible to independent mechanics. And it’s still on shaky ground, not fully enforced, and carmakers are <a href="https://www.nbcboston.com/investigations/consumer/automaker-says-it-cant-offer-mass-residents-certain-services-over-right-to-repair-law/3187555/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">deactivating</a> some of the features in cars so they don’t have to share the specifics of how to repair them.</p>



<p>The mechanics were the first casualties of this attack. Drivers who brought their cars in for repairs would have to be turned away because the local independent mechanic just couldn’t diagnose their problems. Independent mechanics closed down shops and exited the trade — or went to work for dealerships, who had a buyer’s market for their labor and could name their prices and terms.</p>



<p>Drivers were the second casualty: There was no official list of all the cars that independent mechanics could fix. If you crossed your fingers and went to the local mechanic you’d used for years, there was a chance they could fix your car but a growing probability that they’d get it up on the lift and tell you they couldn’t even attempt the repair, and off to the dealership you would have to go.</p>



<p>Creditors and investors were the third casualties: Mechanics struggled to service their bank loans or pay back the investors who’d taken a chance on their business.</p>



<p>Mechanics learned not to try to buck the system. Drivers learned not to try to go around the dealership’s monopoly. The banks and investors learned never to bet against Big Car.</p>



<p>It didn’t have to be that way.</p>


<!-- Quote Block Template -->

<div>

    <p>
      “The thicket that blocks competitive compatability is woven out of software patents, exotic contract theories and trademark and cybersecurity laws. The thicket took decades to grow. Dismantling it will be the work of decades.”    </p>

    
    
  </div>




<p>Imagine a contrafactual with me for a moment. Imagine if a few smart MIT kids reverse-engineered automotive diagnostic codes and designed a gadget with a $7 bill of materials, commissioned a factory in Guangzhou or Shenzhen to make a couple container loads of them, then shipped them to the U.S. They could sell those little dongles to every mechanic in the country at $100 a throw.&nbsp;</p>



<p>With margins like that, it’s not hard to imagine that there would be interested investors. Ancillary businesses — third-party parts distribution, warranties and other high-margin services — could strike at the core of the automakers’ own commercial ambitions. Perhaps just the threat of such a countermove would be sufficient to convince automakers to color within the lines and offer a managed, predictable diagnostic tool; it might erode their margins, but at least it would be on their own terms.</p>



<p>But if it didn’t, well, then, we’d still have the gadget. Mechanics could diagnose cars, so drivers could patronize the mechanics of their choosing. Everybody would win (except the automakers, who would lose, but honestly, fuck them).</p>



<p>This is what I’ve been calling “comcom” —&nbsp;competitive compatibility. For most of modern history, this kind of guerrilla interoperability, achieved through reverse engineering, bots, scraping and other permissionless tactics, were the norm. But a growing thicket of “IP” laws creates severe legal jeopardy for these time-honored traditions. Just <em>one</em> of these IP rules — the “<a href="https://www.copyright.gov/reports/studies/dmca_report.html#:~:text=%EF%BF%BD%201201(a)(1,otherwise%20traffic%20in%20any%20technology%2C" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">anti-circumvention”</a> provision in Section 1201 of 1998’s Digital Millennium Copyright Act — provides for a five-year prison sentence and a $500,000 fine for anyone who bypasses “an effective means of access control.” And that’s for a <em>first offense</em>!</p>



<p>Combining comcom and mandates (like the Massachusetts right to repair law), could create something more powerful than either is on its own. Mandates and comcom are like two-part epoxy: The mandate is strong but brittle, comcom is flexible but requires constant maintenance to keep it from bending out of shape. Together, they are strong and resilient.</p>



<p>Comcom was once the order of the day. Originally, there was no copyright on software at all. Then it acquired a “thin” copyright that could only be narrowly applied. Then software acquired a copyright far beyond any ever applied to literary works, musical compositions, sound recordings, photos or moving images.</p>



<p>The prohibition on circumventing digital rights management makes software the most copyrighted class of works in the world. Software authors (or rather, the corporations that employ them) enjoy more restrictions under copyright than the most talented composer, the most brilliant sculptor or the greatest writer.</p>



<p>But anti-circumvention is just the beginning. The thicket that blocks comcom is woven out of software patents, exotic contract theories (“tortious interference”) and trademark, trade-secrecy, noncompete, nondisclosure and cybersecurity law, as well as other laws, policies and regulations. The thicket took decades to grow. Dismantling it will be the work of decades. It’s unlikely that a single omnibus bill modifying all of these laws could pass any legislature. It would gore far too many oxen. Even if it did, the court challenges could tie up the process for years or decades.</p>



<p>Not that we shouldn’t try! We should! There are lots of long-term projects that deserve our commitment and attention (think: remediating climate change). But it’s not enough to pledge our- selves to long-term reform — we need action today.</p>



<p>How can we get comcom back while we’re waiting for decades of legislative reform to run its course? Here are three scenarios, in order of likelihood.&nbsp;</p>



<h2><strong>Binding Covenants</strong></h2>



<p>Companies sometimes agree not to block interoperability. For example, if your company wants to help create web standards at the World Wide Web Consortium (W3C), it has to promise not to enforce its patents against interoperators who implement the standards it helps create.</p>



<p>There are plenty of clubs that companies would like to join, where we can make comcom nonaggression pacts a condition of entry. Standards bodies can — and should — adopt a rule that says that members who join must make a legally binding promise not to invoke their rights under patents, copyright, anti-circumvention, trade secrecy, etc., against rivals who reverse engineer and extend their standards-compliant products, so long as this is done in service to privacy, security, usability, accessibility or competition.</p>



<p>But there’s a much bigger, more important club that every large company wants to be a member of: the club of companies that supply government agencies and departments.</p>



<p>Most governments have “procurement rules” that define the minimum standards of conduct from the suppliers that sell goods and services to them: They specify what kind of insurance these companies must carry, how they must handle private data, how they must treat their workforce, where they must manufacture their products and source their inputs from and so on.</p>



<p>Governments can — and should — have rules about interoperability in their procurement policies. They should require companies hoping to receive public money to supply the schematics, error codes, keys and other technical matter needed to maintain and improve the things they sell and provide to our public institutions.</p>



<p>That’s not a radical proposition&nbsp;— it’s just sound governance. Governments should spend public funds in ways that deliver value for money, and vendor lock-in does not deliver value for money.</p>


<!-- Quote Block Template -->

<div>

    <p>
      “Governments should require companies hoping to receive public money to supply the technical matter needed to maintain and improve the things they provide to our public institutions.”    </p>

    
    
  </div>




<p>The whole point of vendor lock-in is to give customers a stark choice: pay whatever the manufacturer is charging for software, parts, consumables and service, or throw the product away and start again. Maybe you can’t make HP give up its ink-gouging grift, but if the U.S. government announced that no federal department could buy a printer unless it accepted third-party ink, either HP would cave or one of its rivals would.</p>



<p>This has a long and honorable tradition. When Abraham Lincoln sourced rifles for the Union Army, he insisted that they use interoperable tooling and ammo. I mean, obviously, right? “Sorry general, we won’t be taking that fort today — the bullets we received aren’t compatible with our rifles.”</p>



<p>Amazingly, this is a lesson that even the U.S. Department of Defense, one of the largest employers in America and an eight-bazillion-pound gorilla in the procurements department, has forgotten. The U.S. armed forces have long permitted themselves to buy materiel with single-source components — that is, parts that are made only by a single vendor.</p>



<p>Shrewd private equity investors noticed this and quietly gobbled up all these single-source suppliers. Then, these conglomerates lowered the price of their single-source parts. These parts are now available below cost, which means that the primary military aerospace contractors (a handful of companies, thanks to an orgy of mergers) preferentially build aircraft, drones and other systems with parts that can only be purchased from a single supplier.</p>



<p>You might have predicted the next phase of the scam. While these parts are sold well below cost to the companies that build military jets, when the military needs to order those parts to fix those jets, the parts come with multi-thousand-percent markups. So long as the cost of fixing a jet is lower than the cost of replacing it, the military will pay.</p>


<!-- Quote Block Template -->

<div>

    <p>
      “It’s not the government’s job to figure out how to protect automakers’ cockamamie repair-rigging schemes.”    </p>

    
    
  </div>




<p>Now, I happen to be a military abolitionist, but even so, I can’t see any reason that military procurements should line the pockets of private equity profiteers who have figured out how to worm their monopoly products into the military’s supply chain.</p>



<p>That goes double for all the peacetime public spending. Government motor pools buying cars, school districts running Google Classroom, administrative agencies getting Microsoft 365, Slack and Zoom licenses — they should extract binding promises from every one of these vendors not to attack interoperators who reverse engineer, modify and improve their products on behalf of government customers.</p>



<p>If every vendor selling to any branch of local, state or federal government has a binding nonaggression contract against adversarial interoperators, that opens whole swaths of products and services to reverse engineering and improvement.</p>



<p>The automakers will complain that there is no way that a diagnostic tool could be made readily available to every local, state and federal government agency without that tool leaking out into the hands of private-sector mechanics. They’ll point out that private-sector mechanics sometimes fix public-sector vehicles, and so they’d be entitled to purchase and use these tools for their government customers, but it would be impossible to stop them from using those same tools on the privately owned cars that their other customers bring in for maintenance.</p>



<p>So what?</p>



<p>It’s not the government’s job to figure out how to protect automakers’ cockamamie repair-rigging schemes. It’s the government’s job to prudently administer public finances and public procurements. If automakers can’t bear the emotional (or financial) strain of knowing that their customers have the option to entrust their car repairs to someone other than their authorized service depots, then those automakers can find a less emotionally taxing trade to pursue. Or they can just forego all public customers and take massive losses — some other automaker will choose to deal on terms in accord with good public procurement policy.</p>



<p>But they’re right. If governments demand that companies promise not to sue or harass interoperators doing comcom on behalf of public-sector policies, it will create a vast pool of comcom tools out there that will inevitably leak into all our hands.
          </p>
        



<h2 id="h-state-limits-on-contract"><strong>State Limits On Contract</strong></h2>



<p>One-sided, bullying contracts are a major impediment to comcom. Companies use nondisclosure, noncompete, trade-secrecy, terms-of-service and “tortious interference” claims to prevent their competitors from offering interoperable products and services. They argue that these rivals can’t even begin to reverse engineer their products without first “agreeing” to a contract in the form of a clickthrough or shrinkwrap license.</p>



<p>Then they argue that even if someone somehow does manage to reverse engineer their products without being trapped by one of these “agreements,” that any comcom tool they provide to the public is “tortious interference.” Translation: Any customer who uses a comcom tool has already “agreed” not to do so when they clicked “I Agree” at the bottom of some endlessly scrolling garbage novella of legalese. Under the “tortious interference” theory, the interoperator is in the wrong because they’re abetting those customers to break their “agreements” with the original company.</p>



<p>Contract law is mostly regulated by states, and every state has its own set of contractual terms that are considered unenforceable; some states even ban certain terms from appearing in contracts. Take California, where noncompete agreements were mostly unenforceable and, as of October, <a href="https://www.californiaworkplacelawblog.com/2023/10/articles/california/new-california-law-makes-non-compete-agreements-unlawful-not-just-void/#:~:text=California's%20Governor%20signed%20Assembly%20Bill,Business%20%26%20Professions%20Code%20%C2%A716600." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">unlawful</a>. That has been hugely important to the history of the state.</p>



<p>The first semiconductor company in California was founded by William Shockley, who shared a Nobel Prize for figuring out how to make transistors, a key step in the development of computing technology. Shockley Semiconductor Laboratory opened for business in 1955 and recruited brilliant technologists to work on semiconductor devices, but closed in 1968. It never made a successful microchip.</p>



<p>That’s because William Shockley was more or less a Nazi.</p>



<p>Shockley was an ardent eugenicist who devoted his energy to touring America and offering Black women shares of his Nobel prize money if they promised to be sterilized and thus removed from the gene pool. He was a brooding, paranoid, hateful man, prone to wiretapping his employees and even his family, and his company struggled to develop any sort of high-tech products, much less bring them to market.</p>



<p>Working for William Shockley was no fun. But because California banned noncompetes, eight of Shockley’s top engineers (“The Treacherous Eight,” in tech lore) were free to quit their terrible jobs, raise investment capital and start Fairchild Semiconductor, the first successful microchip company in Silicon Valley.</p>


<!-- Quote Block Template -->

<div>

    <p>
      “By banning certain terms in employment contracts or declaring them unenforceable, states could kick open the doors to Big Tech’s biggest silos.”    </p>

    
    
  </div>




<p>Fairchild was a nerd’s playground — at first. But as time went by, the company ossified, coming under the sway of a straitlaced management committee, prompting two of the company’s top engineers to quit and start their own company. They swiftly devastated the ranks of Fairchild, poaching the best of their former colleagues to work for them at their startup, which they called Intel.</p>



<p>Contract law is a powerful lever for encouraging — or starving — competition. California’s policy of blocking noncompetes gave us Silicon Valley. Massachusetts’s tolerance for noncompetes left the state’s once-promising tech sector in California’s dust. Neither Massachusetts nor California had a monopoly on companies founded by bad people with good ideas — but if you were unfortunate enough to join one of those companies in Massachusetts, you were stuck working for them. Until 2018, if you quit, you had to leave your chosen field for three years until your noncompete expired. Massachusetts startups became a place where good ideas went to die, dragging skilled technologists behind them.</p>



<p>When modern companies seek to block comcom, contract law is a powerful weapon. Terms of service can be invoked to ban users from availing themselves of interoperable tools (from third-party ink to third-party parts to ad blockers for social media), which also opens the door to tortious interference claims against the companies who make comcom tools.</p>



<p>Noncompetes can be invoked (in most states) to prevent former employees from striking out on their own with interoperable products that help their previous employers’ customers pay less and get more from the services they use. Trade secrets and nondisclosure can be invoked even when no noncompete exists, as a means of preventing former employees from directly competing with interoperable products and services.</p>



<p>All of these can be moderated by state-level rules on contracting; by banning certain terms or declaring them unenforceable, states could kick open the doors to Big Tech’s biggest silos. What’s more, given the concentration of tech in a few geographic regions in the U.S. (and the problems associated with moving elsewhere), changes in just a few states could make a huge difference for people across America, and the world. Pass bills in California, New York and Washington and you’d be much of the way there. Throw in Texas and Massachusetts and you’d have nearly every base covered.</p>



<p>These changes would be good for business! Admittedly, they’d be bad for giant, stagnant monopolists, but they’d be good for all the small businesses that would nibble them to death with a thousand comcom products that shifted value back to users and workers and away from big institutional shareholders.</p>



<h2><strong>Adult Supervision</strong></h2>



<p>There is pending legislation called the <a href="https://www.govinfo.gov/app/details/BILLS-117s4309is" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">U.S. ACCESS Act</a>, which has a successful equivalent in the <a href="https://digital-markets-act.ec.europa.eu/index_en" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">EU Digital Markets Act</a>; it is a powerful bill that would force the biggest tech companies to open up their silos by making available APIs (gateways for exchanging information with their users). This is meant to allow interoperability without the messiness and unreliability of comcom.</p>



<p>But while an API sounds like a reliable way for users who quit a platform to go on communicating with the people they left behind there, it has one major weakness: The API has to be run by the big company, and it is designed to erode that company’s monopoly profits by directly enabling its competitors to eat its lunch by luring away its most valuable users.</p>



<p>This creates a powerful incentive for the tech companies to cheat — and there are so many hard-to-detect ways to do so. They could slow things down to a crawl and blame too much traffic. They could throw out a lot of spurious error messages and shake their heads in bewilderment. They could introduce random dropped messages — say, 3% of the overall traffic, which would make everything kind of suck but be hard to decisively identify.</p>



<p>The tech giants cheat all the time. They are pathologically incapable of not cheating. Whether it’s privacy law, competition law, labor law, environmental law — you name it, they cheat on it. But they also kind of suck at it. They keep getting caught. A disgruntled employee blows the whistle, for example, or the conspirators just get sloppy.</p>



<p>When a tech giant cheats on the ACCESS Act or the Digital Markets Act, and when it gets caught, it will have to pay a very large fine. These laws are designed to hurt. Obviously, cheaters will throw lawyers at the problem. When the fine runs into the billions, it’s rational to spend hundreds of millions on outside counsel to get it reduced. One thing those lawyers will eventually do is offer a settlement: “Let’s just resolve this like reasonable people, and spare everyone all that delay and court expenses, shall we?”</p>


<!-- Quote Block Template -->

<div>

    <p>
      “The tech giants are pathologically incapable of not cheating. Whether it’s privacy law, competition law, labor law, environmental law — you name it, they cheat on it.”    </p>

    
    
  </div>




<p>Here’s the settlement we should offer them: a special master. A special master is a court-appointed guardian who supervises the conduct of a company or individual as part of a court procedure or settlement.</p>



<p>This person would act as adult supervision for cheating tech companies. Before a tech giant could sue or threaten another company, the special master would have to sign off on it, to make sure that the lawsuit was about a true infringement and not merely a way to prevent a competitor from doing some comcom to help the cheater’s customers get more privacy, usability, accessibility or equity.</p>



<p>This is like having a corporate parole officer, someone who has to approve any moves outside the usual routine. It’s a very big step to take, but very big companies demand very big steps.&nbsp;</p>



<p>Once a company has adult supervision, would-be interoperators are on a much surer footing. They can reverse engineer, scrape and take other comcom measures and know that the tech giant they’re nibbling away at can’t bring the law to bear against them, provided that they can make a case to the special master that they’re acting on behalf of the users. That’s an assurance that technologists can bring to investors or crowd-funders or granting agencies, opening up space for startups, social enterprises, nonprofits and co-ops to provide interoperable services.</p>



<h2><strong>The Interoperator’s Defense</strong></h2>



<p>This one is way out there, but it’s a potentially valid shortcut. Rather than reforming copyright, trademark, contract, patent, trade-secrecy, cybersecurity and other laws so they can’t be used to obstruct comcom, we just create a legal defense against claims under these laws (and others).</p>



<p>Here’s how that defense works: A company could sue you for breaking one of these laws, but in the early stages of the trial, you can put forward the defense that you were engaged in interoperability that furthered user privacy, security, accessibility or other legitimate interests. If the judge decides that’s what you were doing, the case ends.</p>



<p>This means that companies still get their day in court. They can still use the law to shut down people who hack their service and hurt their users. But interoperators also get a day in court. They can use a relatively cheap, relatively fast legal process to get past otherwise punitively expensive and time-consuming courtroom fights with monopolists whose legal budgets are effectively unlimited — who might be willing to spend otherwise irrational sums of money getting the courts to put interoperators out of business because that will scare off future comcom upstarts.</p>



<p>Interop mandates and comcom are no substitutes for traditional antitrust remedies like corporate breakups. There’s just nothing fair about massive, deep-pocketed companies operating app stores and competing with the companies that sell apps in those stores, or selling e-books and also competing with the authors and publishers who publish on their e-book stores, or serving search results and also competing with the companies listed in those results, or operating a social media network and also a bunch of other social media networks.</p>



<p>But breakups take a long-ass time. Consider the breakup of AT&amp;T. At first it looks like it took eight or so years: from 1974, when the Justice Department <a href="https://www.justice.gov/archive/atr/public/press_releases/1974/338834.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">filed</a> its antitrust lawsuit, to 1982, when the breakup was <a href="https://www.washingtonpost.com/archive/politics/1982/01/09/us-ends-antitrust-suits-against-at38/6545a672-b488-4915-9064-8baf4da21590/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">finalized</a>. That’s extremely misleading! In truth, U.S. competition regulators first took on AT&amp;T in 1913, 69 years before the company was finally broken up. For most of the intervening decades, AT&amp;T was fending off some kind of attempt to tame it.</p>



<p>We have monopolies — lots of them, in every sector, including tech. With monopolies, an ounce of prevention is worth a ton of cure. But, as the old Irish joke goes, “If I were you, I wouldn’t start from here.”</p>


<!-- Quote Block Template -->

<div>

    <p>
      “Interop mandates and comcom are no substitutes for traditional antitrust remedies like corporate breakups. But breakups take a long-ass time.”    </p>

    
    
  </div>




<p>Tech’s critics rightly decry “tech exceptionalism,” the idea that tech is different and so should play by a different set of rules — and they’re right in at least two ways:</p>



<p>First, tech is foundational. The questions of tech monopoly aren’t inherently more important than, say, the climate emergency or gender and racial discrimination. But tech — free, fair, open tech — is a precondition for winning those other fights. Winning the fight for better tech won’t solve those other problems, but losing the fight for better tech extinguishes any hope of winning those more important fights.</p>



<p>Second, tech is interoperable. That means that, long before we break up Meta (formerly Facebook) or Google or Microsoft or Apple, we can offer immediate, profound relief to the people whose freedom of motion is hemmed in by tech’s walled gardens. We don’t have to wait for breakups to allow someone to install a third-party app, or bypass heavy-handed (or overly tolerant) moderation, or overcome the algorithmic burial of their material. We can do that right now, with interop.</p>



<p>And when we do, we hasten breakups! The bullying that walled gardens enable isn’t driven by sadism, after all, but by profit. Letting people wriggle out of companies’ bad decisions means that those companies will lose the money they would have otherwise earned thereby — and if companies behave better to prevent those users from defecting, then they will forego the profits they would have realized by acting worse.</p>



<p>Monopolies need those profits to defend themselves from trustbusters. Hiring lawyers to outfox the Justice Department isn’t cheap, and IBM wouldn’t have been able to pay those bills if it hadn’t been piling up a war chest by abusing its monopoly for decades. Interop starves the beast, depriving monopolists of the excess profits they would otherwise be able to use to keep trustbusters at bay. With interop, it’s harder for a company to make itself too big to jail.</p>



<p>But interop also makes it harder for a company to make itself too big to fail. The Pentagon wouldn’t have been such an ardent defender of AT&amp;T if it hadn’t been so dependent on Ma Bell: If the U.S. military could have easily uncoupled itself from AT&amp;T —&nbsp;by buying interoperable products and services to replace the ones that Bell Labs supplied — then the Defense Department might have been less eager to go to war to defend the Bell System.</p>



<p>And, as Lincoln knew, the military shouldn’t be single-sourcing key capacities to one company without at least securing a promise of interoperability.</p>



<p>Starve monopolies of the profits used to hold trustbusters at bay, cut them off from the allies who fight trustbusters on their behalf, and maybe it won’t take 69 years to break up Microsoft. Or Apple. Or Google. Or Meta. Or Salesforce. Or Oracle.</p>

          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine-tuning Mistral 7B on Magic the Gathering Draft (320 pts)]]></title>
            <link>https://generallyintelligent.substack.com/p/fine-tuning-mistral-7b-on-magic-the</link>
            <guid>38533105</guid>
            <pubDate>Tue, 05 Dec 2023 16:33:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://generallyintelligent.substack.com/p/fine-tuning-mistral-7b-on-magic-the">https://generallyintelligent.substack.com/p/fine-tuning-mistral-7b-on-magic-the</a>, See on <a href="https://news.ycombinator.com/item?id=38533105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>In the last six months, I’ve </span><a href="https://generallyintelligent.substack.com/p/llama-2-time-to-fine-tune" rel="">written about fine tuning</a><span> </span><a href="https://generallyintelligent.substack.com/p/gpt-35-finetuning" rel="">a few times</a><span>. Fine tuning is such an enticing technology — promising to fill the gaps in GPT-4’s capabilities while also being faster and cheaper. For as often as fine tuning is discussed, though, I’ve found a surprisingly small amount of content out there that has helped me reason about </span><strong>how effective fine tuning is and how hard it is to successfully fine tune new capabilities into language models.</strong></p><p>So, I decided to take things into my own hands, dust off my ML chops, and find out for myself. </p><p><span>I was particularly interested in testing models’ ability to </span><em><strong>reason</strong><span> </span></em><span>(i.e., perform a somewhat complex task that requires high context understanding) about </span><em><strong>out-of-distribution</strong><span> (</span></em><span>i.e.,</span><em> </em><span>unseen</span><em>)</em><span> data. I ended up using a hobby of mine: </span><em><strong><a href="https://magic.wizards.com/en" rel="">Magic the Gathering</a><span> (specifically, draft)</span></strong></em><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png" width="716" height="402.25824175824175" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:818,&quot;width&quot;:1456,&quot;resizeWidth&quot;:716,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d021374-2254-4544-8282-b68f72f01ae0_1588x892.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Picking a card in a Magic Draft</figcaption></figure></div><p><span>For the unfamiliar: Magic: The Gathering is a strategic trading card game where players use decks of cards representing creatures and spells to battle against their opponents. One of the ways that players play Magic (and my personal favorite way) is </span><em><strong>draft</strong></em><span>, where players build their decks by selecting individual cards from a rotating pool of randomized cards passed among them.</span></p><p><em><strong>Draft </strong></em><span>fits my criteria pretty nicely:</span></p><ul><li><p><strong>Reasoning: </strong><span>choosing a card from a randomized pack is quite skill testing and often requires a cohesive understanding of the context (e.g., what cards have you picked so far, what cards are available in the current pack)</span></p></li><li><p><strong>Out-of-distribution: </strong><span>New Magic cards are released ~4-6 times a year, and the most recent cards are not found in the training corpus of LLMs.</span></p></li></ul><p><span>Another important piece: </span><strong>data. </strong><span>There’s an awesome service called </span><a href="https://www.17lands.com/" rel="">17lands</a><span> that has a huge trove of historical data — players use 17lands’ tracking service to track draft data from the digital Magic client. With that data, you can extract “ground truth” by looking at the draft picks made by the best players on the service (sorted by win rate). This is all a bit fuzzy (a lot of great Magic players debate about correct picks all the time), but it’s a good enough signal to test LLM’s ability to learn a new task.</span></p><p><em><span>If you’re curious about data details, </span><a href="https://gist.github.com/davidhershey/665d45999376c34eefbb71acbf67dafd" rel="">here’s an example of what 17lands data looks like when transformed into a prompt for an LLM</a><span>.</span></em></p><p>Let’s get straight to the results, then dig into some specific learnings and thoughts:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png" width="1200" height="567.3292999135696" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:547,&quot;width&quot;:1157,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:88838,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca314ee1-ea26-4fcf-a48c-eba1f745cf83_1157x547.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Thoughts:</strong></p><ul><li><p><strong>A fine tuned 7B parameter model handily beat GPT-4 and came close to human-level (or at least author-level) performance on this task.</strong></p></li><li><p><strong> </strong><span>It looks like fine-tuned GPT-3.5 would be even better, but </span><strong>fine-tuning GPT-3.5 is really expensive!</strong><span> (~100x more expensive than fine-tuning Mistral on bare metal + a premium price for each inference). A fine-tuning run of GPT-3.5 equivalent to my largest run of Mistral-7b would have cost ~$500 — an expensive experiment.</span></p></li><li><p><strong>Fine tuning is still a bit of an art</strong><span> — I had hoped that this would feel more like engineering than science, but there was a lot of experimentation to be done. In particular, prompt engineering with the long feedback loop of fine-tuning is brutal. I’ll go into more details below. </span></p><ul><li><p><em><strong><span>When in doubt, </span><a href="https://github.com/OpenAccess-AI-Collective/axolotl" rel="">use axolotl</a></strong><a href="https://github.com/OpenAccess-AI-Collective/axolotl" rel=""> </a><strong><a href="https://github.com/OpenAccess-AI-Collective/axolotl" rel="">for fine tuning</a><span>. </span></strong><span>It will save you from missing out on a lot of little optimizations.</span></em></p></li></ul></li><li><p><strong>Even the small OSS models are huge by the standard of 5 years ago</strong><span>. It’s one thing to read “7 Billion Parameters”; it’s another to deal with fitting 7 billion parameters and all of the associated math onto a GPU. </span></p></li><li><p><span>I did one interesting experiment, fine tuning a model on one set of cards, then evaluating it on an unseen set of cards</span><strong>. </strong><span>The </span><strong>model seemed to generalize on the concept of drafting</strong><span>, not just memorizing which cards were good.</span></p></li></ul><p><strong>Building a text dataset: </strong><span>The 17lands draft dataset is actually a big CSV file that describes a series of draft picks made by users, roughly with the format of:</span></p><ul><li><p>The cards that were available in the current pack</p></li><li><p>The cards the drafter had picked so far</p></li><li><p>The card the drafter picked from that pack</p></li></ul><p>To make this data suitable for fine tuning a language model, you have to transform it into text — I ended up using the assistant format popularized by OpenAI:</p><div itemprop="text" id="gist126705539" data-attrs="{&quot;innerHTML&quot;:&quot;<div id=\&quot;gist126705539\&quot; class=\&quot;gist\&quot;>\n    <div class=\&quot;gist-file\&quot; translate=\&quot;no\&quot;>\n      <div class=\&quot;gist-data\&quot;>\n        <div class=\&quot;js-gist-file-update-container js-task-list-container file-box\&quot;>\n  <div id=\&quot;file-full_draft_prompt_chatml-txt\&quot; class=\&quot;file my-2\&quot;>\n    \n    <div itemprop=\&quot;text\&quot; class=\&quot;Box-body p-0 blob-wrapper data type-text  \&quot;>\n\n        \n<div class=\&quot;js-check-bidi js-blob-code-container blob-code-content\&quot;>\n\n  <template class=\&quot;js-file-alert-template\&quot;>\n  <div data-view-component=\&quot;true\&quot; class=\&quot;flash flash-warn flash-full d-flex flex-items-center\&quot;>\n  <svg aria-hidden=\&quot;true\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 16 16\&quot; version=\&quot;1.1\&quot; width=\&quot;16\&quot; data-view-component=\&quot;true\&quot; class=\&quot;octicon octicon-alert\&quot;>\n    <path d=\&quot;M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\&quot;></path>\n</svg>\n    <span>\n      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.\n      <a class=\&quot;Link--inTextBlock\&quot; href=\&quot;https://github.co/hiddenchars\&quot; target=\&quot;_blank\&quot;>Learn more about bidirectional Unicode characters</a>\n    </span>\n\n\n  <div data-view-component=\&quot;true\&quot; class=\&quot;flash-action\&quot;>        <a href=\&quot;{{ revealButtonHref }}\&quot; data-view-component=\&quot;true\&quot; class=\&quot;btn-sm btn\&quot;>    Show hidden characters\n</a>\n</div>\n</div></template>\n<template class=\&quot;js-line-alert-template\&quot;>\n  <span aria-label=\&quot;This line has hidden Unicode characters\&quot; data-view-component=\&quot;true\&quot; class=\&quot;line-alert tooltipped tooltipped-e\&quot;>\n    <svg aria-hidden=\&quot;true\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 16 16\&quot; version=\&quot;1.1\&quot; width=\&quot;16\&quot; data-view-component=\&quot;true\&quot; class=\&quot;octicon octicon-alert\&quot;>\n    <path d=\&quot;M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\&quot;></path>\n</svg>\n</span></template>\n\n  <table data-hpc class=\&quot;highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file\&quot; data-tab-size=\&quot;8\&quot; data-paste-markdown-skip data-tagsearch-lang=\&quot;Text\&quot; data-tagsearch-path=\&quot;full_draft_prompt_chatml.txt\&quot;>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L1\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;1\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC1\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>{</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L2\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;2\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC2\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>  &amp;quot;messages&amp;quot;: [</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L3\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;3\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC3\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L4\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;4\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC4\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>      &amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;,</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L5\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;5\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC5\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>      &amp;quot;content&amp;quot;: &amp;quot;You are DraftGPT, a Magic the Gathering Hall of Famer and helpful AI assistant that helps players choose what card to pick during a draft. You are a master of the current draft set, and know every card well.\\n\\nWhen asked for a draft pick, respond with the card&amp;#39;s name first.&amp;quot;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L6\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;6\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC6\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    },</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L7\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;7\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC7\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L8\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;8\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC8\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>      &amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;,</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L9\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;9\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC9\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>      &amp;quot;content&amp;quot;: &amp;quot;In our Magic the Gathering draft, we&amp;#39;re on pack 2 pick 13. These are the contents of our pool so far:\\n-------------------------\\nEvolving Wilds --  (common)\\nRat Out -- {B} (common)\\nNot Dead After All -- {B} (common)\\nHopeless Nightmare -- {B} (common)\\nBarrow Naughty -- {1}{B} (common)\\nUnassuming Sage -- {1}{W} (common)\\nThe Witch&amp;#39;s Vanity -- {1}{B} (uncommon)\\nSpell Stutter -- {1}{U} (common)\\nMintstrosity -- {1}{B} (common)\\nWater Wings -- {1}{U} (common)\\nBarrow Naughty -- {1}{B} (common)\\nGadwick&amp;#39;s First Duel -- {1}{U} (uncommon)\\nBitter Chill -- {1}{U} (uncommon)\\nThe Princess Takes Flight -- {2}{W} (uncommon)\\nStockpiling Celebrant -- {2}{W} (common)\\nVoracious Vermin -- {2}{B} (common)\\nDevouring Sugarmaw // Have for Dinner -- {2}{B}{B} // {1}{W} (rare)\\nMisleading Motes -- {3}{U} (common)\\nJohann&amp;#39;s Stopgap -- {3}{U} (common)\\nBesotted Knight // Betroth the Beast -- {3}{W} // {W} (common)\\nThreadbind Clique // Rip the Seams -- {3}{U} // {2}{W} (uncommon)\\nTwining Twins // Swift Spiral -- {2}{U}{U} // {1}{W} (rare)\\nEriette&amp;#39;s Whisper -- {3}{B} (common)\\nFarsight Ritual -- {2}{U}{U} (rare)\\nTwisted Sewer-Witch -- {3}{B}{B} (uncommon)\\nInto the Fae Court -- {3}{U}{U} (common)\\n-------------------------\\n\\nTo keep track of what colors are open, you&amp;#39;ve counted how many cards of each color identity you&amp;#39;ve seen in the last 5 packs. Here is the breakdown:\\nW: 11\\nB: 6\\nG: 4\\nRW: 1\\nR: 2\\n\\nThese are the contents of the pack:\\n-------------------------\\nCut In -- {3}{R}\\nSorcery (common)\\nCut In deals 4 damage to target creature.\\nCreate a Young Hero Role token attached to up to one target creature you control. (If you control another Role on it, put that one into the graveyard. Enchanted creature has \\&amp;quot;Whenever this creature attacks, if its toughness is 3 or less, put a +1/+1 counter on it.\\&amp;quot;)\\n-------------------------\\nSkewer Slinger -- {1}{R}\\nCreature — Dwarf Knight (common)\\nReach\\nWhenever Skewer Slinger blocks or becomes blocked by a creature, Skewer Slinger deals 1 damage to that creature.\\n1/3\\n-------------------------\\n\\nWhat card would you pick from this pack?&amp;quot;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L10\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;10\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC10\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    },</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L11\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;11\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC11\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L12\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;12\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC12\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>      &amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;,</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L13\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;13\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC13\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>      &amp;quot;content&amp;quot;: &amp;quot;Cut In&amp;quot;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L14\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;14\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC14\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    }</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L15\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;15\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC15\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>  ]</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-L16\&quot; class=\&quot;blob-num js-line-number js-code-nav-line-number js-blob-rnum\&quot; data-line-number=\&quot;16\&quot;></td>\n          <td id=\&quot;file-full_draft_prompt_chatml-txt-LC16\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>}</td>\n        </tr>\n  </table>\n</div>\n\n\n    </div>\n\n  </div>\n</div>\n\n      </div>\n      <div class=\&quot;gist-meta\&quot;>\n        <a href=\&quot;https://gist.github.com/davidhershey/f57d0b19563fef86b117751dcbe6de20/raw/7bba77a61f6b698563157efe2a772954456cfe5e/full_draft_prompt_chatml.txt\&quot; style=\&quot;float:right\&quot; class=\&quot;Link--inTextBlock\&quot;>view raw</a>\n        <a href=\&quot;https://gist.github.com/davidhershey/f57d0b19563fef86b117751dcbe6de20#file-full_draft_prompt_chatml-txt\&quot; class=\&quot;Link--inTextBlock\&quot;>\n          full_draft_prompt_chatml.txt\n        </a>\n        hosted with &amp;#10084; by <a class=\&quot;Link--inTextBlock\&quot; href=\&quot;https://github.com\&quot;>GitHub</a>\n      </div>\n    </div>\n</div>\n&quot;,&quot;stylesheet&quot;:&quot;https://github.githubassets.com/assets/gist-embed-94178ea21d55.css&quot;}" data-component-name="GitgistToDOM"><div data-view-component="true"><p><span>
  
    

    </span><span><span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      </span><a href="https://github.co/hiddenchars" target="_blank" rel="">Learn more about bidirectional Unicode characters</a><span>
    </span></span><span>


  </span></p></div><table data-hpc="" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Text" data-tagsearch-path="full_draft_prompt_chatml.txt"><tbody><tr><td id="file-full_draft_prompt_chatml-txt-L1" data-line-number="1"></td><td id="file-full_draft_prompt_chatml-txt-LC1">{</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L2" data-line-number="2"></td><td id="file-full_draft_prompt_chatml-txt-LC2">  "messages": [</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L3" data-line-number="3"></td><td id="file-full_draft_prompt_chatml-txt-LC3">    {</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L4" data-line-number="4"></td><td id="file-full_draft_prompt_chatml-txt-LC4">      "role": "system",</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L5" data-line-number="5"></td><td id="file-full_draft_prompt_chatml-txt-LC5">      "content": "You are DraftGPT, a Magic the Gathering Hall of Famer and helpful AI assistant that helps players choose what card to pick during a draft. You are a master of the current draft set, and know every card well.\n\nWhen asked for a draft pick, respond with the card's name first."</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L6" data-line-number="6"></td><td id="file-full_draft_prompt_chatml-txt-LC6">    },</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L7" data-line-number="7"></td><td id="file-full_draft_prompt_chatml-txt-LC7">    {</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L8" data-line-number="8"></td><td id="file-full_draft_prompt_chatml-txt-LC8">      "role": "user",</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L9" data-line-number="9"></td><td id="file-full_draft_prompt_chatml-txt-LC9">      "content": "In our Magic the Gathering draft, we're on pack 2 pick 13. These are the contents of our pool so far:\n-------------------------\nEvolving Wilds --  (common)\nRat Out -- {B} (common)\nNot Dead After All -- {B} (common)\nHopeless Nightmare -- {B} (common)\nBarrow Naughty -- {1}{B} (common)\nUnassuming Sage -- {1}{W} (common)\nThe Witch's Vanity -- {1}{B} (uncommon)\nSpell Stutter -- {1}{U} (common)\nMintstrosity -- {1}{B} (common)\nWater Wings -- {1}{U} (common)\nBarrow Naughty -- {1}{B} (common)\nGadwick's First Duel -- {1}{U} (uncommon)\nBitter Chill -- {1}{U} (uncommon)\nThe Princess Takes Flight -- {2}{W} (uncommon)\nStockpiling Celebrant -- {2}{W} (common)\nVoracious Vermin -- {2}{B} (common)\nDevouring Sugarmaw // Have for Dinner -- {2}{B}{B} // {1}{W} (rare)\nMisleading Motes -- {3}{U} (common)\nJohann's Stopgap -- {3}{U} (common)\nBesotted Knight // Betroth the Beast -- {3}{W} // {W} (common)\nThreadbind Clique // Rip the Seams -- {3}{U} // {2}{W} (uncommon)\nTwining Twins // Swift Spiral -- {2}{U}{U} // {1}{W} (rare)\nEriette's Whisper -- {3}{B} (common)\nFarsight Ritual -- {2}{U}{U} (rare)\nTwisted Sewer-Witch -- {3}{B}{B} (uncommon)\nInto the Fae Court -- {3}{U}{U} (common)\n-------------------------\n\nTo keep track of what colors are open, you've counted how many cards of each color identity you've seen in the last 5 packs. Here is the breakdown:\nW: 11\nB: 6\nG: 4\nRW: 1\nR: 2\n\nThese are the contents of the pack:\n-------------------------\nCut In -- {3}{R}\nSorcery (common)\nCut In deals 4 damage to target creature.\nCreate a Young Hero Role token attached to up to one target creature you control. (If you control another Role on it, put that one into the graveyard. Enchanted creature has \"Whenever this creature attacks, if its toughness is 3 or less, put a +1/+1 counter on it.\")\n-------------------------\nSkewer Slinger -- {1}{R}\nCreature — Dwarf Knight (common)\nReach\nWhenever Skewer Slinger blocks or becomes blocked by a creature, Skewer Slinger deals 1 damage to that creature.\n1/3\n-------------------------\n\nWhat card would you pick from this pack?"</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L10" data-line-number="10"></td><td id="file-full_draft_prompt_chatml-txt-LC10">    },</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L11" data-line-number="11"></td><td id="file-full_draft_prompt_chatml-txt-LC11">    {</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L12" data-line-number="12"></td><td id="file-full_draft_prompt_chatml-txt-LC12">      "role": "assistant",</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L13" data-line-number="13"></td><td id="file-full_draft_prompt_chatml-txt-LC13">      "content": "Cut In"</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L14" data-line-number="14"></td><td id="file-full_draft_prompt_chatml-txt-LC14">    }</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L15" data-line-number="15"></td><td id="file-full_draft_prompt_chatml-txt-LC15">  ]</td></tr><tr><td id="file-full_draft_prompt_chatml-txt-L16" data-line-number="16"></td><td id="file-full_draft_prompt_chatml-txt-LC16">}</td></tr></tbody></table></div><p><strong>This very quickly exposes the most challenging piece of fine tuning</strong><span>: formatting the data for the right outcome is </span><em>challenging </em><span>and </span><em>fundamentally experimental</em><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png" width="542" height="588.93039049236" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1280,&quot;width&quot;:1178,&quot;resizeWidth&quot;:542,&quot;bytes&quot;:1698572,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1def04-beb3-461b-9581-8e0456acbebd_1178x1280.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>By now, most folks are familiar with prompt engineering — the experimental process of modifying your prompt to get the best performance out of a language model. </span><strong>The prompt engineering process is 100x slower with fine tuning. </strong><span>You typically need to kick off a multiple-hour job to test a prompt. This bogs down the experimental workflow significantly and makes fine-tuning feel just as challenging as classical machine learning.</span></p><p>To illustrate with the Magic draft problem, I considered and tested the following:</p><ul><li><p>~5 prompt formats, in particular how much detail about each card to show</p></li><li><p>Adding additional context about the last few draft picks to have “memory”</p></li><li><p>Including training lines of “card trivia,” where the model is asked to remember details about the new cards</p></li></ul><p>I did ~ 40 hours of experiments and still don’t conclusively feel that I’ve answered questions about what prompt format is “best” for this task. There is a lot of room to experiment.</p><p><strong>Finding GPUs: </strong><span>doesn’t need to be said, but it sucks! Most places don’t have a lot of availability. I ended up renting an hourly GPU from </span><a href="https://www.runpod.io/" rel="">Runpod</a><span> (an RTX 4090 w/ 24GB of VRAM) for ~$0.7/hr. </span></p><p><strong>Fine tuning script: </strong><span>This isn’t my first ML rodeo, so my gut was to write my own training script with HuggingFace transformers + </span><a href="https://www.google.com/search?q=peft&amp;sourceid=chrome&amp;ie=UTF-8" rel="">PEFT</a><span>. Considering my limited GPU situation, </span><a href="https://arxiv.org/abs/2305.14314" rel="">QLoRA</a><span> seemed like the way to go.</span></p><p><span>It turns out that writing my own script was a bad idea! There are a whole bunch of finicky little optimizations and options that range from </span><a href="https://github.com/Dao-AILab/flash-attention" rel="">straightforward-if-you-know-about-them</a><span> to </span><a href="https://huggingface.co/docs/peft/conceptual_guides/lora#common-lora-parameters-in-peft" rel="">pretty obtuse without reading a research paper</a><span>. Nothing insurmountable, but it would take a long time to figure out yourself.</span></p><p><span>I ended up using </span><a href="https://github.com/OpenAccess-AI-Collective/axolotl" rel="">axolotl</a><span>, which implements a ton of those optimizations out of the box and was much easier to get running (and running quickly). Their documentation is actually pretty decent, and I think is the right starting point for most people to fine-tune LLMs.</span></p><p><strong>A note on the models: </strong><span>Holy crap, LLMs are seriously large! The last time I trained models regularly was ~ 2019, when Bert had ~110 million parameters; now, the “small” LLMs are 70 times bigger than that. Models this large are fundamentally cumbersome. Weights being ~16GB makes storage a real concern; GPU memory is challenging even with methods like QLora. No wonder the best researchers are such a hot commodity; this is seriously challenging work at the largest scale.</span></p><p><strong>Start with evaluation first</strong><span>: One lesson from ML of old that I don’t think has been adopted enough among the prompt engineering wizards: you should always build a good evaluation before starting your experiments. Here, evaluation was pretty easy (hold out some full drafts from the training data and check if the model picks the same card as the human on the holdout data), but having a good evaluation set made reasoning about fine-tuning much more straightforward.</span></p><p><strong>Some criteria for language models are hard to define: </strong><span>The “pick the right card” task is pretty easy to define for Magic drafts, but there are some fuzzier things that I would like the final model to do, too:</span></p><ul><li><p>When it makes different picks, they should be justifiable</p></li><li><p>It would be nice if the model could give a reasonable explanation for “why” it made a pick</p></li></ul><p><span>Each of those is much harder to define, and I ended up testing them with the “eye test” by going through a bunch of examples, but this was slow. FWIW, </span><strong>GPT-4 is better at making less “weird” picks and better at justifying its choices than the fine-tuned smaller models.</strong></p><p>My two biggest takeaways from this experiment:</p><ul><li><p>Fine tuning on new data can be remarkably effective, easily surpassing GPT-4 + in-context learning on both accuracy and cost. </p></li><li><p>Fine tuning is a fundamentally experimental process to get “right”, and doing it well is a specialized skillset (and in particular, a skillset that is harder to learn than prompt engineering).</p></li></ul><p>In terms of how the bots actually feel as drafters? Pretty good! </p><p>I wired up the draft pick model to the logs generated by Magic Arena, whipped up a quick electron app, and have done a few drafts with a “Magic Copilot”:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png" width="648" height="857.8077571669477" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1570,&quot;width&quot;:1186,&quot;resizeWidth&quot;:648,&quot;bytes&quot;:511921,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee2540-efad-4fa0-9c8a-3d682df9a567_1186x1570.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Some quirks:</p><ul><li><p>The pick is generated by a fine tuned model, but the commentary is generated by GPT-4. This works well most of the time, but occasionally GPT-4 disagrees with the fine tune and immediately contradicts it 😅</p></li><li><p>I’ve hooked up eight draft AIs to a simulated draft (i.e., all of the bots are drafting against each other). They have some quirky behavior when passing to each other — they have a pretty weird tendency to draft mono-colored decks. If there’s a human making other picks, they tend to converge into much more normal-looking decks.</p></li></ul><p>Overall, I would venture to guess this is probably one of the more powerful and humanlike draft AIs out there right now. Compared to the bots in Magic Arena’s quick draft feature, these are much more similar to a high-quality human drafter than a heuristic bot.</p><p><span>Wizards of the Coast — if you’re looking for excessively high fidelity and somewhat expensive to run draft AI, </span><strong>hit me up! </strong><span>I’m happy to send you some LLMs!</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Common Voice (281 pts)]]></title>
            <link>https://commonvoice.mozilla.org/en</link>
            <guid>38532761</guid>
            <pubDate>Tue, 05 Dec 2023 16:13:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://commonvoice.mozilla.org/en">https://commonvoice.mozilla.org/en</a>, See on <a href="https://news.ycombinator.com/item?id=38532761">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The challenges of supporting foreign key constraints (114 pts)]]></title>
            <link>https://planetscale.com/blog/challenges-of-supporting-foreign-key-constraints</link>
            <guid>38532746</guid>
            <pubDate>Tue, 05 Dec 2023 16:12:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://planetscale.com/blog/challenges-of-supporting-foreign-key-constraints">https://planetscale.com/blog/challenges-of-supporting-foreign-key-constraints</a>, See on <a href="https://news.ycombinator.com/item?id=38532746">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><p>Today, PlanetScale launched support for foreign key constraints. This article covers some of the behind-the-scenes technical challenges we had to overcome to support them.</p></header><div><p><img alt="The challenges of supporting foreign key constraints" fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="100vw" srcset="https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=640&amp;q=75 640w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=750&amp;q=75 750w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=828&amp;q=75 828w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=1080&amp;q=75 1080w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=1200&amp;q=75 1200w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=1920&amp;q=75 1920w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=2048&amp;q=75 2048w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=3840&amp;q=75 3840w" src="https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-shlomi-blog.png&amp;w=3840&amp;q=75"></p></div><p><label for="toc">Table of contents</label></p><section><article><p>Today, <a href="https://planetscale.com/blog/announcing-foreign-key-constraints-support">PlanetScale announced</a> support for foreign key constraints.</p><p>This has been in the making for quite a while — around a year in fact. So, what was the problem? Why did it take so long? It's something that any and every database supports, right? Yes and no. To support foreign key constraints is one thing. To do so while still delivering <a href="https://planetscale.com/docs/learn/how-online-schema-change-tools-work">Online DDL</a>, <a href="https://planetscale.com/docs/concepts/deploy-requests#gated-deployments">gated deployments</a>, <a href="https://planetscale.com/docs/imports/database-imports">online imports</a>, and eventually cross shard support, is another.</p><p>When we launched PlanetScale, we refrained from supporting foreign keys constraints, first and foremost because we could not make them work with branching and Online DDL. It was a realization that came while we were building the product, and <a href="https://vitess.io/blog/2021-06-15-online-ddl-why-no-fk/">we took it as a fact of life</a>, something we'd have to work around. Around a year ago, we decided to really dive in to see what it would actually take to support them.</p><p>It turns out, we had to overcome challenges in almost every single layer of the product: some due to MySQL limitations, some due to how we want to incorporate foreign key support with PlanetScale's (through Vitess) Online DDL, and some due to branching and schema analysis logic. As you will see in this post, these are all closely intertwined.</p><h2 id="branching-and-deploy-requests"><a href="#branching-and-deploy-requests">Branching and Deploy requests</a></h2><p>The first challenge we had to deal with was handling branching and deploy requests. With <a href="https://planetscale.com/docs/concepts/branching">PlanetScale branching</a>, the user works in a development environment where they're free to make schema changes. Once they're ready to deploy those changes, they submit a <a href="https://planetscale.com/docs/concepts/deploy-requests">Deploy request</a>, which lets them review the schema changes they've made before deploying them to production.</p><p>The Deploy request page shows the user the semantic <em>diff</em> between the main (<code>base</code>) branch and their own (<code>head</code>) branch. PlanetScale uses <a href="https://planetscale.com/blog/database-branching-three-way-merge-schema-changes">three-way merge</a> to determine the diffs.</p><p>Supporting the foreign key constraint schema definitions is relatively simple, and is but a matter of understanding the SQL syntax involved. However, the semantic analysis is much more involved. Consider that in MySQL (or in InnoDB, rather, as we will discuss later on), the following rules must apply for any foreign key constraint definition:</p><ul><li>A foreign key constraint is a relationship between a parent table and a child table. As a special case, a table may reference itself as its parent.</li><li>The referenced (parent) table must exist.</li><li>The foreign key reference columns in the parent table must exist.</li><li>The referenced columns in the parent must be indexed in-order. There has to be an index covering the referenced columns in the same order they're referenced by the constraint. Optionally, the index may proceed to cover more columns.</li><li>The child's columns must match the referenced parent columns in count and in data type. An <code>INT</code> column on the child may not reference a <code>BIGINT</code> column on the parent. Interestingly, it's okay for <code>VARCHAR(32)</code> vs <code>VARCHAR(64)</code> in child and parent.</li></ul><p>These rules are strongly enforced by the MySQL server (assuming <code>FOREIGN_KEY_CHECKS=1</code>; things get less consistent when <code>FOREIGN_KEY_CHECKS=0</code>), which means that by the time the user submits their Deploy request, it should be safe to assume that the branch adheres to those rules. However, when PlanetScale evaluates a Deploy request, it not only computes the <em>diff</em> between branches, but also the <em>path</em> towards converting one branch (<code>base</code>) into another (<code>head</code>). That <em>path</em> is a valid sequence of steps which maintain the schema in a valid state at all times. Moreover, it evaluates whether, and how, these steps may be <a href="https://planetscale.com/blog/deploying-multiple-schema-changes-at-once">deployed all at once</a>.</p><p>Foreign key constraints introduce a new complexity to that evaluation. In the simplest form, they may require a specific order of deployment. As a trivial example, suppose we were to create a parent-child pair of tables, such as these (simplified):</p><div><pre><code><p><span>create</span><span> </span><span>table</span><span> parent </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> child </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> parent_id </span><span>int</span><span>,</span><span> </span><span>constraint</span><span> parent_id_fk </span><span>foreign</span><span> </span><span>key</span><span> </span><span>(</span><span>parent_id</span><span>)</span><span> </span><span>references</span><span> parent </span><span>(</span><span>id</span><span>)</span><span>)</span><span>;</span>
</p></code></pre></div><p>The deployment plan must of course first apply the creation of <code>parent</code>, and then the creation of <code>child</code>. The reverse order is invalid because <code>child</code> must reference an existing <code>parent</code> table.</p><p><em>Some</em> changes are eligible to run concurrently. Suppose we have the following:</p><div><pre><code><p><span>create</span><span> </span><span>table</span><span> t1 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> ref </span><span>int</span><span>,</span><span> </span><span>key</span><span> ref_idx </span><span>(</span><span>ref</span><span>)</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> t2 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> ref </span><span>int</span><span>,</span><span> </span><span>key</span><span> ref_idx </span><span>(</span><span>ref</span><span>)</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> t3 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> ref </span><span>int</span><span>,</span><span> </span><span>key</span><span> ref_idx </span><span>(</span><span>ref</span><span>)</span><span>)</span><span>;</span>
</p></code></pre></div><p>And, suppose we add foreign key constraints onto <code>t2</code> and <code>t3</code>, such that the diff evaluates to:</p><div><pre><code><p><span>ALTER</span><span> </span><span>TABLE</span><span> </span><span>`</span><span>t2</span><span>`</span><span> </span><span>ADD</span><span> </span><span>CONSTRAINT</span><span> </span><span>`</span><span>t2_ref_fk</span><span>`</span><span> </span><span>FOREIGN</span><span> </span><span>KEY</span><span> </span><span>(</span><span>`</span><span>ref</span><span>`</span><span>)</span><span> </span><span>REFERENCES</span><span> </span><span>`</span><span>t1</span><span>`</span><span> </span><span>(</span><span>`</span><span>id</span><span>`</span><span>)</span><span> </span><span>ON</span><span> </span><span>DELETE</span><span> </span><span>NO</span><span> </span><span>ACTION</span><span>;</span><span></span>
</p><p><span></span><span>ALTER</span><span> </span><span>TABLE</span><span> </span><span>`</span><span>t3</span><span>`</span><span> </span><span>ADD</span><span> </span><span>CONSTRAINT</span><span> </span><span>`</span><span>t3_ref_fk</span><span>`</span><span> </span><span>FOREIGN</span><span> </span><span>KEY</span><span> </span><span>(</span><span>`</span><span>ref</span><span>`</span><span>)</span><span> </span><span>REFERENCES</span><span> </span><span>`</span><span>t2</span><span>`</span><span> </span><span>(</span><span>`</span><span>id</span><span>`</span><span>)</span><span> </span><span>ON</span><span> </span><span>DELETE</span><span> </span><span>NO</span><span> </span><span>ACTION</span><span>;</span>
</p></code></pre></div><p>The two diffs may run concurrently, even though they both affect table <code>t2</code> (one directly, and one indirectly). More on why this is at all possible when we discuss <a href="#online-ddl">Online DDL</a>.</p><p>Even more complex is a scenario where two migrations cannot execute concurrently. Assume the base schema looks like this:</p><div><pre><code><p><span>create</span><span> </span><span>table</span><span> t1 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> info </span><span>int</span><span> </span><span>not</span><span> </span><span>null</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> t2 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> ts </span><span>timestamp</span><span>)</span><span>;</span>
</p></code></pre></div><p>And that our branch schema is:</p><div><pre><code><p><span>create</span><span> </span><span>table</span><span> t1 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> info </span><span>int</span><span> </span><span>not</span><span> </span><span>null</span><span>,</span><span> p </span><span>int</span><span>,</span><span> </span><span>key</span><span> p_idx </span><span>(</span><span>p</span><span>)</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> t2 </span><span>(</span><span>id </span><span>int</span><span> </span><span>primary</span><span> </span><span>key</span><span>,</span><span> ts </span><span>timestamp</span><span>,</span><span> t1_p </span><span>int</span><span>,</span><span> </span><span>foreign</span><span> </span><span>key</span><span> </span><span>(</span><span>t1_p</span><span>)</span><span> </span><span>references</span><span> t1 </span><span>(</span><span>p</span><span>)</span><span> </span><span>on</span><span> </span><span>delete</span><span> </span><span>no</span><span> </span><span>action</span><span>)</span><span>;</span>
</p></code></pre></div><p>The diffs are:</p><div><pre><code><p><span>ALTER</span><span> </span><span>TABLE</span><span> </span><span>`</span><span>t1</span><span>`</span><span> </span><span>ADD</span><span> </span><span>COLUMN</span><span> </span><span>`</span><span>p</span><span>`</span><span> </span><span>int</span><span>,</span><span> </span><span>ADD</span><span> </span><span>INDEX</span><span> </span><span>`</span><span>p_idx</span><span>`</span><span> </span><span>(</span><span>`</span><span>p</span><span>`</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>ALTER</span><span> </span><span>TABLE</span><span> </span><span>`</span><span>t2</span><span>`</span><span> </span><span>ADD</span><span> </span><span>COLUMN</span><span> </span><span>`</span><span>t1_p</span><span>`</span><span> </span><span>int</span><span>,</span><span> </span><span>ADD</span><span> </span><span>INDEX</span><span> </span><span>`</span><span>t1_p</span><span>`</span><span> </span><span>(</span><span>`</span><span>t1_p</span><span>`</span><span>)</span><span>,</span><span> </span><span>ADD</span><span> </span><span>CONSTRAINT</span><span> </span><span>`</span><span>t2_ibfk_1</span><span>`</span><span> </span><span>FOREIGN</span><span> </span><span>KEY</span><span> </span><span>(</span><span>`</span><span>t1_p</span><span>`</span><span>)</span><span> </span><span>REFERENCES</span><span> </span><span>`</span><span>t1</span><span>`</span><span> </span><span>(</span><span>`</span><span>p</span><span>`</span><span>)</span><span> </span><span>ON</span><span> </span><span>DELETE</span><span> </span><span>NO</span><span> </span><span>ACTION</span><span>;</span>
</p></code></pre></div><p>However, it is impossible to even begin the migration on <code>t2</code> before the migration on <code>t1</code> is fully complete. That's because MySQL strictly requires an index to exist on the parent table's referenced columns. Assuming the parent table is already populated, we're looking at a potentially significant time running the first migration before we can begin the second.</p><p>Last, and of course this is not strictly limited to foreign key constraints, you <em>can go too far</em> with your branch changes. PlanetScale attempts to reduce the diff to a single change per table/view. If a branch differs so much from <code>base</code> that it takes multiple steps to operate on the same table to get it into <code>base</code>, then the Deploy request is not deployable.</p><p>Courtesy of <a href="https://vitess.io/blog/2023-04-24-schemadiff"><code>schemadiff</code></a>, this is all evaluated in-memory at the time a Deploy request is created.</p><h3 id="handling-reverts"><a href="#handling-reverts">Handling reverts</a></h3><p>Within branching, we also had to deal with handling reverts. PlanetScale's deployments are <a href="https://planetscale.com/docs/concepts/deploy-requests#revert-a-schema-change">revertible</a>. If you deploy a schema change, and then realize you made a mistake, we offer you the option to revert that migration while still keep all the data that may have changed during and after the deployment.</p><p>There exist some scenarios where <a href="https://planetscale.com/docs/concepts/deploy-requests#when-are-you-unable-to-revert-a-schema-change">reverts are not possible</a>. For example, if you modify a column from <code>TINYINT</code> to <code>INT</code>, complete the deployment, and populate some row with the value of <code>256</code>, then that value is outside <code>TINYINT</code> range, and the change cannot propagate back to the original table.</p><p>Foreign key constraints create a different limitation. Let's illustrate with a simple example. Say you have <code>parent</code> and <code>child</code> with foreign key relationship. You choose to drop the <code>child</code> table, meaning there's now no foreign key constraint. You then proceed to <code>DELETE FROM parent</code>. You <em>then</em> wish to revert dropping <code>child</code>. This is <em>possible</em>, but it creates an inconvenient situation: the restored <code>child</code> table will have orphaned rows, for we have deleted all rows from <code>parent</code>.</p><p>The same logic applies to any destruction or editing of a constraint. You can't trust that the reverted table complies with the constraint, for you may have modified the data in an incompatible way while the constraint was removed.</p><p>PlanetScale will allow you to make such reverts, but we will warn you that the change may not be revertible. The schema will be fine, but orphaned rows are possible.</p><h2 id="query-serving"><a href="#query-serving">Query serving</a></h2><p>The next challenge we dealt with was query serving. At this time, foreign key constraint support is limited to unsharded/single shard databases. We expect to support shard-scoped foreign key constraints in a multi-shard environment, or even cross-shard foreign keys, but we limit the current discussion to a single shard. This means that a query that uses a table that's in a foreign key relationship will only operate on a single backend database server.</p><p>Vitess, the <a href="https://planetscale.com/blog/what-is-vitess">underlying engine behind PlanetScale</a>, normally optimizes execution of such queries by delegating them to the backend MySQL server. However, a MySQL limitation that affects other critical components of Vitess calls for a different course of action. To understand why, let's digress and discuss Online DDL. We will then return to complete the query serving story.</p><h2 id="online-ddl"><a href="#online-ddl">Online DDL</a></h2><p>Perhaps the largest challenge so far has been with Online DDL. PlanetScale offers <a href="https://planetscale.com/docs/concepts/nonblocking-schema-changes">non-blocking schema changes</a>, which are very compelling, especially when altering large tables in production. The way they work is depicted in detail in <a href="https://planetscale.com/docs/learn/how-online-schema-change-tools-work">our Online schema change tools documentation</a>, but, in short, altering a table works as follows:</p><ul><li>We create a new, empty table, termed the "shadow" table, with the same definition as the original table.</li><li>We apply the <code>ALTER</code> statement to the shadow table.</li><li>We copy over all existing data from the original table to the shadow table, taking into consideration the schema difference between the two.</li><li>We follow the changelog on the original table, to capture any ongoing changes, and apply them on the shadow table.</li><li>Finally, when we are satisfied the shadow table is in sync or almost in-sync with the original table, we take a lock to prevent writes to the original table, apply what remaining changelog there may be, and finalize the operation by swapping the two tables. The shadow table takes the original table's place, and the original table becomes the shadow.</li></ul><p>This technique, used by several tools for online schema changes, cannot work with the existing MySQL foreign key constraints implementation. Online DDL has issues with:</p><ul><li>Tailing the binary logs for child table with a cascading (<code>SET NULL</code> or <code>CASCADE</code>) action.</li><li>Finalizing a foreign key parent table, as children's foreign key constraints <a href="https://vitess.io/blog/2021-06-15-online-ddl-why-no-fk/#changing-a-parent-table">migrate with the old table as it is being swapped</a>.</li><li>Backfilling the <a href="https://vitess.io/blog/2021-06-15-online-ddl-why-no-fk/#changing-a-child-table">shadow of a foreign key child table</a>, where as a copy of the child table's schema, the shadow table itself has a foreign key referencing the same parent.</li></ul><p>Each of these limitations calls for a bespoke solution. Let's break it down.</p><h3 id="tailing-the-changelog"><a href="#tailing-the-changelog">Tailing the changelog</a></h3><p>To backfill the shadow table, Online DDL uses <a href="https://vitess.io/docs/19.0/reference/vreplication/vreplication/"><code>VReplication</code></a>, one of the most powerful components in Vitess. <code>VReplication</code> is the component behind <a href="https://planetscale.com/docs/imports/database-imports">online imports</a>, materialization, live resharding, Online DDL, and more. It can live stream data from a source (or from multiple sources) to a target (or to multiple targets), while possibly manipulating or aggregating the data in transit.</p><p><code>VReplication</code> works by both reading the existing data on the source table(s), as well as by following the <em>changelog</em>: the live, ongoing manipulation of data. The changelog is available in MySQL as the <em>binary logs</em>. <code>VReplication</code> subscribes as a replica and pulls binary log changes from the source server. This is where a major MySQL limitation hits.</p><h4 id="mysql-foreign-key-constraint-support"><a href="#mysql-foreign-key-constraint-support">MySQL foreign key constraint support</a></h4><p>To the casual MySQL user, MySQL is known to support foreign key constraints. However, this is nuanced. MySQL has a pluggable storage engine architecture. Historically, the company MySQL AB focused on non-transactional storage engines. The MySQL engines did not support foreign key constraints. It was a 3rd party pluggable engine named InnoDB that fast became the engine of choice to most users, offering transactional (MVCC) support, as well as foreign key constraint support. There was some period in time when MySQL began work towards implementing foreign key constraints at the server level, but given how MySQL adopted InnoDB as its primary storage engine (now both under Oracle's ownership), that effort was dropped.</p><p>The most important implication, for our discussion, of MySQL not supporting foreign keys at the server level, is this: any cascading of operations (say an <code>ON DELETE SET NULL</code> or <code>ON UPDATE CASCADE</code>) is only done by InnoDB. If you <code>DELETE</code> or <code>UPDATE</code> a row on a parent table, and that, in turn, affects rows in a child table, those changes to the child are done internally in InnoDB, and <strong>are never logged to the binary log</strong>.</p><p>Those changes are hidden from anyone consuming the binary log. MySQL <em>trusts</em> the replica server's InnoDB engine to correctly replay those cascaded writes for it to remain consistent with the primary server.</p><p>Any Change Data Capture (CDC) tool, that tails the binary log or masquerades as a replica, will be <em>missing data</em> when reading a child table's events when the child table has <code>SET NULL</code> or <code>CASCADE</code> foreign key actions. You cannot reliably replay events on those tables, and you will end up with corrupt data, or trying to apply an impossible statement. By way of experiment (not on your production environment), try removing the foreign key constraints on a <em>replica</em> server, then see how long it takes for replication to break.</p><p>For Online DDL, this means we cannot apply a change to a table that has a <code>CONSTRAINT ... FOREIGN KEY ON [DELETE|UPDATE] [SET NULL|CASCADE]</code>.</p><p>One way of solving this issue would be to make InnoDB log cascaded statements. PlanetScale maintains a <a href="https://github.com/planetscale/mysql-server">fork of MySQL</a>, and we looked into making these changes in MySQL. However, we ended up choosing to implement foreign key constraint logic in Vitess itself. It's a trade off, with these considerations:</p><ul><li>The InnoDB codebase is very much detached from the MySQL codebase. There are parallel constructs, parallel entities in MySQL and in InnoDB, which are completely different and do not translate well to one another. Making the necessary changes appears to be a substantial undertaking with high risks.</li><li>Adding the necessary logic to Vitess was also a substantial amount of work. However, our Vitess maintainers are authoritative on the topic and had clarity of the scope of work. The risk was low.</li><li>In the future, we would like to be able to support foreign key constraints in a multi-shard environment. No matter how well we patch MySQL, and even if did provide the necessary cascading changelog, foreign keys would always remain an in-server constraint. There <em>is</em> some technology for running cross-server queries via <em>connectors</em>, but it is subpar (or incapable) in its ability to collaborate inside transactions, or in its ability to apply the correct locking. By implementing foreign key logic in Vitess early on, we pave the way towards multi-shard environments in the future.</li><li>It should come as no surprise that there is a downside to implementing foreign key constraint logic in the Vitess level. It requires more locking and more communication with the MySQL server. Vitess optimizes where it can and delegates some queries directly to the underlying server where possible, but there is a non-zero performance impact to using foreign key constraints with Vitess/PlanetScale.</li></ul><p>How Vitess implements foreign key logic is described later on, when we revisit <a href="#query-serving-revisited">Query serving</a>. In the meantime, let's proceed to discuss the next Online DDL limitation.</p><h3 id="altering-a-parent-table"><a href="#altering-a-parent-table">Altering a parent table</a></h3><p>Described in more detail in <a href="https://vitess.io/blog/2021-06-15-online-ddl-why-no-fk/#changing-a-parent-table">this blog post</a>, if you have a foreign key pair of a <code>parent</code> and a <code>child</code>, and you <code>RENAME TABLE parent TO old_parent</code>, the child's foreign key constraint follows the parent table onto its new name, <code>old_parent</code>. In the internal InnoDB implementation, the parent table retains its memory address, and, in a way, "following the parent to its new name" really means nothing changes in the children's foreign key references, as they keep using the same pointers. It's mostly the external facing schema definition that changes to reflect a <code>FOREIGN KEY (...) REFERENCED old_parent (...)</code>.</p><p>Running Online DDL on a parent table, we want to swap the parent table and its shadow. We want the children to be oblivious to the swap. We want them to point to the <code>parent</code> table name. Of course, we need to take it upon ourselves to ensure the replacement table, the shadow table, is compatible with the existing foreign keys. Imagine swapping in a shadow table that doesn't have the expected referenced column(s)!</p><p>In <a href="https://github.com/planetscale/mysql-server/commit/bb777e3e86387571c044fb4a2beb4f8c60462ced">this patch to MySQL</a>, we introduce a new server variable, <code>rename_table_preserve_foreign_key</code>. When set to <code>1</code>, a <code>RENAME TABLE</code> preserves the foreign key definition on the children by pinning it to the name of the table.</p><h3 id="altering-a-child-table"><a href="#altering-a-child-table">Altering a child table</a></h3><p>Suppose we alter a foreign key child table. Say we just modify some column from <code>INT</code> to <code>BIGINT</code>. The foreign keys that exist on the table should be reflected in the shadow table. For the duration of the Online DDL operation, however, the shadow table is incomplete. It it not in sync with the original table, and may be missing rows that exist in the original table, or may contain rows that do not exist anymore in the original table. But if this shadow table has a foreign key constraint pointing to the same parent as the original table's parent, then that parent is affected by the very existence of the shadow table. It's possible for a <code>DELETE</code> on the parent to be rejected due to a matching row existing in the shadow table, even if that row does not exist in the actual child table.</p><p>When backfilling the shadow table, we may choose to <code>SET FOREIGN_KEY_CHECKS=0</code>, but the application and users of the database will naturally expect to work with <code>FOREIGN_KEY_CHECKS=1</code>.</p><p>Moreover, even if we somehow manage to pull through and swap the tables, what happens now with the old child table? It becomes stale, as production traffic keeps changing the new table. But it still keeps the foreign key constraints to the parent. Again, preventing legitimate queries from executing on the parent. If only it were possible to create the shadow table without foreign key constraints, and just add them at the time of the final swap. Alas, in MySQL, foreign key constraint definitions are created in the scope of a child table. To add a foreign key constraint, or to remove a foreign key constraint, is a full table rebuild operation, locking and blocking; the very thing Online DDL was designed to overcome.</p><p>In our patch to the MySQL server, we introduced the notion of <em>internal operations tables</em>, something already well established within Vitess. Essentially, we tell MySQL: ignore any foreign key checks for these special tables. Do not try and validate row data. Do not attempt to cascade anything. It's as if we <code>SET FOREIGN_KEY_CHECKS=0</code> for specific tables, even while the transaction otherwise applies foreign key logic to other tables.</p><p>This way, MySQL/InnoDB completely ignore our shadow table. It can be out of sync, the parent table won't mind. And as we swap away the original table, MySQL ignores it under its new name. It will not affect production traffic.</p><h2 id="query-serving-revisited"><a href="#query-serving-revisited">Query serving, revisited</a></h2><p>Earlier, we discussed the reasoning behind Vitess owning foreign key logic. What does it mean for Vitess to own that logic?</p><p><a href="https://vitess.io/docs/concepts/vtgate/"><code>VTGate</code></a> is the Vitess component that handles all query serving. It is a proxy between an app and the underlying database, which intercepts queries and creates concrete execution plans, sent to the backend databases. For example, in a multi-sharded environment, VTGate analyzes which shard or shards should be queried for a given <code>SELECT</code> and possibly combines results from multiple shards before returning them to the app.</p><p>VTGate can make various optimizations based on the fact that it knows the structure of the underlying schema, the sharding scheme, and the production traffic patterns. It can cache, lock, buffer or altogether modify queries. It is now also aware of foreign key constraints and the specific rule actions. We will limit the discussion to unsharded or single-shard (the two look the same to the app) environments.</p><p>Starting with the simplest scenario, an <code>ON UPDATE RESTRICT ON DELETE RESTRICT</code> foreign key can be simply handled by the underlying MySQL server, with no additional planning required from VTGate. A <code>RESTRICT</code> (aka <code>NO ACTION</code>) rule means if you're deleting or updating a parent row, and such an action would invalidate a child's row, then the action is rejected. There's no cascading effect: either your query is rejected, or is accepted and only modifies the parent table. Since there's no cascading effect, we do not need to account for missing entries in the binary logs.</p><p>Let's now illustrate the case for an <code>ON DELETE CASCADE</code>. A user issues a <code>DELETE FROM parent WHERE id=7</code>. There could be entries in a <code>child</code> table with matching <code>parent_id=7</code>. If we ran the query directly in MySQL, it would only apply the <code>DELETE</code> on <code>parent</code>, letting InnoDB take care of deleting whatever matching rows are found on <code>child</code>. But those deletes will not be visible in the binary logs. Vitess, therefore, has to take control.</p><p>It must first explicitly <code>DELETE FROM child WHERE parent_id=7</code> — thereby ensuring that any affected rows are recorded in the binary log — and only then issue a <code>DELETE FROM parent WHERE id=7</code>. When faced with this latter <code>DELETE</code> on <code>parent</code>, InnoDB still checks for matching rows in <code>child</code>, but finds none, because Vitess had already purged them.</p><p>At least, that's the naive outline. The implementation is more complicated:</p><ul><li>The <code>DELETE</code>s on <code>parent</code> and <code>child</code> must be part of the same transaction. The changes made by the statement should be atomic, i.e. all or none are applied.</li><li>While we <code>DELETE FROM child</code>, we must acquire a write lock on <code>parent</code>, specifically for row <code>id=7</code>.</li><li>To do that, we must first issue a <code>SELECT col FROM parent WHERE id=7 FOR UPDATE</code>.</li><li>Using the <code>foreign key column</code> values from the parent select, execute the <code>DELETE FROM child WHERE col in (parent_column_values)</code>.</li><li>The child table could itself be a foreign key parent for another table, and let's say it also has an <code>ON DELETE CASCADE</code> child. The same logic is applied recursively: lock the relevant rows on <code>child</code>, <code>DELETE</code> from the grandchild, then delete from <code>child</code>, and then back to <code>parent</code>.</li></ul><p><img alt="" loading="lazy" decoding="async" data-nimg="fill" sizes="(min-width: 1024px) 1024px, 100vw" srcset="https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=640&amp;q=75 640w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=750&amp;q=75 750w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=828&amp;q=75 828w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=1080&amp;q=75 1080w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=1200&amp;q=75 1200w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=1920&amp;q=75 1920w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=2048&amp;q=75 2048w, https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=3840&amp;q=75 3840w" src="https://planetscale.com/_next/image?url=%2Fassets%2Fblog%2Fcontent%2Fchallenges-of-supporting-foreign-key-constraints%2Fforeign-keys-animated.gif&amp;w=3840&amp;q=75"></p><p>As you can see, this implementation introduces more back-and-forth communication between VTGate and the backend MySQL server, as well as having additional locking for correctness.</p><p>To show how weird things can get, let's also illustrate an <code>ON UPDATE CASCADE</code> scenario. Let's assume we issue a <code>UPDATE parent SET id=8 WHERE id=7</code>. This is a generalized example; as a rule of thumb, one should avoid modifying <code>PRIMARY KEY</code> values, but foreign keys do not necessarily need to refer to <code>PRIMARY KEY</code> columns, or even to <code>UNIQUE</code> values.</p><p>Similarly to the <code>DELETE</code> scenario, we want to ensure the cascaded updates appear in the binary log. InnoDB won't do it for us, so we have to do it ourselves. We want to first issue an <code>UPDATE child SET parent_id=8 WHERE parent_id=7</code>, and only then update the <code>parent</code> table. However, we cannot run that update on <code>child</code>, because there is yet no <code>parent</code> row where <code>id=8</code>!</p><p>In this scenario, Vitess must turn off <code>FOREIGN_KEY_CHECKS</code> for the update. This leads Vitess to take responsibility for the integrity of the data, as disabling <code>FOREIGN_KEY_CHECKS</code> leads to MySQL/InnoDB skipping all the foreign key validations for child and parent. Any <code>ON UPDATE RESTRICT</code> for the grandchild or existence of foreign key value in a different parent table needs to be handled by Vitess.</p><p>More complex scenarios involve self-referencing tables or statements with non-literal values. They all take a great amount of attention. Later on, we will explain how we test all the above and what gives us confidence that we aren't missing anything.</p><h2 id="database-imports"><a href="#database-imports">Database imports</a></h2><p>PlanetScale lets you <a href="https://planetscale.com/docs/imports/database-imports">import your data</a> from an external MySQL environment, and without interruption to that environment. Like Online DDL, Imports utilize <code>VReplication</code>. The external MySQL servers are outside PlanetScale's control, and, of course, will not include any of the changes discussed above. In light of that, how can PlanetScale use <code>VReplication</code> to import a database that has foreign key constraints, specifically with <code>SET NULL</code> or <code>CASCADE</code> actions?</p><p>Normally, <code>VReplication</code> moves data from a source (or multiple sources) to a target (or multiple targets) by alternating these two operations:</p><ul><li>Transactionally reading existing rows from the source table(s) and copying them over.</li><li>Tailing the changelog (binary logs) and applying them to capture ongoing changes.</li></ul><p><code>VReplication</code> takes a surgical approach where it keeps track of per-transaction GTID (global transaction IDs, also known as positioning). When it reads existing rows data, it marks the GTID value that applies to the read transaction. That read will take a while on large tables, and during that time, new events will modify the tables. When <code>VReplication</code> switches to applying the changelog, it only evaluates events occurring <em>as of</em> the last read transaction. A third, "fast-forward" smaller phase then glues the next read transaction with the remaining changelog events up to that transaction. <code>VReplication</code> is also able to entirely skip changes to rows that it has not copied yet, by way of reducing unnecessary work.</p><p>With cascading foreign key rules, information is lost. <code>VReplication</code> may attempt to import a child table that has, for example, <code>FOREIGN KEY ... ON DELETE CACADE</code>. As parent rows get deleted, so do matching rows on the child. However, those deletes on the child never make it to the binary logs. <code>VReplication</code> cannot trust that the binary log is complete.</p><p>In closer examination, if the <code>DELETE</code> on the parent makes it to the binary log, and is captured by <code>VReplication</code> and replayed on the target server, won't the InnoDB engine also replay the cascade on the target server? Yes — assuming the relevant row is already in position on the target, but that's not guaranteed. At any given time, only parts of any certain table will have been copied. You cannot apply the <code>DELETE</code> to row <code>1000</code> on the target, if you've only copied rows <code>1..500</code>.</p><p>The solution for database Imports is to import the existing table data in a single, large bulk, followed by tailing the changelog. The two do not alternate. For people familiar with MySQL operations, this is not dissimilar to a point-in-time recovery method, where you first restore a full snapshot of the database, followed by applying a long sequence of binary logs. In this approach, all replayed events necessarily operate on existing data. And while there are still no events for some of the child table changes, we can trust the InnoDB engine on the target side to replay them appropriately.</p><p>It's worth noting that Imports is not expected to work in conjunction with other <code>VReplication</code> operations, i.e. we won't be running, in PlanetScale, an Online DDL on a table that is being imported. This distinction is important because the import process relies on InnoDB to apply cascading changes, which in turn means some changes are missing in the <em>target's</em> changelog. In the future, and because some of Vitess' workflows do integrate with each other, we can expect <code>VReplication</code> to apply changes to foreign key tables through the query serving mechanism discussed above.</p><h2 id="testing-foreign-key-constraint-support"><a href="#testing-foreign-key-constraint-support">Testing foreign key constraint support</a></h2><p>These changes call for rigorous testing. We use multiple testing techniques, from unit testing to end-to-end (e2e) testing, from planned to unplanned scenarios. Here, we illustrate two specific test suites:</p><ul><li>Application-oriented e2e stress tests with Online DDL.</li><li>Fuzzer stress tests, comparing Vitess to MySQL behavior.</li></ul><h3 id="application-stress-tests"><a href="#application-stress-tests">Application stress tests</a></h3><p>In this test suite, we create a hierarchical foreign key structure of tables, and emulate an app that writes to those tables. The app keeps tracks of the changes it makes and the response it gets from the (Vitess) database. At the end of the test, we compare the app's expectations with the actual table data.</p><p>That's just the high level description. The suite also:</p><ul><li>Sets up a variety of foreign key situations, with one parent, two children, and one grandchild table.</li><li>Ensures high concurrency of writes.</li><li>Ensures high contention writes take place on all tables. Changes made by different connections are highly likely to collide and conflict.</li><li>Tests all foreign key rules: <code>ON DELETE NO ACTION / SET NULL / CASCADE</code> and <code>ON UPDATE NO ACTION / SET NULL / CASCADE</code>. Cascading (<code>SET NULL</code> and <code>CASCADE</code>) rules add to the write contention even more.</li><li>Runs the stress tests first without, and then with, Online DDL, on each of the hierarchy tables.</li><li>The underlying database cluster uses MySQL replication, with foreign key constraints completely removed on the replica.</li></ul><p>Let's take a look at some deeper impact of this test design.</p><p>The four table structure showcases a parent-only table, two child-only tables, one table which is both parent and child, and a multi-child scenario. This hierarchy does not represent all possible variants of foreign key relationships (for example, it does not depict a multi-parent setup, or a self-referencing table), but does have enough variance to cover the MySQL fork changes, as well as the fundamental VTGate logic and locking scenarios. We use a classic foreign key relationship: child tables reference the <code>PRIMARY KEY</code> of the parent. This is to assist with expectation management. For other scenarios, see <em>fuzzer tests</em> discussion, below.</p><p>The app emulation uses classic <code>INSERT</code>, <code>UPDATE</code>, and <code>DELETE</code> statements, randomly generated. The app does not know in advance what end result it generates. However, it intentionally limits the range of affected rows to a small enough scope, that, with concurrency and with many cycles, creates high contention on all table rows. Some of the app's auto-generated queries will have no effect and will go to waste. For example, the app may randomly attempt a <code>DELETE FROM stress_parent WHERE id=7 AND updates=1</code>. Possibly, <code>id=7</code> row does not exist, and the statement affects zero rows. In high volumes, however, many queries will have actual effect. The app records the success and effect of any of its statements, and is able to finally conclude how many rows it expects to find in the table, and what actual data should be there.</p><p>We run a test where <code>ON DELETE</code> has <code>NO ACTION</code> rule, and a test where <code>ON DELETE</code> has <code>CASCADE</code> rule, etc. We run combinations of rules. In a <code>CASCADE</code> scenario, it is difficult, or impossible, given the random nature of the query design, for the app to know what data to expect in children tables following a <code>DELETE</code> on a parent. How can we verify that VTGate has made the correct choices, and has cascaded the <code>DELETE</code> correctly? This is where MySQL replication comes in handy.</p><p>As we illustrated before, VTGate implements a <code>ON DELETE CASCADE</code> by first applying the <code>DELETE</code> on children (and, recursively, first on grandchildren) before applying on the parent. As we mentioned, by the time InnoDB sees the <code>DELETE</code> on the parent, there's nothing for it to cascade. We expect the binary logs to fully represent our cascading logic. As mentioned above, we use a MySQL replica, and on that replica we actually strip away all foreign keys on all tables via <code>ALTER TABLE ... DROP FOREIGN KEY</code>. MySQL allows that. However, the InnoDB engine on the replica now has no knowledge of foreign keys, and will not attempt to replay/reproduce any InnoDB cascading logic made on the primary server. That might break replication! At the very least, it will cause data drift between parent and child, and due to the high contention nature of the test this will soon lead to an unresolved inconsistency.</p><p>If VTGate does everything right, though, the data will remain consistent. If VTGate leaves nothing for the InnoDB engine to cascade on the primary server, then no binlog events will be missing on the replica. The replica will be able to replay VTGate's explicit cascaded operations and to remain consistent with the primary server. The test suite does exactly that, and validates not only that replication is unbroken at the end of each test, but also that both primary and replica report the same data metrics.</p><p>Foreign key constraints in MySQL introduce more locking, by nature, and, as we've seen, Vitess adds even more locking scenarios. These workloads ultimately run into locking scenarios. The test ensures we are still able to make progress and that we don't end up in a complete lock down. It goes without saying that any database can be overwhelmed by too much traffic or by too many connections, and it's always possible to shoot yourself in the foot by introducing extremely contentious scenarios. The test suite keeps load under reasonably contentious control.</p><p>Some of the tests suffice with the above workload, and some add an Online DDL operation on top. While the workload runs, and under high contention, we pick any of the tables and run Online DDL, wait for the cut-over to complete, and, only then, give the green light to complete the test. This tests the changes in the MySQL server under load. We verify that no rows are lost when the original and shadow tables are swapped. We verify that no child table ends up with orphaned rows. We verify none of the shadow tables, or the aftermath artifact tables, has any logical effect on the app's traffic.</p><h3 id="fuzzer-tests"><a href="#fuzzer-tests">Fuzzer tests</a></h3><p>We initially started with adding tests for individual cases and queries as we went along adding support for them. But we soon realized that with the amount of possibilities of <code>CASCADE</code>s, <code>SET NULL</code>s, <code>RESTRICT</code>s and their interactions with each other, we would have to add a lot of tests to ensure everything worked. So, instead, we tried a different approach. We started with a set of 20 tables having foreign key relations amongst each other, such that we had good coverage of all the different possibilities. We ensure that we had cases like having a cascade rule on a child that has another cascade rule, having a restrict on a child that has a cascade rule, amongst others. Then, we wrote a fuzzer to generate different DML queries to hammer the database and verify we do the right thing in Vitess.</p><p>We introduced two distinct types of tests. The first type involves single concurrency tests, where we initiate a Vitess cluster alongside a separate MySQL instance. Both instances are initialized with identical schemas, and we execute the same queries on both through a single thread. This approach guarantees deterministic output, serving as a validation that Vitess and MySQL exhibit consistent behavior for all DML queries supported by Vitess.</p><p>The second type of tests encompasses multi-concurrency scenarios. In this case, we exclusively establish a Vitess cluster and initiate multiple threads, each executing DML queries concurrently. This particular test is designed to ensure that Vitess implements adequate locking mechanisms, preventing any correctness issues when numerous concurrent DML queries are executed. The primary goal is to ascertain that the database remains consistent throughout this concurrent operation.</p><p>As we added support for different query types, we kept expanding the fuzzer's range of generated queries to ensure the correct implementation of each addition.<!-- --> <!-- -->Adding fuzzer tests to our suite was incredibly useful. They helped uncover issues that would have been hard to find using manual queries alone. Let's take a look at some problems identified by the fuzzer and how we fixed them.</p><h4 id="updating-a-child-table-with-cascade-foreign-key-and-grandchild-restrict-foreign-key"><a href="#updating-a-child-table-with-cascade-foreign-key-and-grandchild-restrict-foreign-key">Updating a child table with <code>CASCADE</code> foreign key and grandchild <code>RESTRICT</code> foreign key</a></h4><p>Our first test failure came when updating a table that has a child with <code>CASCADE</code> foreign key and a grandchild with <code>RESTRICT</code> foreign key, such that the update doesn't cause an actual row change on the child.</p><p>Clearly, from the length of that header, we are talking about a very specific scenario!</p><p>Consider the scenario where you have the following schema:</p><div><pre><code><p><span>create</span><span> </span><span>table</span><span> parent</span><span>(</span><span>id </span><span>bigint</span><span>,</span><span> col </span><span>varchar</span><span>(</span><span>10</span><span>)</span><span>,</span><span> </span><span>primary</span><span> </span><span>key</span><span> </span><span>(</span><span>id</span><span>)</span><span>,</span><span> </span><span>index</span><span>(</span><span>col</span><span>)</span><span>)</span><span> </span><span>Engine</span><span> </span><span>=</span><span> </span><span>InnoDB</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> child</span><span>(</span><span>id </span><span>bigint</span><span>,</span><span> col </span><span>varchar</span><span>(</span><span>10</span><span>)</span><span>,</span><span> </span><span>primary</span><span> </span><span>key</span><span> </span><span>(</span><span>id</span><span>)</span><span>,</span><span> </span><span>index</span><span>(</span><span>col</span><span>)</span><span>,</span><span> </span><span>foreign</span><span> </span><span>key</span><span> </span><span>(</span><span>col</span><span>)</span><span> </span><span>references</span><span> parent</span><span>(</span><span>col</span><span>)</span><span> </span><span>on</span><span> </span><span>delete</span><span> </span><span>cascade</span><span> </span><span>on</span><span> </span><span>update</span><span> </span><span>cascade</span><span>)</span><span> </span><span>Engine</span><span> </span><span>=</span><span> </span><span>InnoDB</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> grandchild</span><span>(</span><span>id </span><span>bigint</span><span>,</span><span> col </span><span>varchar</span><span>(</span><span>10</span><span>)</span><span>,</span><span> </span><span>primary</span><span> </span><span>key</span><span> </span><span>(</span><span>id</span><span>)</span><span>,</span><span> </span><span>index</span><span>(</span><span>col</span><span>)</span><span>,</span><span> </span><span>foreign</span><span> </span><span>key</span><span> </span><span>(</span><span>col</span><span>)</span><span> </span><span>references</span><span> child</span><span>(</span><span>col</span><span>)</span><span> </span><span>on</span><span> </span><span>delete</span><span> </span><span>restrict</span><span> </span><span>on</span><span> </span><span>update</span><span> </span><span>restrict</span><span>)</span><span> </span><span>Engine</span><span> </span><span>=</span><span> </span><span>InnoDB</span><span>;</span>
</p></code></pre></div><p>We initially have the following data in the three tables:</p><div><pre><code><p><span>insert</span><span> </span><span>into</span><span> parent </span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>3</span><span>)</span><span>,</span><span> </span><span>(</span><span>2</span><span>,</span><span> </span><span>2</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>insert</span><span> </span><span>into</span><span> child </span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>3</span><span>)</span><span>,</span><span> </span><span>(</span><span>2</span><span>,</span><span> </span><span>2</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>insert</span><span> </span><span>into</span><span> grandchild </span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>2</span><span>,</span><span> </span><span>2</span><span>)</span><span>;</span>
</p></code></pre></div><p>Now, if you run a query like <code>update parent set col = 2</code>, it succeeds on MySQL.<!-- --> <!-- -->But Vitess was failing this query with a <code>Cannot delete or update a parent row: a foreign key constraint fails</code> error.</p><p>Upon diving further in, we found out the issue. When Vitess receives a query that requires cascades, we issue a <code>SELECT</code> query on the parent to lock the rows that are being updated, and then update the child first. As stated before, this update would fail on MySQL if we don't run it with foreign key checks off. But, because we are running the query with foreign key checks turned off, it falls on Vitess to validate the <code>RESTRICT</code> foreign keys as well.</p><p>The update we construct for the child table looks like <code>update child set col = 2 where col in (2, 3)</code>. To validate that none of the rows in the grandchild would prevent the updates from going through, Vitess was running a <code>JOIN</code> query to ensure that none of the rows being updated had a foreign key constraint with matching rows.</p><p>The SELECT query we used for validation looked like this:</p><div><pre><code><p><span>select</span><span> </span><span>1</span><span> </span><span>from</span><span> grandchild</span>
</p><p><span>  </span><span>join</span><span> child </span><span>on</span><span> grandchild</span><span>.</span><span>col </span><span>=</span><span> child</span><span>.</span><span>col</span>
</p><p><span>  </span><span>where</span><span> child</span><span>.</span><span>col </span><span>IN</span><span> </span><span>=</span><span> </span><span>(</span><span>2</span><span>,</span><span> </span><span>3</span><span>)</span><span></span>
</p><p><span>  </span><span>limit</span><span> </span><span>1</span>
</p></code></pre></div><p>From the outset, this looks correct. We are trying to find if there are any rows in the <code>grandchild</code> table that match the <code>col</code> of the child table for the rows being updated.</p><p>But here is the kicker. The row <code>(2,2)</code> is not actually resulting in any update! So, MySQL still allows the update to go through, because it doesn't cause the data in <code>grandchild</code> to become orphaned!</p><p>The fix wasn't too hard once we understood the problem. All we had to do was also exclude the rows that weren't actually changing in the <code>SELECT</code> Vitess was running for verification.</p><p>So, we updated the query to look like this, and then everything worked as intended:</p><div><pre><code><p><span>select</span><span> </span><span>1</span><span></span>
</p><p><span>  </span><span>from</span><span> grandchild</span>
</p><p><span>  </span><span>join</span><span> child </span><span>on</span><span> grandchild</span><span>.</span><span>col </span><span>=</span><span> child</span><span>.</span><span>col</span>
</p><p><span>  </span><span>where</span><span> child</span><span>.</span><span>col </span><span>IN</span><span> </span><span>=</span><span> </span><span>(</span><span>2</span><span>,</span><span> </span><span>3</span><span>)</span><span></span>
</p><p><span>  </span><span>and</span><span> child</span><span>.</span><span>col </span><span>NOT</span><span> </span><span>IN</span><span> </span><span>(</span><span>2</span><span>)</span><span></span>
</p><p><span>  </span><span>limit</span><span> </span><span>1</span>
</p></code></pre></div><p>This case illustrates just how powerful the fuzzer is and how good it is at finding cases that are rare enough that we wouldn't have written manual tests for.</p><h4 id="arithmetic-operations-on-a-varchar-column-causing-0-vs-0-problems"><a href="#arithmetic-operations-on-a-varchar-column-causing-0-vs-0-problems">Arithmetic operations on a <code>VARCHAR</code> column causing <code>0</code> vs <code>-0</code> problems</a></h4><p>Consider the scenario where you have the following schema:</p><div><pre><code><p><span>create</span><span> </span><span>table</span><span> parent</span><span>(</span><span>id </span><span>bigint</span><span>,</span><span> col </span><span>varchar</span><span>(</span><span>10</span><span>)</span><span>,</span><span> </span><span>primary</span><span> </span><span>key</span><span> </span><span>(</span><span>id</span><span>)</span><span>,</span><span> </span><span>index</span><span>(</span><span>col</span><span>)</span><span>)</span><span> </span><span>Engine</span><span> </span><span>=</span><span> </span><span>InnoDB</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> child</span><span>(</span><span>id </span><span>bigint</span><span>,</span><span> col </span><span>varchar</span><span>(</span><span>10</span><span>)</span><span>,</span><span> </span><span>primary</span><span> </span><span>key</span><span> </span><span>(</span><span>id</span><span>)</span><span>,</span><span> </span><span>index</span><span>(</span><span>col</span><span>)</span><span>,</span><span> </span><span>foreign</span><span> </span><span>key</span><span> </span><span>(</span><span>col</span><span>)</span><span> </span><span>references</span><span> parent</span><span>(</span><span>col</span><span>)</span><span> </span><span>on</span><span> </span><span>delete</span><span> </span><span>cascade</span><span> </span><span>on</span><span> </span><span>update</span><span> </span><span>cascade</span><span>)</span><span> </span><span>Engine</span><span> </span><span>=</span><span> </span><span>InnoDB</span><span>;</span>
</p></code></pre></div><p>And let's say we initially have the following data in the three tables:</p><div><pre><code><p><span>insert</span><span> </span><span>into</span><span> parent </span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>-</span><span>5</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>insert</span><span> </span><span>into</span><span> child </span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>1</span><span>,</span><span> </span><span>-</span><span>5</span><span>)</span><span>;</span>
</p></code></pre></div><p>Now, if you run a query like <code>update parent set col = col * (col - (col))</code>, then Vitess would end up with inconsistent data in the database:</p><div><pre><code><p><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> parent</span><span>;</span><span></span>
</p><p><span></span><span>+</span><span>----+------+</span><span></span>
</p><p><span></span><span>|</span><span> id </span><span>|</span><span> col  </span><span>|</span><span></span>
</p><p><span></span><span>+</span><span>----+------+</span><span></span>
</p><p><span></span><span>|</span><span>  </span><span>1</span><span> </span><span>|</span><span> </span><span>-</span><span>0</span><span>   </span><span>|</span><span></span>
</p><p><span></span><span>+</span><span>----+------+</span><span></span>
</p><p><span></span><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> child</span><span>;</span><span></span>
</p><p><span></span><span>+</span><span>----+------+</span><span></span>
</p><p><span></span><span>|</span><span> id </span><span>|</span><span> col  </span><span>|</span><span></span>
</p><p><span></span><span>+</span><span>----+------+</span><span></span>
</p><p><span></span><span>|</span><span>  </span><span>1</span><span> </span><span>|</span><span>  </span><span>0</span><span>   </span><span>|</span><span></span>
</p><p><span></span><span>+</span><span>----+------+</span>
</p></code></pre></div><p>After investigation, we found out that the problem was coming from the part where we are doing arithmetic operations on a varchar column.</p><p>Vitess first runs a <code>SELECT</code> query to get the final updated values for non-literal updates. Vitess first runs <code>SELECT id, col, col * (col - (col)) from parent</code>. It then uses the output of the this query to cascade the update onto the child. The problem was that the result of <code>col * (col - (col))</code> evaluation is a value <code>-0</code> of type <code>FLOAT</code>.</p><p>This caused Vitess to issue a query like <code>update child set col = -0 where col IN ('-5')</code>. MySQL, however, interprets <code>0</code> and <code>-0</code> as the same values and ends up setting the col to <code>0</code> causing inconsistencies.</p><p>Once we realized the issue, the fix was again not too difficult. All we had to do was type cast the expression into the type of the column. Now, Vitess issues a query like <code>SELECT id, col, CAST(col * (col - (col)) AS CHAR) from parent</code> and this in turn causes the update to look like <code>update child set col = '-0' where col IN ('-5')</code>, thus fixing the issue.</p><p>It is valuable to appreciate that the problem only surfaces when the arithmetic expression evaluates to <code>-0</code>. If it evaluates to any other value, it doesn't cause any issues. This case illustrates just how useful the fuzzer is in running so many queries that it is eventually able to find cases that only happen in very specific scenarios requiring multiple conditions to be met.</p><h4 id="parent-table-unique-key-locking-issue"><a href="#parent-table-unique-key-locking-issue">Parent table unique key locking issue</a></h4><p>While adding <code>REPLACE INTO</code> support for foreign keys and making adequate changes to fuzzer, we discovered that select queries executed for foreign key cascade were not able to acquire an adequate level of lock on the unique key due to missing gap locks.<!-- --> <!-- -->This led to incorrect results, and further, plan execution would result in missing cascading rows, leading to incomplete data in the binary logs.</p><p>Let's look at a simple example:</p><div><pre><code><p><span>drop</span><span> </span><span>table</span><span> </span><span>if</span><span> </span><span>exists</span><span> some_table</span><span>;</span><span></span>
</p><p><span></span><span>create</span><span> </span><span>table</span><span> some_table </span><span>(</span><span></span>
</p><p><span>    id </span><span>bigint</span><span>,</span><span></span>
</p><p><span>    col </span><span>varchar</span><span>(</span><span>10</span><span>)</span><span>,</span><span></span>
</p><p><span>    </span><span>primary</span><span> </span><span>key</span><span> </span><span>(</span><span>id</span><span>)</span><span>,</span><span></span>
</p><p><span>    </span><span>unique</span><span> </span><span>index</span><span>(</span><span>col</span><span>)</span><span></span>
</p><p><span></span><span>)</span><span> </span><span>;</span><span></span>
</p><p><span></span><span>insert</span><span> </span><span>into</span><span> some_table</span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>3</span><span>,</span><span> </span><span>null</span><span>)</span><span>,</span><span> </span><span>(</span><span>4</span><span>,</span><span> </span><span>5</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>-- Session 1</span><span></span>
</p><p><span></span><span>begin</span><span>;</span><span></span>
</p><p><span></span><span>select</span><span> col </span><span>from</span><span> some_table </span><span>where</span><span> col </span><span>in</span><span> </span><span>(</span><span>5</span><span>)</span><span> </span><span>or</span><span> id </span><span>in</span><span> </span><span>(</span><span>3</span><span>)</span><span>  </span><span>for</span><span> </span><span>update</span><span>;</span><span></span>
</p><p><span></span><span>-- Session 2</span><span></span>
</p><p><span></span><span>begin</span><span>;</span><span></span>
</p><p><span></span><span>select</span><span> col </span><span>from</span><span> some_table </span><span>where</span><span> col </span><span>in</span><span> </span><span>(</span><span>(</span><span>'5'</span><span>)</span><span>)</span><span> </span><span>for</span><span> </span><span>update</span><span>;</span><span></span>
</p><p><span></span><span>-- This should block</span><span></span>
</p><p><span></span><span>-- Session 1</span><span></span>
</p><p><span></span><span>delete</span><span> </span><span>from</span><span> some_table </span><span>where</span><span> col </span><span>in</span><span> </span><span>(</span><span>5</span><span>)</span><span> </span><span>or</span><span> id </span><span>in</span><span> </span><span>(</span><span>3</span><span>)</span><span> </span><span>;</span><span></span>
</p><p><span></span><span>insert</span><span> </span><span>into</span><span> some_table</span><span>(</span><span>id</span><span>,</span><span> col</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>3</span><span>,</span><span> </span><span>5</span><span>)</span><span>;</span><span></span>
</p><p><span></span><span>commit</span><span>;</span><span></span>
</p><p><span></span><span>-- Session 2</span><span></span>
</p><p><span></span><span>-- Unblocked but returns 0 rows</span><span></span>
</p><p><span></span><span>select</span><span> col </span><span>from</span><span> some_table </span><span>where</span><span> col </span><span>in</span><span> </span><span>(</span><span>(</span><span>'5'</span><span>)</span><span>)</span><span> </span><span>for</span><span> </span><span>update</span><span>;</span><span></span>
</p><p><span></span><span>-- This repeatable query in Session 2 now returns 1 row</span><span></span>
</p><p><span></span><span>rollback</span><span>;</span>
</p></code></pre></div><p>As a solution, we went ahead using the <code>NOWAIT</code> lock to promptly acquire the lock for cascade selection. <code>NOWAIT</code> ensures immediate lock acquisition or failure, which may result in more foreign key-related DMLs failing, necessitating query or transaction rollback.</p><p>This approach, however, effectively addresses the problem of lock waiting and prevents incorrect results.</p><h2 id="foreign-key-constraints-support-limitations"><a href="#foreign-key-constraints-support-limitations">Foreign key constraints support limitations</a></h2><p>There still exist some limitations in our support of foreign key constraints. Many have been touched on throughout this article, but we will recap them here:</p><ul><li>While self-referencing tables are supported, cyclic foreign key references between different tables is not allowed.</li><li>Foreign key constraints names change on every deployment. This is largely due to the MySQL limitation (compatible with ANSI SQL specification) where constraint names must be unique to the schema.</li><li>Foreign key constraints are currently only supported in unsharded environments.</li><li>There are some scenarios where schema reverts can create orphaned rows.</li></ul><p>For a full list of limitations, see our <a href="https://planetscale.com/docs/concepts/foreign-key-constraints#limitations">foreign key constraint documentation</a>.</p><h2 id="summary"><a href="#summary">Summary</a></h2><p>In summary, we faced several challenges in supporting foreign key constraints in Vitess and PlanetScale, but are extremely pleased with where we landed.</p><p>If lack of foreign key constraint support has been a barrier to you trying PlanetScale in the past, we welcome you to try out the foreign key constraint open beta now. If you have any questions, don't hesitate to <a href="https://planetscale.com/contact">reach out to us</a>.</p></article></section></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Working more than 55 hours a week kills 750k people a year worldwide (146 pts)]]></title>
            <link>https://english.elpais.com/health/2023-11-28/working-more-than-55-hours-a-week-kills-750000-people-a-year-worldwide.html</link>
            <guid>38532632</guid>
            <pubDate>Tue, 05 Dec 2023 16:04:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/health/2023-11-28/working-more-than-55-hours-a-week-kills-750000-people-a-year-worldwide.html">https://english.elpais.com/health/2023-11-28/working-more-than-55-hours-a-week-kills-750000-people-a-year-worldwide.html</a>, See on <a href="https://news.ycombinator.com/item?id=38532632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>An essential means of survival for the majority, every year work costs the lives of almost three million people worldwide. And of those deaths, almost 800,000 are due to <a href="https://english.elpais.com/economy-and-business/2022-06-20/the-four-day-working-week-theyd-have-to-pay-me-double-to-go-back-to-the-old-schedule.html">working more than 55 hours a week.</a> These are some of the main conclusions of the study <a href="https://www.ilo.org/global/about-the-ilo/newsroom/lang--en/index.htm" target="_blank"><i>A call for healthier and safer work environments</i></a>, conducted by the International Labor Organization (ILO) and published on Sunday, November 26. Of the 2.96 million deaths, 2.6 million are due to diseases derived from employment such as circulatory problems, cancer, and respiratory diseases. The remaining 330,000 are related to work accidents.</p><p>However, the number of deaths at work is not growing at the same rate as the population. In other words, proportionally fewer people die due to their employment now than at the beginning of the century. While deaths resulting from work have increased by 12% from 2000 to 2019 (reference data from the ILO study), the working population has increased by 26% in the same period. “Diagnostic tools have improved substantially in the last two decades, contributing to an increase in detected cases,” the report states.</p><p>The ILO study, prepared in collaboration with the World Health Organization (WHO), relates these deaths to the most common risks at work. The one that causes the most deaths (744,942) is exposure to long working hours of over 55 hours a week. The other risks that cause the most deaths include exposure to gases and smoke (450,381), work-related injuries (363,283), exposure to asbestos (209,481), silica (42,258), substances that cause asthma (29,641), solar ultraviolet radiation (17,936), diesel engine exhaust fumes (14,728), arsenic (7,589), and nickel (7,301) according to the figures for 2016.</p><p>The study also relates these risks to the time they cost workers (disability-adjusted life years, or DALYS). The risk that costs workers the most years of life are work-related injuries (26.44 million), followed by exposure to work days of more than 55 hours (23.26), ergonomic factors (12.27), and exposure to smoke and gases (10.86). The report gives more details: “The rate of trachea, bronchus and <a href="https://english.elpais.com/health/2023-10-05/joaquin-mosquera-oncologist-the-big-obstacle-in-lung-cancer-is-not-having-screening-to-get-ahead-of-the-disease.html">lung cancers</a> attributable to occupational exposure to chromium doubled between 2000 and 2016. Mesothelioma attributable to asbestos exposure has risen by 40%. The rate of non-melanoma skin cancer increased by over 37% between 2000 and 2020. On the other hand, deaths due to exposure to asthmagens [asthma triggers] and particulate matter, gases, and fumes decreased by over 20%.”</p><p>In relation to specific diseases, the ILO indicates that 32.4% of deaths at work are due to circulatory problems, 27.5% to cancer, 14.3% to respiratory diseases, 11.3% to injuries, 7.2% to infectious diseases, 3% to <a href="https://english.elpais.com/health/2023-11-27/can-asthma-be-cured.html">asthma,</a> 2.9% to neuropsychiatric conditions, 0.95% to genitourinary problems, 0.94% to digestive diseases and 0. 15% for other reasons. According to the report, more than 13 million people around the world live with a visual impairment caused by their work.</p><p>The report highlights that employment-related deaths represent 6.7% of all deaths recorded globally. This impact differs by region. The highest proportion was in Africa (7.4%), Asia and the Pacific (7.1%), and Oceania (6.5%). The proportion is lower in Europe and America, but the ILO does not provide the specific data, nor does it provide the information by country, although it will soon distribute this information in an expansion of this study. The ILO highlights agriculture, forestry and fishing, mining, construction, and manufacturing as the most dangerous sectors, and also focuses on the informal economy, in which employees lack “a stable or regular income and adequate legal or social protections.” Likewise, it points out that there are many more work-related deaths among men (51.4 per 100,000 adults of working age) than among women (17.2 per 100,000).</p><p>In addition to the global tragedy of work-related deaths, the ILO estimates that “395 million workers worldwide suffered non-fatal workplace injuries,” the organization states.</p><p><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i>Sign up</i></a><i> for our weekly newsletter to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iMessage, explained (549 pts)]]></title>
            <link>https://jjtech.dev/reverse-engineering/imessage-explained/</link>
            <guid>38532167</guid>
            <pubDate>Tue, 05 Dec 2023 15:33:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jjtech.dev/reverse-engineering/imessage-explained/">https://jjtech.dev/reverse-engineering/imessage-explained/</a>, See on <a href="https://news.ycombinator.com/item?id=38532167">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>This blog post is going to be a cursory overview of the internals iMessage, as I’ve discovered during my work on <a href="https://github.com/JJTech0130/pypush"><code>pypush</code></a>, an open source project that reimplements iMessage.</p>

<p>I gloss over specific technical details in the pursuit of brevity and clarity. If you would like to see how things are specifically implemented, check out the <a href="https://github.com/JJTech0130/pypush"><code>pypush</code> repository</a> as I mentioned above. It’s a pretty cool project, if I do say so myself. Make sure to check it out!</p>

<p>If you still end up with any questions, feel free to ask me in the <a href="https://discord.gg/BVvNukmfTC"><code>pypush</code> Discord</a></p>

<h3 id="the-foundational-layer">the foundational layer</h3>
<p>One of the most foundational components of iMessage is Apple Push Notification Service (APNs). You might have encountered this before, as it is the <em>same service</em> that is used by applications on the App Store to receive realtime notifications and updates, even while the app is closed.</p>

<p>However, what you probably <em>didn’t</em> know about APNs is that it is <em>bidirectional</em>. That’s right, APNs can be used to send push notifications as well as receive them. You can probably already tell where this is going, right?</p>

<p>Internally, after a device connects to APNs it will receive a “push token”. This token can be used to route notifications to that specific device.</p>

<p><strong>Note:</strong> This token is technically different then the token you receive when using the <code>application:didRegisterForRemoteNotificationsWithDeviceToken:</code> API. That token is scoped for per-app use, and is requested using the bundle ID of the application. However, it is basically used for the same purpose.</p>

<p>When sending push notifications to a device, you also need to specify the <em>topic</em> a message is for. This usually looks like a Bundle ID, and for iMessage it’s <code>com.apple.madrid</code>. When a device connects to APNs, it sends a filter message instructing the server on which messages it wants delivered to it.</p>

<p><strong>Note:</strong> The APNs server is also known as the APNs <em>Courier</em>. The filter message includes several lists of topics, for each of the different possible states. It may want a topic to be <code>enabled</code>, <code>opertunistic</code>, <code>paused</code>, or <code>disabled</code></p>

<p>APNs is not only used for the actual message delivery part of iMessage. Using a pseudo-HTTP layer on top of APNs, IDS (which will be explained in a moment) can send queries and receive responses over APNs as well.</p>

<p>One tricky note that I will mention is that in order to connect to APNs, you need a client certificate issued by the Albert activation server.</p>

<h3 id="the-keyserver">the keyserver</h3>
<p>The next piece of this puzzle is IDS. As far as I can figure out, this stands for IDentity Services, though I don’t think there is any official confirmation on that.</p>

<p><strong>Note:</strong> You may also see it referred to as ESS. This is confusing because the APNs topic <em>FaceTime</em> uses is specifically called <code>com.apple.ess</code>. Moving on…</p>

<p>IDS is used as a keyserver for iMessage, as well as a few other services like FaceTime. Remember, iMessage is E2E encrypted, so the public keys of each participant must be exchanged securely.</p>

<p>The first step in registering for IDS is getting an authentication token. This requires giving the API your Apple ID Username and Password.</p>

<p><strong>Note:</strong> As 2FA is now standard, it had to be retrofitted into the IDS API. There are 2 options for this: the legacy option, in which a 2FA code is directly appended to the password, and the “GrandSlam” option. In the GrandSlam option, “Anisette data” is used to prove you are the same device and thus do not need to enter the 2FA code again. You then receive a Password Equivalent Token (PET) which can be used as if it was the password + 2FA code.</p>

<p>After one has gotten an authentication token, it must be immediately exchanged for a longer lived authentication certificate. This certificate allows registering with IDS, but it is not yet enough to perform key lookups.</p>

<p>Perhaps the most important step of the IDS setup process is <em>registration</em>. This is where public encryption and signing keys are uploaded to the keyserver, as well as various other “client data” about what features the device supports.</p>

<p>When making an IDS registration request, a binary blob called “validation data” is required. This is essentially Apple’s verification mechanism to make sure that non-Apple devices cannot use iMessage.</p>

<p><strong>Warning:</strong> In order to generate the “validation data”, pieces of information about the device such as its serial number, model, and disk UUID are used. This means that not all validation data can be treated equivalently: just like with Hackintoshes, the account age and “score” determine if an invalid serial can be used, or if you get the “customer code” error.</p>

<p><strong>Note:</strong> The binary that generates this “validation data” is highly obfuscated. <code>pypush</code> sidesteps this issue by using a custom mach-o loader and the Unicorn Engine to emulate an obfuscated binary. <code>pypush</code> also bundles device properties such as the serial number in a file called data.plist, which it feeds to the emulated binary.</p>

<p>After registering with IDS, you will receive an “identity keypair”. This keypair can then be used to perform public key lookups.</p>

<p>When performing a lookup, you provide the account(s) that you would like to look up, and receive a list of “identities”. Each of these identities corresponds to a device registered on the account, and includes important details such as its public key, push token, and session token.</p>

<p><strong>Warning:</strong> Session tokens are necessary to send messages to a device. They essentially prove that you made a recent lookup, because the session token expires. Session tokens cannot be shared, as they can only be used by the account that performed the lookup request.</p>

<h3 id="message-encryption">message encryption</h3>
<p>Now, we’ve setup the basics of iMessage. We have enough that we can look up the public keys of another user, as well as publish our own. Now we just need to put it together with APNs to send and receive messages!</p>

<p>In order to receive messages, one simply filters the APNs connection to <code>com.apple.madrid</code> and sends the active state packet.</p>

<p>Depending on which capabilities you advertised in your IDS registration, as well as the iOS version of the sending device, you may receive messages in the legacy (pre-iOS 13) <code>pair</code> encryption format, or in the new <code>pair-ec</code> format. While the <code>pair</code> format is much more documented and easier to implement, it does not provide forward secrecy using “pre-keys” (similar to Signal) as the new <code>pair-ec</code> format does.</p>

<p>You can then decrypt the message as described in several papers, and as implemented in <code>pypush</code>. Verifying the message signature is optional, but is obviously important if you intend your client to be secure.</p>

<p>Sending messages is pretty much the inverse to receiving them. Keep in mind that you can chose to individually send out messages to each recipient, or you can bundle all the different recipients and their respective encrypted payloads into a giant bundle, which APNs will split up for you.</p>

<p><strong>Note:</strong> Another thing to keep in mind is that message are delivered to all participants in a conversation, <em>including the other devices on your own account</em>.</p>

<p>One more thing to keep in mind that is often overlooked when sending messages is that the AES key is not entirely random: it is tagged with an HMAC. Your message will fail to decrypt on newer devices if you use an entirely random AES key.</p>

<p>And that’s pretty much it! As I mentioned, this blog post is designed to give you a good idea of how the iMessage protocol fits together, so that you can explore the <code>pypush</code> code, not directly explain every technical detail.</p>

<h3 id="resources-and-attribution">resources and attribution</h3>
<p>Many people and prior works have helped me understand iMessage. Here is a brief list, in no way exhaustive:</p>
<ul>
  <li><a href="https://kb.imfreedom.org/protocols/imessage/">IMFreedom Knowledge Base: iMessage</a></li>
  <li><a href="https://github.com/mfrister/pushproxy">M. Frister: <code>pushproxy</code></a></li>
  <li><a href="https://gitlab.com/nicolas17/apns-dissector">Nicolás: <code>apns-dissector</code></a></li>
  <li><a href="https://blog.quarkslab.com/imessage-privacy.html">QuarkSlab: iMessage Privacy</a></li>
  <li><a href="https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_garman.pdf">Garman et al. Chosen Ciphertext Attacks on Apple iMessage</a></li>
  <li><a href="https://www.nowsecure.com/blog/2021/01/27/reverse-engineering-imessage-leveraging-the-hardware-to-protect-the-software/">NowSecure: Reverse Engineering iMessage</a></li>
  <li><a href="https://blog.elcomsoft.com/2018/11/imessage-security-encryption-and-attachments/">Elcomsoft: iMessage Security and Attachments</a></li>
  <li><a href="https://github.com/open-imcore">Eric Rabil’s <code>open-imcore</code></a></li>
  <li><a href="https://theapplewiki.com/wiki/Apple_Push_Notification_Service">The Apple Wiki: Apple Push Notification Service</a></li>
  <li><a href="https://par.nsf.gov/servlets/purl/10200009">Mihir Bellare and Igors Stepanovs: Security under Message-Derived Keys: Signcryption in iMessage</a></li>
  <li><a href="https://support.apple.com/lt-lt/guide/security/sec70e68c949/web">Apple Platform Security: How iMessage sends and receives messages securely</a></li>
  <li><a href="https://gist.github.com/nicolas17/559bec0d8e636f93f62cca844ee94ada">Nicolás: Apple IDS payload keys</a></li>
  <li><a href="https://discord.gg/NAxRYvysuc">Various people on the Hack Different Discord</a></li>
</ul>

<p>This blog post has been reworked from <a href="https://jjtech.dev/reverse-engineering/imessage-overview-original/">its original version</a>.</p>

        
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Beeper Mini – iMessage Client for Android (1276 pts)]]></title>
            <link>https://www.beeper.com/</link>
            <guid>38531759</guid>
            <pubDate>Tue, 05 Dec 2023 15:06:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.beeper.com/">https://www.beeper.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38531759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c23bdea55fb92a2fb0_Stack.png" loading="lazy" sizes="(max-width: 479px) 100vw, (max-width: 767px) 95vw, 43vw" alt="" width="488" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c23bdea55fb92a2fb0_Stack-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c23bdea55fb92a2fb0_Stack-p-800.png 800w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c23bdea55fb92a2fb0_Stack.png 976w"></p><div id="w-node-dc466a23-24ce-eaac-bc1e-fbc6baf49da5-6455b844"><h2>Full size photos and videos, plus replies and reactions</h2><p>Never share a tiny, grainy video ever again! Now send high resolution files, see reply threads, typing indicators, read receipts and share some 😂 with reactions.</p></div></div><div><div id="w-node-c9aea124-58e6-744b-d387-a0d96371cb45-6455b844"><h2>Join iPhone-only group chats</h2><p>Stop using clunky SMS group chats! Get a blue bubble and join your friends in group chats with features like edit, unsend, encryption and more!</p></div><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c135dfca0ec96c424e_Group%201321320359.png" loading="lazy" sizes="(max-width: 479px) 100vw, (max-width: 767px) 95vw, 43vw" alt="" width="505" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c135dfca0ec96c424e_Group%201321320359-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c135dfca0ec96c424e_Group%201321320359-p-800.png 800w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c135dfca0ec96c424e_Group%201321320359.png 1010w"></p></div><div><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c1c56915a29772ff56_Frame%201274482692.png" loading="lazy" width="491" sizes="(max-width: 479px) 100vw, (max-width: 767px) 95vw, 43vw" alt="" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c1c56915a29772ff56_Frame%201274482692-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c1c56915a29772ff56_Frame%201274482692-p-800.png 800w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656084c1c56915a29772ff56_Frame%201274482692.png 982w"></p><div id="w-node-af898cce-0f14-944a-3f40-449399dd20d4-6455b844"><h2>Turn your Android phone number blue</h2><p>Your phone number is no longer a green bubble! When iPhone friends text you, your number shows up as a blue bubble.<br></p></div></div></div><div><div id="w-node-_322496c1-9167-991a-6317-c9f9949d117a-6455b844"><div><h2>Fully secure, with end-to-end encryption</h2><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655ca962657b847f15a7da89_Icon.png" loading="lazy" width="80" alt=""></p></div><p>Your texts to iPhone friends are now encrypted. No one can read your messages, including Beeper or Apple. <a href="https://blog.beeper.com/p/how-beeper-mini-works" target="_blank">Learn more</a> about security and privacy in Beeper Mini.</p></div><div id="w-node-_31d7a295-cb04-ab3f-9fd1-936df4667a2e-6455b844"><div><h2>No Mac server in the middle (unlike the other&nbsp;apps)</h2><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655ca9629a501d645964ddf3_Icon-1.png" loading="lazy" width="80" alt=""></p></div><div><p>Beeper Mini is a standalone Android app: no laptop, external server, Mac or iPhone is required.</p><p>You don't need an Apple ID to use Beeper Mini. </p></div></div><div id="w-node-_983525ff-11c8-d392-46ef-4430cda9d990-6455b844"><div><h2>How does it work?</h2><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655ca964c2dab08d3701b6f2_Icon-2.png" loading="lazy" width="80" alt=""></p></div><p>With Beeper Mini, your phone number no longer appears as a green bubble. When iPhone friends text you, your number shows up as a blue bubble. Read <a href="https://blog.beeper.com/p/how-beeper-mini-works" target="_blank">our post</a>&nbsp;to learn more.</p></div><div id="w-node-_3b33905f-39ab-29c7-f87e-3f474eefc2ea-6455b844"><div><h2>Made by the people who created Pebble!</h2><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655ca96202694dc1ea772505_Pebble.png" loading="lazy" width="80" alt=""></p></div><div><div id="w-node-_90acbfa4-6e4d-7d7f-929e-4dd9980e7b1d-6455b844"><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/65648190f5afe81e4b4d5f60_Ellipse%204434.png" loading="lazy" alt=""></p></div><div id="w-node-dc3c926b-530f-8d12-f671-26cf03e98251-6455b844"><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6564819093257c05ebe1778e_Ellipse%204435.png" loading="lazy" alt=""></p></div></div></div></div><div><div id="w-node-_8737f3ef-1f6a-7d72-365a-4ba1f02238e4-6455b844"><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554b6303f2a8de1153019b8_beeper%20mini%20logo.png" loading="lazy" sizes="(max-width: 479px) 93vw, (max-width: 767px) 23vw, (max-width: 991px) 24vw, 9vw" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554b6303f2a8de1153019b8_beeper%20mini%20logo-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554b6303f2a8de1153019b8_beeper%20mini%20logo.png 662w" alt=""></p></div><div id="w-node-_0ff9e3ac-9cd3-ee97-4bd9-1a118b870e34-6455b844"><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554bb9100996e72ef84fb3d_Bento%20group%20chat.png" loading="lazy" alt=""></p><p>Get group chats with iPhones</p></div><div id="w-node-_76b273f1-b1ef-d57b-33d2-94c7d7226144-6455b844"><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655cb4ad113a2fc74741b8b3_bento%20mediav3.png" loading="lazy" width="175" sizes="(max-width: 479px) 100vw, (max-width: 991px) 27vw, 11vw" alt="" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655cb4ad113a2fc74741b8b3_bento%20mediav3-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/655cb4ad113a2fc74741b8b3_bento%20mediav3.png 650w"></p><p>Full size media, videos, and audio</p></div><div id="w-node-_2fcc26da-0a8d-8e98-fee7-731fc69c3a5c-6455b844"><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554baee386c4e53f3bec8c9_bento%20blue%20text.png" loading="lazy" sizes="(max-width: 479px) 59vw, (max-width: 767px) 25vw, (max-width: 991px) 24vw, 12vw" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554baee386c4e53f3bec8c9_bento%20blue%20text-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554baee386c4e53f3bec8c9_bento%20blue%20text.png 596w" alt=""></p><p>Turn your phone number blue</p></div><div id="w-node-_033da6bc-e77b-cf3c-6da2-99bf64125674-6455b844"><p>End-to-end encrypted with no server, Mac, or iPhone required</p><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554bc5a24d28bdfc086d454_nicely%20done%20emoji.png" loading="lazy" width="16.5" alt=""></p></div><div id="w-node-f71c9b25-e943-1da1-e090-a2dc4d5c47c7-6455b844"><div><p>Blue bubbles on Android</p><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655cb5c2d3c7f9bcc53eef0d_get%20in%20the%20jam%20image.png" loading="lazy" alt=""></p></div><p>Get in the jam</p></div><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656ef339b0c5f8cb7dcbe186_bento%20screenv3.webp" loading="eager" width="283" sizes="(max-width: 479px) 100vw, (max-width: 767px) 17vw, (max-width: 991px) 18vw, 4vw" alt="" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/656ef339b0c5f8cb7dcbe186_bento%20screenv3-p-500.webp 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/656ef339b0c5f8cb7dcbe186_bento%20screenv3.webp 566w"></p><div id="w-node-_160775d0-6885-f63b-725c-963022816ec3-6455b844"><p>Funky initial avatars</p><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/655b4589cc754248abe1b6ac_bento%20avatars.png" loading="lazy" alt=""></p></div><div id="w-node-_18aaad17-b231-aa0c-b792-2fcbd591e172-6455b844"><p>Thread replies</p><p><img src="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554dbacb47196d30cb9ef6c_bento%20thread.png" loading="lazy" sizes="(max-width: 479px) 67vw, (max-width: 767px) 28vw, (max-width: 991px) 27vw, 13vw" srcset="https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554dbacb47196d30cb9ef6c_bento%20thread-p-500.png 500w, https://assets-global.website-files.com/5ffc199ed786423eb2569667/6554dbacb47196d30cb9ef6c_bento%20thread.png 716w" alt=""></p></div></div><div><div><p>Beeper Mini is a standalone Android app built specifically to send and receive blue bubble messages with iPhones. It has all the chat features you expect like typing status, read receipts, full resolution attachments, emoji reactions, voice messages, editing/unsending, stickers and more. </p><p>For the first time, you can use your Android phone number instead of your email address to send messages! Your phone number will appear as a blue bubble when iPhone friends text you.</p><p>Over time, support for other chat networks will be added, turning Beeper Mini into a multi-network chat app. Read more in our <a href="https://blog.beeper.com/p/d3064165-c5ef-4cb9-90a5-794813a732e8" target="_blank">announcement blog post</a>. </p></div><div><div><p>How does Beeper Mini work? How secure is it?</p></div><div><p>Unlike other similar apps, Beeper Mini does not use a Mac relay server in the cloud. The app connects directly to Apple servers to send and receive end-to-end encrypted messages. Encryption keys never leave your device. No Apple ID is required. Beeper does not have access to your Apple account.</p><p>Your messages are end-to-end encrypted. Neither Beeper, Apple, nor anyone except the intended recipients can read your messages or view attachments. Read more about <a href="https://blog.beeper.com/p/how-beeper-mini-works" target="_blank">how Beeper Mini works</a>.</p></div></div><div><div><p>Do I need a Mac or iPhone to use Beeper Mini?</p></div><div><p>Nope! Beeper Mini is a standalone Android app. Download it now from <a href="https://play.google.com/store/apps/details?id=com.beeper.ima" target="_blank">Google&nbsp;Play</a> and see for yourself today.</p><p>You don't need an Apple ID&nbsp;account to use Beeper Mini.</p></div></div><div><div><p>How much does Beeper Mini cost?</p></div><div><p>We currently offer a 7 day free trial, afterwards there is a $1.99 per month subscription. Beeper Mini is available to <a href="https://play.google.com/store/apps/details?id=com.beeper.ima" target="_blank">download</a> today with no waitlist.</p><p>Our business model is simple - we build a great app and earn money from those who find value in it. We feel that this business model aligns our success with your goals. No ads. Complete data security and privacy. Plus, we’re incentivized to continue improving the app with new features and improvements.</p></div></div><div><div><p>Does Beeper Mini support other chat networks? What about desktop and iOS?</p></div><div><p>Soon! Over time, we will be adding all networks that Beeper supports into Beeper Mini, including SMS/RCS, WhatsApp, Messenger, Signal, Telegram, Instagram, Twitter, Slack, Discord, Google Chat and Linkedin. We'll also bring Beeper Mini to desktop and iOS.</p><p>Also, we've renamed our original app to <a href="https://blog.beeper.com/p/beeper-cloud-and-product-roadmap" target="_blank">Beeper Cloud</a>. We will be adding all features from Beeper Cloud into Beeper Mini (making it not so Mini after all) and after that we'll invite existing users to transition off Beeper Cloud. Learn more about the transition on our blog.</p></div></div><div><div><p>Is Beeper or Beeper Mini affiliated with, or sponsored or endorsed by, Apple, Google, or any other chat network?</p></div><div><p>No. Beeper and Beeper Mini are entirely independent software products, with no relationship to, or endorsement by, Apple, Google, or any other supported chat networks.</p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Beeper Mini Works (127 pts)]]></title>
            <link>https://blog.beeper.com/p/how-beeper-mini-works</link>
            <guid>38531720</guid>
            <pubDate>Tue, 05 Dec 2023 15:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.beeper.com/p/how-beeper-mini-works">https://blog.beeper.com/p/how-beeper-mini-works</a>, See on <a href="https://news.ycombinator.com/item?id=38531720">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:137619,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a64c7-418d-4f48-a1e3-ab59075c1a24_3841x2160.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We’ve written this blog post to help you understand how </span><a href="https://play.google.com/store/apps/details?id=com.beeper.ima" rel="">Beeper Mini</a><span> works. At Beeper, we believe that it is critical for you to be able to trust the software that you use, especially something as important and sensitive as your chat app. We work to earn and keep your trust in three ways:</span></p><ol><li><p><span>Transparency - since we started Beeper 3 years ago, we’ve been taking opportunities like this to explain how Beeper works. We have a proud history of building products, like Pebble, and </span><a href="https://twitter.com/ericmigi" rel="">stand</a><span> </span><a href="https://twitter.com/bradtgmurray" rel="">publicly</a><span> behind our work.</span></p></li><li><p><span>Open source - each major piece of software that we’ve built to interact with other chat networks is open source at </span><a href="http://github.com/beeper" rel="">github.com/beeper</a><span>.</span></p></li><li><p>Privacy and security-aligned business model - we make great software and charge a small subscription fee. Simple as that. No ads. Your data stays private.</p></li></ol><p>Read the entire post for the full story. TLDR: the following features of Beeper Mini ensure that all communication is encrypted and secure.</p><ul><li><p>All messages are end-to-end encrypted before being sent. Beeper (and Apple) cannot see your messages.</p></li><li><p>Encryption keys never leave your device.</p></li><li><p>Beeper Mini connects directly to Apple servers. There is no Mac server relay, like other apps.</p></li><li><p>No Apple ID is required. Beeper does not have access to your Apple account.</p></li><li><p>Your contact list never leaves your device.</p></li></ul><p><span>Don’t believe this is possible? Try the </span><a href="https://github.com/JJTech0130/pypush" rel="">open-source Python proof of concept</a><span> on your own computer to see for yourself. Security researchers are invited to verify all claims that we make, see appendix below.</span></p><p><span>Beeper Mini works differently than Beeper Cloud in important ways that increase your privacy and security. Beeper Mini is a standalone Android app. It does not require a cloud server to send and receive messages. It also implements </span><a href="https://support.apple.com/fr-fr/guide/security/sec70e68c949/web" rel="">Apple’s end-to-end encryption protocol</a><span> natively within the Android app itself. All messages are end-to-end encrypted before they are transmitted directly from your device to Apple servers. Learn more about iMessage encryption on </span><a href="https://support.apple.com/fr-fr/guide/security/sec70e68c949/web" rel="">Apple Platform Security</a><span> page.</span></p><p>This is now possible because the iMessage protocol and encryption have been reverse engineered by jjtech, a security researcher. Leveraging this research, Beeper Mini implements the iMessage protocol locally within the app. All messages are sent and received by Beeper Mini Android app directly to Apple’s servers. The encryption keys needed to encrypt these messages never leave your phone. Neither Beeper, Apple, nor anyone except the intended recipients can read your messages or attachments. Beeper does not have access to your Apple credentials.</p><p><span>We built Beeper Mini by analyzing the traffic sent between the native iMessage app and Apple’s servers, and rebuilding our own app that sends the same requests and understands the same responses. Learn more by reading jjtech’s blog post, </span><a href="https://jjtech.dev/reverse-engineering/imessage-explained/" rel="">iMessage Explained</a><span>, and his proof-of-concept </span><a href="https://github.com/JJTech0130/pypush" rel="">Python implementation on Github</a><span>. Anyone can download this code, run it on any computer that supports Python, login to their iMessage account, and send and receive iMessage protocol messages. No Apple hardware required.</span></p><p><span>Another change is that Beeper Mini does not use the </span><a href="http://matrix.org/" rel="">Matrix</a><span> protocol, encryption or code like Beeper Cloud. It is a completely new codebase, versus our first Android app, which was a fork of </span><a href="https://github.com/vector-im/element-android" rel="">Element</a><span>. In the future, we are planning to add Matrix network support back in, along with support for the 15 other chat networks in Beeper Cloud. Read more about </span><a href="https://blog.beeper.com/p/beeper-cloud-and-product-roadmap" rel="">our roadmap</a><span>.</span></p><p>When you first start the Beeper Mini app and sign in with Google, a registration request is sent to our Beeper API Server. This service only exists to verify your subscription status, as well as give our support team the information they need to debug any issues that you may be running into (including your name and email address). No iMessage credentials or messages are transmitted through these servers, which are for Beeper Mini account management only.</p><p>After that, you are prompted to allow notifications, which sends a push token to Beeper Push Notification service, which enables our servers to send push notifications to your Android device. These push notifications do not contain the contents of messages.</p><p>Next, you are prompted to grant contact list and SMS permission access.</p><ul><li><p>Contact list access is used to match phone numbers to contact names, and display profile pictures. Your contact list is never sent to Beeper servers.</p></li><li><p>SMS access is used to send an SMS text message from your number to Apple’s “Gateway” service. The gateway sends a response via SMS, and the contents from that SMS response are sent to Apple to register your phone number as a blue bubble. Your SMS chat history is also used to determine if any of your recent SMS chats were with people who have iPhones. If so, these chats are shown in the inbox.</p></li></ul><p>It’s at this point that the app generates encryption keys that are used for end-to-end encrypted messaging. The public key is sent to Apple servers, and the private keys are stored in the Android device local filesystem. Beeper Mini is now signed in.</p><p>Optionally, you may also sign in to your Apple ID to enable sending/receiving from your email address. This will also enable you to send and receive messages from other Apple devices like iPad or Macs. The Apple ID login sends your username, password and a 2-factor code using encrypted HTTPS requests directly to Apple servers.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png" width="1456" height="1082" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1082,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9dd427a-aca1-4932-8f94-4376bb7a522a_2000x1486.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Apple’s iMessage protocol works over </span><a href="https://en.wikipedia.org/wiki/Apple_Push_Notification_service" rel="">Apple Push Notification service</a><span>, which most developers would be familiar as the service that allows them to send push notifications to their iOS applications. For iMessage protocol, all messaging traffic flows over this service in both directions, encrypted with keys generated locally on each device. Beeper Mini connects to APNs over TCP, using the credentials generated during the login process.</span></p><p>A persistent connection to APNs is needed to be notified of new incoming messages in real-time. On an iPhone, an APNs connection is maintained by the operating system, and connected at all times. In Beeper Mini, the connection can only be maintained when the app is running, since Android does not support APNs natively.</p><p>To work around this limitation, we built Beeper Push Notification service (BPNs). BPNs connects to Apple’s servers on your behalf when Beeper Mini Android app isn’t running. We can do this while preserving user privacy thanks to Apple separating the credentials needed to connect to APNs to send and receive content (the “push” credentials) and the keys needed to encrypt and decrypt messages (the “identity” keys). Push credentials can be shared securely with the Beeper Push Notification service, and BPNs can connect to APNs on your behalf. Whenever BPNs receives an encrypted message that it won’t be able to decrypt, it simply disconnects from APNs and sends an FCM push notification to wake up the Android app, which then connects to APNs, downloads, decrypts and processes the incoming message. BPNs can only tell when a new message is waiting for you - it does not have credentials to see or do anything else.</p><p>BPNs will be notified when you receive a message, but without the encryption keys it can’t decrypt anything BPNs receives. Also, without the identity credentials, BPNs can’t send messages on your behalf. If you don’t mind not receiving real-time push notifications for new messages, your BPNs can be disabled entirely by going to Settings → Manage Connection → Enable Push.</p><p>When you create a new chat, the phone number or email address of your intended recipient is transmitted to Apple servers. If the contact is on iMessage, a public key is returned.</p><p>Sending messages is even simpler. When you hit send, the message is encrypted with the public keys of the intended recipients and sent directly to Apple servers via an SSL encrypted TCP connection over APNs.</p><p>Beeper Mini connects to a few other services as part of its operation. We use a self-hosted installation of Rudderstack (https://rudderstack.beeper-tools.com) for analytics and diagnostic events, which we use for improving the app but can be disabled in Settings → Preferences →Share Diagnostics. We use OneSignal to send education and account related push notifications, and RevenueCat to help integrate Google Play subscriptions.</p><p>Other than that, that’s it! No other servers or services are used. Beeper Mini keeps your messaging secure by keeping all messaging credentials, keys, messages and media local to your phone, and only sends them directly to Apple’s servers after encrypting them with iMessage’s end-to-end encryption algorithm.</p><p>We value, actually, we treasure feedback. If you run into a bug or have a feature request, there’s a button in-app to report a problem. We read every single report.</p><p><strong><br><span>Brad Murray and Eric Migicovsky</span><br></strong><span>Beeper cofounders</span></p><p><span>To write this blog post, we performed a red team analysis on our own app. We made extensive use of the excellent </span><a href="https://mitmproxy.org/" rel="">mitmproxy</a><span> project to capture the network traffic coming from a real phone running a modified version of the Beeper Mini client. A modified version was needed for this analysis in order to disable certificate pinning, so that the Beeper Mini Android app would accept being connected to mitmproxy instead of only accepting Apple’s certificates for that connection. If researchers would like a copy of this version of Beeper Mini (with cert pinning disabled) to perform a similar analysis, please contact us at </span><a href="mailto:security@beeper.com" rel="">security@beeper.com</a><span>.</span></p><p><span>Below is a capture of the requests that we make with Apple’s servers over HTTPS when logging into iMessage with your phone number. We first register with a service named </span><code>albert.apple.com</code><span>, which sets up our “push” credentials and allows us to connect to APNS. We then make two requests to get the number we need to send an SMS to register our phone number which is different for each carrier (This capture was taken with a device registered with Rogers, a Canadian cell phone carrier 🇨🇦). Finally, we take the contents of the response SMS (not shown here) and send it to </span><code>identity.ess.apple.com</code><span>, registering our account with iMessage and generating the “identity” credentials we’ll use to send and receive.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png" width="1456" height="266" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:266,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b45018a-3063-49b5-a572-afdb7b97a62d_2000x365.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Optionally, you can also register your Apple ID with Beeper Mini as well, as shown in this capture. You first provide your username and password over encrypted HTTPS directly to Apple’s servers, followed by a second request to provide your 2FA code. We can then register for iMessage again, this time providing the certificates from both the earlier phone number registration and our new Apple ID registration. Registering these together in the same call links them together, allowing any other device that you’re logged in with your Apple ID to send and receive with both your Apple ID emails and your phone number.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png" width="1456" height="320" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:320,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F569867c7-ea40-441b-bbf2-82a1ad9c5b7d_2000x439.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Next, a capture of the keys shared with the Beeper Push Notification sevice (hostname </span><code>imux.beeper.com</code><span>). Note, the RSA private key in this request is your “push” credentials that allow you to connect to APNs, not your “identity” credentials that allow you to encrypt and decrypt iMesssages. Push credentials cannot be used to escalate permissions or access anything other than the presence of a new APNs push notification. Check out </span><code>[apns.py](&lt;http://apns.py&gt;)</code><span> in </span><a href="https://github.com/JJTech0130/pypush/blob/e2102d006e4fc558d48e66d3cbf10220e497f26e/apns.py#L116C9-L116C9" rel="">pypush PoC</a><span> to learn more about push credentials.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png" width="1456" height="1025" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1025,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba6b3d4e-41ac-45f8-99bd-c3a4ccffbfe5_2000x1408.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Sending and receiving is not shown here, as they are not done over HTTP but instead through an SSL encrypted TCP connection to APNs. The APNs servers are hosted at </span><code>*-[courier.push.apple.com](&lt;http://courier.push.apple.com/&gt;)</code><span> , where the asterisk is replaced by a number between 1 and 30. All message contents and media are encrypted with your “identity” keys, which never leave your Android phone.</span></p><p><span>There is a </span><code>/login</code><span> endpoint on Beeper servers, but as mentioned previous, this is only for subscription management purposes. The client submits the token received from the Google login process to our servers, and the response contains their subscription status. No iMessage credentials are ever sent to Beeper servers.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png" width="1456" height="499" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:499,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a07ca49-7e6c-445f-943b-7622caece3aa_2000x685.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png" width="1456" height="420" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:420,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f77bf6f-dac4-430b-8394-10a31630da05_2000x577.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Note:</strong><span> Beeper and Beeper Mini are entirely independent software products, with no relationship to, or endorsement by, Apple, Google, or any other supported chat networks.</span></p><p>iMessage, Apple, Mac and iPhone are trademarks of Apple, Inc.</p><p>Android is a trademark of Google, LLC.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: How did YOUR computer reach my server? (571 pts)]]></title>
            <link>https://how-did-i-get-here.net/</link>
            <guid>38531604</guid>
            <pubDate>Tue, 05 Dec 2023 14:56:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://how-did-i-get-here.net/">https://how-did-i-get-here.net/</a>, See on <a href="https://news.ycombinator.com/item?id=38531604">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
		<p>My server is chugging hard right now with a huge influx of traffic, so I lightly rearchitected this to still show the rest of the article below.</p>
		<p>- Lexi, Dec 5, 10:51 AM EST</p>
		
		
			<p>This part of the page is still loading while I wait for the above traceroute to load.</p>
		

		<img src="https://how-did-i-get-here.net/divider.svg" role="separator" alt="">
		
		<h2>Behind the Scenes</h2>
<p>To reach this website, your computer sent some packets across the Internet. If we’re curious what that path was, we can run a tool to generate a <em>traceroute</em> — a rough list of every server your packets touched to reach their destination. To build this website (<a href="https://github.com/hackclub/how-did-i-get-here">source code on GitHub</a>), I wrote my own traceroute program called ktr (<a href="https://github.com/kognise/ktr">also open source</a>) that can stream results in real time while concurrently looking up interesting information about each hop.</p>
<p>How does ktr work? Let’s start with a simplified explanation of Internet routing.</p>
<p>Starting with the source device, each computer that handles a packet has to choose the best device to forward it to — I will explain how these routing decisions are made in a bit. Assuming everything works correctly, the packet will eventually reach a router that knows how to send it directly to its destination.</p>
<p>My traceroute implementation uses a protocol called <a href="https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol">ICMP</a>. ICMP was designed specifically for sending diagnostic information around the Internet, and, helpfully, almost every Internet-connected device speaks it. Interestingly, ICMP packets have a “TTL” (time to live) field. This isn’t actually a “time” as implied by a name — it’s a countdown! Every time a router forwards an ICMP packet along, it’s supposed to decrement the TTL number. When the TTL hits zero, the router should stop forwarding it along and instead send an error message to the packet’s source IP saying that the packet has reached its maximum number of hops.</p>
<p>We can take advantage of this TTL feature! To do a traceroute, we can send a bunch of ICMP packets with increasingly large TTLs. The first packet with a TTL of 1 will error on the first device it reaches, and so on, until we hopefully get an error back from every routing device that touched the packet. These error packets include diagnostic information like the IP address of the device that sent the error, allowing us to trace your packets’ rough path across the Internet.</p>
<h3>Frontend Fun</h3>
<p>This page will work perfectly fine with JavaScript disabled. From the browser’s perspective, this website just loaded slowly. From your perspective, a traceroute magically loaded in.</p>
<p>When you loaded this website, my program received a HTTP request coming from your IP address. It immediately started running a traceroute to your IP. Then, the server started responding to the HTTP request: it sent the beginning of this web page, and then it left the connection open. As ktr, my traceroute program, gave the server updates on your traceroute, it rendered the relevant HTML and sent it to your computer. When the traceroute finished, the server generated all the text and sent the rest of the website along the line before closing out the connection.</p>
<p>You may have noticed that the traceroute progressively loads in lines above the bottom line. Web pages can only load forward. Since I didn’t want to use any JavaScript, I did the hackiest thing possible: every time I update the traceroute display, I embed a CSS block that hides the previous iteration! Since browsers render CSS as the page is loading, this made it look like the traceroute was being edited over time.</p>
<h3>Front to Back, Back to Front</h3>
<p>My claim that this website’s traceroute was the path your packets took to reach my server was a bit of a white lie. To calculate that, I would’ve had to be able to run a traceroute to my server <em>from your computer.</em> Instead, I ran the traceroute from my server to your computer and just reversed it. That’s also why the traceroute at the top seemingly loads in reverse order.</p>
<p>Does running a “reverse traceroute” sacrifice accuracy? A little, actually.</p>
<p>As I said when describing Internet routing, each device a packet traverses makes a decision about where to send the packet next until it reaches its final destination. If you send a packet in the other direction, the devices might make different routing decisions… and if one device makes one different decision, the rest of the path will certainly be different.</p>
<p>This reverse traceroute is still helpful. The paths will be roughly the same, likely differing only in terms of which specific routers see your packet.</p>
<h3>So, What Are All Those Networks?</h3>
<p>This site began with talk about the “networks” you traversed to reach my server. What, concretely, are these networks?</p>
<p>Each network, also called an autonomous system (AS), is a collection of routers and servers that are privately connected to each other and generally owned by the same company. The owners of these autonomous systems decide the shape of the Internet by choosing which other autonomous systems to connect to. Internet traffic travels across autonomous systems that have “peering arrangements” with each other.</p>
<p>The Internet is often described as an open, almost anarchistic network connecting computers, some owned by people like you and me, and some owned by companies. In reality, the Internet is a network of corporation-owned networks, access and control to which is governed by financial transactions and dripping with bureaucracy.</p>
<p>If you want your own autonomous system, you can apply for an autonomous system number (ASN) with one of the five <a href="https://en.wikipedia.org/wiki/Regional_Internet_registry">regional Internet registries (RIRs)</a> that govern the Internet’s numbers. Be warned, they probably won’t listen to you if you aren’t backed by a company or you don’t have enough points of presence on the Internet. Just like we use IP addresses to identify—</p>
<p><em>Wait, what exactly do IP addresses identify? Uh… let’s say they represent devices with Internet access.</em></p>
<p>… Just like we use <a href="https://en.wikipedia.org/wiki/IP_address">IP addresses</a> to identify devices with Internet access, we use ASNs to identify the networks of the Internet. <span>Those are the numbers like “AS63949” in the traceroute from the start.</span></p>
<h3>Notes on WHOIS</h3>
<p>One of the reasons I wrote a cool traceroute program myself is so I could pull information on which autonomous systems own the IPs along your traceroute. A couple of organizations try to keep track of which ASes contain which IP addresses. Many of them let you perform ASN lookups using the <a href="https://en.wikipedia.org/wiki/WHOIS">WHOIS protocol</a>, so I wrote a small client to parse the responses from some servers I arbitrarily selected.</p>
<p>I then used this cool database called <a href="https://www.peeringdb.com/">PeeringDB</a> to figure out the companies behind the ASNs; PeeringDB has information on about 1/3rd of all autonomous systems. I used all of this information, alongside a couple hundred lines of if statements, to generate the text about network traversal for you.</p>
<p>WHOIS is actually an... interesting protocol to make a parser for. It turns out that the <a href="https://datatracker.ietf.org/doc/html/rfc3912/">WHOIS protocol specification</a> doesn't actually specify much. It specifies that you should make a TCP connection to the WHOIS server, send whatever you want to look up, and the server will send back some info and then terminate the connection. That’s all.</p>
<p>And yet, a lot of WHOIS servers will respond with structured-seeming information:</p>
<img src="https://how-did-i-get-here.net/whois-screenshot.png" width="942" height="716" alt="Screenshot of a Terminal app. Command was run: whois 198.58.104.130. Results are structured text, starting with a percent sign and the text &quot;IANA WHOIS server.&quot;">

<p>It turns out this structure is made up by the WHOIS server administrator and there just happen to be some shared conventions between servers. Even with the level of structure, the fields you want often show up with different names (origin? originas?) or even under multiple places at once.</p>
<p>My “parser” ended up as less of a parser and more as a lightweight simulator of how I, a human, might read through WHOIS results to find the ASN I need.</p>
<h2>BGP</h2>
<p>When you send a packet across the Internet, routers sitting at the borders where these networks connect decide which network to send your packet to next, until it reaches the network that contains the destination device.</p>
<p>These border routers talk to each other about which networks they’re able to connect to using a protocol called Border Gateway Protocol (BGP).</p>
<p>BGP is the protocol that gives the Internet its shape, and you <a href="https://jvns.ca/blog/2021/10/05/tools-to-look-at-bgp-routes/">can’t directly speak it yourself</a>.</p>
<h3>History Time</h3>
<p>In 1969, the same year Neil Armstrong landed on the moon, a message was (partially) sent on a prototype of the ARPANET. Over the next 20 years, this “network of interconnected computers” thing got pretty popular and everyone wanted on the train. Various universities, government agencies, and a couple random companies started making networks of their computers left and right.</p>
<p>A couple of these organizations started connecting their networks together so they could share data more easily. The Internet as we know it didn’t exist yet, but these network interconnections were getting out of hand and there wasn’t a great standard for coordinating them. In 1989, engineers at Cisco and IBM published <a href="https://datatracker.ietf.org/doc/html/rfc1105/">RFC 1105</a>, describing the first ever version of BGP.</p>
<p>Over the next couple of years, interconnected-network people got really busy as “the Internet” rapidly became a thing. Just one year after the BGP v1 RFC, Cisco went public and brought a lot of money into the networking industry, the term “IANA” was first used to refer to the <a href="https://en.wikipedia.org/wiki/Jon_Postel">random guy</a> and his college department that were keeping track of numbers on the Internet, ARPANET shut down for good, and <a href="https://datatracker.ietf.org/doc/html/rfc1163">BGP v2</a> was released.</p>
<p>In 1994, as the Internet-is-a-thing-now whirlwind was just beginning to calm, the final major version of BGP, v4, was specified in <a href="https://datatracker.ietf.org/doc/html/rfc1654">RFC 1654</a>. It was revised twice (in <a href="https://datatracker.ietf.org/doc/html/rfc1771">1995</a> and <a href="https://datatracker.ietf.org/doc/html/rfc4271">2006</a>) and got some patches, but BGP v4 is still the protocol we use for choosing routes across the interconnected networks that make up the modern Internet.</p>
<h3>How Does This BGP Thing Work?</h3>
<p>Routers at the borders between autonomous systems (“border gateways”) keep a list of every <em>BGP route</em> they know about, called a <em>routing table</em>. Each BGP route specifies the path of ASNs that could be followed to reach an autonomous system that controls a certain collection of IP addresses.</p>
<p>These routes across the Internet are formed by <em>peering relationships</em> between autonomous systems. When the border gateways of two autonomous systems <em>peer</em>, they are typically agreeing to:</p>
<ol>
<li><p>Allow traffic to travel between the two routers, meaning BGP routes can go directly between the two ASNs.</p>
</li>
<li><p>Keep each other up to date about the BGP routes they know about.</p>
</li>
</ol>
<p>Example time! Router A of AS0001 is physically connected with Router B of AS0002 and they want to peer with each other. They send BGP messages to each other to establish a <em>BGP session</em>. Router A now knows that it should go through Router B for any BGP route that starts with AS0002, and vice versa.</p>
<img src="https://how-did-i-get-here.net/networks-example.svg" width="380" height="308" alt="A diagram of 3 networks. AS0001 is connected to AS0002, which is in turn connected to AS1234.">

<p>BGP peers share the routes they know about with each other in a process called <em>route advertisement</em>. In our above example, when Router A connects to Router B, it would tell Router B “hey, here are all the routes I know about, you can go through my ASN (and by extension, me) to reach all of them.” Router B adds all of those routes through Router A — so, starting with AS0001 — to its routing table. Whenever another one of Router A’s peers advertises a new route, Router A will advertise those forward to Router B.</p>
<p>AS0001 probably directly controls some IP addresses itself. Router A would advertise those to Router B as well. Router B would then, in turn, advertise those direct routes forward, telling <em>its</em> peers that AS0002 → AS0001 is a valid route to reach those IPs. Through this process of forwarding route advertisements to peers, BGP routes are propagated across the entire network of autonomous systems such that any border gateway hopefully knows one or multiple AS paths to reach any IP on the Internet.</p>
<p>To route a packet to a certain IP, a border gateway first searches its routing table for every route that would bring it to an AS that controls that IP. The router then picks the “best” route by <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol#Route_selection_process">various heuristics</a> that include looking for the shortest path and weighing hardcoded preferences for or against certain autonomous systems. Finally, it routes the packet to the first AS in that path by sending it to that AS’s gateway router which it is peered with. That router, in turn, looks at its own routing table and makes its own decision about where to send the packet next.</p>
<h2>Recap</h2>
<ul>
<li><p>When you loaded this website, it used my custom traceroute program to run a traceroute to your public IP (<span>83.78.228.237</span>), stream that over HTTP, and then render a textual explanation of the traceroute.</p>
</li>
<li><p>A traceroute depicts the path of routers traversed between two devices on the Internet. My particular implementation works by sending ICMP packets with increasing TTL fields.</p>
</li>
<li><p>These routers are in networks called autonomous systems. Routers on the edges of these ASes peer with each other using BGP. Border routers use BGP to share their routing tables with each other, and then use this knowledge to make routing decisions.</p>
</li>
<li><p>BGP peering sessions are created according to (often private) arrangements between the owners of autonomous systems. Since traffic can only pass between peered networks, these arrangements are the sole governor of reachability on the Internet.</p>
</li>
</ul>
<h2>Epilogue</h2>
<p>I was frustrated with the state of understanding on the structure of the Internet and sought to write a comprehensive, interactive article covering its history and politics through the lens of protocols. However, I got caught up in a lot of complexity in life and, facing tight deadlines, didn't have the time to reach the lofty goals I had set for myself.</p>
<p>Thanks to the encouragement of my friends at Hack Club, I made the best out of what I had. “Better to ship a tiny raft than never ship that cruise yacht!” If nothing else, I got to make use of the sick ass traceroute program that powers the shiniest part of this site :)</p>
<p>I hope this serves as another fun, informative, and well-crafted thing on the web that can last, be shared around, and inspire people.</p>
<p>With love,<br>Lexi</p>
<h3>Other Stuff</h3>
<p>Some things to check out:</p>
<ul>
<li><a href="https://kognise.dev/writing">Writing I've done in the past</a></li>
<li><a href="https://hackclub.com/">Hack Club, the best community if you're a young person</a></li>
</ul>
<p>Proudly open source:</p>
<ul>
<li><a href="https://github.com/hackclub/how-did-i-get-here">This website’s source code</a></li>
<li><a href="https://github.com/kognise/ktr">My traceroute program’s source code</a></li>
<li><a href="https://www.figma.com/community/file/1260699047973407903/article-diagrams">Public Figma of all art on this website</a></li>
</ul>

	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How does Shazam work? (2022) (361 pts)]]></title>
            <link>https://www.cameronmacleod.com/blog/how-does-shazam-work</link>
            <guid>38531428</guid>
            <pubDate>Tue, 05 Dec 2023 14:44:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cameronmacleod.com/blog/how-does-shazam-work">https://www.cameronmacleod.com/blog/how-does-shazam-work</a>, See on <a href="https://news.ycombinator.com/item?id=38531428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<p><span>Sat 19 February 2022</span>
    <span><a href="https://www.cameronmacleod.com/category/tutorials.html">Tutorials</a></span></p><p><img alt="" src="https://www.cameronmacleod.com/images/abracadabra/header.png"></p>
<p>Your phone's ability to identify any song it listens to is pure technological magic. In this article, I'll show you how one of the most popular apps, <a href="https://www.shazam.com/">Shazam</a>, does it. The founders of Shazam released <a href="https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">a paper</a> in 2003 documenting how it works, and I have been working on an implementation of that paper, <a href="https://github.com/notexactlyawe/abracadabra">abracadabra</a>.</p>
<p>Where the paper doesn't explain something, I will fill in the gaps with how abracadabra approaches it. I've also included links to the corresponding part of the abracadabra codebase in relevant sections so you can follow along in Python if you prefer.</p>
<p>The state of the art has moved on since this paper, and Shazam has probably evolved its algorithm. However, the core principles of audio identification systems haven't changed, and the accuracy you can obtain using the original Shazam method is impressive.</p>
<p>To get the most out of this article, you should understand:</p>
<ul>
<li><a href="https://dobrian.github.io/cmp/topics/physics-of-sound/1.frequency-and-pitch.html">Frequency and pitch</a></li>
<li><a href="https://pudding.cool/2018/02/waveforms/">Waves</a></li>
<li><a href="https://www.twinkl.co.uk/teaching-wiki/axes">Graphs and axes</a></li>
</ul>
<p><strong>Quick links</strong></p>
<div>
<ul>
<li><a href="#what-is-shazam">What is Shazam?</a></li>
<li><a href="#why-is-song-recognition-hard-anyway">Why is song recognition hard anyway?</a></li>
<li><a href="#system-overview">System overview</a></li>
<li><a href="#calculating-a-spectrogram">Calculating a spectrogram</a><ul>
<li><a href="#the-fourier-transform">The Fourier transform</a></li>
<li><a href="#spectrograms">Spectrograms</a></li>
</ul>
</li>
<li><a href="#fingerprinting">Fingerprinting</a><ul>
<li><a href="#why-is-the-fingerprint-based-on-spectrogram-peaks">Why is the fingerprint based on spectrogram peaks?</a></li>
<li><a href="#finding-peaks">Finding peaks</a></li>
<li><a href="#hashing">Hashing</a></li>
</ul>
</li>
<li><a href="#matching">Matching</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#enter-abracadabra">Enter abracadabra</a></li>
<li><a href="#further-reading">Further reading</a></li>
</ul>
</div>
<h2 id="what-is-shazam">What is Shazam?</h2>
<p>Shazam is an app that identifies songs that are playing around you. You open the app while music is playing, and Shazam will record a few seconds of audio which it uses to search its database. Once it identifies the song that's playing, it will display the result on screen.</p>
<video autoplay="" loop="" muted="" playsinline="" src="https://www.cameronmacleod.com/images/abracadabra/shazam.mp4">Shazam recognising a song</video>

<p>Before Shazam was an app, it was a phone number. To identify a song, you would ring up the number and hold your phone's microphone to the music. After 30 seconds, Shazam would hang up and then text you details on the song you were listening to. If you were using a mobile phone back in 2002, you'll understand that the quality of phone calls back then made this a challenging task!</p>
<h2 id="why-is-song-recognition-hard-anyway">Why is song recognition hard anyway?</h2>
<p>If you haven't done much signal processing before, it may not be obvious why this is a difficult problem to solve. To help give you an idea, take a look at the following audio:</p>
<p><img alt="Chris Cornell's &quot;Like a Stone&quot; waveform" src="https://www.cameronmacleod.com/images/abracadabra/likeastone.png"></p>
<p>The above graph shows what <a href="https://www.youtube.com/watch?v=pom_tO2-5s8">Chris Cornell's "Like a Stone"</a> looks like when stored in a computer. Now take a look at the following section of the track:</p>
<p><img alt="Section from Like a Stone" src="https://www.cameronmacleod.com/images/abracadabra/likeastonesection.png"></p>
<p>If you wanted to tell whether this section of audio came from the track above, you could use a brute-force method. For example, you could slide the section of audio along the track and see if it matches at any point:</p>
<video autoplay="" loop="" muted="" playsinline="" src="https://www.cameronmacleod.com/images/abracadabra/slidingtrack.mp4">Matching a section of track by sliding it</video>

<p>This would be a bit slow, but it would work. Now imagine that you didn't know which track this audio came from, and you had a database of 10 million songs to search. This would take a lot longer!</p>
<p>What's worse, when you move from this toy example to samples that are recorded through a microphone you introduce background noise, frequency effects, amplitude changes and more. All of these can change the shape of the audio significantly. The sliding method just doesn't work that well for this problem.</p>
<p>Thankfully, Shazam's approach is a lot smarter than that. In the next section, you'll see the high-level overview of how this works.</p>
<h2 id="system-overview">System overview</h2>
<p>If Shazam doesn't take the sliding approach we described above, what does it do? Take a look at the following high-level diagram:</p>
<p><img alt="Diagram showing high-level overview of Shazam design" src="https://www.cameronmacleod.com/images/abracadabra/shazam_overview.png"></p>
<p>The first thing you will notice is that the diagram is split up into <em>register</em> and <em>recognise</em> flows. The <em>register</em> flow remembers a song to enable it to be recognised in the future. The <em>recognise</em> flow identifies a short section of audio.</p>
<p>Registering a song and identifying some audio share a lot of commonality. The following sections will go into more detail, but both flows have the following steps:</p>
<ol>
<li>Calculate the <strong>spectrogram</strong> of the song/audio. This is a graph of frequency against time. We'll talk more about spectrograms later.</li>
<li><strong>Find peaks</strong> in that spectrogram. These represent the loudest frequencies in the audio and will help us build a fingerprint.</li>
<li><strong>Hash</strong> these peaks. In short, this means pairing peaks up to make a better fingerprint.</li>
</ol>
<p>After calculating these hashes, the <em>register</em> flow will store them in the database. The <em>recognise</em> flow will compare them to hashes already in the database to identify which song is playing through the <strong>matching</strong> step.</p>
<p>In the next few sections, you'll learn more about each of these steps.</p>
<h2 id="calculating-a-spectrogram">Calculating a spectrogram</h2>
<p>The first step for both flows is to obtain a spectrogram of the audio being registered or recognised. To understand spectrograms, you first have to understand Fourier transforms.</p>
<h3 id="the-fourier-transform">The Fourier transform</h3>
<p>A <a href="https://realpython.com/python-scipy-fft/">Fourier transform</a> takes some audio and tells you which frequencies are present in that audio. For example, if you took a 20 Hertz sine wave and used the Fourier transform on it, you would see a big spike around 20 Hertz (Hz):</p>
<p><img alt="20Hz sine wave and its Fourier transform" src="https://www.cameronmacleod.com/images/abracadabra/fouriertransform20hz.png"></p>
<p>In the above image, you can see a large spike around 20Hz and nothing at other frequencies. Sine waves are often called <strong>pure tones</strong> because of this property, since they only contain a single frequency.</p>
<p>The result of a Fourier transform is called a <strong>frequency spectrum</strong>. We say that when you take the Fourier transform of a signal, you move it from the <strong>time domain</strong> into the <strong>frequency domain</strong>. These are fancy terms for describing whether time or frequency is along the bottom of a graph. In mathematical terms, the domain is more or less the X-axis of a graph.</p>
<p>The Y-axis of the frequency spectrum represents the strength of each frequency component. If a frequency component is stronger, then it will be more audible in the time-domain signal.</p>
<p>If you were to add a 50Hz sine wave at half the strength to that 20Hz sine wave, the resulting frequency spectrum would show a spike at 20Hz and a smaller spike at 50Hz:</p>
<p><img alt="20Hz sine wave plus 50Hz sine wave and its Fourier transform" src="https://www.cameronmacleod.com/images/abracadabra/fouriertransform20plus50.png"></p>
<p>As you can see, adding multiple audio waves together combines the frequencies present in them. In fact, all audio signals can be reconstructed from waves like this. For more, take a look at 3Blue1Brown's <a href="https://www.youtube.com/watch?v=spUNpyF58BY">video on the Fourier transform</a>.</p>
<p>One great property of the frequency domain is that it often helps us to see things that aren't clear in the time domain. For example, if you take the signal with two frequencies from before and add noise to it, in the time domain it looks visually very different. However, in the frequency domain, the two spikes are still very clear:</p>
<p><img alt="Fourier transform of a noisy signal" src="https://www.cameronmacleod.com/images/abracadabra/noisyfouriertransform.png"></p>
<p>In the frequency domain graph on the right, you can still clearly see the spikes for the main component frequencies. It would be harder in the time domain to see what frequency sine waves went into the signal.</p>
<p>Up until now, our examples have only contained one or two frequencies, but what happens if you put a more complex signal through the Fourier transform? Let's take a look at our section of audio from Like a Stone:</p>
<p><img alt="Fourier transform of a Like a Stone sample" src="https://www.cameronmacleod.com/images/abracadabra/fouriertransformsample.png"></p>
<p>Real audio files like the one above contain lots of different frequencies. This is a good thing, as it means that the frequencies present can uniquely identify songs.</p>
<h3 id="spectrograms">Spectrograms</h3>
<p><a href="https://github.com/notexactlyawe/abracadabra/blob/e0eb59a944d7c9999ff8a4bc53f5cfdeb07b39aa/abracadabra/fingerprint.py#L9">abracadabra implementation</a></p>
<p>If you run a Fourier transform over an entire song, then you will see the strength of the frequencies present over the whole song. However, the frequencies that are present change over time. To better represent the frequencies changing over time, we need to split the song into small sections before taking the Fourier transform. This is called taking a spectrogram.</p>
<p>Here's a simplified animation of how spectrograms work:</p>
<video autoplay="" loop="" muted="" playsinline="" src="https://www.cameronmacleod.com/images/abracadabra/spectrogram.mp4">Explanation of the spectrogram process</video>

<p>In the above animation, you can see that the song is first split into small sections. Next, we use the Fourier transform to calculate the frequency spectrum of each of these sections. When you put all these frequency spectrums together, you get a spectrogram.</p>
<p>To make this concrete, let's take a look at the spectrogram of Like a Stone:</p>
<p><img alt="Spectrogram of Like a Stone" src="https://www.cameronmacleod.com/images/abracadabra/spectrogram.png"></p>
<p>Even though the spectrogram looks 2-dimensional, it's actually a 3D graph with the following axes:</p>
<ul>
<li>Time (X-axis)</li>
<li>Frequency (Y-axis)</li>
<li>Strength (Z-axis/colour)</li>
</ul>
<p>The Z-axis is represented by colour in the spectrogram above. Bright green shows a high magnitude for a particular frequency component and dark blue shows a low magnitude.</p>
<p>Looking at the spectrogram above, you can see that the brightest spots (strongest frequencies) almost exclusively occur below 5000Hz. This is quite common with music, for example most pianos have a <a href="https://en.wikipedia.org/wiki/Piano_key_frequencies">frequency range</a> of 27Hz-4186Hz.</p>
<p>The frequencies present in a track contain a lot of identifying information, and calculating the spectrogram allows us access to that information. In the next section, you'll learn how we turn all that information into a unique fingerprint for the track.</p>
<h2 id="fingerprinting">Fingerprinting</h2>
<p>Just as a fingerprint uniquely identifies a person, we can extract a unique fingerprint for some audio from its spectrogram.</p>
<p>These audio fingerprints rely on finding peaks in the spectrogram. These peaks are the loudest frequencies at some time in the song. Because they are loud, it's likely they'll survive when subjected to noise or other distortions.</p>
<p>In the next section, you'll read some more about the motivation behind using spectrogram peaks to build fingerprints.</p>
<h3 id="why-is-the-fingerprint-based-on-spectrogram-peaks">Why is the fingerprint based on spectrogram peaks?</h3>
<p>A spectrogram peak is a frequency that is loud at some point in an audio signal. You can recognise these on a spectrogram since they will be the brightest points.</p>
<p>In music, these would represent the loudest notes. For example, during a guitar solo, the notes that the guitar is playing might become spectrogram peaks since they would likely be the loudest notes at that time.</p>
<p>A spectrogram peak is the point least likely to be affected by noise. Noise has to be louder than the spectrogram peak to make it unrecognisable and the spectrogram peaks are the loudest frequency components in the track.</p>
<p>To make this visual, take a look at our earlier example of a Fourier transformed signal that had noise added to it. When noise is added, the frequency peaks still retain their rough shape.</p>
<p><img alt="Fourier transform of a noisy signal" src="https://www.cameronmacleod.com/images/abracadabra/noisyfouriertransform.png"></p>
<p>Another advantage of using spectrogram peaks to fingerprint audio is that they cut down the amount of data we have to store. Storing only the loudest frequency components means we don't have to store everything else. This speeds up searching fingerprints since there is less data to look through.</p>
<p>Before we can use frequency peaks in our fingerprint though, we have to find them. In the next section, you'll learn how.</p>
<h3 id="finding-peaks">Finding peaks</h3>
<p><a href="https://github.com/notexactlyawe/abracadabra/blob/e0eb59a944d7c9999ff8a4bc53f5cfdeb07b39aa/abracadabra/fingerprint.py#L31">abracadabra implementation</a></p>
<p>As discussed in the previous section, the peaks of a spectrogram represent the strongest frequencies in a signal. For frequency peaks to be usable in an audio fingerprint, it's important that they are evenly spaced through the spectrogram.</p>
<p>It's important the peaks are evenly spaced in <strong>time</strong>, so the system can recognise any section of the song. For example, if all the peaks were at the start of the song, then the fingerprint wouldn't cover later sections:</p>
<p><img alt="Peaks clustered in time" src="https://www.cameronmacleod.com/images/abracadabra/peak_cluster_time.png"></p>
<p>In the image above, all the peaks (white crosses) are clustered at the start of the song. This means that the system can't recognise any sample from the rest of the song.</p>
<p>It's also important that the peaks are evenly spaced in <strong>frequency</strong>, so the system can deal with noise and frequency distortion. Sometimes noise will be very loud and concentrated at a specific frequency range, for example a car horn in the background:</p>
<video autoplay="" loop="" muted="" playsinline="" src="https://www.cameronmacleod.com/images/abracadabra/peak_cluster_freq.mp4">Peaks clustered in a frequency band affected by noise</video>

<p>In the above animation, the peaks are well-spaced in time, but are clustered into a small frequency band. When a loud noise is introduced, for example a car horn, it can make an entire section of song unrecognisable by changing which peaks are selected.</p>
<p>To find spectrogram peaks while keeping them well-spaced, we can borrow a technique from image processing known as a maximum filter. The process looks something like the following:</p>
<ol>
<li>Use the maximum filter to highlight peaks in the spectrogram.</li>
<li>Locate the highlighted peaks by comparing to our original spectrogram.</li>
<li>(Optional) Discard some peaks.</li>
</ol>
<p>Let's run through these steps one-by-one. First, let's take a look at how the maximum filter works:</p>
<p><strong>Step 1: Maximum filter</strong></p>
<p>A maximum filter emphasises the peaks in an image. It does this by looking in a neighbourhood around each pixel for the maximum value and then setting the pixel to that local maximum. The following animation shows a maximum filter that looks at a 3x3 neighbourhood around each pixel:</p>
<video autoplay="" loop="" muted="" playsinline="" src="https://www.cameronmacleod.com/images/abracadabra/maximumfilter.mp4">Animation of a maximum filter on a simple image</video>

<p>As you can see in the above animation, the maximum filter takes each pixel of an image in turn and finds the maximum in a region surrounding it. The filtered pixel is then set to that local maximum. This has the effect of expanding each local peak to its surrounding area.</p>
<p>Running a maximum filter on Like a Stone's spectrogram gives the following result:</p>
<p><img alt="Spectrogram and maximum-filtered spectrogram of Like a Stone" src="https://www.cameronmacleod.com/images/abracadabra/maxfilteredspectrogram.png"></p>
<p>The maximum-filtered spectrogram looks like a lower-resolution version of the original spectrogram. This is because the peaks in the signal have expanded and taken over the other pixels. Each box with the same colour in the filtered image corresponds to a local peak in the original image.</p>
<p>The maximum filter has a parameter that controls the size of the box to use when finding the local maxima. When you set this parameter to make a smaller box, you end up getting more peaks. Similarly, by setting this parameter larger you get fewer peaks.</p>
<p><strong>Step 2: Recover original peaks</strong></p>
<p>The maximum filter doesn't do all the work for us. The filter has emphasised the local peaks, but it hasn't found their locations. To find the peak locations, we need to find the points that have equal values in the original spectrogram and the filtered spectrogram.</p>
<p>The idea behind this trick is that all the non-peak points in the spectrogram have been replaced by their local peaks, so their values have changed. The only points whose values haven't changed are the peaks.</p>
<p>Below is a zoomed in section of the spectrogram above. The points where the values are equal in the filtered and original spectrograms are highlighted:</p>
<p><img alt="Zoomed section of spectrogram showing equal values in the maximum-filtered and original spectrograms" src="https://www.cameronmacleod.com/images/abracadabra/zoomed_spectrogram.png"></p>
<p>As you can see in the images above, the highlighted points where the two spectrograms are equal correspond to the local peaks of that part of the image.</p>
<p>Plotting all of the peaks together produces something called a <strong>constellation map</strong>. Here's the constellation map for Like a Stone:</p>
<p><img alt="Constellation map of Like a Stone" src="https://www.cameronmacleod.com/images/abracadabra/constellationmap.png"></p>
<p>These graphs are called constellation maps since they look a bit like an image of the night sky. Who said computer science couldn't be romantic?</p>
<p><strong>Step 3: (Optional) Discard peaks</strong></p>
<p>Once we have a constellation map of peaks, the next step is to potentially discard some. The size of our fingerprint is dependent on the number of peaks that we use in it. Keeping fingerprints small matters when you are storing millions of songs in your database.</p>
<p>However, by reducing the number of peaks we use, we reduce the accuracy of our system. Fewer peaks in a fingerprint mean fewer chances to match a sample to the correct song.</p>
<p>There are a couple of options for reducing the number of peaks in our fingerprint:</p>
<ol>
<li>Take the top N peaks. N should be proportional to the length of audio that you are fingerprinting to avoid over-representing shorter songs.</li>
<li>Take all peaks above a certain threshold. This doesn't guarantee you a certain fingerprint size per time like the other method, but may give more accurate results.</li>
</ol>
<hr>
<p>We have almost finished constructing our fingerprint, the next step is to produce a set of hashes from our peaks.</p>
<h3 id="hashing">Hashing</h3>
<p><a href="https://github.com/notexactlyawe/abracadabra/blob/e0eb59a944d7c9999ff8a4bc53f5cfdeb07b39aa/abracadabra/fingerprint.py#L96">abracadabra implementation</a></p>
<p>To motivate hashing, imagine that our fingerprint was just a collection of spectrogram peaks. Each peak's frequency would be represented by a certain number of bits, for example 10. With 10 bits of information, we can represent 2^10=1024 individual frequencies. With thousands of these points per track, we quickly get a lot of repeats.</p>
<p>Uniqueness is important for a fingerprint, since it makes searching a lot faster and helps to recognise more songs. Shazam's solution to the problem of uniqueness is to create hashes from pairs of peaks:</p>
<p><img alt="Diagram of two spectrogram peaks forming a hash" src="https://www.cameronmacleod.com/images/abracadabra/hash_diagram.png"></p>
<p>The diagram above shows a zoomed in portion of a spectrogram. Each circle represents a peak and the dashed line box represents a hash. You can see that a hash is formed of two peaks. The information that is recorded for each hash is the frequency of each peak, f<sub>A</sub> and f<sub>B</sub>, and the time delta between them, 𝚫T.</p>
<p>The advantage of pairing points up is that two paired points are much more unique than a single point. Looking at it mathematically, if each point has 10 bits of frequency information, and the time delta between the two points could be represented by 10 bits, then you have 30 bits of information. 2^30=1073741824 which is <strong>significantly</strong> larger than 1024 possibilities for a single point.</p>
<p>Shazam creates pairs using the following algorithm:</p>
<ol>
<li>Pick a point. This will be called the anchor point.</li>
<li>Calculate a target zone of the spectrogram for the anchor point.</li>
<li>For every point in the target zone, create a pair with the anchor point.</li>
</ol>
<p>You can see this algorithm illustrated in the following animation:</p>
<video autoplay="" loop="" muted="" playsinline="" src="https://www.cameronmacleod.com/images/abracadabra/pairing.mp4">Animation of pairing points</video>

<p>Choosing a target zone isn't described in the Shazam paper, but the images the paper contains show it as starting slightly ahead of time of the anchor point and being centred on the anchor point's frequency.</p>
<p>Once a pair has been created, it is stored as a hash in the database with the following information:</p>
<table>
  <thead>
    <tr>
      <th colspan="3"></th>
      <th colspan="2">Other information</th>
    </tr>
  </thead>
  <tbody><tr>
    <td>Point A freq (f<sub>A</sub>)
    </td><td>Point B freq (f<sub>B</sub>)
    </td><td>Time delta (𝚫T)
    </td><td>Point A time
    </td><td>Track ID
  </td></tr>
</tbody></table>

<p>The first three columns (f<sub>A</sub>, f<sub>B</sub> and 𝚫T) make up the hash. The "Other information" is used to locate the hash at a specific time in a song. This will be used in matching later.</p>
<p>All of the hashes for a particular track make up the fingerprint. In the next section, you'll read about how Shazam matches these fingerprints.</p>
<h2 id="matching">Matching</h2>
<p>Given a collection of fingerprints in a database, how does Shazam figure out which one a given audio sample matches? This is where the matching part of the system comes in. Recall the system diagram from earlier:</p>
<p><img alt="Diagram showing high-level overview of Shazam design" src="https://www.cameronmacleod.com/images/abracadabra/shazam_overview.png"></p>
<p>The recognise and register flows both generate fingerprints. The difference lies in what they do with them. While the register flow stores fingerprints away for future matching, the recognise flow has to match its fingerprint with what is already in the database.</p>
<p>The matching algorithm contains the following steps:</p>
<ol>
<li>Retrieve all hashes from the database that match the sample's fingerprint.</li>
<li>Group these hashes by song.</li>
<li>For each song, figure out if the hashes line up.</li>
<li>Choose the track with the most lined up hashes.</li>
</ol>
<p>We'll look at each of these steps in turn.</p>
<p><strong>Step 1: Retrieve matching hashes</strong></p>
<p><a href="https://github.com/notexactlyawe/abracadabra/blob/e0eb59a944d7c9999ff8a4bc53f5cfdeb07b39aa/abracadabra/storage.py#L75">abracadabra implementation</a></p>
<p>The first step is to find every hash in the database that matches a hash in the fingerprint we just created. Even though a hash is a 3-tuple of <em>(f<sub>A</sub>, f<sub>B</sub>, 𝚫T)</em>, abracadabra stores this as <em>hash(f<sub>A</sub>, f<sub>B</sub>, 𝚫T)</em> where <code>hash()</code> is a <a href="https://en.wikipedia.org/wiki/Hash_function">hash function</a> that returns a single value. This way you only have to search for a single value per hash instead of three.</p>
<p><strong>Step 2: Group hashes by song</strong></p>
<p>Recall the format of an individual hash in the database:</p>
<table>
  <thead>
    <tr>
      <th colspan="3"></th>
      <th colspan="2">Other information</th>
    </tr>
  </thead>
  <tbody><tr>
    <td>Point A freq (f<sub>A</sub>)
    </td><td>Point B freq (f<sub>B</sub>)
    </td><td>Time delta (𝚫T)
    </td><td>Point A time
    </td><td>Track ID
  </td></tr>
</tbody></table>

<p>Thanks to the track ID that we associated with each hash, we can group the hashes by track. This allows us to score each potentially matching track.</p>
<p><strong>Step 3: Figure out if hashes line up</strong></p>
<p><a href="https://github.com/notexactlyawe/abracadabra/blob/e0eb59a944d7c9999ff8a4bc53f5cfdeb07b39aa/abracadabra/recognise.py#L80">abracadabra implementation</a></p>
<p>If a sample matches a song, then the hashes present in that sample should line up nicely with the hashes in some section of that song. The diagram below illustrates what this would look like:</p>
<p><img alt="Diagram of sample hashes lining up to song hashes" src="https://www.cameronmacleod.com/images/abracadabra/lineduphashes.png"></p>
<p>In the above diagram, a sample has been lined up with the section of the original song that it came from. The blue points represent the anchor points of the hashes.</p>
<p>While the above diagram shows the perfect scenario, there is a chance that the matching hashes from the database don't line up perfectly. For example, noise could have introduced peaks in the sample that resemble peaks at a different point in the song. This can lead to the following scenario:</p>
<p><img alt="Diagram of sample hashes imperfectly lining up with song hashes" src="https://www.cameronmacleod.com/images/abracadabra/badlylineduphashes.png"></p>
<p>In the above diagram, the red circles represent hashes that match to points in the song outside the section the sample came from. In this situation, it's harder to see that the sample is a perfect match for the song.</p>
<p>What's worse, sometimes hashes can match to the wrong song! This is where checking that the hashes line up comes in.</p>
<p>To explain how we can check whether the hashes line up in code, let's look at an example. Let's imagine that we've got a list of matching hashes from the database and grouped them by track. For a given track, we can then check the time that the hash occurs in the original track against the time that the hash occurs in the sample.</p>

<table>
<thead>
  <tr>
    <th>Sample time</th>
    <th>Track time</th>
    <th>Track time - Sample time</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>3</td>
    <td>13</td>
    <td><b>10</b></td>
  </tr>
  <tr>
    <td>4</td>
    <td>14</td>
    <td><b>10</b></td>
  </tr>
  <tr>
    <td>7</td>
    <td>20</td>
    <td>13</td>
  </tr>
  <tr>
    <td>5</td>
    <td>15</td>
    <td><b>10</b></td>
  </tr>
  <tr>
    <td>6</td>
    <td>12</td>
    <td>6</td>
  </tr>
  <tr>
    <td>1</td>
    <td>11</td>
    <td><b>10</b></td>
  </tr>
</tbody>
</table>

<p>In the above table, you can see that all the matches with a <em>Track time - Sample time</em> of 10 have been highlighted. These are the true matches, while the other two rows are false matches. To see this is the case, let's look at a similar diagram to the ones we saw before:</p>
<p><img alt="Diagram of sample hashes lining up to song hashes annotated with times" src="https://www.cameronmacleod.com/images/abracadabra/lineduphashes2.png"></p>
<p>The above diagram contains the same hashes from the previous table. As you can see, the true matches have a <em>Track time - Sample time</em> that is equal to how far into the track time that the sample starts.</p>
<p>To see how we turn this into a score for the track, let's make this data into a histogram. A histogram is a fancy name for a bar chart. We're going to plot each <em>Track time - Sample time</em> against the number of times it occurs:</p>
<p><img alt="Histogram showing frequency of 'Track time - Sample time'" src="https://www.cameronmacleod.com/images/abracadabra/sample_histogram.png"></p>
<p>Each bar in the histogram above is referred to as a <strong>bin</strong>. To score a song on how good a match it is for an audio sample, we just need to take the largest bin. Songs that aren't good matches will have low values in all bins, whereas a song that's a good match will have a large spike in one of the bins.</p>
<p>This way we can compare a sample to all the songs with matching hashes in our database and score each of them. The song with the highest score is likely to be the correct result.</p>
<p>You might wonder why we don't just go for the song that matches the largest number of hashes as it would be much simpler to implement. The problem with this approach is that not all songs are the same length. Longer songs are likely to get more matches than shorter songs and when some Spotify tracks are <a href="https://www.reddit.com/r/spotify/comments/9i2ps6/longest_song_on_spotify/">over 4 hours long</a> this can really bias your results!</p>
<h2 id="conclusion">Conclusion</h2>
<p>Well done for making it this far, that was a long journey! Over the course of this article, you've learned how Shazam extracts fingerprints from audio, and how it matches these fingerprints to those that it has already registered in its database.</p>
<p>To summarise, Shazam does the following to <strong>register</strong> a song:</p>
<ul>
<li>Calculates a <strong>spectrogram</strong> of a song</li>
<li>Extracts <strong>peaks</strong> from that spectrogram</li>
<li>Pairs those peaks up into <strong>hashes</strong></li>
<li>Stores the collection of hashes for a song as a <strong>fingerprint</strong></li>
</ul>
<p>Shazam does the following to <strong>recognise</strong> an audio sample:</p>
<ul>
<li>Calculates a <strong>fingerprint</strong> of the audio sample</li>
<li>Finds the <strong>hashes</strong> that match that fingerprint in the database</li>
<li>For each potential song match:<ul>
<li>Calculate <strong>Track time - Sample time</strong> for each matching hash</li>
<li>Group those values into a <strong>histogram</strong></li>
<li>Take the largest bin in this histogram as the <strong>score</strong> for the song</li>
</ul>
</li>
<li>Return the song with the highest score</li>
</ul>
<h2 id="enter-abracadabra">Enter abracadabra</h2>
<p>I learned everything written here over the process of writing <a href="https://github.com/notexactlyawe/abracadabra">abracadabra</a>, my implementation of this paper.</p>
<p>If you are interested in seeing what this might look like in code, please take a look! Everything is open source and I've done my best to document the project. abracadabra can also be used as a library in other projects, so please feel free to re-mix and build something cool. If you do use it, I'd love to <a href="https://www.cameronmacleod.com/about">hear about it</a>.</p>
<h2 id="further-reading">Further reading</h2>
<p>If you want to find out more about anything mentioned in this article, take a look below. I've also scattered some helpful links throughout the page.</p>
<ul>
<li><a href="https://abracadabra.readthedocs.io/en/latest/">abracadabra docs</a></li>
<li><a href="https://github.com/worldveil/dejavu">dejavu</a> is another implementation of a song recogniser in Python. The author wrote a <a href="https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/">wonderful explanation</a> on how it works.</li>
<li><a href="http://dhoiem.cs.illinois.edu/publications/cvpr2005-mr.pdf">Computer Vision for Music Identification</a> is another approach to song recognition that is similar to how dejavu works.</li>
<li>An algorithm that takes a slightly different approach is <a href="https://acoustid.org/chromaprint">Chromaprint</a>.</li>
<li><a href="https://wiki.musicbrainz.org/Fingerprinting">Musicbrainz</a> is an open-source encyclopedia of music information. This page explains how they fingerprint audio.</li>
<li><a href="http://aubio.org/news/20091111-2339_shazam">Playing with Shazam fingerprints</a> is an article from 2009 about the author's experience implementing the Shazam algorithm.</li>
<li><a href="http://static1.squarespace.com/static/53f7940ae4b05c506d396373/t/5669c81ba2bab86d89ef3dec/1449773083824/Koh_30x40.pdf">Alignment of videos of same event using audio fingerprinting</a> is an example of a use case for this algorithm that goes beyond music.</li>
</ul>
    <hr>
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mtn Dew using AI to find logos on twitch streams and reward streamers [pdf] (249 pts)]]></title>
            <link>https://www.mountaindew.com/wp-content/uploads/2023/11/MTN-DEW-RAID-QA.pdf</link>
            <guid>38531235</guid>
            <pubDate>Tue, 05 Dec 2023 14:35:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mountaindew.com/wp-content/uploads/2023/11/MTN-DEW-RAID-QA.pdf">https://www.mountaindew.com/wp-content/uploads/2023/11/MTN-DEW-RAID-QA.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=38531235">Hacker News</a></p>
Couldn't get https://www.mountaindew.com/wp-content/uploads/2023/11/MTN-DEW-RAID-QA.pdf: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Termshark – A terminal UI for tshark, inspired by Wireshark (165 pts)]]></title>
            <link>https://termshark.io/</link>
            <guid>38531181</guid>
            <pubDate>Tue, 05 Dec 2023 14:32:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://termshark.io/">https://termshark.io/</a>, See on <a href="https://news.ycombinator.com/item?id=38531181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- <h2>About Termshark</h2> -->
<!-- <p>Termshark is a simple terminal user-interface for tshark.</p> -->

<h2>Why?</h2>
<ul>
  <li>You're debugging on a remote machine and need to study a pcap.</li>
  <li>You don't want to copy it back to your desktop.</li>
  <li>You're familiar with Wireshark. 😃</li>
</ul>

<h2>Features</h2>
<ul>
  <li>Read pcap files or sniff live interfaces.</li>
  <li>Use Wireshark's display filters.</li>
  <li>Reassemble TCP and UDP streams.</li>
  <li>View conversations by protocol.</li>
  <li>Written in Go - for Linux, macOS, *BSD, Android (termux) and Windows.</li>
</ul>

<p>For setup, bugs and feature requests head over to <a href="https://github.com/gcla/termshark">GitHub</a>. </p>

<h2>News!</h2>
<ul>
  <li>Jul 11 2022 - <a href="https://termshark.io/changelogv24">Termshark</a> v2.4 is out now, featuring <a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#searching-packets">packet search</a> and <a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#profiles">profiles</a>.</li>
  <li>Sep 04 2021 - <a href="https://termshark.io/changelogv23">Termshark</a> v2.3 is ready! With <a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#columns">configurable columns</a>, <a href="https://termshark.io/wormhole-demo">magic wormhole</a> and more.</li>
  <li>Jan 03 2021 - <a href="https://termshark.io/changelogv22">Termshark</a> v2.2 is here! With <a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#vim-navigation">vim-navigation</a>, a <a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#command-line">cmdline</a><a>, </a><a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#marking-packets">packet marks</a>, and <a href="https://github.com/gcla/termshark/blob/master/docs/UserGuide.md#themes">themes</a>.</li>
</ul>

<hr>




      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox on the Brink? (581 pts)]]></title>
            <link>https://www.brycewray.com/posts/2023/11/firefox-brink/</link>
            <guid>38531104</guid>
            <pubDate>Tue, 05 Dec 2023 14:24:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brycewray.com/posts/2023/11/firefox-brink/">https://www.brycewray.com/posts/2023/11/firefox-brink/</a>, See on <a href="https://news.ycombinator.com/item?id=38531104">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="postArticle"><p><strong>Note</strong>: This post was the subject of a <a href="https://news.ycombinator.com/item?id=38531104" rel="noopener">Hacker News thread</a>.</p><p>A somewhat obscure guideline for developers of U.S. government websites may be about to accelerate the long, sad decline of Mozilla’s Firefox browser. There already are plenty of large entities, both public and private, whose websites lack proper support for Firefox; and that will get only worse in the near future, because the ’fox’s auburn paws are perilously close to the lip of the proverbial slippery slope.</p><p>The <a href="https://designsystem.digital.gov/" rel="noopener">U.S. Web Design System</a> (USWDS) provides a comprehensive set of standards which guide those who build the U.S. government’s many websites. Its <a href="https://designsystem.digital.gov/documentation/developers/" rel="noopener">documentation for developers</a> borrows a “2% rule” from its <a href="https://www.gov.uk/government/organisations/government-digital-service" rel="noopener">British counterpart</a>:</p><blockquote><p>.&nbsp;.&nbsp;.&nbsp;we officially support any browser above 2% usage as observed by <a href="https://analytics.usa.gov/" rel="noopener">analytics.usa.gov</a>.</p></blockquote><p>At this writing, that analytics page shows the following browser traffic for the previous ninety days:</p><table><thead><tr><th>Browser</th><th>Share</th></tr></thead><tbody><tr><td>Chrome</td><td>49%</td></tr><tr><td>Safari</td><td>34.8%</td></tr><tr><td>Edge</td><td>8.4%</td></tr><tr><td>Firefox</td><td>2.2%</td></tr><tr><td>Safari (in-app)</td><td>1.9%</td></tr><tr><td>Samsung Internet</td><td>1.6%</td></tr><tr><td>Android Webview</td><td>1%</td></tr><tr><td>Other</td><td>1%</td></tr></tbody></table><p>I am personally unaware of any serious reason to believe that Firefox’s numbers will improve soon. Indeed, for the web as a whole, they’ve been declining consistently for years, as this chart shows:</p><p><img src="https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_600,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png" srcset="https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_320,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png 320w, https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_640,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png 640w, https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_960,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png 960w, https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_1280,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png 1280w, https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_1600,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png 1600w, https://res.cloudinary.com/brycewray-com/image/upload/f_auto,q_auto:eco,w_1920,x_0,z_01/2023-11-30_screen-cap_StatCounter-browser-2009-01--2023-11_edited_2318x1158.png 1920w" alt="Chart of browser share for January, 2009, through November, 2023" title="Chart of browser share for January, 2009, through November, 2023" width="2318" height="1158" loading="lazy" sizes="(min-width: 1024px) 100vw, 50vw" data-pagefind-ignore=""></p><p>Chrome <em>vs.</em> Firefox <em>vs.</em> Safari for January,&nbsp;2009, through November,&nbsp;2023.<br>Image: <a href="https://gs.statcounter.com/" rel="noopener">StatCounter</a>.</p><p>Firefox peaked at 31.82% in November, 2009 — and then began its long slide in almost direct proportion to the rise of Chrome. The latter shot from 1.37% use in January, 2009, to its own peak of 66.34% in September, 2020, since falling back to a “measly” 62.85% in the very latest data.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>While these numbers reflect worldwide trends, the U.S.-specific picture isn’t really better. In fact, because the iPhone is so popular in the U.S. — which is obvious from what you see on that aforementioned government analytics page — Safari pulls large numbers that also hurt Firefox.</p><p>In my days in tech marketing, we used to worry about how a dominant competitor would take “shelf space” in those large stores where we wanted visibility for our goods and their accompanying point-of-purchase brochures. (Remember point-of-purchase literature, fellow oldsters?) Well, Firefox is quickly losing “web space,” thanks to a perfect storm that’s been kicked up by the dominance of Chrome, the popularity of mobile devices that run Safari by default, and many corporate and government IT shops’ insistence that their users rely on only Microsoft’s Chromium-based Edge browser while toiling away each day.</p><p>With such a continuing free-fall, Firefox is inevitably nearing the point where USWDS will remove it, like Internet Explorer before it, from the list of supported browsers.</p><p>“So what?” you may wonder. “That’s just for web developers in the U.S. government. It doesn’t affect any other web devs.”</p><p>Actually, it very well could. Here’s how I envision the dominoes falling:</p><ol><li>Once Firefox slips below the 2% threshold in the government’s visitor analytics, USWDS tells government web devs they don’t have to support Firefox anymore.</li><li>When that word gets out, it spreads quickly to not only the front-end dev community but also the corporate IT departments for whom some web devs work. Many corporations do a lot of business with the government and, thus, whatever the government does from an IT standpoint is going to influence what corporations do.</li><li>Corporations see this change as an opportunity to lower dev costs and delivery times, in that it provides an excuse to remove <em>some</em> testing (and, in rare cases, specific coding) from their development workflow.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></li></ol><p>.&nbsp;.&nbsp;.&nbsp;and just like that, in less time than you might think, Firefox — the free/open-source browser that was supposed to save the world from the jackboots of Internet Explorer (which had killed Firefox’s ancestor, Netscape Navigator) — is reduced to permanent status as a shrinking part of the fractured miscellany that litters the bottom of browser market-share charts.</p><p>I surely hope I’m wrong about this, but I fear I’m not.</p><hr><p>Nearly five years ago, as the news broke that Microsoft had decided to move its Edge browser to the Blink engine that also powers Google Chrome, I <a href="https://www.brycewray.com/posts/2018/12/on-edge/">wrote</a>:</p><blockquote><p>Supporting multiple browser engines — even if there is a Really Big Dog engine among them that’s about to get even bigger — ain’t always fun, but it goes with the territory; and I firmly believe it will continue to do so, especially for sites that are commercial in nature.</p></blockquote><p>That firm belief remains unchanged, but the meaning of the “multiple browser engines” part is in serious danger of significant change. Unless something dramatically reverses Firefox’s trends, the ’fox could soon be whimpering its way down an ugly, slippery slope to irrelevance.</p><p data-pagefind-ignore="">Latest commit (<a href="https://github.com/brycewray/hugo-site/commit/b1f9fd53f6e9e605008fe0290c7aa21af4e85506" title="Latest commit for this page" rel="noopener"><code>b1f9fd53</code></a>) for page file:<br>2023-12-05 at 9:00:27 AM CST.<br><a href="https://github.com/brycewray/hugo-site/commits/main/content/posts/2023/11/firefox-brink/index.md" title="This page’s commit history">Page history</a></p><contact-button data-pagefind-ignore="" aria-label="Link for generating email to reply to this website post"><span></span><span>Reply via email</span></contact-button></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sequential modeling enables scalable learning for  large vision models (126 pts)]]></title>
            <link>https://yutongbai.com/lvm.html</link>
            <guid>38530948</guid>
            <pubDate>Tue, 05 Dec 2023 14:14:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yutongbai.com/lvm.html">https://yutongbai.com/lvm.html</a>, See on <a href="https://news.ycombinator.com/item?id=38530948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Abstract</h2>
        <div><p>
            We introduce a novel sequential modeling approach which enables learning a Large Vision Model (<b>LVM</b>) without making use of any linguistic data. <br>
            To do this, we define a common format, "visual sentences", in which we can represent raw images and videos as well as annotated data sources such as semantic segmentations and depth reconstructions without needing any meta-knowledge beyond the pixels.<br>
            Once this wide variety of visual data (420 billion tokens) is represented as sequences, the model can be trained to minimize cross-entropy loss for next token prediction. <br>
            By training across various scales of model architecture and data diversity, we provide empirical evidence that our models scale effectively. 
            Many different vision tasks can be solved by designing suitable prompts at test time.</p></div>
      </div><div>
        <h2>Visual Sentences Enable Unified Visual Data Format.</h2>
        <div>
          <p><img src="https://yutongbai.com/static/images/figure1_final.jpg" alt="Visual Sentences"></p><p><b>Figure 1. Visual Sentence</b> allow us to format diverse vision data into the unified structure of image sequences.</p>
        </div>
        </div><div>
        <h2>LVM Shows Scalability Across Model and Data Size.</h2>
        <div>
            <p><img src="https://yutongbai.com/static/images/training_loss_plot.jpg" alt="Scalability Part 1" width="400" height="400"></p><!-- <p class="caption"><b>Figure 2. Training loss for the 300M, 600M, 1B, and 3B models.</b> All models are trained on 420B tokens, which correspond to 1.64B images. The training scales well with model sizes.</p> -->
            <p><b>Figure 2. Training loss for the 300M, 600M, 1B, and 3B models.</b> All models are trained on 420B tokens, which correspond to 1.64B images. The training scales well with model sizes.</p>

            <!-- <p class="total-caption" style="width: 100%; text-align: center;"><b>Total Caption:</b> ThisThisThisThisThisThisThisThisThisThis is the total caption for all four images.</p> -->

          </div>

        <!-- <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3"></h2>
            <div class="content has-text-justified"> -->
              
              <p><b>Figure 3. Larger LVMs perform better on downstream tasks.</b> We evaluate LVMs of varying sizes on 4 different downstream tasks, following the 5 shot setting on the ImageNet validation set and report the perplexity. We find that perplexity decreases with larger models across all tasks, indicating the strong scalability.</p>
              <!-- </div>

          </div> -->
        <!-- </div> -->

        <div>
          <p><img src="https://yutongbai.com/static/images/dataset_ablation.jpg" alt="Scalability Part 1"></p><p>Figure 4. We evaluate the perplexity of 4 models trained on different sub-components of our datasets on tasks using the ImageNet validation set. All models are 3B parameters and all evaluations are conducted in the 5-shot setting. We can see that the model benefits from each single images, videos and annotations, demonstrating the importance of our training dataset diversity.</p>

          <!-- <p class="caption"><b>Figure 2. Training loss for the 300M, 600M, 1B, and 3B models.</b> All models are trained on 420B tokens, which correspond to 1.64B images. The training scales well with model sizes.</p> -->
          <!-- <p class="total-caption" style="width: 100%; text-align: center;"><b>Total Caption:</b> ThisThisThisThisThisThisThisThisThisThis is the total caption for all four images.</p> -->

        </div>
      </div><div>
        <h2>Results, everything in prompts.</h2>
        <div>
          <p><img src="https://yutongbai.com/static/images/videos.jpg" alt="Visual Sentences"></p><p><b>Frame predictions.</b> LVM predicts the next frame (marked in red) given previous video frames as prompt. The results reveal the LVM can predict the video frames while considering dynamic objects and camera motion.</p>

          <p><img src="https://yutongbai.com/static/images/complex_task_2.jpg" alt="Visual Sentences"></p><p><b>In and out of distribution prompting examples.</b> Every row is a prompt that contains a sequence of images interleaved with annotations, followed by a query. The last image is predicted by the model (marked in red). The last 5 rows show examples where the query image is out of distribution (painting, sketch, etc) for the task it was trained for. </p>

          <p><img src="https://yutongbai.com/static/images/complex_task_3.jpg" alt="Visual Sentences"></p><p><b>Compositing &amp; novel tasks.</b> compositing
            several tasks together within a single prompt. Here, we
            demonstrate the rotation task together with the novel key-
            point correspondence task and request the model to continue
            the pattern. </p>



        </div>
        <h2>Miscellaneous Prompts. Guess what's next?</h2>

            <div>

              
             <div> 
              <p><img src="https://yutongbai.com/static/images/Guess_2.jpg" alt="Visual Sentences" width="500" height="500"></p><p><b>Tasks that are not always easily describable in language</b> </p>
              <br>
            
            </div>

    
              <p><img src="https://yutongbai.com/static/images/raven_2.jpg" alt="Visual Sentences"></p><p><b>Non-verbal IQ tests.</b></p>
              <br>
              <div>
                <p><img src="https://yutongbai.com/static/images/misc.jpg" alt="Visual Sentences" width="500" height="500"></p><p>A variety of simple vision
                  tasks, such as object replication (top), relighting (middle), and
                  zooming in (bottom), can be simply specified via a suitably chosen
                  visual sentence prompt that expresses the task to the LVM</p>
            </div>

      </div>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Polish trains lock up when serviced in third-party workshops (873 pts)]]></title>
            <link>https://social.hackerspace.pl/@q3k/111528162462505087</link>
            <guid>38530885</guid>
            <pubDate>Tue, 05 Dec 2023 14:10:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://social.hackerspace.pl/@q3k/111528162462505087">https://social.hackerspace.pl/@q3k/111528162462505087</a>, See on <a href="https://news.ycombinator.com/item?id=38530885">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[AI will enable mass spying (359 pts)]]></title>
            <link>https://www.schneier.com/blog/archives/2023/12/the-internet-enabled-mass-surveillance-ai-will-enable-mass-spying.html</link>
            <guid>38530880</guid>
            <pubDate>Tue, 05 Dec 2023 14:09:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.schneier.com/blog/archives/2023/12/the-internet-enabled-mass-surveillance-ai-will-enable-mass-spying.html">https://www.schneier.com/blog/archives/2023/12/the-internet-enabled-mass-surveillance-ai-will-enable-mass-spying.html</a>, See on <a href="https://news.ycombinator.com/item?id=38530880">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-68165">

	<div>

		
		<p>Spying and surveillance are different but related things. If I hired a private detective to spy on you, that detective could hide a bug in your home or car, tap your phone, and listen to what you said. At the end, I would get a report of all the conversations you had and the contents of those conversations. If I hired that same private detective to put you under surveillance, I would get a different report: where you went, whom you talked to, what you purchased, what you did.</p>
<p>Before the internet, putting someone under surveillance was expensive and time-consuming. You had to manually follow someone around, noting where they went, whom they talked to, what they purchased, what they did, and what they read. That world is forever gone. Our phones track our locations. Credit cards track our purchases. Apps track whom we talk to, and e-readers know what we read. Computers collect data about what we’re doing on them, and as both storage and processing have become cheaper, that data is increasingly saved and used. What was manual and individual has become bulk and mass. Surveillance has <a href="https://www.schneier.com/blog/archives/2013/11/surveillance_as_1.html">become the business model</a> of the internet, and there’s no reasonable way for us to opt out of it.</p>
<p>Spying is another matter. It has long been possible to tap someone’s phone or put a bug in their home and/or car, but those things still require someone to listen to and make sense of the conversations. Yes, spyware companies like <a href="https://citizenlab.ca/tag/nso-group">NSO Group</a> help the government <a href="https://www.theguardian.com/world/2021/dec/03/us-state-department-officials-iphones-hacked-nso-group-spyware">hack into people’s phones</a>, but <em>someone</em> still has to sort through all the conversations. And governments like China could <a href="https://www.technologyreview.com/2022/06/18/1054452/china-censors-social-media-comments/">censor social media posts</a> based on particular words or phrases, but that was coarse and <a href="https://www.npr.org/2022/12/08/1141335778/china-zero-covid-lockdown-protests-online-xi-jinping-censorship">easy to bypass</a>. Spying is limited by the need for human labor.</p>
<p>AI is about to change that. <a href="https://www.notta.ai/en/blog/best-ai-summarizers">Summarization is something</a> a modern generative AI system does well. Give it an hourlong meeting, and it will return a one-page summary of what was said. Ask it to search through millions of conversations and organize them by topic, and it’ll do that. Want to know who is talking about what? It’ll tell you.</p>
<p>The technologies aren’t perfect; some of them are pretty primitive. They miss things that are important. They get other things wrong. But so do humans. And, unlike humans, AI tools can be replicated by the millions and are improving at astonishing rates. They’ll get better next year, and even better the year after that. We are about to enter the era of mass spying.</p>
<p>Mass surveillance fundamentally changed the nature of surveillance. Because all the data is saved, mass surveillance allows people to conduct surveillance backward in time, and without even knowing whom specifically you want to target. Tell me where <em>this</em> person was last year. List all the red sedans that drove down <em>this</em> road in the past month. List all of the people who purchased all the ingredients for a pressure cooker bomb in the past year. Find me all the pairs of phones that were moving toward each other, turned themselves off, then turned themselves on again an hour later while moving away from each other (a sign of a secret meeting).</p>
<p>Similarly, mass spying will change the nature of spying. All the data will be saved. It will all be searchable, and understandable, in bulk. Tell me who has talked about a particular topic in the past month, and how discussions about that topic have evolved. Person A did something; check if someone told them to do it. Find everyone who is plotting a crime, or spreading a rumor, or planning to attend a political protest.</p>
<p>There’s so much more. To uncover an organizational structure, look for someone who gives similar instructions to a group of people, then all the people they have relayed those instructions to. To find people’s confidants, look at whom they tell secrets to. You can track friendships and alliances as they form and break, in minute detail. In short, you can know everything about what everybody is talking about.</p>
<p>This spying is not limited to conversations on our phones or computers. Just as cameras everywhere fueled mass surveillance, microphones everywhere will fuel mass spying. Siri and Alexa and “Hey Google” are already always listening; the conversations just aren’t being saved yet.</p>
<p>Knowing that they are under constant surveillance changes how people behave. They conform. They self-censor, with the <a href="https://citizenlab.ca/2017/07/jon-penney-on-the-chilling-effects-of-online-surveillance/">chilling effects that brings</a>. Surveillance facilitates social control, and spying will only make this worse. Governments around the world already use mass surveillance; they will engage in mass spying as well.</p>
<p>Corporations will spy on people. Mass surveillance ushered in the era of personalized advertisements; mass spying will supercharge that industry. Information about what people are talking about, their moods, their secrets—it’s all catnip for marketers looking for an edge. The tech monopolies that are currently keeping us all under constant surveillance won’t be able to resist collecting and using all of that data.</p>
<p>In the early days of Gmail, Google talked about using people’s Gmail content to serve them personalized ads. The company <a href="https://support.google.com/mail/answer/10434152">stopped doing it</a>, almost certainly because the keyword data it collected was so poor—and therefore not useful for marketing purposes. That will soon change. Maybe Google won’t be the first to spy on its users’ conversations, but once others start, they won’t be able to resist. Their true customers—their advertisers—will demand it.</p>
<p>We could limit this capability. We could prohibit mass spying. We could pass strong data-privacy rules. But we haven’t done anything to limit mass surveillance. Why would spying be any different?</p>
<p><em>This essay originally appeared in <a href="https://slate.com/technology/2023/12/ai-mass-spying-internet-surveillance.html">Slate</a>.</em></p>

		
			<p>
				<span>Tags: <a href="https://www.schneier.com/tag/artificial-intelligence/" rel="tag">artificial intelligence</a>, <a href="https://www.schneier.com/tag/espionage/" rel="tag">espionage</a>, <a href="https://www.schneier.com/tag/privacy/" rel="tag">privacy</a>, <a href="https://www.schneier.com/tag/surveillance/" rel="tag">surveillance</a></span>			</p>

		
		
		<p>
			<a href="https://www.schneier.com/blog/archives/2023/12/the-internet-enabled-mass-surveillance-ai-will-enable-mass-spying.html" rel="bookmark">Posted on December 5, 2023 at 7:10 AM</a>			•
			<a href="https://www.schneier.com/blog/archives/2023/12/the-internet-enabled-mass-surveillance-ai-will-enable-mass-spying.html#comments">10 Comments</a>		</p>

		
	</div>

</article><p id="powered">Sidebar photo of Bruce Schneier by Joe MacInnis.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Internet Enabled Mass Surveillance. A.I. Will Enable Mass Spying (129 pts)]]></title>
            <link>https://slate.com/technology/2023/12/ai-mass-spying-internet-surveillance.html</link>
            <guid>38530795</guid>
            <pubDate>Tue, 05 Dec 2023 14:02:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slate.com/technology/2023/12/ai-mass-spying-internet-surveillance.html">https://slate.com/technology/2023/12/ai-mass-spying-internet-surveillance.html</a>, See on <a href="https://news.ycombinator.com/item?id=38530795">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-uri="slate.com/_components/article/instances/clpkcr4da001ydckw6tcmwkvd@published" data-has-roadblock="false" data-rubric="future-tense" itemscope="" itemtype="http://schema.org/Article">
  

  

<header>

  <a href="https://slate.com/technology/future-tense"><img alt="Future Tense" height="17" width="115.25" src="https://compote.slate.com/images/7ff9545e-d46d-4daa-9328-e1bf5436be86.png"></a>

  

<h2 itemprop="alternativeHeadline">Spying has always been limited by the need for human labor. A.I. is going to change that.</h2>


    </header>
<div>
      <figure data-uri="slate.com/_components/image/instances/clpkcr4d9001rdckwea82pr0p@published" data-editable="imageInfo"><p><img loading="lazy" src="https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0" alt="An open laptop hovering in a glowing turquoise binary sequence of 0's and 1's." width="1560" height="1040" srcset="https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=320 320w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=480 480w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=600 600w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=840 840w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=960 960w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1280 1280w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1440 1440w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1600 1600w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=1920 1920w,
https://compote.slate.com/images/190f9338-037a-482b-b140-68d633dd665e.jpeg?crop=1560%2C1040%2Cx0%2Cy0&amp;width=2200 2200w">
        
      </p>
<figcaption>
<span>Photo illustration by Slate Photos by seamartini/iStock/Getty Images Plus and -slav-/iStock/Getty Images Plus.</span>
</figcaption>
</figure>

  </div>
  

  <section>
      


      

    <div itemprop="mainEntityOfPage">
          <p data-word-count="89" data-uri="slate.com/_components/slate-paragraph/instances/clpkcr4d9001sdckw409u6h3f@published">Spying and surveillance are different but related things. If I hired a private detective to spy on you, that detective could hide a bug in your home or car, tap your phone, and listen to what you said. At the end, I would get a report of all the conversations you had and the contents of those conversations. If I hired that same private detective to put you under surveillance, I would get a different report: where you went, whom you talked to, what you purchased, what you did.</p>

  

  <p data-word-count="119" data-uri="slate.com/_components/slate-paragraph/instances/clpleu2z100083b6yhdps8ths@published">Before the internet, putting someone under surveillance was expensive and time-consuming. You had to manually follow someone around, noting where they went, whom they talked to, what they purchased, what they did, and what they read. That world is forever gone. Our phones track our locations. Credit cards track our purchases. Apps track whom we talk to, and e-readers know what we read. Computers collect data about what we’re doing on them, and as both storage and processing have become cheaper, that data is increasingly saved and used. What was manual and individual has become bulk and mass. Surveillance has <a href="https://www.schneier.com/blog/archives/2013/11/surveillance_as_1.html">become the business model</a> of the internet, and there’s no reasonable way for us to opt out of it.</p>

  


  


  <p data-word-count="92" data-uri="slate.com/_components/slate-paragraph/instances/clpleu31v00093b6ydyq3es74@published">Spying is another matter. It has long been possible to tap someone’s phone or put a bug in their home and/or car, but those things still require someone to listen to and make sense of the conversations. Yes, spyware companies like <a href="https://citizenlab.ca/tag/nso-group">NSO Group</a> help the government <a href="https://www.theguardian.com/world/2021/dec/03/us-state-department-officials-iphones-hacked-nso-group-spyware">hack into people’s phones</a>, but <em>someone</em> still has to sort through all the conversations. And governments like China could <a href="https://www.technologyreview.com/2022/06/18/1054452/china-censors-social-media-comments/">censor social media posts</a> based on particular words or phrases, but that was coarse and <a href="https://www.npr.org/2022/12/08/1141335778/china-zero-covid-lockdown-protests-online-xi-jinping-censorship">easy to bypass</a>. Spying is limited by the need for human labor.</p>

  


  <p data-word-count="60" data-uri="slate.com/_components/slate-paragraph/instances/clpleu33q000a3b6yz28ko6q2@published">A.I. is about to change that. <a href="https://www.notta.ai/en/blog/best-ai-summarizers">Summarization is something</a> a modern generative A.I. system does well. Give it an hourlong meeting, and it will return a one-page summary of what was said. Ask it to search through millions of conversations and organize them by topic, and it’ll do that. Want to know who is talking about what? It’ll tell you.</p>

  


  <p data-word-count="64" data-uri="slate.com/_components/slate-paragraph/instances/clpleu35r000b3b6y6v9rv0ne@published">The technologies aren’t perfect; some of them are pretty primitive. They miss things that are important. They get other things wrong. But so do humans. And, unlike humans, A.I. tools can be replicated by the millions and are improving at astonishing rates. They’ll get better next year, and even better the year after that. We are about to enter the era of mass spying.</p>

  


  


  <p data-word-count="111" data-uri="slate.com/_components/slate-paragraph/instances/clpleu37i000c3b6yvqq0igb7@published">Mass surveillance fundamentally changed the nature of surveillance. Because all the data is saved, mass surveillance allows people to conduct surveillance backward in time, and without even knowing whom specifically you want to target. Tell me where <em>this</em> person was last year. List all the red sedans that drove down <em>this</em> road in the past month. List all of the people who purchased all the ingredients for a pressure cooker bomb in the past year. Find me all the pairs of phones that were moving toward each other, turned themselves off, then turned themselves on again an hour later while moving away from each other (a sign of a secret meeting).</p>

  


  <p data-word-count="75" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8du000d3b6yjhe475ye@published">Similarly, mass spying will change the nature of spying. All the data will be saved. It will all be searchable, and understandable, in bulk. Tell me who has talked about a particular topic in the past month, and how discussions about that topic have evolved. Person A did something; check if someone told them to do it. Find everyone who is plotting a crime, or spreading a rumor, or planning to attend a political protest.</p>

  


  <p data-word-count="68" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8gi000e3b6yhvoa0kk5@published">There’s so much more. To uncover an organizational structure, look for someone who gives similar instructions to a group of people, then all the people they have relayed those instructions to. To find people’s confidants, look at whom they tell secrets to. You can track friendships and alliances as they form and break, in minute detail. In short, you can know everything about what everybody is talking about.</p>

  


  
  <p data-word-count="42" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8ij000f3b6ytgkwbsh7@published">This spying is not limited to conversations on our phones or computers. Just as cameras everywhere fueled mass surveillance, microphones everywhere will fuel mass spying. Siri and Alexa and “Hey Google” are already always listening; the conversations just aren’t being saved yet.</p>

  <p data-word-count="48" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8kc000g3b6y7qg48bgd@published">Knowing that they are under constant surveillance changes how people behave. They conform. They self-censor, with the <a href="https://citizenlab.ca/2017/07/jon-penney-on-the-chilling-effects-of-online-surveillance/">chilling effects that brings</a>. Surveillance facilitates social control, and spying will only make this worse. Governments around the world already use mass surveillance; they will engage in mass spying as well.</p>

  

  <p data-word-count="63" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8mj000h3b6y4aztufgs@published">Corporations will spy on people. Mass surveillance ushered in the era of personalized advertisements; mass spying will supercharge that industry. Information about what people are talking about, their moods, their secrets—it’s all catnip for marketers looking for an edge. The tech monopolies that are currently keeping us all under constant surveillance won’t be able to resist collecting and using all of that data.</p>

  


  <p data-word-count="72" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8on000i3b6yxh1wzj1a@published">In the early days of Gmail, Google talked about using people’s Gmail content to serve them personalized ads. The company <a href="https://support.google.com/mail/answer/10434152">stopped doing it</a>, almost certainly because the keyword data it collected was so poor—and therefore not useful for marketing purposes. That will soon change. Maybe Google won’t be the first to spy on its users’ conversations, but once others start, they won’t be able to resist. Their true customers—their advertisers—will demand it.</p>

  <p data-word-count="31" data-uri="slate.com/_components/slate-paragraph/instances/clpleu8ql000j3b6ydlp19w6p@published">We could limit this capability. We could prohibit mass spying. We could pass strong data-privacy rules. But we haven’t done anything to limit mass surveillance. Why would spying be any <span>different?</span></p>

  <p data-uri="slate.com/_components/future-tense-kicker/instances/clpkcr4da001vdckwnn6h5ajx@published">
<a href="http://www.slate.com/articles/technology/future_tense/2012/03/future_tense_emerging_technologies_society_and_policy_.html">Future Tense</a>
    is a partnership of
    <a href="https://slate.com/">Slate</a>,
    <a href="https://www.newamerica.org/">New America</a>, and
    <a href="https://www.asu.edu/?feature=research">Arizona State University</a>
    that examines emerging technologies, public policy, and society.
</p>

  

</div>

      <ul>
<li>
            <a href="https://slate.com/tag/artificial-intelligence">
              Artificial Intelligence
            </a>
          </li><li>
            <a href="https://slate.com/tag/government-surveillance">
              Government Surveillance
            </a>
          </li><li>
            <a href="https://slate.com/tag/internet">
              Internet
            </a>
          </li>      </ul>

  </section>

      

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Fediverse use – I'm hosting everything myself – PeerTube, Mastodon and Lemmy (210 pts)]]></title>
            <link>https://tube.jeena.net/w/nivehRx8J7ZwujfS2oCoPC</link>
            <guid>38530597</guid>
            <pubDate>Tue, 05 Dec 2023 13:46:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tube.jeena.net/w/nivehRx8J7ZwujfS2oCoPC">https://tube.jeena.net/w/nivehRx8J7ZwujfS2oCoPC</a>, See on <a href="https://news.ycombinator.com/item?id=38530597">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A Brainfuck interpreter written in PostScript (103 pts)]]></title>
            <link>https://github.com/nst/bfps</link>
            <guid>38530565</guid>
            <pubDate>Tue, 05 Dec 2023 13:43:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nst/bfps">https://github.com/nst/bfps</a>, See on <a href="https://news.ycombinator.com/item?id=38530565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-view-component="true">        
        
        <div>
  



<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>



  <p>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/nst/bfps/branches">
          
          <strong>1</strong>
          <span>branch</span>
    </a>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/nst/bfps/tags">
      
        <strong>0</strong>
        <span>tags</span>
    </a>
  </p>

  

  <include-fragment src="/nst/bfps/overview_actions/main"></include-fragment>


    <p><span>
        
<get-repo>
  <details data-action="
              toggle:get-repo#onDetailsToggle
              keydown:get-repo#onDetailsKeydown">
    <summary data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;repository_id&quot;:727703234,&quot;target&quot;:&quot;CLONE_OR_DOWNLOAD_BUTTON&quot;,&quot;originating_url&quot;:&quot;https://github.com/nst/bfps&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="40f8560aaaa80355c7eff4ad27c950ef7873bb85081ac525ff8fbb9e1f7a08be" aria-description="Open clone and codespaces menu" data-view-component="true">  <span>
    <span>Code</span>
  </span>
    <span>
      
    </span>
</summary>
    <div data-target="get-repo.modal">
    <tab-container data-view-component="true">
      <div id="local-panel" role="tabpanel" tabindex="0" aria-labelledby="local-tab" data-view-component="true">          <ul>
              <li>
  <a href="https://docs.github.com/articles/which-remote-url-should-i-use" rel="noopener" target="_blank" aria-label="Which remote URL should I use?">
  
</a>



<tab-container>

  

  <div role="tabpanel">
    

    <p>
        Use Git or checkout with SVN using the web URL.
    </p>
  </div>


  
</tab-container>

</li>
<li data-platforms="windows,mac">
  <a data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;OPEN_IN_DESKTOP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:727703234,&quot;originating_url&quot;:&quot;https://github.com/nst/bfps&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="eb3faad120b51f81f187773b443ccfcb0c8741e1db00f8b9cafe0a59913e127a" data-action="click:get-repo#showDownloadMessage" href="https://desktop.github.com/">
    
    Open with GitHub Desktop
</a></li>
<li>
  <a rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;DOWNLOAD_ZIP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:727703234,&quot;originating_url&quot;:&quot;https://github.com/nst/bfps&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="4640a1dbde5583010ced31ea6eb74f22c10ea0548769db37043c1b34e235c763" data-ga-click="Repository, download zip, location:repo overview" data-open-app="link" data-turbo="false" href="https://github.com/nst/bfps/archive/refs/heads/main.zip">
    
    Download ZIP
</a></li>

          </ul>
</div>
    
</tab-container>    
</div>
  </details>
</get-repo>

    </span>

    <span>
      

    </span>
</p></div>




        


<div>
  <div>
    <h2>Latest commit</h2>
    <div data-issue-and-pr-hovercards-enabled="">
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/nst/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nst">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/51388?s=48&amp;v=4" width="24" height="24" alt="@nst">
</a>  </p>
</div>
  </div>
    <h2 id="files">Files</h2>
    


      <p><a data-hotkey="y" href="https://github.com/nst/bfps/tree/682f0e54388cfb3e3c7bf85bf81da29efd82c265">Permalink</a></p><div data-view-component="true">
  <p>
    Failed to load latest commit information.


  
</p></div>  <div role="grid" aria-labelledby="files" data-hpc="">
        <p>Type</p>
        <p>Name</p>
        <p>Latest commit message</p>
        <p>Commit time</p>
      </div>




</div>

  
    
      <div data-target="readme-toc.content" id="readme" data-tagsearch-path="README.md" data-tagsearch-lang="Markdown">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">bfps</h2>
<p dir="auto">A Brainfuck interpreter written in PostScript</p>
<p dir="auto">This program aims at being accurate, readable and minimal.</p>
<p dir="auto">That's why it comes in three flavors:</p>
<div data-snippet-clipboard-copy-content="bf_long.ps  - full version, debug tools, unit tests
bf.ps       - readable version
bf_tiny.ps  - minimal, golfed version"><pre><code>bf_long.ps  - full version, debug tools, unit tests
bf.ps       - readable version
bf_tiny.ps  - minimal, golfed version
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nst/bfps/blob/main/brainfuck_postscript.png"><img src="https://github.com/nst/bfps/raw/main/brainfuck_postscript.png" alt="Brainfuck PostScript" title="Brainfuck PostScript"></a></p>
</article>
          </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toxic comments are associated with reduced volunteer editors on Wikipedia (216 pts)]]></title>
            <link>https://academic.oup.com/pnasnexus/article/2/12/pgad385/7457939</link>
            <guid>38530466</guid>
            <pubDate>Tue, 05 Dec 2023 13:33:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/pnasnexus/article/2/12/pgad385/7457939">https://academic.oup.com/pnasnexus/article/2/12/pgad385/7457939</a>, See on <a href="https://news.ycombinator.com/item?id=38530466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widgetname="ArticleFulltext">





                    <h2 scrollto-destination="428493695" id="428493695">Abstract</h2>
<section><p>Wikipedia is one of the most successful collaborative projects in history. It is the largest encyclopedia ever created, with millions of users worldwide relying on it as the first source of information as well as for fact-checking and in-depth research. As Wikipedia relies solely on the efforts of its volunteer editors, its success might be particularly affected by toxic speech. In this paper, we analyze all 57 million comments made on user talk pages of 8.5 million editors across the six most active language editions of Wikipedia to study the potential impact of toxicity on editors’ behavior. We find that toxic comments are consistently associated with reduced activity of editors, equivalent to 0.5–2 active days per user in the short term. This translates to multiple human-years of lost productivity, considering the number of active contributors to Wikipedia. The effects of toxic comments are potentially even greater in the long term, as they are associated with a significantly increased risk of editors leaving the project altogether. Using an agent-based model, we demonstrate that toxicity attacks on Wikipedia have the potential to impede the progress of the entire project. Our results underscore the importance of mitigating toxic speech on collaborative platforms such as Wikipedia to ensure their continued success.</p></section>                    
<div id="pgad385-box1"><p>While the prevalence of toxic speech online is well studied, its true impact on the productivity of online communities remains largely unexplored. In this study, we focus on Wikipedia, which as the largest and most-read online reference, serves as a vital source of knowledge for millions of users worldwide. By analyzing all comments made over 20 years on user talk pages of 8.5 million editors across multiple language editions, we demonstrate that toxic speech is associated with a significant loss in the productivity of Wikipedia editors. These findings may have broad implications for large-scale collaborative projects and online communities, emphasizing the need to promote healthy and sustainable communication practices to protect crucial online information ecosystems and ensure their long-term success.</p></div>                    <h2 scrollto-destination="428493697" id="428493697" data-legacy-id="pgad385-s0">Introduction</h2>
<p>Wikipedia is arguably one of the most successful collaborative projects in history. It has become the largest and most-read reference work ever created, and it is currently the fifth most popular website on the Internet (<span id="jumplink-pgad385-B1"></span>1). Millions of users worldwide rely on Wikipedia as their first source of information when encountering a new topic, for fact-checking and in-depth research (<span id="jumplink-pgad385-B2"></span>2). Even if caution might be required when consulting less actively maintained pages (<span id="jumplink-pgad385-B3"></span>3), numerous studies have shown that Wikipedia is a reliable source of information in areas ranging from political science (<span id="jumplink-pgad385-B4"></span>4) to pharmacology (<span id="jumplink-pgad385-B5"></span>5) and its accuracy is comparable to traditional encyclopedias (<span id="jumplink-pgad385-B6"></span>6) and textbooks (<span id="jumplink-pgad385-B7"></span>7).</p><p>One of the most remarkable aspects of Wikipedia’s success is that its content is exclusively created and curated by volunteer editors, known as Wikipedians. The English edition alone has more than 120,000 active editors (<span id="jumplink-pgad385-B8"></span>8). However, this volunteer-driven model also makes Wikipedia susceptible to the inherent challenges associated with maintaining such a large online community (<span id="jumplink-pgad385-B9"></span>9, <span id="jumplink-pgad385-B10"></span>10). For example, it has been previously observed that Wikipedia is not free of conflict, particularly in the form of so-called edit wars (<span id="jumplink-pgad385-B11"></span>11), which impose significant costs on the project (<span id="jumplink-pgad385-B12"></span>12) and could negatively affect the quality of Wikipedia articles (<span id="jumplink-pgad385-B13"></span>13).</p><p>In this paper, we focus on the impact of toxic comments directed toward editors on their activity. This aspect is less studied, but potentially not less important, as affected by toxic comments, Wikipedians might reduce their contributions or abandon the project altogether, threatening the success of the platform (<span id="jumplink-pgad385-B14"></span>14).</p><p>Toxicity has been extensively studied on popular social media websites such as Twitter (<span id="jumplink-pgad385-B15"></span>15, <span id="jumplink-pgad385-B16"></span>16), Reddit (<span id="jumplink-pgad385-B17"></span>17, <span id="jumplink-pgad385-B18"></span>18), and similar platforms (<span id="jumplink-pgad385-B19"></span>19, <span id="jumplink-pgad385-B20"></span>20). However, much of these research focuses on automated toxicity detection and prevalence estimation rather than on evaluating its impact (<span id="jumplink-pgad385-B21"></span>21). As an online encyclopedia, Wikipedia is often perceived as immune to toxicity and has a strict “No personal attacks” policy (<span id="jumplink-pgad385-B22"></span>22). Despite that, toxic speech and harassment have been previously observed on the platform (<span id="jumplink-pgad385-B23 pgad385-B24 pgad385-B25 pgad385-B26 pgad385-B27"></span>23–27). The effects of such behaviors on editors’ contributions are, however, not well understood nor well studied. The largest study to date relies on a voluntary opt-in survey of the 3,845 Wikipedians conducted in 2015 (<span id="jumplink-pgad385-B24"></span>24). It reports that 20% of users witnessing harassment have stopped contributing for a while, 17% considered not contributing anymore and 5% stopped contributing at all.</p><p>In this paper, we analyzed all 57 million comments made on user talk pages of editors on the six most active language editions of Wikipedia (English, German, French, Spanish, Italian, Russian) to understand the potential impact of toxic speech on editors’ contributions (see Methods and materials section for our definition of toxic comments). User talk pages are a place for editors to communicate with each other either on more personal topics or to extend their discussion from an article’s talk page. The majority of toxic comments are left on user talk pages (<span id="jumplink-pgad385-B28"></span>28). The comments we study were extracted from revision histories of talk pages and, thus, include even those toxic comments that were later archived or deleted by the page owner.</p><p>Figure <span id="jumplink-pgad385-F1"></span>1 shows the activity of 50 randomly selected users who have received exactly one toxic comment. While some users are seemingly unaffected by a toxic comment, others temporarily reduce their activity or leave the project completely. The aim of our paper is to quantify this effect on the entire population of editors.</p>                    <div data-id="pgad385-f1" data-content-id="pgad385-f1" swap-content-for-modal="true"><p>Fig. 1.</p><div><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/m_pgad385f1.jpeg?Expires=1704812577&amp;Signature=3wGUQJ8DyvquCBx9e7Y8Cc9YcI0LKvEnIvRC8JYEYgXeHDTpaqgRpnXJ9aRSSWvb22wpodBQk~tPYx2QZyyu58-SHeOhfGmks9J-tJMDD47NkKNeKBirIBFe1nayVcgeZ-hdyXfVYCIKu-rXbftCEa16mAFH9SLXx26c0z8n6SLLxaBq17T5L-t9RnWNEbvdJGs7kXZyBRTh3p6bEcYuSb9LR8vAPGwH2uRKWJ54iaRvKGENtaH96S0Mp3vINAGtMeoURz4JAzEp7MPkqwb3xNsKmvFFpb65HOanpde2xFkyyyGmWtP0fFDAX6p4uIEJZNsJpEhjYmvuAp8LXgHThQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="After receiving a toxic comment many users temporarily reduce their activity or leave the project completely. The figure shows the activity of 50 randomly selected users who received exactly one toxic comment. Blue squares indicate an active day, i.e. a day when at least one edit was done, starting from the first contribution of a given user. Red triangles correspond to toxic comments. Note that while some users are resilient and their activity is seemingly unaffected by toxic comments, many users temporarily reduce their activity or stop contributing altogether." data-path-from-xml="pgad385f1.tif"></p></div><p>After receiving a toxic comment many users temporarily reduce their activity or leave the project completely. The figure shows the activity of 50 randomly selected users who received exactly one toxic comment. Blue squares indicate an active day, i.e. a day when at least one edit was done, starting from the first contribution of a given user. Red triangles correspond to toxic comments. Note that while some users are resilient and their activity is seemingly unaffected by toxic comments, many users temporarily reduce their activity or stop contributing altogether.</p></div><p>We estimate the number of lost active days associated with a toxic comment by comparing the number of active days before and after receiving a toxic comment. To account for potential baseline change, we have matched editors that received a toxic comment with similarly active editors who received a nontoxic comment. We have separately studied if toxic comments increase the probability of editors leaving the project altogether. Finally, we have used an agent-based model to model the potential impact of an increased number of toxic comments on Wikipedia.</p>                    <h2 scrollto-destination="428493706" id="428493706" data-legacy-id="pgad385-s1">Results</h2>
                    <h3 scrollto-destination="428493707" id="428493707" data-legacy-id="pgad385-s1.1">Loss of editor activity</h3>
<p>To estimate the potential effect of a toxic comment, we compute the proportion of users who were active on day X before or after receiving a toxic comment (Fig. <span id="jumplink-pgad385-F2"></span>2). We find that, on average, editors are more active near the time when they receive a toxic comment, with a peak at 24 h prior to the comment. At this time point, more than <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">40</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> of editors were active, as shown by the red line in Fig. <span id="jumplink-pgad385-F2"></span>2a. This is a rather unsurprising observation since toxic comments are often made as a reaction to an edit made by a user and, thus, users are expected to be active around the time of a toxic comment. Note that if the timestamps around which the curve is centered are shuffled (black line in Fig. <span id="jumplink-pgad385-F2"></span>2a) then this pattern disappears completely as expected.</p>                    <div data-id="pgad385-f2" data-content-id="pgad385-f2" swap-content-for-modal="true"><p>Fig. 2.</p><div><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/m_pgad385f2.jpeg?Expires=1704812577&amp;Signature=2fNieTHaIPTku2t6mpRvxIbQH7FsdxmzgpSc618hfT0gf4r9vSqljIraCoA4v8xy4wBRYtr1Rdk0rI1xC8ByOV7fDkpEP4M74b8zfTxX7kXYa~0RYqP2mi2gPDmGAr4-tIorIRb1NQALk~ijD0x304rrpjxpSxaNm3Ebscl3ejhdAvP756KrKhDZLYrprNgLfH3Zn7~KGqbrOVPnjTCAIdhqvlcHMcvnmCUNWDwAnp4fbwcH-DGhF3kGXGUE2nfaCpPLCaaBAZI1~G-bWJaDOsCi7FBAX6CHLiJ6gEQ5qWoE~pVVXbGR1XuT4DQ9SG9dNEEoiOURQex9fMl8aFWGEA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="After receiving a toxic comment, users become less active. On average, users are more active near the time when they receive a toxic comment (peak at zero for the red line in panel a). Average activity across all users who have received a toxic comment is lower in all 100 days after the event compared to the corresponding days before (dashed and solid red lines in panel b). This cannot be explained by a baseline drop in activity after a nontoxic comment (dashed and solid blue lines in panel b). Similar results hold not only for the English edition but also for the other five editions (c–g)." data-path-from-xml="pgad385f2.tif"></p></div><p>After receiving a toxic comment, users become less active. On average, users are more active near the time when they receive a toxic comment (peak at zero for the red line in panel a). Average activity across all users who have received a toxic comment is lower in all 100 days after the event compared to the corresponding days before (dashed and solid red lines in panel b). This cannot be explained by a baseline drop in activity after a nontoxic comment (dashed and solid blue lines in panel b). Similar results hold not only for the English edition but also for the other five editions (c–g).</p></div><p>We also find that average activity across all users who have received a toxic comment is lower during all 100 days after the event compared to the corresponding days before (dashed and solid red lines in Fig. <span id="jumplink-pgad385-F2"></span>2b), e.g. smaller number of users is active five days after receiving a toxic comment than five days before receiving it. To rule out the possibility that this is due to a general drop in activity over time or a drop in activity after any comment, we select a control group of users who have received a nontoxic comment, and whose average activity in the 100 days before the comment is the same as the average activity of users who received a toxic comment (see Methods and materials section for details).</p><p>We observe a similar characteristic peak around the nontoxic comment, likely due to both toxic and nontoxic comments being reactions to a contribution made by an editor. However, in contrast to a toxic comment, a nontoxic comment does not lead to a significant decrease in activity (dashed and solid blue lines in Fig. <span id="jumplink-pgad385-F2"></span>2b). Similar results hold for all six language editions that we have examined (Fig. <span id="jumplink-pgad385-F2"></span>2c–g).</p><p>We then estimate the lost activity associated with a toxic comment by computing the decrease in activity after a toxic comment, taking into account a potential baseline drop, i.e. by computing <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal" xmlns="">Δ</mi><mo xmlns="">=</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">After</mi></mrow><mrow><mrow><mi mathvariant="normal">toxic</mi></mrow></mrow></msub><mo xmlns="">−</mo><msub xmlns=""><mrow><mi mathvariant="normal">Before</mi></mrow><mrow><mrow><mi mathvariant="normal">toxic</mi></mrow></mrow></msub><mo stretchy="false" xmlns="">)</mo><mo xmlns="">−</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">After</mi></mrow><mrow><mrow><mi mathvariant="normal">nontoxic</mi></mrow></mrow></msub><mo xmlns="">−</mo><msub xmlns=""><mrow><mi mathvariant="normal">Before</mi></mrow><mrow><mrow><mi mathvariant="normal">nontoxic</mi></mrow></mrow></msub><mo stretchy="false" xmlns="">)</mo></math>⁠</span>. We find that this loss is statistically significant for all language editions studied (Table <span id="jumplink-pgad385-T1"></span>1). We further explored the robustness of this result with respect to the toxicity threshold and potential filtering of users according to their activity. As expected, for higher toxicity thresholds, i.e. for more severely toxic comments, the effect is stronger (<span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S1</a></span>). Considering only active users also leads to higher estimates; however, here we are reporting a conservative estimate, i.e. no filtering is used for results presented in Fig. <span id="jumplink-pgad385-F2"></span>2 and Table <span id="jumplink-pgad385-T1"></span>1.</p>                    <div content-id="pgad385-T1"><div id="pgad385-T1" data-id="pgad385-T1"><p><span>Table 1.</span></p><p>Lost active days in the 100 days following a toxic comment.</p> </div><div><table role="table"><thead><tr><th>Edition</th><th><em>Δ</em></th><th><em>P</em>-value</th><th><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi mathvariant="bold-italic">N</mi><mrow><mrow><mi mathvariant="bold">u</mi><mi mathvariant="bold">s</mi><mi mathvariant="bold">e</mi><mi mathvariant="bold">r</mi><mi mathvariant="bold">s</mi></mrow></mrow></msub></math></span></th></tr></thead><tbody><tr><td>English</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.207</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>66</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">36</mn><mo xmlns="">,</mo><mn xmlns="">332</mn></math></span></td></tr><tr><td>German</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.546</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1.5</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>7</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">10</mn><mo xmlns="">,</mo><mn xmlns="">346</mn></math></span></td></tr><tr><td>French</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.851</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">4.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">239</mn></math></span></td></tr><tr><td>Spanish</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.563</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">8.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">446</mn></math></span></td></tr><tr><td>Italian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.336</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.3</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">3</mn><mo xmlns="">,</mo><mn xmlns="">567</mn></math></span></td></tr><tr><td>Russian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.219</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">7.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1</mn><mo xmlns="">,</mo><mn xmlns="">134</mn></math></span></td></tr></tbody></table></div><div><table><thead><tr><th>Edition</th><th><em>Δ</em></th><th><em>P</em>-value</th><th><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi mathvariant="bold-italic">N</mi><mrow><mrow><mi mathvariant="bold">u</mi><mi mathvariant="bold">s</mi><mi mathvariant="bold">e</mi><mi mathvariant="bold">r</mi><mi mathvariant="bold">s</mi></mrow></mrow></msub></math></span></th></tr></thead><tbody><tr><td>English</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.207</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>66</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">36</mn><mo xmlns="">,</mo><mn xmlns="">332</mn></math></span></td></tr><tr><td>German</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.546</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1.5</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>7</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">10</mn><mo xmlns="">,</mo><mn xmlns="">346</mn></math></span></td></tr><tr><td>French</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.851</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">4.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">239</mn></math></span></td></tr><tr><td>Spanish</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.563</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">8.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">446</mn></math></span></td></tr><tr><td>Italian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.336</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.3</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">3</mn><mo xmlns="">,</mo><mn xmlns="">567</mn></math></span></td></tr><tr><td>Russian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.219</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">7.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1</mn><mo xmlns="">,</mo><mn xmlns="">134</mn></math></span></td></tr></tbody></table></div><div><p><span><p>The lost active days are estimated by computing the difference between the number of active days during 100 days after a toxic comment and the number of active days during 100 days before a toxic comment. This difference is then compared with the baseline drop after a nontoxic comment, i.e. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal" xmlns="">Δ</mi><mo xmlns="">=</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">After</mi></mrow><mrow><mrow><mi mathvariant="normal">toxic</mi></mrow></mrow></msub><mo xmlns="">−</mo><msub xmlns=""><mrow><mi mathvariant="normal">Before</mi></mrow><mrow><mrow><mi mathvariant="normal">toxic</mi></mrow></mrow></msub><mo stretchy="false" xmlns="">)</mo><mo xmlns="">−</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">After</mi></mrow><mrow><mrow><mi mathvariant="normal">nontoxic</mi></mrow></mrow></msub><mo xmlns="">−</mo><msub xmlns=""><mrow><mi mathvariant="normal">Before</mi></mrow><mrow><mrow><mi mathvariant="normal">nontoxic</mi></mrow></mrow></msub><mo stretchy="false" xmlns="">)</mo></math>⁠</span>. The <em>P</em>-value is computed using Student’s <em>t</em>-test.</p></span></p></div></div><div><div id="pgad385-T1" data-id="pgad385-T1"><p><span>Table 1.</span></p><p>Lost active days in the 100 days following a toxic comment.</p> </div><div><table role="table"><thead><tr><th>Edition</th><th><em>Δ</em></th><th><em>P</em>-value</th><th><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi mathvariant="bold-italic">N</mi><mrow><mrow><mi mathvariant="bold">u</mi><mi mathvariant="bold">s</mi><mi mathvariant="bold">e</mi><mi mathvariant="bold">r</mi><mi mathvariant="bold">s</mi></mrow></mrow></msub></math></span></th></tr></thead><tbody><tr><td>English</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.207</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>66</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">36</mn><mo xmlns="">,</mo><mn xmlns="">332</mn></math></span></td></tr><tr><td>German</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.546</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1.5</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>7</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">10</mn><mo xmlns="">,</mo><mn xmlns="">346</mn></math></span></td></tr><tr><td>French</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.851</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">4.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">239</mn></math></span></td></tr><tr><td>Spanish</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.563</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">8.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">446</mn></math></span></td></tr><tr><td>Italian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.336</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.3</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">3</mn><mo xmlns="">,</mo><mn xmlns="">567</mn></math></span></td></tr><tr><td>Russian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.219</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">7.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1</mn><mo xmlns="">,</mo><mn xmlns="">134</mn></math></span></td></tr></tbody></table></div><div><table><thead><tr><th>Edition</th><th><em>Δ</em></th><th><em>P</em>-value</th><th><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi mathvariant="bold-italic">N</mi><mrow><mrow><mi mathvariant="bold">u</mi><mi mathvariant="bold">s</mi><mi mathvariant="bold">e</mi><mi mathvariant="bold">r</mi><mi mathvariant="bold">s</mi></mrow></mrow></msub></math></span></th></tr></thead><tbody><tr><td>English</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.207</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>66</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">36</mn><mo xmlns="">,</mo><mn xmlns="">332</mn></math></span></td></tr><tr><td>German</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.546</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1.5</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>7</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">10</mn><mo xmlns="">,</mo><mn xmlns="">346</mn></math></span></td></tr><tr><td>French</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.851</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">4.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">239</mn></math></span></td></tr><tr><td>Spanish</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.563</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">8.6</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2</mn><mo xmlns="">,</mo><mn xmlns="">446</mn></math></span></td></tr><tr><td>Italian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.336</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">2.3</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">3</mn><mo xmlns="">,</mo><mn xmlns="">567</mn></math></span></td></tr><tr><td>Russian</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">1.219</mn></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">7.8</mn><mo xmlns="">×</mo><msup xmlns=""><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1</mn><mo xmlns="">,</mo><mn xmlns="">134</mn></math></span></td></tr></tbody></table></div><div><p><span><p>The lost active days are estimated by computing the difference between the number of active days during 100 days after a toxic comment and the number of active days during 100 days before a toxic comment. This difference is then compared with the baseline drop after a nontoxic comment, i.e. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal" xmlns="">Δ</mi><mo xmlns="">=</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">After</mi></mrow><mrow><mrow><mi mathvariant="normal">toxic</mi></mrow></mrow></msub><mo xmlns="">−</mo><msub xmlns=""><mrow><mi mathvariant="normal">Before</mi></mrow><mrow><mrow><mi mathvariant="normal">toxic</mi></mrow></mrow></msub><mo stretchy="false" xmlns="">)</mo><mo xmlns="">−</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">After</mi></mrow><mrow><mrow><mi mathvariant="normal">nontoxic</mi></mrow></mrow></msub><mo xmlns="">−</mo><msub xmlns=""><mrow><mi mathvariant="normal">Before</mi></mrow><mrow><mrow><mi mathvariant="normal">nontoxic</mi></mrow></mrow></msub><mo stretchy="false" xmlns="">)</mo></math>⁠</span>. The <em>P</em>-value is computed using Student’s <em>t</em>-test.</p></span></p></div></div><p>While these results demonstrate that our findings are not limited to one language, they should not be used to compare effects between language editions, as there is no guarantee that the same toxicity threshold for the toxicity detection algorithm will have the same meaning in different languages.</p><p>Note that given that thousands of users have received at least one toxic comment (<span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Table S1</a></span>), even a moderate loss per user could result in many human-years of lost productivity for Wikipedia in the short run. By multiplying the estimated loss per user from Table <span id="jumplink-pgad385-T1"></span>1 by the number of users who have received at least one toxic comment, we could estimate the total loss of activity that is ranging from 5 human-years for Russian Wikipedia to 265 human-years for the English edition. The reason for the lasting effect of toxicity is that some new users might be discouraged by a toxic comment and choose to leave the project altogether after just a few contributions. This means that a single toxic comment could deprive Wikipedia of a potentially long-term contributor.</p><p>To further investigate this effect, we compare the probability of leaving Wikipedia after receiving a toxic comment with the probability of leaving Wikipedia after receiving a nontoxic comment.</p>                    <h3 scrollto-destination="428493717" id="428493717" data-legacy-id="pgad385-s1.2">Leaving Wikipedia</h3>
<p>We observed that the probability of leaving Wikipedia after <em>N</em> contributions declines with <em>N</em>. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>P</mi><mi>N</mi></msub><mo stretchy="false" xmlns="">(</mo><mstyle displaystyle="false" scriptlevel="0" xmlns=""><mtext>leaving</mtext></mstyle><mo stretchy="false" xmlns="">)</mo></math></span> is approximately proportionate to <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>N</mi><mrow><mo>−</mo><mi>α</mi></mrow></msup></math>⁠</span>, where <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">α</mi></math></span> ranges from <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.89</mn></math></span> to <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1.02</mn></math>⁠</span>, indicating a long-tailed distribution. While the probability of leaving the project after the first and only contribution is high (<span>⁠<span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>P</mi><mn>1</mn></msub><mo xmlns="">=</mo><mn xmlns="">47</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> for English Wikipedia), the risk of leaving Wikipedia drops to <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.7</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> for users who have made 100 contributions. To study the potential effects of toxic comments, we separately consider contributions that are followed by a toxic comment and contributions that are not followed by a toxic comment (see Methods and materials section for details). We find that the risk of an editor leaving after a toxic comment is consistently higher for all editions and regardless of the contribution number, see Fig. <span id="jumplink-pgad385-F3"></span>3. We provide an analysis of the significance of these findings in <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S4</a></span>.</p>                    <div data-id="pgad385-f3" data-content-id="pgad385-f3" swap-content-for-modal="true"><p>Fig. 3.</p><div><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/m_pgad385f3.jpeg?Expires=1704812577&amp;Signature=m6wB4K0s~eQV1ukDy952f3qW~IYaa8m9G6CZKx2iiVXh3b6OnUrMvbcu8bBy3WjCntRWS6eR5qvmniIxyMIq6O1XC-v9hGzMCMqrgKCxp0AVlHMnV1GPeCM3B~6TplzYBnDwCqEsdpXoRdQ~YyZtycwT34UrcI3MfN0INUQU-Pz6jRP44y0t95Aor7490vnYB7rXKKpDhqPEHaRCI2pDrjj~Z~xVQwB3te9WykkGGyfrHi4~vOEhxz1MjACn8VvbMnu0sSokBe~vr4Yly2Z6sbTieM0Z73cG77wdOdNDStt3ZAKxalY1Hp3KsBbVIMhOkzfIt3HOS9E9lK7k18WtLA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="The probability of leaving Wikipedia after receiving a toxic comment is substantially higher than might be expected otherwise. For all six editions the probability of leaving declines with the number of contributions. At the same time, this probability is substantially higher after receiving a toxic comment than might be expected otherwise. Dots are probability estimates and solid lines are the best linear fit on a log-log scale." data-path-from-xml="pgad385f3.tif"></p></div><p>The probability of leaving Wikipedia after receiving a toxic comment is substantially higher than might be expected otherwise. For all six editions the probability of leaving declines with the number of contributions. At the same time, this probability is substantially higher after receiving a toxic comment than might be expected otherwise. Dots are probability estimates and solid lines are the best linear fit on a log-log scale.</p></div>                    <h3 scrollto-destination="428493720" id="428493720" data-legacy-id="pgad385-s1.3">Agent-based modeling</h3>
<p>As has been demonstrated above, toxic comments increase the likelihood of editors abandoning Wikipedia. If enough editors leave, this could potentially impede the progress of the project as a whole. In order to estimate the potential impact of toxic comments, we model users’ behaviors by varying the toxicity of the environment, ranging from a nontoxic environment, where the probability of a user leaving follows the empirically observed nontoxic probability distribution, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">non</mi></mrow></mrow></msubsup></math></span> (blue dots in Fig. <span id="jumplink-pgad385-F3"></span>3), to a highly toxic environment, where the probability of leaving corresponds to an empirically observed toxic probability distribution, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup></math></span> (red dots in Fig. <span id="jumplink-pgad385-F3"></span>3). We also consider a potential attack targeted at new users. In this scenario, each user receives a toxic comment after their first and second contributions, e.g. their probability of leaving after the first and second contribution is defined by <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup></math>⁠</span>, and after that follows the empirically observed <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>P</mi><mi>N</mi></msub></math>⁠</span>.</p><p>For our modeling, we focus on a cohort of users who made their first contribution between the 4,000th and 6,000th day from the first recorded contribution to English Wikipedia in our dataset. We opted for this timeframe as it reflects Wikipedia’s current phase characterized by a relatively consistent number of active editors. This period follows the site’s initial exponential growth and a subsequent decline but comes before the anomalous increase in activity due to the COVID-19 pandemic (see Discussion section for details on these stages).</p><p>For our modeling, we employed an agent-based approach. Each day, agents (representing users) join Wikipedia and make their first contribution. The number of agents joining each day is equal to the actual count of first-time contributors to English Wikipedia on that particular day. After their first contribution, agents keep contributing, following a Poisson process, i.e. in such a way that the distance between two consecutive contributions, <em>D</em>, follows an exponential distribution: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">D</mi><mo xmlns="">∼</mo><mstyle displaystyle="false" scriptlevel="0" xmlns=""><mtext>Exp</mtext></mstyle><mo stretchy="false" xmlns="">(</mo><mi xmlns="">λ</mi><mo stretchy="false" xmlns="">)</mo></math>⁠</span>, where <em>λ</em> is estimated from empirical data. After each contribution, the agent’s probability of leaving the project is determined by the toxicity level, <em>T</em>, and the empirically observed distributions <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">non</mi></mrow></mrow></msubsup></math></span> and <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup></math>⁠</span>. In particular, after <em>N</em>’s contribution the user leaves the project with probability <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">T</mi><mo xmlns="">*</mo><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup><mo xmlns="">+</mo><mo stretchy="false" xmlns="">(</mo><mn xmlns="">1</mn><mo xmlns="">−</mo><mi xmlns="">T</mi><mo stretchy="false" xmlns="">)</mo><mo xmlns="">*</mo><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">non</mi></mrow></mrow></msubsup></math>⁠</span>. If the toxicity level is 0, then the probability of leaving follows the nontoxic distribution <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup></math>⁠</span>, and if the toxicity level is 1, then the probability of leaving follows the toxic distribution <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>P</mi><mi>N</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup></math>⁠</span>.</p><p>After the initial 2,000 days, no new agents join the project; however, we continue to model the behavior of the remaining agents for the subsequent 2,000 days, for which we have available empirical data for comparison.</p><p>Our model generally reproduces the dynamics of user activity (Fig. <span id="jumplink-pgad385-F4"></span>4), though, as expected, it cannot account for a later COVID-19-induced spike in activity. We find that an extreme level of toxicity could effectively reduce the cohort to almost no users in the long run, compared to the sustained numbers in a nontoxic setting or as observed in the data. Additionally, targeted attacks on newcomers have the potential to significantly decrease the number of active users, posing a risk to the project. The detailed results of our modeling, showing the effects of different toxicity levels on user count, are presented in <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S6</a></span>.</p>                    <div data-id="pgad385-f4" data-content-id="pgad385-f4" swap-content-for-modal="true"><p>Fig. 4.</p><div><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/m_pgad385f4.jpeg?Expires=1704812577&amp;Signature=GMHMFilPzKTLegsqNtT1at27jZighsJpbXPLuH8J7ajRNfhQhbNDEEQUj5pUayAgh8brg0UIBaQNfThQRtOsLT-~8SJFEchSEU-oUpHMqs6FeZk3kgGPRH4gmL1AqHlke4VSTQnAsL~W3ebgWpOS1ro3WcaN~mQxbb8FYMp4WMiuHZJwRbWpoZTJ46hCKrFDO1S0dLax209QuIJQzY78Knek4GmRB7zmzGDoxW1SAQiJe2KQh1TkqD-2o28iYNeAmi4tPuX-UMqgJZaf4AaBIU-umnfWdfzhW6zYeOAnr6DTlOI11EblEYy5y1jR8spqUhm-OZHzTWe0OkVKn6q2rQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="High levels of toxicity and targeted attacks could significantly reduce the number of active editors. Modeling results for a cohort of editors making their first contribution during the relatively stable phase of Wikipedia (shaded region in the inset). The model reproduces the general dynamics of user activity (blue line) but, as expected, cannot capture the COVID-19-related spike in activity. An extreme level of toxicity (red line) could reduce the cohort to virtually no active users, contrasting with a nontoxic environment (green line) or actual activity (blue line). Targeted attacks on newcomers (orange line) have the potential to significantly reduce the number of active contributors." data-path-from-xml="pgad385f4.tif"></p></div><p>High levels of toxicity and targeted attacks could significantly reduce the number of active editors. Modeling results for a cohort of editors making their first contribution during the relatively stable phase of Wikipedia (shaded region in the inset). The model reproduces the general dynamics of user activity (blue line) but, as expected, cannot capture the COVID-19-related spike in activity. An extreme level of toxicity (red line) could reduce the cohort to virtually no active users, contrasting with a nontoxic environment (green line) or actual activity (blue line). Targeted attacks on newcomers (orange line) have the potential to significantly reduce the number of active contributors.</p></div>                    <h2 scrollto-destination="428493727" id="428493727" data-legacy-id="pgad385-s2">Discussion</h2>
<p>We conducted a large-scale analysis, covering all comments made on user talk pages of the six most active language editions of Wikipedia over a period of 20 years, and found that toxic comments are associated with a decreased activity of editors who have received these comments and an increased risk of them leaving the project altogether. Additionally, via agent-based modeling, we showed that toxicity attacks on Wikipedia have the potential to impede the progress of the entire project.</p><p>The main limitation of our study is its relatively narrow scope, as it focuses solely on the association between toxic comments left on user talk pages and the subsequent decrease in users’ activity. However, this approach allowed us to formulate our findings with precision and ensure their robustness. We believe that our study complements and extends existing studies on Wikipedia and online communities more broadly, and may serve as a foundation for further exploration of the effects of toxicity, as we discuss in this section.</p>                    <h4 scrollto-destination="428493731" id="428493731" data-legacy-id="pgad385-s2.1.1">Conflict on Wikipedia</h4>
<p>Conflict on Wikipedia has already been a subject of numerous studies, with particular attention given to so-called “edit wars” (<span id="jumplink-pgad385-B11"></span>11, <span id="jumplink-pgad385-B29"></span>29, <span id="jumplink-pgad385-B30"></span>30). These arise when groups of editors, disagreeing about page content, repeatedly override each other’s contributions. It has been estimated that edit wars can impose substantial conflict and coordination costs on Wikipedia (<span id="jumplink-pgad385-B12"></span>12). Furthermore, it has been demonstrated that these costs increase over time and a smaller proportion of the total work by Wikipedians directly contributes to new article content. Conflict could also undermine content quality. For instance, the level of conflict on discussion pages, as assessed by raters, has been shown to negatively correlate with the quality of the corresponding Wikipedia articles (<span id="jumplink-pgad385-B13"></span>13).</p><p>In contrast to previous studies, our focus is on comments left on user talk pages rather than article talk pages. While this narrows the scope of our study, it also ensures that the comments we examine are directly addressed to a specific editor. Our approach also mitigates potential bias that could be introduced by the topic of an article. For instance, comments on talk pages linked to articles about violence might be misclassified as toxic by an algorithm due to the presence of highly negative keywords.</p><p>It is possible that toxic comments we observe on user talk pages are not independent from a broader conflict occurring elsewhere on Wikipedia. Therefore, it is conceivable that the effect we observe is not purely explained by toxic comments, but also by a broader conflict which leads both to a toxic comment on a user talk page and decreased activity of this user. Future research is needed to address this limitation and explore the context in which toxic comments occur.</p><p>It is worth noting, however, that it has already been established that toxicity on its own could lead users to stop contributing either temporarily or permanently, as this is what editors themselves report in surveys (<span id="jumplink-pgad385-B24"></span>24). Our study complements such studies by providing an estimate of the potential effects while also being performed on a scale that is not achievable by survey methods.</p>                    <h4 scrollto-destination="428493736" id="428493736" data-legacy-id="pgad385-s2.1.2">Stages of Wikipedia life cycle</h4>
<p>Wikipedia has not grown linearly but has instead passed through several stages. It began with exponential growth (<span id="jumplink-pgad385-B31"></span>31), which subsequently slowed (<span id="jumplink-pgad385-B32"></span>32). Following that, the number of active users declined before Wikipedia entered its current stage, characterized by a relatively stable number of active users (<span id="jumplink-pgad385-B33"></span>33), with a slow decline observed in some language editions. A notable exception was a temporary spike in activity due to the COVID-19 pandemic (<span id="jumplink-pgad385-B34"></span>34). See <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S5</a></span> for an illustration of these patterns in the editions studied in this paper.</p><p>It has been found that the main reason for halted growth is a sharp decline in the retention of newcomers (<span id="jumplink-pgad385-B35"></span>35). Specifically, with the project’s development, the rejection of newcomer contributions has increased, demotivating them and driving them away. Our results complement these findings by highlighting that newcomers are also particularly vulnerable to toxic comments. If users receive a toxic comment after their first or second contributions, their chances of continuing to contribute are 1.8 times lower compared to users who did not receive toxic comments.</p>                    <h4 scrollto-destination="428493739" id="428493739" data-legacy-id="pgad385-s2.1.3">Diversity of editors</h4>
<p>Wikipedia is often considered a neutral and unbiased source of knowledge. In fact, this is ingrained in its “Neutral point of view” policy, which is officially one of the five fundamental principles of Wikipedia (<span id="jumplink-pgad385-B36"></span>36). However, the claim of neutrality should not be accepted uncritically (<span id="jumplink-pgad385-B37"></span>37). For instance, while Wikipedia mandates that its content is supported by reliable sources, the selection of these sources can significantly deviate from the norms of the expert knowledge community, introducing biases to Wikipedia content (<span id="jumplink-pgad385-B38"></span>38). Even if the content of articles is neutral, their coverage may be biased. It is well documented, for example, that biographies of women are underrepresented on Wikipedia (<span id="jumplink-pgad385-B39"></span>39). Wikipedia’s own rules might contribute to such biases. For instance, providing reliable sources as required by Wikipedia for biographies of women might be challenging because fewer sources exist on women due to historic inequalities (<span id="jumplink-pgad385-B40"></span>40). Another case in point is the Oral Citations project, which aimed to use oral citations for content on countries that are underrepresented in other sources (<span id="jumplink-pgad385-B41"></span>41). However, this initiative was met with opposition by the English Wikipedia community.</p><p>These content biases are closely connected to the lack of diversity among editors (<span id="jumplink-pgad385-B38"></span>38, <span id="jumplink-pgad385-B42"></span>42). While estimates vary, the vast majority of Wikipedians are men (<span id="jumplink-pgad385-B43"></span>43). Notably, Wikipedia did not achieve its own goal of having at least 25% women editors by 2015 (<span id="jumplink-pgad385-B44"></span>44). This shortfall is a significant concern for the project, as diversity can improve the quality of content and reduce its biases (<span id="jumplink-pgad385-B13"></span>13, <span id="jumplink-pgad385-B45"></span>45). While multiple barriers confront women editors on Wikipedia (<span id="jumplink-pgad385-B40"></span>40, <span id="jumplink-pgad385-B46"></span>46, <span id="jumplink-pgad385-B47"></span>47), toxicity is likely to be one of key factors contributing to the observed gender imbalance. Specifically, research has shown that while men and women are equally likely to face online harassment and abuse, women experience more severe violations (<span id="jumplink-pgad385-B48"></span>48). They are also more likely to be affected by such incidents and to self-censor in an attempt to prevent potential harassment (<span id="jumplink-pgad385-B48"></span>48). This has been confirmed in the Wikipedia context as well, where it has been demonstrated that the psychological experiences of women and men editors differ, leading to higher attrition rates among women (<span id="jumplink-pgad385-B49"></span>49). Similar results were found in another survey (<span id="jumplink-pgad385-B24"></span>24), showing that women experiencing toxicity are more likely to stop contributing in the future.</p><p>Overall, there are reasons to believe that toxicity might significantly undermine the diversity of Wikipedia editors, which can, in turn, compromise the quality of Wikipedia articles and introduce biases in its coverage. This underscores the importance of our findings. While most of the existing studies focus on the gender gap, we want to emphasize that the Wikipedia diversity problem goes beyond that, including racial, nonbinary, and other biases as well (<span id="jumplink-pgad385-B50 pgad385-B51 pgad385-B52"></span>50–52). For instance, we observed that many of the toxic comments in our data set include ethnic slurs. Future studies are needed to better understand the experiences of minority groups on Wikipedia and the effects that toxicity has on them.</p>                    <h4 scrollto-destination="428493743" id="428493743" data-legacy-id="pgad385-s2.1.4">Interventions</h4>
<p>The Wikipedia community is well aware of the aforementioned problems, and there have been multiple efforts to address them through various interventions. Research into reward systems showed that while they might work effectively for already highly productive editors, they fail to motivate less active editors (<span id="jumplink-pgad385-B53"></span>53). Another study found no significant effect of positive rewards in online communities (<span id="jumplink-pgad385-B54"></span>54).</p><p>To address the gender gap in Wikipedia content, numerous events dedicated to creating entries about women were organized (<span id="jumplink-pgad385-B46"></span>46). An analysis of such interventions, which focused on two popular feminist interventions, confirmed that they succeeded in introducing content about women that would otherwise be missing (<span id="jumplink-pgad385-B55"></span>55). However, there is still a need to address the gender gap on a more systematic and sustainable level. For instance, one study showed that most of the women activists who attended editing workshops later chose not to continue contributing to Wikipedia, citing safety concerns as their primary reason (<span id="jumplink-pgad385-B46"></span>46). This issue was echoed in another study which identified safety as a core concern for women editors (<span id="jumplink-pgad385-B56"></span>56).</p><p>A suggested solution to this problem has been the red-flagging of harassment and harassers (<span id="jumplink-pgad385-B46"></span>46). However, the opinion that toxic comments are negligible and should be seen as merely over-enthusiastic participation is still present among editors (<span id="jumplink-pgad385-B25"></span>25). Furthermore, various anti-harassment measures have been declined multiple times by the community, as they were seen to slow the process of content creation (<span id="jumplink-pgad385-B57"></span>57, <span id="jumplink-pgad385-B58"></span>58). Based on our findings, we believe there is a need to reevaluate these policies, and more research attention is required to understand the impact of potential interventions.</p>                    <h4 scrollto-destination="428493747" id="428493747" data-legacy-id="pgad385-s2.1.5">The wider role of peer-production systems</h4>
<p>Wikipedia plays a crucial role in the global information infrastructure, aiming to provide millions of people with access to free, unbiased knowledge. Due to its reputation as a neutral and comprehensive information source, it has become a trusted first choice source of knowledge for many and its articles frequently appear in top search engine results (<span id="jumplink-pgad385-B59"></span>59, <span id="jumplink-pgad385-B60"></span>60). In fact, studies have shown that Google search results rely heavily on Wikipedia, and the quality of these results significantly diminishes without Wikipedia (<span id="jumplink-pgad385-B61"></span>61). Beyond search engines, Wikipedia was shown to be valuable to other online communities such as Stack Exchange and Reddit (<span id="jumplink-pgad385-B62"></span>62).</p><p>While Wikipedia is arguably the most successful peer-production system, it is certainly not the only one. Others include hundreds of wikis hosted by Fandom, the numerous question-and-answer communities of Stack Exchange, and various other platforms ranging from online maps to online learning (<span id="jumplink-pgad385-B33"></span>33). Interestingly, for these projects, the same patterns that are typical of Wikipedia have been observed (<span id="jumplink-pgad385-B63"></span>63), i.e. the initial growth in number of contributors is followed by a decline characterized by a decreased retention of newcomers. This suggests that our findings might have broader implications for large-scale collaborative projects and online communities. It emphasizes the need to promote healthy and sustainable communication practices to protect crucial online information ecosystems and ensure their long-term success.</p>                    <h2 scrollto-destination="428493750" id="428493750" data-legacy-id="pgad385-s3">Methods and materials</h2>
                    <h3 scrollto-destination="428493751" id="428493751" data-legacy-id="pgad385-s3.1">Data and preprocessing</h3>
                    <h4 scrollto-destination="428493752" id="428493752" data-legacy-id="pgad385-s3.1.1">Comments on user talk pages</h4>
<p>The Wikimedia Foundation provides publicly accessible dumps of all the different wikis’ content.<sup><span id="jumplink-FN1"></span>a</sup> These dumps are updated on a regular basis, with complete revision history dumps generated once per month. For this paper, we used the English dump from 2021 November 1, the German dump from 2022 August 1, the French, Italian, and Spanish dumps from 2022 August 1, and the Russian dump from 2022 July 1. The data was obtained from a mirror hosted by the Umeå University, Sweden.<sup><span id="jumplink-FN2"></span>b</sup></p><p>From the dumps, the user talk pages were extracted. A user’s talk page is a place where other editors can communicate with the user either on more personal topics or to extend their discussion from an article talk page. When the comments left on the talk page are resolved or become too old, users can choose to archive them. This helps them keep better track of new incoming topics. Once archived, the old comments are not displayed on the talk page anymore but are rather linked in a subpage. Nevertheless, the entire history of the user talk page, as of any other page on Wikipedia, can be fully seen under the tab of revision history. The revision history records one entry for every edit made on the page saving each time the complete content of the page. Thus retrieving a single comment requires performing the difference between two consecutive revisions. The Wikimedia API does offer a method to compute the difference between two revisions, however, applying it on a scale that was necessary for this research was unfeasible. For that reason, we developed our own parser to extract comments as a difference between two versions of the page (<span id="jumplink-pgad385-B64"></span>64).</p><p>We excluded from our analysis talk pages that belong to unregistered users, e.g. users who are represented only by an IP address rather than a user name, because IP addresses are dynamic and it can not be assumed that one address represents a single user throughout Wikipedia history. Additionally, we have excluded comments made by officially registered bots. Comments that were made by users on their own pages are also not considered.</p><p>When extracting comments, we cleared wiki-specific formatting and HTML markup, i.e. removed links, attachments, or other formatting-specific sequences irrelevant to the actual content.</p>                    <h4 scrollto-destination="428493757" id="428493757" data-legacy-id="pgad385-s3.1.2">Contributions and active days</h4>
<p>In order to extract information on users’ contributions, i.e. edits of Wikipedia pages made by them, we used the MediaWiki API to retrieve timestamps for each edit made by a given user. The resulting data set is publicly available in the project repository (<span id="jumplink-pgad385-B64"></span>64). The timestamps of contributions were then converted into active days. Specifically, each user <em>i</em> was represented as a binary vector <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>u</mi><mi>i</mi></msub><mo xmlns="">=</mo><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mi>a</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo xmlns="">,</mo><msub xmlns=""><mi>a</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo xmlns="">,</mo><mo xmlns="">…</mo><mo xmlns="">,</mo><msub xmlns=""><mi>a</mi><mrow><mi>i</mi><mi>N</mi></mrow></msub><mo stretchy="false" xmlns="">)</mo></math>⁠</span>, where <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>a</mi><mrow><mi>i</mi><mi>d</mi></mrow></msub><mo xmlns="">=</mo><mn xmlns="">1</mn></math></span> if user <em>i</em> made at least one contribution, i.e. edited a Wikipedia page, within the 24-h period corresponding to day <em>d</em> and <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>a</mi><mrow><mi>i</mi><mi>d</mi></mrow></msub><mo xmlns="">=</mo><mn xmlns="">0</mn></math></span> otherwise. <em>N</em> is the number of days between the first recorded contribution in our data set and the last. The conversion from contribution count to active days was performed because it is hard to interpret and compare the total number of contributions between users as one large contribution could be equivalent to multiple smaller ones. Additionally, the size of a contribution does not necessarily reflect the effort put into it. While being active on a given day could still mean different levels of activity for different users, it represents a certain level of engagement with the project and is substantially different from not contributing at all on a given day.</p>                    <h3 scrollto-destination="428493759" id="428493759" data-legacy-id="pgad385-s3.2">Toxicity</h3>
<p>The automatic detection of offensive language in online communities has been an active area of research since at least 2010 (<span id="jumplink-pgad385-B65"></span>65). Over the past decade, researchers have focused on detecting closely-related and intersecting types of offensive language such as toxicity, abusive language, and hate speech (<span id="jumplink-pgad385-B66"></span>66), see (<span id="jumplink-pgad385-B67"></span>67) for an overview of recent advancements in the field. In this paper, we use a model from the Perspective API (<span id="jumplink-pgad385-B68"></span>68) to identify toxic comments. This is a state-of-the-art toxicity detection algorithm that obtained competitive results at OffensEval-2019 competition (<span id="jumplink-pgad385-B69"></span>69) without any additional training on the contest data and is often used as a baseline system for toxicity detection (<span id="jumplink-pgad385-B66"></span>66). Perspective API is used across multiple platforms, including The New York Times, Der Spiegel, Le Monde, and El País. It uses BERT (Bidirectional Encoder Representations from Transformers) architecture (<span id="jumplink-pgad385-B70"></span>70) and is trained on comments from a variety of online sources, including Wikipedia. Each comment is labeled by 3–10 crowdsourced raters. Perspective models provide scores for several different attributes, see <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Table S2</a></span> for the list of attributes and their definitions, see <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Table S2</a></span> for examples of toxic comments, and see <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Table S3</a></span> for the AUC (Area Under the Curve) scores for those languages and attributes that were used in this paper.</p><p>We define a toxic comment as a comment that has a score of at least <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.8</mn></math></span> on any of the six dimensions provided by Perspective API. The <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.8</mn></math></span> score means that on average 8 out of 10 raters would mark it as toxic. As this threshold can be considered arbitrary, we perform additional robustness checks using different toxicity thresholds. In particular, we compute activity loss not only for the threshold of <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.8</mn></math></span> (Table <span id="jumplink-pgad385-T1"></span>1) but for thresholds from <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.2</mn></math></span> to <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.9</mn></math>⁠</span>. Additionally, we applied different activity filters, e.g. we separately compute an estimate only for those users who were active at least <em>X</em> days in the past 100 days where <em>X</em> varies from 0 to 50. This is done in order to ensure that the results are not exclusively driven by those users who had made few edits and then stopped contributing to the project. We perform this analysis for English Wikipedia as it is the largest edition. As shown in <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S1</a></span>, the estimate is typically in the range from <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.5</mn></math></span> to <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">2</mn></math></span> and significantly lower than zero for all activity thresholds and all toxicity thresholds higher than <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.3</mn></math>⁠</span>. Similarly, we have checked how the toxicity threshold affects the probability of leaving the project. As might be expected, results remain qualitatively the same for different toxicity thresholds but higher thresholds lead to more extreme results, e.g. the probability of leaving after a toxic comment with <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.9</mn></math></span> score is even higher than after a toxic comment with toxicity score of <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">0.8</mn></math></span> (<span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S3</a></span>).</p><p>We also evaluated the robustness of our results with respect to misclassification errors. To achieve a realistic distribution of user activity, we repeatedly sampled <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">100,000</mn></math></span> editors and their activity histories from the English Wikipedia data set. These sampled users were then divided into two groups: treatment and control. We investigated two distinct scenarios: one involving an equal split between the treatment and control groups and a second, more realistic, scenario where the treatment group constituted 1% of the control group.</p><p>In the treatment group, we randomly removed one active day from each user, thereby generating a true effect of one lost active day per user. We then introduced misclassification errors by generating false positives (moving users from control to treatment group) and false negatives (moving users from treatment to control group). Finally, we compared the estimated effect, as a function of the error rate, with the true effect.</p><p>We find that, generally, misclassification leads to the underestimation of the true effect, becoming more pronounced with higher error rates (<span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary Fig. S2</a></span>). The only exception is in the case of false negatives, i.e. undetected toxic comments, in the realistic scenario. Here, misclassification does not significantly bias the estimate, though it does increase its variance.</p><p>Perspective API accepts texts up to <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">20,480</mn></math></span> bytes. As the majority of comments are well below this limit, we have excluded those that are larger.</p>                    <h3 scrollto-destination="428493766" id="428493766" data-legacy-id="pgad385-s3.3">Activity loss</h3>
<p>Users who have received at least one toxic comment constitute our treatment group. For each user in this group, we select a random toxic comment they have received. We then center user activity around the timestamp, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup xmlns=""><mi>t</mi><mi>i</mi><mrow><mrow><mi mathvariant="normal">tox</mi></mrow></mrow></msubsup></math>⁠</span>, of that toxic comment and convert the result to active days by calculating</p><div id="UM0001" content-id="UM0001"><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle displaystyle="false" scriptlevel="0" xmlns=""><mtext>sign</mtext></mstyle><mo stretchy="false" xmlns="">(</mo><mo fence="false" stretchy="false" xmlns="">|</mo><mo fence="false" stretchy="false" xmlns="">{</mo><mi xmlns="">t</mi><mo xmlns="">∈</mo><msub xmlns=""><mi>T</mi><mi>i</mi></msub><mo xmlns="">:</mo><mi xmlns="">t</mi><mo xmlns="">∈</mo><mo stretchy="false" xmlns="">[</mo><msubsup xmlns=""><mi>t</mi><mi>i</mi><mtext>tox</mtext></msubsup><mo xmlns="">+</mo><mi xmlns="">d</mi><mo xmlns="">*</mo><mn xmlns="">24</mn><mo xmlns="">*</mo><mn xmlns="">60</mn><mo xmlns="">*</mo><mn xmlns="">60</mn><mo xmlns="">,</mo><msubsup xmlns=""><mi>t</mi><mi>i</mi><mtext>tox</mtext></msubsup><mo xmlns="">+</mo><mo stretchy="false" xmlns="">(</mo><mi xmlns="">d</mi><mo xmlns="">+</mo><mn xmlns="">1</mn><mo stretchy="false" xmlns="">)</mo><mo xmlns="">*</mo><mn xmlns="">24</mn><mo xmlns="">*</mo><mn xmlns="">60</mn><mo stretchy="false" xmlns="">)</mo><mo fence="false" stretchy="false" xmlns="">}</mo><mo fence="false" stretchy="false" xmlns="">|</mo><mo stretchy="false" xmlns="">)</mo><mo xmlns="">,</mo></math></p></div><p>where <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>T</mi><mi>i</mi></msub></math></span> is the set of timestamps of all contributions made by user <em>i</em>, and <em>d</em> is a day ranging from <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">100</mn></math></span> to 100. Finally, the results are averaged over all users. We repeat the procedure of selecting a random toxic comment 100 times and report average results. However, since most users received only one toxic comment, there is little variation across simulations and the average over 100 simulations is almost identical to the result of a single simulation.</p><p>We then compare these results with a control group comprised of users who did not receive any toxic comments. However, a direct comparison is complicated because users who have received a toxic comment are, on average, more active than those who have not. This is probably due to the fact that each contribution could lead to a toxic response with a certain probability. Hence, the more contributions a user makes, the higher the likelihood of receiving a toxic comment and thereby being in the treatment group.</p><p>Specifically, if each contribution can lead to a toxic comment with a probability <em>p</em>, then the probability of receiving at least one toxic comment depends on the number of contribution, <em>N</em>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo stretchy="false" xmlns="">(</mo><mrow xmlns=""><mi mathvariant="normal">gettoxiccomment</mi></mrow><mo stretchy="false" xmlns="">)</mo><mo xmlns="">=</mo><mn xmlns="">1</mn><mo xmlns="">−</mo><mo stretchy="false" xmlns="">(</mo><mn xmlns="">1</mn><mo xmlns="">−</mo><mi xmlns="">p</mi><msup xmlns=""><mo stretchy="false">)</mo><mi>N</mi></msup><mo stretchy="false" xmlns="">(</mo><mn xmlns="">1</mn><mo stretchy="false" xmlns="">)</mo></math>⁠</span>.</p><p>To ensure our control group is similarly active as the treatment group, we randomly select users with a probability based on the number of their contributions using formula (1). Users selected in this manner form the control group. For these users, we then pick a nontoxic comment at random, center their activity around its timestamp, and follow the same procedure used for the treatment group.</p><p>To test for the significance of the results, we compute 95% bootstrapped confidence intervals for each estimate.</p>                    <h3 scrollto-destination="428493774" id="428493774" data-legacy-id="pgad385-s3.4">Probability of leaving</h3>
<p>For each toxic comment, we find the closest in time contribution that precedes that comment. We define such contributions as “contributions followed by a toxic comment” and compare the probability of leaving after such contributions with the probability of leaving after other contributions. The probability of leaving after <em>N</em> contributions is estimated as a fraction of users who have made exactly <em>N</em> contributions among users who have made at least <em>N</em> contributions. As the probability of leaving strongly depends on <em>N</em>, we make a comparison separately for each contribution number <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">N</mi><mo xmlns="">∈</mo><mo stretchy="false" xmlns="">[</mo><mn xmlns="">1</mn><mo xmlns="">,</mo><mn xmlns="">100</mn><mo stretchy="false" xmlns="">]</mo></math>⁠</span>. For <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">N</mi><mo xmlns="">&gt;</mo><mn xmlns="">100</mn></math></span> the number of users is too small to provide reliable estimates for comparison.</p>                    <h2 scrollto-destination="428493779" id="428493779" data-legacy-id="ack1">Acknowledgments</h2>
<p>We acknowledge the Master’s thesis by Brückner (<span id="jumplink-pgad385-B71"></span>71), which identified a potential pattern in data and provided an inspiration for the design of the study presented in this paper. The initial data collection and experiments were carried out as part of Camelia Oprea’s Master’s thesis (<span id="jumplink-pgad385-B72"></span>72). We thank Liubov Tupikina and David Garcia for their valuable discussions regarding the results presented in this article. We thank the anonymous reviewers for their insightful comments and suggestions.</p>                    <h2 scrollto-destination="428493781" id="428493781" data-legacy-id="pgad385-s4">Supplementary Material</h2>
<p><span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/2/12/10.1093_pnasnexus_pgad385/2/pgad385_supplementary_data.pdf?Expires=1704812577&amp;Signature=d-s6BF9zZtNW0YtYo8mehCN1-eUtIRa8236kGZ1D6y4Oyx59aY10tBRtzXHl3cihdAtit8dZ7dBwyEe~VysBKn4vBGYy-gwqzit5D-IT1I6-cmeBEOaQwLNTCjw2AGwKdPTs1KA-stI9hGUB4BHmygndrSNDif-skuWQ-eTIMrIijDvwgO~eHg27ZAlBD0aXn6~K1gliVYgJtIoB-A0d~701nTIjSSXR8jbAuY~~-1zWLOUfkTsLOMyu0q5TAMetfNmQ1oU0AUfVikVZnQ17wk1RFpqzFHQUkEwab8MtC0om0HlAtjvUg65rv5vlK1wwy-AJyLkHSShIrsonaU6t6w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary material</a></span> is available at <em>PNAS Nexus</em> online.</p>                    <h2 scrollto-destination="428493783" id="428493783" data-legacy-id="pgad385-s5">Funding</h2>
<p>The publication of this article was funded by the University of Mannheim.</p>                    <h2 scrollto-destination="428493785" id="428493785" data-legacy-id="pgad385-s6">Author Contributions</h2>
<p>I.S., C.O., and M.S. designed the study; I.S. and C.O. collected and analyzed the data; I.S., C.O., and M.S. wrote the manuscript; I.S. revised the manuscript.</p>                    <h2 scrollto-destination="428493787" id="428493787" data-legacy-id="pgad385-s7">Previous Presentation</h2>
<p>These results were previously presented at International Conference on Computational Social Science 2023.</p>                    <h2 scrollto-destination="428493789" id="428493789" data-legacy-id="pgad385-s8">Preprints</h2>
<p>A preprint of this article is published at <a href="https://doi.org/10.48550/arXiv.2304.13568" target="_blank">https://doi.org/10.48550/arXiv.2304.13568</a></p>                    <h2 scrollto-destination="428493791" id="428493791" data-legacy-id="pgad385-s9">Data Availability</h2>
<p>The data underlying this article is available in Open Science Framework at <a href="https://osf.io/2qyxj/" target="_blank">https://osf.io/2qyxj/</a>.</p>                    <h2 scrollto-destination="428493793" id="428493793" data-legacy-id="ref1">References</h2>
<div><div id="ref-auto-pgad385-B2" data-id="pgad385-B2" content-id="pgad385-B2" data-legacy-id="pgad385-B2"><p><span>2</span></p><div><p>Singer</p>  <p>P</p><p>, <em>et al</em>. </p><p>2017</p><p>. </p><p>Why we read Wikipedia. In: Proceedings of the 26th International Conference on World Wide Web. Perth, Australia: Association for Computing Machinery. p. 1591–1600</p><p>.</p></div></div><div id="ref-auto-pgad385-B3" data-id="pgad385-B3" content-id="pgad385-B3" data-legacy-id="pgad385-B3"><p><span>3</span></p><div><p>Bruckman</p>  <p>AS</p><p>. </p><p>2022</p><p>. </p><p>Should you believe Wikipedia? Online communities and the construction of knowledge</p><p>. </p><p>Cambridge, UK</p><p>: </p><p>Cambridge University Press</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B4" data-id="pgad385-B4" content-id="pgad385-B4" data-legacy-id="pgad385-B4"><p><span>4</span></p><div><p>Brown</p>  <p>AR</p><p>. </p><p>2011</p><p>. </p><p>Wikipedia as a data source for political scientists: accuracy and completeness of coverage</p><p>. </p><p>PS: Political Sci Politics</p><p>. </p><p>44</p><p>(</p><p>2</p><p>):</p><p>339</p><p>–</p><p>343</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgad385-B5" data-id="pgad385-B5" content-id="pgad385-B5" data-legacy-id="pgad385-B5"><p><span>5</span></p><div><p>Clauson</p>  <p>KA</p><p>, <span><p>Polen</p>  <p>HH</p></span>, <span><p>Boulos</p>  <p>MNK</p></span>, <span><p>Dzenowagis</p>  <p>JH</p></span>. </p><p>2008</p><p>. </p><p>Scope, completeness, and accuracy of drug information in Wikipedia</p><p>. </p><p>Ann Pharmacother</p><p>. </p><p>42</p><p>(</p><p>12</p><p>):</p><p>1814</p><p>–</p><p>1821</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B6" data-id="pgad385-B6" content-id="pgad385-B6" data-legacy-id="pgad385-B6"><p><span>6</span></p><div><p>Giles</p>  <p>J</p><p>. </p><p>2005</p><p>. </p><p>Internet encyclopaedias go head to head</p><p>. </p><p>Nature</p><p>. </p><p>438</p><p>(</p><p>15</p><p>):</p><p>900</p><p>–</p><p>901</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B7" data-id="pgad385-B7" content-id="pgad385-B7" data-legacy-id="pgad385-B7"><p><span>7</span></p><div><p>Kräenbring</p>  <p>J</p><p>, <em>et al</em>. </p><p>2014</p><p>. </p><p>Accuracy and completeness of drug information in Wikipedia: a comparison with standard textbooks of pharmacology</p><p>. </p><p>PLoS ONE</p><p>. </p><p>9</p><p>(</p><p>9</p><p>):</p><p>e106930</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B9" data-id="pgad385-B9" content-id="pgad385-B9" data-legacy-id="pgad385-B9"><p><span>9</span></p><div><p>Kraut</p>  <p>RE</p><p>, <span><p>Resnick</p>  <p>P</p></span>. </p><p>2012</p><p>. </p><p>Building successful online communities: evidence-based social design</p><p>. </p><p>Cambridge, MA, USA</p><p>: </p><p>MIT Press</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B10" data-id="pgad385-B10" content-id="pgad385-B10" data-legacy-id="pgad385-B10"><p><span>10</span></p><div><p>Keegan</p>  <p>B</p><p>, <span><p>Fiesler</p>  <p>C</p></span>. </p><p>2017</p><p>. </p><p>The evolution and consequences of peer producing Wikipedia’s rules. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 11. Montreal, Canada: Association for the Advancement of Artificial Intelligence. p. 112–121</p><p>.</p></div></div><div id="ref-auto-pgad385-B11" data-id="pgad385-B11" content-id="pgad385-B11" data-legacy-id="pgad385-B11"><p><span>11</span></p><div><p>Yasseri</p>  <p>T</p><p>, <span><p>Sumi</p>  <p>R</p></span>, <span><p>Rung</p>  <p>A</p></span>, <span><p>Kornai</p>  <p>A</p></span>, <span><p>Kertész</p>  <p>J</p></span>. </p><p>2012</p><p>. </p><p>Dynamics of conflicts in Wikipedia</p><p>. </p><p>PLoS ONE</p><p>. </p><p>7</p><p>(</p><p>6</p><p>):</p><p>e38869</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B12" data-id="pgad385-B12" content-id="pgad385-B12" data-legacy-id="pgad385-B12"><p><span>12</span></p><div><p>Kittur</p>  <p>A</p><p>, <span><p>Suh</p>  <p>B</p></span>, <span><p>Pendleton</p>  <p>BA</p></span>, <span><p>Chi</p>  <p>EH</p></span>. </p><p>2007</p><p>. </p><p>He says, she says: conflict and coordination in Wikipedia. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. San Jose, CA, USA: Association for Computing Machinery. p. 453–462</p><p>.</p></div></div><div id="ref-auto-pgad385-B13" data-id="pgad385-B13" content-id="pgad385-B13" data-legacy-id="pgad385-B13"><p><span>13</span></p><div><p>Arazy</p>  <p>O</p><p>, <span><p>Nov</p>  <p>O</p></span>, <span><p>Patterson</p>  <p>R</p></span>, <span><p>Yeo</p>  <p>L</p></span>. </p><p>2011</p><p>. </p><p>Information quality in Wikipedia: the effects of group composition and task conflict</p><p>. </p><p>J Manag Inf Syst</p><p>. </p><p>27</p><p>(</p><p>4</p><p>):</p><p>71</p><p>–</p><p>98</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B14" data-id="pgad385-B14" content-id="pgad385-B14" data-legacy-id="pgad385-B14"><p><span>14</span></p><div><p>Preece</p>  <p>J</p><p>. </p><p>2001</p><p>. </p><p>Sociability and usability in online communities: determining and measuring success</p><p>. </p><p>Behav Inf Technol</p><p>. </p><p>20</p><p>(</p><p>5</p><p>):</p><p>347</p><p>–</p><p>356</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B15" data-id="pgad385-B15" content-id="pgad385-B15" data-legacy-id="pgad385-B15"><p><span>15</span></p><div><p>Chatzakou</p>  <p>D</p><p>, <em>et al</em>. </p><p>2017</p><p>. </p><p>Measuring# gamergate: a tale of hate, sexism, and bullying. In: Proceedings of the 26th International Conference on World Wide Web. Perth, Australia: Association for Computing Machinery. p. 1285–1290</p><p>.</p></div></div><div id="ref-auto-pgad385-B16" data-id="pgad385-B16" content-id="pgad385-B16" data-legacy-id="pgad385-B16"><p><span>16</span></p><div><p>Guberman</p>  <p>J</p><p>, <span><p>Schmitz</p>  <p>C</p></span>, <span><p>Hemphill</p>  <p>L</p></span>. </p><p>2016</p><p>. </p><p>Quantifying toxicity and verbal violence on twitter. In: Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing. San Francisco, CA, USA: Association for Computing Machinery. p. 277–280</p><p>.</p></div></div><div id="ref-auto-pgad385-B17" data-id="pgad385-B17" content-id="pgad385-B17" data-legacy-id="pgad385-B17"><p><span>17</span></p><div><p>Xia</p>  <p>Y</p><p>, <span><p>Zhu</p>  <p>H</p></span>, <span><p>Lu</p>  <p>T</p></span>, <span><p>Zhang</p>  <p>P</p></span>, <span><p>Gu</p>  <p>N</p></span>. </p><p>2020</p><p>. </p><p>Exploring antecedents and consequences of toxicity in online discussions: a case study on Reddit</p><p>. </p><p>Proc ACM Hum-Comput Interact</p><p>. </p><p>4</p><p>:</p><p>1</p><p>–</p><p>23</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B18" data-id="pgad385-B18" content-id="pgad385-B18" data-legacy-id="pgad385-B18"><p><span>18</span></p><div><p>Almerekhi</p>  <p>H</p><p>, <span><p>Jansen</p>  <p>BJ</p></span>, <span><p>Kwak</p>  <p>H</p></span>. </p><p>2020</p><p>. </p><p>Investigating toxicity across multiple Reddit communities, users, and moderators. In: Companion Proceedings of the Web Conference. Taipei, Taiwan: Association for Computing Machinery. p. 294–298</p><p>.</p></div></div><div id="ref-auto-pgad385-B19" data-id="pgad385-B19" content-id="pgad385-B19" data-legacy-id="pgad385-B19"><p><span>19</span></p><div><p>Wich</p>  <p>M</p><p>, <em>et al</em>. </p><p>2022</p><p>. </p><p>Introducing an abusive language classification framework for telegram to investigate the german hater community. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 16. Atlanta, GA, USA: Association for the Advancement of Artificial Intelligence. p. 1133–1144</p><p>.</p></div></div><div id="ref-auto-pgad385-B20" data-id="pgad385-B20" content-id="pgad385-B20" data-legacy-id="pgad385-B20"><p><span>20</span></p><div><p>Silva</p>  <p>L</p><p>, <span><p>Mondal</p>  <p>M</p></span>, <span><p>Correa</p>  <p>D</p></span>, <span><p>Benevenuto</p>  <p>F</p></span>, <span><p>Weber</p>  <p>I</p></span>. </p><p>2016</p><p>. </p><p>Analyzing the targets of hate in online social media. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 10. Cologne, Germany: Association for the Advancement of Artificial Intelligence. p. 687–690</p><p>.</p></div></div><div id="ref-auto-pgad385-B21" data-id="pgad385-B21" content-id="pgad385-B21" data-legacy-id="pgad385-B21"><p><span>21</span></p><div><p>Kiritchenko</p>  <p>S</p><p>, <span><p>Nejadgholi</p>  <p>I</p></span>, <span><p>Fraser</p>  <p>KC</p></span>. </p><p>2021</p><p>. </p><p>Confronting abusive language online: a survey from the ethical and human rights perspective</p><p>. </p><p>J Artif Intell Res</p><p>. </p><p>71</p><p>:</p><p>431</p><p>–</p><p>478</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B23" data-id="pgad385-B23" content-id="pgad385-B23" data-legacy-id="pgad385-B23"><p><span>23</span></p><div><p>Arazy</p>  <p>O</p><p>, <span><p>Yeo</p>  <p>L</p></span>, <span><p>Nov</p>  <p>O</p></span>. </p><p>2013</p><p>. </p><p>Stay on the Wikipedia task: when task-related disagreements slip into personal and procedural conflicts</p><p>. </p><p>J Am Soc Inf Sci Technol</p><p>. </p><p>64</p><p>(</p><p>8</p><p>):</p><p>1634</p><p>–</p><p>1648</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B26" data-id="pgad385-B26" content-id="pgad385-B26" data-legacy-id="pgad385-B26"><p><span>26</span></p><div><p>Wulczyn</p>  <p>E</p><p>, <span><p>Thain</p>  <p>N</p></span>, <span><p>Dixon</p>  <p>L</p></span>. </p><p>2017</p><p>. </p><p>Ex machina: personal attacks seen at scale. In: Proceedings of the 26th International Conference on World Wide Web. Perth, Australia: Association for Computing Machinery. p. 1391–1399</p><p>.</p></div></div><div id="ref-auto-pgad385-B28" data-id="pgad385-B28" content-id="pgad385-B28" data-legacy-id="pgad385-B28"><p><span>28</span></p><div><p>Qu</p>  <p>I</p><p>, <span><p>Thain</p>  <p>N</p></span>, <span><p>Hua</p>  <p>Y</p></span>. </p><p>2019</p><p>. </p><p>Wikidetox visualization. In: Wiki Workshop; San Francisco, CA, USA</p><p>.</p></div></div><div id="ref-auto-pgad385-B29" data-id="pgad385-B29" content-id="pgad385-B29" data-legacy-id="pgad385-B29"><p><span>29</span></p><div><p>Sumi</p>  <p>R</p><p>, <span><p>Yasseri</p>  <p>T</p></span>. </p><p>2011</p><p>. </p><p>Edit wars in Wikipedia. In: 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing. Boston, MA, USA: Institute of Electrical and Electronics Engineers. p. 724–727</p><p>.</p></div></div><div id="ref-auto-pgad385-B30" data-id="pgad385-B30" content-id="pgad385-B30" data-legacy-id="pgad385-B30"><p><span>30</span></p><div><p>Chhabra</p>  <p>A</p><p>, <span><p>Kaur</p>  <p>R</p></span>, <span><p>Iyengar</p>  <p>SRS</p></span>. </p><p>2020</p><p>. </p><p>Dynamics of edit war sequences in Wikipedia. In: Proceedings of the 16th International Symposium on Open Collaboration. Virtual Event, Spain: Association for Computing Machinery. p. 1–10</p><p>.</p></div></div><div id="ref-auto-pgad385-B31" data-id="pgad385-B31" content-id="pgad385-B31" data-legacy-id="pgad385-B31"><p><span>31</span></p><div><p>Almeida</p>  <p>RB</p><p>, <span><p>Mozafari</p>  <p>B</p></span>, <span><p>Cho</p>  <p>J</p></span>. </p><p>2007</p><p>. </p><p>On the evolution of Wikipedia. In: Proceedings of the International Conference on Web and Social Media (ICWSM). Boulder, CO, USA: Association for the Advancement of Artificial Intelligence</p><p>.</p></div></div><div id="ref-auto-pgad385-B32" data-id="pgad385-B32" content-id="pgad385-B32" data-legacy-id="pgad385-B32"><p><span>32</span></p><div><p>Suh</p>  <p>B</p><p>, <span><p>Convertino</p>  <p>G</p></span>, <span><p>Chi</p>  <p>EH</p></span>, <span><p>Pirolli</p>  <p>P</p></span>. </p><p>2009</p><p>. </p><p>The singularity is not near: slowing growth of Wikipedia. In: Proceedings of the 5th International Symposium on Wikis and Open Collaboration. Orlando, FL, USA: Association for Computing Machinery. p. 1–10</p><p>.</p></div></div><div id="ref-auto-pgad385-B33" data-id="pgad385-B33" content-id="pgad385-B33" data-legacy-id="pgad385-B33"><p><span>33</span></p><div><p>Hill</p>  <p>BM</p><p>, <span><p>Shaw</p>  <p>A</p></span>. </p><p>2020</p><p>. </p><p>Wikipedia and the end of open collaboration. Wikipedia, 20</p><p>.</p></div></div><div id="ref-auto-pgad385-B34" data-id="pgad385-B34" content-id="pgad385-B34" data-legacy-id="pgad385-B34"><p><span>34</span></p><div><p>Ruprechter</p>  <p>T</p><p>, <em>et al</em>. </p><p>2021</p><p>. </p><p>Volunteer contributions to Wikipedia increased during Covid-19 mobility restrictions</p><p>. </p><p>Sci Rep</p><p>. </p><p>11</p><p>(</p><p>1</p><p>):</p><p>21505</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B35" data-id="pgad385-B35" content-id="pgad385-B35" data-legacy-id="pgad385-B35"><p><span>35</span></p><div><p>Halfaker</p>  <p>A</p><p>, <span><p>Geiger</p>  <p>RS</p></span>, <span><p>Morgan</p>  <p>JT</p></span>, <span><p>Riedl</p>  <p>J</p></span>. </p><p>2013</p><p>. </p><p>The rise and decline of an open collaboration system: how Wikipedia’s reaction to popularity is causing its decline</p><p>. </p><p>Am Behav Sci</p><p>. </p><p>57</p><p>(</p><p>5</p><p>):</p><p>664</p><p>–</p><p>688</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B37" data-id="pgad385-B37" content-id="pgad385-B37" data-legacy-id="pgad385-B37"><p><span>37</span></p><div><p>Matei</p>  <p>SA</p><p>, <span><p>Dobrescu</p>  <p>C</p></span>. </p><p>2011</p><p>. </p><p>Wikipedia’s “neutral point of view”: settling conflict through ambiguity</p><p>. </p><p>Inf Soc</p><p>. </p><p>27</p><p>(</p><p>1</p><p>):</p><p>40</p><p>–</p><p>51</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B38" data-id="pgad385-B38" content-id="pgad385-B38" data-legacy-id="pgad385-B38"><p><span>38</span></p><div><p>Luyt</p>  <p>B</p><p>. </p><p>2012</p><p>. </p><p>The inclusivity of Wikipedia and the drawing of expert boundaries: an examination of talk pages and reference lists</p><p>. </p><p>J Am Soc Inf Sci Technol</p><p>. </p><p>63</p><p>(</p><p>9</p><p>):</p><p>1868</p><p>–</p><p>1878</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B39" data-id="pgad385-B39" content-id="pgad385-B39" data-legacy-id="pgad385-B39"><p><span>39</span></p><div><p>Wagner</p>  <p>C</p><p>, <span><p>Garcia</p>  <p>D</p></span>, <span><p>Jadidi</p>  <p>M</p></span>, <span><p>Strohmaier</p>  <p>M</p></span>. </p><p>2015</p><p>. </p><p>It’s a man’s Wikipedia? Assessing gender inequality in an online encyclopedia. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 9. Oxford, UK: Association for the Advancement of Artificial Intelligence. p. 454–463</p><p>.</p></div></div><div id="ref-auto-pgad385-B40" data-id="pgad385-B40" content-id="pgad385-B40" data-legacy-id="pgad385-B40"><p><span>40</span></p><div><p>Ford</p>  <p>H</p><p>, <span><p>Wajcman</p>  <p>J</p></span>. </p><p>2017</p><p>. </p><p>‘anyone can edit’, not everyone does: Wikipedia’s infrastructure and the gender gap</p><p>. </p><p>Soc Stud Sci</p><p>. </p><p>47</p><p>(</p><p>4</p><p>):</p><p>511</p><p>–</p><p>527</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B42" data-id="pgad385-B42" content-id="pgad385-B42" data-legacy-id="pgad385-B42"><p><span>42</span></p><div><p>Lam</p>  <p>STK</p><p>, <em>et al</em>. </p><p>2011</p><p>. </p><p>Wp: clubhouse? an exploration of Wikipedia’s gender imbalance. In: Proceedings of the 7th International Symposium on Wikis and Open Collaboration. Mountain View, CA, USA: Association for Computing Machinery. p. 1–10</p><p>.</p></div></div><div id="ref-auto-pgad385-B43" data-id="pgad385-B43" content-id="pgad385-B43" data-legacy-id="pgad385-B43"><p><span>43</span></p><div><p>Hill</p>  <p>BM</p><p>, <span><p>Shaw</p>  <p>A</p></span>. </p><p>2013</p><p>. </p><p>The Wikipedia gender gap revisited: characterizing survey response bias with propensity score estimation</p><p>. </p><p>PLoS ONE</p><p>. </p><p>8</p><p>(</p><p>6</p><p>):</p><p>e65782</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B45" data-id="pgad385-B45" content-id="pgad385-B45" data-legacy-id="pgad385-B45"><p><span>45</span></p><div><p>Sydow</p>  <p>M</p><p>, <span><p>Baraniak</p>  <p>K</p></span>, <span><p>Teisseyre</p>  <p>P</p></span>. </p><p>2017</p><p>. </p><p>Diversity of editors and teams versus quality of cooperative work: experiments on Wikipedia</p><p>. </p><p>J Intell Inf Syst</p><p>. </p><p>48</p><p>:</p><p>601</p><p>–</p><p>632</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B46" data-id="pgad385-B46" content-id="pgad385-B46" data-legacy-id="pgad385-B46"><p><span>46</span></p><div><p>Lir</p>  <p>SA</p><p>. </p><p>2021</p><p>. </p><p>Strangers in a seemingly open-to-all Website: the gender bias in Wikipedia</p><p>. </p><p>Equal Divers Incl Int J</p><p>. </p><p>40</p><p>(</p><p>7</p><p>):</p><p>801</p><p>–</p><p>818</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B47" data-id="pgad385-B47" content-id="pgad385-B47" data-legacy-id="pgad385-B47"><p><span>47</span></p><div><p>Menking</p>  <p>A</p><p>, <span><p>Erickson</p>  <p>I</p></span>. </p><p>2015</p><p>. </p><p>The heart work of Wikipedia: gendered, emotional labor in the world’s largest online encyclopedia. In: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. Seoul, Republic of Korea: Association for Computing Machinery. p. 207–210</p><p>.</p></div></div><div id="ref-auto-pgad385-B49" data-id="pgad385-B49" content-id="pgad385-B49" data-legacy-id="pgad385-B49"><p><span>49</span></p><div><p>Bear</p>  <p>JB</p><p>, <span><p>Collier</p>  <p>B</p></span>. </p><p>2016</p><p>. </p><p>Where are the women in Wikipedia? understanding the different psychological experiences of men and women in Wikipedia</p><p>. </p><p>Sex Roles</p><p>. </p><p>74</p><p>:</p><p>254</p><p>–</p><p>265</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B50" data-id="pgad385-B50" content-id="pgad385-B50" data-legacy-id="pgad385-B50"><p><span>50</span></p><div><p>Lemieux</p>  <p>ME</p><p>, <span><p>Zhang</p>  <p>R</p></span>, <span><p>Tripodi</p>  <p>F</p></span>. </p><p>2023</p><p>. </p><p>“too soon” to count? How gender and race cloud notability considerations on Wikipedia</p><p>. </p><p>Big Data Soc</p><p>. </p><p>10</p><p>(</p><p>1</p><p>):</p><p>20539517231165490</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgad385-B51" data-id="pgad385-B51" content-id="pgad385-B51" data-legacy-id="pgad385-B51"><p><span>51</span></p><div><p>Tripodi</p>  <p>F</p><p>. </p><p>2023</p><p>. </p><p>Ms. categorized: gender, notability, and inequality on Wikipedia</p><p>. </p><p>New Media Soc</p><p>. </p><p>25</p><p>(</p><p>7</p><p>):</p><p>1687</p><p>–</p><p>1707</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B52" data-id="pgad385-B52" content-id="pgad385-B52" data-legacy-id="pgad385-B52"><p><span>52</span></p><div><p>Field</p>  <p>A</p><p>, <span><p>Park</p>  <p>CY</p></span>, <span><p>Lin</p>  <p>KZ</p></span>, <span><p>Tsvetkov</p>  <p>Y</p></span>. </p><p>2022</p><p>. </p><p>Controlled analyses of social biases in Wikipedia bios. In: Proceedings of the ACM Web Conference 2022. Lyon, France: Association for Computing Machinery. p. 2624–2635</p><p>.</p></div></div><div id="ref-auto-pgad385-B53" data-id="pgad385-B53" content-id="pgad385-B53" data-legacy-id="pgad385-B53"><p><span>53</span></p><div><p>Restivo</p>  <p>M</p><p>, <span><p>van de Rijt</p>  <p>A</p></span>. </p><p>2014</p><p>. </p><p>No praise without effort: experimental evidence on how rewards affect Wikipedia’s contributor community</p><p>. </p><p>Inf Commun Soc</p><p>. </p><p>17</p><p>(</p><p>4</p><p>):</p><p>451</p><p>–</p><p>462</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B54" data-id="pgad385-B54" content-id="pgad385-B54" data-legacy-id="pgad385-B54"><p><span>54</span></p><div><p>Cheng</p>  <p>J</p><p>, <span><p>Danescu-Niculescu-Mizil</p>  <p>C</p></span>, <span><p>Leskovec</p>  <p>J</p></span>. </p><p>2014</p><p>. </p><p>How community feedback shapes user behavior. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 8. Ann Arbor, MI, USA: Association for the Advancement of Artificial Intelligence. p. 41–50</p><p>.</p></div></div><div id="ref-auto-pgad385-B55" data-id="pgad385-B55" content-id="pgad385-B55" data-legacy-id="pgad385-B55"><p><span>55</span></p><div><p>Langrock</p>  <p>I</p><p>, <span><p>González-Bailón</p>  <p>S</p></span>. </p><p>2022</p><p>. </p><p>The gender divide in Wikipedia: quantifying and assessing the impact of two feminist interventions</p><p>. </p><p>J Commun</p><p>. </p><p>72</p><p>(</p><p>3</p><p>):</p><p>297</p><p>–</p><p>321</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgad385-B56" data-id="pgad385-B56" content-id="pgad385-B56" data-legacy-id="pgad385-B56"><p><span>56</span></p><div><p>Menking</p>  <p>A</p><p>, <span><p>Erickson</p>  <p>I</p></span>, <span><p>Pratt</p>  <p>W</p></span>. </p><p>2019</p><p>. </p><p>People who can take it: how women Wikipedians negotiate and navigate safety. In: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. Glasgow, UK: Association for Computing Machinery. p. 1–14</p><p>.</p></div></div><div id="ref-auto-pgad385-B59" data-id="pgad385-B59" content-id="pgad385-B59" data-legacy-id="pgad385-B59"><p><span>59</span></p><div><p>Vincent</p>  <p>N</p><p>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2021</p><p>. </p><p>A deeper investigation of the importance of Wikipedia links to search engine results</p><p>. </p><p>Proc ACM Hum-Comput Interact</p><p>. </p><p>5</p><p>(</p><p>CSCW1</p><p>):</p><p>1</p><p>–</p><p>15</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgad385-B60" data-id="pgad385-B60" content-id="pgad385-B60" data-legacy-id="pgad385-B60"><p><span>60</span></p><div><p>Vincent</p>  <p>N</p><p>, <span><p>Johnson</p>  <p>I</p></span>, <span><p>Sheehan</p>  <p>P</p></span>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2019</p><p>. </p><p>Measuring the importance of user-generated content to search engines. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 13. Munich, Germany: Association for the Advancement of Artificial Intelligence. p. 505–516</p><p>.</p></div></div><div id="ref-auto-pgad385-B61" data-id="pgad385-B61" content-id="pgad385-B61" data-legacy-id="pgad385-B61"><p><span>61</span></p><div><p>McMahon</p>  <p>C</p><p>, <span><p>Johnson</p>  <p>I</p></span>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2017</p><p>. </p><p>The substantial interdependence of Wikipedia and Google: a case study on the relationship between peer production communities and information technologies. In: Proceedings of the International AAAI Conference on Web and Social Media. Vol. 11. Montreal, Canada: Association for the Advancement of Artificial Intelligence. p. 142–151</p><p>.</p></div></div><div id="ref-auto-pgad385-B62" data-id="pgad385-B62" content-id="pgad385-B62" data-legacy-id="pgad385-B62"><p><span>62</span></p><div><p>Vincent</p>  <p>N</p><p>, <span><p>Johnson</p>  <p>I</p></span>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2018</p><p>. </p><p>Examining Wikipedia with a broader lens: quantifying the value of Wikipedia’s relationships with other large-scale online communities. In: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. Montreal, Canada: Association for Computing Machinery. p. 1–13</p><p>.</p></div></div><div id="ref-auto-pgad385-B63" data-id="pgad385-B63" content-id="pgad385-B63" data-legacy-id="pgad385-B63"><p><span>63</span></p><div><p>TeBlunthuis</p>  <p>N</p><p>, <span><p>Shaw</p>  <p>A</p></span>, <span><p>Hill</p>  <p>BM</p></span>. </p><p>2018</p><p>. </p><p>Revisiting “the rise and decline” in a population of peer production projects. In: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. Montreal, Canada: Association for Computing Machinery. p. 1–7</p><p>.</p></div></div><div id="ref-auto-pgad385-B64" data-id="pgad385-B64" content-id="pgad385-B64" data-legacy-id="pgad385-B64"><p><span>64</span></p><div><p>Smirnov</p>  <p>I</p><p>, <span><p>Oprea</p>  <p>C</p></span>. </p><p>2023</p><p>. </p><p>Toxic comments reduce activity of volunteer editors on Wikipedia: data &amp; code</p><p>, 2023. <a href="https://osf.io/2qyxj" target="_blank">https://osf.io/2qyxj</a>.</p></div></div><div id="ref-auto-pgad385-B65" data-id="pgad385-B65" content-id="pgad385-B65" data-legacy-id="pgad385-B65"><p><span>65</span></p><div><p>Xu</p>  <p>Z</p><p>, <span><p>Zhu</p>  <p>S</p></span>. </p><p>2010</p><p>. </p><p>Filtering offensive language in online communities using grammatical relations. In: Proceedings of the Seventh Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference. Redmond, WA, USA: Association for Computing Machinery. p. 1–10</p><p>.</p></div></div><div id="ref-auto-pgad385-B66" data-id="pgad385-B66" content-id="pgad385-B66" data-legacy-id="pgad385-B66"><p><span>66</span></p><div><p>Fortuna</p>  <p>P</p><p>, <span><p>Soler</p>  <p>J</p></span>, <span><p>Wanner</p>  <p>L</p></span>. </p><p>2020</p><p>. </p><p>Toxic, hateful, offensive or abusive? what are we really classifying? an empirical analysis of hate speech datasets. In: Proceedings of the 12th Language Resources and Evaluation Conference. Marseille, France: Association for Computational Linguistics. p. 6786–6794</p><p>.</p></div></div><div id="ref-auto-pgad385-B67" data-id="pgad385-B67" content-id="pgad385-B67" data-legacy-id="pgad385-B67"><p><span>67</span></p><div><p>Zampieri</p>  <p>M</p><p>, <em>et al</em>. </p><p>2020</p><p>. </p><p>Semeval-2020 task 12: multilingual offensive language identification in social media (offenseval 2020), arXiv, arXiv:2006.07235, preprint: not peer reviewed</p><p>.</p></div></div><div id="ref-auto-pgad385-B69" data-id="pgad385-B69" content-id="pgad385-B69" data-legacy-id="pgad385-B69"><p><span>69</span></p><div><p>Zampieri</p>  <p>M</p><p>, <em>et al</em>. </p><p>2019</p><p>. </p><p>Semeval-2019 task 6: identifying and categorizing offensive language in social media (offenseval), arXiv, arXiv:1903.08983, preprint: not peer reviewed</p><p>.</p></div></div><div id="ref-auto-pgad385-B70" data-id="pgad385-B70" content-id="pgad385-B70" data-legacy-id="pgad385-B70"><p><span>70</span></p><div><p>Lees</p>  <p>A</p><p>, <em>et al</em>. </p><p>2022</p><p>. </p><p>A new generation of perspective API: efficient multilingual character-level transformers, arXiv, arXiv:2202.11176, preprint: not peer reviewed</p><p>.</p></div></div><div id="ref-auto-pgad385-B71" data-id="pgad385-B71" content-id="pgad385-B71" data-legacy-id="pgad385-B71"><p><span>71</span></p><div><p>Brückner</p>  <p>S</p><p>. </p><p>2021</p><p>. </p><p>Modeling sociodemographic attributes of Wikipedia editors [master thesis]. RWTH Aachen</p><p>.</p></div></div><div id="ref-auto-pgad385-B72" data-id="pgad385-B72" content-id="pgad385-B72" data-legacy-id="pgad385-B72"><p><span>72</span></p><div><p>Oprea</p>  <p>C</p><p>. </p><p>2022</p><p>. </p><p>Determining the impact of toxicity on Wikipedia’s talk pages [master thesis]. RWTH Aachen</p><p>.</p></div></div></div>    <!-- /foreach in Model.Sections -->
    



        

        
                    <h2 id="authorNotesSectionTitle" scrollto-destination="authorNotesSectionTitle">Author notes</h2>
<p><span><p><strong>Competing Interest:</strong> The authors declare no competing interest.</p></span></p><p>© The Author(s) 2023. Published by Oxford University Press on behalf of National Academy of Sciences.</p><div><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">https://creativecommons.org/licenses/by/4.0/</a>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</p></div><!-- /foreach -->

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sorry, but a new prompt for GPT-4 is not a paper (247 pts)]]></title>
            <link>https://twitter.com/hbouammar/status/1731970658278469714</link>
            <guid>38530207</guid>
            <pubDate>Tue, 05 Dec 2023 13:06:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/hbouammar/status/1731970658278469714">https://twitter.com/hbouammar/status/1731970658278469714</a>, See on <a href="https://news.ycombinator.com/item?id=38530207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Julius Caesar was once captured by pirates (152 pts)]]></title>
            <link>https://www.britannica.com/story/the-time-julius-caesar-was-captured-by-pirates</link>
            <guid>38529977</guid>
            <pubDate>Tue, 05 Dec 2023 12:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.britannica.com/story/the-time-julius-caesar-was-captured-by-pirates">https://www.britannica.com/story/the-time-julius-caesar-was-captured-by-pirates</a>, See on <a href="https://news.ycombinator.com/item?id=38529977">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><figure data-type="1" data-descid="1"><p><a href="https://cdn.britannica.com/03/184703-050-4C296E27/Gaius-Julius-Caesar-statue-Rimini-Italy-statesman.jpg" target="_blank" data-href="*"><img src="https://cdn.britannica.com/03/184703-050-4C296E27/Gaius-Julius-Caesar-statue-Rimini-Italy-statesman.jpg?w=600&amp;q=60" alt="Julius Caesar in full Gaius Julius Caesar (100? BCE-44 BCE) statue in Rimini, Italy. Roman general and statesman and dictator" data-width="1600" data-height="1049" loading="eager"></a></p><figcaption><cite>© ViewApart/Fotolia</cite></figcaption></figure><!--[BP1]--><p>In the 1st century BCE the <a href="https://www.britannica.com/place/Mediterranean-Sea" data-show-preview="true">Mediterranean Sea</a> had a crime problem. Specifically, it had a <a href="https://www.britannica.com/topic/piracy-international-law" data-show-preview="true">pirate</a> problem. The rugged region of southern Anatolia known as Cilicia Trachea (Rough Cilicia) was notoriously infested with seagoing bandits whose depredations terrified Romans. </p><!--[P1]--><!--[AM1]--><span></span><!--[MOD1]--><span></span><!--[BP2]--><p>In 75 BCE a band of Cilician pirates in the <a href="https://www.britannica.com/place/Aegean-Sea" data-show-preview="true">Aegean Sea</a> captured a 25-year-old Roman nobleman named <a href="https://www.britannica.com/biography/Julius-Caesar-Roman-ruler" data-show-preview="true">Julius Caesar</a>, who had been on his way to study oratory in <a href="https://www.britannica.com/place/Rhodes-Greece" data-show-preview="true">Rhodes</a>. As the story is related in <a href="https://www.britannica.com/biography/Plutarch" data-show-preview="true">Plutarch</a>’s <em>Parallel Lives</em>, the capture was a minor inconvenience for Caesar but very bad luck for the pirates.</p><!--[P2]--><!--[AM2]--><span></span><!--[MOD2]--><span></span><!--[BP3]--><p>From the start, Caesar simply refused to behave like a captive. When the pirates told him that they had set his ransom at the sum of 20 talents, he laughed at them for not knowing who it was they had captured and suggested that 50 talents would be a more appropriate amount. He then sent his entourage out to gather the money and settled in for a period of captivity. The pirates must have been dumbfounded. It’s not every day that a hostage negotiates his ransom <em>up</em>. </p><!--[P3]--><!--[AM3]--><span></span><!--[MOD3]--><span></span><!--[BP4]--><p>Caesar made himself at home among the pirates, bossing them around and shushing them when he wanted to sleep. He made them listen to the speeches and poems that he was composing in his unanticipated downtime and berated them as illiterates if they weren’t sufficiently impressed. He would participate in the pirates’ games and exercises, but he always addressed them as if he were the commander and they were his subordinates. From time to time he would threaten to have them all crucified. They took it as a joke from their overconfident, slightly nutty captive. </p><!--[P4]--><!--[AM4]--><span></span><!--[MOD4]--><span></span><!--[BP5]--><p>It wasn’t a joke. After 38 days, the ransom was delivered and Caesar went free. Astonishingly, Caesar managed to raise a naval force in <a href="https://www.britannica.com/place/Miletus" data-show-preview="true">Miletus</a>—despite holding no public or military office—and he set out in pursuit of the pirates. He found them still camped at the island where he had been held, and he brought them back as his captives. When the governor of Asia seemed to vacillate about punishing them, Caesar went to the prison where they were being held and had them all crucified. </p><!--[P5]--><!--[AM5]--><span></span><!--[MOD5]--><span></span><span></span></article></div>]]></description>
        </item>
    </channel>
</rss>