<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 16 Oct 2023 15:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[OpenBSD 7.4 (112 pts)]]></title>
            <link>https://www.openbsd.org/74.html</link>
            <guid>37899478</guid>
            <pubDate>Mon, 16 Oct 2023 13:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openbsd.org/74.html">https://www.openbsd.org/74.html</a>, See on <a href="https://news.ycombinator.com/item?id=37899478">Hacker News</a></p>
<div id="readability-page-1" class="page">


<table>
<tbody><tr>
<td>
<a href="https://www.openbsd.org/images/ImHappyBecauseEveryoneLovesMe.jpg">
<img width="227" height="303" src="https://www.openbsd.org/images/ImHappyBecauseEveryoneLovesMe-s.gif" alt="I'm mHappy Because Everyone Loves Me"></a>
</td><td>
Released Oct 16, 2023. (55th OpenBSD release)<br>
Copyright 1997-2023, Theo de Raadt.<p>

Artwork by Jessica Scott.
</p><ul>
<li>See the information on <a href="https://www.openbsd.org/ftp.html">the FTP page</a> for
    a list of mirror machines.
</li><li>Go to the <code>pub/OpenBSD/7.4/</code> directory on
    one of the mirror sites.
</li><li>Have a look at <a href="https://www.openbsd.org/errata74.html">the 7.4 errata page</a> for a list
    of bugs and workarounds.
</li><li>See a <a href="https://www.openbsd.org/plus74.html">detailed log of changes</a> between the
    7.3 and 7.4 releases.
</li><li><a href="https://man.openbsd.org/signify.1">signify(1)</a>
    pubkeys for this release:<table>
<tbody><tr><td>
openbsd-74-base.pub:
</td><td>
<a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/openbsd-74-base.pub">
RWRoyQmAD08ajTqgzK3UcWaVlwaJMckH9/CshU8Md5pN1GoIrcBdTF+c</a>
</td></tr><tr><td>
openbsd-74-fw.pub:
</td><td>
RWTRA9KXRuZKunpXYK0ed5OxbE0K7rYWpDnTu+M8wZdqzRroFqed0U6I
</td></tr><tr><td>
openbsd-74-pkg.pub:
</td><td>
RWR/h7gubZ9M/O46RNy3PzLTPevOCK24LGCPca41IHMwSH4YuVA+jnWO
</td></tr><tr><td>
openbsd-74-syspatch.pub:
</td><td>
RWQqty2voy8V8afR9/v2RzuNr7r4y9cKwljABN7Tytd7JcPdBjnXg0Ue
</td></tr></tbody></table>
</li></ul>
<p>
All applicable copyrights and credits are in the src.tar.gz,
sys.tar.gz, xenocara.tar.gz, ports.tar.gz files, or in the
files fetched via <code>ports.tar.gz</code>.
</p></td></tr></tbody></table>

<hr>

<section id="new">
<h3>What's New</h3>
<p>
This is a partial list of new features and systems included in OpenBSD 7.4.
For a comprehensive list, see the <a href="https://www.openbsd.org/plus74.html">changelog</a> leading
to 7.4.

</p><ul>

<!--
<li>New/extended platforms:
  <ul>
  <li>...
  </ul>
-->

<li>Various kernel improvements:
  <ul>
  <li>On arm64, show BTI and SBSS features in
      <a href="https://man.openbsd.org/dmesg.8">dmesg(8)</a>.
  </li><li>New <a href="https://man.openbsd.org/kqueue1">kqueue1(2)</a>
      system call supporting the <code>O_CLOEXEC</code> flag.
  </li><li>Map device tree read/write to unbreak root on
      <a href="https://man.openbsd.org/softraid.4">softraid(4)</a>.
  </li><li>Correctly recognize <a href="https://man.openbsd.org/umass.4">umass(4)</a>
      floppy disk devices as floppy disks.
  </li><li>In <a href="https://man.openbsd.org/wscons.4">wscons(4)</a>,
	catch up with box drawing characters which have
	been standardized in unicode after the original wscons code was
	written and chose placeholder values.
  </li><li>In <a href="https://man.openbsd.org/wscons.4">wscons(4)</a>,
	make sure we do not increase the escape sequence argument count beyond
	usable bounds.
  </li><li>Implement <a href="https://man.openbsd.org/dt.4">dt(4)</a>
	<a href="https://man.openbsd.org/utrace.2">utrace(2)</a>
	support on amd64 and i386.
  </li><li>Correct undefined behavior when using MS-DOS filesystems, fixes imported from FreeBSD.
  </li><li>Make the <a href="https://man.openbsd.org/fstab.5">softdep</a>
	<a href="https://man.openbsd.org/mount.8">mount(8)</a> option a no-op.
	Softdep was a significant impediment to improving the vfs layer.
  </li><li>Allow <a href="https://man.openbsd.org/unveil.2">unveil(2)</a>ed
	programs to dump <a href="https://man.openbsd.org/core.5">core(5)</a>
	into the current working directory.
  </li><li>Address incomplete validation of ELF program headers in <a href="https://man.openbsd.org/execve.2">execve(2)</a>.
  </li><li>On arm64, use the deep idle state available on Apple M1/M2 cores
	in the idle loop and for suspend, resulting in power savings.
  </li><li>Update AMD CPU microcode if a newer patch is available.
  </li><li>Enable a workaround for the 'Zenbleed' AMD CPU bug.
  </li><li>Report speculation control bits in
	<a href="https://man.openbsd.org/dmesg.8">dmesg(8)</a> CPU lines.
  </li><li>To give the primary CPU an opportunity to perform clock interrupt
	preparation in a machine-independent manner we need to separate the
	"initialization" parts of cpu_initclocks() from the "start the clock
	interrupt" parts. Separate cpu_initclocks() from cpu_startclock().
  </li><li>Fix a problem where CPU time accounting and RLIMIT_CPU was
	unreliable on idle systems.
  </li><li>Improve the output of the "show proc" command of the kernel
	debugger <a href="https://man.openbsd.org/ddb.4">ddb(4)</a> and show
	both the PID and TID of the proc.
  </li></ul>

</li><li>SMP Improvements
  <ul>
  <li>Rewrite <a href="https://man.openbsd.org/pfsync.4">pfsync(4)</a>,
	in particular to improve locking and to help with unlocking more
	of <a href="https://man.openbsd.org/pf.4">pf(4)</a> and with
	parallelisation of the network stack in the future.
	The protocol remains compatible with the older version.
  </li><li>Remove kernel locks from the ARP input path.
  </li><li>Pull MP-safe arprequest() out of kernel lock.
  </li><li>Remove the kernel lock from IPv6 neighbor discovery.
  </li><li>Unlock more parts of <a href="https://man.openbsd.org/ioctl.2">ioctl(2)</a> and the <a href="https://man.openbsd.org/route.4">routing</a> code in the network
	stack.
  </li></ul>

</li><li>Direct Rendering Manager and graphics drivers
  <ul>
  <li>Update <a href="https://man.openbsd.org/drm.4">drm(4)</a>
      to Linux 6.1.55.
  </li><li>Don't change end marker in sg_set_page().  Caused bad memory accesses
      when using page flipping on Alder Lake and Raptor Lake.
  </li></ul>

</li><li>VMM/VMD improvements
  <ul>
  <li>Allowed <a href="https://man.openbsd.org/vmm.4">vmm(4)</a> guests to 
	enable and use supervisor IBT.
  </li><li>Suppressed AMD hardware p-state visibility to
	<a href="https://man.openbsd.org/vmm.4">vmm(4)</a> guests. 
  </li><li>Avoid use of uninitialised memory in
      <a href="https://man.openbsd.org/vmd.8">vmd(8)</a>.
  </li><li>Migrate vmd_vm.vm_ttyname to char array allowing a vmd_vm
        object to be transmitted over an ipc channel.
  </li><li>Cleaned up file descriptor closing in
	 <a href="https://man.openbsd.org/vmd.8">vmd(8)</a> vmm process.
  </li><li>Fixed vm send/receive, restoring device virtqueue addresses on
	receive.
  </li><li>Introduced <a href="https://man.openbsd.org/execvp.3">execvp(3)</a>
	after fork for child vm processes.
  </li><li>No longer generate an error in
      <a href="https://man.openbsd.org/vmd.8">vmd(8)</a> if
      <a href="https://man.openbsd.org/vm.conf.5">vm.conf(5)</a> is absent.
  </li><li>Split <a href="https://man.openbsd.org/vmm.4">vmm(4)</a> into MI/MD
	parts.
  </li><li>Introduced multi-process model for 
	<a href="https://man.openbsd.org/vmd.8">vmd(8)</a> virtio block and
	network devices.
  </li><li>Allowed vm owners to override boot kernel when using
	<a href="https://man.openbsd.org/vmctl.8">vmctl(8)</a> to start a
	vm.
  </li><li>Changed staggered start of vms to number of online CPUs.
  </li><li>Fixed a segfault on vm creation.
  </li><li>Switched to anonymous shared memory mappings for
	<a href="https://man.openbsd.org/vmd.8">vmd(8)</a> vm processes,
	introducing a new <a href="https://man.openbsd.org/vmm.4">vmm(4)</a>
	<a href="https://man.openbsd.org/ioctl.2">ioctl(2)</a>.
  </li><li>Relaxed absolute path requirements for 
	<a href="https://man.openbsd.org/vmd.8">vmd(8)</a> configtest mode (-n).
  </li><li>Adjusted shutdown logic by vm id to function similarly as by name.
  </li><li>Moved validation of local network prefixes for the internal
	<a href="https://man.openbsd.org/vmd.8">vmd(8)</a> DHCP service into
	the config parser.
  </li><li>Fixed QCOW2 base images when used with the
	<a href="https://man.openbsd.org/vmd.8">vmd(8)</a> multi-process device
	model.
  </li><li>Fixed setting verbose logging in child processes.
  </li><li>Fixed a race condition related to the emulated i8259 interrupt controller
	by ignoring interrupt masks on assert.
  </li><li>Inlined pending interrupts in the 
	<a href="https://man.openbsd.org/vmm.4">vmm(4)</a>
	<a href="https://man.openbsd.org/ioctl.2">ioctl(2)</a> for running the
	vcpu, reducing vm latency.
  </li><li>Added zero-copy, vectored io to the
	<a href="https://man.openbsd.org/vmd.8">vmd(8)</a> virtio block device.
  </li><li>Changed to logging <a href="https://man.openbsd.org/vmd.8">vmd(8)</a>
	vm ids in the vcpu run loop on error and not the ids used by
	<a href="https://man.openbsd.org/vmm.4">vmm(4)</a>.
  </li><li>Fixed a vm pause deadlock.
  </li><li>Changed <a href="https://man.openbsd.org/vmd.8">vmd(8)</a> logging format
	to disambiguate vm and device process by names and indices.
  </li><li>Fixed dynamically toggling verbose logging mode with
	<a href="https://man.openbsd.org/vmctl.8">vmctl(8)</a>.
  </li></ul>

</li><li>Various new userland features:
  <ul>
  <li>New ISO C11 header <code>&lt;uchar.h&gt;</code> declaring the
      types <code>char32_t</code> and <code>char16_t</code> and the
      functions <a href="https://man.openbsd.org/c32rtomb.3">c32rtomb(3)</a>,
      <a href="https://man.openbsd.org/mbrtoc32.3">mbrtoc32(3)</a>,
      <a href="https://man.openbsd.org/c16rtomb.3">c16rtomb(3)</a>, and
      <a href="https://man.openbsd.org/mbrtoc16.3">mbrtoc16(3)</a>.
  </li><li>Introduce a new <a href="https://man.openbsd.org/malloc.3">malloc(3)</a>
	option <a href="https://man.openbsd.org/malloc.3#D">D</a>
	for memory leak detection with
	<a href="https://man.openbsd.org/ktrace.1">ktrace(1)</a> and
	<a href="https://man.openbsd.org/kdump.1">kdump(1)</a>.
  </li><li>Support <code>${.VARIABLES}</code> in
      <a href="https://man.openbsd.org/make.1">make(1)</a>,
      listing the names of all global variables that have been set.
  </li><li>New <a href="https://man.openbsd.org/kdump.1">kdump(1)</a>
      <code>-u</code> option to select
      <a href="https://man.openbsd.org/utrace.2">utrace(2)</a>
      tracepoints by label.
  </li><li>In <a href="https://man.openbsd.org/openrsync.1">openrsync(1)</a>,
      support the options <code>--size-only</code> and
      <code>--ignore-times</code>.
  </li><li>Update <a href="https://man.openbsd.org/tzset.3">zoneinfo</a>
      to tzdata2023c.
  </li><li>Accept the <a href="https://man.openbsd.org/ucom.4">ucom(4)</a> fixed
      name format as a valid format for the
      <a href="https://man.openbsd.org/cu.1">cu(1)</a> -l option.
  </li><li>In <a href="https://man.openbsd.org/cron.8">cron(8)</a> and
	<a href="https://man.openbsd.org/crontab.5">crontab(5)</a>,
	add support for random offsets when
	using ranges with a step value in cron.  This extends the random range
	syntax to support step values.  Instead of choosing a random number
	between the high and low values, the field is treated as a range with
	a random offset less than the step value.  This can be used to avoid
	thundering herd problems where multiple machines contact a server all
	at the same time via cron jobs.
  </li><li>Extend and improve the
	<a href="https://man.openbsd.org/ibuf_add.3">ibuf</a> API in libutil
	and add functions for more specific data types,
	for modifying data at specific
	offsets, for getting and setting the file descriptor stored on the ibuf
	and for efficient wrapping of ibufs into imsgs. The ibuf API is
	mostly used in network daemons.
  </li><li>In <a href="https://man.openbsd.org/wsconsctl.8">wsconsctl(8)</a>,
	add button mappings for two- and three-finger clicks on clickpads.
  </li></ul>

</li><li>Various bugfixes and tweaks in userland:
  <ul>
  <li>In <a href="https://man.openbsd.org/pax.1">pax(1)</a> and
      <a href="https://man.openbsd.org/tar.1">tar(1)</a>,
      do not open files that will be skipped,
      speeding up archive creation when many files are skipped.
  </li><li>In <a href="https://man.openbsd.org/pax.1">pax(1)</a>,
      <a href="https://man.openbsd.org/tar.1">tar(1)</a>, and
      <a href="https://man.openbsd.org/cpio.1">cpio(1)</a> terminal
      output, escape non-printable characters in messages that may
      include file names, and truncate times to the correct maximum value.
  </li><li>Better diagnostics from
      <a href="https://man.openbsd.org/make.1">make(1)</a>
      when a makefile exists but cannot be opened.
  </li><li>Prevent a buffer underflow in
      <a href="https://man.openbsd.org/patch.1">patch(1)</a>
      that could occur with lines longer than 32kB.
  </li><li>Prevent a segmentation fault in
      <a href="https://man.openbsd.org/patch.1">patch(1)</a>
      that occurred when a patch specified a file name so long that
      <a href="https://man.openbsd.org/basename.3">basename(3)</a> failed.
  </li><li>Prevent a read buffer overrun in
      <a href="https://man.openbsd.org/patch.1">patch(1)</a>
      that could occur when a patch specified a file name ending in a slash.
  </li><li>Let <a href="https://man.openbsd.org/stat.1">stat(1)</a>
      correctly print mtimes after 2038.
  </li><li>Refactoring and documenting of
      <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a> code,
      to make it easier to maintain.
  </li><li><a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a>
       no longer adds extra blanks at the end of lines, eliminating
       spurious line wrapping.
  </li><li>In <a href="https://man.openbsd.org/clang.1">clang(1)</a>,
      allow out-of-class defaulting of comparison operators,
	by ways of backporting an upstream commit.

  </li><li>Many changes in <a href="https://man.openbsd.org/mg.1">mg(1)</a>:
    <ul>
    <li>New command
        <a href="https://man.openbsd.org/mg.1#set-tab-width">set-tab-width</a>
        to change the tabulator width on a per-buffer basis.
    </li><li>Let the <code>space-to-tabstop</code> command move to the right
        position even if the line contains tabs, control characters,
        or non-ASCII bytes.
    </li><li>Fall back to <code>/bin/sh</code> if <code>$SHELL</code> is undefined.
    </li><li>Fix parsing of <a href="https://man.openbsd.org/mg.1#TAGS">tag
        files</a> with duplicate entries.
        Instead of erroring out, ignore duplicates. Fixes using
        <code>/var/db/libc.tags</code> again.
    </li><li>Change the <a href="https://man.openbsd.org/mg.1#visit-tags-table">visit-tags-table</a> command to immediately
	load the tag file, and drop the lazy mechanics.
    </li><li>Do not leak memory in
        <a href="https://man.openbsd.org/mg.1#pop-tag-mark">pop-tag-mark</a>
        if it fails to switch buffers.
    </li><li>Fix a read buffer overrun caused by
        <a href="https://man.openbsd.org/mg.1#u">-u</a> arguments
        longer than 1023 bytes.
    </li><li>Fix a write buffer overrun on the stack caused by
        <a href="https://man.openbsd.org/mg.1#blink-and-insert">blink-and-insert</a> matching a very long line
        that is not currently visible in the window.
    </li><li>Skip checking permissions of conffile with
        <a href="https://man.openbsd.org/access.2">access(2)</a>.
    </li><li>Resurrect
	<a href="https://man.openbsd.org/mg.1#no-tab-mode">no-tab-mode</a>
	and add it to the list of modes that can
	be set with
	<a href="https://man.openbsd.org/mg.1#set-default-mode">set-default-mode</a>.
    </li></ul>

  </li><li>Fix a segfault when the
      <a href="https://man.openbsd.org/disklabel.8">disklabel(8)</a>
	    simple editor encounters an incomplete partition line.
  </li><li>Fix <a href="https://man.openbsd.org/disklabel.8">disklabel(8)</a>
      handling of templates with partitions after a "N-* 100" entry.
  </li><li>Enable <a href="https://man.openbsd.org/disklabel.8">disklabel(8)</a>
      regress tests to work on sparc64.
  </li><li>Fix <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a>
      initialization of CHS/LBA fields in an MBR, allowing machines with
      a BIOS that uses CHS to boot from disks &gt;8G.
  </li><li>Retire <a href="https://man.openbsd.org/disklabel.8">disklabel(8)</a>
      -E expert mode.
  </li><li>When displaying GPT partition attributes
      <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a> prefixes
      Microsoft partition attribute names with 'MS'.
  </li><li>In the absence of the 'disktype' command line parameter
      <a href="https://man.openbsd.org/disklabel.8">disklabel(8)</a>
      always uses the current media type provided by the kernel.
  </li><li>Ensure <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a> handles
      the case where a GPT partition name is not a valid C string.

  </li><li>When creating new crypto volumes with
      <a href="https://man.openbsd.org/bioctl.8">bioctl(8)</a>,
      by default use a hardware based number of KDF rounds for passphrases.
  </li><li>Let <a href="https://man.openbsd.org/bioctl.8">bioctl(8)</a>
      gracefully prompt again during interactive creation and
      passphrase change on CRYPTO and 1C volumes.
  </li><li>Let <a href="https://man.openbsd.org/bioctl.8">bioctl(8)</a>
      read passphrases without prompts or confirmation
      in <code>-s</code> mode, allowing non-interactive use.

  </li><li>Allow the <a href="https://man.openbsd.org/atactl.8">atactl(8)</a>
      command <a href="https://man.openbsd.org/atactl.8#readattr">readattr</a>
      to succeed even for disks where <code>ATA_SMART_READ</code> and
      <code>ATA_SMART_THRESHOLD</code> revisions mismatch, as long as
      checksums are OK.
  </li><li>In <a href="https://man.openbsd.org/ld.so.1">ld.so(1)</a>, treat
	symlinks in $ORIGIN determination the same way as other OS linkers do.
  </li><li>In <a href="https://man.openbsd.org/ld.so.1">ld.so(1)</a>,
	avoid an overflow in the ELF SYSV ABI hash function.
  </li><li>Make sure <a href="https://man.openbsd.org/modf.3">modf(3)</a> and
	<a href="https://man.openbsd.org/modff.3">modff(3)</a>
	return correct values for infinities.
  </li><li>Do not fail in
	<a href="https://man.openbsd.org/ober_scanf_elements.3">ober_scanf_elements(3)</a> when encountering empty sequences.
  </li><li>Remove broken special handling of <code>test -t</code> in
	<a href="https://man.openbsd.org/ksh.1">ksh(1)</a>.
  </li><li>The caching mechanism used by
	<a href="https://man.openbsd.org/pkg_add.1">pkg_add(1)</a>
	to speed up <tt>pkg_add -u</tt> now also works if -stable packages
	are available.
  </li><li>Significantly increase the speed of <a href="https://man.openbsd.org/pkg-config.1">pkg-config(1)</a>.
  </li><li>In <a href="https://man.openbsd.org/seq.1">seq(1)</a>,
	fix a check for rounding error and truncation.
  </li><li>In <a href="https://man.openbsd.org/cron.8">cron(8)</a>,
	introduce upstream fixes in the handling of @yearly, @monthly,
	@weekly, @daily and @hourly entries.
  </li><li>Fix a bug in <a href="https://man.openbsd.org/cron.8">cron(8)</a> where whitespace
	after usernames would not be completely skipped while parsing the
	<a href="https://man.openbsd.org/crontab.5">crontab(5)</a> file.
  </li><li>Make <a href="https://man.openbsd.org/rcctl.8">rcctl(8)</a>
	check if a daemon exists before trying to disable it, thereby avoiding
	parsing and printing of bogus characters.
  </li><li>Print to the console the fingerprint of a newly generated <a href="https://man.openbsd.org/ssh.1">ssh(1)</a> host key of the
	preferred type (currently ED25519), typically when booting for the
	first time.  This simplifies a secure first ssh connection to a
	freshly installed machine.
  </li></ul>

</li><li>Improved hardware support and driver bugfixes, including:
  <ul>
<!-- new drivers -->
  <li>Add <a href="https://man.openbsd.org/rkiovd.4">rkiovd(4)</a>,
      a driver for the I/O voltage domains on Rockchip SoCs.
  </li><li>Add support for TEMPerGold 3.4 temperature sensor to
      <a href="https://man.openbsd.org/ugold.4">ugold(4)</a>.
  </li><li>Add <a href="https://man.openbsd.org/qcrng.4">qcrng(4)</a>,
	a driver for the Qualcomm RNG device found on the ThinkPad X13s.
  </li><li>Add <a href="https://man.openbsd.org/rkusbphy.4">rkusbphy(4)</a>,
      a driver for the usb2phy on Rockchip SoCs.
  </li><li>Support AP806/CP110 SoCs in
	<a href="https://man.openbsd.org/mvtemp.4">mvtemp(4)</a>.
  </li><li>Add <a href="https://man.openbsd.org/dwmshc.4">dwmshc(4)</a>
	to support Designware Mobile Storage Host Controllers
	found on rk356x and rk3588 SoCs.
  </li><li>Add <a href="https://man.openbsd.org/iosf.4">iosf(4)</a>,
	a driver for the Intel OnChip System Fabric.
  </li><li>Add support for the RTL8153D chipset in
	<a href="https://man.openbsd.org/ure.4">ure(4)</a>.
  </li><li>Add support for the Peripheral Authentication Service SMC
	interface in <a href="https://man.openbsd.org/qcscm.4">qcscm(4)</a>.
  </li><li>Add <a href="https://man.openbsd.org/qcmtx.4">qcmtx(4)</a>,
	a driver for the hardware spinlock on Qualcomm
	SoCs that is used to synchronize access to the shared memory table.
  </li><li>Add <a href="https://man.openbsd.org/qcsmptp.4">qcsmptp(4)</a>,
	a driver to share 32-bit values between (co-)processors.
  </li><li>Add <a href="https://man.openbsd.org/qcaoss.4">qcaoss(4)</a>,
	a driver for the Always On Subsystem found on Qualcomm SoCs.
  </li><li>Add <a href="https://man.openbsd.org/qcpas.4">qcpas(4)</a>,
	a driver for the Peripheral Authentication Service
	found on Qualcomm SoCs.  Enable AC detection.
  </li><li>Add <a href="https://man.openbsd.org/qctsens.4">qctsens(4)</a>,
	a driver for the Temperature Sensor found on Qualcomm SoCs.
  </li><li>Add driver <a href="https://man.openbsd.org/qccpu.4">qccpu(4)</a>
	for QC CPU Power States.
  </li><li>Add <a href="https://man.openbsd.org/qcsdam.4">qcsdam(4)</a>,
	a driver for the PMIC Shared Direct Access Memory found on
	Qualcomm SoCs.
  </li><li>Add <a href="https://man.openbsd.org/stfrng.4">stfrng(4)</a>, a
	driver for the random number generator on the StarFive JH7110 SoC.
  </li><li>Add support for the PCIe controller on the JH7110 SoC with <a href="https://man.openbsd.org/stfpciephy.4">stfpciephy(4)</a>


<!-- other -->
  </li><li>New <a href="https://man.openbsd.org/sysctl.2">sysctl(2)</a>
      nodes for battery management, <code>hw.battery.charge*</code>.
      Support them with
      <a href="https://man.openbsd.org/acpithinkpad.4">acpithinkpad(4)</a>
      and <a href="https://man.openbsd.org/aplsmc.4">aplsmc(4)</a>.
  </li><li>Define fixed names for
      <a href="https://man.openbsd.org/ucom.4">ucom(4)</a> USB serial
      ports, display them in attach messages and via the new
      <code>hw.ucomnames</code>
      <a href="https://man.openbsd.org/sysctl.2#HW_UCOMNAMES~2">sysctl(2)</a>.
  </li><li>Add support for the RK3568 32k RTC, RK3588, and other clocks in
      <a href="https://man.openbsd.org/rkclock.4">rkclock(4)</a>.
  </li><li>In <a href="https://man.openbsd.org/dwpcie.4">dwpcie(4)</a>,
      attach Baikal-M PCIe.
  </li><li>In openfirmware, implement regulator notifiers which get called
	when the voltage/current for a regulator is changed or when the
	regulator gets initialized when it attaches for the first time. The
	latter makes it possible to register a notifier for a regulator that
	hasn't attached yet.
  </li><li>Ignore duplicate ACPI lid transitions as they can happen on Dell
	Precision 5510 systems.
  </li><li>Make RK3568 PCIe controllers run at the maximum possible speed
	by using dwpcie_link_config() when initializing.
  </li><li>In the Universal Flash Storage Host Controller Interface
      (<a href="https://man.openbsd.org/ufshci.4">ufshci(4)</a>),
      enable Force Unit Access (FUA) for write commands.
  </li><li>Make SATA (<a href="https://man.openbsd.org/ahci.4">ahci(4)</a>)
	work on a Banana Pi BPI-R2 Pro.
  </li><li>In <a href="https://man.openbsd.org/umcs.4">umcs(4)</a>, set
	parity bits correctly.
  </li><li>Enable the caps lock LED on modern Apple laptop keyboards.
  </li><li>Add support for Rockchip "cryptov2-rng" random number generator in
	<a href="https://man.openbsd.org/rkrng.4">rkrng(4)</a>.
  </li><li>Fix cpuperf on the Apple M2 Pro/Max.
  </li><li>Add support for the PCIe controller found on Apple M2 Pro/Max SoCs.
  </li><li>Add support for enabling both the USB2 and USB3 PHYs in
      <a href="https://man.openbsd.org/xhci.4">xhci(4)</a> with device tree.
  </li><li>In the SCSI tape driver
	<a href="https://man.openbsd.org/st.4">st(4)</a>, add support
	for I/O statistics so that tape speeds can be observed with
	<a href="https://man.openbsd.org/iostat.8">iostat(8)</a>.
  </li><li>Fix use of MMC/SD/SDIO on RK3588 ARM SoC in
	<a href="https://man.openbsd.org/dwmmc.4">dwmmc(4)</a>.
  </li><li>Support thermal sensors on Ryzen 9 79xx in
	<a href="https://man.openbsd.org/ksmn.4">ksmn(4)</a>.
  </li><li>Add support for JH7110 to
	<a href="https://man.openbsd.org/dwmmc.4">dwmmc(4)</a>,
	making eMMC and microSD mostly work on the Starfive VisionFive 2.
  </li><li>Add support for the RK3588 PCIe3 PHY to
	<a href="https://man.openbsd.org/rkpciephy.4">rkpciephy(4)</a>.
	The PHY controls 4 lanes that can be routed to 4 of 5 PCIe controllers.
  </li><li>Add mute control to
	<a href="https://man.openbsd.org/sncodec.4">sncodec(4)</a>.
	This makes the mute button work on laptops using this driver.
  </li><li>Add mute control to <a href="https://man.openbsd.org/tascodec.4">tascodec(4)</a>. This makes
	the mute button on laptops that use tascodec(4) work.
  </li><li>Improve the suspend/resume behavior of several drivers, reducing
	power consumption during suspend.
  </li><li>Add support for the Synopsys DesignWare I2C controller
	(<a href="https://man.openbsd.org/dwiic.4">dwiic(4)</a>) and the
	X-Powers AXP Power Management IC
	(<a href="https://man.openbsd.org/axppmic.4">axppmic(4)</a>).
  </li><li>Enable the <a href="https://man.openbsd.org/mbg.4">mbg(4)</a>
	timedelta sensor on amd64 and match the Meinberg PZF180PEX.
  </li></ul>

</li><li>New or improved network hardware support:
  <ul>
  <li>Fix <a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a>
      on several boards that use
      <a href="https://man.openbsd.org/rgephy.4">rgephy(4)</a> by configuring
	the RGMII interface before taking the PHY out of reset.
  </li><li>Improve <a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a> and
	determine PHY mode and pass the appropriate flags down to the PHY when
	attaching.
  </li><li>Report in <a href="https://man.openbsd.org/dmesg.8">dmesg(8)</a> on
      which gmac the <a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a>
      driver is attaching to.
  </li><li>Document that Intel i226 adapters are supported by
      <a href="https://man.openbsd.org/igc.4">igc(4)</a>.
  </li><li>Add <a href="https://man.openbsd.org/ngbe.4">ngbe(4)</a>,
      a driver for WangXun WX1860 PCI Express 10/100/1Gb Ethernet devices.
      Also support it on amd64 install media.
  </li><li>Add support for the RTL8211F-VD PHY in
      <a href="https://man.openbsd.org/rgephy.4">rgephy(4)</a>.
  </li><li>In openfirmware, add glue for network interfaces to be found by
	fdt/ofw node or phandle in order to support "switch chips" like the
	marvell link street.
  </li><li>Add support for RTL8153D devices to
      <a href="https://man.openbsd.org/ure.4">ure(4)</a>.
  </li><li>Provide byte and packet counter statistics in some
	<a href="https://man.openbsd.org/dwge.4">dwge(4)</a> implementations.
  </li><li>On <a href="https://man.openbsd.org/bge.4">bge(4)</a>, make hardware
	counters available via kstats for BCM5705 and newer controller chips.
  </li><li>Make several improvements to <a href="https://man.openbsd.org/vmx.4">vmx(4)</a>, the VMware VMXNET3
	Virtual Interface Controller.
  </li><li>In <a href="https://man.openbsd.org/em.4">em(4)</a>, stop
	putting multicast addresses into the Receive Address Registers.
	Instead hash them all into the Multicast Table Array. 
  </li><li>Support Mellanox ConnectX-6 Lx in <a href="https://man.openbsd.org/mcx.4">mcx(4)</a>.
  </li><li>In <a href="https://man.openbsd.org/mcx.4">mcx(4)</a>, add 100GB
	LR4 Ethernet capability and map it to IFM_100G_LR4.
  </li><li>Add initial support for Atlantic 2 hardware in
      <a href="https://man.openbsd.org/aq.4">aq(4)</a>.
  </li></ul>

</li><li>Added or improved wireless network drivers:
  <ul>
  <li>Improve how Quectel LTE&amp;5G devices attach to
      <a href="https://man.openbsd.org/umb.4">umb(4)</a>.
  </li></ul>

</li><li>IEEE 802.11 wireless stack improvements and bugfixes:
  <ul>
  <li> Add support for RTL8188FTV devices to the
      <a href="https://man.openbsd.org/urtwn.4">urtwn(4)</a> driver.
  </li><li>Attach Intel wireless devices with PCI product ID 0x51f1 to
      <a href="https://man.openbsd.org/iwx.4">iwx(4)</a>.
  </li><li>Fix a bug where <a href="https://man.openbsd.org/iwm.4">iwm(4)</a> and
      <a href="https://man.openbsd.org/iwx.4">iwx(4)</a> background
      scan tasks were added to the wrong task queue.
  </li><li>Fix a firmware error that occurred when an
      <a href="https://man.openbsd.org/iwx.4">iwx(4)</a> interface
      was brought down.
  </li><li>Fix <a href="https://man.openbsd.org/iwx.4">iwx(4)</a> firmware errors
      triggered during background scans.
  </li><li>Fix a crash in the <a href="https://man.openbsd.org/iwm.4">iwm(4)</a>
      driver when userland attempts to inject frames via bpf in monitor mode.
  </li></ul>

</li><li>Installer, upgrade and bootloader improvements:
  <ul>
  <li>In the arm64 ramdisk, simplify apple firmware copying to make it
	easier to add new firmware.
  </li><li>On armv7 and arm64, silence informational messages from
      <a href="https://man.openbsd.org/dd.1">dd(1)</a>
	when zeroing a disk's first 1MB. Use character not block devices with
	dd(1) like on other architectures.
  </li><li>Refactor the code of md_installboot() on armv7 and arm64 to be
	more in line with other architectures.
  </li><li>Improve the dialogue of the installer without affecting
      <a href="https://man.openbsd.org/autoinstall.8">autoinstall(8)</a>
       files.
  </li><li>Enable <a href="https://man.openbsd.org/ufshci.4">ufshci(4)</a>
      on arm64 install media.
  </li><li>On arm64 pine64 boards, stop writing pine64 firmware to disk.
  </li><li>When media has neither a GPT nor an MBR
      <a href="https://man.openbsd.org/installboot.8">installboot(8)</a>,
      assume OpenBSD occupies the entire disk starting at sector 0.
  </li><li>Attempt to not overflow the ramdisk when extracting firmware on
	Apple arm64 systems.
  </li><li>Add support for loading files from the EFI System Partition.
  </li><li>Fix a bug in the handling of SCSI drives in the bootloader on the luna88k architecture.
  </li><li>On luna88k, implement the chmod() signaling mechanism for
	<code>/bsd.upgrade</code> to prevent re-upgrade, like other
	architectures.


  </li><li>Support for <a href="https://man.openbsd.org/softraid.4">softraid(4)</a> disks in the
	installer was improved:
    <ul>
    <li>Make root on
      <a href="https://man.openbsd.org/softraid.4">softraid(4)</a>
      installations boot out of the box on Raspberry Pis (arm64).
    </li><li>Support installations with root on
      <a href="https://man.openbsd.org/softraid.4">softraid(4)</a>
      on arm64, tested on Pinebook Pro, Raspberry Pi 4b, and SolidRun CEX7.
    </li><li>On riscv64, enable softraid(4) in the ramdisk kernel and support
	installations with root on  
      <a href="https://man.openbsd.org/softraid.4">softraid(4)</a>
    </li><li>When installing on encrypted
	<a href="https://man.openbsd.org/softraid.4">softraid(4)</a>, determine
	the disk for placing the root device automatically and make it default
	as it is the only legit choice.
    </li><li>Add arm64 to the list of architectures with support for guided disk
        encryption.
    </li><li>Retain existing EFI System partitions on systems with APFSISC
      partitions (arm64 Apple M1/M2) during installation with root on
      <a href="https://man.openbsd.org/softraid.4">softraid(4)</a>.
    </li><li>Enable <a href="https://man.openbsd.org/softraid.4">softraid(4)</a> in ramdisk
	on the powerpc64 architecture.
    </li></ul>
  </li></ul>

</li><li>Security improvements:
  <ul>
  <li>Enable indirect branch tracking (IBT) on amd64 and branch target
      identification (BTI) on arm64 in both the kernel and in userland.
      On hardware that supports this feature, it helps enforcing
      control flow integrity by making sure malicious code
      cannot jump into the middle of a function. 
  </li><li>On the arm64 architecture, enable pointer authentication (PAC)
      in userland on those machines where it works correctly.
      It helps enforcing control flow integrity by making sure
      malicious code cannot manipulate a function's return address.
  </li><li>Together with retguard these two features protect against ROP attacks.
      Compiler defaults for base clang, ports clang and ports gcc (as well
      as some other non-C language family compilers in ports) have been
      changed to enable these features by default.  As a result the vast
      majority of programs on OpenBSD (and all programs in the base system)
      run with these security features enabled.
  </li><li>Change <a href="https://man.openbsd.org/malloc.3">malloc(3)</a>
      chunk sizes to be fine grained: chunk sizes are closer to the
      requested allocation size.
  </li><li>In <a href="https://man.openbsd.org/malloc.3">malloc(3)</a>,
      check all chunks in the delayed free list for write-after-free.
  </li><li>The <a href="https://man.openbsd.org/shutdown.8">shutdown(8)</a>
      program can now only be executed by members of the new
      <code>_shutdown</code> group.  The idea is that system
      administrators can now remove most users from the excessively
      powerful <code>operator</code> group, which in particular
      provides read access to disk device nodes.
  </li><li>Using <a href="https://man.openbsd.org/unveil.2">unveil(2)</a>,
	restrict <a href="https://man.openbsd.org/patch.1">patch(1)</a>
	filesystem access to the current directory including subdirectories,
	TMPDIR, and file names given on the command line.
  </li><li>In <a href="https://man.openbsd.org/ksh.1">ksh(1)</a>, consistently
      escape control characters when displaying file name completions,
      even when there are multiple matches.
  </li></ul>

</li><li>Changes in the network stack:
  <ul>
 <li>Sync the use of
     <a href="https://man.openbsd.org/getuptime.9">getuptime(9)</a>
     in the Neighbour Discovery (ND) code with ARP.
 </li><li>In the IPv6 forwarding code, call
     <a href="https://man.openbsd.org/getuptime.9">getuptime(9)</a>
     once for consistency with IPv4.
 </li><li>ARP has a queue of packets that should be sent after name
	resolution. Neighbor discovery (ND6) did only hold a single packet.
	Unified the code, added a queue to ND6 and made the code MP safe.
 </li><li>Implement a new <a href="https://man.openbsd.org/sysctl.2">sysctl(2)</a>
     <code>net.inet6.icmp6.nd6_queued</code> to show the number of packets
     waiting for an ND6 response, analogous to ARP.
 </li><li>When configuring a new IPv6 address on an interface, an upstream router
	doesn't know where to send traffic.  Send an unsolicited
	neighbor advertisement, as described in RFC9131, to the all-routers
	multicast address so all routers on the same link will learn the path
	back to the address.
 </li><li>Implement the inbound portion of RFC9131.  Let routers create new
	neighbor cache entries when receiving valid neighbor advertisements.

 </li><li>Initial support for TCP segmentation offload (TSO) and TCP large receive offload (LRO) was implemented:
   <ul>
   <li>If the driver of a network interface supports TSO,
	do not chop the packet in the network stack,
	but pass it down to the interface layer for TSO.
   </li><li>Provide a software TSO implementation, to be used as a fallback
	if network hardware does not support TSO.
   </li><li>Provide a new <a href="https://man.openbsd.org/sysctl.2">sysctl(2)</a>
	node <a href="https://man.openbsd.org/sysctl.2#tcp.tso">net.inet.tcp.tso</a> such that TSO can be globally disabled.
	By default, it is enabled on all interfaces supporting it.
   </li><li>In <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a>,
	display separate
	<a href="https://man.openbsd.org/ifconfig.8#hwfeatures">hwfeatures</a>
	for TSOv4, TSOv6, and LRO and provide a
	<a href="https://man.openbsd.org/ifconfig.8#tcplro">-tcplro</a>
	parameter to disable LRO on a per-interface basis.
   </li><li>Enable TSO and forwarding of LRO packets via TSO in
	<a href="https://man.openbsd.org/ix.4">ix(4)</a>.
   </li><li>In <a href="https://man.openbsd.org/ix.4">ix(4)</a>, allocate
	less memory for tx buffers.
   </li><li>Speed up TCP transfer on
	<a href="https://man.openbsd.org/lo.4">lo(4)</a>
	interfaces by using TSO and LRO.
   </li><li>Enable LRO per default in network
	drivers. LRO allows to receive aggregated packets larger than the MTU.
	Receiving TCP streams becomes much faster. Currently only <a href="https://man.openbsd.org/ix.4">ix(4)</a> and <a href="https://man.openbsd.org/lo.4">lo(4)</a> devices support LRO, and
	ix(4) is limited to IPv4 and hardware newer than the old 82598 model.
   </li></ul>

 </li><li>The following changes were made to the <a href="https://man.openbsd.org/pf.4">pf(4)</a> firewall:
   <ul>
   <li>Speed up the
	<a href="https://man.openbsd.org/ioctl.2">ioctl(2)</a> request
	<a href="https://man.openbsd.org/pf.4#DIOCGETRULE">DIOCGETRULE</a>
	such that <a href="https://man.openbsd.org/pfctl.8">pfctl(8)</a>
	can retrieve all <a href="https://man.openbsd.org/pf.4">pf(4)</a>
	rules from the kernel in linear rather than in quadratic time.
	To protect the kernel from memory exhaustion,
	userland processes now have to release tickets obtained with
	<a href="https://man.openbsd.org/pf.4#DIOCGETRULES">DIOCGETRULES</a>
	by issuing the new
	<a href="https://man.openbsd.org/ioctl.2">ioctl(2)</a> request
	<a href="https://man.openbsd.org/pf.4#DIOCXEND">DIOCXEND</a>.
	In particular, <a href="https://man.openbsd.org/snmpd.8">snmpd(8)</a>
	and <a href="https://man.openbsd.org/systat.1">systat(1)</a>
	now do that.
   </li><li>Relax the implementation of the <code>pass all</code> rule so all
	forms of neighbor advertisements are allowed in either direction.
   </li><li>When redirecting locally generated IP packets to userland with
	<a href="https://man.openbsd.org/pf.conf.5#divert-packet">divert-packet</a> rules, the packets may have no checksum
	due to hardware offloading.  Calculate the checksum in that case.
   </li><li>Fix a bug where
	<a href="https://man.openbsd.org/pf.conf.5#nat-to">nat-to</a>
	could fail to insert a state
	due to conflict on chosen source port number.
   </li><li>No longer ignore <code>keep state</code> and <code>nat-to</code>
	actions for unsolicited ICMP error responses. 
	Tighten the rule matching logic so ICMP error responses
	no longer match <code>keep state</code> rule.
	In typical scenarios, ICMP errors (if solicited) should match
	existing state.  The change is going to bite firewalls which deal
	with asymmetric routes. In those cases the <code>keep state</code>
	action should be relaxed to sloppy or new <code>no state</code>
	rule to explicitly match ICMP errors should be added.
   </li></ul>
 </li><li>Do not calculate IP, TCP, and UDP checksums on
	<a href="https://man.openbsd.org/lo.4">lo(4)</a> interfaces.
 </li><li>Convert the tcp_now() time counter to 64 bits to avoid 32 bits
	wrap around after changing tcp_now() ticks to milliseconds.
 </li><li>Add initial support for route-based IPsec VPNs.<br>
	Rather than use IPsec flows (aka, entries in the IPsec security
	policy database) to decide which traffic should be encapsulated in
	IPsec and sent to a peer, this changes security associations (SAs)
	so they can also refer to a tunnel interface. When traffic is routed
	over that tunnel interface, an IPsec SA is looked up and used to
	encapsulate traffic before being sent to the peer on the SA. When
	traffic is received from a peer using an interface SA, the specified
	interface is looked up and the packet is handed to it so it looks
	like packets come out of the tunnel.
 </li><li>Add <a href="https://man.openbsd.org/sec.4">sec(4)</a> to support
	route-based IPsec VPNs.
 </li><li>Introduce reference counting for TCP syn cache entries.
 </li><li>Have <a href="https://man.openbsd.org/wg.4">wg(4)</a> copy the
	priority from the inner packet to the outer encrypted packet, so that
	higher priority packets are picked from hfsc queues for earlier
	transmission.
 </li></ul>

</li><li>Routing daemons and other userland network improvements:
  <ul>
  <li>IPsec support was improved:
  <ul>
	<li>In <a href="https://man.openbsd.org/iked.8">iked(8)</a>,
	    support route-based
	    <a href="https://man.openbsd.org/sec.4">sec(4)</a> tunnels.
	</li><li>In <a href="https://man.openbsd.org/iked.8">iked(8)</a>,
	    add support to verify X.509 chain from CERT payloads.
	</li><li>In <a href="https://man.openbsd.org/iked.8">iked(8)</a>,
	    do not leak memory when receiving a CERT payload for pubkey auth
	    or for an invalid CERT Encoding.
	</li><li>In <a href="https://man.openbsd.org/iked.8">iked(8)</a>,
	    do not leak a file descriptor if
	    <a href="https://man.openbsd.org/open_memstream.3">open_memstream(3)</a> fails while trying to enable a child SA.
	</li><li>While trying to verify an ECDSA signature in
            <a href="https://man.openbsd.org/iked.8">iked(8)</a>,
	    correctly detect failure of DER encoding with
	    <a href="https://man.openbsd.org/i2d_ECDSA_SIG.3">i2d_ECDSA_SIG(3)</a>.
	</li><li>In <a href="https://man.openbsd.org/ipsecctl.8">ipsecctl(8)</a>,
	    support route-based IPsec VPN negotiation with
	    <a href="https://man.openbsd.org/sec.4">sec(4)</a>.
	</li><li>In <a href="https://man.openbsd.org/isakmpd.8">isakmpd(8)</a>,
	    support configuring interface SAs for route-based IPsec VPNs.
	</li><li>In <a href="https://man.openbsd.org/isakmpd.8">isakmpd(8)</a>
	    quick mode, do not crash with a <code>NULL</code> pointer
	    access when a group description is specified but it is invalid,
	    unsupported, or memory allocation or key generation fails.
	</li><li>In <a href="https://man.openbsd.org/isakmpd.8">isakmpd(8)</a>,
	    avoid a double free in the unlikely event that
	    <a href="https://man.openbsd.org/EC_KEY_check_key.3">EC_KEY_check_key(3)</a> fails right after generating
	    a new key pair.
	</li><li>Allow building
	    <a href="https://man.openbsd.org/isakmpd.8">isakmpd(8)</a>
	    with a libcrypto library that has
	    <a href="https://man.openbsd.org/OpenBSD-7.3/EC_GROUP_new.3">binary field support</a> ("GF2m") removed.
  </li></ul>

  </li><li>In <a href="https://man.openbsd.org/bgpd.8">bgpd(8)</a>,
  <ul>
	<li>Add first version of flowspec support. Right now only announcement
	    of flowspec rules is possible.
	</li><li>Update ASPA support to follow draft-ietf-sidrops-aspa-verification-16
	    and draft-ietf-sidrops-aspa-profile-16 by making the ASPA lookup
	    tables AFI-agnostic.
	</li><li>Rework UPDATE message generation to use the new ibuf API instead
	    of the hand-rolled solution before.
	</li><li>Fix <code>ext-community * *</code> matching which also affects
	    filters removing all ext-communities.
	</li><li>Improve and extend the bgpctl parser to handle commands like
	    <code>bgpctl show rib 192.0.2.0/24 detail</code>.
	    Also add various flowspec specific commands.
	</li><li>Introduce a semaphore to protect intermittent RTR session data
	    from being published to the RDE.
	</li><li>Limit the socket buffer size to 64k for all sessions.
	    Limiting the buffer size to a reasonable size ensures that not
	    too many updates end up queued in the TCP stack.
	</li><li>Adjust example <code>GRACEFUL_SHUTDOWN</code> filter rule in
	    the example config to only match on ebgp sessions.
  </li></ul>

  </li><li><a href="https://man.openbsd.org/rpki-client.8">rpki-client(8)</a> saw some changes:
  <ul>
	<li>A 30%-50% performance improvement was achieved through libcrypto's
	    partial chains certificate validation feature. Already validated
	    non-inheriting CA certificates are now marked as trusted roots. This
	    way it can be ensured that a leaf's delegated resources are properly
	    covered, and at the same time most validation paths are
	    significantly shortened.
	</li><li>Support for gzip and deflate HTTP Content-Encoding compression was
	    added. This allows web servers to send RRDP XML in compressed form,
	    saving around 50% of bandwidth.
	</li><li>ASPA support was updated to draft-ietf-sidrops-aspa-profile-16.
	    As part of supporting AFI-agnostic ASPAs, the JSON syntax for
	    Validated ASPA Payloads changed in both filemode and normal output.
	</li><li>In filemode (-f option) the applicable manifests are now shown as
	    part of the signature path.
	</li><li>A new -P option was added to manually specify a moment in time
	    to use when parsing the validity window of certificates. Useful
	    for regression testing. Default is invocation time of rpki-client.
	</li><li>The -A option will now also exclude ASPA data from the JSON output.
	</li><li>The synchronisation protocol used to sync the repository is now
	    included in the OpenMetrics output.
	</li><li>Improved accounting by tracking objects both by repo and tal.
	</li><li>Check whether products listed on a manifest were issued by the same
	    authority as the manifest itself.
	</li><li>File modification timestamps of objects retrieved via RRDP are now
	    deterministically set to prepare the on-disk cache for seamless
	    failovers from RRDP to RSYNC.
	</li><li>Improved detection of RRDP session desynchronization: a check was
	    added to compare whether the delta hashes associated to previously
	    seen serials are different in newly fetched notification files.
	</li><li>Improved handling of RRDP deltas in which objects are published,
	    withdrawn, and published again.
	</li><li>Disallow X.509 v2 issuer and subject unique identifiers in certs.
	    RPKI CAs will never issue certificates with V2 unique identifiers.
	</li><li>A check to disallow duplicate X.509 certificate extensions was
	    added.
	</li><li>A check to disallow empty sets of IP Addresses or AS numbers in RFC
	    3779 extensions was added.
	</li><li>A warning is printed when the CMS signing-time attribute in a Signed
	    Object is missing.
	</li><li>Warnings about unrecoverable message digest mismatches now include
	    the manifestNumber to aid debugging the cause.
	</li><li>A check was added to disallow multiple RRDP publish elements for the
	    same file in RRDP snapshots. If this error condition is encountered,
	    the RRDP transfer is failed and the RP falls back to rsync.
	</li><li>A compliance check for the proper X.509 Certificate version and CRL
	    version was added.
	</li><li>A compliance check was added to ensure CMS Signed Objects contain
	    SignedData, in accordance to RFC 6488 section 3 checklist item 1a.
	</li><li>Compliance checks were added for the version, KeyUsage, and
	    ExtendedKeyUsage of EE certificates in Manifest, TAK, and GBR Signed
	    Objects.
	</li><li>A CMS signing-time value being after the X.509 notAfter timestamp
	    was downgraded from an error to a warning.
	</li><li>A bug was fixed in the handling of CA certificates which inherit IP
	    resources.
	</li><li>A compliance check was added to ensure the X.509 Subject only
	    contains commonName and optionally serialNumber.
	</li><li>A compliance check was added to ensure the CMS SignedData and
	    SignerInfo versions to be 3.
	</li><li>Fisher-Yates shuffle the order in which Manifest entries are
	    processed. Previously, work items were enqueued in the order the CA
	    intended them to appear on a Manifest. However, there is no obvious
	    benefit to third parties deciding the order in which things are
	    processed.
  </li></ul>

  </li><li>In <a href="https://man.openbsd.org/smtpd.8">smtpd(8)</a>,
  <ul>
	<li>Swapped link-auth filter arguments to avoid ambiguities with user
	    names containing a "|" character.
	</li><li>Bumped <a href="https://man.openbsd.org/smtpd-filters.7">smtpd-filters(7)</a>
	    protocol version.
	</li><li>Fixed potential truncation of filtered data lines.
	</li><li>Allowed arguments on NOOP.
  </li></ul>

  </li><li>Many other changes in various network programs and libraries:
  <ul>
	<li>Let <a href="https://man.openbsd.org/pcap_fopen_offline.3">pcap_fopen_offline(3)</a> correctly interpret some
	      <code>LINKTYPE_*</code> values in pcap headers written
	      on foreign operating systems.
	  </li><li>Make <a href="https://man.openbsd.org/dig.1">dig(1)</a>
	      use less deprecated LibreSSL API.

	  </li><li>Remove stylistic differences between
	      <a href="https://man.openbsd.org/arp.8">arp(8)</a> and
	      <a href="https://man.openbsd.org/ndp.8">ndp(8)</a> delete()
		function.  This makes it easier to spot real changes in behavior.
	  </li><li>Make <a href="https://man.openbsd.org/ndp.8">ndp(8)</a>
	      not remove cloning routes when no neighbor entry is
		found with <code>ndp -d</code>.


	  </li><li>Improved error handling in the <a href="https://man.openbsd.org/asr_run.3">asr</a> resolver.

	  </li><li>In <a href="https://man.openbsd.org/unwind.8">unwind(8)</a>,
		handle SERVFAIL results on name resolution better.
	  </li><li>In <a href="https://man.openbsd.org/unwind.8">unwind(8)</a>,
		fix a use-after-free bug triggered by fatal write errors
		while sending TCP responses.

	  </li><li>In the router advertisement daemon
		<a href="https://man.openbsd.org/rad.8">rad(8)</a>, update the default
		timers for prefix preferred and valid lifetimes to use the values from
		RFC 9096.
	  </li><li>In <a href="https://man.openbsd.org/slaacd.8">slaacd(8)</a>,
		remove artificial limit of 2 hours on a PIO lifetime.

	  </li><li>In <a href="https://man.openbsd.org/ypldap.8">ypldap(8)</a>,
	      reduce memory usage when updating larger directories.
	  </li><li>Make <a href="https://man.openbsd.org/ypldap.8">ypldap(8)</a>
		more resilient when some servers are
		misbehaving: keep trying LDAP servers until full results arrive
		rather than just until one accepts the TCP connection.

	  </li><li>New <a href="https://man.openbsd.org/ifconfig.8#wgdescription">wgdescription</a> parameter to
	      <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a>
	      to set a string describing the
	      <a href="https://man.openbsd.org/wg.4">wg(4)</a> peer.

	  </li><li>Let <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a>
	      prefix the interface name to many error and warning messages.

	  </li><li>Make the <code>tlsv1.0</code> and <code>tlsv1.1</code> options
		in <a href="https://man.openbsd.org/relayd.8">relayd(8)</a>
		do nothing, as one should use the default <code>tlsv1.2</code>
		instead.
	  </li><li>Fix IPv6 routes being changed by
		<a href="https://man.openbsd.org/relayd.8">relayd(8)</a>
		with Routers configuration.

	  </li><li>In <a href="https://man.openbsd.org/dhcrelay6.8">dhcrelay6(8)</a>, do not
		ignore the AF_LINK entries of <a href="https://man.openbsd.org/carp.4">carp(4)</a> interfaces.

	  </li><li>Improve the config parser of
		<a href="https://man.openbsd.org/radiusd.8">radiusd(8)</a>
		to better handle
		comments, improve error messages and plug a memory leak.
	  </li><li>In <a href="https://man.openbsd.org/radiusd.8">radiusd(8)</a>,
		add request or response decoration feature which is used through the
		radiusd module interface.  This makes additional modules can modify
		RADIUS request or response messages.  Also add new "radius_standard"
		module which uses this new feature, provides some generic features
		like "strip-atmark-realm" which removes the realm part from the
		User-Name attribute.

	  </li><li>Allow UDP for built-in <a href="https://man.openbsd.org/inetd.8">inetd(8)</a> services on
		127.0.0.1. This restriction was added in year 2000 due to IPv6 compatible and
		mapped addresses.  Nowadays our kernel does not support these IPv6
		features and blocks localhost addresses on non-loopback interfaces.
		Make IPv4 127.0.0.1/8 and IPv6 ::1 behave identically and provide
		local services if configured.

	  </li><li>In <a href="https://man.openbsd.org/spamd.8">spamd(8)</a>, log a
		dummy "<unknown>" IP address in the unlikely event that getnameinfo(3)
		fails.
  </unknown></li></ul>
  </li></ul>

</li><li><a href="https://man.openbsd.org/tmux.1">tmux(1)</a> improvements and bug fixes:
  <ul>
  <li>For passthrough, don't write to clients attached to different sessions.
  </li><li>Add a format to show if there are unseen changes while in a mode.
  </li><li>Discard mouse sequences that have the right form but actually
	are invalid.
  </li><li>Invalidate cached tty state after changing features since they may
	change what the terminal can do and need mouse sequences or similar to
	be sent again.
  </li><li>Add options to change the confirm key and default behaviour of
	confirm-before.
  </li><li>Add an option menu-selected-style to configure the currently
	selected menu item.
  </li><li>Add -c to run-shell to set working directory.
  </li><li>Add detach-on-destroy previous and next,
  </li><li>Set visited flag on last windows when linking session.
  </li></ul>

</li><li>LibreSSL version 3.8.2
  <ul>
  <li>Security fixes
    <ul>
    <li>Disabled TLSv1.0 and TLSv1.1 in libssl so that they may no longer
      be selected for use.
    </li><li><a href="https://man.openbsd.org/BN_is_prime_ex.3">BN_is_prime_ex(3)</a>
      and BN_is_prime_fasttest_ex(3) refuse to check numbers larger than
      32 kbits for primality. This mitigates various DoS vectors.
    </li><li>Restricted the RFC 3779 code to IPv4 and IPv6. It was not written
      to be able to deal with anything else.
    </li></ul>
  </li><li>Portable changes
    <ul>
    <li>Extended the endian.h compat header with hto* and *toh macros.
    </li><li>Adapted more tests to the portable framework.
    </li><li>Internal tools are now statically linked.
    </li><li>Applications bundled as part of the LibreSSL package internally,
      <a href="https://man.openbsd.org/nc.1">nc(1)</a> and
      <a href="https://man.openbsd.org/openssl.1">openssl(1)</a>,
      now are linked statically if static libraries are built.
    </li><li>Internal compatibility function symbols are no longer exported from
      libcrypto. Instead, the libcompat library is linked to libcrypto,
      libssl, and libtls separately. This increases size a little, but
      ensures that the libraries are not exporting symbols to programs
      unintentionally.
    </li><li>Selective removal of CET implementation on platforms where it is
      not supported (macOS).
    </li><li>Integrated four more tests.
    </li><li>Added Windows ARM64 architecture to tested platforms.
    </li><li>Removed Solaris 10 support, fixed Solaris 11.
    </li><li>libtls no longer links statically to libcrypto / libssl unless
	    <code>--enable-libtls-only</code> is specified at configure time.
    </li><li>Improved Windows compatibility library, namely handling of files vs
      sockets, correcting an exception when operating on a closed socket.
    </li><li>CMake builds no longer hardcode <code>-O2</code> into the compiler flags,
      instead using flags from the CMake build type instead.
    </li><li>Set the CMake default build type to <code>Release</code>. This can be overridden
      during configuration.
    </li><li>Fixed broken ASM support with MinGW builds.
    </li></ul>
  </li><li>New features
    <ul>
    <li>Added support for
      <a href="https://man.openbsd.org/EVP_sha512_224.3">truncated SHA-2</a>
      and for <a href="https://man.openbsd.org/EVP_sha3_224.3">SHA-3</a>.
    </li><li>The BPSW primality test performs additional Miller-Rabin rounds
      with random bases to reduce the likelihood of composites passing.
    </li><li>Allow testing of ciphers and digests using badly aligned buffers
      in openssl speed using -unalign.
    </li><li>Ed25519 certificates are now supported in openssl(1)
      <a href="https://man.openbsd.org/openssl.1#ca">ca</a> and
      <a href="https://man.openbsd.org/openssl.1#req">req</a>.
      Prepared Ed25519 support in libssl.
    </li><li>Add branch target information (BTI) support to amd64 and arm64
      assembly.
    </li></ul>
  </li><li>Compatibility changes
    <ul>
    <li>Added a workaround for a poorly thought-out change in OpenSSL 3 that
      broke privilege separation support in libtls.
    </li><li>Moved libtls from ECDSA_METHOD to EC_KEY_METHOD.
    </li><li>Removed GF2m support: BIGNUM no longer supports binary extension
      field arithmetic and all binary elliptic builtin curves were removed.
    </li><li>Removed dangerous, "fast" NIST prime and elliptic curve implementations.
      In particular, EC_GFp_nist_method() is no longer available.
    </li><li>Removed most public symbols that were deprecated in OpenSSL 0.9.8.
    </li><li>Removed the public X9.31 API (RSA_X931_PADDING is still available).
    </li><li>Removed Cipher Text Stealing mode.
    </li><li>Removed ENGINE support, including ECDH_METHOD and ECDSA_METHOD.
    </li><li>Removed COMP, DSO, dynamic loading of conf modules and support for
      custom ex_data and error stacks.
    </li><li>Removed proxy certificate (RFC 3820) support.
    </li><li>Removed SXNET and NETSCAPE_CERT_SEQUENCE support including the
      openssl(1) nseq command.
    </li><li>ENGINE support was removed and OPENSSL_NO_ENGINE is set. In spite
      of this, some stub functions are provided to avoid patching some
      applications that do not honor OPENSSL_NO_ENGINE.
    </li><li>The POLICY_TREE and its related structures and API were removed.
    </li><li>In <a href="https://man.openbsd.org/X509_VERIFY_PARAM_inherit.3">X509_VERIFY_PARAM_inherit(3)</a>, copy hostflags independently of the
      host list.
    </li><li>Made <a href="https://man.openbsd.org/CRYPTO_get_ex_new_index.3">CRYPTO_get_ex_new_index(3)</a> not return 0 to allow applications
      to use *_{get,set}_app_data() and *_{get,set}_ex_data() alongside
      each other.
    </li><li><a href="https://man.openbsd.org/X509_NAME_get_text_by_NID.3">X509_NAME_get_text_by_NID(3)</a> and
      <a href="https://man.openbsd.org/X509_NAME_get_text_by_OBJ.3">X509_NAME_get_text_by_OBJ(3)</a> now only succeed if they contain
      valid UTF-8 without embedded NUL.
    </li><li>The explicitText user notice uses UTF8String instead of VisibleString
      to reduce the risk of emitting certificates with invalid DER-encoding.
    </li><li>Initial fixes for RSA-PSS support to make the TLSv1.3 stack more
      compliant with RFC 8446.
    </li><li>Fixed <a href="https://man.openbsd.org/EVP_CIPHER_CTX_iv_length.3">EVP_CIPHER_CTX_iv_length(3)</a> to return what was set with
      EVP_CTRL_AEAD_SET_IVLEN or one of its aliases.
    </li></ul>
  </li><li>Internal improvements
    <ul>
    <li>Improved sieve of Eratosthenes script used for generating a table
      of small primes.
    </li><li>Removed incomplete and dangerous BN_RECURSION code.
    </li><li>Imported RFC 5280 policy checking code from BoringSSL and used it
      to replace the old exponential time code.
    </li><li>Converted more of libcrypto to use CBB/CBS.
    </li><li>Started cleaning up and rewriting SHA internals.
    </li><li>Reduced the dependency of hash implementations on many layers of
      macros. This results in significant speedups since modern compilers
      are now less confused.
    </li><li>Improved BIGNUM internals and performance.
    </li><li>Significantly simplified the BN_BLINDING internals used in RSA.
    </li><li>Made <a href="https://man.openbsd.org/BN_num_bits.3">BN_num_bits(3)</a>
      independent of bn-&gt;top.
    </li><li>Rewrote and simplified bn_sqr().
    </li><li>Significantly improved Montgomery multiplication performance.
    </li><li>Rewrote and improved
      <a href="https://man.openbsd.org/BN_exp.3">BN_exp(3)</a> and
      <a href="https://man.openbsd.org/BN_copy.3">BN_copy(3)</a>.
    </li><li>Changed <a href="https://man.openbsd.org/ASN1_item_sign_ctx.3">ASN1_item_sign_ctx(3)</a> and
      <a href="https://man.openbsd.org/ASN1_item_verify.3">ASN1_item_verify(3)</a> to work with
      Ed25519 and fixed a few bugs in there.
    </li><li>Lots of cleanup for DH, DSA, EC, RSA internals.  Plugged numerous
      memory leaks, fixed logic errors and inconsistencies.
    </li><li>Cleaned up and simplified various ECDH and ECDSA internals.
    </li><li>Removed EC_GROUP precomp machinery.
    </li><li>Fixed various issues with
      <a href="https://man.openbsd.org/EVP_PKEY_CTX_new.3">EVP_PKEY_CTX_new(3)</a> and EVP_PKEY_CTX_dup(3).
    </li><li>Rewrote <a href="https://man.openbsd.org/OBJ_find_sigid_algs">OBJ_find_sigid_algs(3)</a> and OBJ_find_sigid_by_algs(3).
    </li><li>Improved X.509 certificate version checks.
    </li><li>Ensure no X.509v3 extensions appear more than once in certificates.
    </li><li>Replaced ASN1_bn_print with a cleaner internal implementation.
    </li><li>Fix OPENSSL_cpuid_setup() invocations on arm/aarch64.
    </li><li>Improved checks for commonName in libtls.
    </li><li>Fixed error check for
      <a href="https://man.openbsd.org/X509_get_ext_d2i.3">X509_get_ext_d2i(3)</a> failure in libtls.
    </li><li>Removed code guarded by #ifdef ZLIB.
    </li><li>Plug a potential memory leak in
      <a href="https://man.openbsd.org/ASN1_TIME_normalize.3">ASN1_TIME_normalize(3)</a>.
    </li><li>Fixed a use of uninitialized in i2r_IPAddrBlocks().
    </li><li>Rewrote <a href="https://man.openbsd.org/CMS_SignerInfo_sign.3">CMS_SignerInfo_sign(3)</a> and CMS_SignerInfo_verify(3).
    </li></ul>
  </li><li>Bug fixes
    <ul>
    <li>Correctly handle negative input to various BIGNUM functions.
    </li><li>Ensure ERR_load_ERR_strings() does not set errno unexpectedly.
    </li><li>Fix error checking of
      <a href="https://man.openbsd.org/i2d_ECDSA_SIG.3">i2d_ECDSA_SIG(3)</a>
      in ossl_ecdsa_sign().
    </li><li>Fixed aliasing issue in
      <a href="https://man.openbsd.org/BN_mod_inverse.3">BN_mod_inverse(3)</a>.  Disallowed aliasing of result
      and modulus in various BN_mod_* functions.
    </li><li>Fixed detection of extended operations (XOP) on AMD hardware.
    </li><li>Ensure Montgomery exponentiation is used for the initial RSA blinding.
    </li><li>Policy is always checked in X509 validation. Critical policy extensions
      are no longer silently ignored.
    </li><li>Fixed error handling in tls_check_common_name().
    </li><li>Add missing pointer invalidation in
      <a href="https://man.openbsd.org/SSL_free.3">SSL_free(3)</a>.
    </li><li>Fixed X509err() and X509V3err() and their internal versions.
    </li><li>Ensure that
      <a href="https://man.openbsd.org/OBJ_obj2txt.3">OBJ_obj2txt(3)</a>
      always returns a C string again.
    </li><li>Made <a href="https://man.openbsd.org/EVP_PKEY_CTX_set1_hkdf_key">EVP_PKEY_CTX_set1_hkdf_key(3)</a> fail on a NULL key.
    </li><li>On socket errors in the poll loop, netcat could issue system calls
      on invalidated file descriptors.
    </li><li>Allow IP addresses to be specified in a URI.
    </li><li>Fixed a copy-paste error in
      <a href="https://man.openbsd.org/ASN1_TIME_compare.3">ASN1_TIME_compare(3)</a> that could lead to two UTCTimes
      or two GeneralizedTimes incorrectly being compared as equal.
    </li></ul>
  </li><li>Documentation improvements
    <ul>
    <li>Improved documentation of BIO_ctrl(3), BIO_set_info_callback(3),
      BIO_get_info_callback(3), BIO_method_type(3), and BIO_method_name(3).
    </li><li>Marked BIO_CB_return(), BIO_cb_pre(), and BIO_cb_post() as intentionally
      undocumented.
    </li><li>Made it very explicit that the verify callback should not be used.
    </li><li>Called out that the CRL lastUpdate is standardized as thisUpdate.
    </li><li>Documented the RFC 3779 API and its shortcomings.
    </li></ul>
  </li><li>Testing and Proactive Security
    <ul>
    <li>Significantly improved test coverage of
      <a href="https://man.openbsd.org/BN_mod_sqrt.3">BN_mod_sqrt(3)</a>
      and GCD.
    </li><li>As always, new test coverage is added as bugs are fixed and subsystems
      are cleaned up.
    </li></ul>
  </li></ul>

</li><li>OpenSSH 9.5 and OpenSSH 9.4
  <ul>
  <li>Potentially incompatible changes
    <ul>
    <li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
        generate Ed25519 keys by default. Ed25519 public keys
        are very convenient due to their small size. Ed25519 keys are
        specified in RFC 8709 and OpenSSH has supported them since version 6.5
        (January 2014).
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        the Subsystem directive now accurately preserves quoting of
        subsystem commands and arguments. This may change behaviour for exotic
        configurations, but the most common subsystem configuration
        (sftp-server) is unlikely to be affected.
    </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>:
        PKCS#11 modules must now be specified by their full
        paths. Previously dlopen(3) could search for them in system
        library directories.
    </li></ul>
  </li><li>New features
    <ul>
    <li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        add keystroke timing obfuscation to the client. This attempts
        to hide inter-keystroke timings by sending interactive traffic at
        fixed intervals (default: every 20ms) when there is only a small
        amount of data being sent. It also sends fake "chaff" keystrokes for
        a random interval after the last real keystroke. These are
        controlled by a new ssh_config ObscureKeystrokeTiming keyword.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>,
        <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        Introduce a transport-level ping facility. This adds
        a pair of SSH transport protocol messages SSH2_MSG_PING/PONG to
        implement a ping capability. These messages use numbers in the "local
        extensions" number space and are advertised using a "ping@openssh.com"
        ext-info message with a string version number of "0".
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        allow override of Subsystem directives in sshd Match blocks.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        allow forwarding Unix Domain sockets via ssh -W.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        add support for configuration tags to ssh(1).
        This adds a ssh_config(5) "Tag" directive and corresponding
        "Match tag" predicate that may be used to select blocks of
        configuration similar to the pf.conf(5) keywords of the same
        name.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
         add a "match localnetwork" predicate. This allows matching
         on the addresses of available network interfaces and may be used to
         vary the effective client configuration based on network location.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>,
        <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>,
        <a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
        infrastructure support for KRL
        extensions.  This defines wire formats for optional KRL extensions
        and implements parsing of the new submessages. No actual extensions
        are supported at this point.
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        AuthorizedPrincipalsCommand and AuthorizedKeysCommand now
        accept two additional %-expansion sequences: %D which expands to
        the routing domain of the connected session and %C which expands
        to the addresses and port numbers for the source and destination
        of the connection.
    </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
        increase the default work factor (rounds) for the
        bcrypt KDF used to derive symmetric encryption keys for passphrase
        protected key files by 50%.
    </li></ul>
  </li><li>Bugfixes
    <ul>
    <li><a href="https://man.openbsd.org/scp.1">scp(1)</a>:
        fix scp in SFTP mode recursive upload and download of
        directories that contain symlinks to other directories. In scp mode,
        the links would be followed, but in SFTP mode they were not.
    </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
        handle cr+lf (instead of just cr) line endings in
        sshsig signature files.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        interactive mode for ControlPersist sessions if they
        originally requested a tty.
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        make PerSourceMaxStartups first-match-wins
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        limit artificial login delay to a reasonable maximum (5s)
        and don't delay at all for the "none" authentication mechanism.
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        Log errors in kex_exchange_identification() with level
        verbose instead of error to reduce preauth log spam. All of those
        get logged with a more generic error message by sshpkt_fatal().
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        correct math for ClientAliveInterval that caused the probes
        to be sent less frequently than configured.
    </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>:
        improve isolation between loaded PKCS#11 modules
        by running separate ssh-pkcs11-helpers for each loaded provider.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        make -f (fork after authentication) work correctly with
        multiplexed connections, including ControlPersist.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        make ConnectTimeout apply to multiplexing sockets and not
        just to network connections.
    </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>,
        <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        improve defences against invalid PKCS#11
        modules being loaded by checking that the requested module
        contains the required symbol before loading it.
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
        fix AuthorizedPrincipalsCommand when AuthorizedKeysCommand
        appears before it in sshd_config. Since OpenSSH 8.7 the
        AuthorizedPrincipalsCommand directive was incorrectly ignored in
        this situation.
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>,
        <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>,
        <a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
        remove vestigial support for KRL
        signatures When the KRL format was originally defined, it included
        support for signing of KRL objects. However, the code to sign KRLs
        and verify KRL signatures was never completed in OpenSSH. This
        release removes the partially-implemented code to verify KRLs.
        All OpenSSH tools now ignore KRL_SECTION_SIGNATURE sections in
        KRL files.
     </li><li>All: fix a number of memory leaks and unreachable/harmless integer
        overflows.
    </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>,
        <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        don't truncate strings logged from PKCS#11 modules
    </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>,
        <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        better validate CASignatureAlgorithms in
        ssh_config and sshd_config. Previously this directive would accept
        certificate algorithm names, but these were unusable in practice as
        OpenSSH does not support CA chains.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        make <code>ssh -Q CASignatureAlgorithms</code> only list signature
        algorithms that are valid for CA signing. Previous behaviour was
        to list all signing algorithms, including certificate algorithms.
    </li><li><a href="https://man.openbsd.org/ssh-keyscan.1">ssh-keyscan(1)</a>:
        gracefully handle systems where rlimits or the
        maximum number of open files is larger than INT_MAX
    </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
        fix "no comment" not showing on when running
        <code>ssh-keygen -l</code> on multiple keys where one has a comment
        and other following keys do not.
    </li><li><a href="https://man.openbsd.org/scp.1">scp(1)</a>,
        <a href="https://man.openbsd.org/sftp.1">sftp(1)</a>:
        adjust ftruncate() logic to handle servers that
        reorder requests. Previously, if the server reordered requests then
        the resultant file would be erroneously truncated.
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>:
        don't incorrectly disable hostname canonicalization when
        CanonicalizeHostname=yes and ProxyJump was explicitly set to
        "none".
    </li><li><a href="https://man.openbsd.org/scp.1">scp(1)</a>:
        when copying local to remote, check that the source file
        exists before opening an SFTP connection to the server.
    </li></ul>
  </li></ul>

</li><li>Ports and packages:
  <p>Many pre-built packages for each architecture:
  <!-- number of FTP packages minus SHA256, SHA256.sig, index.txt -->
  </p><ul>
    <li>aarch64:    11508
    </li><li>amd64:      11845
    </li><li>arm:        
    </li><li>i386:       10603
    </li><li>mips64:     
    </li><li>powerpc:    
    </li><li>powerpc64:  
    </li><li>riscv64:    
    </li><li>sparc64:    8469
  </li></ul>

  <p>Some highlights:
  </p><ul><!-- XXX all need to be checked/updated 2023-03-04 -->
    <li>Asterisk 16.30.1, 18.19.0 and 20.4.0
    </li><li>Audacity 3.3.3
    </li><li>CMake 3.27.5
    </li><li>Chromium 117.0.5938.149
    </li><li>Emacs 29.1
    </li><li>FFmpeg 4.4.4
    </li><li>GCC 8.4.0 and 11.2.0
    </li><li>GHC 9.2.7
    </li><li>GNOME 44
    </li><li>Go 1.21.1
    </li><li>JDK 8u382, 11.0.20 and 17.0.8
    </li><li>KDE Applications 23.08.0
    </li><li>KDE Frameworks 5.110.0
    </li><li>Krita 5.1.5
    </li><li>LLVM/Clang 13.0.0 and 16.0.6
    </li><li>LibreOffice 7.6.2.1
    </li><li>Lua 5.1.5, 5.2.4, 5.3.6 and 5.4.6
    </li><li>MariaDB 10.9.6
    </li><li>Mono 6.12.0.199
    </li><li>Mozilla Firefox 118.0.1 and ESR 115.3.1
    </li><li>Mozilla Thunderbird 115.3.1
    </li><li>Mutt 2.2.12 and NeoMutt 20230517
    </li><li>Node.js 18.18.0
    </li><li>OCaml 4.12.1
    </li><li>OpenLDAP 2.6.6
    </li><li>PHP 7.4.33, 8.0.30, 8.1.24 and 8.2.11
    </li><li>Postfix 3.7.3
    </li><li>PostgreSQL 15.4
    </li><li>Python 2.7.18, 3.9.18, 3.10.13 and 3.11.5
    </li><li>Qt 5.15.10 and 6.5.2
    </li><li>R 4.2.3
    </li><li>Ruby 3.0.6, 3.1.4 and 3.2.2
    </li><li>Rust 1.72.1
    </li><li>SQLite 3.42.0
    </li><li>Shotcut 23.07.29
    </li><li>Sudo 1.9.14.2
    </li><li>Suricata 6.0.12
    </li><li>Tcl/Tk 8.5.19 and 8.6.13
    </li><li>TeX Live 2022
    </li><li>Vim 9.0.1897 and Neovim 0.9.1
    </li><li>Xfce 4.18
  </li></ul>
  </li><li>As usual, steady improvements in manual pages and other documentation.

</li><li>The system includes the following major components from outside suppliers:
  <ul><!-- XXX all need to be checked/updated 2023-03-04 -->
    <li>Xenocara (based on X.Org 7.7 with xserver 21.1.8 + patches,
        freetype 2.13.0, fontconfig 2.14.2, Mesa 22.3.7, xterm 378,
        xkeyboard-config 2.20, fonttosfnt 1.2.2 and more)
    </li><li>LLVM/Clang 13.0.0 (+ patches)
    </li><li>GCC 4.2.1 (+ patches) and 3.3.6 (+ patches)
    </li><li>Perl 5.36.1 (+ patches)
    </li><li>NSD 4.7.0
    </li><li>Unbound 1.18.0
    </li><li>Ncurses 5.7
    </li><li>Binutils 2.17 (+ patches)
    </li><li>Gdb 6.3 (+ patches)
    </li><li>Awk September 12, 2023
    </li><li>Expat 2.5.0
    </li><li>zlib 1.3 (+ patches)
  </li></ul>

</li></ul>
</section>

<hr>

<section id="install">
<h3>How to install</h3>
<p>
Please refer to the following files on the mirror site for
extensive details on how to install OpenBSD 7.4 on your machine:

</p><ul>
<li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/alpha/INSTALL.alpha">
	.../OpenBSD/7.4/alpha/INSTALL.alpha</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/amd64/INSTALL.amd64">
	.../OpenBSD/7.4/amd64/INSTALL.amd64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/arm64/INSTALL.arm64">
	.../OpenBSD/7.4/arm64/INSTALL.arm64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/armv7/INSTALL.armv7">
	.../OpenBSD/7.4/armv7/INSTALL.armv7</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/hppa/INSTALL.hppa">
	.../OpenBSD/7.4/hppa/INSTALL.hppa</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/i386/INSTALL.i386">
	.../OpenBSD/7.4/i386/INSTALL.i386</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/landisk/INSTALL.landisk">
	.../OpenBSD/7.4/landisk/INSTALL.landisk</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/loongson/INSTALL.loongson">
	.../OpenBSD/7.4/loongson/INSTALL.loongson</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/luna88k/INSTALL.luna88k">
	.../OpenBSD/7.4/luna88k/INSTALL.luna88k</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/macppc/INSTALL.macppc">
	.../OpenBSD/7.4/macppc/INSTALL.macppc</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/octeon/INSTALL.octeon">
	.../OpenBSD/7.4/octeon/INSTALL.octeon</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/powerpc64/INSTALL.powerpc64">
	.../OpenBSD/7.4/powerpc64/INSTALL.powerpc64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/riscv64/INSTALL.riscv64">
	.../OpenBSD/7.4/riscv64/INSTALL.riscv64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.4/sparc64/INSTALL.sparc64">
	.../OpenBSD/7.4/sparc64/INSTALL.sparc64</a>
</li></ul>
</section>

<hr>

<section id="quickinstall">
<p>
Quick installer information for people familiar with OpenBSD, and the use of
the "<a href="https://man.openbsd.org/disklabel.8">disklabel</a> -E" command.
If you are at all confused when installing OpenBSD, read the relevant
INSTALL.* file as listed above!

</p><h3>OpenBSD/alpha:</h3>

<p>
If your machine can boot from CD, you can write <i>install74.iso</i> or
<i>cd74.iso</i> to a CD and boot from it.
Refer to INSTALL.alpha for more details.

</p><h3>OpenBSD/amd64:</h3>

<p>
If your machine can boot from CD, you can write <i>install74.iso</i> or
<i>cd74.iso</i> to a CD and boot from it.
You may need to adjust your BIOS options first.

</p><p>
If your machine can boot from USB, you can write <i>install74.img</i> or
<i>miniroot74.img</i> to a USB stick and boot from it.

</p><p>
If you can't boot from a CD, floppy disk, or USB,
you can install across the network using PXE as described in the included
INSTALL.amd64 document.

</p><p>
If you are planning to dual boot OpenBSD with another OS, you will need to
read INSTALL.amd64.

</p><h3>OpenBSD/arm64:</h3>

<p>
Write <i>install74.img</i> or <i>miniroot74.img</i> to a disk and boot from it
after connecting to the serial console.  Refer to INSTALL.arm64 for more
details.

</p><h3>OpenBSD/armv7:</h3>

<p>
Write a system specific miniroot to an SD card and boot from it after connecting
to the serial console.  Refer to INSTALL.armv7 for more details.

</p><h3>OpenBSD/hppa:</h3>

<p>
Boot over the network by following the instructions in INSTALL.hppa or the
<a href="https://www.openbsd.org/hppa.html#install">hppa platform page</a>.

</p><h3>OpenBSD/i386:</h3>

<p>
If your machine can boot from CD, you can write <i>install74.iso</i> or
<i>cd74.iso</i> to a CD and boot from it.
You may need to adjust your BIOS options first.

</p><p>
If your machine can boot from USB, you can write <i>install74.img</i> or
<i>miniroot74.img</i> to a USB stick and boot from it.

</p><p>
If you can't boot from a CD, floppy disk, or USB,
you can install across the network using PXE as described in
the included INSTALL.i386 document.

</p><p>
If you are planning on dual booting OpenBSD with another OS, you will need to
read INSTALL.i386.

</p><h3>OpenBSD/landisk:</h3>

<p>
Write <i>miniroot74.img</i> to the start of the CF
or disk, and boot normally.

</p><h3>OpenBSD/loongson:</h3>

<p>
Write <i>miniroot74.img</i> to a USB stick and boot bsd.rd from it
or boot bsd.rd via tftp.
Refer to the instructions in INSTALL.loongson for more details.

</p><h3>OpenBSD/luna88k:</h3>

<p>
Copy 'boot' and 'bsd.rd' to a Mach or UniOS partition, and boot the bootloader
from the PROM, and then bsd.rd from the bootloader.
Refer to the instructions in INSTALL.luna88k for more details.

</p><h3>OpenBSD/macppc:</h3>

<p>
Burn the image from a mirror site to a CDROM, and power on your machine
while holding down the <i>C</i> key until the display turns on and
shows <i>OpenBSD/macppc boot</i>.

</p><p>
Alternatively, at the Open Firmware prompt, enter <i>boot cd:,ofwboot
/7.4/macppc/bsd.rd</i>

</p><h3>OpenBSD/octeon:</h3>

<p>
After connecting a serial port, boot bsd.rd over the network via DHCP/tftp.
Refer to the instructions in INSTALL.octeon for more details.

</p><h3>OpenBSD/powerpc64:</h3>

<p>
To install, write <i>install74.img</i> or <i>miniroot74.img</i> to a
USB stick, plug it into the machine and choose the <i>OpenBSD
install</i> menu item in Petitboot.
Refer to the instructions in INSTALL.powerpc64 for more details.

</p><h3>OpenBSD/riscv64:</h3>

<p>
To install, write <i>install74.img</i> or <i>miniroot74.img</i> to a
USB stick, and boot with that drive plugged in.
Make sure you also have the microSD card plugged in that shipped with the
HiFive Unmatched board.
Refer to the instructions in INSTALL.riscv64 for more details.

</p><h3>OpenBSD/sparc64:</h3>

<p>
Burn the image from a mirror site to a CDROM, boot from it, and type
<i>boot cdrom</i>.

</p><p>
If this doesn't work, or if you don't have a CDROM drive, you can write
<i>floppy74.img</i> or <i>floppyB74.img</i>
(depending on your machine) to a floppy and boot it with <i>boot
floppy</i>. Refer to INSTALL.sparc64 for details.

</p><p>
Make sure you use a properly formatted floppy with NO BAD BLOCKS or your install
will most likely fail.

</p><p>
You can also write <i>miniroot74.img</i> to the swap partition on
the disk and boot with <i>boot disk:b</i>.

</p><p>
If nothing works, you can boot over the network as described in INSTALL.sparc64.
</p></section>

<hr>

<section id="upgrade">
<h3>How to upgrade</h3>
<p>
If you already have an OpenBSD 7.3 system, and do not want to reinstall,
upgrade instructions and advice can be found in the
<a href="https://www.openbsd.org/faq/upgrade74.html">Upgrade Guide</a>.
</p></section>

<hr>

<section id="sourcecode">
<h3>Notes about the source code</h3>
<p>
<code>src.tar.gz</code> contains a source archive starting at <code>/usr/src</code>.
This file contains everything you need except for the kernel sources,
which are in a separate archive.
To extract:
</p><blockquote><pre># <kbd>mkdir -p /usr/src</kbd>
# <kbd>cd /usr/src</kbd>
# <kbd>tar xvfz /tmp/src.tar.gz</kbd>
</pre></blockquote>
<p>
<code>sys.tar.gz</code> contains a source archive starting at <code>/usr/src/sys</code>.
This file contains all the kernel sources you need to rebuild kernels.
To extract:
</p><blockquote><pre># <kbd>mkdir -p /usr/src/sys</kbd>
# <kbd>cd /usr/src</kbd>
# <kbd>tar xvfz /tmp/sys.tar.gz</kbd>
</pre></blockquote>
<p>
Both of these trees are a regular CVS checkout.  Using these trees it
is possible to get a head-start on using the anoncvs servers as
described <a href="https://www.openbsd.org/anoncvs.html">here</a>.
Using these files
results in a much faster initial CVS update than you could expect from
a fresh checkout of the full OpenBSD source tree.
</p></section>

<hr>

<section id="ports">
<h3>Ports Tree</h3>
<p>
A ports tree archive is also provided.  To extract:
</p><blockquote><pre># <kbd>cd /usr</kbd>
# <kbd>tar xvfz /tmp/ports.tar.gz</kbd>
</pre></blockquote>
<p>
Go read the <a href="https://www.openbsd.org/faq/ports/index.html">ports</a> page
if you know nothing about ports
at this point.  This text is not a manual of how to use ports.
Rather, it is a set of notes meant to kickstart the user on the
OpenBSD ports system.
</p><p>
The <i>ports/</i> directory represents a CVS checkout of our ports.
As with our complete source tree, our ports tree is available via
<a href="https://www.openbsd.org/anoncvs.html">AnonCVS</a>.
So, in order to keep up to date with the -stable branch, you must make
the <i>ports/</i> tree available on a read-write medium and update the tree
with a command like:
</p><blockquote><pre># <kbd>cd /usr/ports</kbd>
# <kbd>cvs -d anoncvs@server.openbsd.org:/cvs update -Pd -rOPENBSD_7_4</kbd>
</pre></blockquote>
<p>
[Of course, you must replace the server name here with a nearby anoncvs
server.]
</p><p>
Note that most ports are available as packages on our mirrors. Updated
ports for the 7.4 release will be made available if problems arise.
</p><p>
If you're interested in seeing a port added, would like to help out, or just
would like to know more, the mailing list
<a href="https://www.openbsd.org/mail.html">ports@openbsd.org</a> is a good place to know.
</p></section>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Better HTTP server routing in Go 1.22 (111 pts)]]></title>
            <link>https://eli.thegreenplace.net/2023/better-http-server-routing-in-go-122/</link>
            <guid>37898999</guid>
            <pubDate>Mon, 16 Oct 2023 12:38:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eli.thegreenplace.net/2023/better-http-server-routing-in-go-122/">https://eli.thegreenplace.net/2023/better-http-server-routing-in-go-122/</a>, See on <a href="https://news.ycombinator.com/item?id=37898999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p>An <a href="https://github.com/golang/go/issues/61410">exciting proposal</a> is
expected to land in Go 1.22 - enhancing the pattern-matching capabilities of
the default HTTP serving multiplexer in the <tt>net/http</tt> package.</p>
<p>The existing multiplexer (<a href="https://pkg.go.dev/net/http#ServeMux">http.ServeMux</a>) offers rudimentary path matching, but
not much beyond that. This led to a cottage industry of 3rd party libraries
to implement more powerful capabilities. I've explored these options in my
<em>REST Servers in Go</em> series, in parts <a href="https://eli.thegreenplace.net/2021/rest-servers-in-go-part-1-standard-library/">1</a>
and <a href="https://eli.thegreenplace.net/2021/rest-servers-in-go-part-2-using-a-router-package/">2</a>.</p>
<p>The new multiplexer in 1.22 is going to significantly bridge the gap from 3rd
party packages by providing advanced matching. In this short post
I'll provide a quick introduction to the new multiplexer (mux).
I'll also revisit the example from the <em>REST Servers in
Go</em> series and compare how the new stdlib mux fares against <tt>gorilla/mux</tt>.</p>
<p><img alt="A cartoony go gopher holding a multiplexer" src="https://eli.thegreenplace.net/images/2023/cartoony-gopher-multiplexer.png"></p><div id="using-the-new-mux">
<h2>Using the new mux</h2>
<p>If you've ever used a 3rd party mux / router package for Go (like
<tt>gorilla/mux</tt>), using the new standard mux is going to be straightforward and
familiar. Start by reading <a href="https://pkg.go.dev/net/http@master#ServeMux">its documentation</a> - it's short and sweet.</p>
<p>Let's look at a couple of basic usage examples. Our first example demonstrates
some of the new pattern matching capabilities of the mux:</p>
<div><pre><span></span><span>package</span><span> </span><span>main</span><span></span>

<span>import</span><span> </span><span>(</span><span></span>
<span>  </span><span>"fmt"</span><span></span>
<span>  </span><span>"net/http"</span><span></span>
<span>)</span><span></span>

<span>func</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span><span></span>
<span>  </span><span>mux</span><span> </span><span>:=</span><span> </span><span>http</span><span>.</span><span>NewServeMux</span><span>()</span><span></span>
<span>  </span><span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"GET /path/"</span><span>,</span><span> </span><span>func</span><span>(</span><span>w</span><span> </span><span>http</span><span>.</span><span>ResponseWriter</span><span>,</span><span> </span><span>r</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>{</span><span></span>
<span>    </span><span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span><span> </span><span>"got path\n"</span><span>)</span><span></span>
<span>  </span><span>})</span><span></span>

<span>  </span><span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/task/{id}/"</span><span>,</span><span> </span><span>func</span><span>(</span><span>w</span><span> </span><span>http</span><span>.</span><span>ResponseWriter</span><span>,</span><span> </span><span>r</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>{</span><span></span>
<span>    </span><span>id</span><span> </span><span>:=</span><span> </span><span>r</span><span>.</span><span>PathValue</span><span>(</span><span>"id"</span><span>)</span><span></span>
<span>    </span><span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span><span> </span><span>"handling task with id=%v\n"</span><span>,</span><span> </span><span>id</span><span>)</span><span></span>
<span>  </span><span>})</span><span></span>

<span>  </span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>"localhost:8090"</span><span>,</span><span> </span><span>mux</span><span>)</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>Experienced Go programmers will notice two new features right away:</p>
<ol>
<li>In the first handler, the HTTP method (<tt>GET</tt> in this case) is specified
explicitly as part of the pattern. This means that this handler will only
trigger for <tt>GET</tt> requests to paths beginning with <tt>/path/</tt>, not for
other HTTP methods.</li>
<li>In the second handler, there's a wildcard in the second path component
- <tt>{id}</tt>, something that wasn't supported before. The wildcard will match
a single path component and the handler can then access the matched value
through the <tt>PathValue</tt> method of the request.</li>
</ol>
<p>Since Go 1.22 hasn't been released yet, I recommend running this sample with
<tt>gotip</tt>. Please see the <a href="https://github.com/eliben/code-for-blog/tree/master/2023/http-newmux-samples">complete code sample</a>
with full instructions for running this. Let's take this server for a ride:</p>

<p>And in a separate terminal we can issue some <tt>curl</tt> calls to test it:</p>
<div><pre><span></span>$ curl localhost:8090/what/
<span>404</span> page not found

$ curl localhost:8090/path/
got path

$ curl -X POST localhost:8090/path/
Method Not Allowed

$ curl localhost:8090/task/f0cd2e/
handling task with <span>id</span><span>=</span>f0cd2e
</pre></div>
<p>Note how the server rejects a <tt>POST</tt> request to <tt>/path/</tt>, while the (default
for <tt>curl</tt>) <tt>GET</tt> request is allowed. Note also how the <tt>id</tt> wildcard gets
assigned a value when the request matches. Once again, I encourage you to review
the <a href="https://pkg.go.dev/net/http@master#ServeMux">documentation of the new ServeMux</a>. You'll learn about additional
capabilities like matching trailing paths to a wildcard with <tt><span>{id}...</span></tt>,
strict matching of a path end with <tt>{$}</tt>, and other rules.</p>
<p>Particular care in the proposal was given to potential conflicts between
different patterns. Consider this setup:</p>
<div><pre><span></span><span>mux</span><span> </span><span>:=</span><span> </span><span>http</span><span>.</span><span>NewServeMux</span><span>()</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/task/{id}/status/"</span><span>,</span><span> </span><span>func</span><span>(</span><span>w</span><span> </span><span>http</span><span>.</span><span>ResponseWriter</span><span>,</span><span> </span><span>r</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>{</span><span></span>
<span>        </span><span>id</span><span> </span><span>:=</span><span> </span><span>r</span><span>.</span><span>PathValue</span><span>(</span><span>"id"</span><span>)</span><span></span>
<span>        </span><span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span><span> </span><span>"handling task status with id=%v\n"</span><span>,</span><span> </span><span>id</span><span>)</span><span></span>
<span>})</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/task/0/{action}/"</span><span>,</span><span> </span><span>func</span><span>(</span><span>w</span><span> </span><span>http</span><span>.</span><span>ResponseWriter</span><span>,</span><span> </span><span>r</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>{</span><span></span>
<span>        </span><span>action</span><span> </span><span>:=</span><span> </span><span>r</span><span>.</span><span>PathValue</span><span>(</span><span>"action"</span><span>)</span><span></span>
<span>        </span><span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span><span> </span><span>"handling task 0 with action=%v\n"</span><span>,</span><span> </span><span>action</span><span>)</span><span></span>
<span>})</span><span></span>
</pre></div>
<p>And suppose the server receives a request for <tt>/task/0/status/</tt> -- which
handler should it go to? It matches both! Therefore, the new <tt>ServeMux</tt>
documentation meticulously describes the <em>precedence rules</em> for patterns, along
with potential conflicts. In case of a conflict, the registration panics.
Indeed, for the example above we get something like:</p>
<div><pre><span></span>panic: pattern "/task/0/{action}/" (registered at sample-conflict.go:14) conflicts with pattern "/task/{id}/status/" (registered at sample-conflict.go:10):
/task/0/{action}/ and /task/{id}/status/ both match some paths, like "/task/0/status/".
But neither is more specific than the other.
/task/0/{action}/ matches "/task/0/action/", but /task/{id}/status/ doesn't.
/task/{id}/status/ matches "/task/id/status/", but /task/0/{action}/ doesn't.
</pre></div>
<p>The message is detailed and helpful. If we encounter conflicts in complex
registration schemes (especially when patterns are registered in multiple places
in the source code), such details will be much appreciated.</p>
</div>
<div id="redoing-my-task-server-with-the-new-mux">
<h2>Redoing my task server with the new mux</h2>
<p>The <em>REST Servers in Go</em> series implements a simple server for a task/todo-list
application in Go, using several different approaches. <a href="https://eli.thegreenplace.net/2021/rest-servers-in-go-part-1-standard-library/">Part 1</a>
starts with a "vanilla" standard library approach, and <a href="https://eli.thegreenplace.net/2021/rest-servers-in-go-part-2-using-a-router-package/">Part 2</a>
reimplements the same server using the <a href="https://github.com/gorilla/mux">gorilla/mux</a> router.</p>
<p>Now is a great time to reimplement it once again, but with the enhanced mux
from Go 1.22; it will be particularly interesting to compare the solution to
the one using <tt>gorilla/mux</tt>.</p>
<p>The full code for this project is <a href="https://github.com/eliben/code-for-blog/tree/master/2021/go-rest-servers/stdlib-newmux">available here</a>.
Let's look at a few representative code samples, starting with the pattern
registration <a href="#footnote-1" id="footnote-reference-1">[1]</a>:</p>
<div><pre><span></span><span>mux</span><span> </span><span>:=</span><span> </span><span>http</span><span>.</span><span>NewServeMux</span><span>()</span><span></span>
<span>server</span><span> </span><span>:=</span><span> </span><span>NewTaskServer</span><span>()</span><span></span>

<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"POST /task/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>createTaskHandler</span><span>)</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"GET /task/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>getAllTasksHandler</span><span>)</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"DELETE /task/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>deleteAllTasksHandler</span><span>)</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"GET /task/{id}/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>getTaskHandler</span><span>)</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"DELETE /task/{id}/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>deleteTaskHandler</span><span>)</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"GET /tag/{tag}/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>tagHandler</span><span>)</span><span></span>
<span>mux</span><span>.</span><span>HandleFunc</span><span>(</span><span>"GET /due/{year}/{month}/{day}/"</span><span>,</span><span> </span><span>server</span><span>.</span><span>dueHandler</span><span>)</span><span></span>
</pre></div>
<p>Just like in the <tt>gorilla/mux</tt> sample, here we use specific HTTP methods
to route requests (with the same path) to different handlers; with the older
<tt>http.ServeMux</tt>, such matchers had to go to the same handler, which would then
decide what to do based on the method.</p>
<p>Let's also look at one of the handlers:</p>
<div><pre><span></span><span>func</span><span> </span><span>(</span><span>ts</span><span> </span><span>*</span><span>taskServer</span><span>)</span><span> </span><span>getTaskHandler</span><span>(</span><span>w</span><span> </span><span>http</span><span>.</span><span>ResponseWriter</span><span>,</span><span> </span><span>req</span><span> </span><span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span><span> </span><span>{</span><span></span>
<span>  </span><span>log</span><span>.</span><span>Printf</span><span>(</span><span>"handling get task at %s\n"</span><span>,</span><span> </span><span>req</span><span>.</span><span>URL</span><span>.</span><span>Path</span><span>)</span><span></span>

<span>  </span><span>id</span><span>,</span><span> </span><span>err</span><span> </span><span>:=</span><span> </span><span>strconv</span><span>.</span><span>Atoi</span><span>(</span><span>req</span><span>.</span><span>PathValue</span><span>(</span><span>"id"</span><span>))</span><span></span>
<span>  </span><span>if</span><span> </span><span>err</span><span> </span><span>!=</span><span> </span><span>nil</span><span> </span><span>{</span><span></span>
<span>    </span><span>http</span><span>.</span><span>Error</span><span>(</span><span>w</span><span>,</span><span> </span><span>"invalid id"</span><span>,</span><span> </span><span>http</span><span>.</span><span>StatusBadRequest</span><span>)</span><span></span>
<span>    </span><span>return</span><span></span>
<span>  </span><span>}</span><span></span>

<span>  </span><span>task</span><span>,</span><span> </span><span>err</span><span> </span><span>:=</span><span> </span><span>ts</span><span>.</span><span>store</span><span>.</span><span>GetTask</span><span>(</span><span>id</span><span>)</span><span></span>
<span>  </span><span>if</span><span> </span><span>err</span><span> </span><span>!=</span><span> </span><span>nil</span><span> </span><span>{</span><span></span>
<span>    </span><span>http</span><span>.</span><span>Error</span><span>(</span><span>w</span><span>,</span><span> </span><span>err</span><span>.</span><span>Error</span><span>(),</span><span> </span><span>http</span><span>.</span><span>StatusNotFound</span><span>)</span><span></span>
<span>    </span><span>return</span><span></span>
<span>  </span><span>}</span><span></span>

<span>  </span><span>renderJSON</span><span>(</span><span>w</span><span>,</span><span> </span><span>task</span><span>)</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>It extracts the ID value from <tt><span>req.PathValue("id")</span></tt>, similarly to the Gorilla
approach; however, since we don't have a regexp specifying that <tt>{id}</tt> only
matches integers, we have to pay attention to errors returned from
<tt>strconv.Atoi</tt>.</p>
<p>All and all, the end result is remarkably similar to the solution that uses
<tt>gorilla/mux</tt> from <a href="https://eli.thegreenplace.net/2021/rest-servers-in-go-part-2-using-a-router-package/">part 2</a>.
The handlers are much better separated than in the vanilla stdlib approach,
because the mux now can do much more sophisticated routing, without leaving many
of the routing decisions to the handlers themselves.</p>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>"Which router package should I use?" has always been a FAQ for beginner Go
programmers. I believe the common answers to this question will shift after
Go 1.22 is released, as many will find the new stdlib mux sufficient for their
needs without resorting to 3rd party packages.</p>
<p>Others will stick to familiar 3rd party packages, and that's totally fine.
Routers like <tt>gorilla/mux</tt> still provide more capabilities than the standard
library; on top of it, many Go programmers opt for lightweight frameworks like
Gin, which provide a router but also additional tools for building web backends.</p>
<p>All in all, this is certainly a positive change for all Go users. Making the
standard library more capable is a net positive for the entire community,
whether people use 3rd party packages or stick to just the standard library.</p>
<hr>
<table id="footnote-1">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1">[1]</a></td><td>You may have noticed that these patterns aren't very strict w.r.t
path parts that come after the part we care about (e.g.
<tt>/task/22/foobar</tt>). This is in line with the rest of the series, but
the new <tt>http.ServeMux</tt> makes it very easy to restrict the paths with
a trailing <tt>{$}</tt> wildcard, if needed.</td></tr>
</tbody>
</table>
</div>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C Is Not a Low-level Language – Your computer is not a fast PDP-11 (217 pts)]]></title>
            <link>https://queue.acm.org/detail.cfm?id=3212479</link>
            <guid>37897946</guid>
            <pubDate>Mon, 16 Oct 2023 10:46:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://queue.acm.org/detail.cfm?id=3212479">https://queue.acm.org/detail.cfm?id=3212479</a>, See on <a href="https://news.ycombinator.com/item?id=37897946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>

<p><a href="https://queue.acm.org/"><img src="https://queue.acm.org/img/acmqueue_logo.gif"></a>
</p></div>


<p><label>April 30, 2018<br><b><a href="https://queue.acm.org/issuedetail.cfm?issue=3212477">Volume 16, issue 2 </a></b></label></p><p>

&nbsp;
<a href="http://portal.acm.org/citation.cfm?id=3212479">
<img src="https://queue.acm.org/img/icon_pdf.png" alt="Download PDF version of this article">
PDF
</a>
</p>

<h2>Your computer is not a fast PDP-11.</h2>
<h3>David Chisnall</h3>
<p>In the wake of the recent Meltdown and Spectre vulnerabilities, it's worth spending some time looking at root causes. Both of these vulnerabilities involved processors speculatively executing instructions past some kind of access check and allowing the attacker to observe the results via a side channel. The features that led to these vulnerabilities, along with several others, were added to let C programmers continue to believe they were programming in a low-level language, when this hasn't been the case for decades.</p>
<p>Processor vendors are not alone in this. Those of us working on C/C++ compilers have also participated.</p>
<h3>What Is a Low-Level Language?</h3>
<p>Computer science pioneer Alan Perlis defined low-level languages this way:</p>
<p>"A programming language is low level when its programs require attention to the irrelevant."<sup>5</sup></p>
<p>While, yes, this definition applies to C, it does not capture what people desire in a low-level language. Various attributes cause people to regard a language as low-level. Think of programming languages as belonging on a continuum, with assembly at one end and the interface to the Starship<i> Enterprise</i>'s computer at the other. Low-level languages are "close to the metal," whereas high-level languages are closer to how humans think.</p>
<p>For a language to be "close to the metal," it must provide an abstract machine that maps easily to the abstractions exposed by the target platform. It's easy to argue that C was a low-level language for the PDP-11. They both described a model in which programs executed sequentially, in which memory was a flat space, and even the pre- and post-increment operators cleanly lined up with the PDP-11 addressing modes.</p>
<h3>Fast PDP-11 Emulators</h3>
<p>The root cause of the Spectre and Meltdown vulnerabilities was that processor architects were trying to build not just fast processors, but fast processors that expose the same abstract machine as a PDP-11. This is essential because it allows C programmers to continue in the belief that their language is close to the underlying hardware.</p>
<p>C code provides a mostly serial abstract machine (until C11, an entirely serial machine if nonstandard vendor extensions were excluded). Creating a new thread is a library operation known to be expensive, so processors wishing to keep their execution units busy running C code rely on ILP (instruction-level parallelism). They inspect adjacent operations and issue independent ones in parallel. This adds a significant amount of complexity (and power consumption) to allow programmers to write mostly sequential code. In contrast, GPUs achieve very high performance without any of this logic, at the expense of requiring explicitly parallel programs.</p>
<p>The quest for high ILP was the direct cause of Spectre and Meltdown. A modern Intel processor has up to 180 instructions in flight at a time (in stark contrast to a sequential C abstract machine, which expects each operation to complete before the next one begins). A typical heuristic for C code is that there is a branch, on average, every seven instructions. If you wish to keep such a pipeline full from a single thread, then you must guess the targets of the next 25 branches. This, again, adds complexity; it also means that an incorrect guess results in work being done and then discarded, which is not ideal for power consumption. This discarded work has visible side effects, which the Spectre and Meltdown attacks could exploit.</p>
<p>On a modern high-end core, the register rename engine is one of the largest consumers of die area and power. To make matters worse, it cannot be turned off or power gated while any instructions are running, which makes it inconvenient in a dark silicon era when transistors are cheap but powered transistors are an expensive resource. This unit is conspicuously absent on GPUs, where parallelism again comes from multiple threads rather than trying to extract instruction-level parallelism from intrinsically scalar code. If instructions do not have dependencies that need to be reordered, then register renaming is not necessary.</p>
<p>Consider another core part of the C abstract machine's memory model: flat memory. This hasn't been true for more than two decades. A modern processor often has three levels of cache in between registers and main memory, which attempt to hide latency.</p>
<p>The cache is, as its name implies, hidden from the programmer and so is not visible to C. Efficient use of the cache is one of the most important ways of making code run quickly on a modern processor, yet this is completely hidden by the abstract machine, and programmers must rely on knowing implementation details of the cache (for example, two values that are 64-byte-aligned may end up in the same cache line) to write efficient code.</p>
<h3>Optimizing C</h3>
<p>One of the common attributes ascribed to low-level languages is that they're fast. In particular, they should be easy to translate into fast code without requiring a particularly complex compiler. The argument that a sufficiently smart compiler can make a language fast is one that C proponents often dismiss when talking about other languages.</p>
<p>Unfortunately, simple translation providing fast code is not true for C. In spite of the heroic efforts that processor architects invest in trying to design chips that can run C code fast, the levels of performance expected by C programmers are achieved only as a result of incredibly complex compiler transforms. The Clang compiler, including the relevant parts of LLVM, is around 2 million lines of code. Even just counting the analysis and transform passes required to make C run quickly adds up to almost 200,000 lines (excluding comments and blank lines).</p>
<p>For example, in C, processing a large amount of data means writing a loop that processes each element sequentially. To run this optimally on a modern CPU, the compiler must first determine that the loop iterations are independent. The C <code>restrict</code> keyword can help here. It guarantees that writes through one pointer do not interfere with reads via another (or if they do, that the programmer is happy for the program to give unexpected results). This information is far more limited than in a language such as Fortran, which is a big part of the reason that C has failed to displace Fortran in high-performance computing.</p>
<p>Once the compiler has determined that loop iterations are independent, then the next step is to attempt to vectorize the result, because modern processors get four to eight times the throughput in vector code that they achieve in scalar code. A low-level language for such processors would have native vector types of arbitrary lengths. LLVM IR (intermediate representation) has precisely this, because it is always easier to split a large vector operation into smaller ones than to construct larger vector operations.</p>
<p>Optimizers at this point must fight the C memory layout guarantees. C guarantees that structures with the same prefix can be used interchangeably, and it exposes the offset of structure fields into the language. This means that a compiler is not free to reorder fields or insert padding to improve vectorization (for example, transforming a structure of arrays into an array of structures or vice versa). That's not necessarily a problem for a low-level language, where fine-grained control over data structure layout is a feature, but it does make it harder to make C fast.</p>
<p>C also requires padding at the end of a structure because it guarantees no padding in arrays. Padding is a particularly complex part of the C specification and interacts poorly with other parts of the language. For example, you must be able to compare two <code>struct</code>s using a type-oblivious comparison (e.g., <code>memcmp</code>), so a copy of a <code>struct</code> must retain its padding. In some experimentation, a noticeable amount of total runtime on some workloads was found to be spent in copying padding (which is often awkwardly sized and aligned).</p>
<p>Consider two of the core optimizations that a C compiler performs: SROA (scalar replacement of aggregates) and loop unswitching. SROA attempts to replace <code>struct</code>s (and arrays with fixed lengths) with individual variables. This then allows the compiler to treat accesses as independent and elide operations entirely if it can prove that the results are never visible. This has the side effect of deleting padding in some cases but not others.</p>
<p>The second optimization, loop unswitching, transforms a loop containing a conditional into a conditional with a loop in both paths. This changes flow control, contradicting the idea that a programmer knows what code will execute when low-level language code runs. It can also cause significant problems with C's notions of unspecified values and undefined behavior.</p>
<p>In C, a read from an uninitialized variable is an unspecified value and is allowed to be any value each time it is read. This is important, because it allows behavior such as lazy recycling of pages: for example, on FreeBSD the <code>malloc</code> implementation informs the operating system that pages are currently unused, and the operating system uses the first write to a page as the hint that this is no longer true. A read to newly <code>malloc</code>ed memory may initially read the old value; then the operating system may reuse the underlying physical page; and then on the next write to a different location in the page replace it with a newly zeroed page. The second read from the same location will then give a zero value.</p>
<p>If an unspecified value for flow control is used (for example, using it as the condition in an <code>if</code> statement), then the result is undefined behavior: anything is allowed to happen. Consider the loop-unswitching optimization, this time in the case where the loop ends up being executed zero times. In the original version, the entire body of the loop is dead code. In the unswitched version, there is now a branch on the variable, which may be uninitialized. Some dead code has now been transformed into undefined behavior. This is just one of many optimizations that a close investigation of the C semantics shows to be unsound.</p>
<p>In summary, it is possible to make C code run quickly but only by spending thousands of person-years building a sufficiently smart compiler—and even then, only if you violate some of the language rules. Compiler writers let C programmers pretend that they are writing code that is "close to the metal" but must then generate machine code that has very different behavior if they want C programmers to keep believing that they are using a fast language.</p>
<h3>Understanding C</h3>
<p>One of the key attributes of a low-level language is that programmers can easily understand how the language's abstract machine maps to the underlying physical machine. This was certainly true on the PDP-11, where each C expression mapped trivially to one or two instructions. Similarly, the compiler performed a straightforward lowering of local variables to stack slots and mapped primitive types to things that the PDP-11 could operate on natively.</p>
<p>Since then, implementations of C have had to become increasingly complex to maintain the illusion that C maps easily to the underlying hardware and gives fast code. A 2015 survey of C programmers, compiler writers, and standards committee members raised several issues about the comprehensibility of C.<sup>3</sup> For example, C permits an implementation to insert padding into structures (but not into arrays) to ensure that all fields have a useful alignment for the target. If you zero a structure and then set some of the fields, will the padding bits all be zero? According to the results of the survey, 36 percent were sure that they would be, and 29 percent didn't know. Depending on the compiler (and optimization level), it may or may not be.</p>
<p>This is a fairly trivial example, yet a significant proportion of programmers either believe the wrong thing or are not sure. When you introduce pointers, the semantics of C become a lot more confusing. The BCPL model was fairly simple: values are words. Each word is either some data or the address of some data. Memory is a flat array of storage cells indexed by address.</p>
<p>The C model, in contrast, was intended to allow implementation on a variety of targets, including segmented architectures (where a pointer might be a segment ID and an offset) and even garbage-collected virtual machines. The C specification is careful to restrict valid operations on pointers to avoid problems for such systems. The response to Defect Report 260<sup>1</sup> included the notion of <i>pointer provenance</i> in the definition of pointer:</p>
<blockquote>
<p>"Implementations are permitted to track the origins of a bit pattern and treat those representing an indeterminate value as distinct from those representing a determined value. They may also treat pointers based on different origins as distinct even though they are bitwise identical."</p>
</blockquote>
<p>Unfortunately, the word <i>provenance</i> does not appear in the C11 specification at all, so it is up to compiler writes to decide what it means. GCC (GNU Compiler Collection) and Clang, for example, differ on whether a pointer that is converted to an integer and back retains its provenance through the casts. Compilers are free to determine that two pointers to different <code>malloc</code> results or stack allocations always compare as not-equal, even when a bitwise comparison of the pointers may show them to describe the same address.</p>
<p>These misunderstandings are not purely academic in nature. For example, security vulnerabilities have been observed from signed integer overflow (undefined behavior in C) and from code that dereferenced a pointer before a null check, indicating to the compiler that the pointer could not be null because dereferencing a null pointer is undefined behavior in C and therefore can be assumed not to happen (https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2009-1897).</p>
<p>In light of such issues, it is difficult to argue that a programmer can be expected to understand exactly how a C program will map to an underlying architecture.</p>
<h3>Imagining a Non-C Processor</h3>
<p>The proposed fixes for Spectre and Meltdown impose significant performance penalties, largely offsetting the advances in microarchitecure in the past decade. Perhaps it's time to stop trying to make C code fast and instead think about what programming models would look like on a processor designed to be fast. </p>
<p>We have a number of examples of designs that have not focused on traditional C code to provide some inspiration. For example, highly multithreaded chips, such as Sun/Oracle's UltraSPARC Tx series, don't require as much cache to keep their execution units full. Research processors<sup>2</sup> have extended this concept to very large numbers of hardware-scheduled threads. The key idea behind these designs is that with enough high-level parallelism, you can suspend the threads that are waiting for data from memory and fill your execution units with instructions from others. The problem with such designs is that C programs tend to have few busy threads.</p>
<p>ARM's SVE (Scalar Vector Extensions)—and similar work from Berkeley<sup>4</sup>—provides another glimpse at a better interface between program and hardware. Conventional vector units expose fixed-sized vector operations and expect the compiler to try to map the algorithm to the available unit size. In contrast, the SVE interface expects the programmer to describe the degree of parallelism available and relies on the hardware to map it down to the available number of execution units. Using this from C is complex, because the autovectorizer must infer the available parallelism from loop structures. Generating code for it from a functional-style map operation is trivial: the length of the mapped array is the degree of available parallelism.</p>
<p>Caches are large, but their size isn't the only reason for their complexity. The <i>cache coherency protocol</i> is one of the hardest parts of a modern CPU to make both fast and correct. Most of the complexity involved comes from supporting a language in which data is expected to be both shared and mutable as a matter of course. Consider in contrast an Erlang-style abstract machine, where every object is either thread-local or immutable (Erlang has a simplification of even this, where there is only one mutable object per thread). A cache coherency protocol for such a system would have two cases: mutable or shared. A software thread being migrated to a different processor would need its cache explicitly invalidated, but that's a relatively uncommon operation.</p>
<p>Immutable objects can simplify caches even more, as well as making several operations even cheaper. Sun Labs' Project Maxwell noted that the objects in the cache and the objects that would be allocated in a young generation are almost the same set. If objects are dead before they need to be evicted from the cache, then never writing them back to main memory can save a lot of power. Project Maxwell proposed a young-generation garbage collector (and allocator) that would run in the cache and allow memory to be recycled quickly. With immutable objects on the heap and a mutable stack, a garbage collector becomes a very simple state machine that is trivial to implement in hardware and allows for more efficient use of a relatively small cache.</p>
<p>A processor designed purely for speed, not for a compromise between speed and C support, would likely support large numbers of threads, have wide vector units, and have a much simpler memory model. Running C code on such a system would be problematic, so, given the large amount of legacy C code in the world, it would not likely be a commercial success.</p>
<p>There is a common myth in software development that parallel programming is hard. This would come as a surprise to Alan Kay, who was able to teach an actor-model language to young children, with which they wrote working programs with more than 200 threads. It comes as a surprise to Erlang programmers, who commonly write programs with thousands of parallel components. It's more accurate to say that parallel programming in a language with a C-like abstract machine is difficult, and given the prevalence of parallel hardware, from multicore CPUs to many-core GPUs, that's just another way of saying that C doesn't map to modern hardware very well.</p>
<h4>References</h4>
<p>1. C Defect Report 260. 2004; <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/dr_260.htm">http://www.open-std.org/jtc1/sc22/wg14/www/docs/dr_260.htm</a>.</p>
<p>2. Chadwick, G. A. 2013. Communication centric, multi-core, fine-grained processor architecture. Technical Report 832. University of Cambridge, Computer Laboratory; <a href="http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-832.pdf">http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-832.pdf</a>.</p>
<p>3. Memarian, K., Matthiesen, J., Lingard, J., Nienhuis, K., Chisnall, D. Watson, R. N. M., Sewell, P. 2016. Into the depths of C: elaborating the de facto standards. <i>Proceedings of the 37<sup>th</sup> ACM SIGPLAN Conference on Programming Language Design and Implementation</i>: 1-15; <a href="http://dl.acm.org/authorize?N04455">http://dl.acm.org/authorize?N04455</a>.</p>
<p>4. Ou, A., Nguyen, Q., Lee, Y., Asanović, K. 2014. A case for MVPs: mixed-precision vector processors. Second International Workshop on Parallelism in Mobile Platforms at the 41st International Symposium on Computer Architecture. </p>
<p>5. Perlis, A. 1982. Epigrams on programming. <i>ACM SIGPLAN</i> <i>Notices</i> 17(9).</p>
<h4>Related articles</h4>
<p> <b><a href="https://queue.acm.org/detail.cfm?id=2543971">The Challenge of Cross-language Interoperability</a></b> <br>David Chisnall <br>Interfacing between languages is increasingly important. <br><a href="https://queue.acm.org/detail.cfm?id=2543971">https://queue.acm.org/detail.cfm?id=2543971</a> </p>
<p> <b><a href="https://queue.acm.org/detail.cfm?id=2620662">Finding More than One Worm in the Apple</a></b> <br>Mike Bland <br>If you see something, say something. <br><a href="https://queue.acm.org/detail.cfm?id=2620662">https://queue.acm.org/detail.cfm?id=2620662</a> </p>
<p> <b><a href="https://queue.acm.org/detail.cfm?id=1113336">Coding for the Code</a></b> <br>Friedrich Steimann, Thomas Kühne <br>Can models provide the DNA for software development? <br><a href="https://queue.acm.org/detail.cfm?id=1113336">https://queue.acm.org/detail.cfm?id=1113336</a> </p>
<p><b>David Chisnall</b> is a researcher at the University of Cambridge, where he works on programming language design and implementation. He spent several years consulting in between finishing his Ph.D. and arriving at Cambridge, during which time he also wrote books on Xen and the Objective-C and Go programming languages, as well as numerous articles. He also contributes to the LLVM, Clang, FreeBSD, GNUstep, and Étoilé open-source projects, and he dances the Argentine tango.</p>
<p>Copyright © 2018 held by owner/author. Publication rights licensed to ACM.</p>

<div>
<p><img src="https://queue.acm.org/img/q%20stamp_small.jpg" width="26" height="45" alt="acmqueue"></p><p>
<em>Originally published in Queue vol. 16, no. 2</em>—
<br>
Comment on this article in the <a href="http://portal.acm.org/citation.cfm?id=3212479">ACM Digital Library</a></p></div>







<hr noshade="" size="1"><p>
More related articles:
</p><p>
<span>Matt Godbolt</span> - <a href="https://queue.acm.org/detail.cfm?id=3372264"><b>Optimizations in C++ Compilers</b></a>
<br>
There’s a tradeoff to be made in giving the compiler more information: it can make compilation slower. Technologies such as link time optimization can give you the best of both worlds. Optimizations in compilers continue to improve, and upcoming improvements in indirect calls and virtual function dispatch might soon lead to even faster polymorphism.
</p>

<p>
<span>Ulan Degenbaev, Michael Lippautz, Hannes Payer</span> - <a href="https://queue.acm.org/detail.cfm?id=3325132"><b>Garbage Collection as a Joint Venture</b></a>
<br>
Cross-component tracing is a way to solve the problem of reference cycles across component boundaries. This problem appears as soon as components can form arbitrary object graphs with nontrivial ownership across API boundaries. An incremental version of CCT is implemented in V8 and Blink, enabling effective and efficient reclamation of memory in a safe manner.
</p>

<p>
<span>Tobias Lauinger, Abdelberi Chaabane, Christo Wilson</span> - <a href="https://queue.acm.org/detail.cfm?id=3205288"><b>Thou Shalt Not Depend on Me</b></a>
<br>
Most websites use JavaScript libraries, and many of them are known to be vulnerable. Understanding the scope of the problem, and the many unexpected ways that libraries are included, are only the first steps toward improving the situation. The goal here is that the information included in this article will help inform better tooling, development practices, and educational efforts for the community.
</p>

<p>
<span>Robert C. Seacord</span> - <a href="https://queue.acm.org/detail.cfm?id=3041020"><b>Uninitialized Reads</b></a>
<br>
Most developers understand that reading uninitialized variables in C is a defect, but some do it anyway. What happens when you read uninitialized objects is unsettled in the current version of the C standard (C11).3 Various proposals have been made to resolve these issues in the planned C2X revision of the standard. Consequently, this is a good time to understand existing behaviors as well as proposed revisions to the standard to influence the evolution of the C language. Given that the behavior of uninitialized reads is unsettled in C11, prudence dictates eliminating uninitialized reads from your code.
</p>
<br>
<hr noshade="" size="1">
<hr noshade="" size="1">
<p>
<a href="#"><img src="https://queue.acm.org/img/logo_acm.gif"></a>
<br>
© ACM, Inc. All Rights Reserved.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeTube – The Private YouTube Client (201 pts)]]></title>
            <link>https://github.com/FreeTubeApp/FreeTube</link>
            <guid>37897916</guid>
            <pubDate>Mon, 16 Oct 2023 10:40:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/FreeTubeApp/FreeTube">https://github.com/FreeTubeApp/FreeTube</a>, See on <a href="https://news.ycombinator.com/item?id=37897916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
 <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/506f4f7da018a482059435b81af6c5d7a7b79140b09e109c186f15835787de66/68747470733a2f2f646f63732e66726565747562656170702e696f2f696d616765732f6c6f676f436f6c6f722e706e67"><img alt="" src="https://camo.githubusercontent.com/506f4f7da018a482059435b81af6c5d7a7b79140b09e109c186f15835787de66/68747470733a2f2f646f63732e66726565747562656170702e696f2f696d616765732f6c6f676f436f6c6f722e706e67" width="500" data-canonical-src="https://docs.freetubeapp.io/images/logoColor.png"></a>
</p>
<p dir="auto">FreeTube is an open source desktop YouTube player built with privacy in mind.
Use YouTube without advertisements and prevent Google from tracking you with their cookies and JavaScript.
Available for Windows, Mac &amp; Linux thanks to Electron.</p>
<p dir="auto"><a href="https://github.com/FreeTubeApp/FreeTube/releases">Download FreeTube</a></p>
<p dir="auto">
  <a href="https://github.com/FreeTubeApp/FreeTube/actions/workflows/build.yml">
    <img alt="Build status" src="https://github.com/FreeTubeApp/FreeTube/actions/workflows/build.yml/badge.svg?branch=development">
  </a>
  <a href="https://hosted.weblate.org/engage/free-tube/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/979d044f0290f9d6b59ba0154392c94d498cba617ee24575eb7fc8a5df200161/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f667265652d747562652f2d2f7376672d62616467652e737667" alt="Translation status" data-canonical-src="https://hosted.weblate.org/widgets/free-tube/-/svg-badge.svg">
  </a>
</p>
<hr>
<p dir="auto"><a href="#screenshots">Screenshots</a> • <a href="#how-does-it-work">How does it work?</a> • <a href="#features">Features</a> • <a href="#download-links">Download Links</a> • <a href="#contributing">Contributing</a> • <a href="#localization">Localization</a> • <a href="#contact">Contact</a> • <a href="#donate">Donate</a> • <a href="#license">License</a></p>
<p dir="auto"><a href="https://freetubeapp.io/" rel="nofollow">Website</a> • <a href="https://blog.freetubeapp.io/" rel="nofollow">Blog</a> • <a href="https://docs.freetubeapp.io/" rel="nofollow">Documentation</a> • <a href="https://docs.freetubeapp.io/faq/" rel="nofollow">FAQ</a> • <a href="https://github.com/FreeTubeApp/FreeTube/discussions">Discussions</a></p>
<hr>
<p dir="auto"><b>Please note that FreeTube is currently in Beta. While it should work well for most users, there are still bugs and missing features that need to be addressed. If you have an idea or if you found a bug, please submit a <a href="https://github.com/FreeTubeApp/FreeTube/issues/new/choose">GitHub issue</a> so that
we can track it.  Please search <a href="https://github.com/FreeTubeApp/FreeTube/issues">the existing issues</a> before submitting to
prevent duplicates!</b></p>
<h2 tabindex="-1" id="user-content-screenshots" dir="auto"><a href="#screenshots">Screenshots</a></h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d9ec7e7b06799e84e3001c2a58167fae89d5fec94c6c214655594fe9a9ca3299/68747470733a2f2f692e696d6775722e636f6d2f7a46675a5555562e706e67"><img src="https://camo.githubusercontent.com/d9ec7e7b06799e84e3001c2a58167fae89d5fec94c6c214655594fe9a9ca3299/68747470733a2f2f692e696d6775722e636f6d2f7a46675a5555562e706e67" width="300" data-canonical-src="https://i.imgur.com/zFgZUUV.png"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/91eee88d8059318978120c1e495ff2e710024644dde68c5c9b4b6cbb1f71b87d/68747470733a2f2f692e696d6775722e636f6d2f3965765948674e2e706e67"><img src="https://camo.githubusercontent.com/91eee88d8059318978120c1e495ff2e710024644dde68c5c9b4b6cbb1f71b87d/68747470733a2f2f692e696d6775722e636f6d2f3965765948674e2e706e67" width="300" data-canonical-src="https://i.imgur.com/9evYHgN.png"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/2a72a4f0f2874637177da43c55f10bd254cb51f0cc4b929f15b50f8ea96b13be/68747470733a2f2f692e696d6775722e636f6d2f795432557a50612e706e67"><img src="https://camo.githubusercontent.com/2a72a4f0f2874637177da43c55f10bd254cb51f0cc4b929f15b50f8ea96b13be/68747470733a2f2f692e696d6775722e636f6d2f795432557a50612e706e67" width="300" data-canonical-src="https://i.imgur.com/yT2UzPa.png"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/22766008c94ce85e85850919f2d56ae186d6bcce51e6643c3c45d6e6485686ed/68747470733a2f2f692e696d6775722e636f6d2f34377a494574342e706e67"><img src="https://camo.githubusercontent.com/22766008c94ce85e85850919f2d56ae186d6bcce51e6643c3c45d6e6485686ed/68747470733a2f2f692e696d6775722e636f6d2f34377a494574342e706e67" width="300" data-canonical-src="https://i.imgur.com/47zIEt4.png"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c9b1c1b7a7a50660d1c9bc1fc6f929902d21918663a2c510763f2ca3d40c680c/68747470733a2f2f692e696d6775722e636f6d2f68464232664b432e706e67"><img src="https://camo.githubusercontent.com/c9b1c1b7a7a50660d1c9bc1fc6f929902d21918663a2c510763f2ca3d40c680c/68747470733a2f2f692e696d6775722e636f6d2f68464232664b432e706e67" width="300" data-canonical-src="https://i.imgur.com/hFB2fKC.png"></a></p>
<h2 tabindex="-1" id="user-content-how-does-it-work" dir="auto"><a href="#how-does-it-work">How does it work?</a></h2>
<p dir="auto">FreeTube uses a built in extractor to grab and serve data / videos. The <a href="https://github.com/iv-org/invidious">Invidious API</a> can also optionally be used. FreeTube does not use any official APIs to obtain data. While YouTube can still see your video requests, it can no
longer track you using cookies or JavaScript. Your subscriptions and history are stored locally on your computer and never sent out. Using a VPN or Tor is highly recommended
to hide your IP while using FreeTube.</p>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<ul dir="auto">
<li>Watch videos without ads</li>
<li>Use YouTube without Google tracking you using cookies and JavaScript</li>
<li>Two extractor APIs to choose from (Built in or Invidious)</li>
<li>Subscribe to channels without an account</li>
<li>Connect to an externally setup proxy such as Tor</li>
<li>View and search your local subscriptions, history, and saved videos</li>
<li>Organize your subscriptions into "Profiles" to create a more focused feed</li>
<li>Export &amp; import subscriptions</li>
<li>Youtube Trending</li>
<li>Youtube Chapters</li>
<li>Most popular videos page based on the set Invidious instance</li>
<li>SponsorBlock</li>
<li>Open videos from your browser directly into FreeTube (with extension)</li>
<li>Watch videos using an external player</li>
<li>Full Theme support</li>
<li>Make a screenshot of a video</li>
<li>Multiple windows</li>
<li>Mini Player (Picture-in-Picture)</li>
<li>Keyboard shortcuts</li>
<li>Option to show only family friendly content</li>
<li>Show/hide functionality or elements within the app using the distraction free settings</li>
<li>View channel community posts</li>
<li>View most age restricted videos</li>
</ul>
<h3 tabindex="-1" id="user-content-browser-extension" dir="auto"><a href="#browser-extension">Browser Extension</a></h3>
<p dir="auto">FreeTube is supported by the <a href="https://github.com/SimonBrazell/privacy-redirect">Privacy Redirect</a> and <a href="https://github.com/libredirect/libredirect">LibRedirect</a> extensions, which will allow you to open YouTube links into FreeTube. You must enable the option within the advanced settings of the extension for it to work.</p>
<ul dir="auto">
<li>
<p dir="auto">Download Privacy Redirect for <a href="https://addons.mozilla.org/en-US/firefox/addon/privacy-redirect/" rel="nofollow">Firefox</a> or <a href="https://chrome.google.com/webstore/detail/privacy-redirect/pmcmeagblkinmogikoikkdjiligflglb" rel="nofollow">Google Chrome</a>.</p>
</li>
<li>
<p dir="auto">Download LibRedirect for <a href="https://addons.mozilla.org/firefox/addon/libredirect/" rel="nofollow">Firefox</a> or <a href="https://libredirect.github.io/download_chromium.html" rel="nofollow">Google Chrome</a>.</p>
</li>
</ul>
<p dir="auto">If you have issues with the extension working with FreeTube, please create an issue in this repository instead of the extension repository. This extension does not work on Linux portable builds!</p>
<h2 tabindex="-1" id="user-content-download-links" dir="auto"><a href="#download-links">Download Links</a></h2>
<h3 tabindex="-1" id="user-content-official-downloads" dir="auto"><a href="#official-downloads">Official Downloads</a></h3>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/FreeTubeApp/FreeTube/releases">GitHub Releases</a></p>
</li>
<li>
<p dir="auto"><a href="https://freetubeapp.io/#download" rel="nofollow">FreeTube Website</a></p>
</li>
<li>
<p dir="auto">Flatpak on Flathub: <a href="https://flathub.org/apps/details/io.freetubeapp.FreeTube" rel="nofollow">Download</a> and <a href="https://github.com/flathub/io.freetubeapp.FreeTube">Source Code</a></p>
</li>
</ul>
<h4 tabindex="-1" id="user-content-automated-builds-nightly--weekly" dir="auto"><a href="#automated-builds-nightly--weekly">Automated Builds (Nightly / Weekly)</a></h4>
<p dir="auto">Builds are automatically created from changes to our development branch via <a href="https://github.com/FreeTubeApp/FreeTube/actions?query=workflow%3ABuild">GitHub Actions</a>.</p>
<p dir="auto">The first build with a green check mark is the latest build.  You will need to have a GitHub account to download these builds.</p>
<h3 tabindex="-1" id="user-content-unofficial-downloads" dir="auto"><a href="#unofficial-downloads">Unofficial Downloads</a></h3>
<p dir="auto">These builds are maintained by the community. While they should be safe, download at your own risk. There may be issues with using these versus the official builds. Any issues specific with these builds should be sent to their respective maintainer. <b>Make sure u always try an <a href="https://github.com/freetubeapp/freetube/#official-downloads">official download</a> before reporting your issue to us!</b></p>
<ul dir="auto">
<li>
<p dir="auto">Arch User Repository (AUR): <a href="https://aur.archlinux.org/packages/freetube-bin/" rel="nofollow">Download</a></p>
</li>
<li>
<p dir="auto">Chocolatey: <a href="https://chocolatey.org/packages/freetube/" rel="nofollow">Download</a></p>
</li>
<li>
<p dir="auto">FreeTubeCordova (FreeTube port for Android and PWA): <a href="https://github.com/MarmadileManteater/FreeTubeCordova/releases">Download</a> and <a href="https://github.com/MarmadileManteater/FreeTubeCordova">Source Code</a></p>
</li>
<li>
<p dir="auto">makedeb Package Repository (MPR): <a href="https://mpr.makedeb.org/packages/freetube-bin" rel="nofollow">Download</a></p>
</li>
<li>
<p dir="auto">Nix Packages: <a href="https://search.nixos.org/packages?query=freetube" rel="nofollow">Download</a></p>
</li>
<li>
<p dir="auto">PortableApps (Windows Only): <a href="https://github.com/rddim/FreeTubePortable/releases">Download</a> and <a href="https://github.com/rddim/FreeTubePortable">Source Code</a></p>
</li>
<li>
<p dir="auto">Scoop (Windows Only): <a href="https://github.com/ScoopInstaller/Scoop">Usage</a></p>
</li>
<li>
<p dir="auto">Snap: <a href="https://snapcraft.io/freetube" rel="nofollow">Download</a> and <a href="https://git.launchpad.net/freetube" rel="nofollow">Source Code</a></p>
</li>
<li>
<p dir="auto">Windows Package Manager (winget): <a href="https://docs.microsoft.com/en-us/windows/package-manager/winget/" rel="nofollow">Usage</a></p>
</li>
</ul>
<h2 tabindex="-1" id="user-content-contributing" dir="auto"><a href="#contributing">Contributing</a></h2>
<p dir="auto">If you like to get your hands dirty and want to contribute, we would love to
have your help.  Send a pull request and someone will review your code. Please
follow the <a href="https://github.com/FreeTubeApp/FreeTube/blob/development/CONTRIBUTING.md">Contribution
Guidelines</a>
before sending your pull request.</p>
<p dir="auto">Thank you very much to the <a href="https://docs.freetubeapp.io/credits/" rel="nofollow">People and Projects</a> that make FreeTube possible!</p>
<h2 tabindex="-1" id="user-content-localization" dir="auto"><a href="#localization">Localization</a></h2>
<a href="https://hosted.weblate.org/engage/free-tube/" rel="nofollow">
<img src="https://camo.githubusercontent.com/eff8eabbf9b0d6571b3475dd87f74a5e78a4e8ca78291c486b08f0d3e40e4176/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f667265652d747562652f2d2f3238377836362d677265792e706e67" alt="Translation status" data-canonical-src="https://hosted.weblate.org/widgets/free-tube/-/287x66-grey.png">
</a>
<p dir="auto">We are actively looking for translations!  We use <a href="https://hosted.weblate.org/engage/free-tube/" rel="nofollow">Weblate</a> to make it easy for translators to get involved.  Click on the badge above to learn how to get involved.</p>
<p dir="auto">For the Linux Flatpak, the desktop entry comment string can be translated at our <a href="https://github.com/flathub/io.freetubeapp.FreeTube/blob/master/io.freetubeapp.FreeTube.desktop">Flatpak repository</a>.</p>
<h2 tabindex="-1" id="user-content-contact" dir="auto"><a href="#contact">Contact</a></h2>
<p dir="auto">If you ever have any questions, feel free to ask it on our <a href="https://github.com/FreeTubeApp/FreeTube/discussions">Discussions</a> page.  Alternatively, you can email us at <a href="mailto:FreeTubeApp@protonmail.com">FreeTubeApp@protonmail.com</a> or you can join our <a href="https://matrix.to/#/+freetube:matrix.org" rel="nofollow">Matrix Community</a>.  Don't forget to check out the <a href="https://docs.freetubeapp.io/community/matrix/" rel="nofollow">rules</a> before joining.</p>
<h2 tabindex="-1" id="user-content-donate" dir="auto"><a href="#donate">Donate</a></h2>
<p dir="auto">If you enjoy using FreeTube, you're welcome to leave a donation using the following methods.</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://liberapay.com/FreeTube" rel="nofollow">FreeTube on Liberapay</a></p>
</li>
<li>
<p dir="auto">Bitcoin Address: <code>1Lih7Ho5gnxb1CwPD4o59ss78pwo2T91eS</code></p>
</li>
<li>
<p dir="auto">Monero Address: <code>48WyAPdjwc6VokeXACxSZCFeKEXBiYPV6GjfvBsfg4CrUJ95LLCQSfpM9pvNKy5GE5H4hNaw99P8RZyzmaU9kb1pD7kzhCB</code></p>
</li>
</ul>
<p dir="auto">While your donations are much appreciated, only donate if you really want to.  Donations are used for keeping the website up and running and eventual code signing costs. If you are using the Invidious API then we recommend that you donate to the instance that you use. You can also donate to the <a href="https://invidious.io/donate/" rel="nofollow">Invidious team</a> or the <a href="https://github.com/sponsors/LuanRT">Local API developer</a>.</p>
<h2 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License</a></h2>
<p dir="auto"><a href="https://www.gnu.org/licenses/agpl-3.0.html" rel="nofollow"><img src="https://camo.githubusercontent.com/473b62766b498e4f2b008ada39f1d56fb3183649f24447866e25d958ac3fd79a/68747470733a2f2f7777772e676e752e6f72672f67726170686963732f6167706c76332d3135357835312e706e67" alt="GNU AGPLv3 Image" data-canonical-src="https://www.gnu.org/graphics/agplv3-155x51.png"></a></p>
<p dir="auto">FreeTube is Free Software: You can use, study share and improve it at your
will. Specifically you can redistribute and/or modify it under the terms of the
<a href="https://www.gnu.org/licenses/agpl-3.0.html" rel="nofollow">GNU Affero General Public License</a> as
published by the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 10 warns me to use a "Microsoft-verified" app (236 pts)]]></title>
            <link>https://support.mozilla.org/en-US/kb/windows-10-warns-me-use-microsoft-verified-app</link>
            <guid>37897432</guid>
            <pubDate>Mon, 16 Oct 2023 09:23:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.mozilla.org/en-US/kb/windows-10-warns-me-use-microsoft-verified-app">https://support.mozilla.org/en-US/kb/windows-10-warns-me-use-microsoft-verified-app</a>, See on <a href="https://news.ycombinator.com/item?id=37897432">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="doc-content">
    
      <p>In certain versions of Windows 10, you may receive a notification with a warning about <em>Microsoft-verified apps</em> when you run the Firefox installer.
</p><p><img alt="Windows 10 dialog box" data-original-src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-18-10-47-06-7f0552.png" src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-18-10-47-06-7f0552.png" width="600">
</p><p><strong>Any copy of Firefox downloaded from www.mozilla.org is safe to install</strong>, so choose "<em>Install anyway</em>".
</p>
<div>
<p><strong>Note:</strong> 
</p>
<ul><li>You can also <a href="https://support.mozilla.org/en-US/kb/download-firefox-windows-microsoft-store">download and install Firefox from the Microsoft Store</a>. 
</li><li><strong>Using Windows 10 in S mode?</strong> See <a href="https://support.mozilla.org/en-US/kb/windows-s-mode-wont-let-me-install-firefox">Windows in S mode won't let me install Firefox</a>.
</li></ul>
</div>
<p>If you do not see the option to “<em>Install anyway</em>”, follow the steps below to change your system settings.
</p>
<ol><li>Open the Windows 10 start menu and select <strong>Settings</strong>.
<dl><dt><img alt="Windows 10 start menu" data-original-src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-18-10-51-18-9b6441.png" src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-18-10-51-18-9b6441.png" width="600"><br>
</dt></dl>
</li><li>Click on <strong>Apps</strong> in the <em>Windows Settings</em> menu.
<dl><dt><img alt="win10-settings-apps" data-original-src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-21-17-00-28-af2077.png" src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-21-17-00-28-af2077.png" title=""><br>
</dt></dl>
</li><li>In the <em>Apps &amp; features</em> section go to <strong>Choose where to get apps</strong>, click on the dropdown menu below and select one of the options that allows you to install from <em>Anywhere</em>.
<dl><dt><img alt="win10-settings-apps-store" data-original-src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-21-17-01-00-7ce375.png" src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/gallery/images/2020-09-21-17-01-00-7ce375.png" title="">
</dt></dl>
</li><li>Run the Firefox Installer again. Your Windows may now allow it to install Firefox.
</li></ol>
<h2 id="w_related-content">Related content</h2>
<ul><li> <a href="https://support.mozilla.org/en-US/kb/why-do-i-get-harmful-download-message-when-downloading-firefox-windows">Why do I get a harmful download message when downloading Firefox on Windows?</a>
</li></ul>
    
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Atlassian prepares to abandon on-prem server products (139 pts)]]></title>
            <link>https://www.theregister.com/2023/10/16/atlassian_cloud_migration_server_deprecation/</link>
            <guid>37897351</guid>
            <pubDate>Mon, 16 Oct 2023 09:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/10/16/atlassian_cloud_migration_server_deprecation/">https://www.theregister.com/2023/10/16/atlassian_cloud_migration_server_deprecation/</a>, See on <a href="https://news.ycombinator.com/item?id=37897351">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>In October 2020, Atlassian <a target="_blank" href="https://www.theregister.com/2020/10/19/atlassian_server_licenses/">announced</a> that it would end support for its server products on February 15, 2024. With that deadline now less than five months away, the Australian developer is content it's done the right thing by customers – yet has warned investors the move is a risk to revenue.</p>
<p>Atlassian once offered its wares in three forms. The preferred option is from the cloud, in conventional software-as-a-service style that sees Atlassian manage software and infrastructure. Users can also buy datacenter licenses that renew annually and require self-management. Until 2021, you could also get server products under a perpetual license, but users who wanted support and upgrades need to pay.</p>
<p>In 2020 Atlassian decided it wanted to be a cloud company. It argued that doing so would deliver a better experience for customers, and flagged deprecation of its server products.</p>
<blockquote>

<p>By trying to serve both audiences we did neither well</p>
</blockquote>
<p>"Our first products were servers," Atlassian chief revenue officer Cameron Deatsch told <em>The Register</em>. "This was how every software product worked before the internet."</p>
<p>But around 13 years ago Atlassian started to sell cloudy software, and according to Deatsch "realized early on that SaaS is the future of enterprise software, broadly."</p>

    

<p>The Australian vendor kept its SaaS and server products at parity, but didn't find that easy.</p>

        


        

<p>"By trying to serve both audiences we did neither well," Deatsch admitted.</p>
<p>In 2016, Atlassian therefore split the code base for its SaaS and server products – a transition that Deatsch conceded other software companies had done years earlier. While Atlassian believed its future lay in the cloud and SaaS, the server products were kept alive.</p>

        

<p>"The biggest reason we did it is we were not fully capable of handling all our server customers in our cloud at that time," Deatsch told <em>The Register</em>. Privacy, data sovereignty, and the challenge of nailing privacy and regulations like the US Health Insurance Portability and Accountability Act(HIPAA) also meant Atlassian wasn't confident it could deliver for all customers.</p>
<p>But by 2020 it was ready to go all-in on SaaS – for most customers.</p>
<p>"Even with three years to prepare for these changes, we understand that not every customer will be ready to make the switch from our server products to our cloud products. And, some of you have business requirements that might prevent you from ever operating in the cloud," wrote co-founder and co-CEO Scott Farquhar.</p>

        

<p>Atlassian therefore persisted with its datacenter licenses, to ensure it continued to offer an on-prem option.</p>
<p>But the vendor didn't change the licensing tiers for datacenter licenses, which start with a band that covers between one and 500 users – at a flat price, regardless of how many people actually use the software.</p>
<p>Owners of server licenses looking for an on-prem migration path therefore faced the prospect of paying for 500 seats – which costs at least a five figure sum each year – even if they have many fewer users.</p>
<p>Deatsch told <em>The Register</em> that decision was made because Atlassian focussed on the needs of larger users as it continued development of the datacenter products.</p>
<p>Atlassian also felt that larger users might have technical reasons that prevented them from adopting its SaaS, but that smaller customers probably did not. Deatsch added that orgs with around 200 users will find it's cheaper to adopt the SaaS rather than datacenter licenses – likely even more so after total cost of ownership calculations.</p>
<p>Yet Atlassian happily offered server licences priced for up to 10, 25, 50, 100, 250, or 500 users.</p>
<ul>

<li><a href="https://www.theregister.com/2023/09/29/red_hat_bugzilla_jira_migration/">Red Hat bins Bugzilla for RHEL issue tracking, jumps on Jira</a></li>

<li><a href="https://www.theregister.com/2023/03/07/atlassian_fires_500/">Atlassian to dump 500 – by email – in the name of 'rebalancing'</a></li>

<li><a href="https://www.theregister.com/2022/04/11/atlassian_outage_backups/">At last, Atlassian sees an end to its outage ... in two weeks</a></li>

<li><a href="https://www.theregister.com/2023/02/13/jira_upgrade_congress/">'Private cloud server' Jira upgraded for wider teams, dragged into culture wars</a></li>
</ul>
<p>Some customers who can't or won't adopt Atlassian's SaaS aren't happy because the datacenter licenses mean they face price rises.</p>
<p>Users who are caught in that trap tell <em>The Register</em> that repeated requests for flexibility have gone unanswered, and that Atlassian knows some customers face an impossible choice – but the vendor isn't budging.</p>
<p>"I think there are lots of small users at under 500 seats who don't know what to do," said Thomas Murphy, a senior director analyst at Gartner. Murphy cited other vendors' migration plans that offer extended support, especially for custom apps. He's unsure why Atlassian chose not to do so.</p>
<p>Another source of concern is that Atlassian's development plans are now very much cloud first – as typified by last week's acquisition of asynchronous video outfit Loom and <a target="_blank" href="https://www.theregister.com/2023/10/13/atlassian_acquires_loom/">informing</a> users it will only be integrated with cloud products. Holders of datacenter licenses won't get the apparently revolutionary new embedded video features.</p>
<p>Some users who contacted <em>The Register</em> told us they've started, and paused, migrations away from server products because the process was not easy.</p>
<p>Atlassian's Deatsch told <em>The Register</em> migration rates have exceeded the vendor's forecasts.</p>
<p>"We thought enterprises would be slow, but they were fast," he said. "Many got cloud mandates from their CIOs."</p>
<p>His goal for the next five months is to ensure that every remaining server customer "knows their options and understands incentives like migration tools, discounts, and extended trials."</p>
<h3>Revenue risk</h3>
<p>But Atlassian is also bracing for the impact of customers who decide to stop paying for server support.</p>
<p>In the company's most recent <a target="_blank" href="https://www.atlassian.com/blog/announcements/shareholder-letter-q4fy23">letter to investors</a>, co-CEOs Farquhar and Mike Cannon-Brookes named "two significant factors which may impact our revenue results in FY24."</p>
<p>One was macroeconomic uncertainties. The other was "customer purchasing and migration decisions related to the end-of-support for our server offering," which the pair warned will "drive quarter-to-quarter variability in our cloud and datacenter revenue growth rates depending on when and how our server customers ultimately choose to migrate: direct to cloud, direct to datacenter, or to some combination of cloud and datacenter.”</p>
<p>The co-CEOs admitted "some portion of our Server customers will not migrate in FY24." Or perhaps they'll just quit Atlassian altogether.</p>
<p>Deatsch declined to share the number of server users yet to migrate, but said Atlassian is certain its decision to go cloud-first was correct.</p>
<p>"It was a massive strategic bet, but at every step along the way we confirm it is the right call," he said. ®</p>
<p><strong>Bootnote:</strong> If you're yet to migrate your Atlassian server and aren't happy with your options, <a target="_blank" href="https://www.theregister.com/Author/Email/Simon-Sharwood">contact the author here</a>.</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google’s dominance under siege: Antitrust trial threatens sweeping changes (137 pts)]]></title>
            <link>https://www.livenowfox.com/news/googles-internet-dominance-under-siege-antitrust-trial-threatens-sweeping-changes</link>
            <guid>37896806</guid>
            <pubDate>Mon, 16 Oct 2023 07:39:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.livenowfox.com/news/googles-internet-dominance-under-siege-antitrust-trial-threatens-sweeping-changes">https://www.livenowfox.com/news/googles-internet-dominance-under-siege-antitrust-trial-threatens-sweeping-changes</a>, See on <a href="https://news.ycombinator.com/item?id=37896806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-7407f9a8="" lastmodifieddate="2023-10-15T15:13:22-04:00" data-v-6b73e26c=""> <p><strong data-v-7407f9a8="">Published</strong>&nbsp;<time data-v-7407f9a8="">October 15, 2023 3:13PM</time></p> <!---->   </div><div data-v-6b73e26c=""><div data-v-6b73e26c=""><h4>Google Flights has a new feature to help you save money</h4> <p>An upgrade to Google Flights will tell you the best time to book your next getaway.</p></div> <!----><p data-v-6b73e26c="">If government regulators prevail against Google in the <a href="https://apnews.com/article/google-antitrust-trial-search-engine-justice-department-2cfb06271455c7e12c4927959061e832">biggest U.S. antitrust trial in a quarter century,</a> it's likely to unleash drastic changes that will undermine the dominance of a search engine that defines the internet for billions of people.</p> <!----><p data-v-6b73e26c="">As the 10-week trial probing Google's business practices nears its midway point, it's still too early to tell if U.S. District Judge Amit Mehta will side with the Justice Department and try to handcuff one of the world's most dominant tech companies.</p> <!----> <!---->  <p data-v-6b73e26c="">If Mehta rules that Google has been running an illegal monopoly in search, the punishment could open up new online avenues for consumers and businesses to explore in pursuit of information, entertainment and commerce.</p> <!----><p data-v-6b73e26c="">"The judge can compel Google to open the floodgates so more startups and third-party competitors can put greater competitive pressure on Google, which will create higher quality online services," said Luther Lowe, senior vice president of public policy at Yelp. The online business review site has been one of Google's harshest critics while spending more than a decade railing against a strategy that favors its own services in search results.</p> <!----> <!----><p data-v-6b73e26c=""><strong>RELATED: </strong><a href="https://www.fox5ny.com/news/microsoft-copilot-ai-tool-outlook-word-writing-email-replies-for-you"><strong>Microsoft’s AI tool coming soon to Outlook, writing email replies for you</strong></a></p> <!----><p data-v-6b73e26c="">Google's search engine earned its huge market share by almost instantaneously presenting people with helpful information culled from the billions of websites that have been indexed since former Stanford University graduate students Larry Page and Sergey Brin <a href="https://apnews.com/article/google-antitrust-lawsuit-doj-f8f82967dc0d53a42c240b31d1559ccf">developed the technology during the late 1990s</a>.</p> <!----><p data-v-6b73e26c="">In addition to its technological wizardry, Google also pays billions of dollars each year to ensure its search engine is the default choice for answering queries entered in the world's most popular smartphones and web browsers.</p> <!----><div data-v-0dea8073="" data-v-6b73e26c=""><p><img src="https://images.foxtv.com/static.livenowfox.com/www.livenowfox.com/content/uploads/2023/10/932/524/GettyImages-1255158779-1.jpg?ve=1&amp;tl=1" alt="" data-v-0dea8073=""></p><p data-v-0dea8073=""><span data-v-0dea8073="">MOUNTAIN VIEW, CA - MAY 15: Google Headquarters is seen in Mountain View, California, United States on May 15, 2023. (Photo by Tayfun Coskun/Anadolu Agency via Getty Images)</span> <!----></p></div> <!----><p data-v-6b73e26c="">These agreements don’t preclude users from switching to a different search engine in their settings, but it’s a tedious process that few people bother to navigate. This reality is why Google is willing to pay so much for the privileged position, according to the Justice Department.</p> <!----><p data-v-6b73e26c="">Google's payments for preeminent search placement — including an estimated $15 billion to $20 billion per year to Apple alone — are at the head of the Justice Department's case, making it probable the judge would prohibit them if he rules against Google.</p> <!----><p data-v-6b73e26c="">Should that happen, experts believe the most likely remedy in the U.S. would be a requirement for smartphones and web browsers to display a palette of different search engines during the setup process. That's something already being done in Europe, where all indications, so far, are that most people are still opting for Google.</p> <!----><p data-v-6b73e26c=""><strong>RELATED: </strong><a href="https://www.fox5ny.com/news/addictive-social-media-feeds-that-keep-children-online-targeted-by-new-york-lawmakers"><strong>'Addictive' social media feeds that keep children online targeted by New York lawmakers</strong></a></p> <!----><p data-v-6b73e26c="">That could be because they believe Google truly is the best search engine — as Google argues in their defense — or they just trust the brand more than rival options such as Microsoft's Bing or the privacy-focused DuckDuckGo.</p> <!----><p data-v-6b73e26c="">Microsoft CEO Satya Nadella asserted Google has an almost hypnotic hold on users while <a href="https://apnews.com/article/google-antitrust-microsoft-bing-search-engine-37a143e73a12855a12f974e08ec05db4">testifying earlier this month</a> during the trial.</p> <!----><p data-v-6b73e26c="">"You get up in the morning, you brush your teeth and you search on Google," Nadella said. He then added that the only way to break the habit is by changing the default choice.</p> <!----><div data-v-6b73e26c=""><h4>Google Street View genius guesses where he is in the world in seconds</h4> <p>23-year-old Trevor Rainbolt shows FOX TV Stations his process for how he wows the internet with his ability to accurately guess specific locations on Google maps in seconds, usually only being a few miles off.</p></div> <!----><p data-v-6b73e26c="">As long as a ruling doesn't exclude Google's rivals from paying to be the automatic search engine on smartphones and web browsers, Microsoft could buy the default position for Bing — an opportunity Nadella indicated he would seize.</p> <!----><p data-v-6b73e26c="">"There’s defaults — the only thing that matter in terms of changing search behavior," Nadella testified.</p> <!----><p data-v-6b73e26c="">Florian Schaub, associate professor of information at the University of Michigan, believes the fairest outcome in the trial would an across-the-board ban on all default agreements between two companies.</p> <!----><p data-v-6b73e26c="">"The current environment is being shaped by an architecture that's designed by the big companies that control the space," Schaub said. "What the government can do is inject some neutralism into this and give consumers some actual choices. If people still choose to use Google, that is at least a consumer choice, which would better than having people stick to a default because they are conditioned to that default."</p> <!----><p data-v-6b73e26c="">In <a href="https://apnews.com/article/google-antitrust-trial-search-engine-apple-9b9c2e55ae3c261ad845448ee7a390e4">his testimony during the trial,</a> Apple executive Eddy Cue said the company has embraced Google as the preferred search engine on the iPhone and other products because it provides the best experience for its customers. That stance has raised speculation that if Apple is blocked from using Google as the default search engine on the iPhone, it might flex its muscle as the world's richest company to develop its own search technology.</p> <!----><p data-v-6b73e26c="">However, a blanket ban on default search agreements that have been highly profitable for Apple and other companies such as wireless provider Verizon could trigger unintended consequences, such as raising prices on other popular products.</p> <!----><p data-v-6b73e26c=""><strong>RELATED: </strong><a href="https://www.fox5ny.com/news/sony-confirms-slim-playstation-5-console-for-upcoming-holiday-season"><strong>Sony confirms slim PlayStation 5 console for upcoming holiday season</strong></a></p> <!----><p data-v-6b73e26c="">"If Google is no longer paying big bucks to Apple and other companies, they might raise the prices for their devices," said David Olson, an associate professor for the Boston College Law School who is following the antitrust trial. "I don't think they will be big, but we could see some price increases because Google has essentially been subsidizing the cost of devices like the iPhone."</p> <!----><p data-v-6b73e26c="">Another offshoot of a ban on default search agreements is that Google still could have a dominant advantage in search if people continue to proactively choose it and the company would have billions of dollars more to spend in other areas that it once devoted to deals that it really didn't need at all.</p> <!----><p data-v-6b73e26c="">"Google must think they getting a great benefit from those default agreements, but maybe they're really not worth that much," Olson said. "Maybe their cost/benefit analysis is off and they will wind up more money and just as much dominance. That would be ironic."</p> <!----><p data-v-6b73e26c="">Although the trial is focused on Google's search engine, a government victory could have more sweeping consequences across the technology industry if Mehta decided all default settings are anti-competitive and outlaws all defaults in the settings.</p> <!----><p data-v-6b73e26c="">"If one of the outcomes of the trial is that there needs to be more neutral choices, it wouldn't just affect Google on Android phones, it could also affect Apple and the iPhone," Schaub said. "Does it mean Google phones might have to offer (Apple's virtual assistant) Siri as an alternative to the Google Assistant? Or would Apple devices have to offer Google Assistant?"</p> <!----><p data-v-6b73e26c="">A decision like that would open a crack in the digital wall that Apple has built around the iPhone to give its own software and certain pet products such as Siri exclusive access to the device's more than 1 billion users, setting the stage for another potential legal battle.</p> <!---->  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Build a Universe That Doesn’t Fall Apart Two Days Later (1978) (181 pts)]]></title>
            <link>https://urbigenous.net/library/how_to_build.html</link>
            <guid>37896157</guid>
            <pubDate>Mon, 16 Oct 2023 05:17:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://urbigenous.net/library/how_to_build.html">https://urbigenous.net/library/how_to_build.html</a>, See on <a href="https://news.ycombinator.com/item?id=37896157">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text">

<h2>Philip K. Dick, 1978</h2>
<p>
First, before I begin to bore you with the usual sort of things science fiction writers say in speeches, let me bring you official greetings from Disneyland. I consider myself a spokesperson for Disneyland because I live just a few miles from it — and, as if that were not enough, I once had the honor of being interviewed there by Paris TV.
</p>
<p>
For several weeks after the interview, I was really ill and confined to bed. I think it was the whirling teacups that did it. Elizabeth Antebi, who was the producer of the film, wanted to have me whirling around in one of the giant teacups while discussing the rise of fascism with Norman Spinrad… an old friend of mine who writes excellent science fiction. We also discussed Watergate, but we did that on the deck of Captain Hook’s pirate ship. Little children wearing Mickey Mouse hats — those black hats with the ears — kept running up and bumping against us as the cameras whirred away, and Elizabeth asked unexpected questions. Norman and I, being preoccupied with tossing little children about, said some extraordinarily stupid things that day. Today, however, I will have to accept full blame for what I tell you, since none of you are wearing Mickey Mouse hats and trying to climb up on me under the impression that I am part of the rigging of a pirate ship.
</p>
<p>
Science fiction writers, I am sorry to say, really do not know anything. We can’t talk about science, because our knowledge of it is limited and unofficial, and usually our fiction is dreadful. A few years ago, no college or university would ever have considered inviting one of us to speak. We were mercifully confined to lurid pulp magazines, impressing no one. In those days, friends would say me, “But are you writing anything serious?” meaning “Are you writing anything other than science fiction?” We longed to be accepted. We yearned to be noticed. Then, suddenly, the academic world noticed us, we were invited to give speeches and appear on panels — and immediately we made idiots of ourselves. The problem is simply this: What does a science fiction writer know about? On what topic is he an authority?
</p>
<p>
It reminds me of a headline that appeared in a California newspaper just before I flew here. <strong>SCIENTISTS SAY THAT MICE CANNOT BE MADE TO LOOK LIKE HUMAN BEINGS</strong>. It was a federally funded research program, I suppose. Just think: Someone in this world is an authority on the topic of whether mice can or cannot put on two-tone shoes, derby hats, pinstriped shirts, and Dacron pants, and pass as humans.
</p>
<p>
Well, I will tell you what interests me, what I consider important. I can’t claim to be an authority on anything, but I can honestly say that certain matters absolutely fascinate me, and that I write about them all the time. The two basic topics which fascinate me are “What is reality?” and “What constitutes the authentic human being?” Over the twenty-seven years in which I have published novels and stories I have investigated these two interrelated topics over and over again. I consider them important topics. What are we? What is it which surrounds us, that we call the not-me, or the empirical or phenomenal world?
</p>
<p>
In 1951, when I sold my first story, I had no idea that such fundamental issues could be pursued in the science fiction field. I began to pursue them unconsciously. My first story had to do with a dog who imagined that the garbage men who came every Friday morning were stealing valuable food which the family had carefully stored away in a safe metal container. Every day, members of the family carried out paper sacks of nice ripe food, stuffed them into the metal container, shut the lid tightly — and when the container was full, these dreadful-looking creatures came and stole everything but the can.
</p>
<p>
Finally, in the story, the dog begins to imagine that someday the garbage men will eat the people in the house, as well as stealing their food. Of course, the dog is wrong about this. We all know that garbage men do not eat people. But the dog’s extrapolation was in a sense logical — given the facts at his disposal. The story was about a real dog, and I used to watch him and try to get inside his head and imagine how he saw the world. Certainly, I decided, that dog sees the world quite differently than I do, or any humans do. And then I began to think, Maybe each human being lives in a unique world, a private world, a world different from those inhabited and experienced by all other humans. And that led me wonder, If reality differs from person to person, can we speak of reality singular, or shouldn’t we really be talking about plural realities? And if there are plural realities, are some more true (more real) than others? What about the world of a schizophrenic? Maybe, it’s as real as our world. Maybe we cannot say that we are in touch with reality and he is not, but should instead say, His reality is so different from ours that he can’t explain his to us, and we can’t explain ours to him. The problem, then, is that if subjective worlds are experienced too differently, there occurs a breakdown of communication… and there is the real illness.
</p>
<p>
I once wrote a story about a man who was injured and taken to a hospital. When they began surgery on him, they discovered that he was an android, not a human, but that he did not know it. They had to break the news to him. Almost at once, Mr. Garson Poole discovered that his reality consisted of punched tape passing from reel to reel in his chest. Fascinated, he began to fill in some of the punched holes and add new ones. Immediately, his world changed. A flock of ducks flew through the room when he punched one new hole in the tape. Finally he cut the tape entirely, whereupon the world disappeared. However, it also disappeared for the other characters in the story… which makes no sense, if you think about it. Unless the other characters were figments of his punched-tape fantasy. Which I guess is what they were.
</p>
<p>
It was always my hope, in writing novels and stories which asked the question “What is reality?”, to someday get an answer. This was the hope of most of my readers, too. Years passed. I wrote over thirty novels and over a hundred stories, and still I could not figure out what was real. One day a girl college student in Canada asked me to define reality for her, for a paper she was writing for her philosophy class. She wanted a one-sentence answer. I thought about it and finally said, “Reality is that which, when you stop believing in it, doesn’t go away.” That’s all I could come up with. That was back in 1972. Since then I haven’t been able to define reality any more lucidly.
</p>
<p>
But the problem is a real one, not a mere intellectual game. Because today we live in a society in which spurious realities are manufactured by the media, by governments, by big corporations, by religious groups, political groups — and the electronic hardware exists by which to deliver these pseudo-worlds right into the heads of the reader, the viewer, the listener. Sometimes when I watch my eleven-year-old daughter watch TV, I wonder what she is being taught. The problem of miscuing; consider that. A TV program produced for adults is viewed by a small child. Half of what is said and done in the TV drama is probably misunderstood by the child. Maybe it’s all misunderstood. And the thing is, Just how authentic is the information anyhow, even if the child correctly understood it? What is the relationship between the average TV situation comedy to reality? What about the cop shows? Cars are continually swerving out of control, crashing, and catching fire. The police are always good and they always win. Do not ignore that point: The police always win. What a lesson that is. You should not fight authority, and even if you do, you will lose. The message here is, Be passive. And — cooperate. If Officer Baretta asks you for information, give it to him, because Officer Baretta is a good man and to be trusted. He loves you, and you should love him.
</p>
<p>
So I ask, in my writing, What is real? Because unceasingly we are bombarded with pseudo-realities manufactured by very sophisticated people using very sophisticated electronic mechanisms. I do not distrust their motives; I distrust their power. They have a lot of it. And it is an astonishing power: that of creating whole universes, universes of the mind. I ought to know. I do the same thing. It is my job to create universes, as the basis of one novel after another. And I have to build them in such a way that they do not fall apart two days later. Or at least that is what my editors hope. However, I will reveal a secret to you: I like to build universes which do fall apart. I like to see them come unglued, and I like to see how the characters in the novels cope with this problem. I have a secret love of chaos. There should be more of it. Do not believe — and I am dead serious when I say this — do not assume that order and stability are always good, in a society or in a universe. The old, the ossified, must always give way to new life and the birth of new things. Before the new things can be born the old must perish. This is a dangerous realization, because it tells us that we must eventually part with much of what is familiar to us. And that hurts. But that is part of the script of life. Unless we can psychologically accommodate change, we ourselves begin to die, inwardly. What I am saying is that objects, customs, habits, and ways of life must perish so that the authentic human being can live. And it is the authentic human being who matters most, the viable, elastic organism which can bounce back, absorb, and deal with the new.
</p>
<p>
Of course, I would say this, because I live near Disneyland, and they are always adding new rides and destroying old ones. Disneyland is an evolving organism. For years they had the Lincoln Simulacrum, like Lincoln himself, was only a temporary form which matter and energy take and then lose. The same is true of each of us, like it or not.
</p>
<p>
The pre-Socratic Greek philosopher Parmenides taught that the only things that are real are things which never change… and the pre-Socratic Greek philosopher Heraclitus taught that everything changes. If you superimpose their two views, you get this result: Nothing is real. There is a fascinating next step to this line of thinking: Parmenides could never have existed because he grew old and died and disappeared, so, according to his own philosophy, he did not exist. And Heraclitus may have been right — let’s not forget that; so if Heraclitus was right, then Parmenides did exist, and therefore, according to Heraclitus’ philosophy, perhaps Parmenides was right, since Parmenides fulfilled the conditions, the criteria, by which Heraclitus judged things real.
</p>
<p>
I offer this merely to show that as soon as you begin to ask what is ultimately real, you right away begin talk nonsense. Zeno proved that motion was impossible (actually he only imagined that he had proved this; what he lacked was what technically is called the “theory of limits”). David Hume, the greatest skeptic of them all, once remarked that after a gathering of skeptics met to proclaim the veracity of skepticism as a philosophy, all of the members of the gathering nonetheless left by the door rather than the window. I see Hume’s point. It was all just talk. The solemn philosophers weren’t taking what they said seriously.
</p>
<p>
But I consider that the matter of defining what is real — that is a serious topic, even a vital topic. And in there somewhere is the other topic, the definition of the authentic human. Because the bombardment of pseudo-realities begins to produce inauthentic humans very quickly, spurious humans — as fake as the data pressing at them from all sides. My two topics are really one topic; they unite at this point. Fake realities will create fake humans. Or, fake humans will generate fake realities and then sell them to other humans, turning them, eventually, into forgeries of themselves. So we wind up with fake humans inventing fake realities and then peddling them to other fake humans. It is just a very large version of Disneyland. You can have the <span>Pirate Ride</span> or the <span>Lincoln Simulacrum</span> or <span>Mr. Toad’s Wild Ride</span> — you can have all of them, but none is true.
</p>
<p>
In my writing I got so interested in fakes that I finally came up with the concept of fake fakes. For example, in Disneyland there are fake birds worked by electric motors which emit caws and shrieks as you pass by them. Suppose some night all of us sneaked into the park with real birds and substituted them for the artificial ones. Imagine the horror the Disneyland officials would feel when they discovered the cruel hoax. Real birds! And perhaps someday even real hippos and lions. Consternation. The park being cunningly transmuted from the unreal to the real, by sinister forces. For instance, suppose the Matterhorn turned into a genuine snow-covered mountain? What if the entire place, by a miracle of God’s power and wisdom, was changed, in a moment, in the blink of an eye, into something incorruptible? They would have to close down.
</p>
<p>
In Plato’s <span>Timaeus</span>, God does not create the universe, as does the Christian God; He simply finds it one day. It is in a state of total chaos. God sets to work to transform the chaos into order. That idea appeals to me, and I have adapted it to fit my own intellectual needs: What if our universe started out as not quite real, a sort of illusion, as the Hindu religion teaches, and God, out of love and kindness for us, is slowly transmuting it, slowly and secretly, into something real?
</p>
<p>
We would not be aware of this transformation, since we were not aware that our world was an illusion in the first place. This technically is a Gnostic idea. Gnosticism is a religion which embraced Jews, Christians, and pagans for several centuries. I have been accused of holding Gnostic ideas. I guess I do. At one time I would have been burned. But some of their ideas intrigue me. One time, when I was researching Gnosticism in the Britannica, I came across mention of a Gnostic codex called <span>The Unreal God and the Aspects of His Nonexistent Universe</span>, an idea which reduced me to helpless laughter. What kind of person would write about something that he knows doesn’t exist, and how can something that doesn’t exist have aspects? But then I realized that I’d been writing about these matters for over twenty-five years. I guess there is a lot of latitude in what you can say when writing about a topic that does not exist. A friend of mine once published a book called <span>Snakes of Hawaii</span>. A number of libraries wrote him ordering copies. Well, there are no snakes in Hawaii. All the pages of his book were blank.
</p>
<p>
Of course, in science fiction no pretense is made that the worlds described are real. This is why we call it fiction. The reader is warned in advance not to believe what he is about to read. Equally true, the visitors to Disneyland understand that Mr. Toad does not really exist and that the pirates are animated by motors and servo-assist mechanisms, relays and electronic circuits. So no deception is taking place.
</p>
<p>
And yet the strange thing is, in some way, some real way, much of what appears under the title “science fiction” is true. It may not be literally true, I suppose. We have not really been invaded by creatures from another star system, as depicted in <span>Close Encounters of the Third Kind</span>. The producers of that film never intended for us to believe it. Or did they?
</p>
<p>
And, more important, if they did intend to state this, is it actually true? That is the issue: not, Does the author or producer believe it, but — Is it true? Because, quite by accident, in the pursuit of a good yarn, a science fiction author or producer or scriptwriter might stumble onto the truth… and only later on realize it.
</p>
<p>
The basic tool for the manipulation of reality is the manipulation of words. If you can control the meaning of words, you can control the people who must use the words. George Orwell made this clear in his novel 1984. But another way to control the minds of people is to control their perceptions. If you can get them to see the world as you do, they will think as you do. Comprehension follows perception. How do you get them to see the reality you see? After all, it is only one reality out of many. Images are a basic constituent: pictures. This is why the power of TV to influence young minds is so staggeringly vast. Words and pictures are synchronized. The possibility of total control of the viewer exists, especially the young viewer. TV viewing is a kind of sleep-learning. An EEG of a person watching TV shows that after about half an hour the brain decides that nothing is happening, and it goes into a hypnoidal twilight state, emitting alpha waves. This is because there is such little eye motion. In addition, much of the information is graphic and therefore passes into the right hemisphere of the brain, rather than being processed by the left, where the conscious personality is located. Recent experiments indicate that much of what we see on the TV screen is received on a subliminal basis. We only imagine that we consciously see what is there. The bulk of the messages elude our attention; literally, after a few hours of TV watching, we do not know what we have seen. Our memories are spurious, like our memories of dreams; the blanks are filled in retrospectively. And falsified. We have participated unknowingly in the creation of a spurious reality, and then we have obligingly fed it to ourselves. We have colluded in our own doom.
</p>
<p>
And — and I say this as a professional fiction writer — the producers, scriptwriters, and directors who create these video/audio worlds do not know how much of their content is true. In other words, they are victims of their own product, along with us. Speaking for myself, I do not know how much of my writing is true, or which parts (if any) are true. This is a potentially lethal situation. We have fiction mimicking truth, and truth mimicking fiction. We have a dangerous overlap, a dangerous blur. And in all probability it is not deliberate. In fact, that is part of the problem. You cannot legislate an author into correctly labeling his product, like a can of pudding whose ingredients are listed on the label… you cannot compel him to declare what part is true and what isn’t if he himself does not know.
</p>
<p>
It is an eerie experience to write something into a novel, believing it is pure fiction, and to learn later on — perhaps years later — that it is true. I would like to give you an example. It is something that I do not understand. Perhaps you can come up with a theory. I can’t.
</p>
<p>
In 1970 I wrote a novel called <span>Flow My Tears, the Policeman Said</span>. One of the characters is a nineteen-year-old girl named Kathy. Her husband’s name is Jack. Kathy appears to work for the criminal underground, but later, as we read deeper into the novel, we discover that actually she is working for the police. She has a relationship going on with a police inspector. The character is pure fiction. Or at least I thought it was.
</p>
<p>
Anyhow, on Christmas Day of 1970, I met a girl named Kathy — this was after I had finished the novel, you understand. She was nineteen years old. Her boyfriend was named Jack. I soon learned that Kathy was a drug dealer. I spent months trying to get her to give up dealing drugs; I kept warning her again and again that she would get caught. Then, one evening as we were entering a restaurant together, Kathy stopped short and said, “I can’t go in.” Seated in the restaurant was a police inspector whom I knew. “I have to tell you the truth,” Kathy said. “I have a relationship with him.”
</p>
<p>
Certainly, these are odd coincidences. Perhaps I have precognition. But the mystery becomes even more perplexing; the next stage totally baffles me. It has for four years.
</p>
<p>
In 1974 the novel was published by Doubleday. One afternoon I was talking to my priest — I am an Episcopalian — and I happened to mention to him an important scene near the end of the novel in which the character Felix Buckman meets a black stranger at an all-night gas station, and they begin to talk. As I described the scene in more and more detail, my priest became progressively more agitated. At last he said, “That is a scene from the Book of Acts, from the Bible! In Acts, the person who meets the black man on the road is named Philip — your name.” Father Rasch was so upset by the resemblance that he could not even locate the scene in his Bible. “Read Acts,” he instructed me. “And you’ll agree. It’s the same down to specific details.”
</p>
<p>
I went home and read the scene in Acts. Yes, Father Rasch was right; the scene in my novel was an obvious retelling of the scene in Acts… and I had never read Acts, I must admit. But again the puzzle became deeper. In Acts, the high Roman official who arrests and interrogates Saint Paul is named Felix — the same name as my character. And my character Felix Buckman is a high-ranking police general; in fact, in my novel he holds the same office as Felix in the Book of Acts: the final authority. There is a conversation in my novel which very closely resembles a conversation between Felix and Paul.
</p>
<p>
Well, I decided to try for any further resemblances. The main character in my novel is named Jason. I got an index to the Bible and looked to see if anyone named Jason appears anywhere in the Bible. I couldn’t remember any. Well, a man named Jason appears once and only once in the Bible. It is in the Book of Acts. And, as if to plague me further with coincidences, in my novel Jason is fleeing from the authorities and takes refuge in a person’s house, and in Acts the man named Jason shelters a fugitive from the law in his house — an exact inversion of the situation in my novel, as if the mysterious Spirit responsible for all this was having a sort of laugh about the whole thing.
</p>
<p>
Felix, Jason, and the meeting on the road with the black man who is a complete stranger. In Acts, the disciple Philip baptizes the black man, who then goes away rejoicing. In my novel, Felix Buckman reaches out to the black stranger for emotional support, because Felix Buckman’s sister has just died and he is falling apart psychologically. The black man stirs up Buckman’s spirits and although Buckman does not go away rejoicing, at least his tears have stopped falling. He had been flying home, weeping over the death of his sister, and had to reach out to someone, anyone, even a total stranger. It is an encounter between two strangers on the road which changes the life of one of them — both in my novel and in Acts. And one final quirk by the mysterious Spirit at work: the name Felix is the Latin word for “happy.” Which I did not know when I wrote the novel.
</p>
<p>
A careful study of my novel shows that for reasons which I cannot even begin to explain I had managed to retell several of the basic incidents from a particular book of the Bible, and even had the right names. What could explain this? That was four years ago that I discovered all this. For four years I have tried to come up with a theory and I have not. I doubt if I ever will.
</p>
<p>
But the mystery had not ended there, as I had imagined. Two months ago I was walking up to the mailbox late at night to mail off a letter, and also to enjoy the sight of Saint Joseph’s Church, which sits opposite my apartment building. I noticed a man loitering suspiciously by a parked car. It looked as if he was attempting to steal the car, or maybe something from it; as I returned from the mailbox, the man hid behind a tree. On impulse I walked up to him and asked, “Is anything the matter?”
</p>
<p>
“I’m out of gas,” the man said. “And I have no money.”
</p>
<p>
Incredibly, because I have never done this before, I got out my wallet, took all the money from it, and handed the money to him. He then shook hands with me and asked where I lived, so that he could later pay the money back. I returned to my apartment, and then I realized that the money would do him no good, since there was no gas station within walking distance. So I returned, in my car. The man had a metal gas can in the trunk of his car, and, together, we drove in my car to an all-night gas station. Soon we were standing there, two strangers, as the pump jockey filled the metal gas can. Suddenly I realized that this was the scene in my novel — the novel written eight years before. The all-night gas station was exactly as I had envisioned it in my inner eye when I wrote the scene — the glaring white light, the pump jockey — and now I saw something which I had not seen before. The stranger who I was helping was black. We drove back to his stalled car with the gas, shook hands, and then I returned to my apartment building. I never saw him again. He could not pay me back because I had not told him which of the many apartments was mine or what my name was. I was terribly shaken up by this experience. I had literally lived out a scene completely as it had appeared in my novel. Which is to say, I had lived out a sort of replica of the scene in Acts where Philip encounters the black man on the road.
</p>
<p>
What could explain all this?
</p>
<p>
The answer I have come up with may not be correct, but it is the only answer I have. It has to do with time. My theory is this: In some certain important sense, time is not real. Or perhaps it is real, but not as we experience it to be or imagine it to be. I had the acute, overwhelming certitude (and still have) that despite all the change we see, a specific permanent landscape underlies the world of change: and that this invisible underlying landscape is that of the Bible; it, specifically, is the period immediately following the death and resurrection of Christ; it is, in other words, the time period of the Book of Acts.
</p>
<p>
Parmenides would be proud of me. I have gazed at a constantly changing world and declared that underneath it lies the eternal, the unchanging, the absolutely real. but how has this come about? If the real time is circa A.D. 50, then why do we see A.D. 1978? And if we are really living in the Roman Empire, somewhere in Syria, why do we see the United States?
</p>
<p>
During the Middle Ages, a curious theory arose, which I will now present to you for what it is worth. It is the theory that the Evil One — Satan — is the “Ape of God.” That he creates spurious imitations of creation, of God’s authentic creation, and then interpolates them for that authentic creation. Does this odd theory help explain my experience? Are we to believe that we are occluded, that we are deceived, that it is not 1978 but A.D. 50… and Satan has spun a counterfeit reality to wither our faith in the return of Christ?
</p>
<p>
I can just picture myself being examined by a psychiatrist. The psychiatrist says, “What year is it?” And I reply, “A.D. 50.” The psychiatrist blinks and then asks, “And where are you?” I reply, “In Judaea.” “Where the heck is that?” the psychiatrist asks. “It’s part of the Roman Empire,” I would have to answer. “Do you know who is President?” the psychiatrist would ask, and I would answer, “The Procurator Felix.” “You’re pretty sure about this?” the psychiatrist would ask, meanwhile giving a covert signal to two very large psych techs. “Yep,” I’d replay. “Unless Felix has stepped down and had been replaced by the Procurator Festus. You see, Saint Paul was held by Felix for —” “Who told you all this?” the psychiatrist would break in, irritably, and I would reply, “The Holy Spirit.” And after that I’d be in the rubber room, inside gazing out, and knowing exactly how come I was there. Everything in that conversation would be true, in a sense, although palpably not true in another. I know perfectly well that the date is 1978 and that Jimmy Carter is President and that I live in Santa Ana, California, in the United States. I even know how to get from my apartment to Disneyland, a fact I can’t seem to forget. And surely no Disneyland existed back at the time of Saint Paul.
</p>
<p>
So, if I force myself to be very rational and reasonable, and all those other good things, I must admit that the existence of Disneyland (which I know is real) proves that we are not living in Judaea in A.D. 50. The idea of Saint Paul whirling around in the giant teacups while composing First Corinthians, as Paris TV films him with a telephoto lens — that just can’t be. Saint Paul would never go near Disneyland. Only children, tourists, and visiting Soviet high officials ever go to Disneyland. Saints do not.
</p>
<p>
But somehow that biblical material snared my unconscious and crept into my novel, and equally true, for some reason in 1978 I relived a scene which I described back in 1970. What I am saying is this: There is internal evidence in at least one of my novels that another reality, an unchanging one, exactly as Parmenides and Plato suspected, underlies the visible phenomenal world of change, and somehow, in some way, perhaps to our surprise, we can cut through to it. Or rather, a mysterious Spirit can put us in touch with it, if it wishes us to see this permanent other landscape. Time passes, thousands of years pass, but at the same instant that we see this contemporary world, the ancient world, the world of the Bible, is concealed beneath it, still there and still real. Eternally so.
</p>
<p>
Shall I go for broke and tell you the rest of this peculiar story? I’ll do so, having gone this far already. My novel <span>Flow My Tears, the Policeman Said</span> was released by Doubleday in February of 1974. The week after it was released, I had two impacted wisdom teeth removed, under sodium pentathol. Later that day I found myself in intense pain. My wife phoned the oral surgeon and he phoned a pharmacy. Half an hour later there was a knock at my door: the delivery person from the pharmacy with the pain medication. Although I was bleeding and sick and weak, I felt the need to answer the knock on the door myself. When I opened the door, I found myself facing a young woman — who wore a shining gold necklace in the center of which was a gleaming gold fish. For some reason I was hypnotized by the gleaming golden fish; I forgot my pain, forgot the medication, forgot why the girl was there. I just kept staring at the fish sign.
</p>
<p>
“What does that mean?” I asked her.
</p>
<p>
The girl touched the glimmering golden fish with her hand and said, “This is a sign worn by the early Christians.” She then gave me the package of medication.
</p>
<p>
In that instant, as I stared at the gleaming fish sign and heard her words, I suddenly experienced what I later learned is called anamnesis — a Greek word meaning, literally, “loss of forgetfulness.” I remembered who I was and where I was. In an instant, in the twinkling of an eye, it all came back to me. And not only could I remember it but I could see it. The girl was a secret Christian and so was I. We lived in fear of detection by the Romans. We had to communicate with cryptic signs. She had just told me all this, and it was true.
</p>
<p>
For a short time, as hard as this is to believe or explain, I saw fading into view the black prison-like contours of hateful Rome. But, of much more importance, I remembered Jesus, who had just recently been with us, and had gone temporarily away, and would very soon return. My emotion was one of joy. We were secretly preparing to welcome Him back. It would not be long. And the Romans did not know. They thought He was dead, forever dead. That was our great secret, our joyous knowledge. Despite all appearances, Christ was going to return, and our delight and anticipation was boundless.
</p>
<p>
Isn’t it odd that this strange event, this recovery of lost memory, occurred only a week after <span>Flow My Tears</span> was released? And it is <span>Flow My Tears</span> which contains the replication of people and events from the Book of Acts, which is set at the precise moment in time — just after Jesus’ death and resurrection — that I remembered, by means of the golden fish sign, as having just taken place?
</p>
<p>
If you were me, and had this happen to you, I’m sure you wouldn’t be able to leave it alone. You would seek a theory that would account for it. For over four years now, I have been trying one theory after another: circular time, frozen time, timeless time, what is called “sacred” as contrasted to “mundane” time… I can’t count the theories I’ve tried out. One constant has prevailed, though, throughout all theories. There must indeed be a mysterious Holy Spirit which has an exact and intimate relation to Christ, which can indwell in human minds, guide and inform them, and even express itself through those humans, even without their awareness.
</p>
<p>
In the writing of <span>Flow My Tears</span>, back in 1970, there was one unusual event which I realized at the time was not ordinary, was not a part of the regular writing process. I had a dream one night, an especially vivid dream. And when I awoke I found myself under the compulsion — the absolute necessity — of getting the dream into the text of the novel precisely as I had dreamed it. In getting the dream exactly right, I had to do eleven drafts of the final part of the manuscript, until I was satisfied.
</p>
<p>
I will now quote from the novel, as it appeared in the final, published form. See if this dream reminds you of anything.
</p>
<blockquote cite="https://www.librarything.com/work/3368">
The countryside, brown and dry, in summer, where he had lived as a child. He rode a horse, and approaching him on his left a squad of horses nearing slowly. On the horses rode men in shining robes, each a different color; each wore a pointed helmet that sparkled in the sunlight. The slow, solemn knights passed him and as they traveled by he made out the face of one: an ancient marble face, a terribly old man with rippling cascades of white beard. What a strong nose he had. What noble features. So tired, so serious, so far beyond ordinary men. Evidently he was a king. Felix Buckman let them pass; he did not speak to them and they said nothing to him. Together, they all moved toward the house from which he had come. A man had sealed himself up inside the house, a man alone, Jason Taverner, in the silence and darkness, without windows, by himself from now on into eternity. Sitting, merely existing, inert. Felix Buckman continued on, out into the open countryside. And then he heard from behind him one dreadful single shriek. They had killed Taverner, and seeing them enter, sensing them in the shadows around him, knowing what they intended to do with him, Taverner had shrieked. Within himself Felix Buckman felt absolute and utter desolate grief. But in the dream he did not go back nor look back. There was nothing that could be done. No one could have stopped the posse of varicolored men in robes; they could not have been said no to. Anyhow, it was over. Taverner was dead.
</blockquote>
<p>
This passage probably does not suggest any particular thing to you, except a law posse exacting judgment on someone either guilty or considered guilty. It is not clear whether Taverner has in fact committed some crime or is merely believed to have committed some crime. I had the impression that he was guilty, but that it was a tragedy that he had to be killed, a terribly sad tragedy. In the novel, this dream causes Felix Buckman to begin to cry, and therefore he seeks out the black man at the all-night gas station.
</p>
<p>
Months after the novel was published, I found the section in the Bible to which this dream refers. It is Daniel, 7:9:
</p>
<blockquote cite="https://www.biblegateway.com/verse/en/Daniel%207:9">
Thrones were set in place and one ancient in years took his seat. His robe was white as snow and the hair of his head like cleanest wool. Flames of fire were his throne and its wheels blazing fire; a flowing river of fire streamed out before him. Thousands upon thousands served him and myriads upon myriads attended his presence. The court sat, and the book was opened.
</blockquote>
<p>
The white-haired old man appears again in Revelation, 1:13:
</p>
<blockquote cite="https://www.biblegateway.com/verse/en/Revelation%201:13">
I saw… one like a son of man, robed down to his feet, with a golden girdle round his breast. The hair of his head was white as snow-white wool, and his eyes flamed like fire; his feet gleamed like burnished brass refined in a furnace, and his voice was like the sound of rushing waters.
</blockquote>
<p>
And then 1:17:
</p>
<blockquote cite="https://www.biblegateway.com/verse/en/Revelation%201:17">
When I saw him, I fell at his feet as though dead. But he laid his right hand upon me and said, “Do not be afraid. I am the first and the last, and I am the living one, for I was dead and now I am alive for evermore, and I hold the keys of Death and Death’s domain. Write down therefore what you have seen, what is now, and what will be hereafter.”
</blockquote>
<p>
And, like John of Patmos, I faithfully wrote down what I saw and put in my novel. And it was true, although at the time I did not know who was meant by this description:
</p>
<blockquote cite="https://www.librarything.com/work/3368">
…he made out the face of one: an ancient marble face, a terribly old man with rippling cascades of white beard. What a strong nose he had. What noble features. So tired, so serious, so far beyond ordinary men. Evidently he was a king.
</blockquote>
<p>
Indeed he was a king. He is Christ Himself returned, to pass judgment. And this is what he does in my novel: He passes judgment on the man sealed up in darkness. The man sealed up in darkness must be the Prince of Evil, the Force of Darkness. Call it whatever you wish, its time had come. It was judged and condemned. Felix Buckman could weep at the sadness of it, but he knew that the verdict could not be disputed. And so he rode on, without turning or looking back, hearing only the shriek of fear and defeat: the cry of evil destroyed.
</p>
<p>
So my novel contained material from other parts of the Bible, as well as the sections from Acts. Deciphered, my novel tells a quite different story from the surface story (which we need not go into here). The real story is simply this: the return of Christ, now king rather than suffering servant. Judge rather than victim of unfair judgment. Everything is reversed. The core message of my novel, without my knowing it, was a warning to the powerful: You will shortly be judged and condemned. Who, specifically, did it refer to? Well, I can’t really say; or rather would prefer not to say. I have no certain knowledge, only an intuition. And that is not enough to go on, so I will keep my thoughts to myself. But you might ask yourselves what political events took place in this country between February 1974 and August 1974. Ask yourself who was judged and condemned, and fell like a flaming star into ruin and disgrace. The most powerful man in the world. And I feel as sorry for him now as I did when I dreamed that dream. “That poor poor man,” I said once to my wife, with tears in my eyes. “Shut up in the darkness, playing the piano in the night to himself, alone and afraid, knowing what’s to come.” For God’s sake, let us forgive him, finally. But what was done to him and all his men — “all the President’s men,” as it’s put — had to be done. But it is over, and he should be let out into the sunlight again; no creature, no person, should be shut up in darkness forever, in fear. It is not humane.
</p>
<p>
Just about the time that Supreme Court was ruling that the Nixon tapes had to be turned over to the special prosecutor, I was eating at a Chinese restaurant in Yorba Linda, the town in California where Nixon went to school — where he grew up, worked at a grocery store, where there is a park named after him, and of course the Nixon house, simple clapboard and all that. In my fortune cookie, I got the following fortune:
</p>
<blockquote>
DEEDS DONE IN SECRET HAVE A WAY OF BECOMING FOUND OUT.
</blockquote>
<p>
I mailed the slip of paper to the White House, mentioning that the Chinese restaurant was located within a mile of Nixon’s original house, and I said, “I think a mistake has been made; by accident I got Mr. Nixon’s fortune. Does he have mine?” The White House did not answer.
</p>
<p>
Well, as I said earlier, an author of a work supposed fiction might write the truth and not know it. To quote Xenophanes, another pre-Socratic: <q cite="https://archive.org/details/presocratics00huss/page/35/mode/1up">Even if a man should chance to speak the most complete truth, yet he himself does not know it; all things are wrapped in appearances</q> (Fragment 34). And Heraclitus added to this: <q cite="https://archive.org/details/presocratics00huss/page/35/mode/1up">The nature of things is in the habit of concealing itself</q> (Fragment 54). W. S. Gilbert, of Gilbert and Sullivan, put it: “Things are seldom what they seem; skim milk masquerades as cream.” The point of all that is that we cannot trust our senses and probably not even our a priori reasoning. As to our senses, I understand that people who have been blind from birth and are suddenly given sight are amazed to discover that objects appear to get smaller and smaller as they get farther away. Logically, there is no reason for this. We, of course, have come to accept this, because we are used to it. We see objects get smaller, but we know that in actuality they remain the same size. So even the common everyday pragmatic person utilizes a certain amount of sophisticated discounting of what his eyes and ears tell him.
</p>
<p>
Little of what Heraclitus wrote has survived, and what we do have is obscure, but Fragment 54 is lucid and important: <q cite="https://archive.org/details/presocratics00huss/page/35/mode/1up">Latent structure is master of obvious structure.</q> This means that Heraclitus believed that a veil lay over the true landscape. He also may have suspected that time was somehow not what it seemed, because in Fragment 52 he said: <q cite="https://archive.org/details/presocratics00huss/page/48/mode/1up">Time is a child at play, playing draughts; a child’s is the kingdom.</q> This is indeed cryptic. But he also said, in Fragment 18: “If one does not expect it, one will not find out the unexpected; it is not to be tracked down and no path leads us to it.” Edward Hussey, in his scholarly book <a href="https://archive.org/details/presocratics00huss/"><span>The Pre-Socratics</span></a>, says:
</p>
<blockquote cite="https://archive.org/details/presocratics00huss/page/38/mode/1up">
If Heraclitus is to be so insistent on the lack of understanding shown by most men, it would seem only reasonable that he should offer further instructions for penetrating to the truth. The talk of riddle-guessing suggests that some kind of revelation, beyond human control, is necessary… The true wisdom, as has been seen, is closely associated with God, which suggests further that in advancing wisdom a man becomes like, or a part of, God.
</blockquote>
<p>
This quote is not from a religious book or a book on theology; it is an analysis of the earliest philosophers by a Lecturer in Ancient Philosophy at the University of Oxford. Hussey makes it clear that to these early philosophers there was no distinction between philosophy and religion. The first great quantum leap in Greek theology was by Xenophanes of Colophon, born in the mid-sixth century B.C. Xenophanes, without resorting to any authority except that of his own mind, says:
</p>
<blockquote cite="https://archive.org/details/presocratics00huss/page/13/mode/1up">
One god there is, in no way like mortal creatures either in bodily form or in the thought of his mind. The whole of him sees, the whole of him thinks, the whole of him hears. He stays always motionless in the same place; it is not fitting that he should move about now this way, now that.
</blockquote>
<p>
This is a subtle and advanced concept of God, evidently without precedent among the Greek thinkers. <q>The arguments of Parmenides seemed to show that all reality must indeed be a mind,</q> Hussey writes, <q>or an object of thought in a mind.</q> Regarding Heraclitus specifically, he says, <q>In Heraclitus it is difficult to tell how far the designs in God’s mind are distinguished from the execution in the world, or indeed how far God’s mind is distinguished from the world.</q> The further leap by Anaxagoras has always fascinated me. <q>Anaxagoras had been driven to a theory of the microstructure of matter which made it, to some extent, mysterious to human reason.</q> Anaxagoras believed that everything was determined by Mind. These were not childish thinkers, nor primitives. They debated serious issues and studied one another’s views with deft insight. It was not until the time of Aristotle that their views got reduced to what we can neatly — but wrongly — classify as crude. The summation of much pre-Socratic theology and philosophy can be stated as follows: The <span>kosmos</span> is not as it appears to be, and what it probably is, at its deepest level, is exactly that which the human being is at his deepest level — call it mind or soul, it is something unitary which lives and thinks, and only appears to be plural and material. Much of this view reaches us through the Logos doctrine regarding Christ. The Logos was both that which thought, and the thing which it thought: thinker and thought together. The universe, then, is thinker and thought, and since we are part of it, we as humans are, in the final analysis, thoughts of and thinkers of those thoughts.
</p>
<p>
Thus if God thinks about Rome circa A.D. 50, then Rome circa A.D. 50 is. The universe is not a windup clock and God the hand that winds it. The universe is not a battery-powered watch and God the battery. Spinoza believed that the universe is the body of God extensive in space. But long before Spinoza — two thousand years before him — Xenophanes had said, <q cite="https://archive.org/details/presocratics00huss/page/13/mode/1up">Effortlessly, he wields all things by the thought of his mind</q> (Fragment 25).
</p>
<p>
If any of you have read my novel <span>Ubik</span>, you know that the mysterious entity or mind or force called Ubik starts out as a series of cheap and vulgar commercials and winds up saying:
</p>
<blockquote>
I am Ubik. Before the universe was I am. I made the suns. I made the worlds. I created the lives and the places they inhabit; I move them here, I put them there. They go as I say, they do as I tell them. I am the word and my name is never spoken, the name which no one knows. I am called Ubik, but that is not my name. I am. I shall always be.
</blockquote>
<p>
It is obvious from this who and what Ubik is; it specifically says that it is the word, which is to say, the Logos. In the German translation, there is one of the most wonderful lapses of correct understanding that I have ever come across; God help us if the man who translated my novel <span>Ubik</span> into German were to do a translation from the <span>koine</span> Greek into German of the New Testament. He did all right until he got to the sentence “I am the word.” That puzzled him. What can the author mean by that? he must have asked himself, obviously never having come across the Logos doctrine. So he did as good a job of translation as possible. In the German edition, the Absolute Entity which made the suns, made the worlds, created the lives and the places they inhabit, says of itself:
</p>
<blockquote>
I am the brand name.
</blockquote>
<p>
Had he translated the Gospel according to Saint John, I suppose it would have come out as:
</p>
<blockquote>
When all things began, the brand name already was. The brand name dwelt with God, and what God was, the brand name was.
</blockquote>
<p>
It would seem that I not only bring you greetings from Disneyland but from Mortimer Snerd. Such is the fate of an author who hoped to include theological themes in his writing. “The brand name, then, was with God at the beginning, and through him all things came to be; no single thing was created without him.” So it goes with noble ambitions. Let’s hope God has a sense of humor.
</p>
<p>
Or should I say, Let’s hope the brand name has a sense of humor.
</p>
<p>
As I said to you earlier, my two preoccupations in my writing are “What is reality?” and “What is the authentic human?” I’m sure you can see by now that I have not been able to answer the first question. I have an abiding intuition that somehow the world of the Bible is a literally real but veiled landscape, never changing, hidden from our sight, but available to us by revelation. That is all I can come up with — a mixture of mystical experience, reasoning, and faith. I would like to say something about the traits of the authentic human, though; in this quest I have had more plausible answers.
</p>
<p>
The authentic human being is one of us who instinctively knows what he should not do, and, in addition, he will balk at doing it. He will refuse to do it, even if this brings down dread consequences to him and to those whom he loves. This, to me, is the ultimately heroic trait of ordinary people; they say no to the tyrant and they calmly take the consequences of this resistance. Their deeds may be small, and almost always unnoticed, unmarked by history. Their names are not remembered, nor did these authentic humans expect their names to be remembered. I see their authenticity in an odd way: not in their willingness to perform great heroic deeds but in their quiet refusals. In essence, they cannot be compelled to be what they are not.
</p>
<p>
The power of spurious realities battering at us today — these deliberately manufactured fakes never penetrate to the heart of true human beings. I watch the children watching TV and at first I am afraid of what they are being taught, and then I realize, They can’t be corrupted or destroyed. They watch, they listen, they understand, and, then, where and when it is necessary, they reject. There is something enormously powerful in a child’s ability to withstand the fraudulent. A child has the clearest eye, the steadiest hand. The hucksters, the promoters, are appealing for the allegiance of these small people in vain. True, the cereal companies may be able to market huge quantities of junk breakfasts; the hamburger and hot dog chains may sell endless numbers of unreal fast-food items to the children, but the deep heart beats firmly, unreached and unreasoned with. A child of today can detect a lie quicker than the wisest adult of two decades ago. When I want to know what is true, I ask my children. They do not ask me; I turn to them.
</p>
<p>
One day while my son Christopher, who is four, was playing in front of me and his mother, we two adults began discussing the figure of Jesus in the Synoptic Gospels. Christopher turned toward us for an instant and said, “I am a fisherman. I fish for fish.” He was playing with a metal lantern which someone had given me, which I had never used… and suddenly I realized that the lantern was shaped like a fish. I wonder what thoughts were being placed in my little boy’s soul at that moment — and not placed there by cereal merchants or candy peddlers. “I am a fisherman. I fish for fish.” Christopher, at four, had found the sign I did not find until I was forty-five years old.
</p>
<p>
Time is speeding up. And to what end? Maybe we were told that two thousand years ago. Or maybe it wasn’t really that long ago; maybe it is a delusion that so much time has passed. Maybe it was a week ago, or even earlier today. Perhaps time is not only speeding up; perhaps, in addition, it is going to end.
</p>
<p>
And if it does, the rides at Disneyland are never going to be the same again. Because when time ends, the birds and hippos and lions and deer at Disneyland will no longer be simulations, and, for the first time, a real bird will sing.
</p>
<p>
Thank you.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PaLI-3 Vision Language Models (139 pts)]]></title>
            <link>https://arxiv.org/abs/2310.09199</link>
            <guid>37895601</guid>
            <pubDate>Mon, 16 Oct 2023 03:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.09199">https://arxiv.org/abs/2310.09199</a>, See on <a href="https://news.ycombinator.com/item?id=37895601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+X">Xi Chen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+X">Xiao Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beyer,+L">Lucas Beyer</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolesnikov,+A">Alexander Kolesnikov</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+J">Jialin Wu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Voigtlaender,+P">Paul Voigtlaender</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mustafa,+B">Basil Mustafa</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goodman,+S">Sebastian Goodman</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Alabdulmohsin,+I">Ibrahim Alabdulmohsin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Padlewski,+P">Piotr Padlewski</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Salz,+D">Daniel Salz</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiong,+X">Xi Xiong</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vlasic,+D">Daniel Vlasic</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pavetic,+F">Filip Pavetic</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rong,+K">Keran Rong</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+T">Tianli Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keysers,+D">Daniel Keysers</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhai,+X">Xiaohua Zhai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Soricut,+R">Radu Soricut</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2310.09199.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>This paper presents PaLI-3, a smaller, faster, and stronger vision language model (VLM) that compares favorably to similar models that are 10x larger. As part of arriving at this strong performance, we compare Vision Transformer (ViT) models pretrained using classification objectives to contrastively (SigLIP) pretrained ones. We find that, while slightly underperforming on standard image classification benchmarks, SigLIP-based PaLI shows superior performance across various multimodal benchmarks, especially on localization and visually-situated text understanding. We scale the SigLIP image encoder up to 2 billion parameters, and achieves a new state-of-the-art on multilingual cross-modal retrieval. We hope that PaLI-3, at only 5B parameters, rekindles research on fundamental pieces of complex VLMs, and could fuel a new generation of scaled-up models.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Xiaohua Zhai [<a href="https://arxiv.org/show-email/8223bcae/2310.09199">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 13 Oct 2023 15:45:19 UTC (520 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tech giants are hijacking the internet (168 pts)]]></title>
            <link>https://www.dw.com/en/how-tech-giants-are-hijacking-the-internet/a-67037639</link>
            <guid>37895552</guid>
            <pubDate>Mon, 16 Oct 2023 03:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dw.com/en/how-tech-giants-are-hijacking-the-internet/a-67037639">https://www.dw.com/en/how-tech-giants-are-hijacking-the-internet/a-67037639</a>, See on <a href="https://news.ycombinator.com/item?id=37895552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Their thirst for power is immense: In just a few years, <a href="https://www.dw.com/en/eu-imposes-stricter-rules-on-gatekeeper-tech-giants/a-66733910">US digital platforms</a> have seized control of the internet. They've established <a href="https://www.dw.com/en/us-sues-amazon-for-running-illegal-monopoly/a-66931575">impenetrable monopolies</a> using&nbsp;<a href="https://www.dw.com/en/eu-top-court-sides-with-germany-in-meta-antitrust-case/a-66113717">unethical tactics</a>, manipulating both web traffic and revenue to reap substantial profits,&nbsp;writes&nbsp;German media expert Martin Andree, who has just published the book "Big Tech muss weg!" (Big Tech Must Go!).&nbsp;</p>

<p>In his book, Andree suggests that there's room for resistance until 2029, but, after that, it may become impossible. "If we don't act soon, it could spell the demise of our democracy!" he told DW.</p><figure><img data-format="MASTER_LANDSCAPE" data-id="67019721" data-url="https://static.dw.com/image/67019721_${formatId}.jpg" data-aspect-ratio="16/9" alt="Man speaks into microphone." src="https://static.dw.com/image/67019721_$%7BformatId%7D.jpg"><figcaption>Andree warns against tech giant monopolies<small>Image: Thomas Fedra</small></figcaption></figure>

<p>Martin Andree works as a media researcher at the University of Cologne. In his previous book&nbsp;— "Atlas der digitalen Welt" (Atlas of the Digital World), published in 2020&nbsp;— he had&nbsp;already&nbsp;examined&nbsp;the immense influence being amassed by major US internet platforms.</p>

<p>Andree found in his research that the majority of online activity is concentrated in just a handful of websites, gathering&nbsp;70% of internet traffic, while the remaining digital space resembles a "vast graveyard."</p>

<h2>'Hostile takeover'&nbsp;of the internet</h2>

<p>According to Andree,&nbsp;<a href="https://www.dw.com/en/us-and-google-face-off-in-landmark-antitrust-trial/a-66791773">Google</a>, <a href="https://www.dw.com/en/opinion-while-privacy-concerns-persist-facebook-also-contributes-to-democracy/a-43074574">Facebook</a>, <a href="https://www.dw.com/en/amazon-launches-test-satellites-to-rival-musks-starlink/a-67025821">Amazon</a>&nbsp;and their counterparts have executed a "hostile takeover" of the internet&nbsp;by&nbsp;exploiting regulatory loopholes and thus misleading&nbsp;state institutions. "This leads to a glaring and feudalistic system of regulation," he says, meaning that the companies can dictate the conditions for&nbsp;e-commerce&nbsp;on their platforms&nbsp;or which user data they can collect.</p>

<p>Through strategic lobbying tactics, they have engaged in a protracted game of cat-and-mouse with the authorities for years.&nbsp;</p><figure><img data-format="MASTER_LANDSCAPE" data-id="65630414" data-url="https://static.dw.com/image/65630414_${formatId}.jpg" data-aspect-ratio="16/9" alt="French president Emmanuel Macron (left) and US businessman Elon Musk (right) sitting on chairs in Versailles palace " src="https://static.dw.com/image/65630414_$%7BformatId%7D.jpg"><figcaption>Feudalistic system of regulations as tech giants play a cat-and-mouse game with authorities<small>Image: MICHEL EULER/AFP</small></figcaption></figure>

<p>Furthermore, advertising invariably gravitates toward where the audience and purchasers are. Consequently, profits funnel into the treasuries of tech giants, helping them to amass wealth and, in turn, purchase&nbsp;competitors. Case in point: <a href="https://www.dw.com/en/made-to-measure-creating-a-digital-doppelganger/a-66591191">Facebook</a>&nbsp;(now Meta) acquired the messaging service WhatsApp in 2014. Another instance: <a href="https://www.dw.com/en/elon-musk-takes-control-of-twitter/a-63569400">Elon Musk's billion-dollar acquisition of Twitter</a> (<a href="https://www.dw.com/en/twitter-elon-musk-rebrands-platform-to-x/a-66328568">now X</a>) a year ago.</p>

<h2>Total control of the public</h2>

<p>Media companies, bloggers, public broadcasters,&nbsp;and even global corporations,&nbsp;are the primary victims. They stand no chance against the tech giants. Fewer people visit their websites. When editorial media share content on platforms like Youtube or Instagram, they do so on the platform's terms, without the option to redirect users to their own websites using outlinks. Andree warns that in a few years, a handful of US platforms will control the foundation of our political opinion formation.</p>

<p>Furthermore, the economy is increasingly falling under the dominance of internet giants. More sales and transactions are occurring on these major platforms, all subject to the terms set by big tech companies. Valuable user data is also flowing into their hands. Andree points out that knowledge about customer preferences can be used to unfair advantage and turned into profit, like producing custom products "bypassing manufacturers."</p>

<p>For instance, Amazon offers its product line, "Amazon Basics." Apple, with its payment service, has long been entrenched in the financial industry.</p>

<p>Fair competition, Andree states, is a thing of the past.</p><figure><img data-format="MASTER_LANDSCAPE" data-id="66077353" data-url="https://static.dw.com/image/66077353_${formatId}.jpg" data-aspect-ratio="16/9" alt="Google Logo on a reflective building fassade" src="https://static.dw.com/image/66077353_$%7BformatId%7D.jpg"><figcaption>Big tech has hijacked the internet with unclean methods, says Martin Andree<small>Image: Andrew Kelly/File Photo/Reuters</small></figcaption></figure>

<h2>David against Goliath</h2>

<p>Martin Andree's&nbsp;criticism&nbsp;may sound sharp and, at times, alarmist.&nbsp;</p>

<p>Many voices of caution have emerged since the tech industry's initial mission, rooted in the Californian spirit of the 1960s, to bring new freedom, exchange&nbsp;and transparency to the world.</p><div><h2 aria-label="Embedded video — Turning privacy into profit: Is data the death of democracy?"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20"><g fill-rule="evenodd"><path d="M14.114 7.599H13.5l.002 4.706h.601l4.582 3.25-.005-11.11zM11.084 4.444l-9.007.002-1.336.797.002 9.514 1.334.793 9.007.006 1.509-.799-.004-9.516z"></path></g></svg>Turning privacy into profit: Is data the death of democracy?</h2><video id="video-64897765" controls="" playsinline="" preload="none" poster="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=" data-id="64897765" data-posterurl="https://tvdownloaddw-a.akamaihd.net/vps/stills/webvideos/ENG/2023/BUSI/BUSIENG230306_BB_SurveillanceCapitalism_dir_01SM.jpg" data-duration="28:04"><source src="https://hlsvod.dw.com/i/vps/webvideos/ENG/2023/BUSI/BUSIENG230306_BB_SurveillanceCapitalism_dir_01SM_,AVC_512x288,AVC_960x540,AVC_1280x720,AVC_1920x1080,.mp4.csmil/master.m3u8" type="application/x-mpegURL"><source src="https://tvdownloaddw-a.akamaihd.net/vps/webvideos/ENG/2023/BUSI/BUSIENG230306_BB_SurveillanceCapitalism_dir_01SM_AVC_1920x1080.mp4" type="video/mp4"><p>To view this video please enable JavaScript, and consider upgrading to a web browser that <a href="https://videojs.com/html5-video-support/" target="_blank">supports HTML5 video</a></p></video></div>

<p>Yet, few have explained the "brave new internet world" as comprehensively as Andree, outlining winners and losers so clearly and highlighting the undeniable risks to democracy and the economy.</p>

<p>But&nbsp;Andree remains hopeful: "The internet corporations' concentration of power can be dismantled," he asserts. "We can easily free the internet, reintroduce pluralism into the traffic, and eliminate the existing misregulation."</p>

<h2>Liberating the Internet</h2>

<p>Andree's blueprint for "liberating the internet" is based on 15 core principles. Enforcing open standards to enable users to share videos, images&nbsp;and texts across platforms is paramount. Furthermore, content providers must be granted the freedom&nbsp;to directly link to their websites. Tech giants should also disclose their revenues and profits for proper taxation by countries. Also, it must be ensured&nbsp;that user data is accessible to all competitors. The call is now for legislators and regulators to take action.</p>

<p>"All these measures are cost-effective, and most of them can be swiftly implemented if we genuinely seek a solution," states the author.</p>

<p><em>This article was originally written in German.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cockpit: Web-based graphical interface for servers (324 pts)]]></title>
            <link>https://cockpit-project.org/</link>
            <guid>37895446</guid>
            <pubDate>Mon, 16 Oct 2023 02:48:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cockpit-project.org/">https://cockpit-project.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37895446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <header id="branding" role="banner">

  <section>
    
    

    
      <h2><a href="https://cockpit-project.org/"><img id="logo" alt="Cockpit Project" src="https://cockpit-project.org/images/site/cockpit-logo.svg"></a></h2>
    

    
  </section>

  

    

  

</header>

  <section>
    <p>The easy-to-use, integrated, glanceable, and open web-based interface for your servers</p>
    
    
  </section>
</div><section id="page-wrap" role="main">
<h2 id="introducing-cockpit">Introducing Cockpit</h2>

<p>Cockpit is a web-based graphical interface for servers, intended for everyone, especially those who are:</p>

<ul>
  <li><strong>new to Linux</strong> (including Windows admins)</li>
  <li><strong>familiar with Linux</strong> and want an easy, graphical way to administer servers</li>
  <li><strong>expert admins</strong> who mainly use other tools but want an overview on individual systems</li>
</ul>

<p>Thanks to Cockpit intentionally using system APIs and commands, a whole team of admins can manage a system in the way they prefer, including the command line and utilities right alongside Cockpit.</p>

<h3 id="take-a-look">Take a look</h3>

<p>A picture is worth a thousand words. Click a thumbnail to see screenshots of Cockpit in action.</p>

<p><a href="https://cockpit-project.org/images/screenshot/login-opt.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/login-opt.webp" title="Cockpit's log in prompt (on Fedora 34)" alt="Cockpit's log in prompt (on Fedora 34)"></a><a href="https://cockpit-project.org/images/screenshot/debian-in-windows-edge.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/debian-in-windows-edge.webp" title="Cockpit works where you are (Pictured: Connecting to Debian server from Microsoft Edge on Windows 10)" alt="Cockpit works where you are (Pictured: Connecting to Debian server from Microsoft Edge on Windows 10)"></a><a href="https://cockpit-project.org/images/screenshot/journal.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/journal.webp" title="View, filter, and search system logs" alt="View, filter, and search system logs"></a><a href="https://cockpit-project.org/images/screenshot/accounts.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/accounts.webp" title="Edit accounts" alt="Edit accounts"></a><a href="https://cockpit-project.org/images/screenshot/firewall-rhel.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/firewall-rhel.webp" title="Edit the firewall with ease (Pictured: Cockpit Web Console on Red Hat Enterprise Linux, connected from Fedora 34 Workstation)" alt="Edit the firewall with ease (Pictured: Cockpit Web Console on Red Hat Enterprise Linux, connected from Fedora 34 Workstation)"></a><a href="https://cockpit-project.org/images/screenshot/network-overview.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/network-overview.webp" title="Manage your network" alt="Manage your network"></a><a href="https://cockpit-project.org/images/screenshot/overview-f33.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/overview-f33.webp" title="Have a high-level overview of a server" alt="Have a high-level overview of a server"></a><a href="https://cockpit-project.org/images/screenshot/software-updates-cve-auto.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/software-updates-cve-auto.webp" title="Examine and apply software updates (with changelogs and links to CVEs)" alt="Examine and apply software updates (with changelogs and links to CVEs)"></a><a href="https://cockpit-project.org/images/screenshot/storage-overview.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/storage-overview.webp" title="Look at and manage your storage" alt="Look at and manage your storage"></a><a href="https://cockpit-project.org/images/screenshot/system-services-ssh.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/system-services-ssh.webp" title="See system services" alt="See system services"></a><a href="https://cockpit-project.org/images/screenshot/system-service-details.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/system-service-details.webp" title="Manage an individual system service" alt="Manage an individual system service"></a><a href="https://cockpit-project.org/images/screenshot/vm-create.webp"><img loading="lazy" src="https://cockpit-project.org/images/screenshot/vm-create.webp" title="Create and manage virtual machines" alt="Create and manage virtual machines"></a></p>

<h3 id="simple-to-use">Simple to use</h3>

<p>Cockpit makes Linux discoverable. You don’t <em>have to</em> remember commands at a command-line.</p>

<p>See your server in a web browser and perform system tasks with a mouse. It’s easy to start containers, administer storage, configure networks, and inspect logs.  Basically, you can think of Cockpit like a graphical “desktop interface”, but for individual servers.</p>

<h3 id="compatible-with-your-existing-workflows">Compatible with your existing workflows</h3>

<p>Have a favorite app or command line tool that you use on your servers? 
Keep using the command line, Ansible, and your other favorite tools and add Cockpit to the mix with no issues.</p>

<p>Cockpit uses the same system tooling you would use from the command line. You can switch back and forth between Cockpit and whatever else you like. Cockpit even has a built-in terminal, which is useful when you connect from a non-Linux device.</p>

<h3 id="integrated">Integrated</h3>

<p>Cockpit uses APIs that already exist on the system. It doesn’t reinvent subsystems or add a layer of its own tooling.</p>

<p>By default, Cockpit uses <a href="https://cockpit-project.org/guide/latest/privileges">your system’s normal user logins and privileges</a>. Network-wide logins are also supported through <a href="https://cockpit-project.org/guide/latest/sso">single-sign-on</a> and other <a href="https://cockpit-project.org/guide/latest/authentication">authentication</a> techniques.</p>

<p>Cockpit itself doesn’t eat resources or even run in the background when you’re not using it. It runs on demand, thanks to systemd socket activation.</p>

<h3 id="extendable">Extendable</h3>

<p>Cockpit also supports <a href="https://cockpit-project.org/applications.html">a large list of optional and third-party applications</a>.</p>

<h2 id="using-cockpit">Using Cockpit</h2>

<p>Here’s a subset of tasks you can perform on each host running Cockpit:</p>

<ul>
  <li>Inspect and change network settings</li>
  <li>Configure a firewall</li>
  <li>Manage storage (including <abbr title="Redundant Array of Inexpensive Disks">RAID</abbr> and <abbr title="Linux Unified Key Setup (encryption)">LUKS</abbr> partitions)</li>
  <li>Create and manage virtual machines</li>
  <li>Download and run containers</li>
  <li>Browse and search system logs</li>
  <li>Inspect a system’s hardware</li>
  <li>Upgrade software</li>
  <li>Keep tabs on performance</li>
  <li>Manage user accounts</li>
  <li>Inspect and interact with systemd-based services</li>
  <li>Use a terminal on a remote server in your local web browser</li>
  <li>Switch between <a href="https://cockpit-project.org/guide/latest/feature-machines.html">multiple Cockpit servers</a></li>
  <li>Extend Cockpit’s functionality by installing <a href="https://cockpit-project.org/applications.html">a growing list of apps and add-ons</a></li>
  <li><a href="https://cockpit-project.org/blog/cockpit-starter-kit.html">Write your own custom modules</a> to make Cockpit do anything you want</li>
</ul>

<p>Also troubleshoot and fix pesky problems with ease:</p>

<ul>
  <li>Diagnose network issues</li>
  <li>Spot and react to misbehaving virtual machines</li>
  <li>Examine SELinux logs and fix common violations in a click</li>
  <li>Inspect detailed metrics that correlate CPU load, memory usage, network activity, and storage performance with the system’s journal</li>
</ul>

<p>More features appear in Cockpit every release.</p>

<h3 id="designed--tested">Designed &amp; tested</h3>

<p>Cockpit’s design keeps your goals in mind.  We test Cockpit with usability studies to make it work the way you’d expect and adjust accordingly. As a result, Cockpit gets easier to use all the time.</p>

<p>All code changes have tests which must pass before merging, to ensure stability.</p>

<h3 id="free--free">Free &amp; free</h3>

<p>Cockpit is free to use and <a href="https://github.com/cockpit-project/cockpit/blob/master/COPYING">available under the GNU LGPL</a>.</p>

<h3 id="cockpit-works-nearly-everywhere">Cockpit works (nearly) everywhere</h3>

<p>You can install Cockpit on the major distributions, including:</p>



<p>Once Cockpit is up and running, you can access systems from all major web browsers on any operating system (including Windows, MacOS, and Android).</p>

<h2 id="release-schedule">Release schedule</h2>

<p>Cockpit has a time-based release cadence, with new versions appearing every two weeks.</p>

<h2 id="get-started">Get started</h2>

<p>After <a href="https://cockpit-project.org/running.html">installing and enabling Cockpit</a>, visit port 9090 on your server (for example: <a href="https://localhost:9090/">https://localhost:9090/</a> in a browser on the same machine as Cockpit).</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple plans to update iPhones in-store without opening the boxes (112 pts)]]></title>
            <link>https://appleinsider.com/articles/23/10/15/apple-plans-to-update-iphones-in-store-without-opening-the-boxes</link>
            <guid>37895272</guid>
            <pubDate>Mon, 16 Oct 2023 02:13:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://appleinsider.com/articles/23/10/15/apple-plans-to-update-iphones-in-store-without-opening-the-boxes">https://appleinsider.com/articles/23/10/15/apple-plans-to-update-iphones-in-store-without-opening-the-boxes</a>, See on <a href="https://news.ycombinator.com/item?id=37895272">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <div id="article-hero" aria-labelledby="hero-cap" role="figure">
                          <p id="hero-cap" title="iPhone 15 Pro on a box">iPhone 15 Pro on a box</p>
                        <p><a href="https://photos5.appleinsider.com/gallery/56813-115576-56493-114919-iPhone-15-Pro-on-Box-xl-xl.jpg">
              <img src="https://photos5.appleinsider.com/gallery/56813-115576-56493-114919-iPhone-15-Pro-on-Box-xl-xl.jpg" alt="">
            </a>
          </p></div>

          
          
          
                    <p>Apple has come up with a way to update an <a href="https://appleinsider.com/inside/iphone" title="iPhone" data-kpt="1">iPhone</a> still in its packaging, with a system allowing for iOS updates to be applied to unopened smartphones while still in an Apple Store. 
</p><p>One of the problems of buying hardware is that consumers often discover their devices need a software update straight out of the box. This can also apply to devices that have just launched, such as the <a href="https://appleinsider.com/inside/iphone-15" title="iPhone 15" data-kpt="1">iPhone 15</a>, which needed an iOS 17.0.1 <a href="https://appleinsider.com/articles/23/09/21/apple-rolls-out-watchos-1001-update">update</a> that was released before the hardware actually shipped. 
</p><p>Writing in his "Power On" <a href="https://www.bloomberg.com/news/newsletters/2023-10-15/apple-october-2023-executive-promotions-new-vps-of-retail-software-operations-lnrh4t94">newsletter</a> for <em>Bloomberg</em>, Mark Gurman claims that Apple has a system that can update the operating system of iPhones before they get sold. Crucially, it can do so without opening the box. 
</p><p>Consisting of a "pad-like device," store employees place unopened iPhone boxes onto it to trigger an update. The pad wirelessly turns on the iPhone, runs the software update, then turns it off again. 
</p><p>While only iPhones are mentioned in the report, it's plausible that the idea could be extended to other products in Apple's catalog. 
</p><p>It is claimed that consumers may benefit from the system at Apple Stores before the end of 2023. </p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Visualizing American inflation across eight categories (144 pts)]]></title>
            <link>https://perthirtysix.com/tool/visualizing-american-inflation</link>
            <guid>37894684</guid>
            <pubDate>Mon, 16 Oct 2023 00:29:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://perthirtysix.com/tool/visualizing-american-inflation">https://perthirtysix.com/tool/visualizing-american-inflation</a>, See on <a href="https://news.ycombinator.com/item?id=37894684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p> This interactive visualization explores how the value of the American dollar has changed from December 1999 to July 2023 across different categories. This visualization was developed using Chained Consumer Price Index data for U.S. City Averages from the <a href="https://www.bls.gov/data/tools.htm" target="_blank">U.S. Bureau of Labor Statistics</a> (BLS). </p><p> The Consumer Price Index (CPI) is like a yardstick that helps us understand how much the cost of everyday things, like groceries or rent, has gone up or down over time. However, it doesn't tell us everything about how prices change because it doesn't include things like the prices of stocks or homes, which are also important parts of the economy. </p><p> The Chained CPI (C-CPI-U) is a more advanced version of CPI that takes into account how people might switch to different items when prices change, giving us a accurate picture of how inflation affects our spending. </p><p>For more technical definitions, here's are some relevant sections from the BLS's documentation:</p><div><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 975.036 975.036"><path d="M925.036 57.197h-304c-27.6 0-50 22.4-50 50v304c0 27.601 22.4 50 50 50h145.5c-1.9 79.601-20.4 143.3-55.4 191.2-27.6 37.8-69.399 69.1-125.3 93.8-25.7 11.3-36.8 41.7-24.8 67.101l36 76c11.6 24.399 40.3 35.1 65.1 24.399 66.2-28.6 122.101-64.8 167.7-108.8 55.601-53.7 93.7-114.3 114.3-181.9 20.601-67.6 30.9-159.8 30.9-276.8v-239c0-27.599-22.401-50-50-50zM106.036 913.497c65.4-28.5 121-64.699 166.9-108.6 56.1-53.7 94.4-114.1 115-181.2 20.6-67.1 30.899-159.6 30.899-277.5v-239c0-27.6-22.399-50-50-50h-304c-27.6 0-50 22.4-50 50v304c0 27.601 22.4 50 50 50h145.5c-1.9 79.601-20.4 143.3-55.4 191.2-27.6 37.8-69.4 69.1-125.3 93.8-25.7 11.3-36.8 41.7-24.8 67.101l35.9 75.8c11.601 24.399 40.501 35.2 65.301 24.399z"></path></svg><div><!--[--><p> The Consumer Price Index (CPI) is a measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. </p><p> BLS has classified all expenditure items into more than 200 categories, arranged into eight major groups (food and beverages, housing, apparel, transportation, medical care, recreation, education and communication, and other goods and services). </p><p> The C-CPI-U employs a formula that reflects the effect of substitution that consumers make across item categories in response to changes in relative prices. </p><!--]--></div></div><p> We hope you found this visualization interesting and appreciate all of your support for PerThirtySix! You can <strong>follow us on Twitter</strong> at <a href="https://twitter.com/perthirtysixers">@PerThirtySixers</a> or author Shri Khalpada at <a href="https://twitter.com/ShriKhalpada">@ShriKhalpada</a>. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MemGPT: Towards LLMs as Operating Systems (203 pts)]]></title>
            <link>https://arxiv.org/abs/2310.08560</link>
            <guid>37894403</guid>
            <pubDate>Sun, 15 Oct 2023 23:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.08560">https://arxiv.org/abs/2310.08560</a>, See on <a href="https://news.ycombinator.com/item?id=37894403">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2310.08560.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory. Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM's limited context window, and utilizes interrupts to manage control flow between itself and the user. We evaluate our OS-inspired design in two domains where the limited context windows of modern LLMs severely handicaps their performance: document analysis, where MemGPT is able to analyze large documents that far exceed the underlying LLM's context window, and multi-session chat, where MemGPT can create conversational agents that remember, reflect, and evolve dynamically through long-term interactions with their users. We release MemGPT code and data for our experiments at <a href="https://memgpt.ai/" rel="external noopener nofollow">this https URL</a>.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Charles Packer [<a href="https://arxiv.org/show-email/d2b58967/2310.08560">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 12 Oct 2023 17:51:32 UTC (391 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why decline in generalists leads to disjointed games and harms tool quality (146 pts)]]></title>
            <link>https://gameworldobserver.com/2023/10/09/generalists-vs-specialists-gamedev-tool-quality-tim-cain</link>
            <guid>37894390</guid>
            <pubDate>Sun, 15 Oct 2023 23:31:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gameworldobserver.com/2023/10/09/generalists-vs-specialists-gamedev-tool-quality-tim-cain">https://gameworldobserver.com/2023/10/09/generalists-vs-specialists-gamedev-tool-quality-tim-cain</a>, See on <a href="https://news.ycombinator.com/item?id=37894390">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="header">

		        <p><a href="https://gameworldobserver.com/" title="Home">
			        <img src="https://gameworldobserver.com/wp-content/themes/common-news-theme-child/build/img/logo.svg">
		        </a>

                          </p><div id="other-projects-menu">
                <p>Other projects WN Media Group:</p>
                <ul>
                                      
                                      
                                      
                                      
                                  </ul>
              </div>
            
		        

	        </div><section>
    <nav>
		    </nav>
    <div>
		

      <main>
		  
<div id="post-list">
	
<article id="post-21292">
	<div>
				
				
					
				<div>
					<p>Much in the games industry has changed beyond recognition over the past 40 years. But one specific thing that might be an issue not obvious to non-developers is what co-creator of Fallout Tim Cain calls the “decline of generalists.”</p>
					<div>
						<p><img loading="lazy" title="Tim Cain on why the number of generalists in the games industry is declining and what are the key advantages of such professionals" src="https://gameworldobserver.com/wp-content/uploads/2023/10/tim-cain-generalists.jpg" alt="Who are generalists in gamedev and why their decline hurts tool quality, explained by Tim Cain" srcset="https://gameworldobserver.com/wp-content/uploads/2023/10/tim-cain-generalists.jpg 1200w, https://gameworldobserver.com/wp-content/uploads/2023/10/tim-cain-generalists-300x158.jpg 300w, https://gameworldobserver.com/wp-content/uploads/2023/10/tim-cain-generalists-1024x538.jpg 1024w, https://gameworldobserver.com/wp-content/uploads/2023/10/tim-cain-generalists-768x403.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"></p>
<h2>Who are generalists in game development?</h2>
<p>Cain touched on this topic in one of the recent videos <a href="https://youtu.be/_ihX2e9dnYM" target="_blank" rel="noopener">on his YouTube channel</a>.</p>
<ul>
<li>“A generalist is someone who is skilled in multiple disciplines,” he explained, adding that this includes, say, artists who can also write, or producers who can code.</li>
<li>Cain believes that the number of such professionals has declined sharply over the past 20 years.</li>
<li>For example, there used to be just game designers, but now there are level designers, narrative designers, systems designer, etc.</li>
<li>The same goes for programmers — now we have specialists focused on specific areas like gameplay, graphics, or UI.</li>
</ul>
<h2>What happened to generalists?</h2>
<ul>
<li>The decline of generalists occurred as the industry got bigger in terms of the people involved. Most developers working on video games today are specialists focused on one specific area.</li>
<li>“I have met very few narrative designers who do anything but write,” Cain said. “I have met people who work in UX, and that’s all they do.”</li>
<li>Modern games take a much longer time to develop, they require way more people compared to the 90s or 80s, and their fidelity (quality of details) is on another level.</li>
<li>Companies need people who work only in specific areas to ensure the high quality of certain elements, so the shift from generalists to specialists makes good business sense.</li>
<li>And it is also easier for developers to be specialists, as they only need to focus on one discipline (or even a sub-discipline).</li>
</ul>
<h2>The lack of generalists leads to games full of disjointed elements</h2>
<ul>
<li>To illustrate the power of such professionals, Cain recalled how some programmer generalists he worked with understood other areas (sound, UI, etc.) and could link different systems together.</li>
<li>Having one person on the team who knows all the disciplines makes all the difference. For example, a programmer who knows how the art is put together can speed up the loading of the art or put together the particle effect system.</li>
<li>“If a designer or an artist knows code, they can ask for the features they want very specifically. It involves less vague generalizations.” Cain noted, adding that knowing how the code works lets various professionals understand and work around limitations of the game engine.</li>
<li>So it is about having people on the team who can speak to other professionals in their language and understand how things work in areas outside of their core expertise.</li>
<li>Another huge advantage of generalists is tools. As Cain pointed out, “no one makes tools better than generalists because these are programmers who know what the artist, musician, or level designer is trying to do and they make tools that expose those controls in clear, easy ways to use.”</li>
<li>The decline in tool quality is a direct consequence of the decline in the number of generalists.</li>
<li>There are also so-called “force multipliers,” people who can improve the productivity of everyone just by their very existence on the team. Cain believes that only generalists can fill this role, and this is what modern game development is lacking.</li>
<li>This leads to games where individual elements are made in a vacuum, with players then never using certain features. As Cain explained, this is because those features were made by “someone who was very passionate and knew how to put it in, but there was no one who connected it to other things.”</li>
</ul>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/_ihX2e9dnYM?si=mSZ-idU2op7srUWb" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>

																															</div>
				</div>

				
				
				
<section>
	<hr>
<p><em>Got a story you'd like to share? Reach us at <a href="https://gameworldobserver.com/cdn-cgi/l/email-protection#85f5f7e0f6f6c5e2e4e8e0f2eaf7e9e1eae7f6e0f7f3e0f7abe6eae8"><strong><span data-cfemail="dbaba9bea8a89bbcbab6beacb4a9b7bfb4b9a8bea9adbea9f5b8b4b6">[email&nbsp;protected]</span></strong></a></em></p></section>


				
<section>
    <h3>Tags:</h3>
    <ul>
        <li><a href="https://gameworldobserver.com/tag/tim-cain">Tim Cain</a></li>    </ul>
</section>


					

									
				
				
					
			</div>
</article>


  
</div>



      </main>

		


    </div>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canada ends official time signal (133 pts)]]></title>
            <link>https://hackaday.com/2023/10/13/canada-abruptly-ends-official-time-signal/</link>
            <guid>37894382</guid>
            <pubDate>Sun, 15 Oct 2023 23:30:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackaday.com/2023/10/13/canada-abruptly-ends-official-time-signal/">https://hackaday.com/2023/10/13/canada-abruptly-ends-official-time-signal/</a>, See on <a href="https://news.ycombinator.com/item?id=37894382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
    

    <p><a href="#content">Skip to content</a></p><!-- #masthead -->

    <div id="content">
        <main id="main" role="main">

        
            
<article itemscope="" itemtype="http://schema.org/Article" id="post-629594">
    <!-- .entry-header -->

    <div itemprop="articleBody">
        <p>In a sudden move that was noted not only <a href="https://www.cbc.ca/news/canada/ottawa/cbc-stops-broadcasting-national-research-council-long-dash-time-signal-1.6988903" target="_blank">by Canadian media</a>, but also <a href="https://www.theguardian.com/world/2023/oct/12/canada-official-time-signal-ends" target="_blank">international media</a> channels, the <a href="https://en.wikipedia.org/wiki/National_Research_Council_Time_Signal?useskin=vector" target="_blank">National Research Council Time Signal</a> that was broadcast by Canadian Broadcasting Corporation (CBC) on CBC Radio One since November 5 1939 was turned off on October 9th, after eighty-four years, one world war, countless generations, and the rise of modern technology. Although perhaps obsolete by today’s standards, this 15 to 60 second long broadcast at 13:00 Eastern Time every single day has been a constant in the life of Canadians, whether they tuned into local radio, or (increasingly) via Internet radio.</p>
<p>The NRC Time Signal consisted out of a series of 800 Hz sinewave ‘beeps’ followed by a second-long signal to indicate the top of the hour. Back in the day this was extremely useful to sync one’s clocks, watches and other time-keeping devices to. Yet between the transmission delays caused by Internet radio and the increased availability of NTP and other time sources on modern-day devices, the signal’s main use appears to have become a nostalgic reminder of what once was a constant of each and every day.</p>
<p>In this regard the public response to the rather unceremonious decommissioning without prior announcement was rather predictable. After all, even if it wasn’t that useful, why throw out something that is more recognizable than any other radio jingle for generations of Canadians?</p>
<p>Top image: <a href="https://en.wikipedia.org/wiki/National_Research_Council_(Canada)" title="National Research Council (Canada)" target="_blank">National Research Council</a>&nbsp;laboratories in&nbsp;<a href="https://en.wikipedia.org/wiki/Ottawa" title="Ottawa" target="_blank">Ottawa</a>.</p>
	            </div><!-- .entry-content -->
    
    <!-- .entry-footer -->
</article><!-- #post-## -->

            	<!-- .navigation -->
	
            

            
<!-- #comments -->

        
        

        
        

        
        </main><!-- #main -->
    </div><!-- #content -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teaching Apple Cyberdog 1.0 new tricks (featuring OpenDoc) (126 pts)]]></title>
            <link>http://oldvcr.blogspot.com/2023/10/teaching-apple-cyberdog-10-new-tricks.html</link>
            <guid>37894030</guid>
            <pubDate>Sun, 15 Oct 2023 22:35:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://oldvcr.blogspot.com/2023/10/teaching-apple-cyberdog-10-new-tricks.html">http://oldvcr.blogspot.com/2023/10/teaching-apple-cyberdog-10-new-tricks.html</a>, See on <a href="https://news.ycombinator.com/item?id=37894030">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5772204902246566615" itemprop="description articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_ounEByCIvzaixy6z5tECn6GN-54MvNOgYlr-BojwPJCSf-LJM7uOU1a08j6UmrZ3jc4qpzBPLGpPu3GFtwK2240GixQmD23G0YurQU5ACYgrxBrIxQPds9h2Po0iYFM6Q6vPN4T1nlrftO0t9flrvTqRDadyCyly9TZ9ywDmk0zPE_yoFUng6GpkFjk/s4080/PXL_20230826_233622793~2.jpg"><img alt="" data-original-height="4080" data-original-width="3072" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg_ounEByCIvzaixy6z5tECn6GN-54MvNOgYlr-BojwPJCSf-LJM7uOU1a08j6UmrZ3jc4qpzBPLGpPu3GFtwK2240GixQmD23G0YurQU5ACYgrxBrIxQPds9h2Po0iYFM6Q6vPN4T1nlrftO0t9flrvTqRDadyCyly9TZ9ywDmk0zPE_yoFUng6GpkFjk/s320/PXL_20230826_233622793~2.jpg"></a></p><p>

In the distant nethermists of time, documents once briefly ruled the earth (or at least Mac OS), and to that end I managed to find a verrry interesting book recently, complete with an unopened CD-ROM. But seriously, though: what was Apple thinking with that name?

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiSI7UGNfMd_O65mr0b8p6XVDLNYhNNGe-lOqRfHrftBUPl5K93oPymMl2GOoOQKZT4Ii0FyTc28AnmGRvjer0OvnspR1zuhKWYQpvCFqz6uX8rN-pIG_uc-wZ0-daNDSNM0JYCuqYy3KGFfB75pRAyVEQjMVlMO6RfGRluC562YXqoDY73EVtVZoibHDg/s2592/Cyberdog_shop_2009.jpg"><img alt="" data-original-height="1944" data-original-width="2592" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiSI7UGNfMd_O65mr0b8p6XVDLNYhNNGe-lOqRfHrftBUPl5K93oPymMl2GOoOQKZT4Ii0FyTc28AnmGRvjer0OvnspR1zuhKWYQpvCFqz6uX8rN-pIG_uc-wZ0-daNDSNM0JYCuqYy3KGFfB75pRAyVEQjMVlMO6RfGRluC562YXqoDY73EVtVZoibHDg/s320/Cyberdog_shop_2009.jpg" width="320"></a></p><p>

It's not <a href="https://en.wikipedia.org/wiki/Cyberdog_(shop)">this cyberdog</a> (<a href="https://commons.wikimedia.org/wiki/File:Cyberdog_shop_2009.jpg">image credit</a>).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMk29XCZdp4xWV2XMv8y6K52G9MvZkC1YUHLm2P3BRkGqJij-px7YZ0jBYmax9KVf0EmiYBGX0ZDSZeZdIAhv9pinb_OGeMLAYEh-Qhkmv-kt6xoJCAFMy0OszxF9ZzFsdG4rsd_Mk639m-dwl4UO0FoMpBPbYTPJQ86gqMLB1I32q0gtRCAtNqnIBq-U/s2340/Screenshot_20230903-174816.png"><img alt="" data-original-height="2340" data-original-width="1080" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMk29XCZdp4xWV2XMv8y6K52G9MvZkC1YUHLm2P3BRkGqJij-px7YZ0jBYmax9KVf0EmiYBGX0ZDSZeZdIAhv9pinb_OGeMLAYEh-Qhkmv-kt6xoJCAFMy0OszxF9ZzFsdG4rsd_Mk639m-dwl4UO0FoMpBPbYTPJQ86gqMLB1I32q0gtRCAtNqnIBq-U/s320/Screenshot_20230903-174816.png"></a></p><p>

Not <a href="https://www.planetarypinball.com/mm5/Williams/games/safecracker/index.html">that cyberdog</a>, though this is one of my favourite weirdo pinball machines.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEia5cLu2d8nLxHDilJaEq6zGrBHbfhU4IN9itf4NX99-h01Jox_vN10e9INGp1t3TtlY0dzrAzdSNokCwsoZt1yrpPH4MePLkizC6xtfxhTxr_Vh76AwbexINTCtiZpeI1aJENjjrK3MPd5vu9bCTJBPj4ihjrNKCrWgljAz6REt-sr71Eimve_suSSRfY/s2000/cyberdog.jpg"><img alt="" data-original-height="1435" data-original-width="2000" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEia5cLu2d8nLxHDilJaEq6zGrBHbfhU4IN9itf4NX99-h01Jox_vN10e9INGp1t3TtlY0dzrAzdSNokCwsoZt1yrpPH4MePLkizC6xtfxhTxr_Vh76AwbexINTCtiZpeI1aJENjjrK3MPd5vu9bCTJBPj4ihjrNKCrWgljAz6REt-sr71Eimve_suSSRfY/s320/cyberdog.jpg" width="320"></a></p><p>

Definitely not <a href="https://www.theverge.com/2021/8/10/22618043/xiaomi-cyberdog-robot-dog-quadruped-specs-price"><em>that</em> cyberdog</a>.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNyM2RWaFGlRJjbdeNK94BktNvMFP3AF4NMvuaotuvAI6RYccGnzWrEppaeYMXdfWMoP5dEa0RahdJzPPej_t4tghqJ-urQ0LTceo-7c1-BfvZ41gwRFxei5zZ8nVrIHErwjgU2WWRNPZdZ8ygi8YekIV-z3u6ATvQ-RUKHJUJMnoilChOxejZsdxIXOA/s4080/PXL_20230927_230811277.jpg"><img alt="" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNyM2RWaFGlRJjbdeNK94BktNvMFP3AF4NMvuaotuvAI6RYccGnzWrEppaeYMXdfWMoP5dEa0RahdJzPPej_t4tghqJ-urQ0LTceo-7c1-BfvZ41gwRFxei5zZ8nVrIHErwjgU2WWRNPZdZ8ygi8YekIV-z3u6ATvQ-RUKHJUJMnoilChOxejZsdxIXOA/s320/PXL_20230927_230811277.jpg" width="320"></a></p><p>

But thanks to all those other cyberdogs, Apple's own Cyberdog — a seemingly ordinary web browser and Internet suite with some unusual capabilities — has since slid into search engine obscurity. Apple had some big plans for it, though, and even wanted to give developers a way to develop their own components they could run inside of it. Not just plugins, either: we're talking viewers, UI elements and even entire protocol handlers, implemented using Apple's version of OpenDoc embedding.
</p><p>
Cyberdog's initial release belied some wild changes afoot, for in the world it inhabited, the document told the system what it needed to display, and the parts within the document displayed it. The document ruled all. The document was king.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiEdHusJ1qAMrjVY6C1HKZdAHVshxPZCXlWnqrTEDzD-9JP78WezNYheNXKU0--CjCmvX9LDQ_rJ5mv2CVqVWf9-s8d1-P9Loq7oJ-DAV77k57AgOc4CALwOztSjVskWn0tf0ERIEyLc6pWS93cp4t05PBZISE4y1hygGJ_9DnQ_I6jHij2cV33IEWuzm4/s640/InstCDog.pict.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiEdHusJ1qAMrjVY6C1HKZdAHVshxPZCXlWnqrTEDzD-9JP78WezNYheNXKU0--CjCmvX9LDQ_rJ5mv2CVqVWf9-s8d1-P9Loq7oJ-DAV77k57AgOc4CALwOztSjVskWn0tf0ERIEyLc6pWS93cp4t05PBZISE4y1hygGJ_9DnQ_I6jHij2cV33IEWuzm4/s320/InstCDog.pict.png" width="320"></a></p><p>

And all of this came together in a special Cyberdog software development kit, complete with example code and the very first 1.0 release of the browser. Now that we have <a href="http://oldvcr.blogspot.com/2023/10/2023/09/refurb-weekend-powerbook-duo-2300c.html">our PowerBook Duo 2300 rehabilitated</a>, guess what we're gonna look at?
</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4dYkgo88i5bAKdXvMTNUiiUIJXixsn4xP7cC-IcdQITNAJaulNPAs9r59BMwBY57TnX9lIWcJn9U5jl1be65e_yphUPLpvYpWhpQX9KP63fO05XOczuld4KKueOalL8h252iTY1rPFU31BpVHpv6u81DmIsWNifTCiJsn-Hxxr_EQcDZ5ujItX7V_Q5Q/s1312/opendoc.png"><img alt="" data-original-height="952" data-original-width="1312" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4dYkgo88i5bAKdXvMTNUiiUIJXixsn4xP7cC-IcdQITNAJaulNPAs9r59BMwBY57TnX9lIWcJn9U5jl1be65e_yphUPLpvYpWhpQX9KP63fO05XOczuld4KKueOalL8h252iTY1rPFU31BpVHpv6u81DmIsWNifTCiJsn-Hxxr_EQcDZ5ujItX7V_Q5Q/s320/opendoc.png" width="320"></a></p><p>

At its core, Cyberdog was really just an overgrown demonstration of OpenDoc. We're going to necessarily explore OpenDoc's underpinnings in this article, but OpenDoc's basic idea grew from what was initially just a standardized compound document format to defining an entire object-oriented approach, where reusable viewer and editor components could be pulled as instances into such a document and maintain their own views and state. The document, not the app you were running, thus determined its own functionality. Under John Sculley this concept became "Project Amber" in 1993 as a stepping stone to fully realizing Apple's flavour of Taligent, the bundle of next-generation technologies to run on top of their intended successor to System 7, Pink. Eventually Taligent was to use it as its primary compound document format.
</p><p>
Taligent's cross-platform focus made the Project Amber concept cross-platform too: if you had the components, an OpenDoc document theoretically could work the same on any OpenDoc platform. In June 1993 Apple, Novell, IBM and Borland officially announced OpenDoc, and in September Apple, IBM and Novell, along with a host of secondary partners like Adobe, Lotus, Oracle and Taligent itself, established Component Integration Laboratories (CI Labs for short) as a technology provider to support OpenDoc and other component technologies like CORBA. Apple subsequently released the first Developer Release of OpenDoc for System 7.5 in December 1994, with later versions developed by IBM for Windows 95, NT, OS/2 and AIX. 
</p><p>
As System 7 grew long in the tooth, Pink transitioned to Copland and became notorious for its deeply protracted development cycle. Years before its formal demise, it was already painfully clear to Apple management that Copland would never be suitable to run Taligent on, and Apple could not financially sustain the effort. After over $100 million then invested to date in Taligent by the Apple-IBM-HP partnership ($200 million in 2023), Apple cut itself loose and sold their stake in Taligent to IBM in December 1995. OpenDoc thus became the remnant and at the time the only modern object-oriented framework Apple had left. Apple shipped OpenDoc 1.0 in November 1995.
</p><p>
Despite Apple's efforts to seed the technology, OpenDoc didn't get a lot of traction with developers and arguably even less with users, who didn't understand what it was good for. It was also seen as a direct competitor to Microsoft's Object Linking and Embedding (OLE) technology, causing Microsoft to wield its formidable internal synergies and powers of FUD to slow OpenDoc's market progress further, irking IBM. Apple began work on OpenDoc Essentials, a suite of basic components for drawing, text and multimedia, but this in and of itself didn't make a compelling show compared to existing software. On the other hand, Internet suites were the new hotness with end users and could provide developers with a new sales segment, so a parallel group worked on something something OpenDoc something Internet. After all, what could be a hotter document than an <em>Internet</em> document?
</p><p>
Thus was the nucleus of Cyberdog (named for <a href="https://en.wikipedia.org/wiki/On_the_Internet%2C_nobody_knows_you%27re_a_dog">the famous New Yorker cartoon</a>), which entered public beta in February 1996. OpenDoc was of course an absolute requirement, and no 68K Macs need apply: its first release was strictly for Power Macintosh.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj62C1Mr8FUn-YoAP9RSp-8-Jf6Tgi-mdvh9fm5Dyt-lq19BJdhrA7Lvzvc432PPCTao8Cj_AY7KHQXm6-6nA8iwbQnr2RHpUhlxdDWXwphFFcYik-bxuMYqtlnz_WHf1koDEGRQt_oLzw65x4lLey2hb8_JFNcJJLz_rJhswtI38RGEcQEByRtJJSa1g/s512/Movie-Clipping-1.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj62C1Mr8FUn-YoAP9RSp-8-Jf6Tgi-mdvh9fm5Dyt-lq19BJdhrA7Lvzvc432PPCTao8Cj_AY7KHQXm6-6nA8iwbQnr2RHpUhlxdDWXwphFFcYik-bxuMYqtlnz_WHf1koDEGRQt_oLzw65x4lLey2hb8_JFNcJJLz_rJhswtI38RGEcQEByRtJJSa1g/s320/Movie-Clipping-1.png" width="320"></a></p><p>

This is a screenshot from the beta showing Apple's "Internet Pathfinder" home screen in Cyberdog, captured off some of Apple's example developer videos. As was fashionable at the time, the suite had its own internal "home page," centering around Apple-provided services (primarily hosted on the now-defunct </p><tt>cyberdog.apple.com</tt><p>, including the </p><tt>cyberdog.*</tt><p> Usenet hierarchy), but also collecting user bookmarks and history into what Cyberdog referred to as a notebook and log respectively. We'll explore those concepts a little later.
</p><p>
Unlike most Internet suites that either used a pre-rendered image or some sort of markup language, the Pathfinder was nothing less than an OpenDoc document with buttons and GUI elements composed from standard components. Sharp eyes will have noticed that the standard Macintosh File menu has been replaced with Document. We'll come back to that as well.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgzwoaaQTpIOnE6JWM-KAyG4UgXuxJ1U04CYNX3ijoyta7mcq4UNU66mVaruRg7aYdpJpFAUTFdGXvSWS0IFEKfopl-Gz3IN6TGXQwt6WkTDuRWM8GS3nJLLrBaD-GA5Fu2N1g-JBUb-otCG8LGQqd18Xq0T5zbVLAAlA1ljxItSQ7-0BhzmsRM9OQIY9U/s512/Movie-Clipping-2.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgzwoaaQTpIOnE6JWM-KAyG4UgXuxJ1U04CYNX3ijoyta7mcq4UNU66mVaruRg7aYdpJpFAUTFdGXvSWS0IFEKfopl-Gz3IN6TGXQwt6WkTDuRWM8GS3nJLLrBaD-GA5Fu2N1g-JBUb-otCG8LGQqd18Xq0T5zbVLAAlA1ljxItSQ7-0BhzmsRM9OQIY9U/s320/Movie-Clipping-2.png" width="320"></a></p><p>

The core of Cyberdog beta was the browser, here viewing </p><tt>agate.apple.com</tt><p> (the name likely coming as a riff on Amber; this host is now lost, and not in the Wayback Machine), which appears to have been </p><tt>cyberdog.apple.com</tt><p>'s direct ancestor. At first blush this doesn't look too different from any other mid-1990's web browser, and in basic operation it largely isn't. Where the experience gets divergent is when it gets embedded. Also take note of the Cyberdog, Mail/News and Navigate menus, which are in fact provided and driven by the browser's components.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnwqqvxuUH1iDy_ri7nwBqepV9rD5xVWfINKS5yWaBxmEuk0BgvMDErUFt9tGFVw8gdCSOqDchRyJ-7r9B0J6tyOYGpOIKTzyz4NcEh2Brm-3V5UxPUyjXEfLtj_wmQIQaLipgcpWSE4pAzxrhUTSFP1u3o5wgCOhahgie1RhnB12_Bz1gl7EepAzTuHc/s512/Movie-Clipping-3.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnwqqvxuUH1iDy_ri7nwBqepV9rD5xVWfINKS5yWaBxmEuk0BgvMDErUFt9tGFVw8gdCSOqDchRyJ-7r9B0J6tyOYGpOIKTzyz4NcEh2Brm-3V5UxPUyjXEfLtj_wmQIQaLipgcpWSE4pAzxrhUTSFP1u3o5wgCOhahgie1RhnB12_Bz1gl7EepAzTuHc/s320/Movie-Clipping-3.png" width="320"></a></p><p>

It wouldn't be an Internet suite without other protocols. We're <a href="http://oldvcr.blogspot.com/search/label/gopher">big fans of Gopherspace</a> around here, though Cyberdog wasn't actually a particularly good Gopher client even for the time and isn't the main point of this article. Nevertheless, out of the box Cyberdog supported Gopher, E-mail, Telnet, Usenet news and FTP as well. Later versions could also view resources made available via AppleTalk — no HTTP required.
</p><p>
However, one interesting trick it's showing in this clip is the ability to drag and drop files from a Gopher server directly onto the desktop as downloads. The same thing works for browsing FTP sites, which from an interface perspective shouldn't be very surprising, since Gopher was (at least initially) intended to be a friendlier FTP.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnQ98coWmyhuul5JTRXxlILB3bmhfpI32QTdVBIyb8kJBfphRPM_Sx9EsfMVNu3K4Vf1lAXR26UIA1zoeAl5fVYJr7qvXe9j4GBJfZe06xGH4Qz-9BwLHwKfmtBeUDWUg2-McokgrjShufSM8W_pHVRfPj1vhz36Y-fKNBqiMpvmV1OTK5jDFnHiQCn_8/s640/Movie-Clipping-5.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnQ98coWmyhuul5JTRXxlILB3bmhfpI32QTdVBIyb8kJBfphRPM_Sx9EsfMVNu3K4Vf1lAXR26UIA1zoeAl5fVYJr7qvXe9j4GBJfZe06xGH4Qz-9BwLHwKfmtBeUDWUg2-McokgrjShufSM8W_pHVRfPj1vhz36Y-fKNBqiMpvmV1OTK5jDFnHiQCn_8/s320/Movie-Clipping-5.png" width="320"></a></p><p>

To the best I can determine, Cyberdog was never part of the Apple Internet Connection Kit CD-ROM, but it was nonetheless intended to integrate with it (here surfing an early version of AICK's hub site <a href="http://web.archive.org/web/19980211200422/http://www.online.apple.com:80/webcity/">WebCity</a>). Notably, this build still has the traditional File, Edit and View menus which were later eliminated in the beta. Incidentally, if this looks like the prototype Cyberdog is running on Mac OS 8, you're right, except this video is dated over a year before Mac OS 8 was formally released — Apple wasn't nearly so secretive about future product leaks in those days. Also note that whatever pre-release build of Mac OS 8 (7.7?) this was, it still had the System 7-era help icon instead of 8.0's text Help menu, and it certainly wasn't Copland.
</p><p>
Cyberdog reached 1.0 in May 1996, but before we get to actually running it, let's now spend a moment talking about OpenDoc's internals.
</p><p>
OpenDoc components, in OpenDoc lingo, are called "parts." At the system level, an OpenDoc part was based on Apple's implementation of IBM's System Object Model, a language-independent specification for object-oriented programming. IBM intended to use SOM throughout its entire product line, most notably OS/2 where it is <a href="https://komh.github.io/os2books/gg243732/189_L3_SystemObjectModel.html">an integral portion of the Workplace Shell</a>, and some portion of it remains in z/OS via OS/390. It was designed for a pervasively object-oriented world where applications written in one language would need to instantiate objects potentially written in another, and applications using such libraries would need to have a solution for the <a href="https://en.wikipedia.org/wiki/Fragile_binary_interface_problem">fragile binary interface problem</a> or those libraries could not be easily upgraded. To deal with these and other pitfalls, SOM had an interface definition language for describing methods, made late-binding mandatory so that the runtime linker could automatically apply fixups (at a startup performance cost), provided more object-oriented features than competing technologies such as Microsoft COM — a/k/a ActiveX — like multiple inheritance, metaclasses and dynamic dispatch, and supported bindings theoretically in any programming language (though C was the only one ever implemented). There was a lot of potential there, but many developers didn't take advantage of those features, and development of a component could involve a lot of boilerplate code. We'll see this soon enough.
</p><p>
Apart from more abstract classes, concrete OpenDoc parts fell chiefly into two categories, namely editors and viewers. Parts could be hosted within container applications that presented the document which the part instances inhabited. Within such documents, they had a stacking order and could even clip or mask each other for complex effects. However, this also meant container apps at minimum had to be OpenDoc-aware and regular applications couldn't use them without modification, one of OpenDoc's many problems, though OpenDoc provided a default shell out of the box that parts could run in to avoid a chicken-and-egg situation. Part interfaces weren't limited to their spatial boundaries within the document; an active part could also create global UI elements, most notably menus. The Cyberdog, Mail/News and Navigate menus above were from Cyberdog's navigator part running in a document that contained only it. In more complex documents, OpenDoc parts had to all play nice with each other much like regular Mac OS applications, which tended to magnify the already existing deficiencies in the classic Mac OS's limited multitasking.
</p><p>
It was also possible to bootstrap a document from scratch with an active part ready to go. System 7 introduced the concept of stationery, where a document could be saved as a template to create other documents, and OpenDoc expanded on this notion. For this and most of the rest of the article, we'll demonstrate on the Duo 2300, running Mac OS 8.1, which bundles OpenDoc 1.2.1 as part of the operating system.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhkYMwe_C4xJzcBUaEYmifTBWREFvHQdUh4Nws3_4AT0yH0EKwYmHH9DxQnYdBRMlejQVAI8TYpq5BGdqvzhVgDvxWXJByStUekrTzSCO-QjnmGIjONlUWEhjFRqMIOpv0z3eSNbBhS3ZgCAKm20Ks_nk8I3u-kEuyu4Hcfvpnh00gbHVix2Yg33u6LJZY/s640/Picture%207.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhkYMwe_C4xJzcBUaEYmifTBWREFvHQdUh4Nws3_4AT0yH0EKwYmHH9DxQnYdBRMlejQVAI8TYpq5BGdqvzhVgDvxWXJByStUekrTzSCO-QjnmGIjONlUWEhjFRqMIOpv0z3eSNbBhS3ZgCAKm20Ks_nk8I3u-kEuyu4Hcfvpnh00gbHVix2Yg33u6LJZY/s320/Picture%207.png" width="320"></a></p><p>

Let's take the venerable BBEdit Lite as an example, which briefly existed as a fully-functional OpenDoc editor part called BBEdit Lite·od. The Editors folder inside the System Folder contains the various active OpenDoc components. You can just drag libraries in and out of it and OpenDoc will update its parts inventory as necessary; you don't need to restart the Mac. From BBEdit Lite·od, which doesn't exactly roll off the tongue, we dropped in the editor part and the Mercutio shell plugin it requires (equivalent with the Mercutio MDEF used for enhanced pull-down menus), and copied over the included stationery to the OpenDoc Stationery folder.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZTYvpdbViHDoalVhW6e5TRKakK7RmJgma7igzwX3VKF1dg5NgBkm2Xj40zbF_HtE6A2X5t0A_Wr-wgKvKwz_3AJFuq69DDZh5XFSjxkP7WtXqLzW4s7sB1QVycJ0IS33gEkkffP-lB2lJEykXnSa-JTg0k8P3YoSxbwSHRmn7zi4Y7R9nl60woikTPR8/s640/Picture%2010.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZTYvpdbViHDoalVhW6e5TRKakK7RmJgma7igzwX3VKF1dg5NgBkm2Xj40zbF_HtE6A2X5t0A_Wr-wgKvKwz_3AJFuq69DDZh5XFSjxkP7WtXqLzW4s7sB1QVycJ0IS33gEkkffP-lB2lJEykXnSa-JTg0k8P3YoSxbwSHRmn7zi4Y7R9nl60woikTPR8/s320/Picture%2010.png" width="320"></a></p><p>

Like regular Mac OS stationary acts as a document factory (like tearing sheets off a steno pad), OpenDoc stationery acts as an instance factory. Stationery can be dragged ("torn off") into existing documents or, if supported, directly opened to make new documents containing them. Conveniently you can create documents from stationery right in the Apple menu, or from the OpenDoc Stationery folder: since BBEdit Lite·od is a fully-fledged editor, opening its stationery will pop open a brand new document entirely driven by the BBEdit part.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg1oMN1oHUm6TtRatpFQlqS3E7BiT-ctKRyevxl2PNGmIAR7cq4ShtlaA9YCD4qz-Tko90LqLr878W72j-XiaGaumZV7YsJyp3fg3EedVWTpO3PL3ARcIB2KFbCV3LttbEjtAJRwfFwW8Gl-8_Xodl8MEbZhJJXQOOhn7SsHm6phCghymO14uRdlXWVCBY/s640/Picture%208.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg1oMN1oHUm6TtRatpFQlqS3E7BiT-ctKRyevxl2PNGmIAR7cq4ShtlaA9YCD4qz-Tko90LqLr878W72j-XiaGaumZV7YsJyp3fg3EedVWTpO3PL3ARcIB2KFbCV3LttbEjtAJRwfFwW8Gl-8_Xodl8MEbZhJJXQOOhn7SsHm6phCghymO14uRdlXWVCBY/s320/Picture%208.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiksFNVAt8iR6zv7gbaiPQLtNnGomjrRyqLpkFfrQLZj_N1qAJIKwCZDzr62SMkBQumXYv0usMJXbpsyQtaVpaVp5690-ti9pdmIACsXtfC7CcPW-ydUCAentQG1ikt46GzTajsCcuFl57u5auR2FhuBZ3Hunj58qTt9-68sYzWvtBBf4-t_LFtHbryQ88/s640/Picture%209.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiksFNVAt8iR6zv7gbaiPQLtNnGomjrRyqLpkFfrQLZj_N1qAJIKwCZDzr62SMkBQumXYv0usMJXbpsyQtaVpaVp5690-ti9pdmIACsXtfC7CcPW-ydUCAentQG1ikt46GzTajsCcuFl57u5auR2FhuBZ3Hunj58qTt9-68sYzWvtBBf4-t_LFtHbryQ88/s320/Picture%209.png" width="320"></a></p><p>

While OpenDoc has provided the new document with a default container application (called the <em>document shell</em>), this document has just one part, and that part is all BBEdit. The editor part is able to present nearly its entire standard interface, even an About item in the Apple menu.
</p><p>
Still, to users a process like this would look only like a new and weird way to create documents; there's nothing "compound" about what we just did and no new capabilities were obviously unlocked. While you could certainly put a BBEdit part into another compound document, that kind of defeats the purpose of a simple text editor. Bare Bones Software never went any further with the proof of concept, even before OpenDoc started circling the drain, but Apple had other demos to show off.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2q6f1xzKU4WiURj0B4PTTvFFgu9L4BGChPntLO4taOLJMmigHAjGPQ2erTBY8p_zBTcEBJpufLSdvV72Qf1_b0hoh0TJIRpSV8nh2baAxNBIYr7zAbUioIUcGZZNQYG_i5ZwOoq01PBnNWLJmh4vTea0AjP15sCcFOykq0vW58MMTdHd83dvq8KQu3yE/s640/Movie-Clipping-8.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg2q6f1xzKU4WiURj0B4PTTvFFgu9L4BGChPntLO4taOLJMmigHAjGPQ2erTBY8p_zBTcEBJpufLSdvV72Qf1_b0hoh0TJIRpSV8nh2baAxNBIYr7zAbUioIUcGZZNQYG_i5ZwOoq01PBnNWLJmh4vTea0AjP15sCcFOykq0vW58MMTdHd83dvq8KQu3yE/s320/Movie-Clipping-8.png" width="320"></a></p><p>

In this demonstration, an interactive physics demo is part of a compound document with a live view and a "movie controller" that manipulates the simulation's time index. This product was called Dock'Em and was actually sold and used in education. Take that, Jupyter notebooks.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjYqw58rRWfumIBlbzQ-hlQrXlUhIi9COZL0qIt7g_B0r0gw2PUAkhsDvn185XPRGfvGfRAzbxzthzE_NebiB9SUgrygWufXG8Sq-LuoI782O5DMtECK09EbRt1HZwE8_ASJyTdO61oyJfxz26f72EprkO7aH3WgS_qE-RJDmVowm8NlEEOswf61CzqQSg/s640/Movie-Clipping-7.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjYqw58rRWfumIBlbzQ-hlQrXlUhIi9COZL0qIt7g_B0r0gw2PUAkhsDvn185XPRGfvGfRAzbxzthzE_NebiB9SUgrygWufXG8Sq-LuoI782O5DMtECK09EbRt1HZwE8_ASJyTdO61oyJfxz26f72EprkO7aH3WgS_qE-RJDmVowm8NlEEOswf61CzqQSg/s320/Movie-Clipping-7.png" width="320"></a></p><p>

Another demonstration document was this one using a live database viewer part; the other UI elements on the document were also parts. Here Cyberdog's browser component has additionally been embedded to allow the user to look up the shoes listed in the database table (using </p><a href="http://web.archive.org/web/19980714092254/http://jedi.apple.com/Documentation/technical_ref.html"><tt>jedi.apple.com</tt></a><p>, Jedi being another early code name for OpenDoc).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-Ns2EgypyatReOrcaOEMxUo1NkjCdLSaS8NnaRarzUQOUZwG1cR-VcLrrlH9hUv7elwupdQpv0Ot1ODFrBFXYPtwtx6loP6BhJtg4Yp4nwgTjZfA0yPb5lUTwMVxAoFqapspr6gIf4tJK7Lq88T09SC1VbPssV2L21OIzmo-pRE2RowKSJH1KAgCmkYk/s640/Movie-Clipping-6.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-Ns2EgypyatReOrcaOEMxUo1NkjCdLSaS8NnaRarzUQOUZwG1cR-VcLrrlH9hUv7elwupdQpv0Ot1ODFrBFXYPtwtx6loP6BhJtg4Yp4nwgTjZfA0yPb5lUTwMVxAoFqapspr6gIf4tJK7Lq88T09SC1VbPssV2L21OIzmo-pRE2RowKSJH1KAgCmkYk/s320/Movie-Clipping-6.png" width="320"></a></p><p>

An extreme example might be this one: this screenshot shows <em>two</em> pre-release packages, the OpenDoc-enabled version of ClarisWorks 5.0, codenamed "Mars" (eventually scuttled in this form and reworked into the non-OpenDoc AppleWorks 5.0 in 1997) running on the pre-release version of Mac OS 8 we saw before. There are two Cyberdog-provided sections here, the browser and a button above it, plus the other pieces of the document created conventionally in ClarisWorks. We'll play with both of those parts later on.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigVjqwYwfdWOpRswQj7kpUREONcJh2yqi5ehC7mLACeTWdHKFl7l_rj98oNYgO0Yt2AVd3aQr01ldZtg6_bar3x0e_gnqaX9ZA0irloquqKIgckrCaNYsc55TooUUHyx-vHVaHFH508qqVS43EBaRteuaianfUAYfolGlzLUJGMxPIyNuxloyfadmGBBk/s517/partmerchant.png"><img alt="" data-original-height="517" data-original-width="515" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigVjqwYwfdWOpRswQj7kpUREONcJh2yqi5ehC7mLACeTWdHKFl7l_rj98oNYgO0Yt2AVd3aQr01ldZtg6_bar3x0e_gnqaX9ZA0irloquqKIgckrCaNYsc55TooUUHyx-vHVaHFH508qqVS43EBaRteuaianfUAYfolGlzLUJGMxPIyNuxloyfadmGBBk/s320/partmerchant.png"></a></p><p>

This leads to an obvious question: what if you get a document and don't have the parts installed on your computer to view what's embedded in it? This is the same situation people would have confronted with embedded web content requiring a separate plugin; you'd need a plugin finder service to see what could handle that particular MIME type. Products like Kantara's Part Merchant were intended to act like an app store for OpenDoc parts, allowing developers to purchase and download parts on demand, while their PM Finder would dynamically hunt down compatible viewers and editors when an unsupported portion of a document was encountered.
</p><p>
This screenshot was strictly a mockup from one of their product circulars; PartMerchant transformed into <a href="http://web.archive.org/web/19961231020934/http://www.partbank.com/">PartBank</a>, which offered not only OpenDoc parts — <a href="http://web.archive.org/web/19970207032935/http://www.partmerchant.com/cgi-bin/getNode/product?productid=10091">here's their entry for BBEdit</a> — but also Java, ActiveX and Netscape NSAPI Plugin downloads. It fizzled out late in 1997, becoming Java specialist Flashline, and was subsequently bought out by Sun.
</p><p>
Failing those sorts of services, such content could be referred to an existing part on the system that advertises support for it (multiple parts to handle the same sort of content could be present on one computer), or the content might include cached data in a standard format such as PICT that the system could display, or fallback text explaining the needed part could also be shown to the user.
</p><p>
Now that we understand a bit more of what's happening under the hood, let's get back to Cyberdog. However, first we'll need to make it a bit more stable. While OpenDoc was already somewhat memory-hungry, you will find the Cyberdog experience substantially less bumpy with bigger allocations.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLyK6ljaGHv9qGnfYvn5jJcbij_-D_rAMotRKGbOLQL7AGw5W3D6Mj0Yk6ie18M9DV06DiJDgHgrCoCj3aP4uzQ1syNzJToyaHd6e-iZ7TPHAftpVBYogiEbdaeUnl0hj16doSlrogD8Ql4tpoe1a7UQqOipcLEo7_fDzN0O6LtbBUYAtTdYrswaI_dSc/s640/Picture%206.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLyK6ljaGHv9qGnfYvn5jJcbij_-D_rAMotRKGbOLQL7AGw5W3D6Mj0Yk6ie18M9DV06DiJDgHgrCoCj3aP4uzQ1syNzJToyaHd6e-iZ7TPHAftpVBYogiEbdaeUnl0hj16doSlrogD8Ql4tpoe1a7UQqOipcLEo7_fDzN0O6LtbBUYAtTdYrswaI_dSc/s320/Picture%206.png" width="320"></a></p><p>

Before doing anything else, go to the OpenDoc Setup control panel and increase the default document size to at least 1440K, preferably 2048K. This will still fit into our Duo 2300 with a full 56MB of physical RAM and virtual memory pumped up to 64MB. <em>Don't</em> start OpenDoc at system setup in case something goes wrong.
</p><p>
We'll now double-click on the Cyberdog Starting Point (replacing the Internet Pathfinder) document's goofy dog icon to open it from the Finder. The Starting Point is an OpenDoc document that contains the home screen then in vogue for Internet suites, but note well: you could open <em>any</em> document and use <em>that</em> as your starting point because we're not explicitly opening a Cyberdog application. There <em>is</em> no <s>spoon</s> application. The document drives all by invoking Cyberdog parts within it.
</p><p>
In fact, there's actually <em>no</em> way to open Cyberdog 1.0 directly <em>except</em> with a document containing a Cyberdog part. This was the last Cyberdog release where that was true, by the way.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1h1zWEqP_SIh4hUDYXKlu3KcJhY4Iw7IiT9QAgB3yCJzTmQ64_DsFYGwSObyfMRQ3BaSP5rfUALzBXP61F-nBltwHDTSqgEu-3vgh3YvczXl8VXSfxaPjcCIYX02XKDk8OOWiwVCrfD_q3zO4Rsmq0SG901qTyVK0w6HZjT1ozTyxs77CEQjfL7tf9Mw/s640/Picture%201.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1h1zWEqP_SIh4hUDYXKlu3KcJhY4Iw7IiT9QAgB3yCJzTmQ64_DsFYGwSObyfMRQ3BaSP5rfUALzBXP61F-nBltwHDTSqgEu-3vgh3YvczXl8VXSfxaPjcCIYX02XKDk8OOWiwVCrfD_q3zO4Rsmq0SG901qTyVK0w6HZjT1ozTyxs77CEQjfL7tf9Mw/s320/Picture%201.png" width="320"></a></p><p>

Aside from a new, possibly less charming name, the buttons and the things they connect to are the same. Again, since Apple has long since decommissioned the Cyberdog home page and server, most of the buttons don't do anything anymore.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEie0QqFz-hrUS_wUjBFyO6rMBzI2eOJgsTY92hCt2Rwb3AWKhdMUnGrfdrOSqWYcRE81nU0gQHVnQ9tiLJ_38IV-LmYYA7ldsDLOH2NOv3ToFVlPEBjBAXtEeFjyJZA3OHECSxnAJwPLnut6S-VDJodz3YiutZvMfWWOIFqCjQY4K3EbPu7l1TUSgwH-fA/s1798/cyberhom.png"><img alt="" data-original-height="1584" data-original-width="1798" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEie0QqFz-hrUS_wUjBFyO6rMBzI2eOJgsTY92hCt2Rwb3AWKhdMUnGrfdrOSqWYcRE81nU0gQHVnQ9tiLJ_38IV-LmYYA7ldsDLOH2NOv3ToFVlPEBjBAXtEeFjyJZA3OHECSxnAJwPLnut6S-VDJodz3YiutZvMfWWOIFqCjQY4K3EbPu7l1TUSgwH-fA/s320/cyberhom.png" width="320"></a></p><p>

For example, this was the Cyberdog 1.0 home page on Apple's servers. The Wayback Machine doesn't have a copy of this earliest incarnation, so these screenshots from the developer documentation are all that survive from it.
</p><p>
Internally, arbitrary individual browser windows are OpenDoc documents and rendered by the Cyberdog Navigator part, which resides in the Cyberdog Libraries folder within the Editors folder we saw before. Parts can have subparts; Cyberdog's HTML viewer part is the primary subpart within this window's navigator, but its satellite widgets are also parts.
</p><p>
This window also points out the current <i>item</i> it's displaying, a core Cyberdog class that contains information about a given resource (web page, Usenet newsgroup, E-mail address, and so on). You can think of it as a "URL on steroids": it necessarily includes a URL, but also the title of the resource and an icon. Items can be saved to the Finder, where they act rather like bookmarks, or committed to other sorts of storage. When an item is opened, the item determines what Cyberdog part needs to be instantiated to handle the resource the item refers to.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9w8D-5K2FME-PJJmiOUiXe1v-eJGHpsgeCWD5fuWMVk9QIrhknMjYib6YlntWqZOmXeOv1ic5yYxwR0NJElQQZcAjIT9XpgKu565FSGUFUloE4bGH14jKdH03iiif8wnYpEjKpyaeXOpVHT1QRAYemCeR6Nj7xZ84hYM44MY8J3aydFsZihrIHJu5f2g/s1694/logsearch.png"><img alt="" data-original-height="1694" data-original-width="1624" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9w8D-5K2FME-PJJmiOUiXe1v-eJGHpsgeCWD5fuWMVk9QIrhknMjYib6YlntWqZOmXeOv1ic5yYxwR0NJElQQZcAjIT9XpgKu565FSGUFUloE4bGH14jKdH03iiif8wnYpEjKpyaeXOpVHT1QRAYemCeR6Nj7xZ84hYM44MY8J3aydFsZihrIHJu5f2g/s320/logsearch.png"></a></p><p>

Those "other sorts of storage" include Cyberdog notebooks and the log, which are the bottom two windows in this shot. Like the navigator, the log and notebook are Cyberdog parts as well. The default notebook is more or less your bookmarks (to any protocol or service that Cyberdog supports), and the log contains your browsing history. Each terminal entry in the log and in a notebook is a Cyberdog item. A "finger" in the log indicates the user's current position.
</p><p>
The top window was the Apple-provided search page at the time which just forwarded through to Digital's AltaVista, then the state of the art in web searches. (Remember the Internet before Google? Cyberdog remembers.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdpv7bqCncTwV0cHuIRtvKvV2uz_4eghYVsbLxdeW-x1B2JAefzDAhgx7VXLaB_rhQ0SRsRNzx1WWRWb8lOdxcBthyMBjahm1Nlk8_XyH20F1EQLDMRgziMaOADyWwjdnd4gN3hJ2mHkZpB0oNDa4ZajP-pynqJg0wgzttQsE8yJKfcxNMyPzCQEV8jWk/s640/Picture%203.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdpv7bqCncTwV0cHuIRtvKvV2uz_4eghYVsbLxdeW-x1B2JAefzDAhgx7VXLaB_rhQ0SRsRNzx1WWRWb8lOdxcBthyMBjahm1Nlk8_XyH20F1EQLDMRgziMaOADyWwjdnd4gN3hJ2mHkZpB0oNDa4ZajP-pynqJg0wgzttQsE8yJKfcxNMyPzCQEV8jWk/s320/Picture%203.png" width="320"></a></p><p>

The Document menu is the true core of Cyberdog, and we'll look at what it means to create a New Document further in, but the Cyberdog menu is how you operate the browser itself.
</p><p>
Notice there is no Quit in the Document menu: you quit by closing the document. The document, once again, is everything.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiblxo1q2KroYAIYw5MEB-KlNap9sFN-H5XRC08cVsJ4bVC944g2IYCeR6MyImPEYk41StIR5XeqCKM3-fFsYPHxmcdaYDhExiN84XiQNuCU_D_nFzdGJW6hDP-cTBEaoKHKrOaVMoT5BOO3LOnZF8QE27ON5DoH7awXChAfiMjM68EDLmodw8JPKLPjRE/s640/Picture%204.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiblxo1q2KroYAIYw5MEB-KlNap9sFN-H5XRC08cVsJ4bVC944g2IYCeR6MyImPEYk41StIR5XeqCKM3-fFsYPHxmcdaYDhExiN84XiQNuCU_D_nFzdGJW6hDP-cTBEaoKHKrOaVMoT5BOO3LOnZF8QE27ON5DoH7awXChAfiMjM68EDLmodw8JPKLPjRE/s320/Picture%204.png" width="320"></a></p><p>

If you press Command-T or choose it from the Cyberdog menu, the Connect window appears. You can select any supported protocol from the Service box, or simply go to "URL" and enter a URL.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjk6V4YP5sw0zVflVtTlvHzCBM36eNlYb1ZwGCzjWlFuF8WPgT11Mep1JyIK4TXN7N5SA66SA2t9h3fo_dgd7MFxclR2RIfj3tZzn4WMe5MFtKa3q_IYibM3BjdoTfC6VBgJlqz3zaf1ju7zHISvQ3GA05mmkNr7_6v8GA2pITRSVptEBrM6X7CTLI77-o/s640/Picture%205.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjk6V4YP5sw0zVflVtTlvHzCBM36eNlYb1ZwGCzjWlFuF8WPgT11Mep1JyIK4TXN7N5SA66SA2t9h3fo_dgd7MFxclR2RIfj3tZzn4WMe5MFtKa3q_IYibM3BjdoTfC6VBgJlqz3zaf1ju7zHISvQ3GA05mmkNr7_6v8GA2pITRSVptEBrM6X7CTLI77-o/s320/Picture%205.png" width="320"></a></p><p>

And here is Cyberdog 1.0 surfing the Floodgap home page, which I intentionally maintain to be compatible down to Netscape Navigator 3.0 or so. Although Cyberdog has SSL support, it does not support TLS (as Cyberdog predates TLS 1.0 in 1999), and I was not able to find a simple way to substitute in <a href="http://oldvcr.blogspot.com/search/label/crypto%20ancienne">Crypto Ancienne</a>. 1.0 is known to have a notorious bug with proxies and secure sites anyway, which would cause problems regardless for Crypto Ancienne's proxied TLS approach, so perhaps we'll hack in this support in a future article.
</p><p>
If we select Document Info from the Document menu, it explains more about the window we're looking at. Cyberdog Navigator is listed as both its "kind" and editor. Kind, in this case, is OpenDoc's equivalent of a filetype, usually internally specified to the system as a structured string like <tt>+//ISO 9070/ANSI::113722::US::CI LABS::Apple:Cyberdog:SomePart:Kind:SomeThing</tt> (along with another string to be shown to the user, as in this case). There are kinds listed for all the subparts as well. The Size button lets you adjust the document's memory allocation, blurring the lines further between document and regular Mac application.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgM-UBqKqr64X6nxrtQi3zszi-DB6sxJvmERfSrRKuKR6PfOdy4Y63vWaJMFaHK7B070gGKNJG3qXjS1yedXgo7SATuMyMdb_XDnksdltVM241ULaeHqx4eL7lsdQlvaR_XncMB03bxgoi7TfhP8oxE39EVxMPqstvQSoSV8MQQHC_HReyQ1ZD7BewhhB4/s4080/PXL_20230826_233959023~2.jpg"><img alt="" data-original-height="4080" data-original-width="3072" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgM-UBqKqr64X6nxrtQi3zszi-DB6sxJvmERfSrRKuKR6PfOdy4Y63vWaJMFaHK7B070gGKNJG3qXjS1yedXgo7SATuMyMdb_XDnksdltVM241ULaeHqx4eL7lsdQlvaR_XncMB03bxgoi7TfhP8oxE39EVxMPqstvQSoSV8MQQHC_HReyQ1ZD7BewhhB4/s320/PXL_20230826_233959023~2.jpg"></a></p><p>

Since Cyberdog was OpenDoc's most high-profile demonstration application, and everything Internet was hot, Apple published an SDK shortly after 1.0's release in an attempt to build a Cyberdog-centric ecosystem around it specifically. Called the Cyberdog Programmer's Kit, that was the book I showed you back at the beginning. 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxJcSKTejQD_7E5Ihsr_jFZ2u3Py44wKhbAXT9KB_e0aU652UEO5sI9-SOgG-_VOVRUTIW2gHGkvYq3s-rZQuGqkCsroi7NxOxhaN5D2jn0dT1pjT-T70KCE2q8HZQq-GKCeYKang2VOrhy9N8tmrlLCrkSZhd8SF7jaEFuvfkoczvezYXZT-M2tqyYkM/s4080/PXL_20230826_234348131.jpg"><img alt="" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxJcSKTejQD_7E5Ihsr_jFZ2u3Py44wKhbAXT9KB_e0aU652UEO5sI9-SOgG-_VOVRUTIW2gHGkvYq3s-rZQuGqkCsroi7NxOxhaN5D2jn0dT1pjT-T70KCE2q8HZQq-GKCeYKang2VOrhy9N8tmrlLCrkSZhd8SF7jaEFuvfkoczvezYXZT-M2tqyYkM/s320/PXL_20230826_234348131.jpg" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8o2VjtXqxgEFkYpyA8O3KXA6f_48bIHACGAbE_bbmHaD__V5BUH7fVX7TAqFl9jZO9jKkVsoucRUskjeOtbUuQx0JFpPgZIKu_ZSVUpAOa4enkzelvFvPE_g3Oq73ZP4rlX1XQ2CD9Ei8IOCGPvX7SO528Ane-ZgLSRtWAXQhu4N-6MTrzrsjZwJYAzA/s348/cujoondope.png"><img alt="" data-original-height="336" data-original-width="348" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8o2VjtXqxgEFkYpyA8O3KXA6f_48bIHACGAbE_bbmHaD__V5BUH7fVX7TAqFl9jZO9jKkVsoucRUskjeOtbUuQx0JFpPgZIKu_ZSVUpAOa4enkzelvFvPE_g3Oq73ZP4rlX1XQ2CD9Ei8IOCGPvX7SO528Ane-ZgLSRtWAXQhu4N-6MTrzrsjZwJYAzA/s320/cujoondope.png" width="320"></a></p><p>

The Cyberdog 1.0 release we just played briefly with, plus all the movies with the beta screenshots, came on the included disc with an icon that looks like <a href="https://en.wikipedia.org/wiki/Cujo">Cujo</a> on dope. It also includes sample code in C++, headers and libraries. Because Cyberdog 1.0 is PowerPC-only, it only supports generating PowerPC OpenDoc parts with a suitable version of CodeWarrior or MPW. As the disc includes CodeWarrior project files, CodeWarrior Gold 9 will do nicely for our purposes, which was also released in 1996.
</p><p>
Cyberdog has five chief classes, among others: the global <i>session</i> (surfaced as an OpenDoc part with no interface) subsuming all open Cyberdog documents but not Cyberdog parts in other non-Cyberdog documents, <i>items</i>, <i>services</i> to specify a particular protocol, <i>streams</i> to pull down data for that protocol over the network, and <i>display parts</i> to show that data. Since Internet suites generally subdivide their functionality by protocol, let's start with how a service in Cyberdog for an arbitrary protocol might be implemented.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigoKQ0wvKM4LSGbZdVEPTgULwM2vAY3dlLJrTSHEvHdlHNOrFAmLa-AiD5fY2iCN3Cfx6hWcfk5DB7ry4Pbg23Zyjo_-SGnaqo3mzFGlr_lekPMBDNmBIQSmWdHt47vCbQHy4wmcv2nffIkMXI8dqAOXIwLhDXiXODXYy4DSSD7syph39sPRovhflm754/s640/Picture%2011.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigoKQ0wvKM4LSGbZdVEPTgULwM2vAY3dlLJrTSHEvHdlHNOrFAmLa-AiD5fY2iCN3Cfx6hWcfk5DB7ry4Pbg23Zyjo_-SGnaqo3mzFGlr_lekPMBDNmBIQSmWdHt47vCbQHy4wmcv2nffIkMXI8dqAOXIwLhDXiXODXYy4DSSD7syph39sPRovhflm754/s320/Picture%2011.png" width="320"></a></p><p>

When I want to do a simple Internet TCP socket test, my favourite service for example purposes is the <a href="https://en.wikipedia.org/wiki/Finger_%28protocol%29">finger protocol</a> as set forth in RFC 742 <i>et seq.</i>: we connect to the server, we send a single ASCII line, the server emits a reply, and then the server disconnects. (In a very real implementational sense, Gopher is essentially the next step up, as it is also a single command and reply but adds a structured menu format. Some of you will recall exploiting this property to <a href="http://oldvcr.blogspot.com/2020/09/hacking-gopher-client-into-alpha-micro.html">build a Gopher client on the Alpha Micro</a> from a hacked finger client.) It's an easy protocol to understand and build. Apple must have thought so too, because they include just such an example.
</p><p>
The Finger Service example is divided into three sections: the finger service proper, <tt>FSConnect</tt> as its linkage into the Cyberdog Connect window to request a hostname and username, and <tt>FSPrefs</tt> for exposing its single preference stored in Internet Config (to open the finger connection synchronously or asynchronously, which for the purposes of this article we'll simply handwave away).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh7b9C2IhdoTw2L0qwdQZpcopFmtjBc8AKMFqOIycgP7qkjmLxqfGGmTLJQiVUkPsCMDxLhlXCTXm0SAK-ptE6rVrytvbLDKvyqeKRYgoNuq4ONiH-n9WF2Xg5EMisdHWVecBMXR_OlbKKsurQevlh8jbCHwANJHFNkobOuSkTqEK3SfdGHK88BN_3h-vo/s640/Picture%2029.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh7b9C2IhdoTw2L0qwdQZpcopFmtjBc8AKMFqOIycgP7qkjmLxqfGGmTLJQiVUkPsCMDxLhlXCTXm0SAK-ptE6rVrytvbLDKvyqeKRYgoNuq4ONiH-n9WF2Xg5EMisdHWVecBMXR_OlbKKsurQevlh8jbCHwANJHFNkobOuSkTqEK3SfdGHK88BN_3h-vo/s320/Picture%2029.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqKVZ7FEZL4gnoI6LexhDNLZyhLvVpM0laKvUibrgFrk7vciCcUTSo4aKyydlB-0f93oGl1LsikYSLcNOt2bb2SfnybaE_SRVyht9s9Zq4OG8GpdNxUp-Yyf1WYQNH6IH3PmgGS9ZBMcoEv4z5jhClKdADNDkRDZlaBeEGxrE_1CwG5kINOuDG_QjiLLY/s640/Picture%2030.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqKVZ7FEZL4gnoI6LexhDNLZyhLvVpM0laKvUibrgFrk7vciCcUTSo4aKyydlB-0f93oGl1LsikYSLcNOt2bb2SfnybaE_SRVyht9s9Zq4OG8GpdNxUp-Yyf1WYQNH6IH3PmgGS9ZBMcoEv4z5jhClKdADNDkRDZlaBeEGxrE_1CwG5kINOuDG_QjiLLY/s320/Picture%2030.png" width="320"></a></p><p>

Before trying to build it, copy the examples to your hard disk — I just copied the entire disc over — and fix the access paths in CodeWarrior, which by default appear to be completely blank. All of the necessary libraries and headers are included as either part of CodeWarrior Gold 9 or on the SDK disc itself.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDmmsUENidLCoqehHcFgeBtePXEuRj9e8IZe1LEGCxDr3FYqItOtW6_krYqA7TdQ-NIqXlqpABQfbQ6SD8e63Ejwy1l9o3V7viKvSk2J4QfT_dw0mERZj3_MUsxzr-M0Zgslasxpff_Zm3UYWNiIVpgLdctGpGw4LL_NRz3rw4SuFHcaxNFZQLUjarDWI/s640/Picture%2014.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDmmsUENidLCoqehHcFgeBtePXEuRj9e8IZe1LEGCxDr3FYqItOtW6_krYqA7TdQ-NIqXlqpABQfbQ6SD8e63Ejwy1l9o3V7viKvSk2J4QfT_dw0mERZj3_MUsxzr-M0Zgslasxpff_Zm3UYWNiIVpgLdctGpGw4LL_NRz3rw4SuFHcaxNFZQLUjarDWI/s320/Picture%2014.png" width="320"></a></p><p>

We'll start with </p><tt>FingerService</tt><p>. This contains everything you would think would be needed: a subclassed item for references to finger resources and support for understanding finger URLs, the stream class itself, and a resource and handler for an example menu item. The component is linked against various stub dynamic libraries, notably Cyberdog's stub shared library itself, and a number of OpenDoc stub shlbs. So far, so good.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgCSzU7Uhj78WwUFfwy13rPoOSnX7ZwOdGwh1p36-xBg1Th8a5lzPhi079i4dFYG2DqGHUWbEuPu5T-TBKLdfRnukrKbH86SYzFOEJeCHudNyJCKycxnb6KuqDKBm5dy1IGjzksT63Ro7KR589JjUjUjYBPfK7udriLrjgxn68wnjU5AM2KoemQNhtq0m8/s640/Picture%2015.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgCSzU7Uhj78WwUFfwy13rPoOSnX7ZwOdGwh1p36-xBg1Th8a5lzPhi079i4dFYG2DqGHUWbEuPu5T-TBKLdfRnukrKbH86SYzFOEJeCHudNyJCKycxnb6KuqDKBm5dy1IGjzksT63Ro7KR589JjUjUjYBPfK7udriLrjgxn68wnjU5AM2KoemQNhtq0m8/s320/Picture%2015.png" width="320"></a></p><p>

But it's what <em>else</em> gets rolled into it that raises eyebrows somewhat, and these pieces are unexpectedly linked in <em>statically</em>. Network access, rather than using MacTCP or OpenTransport directly, uses Cyberdog-specific classes such as a specialized domain name resolver and the </p><tt>tcp_endpoint</tt><p>, which is more or less a socket-like entity. These pieces don't appear to be part of Cyberdog's shlb — we have to compile them in. OpenDoc is even worse, with a mass of utility classes that also aren't part of its own stubs.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgqSnwGYEsyM4FOwxTUbpSiVlZft0DjlNdCskIOsI_4WN0apFbgkowPJpT4tLM8NW4c0ZU2eaIAjweuwDK9P8E-viC1Xo9XfyYTw7Jc-LLwMNNc4CL4U-yC8sUSYN_16w7nMMfB0qYyDGkgTjyOKpbEVoxvIy00hd9rvJMlvFnx1-xHwIi3Ikdf7Fa7Dtc/s640/Picture%2036.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgqSnwGYEsyM4FOwxTUbpSiVlZft0DjlNdCskIOsI_4WN0apFbgkowPJpT4tLM8NW4c0ZU2eaIAjweuwDK9P8E-viC1Xo9XfyYTw7Jc-LLwMNNc4CL4U-yC8sUSYN_16w7nMMfB0qYyDGkgTjyOKpbEVoxvIy00hd9rvJMlvFnx1-xHwIi3Ikdf7Fa7Dtc/s320/Picture%2036.png" width="320"></a></p><p>

The included resource file defines a </p><tt>srvc</tt><p> resource which points to standard </p><tt>STR#</tt><p> string resources to provide the protocol's name and URL scheme (</p><tt>finger</tt><p>), the finger service's C++ class name (</p><tt>AppleCyberdog::FingerService</tt><p>), the finger item's class name (</p><tt>AppleCyberdog::FingerItem</tt><p>), and the OpenDoc kinds for its Connect interface ("</p><tt>+//ISO 9070/ANSI::113722::US::CI LABS::Apple:Cyberdog:FingerSample:Kind:ConnectPanel</tt><p>") and preferences interface ("</p><tt>+//ISO 9070/ANSI::113722::US::CI LABS::Apple:Cyberdog:FingerSample:Kind:PrefsPanel</tt><p>"). It also specifies strings for a single menu item, called "Finger Beep."

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjngLG__mw5mONPYU90p2mLyrTRyVMhVuHLX85kJsvj3wzj3Vf-nXVxXiA3ncsZqFZmRyOZeR7dQt6zQcnyZYWLeuDSCbsJENIDyIzbhICJpz3bCRU61eIrJCfB9xpZvjDNZ_cw3inhaAj8zWtpXHYiea7YBteE7dxznkfs-IstDsivoWekaCp5RADN6Kw/s640/Picture%2035.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjngLG__mw5mONPYU90p2mLyrTRyVMhVuHLX85kJsvj3wzj3Vf-nXVxXiA3ncsZqFZmRyOZeR7dQt6zQcnyZYWLeuDSCbsJENIDyIzbhICJpz3bCRU61eIrJCfB9xpZvjDNZ_cw3inhaAj8zWtpXHYiea7YBteE7dxznkfs-IstDsivoWekaCp5RADN6Kw/s320/Picture%2035.png" width="320"></a></p><p>

And that item beeps. Despite this being a C++ file, and despite implementing a C++ object backing the finger service, this function is not C++. </p><tt>FingerService__DoMenuItemSelected</tt><p> — <em>not</em></p><tt>FingerService::DoMenuItemSelected</tt><p> — is actually called through SOM to override that method in </p><tt>SimpleCyberService</tt><p> (of which </p><tt>FingerService</tt><p> is a subclass), which is why we use a <em>C</em> declaration because the name mangling is different and SOM bindings only exist for C. Anything that needs to be accessible to a SOM call will need a SOM-compatible declaration. Fortunately, at least the pre-generated header files and stub glue code are all provided for you with the SDK, so you don't need the SOM IDL compiler merely to build these demo projects.
</p><p>
This function takes an <tt>AppleCyberdog_FingerService</tt> (basically a <tt>this</tt> pointer), an SOM <tt>Environment</tt> pointer, and then the index of the selected menu item relative to this part's menu (starting from 0), a pointer to the OpenDoc frame (<tt>ODFrame</tt>) associated with the menu event, and a pointer to the service's menu data (<tt>CyberMenuData</tt>). Represented in SOM Object IDL, the function declaration is <tt>void DoMenuItemSelected (in long index, in ODFrame frame, in CyberMenuData menuData);</tt> (the self and environment pointers are implied arguments to every SOM call).
</p><p>
Setting up menus themselves is no picnic either. The Cyberdog programmer's manual says that "[y]ou must anticipate changes in the menu bar between activations of your part. You should re-create the menu bar each time your part is activated or its menus are adjusted." You also have to handle deactivating or removing the Cyberdog menu when your part loses focus (and activating it again when it does), and you have to allow menu items to adjust themselves and handle their own events. This turned out to be an exceptionally bad design choice for all kinds of reasons, which we'll revisit at the end.
</p><p>
But once we're past all that, the actual code to handle the menu event is very simple and much like handling pull-down menus otherwise: if the index is 0, which is the only menu item we provided in the <tt>srvc</tt> resource, then we call the Toolbox <tt>SysBeep</tt> routine. If we wanted more or different menu items, we'd add more strings to the specified menu item <tt>STR#</tt> resource, and check for and handle those indices here.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0I2-Cy2GXuVkF-S_bAP9xAlSTsXLpUMGeDxzwN0bqxpn_MWhtIqpK0XapvbUwb0wzvR3TOcymCQyAwqtUHMnEu9EiRdMsCMicw6jsvnI7k6QbQx-zPSj30JaoBOkzIwWYWdTt_cngK8pBqjGPKnvThbYMYXSAIwVx_MEtmWZuUANbuOGw3ePMzeBXI7g/s640/Picture%2013.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0I2-Cy2GXuVkF-S_bAP9xAlSTsXLpUMGeDxzwN0bqxpn_MWhtIqpK0XapvbUwb0wzvR3TOcymCQyAwqtUHMnEu9EiRdMsCMicw6jsvnI7k6QbQx-zPSj30JaoBOkzIwWYWdTt_cngK8pBqjGPKnvThbYMYXSAIwVx_MEtmWZuUANbuOGw3ePMzeBXI7g/s320/Picture%2013.png" width="320"></a></p><p>

The implementation of the finger URL is pretty straightforward.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGV1vXJtJ-7KfpBWYDNykXin3o3GcA5qkqU0nL_YFbVf_5aNu6kcYrheX2RSVLeKnbXGOPk3BviJU5G-RukE0xKE80-3XQv3CpE1jL3JdZoWp8P3ATvulu-KOUFKy0vt8v2mcjKwZFguTDajIdktq4-eKIjHyR-DQxhXyj-Y_JtefxwGX3aVdgK5qz8XA/s640/Picture%2012.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGV1vXJtJ-7KfpBWYDNykXin3o3GcA5qkqU0nL_YFbVf_5aNu6kcYrheX2RSVLeKnbXGOPk3BviJU5G-RukE0xKE80-3XQv3CpE1jL3JdZoWp8P3ATvulu-KOUFKy0vt8v2mcjKwZFguTDajIdktq4-eKIjHyR-DQxhXyj-Y_JtefxwGX3aVdgK5qz8XA/s320/Picture%2012.png" width="320"></a></p><p>

But then we start getting into a blizzard of SOM methods again when we implement the Cyberdog finger item. There is a C++ backing object, but everything else is SOM, subclassing </p><tt>CyberItem</tt><p>. Everything gets overridden. <em>Everything.</em> (To add further insult, </p><tt>ctopstr</tt><p> and </p><tt>pstrcpy</tt><p> handle conversion between Macintosh Pascal strings and regular C strings. You'd think that would get handled for you in this brave new OpenDoc world, but noooo.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi8iZQkMm_hzjIcTLkY2_JgRz9vkYzlScZOFUU1Q8G4q61zp7IjamL6A85SQgUQ6MKiu_ns67iNnoHKWVDO8IbwGMTwGfPt7jz40vqbvwxj-JTE9sitOrTRc25DMNK-qMuQar6ljYCPUAg7_XqbY1J8zLb_3RZzG3_Ji8dqWPfUl3fyDTt6qCVcHO0FgfE/s640/Picture%2016.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi8iZQkMm_hzjIcTLkY2_JgRz9vkYzlScZOFUU1Q8G4q61zp7IjamL6A85SQgUQ6MKiu_ns67iNnoHKWVDO8IbwGMTwGfPt7jz40vqbvwxj-JTE9sitOrTRc25DMNK-qMuQar6ljYCPUAg7_XqbY1J8zLb_3RZzG3_Ji8dqWPfUl3fyDTt6qCVcHO0FgfE/s320/Picture%2016.png" width="320"></a></p><p>

It gets even worse when we move to </p><tt>FSConnect</tt><p>. Since this has to worm itself into the Cyberdog Connect window, you would expect a lot of SOM-compliant methods. And that's what you're gonna get, all right, but we have to start with its underlying C++ class first.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxIELCOW0UcM3A66dmUBI9NZvxC_pgMMd8NyTMz7Zi9-QHjMbRcowaqbRV01pu2IDxZeSvcSubrMgDm65VImfs0bA_cawzpr4hD9Z9CR7cxYVigzrvqqWeBEeWApzgQsgzPWT3-5BwQD7zrKnU8rsMhhLywqGQkxqp60uz3YTuBn3pVXuQF4dZtQ4y2Zk/s640/Picture%2017.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxIELCOW0UcM3A66dmUBI9NZvxC_pgMMd8NyTMz7Zi9-QHjMbRcowaqbRV01pu2IDxZeSvcSubrMgDm65VImfs0bA_cawzpr4hD9Z9CR7cxYVigzrvqqWeBEeWApzgQsgzPWT3-5BwQD7zrKnU8rsMhhLywqGQkxqp60uz3YTuBn3pVXuQF4dZtQ4y2Zk/s320/Picture%2017.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBsdeB2RTTpprGd3hLIiGsipaty-bVDKEnon2ARE8Vfpi84HAkBgxd5DEeC36KtjzKwlUNrZxu_xz9K2qfhGegiAWkDFVS2rkRw0qpnQYwFLPEpkN5M69fXvTOx_oKLrjpkMlGAkUV-mTaX2joRs9iN9mDXbV7uEfpaph0g9zApX37zZrtEjo5WmjlXOg/s640/Picture%2018.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBsdeB2RTTpprGd3hLIiGsipaty-bVDKEnon2ARE8Vfpi84HAkBgxd5DEeC36KtjzKwlUNrZxu_xz9K2qfhGegiAWkDFVS2rkRw0qpnQYwFLPEpkN5M69fXvTOx_oKLrjpkMlGAkUV-mTaX2joRs9iN9mDXbV7uEfpaph0g9zApX37zZrtEjo5WmjlXOg/s320/Picture%2018.png" width="320"></a></p><p>

This C++ class handles all the OpenDoc code to maintain and display its part within that window, and it's a doozy. Did you expect <em>this</em> many methods? I haven't even shown you them all.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinDyFblazGHuNirWcz-4GM8D4evqf9ZybA-gzlZxj6las2LHcI10qMkWwDJya8khYJTKww4tBP0p24_0jegcHOXsTIwC4JFblXPhK3J83FdUPEwsj2Sa3HBZP-lGZJ0EB2qNTg6DMZSYqinTRz14qQQgg0hKBZyaTaNYb5y5-tn8ZP-tfmHJgXh0KMaqQ/s640/Picture%2022.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinDyFblazGHuNirWcz-4GM8D4evqf9ZybA-gzlZxj6las2LHcI10qMkWwDJya8khYJTKww4tBP0p24_0jegcHOXsTIwC4JFblXPhK3J83FdUPEwsj2Sa3HBZP-lGZJ0EB2qNTg6DMZSYqinTRz14qQQgg0hKBZyaTaNYb5y5-tn8ZP-tfmHJgXh0KMaqQ/s320/Picture%2022.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfVE0nXPByGdZROldxoFeeJzo3DJoQPDQGeSV5d3AS2CJCq9MaD_wJQ-t9JzAv7v3urDmhR83z8BLGxGMfVXHTlxwBrnZh8_Im2F71I0ogdhsuqs7CppsOEAn72rm31cK8SE3ieiDaPlg2lE2Z7GjVxIJrQVw52onxA0Rx57c47NTVvHN-Dm9991oyJgI/s640/Picture%2023.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfVE0nXPByGdZROldxoFeeJzo3DJoQPDQGeSV5d3AS2CJCq9MaD_wJQ-t9JzAv7v3urDmhR83z8BLGxGMfVXHTlxwBrnZh8_Im2F71I0ogdhsuqs7CppsOEAn72rm31cK8SE3ieiDaPlg2lE2Z7GjVxIJrQVw52onxA0Rx57c47NTVvHN-Dm9991oyJgI/s320/Picture%2023.png" width="320"></a></p><p>

But wait, there's more! <em>Now</em> (because SOM doesn't have direct bindings for C++) we have to provide the SOM glue to actually <em>call</em> those C++ methods. The IDL compiler would generate the scaffolding but you'd still have to labouriously hook them all up.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgm_Srh--fGBlDip_6y8QVcVLFdHliq7_7FKIW07Ve4sCNETw9r0W1uou30JI0xBwOWmqwdCspaKDrpt_Dx26hmESeq2W6YEkoLARIK67P6uvNizW6nQB-qy_mh2rXwWvsq3Gqd5hzRSufdkGh4h6JqSbrgn_0_uIbt4DTyKr5_QEVEVF-edBe729zK2ew/s640/Picture%2019.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgm_Srh--fGBlDip_6y8QVcVLFdHliq7_7FKIW07Ve4sCNETw9r0W1uou30JI0xBwOWmqwdCspaKDrpt_Dx26hmESeq2W6YEkoLARIK67P6uvNizW6nQB-qy_mh2rXwWvsq3Gqd5hzRSufdkGh4h6JqSbrgn_0_uIbt4DTyKr5_QEVEVF-edBe729zK2ew/s320/Picture%2019.png" width="320"></a></p><p>

There are also various utility methods ...

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEuZCK1HaxP28FPzDTRoox9kW-yE-y0lLoUxufJl_AMTKtYvw_O4h4QKbdM-72uv_9KFKLURswK_xH_FK-UK4_WA6JYZ6XAfTBH4ZxW_ERCr4Oeuw2_oiKOSxlpOHpeRuGRJAjUaUXENLxwJ9K9mBFZECHFKZvLhyUI8SETeJhtAO3huhX_fKg5y_W2qc/s640/Picture%2020.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEuZCK1HaxP28FPzDTRoox9kW-yE-y0lLoUxufJl_AMTKtYvw_O4h4QKbdM-72uv_9KFKLURswK_xH_FK-UK4_WA6JYZ6XAfTBH4ZxW_ERCr4Oeuw2_oiKOSxlpOHpeRuGRJAjUaUXENLxwJ9K9mBFZECHFKZvLhyUI8SETeJhtAO3huhX_fKg5y_W2qc/s320/Picture%2020.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiK7CN17Mzx37Q_wLW6Zxg4xc1Lwnar7xO9CTb8ubLHpIrKRpOXYbsJRGG4R1WRx2G2ltehdgXRp_J7HX4_2UQQhjySFgBlUyznUBlUUdWjqnDIDNLv40u0Oy4mMSM4Z7wnEl3n9NUepVW-QrKebF-89ro6cY9dEH1Rs2AsvqvXYBZVg0jZNxKjLN1FNsk/s640/Picture%2021.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiK7CN17Mzx37Q_wLW6Zxg4xc1Lwnar7xO9CTb8ubLHpIrKRpOXYbsJRGG4R1WRx2G2ltehdgXRp_J7HX4_2UQQhjySFgBlUyznUBlUUdWjqnDIDNLv40u0Oy4mMSM4Z7wnEl3n9NUepVW-QrKebF-89ro6cY9dEH1Rs2AsvqvXYBZVg0jZNxKjLN1FNsk/s320/Picture%2021.png" width="320"></a></p><p>

... a list iterator (we have to provide our own list iterator?) ...

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxhUbTz_80eof40HdlaCbRgm5dvKHAiJXzhZKHQnca7E_cZXLwfz-vn8CcI-GSKjJ0Fxo1KNG9VlOH-DQklphM52TQ6YAL1YXzLTH37Oj88WtP-fcIuU6ZVctHuGjqZFLR2aA1j5zneLkwSrDCwd2-1R-WFS2ziAj1vYKujhFGq8EdIRIcRGNbDXP0CKI/s640/Picture%2024.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxhUbTz_80eof40HdlaCbRgm5dvKHAiJXzhZKHQnca7E_cZXLwfz-vn8CcI-GSKjJ0Fxo1KNG9VlOH-DQklphM52TQ6YAL1YXzLTH37Oj88WtP-fcIuU6ZVctHuGjqZFLR2aA1j5zneLkwSrDCwd2-1R-WFS2ziAj1vYKujhFGq8EdIRIcRGNbDXP0CKI/s320/Picture%2024.png" width="320"></a></p><p>

... and then this little blob of SOM glue for when the finger </p><tt>CyberItem</tt><p> is actually generated by the Connect window, so we can do something with it. Notice the pre-processor macros for SOM's particular flavour of exception handling.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzqpOYxA5qh44Al0yhEWwm2p0hqCnbHODSIwAAXscCc9v0hqs729yv_Y53ikbyfScYUqck3rz_uRqO8z9oxOMZbvvhlyhKQ5cAB_eLuRVVvv0G1yYiogR6KYMzdtMC_yUukrgxTYv9Rr68WrzZic6Akc-XrGMM-qHrOk6QmpF374hyQsXoLGSPSC_ZEOk/s640/Picture%2027.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzqpOYxA5qh44Al0yhEWwm2p0hqCnbHODSIwAAXscCc9v0hqs729yv_Y53ikbyfScYUqck3rz_uRqO8z9oxOMZbvvhlyhKQ5cAB_eLuRVVvv0G1yYiogR6KYMzdtMC_yUukrgxTYv9Rr68WrzZic6Akc-XrGMM-qHrOk6QmpF374hyQsXoLGSPSC_ZEOk/s320/Picture%2027.png" width="320"></a></p><p>

It's the same story when we get to </p><tt>FSPrefs</tt><p>: a big C++ class and a lot of SOM glue, just to wedge our own trivial interface pane into Cyberdog's.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbGbtRa9CLbmsZuz3OAodlRJVXRATpBN0xJdikC9OcU25jwScj4aARuBPYakJe7zdkyUwJMt7drAt4_dEeuJWPEwwRMklDy3EmQ9y-BquH4RVtpHcmyL60c4aoRmYswaMU4I8FiafzzT9uaf1-DR7NEDPi9dHNrjzYCMk2Q3AZ4LFR7l6AlIzjafeAYKM/s640/Picture%2025.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbGbtRa9CLbmsZuz3OAodlRJVXRATpBN0xJdikC9OcU25jwScj4aARuBPYakJe7zdkyUwJMt7drAt4_dEeuJWPEwwRMklDy3EmQ9y-BquH4RVtpHcmyL60c4aoRmYswaMU4I8FiafzzT9uaf1-DR7NEDPi9dHNrjzYCMk2Q3AZ4LFR7l6AlIzjafeAYKM/s320/Picture%2025.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgAZfPC3NoE5NlzBWRmERv4QagH5I-sMGZ7gZKENophT9geWhfiN9lP6y32YW-yZ2-lk0rwT0MG442XH_rML7oNjNK1BnLwCOKDGhTAzpDGQX3rPemKKEXeWRf1K45oYxfk2eqC9E_niRXYkuyGfL7gbjfxRLtVd6S2IVFV-WxTMspvzOnKNJd45rZNyd8/s640/Picture%2026.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgAZfPC3NoE5NlzBWRmERv4QagH5I-sMGZ7gZKENophT9geWhfiN9lP6y32YW-yZ2-lk0rwT0MG442XH_rML7oNjNK1BnLwCOKDGhTAzpDGQX3rPemKKEXeWRf1K45oYxfk2eqC9E_niRXYkuyGfL7gbjfxRLtVd6S2IVFV-WxTMspvzOnKNJd45rZNyd8/s320/Picture%2026.png" width="320"></a></p><p>

I'll spare you the entirety of it here. Just know, like with </p><tt>FSConnect</tt><p>, nearly all these C++ methods also have SOM glue, and of course there's the rest of the boilerplate you saw in the project.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVSEJt-VJXsNHWLmKPhwpPOADdvTlDob7pUILbGb6j8clR1oT5nAVdw4i73YsrVHyZZPC_Kc8l-yMmnYiDP9NMHmgsuVL1LePeItjIqanaLm1FMrJyOiW3bhSEA6QaHp4RTF7mmJqjwkvPU-9mEGnoRYNWK97phe2hCgAHHkS5o4jkiOJ-QIEoqvyaoMM/s640/Picture%2031.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVSEJt-VJXsNHWLmKPhwpPOADdvTlDob7pUILbGb6j8clR1oT5nAVdw4i73YsrVHyZZPC_Kc8l-yMmnYiDP9NMHmgsuVL1LePeItjIqanaLm1FMrJyOiW3bhSEA6QaHp4RTF7mmJqjwkvPU-9mEGnoRYNWK97phe2hCgAHHkS5o4jkiOJ-QIEoqvyaoMM/s320/Picture%2031.png" width="320"></a></p><p>

Having built all three projects (or copied the pre-built ones), we deposit the resulting binaries into the Cyberdog Libraries folder. The Cyberdog library itself, containing nearly the entirety of the browser and its component parts, is a relatively svelte 2.8MB. Our overweight, freshly built and thoroughly flabby little finger service, on the other hand, summed over all three libraries is 427K — and 334K of that is just the pieces for the Connect and Preferences windows. We might blame some of this on debugging and maybe some on CodeWarrior, but we can't ascribe all of it.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhHayOSLaOtwuR2-nnQoCi9Bxh7OA-e-1W7cGqAsr2PW06lycI332TlFVRhajLhXqVXYW5-AYapTYfD69eAdEffThZjXJ00lumarUqPkP1zOJMduGBVt4UFKaY7EEQ_1UOqq4JHjIVPaG6ATqYmmCLvW5Of-DAVOsye8JVSpu6FOI0vy_YqpY1Tq34RN7U/s640/Picture%2032.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhHayOSLaOtwuR2-nnQoCi9Bxh7OA-e-1W7cGqAsr2PW06lycI332TlFVRhajLhXqVXYW5-AYapTYfD69eAdEffThZjXJ00lumarUqPkP1zOJMduGBVt4UFKaY7EEQ_1UOqq4JHjIVPaG6ATqYmmCLvW5Of-DAVOsye8JVSpu6FOI0vy_YqpY1Tq34RN7U/s320/Picture%2032.png" width="320"></a></p><p>

Our "Finger Beep" menu item now duly appears in the Cyberdog menu, and does beep.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmuET4JgWhTk7_lkayVNf6Sps_aT3x1vky8vD6Vp4IuZQfu7X7XMBqlGg-7Upi5oPNt3fTvJAdEv1XeFbwJPX2Ka3goncBYkgNLO_yLhPz5Q3FAHaE08YMr2dtaOvicDUSU0CoKqV-ztpvhrMXOFbnyKTZ6adYSr427Gh4kfYfU7TB_9KXLDKxGKLaEMs/s640/Picture%2033.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmuET4JgWhTk7_lkayVNf6Sps_aT3x1vky8vD6Vp4IuZQfu7X7XMBqlGg-7Upi5oPNt3fTvJAdEv1XeFbwJPX2Ka3goncBYkgNLO_yLhPz5Q3FAHaE08YMr2dtaOvicDUSU0CoKqV-ztpvhrMXOFbnyKTZ6adYSr427Gh4kfYfU7TB_9KXLDKxGKLaEMs/s320/Picture%2033.png" width="320"></a></p><p>

Here's what all that code for the Connect window actually bought us — two lousy text fields. (T-shirt idea: I compiled </p><tt>FSPrefs</tt><p> and all I got was a label and a check box!) They really are lousy too, because if you press RETURN in them, they don't seem to recognize they shouldn't be multi-line. The code then takes the results from those fields and generates a Cyberdog item to display finger information, which it then opens.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgyuLSPbYNTb6m9_E0-pHGTFMHZhrA0fhgoFk86UmwEJJrQaw9a7oKR5Al781CLtvwHkxYfJrGvo09v-3HwpOKtKX-pdm2qtvFgay7zG2F4Vrb-mrXGdSsJyO-5YfQdjxnYiGL4Q7sY62UbtCTy4HIqrpYOCCTD9Clj4T32z3PynK7fL38thqtMnSvqoYQ/s640/Picture%2034.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgyuLSPbYNTb6m9_E0-pHGTFMHZhrA0fhgoFk86UmwEJJrQaw9a7oKR5Al781CLtvwHkxYfJrGvo09v-3HwpOKtKX-pdm2qtvFgay7zG2F4Vrb-mrXGdSsJyO-5YfQdjxnYiGL4Q7sY62UbtCTy4HIqrpYOCCTD9Clj4T32z3PynK7fL38thqtMnSvqoYQ/s320/Picture%2034.png" width="320"></a></p><p>

Fortunately, opening the item works pretty much seamlessly, here fingering </p><tt>root</tt><p> on one of my internal servers. The name in the title bar is the name stored in the generated item. I'll reproduce part of the code from the </p><tt>FingerService</tt><p> here that opens the finger item, using the synchronous version for clarity.
</p><div><pre>SOM_Scope void  SOMLINK FingerItem__Open
                                    (AppleCyberdog_FingerItem *somSelf,
                                     Environment *ev,
                                     ParameterSet* theParams)
{
 ...
 // Extract the opener part (if any) from the parameter set.
 ODPart* openerPart = kODNULL;
 if(theParams)
   if(!theParams-&gt;GetParameter(ev, kCDInitialOpenerPartKey,
                               &amp;openerPart))
     theParams-&gt;GetParameter(ev, kCDObtainedOpenerPartKey,
                             &amp;openerPart);

 // Create the right kind of part in the right document.
 CyberSession* cyberSession = ::GetCyberSession(ev);
 TempODPart cyberPart = cyberSession-&gt;CreateCyberPart(ev,
                                                      openerPart, kTextPlainKind, kODNULL);

 // If the display part handles the kTextPlain kind of data,
 // create a download part instead.
 if(cyberPart == kODNULL)
   cyberPart = cyberSession-&gt;CreatePartInCyberDocument(ev,
                                                       kDownloadPartKind, kODNULL);

 // Open the Cyberdog item.
 if(cyberPart)
 {
   TempCyberPartExtension cyberPartExt(cyberPart, kCyberPartExtension);
   cyberPartExt-&gt;OpenCyberItem(ev, fingerItem, openerPart, params);
 }
 ...
}
</pre></div>
<p>
Among other things, this first tries to figure out what wants to open it, and then calls for a new part to display the data to be received. Notice how we're treating these calls like regular C++, which will give us <tt>this</tt> as the first argument for free, but we still must pass the SOM environment pointer.
</p><p>
<tt>CreateCyberPart</tt> is a method provided by the global Cyberdog session that determines what document to insert a new display part into, be it within or without the current Cyberdog session proper, with an optional editor argument (here we've passed a null pointer to use the default). If there's no document to insert it into, we'll create a "download part" to stream the data directly into a plain text display part in a brand new document. We then open the item, which starts the network transfer.
</p><p>
Asynchronous opening would spin off a separate thread to do most of this. If you were connecting to the world's slowest finger server and wanted to cancel the connection before it timed out, you can check for posted stop events with a Cyberdog progress broadcaster while your network transaction runs, which is what you'd do normally for user-facing code.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-Bgw6clvX4nTDgk9hFaUdhJQxuGSKjV7nP2_lwGjR5AORdQfbz9ltxCati6rmM2kgtYDpVCOsIdL1RQeuhtWgBZf6rLNn1IfZe-8CnEnupLQKsMqZTOvifncxgtUMT1Wdd74Ws8otmjyMkPBGXsAwprQXAWK2sVIenS1JcZdrvVhi_CJ_2yTFrlW6Z1I/s640/Picture%2037.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-Bgw6clvX4nTDgk9hFaUdhJQxuGSKjV7nP2_lwGjR5AORdQfbz9ltxCati6rmM2kgtYDpVCOsIdL1RQeuhtWgBZf6rLNn1IfZe-8CnEnupLQKsMqZTOvifncxgtUMT1Wdd74Ws8otmjyMkPBGXsAwprQXAWK2sVIenS1JcZdrvVhi_CJ_2yTFrlW6Z1I/s320/Picture%2037.png" width="320"></a></p><p>

If all that for all that seemed as excessive to you as it did to me, it apparently did so to Apple as well. But instead of trying to streamline the API and make it less verbose, Apple's solution was to ... semi-automate generating the </p><s>bullshi</s><p> boilerplate instead. Apart from their implementation of the SOM IDL compiler — which initially only ran as an MPW tool, not in CodeWarrior — Apple provided a third-party tool for this purpose called CodeSampler, which takes a part template you want to modify and spits out a new one with basic changes that you can then go and edit.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFo_Wp8GQ7oE6dPhu3_UjkyUMteM8ye-0NR2yLDHHC6JVMLg-AvaGeY1eWPTKDDA3-HWmBQv_Q_TbLINpHUmTEJqs78jI7NN9uunqx6VhionkIoTLCncWEZ4JVb4Dt7c5sxxoek16V-8yB4qkWiRameWtsPl2o027Xg0Xv22p07VtGzieCQcTRRky2twY/s640/Picture%2038.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFo_Wp8GQ7oE6dPhu3_UjkyUMteM8ye-0NR2yLDHHC6JVMLg-AvaGeY1eWPTKDDA3-HWmBQv_Q_TbLINpHUmTEJqs78jI7NN9uunqx6VhionkIoTLCncWEZ4JVb4Dt7c5sxxoek16V-8yB4qkWiRameWtsPl2o027Xg0Xv22p07VtGzieCQcTRRky2twY/s320/Picture%2038.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMfuF8cjVC3CDAXhjvzA-0JrR6dWlEjhR0UrbM2AjcspVvzktjIbZ7BRPJxemyrd6bo8coRcUx7SdgNWYJHFE-OY5_yJY4hJS4L1n0sl3mQOAAVD7TAM_xRbAUorW-CjBYBr9FzKGCdbqhbSWWxYxfmx31cXkOGeSQihN4SsQyJ2FHk5SoFV3N8EdkWAk/s640/Picture%2039.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMfuF8cjVC3CDAXhjvzA-0JrR6dWlEjhR0UrbM2AjcspVvzktjIbZ7BRPJxemyrd6bo8coRcUx7SdgNWYJHFE-OY5_yJY4hJS4L1n0sl3mQOAAVD7TAM_xRbAUorW-CjBYBr9FzKGCdbqhbSWWxYxfmx31cXkOGeSQihN4SsQyJ2FHk5SoFV3N8EdkWAk/s320/Picture%2039.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2osqpCtCuF8vajHUsc0bU2tX5bYmg_rchGFoiKwHP8-XMCIIZ4iDm_NbutuW_lq_j3N5SsLd65bpCTL1t-TmfsmYloyYFk0AtrBOvvKE_SB4iafPwYmvnehzsRVRG3h73uunNYUWfU4wy4zXTFeWdEescjSnjteExcMDhXScuBwOKfUDMZae2lEtJMVw/s640/Picture%2040.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2osqpCtCuF8vajHUsc0bU2tX5bYmg_rchGFoiKwHP8-XMCIIZ4iDm_NbutuW_lq_j3N5SsLd65bpCTL1t-TmfsmYloyYFk0AtrBOvvKE_SB4iafPwYmvnehzsRVRG3h73uunNYUWfU4wy4zXTFeWdEescjSnjteExcMDhXScuBwOKfUDMZae2lEtJMVw/s320/Picture%2040.png" width="320"></a></p><p>

I say "semi-automate" because the template only handles basic bikeshedding, and only for the templates that are included. Even on those that are, you still have to deal with looking at all the methods it subclassed, though at least you'd have a (theoretically) working scaffold to start from rather than writing every agonizing bit from scratch.
</p><p>
Naturally, there were more practical reasons to create a Cyberdog service. One of Cyberdog's rather obnoxious deficiencies was the inability to directly open a file from the UI; files could only be referenced by typing in <tt>file:</tt> URLs (on locally mounted disks, or via AppleTalk and/or Apple Filing Protocol in later releases) or opening an item referencing it that already existed. <a href="http://web.archive.org/web/19961101214106/http://cyberdog.apple.com/download/openfileservice.html">The OpenFileService part</a> provided a menu option which would dynamically generate a Cyberdog item to a file reference using the Standard Open dialogue, and you've now seen enough from the finger service example to understand generally how that would be implemented. Unfortunately, this rather useful component was stored on the Cyberdog FTP server, which I could find no existing mirrors or archives of, and thus to the best of my knowledge is now lost. Also notice this component says it was <em>68K</em> compatible — hold that thought.
</p><p>
For the next project in the SDK, we'll first move on to Cyberdog's most notable, most unique and probably most underutilized feature: creating OpenDoc documents that could embed buttons and browser views. We start up DocBuilder by creating a new document from the Document menu.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg88oUHpf18g5V-9mAUmnar1LnBoAbXhHpewhHPw8OcZCw7VClYp51CjfY23TKxEJStu8GuawL-Byq6sNlMqAQ8m-J3fpe5EiTtkWgeObx0UfZz0NeS7_GnE3CYcyBcbddfK2nn3Zh6S0GPhdRoYmCC3bonQwRGqQgI76w-XCm6bJ9qtWZny8_NJM1_FMA/s640/Picture%2054.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg88oUHpf18g5V-9mAUmnar1LnBoAbXhHpewhHPw8OcZCw7VClYp51CjfY23TKxEJStu8GuawL-Byq6sNlMqAQ8m-J3fpe5EiTtkWgeObx0UfZz0NeS7_GnE3CYcyBcbddfK2nn3Zh6S0GPhdRoYmCC3bonQwRGqQgI76w-XCm6bJ9qtWZny8_NJM1_FMA/s320/Picture%2054.png" width="320"></a></p><p>

DocBuilder came with every version of Cyberdog from the very beginning, and is nothing less than a full-blown OpenDoc document editor lurking within Cyberdog. It was written for Apple under contract by <a href="http://web.archive.org/web/19970412130718/http://www.6prime.com:80/services.html">6prime</a> (who also wrote CodeSampler), a small software company founded specifically to cater to OpenDoc on the Mac by Eric Soldan and Tantek Çelik, who previously worked on OpenDoc as an Apple employee. 6prime's key product was <a href="http://web.archive.org/web/19970412130847/http://www.6prime.com/rev/index.html"><i>REV</i></a>, an auto-versioning tool that got bought out by Aladdin Systems in 1997. Çelik ended up at Microsoft where he developed Internet Explorer for the Mac, and is now the Web standards lead at Mozilla.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEsAOCH0oCsTlQ2KdC4VsESLzHptt-VP-V0NtyjiU6fcf13hSHaUjXnZKKYW4_4TGMzGLd_L9lpjZN0IrfZ0E3fEQXMF4RzPBsePiQ8bRR1ubt4sFL-aiUxz5pxlms9tNCMH_oE3qN_SBrrwFo3_yw5qiruD7qWsiDipJDuPHMOgJRRZbX_WOfdBQxLmw/s640/Picture%2045.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEsAOCH0oCsTlQ2KdC4VsESLzHptt-VP-V0NtyjiU6fcf13hSHaUjXnZKKYW4_4TGMzGLd_L9lpjZN0IrfZ0E3fEQXMF4RzPBsePiQ8bRR1ubt4sFL-aiUxz5pxlms9tNCMH_oE3qN_SBrrwFo3_yw5qiruD7qWsiDipJDuPHMOgJRRZbX_WOfdBQxLmw/s320/Picture%2045.png" width="320"></a></p><p>

Unfortunately, DocBuilder is just as memory-hungry as everything else, and you'll definitely want 2MB for the document if you didn't already specify it (from Document Info, click the Size button).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjM6KMp0VzLJPZiNdNjALABqgi2k8ro5K6ybisEL_QT-AGLL6DhTrtQ4jEiwnoBns6EVuzKQ5abtM-_nSLSqoZxQsVsNDoCUpNQfz2vQu05yQ8kS0hu5gDKzfpuipySu9I5H-6JrTCtDQPoWmhV3zfDJFCVs7Q2aHFQMIWUIwZz5hdpLD0EuE1QUphZc2k/s640/Picture%2046.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjM6KMp0VzLJPZiNdNjALABqgi2k8ro5K6ybisEL_QT-AGLL6DhTrtQ4jEiwnoBns6EVuzKQ5abtM-_nSLSqoZxQsVsNDoCUpNQfz2vQu05yQ8kS0hu5gDKzfpuipySu9I5H-6JrTCtDQPoWmhV3zfDJFCVs7Q2aHFQMIWUIwZz5hdpLD0EuE1QUphZc2k/s320/Picture%2046.png" width="320"></a></p><p>

Save the blank document to disk so that the memory allocation sticks (I closed and reopened it for good measure). Notice that you could save OpenDoc documents as stationery too. How meta.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3qavqypkrQofokZyW7Ga4Ss_Xml5snOp1nzmt8r9zeCm-mMJSV9RSabXTS0g53Q2dFXUxwT-5RaF22q996ji92YppqlVYr_cf20IpC6sKDT5eKHF87lUHtDN5Vjmd2zTkxR0Ez--lSCnOU_lhrZGTZjg59Kjfc8S2Hq1QUThSEkjkVutl08r7cnRzvZ0/s640/Picture%2047.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3qavqypkrQofokZyW7Ga4Ss_Xml5snOp1nzmt8r9zeCm-mMJSV9RSabXTS0g53Q2dFXUxwT-5RaF22q996ji92YppqlVYr_cf20IpC6sKDT5eKHF87lUHtDN5Vjmd2zTkxR0Ez--lSCnOU_lhrZGTZjg59Kjfc8S2Hq1QUThSEkjkVutl08r7cnRzvZ0/s320/Picture%2047.png" width="320"></a></p><p>

Here is a sample document I created in DocBuilder's layout mode (where the dog is "laying" down, get it?). In addition to the standard drawing tools on the upper floating palette, DocBuilder provides three core parts offered on the lower one. The text labels were created with the text editor part (left), which can also include scrolling content (here I haven't, and I've also made them read-only). The dog button comes from the button part (middle), which oddly can only show graphics in Cyberdog 1.0; I pasted in the goofy dog icon from the Finder and added the explanation as a text blurb. You can also embed notebooks in the window to provide a hierarchical, collapsable list of links (right), as well as drag or paste PICTs directly into the document. The Starting Point is merely a Cyberdog document created exactly thus, and you could also use the DocBuilder for constructing rich E-mail messages — as long as the person on the other end also used Cyberdog.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg962eU66LmNwRTHMKtP2Ga0eJwz3rirtJYgWwsVIWvBM7nxzhPlwfNQJ9QYE886P4JXIPY1kvbQLFa_ZZL7GS2Bdor5SzUEz8vl2v2SxBzFW2yrkV73Wm9ZB3F2lXWY1juEkw_nVQDnNAFq45zQDv0F14hidt-Yutr0_6QrTUUr5ZDRkqD4treYy8-eQc/s640/Picture%2048.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg962eU66LmNwRTHMKtP2Ga0eJwz3rirtJYgWwsVIWvBM7nxzhPlwfNQJ9QYE886P4JXIPY1kvbQLFa_ZZL7GS2Bdor5SzUEz8vl2v2SxBzFW2yrkV73Wm9ZB3F2lXWY1juEkw_nVQDnNAFq45zQDv0F14hidt-Yutr0_6QrTUUr5ZDRkqD4treYy8-eQc/s320/Picture%2048.png" width="320"></a></p><p>

Embedding a live browser, however, requires slightly more work: you drag the desired URL or item from a separate navigator into the window and then adjust ad lib. OpenDoc is "semi-modal" in the sense that you have to <em>activate</em> — not just select, notice the unusually thick frame — a part to bring up its menu(s), which cancels menus from other parts and here as a side effect hides the palettes until the overall document regains focus. The select-versus-activate distinction was yet another one of OpenDoc's interface faults. Here I've turned off the controls and location bar in the embedded navigator, though you can still click on links and use forms.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBksuxSidoepYUXjMMET78xZP9vSy-6Sv7oNge3yv3CSTAbPkCcGT3j0Z00SetnD4Vpqc__nq8PklJyEwyk9sojQEGbMSyV-ucu6vSKQZthhX6huYdTUwEARL0mVQ_urRlwVgawHePDTC3ep--drCCncXBExqAPWo_VvMBSgVDhZLwfYInOhbcKbEQAQE/s640/Picture%2049.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBksuxSidoepYUXjMMET78xZP9vSy-6Sv7oNge3yv3CSTAbPkCcGT3j0Z00SetnD4Vpqc__nq8PklJyEwyk9sojQEGbMSyV-ucu6vSKQZthhX6huYdTUwEARL0mVQ_urRlwVgawHePDTC3ep--drCCncXBExqAPWo_VvMBSgVDhZLwfYInOhbcKbEQAQE/s320/Picture%2049.png" width="320"></a></p><p>

Since browser parts will automatically try to connect to their embedded locations as soon as the document is opened, buttons serve as "deferred links" (well, really, just buttons) to avoid cheesing off the dialup users. Buttons have a limited number of things they will connect to, mostly URLs/items and some internal components, and they weren't capable of scripted behaviour.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2q7FhITJInWeUk4OYNDyW9vVGO4daGis1ts6T_o2GLT63gqwzD_Pv5eMUTS9o8rTVAlCPPZKrBv4tnfLg_CfTBnuZZTF9U1s36kH2QYnb1gmmgNCjA6EEuQxPyhV4nBF_cmw_DWUSirUDdSpNgCWXp7fpOomVZNpWuHz3gpw3gu9aH5NBk2bwd2-27Ck/s640/Picture%2059.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2q7FhITJInWeUk4OYNDyW9vVGO4daGis1ts6T_o2GLT63gqwzD_Pv5eMUTS9o8rTVAlCPPZKrBv4tnfLg_CfTBnuZZTF9U1s36kH2QYnb1gmmgNCjA6EEuQxPyhV4nBF_cmw_DWUSirUDdSpNgCWXp7fpOomVZNpWuHz3gpw3gu9aH5NBk2bwd2-27Ck/s320/Picture%2059.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqWLeN-eZG_zksc8s_euMfB0GjIZPvQQak8tzPVeJLOLDJ3HauLUYYw9CgsQfkd59Q89DuH_-J8DWVcUGVTROBtRGCkiUPVjyZaIwpB56tIxPuZqTBlSWBvN1Om-2CxCRdDSMhm8tB8Crp4gpfLLAUn8ijfRd6tbKtSHcBZN6QX14ZldaF6UFH2WJCRUA/s640/Picture%2060.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqWLeN-eZG_zksc8s_euMfB0GjIZPvQQak8tzPVeJLOLDJ3HauLUYYw9CgsQfkd59Q89DuH_-J8DWVcUGVTROBtRGCkiUPVjyZaIwpB56tIxPuZqTBlSWBvN1Om-2CxCRdDSMhm8tB8Crp4gpfLLAUn8ijfRd6tbKtSHcBZN6QX14ZldaF6UFH2WJCRUA/s320/Picture%2060.png" width="320"></a></p><p>

Interestingly, the Help menu is live, and actually brings up an Apple Guide which is dynamically populated based on what parts are present in the document. This would probably be more useful in practice if the parts were better documented, but it's another example of how OpenDoc was designed to blur the borders between document and app.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhLRBLxQeoKTNUK94hT3FLHPACMIRI0hAw8l16pPPEF6xwhs_oWQpKwPfzsiaCBRSMaLb2sfXqxEfqcIviPSJwDg3vPh9-tydRJJYHV2h2o4jKd1McCUGoCtU4vS8eUaegYNuMy3tOk7hthRH7QQ1jXI25F177YriLWAVsFQlC-7BUT7w3loIk6h9Q3dOk/s640/Picture%2050.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhLRBLxQeoKTNUK94hT3FLHPACMIRI0hAw8l16pPPEF6xwhs_oWQpKwPfzsiaCBRSMaLb2sfXqxEfqcIviPSJwDg3vPh9-tydRJJYHV2h2o4jKd1McCUGoCtU4vS8eUaegYNuMy3tOk7hthRH7QQ1jXI25F177YriLWAVsFQlC-7BUT7w3loIk6h9Q3dOk/s320/Picture%2050.png" width="320"></a></p><p>

When you click the running dog (to run), the layout grid goes away and the document becomes conventionally interactive. You can save it to disk and share it with your small number of friends who had OpenDoc, Cyberdog or something compatible and the same parts you used, which for many people was approximately zero, even in 1996.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnS7iCiT09YBZcAqOD80Z5bbxNsxcXACyzB_faqg-cbpwmBtl_NlSKn3jroSOFHIyY-A1LCZ3ex70Xno-RVzxVppN2lVlEtR4ebsP67KhUEO3-EvjRnY7XtQqjaPs_YHCN6MRSjIG9LfCJso9Tx3l0mOIlMaP72Px5xOs-hFNds7Hjtor434Wrn6xl_pY/s512/Movie-Clipping-4.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnS7iCiT09YBZcAqOD80Z5bbxNsxcXACyzB_faqg-cbpwmBtl_NlSKn3jroSOFHIyY-A1LCZ3ex70Xno-RVzxVppN2lVlEtR4ebsP67KhUEO3-EvjRnY7XtQqjaPs_YHCN6MRSjIG9LfCJso9Tx3l0mOIlMaP72Px5xOs-hFNds7Hjtor434Wrn6xl_pY/s320/Movie-Clipping-4.png" width="320"></a></p><p>

One of the demonstration videos on the CD showed off this sample document embedding a live, interactive view of many top-level Usenet newsgroup hierarchies, showing the concept was by no means limited to typical Web, Gopher or FTP sites. What exactly this had to do with Apple technical support was not explained.
</p><p>
The fact that buttons only took graphical images in Cyberdog 1.0 was a strange limitation in my view, and defeated creating traditional-looking links in Cyberdog documents. But the second example we'll look at in the Cyberdog SDK seemed to address this, called the <tt>CybTxtBtn</tt> (short for Cyberdog text button).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgaDSQH-3MQzx2EX9MPI9iExH_bOTri0adkdxbv67vW-2NsV7xZHO8zqjdIFODfLAvpb_CKhCZa6QrLh0ySFnXSAA8mL4XJCn7yYAFfr8NoS9BNZt3H59YAqQaXJ-qDD8FMzO-TuL02JsuBZox22ZwM_Lbml9wCyvZ8CQID9gclA06GlnqTSt-DH6oWDo8/s640/Picture%2041.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgaDSQH-3MQzx2EX9MPI9iExH_bOTri0adkdxbv67vW-2NsV7xZHO8zqjdIFODfLAvpb_CKhCZa6QrLh0ySFnXSAA8mL4XJCn7yYAFfr8NoS9BNZt3H59YAqQaXJ-qDD8FMzO-TuL02JsuBZox22ZwM_Lbml9wCyvZ8CQID9gclA06GlnqTSt-DH6oWDo8/s320/Picture%2041.png" width="320"></a></p><p>

This component is actually a modified example object from the OpenDoc SDK using its generic </p><tt>SamplePart</tt><p> project. I won't go through the code in great detail except to show you the finger service was not an aberration: this codebase is just as verbose.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZlR9kqW0esZHMDPmQHaji6i-SA28PjeiagUAF_trGRfzjSv9qwUcHI5YjbQINkbh8vaqfGfhNmkKGBlnPQ308H9hqVBBOTSnG-3k2I5uyePtUS6MKEli34EHe2ZS3quJCJEI6x0ml0d69sDtyhL2AvVyM_GFNFcVOXR-YPX6D4ZNqTsOcP24vylegXzk/s640/Picture%2044.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZlR9kqW0esZHMDPmQHaji6i-SA28PjeiagUAF_trGRfzjSv9qwUcHI5YjbQINkbh8vaqfGfhNmkKGBlnPQ308H9hqVBBOTSnG-3k2I5uyePtUS6MKEli34EHe2ZS3quJCJEI6x0ml0d69sDtyhL2AvVyM_GFNFcVOXR-YPX6D4ZNqTsOcP24vylegXzk/s320/Picture%2044.png" width="320"></a></p><p>

With the library built (remember to fix the project paths) and installed in the Editors folder, drop the library on the OpenDoc document shell hidden in the System Folder to emit stationery, and then put the resulting stationery in its usual place, though in practice it should work from anywhere.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiT_EpIoPKNL63zm-Ep7NzY58s8jDd9qPD6ZDZfr9BrT2la1vaUZ6PnuLfG2cpm-RhqP9wSU9O7Jj04Mpi6lqajb_xcwEPpa_n9w5KpPcqOjBUpdo6r0yBKkccW24iHtWFbAjawv7tsM6Rca3F8S4KVFwc7bUjlBf8Cysv7IwH68vJfiZUIUkW42qMO94M/s640/Picture%2055.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiT_EpIoPKNL63zm-Ep7NzY58s8jDd9qPD6ZDZfr9BrT2la1vaUZ6PnuLfG2cpm-RhqP9wSU9O7Jj04Mpi6lqajb_xcwEPpa_n9w5KpPcqOjBUpdo6r0yBKkccW24iHtWFbAjawv7tsM6Rca3F8S4KVFwc7bUjlBf8Cysv7IwH68vJfiZUIUkW42qMO94M/s320/Picture%2055.png" width="320"></a></p><p>

Now drag the stationery to the document to generate a new instance. You'll see a text URL appear, by default the Cyberdog home page. 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCMHifO9g6Msv-paIzWVv7J1YJ_PuBoCTI_-xLYk0ChXoKxZg_u0qnhS9NsbEiMfc8ynj_Qu67LF3pgi3iqOnw7y0qyqB-a-5IHigqVfHWimoU7kQiipYKmVm1A7YFZAYWqo9mN-AfgHQjDbWJC0PCiolMEDH4oq5NxBzvZ1rOe3af-5L8FR24wuMirig/s640/Picture%2056.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCMHifO9g6Msv-paIzWVv7J1YJ_PuBoCTI_-xLYk0ChXoKxZg_u0qnhS9NsbEiMfc8ynj_Qu67LF3pgi3iqOnw7y0qyqB-a-5IHigqVfHWimoU7kQiipYKmVm1A7YFZAYWqo9mN-AfgHQjDbWJC0PCiolMEDH4oq5NxBzvZ1rOe3af-5L8FR24wuMirig/s320/Picture%2056.png" width="320"></a></p><p>

It's a working link, so if you click on it, it opens the referenced page like regular buttons do. However, it can hold any item, and will display the title of the item it represents (or if no title is available, the URL). Here, we'll drop a Gopher item from a navigator window on the text button ... 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjgP_uh6xUdxJ3ETSjRB50KBruWnTk4pijvRpGfisf3FiCT6oeX2kbhTSLUjUlm6UIUvS79Ta-w7BlbK5aemb9ypFkf3WSfXc5rgq0Kb3VAvQsWUR2iSP7uoJIR4DP32OrTsOQcUmDtADvB9ZX0q4s-qG-ggnodcTV_01P26X_Mf50KZAcVIz6dhtN40bA/s640/Picture%2057.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjgP_uh6xUdxJ3ETSjRB50KBruWnTk4pijvRpGfisf3FiCT6oeX2kbhTSLUjUlm6UIUvS79Ta-w7BlbK5aemb9ypFkf3WSfXc5rgq0Kb3VAvQsWUR2iSP7uoJIR4DP32OrTsOQcUmDtADvB9ZX0q4s-qG-ggnodcTV_01P26X_Mf50KZAcVIz6dhtN40bA/s320/Picture%2057.png" width="320"></a></p><p>

... and it obligingly changes, taking its new title from the title bar of the window we dragged the item from. This part appears to be the only way you could generate such a link in a Cyberdog document with 1.0, and it never shipped with Cyberdog itself.
</p><p>
Apple did try to encourage building Cyberdog documents and shared some they found particularly noteworthy, but these documents were also stored on the Apple Cyberdog FTP server and are also believed lost. Some of Apple's "Cyberdog Dogshow" winners are <a href="http://web.archive.org/web/19961101213809/http://cyberdog.apple.com/cyberdocs.html">listed here</a>.
</p><p>
Additionally, the whole docu-centrism concept got rather muddled with <a href="http://web.archive.org/web/19961101213711/http://cyberdog.apple.com/">Cyberdog 1.1</a> in September 1996, which turned things on its head. Instead of, or at least in addition to, you opening the Starting Point document to open Cyberdog, 1.1 now had a stub app that you opened conventionally and <em>it</em> opened the Starting Point (now "Cyberdog Tour"). To make the sea change even clearer, the Document menu reverted to a standard File menu and stayed so for the rest of Cyberdog's existence, while simultaneously the explicit Quit option returned. It was all a subtle yet stinging retcon of the OpenDoc way.
</p><p>
Cyberdog 1.1 required the new OpenDoc 1.1, a speed and bugfix release that came out just before in August of that year. But a bigger change in Cyberdog 1.1, besides support for NSAPI plugins, multiple pages in Cyberdog documents, accessing resources over AppleTalk and a basic AppleScript dictionary, was compatibility with 68K Macintoshes (68030 or better). The SDK was duly updated to include support for 68K, but the 68K stub library, headers and updated examples were <a href="http://web.archive.org/web/19961101213833/http://cyberdog.apple.com/developer.html">all on the defunct Cyberdog FTP server too</a>. That means our PowerPC-only CD here is apparently the only version of the SDK that appears to still exist, and while components we build with it should work fine with later versions of PPC Cyberdog, they will never run on a 68K machine.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSlRZuBRIOXZbYDzMAxYVVG0sLeLZbq989AtBxE8IlUYJl6UD30lUFUTpmMZ0tlmooZmvD-oxmu89yFDDGOTTUjJ2VQgTNu1VHp3EtSKnuBglVR6L3ljBDYvMCY2y42bFkIh8URKwZYI0RwC5M9P1sKcGLLDWfNNlVlS5kvzGgBtqL9B0r3gNb0WJmE9k/s640/Picture%2042.png"><img alt="" data-original-height="480" data-original-width="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSlRZuBRIOXZbYDzMAxYVVG0sLeLZbq989AtBxE8IlUYJl6UD30lUFUTpmMZ0tlmooZmvD-oxmu89yFDDGOTTUjJ2VQgTNu1VHp3EtSKnuBglVR6L3ljBDYvMCY2y42bFkIh8URKwZYI0RwC5M9P1sKcGLLDWfNNlVlS5kvzGgBtqL9B0r3gNb0WJmE9k/s320/Picture%2042.png" width="320"></a></p><p>

There are two other examples on the CD which I'm simply going to mention rather than demonstrate, as they're really intended as templates and introduce no obvious new functionality. </p><tt>CybTxtViewer</tt><p> is a Cyberdog display part that displays plain text; this is not too useful as is, as Cyberdog already displays plain text just fine, and is obviously intended to be used as scaffolding for other things (via CodeSampler). The other one, </p><tt>CybTxtNavViewer</tt><p>, shows how you would embed such a part in a Cyberdog navigator, including getting status messages from the navigator and enabling saving and printing.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgH9RBEUqqDYgotF-8nLRtTg_cSUP8e9zxSbfBD-V5JxblxLPLPMa-wUjthYggDQWUE7L6hB6yvZxTAC501v_yY6LeM2Cy577FiLtm55x77fCKL3PQzINduWRLjdbFwDtIKcNvJ1KyjNVqGwetukVMmbAhVT_eK_wc0bxtOncR-3uTefYISiDoYl6GqoC8/s515/startingpoint.gif"><img alt="" data-original-height="363" data-original-width="515" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgH9RBEUqqDYgotF-8nLRtTg_cSUP8e9zxSbfBD-V5JxblxLPLPMa-wUjthYggDQWUE7L6hB6yvZxTAC501v_yY6LeM2Cy577FiLtm55x77fCKL3PQzINduWRLjdbFwDtIKcNvJ1KyjNVqGwetukVMmbAhVT_eK_wc0bxtOncR-3uTefYISiDoYl6GqoC8/s320/startingpoint.gif" width="320"></a></p><p>

Regardless of all Cyberdog 1.1's systems changes, however, the most <em>visible</em> one was a far more refined look. Gone was the dorky dog in the beta and 1.0; in came the dignified painterly hound most people who have used Cyberdog associate with the browser today. This new look coalesced around a superbly elegant new Cyberdog Tour (replacing the Starting Point) which cleverly hid the rectangular buttons by dressing them with irregular hand-drawn borders, pasted in as static graphics. There was little new functionality other than some additional buttons, but the visual effect is exquisite and easily the most artistic chrome style from that era.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhvSA5oyCqoPPZCiJmayXAbjWDfIT7x9k6ulZBSKWiOdVOcFlmDCBc-pjxq5WEsTmbT1Bly50qc1eEbok3opM65L5AF9d88aPqLBFpl9sxUkIccm0JaREHVCXU18XFZkmLnMwBaaapczcJPQD_5RMpGh07lSJ0YadIyJnU4h0lChmFGcyFZJGZycBvffE/s832/Picture%202.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhvSA5oyCqoPPZCiJmayXAbjWDfIT7x9k6ulZBSKWiOdVOcFlmDCBc-pjxq5WEsTmbT1Bly50qc1eEbok3opM65L5AF9d88aPqLBFpl9sxUkIccm0JaREHVCXU18XFZkmLnMwBaaapczcJPQD_5RMpGh07lSJ0YadIyJnU4h0lChmFGcyFZJGZycBvffE/s320/Picture%202.png" width="320"></a></p>

<p><a href="http://web.archive.org/web/19961219205419/http://cyberdog.apple.com:80/">Cyberdog 1.2</a> was released in December 1996. It was primarily a bug-fix and polish release, but also expanded its AppleScript and drag and drop capabilities, offered support for buttons with labels for the first time, and even could display transparent buttons. Cyberdog 1.2.1 fixed a few additional bugs and appeared with Mac OS 7.6 in January 1997, shown running here on my clock-chipped Quadra 800 with Mac OS 8.1. OpenDoc came as part of the Mac OS starting with 7.6, but that galling File menu in what should have been its killer </p><s>app</s><p> doc reminds you that Apple's relationship with it was  increasingly complicated.
</p><p>
The Cyberdog SDK was also updated both for 1.1 and 1.2, and new with the 1.2 SDK was <a href="http://web.archive.org/web/19970606214215/http://www.cyberdog.apple.com:80/developer.html">specific support for CodeWarrior's new Direct-To-SOM compiler</a>, which dramatically cut down the need to manually write SOM glue methods. This piece of the Cyberdog SDK is lost too.
</p><p>
In the meantime, Copland made its disastrous developer début (as the infamous "Developer Release 0") in August 1996, and mindful of its mortally flawed history, Gil Amelio hired Ellen Hancock as CTO to evaluate its future. Hancock quickly concluded Copland would never be able to ship and Amelio duly cancelled it, leaving a void to be ultimately filled by NeXT as Apple's next-generation OS. With Rhapsody's Yellow Box (i.e., Cocoa in Mac OS X) poised to become the unifying object-oriented framework Apple always wanted, there was no further need for OpenDoc at Apple — or to show it off with Cyberdog. (This realization can't be merely coincidental with Cyberdog 1.1 turning about so suddenly on 1.0's docu-centrism: it was now time to turn Cyberdog into "just another application.")
</p><p>
To that end, on April 11, 1997 <a href="http://web.archive.org/web/19980422030238/http://opendoc.apple.com/dev/faq.4.97.html">Apple said the quiet part out loud</a> and cut loose their implementation of OpenDoc. While OpenDoc would remain compatible with the Blue Box compatibility environment (and indeed remains compatible with Classic under Tiger 10.4 and earlier), it would not be part of Rhapsody. When the recently returned Steve Jobs himself <a href="https://www.youtube.com/watch?v=H8eP99neOVs">was asked</a> at WWDC'97 "what about OpenDoc?" he famously quipped, "What about it?" Although he called out Apple's faults in engineering management and acknowledged the work people in the audience had done with it and other failed Apple technologies, he refused to backtrack on OpenDoc's cancellation, telling attendees that "focusing is about saying no."

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHLneTKYqkxd92AFCdvvtQJo8WHcbd_RCVI-XPWklnzbnUr7WtpmmuxGoJ7yUq7h-TgpW2iGae_cijEJRJIqPxwuSCnInIqPnx6pnAbRtsURKcOW2VZ8u4bwg7VUGvVvrYvTR-GcjpjXN4u5HmX6SFKRDKsR0YevZESvRZaw04c03l6ZqOVQTjuiCR2g0/s832/Picture%201.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHLneTKYqkxd92AFCdvvtQJo8WHcbd_RCVI-XPWklnzbnUr7WtpmmuxGoJ7yUq7h-TgpW2iGae_cijEJRJIqPxwuSCnInIqPnx6pnAbRtsURKcOW2VZ8u4bwg7VUGvVvrYvTR-GcjpjXN4u5HmX6SFKRDKsR0YevZESvRZaw04c03l6ZqOVQTjuiCR2g0/s320/Picture%201.png" width="320"></a></p><p>

And so the last Cyberdog (really a roll-up release) was pushed out later that month, tagged as <a href="http://web.archive.org/web/19970606214015/http://www.cyberdog.apple.com:80/">final version 2.0</a>. During the alpha releases 2.0a2 had a holiday theme which sadly never made it to the release.
</p><p>
Cyberdog 2 was the first version I ever personally used, and I have it installed here on my clock-chipped Quadra 800 also running Mac OS 8.1. I've already bumped up the OpenDoc document size for the screenshots, as without it I would get terrible crashes and system errors when OpenDoc shut down while quitting Cyberdog.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjczNPRzRf7EmZyazm5Ppc_nmZwu4qe2935vkzuD9nzhRYbLBCfWfZEZ_lqcMZ_ApSFFGKpksUkTb56t5I01x2fcJ7q_jCE1kZnkAuNkrRE5UqvE9rWZeyOZ3EmN7qazRQNE_658jt1GH_QZMnU9LNrlm6Gq6k2Y4iU1Zk6t89wwKufphV-4mqpg61K4l0/s832/Picture%203.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjczNPRzRf7EmZyazm5Ppc_nmZwu4qe2935vkzuD9nzhRYbLBCfWfZEZ_lqcMZ_ApSFFGKpksUkTb56t5I01x2fcJ7q_jCE1kZnkAuNkrRE5UqvE9rWZeyOZ3EmN7qazRQNE_658jt1GH_QZMnU9LNrlm6Gq6k2Y4iU1Zk6t89wwKufphV-4mqpg61K4l0/s320/Picture%203.png" width="320"></a></p><p>

Cyberdog 2.0's main advance was a substantially improved Web browser component. It now supported frames, animated GIFs, client pulls, some extra tags and attributes and variable text encoding, was faster, and understood cookies. The mail and news support was more tunable for better performance, and the default notebook was subtly rearranged for no obvious reason compared to 1.2.1.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhEFCTh1IFqqZDQTvMr_jdnhVzM6pdjfKCyT8Bk3nYk04uqu82SOVhXe9SoGV7cXJLNU5EZBVHk-V0Hxjfr3PoUrBXclB5gfyyT-awTPg9kYPQ2f5pYmdUjnMNIZJOczzGUZgGITxA-s6kenZBfQsH8Da-18Hjl9WYj_ug46EQsDeBJnyDsdtQ9uu7db8/s832/Picture%204.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhEFCTh1IFqqZDQTvMr_jdnhVzM6pdjfKCyT8Bk3nYk04uqu82SOVhXe9SoGV7cXJLNU5EZBVHk-V0Hxjfr3PoUrBXclB5gfyyT-awTPg9kYPQ2f5pYmdUjnMNIZJOczzGUZgGITxA-s6kenZBfQsH8Da-18Hjl9WYj_ug46EQsDeBJnyDsdtQ9uu7db8/s320/Picture%204.png" width="320"></a></p><p>

Otherwise, it supported what 1.2 did: FTP, Gopher, mail/news and AppleTalk were all still first-class citizens.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3AJyglmlpBecxYZskYkJ_zqvHWtEDTTspaE_eAEfhC2xS3Rd29_s0W2B8XGJ8NDAWgY8g5tsfGV0CJpbfY65XPDM6PAosS0soz-7X__6Qh6zz6LPZzXxt6JqkCqtLZ-dmzyr_ailZ2v-H9MxBK0zGMLE99xpqCbagy83NfUsEHZ8-de2CPjJdMtY5Gmk/s832/Picture%205.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3AJyglmlpBecxYZskYkJ_zqvHWtEDTTspaE_eAEfhC2xS3Rd29_s0W2B8XGJ8NDAWgY8g5tsfGV0CJpbfY65XPDM6PAosS0soz-7X__6Qh6zz6LPZzXxt6JqkCqtLZ-dmzyr_ailZ2v-H9MxBK0zGMLE99xpqCbagy83NfUsEHZ8-de2CPjJdMtY5Gmk/s320/Picture%205.png" width="320"></a></p><p>

The interface was also virtually unchanged, but the rendering is quite quick, and noticeably faster on the 36MHz Q800 than on the 100MHz Duo 2300. Part of this was the Duo's gimped system bus and part of this is the Quadra has over double the RAM in the Duo, but any way you sliced it (especially since both these systems have the same version of OpenDoc), Cyberdog 2.0 was a lot faster than 1.x.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6UqAU0DHZ70fP5AHtwRb4CwAJF9kMiJlf8kVvhyV6R3a5VS9U-76g6alvedlhT6oRgqh5pF3DzIvyDN6yWpl6GRobMfeX-tefKqThtU4rFhwDQGvO7E3dcax3gL8yAzIPGrAN35qU8-VWge1siaVia_IspI8Q6pkjT8vorxKAQg_kAIK-2cUvBhd58Nc/s832/Picture%206.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6UqAU0DHZ70fP5AHtwRb4CwAJF9kMiJlf8kVvhyV6R3a5VS9U-76g6alvedlhT6oRgqh5pF3DzIvyDN6yWpl6GRobMfeX-tefKqThtU4rFhwDQGvO7E3dcax3gL8yAzIPGrAN35qU8-VWge1siaVia_IspI8Q6pkjT8vorxKAQg_kAIK-2cUvBhd58Nc/s320/Picture%206.png" width="320"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxxhNMP5u3zYCJASqeyOMNS5frIlNjdNiK0tYDtsDjvYw0a8TyEXH8rAbKWjm3uZR9q4bme6Lv-hglXCu-RCgBUNsZENOYdeKOWbvv-kAmNf56Z8mjV0ubMvtzJmF351NS0zMXq-Pv1dvtsYCoQrceWhje5_IJE4EGuFsGxtm0qHCO_jK7DbcNCtnsPuA/s832/Picture%207.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxxhNMP5u3zYCJASqeyOMNS5frIlNjdNiK0tYDtsDjvYw0a8TyEXH8rAbKWjm3uZR9q4bme6Lv-hglXCu-RCgBUNsZENOYdeKOWbvv-kAmNf56Z8mjV0ubMvtzJmF351NS0zMXq-Pv1dvtsYCoQrceWhje5_IJE4EGuFsGxtm0qHCO_jK7DbcNCtnsPuA/s320/Picture%207.png" width="320"></a></p><p>

You could still create documents in 2.0 with DocBuilder, but the File menu was the File menu, and there was no going back. (Focus!) Notice the page indicator, introduced back in 1.1, which could appear as (nothing), arrows or a dog-eared page. Somehow the dog-ear sounds right.
</p><p>
The swan song was OpenDoc 1.2 (1.2.1 for Mac OS 8.0), which came out in September 1997 as the last version Apple would release and what our demonstration systems have been running here. And, well, maybe there was another good reason for OpenDoc to die: it turned out users just didn't get it. Almost as a post-mortem, Apple published an August 1997 journal article on "The Role of User Studies in the Design of OpenDoc" (Dykstra-Erickson and Curbow, <a href="https://dl.acm.org/doi/10.1145/263552.263588">doi:10.1145/263552.263588</a>). Among its notable observations was that users didn't really understand the concept of stationery (in System 7 or OpenDoc), the select-versus-activate distinction was the root of many user interface problems, and inexperienced users tended to imagine tasks as less complex than they actually were.
</p><p>  
But I think the real bullet in OpenDoc's head (as Jobs put it) was the authors' discovery that the most adept users had a menu of strategies to randomly try and just ended up doing whatever worked, which is damning evidence even those skilled users didn't truly grok OpenDoc, let alone have a functioning mental model of its operation. As the authors observed, "Users figure out their own way of doing things and don’t adhere to our expectations for how they will work with OpenDoc. ... Recognizing a useful strategy and employing it <em>without</em> [emphasis theirs] a firm grasp of the underlying mental model requires the user to rethink strategies every time they are faced with a problem." When I was building the Cyberdog Humane Society in DocBuilder, it certainly took a lot of screwing around for me to get what I wanted, and some of the steps I ended up taking absolutely felt arbitrary. The authors concluded, "We have yet to determine 1) how to increase user comprehension of the model; 2) how complete the user’s mental model of OpenDoc needs to be in order to use it and feel good about it; and 3) what instrument is best to measure learnability."
</p><p>
Those problems would never be addressed, for Cyberdog 2.0 was really OpenDoc's last stand on any platform, not just the Mac. While you could still download Cyberdog for some period afterwards, Apple never released any followups or bug fixes, and OpenDoc no longer came bundled from Mac OS 8.5 on. SOM objects remained an integral part of OS/2, but the Windows and OS/2 releases of OpenDoc proper were quietly dropped by IBM as well, and thus the brief 1990s tyranny of the document came to an ignominious end. Apps, once again, were king.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiiOnGYT2Sub0KDfP3sg6InpZlXMdP31I9kSOMjviGq8LTSz3m_5ppvKcivzn_otavnsZtLh_ZNBCtHwTeeg62WNKpTPtB1oqLfSQRQEPpLWnuIdokUh4F20ntnsxP6DItYlt9S7rzQtIU5zphJ0Vzw-6C0YjD_XeM8uxfbAI7Su2VUeqYMO8-AlO6-8I/s2340/Screenshot_20230906-194901.png"><img alt="" data-original-height="2340" data-original-width="1080" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiiOnGYT2Sub0KDfP3sg6InpZlXMdP31I9kSOMjviGq8LTSz3m_5ppvKcivzn_otavnsZtLh_ZNBCtHwTeeg62WNKpTPtB1oqLfSQRQEPpLWnuIdokUh4F20ntnsxP6DItYlt9S7rzQtIU5zphJ0Vzw-6C0YjD_XeM8uxfbAI7Su2VUeqYMO8-AlO6-8I/s320/Screenshot_20230906-194901.png"></a></p><p>

Never forget. If you copied, or know where to find, the contents of the Cyberdog FTP server from any point in its prior existence, please post in the comments or E-mail me privately at ckaiser at floodgap dawt com.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why the Culture Wins: An Appreciation of Iain M. Banks (2017) (138 pts)]]></title>
            <link>https://www.sciphijournal.org/index.php/2017/11/12/why-the-culture-wins-an-appreciation-of-iain-m-banks/</link>
            <guid>37893856</guid>
            <pubDate>Sun, 15 Oct 2023 22:10:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciphijournal.org/index.php/2017/11/12/why-the-culture-wins-an-appreciation-of-iain-m-banks/">https://www.sciphijournal.org/index.php/2017/11/12/why-the-culture-wins-an-appreciation-of-iain-m-banks/</a>, See on <a href="https://news.ycombinator.com/item?id=37893856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wi-main">
<article id="wi-content" itemscope="" itemtype="https://schema.org/CreativeWork">
    
        
    
    
        
<div>
        
                
        <article itemscope="" itemtype="https://schema.org/CreativeWork">
            
            <div>
            
                    
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2017/11/05/worlds-enough/">
            
        
            <p><img width="598" height="600" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2020/04/placeholder.jpg?fit=598%2C600&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2020/04/placeholder.jpg?w=598&amp;ssl=1 598w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2020/04/placeholder.jpg?resize=480%2C482&amp;ssl=1 480w" sizes="(max-width: 598px) 100vw, 598px"><span></span>
            </p><!-- .image-element -->

            
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


                <div>

                    <p>Previous Story</p>
                    <h3 itemprop="headline">Worlds Enough</h3>

                </div><!-- .post-nav-item-body -->

                

                </div>
        
        </article><!-- .post-nav-item -->
        
                
                
        <article itemscope="" itemtype="https://schema.org/CreativeWork">
            
            <div>
            
                    
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2017/11/19/the-heinlein-hypocrisy-part-i-what-words-mean/">
            
        
            <p><img width="598" height="600" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2020/04/placeholder.jpg?fit=598%2C600&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2020/04/placeholder.jpg?w=598&amp;ssl=1 598w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2020/04/placeholder.jpg?resize=480%2C482&amp;ssl=1 480w" sizes="(max-width: 598px) 100vw, 598px"><span></span>
            </p><!-- .image-element -->

            
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


                <div>

                    <p>Next Story</p>
                    <h3 itemprop="headline">The Heinlein Hypocrisy Part I: What Words Mean</h3>

                </div><!-- .post-nav-item-body -->

                

                </div>
        
        </article><!-- .post-nav-item -->
        
            
    </div><!-- .single-navigation-section -->


<div>

            <h3 id="posts-small-heading">

                <span>Latest from Fact &amp; Opinion</span>

            </h3>

            

<div>
    
    
<article itemscope="" itemtype="https://schema.org/CreativeWork">

    <div>
        
                
            
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2023/09/28/welcome-to-the-zineverse/">
            
        
            <p><img width="1020" height="1018" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/03-zineverse.png?fit=1020%2C1018&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/03-zineverse.png?w=1920&amp;ssl=1 1920w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/03-zineverse.png?resize=1500%2C1497&amp;ssl=1 1500w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/03-zineverse.png?resize=768%2C766&amp;ssl=1 768w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/03-zineverse.png?resize=1536%2C1533&amp;ssl=1 1536w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/03-zineverse.png?resize=480%2C479&amp;ssl=1 480w" sizes="(max-width: 1020px) 100vw, 1020px"><span></span>
            </p><!-- .image-element -->

            <span></span>
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


<div>

        <p>A compact tour through the publishing landscape of English-language SF short fiction, by Mina.</p>
    
    </div><!-- .post-item-body -->


        
    </div><!-- .post-item-inner -->

</article><!-- .post-item -->
<article itemscope="" itemtype="https://schema.org/CreativeWork">

    <div>
        
                
            
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2023/09/28/science-fiction-and-the-shaping-of-belief/">
            
        
            <p><img width="1020" height="1620" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/10-milling.png?fit=1020%2C1620&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/10-milling.png?w=1209&amp;ssl=1 1209w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/10-milling.png?resize=945%2C1500&amp;ssl=1 945w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/10-milling.png?resize=768%2C1220&amp;ssl=1 768w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/10-milling.png?resize=967%2C1536&amp;ssl=1 967w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/09/10-milling.png?resize=480%2C762&amp;ssl=1 480w" sizes="(max-width: 1020px) 100vw, 1020px"><span></span>
            </p><!-- .image-element -->

            <span></span>
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


<div>

        <p>With great editorial power comes great responsibility, by Manjula Menon.</p>
    
    </div><!-- .post-item-body -->


        
    </div><!-- .post-item-inner -->

</article><!-- .post-item -->
<article itemscope="" itemtype="https://schema.org/CreativeWork">

    <div>
        
                
            
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2023/06/23/why-is-her-face-doing-that-the-personhood-of-robot-nanny/">
            
        
            <p><img width="960" height="1920" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/04-wooden-robot.png?fit=960%2C1920&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/04-wooden-robot.png?w=960&amp;ssl=1 960w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/04-wooden-robot.png?resize=750%2C1500&amp;ssl=1 750w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/04-wooden-robot.png?resize=768%2C1536&amp;ssl=1 768w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/04-wooden-robot.png?resize=480%2C960&amp;ssl=1 480w" sizes="(max-width: 960px) 100vw, 960px"><span></span>
            </p><!-- .image-element -->

            <span></span>
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


<div>

        <p>A machine-assisted family trip through uncanny valley, by Eduardo Frajman.</p>
    
    </div><!-- .post-item-body -->


        
    </div><!-- .post-item-inner -->

</article><!-- .post-item -->
<article itemscope="" itemtype="https://schema.org/CreativeWork">

    <div>
        
                
            
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2023/06/23/truth-embedded-in-a-tale-stories-of-utopia-from-philosophers-of-the-early-modern-period/">
            
        
            <p><img width="1020" height="1348" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/08-wisdom-parable.png?fit=1020%2C1348&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/08-wisdom-parable.png?w=1453&amp;ssl=1 1453w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/08-wisdom-parable.png?resize=1135%2C1500&amp;ssl=1 1135w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/08-wisdom-parable.png?resize=768%2C1015&amp;ssl=1 768w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/08-wisdom-parable.png?resize=1162%2C1536&amp;ssl=1 1162w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/08-wisdom-parable.png?resize=480%2C634&amp;ssl=1 480w" sizes="(max-width: 1020px) 100vw, 1020px"><span></span>
            </p><!-- .image-element -->

            <span></span>
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


<div>

        <p>A journey across the landscape of better worlds dreamt up in the proto-SF era, by Manjula</p>
    
    </div><!-- .post-item-body -->


        
    </div><!-- .post-item-inner -->

</article><!-- .post-item -->
<article itemscope="" itemtype="https://schema.org/CreativeWork">

    <div>
        
                
            
<figure itemscope="" itemtype="https://schema.org/ImageObject">
    
    <div>
    
                
        <a href="https://www.sciphijournal.org/index.php/2023/06/23/the-economy-of-words-differing-philosophies-of-humanism-between-western-and-muslim-science-fiction/">
            
        
            <p><img width="1020" height="1772" src="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/12-quietly-sneaking.png?fit=1020%2C1772&amp;ssl=1" alt="" decoding="async" loading="lazy" srcset="https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/12-quietly-sneaking.png?w=1105&amp;ssl=1 1105w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/12-quietly-sneaking.png?resize=863%2C1500&amp;ssl=1 863w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/12-quietly-sneaking.png?resize=768%2C1334&amp;ssl=1 768w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/12-quietly-sneaking.png?resize=884%2C1536&amp;ssl=1 884w, https://i0.wp.com/www.sciphijournal.org/wp-content/uploads/2023/06/12-quietly-sneaking.png?resize=480%2C834&amp;ssl=1 480w" sizes="(max-width: 1020px) 100vw, 1020px"><span></span>
            </p><!-- .image-element -->

            <span></span>
            
                    
        </a>
        
                
    </div><!-- .thumbnail-inner -->
    
    
</figure><!-- .fox-thumbnail -->


<div>

        <p>A comparison of narrative approaches in the oriental and occidental corpus, by Emad El-Din Aysha.</p>
    
    </div><!-- .post-item-body -->


        
    </div><!-- .post-item-inner -->

</article><!-- .post-item -->        
            
    </div><!-- .fox-blog-container -->

    
        </div><!-- .single-bottom-posts-section -->
        
</article><!-- .post -->
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft buys Activision – what happens to Infocom's text adventures now? (190 pts)]]></title>
            <link>https://blog.zarfhome.com/2023/10/microsoft-consumes-activision</link>
            <guid>37893794</guid>
            <pubDate>Sun, 15 Oct 2023 21:59:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.zarfhome.com/2023/10/microsoft-consumes-activision">https://blog.zarfhome.com/2023/10/microsoft-consumes-activision</a>, See on <a href="https://news.ycombinator.com/item?id=37893794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>The gavel has fallen; the cup has been stomped; pick your metaphor. Microsoft has succeeded in its almost-two-year quest to <a href="https://www.theverge.com/2023/10/13/23791235/microsoft-activision-blizzard-acquisition-complete-finalized">gobble up Activision</a>.</p>
<p>The peculiar side effect in my corner of the world is that Microsoft now owns the dusty remains of Infocom. Microsoft owns all the classic Infocom games (except maybe <em>Hitchhiker</em> and <em>Shogun</em>). They own the rights to <em>sell</em> the games. They own the rights to make more Zork spinoffs.</p>
<p>Of course, from a corporate point of view, this means exactly nothing. Activision has kept a few Infocom games <a href="https://www.gog.com/en/game/the_zork_anthology">up on GOG</a>. For a while they sold them for iOS, but that was too much work so they stopped. In 2009 they flirted with a <a href="https://blog.zarfhome.com/2011/05/legends-of-zork-going-squish">casual Zork tie-in</a> that went nowhere. None of this rates even a footnote in the Microsoft acquisition prospectus, which I imagine is six hundred pages of <em>Candy Crush</em> stats with an appendix mentioning <em>WoW</em> and <em>CoD</em> as "also nice to have". </p>
<p>But of course I'm interested in the Zork stuff. Let's follow the bouncing brogmoid!</p>
<!--more-->
<ul>
<li>1979: Infocom is founded. It enjoys a few years of wild stardom, followed by an inevitable downturn in the face of graphical games. (Plus the whole <em><a href="https://web.mit.edu/6.933/www/Fall2000/infocom/">Cornerstone</a></em> thing.)</li>
<li>1986: Activision acquires Infocom, saving Infocom's bacon for a couple of years.</li>
<li>1987: Activision's board replaces CEO Jim Levy, who had brought Infocom on board, with Bruce Davis.</li>
<li>1988: Davis shakes up Activision and renames it Mediagenic.</li>
<li>1989: Mediagenic/Activision shuts down Infocom as a studio. (It keeps the name alive as an adventure publishing label.)</li>
<li>1990-1991: Mediagenic is now itself sliding down the tubes.</li>
<li>1991: Bobby Kotick buys the carcass of Mediagenic. To make a quick buck, he has the <a href="https://archive.org/details/lost-treasures-of-infocom">Infocom library</a> reissued, which saves <em>his</em> bacon. Also there's <em>Return to Zork</em>.</li>
<li>1992-1993: Kotick mulches the rest of Mediagenic and reorganizes it as (effectively) a new company called Activision. </li>
<li>1996: Activision reissues the Infocom games again as the <em><a href="https://archive.org/details/Classic_Text_Adventure_Masterpieces_of_Infocom_Activision_CDD-3650-101-U3_1996">Masterpieces</a></em> CD-ROM. As a bonus, this includes the winners of the first <a href="https://ifcomp.org/comp/1995">IFComp</a>, including <em><a href="https://ifdb.org/viewgame?id=00wlim27k5d1hmf2">A Change in the Weather</a></em>. No complaints.</li>
<li>2008: Activision merges with Vivendi/Blizzard, forming "Activision Blizzard". Despite the name, if you look at the details it's really more like Vivendi acquiring Activision.</li>
<li>2016: Now it's "Activision Blizzard King".</li>
<li>2022: Microsoft gets a gleam in its eye. Microsoft does not offer to change its name to "Microsoft Activision".</li>
</ul>
<p>Depending on how you count, that's three-to-five companies which have died and passed the Infocom IP on to a successor.</p>
<p>(And the Implementors, aka the folks who wrote the Infocom games in the first place? They never had any rights to the stuff. They were on salary. All the Infocom games were "<a href="https://www.law.cornell.edu/wex/work_for_hire">works for hire</a>".)</p>
<hr>
<p>So why am I digging this up? Aside from "history is interesting", which it is.</p>
<p>Microsoft-the-company does not care about Infocom. But a lot of people <em>in</em> Microsoft must care. Microsoft is heavily populated by greying GenX nerds just like me. Folks who grew up with the first home computers and fondly remember the games of the early 1980s.</p>
<p>To those nerds, I direct this request:</p>
<p>It is time to do right by the memory of Infocom. It is time to let it go.</p>
<p>For twenty years, Infocom properties have existed in a foggy hinterland of "Well, Activision <em>owns</em> it, but... you know. You can find the stuff online." I don't just mean the <a href="https://eblong.com/infocom/">games</a>! It's also the <a href="http://infodoc.plover.net/">manuals</a>, the <a href="https://www.mocagh.org/loadpage.php?getgame=header-infocom">advertisements</a>, the <a href="https://gallery.guetech.org/">packaging</a>, all the ephemera. It's all available, but... you know. Illegally.</p>
<p>This represents an enormous success of videogame history preservation -- except when you look at those links, they're <em>all</em> individual hobbyists who just collect stuff. (Spoiler: one of them is me.) The lucky ones maybe got an Activision guy to say "Sure, you have permission to do that" back in the mid-90s. Everyone else is just skating by on legal obscurity.</p>
<p>Now, Activision has never hassled fans over this stuff. Fans have been circumspect and mostly not tried to distribute the games in playable form. It's peaceable. But it's not <em>legal</em>, which makes life hard for real-world libraries and universities.</p>
<p>The top-hatted elephant in the room is of course Jason Scott, who scanned an <em>enormous</em> amount of <a href="https://archive.org/details/infocomcabinet">Infocom trivia</a> from Steve Meretzky's personal collection. The scans went up on the <a href="https://archive.org/details/infocomcabinet">Internet Archive</a>. (Meretzky later donated his physical collection to Stanford.) A few years later, Jason said "the heck with it" and also posted <a href="https://github.com/historicalsource/">all the Infocom source code</a>, or as much of it as has been preserved by fans, anyway.</p>
<p>(Ironically, that source code dump went up on Github, which is <em>also</em> a Microsoft acquisition...)</p>
<p>Anyhow. I say it is time to end this liminality and bring all this work into the legal daylight. I see two paths.</p>
<ul>
<li>
<p>Microsoft could place all of the Infocom intellectual property under a <a href="https://creativecommons.org/">Creative Commons</a> license. Again, <em>not just the games</em>. This needs to include <em>all</em> of Infocom's material: source code, manuals, maps, packaging, advertisements, newsletters. Everything that people have scanned over the years, or could scan in the future.</p>
</li>
<li>
<p>Or, bolder: Microsoft could donate the Infocom copyrights to a worthy nonprofit. Naturally I put forth the <a href="https://iftechfoundation.org/">Interactive Fiction Technology Foundation</a>! But, really, there's options. I already mentioned the <a href="https://archive.org/">Internet Archive</a>. The <a href="https://gamehistory.org/">Video Game History Foundation</a> does sterling work. I'm sure you can name more.</p>
</li>
</ul>
<p>For what it's worth, if <a href="https://iftechfoundation.org/">IFTF</a> becomes the guardian of any Infocom or other historic IF material, our first order of business to discuss would be a Creative Commons release.</p>
<p>Just to be clear, I'm talking about copyrights and other <em>information</em> rights: publication, scanning. The rights of students to play games for classes. The right to make sequels and fan works.</p>
<p><em>Physical artifacts</em> from the Infocom era are a whole 'nother story. I have no idea if any such objects still exist in Activision's basement. If they do, they should be handled by a university or a museum. (See above re Meretzky's stuff at Stanford. The <a href="https://mitmuseum.mit.edu/collections/search-results?query=infocom">MIT Museum</a> has material donated by Dave Lebling and Mike Dornbrook.)</p>
<p>Right. That's my proposal. If you happen to work at Microsoft Activision Blizzard Github King, maybe pass it around a little? See if the higher-ups are amenable. My lines are open, personally or through <a href="https://iftechfoundation.org/">IFTF</a>.</p>
<p>Thanks!</p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPL-3.0 licensed BIOS for Intel 8088 based computers (171 pts)]]></title>
            <link>https://github.com/skiselev/8088_bios</link>
            <guid>37893555</guid>
            <pubDate>Sun, 15 Oct 2023 21:30:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/skiselev/8088_bios">https://github.com/skiselev/8088_bios</a>, See on <a href="https://news.ycombinator.com/item?id=37893555">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-view-component="true">        
        
        <div>
  



<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>



  <p>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/skiselev/8088_bios/branches">
          
          <strong>4</strong>
          <span>branches</span>
    </a>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/skiselev/8088_bios/tags">
      
        <strong>13</strong>
        <span>tags</span>
    </a>
  </p>

  

  <include-fragment src="/skiselev/8088_bios/overview_actions/master"></include-fragment>


    <p><span>
        
<get-repo>
  <details data-action="
              toggle:get-repo#onDetailsToggle
              keydown:get-repo#onDetailsKeydown">
      <summary data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;repository_id&quot;:103484871,&quot;target&quot;:&quot;CLONE_OR_DOWNLOAD_BUTTON&quot;,&quot;originating_url&quot;:&quot;https://github.com/skiselev/8088_bios&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0db4052ce872213638a2fabb4f4564862d3446c587bffef95daf7db5afd6d0a3" data-view-component="true">    <span>
      <span>Code</span>
    </span>
      <span>
        
      </span>
</summary>  
    <div data-target="get-repo.modal">
    <tab-container data-view-component="true">
      <div id="local-panel" role="tabpanel" tabindex="0" aria-labelledby="local-tab" data-view-component="true">          <ul>
              <li>
  <a href="https://docs.github.com/articles/which-remote-url-should-i-use" rel="noopener" target="_blank" aria-label="Which remote URL should I use?">
  
</a>



<tab-container>

  

  <div role="tabpanel">
    

    <p>
        Use Git or checkout with SVN using the web URL.
    </p>
  </div>


  
</tab-container>

</li>
<li data-platforms="windows,mac">
  <a data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;OPEN_IN_DESKTOP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:103484871,&quot;originating_url&quot;:&quot;https://github.com/skiselev/8088_bios&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="59eb278e5213a92b484885bc80b669ff39d63ae547931de203cf2a7395768ad6" data-action="click:get-repo#showDownloadMessage" href="https://desktop.github.com/">
    
    Open with GitHub Desktop
</a></li>
<li>
  <a rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;DOWNLOAD_ZIP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:103484871,&quot;originating_url&quot;:&quot;https://github.com/skiselev/8088_bios&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="9acbec055fab0ab94245a25f1a95191061778fa9833c027b9779d2256f6cbf78" data-ga-click="Repository, download zip, location:repo overview" data-open-app="link" data-turbo="false" href="https://github.com/skiselev/8088_bios/archive/refs/heads/master.zip">
    
    Download ZIP
</a></li>

          </ul>
</div>
    
</tab-container>    
</div>
  </details>
</get-repo>

    </span>

    <span>
      

    </span>
</p></div>




        


<div>
  <div>
    <h2>Latest commit</h2>
    <div data-issue-and-pr-hovercards-enabled="">
      
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/skiselev/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/skiselev">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/11326662?s=48&amp;v=4" width="24" height="24" alt="@skiselev">
</a>  </p>
</div>
  
  <div>
      
      <pre>Signed-off-by: Sergey Kiselev &lt;skiselev@gmail.com&gt;</pre>
    <p><code>dfff4fd</code>
    </p>
  </div>
      
    </div>
  </div>
    <h2 id="files">Files</h2>
    


      <p><a data-hotkey="y" href="https://github.com/skiselev/8088_bios/tree/dfff4fddc8ea73c8ac27435238449fb09b9ef252">Permalink</a></p><div data-view-component="true">
  <p>
    Failed to load latest commit information.


  
</p></div>  <div role="grid" aria-labelledby="files" data-hpc="">
        <p>Type</p>
        <p>Name</p>
        <p>Latest commit message</p>
        <p>Commit time</p>
      </div>




</div>

  
      <readme-toc>

      <div data-target="readme-toc.content" id="readme" data-tagsearch-path="README.md" data-tagsearch-lang="Markdown">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-8088-bios" dir="auto"><a href="#8088-bios">8088 BIOS</a></h2>
<p dir="auto">Open source BIOS for <a href="https://github.com/skiselev/micro_8088">Micro 8088</a>, <a href="https://www.vogonswiki.com/index.php/NuXT" rel="nofollow">NuXT</a> (<a href="https://github.com/monotech/NuXT">Git repo</a>),
and <a href="http://www.malinov.com/Home/sergeys-projects/xi-8088" rel="nofollow">Xi 8088</a> systems</p>
<h2 tabindex="-1" id="user-content-acknowledgements" dir="auto"><a href="#acknowledgements">Acknowledgements</a></h2>
<p dir="auto">Following folks contributed to this project. Thank you!</p>
<ul dir="auto">
<li><a href="https://github.com/640-KB">640-KB</a>
<ul dir="auto">
<li>XT-related fixes</li>
<li>Delay implementation using the 8253 PIT</li>
</ul>
</li>
<li><a href="https://github.com/spark2k06">Aitor Gómez</a>
<ul dir="auto">
<li>RTC add-on board support</li>
<li>CPU clock frequency configuration setting</li>
</ul>
</li>
<li><a href="https://github.com/horkthane">horkthane</a>
<ul dir="auto">
<li>Keyboard code fixes</li>
<li>VGA/EGA initialization fixes</li>
</ul>
</li>
<li><a href="https://github.com/0cjs">Curt J. Sampson</a>
<ul dir="auto">
<li>Documentation enhancements</li>
</ul>
</li>
<li><a href="https://github.com/zhmu">Rink</a>
<ul dir="auto">
<li>Video code update that improves compatibility with FreeDOS utilties</li>
</ul>
</li>
<li>Multiple other individuals that helped this project by testing the code, submitting bug reports, and contributing their ideas for improvements</li>
</ul>
<h2 tabindex="-1" id="user-content-bios-images" dir="auto"><a href="#bios-images">BIOS Images</a></h2>
<table>
<thead>
<tr>
<th>File name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-micro8088.bin">bios-micro8088.bin</a></td>
<td>BIOS image for Micro 8088 Version 1.1 to use with xiflash utility</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-micro8088-noide.rom">bios-micro8088-noide.rom</a></td>
<td>BIOS image for Micro 8088 Version 1.1</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-micro8088-xtide.rom">bios-micro8088-xtide.rom</a></td>
<td>BIOS image for Micro 8088 Version 1.1 with XT-IDE</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-xi8088.bin">bios-xi8088.bin</a></td>
<td>BIOS image for Xi 8088 Version 2.0 to use with xiflash utility</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-xi8088-noide.rom">bios-xi8088-noide.rom</a></td>
<td>BIOS image for Xi 8088 Version 2.0</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-xi8088-xtide.rom">bios-xi8088-xtide.rom</a></td>
<td>BIOS image for Xi 8088 Version 2.0 with XT-IDE</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-sergey-xt-noide.rom">bios-sergey-xt-noide.rom</a></td>
<td>BIOS image for Sergey's XT Version 1.0</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-sergey-xt-xtide.rom">bios-sergey-xt-xtide.rom</a></td>
<td>BIOS image for Sergey's XT Version 1.0 with XT-IDE</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-book8088-xtide.rom">bios-book8088-xtide.rom</a></td>
<td>BIOS image for Book8088 with XT-IDE</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-book8088-xtide-v20.rom">bios-book8088-xtide-v20.rom</a></td>
<td>BIOS image for Book8088 with XT-IDE optimized for NEC V20</td>
</tr>
<tr>
<td><a href="https://github.com/skiselev/8088_bios/blob/master/binaries/bios-xt.bin">bios-xt.bin</a></td>
<td>BIOS image for IBM XT (not tested, 16 KiB ROM)</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" id="user-content-build-instructions" dir="auto"><a href="#build-instructions">Build Instructions</a></h2>
<ul dir="auto">
<li><a href="https://github.com/skiselev/8088_bios/blob/master/Build_Instructions-Linux.md">Linux Build Instructions</a></li>
<li><a href="https://github.com/skiselev/8088_bios/blob/master/Build_Instructions-Windows.md">Windows Build Instructions</a></li>
</ul>
<h2 tabindex="-1" id="user-content-release-notes" dir="auto"><a href="#release-notes">Release Notes</a></h2>
<h3 tabindex="-1" id="user-content-changes" dir="auto"><a href="#changes">Changes</a></h3>
<ul dir="auto">
<li>
<p dir="auto">Version 1.0.0</p>
<ul dir="auto">
<li>Add support for Book8088</li>
<li>Use PIT for delays on XT-compatible systems</li>
<li>Implement several fixes for IBM XT</li>
<li>Update XT-IDE Extension BIOS to r625</li>
<li>Use CMake and build ROM images for all supported machines and configurations</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.9</p>
<ul dir="auto">
<li>Port floppy BIOS from <a href="https://github.com/skiselev/floppy_bios">Multi-Floppy BIOS extension</a></li>
<li>Add chipset detection for Faraday FE2010A and Proton PT8010AF chipsets. Disable memory refresh on these chipsets</li>
<li>Add a setup option for configuring wait states for Faraday FE2010A and Proton PT8010AF chipsets</li>
<li>Add a setup configuration option to disable power-on memory test. Disabling the memory test speeds up the boot process</li>
<li>Add support for SST39SF020A and SST39SF040 Flash ROMs. Note that unused address lines on these chips need to be connected to the ground</li>
<li>Update XT-IDE BIOS ROM Extension to r624. Add corresponding xtidecfg.com utility. The XT-IDE BIOS ROM image provided with 8088 BIOS is configured for XT-CF-Lite at port 0x320. Use the xtidecfg.com utility to reconfigure that if needed prior to building the BIOS</li>
<li>Fix keyboard scan codes for several key combinations: Ctrl-b, Ctrl-v, Ctrl-q, Alt-q, Ctrl-+</li>
<li>Fix an issue with BIOS resetting equipment list after VGA BIOS extension initialization, which resulted in a missing or incorrect video output then VGA is connected to a monochrome display</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.8</p>
<ul dir="auto">
<li>Merge Micro 8088 and Xi 8088 to master branch (use same code base)</li>
<li>Implement BIOS setup option for F0000-F7FFF area extension ROM scan</li>
<li>Fix FDC data rate setting on systems with 360KB/720KB drives</li>
<li>Update the number of floppies in equipment_word when saving configuration</li>
<li>Revise POST codes. Display POST code prior to an action, such as device test or subsystem initialization</li>
<li>Micro 8088: RTC autodetect fixes</li>
<li>Micro 8088: Fix floppy drives configuration</li>
<li>Xi 8088: AT / PS/2 keyboard controller initialization code improved</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.7</p>
<ul dir="auto">
<li>Micro 8088: Implement RTC support and autodetect (based on the code contributed by Aitor Gomez)</li>
<li>Micro 8088: Implement setting 40x25 CGA mode using DIP switches</li>
<li>Xi 8088: Implement CPU clock frequency configuration in the BIOS setup</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.6</p>
<ul dir="auto">
<li>Micro 8088: Implement CPU clock frequency configuration in the BIOS setup utility (contributed by Aitor Gomez)</li>
<li>Fix the issue where BIOS would activate RTS when sending a character</li>
<li>Fix the issue with 24 hours clock rollover</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.5</p>
<ul dir="auto">
<li>Micro 8088: Fix reading serial port status</li>
<li>Micro 8088: Implement checksum for the Flash ROM configuration space</li>
<li>Fix booting without XTIDE Universal BIOS</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.4</p>
<ul dir="auto">
<li>Micro 8088: Implement BIOS setup utility including saving configuration to the BIOS Flash ROM</li>
<li>Improve build configurability</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.3</p>
<ul dir="auto">
<li>Implement turbo mode switching using keyboard on Micro 8088</li>
<li>Fix the issue where the number of serial and printer ports was not updated in the equipment word</li>
<li>Update XT keyboard reset and buffer flush code</li>
<li>Fix the issue where the BIOS would hang when one of the Lock keys is pressed</li>
<li>Increase I/O delay in RTC code to solve 'FF' displayed in the year issue</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.2</p>
<ul dir="auto">
<li>Update configuration mechanism to enable support of multiple target platforms</li>
<li>Add initial support for Micro 8088 board using Faraday FE2010A chipset</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.9.0</p>
<ul dir="auto">
<li>No updates except of BIOS date and version</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.8.2</p>
<ul dir="auto">
<li>Fix keypad '*' interpreted as print screen</li>
<li>Output '00' POST code to Port 80h when booting OS</li>
<li>Use OKI-designed 80C88 and Harris-designed 80C88 instead older/newer 80C88</li>
<li>Add date and time setup to RTC setup utility</li>
<li>NVRAM setup utility - print help only if requested</li>
<li>Minor bug fixes and readability improvements in floppy code</li>
<li>Fix compilation errors with AT_COMPAT and PS2_MOUSE disabled</li>
</ul>
</li>
<li>
<p dir="auto">Changes - Version 0.8.1</p>
<ul dir="auto">
<li>Fix BIOS extension ROM scan procedure. Previously in some cases it was failing to initialize more than one BIOS extension ROM.</li>
</ul>
</li>
<li>
<p dir="auto">Changes - Version 0.8</p>
<ul dir="auto">
<li>Add serial port (INT 14h) support</li>
<li>Add printer (INT 17h) support</li>
<li>Add print screen (INT 5) support</li>
<li>Print BIOS extension ROM addresses on ROM initialization</li>
<li>Add more POST checkpoints, update POST codes</li>
<li>Rename Sergey's XT references to Xi 8088</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.7e</p>
<ul dir="auto">
<li>Set DS to the BIOS data segment after calling extension ROM initialization routines. Fixes the bug where POST would stuck following initialization of an extension ROM that doesn't preserve DS. (Reported by Bill Lewis)</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.7d</p>
<ul dir="auto">
<li>Extension ROM scan
<ul dir="auto">
<li>Include 0F0000h - 0F7FFFh area in scan, so that extensions can be added to the system's flash.</li>
</ul>
</li>
<li>POST
<ul dir="auto">
<li>Reset IOCHK trigger, disable turbo mode</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.7c</p>
<ul dir="auto">
<li>IPL
<ul dir="auto">
<li>Fix boot sector signature address</li>
<li>Fix error when booting from floppy (call INT 13h AH=08h before boot)</li>
</ul>
</li>
<li>POST
<ul dir="auto">
<li>Add DMA initialization</li>
<li>Skip memory test if ESC pressed</li>
<li>Skip memory test on warm reboot</li>
</ul>
</li>
<li>Keyboard / INT 09h
<ul dir="auto">
<li>Add support for Ctrl-Break</li>
<li>Add support for Pause</li>
</ul>
</li>
<li>Video / INT 10h
<ul dir="auto">
<li>Functions 06h and 07h: Improve scrolling implementation</li>
<li>Function 00h: Fix bug with clearing display in graphics modes</li>
<li>Use free font for graphics modes</li>
<li>Add graphics font for characters 80h-0FFh</li>
</ul>
</li>
<li>Floppy / INT 13h:
<ul dir="auto">
<li>Use 2.88M settings for the default disk parameter table. Previosly 160K settings were used and BIOS was failing to boot from disks with more than 8 sectors per track.</li>
<li>More clean and effective fdc_get_result implementation, fdc_wait_input removed as it no longer needed</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">Version 0.7b</p>
<ul dir="auto">
<li>Initial public release</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" id="user-content-todo" dir="auto"><a href="#todo">TODO</a></h2>
<ul dir="auto">
<li><strong>(high)</strong> Add technical documentation</li>
<li><strong>(med)</strong> Finalize extended keyboard support - full extended keyboard support</li>
<li><strong>(med)</strong> Beep if no video, install dummy handler</li>
<li><strong>(low)</strong> Xi 8088: Debug mouse issue with Intel 8242</li>
<li><strong>(low)</strong> Xi 8088: Debug issues with Microsoft and Logitech mouse drivers</li>
<li><strong>(low)</strong> Keyboard - sound on buffer overflow</li>
<li><strong>(low)</strong> More tests - RTC, memory, DMA</li>
<li><strong>(low)</strong> Init display before keyboard, so KBD errors can be displayed. Alternatively store non-fatal errors and display them after display is initialized</li>
<li><strong>(low)</strong> Check possibility of using same EBDA for XT-IDE BIOS and system BIOS PS/2 mouse functions</li>
<li><strong>(low)</strong> BIOS checksum</li>
<li><strong>(enh)</strong> Add PnP extension</li>
</ul>
<h2 tabindex="-1" id="user-content-switches-and-jumpers-settings---xi-8088" dir="auto"><a href="#switches-and-jumpers-settings---xi-8088">Switches and jumpers settings - Xi 8088</a></h2>
<ul dir="auto">
<li>SW2-8: Display adapter type:
<ul dir="auto">
<li>Off = CGA</li>
<li>On = MDA or Hercules</li>
<li>Ignored if Video BIOS is present (EGA / VGA cards)</li>
</ul>
</li>
</ul>
</article>
          </div>

  </readme-toc>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yes, You Can Use Lightguns on LCDs– Sometimes (131 pts)]]></title>
            <link>https://nicole.express/2023/bang-bang-youre-dead.html</link>
            <guid>37893291</guid>
            <pubDate>Sun, 15 Oct 2023 20:52:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicole.express/2023/bang-bang-youre-dead.html">https://nicole.express/2023/bang-bang-youre-dead.html</a>, See on <a href="https://news.ycombinator.com/item?id=37893291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Old-school cathode ray tube TVs have become <em>de rigeur</em> in the retro scene as the <em>true</em> way to experience retro games “the way they were designed”. But there’s a lot of benefits to modern TVs; they’re lighter, usually bigger, and there are a lot of upscalers that give really good pictures. But then you give up peripherals like light guns, that are permanently tied to the television’s timing. Or <em>are</em> they?</p>

<h2 id="the-humble-lightgun">The humble lightgun</h2>

<p>For the purposes of this blog post, let’s set out some ground rules.</p>

<ul>
  <li>When I say “lightgun”, I mean the guns that were shipped for the Famicom and the Nintendo Entertainment System. Different guns worked different ways.</li>
  <li>When I say “LCDs”, I pretty much mean all modern television screens. In fact, even the short-lived generation of HD widescreen CRT TVs share this problem.</li>
</ul>

<p>But what problem? Well, I’m getting ahead of myself.</p>

<p><img src="https://nicole.express/assets/img/gunz/zapper.jpg" title="Not to be confused with the ?ZAPer, who is just some guy who cheats in ZZT" alt="THE INCREDIBLY ACCURATE LIGHT SENSING VIDEO GUN."></p>

<p>The Zapper was the western packaging of the Famicom Gun. Either way they work the same inside, just one looks like a raygun and is fondly remembered, and one looks like a realistic gun and doesn’t seem to have been nearly as popular. Make your own cultural assumptions.</p>

<p><img src="https://nicole.express/assets/img/blast/gun.JPEG" title="plastic guns for a plastic world" alt="The Famicom Gun, much more realistic looking"></p>

<p>This is one case where Nintendo drew on their history. They had actually been making light gun games since 1973’s Laser Clay Shooting System and toys before that. The exact details of each system they’ve used varied a bit, but the basic concept doesn’t differ too much.</p>

<p>The Zapper gun consists of a trigger and a photodiode, basically a simple light sensor. When the trigger is pulled (on the NES and Famicom, this is a falling edge from 5V to 0V), the game reads the signals from the photodiode to determine what happened. (Interestingly, on the NES and Famicom, the Zapper trigger and photodiode have their own pins, and aren’t read serially like the controller is)</p>

<p>The thing to stress is, the photodiode is literally one bit of information. All the game can figure out from that is whether there’s light going into it at any particular time.</p>

<p>Let’s use a concrete example– <em>Hogan’s Alley</em>.</p>

<p><img src="https://nicole.express/assets/img/gunz/title.png" title="no YOUR framemeister is too bright" alt="Hogan's Alley title screen"></p>

<p>Game mode “A” is a simple shooting gallery. You are given three figures, and have to make a split-second decision which of the three you should shoot.</p>

<p><img src="https://nicole.express/assets/img/gunz/trio.png" title="basically 'profiling the game'" alt="Hogan's Alley gameplay, showing the three figures"></p>



<p>So there’s your problem. The photodiode gives you one bit of information; that’s not nearly enough to distinguish the three characters. After all, they all use similarly colored pixels, not that the photodiode even has color information.</p>

<p>Well, you might already know the answer. The photodiode only provides one bit… <em>at a time</em>. By setting a clever number of frames, you can extract more information.</p>

<p><img src="https://nicole.express/assets/img/gunz/violence.gif" title="Look just don't shoot people it's rude" alt="Hogan's Alley, showing the three figures, and then alternating through each white frame described below"></p>

<p>First, a black frame. This helps prevent cheating; at this point, it knows that your gun is pointed at a TV which is turned off. Then, a succession of frames that are mostly black, with white targets. Each one corresponds to one of the figures on screen. Since this all happened so fast, your gun is still pointing at the same place it was when you pulled the trigger.</p>

<p>Why does it only check two? It thinks it figured out who I shot. And there’s the problem; I was pointing the gun at an LCD TV; a small widescreen monitor I keep next to my desktop alongside a CRT as a test setup.</p>

<p>The problem is, a CRT TV draws frames in real time. The Nintendo knows that when it draws a frame, that frame drawing is corresponding with the moving electron beam of the television in real time. In fact, <a href="https://www.nesdev.org/wiki/Zapper">NESdev</a> claims that the photodiodes use have their signal die in as short as 10 scanlines, so the game needs to check more frequently than the 60Hz clock that usually governs an NES game.</p>

<p>What the Famicom <em>doesn’t</em> expect is that the screen could be <em>late</em>.</p>

<h3 id="resolutions-and-frequencies">Resolutions and frequencies</h3>

<p>Pretty much all analog video signals, RGB or otherwise, are imitating the raster of a television. That is to say, it assumes there is only a dot being drawn on screen at a time, and it provides signals that are timed as that dot moves across the screen.</p>

<p><img src="https://nicole.express/assets/img/inter&amp;lace/progressive-scan.png" title="i wrote a blog post on interlacing we're not talking about it today" alt="Successive lines being scanned on a television"></p>

<p>This works perfectly fine for a CRT television that’s tuned to expect a line frequency of 15kHz and field rate of 60Hz, like most standard-definition televisions in Japan or here in North America. However, this assumption breaks down very fast. Those 60Hz monitors almost certainly can’t even handle PAL video, with the same line frequency. For example, here’s a 60Hz Monitor /// failing to handle <a href="https://nicole.express/2021/pal-in-the-usa.html">a 50Hz signal</a> coming out of an SC-3000.</p>

<p><img src="https://nicole.express/assets/img/pal/monitor3.jpg" title="the long-lasting phosphor isn't helping; and might stymie a light gun too, actually" alt="The Monitor III with an NTSC raster failing miserably to display PAL video"></p>

<p>The same issue applies to VGA CRTs and HD CRT televisions, whose native line frequencies are much higher. Non-CRT televisions don’t even draw the screen in the same way! And oftentimes even a digital input signal won’t be at the same resolution as the panel in the screen.</p>

<p>So every single modern TV has a scaler inside. These can be particularly bad at handling 240p, but pretty much every signal that comes into a television will need some processing to match how it works inside.</p>

<p>And that’s why your lightgun won’t work on an LCD television. By the time the screen shows the white frames, the game already thinks you lost and went out to do something else. This is true even the Framemeister scaler I’m using here; as its very name implies, it’s a frame-buffer, so before even the TV has seen the signal it’s a frame behind.</p>

<p>Note that even “Game Modes” can’t get the lag down to the zero it needs to be here. The signal just isn’t suitable for your television. It <em>must</em> be processed.</p>

<h2 id="so-thats-it">So… that’s it?</h2>

<p>Obviously not, didn’t you read the title of the post? You can still play <em>Wild Gunman</em>! The GAME A mode, anyways. It turns out this doesn’t actually go through the dance above; there’s only one thing on screen. It just checks your timing. But be warned; you can still lose!</p>

<p><img src="https://nicole.express/assets/img/gunz/gunman.jpg" title="bang" alt="Wild Gunman loss screen"></p>

<p>But what if you want to play a <del>better</del> different lightgun game? Even the other game modes on <em>Wild Gunman</em> won’t work like this.</p>

<p>Here’s the clever thing. While your television is definitely displaying the screen late, if it’s a decent scaler, the lag is going to be constant. If it’s constant, it can be predicted. If it can be predicted, the game can be reprogrammed to wait that long.</p>

<p>Now, you might say, that seems like a lot of work! And it is. But thankfully, I don’t have to do it– the folks at <a href="http://neslcdmod.com/">LCDMOD</a> already have. Unfortunately, this is a pretty considerable mod, so patches are mostly limited to the earlier titles.</p>

<p><img src="https://nicole.express/assets/img/gunz/allee.jpg" title="look I like Hogan's Alley okay" alt="Hogan's Alley gameplay, showing the three figures"></p>

<h3 id="tools-of-the-trade">Tools of the trade</h3>

<p>It’s worth noting that Nintendo, which had been making light toys for awhile, was already wise to ways people cheated. One way they got around that was to use a photodiode that was most sensitive to the 15kHz light of a CRT television electron beam. That way, in addition to the black frame check above, it wouldn’t work to just point the gun at a lightbulb or other light source.</p>

<p><img src="https://nicole.express/assets/img/gunz/tomy.jpg" title="honestly the black plastic is a pretty nice look" alt="A Tomee light gun. It has no visible branding, and is made of orange and black plastic"></p>

<p>Of course, an LCD TV doesn’t put off a 15kHz light. Thankfully, the solution to this is pretty simple. Just use a third-party light gun– <em>Duck Hunt</em> is legendary enough that they still make these things. You don’t need to buy <a href="https://hyperkinstore.com/hyper-blaster-hd-hyperkin/">Hyperkin’s</a> model; I used a “Tomee” branded one and it also had a compatible photodiode. In this case being cheap is better.</p>



<p>Note that I’m not sure if these modern guns are made for the Famicom, where, as I noted, the light gun seems to have been a lot less popular. (<em>Gumshoe</em>, a first-party Nintendo light-gun game, was only released in the west; a rare case of Nintendo ignoring its own home market.) Personally, I’m using an <a href="https://misteraddons.com/products/nes-controllers-to-famicom-console-adapter">adapter</a> from MiSTer Addons; make sure to use the controller 2 position. (Also not sponsored)</p>

<p>And, well, that’s it. Well, you need a way to play modded ROMs on your console, too, and dump the original ROMs so you can patch them. But I’m assuming most people who read this blog can figure that out?</p>

<h3 id="it-just-works">It just works?</h3>

<p>Yep! At least it did for me.</p>

<p><img src="https://nicole.express/assets/img/gunz/time.jpg" title="that time was also wrong" alt="Hogan's Alley title screen with a delay time in the top of the screen"></p>

<p>Note that generally, the title screens of the supported games have been modded to add a system to detect when the gun is pressed, and figure out the particular lag time for your particular TV; after all, this can vary considerably from television to television. (The 0.0 earlier was from when I ran it on a CRT)</p>

<p>All of these screenshots were taken from my composite-modded (and <a href="https://nicole.express/2022/what-does-the-nes-say.html">stereo-modded</a>) Famicom connected through the RGB Blaster through the Framemeister, but my actual goal was to use the <a href="https://nicole.express/2019/battle-of-the-neslikes.html">RetroUSB AVS</a>, which forms part of my living room setup. Its slightly-different framerate didn’t matter at all, thankfully.</p>

<h2 id="can-sega-do-what-nintendoes">Can Sega do what Nintendoes?</h2>

<p>Now, you might wonder, does this apply to the Sega Light Phaser as well? After all, the <a href="https://nicole.express/2021/i-am-the-mark-iii.html">Master System</a> had a great many games using this light gun, generally reported to be more advanced and more accurate than the Nintendo counterpart.</p>

<p><img src="https://nicole.express/assets/img/gunz/phased.jpg" title="Sensitive. Caring. Even loving. Our researchers say that the Sega Light Phaser is the most affectionate peripheral we've made yet." alt="The back of the box of the Sega Light Phaser, which calls it 'Sensitive' and 'Super accurate'"></p>

<p>Well, uh, I don’t have a Light Phaser. But I’m pretty sure that it won’t work. Now, the light phaser is a photodiode and a trigger, much like the NES Zapper, Famicom Gun, or its clones. The big difference is the sensitivity of the photodiode– essentially, while the Zapper’s takes 10-25 scanlines to go from “on” to “off” after it stops seeing light, the Light Phaser is fast enough that, from the perspective of the 3.5MHz Z80, more or less instant. If the photodiode is on, the Phaser sees light. If it’s not, then it doesn’t.</p>

<p><img src="https://nicole.express/assets/img/gunz/gangz.jpg" title="named for Clarence W. Gangster, I assume" alt="Gangster Town title screen"></p>

<p>Here’s <em>Gangster Town</em>. Now as I said, I don’t have a light phaser. But here’s something interesting about the light phaser: it doesn’t use extra pins. The trigger of the light phaser is also button 1 on the joypad. So even though I can’t successfully shoot something, I can see what the game does when it <em>tries</em> to detect if I shot something.</p>



<p>The game starts with a feature that I have to assume Sega added mostly to show off how accurate the phaser is; you write in your name by using the phaser to shoot the letters. This would take a lot of frames to check every single letter if this worked the same way as the Zapper.</p>

<p><img src="https://nicole.express/assets/img/gunz/grid.gif" title="re-read the box text above, it warned you" alt="A grid of letters to input your name, alternating with a plain white frame"></p>

<p>The Light Phaser doesn’t draw any boxes; it just turns the screen entirely white for several frames. This is made possible by two things. First, that faster photodiode. But also, the Sega Master System has some features the NES doesn’t: horizontal and vertical counters.</p>

<p>A Master System game can read two IO registers to determine exactly what horizontal pixel (HCounter) and what scanline (VCounter) is being drawn. Even better, because horizontal beam timing is hard (ask any <a href="https://nicole.express/2023/have-you-read-atari-today.html">Atari 2600</a> programmer), it latches the HCounter. While the photodiode is active, the HCounter won’t change, so it will appear “stuck” at the value of the first horizontal position where the gun saw the screen. Vertical timing is more forgiving, so no latch is needed.</p>

<p>Of course, the gun will be pointing (the photodiode will “see”) an area on the screen larger than one pixel, so some processing of these signals is necessary; the <a href="https://www.smspower.org/Development/SMSOfficialDocs#HOWTHEGUNWORKS">Sega official documentation</a> recommends doing some averaging across frames to get a good signal. But in theory this is much more accurate than the Zapper, and doesn’t require the white boxes.</p>

<p>But look at what we’ve done here: the Master System is literally reading in-line with the electron beam. This means that for this to work, you really do need an electron beam that moves in sync with the VDP. An LCD just won’t give you that moving dot, no matter how much delay you add.</p>

<p>While you could fall back to the white boxes with delays approach if you were writing Master System Light Phaser homebrew for HDTVs, it would be harder to implement than the NES, because it would require much stricter timing. After all, the photodiode is going to go out much sooner; the slower photodiode on the Zapper gives some leeway. I doubt anyone will bother. The town can keep its gangsters one more day.</p>

<p><img src="https://nicole.express/assets/img/gunz/scott.jpg" title="GREAT SCOTT, YOU'VE GOT ZERO POINTS!" alt="Gangster Town attract mode, showing Gangsters in pinstripe suits marching around a brightly-colored city"></p>

<p><em>Note that there are more elaborate ways to play lightgun games on modern TVs, including one, the <a href="https://www.lightgunverter.com/">LightGunVerter</a>, which promises Master System support, and uses a Wiimote as a gun and internally fakes the signal timing to match what the console might expect. This device is no longer manufactured, but it is an open source project, so perhaps I might take a future look at it.</em></p>

  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Sycamore Gap tree held a particularly deep place in people's hearts (139 pts)]]></title>
            <link>https://www.economist.com/obituary/2023/10/04/the-sycamore-gap-tree-held-a-particularly-deep-place-in-peoples-hearts</link>
            <guid>37893091</guid>
            <pubDate>Sun, 15 Oct 2023 20:24:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/obituary/2023/10/04/the-sycamore-gap-tree-held-a-particularly-deep-place-in-peoples-hearts">https://www.economist.com/obituary/2023/10/04/the-sycamore-gap-tree-held-a-particularly-deep-place-in-peoples-hearts</a>, See on <a href="https://news.ycombinator.com/item?id=37893091">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><h2>It was felled maliciously in the small hours of September 28th, aged around 300 </h2></section><div><div data-body-id="cp2"><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/092%20Obituary%20-%20The%20Sycamore%20Gap%20tree-ab22588d7b7597672f9304d6345ccf67.mp3" title="The Sycamore Gap tree held a particularly deep place in people’s hearts " controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p data-component="paragraph"><span data-caps="initial">G</span><small>ardeners often</small> think unfondly of sycamores. These are big, resilient, untidy trees, relatively recent arrivals, and of careless habits. Their winged seeds, and the tough little seedlings that sprout from them, spread everywhere they can. One such seedling was determined enough to drive its taproot through thin marshy topsoil into the dark, crystalline dolerite of Whin Sill, the cliff-like ridge in Northumberland which carries Hadrian’s Wall. And there, over two or three centuries, it grew.</p><p data-component="paragraph">Being a sycamore, it liked to cluster, and also to sow offspring round about. It seems that for a time the tree on Whin Sill had others growing close, with which its roots and its canopy could correspond. But gradually these disappeared. The natural dip in the landscape there gave protection of a sort. More important, the tree now had space to grow into the most beautiful shape possible for sycamores, with a rounded dome on a trunk slightly twisting, lovely as a cedar of Lebanon. Long before, when it was still germinating, 18th-century gardeners with parks to plan put in well spaced sycamores for that reason.</p><p data-component="paragraph">Unlike other members of the genus <i>Acer</i>, it did not put on a blazing autumn display. Its big five-lobed leaves, with their irregular notching, merely turned a crumpled brown. No one minded.&nbsp;It was where and how it stood that drew crowds to the Steel Rigg car park and a good 20 minutes of perilous ascents and descents, to get a sighting. It was photographed in snow, mist and starlight, at sunrise and under the northern lights. It posed exquisitely. In 2016 it was voted England’s Tree of the Year, and the next year it came fifth in the European league, when the winner was a far less prepossessing Polish oak called Jozef.</p><p data-component="paragraph">The sycamore was also snapped on thousands of ordinary phones. It had star billing when the Potters came to celebrate a 60th birthday, with the birthday girl in a gold sash and the spaniels behaving for once; when the Courage family gathered for Christmas, all in their wellingtons, shouting in triumph; when Lee proposed to Hayley and Brendan proposed to Sinead, kneeling awkwardly among the rocks and roots, and when miscellaneous walkers and rain-refugees brought out their pork pies and Kit-Kats. Not a few went on to the Twice Brewed pub where the beer was called Sycamore Gap, with the tree’s portrait on the bottle. It was left alone then to the stars, and the quietly munching sheep.</p><p data-component="paragraph">Dramas happened to the sycamore, too. When “Robin Hood, Prince of Thieves” was filmed there in 1991 a henchman of the local lord, in chain-mail and metal helmet, almost took an axe to it. It was saved by Kevin Costner shouting “This is my land, and my tree!” before pinning the henchman to the ground with his sword. A narrow shave. Mr Costner roughly proved his “ownership” by breaking off leaves as he passed, but the sycamore had the last word, effortlessly upstaging the star as he trudged up the hill away from it, an ant beside its glorious silhouette.</p><p data-component="paragraph">There were other excitements. In 2003 a helicopter filming a nature documentary crashed 100 feet away, threatening to explode; the tree was unperturbed. At another point, during filming for a television crime drama, it was surrounded by police cars. So locals imagined there might be another episode in the making when, on the morning of September 28th, they saw police round the sycamore again. But the tree was down. It lay awkwardly across the Wall, its severed stump shockingly white where it had been sliced with a 28-inch chainsaw.</p><p data-component="paragraph">Technically, it still lived. The stump, remarkably healthy, was in the ground, the roots taking in water. But the water had nothing to flow to. As word spread, people gathered again, this time in a state of grief and disbelief. Some laid flowers, before the crime tape kept them out.&nbsp;One young man came with a sycamore sapling bought in a garden centre, planting it as close as he could to the right place. The National Trust removed it. Foresters said the stump could be coppiced, with new shoots sprouting, but after many, many years it would still be no more than a bush. The tree, as everyone knew it, could not be saved.</p><p data-component="paragraph">The sycamore had not officially been a sacred or magic tree. It was a locus of calm and deep summer shade; stargazers liked to gather there, and it bore, said the Bishop of Newcastle, “a pastoral load” of the worries and pain of local folk. It was the guardian of a place where people scattered ashes and painted pebbles inscribed with “Love you 4 ever Mum xx”. But it was not tied with ribbons or haunted by druids; it was just “our tree”. Nonetheless, on social media its felling seemed like sacrilege. First, it had hurt Northumberland and Northumbrians, tearing a hole in their hearts, killing some elemental spirit of the county, as badly as if someone had destroyed the Tyne Bridge. It had taken their symbol and their pride away. The gap left was immeasurable.</p><p data-component="paragraph">The felling had also outraged some numinous power of nature. Several social posts mentioned the story of Erysichthon, King of Thessaly, who felled the sacred grove of the harvest-goddess Demeter to build himself a feast hall. Her favourite poplar felt the blows of the double axes first. Erysichthon did not escape, however; Demeter afflicted him with such insatiable hunger that he ended by devouring himself. In Irish tradition, too, anyone who cut an ash would have his house consumed by fire. Similar thoughts of awful retribution were voiced against whoever had ventured out, on a night of raging storm and a full moon, armed with white paint to mark the place for the blade, to fell the sycamore. “Beware the wrath of nature,” one tweet ran.</p><p data-component="paragraph">More people, though, dwelt on absence. What they felt was perhaps best expressed in Gerard Manley Hopkins’s “Binsey Poplars”, addressed to favourite trees felled in Oxford in 1879:</p><blockquote><p>O if we but knew what we do<br>When we delve or hew—<br>Hack and rack the growing green!...<br>After-comers cannot guess the beauty been.</p></blockquote></div><p>This article appeared in the Obituary section of the print edition under the headline "Beauty been"</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Are free markets history? The rise of homeland economics" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20231007_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20231007_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20231007_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20231007_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20231007_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20231007_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20231007_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20231007_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20231007_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20231007_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20231007_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20231007_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20231007_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20231007_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20231007_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20231007_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20231007_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the October 7th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-10-07" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omnigres: Postgres as a Platform (176 pts)]]></title>
            <link>https://github.com/omnigres/omnigres</link>
            <guid>37893080</guid>
            <pubDate>Sun, 15 Oct 2023 20:23:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/omnigres/omnigres">https://github.com/omnigres/omnigres</a>, See on <a href="https://news.ycombinator.com/item?id=37893080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="" dir="auto"><a href="#"><img src="https://github.com/omnigres/omnigres/raw/master/header_logo.svg" alt="Omnigres"></a></h2>
<p dir="auto"><a href="https://discord.omnigr.es/" rel="nofollow"><img src="https://camo.githubusercontent.com/c63c9e77112ef2dfd1b07422bdf2efbfb5bda2dfa12dd386b4bb7f282262f704/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313036303536383938313732353030333738393f6c6162656c3d446973636f7264" alt="Discord Chat" data-canonical-src="https://img.shields.io/discord/1060568981725003789?label=Discord"></a>
<a href="https://docs.omnigres.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/e9badd1e137676d8fdcfd6615d878ed96ada1085e996fe0a9114930b61a0025b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d72656164792d677265656e" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-ready-green"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4beec76b00dcaf424f74a33aaf04677f56df63942bb6ad030dac75b1e7ae4d4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6f6d6e69677265732f6f6d6e6967726573"><img src="https://camo.githubusercontent.com/4beec76b00dcaf424f74a33aaf04677f56df63942bb6ad030dac75b1e7ae4d4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6f6d6e69677265732f6f6d6e6967726573" alt="License" data-canonical-src="https://img.shields.io/github/license/omnigres/omnigres"></a></p>
<p dir="auto">Omnigres makes Postgres a developer-first application platform. You can deploy a single database instance and it can host your entire application, scaling as needed.</p>
<ul dir="auto">
<li>Running application logic <strong>inside</strong> or <strong>next to</strong> the database instance</li>
<li><strong>Deployment</strong> provisioning (<strong>Git</strong>, <strong>containers</strong>, etc.)</li>
<li>Database instance serves <strong>HTTP</strong>, <strong>WebSocket</strong> and other protocols</li>
<li>In-memory and volatile on-disk <strong>caching</strong></li>
<li>Routine application building blocks (<strong>authentication</strong>, <strong>authorization</strong>, <strong>payments</strong>, etc.)</li>
<li>Database-modeled application logic via <strong>reactive</strong> queries</li>
<li>Automagic remote <strong>APIs</strong> and <strong>form</strong> handling</li>
<li><strong>Live</strong> data updates</li>
</ul>
<h2 tabindex="-1" id="user-content-blogs-and-publications" dir="auto"><a href="#blogs-and-publications">Blogs and Publications</a></h2>
<ul dir="auto">
<li><a href="https://yrashk.com/blog/category/omnigres/" rel="nofollow">Omnigres maintainer's blog</a></li>
</ul>
<h2 tabindex="-1" id="user-content-runner-quick-start" dir="auto"><a href="#runner-quick-start">🏃 Quick start</a></h2>
<p dir="auto">The fastest way to try Omnigres out is by using its <a href="https://github.com/omnigres/omnigres/pkgs/container/omnigres">container image</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker volume create omnigres
docker run --name omnigres --mount source=omnigres,target=/var/lib/postgresql/data \
           -p 127.0.0.1:5432:5432 -p 127.0.0.1:8080:8080 --rm ghcr.io/omnigres/omnigres:latest
# Now you can connect to it:
psql -h localhost -p 5432 -U omnigres omnigres # password is `omnigres`"><pre>docker volume create omnigres
docker run --name omnigres --mount source=omnigres,target=/var/lib/postgresql/data \
           -p 127.0.0.1:5432:5432 -p 127.0.0.1:8080:8080 --rm ghcr.io/omnigres/omnigres:latest
<span><span>#</span> Now you can connect to it:</span>
psql -h localhost -p 5432 -U omnigres omnigres <span><span>#</span> password is `omnigres`</span></pre></div>
<p dir="auto">Postgres parameters such as database, user or password can be overridden as per the
"Environment Variales" section in <a href="https://hub.docker.com/_/postgres/" rel="nofollow">postgres image instructions</a></p>
<p dir="auto">You can access the HTTP server at <a href="http://localhost:8080/" rel="nofollow">localhost:8080</a></p>
<h3 tabindex="-1" id="user-content-building-your-own-image" dir="auto"><a href="#building-your-own-image">Building your own image</a></h3>
<p dir="auto">If you can't use the pre-built image (for example, you are running a fork or made changes), you can build the image yourself:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build the image
DOCKER_BUILDKIT=1 docker build . -t ghcr.io/omnigres/omnigres"><pre><span><span>#</span> Build the image</span>
DOCKER_BUILDKIT=1 docker build <span>.</span> -t ghcr.io/omnigres/omnigres</pre></div>
<h2 tabindex="-1" id="user-content-wave-hello-world" dir="auto"><a href="#wave-hello-world">👋 "Hello, world"</a></h2>
<p dir="auto">Here we expect you are running the <a href="#-runner--quick-start">container image</a>, which has
omni_httpd and omni_web extensions provisioned by default.</p>
<p dir="auto">Let's start with a traditional example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="update omni_httpd.handlers
set
    query =
        $$select omni_httpd.http_response('Hello, world!') from request;$$;"><pre><span>update</span> <span>omni_httpd</span>.<span>handlers</span>
<span>set</span>
    query <span>=</span>
        $$<span>select</span> <span>omni_httpd</span>.<span>http_response</span>(<span><span>'</span>Hello, world!<span>'</span></span>) <span>from</span> request;$$;</pre></div>
<p dir="auto">Here we instruct the handler that is provisioned by omni_httpd by default
to use the enclosed query to greet the world:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl localhost:8080
Hello, world!"><pre>$ curl localhost:8080
Hello, world<span>!</span></pre></div>
<p dir="auto">Now, let's make it more personal and let it greet the requester by name.</p>
<div dir="auto" data-snippet-clipboard-copy-content="update omni_httpd.handlers
set
    query =
        $$select omni_httpd.http_response('Hello, ' || 
                   coalesce(omni_web.param_get(request.query_string, 'name'), 'world') || '!')
          from request;$$;"><pre><span>update</span> <span>omni_httpd</span>.<span>handlers</span>
<span>set</span>
    query <span>=</span>
        $$<span>select</span> <span>omni_httpd</span>.<span>http_response</span>(<span><span>'</span>Hello, <span>'</span></span> <span>||</span> 
                   coalesce(<span>omni_web</span>.<span>param_get</span>(<span>request</span>.<span>query_string</span>, <span><span>'</span>name<span>'</span></span>), <span><span>'</span>world<span>'</span></span>) <span>||</span> <span><span>'</span>!<span>'</span></span>)
          <span>from</span> request;$$;</pre></div>
<p dir="auto">Now, it'll respond in a personalized manner if <code>name</code> query string parameter is provided:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl localhost:8080
Hello, world!

$ curl &quot;localhost:8080?name=John&quot;
Hello, John!"><pre>$ curl localhost:8080
Hello, world<span>!</span>

$ curl <span><span>"</span>localhost:8080?name=John<span>"</span></span>
Hello, John<span>!</span></pre></div>
<p dir="auto">This, of course, only barely scratches the surface, but it may give you a very high-level concept
of how Omnigres web services can be built.</p>
<p dir="auto">For a more complex example, that uses the underlying database and employs more real-world layout, check out
this <a href="https://docs.omnigres.org/examples/motd/" rel="nofollow">MOTD service example</a>.</p>
<h2 tabindex="-1" id="user-content-building_construction-component-roadmap" dir="auto"><a href="#building_construction-component-roadmap">🏗️ Component Roadmap</a></h2>
<p dir="auto">Below is the current list of components being worked on, experimented with and discussed. This list will change
(and grow) over time.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Status</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_schema/README.md">omni_schema</a></td>
<td>✅ First release candidate</td>
<td>Application schema management</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_json/README.md">omni_json</a></td>
<td>✅ First release candidate</td>
<td>JSON toolkit</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_http/README.md">omni_http</a></td>
<td>✅ First release candidate</td>
<td>Common HTTP types library</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_httpd/README.md">omni_httpd</a> and <a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_web/README.md">omni_web</a></td>
<td>✅ First release candidate</td>
<td>Serving HTTP in Postgres and building services in SQL</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_mimetypes/README.md">omni_mimetypes</a></td>
<td>✅ First release candidate</td>
<td>MIME types and file extensions</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_httpc/README.md">omni_httpc</a></td>
<td>✅ First release candidate</td>
<td>HTTP client</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_sql/README.md">omni_sql</a></td>
<td>🚧 Extremely limited API surface</td>
<td>Programmatic SQL manipulation</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_vfs/README.md">omni_vfs</a></td>
<td>☑️ Initial prototype</td>
<td>Virtual File System interface</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_containers/README.md">omni_containers</a></td>
<td>☑️ Initial prototype</td>
<td>Managing containers</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_ext/README.md">omni_ext</a> and  <a href="https://github.com/omnigres/omnigres/blob/master/dynpgext/README.md">Dynpgext interface</a></td>
<td>☑️ Getting ready to become first release candidate</td>
<td>Advanced Postgres extension loader</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_types/README.md">omni_types</a></td>
<td>✅ First release candidate</td>
<td>Advanced Postgres typing techniques (sum types, etc.)</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_seq/README.md">omni_seq</a></td>
<td>✅ First release candidate</td>
<td>Extended Postgres sequence tooling</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_txn/README.md">omni_txn</a></td>
<td>✅ First release candidate</td>
<td>Transaction management</td>
</tr>
<tr>
<td><a href="https://github.com/omnigres/omnigres/blob/master/extensions/omni_python/README.md">omni_python</a></td>
<td>☑️ Initial prototype</td>
<td>First-class Python Development Experience</td>
</tr>
<tr>
<td>omni_git</td>
<td>🥼 Early experiments (unpublished)</td>
<td>Postgres Git client</td>
</tr>
<tr>
<td>omni_reactive</td>
<td>🗓️ Haven't started yet</td>
<td>Reactive queries</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" id="user-content-keyboard-hacking" dir="auto"><a href="#keyboard-hacking">⌨️ Hacking</a></h2>
<h2 tabindex="-1" id="user-content-building--using-extensions" dir="auto"><a href="#building--using-extensions">Building &amp; using extensions</a></h2>
<p dir="auto">To build and run Omnigres, you would currently need a recent C compiler, OpenSSL and cmake:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir -p build &amp;&amp; cd build
cmake ..
make psql_<COMPONENT_NAME> # for example, `psql_omni_containers`"><pre>mkdir -p build <span>&amp;&amp;</span> <span>cd</span> build
cmake ..
make psql_<span>&lt;</span>COMPONENT_NAME<span>&gt;</span> <span><span>#</span> for example, `psql_omni_containers`</span></pre></div>
<h3 tabindex="-1" id="user-content-running-tests" dir="auto"><a href="#running-tests">Running tests</a></h3>
<div dir="auto" data-snippet-clipboard-copy-content="# in the build directory
CTEST_PARALLEL_LEVEL=$(nproc) make -j $(nproc) all test"><pre><span><span>#</span> in the build directory</span>
CTEST_PARALLEL_LEVEL=<span><span>$(</span>nproc<span>)</span></span> make -j <span><span>$(</span>nproc<span>)</span></span> all <span>test</span></pre></div>
<h2 tabindex="-1" id="user-content-devenvsh-based-local-development-environment" dir="auto"><a href="#devenvsh-based-local-development-environment">Devenv.sh-based local development environment</a></h2>
<h3 tabindex="-1" id="user-content-initial-setup" dir="auto"><a href="#initial-setup">Initial setup</a></h3>
<p dir="auto">Follow these guides:</p>
<ol dir="auto">
<li><a href="https://devenv.sh/getting-started/" rel="nofollow">https://devenv.sh/getting-started/</a></li>
<li><a href="https://devenv.sh/automatic-shell-activation/" rel="nofollow">https://devenv.sh/automatic-shell-activation/</a></li>
<li>Run <code>direnv allow</code> in omnigres repo</li>
</ol>
<h3 tabindex="-1" id="user-content-day-to-day-development" dir="auto"><a href="#day-to-day-development">Day-to-day development</a></h3>
<ol dir="auto">
<li><code>cd</code> into the repo. This brings in all dependencies.</li>
<li>To bring up development stack (Postgres with all extensions, etc.), run:
<code>devenv up</code></li>
</ol>
<p dir="auto">Once the development environment is running, you can connect to it by issuing:</p>
<ul dir="auto">
<li><code>pg</code> -&gt; this connects to Postgres through a UNIX socket, for maximum
performance. CLI args forwarded.</li>
<li><code>pgclear</code> -&gt; removes the PGDATA folder contents. You want to
restart <code>devenv up</code> after this so Postgres can reinitialize as
per <code>devenv.nix</code>.</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mastercard Should Stop Selling Our Data (539 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/10/mastercard-should-stop-selling-our-data</link>
            <guid>37892684</guid>
            <pubDate>Sun, 15 Oct 2023 19:33:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/10/mastercard-should-stop-selling-our-data">https://www.eff.org/deeplinks/2023/10/mastercard-should-stop-selling-our-data</a>, See on <a href="https://news.ycombinator.com/item?id=37892684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p>We trust companies with our information every day. But many companies—even those that hold our most revealing information—are using it not just to provide the services we ask for, but to amp up their profits at the cost of our privacy.</p>
<p>That's why EFF has joined a campaign, led by the U.S. Public Interest Research Group (U.S. PIRG), to call on Mastercard to limit its data collection and stop selling cardholder information.</p>
<p>Mastercard is just one company that profits from the sale of personal data collected from the people who trust them with their information. As consumer advocates, we’re calling on the company to honor the trust that cardholders place in them by committing to stop selling their information.</p>
<p>Why make this ask of Mastercard? As U.S. PIRG <a href="https://pirg.org/edfund/articles/mastercard-dont-sell-my-data/">explains in its report</a> accompanying the campaign, the company’s position as a global payments technology company affords it "access to enormous amounts of information derived from the financial lives of millions, and its monetization strategies tell a broader story of the data economy that’s gone too far."</p>
<p>Knowing where you shop, just by itself, can <a href="https://www.vice.com/en/article/dygy8k/researchers-find-anonymized-data-is-even-less-anonymous-than-we-thought">reveal a lot about who you are</a>. Mastercard takes this a step further, as U.S. PIRG reported, by analyzing the amount and frequency of transactions, plus the location, date, and time to create categories of cardholders and make inferences about what type of shopper you may be. In some cases, this means predicting who’s a “big spender” or which cardholders Mastercard thinks will be “high-value”—predictions used to target certain people and encourage them to spend more money.</p>
<p>These kinds of actions work against the trust that many people have for the company that issues their cards. In fact, the Bank for International Settlements found that people <a href="https://www.bis.org/publ/bisbull42.pdf">trust traditional financial institutions</a> with their data more than big tech companies, government bodies, or fintech firms. When people get a card from Mastercard, they do not anticipate the ways the financial profile of their purchases will be remixed, repackaged, and used against them. Mastercard <a href="https://www.marketingbrew.com/stories/2021/09/13/visa-shutting-personal-data-business-advertisers">can</a> and should do better. We call on the company to respect the trust and privacy of its cardholders and change its current data practices.</p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hyphens in man pages (108 pts)]]></title>
            <link>https://lists.debian.org/debian-devel/2023/10/msg00083.html</link>
            <guid>37892654</guid>
            <pubDate>Sun, 15 Oct 2023 19:30:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.debian.org/debian-devel/2023/10/msg00083.html">https://lists.debian.org/debian-devel/2023/10/msg00083.html</a>, See on <a href="https://news.ycombinator.com/item?id=37892654">Hacker News</a></p>
<div id="readability-page-1" class="page">
<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->
<hr>



<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->

<hr>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul>
<li><em>To</em>: debian-devel &lt;<a href="mailto:debian-devel%40lists.debian.org">debian-devel@lists.debian.org</a>&gt;</li>
<li><em>Subject</em>: Hyphens in man pages</li>
<li><em>From</em>: Antonio Russo &lt;<a href="mailto:aerusso%40aerusso.net">aerusso@aerusso.net</a>&gt;</li>
<li><em>Date</em>: Sat, 14 Oct 2023 20:51:27 -0600</li>
<li><em>Message-id</em>: &lt;<a href="https://lists.debian.org/msgid-search/e21c0729-0789-4079-b9a2-b9a4b1843e05@aerusso.net">[🔎]</a>&nbsp;<a href="https://lists.debian.org/debian-devel/2023/10/msg00083.html">e21c0729-0789-4079-b9a2-b9a4b1843e05@aerusso.net</a>&gt;</li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
<hr>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre>Hello,

I discovered a new pet peeve today: if you search for a command in a manual page,
say -e in man 1 zgrep, it's a crapshot whether just searching for '-e' will find
the command or not.  The reason is that "-" may been accidentally encoded as ‐
instead of -.

Now, depending on your email client and settings, the above will appear to be the
ravings of an unhinged lunatic who wrote the same thing twice, or an unhinged
lunatic who slammed their fists onto the keyboard.

The reason is that man(1) convert bare dashes (0x2D) to hyphens (U+2010).  These
are not the same symbol: searching for one does not find the other without some
kind of normalization, pasting commands with one vs. the other does different
things.  New users who do not understand this will be discouraged trying to read
manual pages.  Chances are, they will fill forums with mundane questions that
could and should have been addressed by a simple search of a manual page.

I recently fixed a ton of these in another upstream package with this vim "one-liner":

:%s/--\([a-z]\+\)\(-[a-z]\+\)*/\=substitute(submatch(0), '-', '\\-', 'g')/g

However, this requires manual review and does not fix the '-e' example from zgrep.
There are also a whole host of this kind of problem, e.g., dashes in URLs that get
naievely pasted into man pages (another live example I just addressed).

I come here with several questions:

 - Am I off-base thinking this is a problem?
 - Should we really be using troff to typeset anything in this year 2023?
   (In particular, if we can make the source text more human-readable, we might
   be able to leverage LLMs on this wealth of information in the future and automate
   support.  Are LLMs "fluent" in troff? I have not investigated at all.)
 - Are there any alternatives that actually produce nice looking man pages?
   (My experience with pandoc is that the source is still awkward, I literally
   just found another example of this bug in my own man page, and it looks pretty
   ugly in man. But maybe I just didn't find good examples/documentation.)
 - Should we try to come up with some lintian rules to flag this behavior?
   (This one: /--\([a-z]\+\)\(-[a-z]\+\)*/ finds long GNU-style commands, I'd
   have to think for at least a little bit about finding short ones.  This would
   ultimately be fragile. For example, the above doesn't find partially broken
   tokens; i.e., only one unescaped dash.)
&lt;li&gt; Automated tooling around this, more generally, seems fragile.  HTML might have
   been a nice compromise, but writing that appears to be out of vogue these days,
   &lt;sarcasm intensity="medium"&gt;despite being a pretty OK thing to read and write
   by hand&lt;/sarcasm&gt;.&lt;/li&gt; But seriously, I would love to be writing HTML instead
   of troff for manual pages.

Antonio</pre><p><strong>Attachment:
<a href="https://lists.debian.org/debian-devel/2023/10/bin8AN4dT_ZPQ.bin"><tt>OpenPGP_0xB01C53D5DED4A4EE.asc</tt></a></strong><br>
<em>Description:</em> OpenPGP public key</p>
<p><strong>Attachment:
<a href="https://lists.debian.org/debian-devel/2023/10/pgpSD95L7uMcj.pgp"><tt>OpenPGP_signature.asc</tt></a></strong><br>
<em>Description:</em> OpenPGP digital signature</p>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<hr>
<strong>Reply to:</strong>
<ul>
  <li><a href="mailto:debian-devel@lists.debian.org?in-reply-to=%3Ce21c0729-0789-4079-b9a2-b9a4b1843e05@aerusso.net%3E&amp;subject=Re:%20Hyphens%20in%20man%20pages">debian-devel@lists.debian.org</a></li>
  <li><a href="mailto:aerusso@aerusso.net?in-reply-to=%3Ce21c0729-0789-4079-b9a2-b9a4b1843e05@aerusso.net%3E&amp;subject=Re:%20Hyphens%20in%20man%20pages&amp;cc=debian-devel@lists.debian.org">Antonio Russo (on-list)</a></li>
  <li><a href="mailto:aerusso@aerusso.net?in-reply-to=%3Ce21c0729-0789-4079-b9a2-b9a4b1843e05@aerusso.net%3E&amp;subject=Re:%20Hyphens%20in%20man%20pages">Antonio Russo (off-list)</a></li>
</ul>
<hr>
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="00084" href="https://lists.debian.org/debian-devel/2023/10/msg00084.html">Re: Hyphens in man pages</a></strong>
<ul><li><em>From:</em> Jochen Sprickerhof &lt;jspricke@debian.org&gt;</li></ul></li>
<li><strong><a name="00085" href="https://lists.debian.org/debian-devel/2023/10/msg00085.html">Re: Hyphens in man pages</a></strong>
<ul><li><em>From:</em> "G. Branden Robinson" &lt;g.branden.robinson@gmail.com&gt;</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<!--X-References-End-->
<!--X-BotPNI-->
<ul>
<li>Prev by Date:
<strong><a href="https://lists.debian.org/debian-devel/2023/10/msg00082.html">Re: The Technical Committee needs you!</a></strong>
</li>
<li>Next by Date:
<strong><a href="https://lists.debian.org/debian-devel/2023/10/msg00084.html">Re: Hyphens in man pages</a></strong>
</li>
<li>Previous by thread:
<strong><a href="https://lists.debian.org/debian-devel/2023/10/msg00082.html">Re: The Technical Committee needs you!</a></strong>
</li>
<li>Next by thread:
<strong><a href="https://lists.debian.org/debian-devel/2023/10/msg00084.html">Re: Hyphens in man pages</a></strong>
</li>
<li>Index(es):
<ul>
<li><a href="https://lists.debian.org/debian-devel/2023/10/maillist.html#00083"><strong>Date</strong></a></li>
<li><a href="https://lists.debian.org/debian-devel/2023/10/threads.html#00083"><strong>Thread</strong></a></li>
</ul>
</li>
</ul>

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[SSH-audit: SSH server and client security auditing (261 pts)]]></title>
            <link>https://github.com/jtesta/ssh-audit</link>
            <guid>37892028</guid>
            <pubDate>Sun, 15 Oct 2023 18:18:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jtesta/ssh-audit">https://github.com/jtesta/ssh-audit</a>, See on <a href="https://news.ycombinator.com/item?id=37892028">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-ssh-audit" dir="auto"><a href="#ssh-audit">ssh-audit</a></h2>
<p dir="auto"><a href="https://github.com/jtesta/ssh-audit/blob/master/LICENSE"><img src="https://camo.githubusercontent.com/992daabc2aa4463339825f8333233ba330dd08c57068f6faf4bb598ab5a3df2e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-MIT-brightgreen.svg"></a>
<a href="https://pypi.org/project/ssh-audit/" rel="nofollow"><img src="https://camo.githubusercontent.com/8a53e63392135a30695739469904d2bcd65312feff37d792392580027c3e5de3/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f7373682d6175646974" alt="PyPI Downloads" data-canonical-src="https://img.shields.io/pypi/dm/ssh-audit"></a>
<a href="https://hub.docker.com/r/positronsecurity/ssh-audit" rel="nofollow"><img src="https://camo.githubusercontent.com/00e3917cc72475a85dcaa26a9f03f40a3b2441cfe235081a601b478a62303b6d/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f706f736974726f6e73656375726974792f7373682d6175646974" alt="Docker Pulls" data-canonical-src="https://img.shields.io/docker/pulls/positronsecurity/ssh-audit"></a>
<a href="https://github.com/jtesta/ssh-audit/actions"><img src="https://github.com/jtesta/ssh-audit/actions/workflows/tox.yaml/badge.svg" alt="Build Status"></a>
<a href="https://github.com/jtesta/ssh-audit/blob/master/CONTRIBUTING.md"><img src="https://camo.githubusercontent.com/b0ad703a46e8b249ef2a969ab95b2cb361a2866ecb8fe18495a2229f5847102d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e737667" alt="PRs Welcome" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"></a></p>
<p dir="auto"><strong>ssh-audit</strong> is a tool for ssh server &amp; client configuration auditing.</p>
<p dir="auto"><a href="https://github.com/jtesta/ssh-audit/">jtesta/ssh-audit</a> (v2.0+) is the updated and maintained version of ssh-audit forked from <a href="https://github.com/arthepsy/ssh-audit">arthepsy/ssh-audit</a> (v1.x) due to inactivity.</p>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#screenshots">Screenshots</a>
<ul dir="auto">
<li><a href="#server-standard-audit-example">Server Standard Audit Example</a></li>
<li><a href="#server-policy-audit-example">Server Policy Audit Example</a></li>
<li><a href="#client-standard-audit-example">Client Standard Audit Example</a></li>
</ul>
</li>
<li><a href="#hardening-guides">Hardening Guides</a></li>
<li><a href="#pre-built-packages">Pre-Built Packages</a></li>
<li><a href="#web-front-end">Web Front-End</a></li>
<li><a href="#changelog">ChangeLog</a></li>
</ul>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<ul dir="auto">
<li>SSH1 and SSH2 protocol server support;</li>
<li>analyze SSH client configuration;</li>
<li>grab banner, recognize device or software and operating system, detect compression;</li>
<li>gather key-exchange, host-key, encryption and message authentication code algorithms;</li>
<li>output algorithm information (available since, removed/disabled, unsafe/weak/legacy, etc);</li>
<li>output algorithm recommendations (append or remove based on recognized software version);</li>
<li>output security information (related issues, assigned CVE list, etc);</li>
<li>analyze SSH version compatibility based on algorithm information;</li>
<li>historical information from OpenSSH, Dropbear SSH and libssh;</li>
<li>policy scans to ensure adherence to a hardened/standard configuration;</li>
<li>runs on Linux and Windows;</li>
<li>supports Python 3.7 - 3.11;</li>
<li>no dependencies</li>
</ul>
<h2 tabindex="-1" id="user-content-usage" dir="auto"><a href="#usage">Usage</a></h2>
<div data-snippet-clipboard-copy-content="usage: ssh-audit.py [options] <host>

   -h,  --help             print this help
   -1,  --ssh1             force ssh version 1 only
   -2,  --ssh2             force ssh version 2 only
   -4,  --ipv4             enable IPv4 (order of precedence)
   -6,  --ipv6             enable IPv6 (order of precedence)
   -b,  --batch            batch output
   -c,  --client-audit     starts a server on port 2222 to audit client
                               software config (use -p to change port;
                               use -t to change timeout)
   -d,  --debug            Enable debug output.
   -g,  --gex-test=<x[,y,...]>  dh gex modulus size test
                   <min1:pref1:max1[,min2:pref2:max2,...]>
                   <x-y[:step]>
   -j,  --json             JSON output (use -jj to enable indents)
   -l,  --level=<level>    minimum output level (info|warn|fail)
   -L,  --list-policies    list all the official, built-in policies
        --lookup=<alg1,alg2,...>    looks up an algorithm(s) without
                                    connecting to a server
   -m,  --manual           print the man page (Windows only)
   -M,  --make-policy=<policy.txt>  creates a policy based on the target server
                                    (i.e.: the target server has the ideal
                                    configuration that other servers should
                                    adhere to)
   -n,  --no-colors        disable colors
   -p,  --port=<port>      port to connect
   -P,  --policy=<&quot;policy name&quot; | policy.txt>  run a policy test using the
                                                   specified policy
   -t,  --timeout=<secs>   timeout (in seconds) for connection and reading
                               (default: 5)
   -T,  --targets=<hosts.txt>  a file containing a list of target hosts (one
                                   per line, format HOST[:PORT])
        --threads=<threads>    number of threads to use when scanning multiple
                                   targets (-T/--targets) (default: 32)
   -v,  --verbose          verbose output"><pre><code>usage: ssh-audit.py [options] &lt;host&gt;

   -h,  --help             print this help
   -1,  --ssh1             force ssh version 1 only
   -2,  --ssh2             force ssh version 2 only
   -4,  --ipv4             enable IPv4 (order of precedence)
   -6,  --ipv6             enable IPv6 (order of precedence)
   -b,  --batch            batch output
   -c,  --client-audit     starts a server on port 2222 to audit client
                               software config (use -p to change port;
                               use -t to change timeout)
   -d,  --debug            Enable debug output.
   -g,  --gex-test=&lt;x[,y,...]&gt;  dh gex modulus size test
                   &lt;min1:pref1:max1[,min2:pref2:max2,...]&gt;
                   &lt;x-y[:step]&gt;
   -j,  --json             JSON output (use -jj to enable indents)
   -l,  --level=&lt;level&gt;    minimum output level (info|warn|fail)
   -L,  --list-policies    list all the official, built-in policies
        --lookup=&lt;alg1,alg2,...&gt;    looks up an algorithm(s) without
                                    connecting to a server
   -m,  --manual           print the man page (Windows only)
   -M,  --make-policy=&lt;policy.txt&gt;  creates a policy based on the target server
                                    (i.e.: the target server has the ideal
                                    configuration that other servers should
                                    adhere to)
   -n,  --no-colors        disable colors
   -p,  --port=&lt;port&gt;      port to connect
   -P,  --policy=&lt;"policy name" | policy.txt&gt;  run a policy test using the
                                                   specified policy
   -t,  --timeout=&lt;secs&gt;   timeout (in seconds) for connection and reading
                               (default: 5)
   -T,  --targets=&lt;hosts.txt&gt;  a file containing a list of target hosts (one
                                   per line, format HOST[:PORT])
        --threads=&lt;threads&gt;    number of threads to use when scanning multiple
                                   targets (-T/--targets) (default: 32)
   -v,  --verbose          verbose output
</code></pre></div>
<ul dir="auto">
<li>if both IPv4 and IPv6 are used, order of precedence can be set by using either <code>-46</code> or <code>-64</code>.</li>
<li>batch flag <code>-b</code> will output sections without header and without empty lines (implies verbose flag).</li>
<li>verbose flag <code>-v</code> will prefix each line with section type and algorithm name.</li>
<li>an exit code of 0 is returned when all algorithms are considered secure (for a standard audit), or when a policy check passes (for a policy audit).</li>
</ul>
<p dir="auto">Basic server auditing:</p>
<div data-snippet-clipboard-copy-content="ssh-audit localhost
ssh-audit 127.0.0.1
ssh-audit 127.0.0.1:222
ssh-audit ::1
ssh-audit [::1]:222"><pre><code>ssh-audit localhost
ssh-audit 127.0.0.1
ssh-audit 127.0.0.1:222
ssh-audit ::1
ssh-audit [::1]:222
</code></pre></div>
<p dir="auto">To run a standard audit against many servers (place targets into servers.txt, one on each line in the format of <code>HOST[:PORT]</code>):</p>

<p dir="auto">To audit a client configuration (listens on port 2222 by default; connect using <code>ssh -p 2222 anything@localhost</code>):</p>

<p dir="auto">To audit a client configuration, with a listener on port 4567:</p>

<p dir="auto">To  list all official built-in policies (hint: use resulting policy names with <code>-P</code>/<code>--policy</code>):</p>

<p dir="auto">To run a policy audit against a server:</p>
<div data-snippet-clipboard-copy-content="ssh-audit -P [&quot;policy name&quot; | path/to/server_policy.txt] targetserver"><pre><code>ssh-audit -P ["policy name" | path/to/server_policy.txt] targetserver
</code></pre></div>
<p dir="auto">To run a policy audit against a client:</p>
<div data-snippet-clipboard-copy-content="ssh-audit -c -P [&quot;policy name&quot; | path/to/client_policy.txt]"><pre><code>ssh-audit -c -P ["policy name" | path/to/client_policy.txt]
</code></pre></div>
<p dir="auto">To run a policy audit against many servers:</p>
<div data-snippet-clipboard-copy-content="ssh-audit -T servers.txt -P [&quot;policy name&quot; | path/to/server_policy.txt]"><pre><code>ssh-audit -T servers.txt -P ["policy name" | path/to/server_policy.txt]
</code></pre></div>
<p dir="auto">To create a policy based on a target server (which can be manually edited):</p>
<div data-snippet-clipboard-copy-content="ssh-audit -M new_policy.txt targetserver"><pre><code>ssh-audit -M new_policy.txt targetserver
</code></pre></div>
<h2 tabindex="-1" id="user-content-screenshots" dir="auto"><a href="#screenshots">Screenshots</a></h2>
<h3 tabindex="-1" id="user-content-server-standard-audit-example" dir="auto"><a href="#server-standard-audit-example">Server Standard Audit Example</a></h3>
<p dir="auto">Below is a screen shot of the standard server-auditing output when connecting to an unhardened OpenSSH v5.3 service:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2982011/64388792-317e6f80-d00e-11e9-826e-a4934769bb07.png"><img src="https://user-images.githubusercontent.com/2982011/64388792-317e6f80-d00e-11e9-826e-a4934769bb07.png" alt="screenshot"></a></p>
<h3 tabindex="-1" id="user-content-server-policy-audit-example" dir="auto"><a href="#server-policy-audit-example">Server Policy Audit Example</a></h3>
<p dir="auto">Below is a screen shot of the policy auditing output when connecting to an un-hardened Ubuntu Server 20.04 machine (hint: use <code>-L</code>/<code>--list-policies</code> to see names of built-in policies to use with <code>-P</code>/<code>--policy</code>):
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2982011/94370881-95178700-00c0-11eb-8705-3157a4669dc0.png"><img src="https://user-images.githubusercontent.com/2982011/94370881-95178700-00c0-11eb-8705-3157a4669dc0.png" alt="screenshot"></a></p>
<p dir="auto">After applying the steps in the hardening guide (see below), the output changes to the following:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2982011/94370873-87620180-00c0-11eb-9a59-469f61a56ce1.png"><img src="https://user-images.githubusercontent.com/2982011/94370873-87620180-00c0-11eb-9a59-469f61a56ce1.png" alt="screenshot"></a></p>
<h3 tabindex="-1" id="user-content-client-standard-audit-example" dir="auto"><a href="#client-standard-audit-example">Client Standard Audit Example</a></h3>
<p dir="auto">Below is a screen shot of the client-auditing output when an unhardened OpenSSH v7.2 client connects:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2982011/68867998-b946c100-06c4-11ea-975f-1f47e4178a74.png"><img src="https://user-images.githubusercontent.com/2982011/68867998-b946c100-06c4-11ea-975f-1f47e4178a74.png" alt="client_screenshot"></a></p>
<h2 tabindex="-1" id="user-content-hardening-guides" dir="auto"><a href="#hardening-guides">Hardening Guides</a></h2>
<p dir="auto">Guides to harden server &amp; client configuration can be found here: <a href="https://www.ssh-audit.com/hardening_guides.html" rel="nofollow">https://www.ssh-audit.com/hardening_guides.html</a></p>
<h2 tabindex="-1" id="user-content-pre-built-packages" dir="auto"><a href="#pre-built-packages">Pre-Built Packages</a></h2>
<p dir="auto">Pre-built packages are available for Windows (see the releases page), PyPI, Snap, and Docker:</p>
<p dir="auto">To install from PyPI:</p>

<p dir="auto">To install the Snap package:</p>

<p dir="auto">To install from Dockerhub:</p>
<div data-snippet-clipboard-copy-content="$ docker pull positronsecurity/ssh-audit"><pre><code>$ docker pull positronsecurity/ssh-audit
</code></pre></div>
<p dir="auto">(Then run with: <code>docker run -it -p 2222:2222 positronsecurity/ssh-audit 10.1.1.1</code>)</p>
<p dir="auto">The status of various other platform packages can be found below (via Repology):</p>
<p dir="auto"><a href="https://repology.org/project/ssh-audit/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/a26cc37401d1021fdde020bbfe9220fab67569ca9817579fa6991821de9b9adb/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f7373682d61756469742e7376673f636f6c756d6e733d34" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/ssh-audit.svg?columns=4"></a></p>
<h2 tabindex="-1" id="user-content-web-front-end" dir="auto"><a href="#web-front-end">Web Front-End</a></h2>
<p dir="auto">For convenience, a web front-end on top of the command-line tool is available at <a href="https://www.ssh-audit.com/" rel="nofollow">https://www.ssh-audit.com/</a>.</p>
<h2 tabindex="-1" id="user-content-changelog" dir="auto"><a href="#changelog">ChangeLog</a></h2>
<h3 tabindex="-1" id="user-content-v300-2023-09-07" dir="auto"><a href="#v300-2023-09-07">v3.0.0 (2023-09-07)</a></h3>
<ul dir="auto">
<li>Results from concurrent scans against multiple hosts are no longer improperly combined; bug discovered by <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Hostname resolution failure no longer causes scans against multiple hosts to terminate unexpectedly; credit <a href="https://github.com/daniel-cues">Dani Cuesta</a>.</li>
<li>Algorithm recommendations resulting from warnings are now printed in yellow instead of red; credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Added failure, warning, and info notes to JSON output (note that this results in a breaking change to the banner protocol, "enc", and "mac" fields); credit <a href="https://github.com/BareqAZ">Bareq Al-Azzawi</a>.</li>
<li>Docker Makefile now creates multi-arch builds for amd64, arm64, and armv7; credit <a href="https://github.com/tisba">Sebastian Cohnen</a>.</li>
<li>Fixed crash during GEX tests.</li>
<li>Refined GEX testing against OpenSSH servers: when the fallback mechanism is suspected of being triggered, perform an additional test to obtain more accurate results.</li>
<li>The color of all notes will be printed in green when the related algorithm is rated good.</li>
<li>Prioritized host key certificate algorithms for Ubuntu 22.04 LTS client policy.</li>
<li>Marked all NIST K-, B-, and T-curves as unproven since they are so rarely used.</li>
<li>Added built-in policy for OpenSSH 9.4.</li>
<li>Added 12 new host keys: <code>ecdsa-sha2-curve25519</code>, <code>ecdsa-sha2-nistb233</code>, <code>ecdsa-sha2-nistb409</code>, <code>ecdsa-sha2-nistk163</code>, <code>ecdsa-sha2-nistk233</code>, <code>ecdsa-sha2-nistk283</code>, <code>ecdsa-sha2-nistk409</code>, <code>ecdsa-sha2-nistp224</code>, <code>ecdsa-sha2-nistp192</code>, <code>ecdsa-sha2-nistt571</code>, <code>ssh-dsa</code>, <code>x509v3-sign-rsa-sha256</code>.</li>
<li>Added 15 new key exchanges: <code>curve448-sha512@libssh.org</code>, <code>ecdh-nistp256-kyber-512r3-sha256-d00@openquantumsafe.org</code>, <code>ecdh-nistp384-kyber-768r3-sha384-d00@openquantumsafe.org</code>, <code>ecdh-nistp521-kyber-1024r3-sha512-d00@openquantumsafe.org</code>, <code>ecdh-sha2-brainpoolp256r1@genua.de</code>, <code>ecdh-sha2-brainpoolp384r1@genua.de</code>, <code>ecdh-sha2-brainpoolp521r1@genua.de</code>, <code>kexAlgoDH14SHA1</code>, <code>kexAlgoDH1SHA1</code>, <code>kexAlgoECDH256</code>, <code>kexAlgoECDH384</code>, <code>kexAlgoECDH521</code>, <code>sm2kep-sha2-nistp256</code>, <code>x25519-kyber-512r3-sha256-d00@amazon.com</code>, <code>x25519-kyber512-sha512@aws.amazon.com</code>.</li>
<li>Added 8 new ciphers: <code>aes192-gcm@openssh.com</code>, <code>cast128-12-cbc</code>, <code>cast128-12-cfb</code>, <code>cast128-12-ecb</code>, <code>cast128-12-ofb</code>, <code>des-cfb</code>, <code>des-ecb</code>, <code>des-ofb</code>.</li>
<li>Added 14 new MACs: <code>cbcmac-3des</code>, <code>cbcmac-aes</code>, <code>cbcmac-blowfish</code>, <code>cbcmac-des</code>, <code>cbcmac-rijndael</code>, <code>cbcmac-twofish</code>, <code>hmac-sha256-96</code>, <code>md5</code>, <code>md5-8</code>, <code>ripemd160</code>, <code>ripemd160-8</code>, <code>sha1</code>, <code>sha1-8</code>, <code>umac-128</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v290-2023-04-29" dir="auto"><a href="#v290-2023-04-29">v2.9.0 (2023-04-29)</a></h3>
<ul dir="auto">
<li>Dropped support for Python 3.6, as it reached EOL at the end of 2021.</li>
<li>Added Ubuntu Server &amp; Client 22.04 hardening policies.</li>
<li>Removed experimental warning tag from <code>sntrup761x25519-sha512@openssh.com</code>.</li>
<li>Updated CVE database; credit <a href="https://github.com/noraj">Alexandre Zanni</a>.</li>
<li>Added <code>-g</code> and <code>--gex-test</code> for granular GEX modulus size tests; credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Snap packages now print more user-friendly error messages when permission errors are encountered.</li>
<li>JSON 'target' field now always includes port number; credit <a href="https://github.com/tomatohater1337">tomatohater1337</a>.</li>
<li>JSON output now includes recommendations and CVE data.</li>
<li>Mixed host key/CA key types (i.e.: RSA host keys signed with ED25519 CAs, etc.) are now properly handled.</li>
<li>Warnings are now printed for 2048-bit moduli; partial credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>SHA-1 algorithms now cause failures.</li>
<li>CBC mode ciphers are now warnings instead of failures.</li>
<li>Generic failure/warning messages replaced with more specific reasons (i.e.: 'using weak cipher' =&gt; 'using broken RC4 cipher').</li>
<li>Updated built-in policies to include missing host key size information.</li>
<li>Added built-in policies for OpenSSH 8.8, 8.9, 9.0, 9.1, 9.2, and 9.3.</li>
<li>Added 33 new host keys: <code>dsa2048-sha224@libassh.org</code>, <code>dsa2048-sha256@libassh.org</code>, <code>dsa3072-sha256@libassh.org</code>, <code>ecdsa-sha2-1.3.132.0.10-cert-v01@openssh.com</code>, <code>eddsa-e382-shake256@libassh.org</code>, <code>eddsa-e521-shake256@libassh.org</code>, <code>null</code>, <code>pgp-sign-dss</code>, <code>pgp-sign-rsa</code>, <code>spki-sign-dss</code>, <code>spki-sign-rsa</code>, <code>ssh-dss-sha224@ssh.com</code>, <code>ssh-dss-sha384@ssh.com</code>, <code>ssh-dss-sha512@ssh.com</code>, <code>ssh-ed448-cert-v01@openssh.com</code>, <code>ssh-rsa-sha224@ssh.com</code>, <code>ssh-rsa-sha2-256</code>, <code>ssh-rsa-sha2-512</code>, <code>ssh-rsa-sha384@ssh.com</code>, <code>ssh-rsa-sha512@ssh.com</code>, <code>ssh-xmss-cert-v01@openssh.com</code>, <code>ssh-xmss@openssh.com</code>, <code>webauthn-sk-ecdsa-sha2-nistp256@openssh.com</code>, <code>x509v3-ecdsa-sha2-1.3.132.0.10</code>, <code>x509v3-sign-dss-sha1</code>, <code>x509v3-sign-dss-sha224@ssh.com</code>, <code>x509v3-sign-dss-sha256@ssh.com</code>, <code>x509v3-sign-dss-sha384@ssh.com</code>, <code>x509v3-sign-dss-sha512@ssh.com</code>, <code>x509v3-sign-rsa-sha1</code>, <code>x509v3-sign-rsa-sha224@ssh.com</code>, <code>x509v3-sign-rsa-sha384@ssh.com</code>, <code>x509v3-sign-rsa-sha512@ssh.com</code>.</li>
<li>Added 46 new key exchanges: <code>diffie-hellman-group14-sha224@ssh.com</code>, <code>diffie-hellman_group17-sha512</code>, <code>diffie-hellman-group-exchange-sha224@ssh.com</code>, <code>diffie-hellman-group-exchange-sha384@ssh.com</code>, <code>ecdh-sha2-1.2.840.10045.3.1.1</code>, <code>ecdh-sha2-1.2.840.10045.3.1.7</code>, <code>ecdh-sha2-1.3.132.0.1</code>, <code>ecdh-sha2-1.3.132.0.16</code>, <code>ecdh-sha2-1.3.132.0.26</code>, <code>ecdh-sha2-1.3.132.0.27</code>, <code>ecdh-sha2-1.3.132.0.33</code>, <code>ecdh-sha2-1.3.132.0.34</code>, <code>ecdh-sha2-1.3.132.0.35</code>, <code>ecdh-sha2-1.3.132.0.36</code>, <code>ecdh-sha2-1.3.132.0.37</code>, <code>ecdh-sha2-1.3.132.0.38</code>, <code>ecdh-sha2-4MHB+NBt3AlaSRQ7MnB4cg==</code>, <code>ecdh-sha2-5pPrSUQtIaTjUSt5VZNBjg==</code>, <code>ecdh-sha2-9UzNcgwTlEnSCECZa7V1mw==</code>, <code>ecdh-sha2-D3FefCjYoJ/kfXgAyLddYA==</code>, <code>ecdh-sha2-h/SsxnLCtRBh7I9ATyeB3A==</code>, <code>ecdh-sha2-m/FtSAmrV4j/Wy6RVUaK7A==</code>, <code>ecdh-sha2-mNVwCXAoS1HGmHpLvBC94w==</code>, <code>ecdh-sha2-qCbG5Cn/jjsZ7nBeR7EnOA==</code>, <code>ecdh-sha2-qcFQaMAMGhTziMT0z+Tuzw==</code>, <code>ecdh-sha2-VqBg4QRPjxx1EXZdV0GdWQ==</code>, <code>ecdh-sha2-wiRIU8TKjMZ418sMqlqtvQ==</code>, <code>ecdh-sha2-zD/b3hu/71952ArpUG4OjQ==</code>, <code>ecmqv-sha2</code>, <code>gss-13.3.132.0.10-sha256-*</code>, <code>gss-curve25519-sha256-*</code>, <code>gss-curve448-sha512-*</code>, <code>gss-gex-sha1-*</code>, <code>gss-gex-sha256-*</code>, <code>gss-group14-sha1-*</code>, <code>gss-group14-sha256-*</code>, <code>gss-group15-sha512-*</code>, <code>gss-group16-sha512-*</code>, <code>gss-group17-sha512-*</code>, <code>gss-group18-sha512-*</code>, <code>gss-group1-sha1-*</code>, <code>gss-nistp256-sha256-*</code>, <code>gss-nistp384-sha256-*</code>, <code>gss-nistp521-sha512-*</code>, <code>m383-sha384@libassh.org</code>, <code>m511-sha512@libassh.org</code>.</li>
<li>Added 28 new ciphers: <code>3des-cfb</code>, <code>3des-ecb</code>, <code>3des-ofb</code>, <code>blowfish-cfb</code>, <code>blowfish-ecb</code>, <code>blowfish-ofb</code>, <code>camellia128-cbc@openssh.org</code>, <code>camellia128-ctr@openssh.org</code>, <code>camellia192-cbc@openssh.org</code>, <code>camellia192-ctr@openssh.org</code>, <code>camellia256-cbc@openssh.org</code>, <code>camellia256-ctr@openssh.org</code>, <code>cast128-cfb</code>, <code>cast128-ecb</code>, <code>cast128-ofb</code>, <code>cast128-12-cbc@ssh.com</code>, <code>idea-cfb</code>, <code>idea-ecb</code>, <code>idea-ofb</code>, <code>rijndael-cbc@ssh.com</code>, <code>seed-ctr@ssh.com</code>, <code>serpent128-gcm@libassh.org</code>, <code>serpent256-gcm@libassh.org</code>, <code>twofish128-gcm@libassh.org</code>, <code>twofish256-gcm@libassh.org</code>, <code>twofish-cfb</code>, <code>twofish-ecb</code>, <code>twofish-ofb</code></li>
<li>Added 5 new MACs: <code>hmac-sha1-96@openssh.com</code>, <code>hmac-sha224@ssh.com</code>, <code>hmac-sha256-2@ssh.com</code>, <code>hmac-sha384@ssh.com</code>, <code>hmac-whirlpool</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v250-2021-08-26" dir="auto"><a href="#v250-2021-08-26">v2.5.0 (2021-08-26)</a></h3>
<ul dir="auto">
<li>Fixed crash when running host key tests.</li>
<li>Handles server connection failures more gracefully.</li>
<li>Now prints JSON with indents when <code>-jj</code> is used (useful for debugging).</li>
<li>Added MD5 fingerprints to verbose output.</li>
<li>Added <code>-d</code>/<code>--debug</code> option for getting debugging output; credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Updated JSON output to include MD5 fingerprints.  Note that this results in a breaking change in the 'fingerprints' dictionary format.</li>
<li>Updated OpenSSH 8.1 (and earlier) policies to include <code>rsa-sha2-512</code> and <code>rsa-sha2-256</code>.</li>
<li>Added OpenSSH v8.6 &amp; v8.7 policies.</li>
<li>Added 3 new key exchanges: <code>gss-gex-sha1-eipGX3TCiQSrx573bT1o1Q==</code>, <code>gss-group1-sha1-eipGX3TCiQSrx573bT1o1Q==</code>, and <code>gss-group14-sha1-eipGX3TCiQSrx573bT1o1Q==</code>.</li>
<li>Added 3 new MACs: <code>hmac-ripemd160-96</code>, <code>AEAD_AES_128_GCM</code>, and <code>AEAD_AES_256_GCM</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v240-2021-02-23" dir="auto"><a href="#v240-2021-02-23">v2.4.0 (2021-02-23)</a></h3>
<ul dir="auto">
<li>Added multi-threaded scanning support.</li>
<li>Added built-in Windows manual page (see <code>-m</code>/<code>--manual</code>); credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Added version check for OpenSSH user enumeration (CVE-2018-15473).</li>
<li>Added deprecation note to host key types based on SHA-1.</li>
<li>Added extra warnings for SSHv1.</li>
<li>Added built-in hardened OpenSSH v8.5 policy.</li>
<li>Upgraded warnings to failures for host key types based on SHA-1.</li>
<li>Fixed crash when receiving unexpected response during host key test.</li>
<li>Fixed hang against older Cisco devices during host key test &amp; gex test.</li>
<li>Fixed improper termination while scanning multiple targets when one target returns an error.</li>
<li>Dropped support for Python 3.5 (which reached EOL in Sept. 2020).</li>
<li>Added 1 new key exchange: <code>sntrup761x25519-sha512@openssh.com</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v231-2020-10-28" dir="auto"><a href="#v231-2020-10-28">v2.3.1 (2020-10-28)</a></h3>
<ul dir="auto">
<li>Now parses public key sizes for <code>rsa-sha2-256-cert-v01@openssh.com</code> and <code>rsa-sha2-512-cert-v01@openssh.com</code> host key types.</li>
<li>Flag <code>ssh-rsa-cert-v01@openssh.com</code> as a failure due to SHA-1 hash.</li>
<li>Fixed bug in recommendation output which suppressed some algorithms inappropriately.</li>
<li>Built-in policies now include CA key requirements (if certificates are in use).</li>
<li>Lookup function (<code>--lookup</code>) now performs case-insensitive lookups of similar algorithms; credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Migrated pre-made policies from external files to internal database.</li>
<li>Split single 3,500 line script into many files (by class).</li>
<li>Added setup.py support; credit <a href="https://github.com/gschaffner">Ganden Schaffner</a>.</li>
<li>Added 1 new cipher: <code>des-cbc@ssh.com</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v230-2020-09-27" dir="auto"><a href="#v230-2020-09-27">v2.3.0 (2020-09-27)</a></h3>
<ul dir="auto">
<li>Added new policy auditing functionality to test adherence to a hardening guide/standard configuration (see <code>-L</code>/<code>--list-policies</code>, <code>-M</code>/<code>--make-policy</code> and <code>-P</code>/<code>--policy</code>).  For an in-depth tutorial, see <a href="https://www.positronsecurity.com/blog/2020-09-27-ssh-policy-configuration-checks-with-ssh-audit/" rel="nofollow">https://www.positronsecurity.com/blog/2020-09-27-ssh-policy-configuration-checks-with-ssh-audit/</a>.</li>
<li>Created new man page (see <code>ssh-audit.1</code> file).</li>
<li>1024-bit moduli upgraded from warnings to failures.</li>
<li>Many Python 2 code clean-ups, testing framework improvements, pylint &amp; flake8 fixes, and mypy type comments; credit <a href="https://github.com/jugmac00">Jürgen Gmach</a>.</li>
<li>Added feature to look up algorithms in internal database (see <code>--lookup</code>); credit <a href="https://github.com/thecliguy">Adam Russell</a>.</li>
<li>Suppress recommendation of token host key types.</li>
<li>Added check for use-after-free vulnerability in PuTTY v0.73.</li>
<li>Added 11 new host key types: <code>ssh-rsa1</code>, <code>ssh-dss-sha256@ssh.com</code>, <code>ssh-gost2001</code>, <code>ssh-gost2012-256</code>, <code>ssh-gost2012-512</code>, <code>spki-sign-rsa</code>, <code>ssh-ed448</code>, <code>x509v3-ecdsa-sha2-nistp256</code>, <code>x509v3-ecdsa-sha2-nistp384</code>, <code>x509v3-ecdsa-sha2-nistp521</code>, <code>x509v3-rsa2048-sha256</code>.</li>
<li>Added 8 new key exchanges: <code>diffie-hellman-group1-sha256</code>, <code>kexAlgoCurve25519SHA256</code>, <code>Curve25519SHA256</code>, <code>gss-group14-sha256-</code>, <code>gss-group15-sha512-</code>, <code>gss-group16-sha512-</code>, <code>gss-nistp256-sha256-</code>, <code>gss-curve25519-sha256-</code>.</li>
<li>Added 5 new ciphers: <code>blowfish</code>, <code>AEAD_AES_128_GCM</code>, <code>AEAD_AES_256_GCM</code>, <code>crypticore128@ssh.com</code>, <code>seed-cbc@ssh.com</code>.</li>
<li>Added 3 new MACs: <code>chacha20-poly1305@openssh.com</code>, <code>hmac-sha3-224</code>, <code>crypticore-mac@ssh.com</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v220-2020-03-11" dir="auto"><a href="#v220-2020-03-11">v2.2.0 (2020-03-11)</a></h3>
<ul dir="auto">
<li>Marked host key type <code>ssh-rsa</code> as weak due to <a href="https://eprint.iacr.org/2020/014.pdf" rel="nofollow">practical SHA-1 collisions</a>.</li>
<li>Added Windows builds.</li>
<li>Added 10 new host key types: <code>ecdsa-sha2-1.3.132.0.10</code>, <code>x509v3-sign-dss</code>, <code>x509v3-sign-rsa</code>, <code>x509v3-sign-rsa-sha256@ssh.com</code>, <code>x509v3-ssh-dss</code>, <code>x509v3-ssh-rsa</code>, <code>sk-ecdsa-sha2-nistp256-cert-v01@openssh.com</code>, <code>sk-ecdsa-sha2-nistp256@openssh.com</code>, <code>sk-ssh-ed25519-cert-v01@openssh.com</code>, and <code>sk-ssh-ed25519@openssh.com</code>.</li>
<li>Added 18 new key exchanges: <code>diffie-hellman-group14-sha256@ssh.com</code>, <code>diffie-hellman-group15-sha256@ssh.com</code>, <code>diffie-hellman-group15-sha384@ssh.com</code>, <code>diffie-hellman-group16-sha384@ssh.com</code>, <code>diffie-hellman-group16-sha512@ssh.com</code>, <code>diffie-hellman-group18-sha512@ssh.com</code>, <code>ecdh-sha2-curve25519</code>, <code>ecdh-sha2-nistb233</code>, <code>ecdh-sha2-nistb409</code>, <code>ecdh-sha2-nistk163</code>, <code>ecdh-sha2-nistk233</code>, <code>ecdh-sha2-nistk283</code>, <code>ecdh-sha2-nistk409</code>, <code>ecdh-sha2-nistp192</code>, <code>ecdh-sha2-nistp224</code>, <code>ecdh-sha2-nistt571</code>, <code>gss-gex-sha1-</code>, and <code>gss-group1-sha1-</code>.</li>
<li>Added 9 new ciphers: <code>camellia128-cbc</code>, <code>camellia128-ctr</code>, <code>camellia192-cbc</code>, <code>camellia192-ctr</code>, <code>camellia256-cbc</code>, <code>camellia256-ctr</code>, <code>aes128-gcm</code>, <code>aes256-gcm</code>, and <code>chacha20-poly1305</code>.</li>
<li>Added 2 new MACs: <code>aes128-gcm</code> and <code>aes256-gcm</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v211-2019-11-26" dir="auto"><a href="#v211-2019-11-26">v2.1.1 (2019-11-26)</a></h3>
<ul dir="auto">
<li>Added 2 new host key types: <code>rsa-sha2-256-cert-v01@openssh.com</code>, <code>rsa-sha2-512-cert-v01@openssh.com</code>.</li>
<li>Added 2 new ciphers: <code>des</code>, <code>3des</code>.</li>
<li>Added 3 new PuTTY vulnerabilities.</li>
<li>During client testing, client IP address is now listed in output.</li>
</ul>
<h3 tabindex="-1" id="user-content-v210-2019-11-14" dir="auto"><a href="#v210-2019-11-14">v2.1.0 (2019-11-14)</a></h3>
<ul dir="auto">
<li>Added client software auditing functionality (see <code>-c</code> / <code>--client-audit</code> option).</li>
<li>Added JSON output option (see <code>-j</code> / <code>--json</code> option; credit <a href="https://github.com/x-way">Andreas Jaggi</a>).</li>
<li>Fixed crash while scanning Solaris Sun_SSH.</li>
<li>Added 9 new key exchanges: <code>gss-group1-sha1-toWM5Slw5Ew8Mqkay+al2g==</code>, <code>gss-gex-sha1-toWM5Slw5Ew8Mqkay+al2g==</code>, <code>gss-group14-sha1-</code>, <code>gss-group14-sha1-toWM5Slw5Ew8Mqkay+al2g==</code>, <code>gss-group14-sha256-toWM5Slw5Ew8Mqkay+al2g==</code>, <code>gss-group15-sha512-toWM5Slw5Ew8Mqkay+al2g==</code>, <code>diffie-hellman-group15-sha256</code>, <code>ecdh-sha2-1.3.132.0.10</code>, <code>curve448-sha512</code>.</li>
<li>Added 1 new host key type: <code>ecdsa-sha2-1.3.132.0.10</code>.</li>
<li>Added 4 new ciphers: <code>idea-cbc</code>, <code>serpent128-cbc</code>, <code>serpent192-cbc</code>, <code>serpent256-cbc</code>.</li>
<li>Added 6 new MACs: <code>hmac-sha2-256-96-etm@openssh.com</code>, <code>hmac-sha2-512-96-etm@openssh.com</code>, <code>hmac-ripemd</code>, <code>hmac-sha256-96@ssh.com</code>, <code>umac-32@openssh.com</code>, <code>umac-96@openssh.com</code>.</li>
</ul>
<h3 tabindex="-1" id="user-content-v200-2019-08-29" dir="auto"><a href="#v200-2019-08-29">v2.0.0 (2019-08-29)</a></h3>
<ul dir="auto">
<li>Forked from <a href="https://github.com/arthepsy/ssh-audit">https://github.com/arthepsy/ssh-audit</a> (development was stalled, and developer went MIA).</li>
<li>Added RSA host key length test.</li>
<li>Added RSA certificate key length test.</li>
<li>Added Diffie-Hellman modulus size test.</li>
<li>Now outputs host key fingerprints for RSA and ED25519.</li>
<li>Added 5 new key exchanges: <code>sntrup4591761x25519-sha512@tinyssh.org</code>, <code>diffie-hellman-group-exchange-sha256@ssh.com</code>, <code>diffie-hellman-group-exchange-sha512@ssh.com</code>, <code>diffie-hellman-group16-sha256</code>, <code>diffie-hellman-group17-sha512</code>.</li>
<li>Added 3 new encryption algorithms: <code>des-cbc-ssh1</code>, <code>blowfish-ctr</code>, <code>twofish-ctr</code>.</li>
<li>Added 10 new MACs: <code>hmac-sha2-56</code>, <code>hmac-sha2-224</code>, <code>hmac-sha2-384</code>, <code>hmac-sha3-256</code>, <code>hmac-sha3-384</code>, <code>hmac-sha3-512</code>, <code>hmac-sha256</code>, <code>hmac-sha256@ssh.com</code>, <code>hmac-sha512</code>, <code>hmac-512@ssh.com</code>.</li>
<li>Added command line argument (<code>-t</code> / <code>--timeout</code>) for connection &amp; reading timeouts.</li>
<li>Updated CVEs for libssh &amp; Dropbear.</li>
</ul>
<h3 tabindex="-1" id="user-content-v170-2016-10-26" dir="auto"><a href="#v170-2016-10-26">v1.7.0 (2016-10-26)</a></h3>
<ul dir="auto">
<li>implement options to allow specify IPv4/IPv6 usage and order of precedence</li>
<li>implement option to specify remote port (old behavior kept for compatibility)</li>
<li>add colors support for Microsoft Windows via optional colorama dependency</li>
<li>fix encoding and decoding issues, add tests, do not crash on encoding errors</li>
<li>use mypy-lang for static type checking and verify all code</li>
</ul>
<h3 tabindex="-1" id="user-content-v160-2016-10-14" dir="auto"><a href="#v160-2016-10-14">v1.6.0 (2016-10-14)</a></h3>
<ul dir="auto">
<li>implement algorithm recommendations section (based on recognized software)</li>
<li>implement full libssh support (version history, algorithms, security, etc)</li>
<li>fix SSH-1.99 banner recognition and version comparison functionality</li>
<li>do not output empty algorithms (happens for misconfigured servers)</li>
<li>make consistent output for Python 3.x versions</li>
<li>add a lot more tests (conf, banner, software, SSH1/SSH2, output, etc)</li>
<li>use Travis CI to test for multiple Python versions (2.6-3.5, pypy, pypy3)</li>
</ul>
<h3 tabindex="-1" id="user-content-v150-2016-09-20" dir="auto"><a href="#v150-2016-09-20">v1.5.0 (2016-09-20)</a></h3>
<ul dir="auto">
<li>create security section for related security information</li>
<li>match and output assigned CVE list and security issues for Dropbear SSH</li>
<li>implement full SSH1 support with fingerprint information</li>
<li>automatically fallback to SSH1 on protocol mismatch</li>
<li>add new options to force SSH1 or SSH2 (both allowed by default)</li>
<li>parse banner information and convert it to specific software and OS version</li>
<li>do not use padding in batch mode</li>
<li>several fixes (Cisco sshd, rare hangs, error handling, etc)</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020160902" dir="auto"><a href="#v1020160902">v1.0.20160902</a></h3>
<ul dir="auto">
<li>implement batch output option</li>
<li>implement minimum output level option</li>
<li>fix compatibility with Python 2.6</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020160812" dir="auto"><a href="#v1020160812">v1.0.20160812</a></h3>
<ul dir="auto">
<li>implement SSH version compatibility feature</li>
<li>fix wrong mac algorithm warning</li>
<li>fix Dropbear SSH version typo</li>
<li>parse pre-banner header</li>
<li>better errors handling</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020160803" dir="auto"><a href="#v1020160803">v1.0.20160803</a></h3>
<ul dir="auto">
<li>use OpenSSH 7.3 banner</li>
<li>add new key-exchange algorithms</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020160207" dir="auto"><a href="#v1020160207">v1.0.20160207</a></h3>
<ul dir="auto">
<li>use OpenSSH 7.2 banner</li>
<li>additional warnings for OpenSSH 7.2</li>
<li>fix OpenSSH 7.0 failure messages</li>
<li>add rijndael-cbc failure message from OpenSSH 6.7</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020160105" dir="auto"><a href="#v1020160105">v1.0.20160105</a></h3>
<ul dir="auto">
<li>multiple additional warnings</li>
<li>support for none algorithm</li>
<li>better compression handling</li>
<li>ensure reading enough data (fixes few Linux SSH)</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020151230" dir="auto"><a href="#v1020151230">v1.0.20151230</a></h3>
<ul dir="auto">
<li>Dropbear SSH support</li>
</ul>
<h3 tabindex="-1" id="user-content-v1020151223" dir="auto"><a href="#v1020151223">v1.0.20151223</a></h3>
<ul dir="auto">
<li>initial version</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finland to vote against the EU mass surveillance and encryption ban directive (409 pts)]]></title>
            <link>https://dawn.fi/uutiset/2023/10/14/eu-csam-suomi-eduskunta-kanta</link>
            <guid>37891886</guid>
            <pubDate>Sun, 15 Oct 2023 18:01:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dawn.fi/uutiset/2023/10/14/eu-csam-suomi-eduskunta-kanta">https://dawn.fi/uutiset/2023/10/14/eu-csam-suomi-eduskunta-kanta</a>, See on <a href="https://news.ycombinator.com/item?id=37891886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<p>Kuten <a href="https://dawn.fi/uutiset/2023/10/12/suomi-csam-suuri-valiokunta">uutisoimme aiemmin tällä viikolla</a>, Suomen eduskunnan oli tarkoitus ottaa tämän viikon perjantaina <i>(13.10.2023)</i> lopullisesti kantaa <strong>Euroopan Unionin</strong> niin kutsuttuun <strong>CSAM-asetukseen</strong>.</p><p>Kyseinen asetus toteutuessaan nykymuodossa käytännössä kieltäisi vahvan, päästä päähän ulottuvan salauksen koko Euroopassa, kaikissa viestinnän muodoissa. Tavalliselle kuluttajalle kenties tunnetuin esimerkki vahvasta salauksesta ovat pikaviestimet, kuten <strong>WhatsApp</strong> ja <strong>Signal</strong>. Vahvasti salatut pikaviestimet ovat mahdottomia murtaa ja viestejä voi lukea vain viestin lähettäjä sekä sen tarkoitettu vastaanottaja.</p><p>EU haluaa, että Euroopan viranomaiset pääsisivät murtamaan tämän välin siten, että kaikkea viestintää voitaisiin seurata tekoälyn avulla ja etsiä sieltä epäilyttävää materiaalia, ilman erillistä oikeuden määräystä. Eli salaus pitäisi murtaa - ja rakentaa kaikkea viestintää seuraava massavalvonta.</p><h2>Suomen kanta</h2><p>Suomessa asiaan otettiin kantaa perjantaina, kun eduskunnan <strong>Suuri valiokunta</strong> antoi asiasta päätöksensä. Suuren valiokunnan päätös pohjautuu useilta eri tahoilta kerättyihin asiantuntijalausuntoihin, mukana mm. IT-alan edustajat, perustuslakivaliokunta, jne.</p>
			<p>Suuren valiokunnan kanta sitoo Suomen hallitusta, kun hallitus alkaa neuvottelemaan asetuksesta EU:ssa, eli hallituksen on pakko noudattaa valiokunnan ohjeistusta.</p><p><a href="https://www.eduskunta.fi/FI/vaski/Lausunto/Sivut/SuVL_7+2023.aspx" target="_blank">Suuren valiokunnan päätös</a> saatiin perjantaina iltapäivällä ja sen voisi tiivistää termiin "varovainen ei".</p><p>Valiokunta kehui CSAM-esityksen taustalla olevaa ideaa, eli lasten suojelua verkon vaaroilta:</p><blockquote>Suuri valiokunta katsoo, että asetusehdotuksella on erittäin painava tavoite tehokkaasti ennaltaehkäistä ja torjua lapsiin kohdistuvaa verkkovälitteistä seksuaaliväkivaltaa EU-tason toimin. Valiokunta pitää tärkeänä, että EU-tasolla syntyy selkeä ja sitova oikeudellinen kehys, jolla voidaan tehostaa hyväksikäytön havaitsemista, ilmoittamista ja poistamista. Valtioneuvoston tavoin suuri valiokunta painottaa lapsen edun merkitystä, kun punnitaan ehdotuksen eri osien suhdetta perustuslakiin ja perus- ja ihmisoikeuksiin.</blockquote><p>Mutta siihen sitten asetuksen kanssa myötäily pitkälti loppuukin, sillä valiokunta nosti esiin CSAM-esityksen lukuisia ongelmakohtia.</p>
			<p>Ensinnäkin valiokunta on sitä mieltä, että päästä päähän salausta ei saa murtaa, sillä se murentaisi tietoturvaa:</p><blockquote>Suuri valiokunta katsoo liikenne- ja viestintävaliokunnan tavoin, että jatkoneuvotteluissa on erityisen tärkeä varmistaa, etteivät tunnistamismääräykset johda päästä päähän -salauksen tai muiden vastaavien tietoturvatoimenpiteiden yleiseen heikentämiseen, purkamiseen tai käytön rajoittamiseen ja tätä kautta viestinnän sekä viestinnän palvelujen tietoturvan ja kyberturvallisuuden tason heikkenemiseen. </blockquote><p>Lisäksi valiokunta katsoo, että ehdotusta ei voida kannattaa sellaisessa muodossa, että se sallisi massavalvonnan. Valiokunnan mukaan valvontaa pitäisi tehdä ainoastaan tunnistettuihin kohteisiin, eikä siis koko kansan tasolla. Eli valiokunta tyrmäsi ehdotuksen siitä, että kaikkien ihmisten kaikkia viestejä aletaan skannaamaan, josko sieltä löytyisi jotain epäilyttävää.</p><p>Eli Suomi ei voi suuren valiokunnan lausunnon pohjalta hyväksyä ehdotusta tällaisenaan. </p><h2>Miten asia etenee?</h2><p>EU-maat äänestävät ehdotuksesta lokakuun lopulla. Tuolloin ehdotus menee läpi, mikäli sitä ei vastusta sellainen määrä maita, jotka edustavat yhteensä vähintään 35 prosenttia EU-kansalaisista.</p>
			<center><blockquote><p lang="fi" dir="ltr">35% määrävähemmistö edustetuista EU-kansalaisista. Neuvoston sivulla on näppärä laskuri: <a href="https://t.co/JCZP43ThCX">https://t.co/JCZP43ThCX</a></p>-- Asko Metsola (@AskoMetsola) <a href="https://twitter.com/AskoMetsola/status/1712819824567484795?ref_src=twsrc%5Etfw">October 13, 2023</a></blockquote> </center><p>Tiedossa on, että ainakin Saksa, Itävalta ja Viro vastustavat ehdotusta. Kannattajia on tiedossa selkeästi enemmän, mm. Espanja, Tanska, Unkari ja Irlanti kannattavat komission ehdotusta.</p><p>Päätöstä eivät ole vielä tehneet läheskään kaikki maat, sillä päätöstä odotetaan mm. Ranskan, Ruotsin, Belgian, Hollannin ja Portugalin osalta.</p>
								
								
									
										
									
								

								<!--added sharing bar-->
								<div>
									<!-- Facebook -->
									<p><a href="https://www.facebook.com/sharer.php?u=https://dawn.fi/uutiset/2023/10/14/eu-csam-suomi-eduskunta-kanta" target="_blank" rel="noreferrer">
										<img src="https://cdn.afterdawn.fi/x2fi/responsive/img/facebook.png" alt="Jaa Facebookissa" width="35" height="35" loading="lazy">
									</a></p><!-- Twitter -->
									<p><a href="https://twitter.com/share?url=https://dawn.fi/uutiset/2023/10/14/eu-csam-suomi-eduskunta-kanta" target="_blank" rel="noreferrer">
										<img src="https://cdn.afterdawn.fi/x2fi/responsive/img/twitter.png" alt="Jaa Twitterissä" width="35" height="35" loading="lazy">
									</a></p><!-- Whatsapp -->
									<!-- Sharing icon -->
									</div>
								<!--added sharing bar end-->
								
								

							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Async Rust? (193 pts)]]></title>
            <link>https://without.boats/blog/why-async-rust/</link>
            <guid>37891020</guid>
            <pubDate>Sun, 15 Oct 2023 16:18:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://without.boats/blog/why-async-rust/">https://without.boats/blog/why-async-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=37891020">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Async/await syntax in Rust was initially released to much fanfare and excitement. To quote <a href="https://news.ycombinator.com/item?id=21473418">Hacker
News</a> at the time:</p><blockquote><p>This is going to open the flood gates. I am sure lot of people were just waiting for this moment
for Rust adoption. I for one was definitely in this boat.</p><p>Also, this has all the goodness: open-source, high quality engineering, design in open, large
contributors to a complex piece of software. Truly inspiring!</p></blockquote><p>Recently, the reception has been a bit more mixed. To a quote a comment on <a href="https://news.ycombinator.com/item?id=37436413">Hacker News</a> again,
discussing a recent blog post on the subject:</p><blockquote><p>I genuinely can’t understand how anybody could look at the mess that’s Rust’s async and think that
it was a good design for a language that already had the reputation of being very complicated to
write.</p><p>I tried to get it, I really did, but my god what a massive mess that is. And it contaminates
everything it touches, too. I really love Rust and I do most of my coding in it these days, but
every time I encounter async-heavy Rust code my jaw clenches and my vision blurs.</p></blockquote><p>Of course, neither of these comments are completely representative: even four years ago, some people
had pointed concerns. And in the same thread as this comment about jaws clenching and vision
blurring, there were many people defending async Rust with equal fervor. But I don’t think I would
be out of pocket to say that the nay-sayers have grown more numerous and their tone more strident as
time has gone on. To some extent this is just the natural progression of the hype cycle, but I also
think as we have become more distant from the original design process, some of the context has been
lost.</p><p>Between 2017 and 2019, I drove the design of async/await syntax, in collaboration with others and
building on the work of those who came before me. Forgive me if I am put a bit off when someone says
that they don’t know how anyone could look at that “mess” and “think that it was a good design,” and
please indulge me in this imperfectly organized and overly long explanation of how async Rust came
to exist, what its purpose was, and why, in my opinion, for Rust there was no viable alternative. I
hope that along the way I might shed more light on the design of Rust in a broader and deeper sense,
at least slightly, and not merely regurgitate the justifications of the past.</p><h2 id="some-background-on-terminology">Some background on terminology</h2><p>The basic issue at stake in this debate is Rust’s decision to use a “stackless coroutine” approach
to implementing user-space concurrency. A lot of terms are thrown around in this discussion and its
reasonable not to be familiar with all of them.</p><p>The first concept we need to get straight is the very purpose of the feature: “user-space
concurrency.” The major operating systems present a set of fairly similar interfaces to achieve
concurrency: you can spawn threads, and perform IO on those threads using syscalls, which block that
thread until they complete. The problem with these interfaces is that they involve certain overheads
that can become a limiting factor when you want to achieve certain performance targets. These are
two-fold:</p><ol><li>Context-switching between the kernel and userspace is expensive in terms of CPU cycles.</li><li>OS threads have a large pre-allocated stack, which increases per-thread memory overhead.</li></ol><p>These limitations are fine up to a certain point, but for massively concurrent programs they do not
work. The solution is to use a non-blocking IO interface and schedule many concurrent operations on
a single OS thread. This can be done by the programmer “by hand,” but modern languages frequently
provide facilities to make this easier. Abstractly, languages have some way of dividing work into
tasks and scheduling those tasks onto threads. Rust’s system for this is async/await.</p><p>The first axis of choice in this design space is between <em>cooperative</em> and <em>preemptive</em> scheduling.
Must tasks “cooperatively” yield control back to the scheduling subsystem, or can they be
“preemptively” stopped at some point while they’re running, without the task being aware of it?</p><p>A term that gets thrown around a lot in these discussions is <em>coroutine</em>, and it is used in somewhat
contradictory ways. A coroutine is a function which can be paused and then later resumed. The big
ambiguity is that some people use the term “coroutine” to mean a function which has explicit syntax
for pausing and resuming it (this would correspond to a cooperatively scheduled task) and some
people use it to mean any function that can pause, even if the pause is performed implicitly by a
language runtime (this would also include a preemptively scheduled task). I prefer the first
definition, because it introduces some manner of meaningful distinction.</p><p><em>Goroutines</em>, on the other hand, are a Go language feature which enables concurrent, preemptively
scheduled tasks. They have an API that is the same as a thread, but it is implemented as part of the
language instead of as an operating system primitive, and in other languages they are often called
<em>virtual threads</em> or else <em>green threads.</em> So by my definition, goroutines are not coroutines, but
other people use the broader definition and say goroutines are a kind of coroutine. I’ll refer to
this approach as green threads, because that’s been the terminology used in Rust.</p><p>The second axis of choice is between a <em>stackful</em> and a <em>stackless</em> coroutine. A stackful coroutine
has a program stack in the same way that an OS thread has a program stack: as functions are called
as part of the coroutine, their frames are pushed on the stack; when the coroutine yields, the state
of the stack is saved so that it can be resumed from the same position. A stackless coroutine on
the other hand stores the state it needs to resume in a different way, such as in a continuation
or in a state machine. When it yields, the stack it was using is used by the operation that took
over from it, and when it resumes it takes back control of the stack and that continuation or state
machine is used to resume the coroutine where it left off.</p><p>One issue that is often brought up with async/await (in Rust and other languages) is the “function
coloring problem” - a complaint that in order to get the result of an async function, you need to
use a different operation (such as awaiting it) rather than call it normally. Both green threads and
stackful coroutine mechanisms can avoid this outcome, because it’s that special syntax that is used
to indicate that something special is happening to manage the stackless state of the coroutine
(what specifically depends on the language).</p><p>Rust’s async/await syntax is an example of a stackless coroutine mechanism: an async function is
compiled to a function which returns a <code>Future</code>, and that future is what is used to store the state
of the coroutine when it yields control. The basic question at hand in this debate is whether Rust
was correct to adopt this approach, or if it should have adopted a more Go-like “stackful” or “green
thread” approach, ideally without explicit syntax that “colors” functions.</p><h2 id="the-development-of-async-rust">The development of async Rust</h2><h2 id="green-threads">Green threads</h2><p>A third <a href="https://news.ycombinator.com/item?id=37791635">Hacker News</a> comment represents well the kind of remark that I often see in this
debate:</p><blockquote><p>The alternative concurrency model people want is structured concurrency via stackful coroutines
and channels on top of a work stealing executor.</p><p>Until someone does the work to demo that and compare it to async/await with futures I don’t think
there’s any productive discussion to be had.</p></blockquote><p>Setting aside the references to structured concurrency, channels and a work stealing executor
(completely orthogonal concerns), the bewildering thing about comments like this is that originally
Rust <em>did</em> have a stackful coroutine mechanism, in the form of green threads. It was removed in late
2014, shortly before the 1.0 release. Understanding the reason why will help us get to the bottom of
why Rust shipped async/await syntax.</p><p>A big issue for any green threading system - Rust’s or Go’s or any other language’s - is what to do
about the program stack for these threads. Remember that one of the goals of a user-space
concurrency mechanism is to reduce the memory overhead of the large, pre-allocated stack used by OS
threads. Therefore, green thread libraries tend to try to adopt a mechanism to spawn threads with
smaller stacks, and grow them only as needed.</p><p>One way to achieve this is so-called “segmented stacks,” in which the stack is a linked list of
small stack segments; when the stack grows beyond the bound of its segment, a new segment is added
to the list, and when it shrinks, that segment is removed. The problem with this technique is that
introduces a high variability in the cost of pushing a stack frame onto the stack. If the frame fits
in the current segment, this is basically free. If it doesn’t, it requires allocating a new segment.
A particularly pernicious version of this is when a function call in a hot loop requires allocating
a new segment. This adds an allocation and deallocation to every iteration of that loop, having a
significant impact on performance. And it is entirely opaque to users, because users don’t know how
deep the stack will be when a function is called. Both Rust and Go started with segmented stacks,
and then abandoned this approach for these reasons.</p><p>Another approach is called “stack copying.” In this case, a stack is more like a <code>Vec</code> than a linked
list: when the stack hits its limit, it is reallocated larger so that the limit isn’t hit. This
allows stacks to start small and grow as needed, without the downsides of segmented stacks. The
problem with this is that reallocating the stack means copying it, which means the stack will now be
at a new location in memory. Any pointers into the stack are now invalid, and there needs to be some
mechanism for updating them.</p><p><a href="https://blog.cloudflare.com/how-stacks-are-handled-in-go/">Go uses stack copying</a>, and benefits from the fact that in Go pointers into a stack can only
exist in the same stack, so it just needs to scan that stack to rewrite pointers. Even this requires
runtime type information which Rust doesn’t keep, but Rust also allows pointers into a stack that
aren’t stored inside that stack - they could be somewhere in the heap, or in the stack of another
thread. The problem of tracking these pointers is ultimately the same as the problem of garbage
collection, except that instead of freeing memory it is moving it. Rust could not adopt this
approach because Rust does not have a garbage collector, so in the end it could not adopt stack
copying. Instead, Rust solved the problem of segmented stacks by making its green threads large,
just like OS threads. But this eliminated one of the key advantages of green threads.</p><p>Even in a situation like Go, which can have resizing stacks, green threads carry certain unavoidable
costs when trying to integrate with libraries written in other languages. The C ABI, with its OS
stack, is the shared minimum of every language. Switching code from executing on a green thread to
running on the OS thread stack can be prohibitively expensive for FFI. Go just accepts this FFI
cost; C# recently <a href="https://github.com/dotnet/runtimelab/issues/2398">aborted an experiment</a> with green threads for this reason.</p><p>This was especially problematic for Rust, because Rust is designed to support use cases like
embedding a Rust library into a binary written in another language, and to run on embedded systems
that don’t have the clock cycles or memory to operate a virtual threading runtime. To attempt to
resolve this problem, the green threading runtime was made optional, and Rust could instead be
compiled to run on native threads, using blocking IO. This was designed to be a compile time
decision made by the final binary. Thus, for a time, there were two varieties of Rust, one of which
used blocking IO and native threads, and one of which used non-blocking IO and green threads, and
all code was intended to be compatible with both varieties. This did not play out well, and green
threads were removed from Rust as a result of <a href="https://github.com/rust-lang/rfcs/pull/230">RFC 230</a>, which enumerated the reasons:</p><ul><li>The abstraction over green and native threads was not “zero-cost,” and resulted in unavoidable
virtual calls and allocations when performing IO, which was not acceptable especially to native
code.</li><li>It forced native threads and green threads to support identical APIs, even when that didn’t make
sense.</li><li>It was not fully interoperable, because it was still possible to invoke native IO through FFI,
even on a green thread.</li></ul><p>Once green threads were removed, the problem of high performance user space concurrency remained.
The Future trait and later the async/await syntax were developed to resolve that problem. But to
understand that path, we need to take one further step back and look at Rust’s solution to a
different problem.</p><h2 id="iterators">Iterators</h2><p>I contend the true beginning of the journey to async Rust is to be found in an old <a href="https://web.archive.org/web/20140716172928/https://mail.mozilla.org/pipermail/rust-dev/2013-June/004599.html">mailing list
post</a> from 2013 by a former contributor named Daniel Micay. This post has nothing to do with
async/await or futures or non-blocking IO: it was a post about iterators. Micay proposed shifting
Rust to use what were called “external” iterators, and it was this shift - and its effectiveness in
combination with Rust’s ownership and borrowing model - that set Rust inexorably on the course
toward async/await. No one knew that at the time, obviously.</p><p>Rust had always prohibited mutating state through a binding that was aliased with another variable -
this edict “mutable XOR aliased” was as central to early Rust as it is today. But initially it
enforced it with different mechanisms, not with lifetime analysis. At the time, references were just
“argument modifiers,” similar in concept to things like the <a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/functions/#In-Out-Parameters">“inout” modifier</a> from
Swift. In 2012, Niko Matsakis had proposed and implemented the first version of Rust’s lifetime
analysis, promoting references to real types and enabling them to be embedded into structs.</p><p>Though the shift to lifetime analysis has been rightly recognized for its enormous impact in making
Rust what it is today, its symbiotic interaction with external iterators, and the fundamental
importance of that API to settling Rust into its current niche, has not received enough attention.
Before the adoption of “external” iterators, Rust used a kind of callback based approach to define
iterators, something that in modern Rust would look like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>enum</span> <span>ControlFlow</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>Break</span><span>,</span><span>
</span></span></span><span><span><span>    </span><span>Continue</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>trait</span><span> </span><span>Iterator</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>type</span> <span>Item</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>iterate</span><span>(</span><span>self</span><span>,</span><span> </span><span>f</span>: <span>impl</span><span> </span><span>FnMut</span><span>(</span><span>Self</span>::<span>Item</span><span>)</span><span> </span>-&gt; <span>ControlFlow</span><span>)</span><span> </span>-&gt; <span>ControlFlow</span><span>;</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Iterators defined this way call their callback on each element of the collection, unless it returns
<code>ControlFlow::Break</code>, in which case they are meant to stop iterating. The body of a <code>for</code> loop was
compiled to a closure that was passed to the iterator being looped over. Such iterators were much
easier to write than external iterators, but there are two key problems with this approach:</p><ol><li>The language couldn’t guarantee that iteration actually stops running when the loop says to
break, so you couldn’t rely on that for memory safety. This meant things like return references
from a loop was not possible, because the loop could actually continue.</li><li>They couldn’t be used to implement generic combinators that interleave multiple iterators, like
<code>zip</code>, because the API doesn’t support iterating alternatively through one iterator and then
another.</li></ol><p>Instead, Daniel Micay proposed to shift Rust to use “external” iterators, which completely resolve
these problems and have the interface Rust users are used to today:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>trait</span><span> </span><span>Iterator</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>type</span> <span>Item</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>next</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span>-&gt; <span>Option</span><span>&lt;</span><span>Self</span>::<span>Item</span><span>&gt;</span><span>;</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p><em>(Very well-informed readers will be aware that Rust’s Iterator has an a provided method called
<code>try_fold</code> which is functionally very similar to the internal iterator API and is used in the
definition of some other iterator combinators because it can result in better code generation. But
it isn’t the key underlying method by which all iterators are defined.)</em></p><p>External iterators integrated perfectly with Rust’s ownership and borrowing system because they
essentially compile to a struct which holds the state of iteration inside of itself, and which can
therefore contain references to data structures being iterated over just like any other struct. And
thanks to monomorphization, a complex iterator built by assembling multiple combinators also
compiled into a single struct, making it transparent to the optimizer. The only problem was that
they were harder to write by hand, because you need to define the state machine that will be used
for iteration. Foreshadowing future developments, Daniel Micay wrote at the time:</p><blockquote><p>In the future, Rust can have generators using a <code>yield</code> statement like C#, compiling down to a
fast state machine without requiring context switches, virtual functions or even closures. This
would eliminate the difficulty of coding recursive traversals by-hand with external iterators.</p></blockquote><p>Progress on generators has not moved swiftly, though an exciting <a href="https://github.com/rust-lang/rust/pull/116447">RFC</a> was recently published
that would suggest we may see this feature soon.</p><p>Even without generators, external iterators proved to be a great success, and the general value of
the technique was recognized. For example, Aria Beingessner used a similar approach in the “Entry
API” for accessing map entries. Tellingly, in the <a href="https://github.com/rust-lang/rfcs/pull/216">RFC</a> for the API, she refers to it as
“iterator-like.” What she means by this is that the API builds a state machine via series of
combinators, which presented itself to the compiler as highly legible and thus optimizable. This
technique had legs.</p><h2 id="futures">Futures</h2><p>When they needed to replace green threads, Aaron Turon and Alex Crichton began by copying the API
used in many other languages, which has come to be called futures or promises. APIs like this are
based on what is called a “continuation passing style.” A future defined in this way takes a
callback as an additional argument, called the continuation, and calls the continuation as its final
operation when the future completes. This is how this abstraction is defined in most languages, and
the async/await syntax of most languages is compiled into this sort of continuation passing style.</p><p>In Rust, that sort of API would have looked something like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>trait</span><span> </span><span>Future</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>type</span> <span>Output</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>schedule</span><span>(</span><span>self</span><span>,</span><span> </span><span>continuation</span>: <span>impl</span><span> </span><span>FnOnce</span><span>(</span><span>Self</span>::<span>Output</span><span>));</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Aaron Turon and Alex Crichton tried this approach, but as Aaron Turon wrote in an enlightening <a href="http://aturon.github.io/blog/2016/09/07/futures-design/">blog
post</a>, they quickly ran into the problem that using a continuation passing style too often
required allocating the callback. Turon gives the example of <code>join</code>: join takes two futures, and
runs them both concurrently. The continuation of join needs to be owned by <em>both</em> child futures,
because whichever of them finishes last needs to execute it. This ended up requiring reference
counting and allocations to implement, which wasn’t considered acceptable for Rust.</p><p>Instead, they examined how C programmers tend to implement async programming: in C, programmers
handle non blocking IO by building a state machine. What they wanted was a definition of Future that
could be compiled into the sort of state machine that C programmers would write by hand. After some
experimentation, they landed on what they called a “readiness-based” approach:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>enum</span> <span>Poll</span><span>&lt;</span><span>T</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>Ready</span><span>(</span><span>T</span><span>),</span><span>
</span></span></span><span><span><span>    </span><span>Pending</span><span>,</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>trait</span><span> </span><span>Future</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>type</span> <span>Output</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>poll</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span>-&gt; <span>Poll</span><span>&lt;</span><span>Self</span>::<span>Output</span><span>&gt;</span><span>;</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>Instead of storing a continuation, a future is polled by some external executor. When a future is
pending, it stores a way to wake that executor, which it will execute when it is ready to be polled
again. By inverting control in this way, they no longer needed to store a callback for when a future
completes, which allowed them to represent a future as a single state machine. They built a library
of combinators on top of this interface, that all would be compiled into a single state machine.</p><p>Switching from a callback-based approach to an external driver, compiling a set of combinators into
a single state machine, even the exact specification of these two APIs: all of this should sound
very familiar if you read the previous section. <strong>The shift from continuations to polling is exactly
the same shift that was performed with iterators in 2013!</strong> Once again, it was Rust’s ability to
handle structs with lifetimes and therefore to handle stackless coroutines which borrow state from
outside themselves that allowed it to optimally represent futures as state machines without
violating memory safety. This pattern of building single-object state machines out of smaller
components, whether applied to iterators or futures, is a key part of how Rust works. It falls out
of the language almost naturally.</p><p>I’ll pause for a moment to highlight one difference between iterators and futures: combinators that
interleave two iterators, like <code>Zip</code>, are not even possible with a callback-like approach, unless
your language has some sort of native support for coroutines you’re building on top of. On the other
hand, if you want to interleave two futures, like <code>Join</code>, the continuation based approach can
support that: it just carries some runtime costs. This explains why external iterators are common in
other languages, but Rust is unique in applying this transform to futures.</p><p>In its initial iteration, the futures library was designed with the principle that users would
construct futures in much the same way that they constructed iterators: low-level library authors
would use the <code>Future</code> trait, whereas users writing applications would use a set of combinators,
provided by the <code>futures</code> library, to construct more complex futures out of simpler components.
Unfortunately, users immediately faced frustrating compiler errors when they tried to follow this
approach. The problem was that futures, when spawned, need to “escape” the surrounding context, and
therefore can’t borrow state from that context: the task most own all of its state.</p><p>This was a problem for futures combinators, because often that state needs to be accessed in
multiple combinators that form part of the chain of actions that make up the future. For example, it
was common for users to call one “async” method on an object, and then another, which would be
written like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>foo</span><span>.</span><span>bar</span><span>().</span><span>and_then</span><span>(</span><span>|</span><span>result</span><span>|</span><span> </span><span>foo</span><span>.</span><span>baz</span><span>(</span><span>result</span><span>))</span><span>
</span></span></span></code></pre></div><p>The problem was that <code>foo</code> was borrowed both in the <code>bar</code> method and then in the closure passed to
<code>and_then</code>. Essentially, what users wanted to do was store state “across an await point,” the await
point being formed by the chaining of future combinators; this usually resulted confounding and
perplexing borrow-checker errors. The most accessible solution to this was to store that state in an
<code>Arc</code> and <code>Mutex</code>, which is not zero-cost and more importantly was very unwieldy and awkward as your
system grew in complexity. For example:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>foo</span><span> </span><span>=</span><span> </span><span>Arc</span>::<span>new</span><span>(</span><span>Mutex</span>::<span>new</span><span>(</span><span>foo</span><span>));</span><span>
</span></span></span><span><span><span></span><span>foo</span><span>.</span><span>clone</span><span>().</span><span>lock</span><span>().</span><span>bar</span><span>()</span><span>
</span></span></span><span><span><span>   </span><span>.</span><span>and_then</span><span>(</span><span>move</span><span> </span><span>|</span><span>result</span><span>|</span><span> </span><span>foo</span><span>.</span><span>lock</span><span>().</span><span>baz</span><span>(</span><span>result</span><span>))</span><span>
</span></span></span></code></pre></div><p>Despite the great benchmarks that futures had shown in the initial experimentation, the result of
this limitation was that users weren’t able to use them to build complex systems. This is where I
came into the story.</p><h2 id="asyncawait">Async/await</h2><p>In late 2017, it was clear that the futures ecosystem was failing to launch for reasons of bad user
experience. It was always the end goal of the futures project to implement a so-called “stackless
coroutine transform,” in which functions using async and await syntax operators could be transformed
into functions that evaluate to futures, avoiding users having to write futures by hand. Alex
Crichton had developed a macro based async/await implementation as a <a href="https://github.com/alexcrichton/futures-await">library</a>, but this
had gained almost no traction. Something needed to change.</p><p>One of the biggest problems with Alex Crichton’s macros was that it would produce an error if a user
attempted to have a reference to future state that was held over an <code>await</code> point. This was really
the same issue as the borrowing issue users encountered with futures combinators, appearing again in
the new syntax. It was not possible for a future to hold a reference to its own state while
awaiting, because this would need to be compiled into a self-referential struct, which Rust had no
support for.</p><p>It’s interesting to compare this to the problem of green threads. One way we’ve explained the
compilation of futures to state machines is to say that the state machine is a “perfectly sized
stack” - unlike the stack of a green thread, which must grow to accommodate the state of the unknown
sized that any thread stack may have, a compiled future (implemented by hand, with combinators, or
with an async function) is exactly as large as it needs to be. So we don’t have the problem of
growing this stack at runtime.</p><p>However, this stack is represented as a struct, and it is always safe to move structs in Rust. This
means that even though we don’t <em>need</em> to move a future around while it’s being executed, according
to the rules of Rust we need to be <em>able</em> to. Thus, the problem of stack pointers that we
encountered with green threads re-emerged in the new system. This time, though, we had the advantage
that we didn’t need to be able to move the future, we just needed to express that the future was
immovable.</p><p>The initial attempt to implement this was to try to define a new trait, called <code>Move</code>, which would
be used to exclude coroutines from APIs which can move them. This ran into some backwards
compatibility problems that I have previously <a href="https://without.boats/blog/changing-the-rules-of-rust">documented</a>. My thesis for
async/await had three main points:</p><ol><li>We needed async/await syntax in the language so that users could build complex futures using
coroutine-like functions.</li><li>Async/await syntax needed to support compiling those functions to self-referential structs, so
that users could use references in coroutines.</li><li>This feature needed to ship as soon as humanly possible.</li></ol><p>The combination of these three points led me to search for an alternative solution to the <code>Move</code>
trait, one that could be implemented without any major disruptive change to the language.</p><p>My initial plan to achieve this result was much worse than what we ended up with. I proposed that we
would just make the <code>poll</code> method unsafe, and include as an invariant that once you have started
polling a future, you cannot move it again. This was simple, immediately implementable, and
extremely brute force: it would have made every hand-written future unsafe, and imposed a difficult
to verify requirement with no assistance from the compiler. It likely would have ran aground on some
soundness issue eventually, and it would certainly have been extremely controversial.</p><p>So it was wonderful that Eddy Burtescu made a few remarks that led me in the direction of a much
better API, which would enable us to enforce the invariants required in a much more fine-grained
way. This would eventually become the <code>Pin</code> type. The <code>Pin</code> type itself has been the source of a
fair amount of consternation, but I think it was an undeniable improvement on the other options were
were considering at the time, in that it was targeted, enforceable, and also shippable on time.</p><p>In retrospect, there are two categories of problems with the pinning approach:</p><ol><li><strong>Backward compatibility:</strong> some interfaces that already existed (especially Iterator and Drop)
should have supported immovable types for various reasons, and this has limited the options in
developing the language further.</li><li><strong>Exposure to end users:</strong> our intention was that users writing “normal async Rust” would never
have to deal with <code>Pin</code>. Mostly this has been true, but there are a few notable exceptions.
Almost all of these would be fix-able with some syntax improvements. The only one that’s really
bad (and embarrassing to me personally) is that you need to pin a future trait object to await
it. This was an unforced error that would now be a breaking change to fix.</li></ol><p>The only other decisions to be made about async/await were syntactic, which I will not unsettle in
this already overly long post.</p><h2 id="organizational-considerations">Organizational considerations</h2><p>My reason in exploring all this history is to demonstrate that a series of facts about Rust led us
inevitably into a specific design space. The first was that Rust’s lack of runtime made green
threads a non-viable solution, both because Rust needs to support embedding (both embedding into
other applications and running on embedded systems) and because Rust cannot perform the memory
management necessary for green threads. The second was that Rust has a natural capacity for
expressing coroutines compiled to highly optimizable state machines while still being memory safe,
which we exploit not only for futures but also for iterators.</p><p>But there is another side to this history: <em>why</em> did we pursue a runtime system for user-space
concurrency? Why have futures and async/await at all? This argument usually takes one of two forms:
on the one hand, you have people who are used to managing user-space concurrency “by hand,” using an
interface like epoll directly; these people sometimes sneer at async/await syntax as “webcrap.” On
the other hand, some people just say “you aren’t gonna need it,” and propose using simpler OS
concurrency like threads and blocking IO.</p><p>People implementing highly performant network services in languages without facilities for
user-space concurrency like C tend to implement them using a hand-written state machine. This is
exactly what the <code>Future</code> abstraction was designed to compile into, but without having to write the
state machine by hand: the whole point of the coroutine transform to write imperative code “as if
your function never yields,” but have the compiler generate the state transitions to suspend it when
it would block. The benefits of this are not insignificant. A recent curl <a href="https://daniel.haxx.se/blog/2023/10/11/how-i-made-a-heap-overflow-in-curl/">CVE</a> was ultimately
caused by a failure to recognize state that needed to be saved during a state transition. This kind
of logic error is easy to make when implementing a state machine by hand.</p><p>The goal of shipping async/await syntax in Rust was to ship a feature which avoided those bugs while
still having the same performance profile. Systems like this, most often written in C or C++, were
considered well within our addressable audience, given the level of control we provide and the lack
of memory management runtime.</p><p>In early 2018, the Rust project had committed to the idea of releasing a new “edition” that year, to
fix some of the syntactic issues that had emerged with 1.0. It was also decided to use this edition
as an opportunity to promote a narrative around Rust being ready for prime-time; the Mozilla team was
mostly compiler hackers and type theorists, but we had some basic idea about marketing and
recognized the edition as an opportunity to get eyeballs on the product. I proposed to Aaron Turon
that we should focus on four basic user stories which seemed like growth opportunities for Rust.
These were:</p><ul><li>Embedded systems</li><li>WebAssembly</li><li>Command-line interfaces</li><li>Network services</li></ul><p>This remark was the jumping off point for the creation of the <a href="https://internals.rust-lang.org/t/announcing-the-2018-domain-working-groups/6737">“Domain Working
Groups”</a>, which were intended to be cross-functional groups focused on a particular
use “domains” (in contrast to the pre-existing “teams” controlling some technical or organizational
bailiwick). The concept of working groups in the Rust project has morphed since then and mostly lost
this sense, but I digress.</p><p>The work on async/await was pioneered by the “network services” working group, which eventually
become known as simply the async working group (and still exists under this name today). However, we
were also acutely aware that given its lack of runtime dependencies, async Rust could also be of
great service in the other domains, especially embedded systems. We designed the feature with both
of these use cases in mind.</p><p>It was clear, though usually left unsaid, that what Rust needed to succeed was industry adoption, so
that it could continue to receive support once Mozilla stopped being willing to fund an experimental
new language. And it was clear that the most likely path to short-term industry adoption was in
network services, especially those with a performance profile that compelled them at the time to be
written in C/C++. This use case fit the niche of Rust perfectly - these systems need high degrees of
control to achieve their performance requirements but avoiding exploitable memory bugs is critical
because they are exposed to the network.</p><p>The other advantage of network services was that this wing of the software industry has the
flexibility and appetite to rapidly adopt a new technology like Rust. The other domains were - and
are! - viable long term opportunities for Rust, but they were seen as not as quick to adopt new
technology (embedded), depended on a new platform that had not yet seen widespread adoption itself
(WebAssembly), or were not a particularly lucrative industrial application that could lead to
funding for the language (CLIs). I drove at async/await with the diligent fervor of the assumption
that Rust’s survival depended on this feature.</p><p>In that regard, async/await has been phenomenally successful. Many of the most prominent sponsors of
the Rust Foundation, especially those who pay developers, depend on async/await to write high
performance network services in Rust as one of their primary use cases that justify their funding.
Using async/await for embedded systems or kernel programming is also a growing area of interest with
a bright future. Async/await has been so successful that the most common complaint about it is
that the ecosystem is too centered on it, rather than “normal” Rust.</p><p>I don’t know what to tell users who would rather just use threads and blocking IO. Certainly, I
think there are a lot of systems for which that is a reasonable approach. And nothing in the Rust
language prevents them from doing it. Their objection seems to be that the ecosystem on crates.io,
especially for writing network services, is centered on using async/await. Ocassionally, I see a
library which uses async/await in a “cargo cult” way, but mostly it seems safe to assume that the
author of the library actually wants to perform non-blocking IO and get the performance benefits of
user-space concurrency.</p><p>None of us can control what everyone else decides to work on, and the fact of the matter is just
that most people who release networking-related libraries on crates.io want to use async Rust,
whether for business reasons or just out of interest. I’d like it to be easier to use those
libraries in a non-async context (e.g. by bringing a <a href="https://docs.rs/pollster/0.3.0/pollster/">pollster</a>-like API into the standard
library), but it’s hard to know what to say to people who’s gripe is that the people putting code
online for free don’t have exactly the same use case as them.</p><h2 id="to-be-continued">To be continued</h2><p>Although I contend there was no alternative for <em>Rust</em>, I don’t believe async/await is the right
alternative to any language. In particular, I think there is a possibility for a language which
provides the same sort of reliability guarantees that Rust provides, but less control over the
runtime representation of values, which uses stackful coroutines instead of stackless ones. I even
think - if such a language supported such coroutines in such a way that they could be used for both
iteration and concurrency - that language could do without lifetimes entirely while still
eliminating errors that arise from aliased mutability. If you read his <a href="https://graydon2.dreamwidth.org/307291.html">notes</a>, you can see
that this language is what Graydon Hoare was originally driving at, before Rust changed course to be
a systems language that could complete with C and C++.</p><p>I think there are users of Rust who would be perfectly happy using this language if it existed, and
I understand why they dislike that they have to deal with inherent complexity of the low level
details. It be that these users complained about the myriad string types, now they are more likely
to complain about async. I wish that a language for this use case with the same kinds of guarantees
as Rust also existed, but the problem here isn’t with Rust.</p><p>And despite the fact that I believe async/await is the right approach for Rust, I also think its
reasonable to be unhappy with the state of async ecosystem today. We shipped an MVP in 2019, tokio
shipped a 1.0 in 2020, and things have been more stagnant since then than I think anyone involved
would like. In a follow up post, I want to discuss the state of the async ecosystem today, and what
I think the project could do to improve users’ experience. But this is already the longest blog post
I’ve ever published, so for now I will have to leave it there.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omnivore – free, open source, read-it-later App (247 pts)]]></title>
            <link>https://omnivore.app/</link>
            <guid>37890742</guid>
            <pubDate>Sun, 15 Oct 2023 15:48:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://omnivore.app/">https://omnivore.app/</a>, See on <a href="https://news.ycombinator.com/item?id=37890742">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Being picky about a CSS reset for fun (132 pts)]]></title>
            <link>https://chriscoyier.net/2023/10/03/being-picky-about-a-css-reset-for-fun-pleasure/</link>
            <guid>37890725</guid>
            <pubDate>Sun, 15 Oct 2023 15:47:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriscoyier.net/2023/10/03/being-picky-about-a-css-reset-for-fun-pleasure/">https://chriscoyier.net/2023/10/03/being-picky-about-a-css-reset-for-fun-pleasure/</a>, See on <a href="https://news.ycombinator.com/item?id=37890725">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Just days before <a href="https://andy-bell.co.uk/a-more-modern-css-reset/">Andy revamped his (more) Modern CSS Reset</a>, <a href="https://shoptalkshow.com/582/#t=43:01">Dave and I were line-by-lining it</a> on ShopTalk Show. Mouthblogging is fun and all, but so is Writemouthblogging, known colloquially as “blogging”. </p>
<p>Allow me to do it again with my fingers on this new version. </p>
<p>Obviously this is all subjective and you can and should do whatever you want with your life.</p>
<hr>
<pre aria-describedby="shcb-language-1" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code>*,
*<span>::before</span>,
*<span>::after</span> {
  <span>box-sizing</span>: border-box;
}</code></span><small id="shcb-language-1"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>You gotta do it. This is one of the things that makes me wish we could do a CSS version of <code>"use strict";</code> at the top to opt into a version of CSS with all the <a href="https://wiki.csswg.org/ideas/mistakes">mistakes</a> fixed. The psuedos make that selector so ugly, don’t they? Ughghk. Since setting <code>width</code> and <code>height</code> is getting rarer in a world of flexbox and grid anyway (which is what <code>box-sizing</code> “fixes”), and the pseudo usage rarer still, it makes me want to start omitting this entirely, but every time I try it, I regret it, and put it back. </p>
<p>This was a popular alternative for a minute, I think credit to Jon Neal for thinking it through:</p>
<pre aria-describedby="shcb-language-2" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>html</span> {
  <span>box-sizing</span>: border-box;
}
*, *<span>:before</span>, *<span>:after</span> {
  <span>box-sizing</span>: inherit;
}</code></span><small id="shcb-language-2"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>The idea is that on any given element you could set a <em>different</em> <code>box-sizing</code> value and it would change it not only for that DOM node but all its descendants, which is maybe what you want. But it didn’t seem to catch on, probably because it’s <em>so</em> niche. I also don’t like looking at the slightly incorrect single colons, even though they will work fine forever.</p>
<hr>
<pre aria-describedby="shcb-language-3" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>html</span> {
  <span>-moz-text-size-adjust</span>: none;
  <span>-webkit-text-size-adjust</span>: none;
  <span>text-size-adjust</span>: none;
}</code></span><small id="shcb-language-3"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>This makes it so iPhones don’t dork up the font size in landscape mode, <a href="https://kilianvalkhof.com/2022/css-html/your-css-reset-needs-text-size-adjust-probably/">as Kilian documented</a>. Dumb. Apple should ditch that behavior. But for now, <em>fine</em>.</p>
<hr>
<pre aria-describedby="shcb-language-4" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>body</span>, <span>h1</span>, <span>h2</span>, <span>h3</span>, <span>h4</span>, <span>p</span>,
<span>figure</span>, <span>blockquote</span>, <span>dl</span>, <span>dd</span> {
  <span>margin</span>: <span>0</span>;
}</code></span><small id="shcb-language-4"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>I like the idea of nuking margins. Definitely on the <code>body</code>. That one is extra annoying. <code>8px</code> lol go to bed. Why? <a href="https://www.miriamsuzanne.com/2022/07/04/body-margin-8px/#:~:text=All%20browsers%20add%20an%208px,own%20'user%20agent'%20styles.">why.</a> But I get it. We can’t have text touching the edge of the browser window that would be worse. I think <code>1rem</code> would be a heck of a lot nicer, if not some exotic <code>max()</code> calculation with viewport units so large screens get more than small screens. But you can’t just <em>change things</em> on the web, lest it decent into chaos (cats/dogs/living together/etc). </p>
<p>I’d probably be a little more comprehensive here though. The list sisters <code>ol</code> and <code>ul</code> for sure, and <code>pre</code>, just to pick one more. And clearly Andy hates h5 and h6 👀. <em>personally.</em></p>
<hr>
<pre aria-describedby="shcb-language-5" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>ul</span><span>[role=<span>'list'</span>]</span>,
<span>ol</span><span>[role=<span>'list'</span>]</span> {
  <span>list-style</span>: none;
}</code></span><small id="shcb-language-5"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>This was a head-scratcher to me, but Andy explains it’s to make sure Safari doesn’t wipe out the correct accessible role:</p>
<blockquote>
<p>… to make sure that a&nbsp;<code>role</code>&nbsp;is added, I remove the list styling by default for it as a little reward.</p>
</blockquote>
<p>lol that is so weird that now I like it again. It reminds me of those selectors <a href="https://adrianroselli.com/2020/11/under-engineered-responsive-tables.html#CSS">like Adrian likes</a> where you are only awarded the correct styles if you use <em>all</em> the correct attributes…</p>
<details><summary>… like this beauty.</summary><pre aria-describedby="shcb-language-6" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>[role=<span>"region"</span>]</span><span>[aria-labelledby]</span><span>[tabindex]</span> {
  <span>overflow</span>: auto;
}

<span>[role=<span>"region"</span>]</span><span>[aria-labelledby]</span><span>[tabindex]</span><span>:focus</span> {
  <span>outline</span>: .<span>1em</span> solid <span>rgba</span>(<span>0</span>,<span>0</span>,<span>0</span>,.<span>1</span>);
}</code></span><small id="shcb-language-6"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>

</details>
<p>A more sober me might do something like this instead:</p>
<pre aria-describedby="shcb-language-7" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>ul</span><span>[class]</span>,
<span>ol</span><span>[class]</span> {
  <span>margin</span>: <span>0</span>;
  <span>padding</span>: <span>0</span>;
  <span>list-style</span>: none;
}</code></span><small id="shcb-language-7"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>… where I’m like: hey if you’re adding a class to this list, you’re probably doing something fancy to it, so boot it back to normal town first.</p>
<p>Maybe we need “JavaScript resets”? Like if we’re worried about roles getting wiped out, let’s force the issue.</p>
<pre aria-describedby="shcb-language-8" data-shcb-language-name="PHP" data-shcb-language-slug="php"><span><code>document
  .querySelectorAll(<span>"ul, ol"</span>)
  .<span>forEach</span>(<span>list</span> =&gt; <span>list</span>.setAttribute(<span>"role"</span>, <span>"list"</span>));</code></span><small id="shcb-language-8"><span>Code language:</span> <span>PHP</span> <span>(</span><span>php</span><span>)</span></small></pre>
<p>I can forsee no problems with that — ship it.</p>
<hr>
<pre aria-describedby="shcb-language-9" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>body</span> {
  <span>min-height</span>: <span>100vh</span>;
  <span>line-height</span>: <span>1.5</span>;
}</code></span><small id="shcb-language-9"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>First of all I’d smash that <code>line-height</code> on the <code>html</code> element instead, mostly because I think that high-level “inherit me!!” typography stuff should happen there. The <code>r</code> in <code>rem</code> means “root” and only responds to changes in size there. Likewise there is new units like <code>rlh</code> that mean “root line height” and it makes sense to me to just use the root in case we want to use that value. </p>
<p>Every part of me wants to use <code>dvh</code> instead of <code>vh</code> on that <code>min-height</code> because when browser chrome and crap comes up it makes sense to me that that size shrinks to the new area. But apparently it <a href="https://ishadeed.com/article/new-viewport-units/#:~:text=Be%20careful%20with%20the%20dvh,is%20scrolling%20up%20or%20down.">can be a performance issue</a> (??) so maybe not. Would like to see some testing there. Although I might just need to adjust my thinking and <a href="https://mastodon.social/@simevidas/111088262361593466">embrace the <code>svh</code></a>.</p>
<hr>
<pre aria-describedby="shcb-language-10" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>h1</span>, <span>h2</span>, <span>h3</span>, <span>h4</span>,
<span>button</span>, <span>input</span>, <span>label</span> {
  <span>line-height</span>: <span>1.1</span>;
}</code></span><small id="shcb-language-10"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Heck yeah, if you’re going to go with that luxuriously tall <code>line-height</code> for the page, you gotta suck it back down for headers. Except <code>h5</code> and <code>h6</code> who can apparently suck it. Makes sense on the inputs too, I’ve never seen that in a reset before and I like it.</p>
<hr>
<pre aria-describedby="shcb-language-11" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>h1</span>, <span>h2</span>,
<span>h3</span>, <span>h4</span> {
  <span>text-wrap</span>: balance;
}</code></span><small id="shcb-language-11"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Hell yeah. This makes me think we should also be putting <code>text-wrap: pretty;</code> on all the Small But Long Text elements like <code>p</code>, <code>li</code>, <code>.intro-text</code>, <code>dd</code>, and whatnot. But that makes me feel like that’s maybe over-reaching? Doesn’t it bail out on elements over 4 lines or something anyway?</p>
<hr>
<pre aria-describedby="shcb-language-12" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>a</span><span>:not(</span><span>[class]</span>) {
  <span>text-decoration-skip-ink</span>: auto;
  <span>color</span>: currentColor;
}</code></span><small id="shcb-language-12"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p><code>auto</code> is already the default on <code>text-decoration-skip-ink</code> so I’m not sure how useful that is. I <em>kinda</em> like the <code>currentColor</code> idea, but it means you <em>really</em> need to keep the underlines then or have some other really obvious link style. “Links are supposed to be blue” and all that. </p>
<hr>
<pre aria-describedby="shcb-language-13" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>input</span>,
<span>button</span>,
<span>textarea</span>,
<span>select</span> {
  <span>font</span>: inherit;
}</code></span><small id="shcb-language-13"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Love it. I like that that even works on select now, I could have sworn it didn’t. I wonder if we should add <code>selectmenu</code> now too? Isn’t that getting close? I bet it would even cascade down into the <code>option</code>s then, maybe?</p>
<pre aria-describedby="shcb-language-14" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>textarea</span><span>:not(</span><span>[rows]</span>) {
  <span>min-height</span>: <span>10em</span>;
}</code></span><small id="shcb-language-14"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Fair. A rare case I like the <code>em</code> instead of <code>rem</code>. My optimisitically chuck on <code>form-sizing: normal;</code> also. </p>
<hr>
<pre aria-describedby="shcb-language-15" data-shcb-language-name="CSS" data-shcb-language-slug="css"><span><code><span>:target</span> {
  <span>scroll-margin-block</span>: <span>5ex</span>;
}</code></span><small id="shcb-language-15"><span>Code language:</span> <span>CSS</span> <span>(</span><span>css</span><span>)</span></small></pre>
<p>Like it. Browsers butt targets too high. The <code>ex</code> unit is showing off a little lol. I vote for <code>1rlh</code>. </p>

 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Causal inference as a blind spot of data scientists (197 pts)]]></title>
            <link>https://dzidas.com/ml/2023/10/15/blind-spot-ds/</link>
            <guid>37890685</guid>
            <pubDate>Sun, 15 Oct 2023 15:43:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dzidas.com/ml/2023/10/15/blind-spot-ds/">https://dzidas.com/ml/2023/10/15/blind-spot-ds/</a>, See on <a href="https://news.ycombinator.com/item?id=37890685">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <article>
    

    <div>
          <p>Throughout much of the 20th century, frequentist statistics dominated the field of statistics and scientific research. Frequentist statistics primarily focus on the analysis of data in terms of probabilities and observed frequencies. Causal inference, on the other hand, involves making inferences about cause-and-effect relationships, which often goes beyond the scope of traditional frequentist statistical methods.</p>

<p>Causal inference has a long history, but it gained more prominent attention in the latter half of the 20th century. This increased interest was partly due to advancements in statistical methods and the development of causal inference frameworks. In the 1980s, the work of Judea Pearl on causal inference significantly contributed to the field which continued into the 21st century. Economists and social scientists were among the first to recognize the advantages of these emerging causal inference techniques and incorporated in their research.</p>

<p>However, based on my personal anecdote, the data science community didn’t truly prioritize causal inference until around 2015 or later. It was during this period that less technically oriented economists faced significant challenges related to the scaling of big data, prompting them to seek assistance from data scientists. Unfortunately, data scientists often lacked the necessary expertise in causal inference, resulting in limited knowledge transfer to business stakeholders. As a result, we, the data scientists, missed an important development for quite a bit, so let’s catch up on that!</p>

<h3 id="what-is-causal-inference">What is causal inference?</h3>

<p><img src="https://dzidas.com/images/ny.png" alt="New York in the parallel worlds">
<em>New York in the parallel worlds</em></p>

<p>To explain causal inference, I like an analogy of a parallel or alternative world. Nowadays, with the help of GenerativeAI, we can really simulate or create new worlds. Have you ever wondered how New York would be if the Aztecs would take over of Americas? Or what if the Roman Empire still ruled the world?</p>

<p>Now, how does this relate to data science and business decisions? Well, businesses make important choices every day, like where to invest money, who to hire or fire, and what the consequences of public policies might be. The data they collect only shows one side of reality. To really understand the results of their decisions, they need to explore an unseen or simulated reality. That’s where causal inference comes in, helping us make better decisions by considering alternative outcomes.</p>

<p>Let’s take an example to make it clear. Imagine you’re in charge of expanding the business of a company that makes snack bars for kids. Your  goal is to boost sales, and you’re considering adding more sugar to your products because you have a hunch that kids love sugar. After enchancing all your snacks with sugar, you want to measure its impact. You want to know how much your sales would be in a parallel world where kids were stuck with bland snacks compared to your sweet treats. This is where causal inference steps in to provide the solution.</p>

<p><img src="https://dzidas.com/images/sweet.png" alt="">
<em>Sales of sweet snacks vs bland snacks</em></p>

<p>The chart above illustrates the difference between an observed scenario represented by the red line and an unobserved scenario represented by the black line. The technical term for the black line is ‘counterfactual’—it represents what the sales would be if we didn’t enhance the snacks with sugar.</p>

<p>To continue this intriguing story, let’s fast forward a bit. Now, you’re the CEO of the same company, which has gained international recognition and is traded on stock markets worldwide. However, recently, some pesky Facebook groups formed by moms and dads have launched a public campaign, claiming that your products and the entire concept behind them are making their children overweight and prone to diabetes.</p>

<p>In an effort to address these concerns and launch a PR campaign, you reach out to a university with whom you’ve collaborated in the past to improve your products. You ask them to investigate these claims. To your surprise, they request the same sales data that initially sparked the sugary product campaign. A few nights later, an underpaid PhD student conducts a causal inference analysis, constructs counterfactuals and uncovers the following findings.</p>

<p><img src="https://dzidas.com/images/diabetes.png" alt="">
<em>Percentage of people with diabetes, simulated data</em></p>

<p>Upon seeing these results, you become convinced that there is a conspiracy against you and your company. You quickly instruct your lawyers to halt any further funding to the university and come up with a plan to take legal action against all parties threatening you. From this intriguing tale, we can take two valuable lessons about how Causal Inference played a pivotal role in two critical business scenarios:</p>

<ul>
  <li>Assesing the impact on sales by adding more sugar to your products.</li>
  <li>Assessing the effects of a sugary diet on children’s health.</li>
</ul>

<p>Here are more examples of causal inference:</p>

<ul>
  <li>Effect of attending a data science meetup on a person’s future and earnings</li>
  <li>Air quality and free public transport</li>
  <li>Percentage of electric vehicles and air quality</li>
  <li>Impact of your campaigns (sales, marketing or support) on the revenue, profit, employees satisfaction and etc.</li>
  <li>A product or service price change on the demand</li>
</ul>

<h3 id="running-a-causal-inference-analysis">Running a causal inference analysis</h3>

<p><img src="https://dzidas.com/images/umbrellas_sun_small.png" alt="">
Looking back at our fictional story, the lawyers could raise a valid argument that association or correlation doesn’t necessarily imply causation. In simpler terms, just because there’s a correlation between high sugar consumption and an increase in the number of people with diabetes doesn’t mean that one directly causes the other. It’s another case of a spurious correlation, isn’t it? Take, for example, the high correlation between umbrellas and wet streets. Does that imply that people with umbrellas cause puddles on the streets? Of course not. It’s more likely that a common factor, in this case, a rain (or, using the technical term, a confounder), affects both variables. Now, the question is how can we estimate the impact given that there is a causal link between diabetes and a sugary diet?</p>

<p>One approach to understanding the impact of sugary snack consumption on diabetes risk would involve conducting an experiment. In this experiment, children would be randomly assigned to receive either unsweetened or sugary snacks. After a decade, we’d analyze how many children developed diabetes in each group and calculate any observed differences. If differences exist, we could confidently attribute them to causation since the random assignment eliminates biases. However, I can already see parents rolling their eyes and rightly questioning my moral values. And they’re correct - we can’t conduct cruel experiments on children or people. Secondly, it would take 10 years to figure out the difference, and thirdly, there are other biases to consider. Last but not least, it would be really expensive.</p>

<h3 id="linear-regression">Linear regression</h3>

<p>Let’s set aside for the moment the need to estimate <strong>causal</strong> impact and explore modeling the problem using linear regression. If we represent snack consumption as a binary variable (sugary or not), we can proceed as follows:</p><p>

\[diabetes_{i} = \alpha_0 + \beta * sugar_i + \varepsilon_i\]

</p><p>Now, here comes the exciting part – we can enhance our model by incorporating all the additional variables available to us. In our example, we might have access to demographic data, an individual’s activity or behavioral information. For instance, we can consider factors like how frequently and for how many hours a person exercises each week, their dietary habits, and so on.</p><p>

\[diabetes_{i} = \alpha_0 + \beta_s * sugar_i + \beta_r * race_i + \beta_g * gender_i + \beta_x * X_i  + \varepsilon_i\]

</p><p><em>\(X_i\) denotes extra variables what we might include</em></p>

<p>You might be wondering whether adding more variables to the model is a good idea, and the short answer is: it depends. When dealing with a causal question, it’s crucial to include variables known as confounders. These are variables that can influence both the treatment and the outcome. By including confounding variables, we can better isolate and estimate the true causal effect of the treatment. Failing to add or account for confounding variables may lead to incorrect estimates.</p>

<p><img src="https://dzidas.com/images/confounder.png" alt="">
<em>Example of a confounder</em></p>

<p>Additionally, including variables that are only predictors of the outcome can be beneficial. It reduces the variance and allows for a more precise estimation of the causal effect. However, adding a variable that predicts only the treatment can lead to a less accurate estimation of causal effect. This occurs because it increases the variance, making it more challenging to estimate the causal effect accurately.</p>

<p>It is worth to emphasize, that a regression model gives an average estimate based on the given inputs. In causal inference, this outcome is referred to as the <strong>average treatment effect</strong>, \(ATE\), which provides an estimation across the entire group, rather than on an individual basis. Depending on the problem at hand, you might need to estimate an individual treatment effect. The Synthetic Control method, discussed below, allows you to assess the impact at an individual level.</p>

<h3 id="causal-graphical-models">Causal graphical models</h3>

<p>Now that we’ve discussed the cases to consider, let’s dive into the process of deciding which variables to include and which to omit in your model. Causal graphical models, championed by Jude Pearl since the 1980s, offer an appealing approach at first glance. The fundamental concept is to construct a Directed Acyclic Graph (DAG) that contains all variables in your analysis. Using this graphical representation  you can make informed decisions about which variables to retain and which to exclude.</p>

<p>In this framework, each node in the graph represents a variable, and an arrow pointing to another node signifies a causal relationship. The process of constructing this graph involves utilizing three building blocks: a pipe, a fork, and a collider, which help describe the causal flow between variables. This approach forces you to engage in a thoughtful and clarifying exploration of your model’s causal structure.</p>

<p><img src="https://dzidas.com/images/components_small.png" alt="">
<em>From left to right: a pipe, a fork and a collider</em></p>

<p>While learning about causal graphs can be challenging, it offers substantial benefits in understanding and addressing various causal inference problems and their solutions. Some argue that this approach doesn’t scale well on a model with +20 input variables. In my experience, most of the time we start with a limited set of variables and build the derivatives of these variables. Therefore, there is an opportunity to build a structural map on the primary variables in most of the cases.</p>

<p>Additionally, to alleviate the pain and speedup process, frameworks such as DoWhy and econml have been developed. In summary, starting your modeling journey with a causal graph may indeed be a challenging task, however it is a proven framework to get a robust and insightful model.</p>

<h3 id="instrumental-variable">Instrumental Variable</h3>

<p><img src="https://dzidas.com/images/instrument_small.png" alt="">
In a nutshell, the causal graph should facilitate a solution of a causal problem. However, there many methods to tackle the problem depending what data and challenge you have at hands. Instrumental Variable (IV) method is quite unique. In theory, it seems like a magical solution — you find a variable that has a causal link to a treatment, but doesn’t impact the outcome directly, and voilà, you’ve cracked the code of causation. However, there’s a crucial requirement: the IV must remain completely unrelated to any unobservable factors. This means you need prior knowledge ensuring that the treatment and the outcome have no connections with any variables — an undertaking that can be quite challenging, if not nearly impossible, in the real world. In my experience, I haven’t come across any instances of its use, but interestingly, nearly every causal inference course dedicates a chapter to this intriguing concept.</p>

<h3 id="difference-in-differences">Difference in Differences</h3>

<p>DiD is a straightforward method that can be implemented in Excel without the need for advanced tools. The concept revolves around comparing two versions of a subject or a unit under investigation: one before a particular event or treatment and the other after. To enhance the analysis, you introduce a control group — a similar entity that remains unaffected by the treatment.</p>

<p><img src="https://dzidas.com/images/diff-diffs.png" alt="">
<em>What are the potential effects of a young girl taking her chemistry classes seriously</em></p>

<p>Let’s consider an illustrative example: before the introduction of the free transport policy in San Diego, the average air pollution level was 10. After the policy was implemented, it decreased to 8. However, we can’t simply subtract 10 from 8, as it would yield biased results.
To address this issue, we turn to data from a neighboring city, Tijuana, located just across the border. In Tijuana, the pollution level before the policy was 11, and after its introduction, it dropped to 10. Notably, Tijuana was not affected by the policy. Applying this approach, we find that the bias reduction diminishes the impact from \(-2\) to \(-1\).</p>

<p>\(diff = (SanDiego_{after} - SanDiego_{before}) - (Tijuana_{after} - Tijuana_{before}) =\)
\((8 - 10) - (10 - 11) = -1\)</p>

<h3 id="synthetic-control">Synthetic control</h3>

<p>In our previous example, we made an assumption that the cities were similar, with the treatment being the only differing factor. Furthermore, we simplified the problem by considering only four parameters, which inevitably introduced a degree of uncertainty into our estimation. But what if we had access to a wealth of data from various units (cities in the previous example) and the ability to observe changes over time?</p>

<p><img src="https://dzidas.com/images/Zuckerberg_twin_small.png" alt=""></p>

<p>Enter the word of Synthetic Control. Like a magician, we build a synthetic twin for our treatment group. To do that, we take the treatment group and regress against a bunch of similar units, and with regularization, we select the most relevant features and determine their weights.</p>

<p>For instance, let’s evaluate the impact of Mark Zuckerberg having children on teenagers’ happiness in social networks. In order to construct a synthetic control group, we certainly include Bezos, Musk, and Gates, but we might also add Jon from the UK and Guiseppe from France. Never heard of the latter two? That’s precisely the point!
With this model, built from data preceding the event (Zuckerberg having children), we project the data into the future, thereby generating our imaginery future, namely counterfactuals, which gives us a way to measure the impact.</p>

<p><img src="https://dzidas.com/images/zucker_small.png" alt="">
<em>Fictitious example</em></p>

<p>Previously, we discussed the average treatment effect, a measure that helps us estimate the overall causal impact on a treatment group. Now, with the synthetic control method, it becomes possible to estimate an individual treatment effect (in this case, the effect of Zuckerberg having children), provided that we have a sufficient amount of data to create a synthetic control.</p>

<p>Now, lets magic fade and look at disadvangates of synthetic control. The method assumes that all potential confounding variables are measured and controlled for as with linear regression. The synthetic control method assumes that the pre-treatment data accurately represent the underlying data-generating process. And on top of that, you get the standard ML problems - overfitting, difficult to validate (but not impossible) just to name few.</p>

<h3 id="double-ml">Double ML</h3>

<p>Since the ’90s, when causal inference gained popularity, the data landscape has changed significantly. More often than not, we now find ourselves dealing with enormous amounts of data for a given problem, often without a clear understanding of how all the variables interconnect. In theory, DoubleML can be helpful in such cases.</p>

<p><img src="https://dzidas.com/images/doubleml.png" alt=""></p>

<p>The DoubleML method is founded on machine learning modeling and consists of two key steps. First, we build a model \(m(X)\) that predicts the treatment variable \(T\) based on the input variables \(X\). Then, we create a separate model \(g(X)\) that predicts the outcome variable \(Y\)
using the same set of input variables \(X\). Subsequently, we calculate <strong>the residuals</strong> from the former model and regress them against <strong>the residuals</strong> from the latter model. An important feature of this method is its flexibility in accommodating non-linear models, which allows us to capture non-linear relationships — a distinctive advantage of this approach.</p><p>

\[\tilde{T}_{sugar} = T_{sugar} - m(X)\]

\[\tilde{Y}_{outcome} = Y_{outcome} - g(X)\]

\[\tilde{Y}_{outcome} = \alpha_0 + \beta_t *\tilde{T}_{sugar}\]

</p><p>Consider using DoubleML when you have high-dimensional data (many features) or when the relationships between inputs and treatment/outcome are not linear. DoubleML is particularly useful when you need to estimate treatment effects that vary across different subgroups or individuals. However, it’s essential to remember that DoubleML cannot magically eliminate the influence of poorly considered confounding variables.</p>

<h3 id="useful-resources">Useful resources</h3>

<p>The purpose of this blog post was to introduce readers to the world of Causal Inference and inspire them to explore it further. I’m planning to follow up with a hands-on post using public data. Below, you can find a list of resources that I found helpful during my own journey of learning about Causal Inference.”</p>

<ul>
  <li><a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html">Causal Inference for The Brave and True</a>. It’s freely available on the internet, hands-on focused, and presents easily understandable formulas.</li>
  <li><img src="https://dzidas.com/images/why.jpg" alt=""> <a target="_blank" href="https://www.amazon.com/Book-Why-Science-Cause-Effect-ebook/dp/B075DCKP7V?&amp;_encoding=UTF8&amp;tag=quantitativ0e-20&amp;linkCode=ur2&amp;linkId=2e09720775e30ccd7e76b53f970711c9&amp;camp=1789&amp;creative=9325">The Book of Why</a> by Judea Pearl,  the inventor of causal diagrams, not only delves deep into the theory but also offers valuable insights from a historical perspective.</li>
</ul>

        </div>
  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mark Twain filmed by Thomas Edison in 1909 (209 pts)]]></title>
            <link>https://www.youtube.com/watch?v=leYj--P4CgQ</link>
            <guid>37890369</guid>
            <pubDate>Sun, 15 Oct 2023 15:08:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=leYj--P4CgQ">https://www.youtube.com/watch?v=leYj--P4CgQ</a>, See on <a href="https://news.ycombinator.com/item?id=37890369">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>