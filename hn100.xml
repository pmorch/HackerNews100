<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 19 Nov 2023 00:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[OpenAI board in discussions with Sam Altman to return as CEO (391 pts)]]></title>
            <link>https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo</link>
            <guid>38325552</guid>
            <pubDate>Sat, 18 Nov 2023 22:51:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo">https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo</a>, See on <a href="https://news.ycombinator.com/item?id=38325552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The OpenAI board is in discussions with Sam Altman to return to the company as its CEO, according to multiple people familiar with the matter. One of them said Altman, who was <a href="https://www.theverge.com/2023/11/17/23965982/openai-ceo-sam-altman-fired">suddenly fired by the board on Friday</a> with no notice, is “ambivalent” about coming back and would want significant governance changes.</p><p>Altman holding talks with the company just a day after he was ousted indicates that OpenAI is in a state of free-fall without him. Hours after he was axed, Greg Brockman, OpenAI’s president and former board chairman, resigned, and the two have been talking to friends and investors about starting another company. A string of senior researchers <a href="https://www.theinformation.com/articles/three-senior-openai-researchers-resign-as-crisis-deepens?rc=k5vrz1">also resigned</a> on Friday, and people close to OpenAI say more departures are in the works.</p><div><p>Altman is “ambivalent” about coming back</p></div><p>OpenAI’s largest investor, Microsoft, said in a statement shortly after Altman’s firing that the company “remains committed” to its partnership with the AI firm. However, OpenAI’s investors weren’t given advance warning or opportunity to weigh in on the board’s decision to remove Altman. As the face of the company and the most prominent voice in AI, his removal throws the future of OpenAI into uncertainty at a time when <a href="https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai">rivals are racing to catch up</a> with the unprecedented rise of ChatGPT.</p><p>A spokesperson for OpenAI didn’t respond to a request for comment about Altman discussing a return with the board. A Microsoft spokesperson declined to comment.</p><p>OpenAI’s current board consists of chief scientist Ilya Sutskever, Quora CEO Adam D’Angelo, former GeoSim Systems CEO Tasha McCauley, and Helen Toner, the director of strategy at Georgetown’s Center for Security and Emerging Technology. Unlike traditional companies, the board isn’t tasked with maximizing shareholder value, and none of them hold equity in OpenAI. Instead, their stated mission is to ensure the creation of “broadly beneficial” artificial general intelligence, or AGI.</p><p>Sutskever, who also co-founded OpenAI and leads its researchers, <a href="https://www.theverge.com/2023/11/17/23966446/what-happened-to-sam-altman-open-ai">was instrumental in the ousting of Altman this week</a>, according to multiple sources. His role in the coup suggests a power struggle between the research and product sides of the company, the sources say.</p><div><form action="#"><div><h2>Command Line</h2><p> / <span>A newsletter from Alex Heath about the tech industry’s inside conversation.</span></p></div></form></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Altman was raising billions from Middle East sovereign funds for AI chip startup (116 pts)]]></title>
            <link>https://twitter.com/unusual_whales/status/1725945364140986796?s=20</link>
            <guid>38323939</guid>
            <pubDate>Sat, 18 Nov 2023 20:19:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/unusual_whales/status/1725945364140986796?s=20">https://twitter.com/unusual_whales/status/1725945364140986796?s=20</a>, See on <a href="https://news.ycombinator.com/item?id=38323939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lockheed is now tracking phones and walkie-talkies from space (272 pts)]]></title>
            <link>https://jackpoulson.substack.com/p/lockheed-is-now-tracking-phones-and</link>
            <guid>38322966</guid>
            <pubDate>Sat, 18 Nov 2023 18:48:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jackpoulson.substack.com/p/lockheed-is-now-tracking-phones-and">https://jackpoulson.substack.com/p/lockheed-is-now-tracking-phones-and</a>, See on <a href="https://news.ycombinator.com/item?id=38322966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg" width="1456" height="1031" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1031,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;Situational Awareness Example&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" title="Situational Awareness Example" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8319517-1174-497e-a2fb-486ecc0825ff_2048x1450.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><a href="https://www.he360.com/technology/" rel="">Marketing materials</a><span> from space-based surveillance firm HawkEye 360 depicting how the company’s radio-frequency geolocation could detect a ship covertly visiting a port in Syria despite its AIS beacon being turned off.</span></figcaption></figure></div><p><span>This morning, space-based surveillance firm HawkEye 360 </span><a href="https://www.he360.com/hawkeye-360-closes-additional-10-million-in-series-d-1-funding-from-lockheed-martin-ventures-and-company-insiders/" rel="">announced</a><span> its “Strategic Cooperative Agreement” with weapons giant Lockheed Martin “on delivering sophisticated RF [radio-frequency] intelligence systems globally”. HawkEye’s current constellation of </span><a href="https://www.he360.com/technology/launch-timeline/" rel="">21 satellites</a><span> is trained to locate the sources of electromagnetic emissions with wavelengths ranging from roughly 2 meters down to 2 centimeters, with “Signals of Interest” including satellite phones, walkie-talkies, cellular towers, and GPS. </span></p><p><span>The announcement of HawkEye’s partnership with Lockheed came as part of a $10 million addition to HawkEye 360’s fourth major investment round — known as a “Series D” — with Lockheed Martin Ventures named as the primary additional investor, alongside unnamed “company insiders”. Despite not being a household name, HawkEye has long been considered one of the six most influential U.S. defense technology companies, as evidenced by serving as the ‘H’ in the popular defense tech acronym ‘</span><a href="https://www.avascent.com/news-insights/perspectives/sharpe-focus-the-recent-emergence-of-defense-unicorns/" rel="">SHARPE</a><span>’, alongside data-fusion giant Palantir’s ‘P’.</span></p><p><span>In addition to former Texas Congressman Lamar Smith having </span><a href="https://lda.senate.gov/filings/public/filing/17e13242-b57e-417e-b460-9fc9ba99f388/print/" rel="">formally lobbied</a><span> for the company, former U.S. counterterrorism czar Richard Clarke has been a </span><a href="https://www.he360.com/team/richard-clarke/" rel="">special assistant</a><span> to HawkEye CEO John Serafini. And the company’s </span><a href="https://www.he360.com/about-us-rf-analytics/hawkeye-360-team/" rel="">advisory board</a><span> has been </span><a href="https://www.he360.com/new-members-join-hawkeye-360s-advisory-board/" rel="">packed</a><span> with three former members of Congress as well as </span><a href="https://www.prnewswire.com/news-releases/hawkeye-360-announces-advisory-board-class-of-2022-301482520.html" rel="">former</a><span> high-level military officials, including former National Security Agency Director Michael Rogers and John Abizaid, the former head of Central Command who subsequently became Donald Trump’s Ambassador to Saudi Arabia. President Biden’s </span><a href="https://www.bloomberg.com/news/articles/2023-04-03/joe-biden-s-cybersecurity-dream-team-roiled-as-chris-inglis-resigns" rel="">departed</a><span> National Cyber Director, Chris Inglis, was similarly an </span><a href="https://www.he360.com/new-members-join-hawkeye-360s-advisory-board/" rel="">early member</a><span>, and HawkEye’s board of directors previously </span><a href="https://web.archive.org/web/20220725130829/https://www.ohio.edu/research/communications/konneker-medals-awarded-ohio-alumni-technology-innovations-entrepreneurial" rel="">included</a><span> the former Chief Technologist of Google Federal, Rob Painter.</span></p><p><span>Despite months of requests, HawkEye 360 has not responded to inquiries on either its alleged “strong” role supporting the military of the United Arab Emirates, or on leaked details of its technological approach obtained by the author. HawkEye’s alleged contract with the UAE Armed Forces was uncovered as part of the author’s </span><a href="https://jackpoulson.substack.com/p/exclusive-google-backed-startups" rel="">ongoing</a><span> reporting on imagery and location-analytics company Orbital Insight’s surveillance contract with the Indonesian government, codenamed “Project Alpha”. As part of Orbital CEO Kevin O’Brien’s presentation to an investor group last month, he noted that the “Emerati ISR leads” were a “Strong HawkEye 360 customer”.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png" width="1456" height="832" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:832,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:668035,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8eeb01d-d422-440e-8654-8e7c41a6b418_1498x856.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>A portion of the </span><a href="https://jackpoulson.substack.com/p/exclusive-google-backed-startups" rel="">fifth slide</a><span> of Orbital Insight’s September 7, 2023 presentation to the SATIF investment group which detailed the company’s plans to expand its military partnerships around the world. The fifth of the thirteen named targets was the armed forces of the United Arab Emirates, which Orbital CEO Kevin E. O’Brien claimed to be a “Strong HawkEye360 customer.”</span></figcaption></figure></div><p><span>Beyond HawkEye’s alleged “strong” support for UAE military surveillance, perhaps the company’s largest public contract was a </span><a href="https://www.usaspending.gov/award/CONT_AWD_N6600122C0065_9700_-NONE-_-NONE-" rel="">recently completed</a><span> $5.8 million project with U.S. Naval Information Warfare Systems to monitor radio-frequency emissions in the Pacific. The company also received a 1.5 million euro </span><a href="https://ted.europa.eu/udl?uri=TED:NOTICE:599045-2019:TEXT:EN:HTML" rel="">contract</a><span> in 2019 with the European Union’s border enforcement agency, </span><a href="https://frontex.europa.eu/" rel="">Frontex</a><span>, entitled “Satellite Radio Frequency Emitter Detection for Maritime Situational Awareness”.</span></p><p><span>HawkEye’s </span><a href="https://www.he360.com/about-us-rf-analytics/hawkeye-360-team/" rel="">advisors</a><span> have helped lead a large percentage of U.S. military and intelligence organizations — including the Central Intelligence Agency’s technical surveillance programs — and have included two former members of Congress who pivoted into lobbying, Norm Coleman and Lamar Smith. And so one can only conclude that HawkEye’s surveillance support for Gulf dictatorships is not an anomaly, but rather a corporate extension of official U.S. foreign policy.</span></p><p><span>The full text of Hawkeye 360’s pitch to the Pentagon through the </span><a href="https://jackpoulson.substack.com/p/exclusive-inside-trident-spectre" rel="">Vulcan</a><span> contracting marketplace follows:</span></p><blockquote><p>(U//PROPIN) HawkEye 360 (HE360) operates the first-of-its-kind constellation of commercial satellites that can independently detect, identify, and geolocate radio-frequency (RF) signals to within 500 meters of their point of origin. Launched in December 2018, the first cluster of three spacecraft (known as the Pathfinder Cluster) has been fully operational since February of 2019. The software-defined radio (SDR) payload on all three spacecraft can be tuned to a wide range of different frequencies (144MHz-15GHz) and switched between several different RF front end and antenna paths. The HE360 Signal of Interest (SOI) library is the list of signals that can be geolocated by the company’s spacecraft. Common SOIs include UHF GMRS/FRS Push-to-talk Radios, VHF Radios, Automatic Identification System (AIS) EPIRB Emergency Radio Beacons, Cellular Towers, Satellite Phone, X-band Maritime Navigation Radars, Ku-band VSAT Terminals. Tools developed in-house by HE360 efficiently process this data in an integrated signal-processing and geo-engine to calculate and deliver information about myriad emitter types from around the planet.</p><p>(U//PROPIN) Additionally, HawkEye 360 satellites can detect RF signals in the GPS bands, as well as other GNSS systems, e.g. GLONASS. If detected by all three spacecraft, the RF energy from a GNSS interference can be geolocated to its point of origin using an adaptation of the company’s existing geolocation techniques. Due to the global coverage of the constellation, geolocation of GNSS jamming or spoofing can be conducted over denied areas without exposing airborne or terrestrial sensors or personnel to hostile conditions. Unlike electro optical sensors, RF geolocation provides data day and night in all weather conditions.</p><p>(U//PROPIN) HE360 Spectrum Awareness products can support multiple applications and mission areas; including theater indications and warning, pattern of life analysis; maritime domain awareness; illegal fishing identification; border monitoring, mapping communications nodes; and disaster response.</p><p>(U) HE360 data and products are entirely unclassified, providing theater intelligence officers with an unprecedented ability to share RF geolocations with tactical echelons and partner nations. HE360 data is easily accessible via a web interface, and is interoperable “out of the box” with all GIS, C4ISR, and mobile device systems.</p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nanoplastics promote conditions for Parkinson's across various lab models (124 pts)]]></title>
            <link>https://corporate.dukehealth.org/news/nanoplastics-promote-conditions-parkinsons-across-various-lab-models</link>
            <guid>38322944</guid>
            <pubDate>Sat, 18 Nov 2023 18:45:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://corporate.dukehealth.org/news/nanoplastics-promote-conditions-parkinsons-across-various-lab-models">https://corporate.dukehealth.org/news/nanoplastics-promote-conditions-parkinsons-across-various-lab-models</a>, See on <a href="https://news.ycombinator.com/item?id=38322944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <div>
    <div>
                                                <p><img data-nmc-src="/sites/default/files/api/images/aspect:1.25-width:680-position:center/2023-11/Plastic neuron.png" alt="">
</p>
                                                                <p>Plastic nanoparticles (green), visible under a microscope, co-mingling with protein aggregates(red) in neuronal lysosomes (blue). Typically, concentrations of the protein aggregates are so small, they would not be viable at this level.</p>
                            </div>
    <div>
                                        <p><img data-nmc-src="/sites/default/files/api/images/aspect:1.25-width:680-position:center/2023-11/Plastic neuron.png" alt="">
</p>
                                </div>
</div>

                
    
    <p><span>
    <h4>Contact</h4>
                        

            </span></p><p><span><span><span><span>DURHAM, N.C. – Nanoplastics interact with a particular protein that is naturally found in the brain, creating changes linked to Parkinson’s disease and some types of dementia.</span></span></span></span></p>

<p><span><span><span><span>In a Duke-led study appearing Nov. 17 in Science Advances, the researchers report that the findings create a foundation for a new area of investigation, fueled by the timely impact of environmental factors on human biology. </span></span></span></span></p>

<p><span><span><span><span>“Parkinson’s disease has been called the fastest growing neurological disorder in the world,” said principal investigator, </span></span><a href="https://scholars.duke.edu/person/andrew.west"><span><span>Andrew West, Ph.D.,</span></span></a><span><span> professor in the </span></span><a href="https://pcb.duke.edu/"><span><span>Department of Pharmacology and Cancer Biology</span></span></a><span><span> at </span></span><a href="https://medschool.duke.edu/"><span><span>Duke University School of Medicine</span></span></a><span><span>. “Numerous lines of data suggest environmental factors might play a prominent role in Parkinson’s disease, but such factors have for the most part not been identified.”</span></span></span></span></p>

<p><span><span><span><span>Improperly disposed plastics have been shown to break into very small pieces and accumulate in water and food supplies, and were found in the blood of most adults in a recent study. </span></span></span></span></p>

<p><span><span><span><span>“Our study suggests that the emergence of micro and nanoplastics in the environment might represent a new toxin challenge with respect to Parkinson’s disease risk and progression,” West said. “This is especially concerning given the predicted increase in concentrations of these contaminants in our water and food supplies.”</span></span></span></span></p>

<p><span><span><span><span>West and colleagues in Duke’s </span></span><a href="https://nicholas.duke.edu/"><span><span>Nicholas School of the Environment</span></span></a><span><span> and the </span></span><a href="https://chem.duke.edu/"><span><span>Department of Chemistry</span></span></a><span><span> at </span></span><a href="https://trinity.duke.edu/"><span><span>Trinity College of Arts and Sciences</span></span></a><span><span> found that nanoparticles of the plastic polystyrene -- typically found in single use items such as disposable drinking cups and cutlery -- attract the accumulation of the protein known as alpha-synuclein. West said the study’s most surprising findings are the tight bonds formed between the plastic and the protein within the area of the neuron where these accumulations are congregating, the </span></span><span><span><span>lysosome.</span></span></span> </span></span></p>

<p><span><span><span><span>Researchers said the plastic-protein accumulations happened across three different models performed in the study - in test tubes, cultured neurons, and mouse models of Parkinson’s disease. West said questions remain about how such interactions might be happening within humans and whether the type of plastic might play a role.</span></span></span></span></p>

<p><span><span><span><span>“While microplastic and nanoplastic contaminants are being closely evaluated for their potential impact in cancer and autoimmune diseases, the striking nature of the interactions we could observe in our models suggest a need for evaluating increasing nanoplastic contaminants on Parkinson’s disease and dementia risk and progression,” West said. </span></span></span></span></p>

<p><span><span><span><span>“The technology needed to monitor nanoplastics is still at the earliest possible stages and not ready yet to answer all the questions we have,” he said. “But hopefully efforts in this area will increase rapidly, as we see what these particles can do in our models. If we know what to look out for, we can take the necessary steps to protect ourselves, without compromising all the benefits we reap every day from plastics.”</span></span></span></span></p>

<p><span><span><span><span>The study was funded by in part by The Michael J. Fox Foundation for Parkinson’s Research and the Aligning Science Across Parkinson’s initiative (ASAP-020527).</span></span></span></span></p>

<p><span><span><span><span>In addition to West, study authors include Zhiyong Liu, Arpine Sokratian, Addison M. Duda, Enquan Xu, Christina Stanhope, Amber Fu, Samuel Strader, Huizhong Li, Yuan Yuan, Benjamin G. Bobay, Joana Sipe, Ketty Bai, Iben Lundgaard, Na Liu, Belinda Hernandez, Catherine Bowes Rickman, and Sara E. Miller.</span></span></span></span></p>


    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Berkeley Mono Typeface (220 pts)]]></title>
            <link>https://berkeleygraphics.com/typefaces/berkeley-mono/</link>
            <guid>38322793</guid>
            <pubDate>Sat, 18 Nov 2023 18:32:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://berkeleygraphics.com/typefaces/berkeley-mono/">https://berkeleygraphics.com/typefaces/berkeley-mono/</a>, See on <a href="https://news.ycombinator.com/item?id=38322793">Hacker News</a></p>
Couldn't get https://berkeleygraphics.com/typefaces/berkeley-mono/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[No "malfeasance" behind Sam Altman's firing, OpenAI memo says (148 pts)]]></title>
            <link>https://www.axios.com/2023/11/18/openai-memo-altman-firing-malfeasance-communications-breakdown?stream=technology&amp;utm_source=alert&amp;utm_medium=email&amp;utm_campaign=alerts_technology</link>
            <guid>38322688</guid>
            <pubDate>Sat, 18 Nov 2023 18:24:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2023/11/18/openai-memo-altman-firing-malfeasance-communications-breakdown?stream=technology&#x26;utm_source=alert&#x26;utm_medium=email&#x26;utm_campaign=alerts_technology">https://www.axios.com/2023/11/18/openai-memo-altman-firing-malfeasance-communications-breakdown?stream=technology&#x26;utm_source=alert&#x26;utm_medium=email&#x26;utm_campaign=alerts_technology</a>, See on <a href="https://news.ycombinator.com/item?id=38322688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Sam Altman's <a data-vars-link-text="firing as OpenAI CEO" data-vars-click-url="https://www.axios.com/2023/11/18/sam-altman-fired-greg-brockman-openai-microsoft" data-vars-content-id="0d18bdd3-897a-49fc-8c6b-79f0e7c9510c" data-vars-headline="No &quot;malfeasance&quot; behind Sam Altman's firing, OpenAI memo says" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/11/18/sam-altman-fired-greg-brockman-openai-microsoft" target="_self">firing as OpenAI CEO</a> was not the result of "malfeasance or anything related to our financial, business, safety, or security/privacy practices" but rather a "breakdown in communications between Sam Altman and the board," per an internal memo from chief operating officer Brad Lightcap seen by Axios.</p><p><strong>Why it matters</strong>: OpenAI's board has been mum since midday Friday when it announced Altman's departure, leaving room for speculation and uncertainty over the basis for the firing.</p><p><strong>The full memo </strong>from Lightcap reads:</p><ul><li>"Team - after yesterday's announcement, which took us all by surprise, we have had multiple conversations with the board to try to better understand the reasons and process behind their decision. These discussions, and options regarding our path forward, are ongoing this morning."</li><li>"We can say definitively that the board's decision was not made in response to malfeasance or anything related to our financial, business, safety, or security/privacy practices. This was a breakdown in communication between Sam and the board."</li><li>"Our position as a company remains extremely strong, and Microsoft remains fully committed to our partnership.  [Interim CEO] Mira [Murati] has our full support as CEO. We still share your concerns about how the process has been handled, are working to resolve the situation, and will provide updates as we're able."</li><li>"I'm sure you all are feeling confusion, sadness, and perhaps some fear. We are fully focused on handling this, pushing toward resolution and clarity, and getting back to work. Our collective responsibility right now is to our teammates, partners, users, customers, and the broader world who shares our vision of broadly beneficial AGI. Hang in there, we are behind you all 1000%."</li></ul><p><strong>Catch up quick:</strong> OpenAI's board announced Friday that Altman was departing because he was <a data-vars-link-text="&quot;not consistently candid&quot;" data-vars-click-url="https://openai.com/blog/openai-announces-leadership-transition" data-vars-content-id="0d18bdd3-897a-49fc-8c6b-79f0e7c9510c" data-vars-headline="No &quot;malfeasance&quot; behind Sam Altman's firing, OpenAI memo says" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://openai.com/blog/openai-announces-leadership-transition" target="_blank">"not consistently candid"</a> with the board. </p><ul><li>It also said the board's chair — Greg Brockman, who was also OpenAI's president — would step down. Brockman announced soon after that he was quitting.</li><li>OpenAI, a non-profit organization that controls a for-profit subsidiary, has led the generative-AI boom since releasing ChatGPT a year ago. </li></ul><p><strong>Go deeper: </strong></p><ul><li><a data-vars-link-text="The culture clash behind OpenAI's CEO firing" data-vars-click-url="https://www.axios.com/2023/11/18/sam-altman-fired-openai-board-ai-culture-clash" data-vars-content-id="0d18bdd3-897a-49fc-8c6b-79f0e7c9510c" data-vars-headline="No &quot;malfeasance&quot; behind Sam Altman's firing, OpenAI memo says" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/11/18/sam-altman-fired-openai-board-ai-culture-clash" target="_self">The culture clash behind OpenAI's CEO firing</a></li><li><a data-vars-link-text="What we know about Sam Altman's shock exit from OpenAI" data-vars-click-url="https://www.axios.com/2023/11/18/sam-altman-fired-greg-brockman-openai-microsoft" data-vars-content-id="0d18bdd3-897a-49fc-8c6b-79f0e7c9510c" data-vars-headline="No &quot;malfeasance&quot; behind Sam Altman's firing, OpenAI memo says" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/11/18/sam-altman-fired-greg-brockman-openai-microsoft" target="_self">What we know about Sam Altman's shock exit from OpenAI</a></li><li><a data-vars-link-text="Microsoft, a key investor in OpenAI, was blindsided by Altman's exit" data-vars-click-url="https://www.axios.com/2023/11/17/microsoft-openai-sam-altman-ouster" data-vars-content-id="0d18bdd3-897a-49fc-8c6b-79f0e7c9510c" data-vars-headline="No &quot;malfeasance&quot; behind Sam Altman's firing, OpenAI memo says" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/11/17/microsoft-openai-sam-altman-ouster" target="_self">Microsoft, a key investor in OpenAI, was blindsided by Altman's exit</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Greg (2017) (151 pts)]]></title>
            <link>https://blog.samaltman.com/greg</link>
            <guid>38322660</guid>
            <pubDate>Sat, 18 Nov 2023 18:22:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.samaltman.com/greg">https://blog.samaltman.com/greg</a>, See on <a href="https://news.ycombinator.com/item?id=38322660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_container">
  <article>
    
  <header>
    

    
  </header>

  <div id="post_body_1136625"><p>A lot of people ask me what the ideal cofounder looks
like.&nbsp; I now have an answer: Greg Brockman.</p>

<p>Every successful startup I know has at least one person&nbsp;who
provides the force of will to make the startup happen. &nbsp;I’d thought a lot
about this in the abstract while advising YC startups, but until OpenAI I
hadn’t observed up close someone else drive the formation of a startup.</p>

<p>OpenAI wouldn’t have happened without Greg. &nbsp;He commits
quickly and fully to things. &nbsp;I organized a group dinner early on to talk about
what such an organization might look like, and drove him home afterwards.&nbsp;
Greg asked me questions for the first half of the drive back to San Francisco,
then declared he was in, and started planning logistics for the rest of the
drive.</p>

<p>From then on he was fully in, with an average email response
time of about 5 minutes to anything.&nbsp; Elon and I were both busy with day
jobs, but Greg kept everything moving forward with imperfect information and a
very high-latency connection.</p>

<p>He recruited the founding team. &nbsp;Greg is a world-class recruiter
(he plans every detail of interviews, heavily researches candidate’s
backgrounds, sends thoughtful and persistent followups, and so on), and&nbsp;I
now believe even more strongly that someone on the founding team has to be an
amazing recruiter.</p>

<p>He’s incredibly open to feedback.&nbsp; Large or small, he’s
always willing to hear it, never gets offended, and processes it very
quickly.&nbsp; I once suggested to him that he wasn't communicating a bold
enough vision for the organization, and&nbsp;the next time I heard him talk
about it (and every time since) it was&nbsp;a perfectly calibrated explanation
of how we were going to succeed at something that really mattered.&nbsp; Even
on non-traditional ideas, like when I suggested he co-lead the organization with
Ilya, he was always open-minded and thoughtful.</p>

<p>Greg also played the role of ‘non-technical cofounder’, which is
a misnomer because most people who know him will say something like “Greg is
the most productive engineer I know”.&nbsp; But he took on all the
non-technical roles at the beginning, defining the culture, making offers,
organizing offsites, letting everyone work out of his apartment, ordering
supplies, cleaning up after meals, etc.&nbsp; It's important to have someone
great in this role at a small startup—many people gloss over it.</p>

<p>Without someone dedicated to finding a solution to all problems,
no matter how difficult, eventually a large problem will come along and kill you while you’re
still weak.&nbsp; Founding teams need a Chief
Optimist to rally everyone to press on despite the difficulties, and it’s always hard on that
person because they can’t really lean on anyone else in the hardest times.</p>

<p>You for sure need great technical talent on a founding team, but
make sure you also have someone like Greg.&nbsp; If they’re the same person,
then you’ve hit the jackpot.</p></div>


  </article>

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Surveillance Tech Write Press Releases for Cops; News Agencies Are Publishing It (102 pts)]]></title>
            <link>https://www.techdirt.com/2023/11/17/surveillance-tech-companies-are-writing-press-releases-for-cops-worse-news-agencies-are-publishing-them/</link>
            <guid>38322208</guid>
            <pubDate>Sat, 18 Nov 2023 17:48:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/11/17/surveillance-tech-companies-are-writing-press-releases-for-cops-worse-news-agencies-are-publishing-them/">https://www.techdirt.com/2023/11/17/surveillance-tech-companies-are-writing-press-releases-for-cops-worse-news-agencies-are-publishing-them/</a>, See on <a href="https://news.ycombinator.com/item?id=38322208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-425240">


<h3>from the <i>you-both-serve-the-public.-try-that-out-sometime.</i> dept</h3>

<p>There’s nothing new about cop shops letting their tech providers write their press releases for them. Law enforcement officers <em>love</em> power but often think nothing of surrendering their autonomy to the providers of the snooping tools.</p>
<p>For years, Harris Corporation — the maker of Stingray devices — told cops what they could or couldn’t say about their use of the tech, tying them up (often <a href="https://www.techdirt.com/2015/05/18/fbi-says-it-has-no-idea-why-law-enforcement-agencies-are-following-terms-stingray-non-disclosure-agreements/" data-type="link" data-id="https://www.techdirt.com/2015/05/18/fbi-says-it-has-no-idea-why-law-enforcement-agencies-are-following-terms-stingray-non-disclosure-agreements/">with the help</a> of the FBI) with <a href="https://www.techdirt.com/2018/01/25/harris-stingray-nondisclosure-agreement-forbids-cops-telling-legislators-about-surveillance-tech/" data-type="link" data-id="https://www.techdirt.com/2018/01/25/harris-stingray-nondisclosure-agreement-forbids-cops-telling-legislators-about-surveillance-tech/">non-disclosure agreements</a>. Ring — the biggest name in front-door surveillance — has given cops cameras to hand out in exchange for expanding its customer base and <a href="https://www.techdirt.com/2019/07/30/amazons-free-doorbell-cameras-only-cost-law-enforcement-agencies-their-dignity-autonomy/" data-type="link" data-id="https://www.techdirt.com/2019/07/30/amazons-free-doorbell-cameras-only-cost-law-enforcement-agencies-their-dignity-autonomy/">allowing Ring to man the PR front</a>.</p>
<p>And <a href="https://www.techdirt.com/2017/09/07/police-chief-says-hell-decide-who-is-isnt-real-journalist/" data-type="link" data-id="https://www.techdirt.com/2017/09/07/police-chief-says-hell-decide-who-is-isnt-real-journalist/">there’s nothing new</a> about so-called journalists <a href="https://www.techdirt.com/2016/11/28/media-critic-calls-journalists-to-be-obedient-stenographers/" data-type="link" data-id="https://www.techdirt.com/2016/11/28/media-critic-calls-journalists-to-be-obedient-stenographers/">acting as stenographers</a> for cops. When something happens that suggests police misconduct, <a href="https://www.techdirt.com/2015/06/11/every-kill-good-kill-how-police-media-cooperate-to-disparage-dead/" data-type="link" data-id="https://www.techdirt.com/2015/06/11/every-kill-good-kill-how-police-media-cooperate-to-disparage-dead/">some journalists do nothing more</a> than publish PD press releases and/or seek comment only from law enforcement PR reps or (vomits in mouth) police union representatives.</p>
<p>Perhaps its these years of underservice that has led to press outlets publishing full-page ads for tech providers, apparently without feeling they might be crossing ethical lines. That’s what’s being called out by the EFF in its post titled “<a href="https://www.eff.org/deeplinks/2022/11/rise-police-advertiser" data-type="link" data-id="https://www.eff.org/deeplinks/2022/11/rise-police-advertiser">The Rise of the Police-Advertiser.</a>” Who exactly is being served when “journalists” add a couple of sentences to name brand heavy posts that unabashedly celebrate the products and the cops that claim these tech marvels pretty much pay for themselves?</p>
<blockquote>
<p><em>In August, the Tulsa police department held a&nbsp;<a href="https://ktul.com/news/local/tulsa-police-to-hold-press-conference-about-success-of-flock-safety-devices">press conference</a>&nbsp;about how its new Automated License Plate Readers (ALPRs), a&nbsp;<a href="https://www.eff.org/deeplinks/2020/09/flock-license-plate-reader-homeowners-association-safe-problems">controversial</a>&nbsp;piece of surveillance technology, was the policing equivalent of “turning the lights on” for the first time. In Ontario, California, the city put out a&nbsp;<a href="https://www.ontarioca.gov/press_releases/flock-cameras-assist-apprehension-burglary-suspect">press release</a>&nbsp;about how its ALPRs were a “vital resource.” In Madison, South Dakota,&nbsp;<a href="https://www.dakotanewsnow.com/2022/09/01/how-states-first-flock-safety-camera-busted-car-thieves-madison/">local news</a>&nbsp;covered how the city’s expenditure of $30,000 for ALPRs “paid off” twice in two days. &nbsp;</em></p>
</blockquote>
<p>Let’s go to the local piece (he said, living in South Dakota). Here’s an eagle-eye view of this so-called reporting, with the name brand of the tech central to piece highlighted:</p>
<div>
<figure><img fetchpriority="high" decoding="async" width="773" height="863" src="https://i0.wp.com/www.techdirt.com/wp-content/uploads/2023/11/Screenshot-2023-11-12-6.29.59-PM.png?resize=773%2C863&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.techdirt.com/wp-content/uploads/2023/11/Screenshot-2023-11-12-6.29.59-PM.png?w=773&amp;ssl=1 773w, https://i0.wp.com/www.techdirt.com/wp-content/uploads/2023/11/Screenshot-2023-11-12-6.29.59-PM.png?resize=269%2C300&amp;ssl=1 269w, https://i0.wp.com/www.techdirt.com/wp-content/uploads/2023/11/Screenshot-2023-11-12-6.29.59-PM.png?resize=768%2C857&amp;ssl=1 768w, https://i0.wp.com/www.techdirt.com/wp-content/uploads/2023/11/Screenshot-2023-11-12-6.29.59-PM.png?resize=600%2C670&amp;ssl=1 600w" sizes="(max-width: 773px) 100vw, 773px" data-recalc-dims="1"></figure>
</div>
<p>Does that look like journalism to you? Flock flock flock flock flock flock flock. Six times, including the headline. This is an advertisement for Flock, published for free by KSFY and distributed by other local news sources who had to do nothing but credit KSFY for its original “reporting.” That’s six mentions of Flock and a couple of statements from a PD official who saw the plate readers hit twice and somehow decided this was newsworthy enough he should call the local station.</p>
<p>Or maybe Madison Police Chief Justin Meyer didn’t even have to place a call. Maybe all he needed to do was insert a few words into Flock’s PR boilerplate and email it to the nearest news agencies. That’s what Flock does: it writes most of the words and instructs cops to fill in the blanks.</p>
<blockquote>
<p><em>Flock Safety has distributed a&nbsp;<a href="https://flocksafety.showpad.com/share/v7QdbufyT5cXl2UQzowre">Public Information Officer Toolkit</a>, providing “resources and templates for public information officers.” A Flock draft press release states:</em></p>
</blockquote>
<blockquote>
<p><em>The ___ Police Department has solved [CRIME] with the help of their Flock Safety camera system. Flock Safety ALPR cameras help law enforcement investigate crime by providing objective evidence. [CRIME DETAILS AND STORY] ____ Police installed Flock cameras on [DATE] to solve and reduce crime in [CITY].</em></p>
</blockquote>
<blockquote>
<p><em>This Mad Libs of a press release is an advertisement, and one Flock hopes your police departments will distribute so that they can sell more ALPRs.</em></p>
</blockquote>
<p>I can only hope some news outlet lets one of these hit the front page of their website with half-completed boilerplate. Sooner or later, someone from the cop PR department is going to send out an email blast that trumpets the success of [INSERT TECH PROVIDER] in solving [CRIME DETAILS AND STORY].</p>
<p>Flock isn’t alone. In addition to the previously mentioned Harris and Ring, ShotSpotter has its own PR wing that pretty much composes press releases for cops and pushes them to become unpaid brand ambassadors for a brand <a href="https://www.techdirt.com/2021/08/23/investigation-shotspotters-practices-is-raising-questions-companys-angry-statement-really-doesnt-answer/" data-type="link" data-id="https://www.techdirt.com/2021/08/23/investigation-shotspotters-practices-is-raising-questions-companys-angry-statement-really-doesnt-answer/">so controversial</a> it recently <a href="https://www.techdirt.com/2023/04/19/shotspotter-attempts-to-memory-hole-itself-rebrands-as-soundthinking/" data-type="link" data-id="https://www.techdirt.com/2023/04/19/shotspotter-attempts-to-memory-hole-itself-rebrands-as-soundthinking/">rebranded</a> as “SoundThinking.”</p>
<blockquote>
<p><em>A 2021&nbsp;<a href="https://ir.shotspotter.com/annual-reports/content/0001564590-21-016134/0001564590-21-016134.pdf">yearly report</a>&nbsp;to the SEC filed by&nbsp;<a href="https://www.nbcnews.com/news/us-news/shotspotter-police-gunshot-technology-federal-grants-rcna13815">ShotSpotter</a>, an acoustic gunshot detection company, reports that their marketing team “leveraged our extremely satisfied and loyal customer base to create a significant set of new ‘success stories’ that show proof of value to prospects…. In the area of public relations, we work closely with many of our customers to help them communicate the success of ShotSpotter to their local media and communities.”</em></p>
</blockquote>
<p>This is ugly stuff. Not only does it damage the trustworthiness of journalistic outlets, it makes cops appear to be nothing more than pushers of tech company propaganda. None of this appears organic. And that’s because none of it is.</p>
<p>In both cases, the public is being screwed by entities they’d rather trust. The sad thing is neither of these entities appear to care they’re harming their relationship with the people they serve. Understaffed news desks are more than happy to simply republish garbage like this because it frees them up to handle stuff they actually care about. And cops are only too happy to do this because it means their tech supplier will be pleased with their obeisance and possibly shower them with freebies or preferential pricing.</p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/alpr/" rel="tag">alpr</a>, <a href="https://www.techdirt.com/tag/madison-police-department/" rel="tag">madison police department</a>, <a href="https://www.techdirt.com/tag/police/" rel="tag">police</a>, <a href="https://www.techdirt.com/tag/press-releases/" rel="tag">press releases</a>, <a href="https://www.techdirt.com/tag/privacy/" rel="tag">privacy</a>, <a href="https://www.techdirt.com/tag/surveillance/" rel="tag">surveillance</a>
<br>
Companies: <a href="https://www.techdirt.com/company/flock-safety/" rel="category tag">flock safety</a>, <a href="https://www.techdirt.com/company/harris-corp/" rel="category tag">harris corp.</a>, <a href="https://www.techdirt.com/company/shotspotter/" rel="category tag">shotspotter</a>, <a href="https://www.techdirt.com/company/soundthinking/" rel="category tag">soundthinking</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Frigate: Open-source network video recorder with real-time AI object detection (299 pts)]]></title>
            <link>https://frigate.video/</link>
            <guid>38321413</guid>
            <pubDate>Sat, 18 Nov 2023 16:44:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frigate.video/">https://frigate.video/</a>, See on <a href="https://news.ycombinator.com/item?id=38321413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main id="content"><div id="hero"><p><img src="https://frigate.video/images/ui.jpg" alt="App preview"></p><div><h2>Monitor your security cameras with locally processed AI</h2><div><p>Frigate is an open source NVR built around real-time AI object detection. All processing is performed locally on your own hardware, and your camera feeds never leave your home.</p><p><strong>Coming Soon:</strong> Get access to custom models designed specifically for Frigate with Frigate+.</p></div></div></div><div id="features"><div><p><img src="https://frigate.video/images/detection.jpg" alt="App preview on a phone and tablet"></p><div><h3>Reduce false positives with local object detection</h3><p>Traditional NVRs can require hours of fine tuning to reduce false positive rates because they rely on simple motion detection. By offloading object detection to the <a href="https://coral.ai/">Google Coral TPU</a>, even modest hardware can run advanced analysis to determine if the motion is actually a person, car, or other object of interest. With Frigate's local processing, there is no need to pay for your personal camera footage to be sent to the cloud for analysis.</p></div></div><div><p><img src="https://frigate.video/images/events-mobile-cropped.jpg" alt="App users welcoming a new member"></p><div><h3>Stop reviewing shadows and wind and start reviewing detections that matter</h3><p>Let Frigate's AI scrub your video feeds for you. With a single Google Coral TPU, Frigate can run 100+ object detections per second so it doesn't miss a single frame.</p></div></div><div><p><img src="https://frigate.video/images/driveway_zones-min.png" alt="App users welcoming a new member"></p><div><h3>Fine tune your events and alerts with zones</h3><p>Frigate tracks objects in real-time and can determine the exact moment a person starts walking up your front steps or when a car enters your driveway. Refine your notifications based on precise locations.</p></div></div><div><p><img src="https://frigate.video/images/hass-opt.png" alt="App user profile preview"></p><div><h3>Integrate with Home Assistant and other automation platforms</h3><p>Give your home eyes by integrating object detection into Home Assistant, OpenHab, NodeRed, or anything with MQTT support. Frigate integrates directly into Home Assistant's media browser, provides low latency camera entities, and exposes real-time sensors and switches to power automations and notifications to your heart's content.</p></div></div><div><p><img src="https://frigate.video/images/birdseye-2-optimized.jpg" alt="App user profile preview"></p><div><h3>Watch a dynamic real-time video feed for your cameras</h3><p>Birdseye view dynamically renders cameras with active detections so you can easily see cameras of interest. Stop squinting at a tiny square in a grid of cameras to see what is happening.</p></div></div></div><div id="reviews"><blockquote><div><p>Frigate's high level of customizability, fast object detection and tight integration with  Home Assistant creates the perfect open source, locally controlled, security camera system.</p></div></blockquote><blockquote><div><p>Frigate has helped me reduce hours of false detections from my hard drive and saved me maybe as much time scouring through said, uneventful, footage. Ok maybe not that much, but seriously,  zero false detections.</p></div></blockquote><blockquote><div><p>Frigate has allowed me to remove all cloud dependencies from my security cameras, without losing  any sort of object detection features or recording history. Support is second to none. Highly recommended.</p></div></blockquote></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is embedding inaudible watermarks into its AI generated music (113 pts)]]></title>
            <link>https://www.theverge.com/2023/11/16/23963607/google-deepmind-synthid-audio-watermarks</link>
            <guid>38321324</guid>
            <pubDate>Sat, 18 Nov 2023 16:36:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/11/16/23963607/google-deepmind-synthid-audio-watermarks">https://www.theverge.com/2023/11/16/23963607/google-deepmind-synthid-audio-watermarks</a>, See on <a href="https://news.ycombinator.com/item?id=38321324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Audio created using Google DeepMind’s AI Lyria model, such as tracks made with <a href="https://www.theverge.com/2023/11/16/23963570/youtube-generative-ai-dream-track-music-tools-voice-clone">YouTube’s new audio generation features</a>, will be watermarked with SynthID to let people identify their AI-generated origins after the fact. In a <a href="https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/">blog post</a>, DeepMind said the watermark shouldn’t be detectable by the human ear and “doesn’t compromise the listening experience,” and added that it should still be detectable even if an audio track is compressed, sped up or down, or has extra noise added.</p><p>Watermarking tools like SynthID are seen as an important safeguard against some of the harms of generative AI. <a href="https://www.theverge.com/2023/10/30/23914507/biden-ai-executive-order-regulation-standards">President Joe Biden’s executive order on artificial intelligence</a>, for example, calls for a new set of government-led standards for watermarking AI-generated content. It’s a promising area, but current technologies are <a href="https://www.theverge.com/2023/10/31/23940626/artificial-intelligence-ai-digital-watermarks-biden-executive-order">far from a silver bullet</a> to defend against fakes.</p><p>According to DeepMind, SynthID’s audio implementation works by “converting the audio wave into a two-dimensional visualization that shows how the spectrum of frequencies in a sound evolves over time.” It claims the approach is “unlike anything that exists today.”</p><p>The news that Google is embedding the watermarking feature into AI-generated audio comes just a few short months after the company released <a href="https://www.theverge.com/2023/8/29/23849107/synthid-google-deepmind-ai-image-detector">SynthID in beta</a> for images created by Imagen on Google Cloud’s Vertex AI. The watermark is resistant to editing like cropping or resizing, although DeepMind cautioned that it’s not foolproof against “<a href="https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/#:~:text=SynthID%20isn%E2%80%99t%20foolproof,video%2C%20and%20text.">extreme image manipulations.</a>”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Details emerge of surprise board coup that ousted CEO Sam Altman at OpenAI (363 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/</link>
            <guid>38321003</guid>
            <pubDate>Sat, 18 Nov 2023 16:07:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/">https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/</a>, See on <a href="https://news.ycombinator.com/item?id=38321003">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Things fall apart    —
</h4>
            
            <h2 itemprop="description">Microsoft CEO Nadella "furious"; OpenAI President and three senior researchers resign.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/sutskever_header_2-800x450.jpg" alt="Ilya Sutskever, OpenAI Chief Scientist, speaks at Tel Aviv University on June 5, 2023.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/sutskever_header_2.jpg" data-height="675" data-width="1200">Enlarge</a> <span>/</span> Ilya Sutskever, OpenAI Chief Scientist, speaks at Tel Aviv University on June 5, 2023.</p></figcaption>  </figure>

  




<!-- cache hit 181:single/related:94cf44775f0ab56ff87fde04dd3d1807 --><!-- empty -->
<p>On Friday, OpenAI <a href="https://arstechnica.com/ai/2023/11/openai-fires-ceo-sam-altman-citing-less-than-candid-communications/">fired CEO Sam Altman</a> in a surprise move that led to the <a href="https://arstechnica.com/information-technology/2023/11/openai-president-greg-brockman-quits-as-nervous-employees-hold-all-hands-meeting/">resignation</a> of President Greg Brockman and <a href="https://x.com/hellokillian/status/1725797467315486902?s=20">three senior scientists</a>. The move also blindsided key investor and minority owner Microsoft, <a href="https://www.bloomberg.com/news/articles/2023-11-18/openai-altman-ouster-followed-debates-between-altman-board#xj4y7vzkg">reportedly</a> making CEO Satya Nadella furious. As Friday night wore on, <a href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety">reports emerged</a> that the ousting was likely orchestrated by Chief Scientist Ilya Sutskever over concerns about the safety and speed of OpenAI's tech deployment.</p>

<p>"This was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAI builds AGI that benefits all of humanity," Sutskever told employees at an emergency all-hands meeting on Friday afternoon, as reported by <a href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety">The Information</a>.</p>
<p>Since its founding, OpenAI has pursued the development of artificial general intelligence (or AGI), which is a hypothetical technology that would be able to perform any intellectual task a human can do, potentially replacing a large number of humans at their jobs.</p>
<p>Internally at OpenAI, insiders say that disagreements had emerged over the speed at which Altman was pushing for commercialization and company growth, with Sutskever arguing to slow things down. Sources <a href="https://x.com/karaswisher/status/1725702612379378120?s=20">told</a> reporter Kara Swisher that OpenAI's <a href="https://arstechnica.com/information-technology/2023/11/openai-introduces-gpt-4-turbo-larger-memory-lower-cost-new-knowledge/">Dev Day event</a> on November 6, with Altman front and center in a keynote pushing consumer-like products, was an "inflection moment of Altman pushing too far, too fast."</p>
<p>In a <a href="https://x.com/gdb/status/1725736242137182594?s=20">joint statement</a> released Friday night, Altman and Brockman said they were "shocked and saddened" by the board's actions. And they weren't the only ones shocked by the news, as tech insiders took to social media on Friday to share their reactions. Angel investor Ron Conway <a href="https://x.com/RonConway/status/1725759359748309381?s=20">wrote</a>, "What happened at OpenAI today is a Board coup that we have not seen the likes of since 1985 when the then-Apple board pushed out Steve Jobs. It is shocking; it is irresponsible; and it does not do right by Sam &amp; Greg or all the builders in OpenAI."</p>                                            
                                                        
<p>OpenAI has an <a href="https://openai.com/our-structure">unusual structure</a> where its for-profit arm is owned and controlled by a non-profit 501(c)(3) public charity. Prior to yesterday, that non-profit was controlled by a board of directors that <a href="https://www.forbes.com/sites/alexkonrad/2023/11/17/these-are-the-people-that-fired-openai-ceo-sam-altman/">included</a> Altman, Brockman, Ilya Sutskever and three others who were not OpenAI employees: Adam D’Angelo, the CEO of Quora; Tasha McCauley, an adjunct senior management scientist at RAND corporation; and Helen Toner, director of strategy and foundational research grants at Georgetown’s Center for Security and Emerging Technology. Now, only Sutskever, D'Angelo, McCauley, and Toner remain.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure.jpg" data-height="652" data-width="873" alt="A block diagram of OpenAI's unusual structure, provided by OpenAI."><img alt="A block diagram of OpenAI's unusual structure, provided by OpenAI." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure-640x478.jpg" width="640" height="478" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/openai_Structure.jpg" data-height="652" data-width="873">Enlarge</a> <span>/</span> A block diagram of OpenAI's unusual structure, provided by OpenAI.</p></figcaption></figure>
<h2>Surprise moves and turmoil</h2>
<p>According to the joint statement from Brockman and Altman, Altman's firing came as a complete surprise to the pair, and they laid out a rough timeline of what happened. On Thursday night, Altman was asked to attend a remote board meeting on Friday at noon. The next day, Brockman, who was Chairman of the OpenAI board, was not invited to this board meeting, where Altman was fired.</p>

<p>Around 30 minutes later, Brockman was informed by Sutskever that he was being removed from his board role but could remain at the company, and that Altman had been fired (Brockman declined, and <a href="https://arstechnica.com/information-technology/2023/11/openai-president-greg-brockman-quits-as-nervous-employees-hold-all-hands-meeting/">resigned</a> his role later on Friday). According to Brockman, the OpenAI management team was only made aware of these moves shortly after the fact, but former CTO (now interim CEO) Mira Murati had been informed on Thursday night.</p>
<p>Key questions remain about accusations made against Altman in the <a href="https://openai.com/blog/openai-announces-leadership-transition">OpenAI blog post</a> that announced his departure, where the board said that Altman "was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities." That has yet to be clarified by the company, but insiders say the move was mostly a power play that resulted from a cultural schism between Altman and Sutskever over Altman's <a href="https://x.com/karaswisher/status/1725733594310512775?s=20">management style</a> and drive for high-profile publicity. On September 29, Sutskever <a href="https://x.com/ilyasut/status/1707752576077176907?s=20">tweeted</a>, "Ego is the enemy of growth."</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-scaled.jpg" data-height="1707" data-width="2560" alt="Sam Altman and Ilya Sutskever speak together at Tel Aviv University on June 5, 2023."><img alt="Sam Altman and Ilya Sutskever speak together at Tel Aviv University on June 5, 2023." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-640x427.jpg" width="640" height="427" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-1280x853.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/GettyImages-1258459514-scaled.jpg" data-height="1707" data-width="2560">Enlarge</a> <span>/</span> Sam Altman and Ilya Sutskever speak together at Tel Aviv University on June 5, 2023.</p></figcaption></figure>
<p>The schism is causing further turmoil on the inside. Three AI researchers loyal to Altman departed the company as well on Friday, resigning in reaction to the news: Jakub Pachocki, GPT-4 lead and OpenAI's director of research; Aleksander Madry, head of a team evaluating AI risk, and Szymon Sidor, an open source baselines researcher.</p>
<h2>Pushing back the "veil of ignorance"</h2>
<p>Rumors have already begun swirling about potential internal breakthroughs at OpenAI that may have intensified the slow/fast rift within the company, owing to Sutskever's role as co-lead of a "<a href="https://openai.com/blog/introducing-superalignment">Superalignment</a>" team that is tasked with figuring out how to control hypothetical superintelligent AI. At the APEC CEO Summit on Thursday, Altman <a href="https://x.com/thecaptain_nemo/status/1725743009629983215?s=20">said</a>, "Four times now in the history of OpenAI—the most recent time was just in the last couple of weeks—I’ve gotten to be in the room when we push the veil of ignorance back and the frontier of discovery forward. And getting to do that is like the professional honor of a lifetime."</p>

<p>The concern here not necessarily being that OpenAI has developed superintelligence, which experts say is unlikely, but that the new breakthrough Altman mentioned may have added pressure to a company that is fighting within itself to proceed safely (from its non-profit branch) but also make money (from its for-profit subsidiary). Altman also <a href="https://arstechnica.com/ai/2023/11/openai-ceo-sam-altman-wants-to-build-ai-superintelligence/">recently said</a> that GPT-5, presumed to be a powerful successor to the <a href="https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/">alarm-causing GPT-4</a>, is now in development.</p>
<p>As news spread, some predictably shared quips on social media. X user shaurya <a href="https://x.com/shauseth/status/1725757968619278587?s=20">wrote</a>, "this is like the roman empire for people who do matrix multiplication." And AI futurist Daniel Jeffries <a href="https://x.com/Dan_Jeffries1/status/1725807257772872062?s=20">said</a>, "<span>The entire AI industry would like to thank the OpenAI board for giving us all a chance to catch up.</span>"</p>
<p>But not all reactions were doom and gloom. As Friday night wore on, some at OpenAI made forward-looking statements. Evan Morikawa, Engineering Manager at OpenAI <a href="https://x.com/E0M/status/1725721507161395415?s=20">wrote on X</a>, "For those wondering what’ll happen next, the answer is we’ll keep shipping. @sama &amp; @gdb weren’t micro-managers. The ✨ comes from the many geniuses here in research product eng &amp; design. There’s clear internal uniformity among these leaders that we’re here for the bigger mission."</p>
<p>Expect to hear more on the OpenAI board's side of the story as further details emerge.</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I disagree with Geoff Hinton regarding "glorified autocomplete" (134 pts)]]></title>
            <link>https://statmodeling.stat.columbia.edu/2023/11/18/i-disagree-with-geoff-hinton-regarding-glorified-autocomplete/</link>
            <guid>38320698</guid>
            <pubDate>Sat, 18 Nov 2023 15:39:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://statmodeling.stat.columbia.edu/2023/11/18/i-disagree-with-geoff-hinton-regarding-glorified-autocomplete/">https://statmodeling.stat.columbia.edu/2023/11/18/i-disagree-with-geoff-hinton-regarding-glorified-autocomplete/</a>, See on <a href="https://news.ycombinator.com/item?id=38320698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>Computer scientist and <a rel="nofollow" href="https://www.newyorker.com/magazine/2023/11/20/geoffrey-hinton-profile-ai">“godfather of AI”</a> Geoff Hinton says this about chatbots:</p>
<blockquote><p>“People say, It’s just glorified autocomplete . . . Now, let’s analyze that. Suppose you want to be really good at predicting the next word. If you want to be really good, you have to understand what’s being said. That’s the only way. So by training something to be really good at predicting the next word, you’re actually forcing it to understand. Yes, it’s ‘autocomplete’—but you didn’t think through what it means to have a really good autocomplete.”</p></blockquote>
<p>This got me thinking about what I do at work, for example in a research meeting.  I spend a lot of time doing “glorified autocomplete” in the style of a well-trained chatbot:  Someone describes some problem, I listen and it reminds me of a related issue I’ve thought about before, and I’m acting as a sort of FAQ, but more like a chatbot than a FAQ in that the people who are talking with me do not need to navigate through the FAQ to find the answer that is most relevant to them; I’m doing that myself and giving a response.</p>
<p>I do that sort of thing a lot in meetings, and it can work well, indeed often I think this sort of shallow, associative response can be more effective than whatever I’d get from a direct attack on the problem in question.  After all, the people I’m talking with have already thought for awhile about whatever it is they’re working on, and my initial thoughts may well be in the wrong direction, or else my thoughts are in the right direction but are just retracing my collaborators’ past ideas.  From the other direction, my shallow thoughts can be useful in representing insights from problems that these collaborators had not ever thought about much before.  Nonspecific suggestions on multilevel modeling or statistical graphics or simulation or whatever can really help!</p>
<p>At some point, though, I’ll typically have to bite the bullet and think hard, not necessarily reaching full understanding in the sense of mentally embedding the problem at hand into a coherent schema or logical framework, but still going through whatever steps of logical reasoning that I can.  This feels different than autocomplete; it requires an additional level of focus.  Often I need to consciously “flip the switch,” as it were, to turn on that focus and think rigorously.  Other times, I’m doing autocomplete and either come to a sticking point or encounter an interesting idea, and this causes me to stop and think.</p>
<p>It’s almost like the difference between jogging and running.  I can jog and jog and jog, thinking about all sorts of things and not feeling like I’m expending much effort, my legs pretty much move up and down of their own accort . . . but then if I need to <em>run</em>, that takes concentration.</p>
<p>Here’s another example.  Yesterday I participated in the methods colloquium in our political science department.  It was Don Green and me and a bunch of students, and the structure was that Don asked me questions, I responded with various statistics-related and social-science-related musings and stories, students followed up with questions, I responded with more stories, etc.  Kinda like the way things go here on the blog, but spoken rather than typed.  Anyway, the point is that most of my responses were a sort of autocomplete—not in a word-by-word chatbot style, more at a larger level of chunkiness, for example something would remind me of a story, and then I’d just insert the story into my conversation—but still at this shallow, pleasant level.  Mellow conversation with no intellectual or social strain.  But then, every once in awhile, I’d pull up short and have some new thought, some juxtaposition that had never occurred to me before, and I’d need to think things through.</p>
<p>This also happens when I give prepared talks.  My prepared talks are not super-well prepared—this is on purpose, as I find that too much preparation can inhibit flow.  In any case, I’ll often finding myself stopping and pausing to reconsider something or another.  Even when describing something I’ve done before, there are times when I feel the need to think it all through logically, as if for the first time.  I noticed something similar when I saw my sister give a talk once:  she had the same habit of pausing to work things out from first principles.  I don’t see this behavior in every academic talk, though; different people have different styles of presentation.</p>
<p>This seems related to models of associative and logical reasoning in psychology.  As a complete non-expert in that area, I’ll turn <a rel="nofollow" href="https://en.wikipedia.org/wiki/Dual_process_theory">to wikipedia</a>:</p>
<blockquote><p>The foundations of dual process theory likely come from William James. He believed that there were two different kinds of thinking: associative and true reasoning. . . . images and thoughts would come to mind of past experiences, providing ideas of comparison or abstractions. He claimed that associative knowledge was only from past experiences describing it as “only reproductive”. James believed that true reasoning could enable overcoming “unprecedented situations” . . .</p></blockquote>
<p>That sounds about right!</p>
<p>After describing various other theories from the past hundred years or so, Wikipedia continues:</p>
<blockquote><p>Daniel Kahneman provided further interpretation by differentiating the two styles of processing more, calling them intuition and reasoning in 2003. Intuition (or system 1), similar to associative reasoning, was determined to be fast and automatic, usually with strong emotional bonds included in the reasoning process. Kahneman said that this kind of reasoning was based on formed habits and very difficult to change or manipulate. Reasoning (or system 2) was slower and much more volatile, being subject to conscious judgments and attitudes.</p></blockquote>
<p>This sounds a bit different from what I was talking about above.  When I’m doing “glorified autocomplete” thinking, I’m still <em>thinking</em>—this isn’t automatic and barely conscious behavior along the lines of driving to work along a route I’ve taken a hundred times before—; I’m just thinking in a shallow way, trying to “autocomplete” the answer.  It’s pattern-matching more than it is logical reasoning.</p>
<p><strong>P.S.</strong>  Just to be clear, I have a lot of respect for Hinton’s work; indeed, Aki and I included Hinton’s work in our brief review of <a rel="nofollow" href="https://news.columbia.edu/news/top-10-ideas-statistics-ai">10 pathbreaking research articles during the past 50 years of statistics and machine learning</a>.  Also, I’m not trying to make a hardcore, AI-can’t-think argument.  Although not myself a user of large language models, I respect <a href="https://statmodeling.stat.columbia.edu/2023/08/20/report-on-the-large-language-model-meeting-at-berkeley/">Bob Carpenter’s respect</a> for them.</p>
<p>I think that where Hinton got things wrong in the quote that led off this post was not in his characterization of chatbots, but rather in his assumptions about human thinking, in not distinguishing autocomplete-like associative reasoning with logical thinking.  Maybe Hinton’s problem in understanding this is that he’s just too logical!  At work, I do a lot of what seems like autocomplete—and, as I wrote above, I think it’s useful—but if I had more discipline, maybe I’d think more logically and carefully all the time.  It could well be that Hinton has that habit or inclination to always be in focus.  If Hinton does not have consistent personal experience of shallow, autocomplete-like thinking, he might not recognize it as something different, in which case he could be giving the chatbot credit for something it’s not doing.</p>
<p>Come to think of it, one thing that impresses me about Bob is that, when he’s working, he seems to always be on focus.  I’ll be in a meeting, just coasting along, and Bob will interrupt someone to ask for clarification, and I suddenly realize that Bob absolutely <em>demands</em> understanding.  He seems to have no interest in participating in a research meeting in a shallow way.  I guess we just have different styles.  It’s my impression that the vast majority of researchers are like me, just coasting on the surface most of the time (for some people, all of the time!), while Bob, and maybe Geoff Hinton, is one of the exceptions.</p>
<p><strong>P.P.S.</strong>  Sometimes we really want to be doing shallow, auto-complete-style thinking.  For example, if we’re <a href="https://statmodeling.stat.columbia.edu/2023/06/13/world-premiere-performance-of-recursion-is-tonight/">writing a play</a> and want to simulate how some characters might interact.  Or just as a way of casting the intellectual net more widely.  When I’m in a research meeting and I free-associate, it might not help immediately solve the problem at hand, but it can bring in connections that will be helpful later.  So I’m not knocking auto-complete; I’m just disagreeing with Hinton’s statement that “by training something to be really good at predicting the next word, you’re actually forcing it to understand.”  As a person who does a lot of useful associative reasoning and also a bit of logical understanding, I think they’re different, both in how they feel and also in what they do.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cryptographers solve decades-old privacy problem (238 pts)]]></title>
            <link>https://nautil.us/cryptographers-solve-decades-old-privacy-problem-444899/</link>
            <guid>38320675</guid>
            <pubDate>Sat, 18 Nov 2023 15:37:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/cryptographers-solve-decades-old-privacy-problem-444899/">https://nautil.us/cryptographers-solve-decades-old-privacy-problem-444899/</a>, See on <a href="https://news.ycombinator.com/item?id=38320675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>W</span>e all know to be careful about the details we share online, but the information we seek can also be revealing. Search for driving directions, and our location becomes far easier to guess. Check for a password in a trove of compromised data, and we risk leaking it ourselves.</p><p>These situations fuel a key question in cryptography: How can you pull information from a public database without revealing anything about what you’ve accessed? It’s the equivalent of checking out a book from the library without the librarian knowing which one.</p>
      
    <p>Concocting a strategy that solves this problem—known as private information retrieval—is “a very useful building block in a number of privacy-preserving applications,” said&nbsp;<a href="https://www.cs.utexas.edu/~dwu4/" target="_blank" rel="noreferrer noopener">David Wu</a>, a cryptographer at the University of Texas, Austin. Since the 1990s, researchers have chipped away at the question, improving strategies for privately accessing databases. One major goal, still impossible with large databases, is the equivalent of a private Google search, where you can sift through a heap of data anonymously without doing any heavy computational lifting.</p><blockquote>
<p>It would be like having a librarian scour every shelf before returning with your book.</p>
</blockquote>
          <p>Now, three researchers have&nbsp;<a href="https://eprint.iacr.org/2022/1703" target="_blank" rel="noreferrer noopener">crafted</a>&nbsp;a long-sought version of private information retrieval and extended it to build a more general privacy strategy. The work, which received a&nbsp;<a href="https://www.sigact.org/prizes/best_paper.html" target="_blank" rel="noreferrer noopener">Best Paper Award</a>&nbsp;in June at the annual&nbsp;<a href="http://acm-stoc.org/stoc2023/" target="_blank" rel="noreferrer noopener">Symposium on Theory of Computing</a>, topples a major theoretical barrier on the way to a truly private search.</p><p>“[This is] something in cryptography that I guess we all wanted but didn’t quite believe that it exists,” said&nbsp;<a href="http://people.csail.mit.edu/vinodv/" target="_blank" rel="noreferrer noopener">Vinod Vaikuntanathan</a>, a cryptographer at the Massachusetts Institute of Technology who was not involved in the paper. “It is a landmark result.”</p><p>The problem of private database access took shape in the 1990s. At first, researchers assumed that the only solution was to scan the entire database during every search, which would be like having a librarian scour every shelf before returning with your book. After all, if the search skipped any section, the librarian would know that your book is not in that part of the library.</p><p>That approach works well enough at smaller scales, but as the database grows, the time required to scan it grows at least proportionally. As you read from bigger databases—and the internet is a pretty big one—the process becomes prohibitively inefficient.</p>
          <p>In the early 2000s, researchers started to suspect they could dodge the full-scan barrier by “preprocessing” the database. Roughly, this would mean encoding the whole database as a special structure, so the server could answer a query by reading just a small portion of that structure. Careful enough preprocessing could, in theory, mean that a single server hosting information only goes through the process once, by itself, allowing all future users to grab information privately without any more effort.</p><p>For&nbsp;<a href="https://www.khoury.northeastern.edu/home/wichs/" target="_blank" rel="noreferrer noopener">Daniel Wichs</a>, a cryptographer at Northeastern University and a co-author of the new paper, that seemed too good to be true. Around 2011, he started trying to prove that this kind of scheme was impossible. “I was convinced that there’s no way that this could be done,” he said.</p><p>But in 2017, two groups of researchers&nbsp;<a href="https://eprint.iacr.org/2017/567" target="_blank" rel="noreferrer noopener">published</a>&nbsp;<a href="https://eprint.iacr.org/2017/568" target="_blank" rel="noreferrer noopener">results</a>&nbsp;that changed his mind. They built the first programs that could do this kind of private information retrieval, but they weren’t able to show that the programs were secure. (Cryptographers demonstrate a system’s security by showing that breaking it is as difficult as solving some hard problem. The researchers weren’t able to compare it to a canonical hard problem.)</p><figure><img decoding="async" width="800" height="286" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Goldberg_BREAKER.png?auto=compress&amp;fit=scale&amp;fm=png&amp;h=366&amp;ixlib=php-3.3.1&amp;w=1024&amp;wpsize=large" srcset="https://assets.nautil.us/sites/3/nautilus/Goldberg_BREAKER.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/Goldberg_BREAKER.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Goldberg_BREAKER.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>SEARCHING IN THE DARK:</strong> From left: Wei-Kai Lin, Ethan Mook, and Daniel Wichs devised a new method for privately searching large databases. <em>Courtesy of Ian MacLellan and Khoury College of Computer Sciences/Northeastern University.</em></figcaption></figure>
          <p>So even with his hope renewed, Wichs assumed that any version of these programs that was secure was still a long way off. Instead, he and his co-authors—<a href="https://weikailin.github.io/" target="_blank" rel="noreferrer noopener">Wei-Kai Lin</a>, now at the University of Virginia, and&nbsp;<a href="https://ethanmook.com/" target="_blank" rel="noreferrer noopener">Ethan Mook</a>, also at Northeastern—worked on problems they thought would be easier, which involved cases where multiple servers host the database.</p><p>In the methods they studied, the information in the database can be transformed into a mathematical expression, which the servers can evaluate to extract the information. The authors figured it might be possible to make that evaluation process more efficient. They toyed with an idea from 2011, when other researchers had found a way to quickly evaluate such an expression by preprocessing it, creating special, compact tables of values that allow you to skip the normal evaluation steps.</p><p>That method didn’t produce any improvements, and the group came close to giving up—until they wondered whether this tool might actually work in the coveted single-server case. Choose a polynomial carefully enough, they saw, and a single server could preprocess it based on the 2011 result—yielding the secure, efficient lookup scheme Wichs had pondered for years. Suddenly, they’d solved the harder problem after all.</p><p>At first, the authors didn’t believe it. “Let’s figure out what’s wrong with this,” Wichs remembered thinking. “We kept trying to figure out where it breaks down.”</p>
          <p>But the solution held: They had really discovered a secure way to preprocess a single-server database so anyone could pull information in secret. “It’s really beyond everything we had hoped for,” said&nbsp;<a href="https://yuvali.cswp.cs.technion.ac.il/" target="_blank" rel="noreferrer noopener">Yuval Ishai</a>, a cryptographer at the Technion in Israel who was not involved in this work. It’s a result “we were not even brave enough to ask for,” he said.</p><blockquote>
<p>Cryptographers have a long history of results that were initially impractical.</p>
</blockquote><p>After building their secret lookup scheme, the authors turned to the real-world goal of a private internet search, which is more complicated than pulling bits of information from a database, Wichs said. The private lookup scheme on its own does allow for a version of private Google-like searching, but it’s extremely labor-intensive: You run Google’s algorithm yourself and secretly pull data from the internet when necessary. Wichs said a true search, where you send a request and sit back while the server collects the results, is really a target for a broader approach known as homomorphic encryption, which disguises data so that someone else can manipulate it without ever knowing anything about it.</p><p>Typical homomorphic encryption strategies would hit the same snag as private information retrieval, plodding through all the internet’s contents for every search. But using their private lookup method as scaffolding, the authors constructed a new scheme which runs computations that are more like the programs we use every day, pulling information covertly without sweeping the whole internet. That would provide an efficiency boost for internet searches and any programs that need quick access to data.</p>
          <p>While homomorphic encryption is a useful extension of the private lookup scheme, Ishai said, he sees private information retrieval as the more fundamental problem. The authors’ solution is the “magical building block,” and their homomorphic encryption strategy is a natural follow-up.</p><p>For now, neither scheme is practically useful: Preprocessing currently helps at the extremes, when the database size balloons toward infinity. But actually deploying it means those savings can’t materialize, and the process would eat up too much time and storage space.</p><p>Luckily, Vaikuntanathan said, cryptographers have a long history of optimizing results that were initially impractical. If future work can streamline the approach, he believes private lookups from giant databases may be within reach. “We all thought we were kind of stuck there,” he said. “What Daniel’s result gives is hope.”</p><p><em>This article was&nbsp;<a href="https://www.quantamagazine.org/cryptographers-devise-an-approach-for-total-search-privacy-20231106/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">originally published</a>&nbsp;on the</em>&nbsp;&nbsp;<a href="https://www.quantamagazine.org/abstractions/" target="_blank" rel="noreferrer noopener">Quanta Abstractions</a><em>&nbsp;blog.&nbsp;</em></p>
          <p><em>Lead image: Allison Li for&nbsp;Quanta Magazine</em></p>                  <ul>
                                          <li>
                        <div>
                          <h6>
                            Madison Goldberg                          </h6>
                          <p>
                            Posted on November 17, 2023                          </p>
                        </div>
                                                    <p>
                              Madison is a science journalist and a graduate student in New York University’s Science, Health and Environmental Reporting Program. Her work has also appeared in <i>Sky &amp; Telescope</i> magazine and the NPR project <i>StateImpact Pennsylvania</i>. She holds a bachelor’s degree in Earth and planetary sciences from Harvard University.                            </p>
                                                </li>
                                      </ul>
              <div>
  <p><img decoding="async" src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
    <h4>Get the Nautilus newsletter</h4>
    <p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
  </div>

  
</div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why is OpenAI firing Sam Altman such a big deal? (134 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38319543</link>
            <guid>38319543</guid>
            <pubDate>Sat, 18 Nov 2023 13:47:38 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38319543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38319691"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319691" href="https://news.ycombinator.com/vote?id=38319691&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>A few things:<p>1. It came completely out of left field, at a time when OpenAI has had an astonishingly successful year.</p><p>2. It was much more harshly worded than most corporate press releases letting their CEO go, basically accusing Sam Altman of serious wrongdoing.</p><p>3. It occurred during market hours and blindsided their investors and partners.</p><p>4. It revealed a schism inside the company that the public had little awareness of.</p><p>5. It has deep implications for the trajectory of a technology that many see as heralding a revolution at least as significant as — if not more than — agriculture or industry, with truly existential implications for humanity.</p><p>6. The revealed schism appears to go right to the heart of heated debates over those existential risks and the right course to navigate through them.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38320234"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38320234" href="https://news.ycombinator.com/vote?id=38320234&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>I need to jump on the wagon here and beg you and others to stop comparing AI to Agriculture, mastering of Fire, the Wheel, Electricity or the Combustion Engine.<p>It's hard to even argue, cause these things stand on very disparate levels of civilizatory pressure. AI has, no question, potential to deeply change human experience, but even if it does, that will be mostly due to extreme optimization of existing processes, not likely the development of new modes of living.</p><p>And it's very, very, very far from getting there. All this hype over Generational AI is, sadly, more of a Marketing stunt than anything else. Generational AI don't bring any great innovation in what AI can achieve, only in how people perceive what AI already does. GPT's biggest achievement is to sound coherent, not to leap forward human knowledge in any meaning full way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319851"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319851" href="https://news.ycombinator.com/vote?id=38319851&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>&gt; at least as significant as — if not more than — agriculture<p>Are there really people out there who believe that? I mean, agriculture was a BIG BIG BIG deal for humanity, it is not unreasonable to thing that this will have been out biggest deal.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38320222"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38320222" href="https://news.ycombinator.com/vote?id=38320222&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Depends on how you measure the bigness of the deal. AI, over the long term, will render humans mostly useless. We'll basically only be tasked with keeping ourselves entertained. Agriculture, if you disconnect it from the industrial revolution, really only allowed us to stay in on place while <i>mostly</i> not starving to death. Although, when the weather went bad, we did still starve to death.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319875"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319875" href="https://news.ycombinator.com/vote?id=38319875&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Yes. Depending on improvement trajectory and implementation velocity, this could replace a material amount of global aggregate knowledge work.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38319891"><td></td></tr>
                  <tr id="38319885"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319885" href="https://news.ycombinator.com/vote?id=38319885&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>It’s of course hard to directly compare, in large part because the AI revolution wouldn’t be possible without the agricultural revolution. But yeah, a lot of people think AI is a BIG BIG BIG BIG (note: I used one more “BIG” than you) deal for humanity.</span></p></div></td></tr>
        </tbody></table></td></tr>
                      <tr id="38320250"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38320250" href="https://news.ycombinator.com/vote?id=38320250&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Yes, people that delusional actually exist.<p>I’m bullish on AI but with comments like that I sympathize with people who think it’s just a bunch of rebranded cryptocoin scammers.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320055"><td></td></tr>
                <tr id="38320096"><td></td></tr>
                        <tr id="38319896"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319896" href="https://news.ycombinator.com/vote?id=38319896&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>It seems to me that in the grand scheme of things, this firing will be a side note. The people with the knowledge continue to exist, and the cat is out now. Everybody knows about the huge potential that's ripe for pickings in this field. I really doubt that this huge structural pressure will be flattened by a CEO losing his job.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38319980"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319980" href="https://news.ycombinator.com/vote?id=38319980&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>It would be significant if one believed OpenAI was responsible for keeping the cat partially in the bag, and now the bag has holes. In which case, the weakening of OpenAI (or simply a change of trajectory) could be very significant to this historical trajectory. More control vs less control is a very important knob to turn, and it's just been turned if power shifts from OpenAI's closed model approach to players pushing open models. It's up to each person to decide if this is good or bad *shrug*<p>I personally am unsure, but I worry Sam's departure is bad news for our trajectory. (Though I also feared his influence, as I fear anyone with heavy influence.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38319961"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319961" href="https://news.ycombinator.com/vote?id=38319961&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Your comparison to agriculture detracts from your otherwise excellent points.  We can survive without AI.  Without agriculture - not so much.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38320070"><td></td></tr>
                <tr id="38320114"><td></td></tr>
                <tr id="38320272"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38320272" href="https://news.ycombinator.com/vote?id=38320272&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>The point is that post AI, we will surely grow dependant on AI tech in the same way we are now dependant on agriculture, but were not before.<p>Think all hospitals being administered by AI, all logistical chains bringing food to your plates, etc... it is not far fetched to bet on us relying a lot on AI, iff it works as well as some people think
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38320018"><td></td></tr>
                <tr id="38320092"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38320092" href="https://news.ycombinator.com/vote?id=38320092&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>If Star Trek-style food synthesizers are developed with/by AI synthesis, you just might. More likely though, they'll be of the variant with a big "don't panic" sticker on the front.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38320132"><td></td></tr>
                        <tr id="38319886"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319886" href="https://news.ycombinator.com/vote?id=38319886&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>&gt; 3. It occurred during market hours and blindsided their investors and partners.<p>(Possibly dumb) question: OpenAI isn't publicly traded right? Do market hours really matter for this sort of thing for private companies?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38319908"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319908" href="https://news.ycombinator.com/vote?id=38319908&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Microsoft is publicly traded, and owns 49% of the for-profit OpenAI Global (the company that makes money with ChatGPT etc.).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319934"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319934" href="https://news.ycombinator.com/vote?id=38319934&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>It probably scared the downstream, see Microsoft pushing out a press release as soon as possible since they have been investing tons of money and PR into their OpenAPI partnership and needed to calm <i>their</i> investors and partners.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38320249"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38320249" href="https://news.ycombinator.com/vote?id=38320249&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Good point, and the answer to that is possibly not. But, considering that it isn't ideal to publicize this sort of thing during market hours anyway, regardless of your public/private status, my takeaway is that OpenAI felt that they had to get in front of this news at all costs. I find that very interesting, and I wonder what the competing narrative would have been had they not done that.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38320233"><td></td></tr>
            <tr id="38319880"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319880" href="https://news.ycombinator.com/vote?id=38319880&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>&gt; 5. It has deep implications for the trajectory of a technology that many see as heralding a revolution at least as significant as — if not more than — agriculture or industry, with truly existential implications for humanity.<p>Yes, this is likely to be one of the most important events in human history. We are living through a special period of evolution on Earth.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319843"><td></td></tr>
                  <tr id="38319634"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319634" href="https://news.ycombinator.com/vote?id=38319634&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>&gt; Also, a death is a much more significant event than a firing.<p>If Apple had very suddenly fired Jobs at the hight of the Apple Renaissance during market hours and very publicly accused him of lying it would have been a bigger deal than his eventual death.</p><p>There are many open questions right now about what exactly Altman did that was bad enough to get him fired on the spot (and for openAI to burn all their bridges with him in a harshly worded press release) and what it means for the future of OpenAI and the AI field in general and the rest of Altman’s companies. It’s a highly salient topic for discussion and speculation, so no wonder that it does well on HN.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38319683"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319683" href="https://news.ycombinator.com/vote?id=38319683&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Yeah, there wasn't really much scope for <i>speculation</i> about Jobs' death (and iirc there were plenty of other threads for people to share their love of Apple products or reminisce over his keynote addresses around the same time)<p>Altman obviously also has much more of a YC connection
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38320054"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320054" href="https://news.ycombinator.com/vote?id=38320054&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>HN is the water cooler of the startup and Silicon Valley world. Sam Altman was, and still is, an influential part of that community, being the president of Y Combinator from 2014 to 2019 [0] in addition to having personal interactions with many of founders of a wide variety of startups ( * ).<p>HN is open to a wider community (I'm not in SF or a startup founder) but HN is focused on startup and Silicon Valley news. I wouldn't be surprised if most of the users on HN with 10k+ karma are affiliated with Y Combinator, either as alum or more directly, in some way.</p><p>So, in my opinion, this is the office gossip talk of people who's everyday lives revolve around startup culture and Silicon Valley news. I think the news about OpenAI and Sam Altman's departure is relevant and interesting but the outsized weight on HN is most likely because of the communities attention to the niche domain of interest (SV/SF area tech news, startup culture, cult of personalities within that culture, etc.).</p><p>(*) With most having overwhelmingly positive things to say about their interaction.</p><p>[0] <a href="https://en.wikipedia.org/wiki/Sam_Altman" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Sam_Altman</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319717"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319717" href="https://news.ycombinator.com/vote?id=38319717&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Sam Altman was president of Y Combinator from 2014 to 2019.  Y Combinator is the company behind Hacker News.<p>It's a small world, the one where money pours round.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38320122"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38320122" href="https://news.ycombinator.com/vote?id=38320122&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Idk, the HN community does not seem to care for startups, VC funding, or AI in general. Ironically the opposite of what it's founded on.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38320260"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38320260" href="https://news.ycombinator.com/vote?id=38320260&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>How do you draw that conclusion? There is a large number here who are interested in all related things. Now certainly a lot of people here question how useful a lot of VC is but still very curious about everything happening.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38319816"><td></td></tr>
                  <tr id="38319645"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319645" href="https://news.ycombinator.com/vote?id=38319645&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>FWIW hackernews had way fewer users back then, than today. So you can't compare it directly just through the count of votes.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38320287"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320287" href="https://news.ycombinator.com/vote?id=38320287&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>I remember my first experiences with touch screen phones. It was magic, and it was clear that this would change the world. Touch screen phones were the biggest and final "dent in the universe" Jobs made.<p>But it was not as magic and promising as my first experiences with AI that I had over the last 24 months or so.</p><p>AI is a much bigger step for mankind than home computers and smartphones. So Altman is involved in making much bigger dents in the universe than Jobs was.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320074"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320074" href="https://news.ycombinator.com/vote?id=38320074&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>A firing like that is an emergency measure, and we don't really have AI emergencies. Consider that just 8 months after public launch, there have been congressional hearings in the US and a summit in London about whether this technology needs a non-proliferation agreement - and there's just been an emergency that requires jettisoning the project leader. The uncertainty is a bit alarming.<p>What is still very unclear is what removing Altman protects or preserves about the integrity of OpenAI and its work. The unexpected outcome is that by fragmenting OpenAI with firings and resignations, it will spread the core research know how more broadly, so if the firing were over an AI governance/safety concern, it might delay it a couple months, but could have the opposite effect.</p><p>It's not Altman himself, it's the instability in developing the tech that is the big deal. Personally, I suspect it's a bit of a valley palace intrigue gone wrong, where someone supported some of the upstream orchestration that resulted in this outcome, but as far as why this is important, it really is the tech.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319795"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319795" href="https://news.ycombinator.com/vote?id=38319795&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Obviously the comparison is not one to one, different time, different traffic, different event, and number of upvotes is not the main measure of importance.<p>That said, this is pretty big. OpenAI is a wildly successful company and as CEO Sam Altman is one of the big players in that.</p><p>Not only was he fired, but he was fired unexpectedly and very publicly, this rarely happens. Usually companies try to prevent the media storm that is happening right now by quietly moving people to less important roles and or they “want to spent more time with family” or “are looking for another challenge”.</p><p>So it’s not just the firing of the ceo of one of, if not the most, successful startups of this time, it’s completely unexpected, and the wording suggests something really big has happened or will be happening, or the board is making reckless decisions, which would be newsworthy on its own.</p><p>Not having all the information makes people wonder what’s going on adding to the attention as we all speculate on what’s going on and how it is going to change things.</p><p>Another factor in this is that a lot of startups and companies rely on OpenAI making it directly relevant to a lot of people, especially those on this website.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319650"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319650" href="https://news.ycombinator.com/vote?id=38319650&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>It brings a tremendous uncertainity in the direction the OpenAI is heading. They could block out APIs now, or do other kinds of strategic shifts that would affect the users.<p>So far, from my viewpoint, OpenAI was perfectly as a product - both in terms of features and their deployments. Now anything can be possible.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38319684"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38319684" href="https://news.ycombinator.com/vote?id=38319684&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>&gt; They could block out APIs now, or do other kinds of strategic shifts that would affect the users.<p>but why would that not have been the case regardless of whether sam was fired or not? Just because they are a non-profit, doesn't really mean they have anyone's interest at heart (except the controllers of said non-profit).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38319720"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319720" href="https://news.ycombinator.com/vote?id=38319720&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>A strategic shift becomes more likely when leadership is pushed out, especially when that occurrs because of a difference of opinion over strategy.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319726"><td></td></tr>
                <tr id="38320246"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38320246" href="https://news.ycombinator.com/vote?id=38320246&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Or there were changes in the works that the board decided they had to put an emergency stop to. I guess things will become clearer in a few weeks.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38319747"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319747" href="https://news.ycombinator.com/vote?id=38319747&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Does anyone track upvote inflation?<p>E.g. has anyone calculated the total number of upvotes across all front page stories each day at midnight UTC for a year, and how it changes per year?</p><p>Would be informative to compare story popularities "objectively" across time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320198"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320198" href="https://news.ycombinator.com/vote?id=38320198&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Although it is pointless to speculate about what Sam actually did - that will doubtlessly be public in time, with spin - we can reason that it must be criminal, litigious or extremely commercially disloyal.<p>The median commenter seems to think that OpenAI has committed commercial suicide and Sam and those who leave with him will start the competitor that will dethrone OpenAI….</p><p>Myself, I’m guessing that whatever he has done is going to be reason enough for investors to steer clear and he’ll be mostly forgotten by the next hype cycle.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319746"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319746" href="https://news.ycombinator.com/vote?id=38319746&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>It was a big surprise that <i>nobody</i> saw coming<p>It occurred while we were already paying heightened attention to OpenAI (seriously, have you seen the front page of HN?)</p><p>There is inherent drama — a guy got kicked out of his own company</p><p>There is no explanation, so people want to speculate about it, which means lots of comments
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319633"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319633" href="https://news.ycombinator.com/vote?id=38319633&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>You can't directly compare votes on a post from 2023 to a post from 2011 because HN didn't have the same number of users back then.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319639"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319639" href="https://news.ycombinator.com/vote?id=38319639&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Because it happened out of the blue (apparently also for those involved and partners) right when OpenAI seems to absolutely be killing it. It's a crazy story.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319837"><td></td></tr>
            <tr id="38319995"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319995" href="https://news.ycombinator.com/vote?id=38319995&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>It is a big deal because he is known to us all. When something happens to a person you know, you care. When a person is known to a large community, us, our shared amazement adds up.<p>ps, The overthinking is most of this conversation is amazing and almost all wrong. The closest to a 'non-community gasp' idea that is correct is that it appears that this powerful and respected person has been lying to his board of directors and he will probably still be around to do, uh, more lying. Still, that's not a big deal at all. He's just a guy.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319842"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319842" href="https://news.ycombinator.com/vote?id=38319842&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>In addition to the drama surrounding an unexpected firing decision made by a less-than-typical 501(c)3 board of directors, there is a large vacuum of information about what exactly happened.<p>On one side, there are proponents of an argument that Sam hid evidence of the achievement of AGI from the board, or that he pushed for acceleration of development in a way that scared the board.</p><p>On the other side, there are proponents of an argument that the board wasn't happy with OpenAI Dev Day pushing commercialization directly within OpenAI (e.g. the marketplace) against the wishes of the board and OpenAI's charter.</p><p>Until Sam, OpenAI, or others comment further, this is the perfect playground for speculation and court intrigue about what is arguably the most prominent technology company of the 2020's (thus far).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320120"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320120" href="https://news.ycombinator.com/vote?id=38320120&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Others made good points about why this is big news in general. I suppose the biggest reason it’s #3 on this website specifically is due to Sam’s outsized influence on YC and this forum in general.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38320056"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320056" href="https://news.ycombinator.com/vote?id=38320056&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>A lot of people are building GPTs and want to know how they can monetise them.<p>The GPTs shop is not yet active and many directory sites like gipeties.com have sprung up to fill the gap.</p><p>Which way the cookie crumbles will affect how the directory sites and the people creating gipeties will do.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319972"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319972" href="https://news.ycombinator.com/vote?id=38319972&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Such a Firing + Press release is basically unheard of. Looks more like two sides are at war with each other. Almost as if this is about their core believes, about what AI/AGI is and when it is or will be reached and what direction "OpenAI Global, LLC" should go. So their is massive room for Conspiration Theories and speculation.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38320193"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320193" href="https://news.ycombinator.com/vote?id=38320193&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>people have 2 reasons to do things-- the real reason and the one the brain comes up to rationalize-- in this case the upvote. ask them, and you almost always get the rationalized reason.<p>do some thinking, and you can get the real one. maybe hn's audience of top-minds are actually just as human as the people who watched shakespearean tragedies 100s of years ago or people buying people magazine and other tabloids today. sam altman is a celebrity, [was] one of the most powerful and important figures in the direction of AI (even if he didn't develop it), and this was his (imo hopefully temporary) tragic fall.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319909"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319909" href="https://news.ycombinator.com/vote?id=38319909&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>OpenAI is literally world changing but with obvious dangers. This seems like a first for big tech, I mean firing a CEO for ethics. (And while lying is the official reason, I think it's more about pointing out the dangers while squeezing ChatGPT's capabilities to their full extent for the better and the worse.) That's my understanding anyway.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38320110"><td></td></tr>
            <tr id="38319665"><td></td></tr>
            <tr id="38320185"><td></td></tr>
            <tr id="38319714"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319714" href="https://news.ycombinator.com/vote?id=38319714&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>What is feared as lost given the leadership change? That seems to be main driver behind speculation and discussion.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319874"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319874" href="https://news.ycombinator.com/vote?id=38319874&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Because he basically got fired by Tasha McCauley and Helen Toner who are inexperienced outsiders. Either Adam or Ilya initiated the move, but those two give them the votes needed to fire Sam. Not to mention those board members have no stake, so whatever incentives they were given to do this are likely not aligned with the OpenAI business.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38319919"><td></td></tr>
                <tr id="38320254"><td></td></tr>
                        <tr id="38319791"><td></td></tr>
            <tr id="38319871"><td></td></tr>
            <tr id="38320059"><td></td></tr>
            <tr id="38319790"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319790" href="https://news.ycombinator.com/vote?id=38319790&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Steve Jobs was fired from Apple and in hindsight that was a pivotal moment that has been heavily studied<p>This looks like that
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320045"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320045" href="https://news.ycombinator.com/vote?id=38320045&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>A lot of <i>want</i> OpenAI to fail, for many reasons. A lot of people think it's been faking things all along - things like capacity, data privacy &amp; safety, exponentially growing intelligence, enshittification, sustainability, or whether GPT is some dudes in a trenchcoat.<p>A firing with the odd reasoning of being dishonest is just a perfect storm.</p><p>Also many things are shared because they confirm what someone wants to believe, sometimes even being just a headline with no content.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319832"><td></td></tr>
            <tr id="38319710"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319710" href="https://news.ycombinator.com/vote?id=38319710&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>Steve Jobs died a long long time ago. The amt of global internet users has 2.5x’ed (2B to 5B). Even for the US alone, internet users has gone from ~220M to ~310M+ in that time span.<p>YC has grown a a lot in that time too.</p><p>Lots of changes. No comparison.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38319826"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319826" href="https://news.ycombinator.com/vote?id=38319826&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>It was done too abruptly. OpenAI is literally at the pinnacle of the AI world, but the sudden firing revealed deep internal rifts at the company.<p>Usually, an ouster will come with preceding signs of trouble, but not this.
Imagine if Tim Cook was suddenly fired today with a press release bluntly stating they lost confidence in his abilities (despite Apple's stellar performance). I bet you'll get a similar number of votes.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320043"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38320043" href="https://news.ycombinator.com/vote?id=38320043&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>There's a certain amount of belly-button gazing going on.  It's not that big of deal outside of the corporate CEO-worshipping world. For example, if OpenAI were to open-source their code and their models, that would be a much bigger deal IMO.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319901"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319901" href="https://news.ycombinator.com/vote?id=38319901&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>I have no idea why it’s such a big deal.  People should come to terms with the fact that no one on Earth is irreplaceable.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319870"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319870" href="https://news.ycombinator.com/vote?id=38319870&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Because everybody is afraid they will cut access to the API now (saying "we need to focus on research rather than business"). And since they are the only ones controlling the access to the API, (1) people depending on it are screwed, (2) the competition like Claude will have a big boost.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38320026"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38320026" href="https://news.ycombinator.com/vote?id=38320026&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>That was also my first reaction. I worry those who are being disrupted found a way to take drastic action to interrupt the progress.<p>Sadly that has me hoping personal or professional misconduct is behind it, he does give me a bad vibe, but that could be easily internal bias and bad stereotyping on my part.</p><p>If it is revealed to be from an interference or slow down the progress the only silver lining is perhaps this gives open source projects some space to try and catch up.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38320214"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38320214" href="https://news.ycombinator.com/vote?id=38320214&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Why would they even consider doing such a thing? Lmfao that seems unfathomable, there are so many business applications dependent on API access right now it's like they're too big to fail, how would this even go down?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38319768"><td></td></tr>
                <tr id="38319882"><td></td></tr>
                  <tr id="38319708"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38319708" href="https://news.ycombinator.com/vote?id=38319708&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><p><span>It’s drama and we <i>love</i> drama and the Elon Musk well has been rather predictable, if not altogether dry lately. (We = humans)<p>The way the statement was phrased is practically unheard of at the board/executive level. The board essentially accused Sam Altman of lying to them, which would normally be a permanent black mark against someone. On top of that OpenAI’s corporate structure makes the outcome of this exercise particularly unpredictable with a bunch of board members that - frankly - probably have no idea what they’re doing.</p><p>Altman also ran YC at one point but at the end of the day ChatGPT is all the hype nowadays and we just abso-fucking-lutely <i>love drama.</i>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38319725"><td></td></tr>
                <tr id="38319897"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38319897" href="https://news.ycombinator.com/vote?id=38319897&amp;how=up&amp;goto=item%3Fid%3D38319543"></a></center>    </td><td><br><div>
                  <p><span>Was wondering where he'd fall upward <i>to</i>, then I remembered how much groundwork he'd laid for AI being so dangerous everyone else should just stop researching it and if they didn't, someone in the government needed to step in and decide for them...</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38319793"><td></td></tr>
                        <tr id="38319856"><td></td></tr>
                <tr id="38319930"><td></td></tr>
                  <tr id="38319799"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Death by AI – a free Jackbox style party game. AI judges your plans to survive (347 pts)]]></title>
            <link>https://deathbyai.gg</link>
            <guid>38318889</guid>
            <pubDate>Sat, 18 Nov 2023 12:40:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deathbyai.gg">https://deathbyai.gg</a>, See on <a href="https://news.ycombinator.com/item?id=38318889">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Starship Integrated Flight Test 2 at 7 Am Central Time (385 pts)]]></title>
            <link>https://twitter.com/i/flow/login?redirect_after_login=%2Fi%2Fbroadcasts%2F1dRKZEWQvrXxB</link>
            <guid>38317247</guid>
            <pubDate>Sat, 18 Nov 2023 09:11:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/i/flow/login?redirect_after_login=%2Fi%2Fbroadcasts%2F1dRKZEWQvrXxB">https://twitter.com/i/flow/login?redirect_after_login=%2Fi%2Fbroadcasts%2F1dRKZEWQvrXxB</a>, See on <a href="https://news.ycombinator.com/item?id=38317247">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GTK: Introducing Graphics Offload (257 pts)]]></title>
            <link>https://blog.gtk.org/2023/11/15/introducing-graphics-offload/</link>
            <guid>38316953</guid>
            <pubDate>Sat, 18 Nov 2023 08:31:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gtk.org/2023/11/15/introducing-graphics-offload/">https://blog.gtk.org/2023/11/15/introducing-graphics-offload/</a>, See on <a href="https://news.ycombinator.com/item?id=38316953">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-9664">
	<!-- .entry-header -->

	
	
	<div>
		<p>Some of us in the GTK team have spent the last month or so exploring the world of linux kernel graphics apis, in particular, dmabufs. We are coming back from this adventure with some frustrations and some successes.</p>
<h3>What is a dmabuf?</h3>
<p>A dmabuf is a memory buffer in kernel space that is identified by a file descriptor. The idea is that you don’t have to copy lots of pixel data around, and instead just pass a file descriptor between kernel subsystems.</p>
<p>Reality is of course more complicated that this rosy picture: the memory may be device memory that is not accessible in the same way as ‘plain’ memory, and there may be more than one buffer (and more than one file descriptor), since graphics data is often split into planes (e.g. RGB and A may be separate, or Y and UV).</p>
<h3>Why are dmabufs useful?</h3>
<p>I’ve already mentioned that we hope to avoid copying the pixel data and feeding it through the GTK compositing pipeline (and with 4k video, that can be quite a bit of data for each frame).</p>
<p>The use cases where this kind of optimization matters are those where frequently changing content is displayed for a long time, such as</p>
<ul>
<li>Video players</li>
<li>Virtual machines</li>
<li>Streaming</li>
<li>Screencasting</li>
<li>Games</li>
</ul>
<p>In the best case, we may be able to avoid feeding the data through the compositing pipeline of the compositor as well, if the compositor supports <em>direct scanout</em> and the dmabuf is suitable for it.&nbsp; In particular on mobile systems, this may avoid using the GPU altogether, thereby reducing power consumption.</p>
<h3>Details</h3>
<p>GTK has already been using dmabufs since 4.0: When composing a frame, GTK translates all the render nodes (typically several for each widget) into GL commands, sends those to the GPU, and mesa then exports the resulting texture as a dmabuf and attaches it to our Wayland surface.</p>
<p>But if the only thing that is changing in your UI is the video content that is already in a dmabuf, it would be nice to avoid the detour through GL and just hand the data directly to the compositor, by giving it the file descriptor for the the dmabuf.</p>
<p>Wayland has the concept of subsurfaces that let applications defer some of their compositing needs to the compositor: The application attaches a buffer to each (sub)surface, and it is the job of the compositor to combine them all together.</p>
<p>With what is now in git main, GTK will create subsurfaces as-needed in order to pass dmabufs directly to the compositor. We can do this in two different ways: If nothing is drawn on top of the dmabuf (no rounded corners, or overlaid controls), then we can stack the subsurface above the main surface without changing any of the visuals.</p>
<p><a href="https://blog.gtk.org/files/2023/11/bbb-above.png"><img fetchpriority="high" decoding="async" src="https://blog.gtk.org/files/2023/11/bbb-above.png" alt="" width="525" height="675" srcset="https://blog.gtk.org/files/2023/11/bbb-above.png 525w, https://blog.gtk.org/files/2023/11/bbb-above-233x300.png 233w" sizes="(max-width: 525px) 85vw, 525px"></a>This is the ideal case, since it enables the compositor to set up <em>direct</em> <em>scanout, </em>which gives us a zero-copy path from the video decoder to the display.</p>
<p>If there is content that gets drawn on top of the video, we may not be able to get that, but we can still get the benefit of letting the compositor do the compositing, by placing the subsurface with the video <em>below</em> the main surface and poking a translucent hole in the main surface to let it peek through.</p>
<p><a href="https://blog.gtk.org/files/2023/11/bbb-below.png"><img decoding="async" src="https://blog.gtk.org/files/2023/11/bbb-below.png" alt="" width="625" height="675" srcset="https://blog.gtk.org/files/2023/11/bbb-below.png 625w, https://blog.gtk.org/files/2023/11/bbb-below-278x300.png 278w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"></a>The round play button is what forces the subsurface to be placed below the main surface here.</p>
<p>GTK picks these modes automatically and transparently for each frame, without the application developer having to do anything. Once that play button appears in a frame, we place the subsurface below, and once the video is clipped by rounded corners, we stop offloading altogether. Of course, the advantages of offloading also disappear.</p>
<p>The graphics offload visualization in the GTK inspector shows these changes as they happen:</p>
<p><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video id="video-9664-1" width="840" height="660" preload="metadata" controls="controls"><source type="video/webm" src="https://blog.gtk.org/files/2023/11/offload-visualization.webm?_=1"><a href="https://blog.gtk.org/files/2023/11/offload-visualization.webm">https://blog.gtk.org/files/2023/11/offload-visualization.webm</a></video></p>
<p>Initially, the camera stream is not offloaded because the rounded corners clip it. The magenta outline indicates that the stream is offloaded to a subsurface below the main surface (because the video controls are on top of it). The golden outline indicates that the subsurface is above the main surface.</p>
<h3>How do you use this?</h3>
<p>GTK 4.14 will introduce a <a href="https://docs.gtk.org/gtk4/class.GraphicsOffload.html">GtkGraphicsOffload</a> widget, whose only job it is to give a hint that GTK should try to <em>offload</em> the content of its child widget by attaching it to a subsurface instead of letting GSK process it like it usually does.</p>
<p>To create suitable content for offloading, the new <a href="https://docs.gtk.org/gdk4/class.DmabufTextureBuilder.html">GdkDmabufTextureBuilder</a> wraps dmabufs in GdkTexture objects. Typical sources for dmabufs are pipewire, video4linux or gstreamer. The dmabuf support in gstreamer will be much more solid in the upcoming 1.24 release.</p>
<p>When testing this code, we used the GtkMediaStream implementation for pipewire by Georges Basile Stavracas Neto that can be found in <a href="https://gitlab.gnome.org/GNOME/pipewire-media-stream">pipewire-media-stream</a> and <a href="https://gitlab.gnome.org/GNOME/libmks/">libmks</a> by Christian Hergert and Bilal Elmoussaoui.</p>
<h3>What are the limitations?</h3>
<p>At the moment, graphics offload will only work with Wayland on Linux. There is some hope that we may be able to implement similar things on MacOS, but for now, this is Wayland-only. It also depends on the content being in dmabufs.</p>
<p>Applications that want to take advantage of this need to play along and avoid doing things that interfere with the use of subsurfaces, such as rounding the corners of the video content. The <a href="https://docs.gtk.org/gtk4/class.GraphicsOffload.html">GtkGraphicsOffload</a> docs have more details for developers on constraints and how to debug problems with graphics offload.</p>
<h3>Summary</h3>
<p>The GTK 4.14 release will have some interesting new capabilities for media playback. You can try it now, with the just-released 4.13.3 snapshot.</p>
<p>Please try it and let us know what does and doesn’t work for you.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-source tool for creating courses like Duolingo (353 pts)]]></title>
            <link>https://uneebee.com</link>
            <guid>38316936</guid>
            <pubDate>Sat, 18 Nov 2023 08:28:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uneebee.com">https://uneebee.com</a>, See on <a href="https://news.ycombinator.com/item?id=38316936">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>UneeBee lets you quickly build lessons that go beyond watching videos. Bring your content to life with real-world scenarios, making it easy to create content that’s interactive and impactful. Lead your audience through choices that matter, fostering a deeper understanding with each step.</p><div><p><dt>Friendly editor.</dt> <dd>Our editor empowers you to create courses with ease. No technical expertise needed. Design, edit, and publish your interactive lessons with a simple, intuitive interface.</dd></p><p><dt>Manage students.</dt> <dd>Managing your students is seamless. Track progress, gain insights into learning patterns, and customize courses to fit the unique needs of each learner group.</dd></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York may ban noncompete employment agreements and Wall Street is not happy (521 pts)]]></title>
            <link>https://fortune.com/2023/11/16/new-york-may-ban-noncompete-employment-agreements-wall-street-not-happy-kathy-hochul/</link>
            <guid>38316870</guid>
            <pubDate>Sat, 18 Nov 2023 08:17:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2023/11/16/new-york-may-ban-noncompete-employment-agreements-wall-street-not-happy-kathy-hochul/">https://fortune.com/2023/11/16/new-york-may-ban-noncompete-employment-agreements-wall-street-not-happy-kathy-hochul/</a>, See on <a href="https://news.ycombinator.com/item?id=38316870">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>When people think of <a href="https://fortune.com/2023/04/28/ftc-must-free-american-workers-consumers-entrepreneurs-non-compete-agreements-politics-labor-john-arensmeyer/" target="_self" rel="">noncompete agreements</a>, they usually think of corporate executives with knowledge of prized trade secrets, whose lavish pay packages often come with a condition that if they quit or get fired, they <a href="https://fortune.com/2023/03/23/doctors-hospitals-noncompete-ftc-proposed-rule/" target="_self" rel="">can’t go work for an industry rival</a>.</p><div>



<p>More and more, though, employers are requiring regular workers to sign those deals. About 1 in 5 American workers, nearly 30 million people, are bound by noncompete agreements,&nbsp;<a href="https://www.ftc.gov/legal-library/browse/federal-register-notices/non-compete-clause-rulemaking#:~:text=Overview,from%20pursuing%20better%20employment%20opportunities." target="_self" rel="">according</a>&nbsp;to the Federal Trade Commission.</p>



<p>Horror stories about companies using noncompete agreements to trap workers in middling jobs or punish them for taking their skills elsewhere for better pay prompted New York legislators to pass a bill last June that would ban noncompete agreements.</p>



<p>Five months later, though, Gov. Kathy Hochul hasn’t said whether she intends to sign the legislation, which has come under a fierce attack by business groups.</p>



<p>The Public Policy Institute of the State of New York, an affiliate of the Business Council of New York, launched a $1 million ad campaign last month in an attempt to thwart the legislation. Some of the loudest opposition has come from Wall Street, where firms see noncompete agreements as important to protecting investment strategies and keeping highly-paid workers from walking out with valuable inside information.</p>



<p>Supporters of the ban say <a href="https://fortune.com/2023/03/15/heres-what-chros-actually-think-about-the-potential-ban-on-noncompetes/" target="_self" rel="">it would help people</a> like lighting designer Richard Tatum, a New York City resident who had signed a noncompete agreement and spent a year fighting a former employer in court after they sued him for getting another job shortly after they laid him off in 2009. He had a family to support and wasn’t moving or leaving his industry, he said.</p>



<p>“I felt I had no choice but to fight,” said Tatum, who now works for an event production company. He said he understands being fired during the financial meltdown. “But the fact that I had to spend a year fighting off my former employer was just wrong.”</p>



<p>A handful of states, including California, already ban noncompete agreements. Other states, including Minnesota and Oklahoma, have laws that void noncompete agreements if a person is laid off.</p>



<p>The Federal Trade Commission&nbsp;<a href="https://apnews.com/article/biden-technology-politics-business-9fb699837e8bf8ecd9c70dcf27699dcf" target="_self" rel="">proposed a regulation</a>&nbsp;in January banning noncompete agreements, arguing that they hurt workers. President Joe Biden said at the time that the agreements “block millions of retail workers, construction workers and other working folks from taking better jobs and getting better pay and benefits in the same field.”</p>



<p>If signed by Hochul, a Democrat, the New York bill would only affect noncompete agreements signed after the law goes into effect. The legislation would not restrict nondisclosure agreements.</p>



<p>Hochul’s office said she’s still reviewing the legislation. She has until the end of the year to make a decision.</p>



<p>Business groups say the ban shouldn’t apply to certain industries and job levels, like top executives or partners in tech companies or law firms. They also said it could push employers to ship jobs to states like Florida and Texas that do not have similar laws.</p>



<p>“This bill poses a serious risk to innovation and job growth and, if enacted, could unravel the delicate balance between protecting business investment and fostering a competitive job market,” said Paul Zuber, the executive vice president for the Business Council of New York.</p>



<p>Advocates for the bill argue that striking noncompete agreements will actually be good for innovation.</p>



<p>State Senator Sean Ryan, a Democrat who sponsored the bill, pointed to Silicon Valley in California, a hub for tech companies.</p>



<p>“All the flexibility you see in that economy would have been dashed had they made it so you couldn’t go work for an emerging tech company,” Ryan said.</p>



<p>The bill, he added, would give employees more flexibility and agency when considering other employment opportunities.</p>



<p>Tatum, the lighting designer who reached a legal settlement with his former employer to keep working in his profession, said, “I just don’t think anyone like me should have to go through that again.”</p></div><p>Subscribe to the CEO Daily newsletter to get the CEO perspective on the biggest headlines in business. <a href="https://www.fortune.com/newsletters/ceo-daily?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=ceo_daily" target="_self" rel="">Sign up</a> for free.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calibre – New in Calibre 7.0 (284 pts)]]></title>
            <link>https://calibre-ebook.com/new-in/sixteen</link>
            <guid>38316846</guid>
            <pubDate>Sat, 18 Nov 2023 08:14:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://calibre-ebook.com/new-in/sixteen">https://calibre-ebook.com/new-in/sixteen</a>, See on <a href="https://news.ycombinator.com/item?id=38316846">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-wrapper" tabindex="-1">
            


<p>Welcome back, calibre users. It has been a year since calibre
6.0. The headline new feature is <b>notes for authors, series, tags, etc.</b>
calibre can now store notes with links, images and rich text formatting associated
with every author, series, publisher, tag, etc. The notes are searchable, browseable,
linkable and can be exported as standalone HTML files.
</p>

<p>To use the new <i>Notes</i> feature, right click (or <code>Ctrl+click</code> on macOS) on 
an author or tag in the <i>Tag browser</i> or <i>Book details</i> panel and <i>Edit notes</i>.
</p>

<ul id="feature-list">
    <li>
        <span>Category notes</span>
        <div>

            <p>
            You can store notes associated with an author, publisher, series, et cetera,
            in your calibre library. To do so right click (or <code>Ctrl+click</code> on macOS) on
            an author or tag name in the <i>Tag browser</i> or <i>Book details</i> panel and
            choose <i>Edit notes</i>. Once you have created the note, a little pencil icon
            will show next to the name in the book details panel. You can click the
            pencil to view the note.
            </p>

            <p>
            You can browse and search through all notes in your library by pressing <code>Ctrl+Shift+N</code>
            or adding the <i>Browse notes</i> tool to the toolbar via <i>Preferences-&gt;Toolbars &amp; menus</i>.
            </p>

            <p><a title="The notes display window" href="https://download.calibre-ebook.com/images/4/notes-show.webp"><img src="https://download.calibre-ebook.com/images/4/notes-show-thumb.webp" alt="First"></a>
                <a title="Browsing all notes" href="https://download.calibre-ebook.com/images/4/notes-browse.webp"><img src="https://download.calibre-ebook.com/images/4/notes-browse-thumb.webp" alt="Second"></a>
            </p>
        </div>
    </li>

    <li>
        <span>Audio EPUB books in the E-book viewer</span>
        <div>

            <p>
            calibre has gained support for so called "Audio EPUB" books. Typically,
            these are books that have a pre-recorded voice reading the text. Freely downloadable
            examples of such books are available at: <a title="Read Beyond books" href="https://www.readbeyond.it/ebooks.html">Read Beyond books</a>.
            When reading such a book, clicking the <i>Read Aloud</i> button in the
            viewer will automatically use the embedded audio in the book to read the text
            aloud, marking the currently read sentence and showing progress. Note that
            this may not work on Linux because of issues with patented codecs, but works on
            Windows and macOS.
            </p>

            <p><a title="Read aloud playing embedded audio" href="https://download.calibre-ebook.com/images/4/audio-epub.webp"><img src="https://download.calibre-ebook.com/images/4/audio-epub-thumb.webp" alt="First"></a>
            </p>
        </div>

    </li>

    <li>
        <span>Store extra data files associated with any book</span>
        <div>

            <p>
            A long requested feature in calibre, was the ability to store "data" files associated with a book
            and have calibre manage them automatically. This is finally available. Extra data files can be
            added to a book by selecting the book, right clicking the <i>Add books</i> button and choosing
            <i>Add data files to selected book records</i>. You can also manage the data files by right clicking
            the <i>Edit metadata</i> button and choosing <i>Manage data files</i>. The data files are simple
            files stored in the <code>data</code> sub-folder inside the book's folder. A common use for such
            files is storing alternate covers or supplementary material associated with the book.
            </p>

            <p><a title="Managing data files" href="https://download.calibre-ebook.com/images/4/data-files.webp"><img src="https://download.calibre-ebook.com/images/4/data-files-thumb.webp" alt="First"></a>
            </p>

        </div>
    </li>


    <li>
        <span>calibre's own private Recycle Bin</span>
        <div>

            <p>
            calibre now has its own private Recycle Bin instead of using the
            operating system one. This means that it is now possible undo the
            deletion of a book with a single click, restoring all its files and
            metadata automatically. Indeed when you delete a book calibre will
            show an unobtrusive popup offering to undo the deletion for a few
            seconds. You can also browse recently deleted books by right
            clicking the <i>Remove books</i> button and choosing <i>Restore
            recently deleted</i>.
            </p>

            <p><a title="Restoring recently deleted books" href="https://download.calibre-ebook.com/images/4/undo-delete.webp"><img src="https://download.calibre-ebook.com/images/4/undo-delete-thumb.webp" alt="First"></a>
            </p>

        </div>
    </li>

</ul>

<hr>

<p>This is an appropriate time to throw out a big thank you to the calibre
community who have contributed selflessly of their energy and enthusiasm —
without which many of the features above would never have seen the light of
day.</p>

<p>Note that some of these features were actually introduced during the
lifetime of the 6.x series. This document describes new features as compared
to 6.0</p>

<p>See what was new in previous major calibre releases:
<a href="https://calibre-ebook.com/new-in/fifteen">6.0</a>, 
<a href="https://calibre-ebook.com/new-in/fourteen">5.0</a>, 
<a href="https://calibre-ebook.com/new-in/thirteen">4.0</a>, 
<a href="https://calibre-ebook.com/new-in/twelve">3.0</a>, 
<a href="https://calibre-ebook.com/new-in/eleven">2.0</a>, 
<a href="https://calibre-ebook.com/new-in/ten">1.0</a>, 
<a href="https://calibre-ebook.com/new-in/nine">0.9</a>, 
<a href="https://calibre-ebook.com/new-in/eight">0.8</a>, 
<a href="https://calibre-ebook.com/new-in/seven">0.7</a>.
</p>



        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rogue superintelligence: Inside the mind of OpenAI's chief scientist (118 pts)]]></title>
            <link>https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/</link>
            <guid>38316521</guid>
            <pubDate>Sat, 18 Nov 2023 07:25:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/">https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=38316521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content--body"><div> <p>Ilya Sutskever, head bowed, is deep in thought. His arms are spread wide and his fingers are splayed on the tabletop like a concert pianist about to play his first notes. We sit in silence.</p>  <p>I’ve come to meet Sutskever, OpenAI’s cofounder and chief scientist, in his company’s&nbsp;unmarked office building on an unremarkable street in the Mission District of San Francisco to hear what’s next for the world-tilting technology he has had a big hand in bringing about. I also want to know what’s next for him—in particular, why building the next generation of his company’s flagship generative models is no longer the focus of his work.&nbsp;</p> </div><div> <p>Instead of building the <a href="https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and-better-chatgpt-openai/">next GPT</a> or <a href="https://www.technologyreview.com/2022/04/06/1049061/dalle-openai-gpt3-ai-agi-multimodal-image-generation/">image maker DALL-E</a>, Sutskever tells me his new priority is to figure out how to stop an artificial superintelligence (a hypothetical future technology he sees coming with the foresight of a true believer) from going rogue.</p>  <p>Sutskever tells me a lot of other things too. He thinks <a href="https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai/">ChatGPT</a> just might be conscious (if you squint). He thinks the world needs to wake up to the true power of the technology his company and others are racing to create. And he thinks some humans will one day choose to merge with machines.</p> 
 <p>A lot of what Sutskever says is wild. But not nearly as wild as it would have sounded just one or two years ago. As he tells me himself, ChatGPT has already rewritten a lot of people’s expectations about what’s coming, turning “will never happen” into “will happen faster than you think.”</p>  <p>“It’s important to talk about where it’s all headed,” he says, before predicting the development of artificial general intelligence (by which he means machines as smart as humans) as if it were as sure a bet as another iPhone: “At some point we really will have AGI. Maybe OpenAI will build it. Maybe some other company will build it.”</p> 
 <p>Since the release of its sudden <a href="https://www.technologyreview.com/2023/02/08/1068068/chatgpt-is-everywhere-heres-where-it-came-from">surprise hit, ChatGPT</a>, last November, the buzz around OpenAI has been astonishing, even in an industry known for hype. No one can get enough of this nerdy <a href="https://www.nytimes.com/2023/10/20/technology/openai-artifical-intelligence-value.html">$80 billion startup</a>. World leaders seek (and get) private audiences. Its clunky product names pop up in casual conversation.&nbsp;</p>  <p>OpenAI’s CEO, Sam Altman, spent a good part of the summer on a weeks-long outreach tour, glad-handing politicians and speaking to packed auditoriums around the world. But Sutskever is much less of a public figure, and he doesn’t give a lot of interviews.&nbsp;</p>  <p>He is deliberate and methodical when he talks. There are long pauses when he thinks about what he wants to say and how to say it, turning questions over like puzzles he needs to solve. He does not seem interested in talking about himself. “I lead a very simple life,” he says. “I go to work; then I go home. I don’t do much else. There are a lot of social activities one could engage in, lots of events one could go to. Which I don’t.”</p>  <p>But when we talk about AI, and the epochal risks and rewards he sees down the line, vistas open up: “It’s going to be monumental, earth-shattering. There will be a before and an after.”</p> </div><div> <h3>Better and better and better</h3>  <p>In a world without OpenAI, Sutskever would still get an entry in the annals of AI history. An Israeli-Canadian, he was born in Soviet Russia but brought up in Jerusalem from the age of five (he still speaks Russian and Hebrew as well as English). He then moved to Canada to study at the University of Toronto with Geoffrey Hinton, the AI pioneer who went public with his <a href="https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/">fears about the technology he helped invent</a> earlier this year. (Sutskever didn’t want to comment on Hinton’s pronouncements, but his new focus on rogue superintelligence suggests they’re on the same page.)</p>  <p>Hinton would later share the Turing Award with Yann LeCun and Yoshua Bengio for their work on neural networks. But when Sutskever joined him in the early 2000s, most AI researchers believed neural networks were a dead end. Hinton was an exception. He was already training tiny models that could produce short strings of text one character at a time, says Sutskever: “It was the beginning of generative AI right there. It was really cool—it just wasn’t very good.”</p>  <p>Sutskever was fascinated with brains: how they learned and how that process might be re-created, or at least mimicked, in machines. Like Hinton, he saw the potential of neural networks and the trial-and-error technique Hinton used to train them, called deep learning. “It kept getting better and better and better,” says Sutskever.</p>  <p>In 2012 Sutskever, Hinton, and another of Hinton’s graduate students, Alex Krizhevsky, built a neural network called AlexNet that they trained to identify objects in photos far better than any other software around at the time. It was deep learning’s Big Bang moment.</p> 

 <p>After many years of false starts, they had showed that neural networks were amazingly effective at pattern recognition after all. You just needed more data than most researchers had seen before (in this case, a million images from the ImageNet data set that Princeton University researcher <a href="https://www.technologyreview.com/2017/10/09/3988/put-humans-at-the-center-of-ai/">Fei-Fei Li</a> had been building since 2006) and an eye-watering amount of computer power.</p>  <p>The step change in compute came from a new kind of chip called a graphics processing unit (GPU), made by Nvidia. GPUs were designed to be lightning quick at throwing fast-moving video-game visuals onto screens. But the calculations that GPUs are good at—multiplying massive grids of numbers—happened to look a lot like the calculations needed to train neural networks.&nbsp;</p>  <p>Nvidia is now a trillion-dollar company. At the time it was desperate to find applications for its niche new hardware. “When you invent a new technology, you have to be receptive to crazy ideas,” says Nvidia CEO Jensen Huang. “My state of mind was always to be looking for something quirky, and the idea that neural networks would transform computer science—that was an outrageously quirky idea.”</p>  <p>Huang says that Nvidia sent the Toronto team a couple of GPUs to try when they were working on AlexNet. But they wanted the newest version, a chip called the GTX 580 that was fast selling out in stores. According to Huang, Sutskever drove across the border from Toronto to New York to buy some. “People were lined up around the corner,” says Huang. “I don’t know how he did it—I’m pretty sure you were only allowed to buy one each; we had a very strict policy of one GPU per gamer—but he apparently filled a trunk with them. That trunk full of GTX 580s changed the world.”&nbsp;</p> </div><div> <p>It’s a great story—it just might not be true. Sutskever insists he bought those first GPUs online. But such myth-making is commonplace in this buzzy business. Sutskever himself is more humble: “I thought, like, if I could make even an ounce of real progress, I would consider that a success,” he says. “The real-world impact felt so far away because computers were so puny back then.”</p>  <p>After the success of AlexNet, Google came knocking. It acquired Hinton’s spin-off company DNNresearch and hired Sutskever. At Google Sutskever showed that deep learning’s powers of pattern recognition could be <a href="https://arxiv.org/pdf/1409.3215.pdf">applied to sequences of data</a>, such as words and sentences, as well as images. “Ilya has always been interested in language,” says Sutskever’s former colleague Jeff Dean, who is now Google’s chief scientist: “We’ve had great discussions over the years. Ilya has a strong intuitive sense about where things might go.”</p>  <p>But Sutskever didn’t remain at Google for long. In 2014, he was recruited to become a cofounder of OpenAI. Backed by $1 billion (from Altman, Elon Musk, Peter Thiel, Microsoft, Y Combinator, and others) plus a massive dose of Silicon Valley swagger, the new company set its sights from the start on developing AGI, a prospect that few took seriously at the time.</p>  <p>With Sutskever on board, the brains behind the bucks, the swagger was understandable. Up until then, he had been on a roll, getting more and more out of neural networks. His reputation preceded him, making him a major catch, says Dalton Caldwell, managing director of investments at Y Combinator.</p> 
 <p>“I remember Sam [Altman] referring to Ilya as one of the most respected researchers in the world,” says Caldwell. “He thought that Ilya would be able to attract a lot of top AI talent. He even mentioned that Yoshua Bengio, one of the world's top AI experts, believed that it would be unlikely to find a better candidate than Ilya to be OpenAI's lead scientist."</p>  <p>And yet at first OpenAI floundered. “There was a period of time when we were starting OpenAI when I wasn’t exactly sure how the progress would continue,” says Sutskever. “But I had one very explicit belief, which is: one doesn’t bet against deep learning. Somehow, every time you run into an obstacle, within six months or a year researchers find a way around it.”</p> 
 <p>His faith paid off. The first of OpenAI’s GPT large language models (the name stands for “generative pretrained transformer”) appeared in 2016. Then came GPT-2 and <a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/">GPT-3</a>. Then <a href="https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/">DALL-E</a>, the striking text-to-image model. Nobody was building anything as good. With each release, OpenAI raised the bar for what was thought possible.&nbsp;</p>  <h3>Managing expectations</h3>  <p>Last November, OpenAI released a free-to-use chatbot that repackaged some of its existing tech. It reset the agenda of the entire industry.&nbsp;&nbsp;&nbsp;</p> </div><div> <p>At the time, OpenAI had no idea what it was putting out. Expectations inside the company couldn’t have been lower, says Sutskever: “I will admit, to my slight embarrassment—I don’t know if I should, but what the hell, it is true—when we made ChatGPT, I didn’t know if it was any good. When you asked it a factual question, it gave you a wrong answer. I thought it was going to be so unimpressive that people would say, ‘Why are you doing this? This is so boring!’”</p>  <p>The draw was the convenience, says Sutskever. The large language model under ChatGPT’s hood had been around for months. But wrapping that in an accessible interface and giving it away for free made billions of people aware for the first time of what OpenAI and others were building.</p>  <p>“That first-time experience is what hooked people,” says Sutskever. “The first time you use it, I think it’s almost a spiritual experience. You go, ‘Oh my God, this computer seems to understand.’”</p>  <p>OpenAI amassed 100 million users in less than two months, many of them dazzled by this stunning new toy. Aaron Levie, CEO of the storage firm Box, summed up the vibe in the week after launch when he tweeted: “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.”&nbsp;</p> 
 <p>That wonder collapses as soon as ChatGPT says something stupid. But by then it doesn’t matter. That glimpse of what was possible is enough, says Sutskever. ChatGPT changed people’s horizons.</p>  <p>“AGI stopped being a dirty word in the field of machine learning,” he says. “That was a big change. The attitude that people have taken historically has been: AI doesn’t work, every step is very difficult, you have to fight for every ounce of progress. And when people came with big proclamations about AGI, researchers would say, ‘What are you talking about? This doesn’t work, that doesn’t work. There are so many problems.’ But with ChatGPT it started to feel different.”</p>  <p>And that shift only started to happen a year ago? “It happened because of ChatGPT,” he says. “ChatGPT has allowed machine-learning researchers to dream.”</p>  <p>Evangelists from the start, OpenAI’s scientists have been stoking those dreams with blog posts and speaking tours. And it is working: “We have people now talking about how far AI will go—people who talk about AGI, or superintelligence.” And it’s not just researchers. “Governments are talking about it,” says Sutskever. “It’s crazy.”</p> 
</div><div> <h3>Incredible things</h3>  <p>Sutskever insists all this talk about a technology that does not yet (and may never) exist is a good thing, because it makes more people aware of a future that he already takes for granted.</p>  <p>“You can do so many amazing things with AGI, incredible things: automate health care, make it a thousand times cheaper and a thousand times better, cure so many diseases, actually solve global warming,” he says. “But there are many who are concerned: ‘My God, will AI companies succeed in managing this tremendous technology?’”</p>  <p>Presented this way, AGI sounds more like a wish-granting genie than real-world prospect. Few would say no to saving lives and solving climate change. But the problem with a technology that doesn’t exist is that you can say whatever you want about it.&nbsp;</p>  <p>What is Sutskever really talking about when he talks about AGI? “AGI is not meant to be a scientific term,” he says. “It’s meant to be a useful threshold, a point of reference.”</p>  <p>“It is the idea—” he starts, then stops. “It’s the point at which AI is so smart that if a person can do some task, then AI can do it too. At that point you can say you have AGI.”</p>  <p>People may be talking about it, but AGI remains one of the field’s most <a href="https://www.technologyreview.com/2020/10/15/1010461/artificial-general-intelligence-robots-ai-agi-deepmind-google-openai/">controversial ideas</a>. Few take its development as a given. Many researchers believe that major conceptual breakthroughs are needed before we see anything like what Sutskever has in mind—and some believe we never will.&nbsp;</p>  <p>And yet it’s a vision that has driven him from the start. “I’ve always been inspired and motivated by the idea,” says Sutskever. “It wasn’t called AGI back then, but you know, like, having a neural network do everything. I didn’t always believe that they could. But it was the mountain to climb.”</p>  <p>He draws a parallel between the way that neural networks and brains operate. Both take in data, aggregate signals from that data, and then—based on some simple process (math in neural networks, chemicals and bioelectricity in brains)—propagate them or not. It’s a massive simplification, but the principle stands.</p> </div><div> <p>“If you believe that—if you allow yourself to believe that—then there are a lot of interesting implications,” says Sutskever. “The main implication is that if you have a very big artificial neural network, it should do a lot of things. In particular, if the human brain can do something, then a big artificial neural network could do something similar too.”&nbsp;</p>  <p>“Everything follows if you take this realization seriously enough,” he says. “And a big fraction of my work can be explained by that.”</p>  <p>While we’re talking about brains, I want to ask about one of Sutskever’s posts on X, the site formerly known as Twitter. Sutskever’s feed reads like a scroll of aphorisms: “If you value intelligence above all other human qualities, you’re gonna have a bad time”; “Empathy in life and business is underrated”; “The perfect has destroyed much perfectly good good.”</p>  <p>In February 2022 he <a href="https://twitter.com/ilyasut/status/1491554478243258368?lang=en">posted</a>, “it may be that today’s large neural networks are slightly conscious” (to which Murray Shanahan, principal scientist at Google DeepMind and a professor at Imperial College London, as well as the scientific advisor on the movie <em>Ex Machina</em>, replied: “... in the same sense that it may be that a large field of wheat is slightly pasta”).</p>  <p>Sutskever laughs when I bring it up. Was he trolling? He wasn’t. “Are you familiar with the concept of a Boltzmann brain?” he asks.</p>  <p>He's referring to a (tongue-in-cheek) <a href="https://en.wikipedia.org/wiki/Boltzmann_brain">thought experiment</a> in quantum mechanics named after the 19th-century physicist Ludwig Boltzmann, in which random thermodynamic fluctuations in the universe are imagined to cause brains to pop in and out of existence.</p>  <p>“I feel like right now these language models are kind of like a Boltzmann brain,” says Sutskever. “You start talking to it, you talk for a bit; then you finish talking, and the brain kind of—” He makes a disappearing motion with his hands. Poof—bye-bye, brain.</p>  <p>You’re saying that while the neural network is active—while it’s firing, so to speak—there’s something there? I ask.</p> </div><div> <p>“I think it might be,” he says. “I don’t know for sure, but it’s a possibility that’s very hard to argue against. But who knows what’s going on, right?”</p>  <h3>AI but not as we know it</h3>  <p>While others wrestle with the idea of machines that can match human smarts, Sutskever is preparing for machines that can <em>outmatch</em> us. He calls this artificial superintelligence: “They’ll see things more deeply. They’ll see things we don’t see.”</p>  <p>Again, I have a hard time grasping what this really means. Human intelligence is our benchmark for what intelligence is. What does Sutskever mean by smarter-than-human intelligence?</p>  <p>“We’ve seen an example of a very narrow superintelligence in AlphaGo,” he says. In 2016, DeepMind’s board-game-playing AI beat Lee Sedol, one of the best Go players in the world, 4–1 in a five-game match. “It figured out how to play Go in ways that are different from what humanity collectively had developed over thousands of years,” says Sutskever. “It came up with new ideas.”</p>  <p>Sutskever points to AlphaGo’s infamous Move 37. In its second game against Sedol, the AI made a move that flummoxed commentators. They thought AlphaGo had screwed up. In fact, it had played a winning move that nobody had ever seen before in the history of the game. “Imagine that level of insight, but across everything,” says Sutskever.&nbsp;</p>  <p>It’s this train of thought that has led Sutskever to make the biggest shift of his career. Together with Jan Leike, a fellow scientist at OpenAI, he has set up a team that will focus on what they call <a href="https://openai.com/blog/introducing-superalignment">superalignment</a>. Alignment is jargon that means making AI models do what you want and nothing more. Superalignment is OpenAI’s term for alignment applied to superintelligence.</p>  <p>The goal is to come up with a set of fail-safe procedures for building and controlling this future technology. OpenAI says it will allocate a fifth of its vast computing resources to the problem and solve it in four years.&nbsp;</p>  <p>“Existing alignment methods won’t work for models smarter than humans because they fundamentally assume that humans can reliably evaluate what AI systems are doing,” says Leike. “As AI systems become more capable, they will take on harder tasks.” And that—the idea goes—will make it harder for humans to assess them. “In forming the superalignment team with Ilya, we’ve set out to solve these future alignment challenges,” he says.</p> </div><div><p>“It’s super important to not only focus on the potential opportunities of large language models, but also the risks and downsides,” says Dean, Google’s chief scientist.&nbsp;</p>  <p>The company announced the project in July with typical fanfare. But for some it was yet more fantasy. OpenAI’s post on Twitter attracted scorn from prominent critics of Big Tech, including Abeba Birhane, who works on AI accountability at Mozilla (“so many grandiose sounding yet vacuous words in one blog post”); Timnit Gebru, cofounder of the Distributed Artificial Intelligence Research Institute (“Imagine ChatGPT even more ‘super aligned’ with OpenAI techbros. *shudder*”); and Margaret Mitchell, chief ethics scientist at the AI firm Hugging Face (“My alignment is bigger than yours”). It’s true that these are familiar voices of dissent. But it’s a strong reminder that where some see OpenAI leading from the front, others see it leaning in from the fringes.</p>  <p>But, for Sutskever, superalignment is the inevitable next step. “It’s an unsolved problem,” he says. It’s also a problem that he thinks not enough core machine-learning researchers, like himself, are working on. “I’m doing it for my own self-interest,” he says. “It’s obviously important that any superintelligence anyone builds does not go rogue. Obviously.”&nbsp;</p>  <p>The work on superalignment has only just started. It will require broad changes across research institutions, says Sutskever.&nbsp;But he has an exemplar in mind for the safeguards he wants to design: a machine that looks upon people the way parents look on their children. “In my opinion, this is the gold standard,” he says. “It is a generally true statement that people really care about children.” (Does he have children? “No, but I want to,” he says.)</p>  <p>My time with Sutskever is almost up, and I figure we’re done. But he’s on a roll and has one more thought to share—one I don't see coming.&nbsp;</p>  <p>“Once you overcome the challenge of rogue AI, then what? Is there even room for human beings in a world with smarter AIs?” he says.</p>  <p>“One possibility—something that may be crazy by today’s standards but will not be so crazy by future standards—is that many people will choose to become part AI.” Sutskever is saying this could be how&nbsp;humans try to keep up. “At first, only the most daring, adventurous people will try to do it. Maybe others will follow. Or not.”</p>  <p>Wait, what? He’s getting up to leave. Would he do it? I ask. Would he be one of the first? “The first? I don’t know,” he says. “But it’s something I think about. The true answer is: maybe.”&nbsp;</p>  <p>And with that galaxy-brained mic drop, he stands and walks out of the room. “Really good to see you again,” he says as he goes.&nbsp; </p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft is a minority owner of OpenAI Global LLC (119 pts)]]></title>
            <link>https://openai.com/our-structure</link>
            <guid>38316497</guid>
            <pubDate>Sat, 18 Nov 2023 07:22:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/our-structure">https://openai.com/our-structure</a>, See on <a href="https://news.ycombinator.com/item?id=38316497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><!--[--><!--[--><div><p>We <a href="https://openai.com/blog/openai-lp" rel="noopener noreferrer" target="_blank">announced</a> our “capped profit” structure in 2019, about three years after <a href="https://openai.com/blog/introducing-openai" rel="noopener noreferrer" target="_blank">founding</a> the original OpenAI Nonprofit.</p><p>Since the beginning, we have believed that powerful AI, culminating in AGI—meaning a highly autonomous system that outperforms humans at most economically valuable work—has the potential to reshape society and bring tremendous benefits, along with risks that must be safely addressed. The increasing capabilities of present day systems mean it’s more important than ever for OpenAI and other AI companies to share the principles, economic mechanisms, and governance models that are core to our respective missions and operations.<br></p></div><!--]--><!--[--><div id="overview" data-heading=""><p><h2>Overview</h2></p></div><!--]--><!--[--><div><p>We founded the OpenAI Nonprofit in late 2015 with the goal of building safe and beneficial artificial general intelligence for the benefit of humanity. A project like this might previously have been the provenance of one or multiple governments—a humanity-scale endeavor pursuing broad benefit for humankind.</p><p>Seeing no clear path in the public sector, and given the success of other ambitious projects in private industry (e.g., SpaceX, Cruise, and others), we decided to pursue this project through private means bound by strong commitments to the public good. We initially believed a 501(c)(3) would be the most effective vehicle to direct the development of safe and broadly beneficial AGI while remaining unencumbered by profit incentives. We committed to publishing our research and data in cases where we felt it was safe to do so and would benefit the public.</p><p>We always suspected that our project would be capital intensive, which is why we launched with the goal of $1 billion in donation commitments. Yet over the years, OpenAI’s Nonprofit received approximately $130.5 million in total donations, which funded the Nonprofit’s operations and its initial exploratory work in deep learning, safety, and alignment.</p><p>It became increasingly clear that donations alone would not scale with the cost of computational power and talent required to push core research forward, jeopardizing our mission. So we devised a structure to preserve our Nonprofit’s core mission, governance, and oversight while enabling us to raise the capital for our mission:</p><ul><li>The OpenAI Nonprofit would remain intact, with its board continuing as the overall governing body for all OpenAI activities.<br></li><li>A new for-profit subsidiary would be formed, capable of issuing equity to raise capital and hire world class talent, but still at the direction of the Nonprofit. Employees working on for-profit initiatives were transitioned over to the new subsidiary. <br></li><li>The for-profit would be legally bound to pursue the Nonprofit’s mission, and carry out that mission by engaging in research, development, commercialization and other core operations. Throughout, OpenAI’s guiding principles of safety and broad benefit would be central to its approach.<br></li><li>The for-profit’s equity structure would have caps that limit the maximum financial returns to investors and employees to incentivize them to research, develop, and deploy AGI in a way that balances commerciality with safety and sustainability, rather than focusing on pure profit-maximization. <br></li><li>The Nonprofit would govern and oversee all such activities through its board in addition to its own operations. It would also continue to undertake a wide range of charitable initiatives, such as sponsoring a comprehensive <a href="https://www.openresearchlab.org/basic-income" rel="noopener noreferrer" target="_blank">basic income study, </a>supporting <a href="https://openai.com/research/gpts-are-gpts" rel="noopener noreferrer" target="_blank">economic impact research</a>, and experimenting with education-centered programs like <a href="https://openai.com/blog/openai-scholars-2021-final-projects" rel="noopener noreferrer" target="_blank">OpenAI Scholars</a>. Over the years, the Nonprofit also supported a number of other public charities focused on technology, economic impact and justice, including the Stanford University Artificial Intelligence Index Fund, Black Girls Code, and the ACLU Foundation.</li></ul><p>In that way, the Nonprofit would remain central to our structure and control the development of AGI, and the for-profit would be tasked with marshaling the resources to achieve this while remaining duty-bound to pursue OpenAI’s core mission. The primacy of the mission above all is encoded in the operating agreement of the for-profit, which every investor and employee is subject to:<br></p></div><!--]--><!--[--><div><figure><p><img src="https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=10&amp;height=10&amp;quality=50" width="1940" height="926" alt="OpenAI investor disclaimer" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/142770fb-3df2-45d9-9ee3-7aa069acada1/image1.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false"></p><figcaption><!--[--><!--]--></figcaption></figure></div><!--]--><!--[--><div id="the-structure-in-more-detail" data-heading=""><p><h2>The structure in more detail</h2></p></div><!--]--><!--[--><div><p>While investors typically seek financial returns, we saw a path to aligning their motives with our mission. We achieved this innovation with a few key economic and governance provisions:</p><ul><li>First, the for-profit subsidiary is fully controlled by the OpenAI Nonprofit. We enacted this by having the Nonprofit wholly own and control a manager entity (OpenAI GP LLC) that has the power to control and govern the for-profit subsidiary.</li><li>Second, because the board is still the board of a Nonprofit, each director must perform their fiduciary duties in furtherance of its mission—safe AGI that is broadly beneficial. While the for-profit subsidiary is permitted to make and distribute profit, it is subject to this mission. The Nonprofit’s principal beneficiary is humanity, not OpenAI investors.</li><li>Third, the board remains majority independent. Independent directors do not hold equity in OpenAI. Even OpenAI’s CEO, Sam Altman, does not hold equity directly. His only interest is indirectly through a Y Combinator investment fund that made a small investment in OpenAI before he was full-time.</li><li>Fourth, profit allocated to investors and employees, including Microsoft, is capped. All residual value created above and beyond the cap will be returned to the Nonprofit for the benefit of humanity.</li><li>Fifth, the board determines when we've attained AGI. Again, by AGI we mean a highly autonomous system that outperforms humans at most economically valuable work. Such a system is excluded from IP licenses and other commercial terms with Microsoft, which only apply to pre-AGI technology.<br></li></ul></div><!--]--><!--[--><div><figure><p><img src="https://images.openai.com/blob/f3e12a69-e4a7-4fe2-a4a5-c63b61f26ab7/org-structure.svg?width=10&amp;height=10&amp;quality=50" width="796" height="551" alt="OpenAI Org Structure" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" aria-hidden="false"></p><figcaption><!--[--><!--]--></figcaption></figure></div><!--]--><!--[--><div><p>We strive to preserve these core governance and economic components of our structure when exploring opportunities to accelerate our work. Indeed, given the path to AGI is uncertain, our structure is designed to be adaptable—we believe this is a feature, not a bug.<br></p></div><!--]--><!--[--><div id="microsoft" data-heading=""><p><h2>Microsoft</h2></p></div><!--]--><!--[--><div><p>Shortly after announcing the OpenAI capped profit structure (and our initial round of funding) in 2019, we <a href="https://openai.com/blog/microsoft-invests-in-and-partners-with-openai" rel="noopener noreferrer" target="_blank">entered</a> into a strategic partnership with Microsoft. We subsequently <a href="https://openai.com/blog/openai-and-microsoft-extend-partnership" rel="noopener noreferrer" target="_blank">extended</a> our partnership, expanding both Microsoft’s total investment as well as the scale and breadth of our commercial and supercomputing collaborations.</p><p>While our partnership with Microsoft includes a multibillion dollar investment, OpenAI remains an entirely independent company governed by the OpenAI Nonprofit. Microsoft has no board seat and no control. And, as explained above, AGI is explicitly carved out of all commercial and IP licensing agreements.</p><p>These arrangements exemplify why we chose Microsoft as our compute and commercial partner. From the beginning, they accepted our capped equity offer and our request to leave AGI technologies and governance for the Nonprofit and the rest of humanity. They have also worked with us to create and refine our joint safety board that reviews our systems before they are deployed. Harkening back to our origins, they understand that this is a unique and ambitious project that requires resources at the scale of the public sector, as well as the very same conscientiousness to share the ultimate results with everyone.<br></p></div><!--]--><!--[--><div id="our-board" data-heading=""><p><h2>Our board</h2></p></div><!--]--><!--[--><div><p>OpenAI is governed by the board of the OpenAI Nonprofit, comprised of OpenAI Global, LLC employees Greg Brockman (Chairman &amp; President), Ilya Sutskever (Chief Scientist), and Sam Altman (CEO), and non-employees Adam D’Angelo, Tasha McCauley, Helen Toner.<br></p></div><!--]--><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Three senior researchers have resigned from OpenAI (829 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38316378</link>
            <guid>38316378</guid>
            <pubDate>Sat, 18 Nov 2023 07:04:20 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38316378">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38316682"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316682" href="https://news.ycombinator.com/vote?id=38316682&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>Makes me wonder whether to keep building upon OpenAI? Given that they have an API and it takes effort to build on that vs. something else. I am small fry but maybe other people are wondering the same? Can they give reassurances about their products going into the future?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38316719"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38316719" href="https://news.ycombinator.com/vote?id=38316719&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>I am wondering the same. It’s a PR desaster to their dev community and i’m not even sure if Sutskever isn’t secretly happy about this.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38316742"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38316742" href="https://news.ycombinator.com/vote?id=38316742&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>&gt; Makes me wonder whether to keep building upon OpenAI?<p>You don't have the choice. You _will_ follow the compulsion regardless.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38316712"><td></td></tr>
            <tr id="38316425"><td></td></tr>
            <tr id="38316461"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316461" href="https://news.ycombinator.com/vote?id=38316461&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>Aleksander in particular is deeply invested in AI safety as a mission. It's a very confusing departure, since most of the reporting so far indicates that Ilya and the board fired Sam to prioritize safety and non-profit objectives. A huge loss for OpenAI nonetheless.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38316591"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38316591" href="https://news.ycombinator.com/vote?id=38316591&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>Perhaps you could argue that he wants to stick with Sam and the others because if they start a company that competes with OpenAI, there’s a real chance they catch up and surpass OpenAI. If you really want to be a voice for safety, it’ll be most effective if you’re on the winning team.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38316561"><td></td></tr>
                  <tr id="38316395"><td></td></tr>
            <tr id="38316711"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316711" href="https://news.ycombinator.com/vote?id=38316711&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>people can have multiple overlapping reasons for things, it doesn't have to be they are on "sam's side" or the "board's side" or whatever.  you can agree w/ a firing and for whatever reason disagree w/ the way it was done or future direction of a company, etc.  all just guessing anyway.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38316603"><td></td></tr>
                <tr id="38316623"><td></td></tr>
                <tr id="38316643"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38316643" href="https://news.ycombinator.com/vote?id=38316643&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>I agree AI is useful, but not to that extent to what it is valued on the market. I do not think that AI companies can deliver as much as they promise. With the driving core at OpenAI basically gone, I bet they will soon implode under the weight of their promises. Which means, investors will start pulling out their stakes. boom</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38316694"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38316694" href="https://news.ycombinator.com/vote?id=38316694&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>What's the use of a newborn baby?<p>AI is as real as the mobile/internet/pc revolution of the past.</p><p>So many use it obsessively every single day.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38316724"><td></td></tr>
                  <tr id="38316696"><td></td></tr>
                  <tr id="38316647"><td></td></tr>
            <tr id="38316731"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38316731" href="https://news.ycombinator.com/vote?id=38316731&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>It is a bubble if it is overvalued.  I don't think it is, but nothing prevents something useful from being a bubble, if the valuation is extreme.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38316644"><td></td></tr>
                <tr id="38316699"><td></td></tr>
                  <tr id="38316723"><td></td></tr>
            <tr id="38316648"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38316648" href="https://news.ycombinator.com/vote?id=38316648&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>It can be useful in certain contexts, most certainly as a code co-pilot, but that and yours/others' usage doesn't change the fundamental mismatch between the limits of this tech and what Sam and others have hyped it up to do.<p>We've already trained it on all the data there is, it's not going to get "smarter" and it'll always lack true subjective understanding, so the overhype has been real, indeed to bubble levels as per OP.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38316681"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38316681" href="https://news.ycombinator.com/vote?id=38316681&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>&gt; it's not going to get "smarter" and it'll always lack true subjective understanding<p>What is your basis for those claims? Especially the first one; I would think it's obvious that it <i>will</i> get smarter; the only questions are how much and how quickly. As far as subjective understanding, we're getting into the nature of consciousness territory, but if it can perform the same tasks, it doesn't really impact the value.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38316698"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38316698" href="https://news.ycombinator.com/vote?id=38316698&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>I would appreciate another example where a major new communications technology peaks in its implementation within the first year after it is introduced to the market.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38316714"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38316714" href="https://news.ycombinator.com/vote?id=38316714&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>You must not use AI if you think this. AI is not the bubble. Everything AI will replace is the bubble.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38316580"><td></td></tr>
            <tr id="38316562"><td></td></tr>
                <tr id="38316585"><td></td></tr>
                  <tr id="38316614"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316614" href="https://news.ycombinator.com/vote?id=38316614&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>We need to know why he was let go. All else is speculation. I doubt people would follow Sam if he was let go for a good reason.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38316651"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38316651" href="https://news.ycombinator.com/vote?id=38316651&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>Unless they don't know the reason. (But of course, it's hard to imagine what reason could be so secret that it's better to let people start jumping ship than share it with employees.)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38316633"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316633" href="https://news.ycombinator.com/vote?id=38316633&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>I just want to point out that it was exactly a week ago that OpenAI was openly announcing $10M pay packages to pull AI researchers from other major companies, like Alphabet. These other companies are well established and if OpenAI were a normal corporation might look at various hostile takeover strategies.<p>How much more cost effective to just fool half the board of a nonprofit into taking unnecessarily aggressive action.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38316558"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316558" href="https://news.ycombinator.com/vote?id=38316558&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>I'm going to predict more by tomorrow as the AGI secures its position.<p>In other news, Tesla FSD has been rebranded Saneer-Weeksbooth Autobot. So be careful out there folks.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38316568"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316568" href="https://news.ycombinator.com/vote?id=38316568&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>Well it begins. OpenAI will be a shell of itself in very short time.<p>Advice: you can't win over a narrative, which is what Sam has become. People and resources will come to him, by themselves.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38316621"><td></td></tr>
                <tr id="38316638"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38316638" href="https://news.ycombinator.com/vote?id=38316638&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><p><span>Doomerism when it comes to technology has always been such a weird mindset to me. "oh no, they're gonna take the horses/horse buggies/telegram/landlines away!"<p>"Goddamn, how dare they invent the bigger cannons!?" - Romans, 1453, in Constantinople probably. (One incident where I can use my exempt powers).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38316654"><td></td></tr>
                        <tr id="38316575"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38316575" href="https://news.ycombinator.com/vote?id=38316575&amp;how=up&amp;goto=item%3Fid%3D38316378"></a></center>    </td><td><br><div>
                  <p><span>Sam should lead a group of outstanding engineers to rebuild another AI company. Maybe in the long run, leaving openai's naive board of directors might not be a bad thing for him.</span></p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman and Greg Brockman Joint Statement (149 pts)]]></title>
            <link>https://twitter.com/gdb/status/1725736242137182594</link>
            <guid>38315309</guid>
            <pubDate>Sat, 18 Nov 2023 04:42:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/gdb/status/1725736242137182594">https://twitter.com/gdb/status/1725736242137182594</a>, See on <a href="https://news.ycombinator.com/item?id=38315309">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Board Members (2014) (107 pts)]]></title>
            <link>https://blog.samaltman.com/board-members</link>
            <guid>38315265</guid>
            <pubDate>Sat, 18 Nov 2023 04:37:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.samaltman.com/board-members">https://blog.samaltman.com/board-members</a>, See on <a href="https://news.ycombinator.com/item?id=38315265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_container">
  <article>
    
  <header>
    

    
  </header>

  <div id="post_body_768297"><p>Over the
last five years, there has been an incredible shift in leverage from investors
to founders.&nbsp; It’s good in most ways, but bad in an important few.&nbsp; Founders’ desire for control is good in
moderation but hurts companies when it gets taken to extremes.&nbsp;</p>

<p>Many founders
(or at least, many of the founders I talk to) generally want few to no
outsiders on their boards.&nbsp;&nbsp;A popular way to win an A round in the
current environment is to not ask for a board seat.&nbsp;&nbsp;Some investors
are happy to do this—it’s certainly easier to write a check and go hang out on
the beach than it is to take a board seat.&nbsp;&nbsp;And this trend is likely
to continue, because these new investors are generally willing to pay much
higher prices than investors that want to be involved with the company.</p>

<p>But great
board members, with a lot of experience seeing companies get built, are the
sort of people founders should want thinking about their companies every day.&nbsp;&nbsp;There
are a lot of roles where experience doesn’t matter in a startup, but board
members usually aren’t one of them.&nbsp; Board
members are very useful in helping founders think big and hire executives.&nbsp;</p>

<p>Board
members are also a good forcing function to keep the company focused on
execution.&nbsp; In my experience, companies
without any outsiders on their boards often have less discipline around operational
cadence.&nbsp;</p>

<p>Finally,
board members stick with the company when things really go wrong, in a way that
advisors usually don’t.</p>

<p>Board members certainly don't have to be investors. &nbsp;If founders
do choose to take money without an involved board member, I think it’s very
important to get an advisor with a significant equity position that will play
the role of a board member (or better, actually put them on the board).&nbsp;</p>

<p>Personally,
I think the ideal board structure for most early-stage companies is a 5-member
board with 2 founders, 2 investors, and one outsider.&nbsp;&nbsp;I think a 4-member
board with 2 founders, 1 investor and 1 outsider is also good (in practice, the
even number is almost never a problem).</p>

<p>As a side
note, bad board members are disastrous.&nbsp;&nbsp;You should check references
thoroughly on someone before you let them join your board.</p>

<p>The
companies that have had the biggest impact and created the most value have had
excellent board members (and executives).&nbsp;&nbsp;I don’t believe this is a
coincidence.</p>

<p>It’s a good
idea to keep enough control so that investors can’t fire you (there are a lot
of different ways to do this), but beyond that, it’s important to bring in
other people and trust them to help you build the company.</p>



<p>Thanks to
Mike Moritz for reviewing a draft of this.</p></div>


  </article>

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sutskever: OpenAI board doing its mission to build AGI that benefits all (118 pts)]]></title>
            <link>https://twitter.com/GaryMarcus/status/1725707548106580255</link>
            <guid>38314407</guid>
            <pubDate>Sat, 18 Nov 2023 02:54:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/GaryMarcus/status/1725707548106580255">https://twitter.com/GaryMarcus/status/1725707548106580255</a>, See on <a href="https://news.ycombinator.com/item?id=38314407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ilya Sutskever "at the center" of Altman firing (397 pts)]]></title>
            <link>https://twitter.com/karaswisher/status/1725702501435941294</link>
            <guid>38314299</guid>
            <pubDate>Sat, 18 Nov 2023 02:40:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karaswisher/status/1725702501435941294">https://twitter.com/karaswisher/status/1725702501435941294</a>, See on <a href="https://news.ycombinator.com/item?id=38314299">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Parental controls? What parental controls? (121 pts)]]></title>
            <link>https://gabrielsieben.tech/2023/11/15/parental-controls-are-unusable-and-its-why-congress-is-stepping-in/</link>
            <guid>38314224</guid>
            <pubDate>Sat, 18 Nov 2023 02:31:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gabrielsieben.tech/2023/11/15/parental-controls-are-unusable-and-its-why-congress-is-stepping-in/">https://gabrielsieben.tech/2023/11/15/parental-controls-are-unusable-and-its-why-congress-is-stepping-in/</a>, See on <a href="https://news.ycombinator.com/item?id=38314224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">
		Skip to content	</a></p><!-- #masthead -->

	<div id="content">
		<main id="main">

			
<article id="post-996">
		
	
	<div>
		
<p>Congress has recently proposed multiple bills to regulate the internet (such as the recent “Kids Online Safety Act”), in the name of protecting children. This has caused a simple response: “Just have parents be parents and set up parental controls if they care.”</p>



<p>That’s simpler said than done. Parental controls right now <em>completely suck</em> by being incomplete, full of loopholes, extremely buggy, overly complicated, poorly designed, privacy invading, or a combination of the above. As someone who has used almost every ecosystem, here’s an eye opener. </p>



<p>Also here’s my rallying cry: If you don’t want Congress regulating the internet to “protect the Kids,” demand companies fix their parental controls. </p>



<p><strong>Windows 11</strong></p>



<p>Microsoft has <em>Family Safety</em> as their tool for parental controls on Windows. Here’s my hate list.</p>



<ol>
<li>Every child must have a Microsoft Account to use it. Even the 8-year-olds. Local accounts are still supported by Windows 11 after setting up the main account, but you can’t use parental controls with them. </li>



<li>You can’t disable Windows Copilot, or Edge Copilot. Don’t want your kid using AI from Bing or ChatGPT when they are just learning to write? Too bad. Don’t want them using AI for any host of ethical or personal issues? Too bad. </li>



<li>You can’t disable the Microsoft News feed of tabloid content on new Microsoft Edge tabs, without disabling Bing (rendering you unable to offer restricted “SafeSearch” browsing of any kind, to your child, at all). </li>



<li>You can’t disable the Microsoft Search button, which shows… surprise, more tabloid content. Even if you have your child’s account set to “allowed websites only.” They’ll still see headlines of the day about how the world is on fire.</li>



<li>You can’t disable the Widgets button. The entire purpose of widgets is to serve tabloid content. And once again, “allowed websites only” doesn’t disable that or do basically anything to it. </li>



<li>Windows 11 comes preloaded with Movies+TV, Xbox, Microsoft News, and other apps. Unless you as a parent <em>know</em> about these apps, open these apps individually so they appear in the dashboard, and <em>then</em> block these apps, they’re allowed. <em>What?</em></li>



<li>You can’t disable the Microsoft Store. You can set age restrictions; so setting everything to block all apps rated above the Age of 3 is the best you’ll be able to do. </li>



<li>Microsoft Office lets you embed content from Bing, and does not respect system parental controls… at all. Even if you block Bing, your 8-year-old can still watch videos to their heart’s content by embedding them in a Word document, because the internet filters <em>only work in Microsoft Edge</em>.</li>
</ol>



<p>So let’s say you want to allow your 8-year-old to work on school, on a Windows PC. What’s the point of parental controls when you can’t disable Widgets, can’t disable the tabloid content in the Search box even if you block Bing, the Bing filter can still be bypassed using Office, and your student can use AI all they want? These are “parental controls”?</p>



<p><strong>MacOS / iOS</strong></p>



<ol>
<li>Quite powerful, stupidly buggy. So much so that Apple even admitted as such to a reporter a few months ago. There is, in my experience, no part of macOS more buggy than Screen Time. How so? </li>



<li> It appears that Screen Time runs using a daemon (background process) on the child’s account. That daemon has a propensity to randomly crash after running for a few hours. When it does, <em>all locks are disabled. </em>Safari will just let you open Private windows without filtering of any kind, regardless of your internet filtering settings, when that happens. This state then remains until the child logs out and logs back in. Naturally, <em>what’s the point of parental controls that randomly fail open?</em></li>



<li>The “allowed websites only” option shows Apple has never used this feature, ever. You will be swarmed on your first login with prompts to approve random IP addresses and Apple domains because of system services that can no longer communicate with the mother ship. And they will nag you <em>constantly</em> with no option to disable them, so your first experience of enabling this is entering your PIN code a dozen or more time to approve all sorts of random junk just to get to a usable state. </li>



<li>The “allow this website” button on the “website blocked” page randomly doesn’t work; and this might be because the codebase is so old (and likely untested for so long), <em>it’s not even HTML5</em>. Meaning it’s probably been, what, a decade and a half since anyone really looked at it last?</li>



<li>You can’t disable any in-box system apps. You don’t want your kid reading through the Apple Books store? You don’t want your kid seeing suggestive imagery and nudity in the Apple Music app? You don’t want your kid listening to random Podcasts from anyone in the Apple Podcasts app? You can’t do anything about it but set a time limit for 1 minute. Of course, that time limit randomly doesn’t work either.</li>



<li>The “allowed websites” list in macOS has a comical, elementary bug showing how badly tested the code is. If you open the preference pane, it shows a list of allowed websites (say, A, B, and C). Let’s say I add a website called D, and close it. I open the preference pane again – only A, B, and C are in the list, D nowhere to be seen! However, D <em>was</em> added to the system, but it’s not in the list. If I go add E (so the list is now A, B, C, and E); D will then be <em>removed</em> and opening the preference pane will one again just show A, B, and C.</li>
</ol>



<p><strong>Nintendo Switch</strong></p>



<p>I generally like Nintendo, but the Nintendo Switch Parental Controls are inexcusable.</p>



<ol>
<li>Every parental control is per-device. What about families that have, say, multiple children and can’t afford (or don’t want the risk) of having multiple Switches? Seems reasonable, but no, every Switch is personal to the owner if you use Parental Controls.</li>



<li>Let’s say you then go, fine, and buy multiple Switches. There’s no ability to set a PIN lock; so theoretically the kids could just… swipe the other’s Switch?</li>



<li>You can’t hide titles on the menu. Let’s say you have two kids on the same Switch. One plays M-rated titles, the other plays E-rated titles. The kid who plays E-rated titles will see all the M-rated titles on the Home Screen, and nothing can be done about it. They can even <em>launch them and play them</em>. </li>



<li>You can’t disable the eShop from within the Parental Controls app. You can dig through the eShop settings to find the option to require a password before signing in, but that requires the kid to not know their own Nintendo password. If your kid uses, say, their actual email address on their Nintendo account, locking down the eShop is impossible – and they’ll see every game for sale regardless of how appropriate or inappropriate it is (<em>Hentai Girls</em>, <em>Waifu Uncovered</em>, anyone? Games you can “play with one hand”? Actual titles on the eShop). </li>
</ol>



<p><strong>Router based filtering</strong></p>



<p>One of the best solutions. Unfortunately, </p>



<ol>
<li>Every child must have their own device (again, poor families need not apply, making this very financially uninclusive solution).</li>



<li>Often, technically overwhelming for parents. What IP address is that kid’s laptop again? </li>



<li>Premium routers like Eero, which have very easy to use router-based parental controls, often demand subscriptions to use them. In the case of Eero, $9.99/mo. after you already paid ~$200 for the devices. That’s not a viable solution – I can’t tell a poor family to pay $200+ for routers <em>and </em>a $9.99/mo. subscription as their solution.</li>



<li>Some routers have parental controls that make me wonder what idiot thought this would work. Case in point – a Netgear router from a few years ago that let me “block websites” and had “parental controls” right on the box. Cool – but they worked by letting a parent individually enter, domain by domain, websites to block. Considering the internet’s scale, that’s criminally useless and if I had a lawyer, I would’ve sued for false advertising.</li>



<li>Remember the Nintendo eShop? Try using router-based parental controls to block eShop access without blocking software updates or online play. Good luck with that. Router-based blocking has the least nuance of any of the above solutions. </li>
</ol>



<p>But sure. It’s the parent’s job to set up parental controls. My response is, once again, if you don’t want Congress regulating the internet, parents need better tools than these. </p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		Gabriel Sieben is a 21-year-old software developer from St. Paul, MN, who enjoys experimenting with computers and loves to share his various technology-related projects. He owns and runs this blog, and is a traditional Catholic. In his free time (when not messing with computers), he enjoys hiking, fishing, and board games.		<a href="https://gabrielsieben.tech/author/gjsman/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
		
</article><!-- #post-996 -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</div><!-- #content -->

	<!-- #colophon -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LMAX Disruptor – High Performance Inter-Thread Messaging Library (121 pts)]]></title>
            <link>https://lmax-exchange.github.io/disruptor/</link>
            <guid>38313457</guid>
            <pubDate>Sat, 18 Nov 2023 01:08:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lmax-exchange.github.io/disruptor/">https://lmax-exchange.github.io/disruptor/</a>, See on <a href="https://news.ycombinator.com/item?id=38313457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<div>
<h2 id="_read_this_first">Read This First</h2>
<div>
<p>To understand the problem the Disruptor is trying to solve, and to get a feel for why this concurrency framework is so fast, read the <a href="https://lmax-exchange.github.io/disruptor/disruptor.html">Technical Paper</a>.
It also contains detailed performance results.</p>
<p>And now for some words from our sponsors…​</p>
<p>LMAX are recruiting once again.
If you are interested in working with a great team, with some amazing technology, and think you can add something to the mix then please check out our <a href="https://careers.lmax.com/">jobs page</a>.</p>
</div>
</div>
<div>
<h2 id="_what_is_the_disruptor">What is the Disruptor?</h2>
<div>
<p><a href="https://www.lmax.com/">LMAX</a> aims to be the fastest trading platform in the world.
Clearly, in order to achieve this we needed to do something special to achieve very low-latency and high-throughput with our Java platform.
Performance testing showed that using queues to pass data between stages of the system was introducing latency, so we focused on optimising this area.</p>
<p>The Disruptor is the result of our research and testing.
We found that cache misses at the CPU-level, and locks requiring kernel arbitration are both extremely costly, so we created a framework which has "mechanical sympathy" for the hardware it’s running on, and that’s lock-free.</p>
<p>This is not a specialist solution, it’s not designed to work only for a financial application.
The Disruptor is a general-purpose mechanism for solving a difficult problem in concurrent programming.</p>
<p>It works in a different way to more conventional approaches, so you use it a little differently than you might be used to.
For example, applying the pattern to your system is not as simple as replacing all your queues with the <a href="https://trishagee.com/2011/06/22/dissecting_the_disruptor_whats_so_special_about_a_ring_buffer/">magic ring buffer</a>.
We’ve got:</p>
<div>
<ul>
<li>
<p>a <a href="https://lmax-exchange.github.io/disruptor/user-guide/index.html">User Guide</a> to guide you,</p>
</li>
<li>
<p>a growing number of <a href="https://github.com/LMAX-Exchange/disruptor/wiki/Blogs-And-Articles">blogs and articles</a> giving an overview of how it works,</p>
</li>
<li>
<p>the <a href="https://lmax-exchange.github.io/disruptor/disruptor.html">technical paper</a> goes into some detail as you’d expect,</p>
</li>
<li>
<p>and the performance tests give examples of how to use the Disruptor.</p>
</li>
</ul>
</div>
<p>If you prefer real, live people explaining things instead of a dry paper or content-heavy website, there’s always the <a href="https://www.infoq.com/presentations/LMAX/">presentation Mike and Martin gave</a> at QCon San Francisco.
If you fancy a natter with the folks involved head over to our <a href="https://groups.google.com/g/lmax-disruptor">Discussion Group</a>.
Martin Thompson will also witter on occasionally about performance in his <a href="https://mechanical-sympathy.blogspot.com/">Mechanical Sympathy blog</a>.
Martin Fowler has also done a great <a href="https://martinfowler.com/articles/lmax.html">review</a> of the Disruptor’s application at LMAX.</p>
</div>
</div>
<div>
<h2 id="_whats_the_big_deal">What’s the big deal?</h2>
<div>
<p>It’s fast.
Very fast.</p>
<div>
<p><img src="https://lmax-exchange.github.io/disruptor/resources/images/latency-histogram.png" alt="latency histogram">
</p>
<p>Figure 1. Latency histogram comparing Disruptor to ArrayBlockingQueue</p>
</div>
<p>Note that this is a log-log scale, not linear.
If we tried to plot the comparisons on a linear scale, we’d run out of space very quickly.
We have performance results of the test that produced these results, plus others of throughput testing.</p>
</div>
</div>

<div>
<h2 id="_discussion_blogs_other_useful_links">Discussion, Blogs &amp; Other Useful Links</h2>

</div>
<div>
<h2 id="_presentations">Presentations</h2>

</div>
<div>
<h2 id="_changelog">Changelog</h2>

</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kara Swisher: there will be more departures of top folks at OpenAI tonight (193 pts)]]></title>
            <link>https://twitter.com/karaswisher/status/1725678074333635028</link>
            <guid>38313359</guid>
            <pubDate>Sat, 18 Nov 2023 00:59:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karaswisher/status/1725678074333635028">https://twitter.com/karaswisher/status/1725678074333635028</a>, See on <a href="https://news.ycombinator.com/item?id=38313359">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yuzu Progress Report October 2023 (129 pts)]]></title>
            <link>https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/</link>
            <guid>38312974</guid>
            <pubDate>Sat, 18 Nov 2023 00:28:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/">https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/</a>, See on <a href="https://news.ycombinator.com/item?id=38312974">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    
    <p>Hello yuz-ers! This past month, we got a plethora of GPU fixes, support for new applets, a lot of work poured into the Android builds, some interesting news of the future, and more. Let’s get to it!</p>
<h2 id="wowie-zowie">Wowie Zowie!</h2>
<p>A new Mario game! And it’s an excellent one at that.
<code>Super Mario Bros. Wonder</code> joins the fray of side-scrolling Mario games and refines the genre’s gameplay with its new and <em>wonderful</em> levels.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder1.png" title=" Such a pretty game (Super Mario Bros. Wonder)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder1_hu980adc554ff5c9e1c33b52c71d63f429_1591694_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Such a pretty game (Super Mario Bros. Wonder)"></a></p><p> Such a pretty game (Super Mario Bros. Wonder)</p>
        
    </div>

<p>The game didn’t boot at release due to incorrect used memory reporting in the kernel.
Thankfully, <a href="https://github.com/liamwhite">byte[]</a> quickly found the culprit. It was a <a href="https://github.com/yuzu-emu/yuzu/pull/11825" data-gh-pr="11825">single-line change!</a>
</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder2.png" title=" Hope your platforming skills are up to par (Super Mario Bros. Wonder)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder2_hub50d25e9577d2e2a29b17031e3cf1beb_950859_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Hope your platforming skills are up to par (Super Mario Bros. Wonder)"></a></p><p> Hope your platforming skills are up to par (Super Mario Bros. Wonder)</p>
        
    </div>

<p>However, this wasn’t enough to get the game in a playable state.
Depending on where you are in the game, <code>Super Mario Bros. Wonder</code> internally switches between double and triple buffered VSync presentation modes.
This causes the number of images it has available for presentation to frequently change.</p>
<p>yuzu wasn’t ready for this due to a misunderstanding of how nvnflinger works.
On Android, SurfaceFlinger (the OG Flinger) can free buffers that are beyond the maximum count a program has allocated, but nvnflinger (the Switch’s fork) is never supposed to free any buffers unless the program requests it.
Maide made a <a href="https://github.com/yuzu-emu/yuzu/pull/11827" data-gh-pr="11827">few presentation code changes</a>
 to support this behaviour, and players are now set to grab those fun Wonder Flowers!</p>


<div>
    
    
    
    
    
    
    
    <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder3.png" title="">
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder3_hu2eba16d64da29fc5f0d14810c5a59a24_1557306_800x0_resize_q90_bgffffff_box_3.jpg" alt="Classic Mario (Super Mario Bros. Wonder)"></a>
        
    </p>
    
    
    
    
    
    
    
    <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder4.png" title="">
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wonder4_hu0ac37ce5d244ba1e9fd592f23aa8247b_787222_800x0_resize_q90_bgffffff_box_3.jpg" alt="Classic Mario (Super Mario Bros. Wonder)"></a>
        
    </p>
    
</div>


<p>Classic Mario (Super Mario Bros. Wonder)</p>


<p>I bet you didn’t expect to see the sole input change of the month here ― yet here we are.
<code>Super Mario Bros. Wonder</code> <em>loves</em> vibration, to a point of saturating the old implementation when using HD Rumble on Nintendo controllers (Joy-Cons, Pro Controllers).
This is because waiting for the controller to reply takes time, more than the game would have the patience for, leading to noticeable and bothersome vibration stuttering. That’s right, ASTC, you’re not the only one in town causing stutters.
By <a href="https://github.com/yuzu-emu/yuzu/pull/11852" data-gh-pr="11852">making vibration calls asynchronous,</a>
 vibration is, while not entirely solved, now <em>much</em> more pleasant.</p>
<h2 id="the-gpu-changes">The GPU changes</h2>
<p>Undefined behaviour: the formal way to say “here be dragons”.
It’s a good practice to avoid dragons ― I mean, undefined behaviour ― in your code, especially when dealing with a complex graphics API like Vulkan.</p>
<p>Remember our explanation of <code>depth stencils</code> <a href="https://yuzu-emu.org/entry/yuzu-progress-report-aug-2023/#more-gpu-changes">back in August</a>? You may wish to reread that, as it provides useful context to what we will talk about next.</p>
<p>When a game is using a depth buffer, it is usually drawing into a busy 3D scene while taking advantage of a hardware-accelerated process called depth testing.</p>
<p>During depth testing, the GPU hardware determines if a pixel is visible or hidden (occluded) by another pixel. This is decided by their depth values.
The depth buffer tracks how far away each stored pixel is from the camera.
If a rendered pixel is further away than what has already been drawn on the scene, then the pixel is discarded; if it is closer, then it is kept and the colour buffers are updated.
Typically, the depth buffer is also updated and written to, in this case, to store the depth of the new, closer object.</p>
<p>It is possible for a game to use depth testing alone, and turn the actual writes to the depth buffer off for specific elements, and many games do this when rendering partially transparent objects.
However, the opposite is not allowed by graphics APIs like Vulkan ― hardware designs require depth testing to be enabled in order update the depth buffer.
yuzu’s masked clear path for depth/stencil buffers has a shader which updates the depth buffer, and so enables depth writes, but forgot to also enable depth tests.
Most of the time, this worked by coincidence, as the game was enabling depth tests and yuzu was not clearing this state.
However, not all games enabled them, and without depth tests, games like <code>Super Mario 64</code>, part of <code>Super Mario 3D All-Stars</code>, can’t properly render the face of a certain character (I <em>think</em> his name is in the title of the game.)</p>


<div>
    <p><img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/depthbug_hu0c0a859a0230a314797b2ceb67fcf7b7_967018_1024x0_resize_q90_bgffffff_box_3.jpg" alt="Wonder who he is (Super Mario 64)">
    
    
    
    
    
    
        
        
        <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/depthfix_hu76ef8519ffe23cc9baed7ea24ee5ba18_723120_1024x0_resize_q90_bgffffff_box_3.jpg" alt="Wonder who he is (Super Mario 64)">
    </p>
</div>


<p>Wonder who he is (Super Mario 64)</p>


<p>Thanks to <a href="https://github.com/yuzu-emu/yuzu/pull/11630" data-gh-pr="11630">the work done</a>
 by <a href="https://github.com/Kelebek1">Maide</a>, Mr. Mario Mario renders correctly now.</p>
<p>Not stopping there, Maide’s dragon-hunting continued for another pull request.
One advantage of using the standard Vulkan Memory Allocator (VMA for short) is how it can help sanitise code.</p>
<p>VMA will raise asserts if things are wrong somewhere.
In this case, we were accidentally marking a device-local buffer we intend to use exclusively in VRAM as CPU mapped.
VMA is very clear here: device local buffers should not be allocated as mapped because they are outright <em>not</em> intended for CPU access.
Making it happy <a href="https://github.com/yuzu-emu/yuzu/pull/11734" data-gh-pr="11734">has soothed another dragon.</a>
</p>
<p>Thanks to users’ reports, <a href="https://github.com/FernandoS27">Blinkhawk</a> managed to figure out why the new query cache was leaking memory in many games, including <code>The Legend of Zelda: Tears of the Kingdom</code>.
After <a href="https://github.com/yuzu-emu/yuzu/pull/11646" data-gh-pr="11646">some slight tweaking,</a>
 RAM consumption is put in its place.</p>
<p>Starting a campaign to combat holes in yuzu’s format support, <a href="https://github.com/Squall-Leonhart">Squall-Leonhart</a> has been working on implementing some of the more obscure format conversions, like  <code>D32_SFLOAT</code>.
For this particular depth format on Vulkan, it can <a href="https://github.com/yuzu-emu/yuzu/pull/11677" data-gh-pr="11677">now be converted</a>
 to <code>ABGR8_UNORM</code> when the game needs this behaviour.
Combined with <a href="https://github.com/yuzu-emu/yuzu/pull/11716" data-gh-pr="11716">adding support for</a>
 the <code>Z32</code>, <code>FLOAT</code>, <code>UINT</code>, <code>UINT</code>, <code>UINT</code>, <code>LINEAR</code> variants in the internal format table, this work solves rendering issues in games like <code>Disney Speedstorm</code> and <code>Titan Glory</code>.</p>


<div>
    <p><img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/disneybug_hu3bb363884c1ac53d0c859b122b054f8e_1080239_1024x0_resize_q90_bgffffff_box_3.jpg" alt="Look, the most powerful mouse in the world (Disney Speedstorm)">
    
    
    
    
    
    
        
        
        <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/disneyfix_hu12311cfd5a6b94d636b041fe33ab2659_1803754_1024x0_resize_q90_bgffffff_box_3.jpg" alt="Look, the most powerful mouse in the world (Disney Speedstorm)">
    </p>
</div>


<p>Look, the most powerful mouse in the world (Disney Speedstorm)</p>


<p>Some games also make aliases of images in the D32 depth format.
Since a similar limitation with format conversion was present here too, <code>ARGB8_SRGB</code> and <code>BGRA8_UNORM</code>/<code>BGRA8_SRGB</code> <a href="https://github.com/yuzu-emu/yuzu/pull/11795" data-gh-pr="11795">can now be converted to</a>
 <code>D32_SFLOAT</code> to provide proper compatibility.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/gothic.png" title=" Aged graphics have this feel of nostalgia (Gothic)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/gothic_hu951a8e7f673e10ce1064cd42733ab1c5_1321520_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Aged graphics have this feel of nostalgia (Gothic)"></a></p><p> Aged graphics have this feel of nostalgia (Gothic)</p>
        
    </div>

<p>Continuing with this streak, Maide <a href="https://github.com/yuzu-emu/yuzu/pull/11688" data-gh-pr="11688">implemented</a>
 the <code>X8_D24</code> depth format, allowing <code>A Sound Plan</code> to start rendering.
However, more work is needed to make this game properly playable.</p>
<p>Robustness is a feature Vulkan provides that lets developers handle invalid memory accesses in a cleanly defined way.
This can help prevent the application from crashing or <del>summoning dragons</del> invoking undefined behaviour when some part of the code tries to access memory out of bounds.</p>
<p>For some reason, either Maxwell and Pascal NVIDIA GPUs have broken robustness support on uniform buffers, or yuzu’s codebase makes a wrong assumption somewhere (most likely the latter). As a result, those two NVIDIA GPU generations (GTX 750/GTX 900/GTX 1000 series) suffer from oversized graphics on <code>Crash Team Racing Nitro-Fueled</code>, due to the game accessing memory out of bounds in the shader.
<a href="https://github.com/yuzu-emu/yuzu/pull/11789" data-gh-pr="11789">Manually clamping out-of-bounds buffer reads to 0</a>
 on the affected GPU architectures solves the issues. We are also now investigating what causes this problem in the first place.
Maide gets to play detective yet again, dear Watson.</p>


<div>
    <p><img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/ctrbug_hu50eb2b509adb494070afc449c1d9e315_1177891_1024x0_resize_q90_bgffffff_box_3.jpg" alt="This GTX 1050 needed a diet (Crash Team Racing Nitro-Fueled)">
    
    
    
    
    
    
        
        
        <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/ctrfix_hu909be9e5c1cd1e6b34bc4798d6d9e9b4_945308_1024x0_resize_q90_bgffffff_box_3.jpg" alt="This GTX 1050 needed a diet (Crash Team Racing Nitro-Fueled)">
    </p>
</div>


<p>This GTX 1050 needed a diet (Crash Team Racing Nitro-Fueled)</p>


<p>Maide also fixed a hidden issue with the resolution scaler.
Images were being <a href="https://github.com/yuzu-emu/yuzu/pull/11744" data-gh-pr="11744">marked as rescaled,</a>
 even if the resolution scaler was not in use (running at 1x).
This led to a slight additional overhead, and rarely, some assertion failures.
While no game bug was known to be caused by this, it’s good to have preemptive fixes for once instead of just reactionary ones.</p>
<p>In the meantime, Maide has also been removing image alias bits for all image attachments in an effort to allow the drivers to use more memory optimizations.
This pull request also includes <a href="https://github.com/yuzu-emu/yuzu/pull/11747" data-gh-pr="11747">some other minor fixes</a>
 with it.</p>
<p>By <a href="https://github.com/yuzu-emu/yuzu/pull/11775" data-gh-pr="11775">implementing</a>
 the first and subsequent draw commands for vertex arrays, <code>Super Meat Boy</code> finally renders correctly! No more black screens!</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/smb.png" title=" Well done (Super Meat Boy)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/smb_hu91e9935c0e86ad43b13518d548ad461d_1142993_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Well done (Super Meat Boy)"></a></p><p> Well done (Super Meat Boy)</p>
        
    </div>

<p>And now, one for the Linux gang.
<a href="https://github.com/v1993">v1993</a> tested and <a href="https://github.com/yuzu-emu/yuzu/pull/11786" data-gh-pr="11786">re-enabled CUDA video decoding</a>
 on Linux, allowing better video decoding performance for NVIDIA users (running the proprietary driver, of course).
We previously disabled CUDA by default because it can fail on systems running both a dedicated NVIDIA GPU and a dedicated AMD GPU (iGPUs are fine), a decently rare configuration that only a few people, like your writer, actually ever use.</p>
<p>For those few users running mixed hardware vendors on your systems, please manually  select “CPU Video Decoding” if you’re affected by video decoding issues now.
This was the previous default behaviour.</p>
<p>We received user reports of crashes occurring when grabbing a Grand Star in <code>Super Mario Galaxy</code>, as part of <code>Super Mario 3D All-Stars</code>.
byte[] found that the problem is in how the Vulkan scheduler incorrectly flushes data.
The solution? <a href="https://www.youtube.com/watch?v=SNgNBsCI4EA">Use a lock</a>.
And if that doesn’t work, <a href="https://github.com/yuzu-emu/yuzu/pull/11806" data-gh-pr="11806">use more locks.</a>

Happy star hunting!</p>
<p>To improve OpenGL support even further, <a href="https://github.com/ameerj">Epicboy</a> returns.
First, he found that the <code>shfl_in_bounds</code> variable, which is used to track data used in compute shaders, could result in undefined behaviour when threads were inactive and return invalid results.
<a href="https://github.com/yuzu-emu/yuzu/pull/11847" data-gh-pr="11847">The solution</a>
 was to move the <code>shfl_in_bounds</code> check after the <code>readInvocationARB</code> function, which requires all threads to be active, to avoid <del>dragons</del> undefined behaviour.
This fixed some graphical corruption issues in unit tests, which should lead to fixes in real games too.</p>
<p>Next, a simple gift from epicboy: <a href="https://github.com/yuzu-emu/yuzu/pull/11904" data-gh-pr="11904">force enabling</a>
 <code>Threaded optimization</code>, an NVIDIA-specific OpenGL optimization that enables the use of a new separate CPU thread for graphics rendering.
This is a solid performance boost for those running OpenGL with NVIDIA hardware.
And for those asking, yes, Vulkan allows the use of a separate thread for rendering too ― but we do it on an API level, instead of a driver setting, so all GPUs can benefit.</p>
<p>Maide found a problem occurring with compute shaders when they were triggering invalidations in the buffer cache.
yuzu has a lot of code to track the sizes of buffers used by the games.
Consider a game using two buffers: the first, with an address range from 1 to 2, and another with a range of 3 to 5. They don’t overlap, so there is no issue.
Then, after the game runs for a while, a buffer requiring a range of 1 to 5 is used.
The previous two buffers would be considered to overlap it and will be deleted.
Then, the old buffer data from the two overlaps gets moved to the new third buffer.
While this was already working for graphics-related buffers, it didn’t correctly consider compute buffers.</p>
<p><a href="https://github.com/yuzu-emu/yuzu/pull/11859" data-gh-pr="11859">Adding the missing loop</a>
 to fix this behaviour, problems ranging from minimal graphical issues to completely broken game logic are potentially solved.
You know what they say: with compute, the sky’s the limit. Just ask AI developers.</p>
<p>Another optimization Maide implemented affects how buffers are handled after they are successfully deleted.
The previous method would unnecessarily create several copies, wasting resources.
By <a href="https://github.com/yuzu-emu/yuzu/pull/11683" data-gh-pr="11683">removing one synchronisation step,</a>
 only the exact amount of needed copies are used.</p>
<p>Now let’s discuss a long-standing issue: some 2D games were flipped on AMD, Intel, and Android GPUs.
Games can use different APIs to run on the Switch.
Nintendo allows the use of Vulkan, OpenGL, and their proprietary API, NVN.
This poses a problem for emulation on Vulkan, since <a href="https://vulkan.gpuinfo.org/listdevicescoverage.php?extension=VK_NV_viewport_swizzle&amp;platform=all">only NVIDIA GPUs</a> support the viewport swizzle extension (which allows for transforming viewports).</p>
<p>To allow other GPU vendors to render properly in most cases, a fallback implementation was made to handle the case of vertical flips, for use by OpenGL games.
A tiny error in its implementation made it unable to correctly track invalidations of the viewport flip state, resulting in garbled graphics in several games.
byte[] <a href="https://github.com/yuzu-emu/yuzu/pull/11893" data-gh-pr="11893">solved</a>
 that issue with a one-line change, making games like <code>Stardew Valley</code>, and <code>Streets of Rage 4</code>, finally render properly on non-NVIDIA hardware.
No more mirrors needed!</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/sv.png" title=" THE cozy farming game (Stardew Valley)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/sv_hu7523f5a5e46db621596c28ada1a8ba6f_783219_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" THE cozy farming game (Stardew Valley)"></a></p><p> THE cozy farming game (Stardew Valley)</p>
        
    </div>

<p>While investigating this, a similar but different issue came to light.
Many OpenGL games (that is, games using OpenGL to render, not yuzu rendering on OpenGL) ask for a 1920x1080 framebuffer, regardless of whether the game is running in handheld or docked mode.
The game then simply moves and resizes the region it’s rendering to inside that 1920x1080 buffer, like moving a small box inside a bigger box, if you will.
In the final step, the image is flipped and sent to the bottom of that 1080p render target.
yuzu was incorrectly rendering only the top of the render target due to how it used to calculate that flip in the final pass.</p>
<p><a href="https://github.com/yuzu-emu/yuzu/pull/11894" data-gh-pr="11894">Adjusting</a>
 this behaviour made <code>Tiny Thor</code> render correctly in handheld mode.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/tt.png" title=" To Valhalla (Tiny Thor)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/tt_hu2b53a1cd6dd4ef8b15e95d5923319967_750150_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" To Valhalla (Tiny Thor)"></a></p><p> To Valhalla (Tiny Thor)</p>
        
    </div>

<p>And to close the graphics section, by following this chain of events, the previous pull request helped spot a bug in our Vulkan presentation that led to <code>Arcaea</code> being incorrectly cropped in handheld mode.
95 lines of <a href="https://github.com/yuzu-emu/yuzu/pull/11896" data-gh-pr="11896">cropping-behaviour code changes</a>
 later, and byte[] solved the issue.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/arcaea.png" title=" Good art style (Arcaea)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/arcaea_hu7b691fcef71ea8b7d5c5641425008037_1145047_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Good art style (Arcaea)"></a></p><p> Good art style (Arcaea)</p>
        
    </div>

<h2 id="android-changes">Android changes</h2>
<p>This month the Android build got not only significant UI changes to improve quality of life, but device compatibility was greatly improved for Adreno users.
Here’s the full list!</p>
<ul>
<li>A new <a href="https://github.com/yuzu-emu/yuzu/pull/11649" data-gh-pr="11649">GPU driver manager</a>
 was developed by <a href="https://github.com/t895">t895</a>, allowing the listing of multiple drivers, useful for quickly switching between proprietary Qualcomm or Mesa Turnip releases, or several versions of each. Due to the beta status of Turnip drivers and the immature code of Qualcomm drivers, the latest release is not always the best.</li>
</ul>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/gpu.png" title=" For all your driver-switching needs!">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/gpu_hua4dd432e794ccf666de8c0d679c30ff6_40908_356x0_resize_q90_bgffffff_box_3.jpg" alt=" For all your driver-switching needs!"></a></p><p> For all your driver-switching needs!</p>
        
    </div>

<ul>
<li>byte[] solved a <a href="https://github.com/yuzu-emu/yuzu/pull/11656" data-gh-pr="11656">crash related to surface recreation,</a>
 which could be triggered by simply rotating the device.</li>
<li>byte[] solved an issue affecting some Android devices that ship an <a href="https://github.com/yuzu-emu/yuzu/pull/11876" data-gh-pr="11876">outdated Vulkan 1.1 loader</a>
 instead of the current latest 1.3, causing the device to report older features than the driver in use actually supports. This resulted in specific Adreno 600 and 700 devices crashing at boot when using any Mesa Turnip driver version. Forcing the correct Vulkan 1.3 features the driver supports solves the issue. We’ll expand on this at the end of the article.</li>
<li>t895 implemented a <a href="https://github.com/yuzu-emu/yuzu/pull/11909" data-gh-pr="11909">home settings menu grid</a>
 for devices with bigger screens and/or higher DPIs. This should please our tablet and foldable users. Enjoy!</li>
</ul>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wide.png" title=" Landscape lovers rejoice">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/wide_hu26880f346c915470ab53881d53d5c956_71512_772x0_resize_q90_bgffffff_box_3.jpg" alt=" Landscape lovers rejoice"></a></p><p> Landscape lovers rejoice</p>
        
    </div>

<ul>
<li>byte[] <a href="https://github.com/yuzu-emu/yuzu/pull/11910" data-gh-pr="11910">fixed another case</a>
 where yuzu would fail to recreate the surface on screen rotations.</li>
<li>t895 moved the <a href="https://github.com/yuzu-emu/yuzu/pull/11915" data-gh-pr="11915">game list loading process to a separate thread</a>
 to reduce stuttering when opening yuzu. The process still takes a similar amount of time, but the perceived smoothness is very welcome.</li>
<li>t895 solved an issue that caused the <a href="https://github.com/yuzu-emu/yuzu/pull/11916" data-gh-pr="11916">touch buttons overlay to get stuck</a>
 while drawing the in-game menu from the left side.</li>
<li>While waiting for a controller settings menu, t895 fixed a bug that caused <a href="https://github.com/yuzu-emu/yuzu/pull/11925" data-gh-pr="11925">all controller input to move to player 2</a>
 on some devices, blocking users from playing most games. Devices with integrated controllers should have a much better experience now.</li>
<li>And finally, following the <a href="https://yuzu-emu.org/entry/yuzu-progress-report-sep-2023/#of-miis-and-applets">recent changes</a> in the desktop version, t895 added a <a href="https://github.com/yuzu-emu/yuzu/pull/11931" data-gh-pr="11931">menu to access the currently supported applets,</a>
 Album and Mii editor, along with the Cabinet applet to manage amiibo data. Wii think you will have fun!</li>
</ul>


<div>
    
    
    
    
    
    
    
    <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/cabinet1.png" title="">
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/cabinet1_hu6c205d51bb64aafdf9db14b82f9c8d77_34508_800x0_resize_q90_bgffffff_box_3.jpg" alt="We hope to expand this selection in the future"></a>
        
    </p>
    
    
    
    
    
    
    
    <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/cabinet2.png" title="">
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/cabinet2_huf7351c4bd5851a32809f1a30df097184_37863_800x0_resize_q90_bgffffff_box_3.jpg" alt="We hope to expand this selection in the future"></a>
        
    </p>
    
</div>


<p>We hope to expand this selection in the future</p>




<div>
    
    
    
    
    
    
    
    <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/mii.png" title="">
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/mii_hu7941743f3578c06234d07f441155d2a4_301240_800x0_resize_q90_bgffffff_box_3.jpg" alt="Wii want to play"></a>
        
    </p>
    
    
    
    
    
    
    
    <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/album.png" title="">
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/album_hu274f6a753c1bfcc81149a9d3f2d0ef7a_332512_800x0_resize_q90_bgffffff_box_3.jpg" alt="Wii want to play"></a>
        
    </p>
    
</div>


<p>Wii want to play</p>


<p>The settings menu was also reorganised:</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/settings.png" title=" Hope it’s more convenient now">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/settings_hu330d36628c0bf45df70c0c778fc8a487_73745_356x0_resize_q90_bgffffff_box_3.jpg" alt=" Hope it’s more convenient now"></a></p><p> Hope it’s more convenient now</p>
        
    </div>

<h2 id="ui-and-applet-changes">UI and Applet changes</h2>
<p>After a rocky start, thanks to the early work of <a href="https://github.com/roenyroeny">roenyroeny</a>, <a href="https://github.com/boludoz">boludoz</a>, and <a href="https://github.com/FearlessTobi">FearlessTobi</a>, we now have proper <a href="https://github.com/yuzu-emu/yuzu/pull/11705" data-gh-pr="11705">shortcut creation</a>
 support for Windows too!</p>
<p>To access this feature, simply right click a game in yuzu’s game list, select Create Shortcut, and pick if you want it on your desktop or the applications section of the start menu. This allows you to start games with a quick start menu search or even from a pin in the menu/taskbar if you so choose.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/shortcut.png" title=" Populate that taskbar">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/shortcut_hu600f5dbf370befc70c2c96ed9a17a6e5_45448_611x0_resize_q90_bgffffff_box_3.jpg" alt=" Populate that taskbar"></a></p><p> Populate that taskbar</p>
        
    </div>

<p>Helping improve this, <a href="https://github.com/german77">german77</a> made the required changes to <a href="https://github.com/yuzu-emu/yuzu/pull/11740" data-gh-pr="11740">save multiple resolutions per icon,</a>
 making smaller sized desktop icons much more readable than before.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/icons.png" title=" Scaling images down doesn’t always look the best">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/icons_hudf885ea0623cf4f8a6fb80ec9378e900_151664_287x0_resize_q90_bgffffff_box_3.jpg" alt=" Scaling images down doesn’t always look the best"></a></p><p> Scaling images down doesn’t always look the best</p>
        
    </div>

<p><a href="https://github.com/DanielSvoboda">DanielSvoboda</a> made several changes in file system handling to <a href="https://github.com/yuzu-emu/yuzu/pull/11749" data-gh-pr="11749">improve directory path detection</a>
 for the shortcuts, making them far more usable and stable.
Thank you!</p>
<p>Work on improving user experience (UX) is always welcome, it is your writer’s belief that UX is as important as proper functionality, and should never be ignored.
To improve the quality of life of people playing with multiple controllers, <a href="https://github.com/flodavid">flodavid</a> changed the behaviour of how users interact with the <a href="https://github.com/yuzu-emu/yuzu/pull/11779" data-gh-pr="11779">number of connected controllers</a>
 in the Controls settings.
Users can now more intuitively click the green lights at the bottom to select how many players/controllers they would like to be active.
Thank you!</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/controls.png" title=" Epic Smash sleepover!">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/controls_hue9f91c81c3bebfddc97ed829142816bb_1063_236x0_resize_q90_bgffffff_box_3.jpg" alt=" Epic Smash sleepover!"></a></p><p> Epic Smash sleepover!</p>
        
    </div>

<p>Another welcome UX addition is by <a href="https://github.com/Macj0rdan">Macj0rdan</a>, who implemented <a href="https://github.com/yuzu-emu/yuzu/pull/11903" data-gh-pr="11903">a quick control for game volume</a>
 with the mouse wheel when the pointer is placed over the volume button in the UI, removing the need to click it and drag a small slider.
Thank you!</p>
<p>Continuing his work on applet support, german77 implemented the <code>SaveScreenShotEx0</code> <a href="https://github.com/yuzu-emu/yuzu/pull/11812" data-gh-pr="11812">service method and its variants,</a>
 allowing users to take captures from within games themselves instead of globally with the screenshot hotkey.
This works for games like <code>Super Smash Bros. Ultimate</code> ― however, note that screenshot editing is not available yet.
Homework for later!</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/smash.png" title=" Save your best moments (Super Smash Bros. Ultimate)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/smash_hu8f12f9c99347fa5c2150b7216b1c4eb3_1334357_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Save your best moments (Super Smash Bros. Ultimate)"></a></p><p> Save your best moments (Super Smash Bros. Ultimate)</p>
        
    </div>

<p>german77 also <a href="https://github.com/yuzu-emu/yuzu/pull/11892" data-gh-pr="11892">implemented the</a>
 <code>SaveCurrentScreenshot</code> method, allowing users to take in-game screenshots in <code>Pokémon Scarlet/Violet</code> with its latest update installed.
Happy selfie shooting!</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/poke.png" title=" Feeling cute, might capture a shiny later (Pokémon Scarlet)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/poke_hu114389c1174a7f1d7ac91db21ec9d2b9_337813_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Feeling cute, might capture a shiny later (Pokémon Scarlet)"></a></p><p> Feeling cute, might capture a shiny later (Pokémon Scarlet)</p>
        
    </div>

<p>One of the changes german77 introduced broke the <code>Find Mii</code> stage in <code>Super Smash Bros. Ultimate</code>.
Since it’s not a popular stage, even among the Smash community, we didn’t notice this issue, and no one reported in our <a href="https://discord.gg/u77vRWY">Discord server</a>, <a href="https://community.citra-emu.org/c/yuzu-support/14">forums</a>, or <a href="https://github.com/yuzu-emu/yuzu/issues/new/choose">GitHub bug report page</a> ― we only found out thanks to complaints on Reddit. This is a reminder to you, the users, please try to report issues in the proper channels! Doing so ensures we see the problems you are having and can work to fix them.</p>
<p>yuzu is a large project with many “black box” areas. There will be bugs, many thousands of bugs, that our team may never encounter. Your voice is so important, we hate to see any bug reports slip through the cracks outside of our channels.</p>
<p>With that out of the way, by <a href="https://github.com/yuzu-emu/yuzu/pull/11822" data-gh-pr="11822">creating random Miis</a>
 with names, german77 solved the issue.</p>
<p>german77 also <a href="https://github.com/yuzu-emu/yuzu/pull/11846" data-gh-pr="11846">expanded the character limit of cheats</a>
 to more than 64 characters.
Now you can cheat to your heart’s content.</p>
<p>You know our developers spend a lot of time opening and closing yuzu when byte[] can accurately measure that 10% of shutdown crashes are caused by the game list.
He found that the issue was in how Qt deals with messages from objects that were destroyed or disconnected (like stopping the emulator while the game list is loading).
By <a href="https://github.com/yuzu-emu/yuzu/pull/11846" data-gh-pr="11846">changing the behaviour</a>
 of how the game list is reported to those events, another source of shutdown crashes has been defeated.</p>
<h2 id="kernel-cpu-and-file-system-changes">Kernel, CPU, and file system changes</h2>
<p>byte[] has been having a lot of “fun” lately fixing and implementing kernel changes.
First off, he <a href="https://github.com/yuzu-emu/yuzu/pull/11686" data-gh-pr="11686">fully implemented transfer memory,</a>
 fixed <a href="https://github.com/yuzu-emu/yuzu/pull/11766" data-gh-pr="11766">incorrect page group tracking,</a>
 <a href="https://github.com/yuzu-emu/yuzu/pull/11914" data-gh-pr="11914">updated the implementation</a>
 of KPageTableBase, and has now <a href="https://github.com/yuzu-emu/yuzu/pull/11843" data-gh-pr="11843">nearly completed</a>
 the entire KProcess implementation!</p>
<p>As preliminary work for NCE support coming in the near future, byte[] implemented <a href="https://github.com/yuzu-emu/yuzu/pull/11718" data-gh-pr="11718">native clock support</a>
 for arm64 devices running on Linux or Android.
There is no support for ARM Windows devices for now, as none have bothered to include a Vulkan driver yet.</p>
<p>The kernel was updated to reflect changes made in <a href="https://github.com/yuzu-emu/yuzu/pull/11748" data-gh-pr="11748">firmware version 17.0.0,</a>
 ensuring support for future games.</p>
<p>v1993 <a href="https://github.com/yuzu-emu/yuzu/pull/11772" data-gh-pr="11772">solved some warnings</a>
 that were spamming our build logs ― namely, using <code>std::forward</code> where appropriate, and qualifying <code>std::move</code> calls.
This should solve build issues for those experimenting with Darwin build targets.</p>
<p>By user request, byte[] <a href="https://github.com/yuzu-emu/yuzu/pull/11774" data-gh-pr="11774">further improved the build performance of RomFS mods</a>
 by getting rid of some unnecessary object copies.
This also fixed a file handle leak, which now allows modders to edit mod files after stopping emulation, helping them work faster on those <em>juicy and delicious</em> game mods.</p>
<h2 id="audio-changes">Audio changes</h2>
<p>Thanks to user reports, our audio connoisseur, Maide, found that <code>Ancient Rush 2</code> would crash at the end of the first developers screen.
<a href="https://github.com/yuzu-emu/yuzu/pull/11735" data-gh-pr="11735">Clearing the DSP buffer</a>
 after each execution fixes the issue.</p>

<div>
        
            <p><a href="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/ar2.png" title=" Diggy Diggy Hole! (Ancient Rush 2)">
                
                
                <img src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/ar2_hu326136e5c95b9e8f32f19b6b750a98aa_2734943_1024x0_resize_q90_bgffffff_box_3.jpg" alt=" Diggy Diggy Hole! (Ancient Rush 2)"></a></p><p> Diggy Diggy Hole! (Ancient Rush 2)</p>
        
    </div>

<p>Speaking of audio, byte[] delivered another resounding victory in the shutdown department by <a href="https://github.com/yuzu-emu/yuzu/pull/11778" data-gh-pr="11778">fixing a deadlock</a>
 in the audio renderer.</p>
<h2 id="hardware-section">Hardware section</h2>
<p>We have some sad news for the old Red Team guard, a warning for the Green Team, and very good news for Adreno droids.</p>
<h3 id="nvidia-our-fault-this-time">NVIDIA, our fault this time</h3>
<p>The 545 and 546 series of drivers have solved the high VRAM usage crashes we reported this last month, but users are reporting new crashes in games with these drivers.
Reverting to the 53X series of drivers solves the problem, but this time, it’s not NVIDIA’s fault!
Mesa also has many new crashes with the 24.0.0 release, and having the top two drivers crashing under the same conditions is not a coincidence.</p>
<p>We found that the problem is in how we are recompiling shaders ― the types of some variables are mismatched.
The fix will take some time to implement, so for NVIDIA and Mesa users experiencing crashes in games like <code>Bayonetta 3</code>, we suggest not updating your drivers for the time being.</p>
<h3 id="amd-giving-a-last-hurrah-to-polaris-and-vega">AMD, giving a last hurrah to Polaris and Vega</h3>
<p>The time has come. The last 2 remnants of the GCN architecture are on their way to be discontinued.
AMD started releasing <a href="https://www.anandtech.com/show/21126/amd-reduces-ongoing-driver-support-for-polaris-and-vega-gpus">split drivers</a> for those products, which run outdated Vulkan driver branches compared to RDNA and newer hardware.
<a href="https://www.phoronix.com/news/Mesa-24.0-Faster-RADV-Vega">The news</a> of AMDVLK, the official Linux AMD driver, killing support for these products means no new Vulkan drivers will be available.</p>
<p>This doesn’t mean the show is over for their owners.
For the time being, no new change breaks compatibility with the cards, and Linux Mesa drivers like RADV will continue to provide support, most likely extending it past what the Windows drivers report as supported (as is usually the case with Mesa).</p>
<p>But for those stuck on Windows, this is the last ride.</p>
<p>GCN4.0, GCN5.0, you weren’t the most efficient cards, but you gave us good value in the worst moments, <em>years</em> of amazing gameplay, and great FineWine moments.
We salute you and thank you for your impeccable service, few GPU architectures leave the stage with such a round of applause.</p>
<p>o7</p>
<h3 id="turnip-a-very-quickly-improving-work-in-progress">Turnip, a very quickly improving work-in-progress</h3>
<p>yuzu uses a single codebase for all its releases, upstream/master/main, however you prefer to call it, Mainline, Early Access, and Android all start from there.
When improvements to the codebase are added, they eventually reach all releases, Android included.</p>
<p>We recently added improved support for <code>occlusion queries</code> (part of project Y.F.C.) to Android to increase performance and accuracy on all devices. But occlusion query support on Turnip drivers with Adreno 725 and 730 GPUs was not working correctly, and this took us a very long time to find.
Users experienced crashes that forced them to remain on outdated <a href="https://github.com/yuzu-emu/yuzu-android/releases/">GitHub</a> versions, and we needed to stall a new Play Store release until the problem was investigated and properly solved.</p>
<p>The issue was found, reported, and resolved by Mesa in record time in their current Adreno 700 branches, which then driver packagers like <a href="https://github.com/K11MCH1/AdrenoToolsDrivers/releases">K11MCH1</a> use to build packages Qualcomm users can load on emulators.</p>
<p>For this reason we <em>strongly</em> recommend Adreno 730 and Adreno 725 users to update to the latest <a href="https://github.com/K11MCH1/AdrenoToolsDrivers/releases/tag/24.0.0-R-X">Release X</a> driver, which not only fixes the crashes caused by occlusion queries, but also the lack of support for the Adreno 725 and some variants (yes, there are several) of the Adreno 730.
It isn’t only desktop GPU vendors who love to rename things.</p>
<p>By using this driver, we were able to launch newer Android builds with the latest upstream changes, and all Qualcomm users can safely use the latest GitHub builds if they prefer.</p>
<p>By the way, the GitHub builds are now properly signed. Rejoice, as you can now update from one to the next without needing to uninstall first.
If you want to test experimental and potentially unsafe (but maybe faster) changes before Play Store updates, it’s now much easier.</p>
<h2 id="future-projects">Future projects</h2>
<p>Let’s begin with what most people want to hear about: Project Nice for Android devices.
NCE (Native Code Execution) is progressing very well, but there are still some bugs to iron out.
Games are becoming not only playable, but also <em>faster</em> on devices with thermal restrictions. Additionally, the time spent loading and closing games has been significantly reduced now!
NCE has helped us understand issues in our CPU emulation in x86_64 too, so expect gains on both fronts.</p>

<div>
        
            <video preload="auto" autoplay="autoplay" muted="muted" loop="loop" webkit-playsinline="">
                <source src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/smo.mp4" type="video/mp4">
                Your browser doesn't support mp4 video. :(
            </video>
        
        
            <p> Recorded with a Red Magic 7S Pro (SUPER MARIO ODYSSEY)</p>
        
    </div>

<p>No promises on a release date per usual, but as politicians love to say: “We’re working on it.”</p>

<div>
        
            <video preload="auto" autoplay="autoplay" muted="muted" loop="loop" webkit-playsinline="">
                <source src="https://yuzu-emu.org/entry/yuzu-progress-report-oct-2023/bayo2.mp4" type="video/mp4">
                Your browser doesn't support mp4 video. :(
            </video>
        
        
            <p> Destroying those touch screen controls! (Bayonetta 2)</p>
        
    </div>

<p>Blinkhawk is <em>suggesting</em> that your writer informs you he is working on a new project seeking to make the GPU process-agnostic, allowing multiprocess emulation within the GPU.
No fancy names this time, we’ve simply been calling this “Multiprocess” internally.
Multiprocess is a mandatory step towards UMA support, which will provide huge gains for iGPUs and SoC users, as well as reducing RAM consumption.</p>
<p>That’s all folks! Apologies for the delay, university homework and finals are killing your writer.
Thank you for reading until the end. See you next time!</p>
<h4>
<b>Please consider supporting us on <a href="https://www.patreon.com/yuzuteam">Patreon</a>!<br>
If you would like to contribute to this project, check out our <a href="https://github.com/yuzu-emu/yuzu">GitHub</a>!</b>
</h4>












</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Greg Brockman quits OpenAI (1378 pts)]]></title>
            <link>https://twitter.com/gdb/status/1725667410387378559?s=20</link>
            <guid>38312704</guid>
            <pubDate>Sat, 18 Nov 2023 00:10:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/gdb/status/1725667410387378559?s=20">https://twitter.com/gdb/status/1725667410387378559?s=20</a>, See on <a href="https://news.ycombinator.com/item?id=38312704">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Hacked the Magic Mouse (382 pts)]]></title>
            <link>https://uplab.pro/2023/11/i-hacked-the-magic-mouse/</link>
            <guid>38312649</guid>
            <pubDate>Sat, 18 Nov 2023 00:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uplab.pro/2023/11/i-hacked-the-magic-mouse/">https://uplab.pro/2023/11/i-hacked-the-magic-mouse/</a>, See on <a href="https://news.ycombinator.com/item?id=38312649">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1608">
								
				<div>
					
<figure><img fetchpriority="high" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231117_1228195082.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231117_1228195082-scaled.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231117_1228195082-scaled.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231117_1228195082-scaled.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231117_1228195082-scaled.jpg?resize=1536%2C1157&amp;ssl=1 1536w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231117_1228195082-scaled.jpg?resize=2048%2C1542&amp;ssl=1 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>Thank you all so much! The original post got such a great response it would be rude not to tell you more about the project.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I hacked the Magic Mouse.<br>And created the world's first ergonomic Magic Mouse with no weaknesses.<br>Yes, you can charge it via USB-C right while you're working!<br>More details + demo in the thread <a href="https://t.co/lxvCXArZdG">pic.twitter.com/lxvCXArZdG</a></p>— Ivan Kuleshov (@Merocle) <a href="https://twitter.com/Merocle/status/1725213431555400048?ref_src=twsrc%5Etfw">November 16, 2023</a></blockquote>
</div></figure>







<h2>Some media coverage</h2>



<ul>
<li><a href="https://appleinsider.com/articles/23/11/17/you-dont-have-to-flip-this-magic-mouse-hack-over-to-charge" target="_blank" rel="noreferrer noopener">appleinsider.com</a></li>



<li><a href="https://www.tomshardware.com/news/apple-magic-mouse-issues-fixed-by-hardware-hacker" target="_blank" rel="noreferrer noopener">tomshardware.com</a></li>



<li><a href="https://gizmodo.com/engineer-magic-mouse-usb-c-1851031329" target="_blank" rel="noreferrer noopener">gizmodo.com</a></li>



<li><a href="https://www.creativebloq.com/news/magic-mouse" target="_blank" rel="noreferrer noopener">creativebloq.com</a></li>
</ul>



<h2>First of all</h2>



<p>This may be a little intrusive, but I’d appreciate it if you’d join our <a href="https://discord.gg/2MZjPUU59P" target="_blank" rel="noreferrer noopener">Discord server</a>, and subscribe to my <a href="https://www.instagram.com/uptime.lab/" target="_blank" rel="noreferrer noopener">Instagram</a> and/or <a href="https://twitter.com/Merocle" target="_blank" rel="noreferrer noopener">X (Twitter)</a>. It will be the best “thanks” if you liked the article 🙂 Thank you, and <em>May the Force be with you</em>! </p>











<h2 id="0-how-i-came-up-with-the-idea">How I came up with the idea.</h2>







<p><br>Yes, I know that the mouse is quite questionable in terms of convenience, but the main driver of my idea was these two clips.</p>



<p>Some time ago, I saw this video and immediately thought of what I needed to do to solve the author’s problem:</p>







<figure><p>
<iframe title="I fixed Apple's biggest design flaw..sort of." width="1778" height="1000" src="https://www.youtube.com/embed/gzipeeQR2l0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>







<p>A year later, I saw this video and decided my time had come:</p>







<figure><p>
<iframe title="I Tried Building the ULTIMATE Magic Mouse" width="1778" height="1000" src="https://www.youtube.com/embed/y3lNrRydr4g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>







<h2 id="1-the-idea">The idea</h2>



<p>It became obvious to me that I should just charge the battery and do not to connect mouse schematics, well as it turns out it worked. Not without some interesting findings, though.</p>



<p>To make it ergonomic and prevent problems with the sensor (which is not working perfectly as it is) I will have to divide the mouse into 2 halves. I was prepared to have to lengthen the cable from the top part (touch sensor), but luckily, the standard length turned out to be enough.</p>







<h2 id="2-implementation">Implementation</h2>



<p>The found models did not fit at all. I had to do it myself, and the first attempts were quite …. ugly, what can I say?</p>



<figure><img loading="lazy" decoding="async" width="1024" height="850" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image.jpg?resize=1024%2C850&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image.jpg?resize=1024%2C850&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image.jpg?resize=300%2C249&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image.jpg?resize=768%2C637&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image.jpg?w=1465&amp;ssl=1 1465w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>Moreover, all the Magic Mouse 3d models I’ve found aren’t perfect either. So, I adjusted the shape of the enclosure step by step, just by eye. It’s a concept, after all 🙂<br>Create-&gt; print -&gt; Adjust -&gt; print -&gt; Adjust -&gt; print -&gt; etc…</p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231116_1718401852.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231116_1718401852-scaled.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231116_1718401852-scaled.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231116_1718401852-scaled.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231116_1718401852-scaled.jpg?resize=1536%2C1157&amp;ssl=1 1536w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/PXL_20231116_1718401852-scaled.jpg?resize=2048%2C1542&amp;ssl=1 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>A last, but probably not the final option. After all, there is no limit to perfection. But if I were to perfect it, I’m afraid the project would never see the light of day</p>



<figure><img loading="lazy" decoding="async" width="1024" height="859" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-1.jpg?resize=1024%2C859&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-1.jpg?resize=1024%2C859&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-1.jpg?resize=300%2C252&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-1.jpg?resize=768%2C644&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-1.jpg?w=1492&amp;ssl=1 1492w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<figure><img loading="lazy" decoding="async" width="1024" height="812" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-2.jpg?resize=1024%2C812&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-2.jpg?resize=1024%2C812&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-2.jpg?resize=300%2C238&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-2.jpg?resize=768%2C609&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-2.jpg?w=1277&amp;ssl=1 1277w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>In the photo, you can notice a frame-adapter for the upper part of the mouse. It was made in only four iterations</p>



<figure><img loading="lazy" decoding="async" width="1024" height="792" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-3.jpg?resize=1024%2C792&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-3.jpg?resize=1024%2C792&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-3.jpg?resize=300%2C232&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-3.jpg?resize=768%2C594&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-3.jpg?resize=1536%2C1188&amp;ssl=1 1536w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-3.jpg?w=1650&amp;ssl=1 1650w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>drawn “by eye with a caliper”</figcaption></figure>







<p>Its task is essentially to repeat and extend the original mount (which, by the way, is quite difficult to disassemble without breaking anything off).<br>There is also a place for a spring (a long metal part near the button) and an offset lever that presses the button.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-4.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-4.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-4.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-4.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-4.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-5.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-5.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-5.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-5.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-5.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>I was so confident of success that I didn’t even bother to see if the charging idea would work.<br>Better late than never. The labeling on the battery is not standard (3.61V), but according to the tests, it is a normal one cell that can be charged to 4.2V, which is defined as 100% in the OS.</p>



<figure><img loading="lazy" decoding="async" width="771" height="1024" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-6.jpg?resize=771%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-6.jpg?resize=771%2C1024&amp;ssl=1 771w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-6.jpg?resize=226%2C300&amp;ssl=1 226w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-6.jpg?resize=768%2C1020&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-6.jpg?w=964&amp;ssl=1 964w" sizes="(max-width: 771px) 100vw, 771px" data-recalc-dims="1"><figcaption>Easy to open</figcaption></figure>







<figure><img loading="lazy" decoding="async" width="771" height="1024" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-7.jpg?resize=771%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-7.jpg?resize=771%2C1024&amp;ssl=1 771w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-7.jpg?resize=226%2C300&amp;ssl=1 226w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-7.jpg?resize=768%2C1020&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-7.jpg?w=964&amp;ssl=1 964w" sizes="(max-width: 771px) 100vw, 771px" data-recalc-dims="1"><figcaption>4.03V is about 80% in the OS</figcaption></figure>


<div id="ub-content-toggle-f0cd42fc-7bed-4b8d-9fb1-f835bd310c2d" data-mobilecollapse="false" data-desktopcollapse="true">
                <div "="" aria-controls="ub-content-toggle-panel-0-f0cd42fc-7bed-4b8d-9fb1-f835bd310c2d" tabindex="0">
                    <p>My interesting find, for the careful reader</p></div><div role="region" aria-expanded="false" id="ub-content-toggle-panel-0-f0cd42fc-7bed-4b8d-9fb1-f835bd310c2d">

<p>When I charge the battery using my BMC (TP4056) the mouse is not aware that it is in the process of charging.<br>The TP4056 raises the voltage to ~4.258V when the charge is complete. And then shuts down, and the battery stays at ~4.2V.</p>



<p>So here’s the finding:<br>If we monitor the percentage of charge in the OS, we see <strong>100%</strong> at 4.15, and then the wonders begin.<br>At ~4.17V, the percentage drops to <strong>99%</strong>.<br>~4.19V – <strong>98%</strong><br>~4.21V – <strong>97%</strong><br>~4.24V – <strong>96%</strong><br>After charging is finished and I restarted the mouse, the percentage is back to <strong>100%</strong>.<br>Maybe I’ve found why the mouse is magical? 🙂</p>

</div></div>


<p>Next, I soldered a regular TP4056 directly to the battery outputs. Don’t have to make it complicated. With this battery capacity, it will do the job just fine, there is no need for additional current limiters. Just in case, I monitored the temperature while charging, and everything seemed to be working great.</p>


<div id="ub-content-toggle-0417f60a-a2a9-45f3-8c4e-cdd1c0107ee2" data-mobilecollapse="false" data-desktopcollapse="true">
                <div "="" aria-controls="ub-content-toggle-panel-0-0417f60a-a2a9-45f3-8c4e-cdd1c0107ee2" tabindex="0">
                    <p>The boring soldering of a few wires</p></div><div role="region" aria-expanded="false" id="ub-content-toggle-panel-0-0417f60a-a2a9-45f3-8c4e-cdd1c0107ee2">

<p>People say you have to be very careful when working with batteries!<br>Do not overheat, open, or short-circuit them.</p>



<p>Wear goggles and have fire extinguishers handy. Trained professionals perform these stunts.</p>



		<figure>
			
			
		</figure>
		
</div></div>


<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-11.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-11.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-11.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-11.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-11.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>






<div id="ub-content-toggle-8dbf17a1-a41b-4c3f-a228-4586496dfec5" data-mobilecollapse="false" data-desktopcollapse="true">
                <div "="" aria-controls="ub-content-toggle-panel-0-8dbf17a1-a41b-4c3f-a228-4586496dfec5" tabindex="0">
                    <p>Proof of concept. Charging demo</p></div><div role="region" aria-expanded="false" id="ub-content-toggle-panel-0-8dbf17a1-a41b-4c3f-a228-4586496dfec5">

<p>The mouse continues to work while charging.<br>The system doesn’t track that it’s charging, but the battery percentage just goes up.<br>Just as I’d hoped</p>



		<figure>
			
			
		</figure>
		
</div></div>






<h2>Assembling</h2>



<p>As in most advanced devices, I used double-sided tape to glue the battery on.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-9.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-9.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-9.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-9.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-9.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>However, double-sided tape was mostly used for assembly as well. By the way, for the first time, I tried printing on an FDM printer at 60 microns (0.06mm) resolution.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-12.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-12.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-12.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-12.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-12.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>I installed this adapter into the top of the mouse and taped it to the battery so it could be disassembled for fine-tuning. Once the exact position has been selected, it makes sense to glue it firmly in place and snap the top part into place.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-13.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-13.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-13.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-13.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-13.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Trying on</figcaption></figure>






<div id="ub-content-toggle-40d78199-76e5-4a9e-824d-9ccd9596ffcb" data-mobilecollapse="false" data-desktopcollapse="false">
                <div "="" aria-controls="ub-content-toggle-panel-0-40d78199-76e5-4a9e-824d-9ccd9596ffcb" tabindex="0">
                    <p>A short video about the top-part extension adapter</p></div><div role="region" aria-expanded="true" id="ub-content-toggle-panel-0-40d78199-76e5-4a9e-824d-9ccd9596ffcb">

<p>Just trying it on and showing how the click works. I apologize for the noise of the printers in the background.</p>



		<figure>
			
			
		</figure>
		
</div></div>


<p>And then there’s the final view. I added high-tech hot glue (sarcasm) to secure the wires and USB-C port. If it works, why think of anything else?</p>



		<figure>
			
			
		</figure>
		






<p>Carefully connected the FFC cable and secured it with the native fasteners.<br>I added double-sided tape to the plastic extension adapter and simply taped it to the battery at the very end.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-14.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-14.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-14.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-14.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-14.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>Final demo</p>



		<figure>
			
			
		</figure>
		






<p>That’s it.</p>



<h2>Sources</h2>



<p>repository in progress</p>



<h2>One more thing</h2>



<p>When I started working on the project, I immediately had very global plans.</p>



<p><br>Namely:</p>



<ol>
<li>Add RGB backlighting.</li>



<li>Add a Raspberry Pi RP2040 with an accelerometer to activate the backlighting.</li>



<li>Consider installing additional buttons connecting RP2040 to the Macbook with a separate BT channel or cable.</li>



<li>Install an additional battery to ensure the operation of the backlighting.</li>
</ol>



<p>Fortunately, I came to my senses in time. </p>



<figure><img loading="lazy" decoding="async" width="1024" height="771" src="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-15.jpg?resize=1024%2C771&amp;ssl=1" alt="" srcset="https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-15.jpg?resize=1024%2C771&amp;ssl=1 1024w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-15.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-15.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/uplab.pro/wp-content/uploads/2023/11/image-15.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>







<p>But you know, sometimes it’s so hard to stop yourself.</p>



		<figure>
			
			
		</figure>
		<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="Ivan Kuleshov" src="https://secure.gravatar.com/avatar/b2341fde4a191f98572cdbb21d017c4f?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/b2341fde4a191f98572cdbb21d017c4f?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image"></p><div><p>I’m a systems engineer in JetBrains company. Uptime Lab founder. I’m glad to see you on my website! I hope you find my content useful. Please subscribe to my Instagram and Twitter. I post the newest updates there.</p></div></div>			
				</div><!-- end .entry-content -->
							</article></div>]]></description>
        </item>
    </channel>
</rss>