<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 01 Oct 2025 21:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[U.S. Lost 32,000 Private-Sector Jobs in September, Says Payroll Processor (183 pts)]]></title>
            <link>https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340</link>
            <guid>45442185</guid>
            <pubDate>Wed, 01 Oct 2025 19:30:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340">https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340</a>, See on <a href="https://news.ycombinator.com/item?id=45442185">Hacker News</a></p>
Couldn't get https://www.wsj.com/economy/jobs/u-s-lost-32-000-jobs-in-september-says-payroll-processor-06528340: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Jane Goodall has died (730 pts)]]></title>
            <link>https://www.latimes.com/obituaries/story/2025-10-01/jane-goodall-chimpanzees-dead</link>
            <guid>45441069</guid>
            <pubDate>Wed, 01 Oct 2025 18:10:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/obituaries/story/2025-10-01/jane-goodall-chimpanzees-dead">https://www.latimes.com/obituaries/story/2025-10-01/jane-goodall-chimpanzees-dead</a>, See on <a href="https://news.ycombinator.com/item?id=45441069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>Jane Goodall, the trailblazing naturalist whose intimate observations of chimpanzees in the African wild produced powerful insights that transformed basic conceptions of humankind, has died. She was 91.</p><p>A tireless advocate of preserving chimpanzees’ natural habitat, Goodall died on Wednesday morning in California of natural causes, the Jane Goodall Institute announced on its <a href="https://www.instagram.com/p/DPRn2HTCFYt/?igsh=NTc4MTIwNjQ2YQ%3D%3D" target="_blank">Instagram page</a>. </p><p>“Dr. Goodall’s discoveries as an ethologist revolutionized science,” the Jane Goodall Institute said in a statement. </p><p>A protege of anthropologist Louis S.B. Leakey, Goodall made history in 1960 when she discovered that chimpanzees, humankind’s closest living ancestors, made and used tools, characteristics that scientists had long thought were exclusive to humans.</p><p>She also found that chimps hunted prey, ate meat, and were capable of a range of emotions and behaviors similar to those of humans, including filial love, grief and violence bordering on warfare.</p><p>In the course of establishing one of the world’s longest-running studies of wild animal behavior at what is now Tanzania’s Gombe Stream National Park, she gave her chimp subjects names instead of numbers, a practice that raised eyebrows in the male-dominated field of primate studies in the 1960s. But within a decade, the trim British scientist with the tidy ponytail was a National Geographic heroine, whose books and films educated a worldwide audience with stories of the apes she called David Graybeard, Mr. McGregor, Gilka and Flo.</p><p>“When we read about a woman who gives funny names to chimpanzees and then follows them into the bush, meticulously recording their every grunt and groom, we are reluctant to admit such activity into the big leagues,” the late biologist Stephen Jay Gould wrote of the scientific world’s initial reaction to Goodall.</p><p>But Goodall overcame her critics and produced work that Gould later characterized as “one of the Western world’s great scientific achievements.”</p><p>Tenacious and keenly observant, Goodall paved the way for other women in primatology, including the late gorilla researcher Dian Fossey and orangutan expert Birutė Galdikas. She was honored in 1995 with the National Geographic Society’s Hubbard Medal, which then had been bestowed only 31 times in the previous 90 years to such eminent figures as North Pole explorer Robert E. Peary and aviator Charles Lindbergh.</p><p>In her 80s she continued to travel 300 days a year to speak to schoolchildren and others about the need to fight deforestation, preserve chimpanzees’ natural habitat and promote sustainable development in Africa. She was in California as part of her speaking tour in the U.S. at the time of her death.</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/4ac8360/2147483647/strip/true/crop/1024x680+0+0/resize/320x213!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/482653b/2147483647/strip/true/crop/1024x680+0+0/resize/568x377!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/2a1995f/2147483647/strip/true/crop/1024x680+0+0/resize/768x510!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/169fbf0/2147483647/strip/true/crop/1024x680+0+0/resize/1024x680!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/f152c13/2147483647/strip/true/crop/1024x680+0+0/resize/1200x797!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1200w" sizes="100vw">       <img alt="Jane Goodall in Gombe National Park in Tanzania." srcset="https://ca-times.brightspotcdn.com/dims4/default/855f60f/2147483647/strip/true/crop/1024x680+0+0/resize/320x213!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 320w,https://ca-times.brightspotcdn.com/dims4/default/2b83032/2147483647/strip/true/crop/1024x680+0+0/resize/568x377!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 568w,https://ca-times.brightspotcdn.com/dims4/default/b66c829/2147483647/strip/true/crop/1024x680+0+0/resize/768x510!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 768w,https://ca-times.brightspotcdn.com/dims4/default/7570df9/2147483647/strip/true/crop/1024x680+0+0/resize/1024x680!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1024w,https://ca-times.brightspotcdn.com/dims4/default/04e829c/2147483647/strip/true/crop/1024x680+0+0/resize/1200x797!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg 1200w" sizes="100vw" width="1200" height="797" src="https://ca-times.brightspotcdn.com/dims4/default/04e829c/2147483647/strip/true/crop/1024x680+0+0/resize/1200x797!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F9c%2F39%2F72e661ad406e8fbe8af7e121da8e%2Fhope-art-56.jpg" decoding="async" loading="lazy">   </picture>   <div>      <p>(Chase Pickering / Jane Goodall Institute)</p>   </div>   </figure> </div><p>Goodall was born April 3, 1934, in London and grew up in the English coastal town of Bournemouth. The daughter of a businessman and a writer who separated when she was a child and later divorced, she was raised in a matriarchal household that included her maternal grandmother, her mother, Vanne, some aunts and her sister, Judy.</p><p>She demonstrated an affinity for nature from a young age, filling her bedroom with worms and sea snails that she rushed back to their natural homes after her mother told her they would otherwise die.</p><p>When she was about 5, she disappeared for hours to a dark henhouse to see how chickens laid eggs, so absorbed that she was oblivious to her family’s frantic search for her. She did not abandon her study until she observed the wondrous event.</p><p>“Suddenly with a plop, the egg landed on the straw. With clucks of pleasure the hen shook her feathers, nudged the egg with her beak, and left,” Goodall wrote almost 60 years later. “It is quite extraordinary how clearly I remember that whole sequence of events.”</p><p>When finally she ran out of the henhouse with the exciting news, her mother did not scold her but patiently listened to her daughter’s account of her first scientific observation.</p><p>Later, she gave Goodall books about animals and adventure — especially the Doctor Dolittle tales and Tarzan. Her daughter became so enchanted with Tarzan’s world that she insisted on doing her homework in a tree.</p><p>“I was madly in love with the Lord of the Jungle, terribly jealous of his Jane,” Goodall wrote in her 1999 memoir, “Reason for Hope: A Spiritual Journey.” “It was daydreaming about life in the forest with Tarzan that led to my determination to go to Africa, to live with animals and write books about them.”</p><p>Her opportunity came after she finished high school. A week before Christmas in 1956 she was invited to visit an old school chum’s family farm in Kenya. Goodall saved her earnings from a waitress job until she had enough for a round-trip ticket.</p><div data-click="enhancement" data-align-center-expanded=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/48fc7d0/2147483647/strip/true/crop/1992x1334+0+0/resize/320x214!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/95b8306/2147483647/strip/true/crop/1992x1334+0+0/resize/568x381!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/17a7894/2147483647/strip/true/crop/1992x1334+0+0/resize/768x515!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/1c876f0/2147483647/strip/true/crop/1992x1334+0+0/resize/1024x686!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/30c89ba/2147483647/strip/true/crop/1992x1334+0+0/resize/1200x804!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1200w" sizes="100vw">       <img alt="Jane Goodall gives a little kiss to Tess, a 5- or 6-year-old female chimpanzee, in 1997." srcset="https://ca-times.brightspotcdn.com/dims4/default/ab5b58c/2147483647/strip/true/crop/1992x1334+0+0/resize/320x214!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/ef5412a/2147483647/strip/true/crop/1992x1334+0+0/resize/568x381!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/62ea93b/2147483647/strip/true/crop/1992x1334+0+0/resize/768x515!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/b8e4b6b/2147483647/strip/true/crop/1992x1334+0+0/resize/1024x686!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/d37bd3f/2147483647/strip/true/crop/1992x1334+0+0/resize/1200x804!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG 1200w" sizes="100vw" width="1200" height="804" src="https://ca-times.brightspotcdn.com/dims4/default/d37bd3f/2147483647/strip/true/crop/1992x1334+0+0/resize/1200x804!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F77%2Ff9%2Fe58d647d4f408ecab087c086fc4c%2Fla-photos-wgetty-kenya-jane-goodall.JPG" decoding="async" loading="lazy">   </picture>   <div>      <p>(Jean-Marc Bouju / Associated Press)</p>   </div>   </figure> </div><p>She arrived in Kenya in 1957, thrilled to be living in the Africa she had “always felt stirring in my blood.” At a dinner party in Nairobi shortly after her arrival, someone told her that if she was interested in animals, she should meet Leakey, already famous for his discoveries in East Africa of man’s fossil ancestors.</p><p>She went to see him at what’s now the National Museum of Kenya, where he was curator. He hired her as a secretary and soon had her helping him and his wife, Mary, dig for fossils at Olduvai Gorge, a famous site in the Serengeti Plains in what is now northern Tanzania.</p><p>Leakey spoke to her of his desire to learn more about all the great apes. He said he had heard of a community of chimpanzees on the rugged eastern shore of Lake Tanganyika where an intrepid researcher might make valuable discoveries.</p><p>When Goodall told him this was exactly the kind of work she dreamed of doing, Leakey agreed to send her there.</p><p>It took Leakey two years to find funding, which gave Goodall time to study primate behavior and anatomy in London. She finally landed in Gombe in the summer of 1960.</p><p>On a rocky outcropping she called the Peak, Goodall made her first important observation. Scientists had thought chimps were docile vegetarians, but on this day about three months after her arrival, Goodall spied a group of the apes feasting on something pink. It turned out to be a baby bush pig.</p><p>Two weeks later, she made an even more exciting discovery — the one that would establish her reputation. She had begun to recognize individual chimps, and on a rainy October day in 1960, she spotted the one with white hair on his chin. He was sitting beside a mound of red earth, carefully pushing a blade of grass into a hole, then withdrawing it and poking it into his mouth.</p><p>When he finally ambled off, Goodall hurried over for a closer look. She picked up the abandoned grass stalk, stuck it into the same hole and pulled it out to find it covered with termites. The chimp she later named David Graybeard had been using the stalk to fish for the bugs.</p><p>“It was hard for me to believe what I had seen,” Goodall later wrote. “It had long been thought that we were the only creatures on earth that used and made tools. ‘Man the Toolmaker’ is how we were defined...” What Goodall saw challenged man’s uniqueness.</p><p>When she sent her report to Leakey, he responded: “We must now redefine man, redefine tool, or accept chimpanzees as human!”</p><p>Goodall’s startling finding, published in Nature in 1964, enabled Leakey to line up funding to extend her stay at Gombe. It also eased Goodall’s admission to Cambridge University to study ethology. In 1965, she became the eighth person in Cambridge history to earn a doctorate without first having a bachelor’s degree.</p><p>In the meantime, she had met and in 1964 married Hugo Van Lawick, a gifted filmmaker who had traveled to Gombe to make a documentary about her chimp project. They had a child, Hugo Eric Louis — later nicknamed Grub — in 1967.</p><p>Goodall later said that raising Grub, who lived at Gombe until he was 9, gave her insights into the behavior of chimp mothers. Conversely, she had “no doubt that my observation of the chimpanzees helped me to be a better mother.”</p><p>She and Van Lawick were married for 10 years, divorcing in 1974. The following year she married Derek Bryceson, director of Tanzania National Parks. He died of colon cancer four years later.</p><p>Within a year of arriving at Gombe, Goodall had chimps literally eating out of her hands. Toward the end of her second year there, David Graybeard, who had shown the least fear of her, was the first to allow her physical contact. She touched him lightly and he permitted her to groom him for a full minute before gently pushing her hand away. For an adult male chimpanzee who had grown up in the wild to tolerate physical contact with a human was, she wrote in her 1971 book “In the Shadow of Man,” “a Christmas gift to treasure.”</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/fdcd33a/2147483647/strip/true/crop/1992x1344+0+0/resize/320x216!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/b6a5133/2147483647/strip/true/crop/1992x1344+0+0/resize/568x383!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/5652127/2147483647/strip/true/crop/1992x1344+0+0/resize/768x518!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/c9d1992/2147483647/strip/true/crop/1992x1344+0+0/resize/1024x691!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/0e0c1d4/2147483647/strip/true/crop/1992x1344+0+0/resize/1200x810!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1200w" sizes="100vw">       <img alt="Jane Goodall shares a play with Bahati, a 3 year-old female chimpanzee" srcset="https://ca-times.brightspotcdn.com/dims4/default/d73d494/2147483647/strip/true/crop/1992x1344+0+0/resize/320x216!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/aa710d0/2147483647/strip/true/crop/1992x1344+0+0/resize/568x383!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/6f21bf4/2147483647/strip/true/crop/1992x1344+0+0/resize/768x518!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/45da23e/2147483647/strip/true/crop/1992x1344+0+0/resize/1024x691!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/dd65665/2147483647/strip/true/crop/1992x1344+0+0/resize/1200x810!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG 1200w" sizes="100vw" width="1200" height="810" src="https://ca-times.brightspotcdn.com/dims4/default/dd65665/2147483647/strip/true/crop/1992x1344+0+0/resize/1200x810!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fd9%2Fa9%2Fca7199564ac18bd4fa065efdfd96%2Fla-photos-wgetty-kenya-jane-goodall1.JPG" decoding="async" loading="lazy">   </picture>   <div>   <p>Jane Goodall shares a play with Bahati, a 3 year-old female chimpanzee at the Sweetwaters Chimpanzee Sanctuary,  north of Nairobi Sunday December 6, 1997.</p>   <p>(Jean-Marc Bouju/Associated Press)</p>   </div>   </figure> </div><p>Her studies yielded a trove of other observations on behaviors, including etiquette (such as soliciting a pat on the rump to indicate submission) and the sex lives of chimps. She collected some of the most fascinating information on the latter by watching Flo, an older female with a bulbous nose and an amazing retinue of suitors who was bearing children well into her 40s.</p><p>Her reports initially caused much skepticism in the scientific community. “I was not taken very seriously by many of the scientists. I was known as a [National] Geographic cover girl,” she recalled in a CBS interview in 2012.</p><p>Her unorthodox personalizing of the chimps was particularly controversial. The editor of one of her first published papers insisted on crossing out all references to the creatures as “he” or “she” in favor of “it.” Goodall eventually prevailed.</p><p>Her most disturbing studies came in the mid-1970s, when she and her team of field workers began to record a series of savage attacks.</p><p>The incidents grew into what Goodall called the four-year war, a period of brutality carried out by a band of male chimpanzees from a region known as the Kasakela Valley. The marauders beat and slashed to death all the males in a neighboring colony and subjugated the breeding females, essentially annihilating an entire community.</p><p>It was the first time a scientist had witnessed organized aggression by one group of non-human primates against another. Goodall said this “nightmare time” forever changed her view of ape nature.</p><p>“During the first 10 years of the study I had believed ... that the Gombe chimpanzees were, for the most part, rather nicer than human beings,” she wrote in “Reason for Hope: A Spiritual Journey,” a 1999 book co-authored with Phillip Berman. “Then suddenly we found that the chimpanzees could be brutal — that they, like us, had a dark side to their nature.”</p><p>Critics tried to dismiss the evidence as merely anecdotal. Others thought she was wrong to publicize the violence, fearing that irresponsible scientists would use the information to “prove” that the tendency to war is innate in humans, a legacy from their ape ancestors. Goodall persisted in talking about the attacks, maintaining that her purpose was not to support or debunk theories about human aggression but to “understand a little better” the nature of chimpanzee aggression.</p><p>“My question was: How far along our human path, which has led to hatred and evil and full-scale war, have chimpanzees traveled?”</p><p>Her observations of chimp violence marked a turning point for primate researchers, who had considered it taboo to talk about chimpanzee behavior in human terms. But by the 1980s, much chimp behavior was being interpreted in ways that would have been labeled anthropomorphism — ascribing human traits to non-human entities — decades earlier. Goodall, in removing the barriers, raised primatology to new heights, opening the way for research on subjects ranging from political coalitions among baboons to the use of deception by an array of primates.</p><p>Her concern about protecting chimpanzees in the wild and in captivity led her in 1977 to found the <a href="https://www.janegoodall.org/" target="_blank">Jane Goodall Institute</a> to advocate for great apes and support research and public education. She also established Roots and Shoots, a program aimed at youths in 130 countries, and TACARE, which involves African villagers in sustainable development.</p><p>She became an international ambassador for chimps and conservation in 1986 when she saw a film about the mistreatment of laboratory chimps. The secretly taped footage “was like looking into the Holocaust,” she told interviewer Cathleen Rountree in 1998. From that moment, she became a globe-trotting crusader for animal rights. </p><p>In the 2017 documentary “Jane,” the producer poured through 140 hours of footage of Goodall that had been hidden away in the National Geographic archives. The film won a Los Angeles Film Critics Assn. Award, one of many honors it received.</p><div data-video-disable-history="" data-click="enhancement" data-align-center="">  <ps-youtubeplayer data-video-player="" data-player-id="f826de22fae514bee8031d59e313f3fbc" data-video-id="X6CW7dSXKWo" data-video-title="Jane Goodall discusses “The Book of Hope”" data-slot-name="/21787098806/web.latimes/obituaries/video" data-lazy-offset="1.0" data-autoplay-threshold="50" data-miniplayer="" data-internal-video-id="X6CW7dSXKWo" data-ad-slot-name="/21787098806/web.latimes/obituaries/video" data-ad-provider="ima" data-ima-sdk-url="https://imasdk.googleapis.com/js/sdkloader/ima3.js" data-ima-ad-tag-url="https://pubads.g.doubleclick.net/gampad/ads?sz=640x480&amp;gdfp_req=1&amp;env=vp&amp;output=vast&amp;unviewed_position_start=1&amp;cmsid=2652439&amp;ad_rule=0&amp;plcmt=1">  <picture> <source srcset="https://img.youtube.com/vi_webp/X6CW7dSXKWo/maxresdefault.webp" type="image/webp"> <source srcset="https://img.youtube.com/vi/X6CW7dSXKWo/maxresdefault.jpg"> <img id="yt-img-X6CW7dSXKWo" alt="" src="https://img.youtube.com/vi/X6CW7dSXKWo/hqdefault.jpg" loading="lazy" decoding="async"> </picture>       </ps-youtubeplayer> </div><p>In a <a href="https://www.latimes.com/la-oe-morrison18-2009jul18-column.html" target="_blank">ranging 2009 interview</a> with Times columnist Patt Morrison, Goodall mused on topics from traditional zoos — she said most captive environments should be abolished — to climate change, a battle she feared humankind was quickly losing, if not lost already. She also spoke about the power of what one human can accomplish.</p><p>“I always say, ‘If you would spend just a little bit of time learning about the consequences of the choices you make each day’ — what you buy, what you eat, what you wear, how you interact with people and animals — and start consciously making choices, that would be beneficial rather than harmful.”</p><p>As the years  passed, Goodall continued to track Gombe’s chimps, accumulating enough information to draw the arcs of their lives — from birth through sometimes troubled adolescence, maturity, illness and finally death.</p><p>She wrote movingly about how she followed Mr. McGregor, an older, somewhat curmudgeonly chimp, through his agonizing death from polio, and how the orphan Gilka survived to lonely adulthood only to have her babies snatched from her by a pair of cannibalistic female chimps.</p><div data-click="enhancement" data-align-left=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/fe7d253/2147483647/strip/true/crop/3960x2640+0+0/resize/320x213!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/097a3cb/2147483647/strip/true/crop/3960x2640+0+0/resize/568x379!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/2cf83f8/2147483647/strip/true/crop/3960x2640+0+0/resize/768x512!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/fed4802/2147483647/strip/true/crop/3960x2640+0+0/resize/1024x683!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/66b9217/2147483647/strip/true/crop/3960x2640+0+0/resize/1200x800!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1200w" sizes="100vw">       <img alt="Jane Goodall in San Diego." srcset="https://ca-times.brightspotcdn.com/dims4/default/e0c32f5/2147483647/strip/true/crop/3960x2640+0+0/resize/320x213!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/7700788/2147483647/strip/true/crop/3960x2640+0+0/resize/568x379!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/fd7c124/2147483647/strip/true/crop/3960x2640+0+0/resize/768x512!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/f2aaab4/2147483647/strip/true/crop/3960x2640+0+0/resize/1024x683!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1024w,https://ca-times.brightspotcdn.com/dims4/default/4373298/2147483647/strip/true/crop/3960x2640+0+0/resize/1200x800!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG 1200w" sizes="100vw" width="1200" height="800" src="https://ca-times.brightspotcdn.com/dims4/default/4373298/2147483647/strip/true/crop/3960x2640+0+0/resize/1200x800!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2f%2F63%2Fcffde3f94732b171d7b069c37f19%2F458667-sd-me-jane-goodall001.JPG" decoding="async" loading="lazy">   </picture>   <div>      <p>(Sam Hodgson/The San Diego Union-Tribune)</p>   </div>   </figure> </div><p>Her reaction in 1972 to the death of Flo, a prolific female known as Gombe’s most devoted mother, suggested the depth of feeling that Goodall had for the animals. Knowing that Flo’s faithful son Flint was nearby and grieving, Goodall watched over the body all night to keep marauding bush pigs from violating her remains.</p><p>“People say to me, thank you for giving them characters and personalities,” Goodall once told CBS’s “60 Minutes.” “I said I didn’t give them anything. I merely translated them for people.”</p><p><i>Woo is a former Times staff writer.</i></p><div data-list-id="00000192-be42-da32-a3db-ff76fc3b0000" data-module-id="00000192-be42-da32-a3db-ff76fc3b0000" data-click="enhancement" data-align-center="">  <p data-element="element-header" data-click="liZZListTitleCTA">  <h3 data-element="element-header-title" data-counter="3">More to Read </h3>  </p>      </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Avoiding Politics (262 pts)]]></title>
            <link>https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/</link>
            <guid>45440571</guid>
            <pubDate>Wed, 01 Oct 2025 17:36:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/">https://terriblesoftware.org/2025/10/01/stop-avoiding-politics/</a>, See on <a href="https://news.ycombinator.com/item?id=45440571">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Say the word “politics” to most engineers and watch their face scrunch up like they just bit into a lemon. We’ve all been conditioned to believe that workplace politics is this dirty game played by manipulative ladder-climbers while the “real” engineers focus on the code.</p>



<p>I used to think the same way. For years as an engineer, I wore my hatred of politics like a badge of honor. I was above all that nonsense. I just wanted to ship. Politics was for those other people, the ones who didn’t have what it takes technically.</p>



<p>Now I think the opposite: <strong>politics isn’t the problem; bad politics is.</strong> And pretending politics doesn’t exist? That’s how bad politics wins.</p>



<p>Politics is just how humans coordinate in groups. It’s the invisible network of relationships, influence, and informal power that exists in every organization. You can refuse to participate, but that doesn’t make it go away. It just means decisions get made without you.</p>



<p>Think about the last time a terrible technical decision got pushed through at your company. Maybe it was adopting some overcomplicated architecture, or choosing a vendor that everyone knew was wrong, or killing a project that was actually working. I bet if you dig into what happened, you’ll find it wasn’t because the decision-makers were stupid. It’s because the people with the right information weren’t in the room. They “didn’t do politics.”</p>



<p>Meanwhile, someone who understood how influence works was in that room, making their case, building coalitions, showing they’d done their homework. And their idea won. Not because it was better, but because they showed up to play while everyone else was “too pure” for politics.</p>



<p>Ideas don’t speak. People do. And the people who understand how to navigate organizational dynamics, build relationships, and yes, play politics? Their ideas get heard.</p>



<p>When you build strong relationships across teams, understand what motivates different stakeholders, and know how to build consensus, you’re doing politics. When you take time to explain your technical decisions to non-technical stakeholders in language they understand, that’s politics. When you grab coffee with someone from another team to understand their challenges, that’s politics too.</p>



<p><strong>Good politics is just being strategic about relationships and influence in the service of good outcomes.</strong></p>



<p>The best technical leaders are incredibly political. They just don’t call it that. They call it “stakeholder management” or “building alignment” or “organizational awareness.” But it’s politics, and they’re good at it.</p>



<p>The engineers who refuse to engage with politics often complain that their companies make bad technical decisions. But they’re not willing to do what it takes to influence those decisions. They want a world where technical merit alone determines outcomes. That world doesn’t exist and never has.</p>



<p>This isn’t about becoming a scheming backstabber. As I wrote in <a href="https://terriblesoftware.org/2025/03/31/your-strengths-are-your-weaknesses/">Your Strengths Are Your Weaknesses</a>, the same trait can be positive or negative depending on how you use it. Politics is the same way. You can use political skills to manipulate and self-promote, or you can use them to get good ideas implemented and protect your team from bad decisions.</p>



<p>Here’s what good politics looks like in practice:</p>



<ol>
<li><strong>Building relationships before you need them.</strong> That random coffee with someone from the data team? Six months later, they’re your biggest advocate for getting engineering resources for your data pipeline project.</li>



<li><strong>Understanding the real incentives.</strong> Your VP doesn’t care about your beautiful microservices architecture. They care about shipping features faster. Frame your technical proposals in terms of what they actually care about.</li>



<li><strong>Managing up effectively.</strong> Your manager is juggling competing priorities you don’t see. Keep them informed about what matters, flag problems early with potential solutions, and help them make good decisions. When they trust you to handle things, they’ll fight for you when it matters</li>



<li><strong>Creating win-win situations.</strong> Instead of fighting for resources, find ways to help other teams while getting what you need. It doesn’t have to be a zero-sum game.</li>



<li><strong>Being visible.</strong> If you do great work but nobody knows about it, did it really happen? Share your wins, present at all-hands, write those design docs that everyone will reference later.</li>
</ol>



<p>The alternative to good politics isn’t no politics. It’s bad politics winning by default. It’s the loud person who’s wrong getting their way because the quiet person who’s right won’t speak up. It’s good projects dying because nobody advocated for them. It’s talented people leaving because they couldn’t navigate the organizational dynamics.</p>



<p>Stop pretending you’re above politics. You’re not. Nobody is. The only question is whether you’ll get good at it or keep losing to people who already are.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenTSLM: Language models that understand time series (129 pts)]]></title>
            <link>https://www.opentslm.com/</link>
            <guid>45440431</guid>
            <pubDate>Wed, 01 Oct 2025 17:25:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.opentslm.com/">https://www.opentslm.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45440431">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>The Future of AI Delivered on Time</p><div><p>Paper Released Sep 30, 2025</p><p>Stanford Repo Released Oct 1, 2025</p></div></div><section><p>AI understands text, images, audio, and video.<br>But the real world runs on time.</p><p>Every heartbeat, price tick, sensor pulse, machine log, and user click is a temporal signal.<br>Current models can't reason about them.</p><p>We're changing that.</p></section><section><h2>A New Class of Foundation Models</h2><div><p><span>Time-Series Language Models (TSLMs)</span> are multimodal foundation models with time series as a native modality, next to text, enabling direct reasoning, explanation, and forecasting over temporal data in natural language.</p><p>Our research shows order-of-magnitude gains in temporal reasoning while running on smaller, faster backbones. TSLMs are not an add-on. They're a new modality for AI.</p></div></section><section><h2>Open Core, Frontier Edge</h2><div><p><span>OpenTSLM:</span> Lightweight base models trained on public data, released openly. They set the standard for temporal reasoning and power a global developer and research ecosystem.</p><p><span>Frontier TSLMs:</span> Advanced proprietary models trained on specialized data, delivering enterprise-grade performance and powering APIs, fine-tuning, and vertical solutions.</p></div></section><section><h2>Our Vision</h2><div><p>We're building the temporal interface for AI - the layer that connects continuous real-world signals to intelligent decisions and autonomous agents.</p><p>A universal TSLM will power proactive healthcare, adaptive robotics, resilient infrastructure, and new forms of human-AI collaboration.</p></div></section><section><h2>About Us</h2><p>OpenTSLM is a team of scientists, engineers, and builders from ETH, Stanford, Harvard, Cambridge, TUM, CDTM, Google, Meta, AWS, and beyond. We are the original authors of the OpenTSLM paper.</p></section><section><h2><p>Discover how TSLMs could transform</p></h2></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Solar leads EU electricity generation as renewables hit 54% (192 pts)]]></title>
            <link>https://electrek.co/2025/09/30/solar-leads-eu-electricity-generation-as-renewables-hit-54-percent/</link>
            <guid>45440387</guid>
            <pubDate>Wed, 01 Oct 2025 17:22:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/09/30/solar-leads-eu-electricity-generation-as-renewables-hit-54-percent/">https://electrek.co/2025/09/30/solar-leads-eu-electricity-generation-as-renewables-hit-54-percent/</a>, See on <a href="https://news.ycombinator.com/item?id=45440387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="900" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?quality=82&amp;strip=all&amp;w=1600" alt="EU electricity" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/09/pexels-photo-30762864.jpeg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">			<figcaption>
				Photo by Wolfgang Weiser on <a href="https://www.pexels.com/photo/historic-war-memorial-in-salzkotten-germany-30762864/" rel="nofollow">Pexels.com</a>			</figcaption>
			</figure>

<p>More than half of the European Union’s (EU) electricity came from renewables in the second quarter of 2025, and solar is leading from the front.</p>



<p>According to new data from Eurostat, renewable energy sources generated 54% of the EU’s net electricity in Q2 2025, up from 52.7% year-over-year. The growth came mainly from solar, which produced 122,317 gigawatt-hours (GWh) – nearly 20% of the total electricity generation mix.</p>



<p>June 2025 was a milestone month: Solar became the EU’s single largest electricity source for the first time ever. It supplied 22% of all power that month, edging out nuclear (21.6%), wind (15.8%), hydro (14.1%), and natural gas (13.8%).</p>



<p>Some countries are already nearly 100% renewable. Denmark led with an impressive 94.7% share of renewables in net electricity generated, followed by Latvia (93.4%), Austria (91.8%), Croatia (89.5%), and Portugal (85.6%). At the other end of the spectrum, Slovakia (19.9%), Malta (21.2%), and the Czech Republic (22.1%) lagged behind.</p>	
	



<p>In total, 15 EU countries saw their share of renewable generation rise year-over-year. Luxembourg (+13.5 percentage points) and Belgium (+9.1 pp) posted the most significant gains, driven largely by solar power growth.</p>



<p>Across the EU, solar made up 36.8% of renewable generation, followed by wind at 29.5%, hydro at 26%, biomass at 7.3%, and geothermal at 0.4%.</p>



<p><strong>Read more:</strong> <a href="https://electrek.co/2025/09/24/eia-solar-and-wind-crush-coal-with-20-percent-more-power-in-2025/">EIA: Solar and wind crush coal with 20% more power in 2025</a></p>



<figure><a href="https://www.energysage.com/landing/home-solar/p/electrek-rsm-ml/?utm_medium=Partner&amp;utm_source=Electrek" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="750" height="150" src="https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png 750w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=150,30 150w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=300,60 300w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=350,70 350w, https://electrek.co/wp-content/uploads/sites/3/2025/09/DES-1038_Electrek-Banners_Resiliency_b651c0.png?resize=140,28 140w" sizes="(max-width: 750px) 100vw, 750px"></a></figure>



<hr>



<p><strong><em>The 30% federal solar tax credit is ending this year. If you’ve ever considered going solar, now’s the time to act. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out </em></strong><a href="https://c32b704.na1.hs-sales-engage.com/Ctc/P+23284/c32B704/JlF3crJ5W8wLKSR6lZ3p-W7s8QC84nlPDsW35x5rq5vFtfyW88cj9v1vtBqZVbfGXn1xzh51W8jvN5t8yhpLdW57_shc5Rp3MdMN0T8GbTR9LW5kbjcl41XSlfW1DWv0v4vFzCtW8zy2kd45l-lnW8TNZ_52QnSx-W54zS-f2SKtm5W5WK2df426XsKV7j3fd6CkxT7W7x6GCb20V3brW6qqHST3bthfYW6CpFKd7_yQ0XW2ysWt869bCphW6r8YtG4GrsVkW46V-MQ5bp2VwW5m6Bnn8b0H0_VsQ6Xw673G4GW2FfPnr6RDKb7W7dQjKN7Mqbk0W2D2_x791FrC9W84mN5P1JPzsPW5Ymmh58m7YHdW2RdHWF257Zzhf4hJ8JP04"><strong><em>EnergySage</em></strong></a><strong><em>, a free service that makes it easy for you to go solar. It has hundreds of pre-vetted solar installers competing for your business, ensuring you get high-quality solutions and save 20-30% compared to going it alone. Plus, it’s free to use, and you won’t get sales calls until you select an installer and share your phone number with them.&nbsp;</em></strong></p>



<p><strong><em>Your personalized solar quotes are easy to compare online and you’ll get access to unbiased Energy Advisors to help you every step of the way. </em></strong><a href="https://c32b704.na1.hs-sales-engage.com/Ctc/P+23284/c32B704/JlF3crJ5W8wLKSR6lZ3p-W7s8QC84nlPDsW35x5rq5vFtfyW88cj9v1vtBqZVbfGXn1xzh51W8jvN5t8yhpLdW57_shc5Rp3MdMN0T8GbTR9LW5kbjcl41XSlfW1DWv0v4vFzCtW8zy2kd45l-lnW8TNZ_52QnSx-W54zS-f2SKtm5W5WK2df426XsKV7j3fd6CkxT7W7x6GCb20V3brW6qqHST3bthfYW6CpFKd7_yQ0XW2ysWt869bCphW6r8YtG4GrsVkW46V-MQ5bp2VwW5m6Bnn8b0H0_VsQ6Xw673G4GW2FfPnr6RDKb7W7dQjKN7Mqbk0W2D2_x791FrC9W84mN5P1JPzsPW5Ymmh58m7YHdW2RdHWF257Zzhf4hJ8JP04"><strong><em>Get started here</em></strong></a><strong><em>.</em></strong></p>
	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Codeberg Reaches 300k Projects (176 pts)]]></title>
            <link>https://codeberg.org/</link>
            <guid>45439955</guid>
            <pubDate>Wed, 01 Oct 2025 16:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeberg.org/">https://codeberg.org/</a>, See on <a href="https://news.ycombinator.com/item?id=45439955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<header>
		
	</header>

	<section id="home-section-about">
		<div>
				<div>
					<h3>NON-PROFIT</h3>
					<p>
						Codeberg is maintained by the non-profit organization <b>Codeberg e.V.</b>,
						based in <b>Berlin, Germany</b>. For us, supporting the commons comes <b>first</b>.
					</p>
					<p>
						<b>
							 Its future is in the hands of its users. You can help too!
						</b>
					</p>
				</div>
				<div>
					<h3>COMMUNITY</h3>
					<p>
						We are more than just Git hosting: Our community is comprised of like-minded
						developers, artists, academics, hobbyists and professionals.
					</p>
					<p>
						<b>
							We celebrate free culture, openness and creativity.
						</b>
					</p>
				</div>
				<div>
					<h3>RESPECT</h3>
					<p>
						No tracking. No third-party cookies. No profiteering.
						Everything runs on servers that we control. Your data is <b>not</b> for sale.
					</p>
					<p>
						<b>
							Hosted in Europe, we welcome the world.
						</b>
					</p>
				</div>
				
					
				
			</div>

		<div>
				<h4>POWERED BY</h4>
				
			</div>
	</section>

	<section id="home-section-support">
		<h3>Your support helps us grow!</h3>
		<div>
			<a href="https://join.codeberg.org/">
				
				Become a member
			</a>
			<p>
				Our non-profit structure reinforces our independence. Your donations and contributions sustain our community.
				Help us achieve our mission by joining Codeberg e.V. as a supporting or active member with full voting rights!
			</p>
		</div>
		<hr>
		<div>
			<a href="https://docs.codeberg.org/improving-codeberg/#donate-to-codeberg">
				
				Fund our project
			</a>
			<p>
				Free as in freedom, not as in beer! Maintaining our systems and developing our software has its costs, which
				are backed by optional donations. We appreciate them a lot, as they help provide a better service for everyone.
			</p>
		</div>
		<hr>
		<div>
			<a href="https://docs.codeberg.org/improving-codeberg/#contribute-to-codeberg">
				
				Develop Codeberg
			</a>
			<p>
				Powered by Free Software! Get involved with Codeberg and help improve your experience. We
				are always looking for contributions to our projects and services.
			</p>
		</div>
	</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DuckDuckGo Donates $25,000 to The Perl and Raku Foundation v2025 (130 pts)]]></title>
            <link>https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation-v2025/</link>
            <guid>45439883</guid>
            <pubDate>Wed, 01 Oct 2025 16:42:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation-v2025/">https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation-v2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45439883">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
              
              <p>Oct 1, 2025 by
              
              
                
                
                <a href="#author-bio-olaf-alders">Olaf Alders</a>
              
              </p>
               <img alt="" src="https://www.perl.com/images/duck-duck-go/DuckDuckGo-Logo-1.png">
                <p>For the second consecutive year, The Perl and Raku Foundation (TPRF) is
overjoyed to announce <a href="https://spreadprivacy.com/2025-duckduckgo-charitable-donations/">a donation of USD 25,000 from
DuckDuckGo</a>.</p>
<blockquote>
<p>DuckDuckGo has demonstrated how Perl and its ecosystem can deliver power and
scale to drive the DuckDuckGo core systems, plug-in framework and Instant
Answers. The Foundation is grateful that DuckDuckGo recognises the importance
of Perl, and for their generous funding support for a second year through
their charitable donations programme.</p></blockquote>
<p>– Stuart J Mackintosh, President of The Perl and Raku Foundation</p>
<p><a href="https://www.perl.com/article/duckduckgo-donates-25-000-to-the-perl-and-raku-foundation/">Last year’s donation of USD 25,000 from
DuckDuckGo</a>
was instrumental in helping to fund the foundation’s Core Perl Maintenance Fund
and this year’s donation will help to fund more of the same crucial work that
keeps the Perl language moving forward.</p>
<p><img src="https://www.perl.com/images/duck-duck-go/fireworks.jpg" alt="Fireworks celebration"></p>
<p><a href="https://metacpan.org/author/PEVANS">Paul “LeoNerd” Evans</a> is one of the
developers who gets regular funding from the Perl Core Maintenance Fund. Here
is a short list of just some of the many contributions which Paul has made to
core Perl as part of the maintenance fund work:</p>
<hr>
<ul>
<li>The <a href="https://perldoc.perl.org/builtin">builtin</a> module (5.36), making
available many new useful language-level utilities that were previously
loaded from modules like <a href="https://metacpan.org/pod/Scalar::Util">Scalar::Util</a></li>
<li>The complete <a href="https://perldoc.perl.org/feature#The-'class'-feature">feature
‘class’</a> system
(5.38), adding proper object-orientation syntax and abilities</li>
<li>Lexical method support (5.42), adding <code>my method</code> and
the <code>$obj-&gt;&amp;method</code> invocation syntax for better object encapsulation</li>
<li>Stabilising some of the recent experiments - signatures (5.36),
try/catch (5.40), foreach on multiple vars (5.40)</li>
<li>Ability to use the //= and ||= operators in signatures (5.38),
performance improvements and named parameters (upcoming in next
release)</li>
<li>The new <a href="https://perldoc.perl.org/functions/any">any</a> and
<a href="https://perldoc.perl.org/functions/all">all</a> keywords (5.42)</li>
</ul>
<hr>
<p>We look forward to many more innovative contributions from Paul over the coming
year.</p>
<p>While TPRF never takes continued support for granted, when it does arrive, it
allows the foundation to plan for the future with much greater confidence.
Multi-year partnerships with our sponsors allow us to continue to prioritize
important work, knowing that we will have the runway that we need to fund the
work which helps to sustain the Perl Language and its associated communities.</p>
<p>For more information on how to become a sponsor, please contact:
<a href="mailto:olaf@perlfoundation.org">olaf@perlfoundation.org</a></p>
<hr>
<p><em>"<a href="https://www.flickr.com/photos/67458569@N00/7722577066">Fireworks</a>" by <a href="https://www.flickr.com/photos/67458569@N00">colink.</a> is licensed under <a href="https://creativecommons.org/licenses/by-sa/2.0/?ref=openverse">CC BY-SA 2.0</a>.</em></p>

              </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No more "check mail from other accounts" in Gmail web (134 pts)]]></title>
            <link>https://support.google.com/mail/answer/16604719?hl=en</link>
            <guid>45439670</guid>
            <pubDate>Wed, 01 Oct 2025 16:25:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.google.com/mail/answer/16604719?hl=en">https://support.google.com/mail/answer/16604719?hl=en</a>, See on <a href="https://news.ycombinator.com/item?id=45439670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hcfe-content" role="main">                   <article class="page" sc-render-smart-button="false" itemscope=""> <div data-stats-ve="35"><p>Starting January 2026, Gmail will no longer provide support for the following:</p>

<ul>
  <li><strong>Gmailify:</strong> This feature allows you to get special features like spam protection or inbox organization applied to your third-party email account. <a href="https://support.google.com/mail/answer/6304825" rel="noopener">Learn more about Gmailify</a>.</li>
  <li><strong>POP:</strong> This feature allows you to read your messages from a third-party account in Gmail. Unlike IMAP connections, POP only works with a single device and doesn’t sync your email in real time. Instead, emails are downloaded, and you decide how often you want to download new emails. As an alternative, you can still link your third-party accounts in the Gmail app.</li>
</ul>

<p>These changes help provide the most secure and current options to access your messages in Gmail.</p>

<h2>Learn about changes to Gmailify</h2>

<p>You won’t be able to get specific features in Gmail applied to your third-party account, like:</p>

<ul>
  <li><a href="https://safety.google/intl/en_us/gmail/" rel="noopener" target="_blank">Spam protection</a></li>
  <li>Better email notifications on mobile</li>
  <li><a href="https://support.google.com/mail/answer/3094499" rel="noopener">Inbox categories</a></li>
  <li>Faster search with <a href="https://support.google.com/mail/answer/7190" rel="noopener">advanced search operators</a></li>
</ul>

<h3>What you need to do</h3>

<ul>
  <li>You can still read and send emails from your other account within the Gmail app. This uses a standard IMAP connection, which is supported in the Gmail mobile app.</li>
  <li><a href="https://support.google.com/mail/answer/6078445" rel="noopener">Learn how to add another email account to the Gmail app</a>.</li>
</ul>

<h2>Learn about changes to POP connections</h2>

<ul>
  <li>Gmail will no longer support checking emails from third-party accounts through POP.</li>
  <li>The option to "Check mail from other accounts" will no longer be available in Gmail on your computer.</li>
</ul>

<h3>What you need to do</h3>

<p><strong>Important:</strong> If you have a work or school account, your administrator can help migrate your email data into Google Workspace. <a href="https://support.google.com/a/topic/14012345" rel="noopener">Learn more about the data migration service</a>.</p>

<ul>
  <li>To continue to receive messages from your other account in Gmail, you need to set up IMAP access.
    <ul>
      <li>Check your email provider’s documentation for instructions on how to enable IMAP for your account.</li>
    </ul>
  </li>
  <li>To read your messages from your other account, use the Gmail app. <a href="https://support.google.com/mail/answer/6078445" rel="noopener">Learn how to add another email account to the Gmail app</a>.</li>
</ul>

<h2>Frequently asked questions</h2>
<p><a>Will I lose the emails I already imported?</a></p><p>No. All messages synced before the deprecation stay in Gmail.</p>
<p><a>Can I still use other email accounts in the Gmail app?</a></p><p>Yes. For third-party accounts like Yahoo! and Outlook, you can add them to the Gmail mobile app on Android and iPhone and iPad.</p>

<h2>Related resources</h2>

<ul>
  <li><a href="https://support.google.com/mail/answer/6304825" rel="noopener">Get Gmail features for your other email accounts</a></li>
  <li><a href="https://support.google.com/mail/answer/21289" rel="noopener">Add another email account on your computer</a></li>
</ul>
</div>      </article>            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Who is hiring? (October 2025) (111 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=45438503</link>
            <guid>45438503</guid>
            <pubDate>Wed, 01 Oct 2025 15:01:06 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=45438503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bigbox"><td><table><tbody><tr id="45438503"><td><span></span></td><td><center><a id="up_45438503" href="https://news.ycombinator.com/vote?id=45438503&amp;how=up&amp;goto=item%3Fid%3D45438503"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=45438503">Ask HN: Who is hiring? (October 2025)</a></span></td></tr><tr><td colspan="2"></td><td><span><span id="score_45438503">111 points</span> by <a href="https://news.ycombinator.com/user?id=whoishiring">whoishiring</a> <span title="2025-10-01T15:01:06 1759330866"><a href="https://news.ycombinator.com/item?id=45438503">4 hours ago</a></span> <span id="unv_45438503"></span> | <a href="https://news.ycombinator.com/hide?id=45438503&amp;goto=item%3Fid%3D45438503">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Who%20is%20hiring%3F%20%28October%202025%29&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=45438503&amp;auth=e62bfd643e03dbfc11da0f07461353f48e2b6638">favorite</a> | <a href="https://news.ycombinator.com/item?id=45438503">162&nbsp;comments</a></span></td></tr><tr><td colspan="2"></td><td><div><p>Please state the location and include REMOTE for remote work, REMOTE (US)
or similar if the country is restricted, and ONSITE when remote work is <i>not</i> an option.</p><p>Please only post if you personally are part of the hiring company—no
recruiting firms or job boards. One post per company. If it isn't a household name,
explain what your company does.</p><p>Please only post if you are actively filling a position and are committed
to responding to applicants.</p><p>Commenters: please don't reply to job posts to complain about
something. It's off topic here.</p><p>Readers: please only email if you are personally interested in the job.</p><p>Searchers: try <a href="https://dheerajck.github.io/hnwhoishiring/" rel="nofollow">https://dheerajck.github.io/hnwhoishiring/</a>,
<a href="https://amber-williams.github.io/hackernews-whos-hiring/" rel="nofollow">https://amber-williams.github.io/hackernews-whos-hiring/</a>,
<a href="http://nchelluri.github.io/hnjobs/" rel="nofollow">http://nchelluri.github.io/hnjobs/</a>, <a href="https://hnresumetojobs.com/" rel="nofollow">https://hnresumetojobs.com</a>,
<a href="https://hnhired.fly.dev/" rel="nofollow">https://hnhired.fly.dev</a>, <a href="https://kennytilton.github.io/whoishiring/" rel="nofollow">https://kennytilton.github.io/whoishiring/</a>,
<a href="https://hnjobs.emilburzo.com/" rel="nofollow">https://hnjobs.emilburzo.com</a>, or this (unofficial) Chrome extension:
<a href="https://chromewebstore.google.com/detail/hn-hiring-pro/mpfaljjblphnlloddaplgicpkinikjlp" rel="nofollow">https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal...</a>.</p><p>Don't miss these other fine threads:</p><p><i>Who wants to be hired?</i> <a href="https://news.ycombinator.com/item?id=45438501">https://news.ycombinator.com/item?id=45438501</a></p><p><i>Freelancer? Seeking freelancer?</i> <a href="https://news.ycombinator.com/item?id=45438502">https://news.ycombinator.com/item?id=45438502</a></p></div></td></tr><tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr></tbody></table><br>
</td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building the heap: racking 30 petabytes of hard drives for pretraining (200 pts)]]></title>
            <link>https://si.inc/posts/the-heap/</link>
            <guid>45438496</guid>
            <pubDate>Wed, 01 Oct 2025 15:00:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://si.inc/posts/the-heap/">https://si.inc/posts/the-heap/</a>, See on <a href="https://news.ycombinator.com/item?id=45438496">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>We built a storage cluster in downtown SF to store 90 million hours worth of video data. Why? We’re pretraining models to solve computer use. Compared to text LLMs like LLaMa-405B, which require ~60 TB of text data to train, videos are sufficiently large that we need 500 times more storage. Instead of paying the $12 million / yr it would cost to store all of this on AWS, we rented space from a colocation center in San Francisco to bring that cost down ~40x to $354k per year, including depreciation.</p>
<h2 id="why">Why</h2>
<p>Our use case for data is unique. Most cloud providers care highly about redundancy, availability, and data integrity, which tends to be unnecessary for ML training data. Since pretraining data is a commodity—we can lose any individual 5% with minimal impact—we can handle relatively large amounts of data corruption compared to enterprises who need guarantees that their user data isn’t going anywhere. In other words, we don’t need AWS’s 13 nines of reliability; 2 is more than enough.</p>
<p>Additionally, storage tends to be priced substantially above cost. Most companies use relatively small amounts of storage (even ones like Discord still use <a href="https://discord.com/blog/how-discord-stores-trillions-of-messages">under a petabyte</a> for messages), and the companies that use petabytes are so large that storage remains a tiny fraction of their total compute spend.</p>
<p>Data is one of our biggest contraints, and would be prohibitively expensive otherwise. As long as the cost predictions work out in favor of a local datacenter, and it would not consume too much of the core team’s time, it would make sense to stack hard drives ourselves. 

<span data-note-content="We talked to some engineers at the Internet Archive, which had basically the same problem as us; even after massive friends &amp; family discounts on AWS, it was still 10 times more cost-effective to buy racks and store the data themselves\! " data-number="1">
<sup data-sidenote="sidenote-0">[1]</sup>
<span id="sidenote-0">1. We talked to some engineers at the Internet Archive, which had basically the same problem as us; even after massive friends &amp; family discounts on AWS, it was still 10 times more cost-effective to buy racks and store the data themselves!</span>
</span></p>
<h2 id="the-cost-breakdown-cloud-alternatives-vs-in-house">The Cost Breakdown: Cloud Alternatives vs In-House</h2>
<p>Internet and electricity total $17.5k as our only recurring expenses (the price of colocation space, cooling, etc were bundled into electricity costs). One-time costs were dominated by hard drive capex. 

<span data-note-content=" When deciding the datacenter location we had multiple options across the Bay Area, including options in Fremont through Hurricane Electric for around $10k in setup fees and $12.8k per month, saving us $38.5k initially and $4.7k per month, but ended up opting for a datacenter that was only a couple blocks from our office in SF. Though this came at a premium, it was extremely helpful to get the initial nodes setup and for ongoing maintenance. Our team is just 5 people, so any friction in going to the datacenter would come at a noticeable cost to team productivity." data-number="2">
<sup data-sidenote="sidenote-1">[2]</sup>
<span id="sidenote-1">2. When deciding the datacenter location we had multiple options across the Bay Area, including options in Fremont through Hurricane Electric for around $10k in setup fees and $12.8k per month, saving us $38.5k initially and $4.7k per month, but ended up opting for a datacenter that was only a couple blocks from our office in SF. Though this came at a premium, it was extremely helpful to get the initial nodes setup and for ongoing maintenance. Our team is just 5 people, so any friction in going to the datacenter would come at a noticeable cost to team productivity.</span>
</span></p>
<p><img src="https://si.inc/the-heap/datacenter_cost_comparison.png" alt="cost comparison">
<em>Table 1: Cost comparison of cloud alternatives vs in-house. AWS is $1,130,000/month including estimated egress, Cloudflare is $270,000/month (with bulk-discounted pricing), and our datacenter is $29,500/month (including recurring costs and depreciation).</em></p>
<h3 id="monthly-recurring-costs">Monthly Recurring Costs</h3>
<table>
<thead>
<tr>
<th>Item</th>
<th>Cost</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Internet</td>
<td>$7,500/month</td>
<td>100Gbps DIA from Zayo, 1yr term.</td>
</tr>
<tr>
<td>Electricity</td>
<td>$10,000/month</td>
<td>1 kW/PB, $330/kW. Includes cabinet space &amp; cooling. 1yr term.</td>
</tr>
<tr>
<td><strong>Total Monthly</strong></td>
<td><strong>$17,500/month</strong></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="one-time-costs">One-Time Costs</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Item</th>
<th>Cost</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td>Storage</td>
<td>Hard drives (HDDs)</td>
<td>$300,000</td>
<td>2,400 drives. Mostly 12TB used enterprise drives (3/4 SATA, 1/4 SAS). The JBOD DS4246s work for either.</td>
</tr>
<tr>
<td>Storage Infrastructure</td>
<td>NetApp DS4246 chassis</td>
<td>$35,000</td>
<td>100 dual SATA/SAS chassis, 4U each</td>
</tr>
<tr>
<td>Compute</td>
<td>CPU head nodes</td>
<td>$6,000</td>
<td>10 Intel RR2000s from eBay</td>
</tr>
<tr>
<td>Datacenter Setup</td>
<td>Install fee</td>
<td>$38,500</td>
<td>One-off datacenter install fee</td>
</tr>
<tr>
<td>Labor</td>
<td>Contractors</td>
<td>$27,000</td>
<td>Contractors to help physically screw in / install racks and wire cables</td>
</tr>
<tr>
<td>Networking &amp; Misc</td>
<td>Install expenses</td>
<td>$20,000</td>
<td>Power cables, 100GbE QSFP CX4 NICs, Arista router, copper jumpers, one-time internet install fee</td>
</tr>
<tr>
<td><strong>Total One-Time</strong></td>
<td></td>
<td><strong>$426,500</strong></td>
<td></td>
</tr>
</tbody>
</table>
<p>Our price assuming three-year depreciation (including for the one-off install fees) is $17.5k/month in fixed monthly costs (internet, power, etc.) and $12k/month in depreciation, for $29.5k/month overall.</p>
<p>We compare our costs to two main providers: AWS’s public pricing numbers as a baseline, and Cloudflare’s discounted pricing for 30PB of storage. It’s important to note that AWS egress would be substantially lower if we utilized AWS GPUs. This is not reflected on our graph because AWS GPUs are priced at substantially above market prices and large clusters are difficult to attain, untenable at our compute scales.</p>
<p>Here are the pricing breakdowns:</p>
<h3 id="aws-pricing-breakdown">AWS Pricing Breakdown</h3>
<table>
<thead>
<tr>
<th>Cost Component</th>
<th>Rate</th>
<th>Monthly Cost</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Storage</td>
<td>$0.021/GB/month</td>
<td>$630,000</td>
<td>For data over 500TB</td>
</tr>
<tr>
<td>Egress</td>
<td>$0.05/GB</td>
<td>$500,000</td>
<td>Entire dataset egressed quarterly (10 PB/month)</td>
</tr>
<tr>
<td><strong>Total AWS Monthly</strong></td>
<td></td>
<td><strong>$1,130,000</strong></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="cloudflare-r2-pricing">Cloudflare R2 Pricing</h3>
<table>
<thead>
<tr>
<th>Pricing Tier</th>
<th>Rate</th>
<th>Monthly Cost</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Published Rate</td>
<td>$0.015/GB/month</td>
<td>$450,000</td>
<td>No egress fees</td>
</tr>
<tr>
<td>Estimated Private Pricing 

<span data-note-content="
Cloudflare has a more reasonable estimate for the 30 PB, placing it at an overall monthly cost of $270k without egress fees. We also have bulk-discounted pricing estimates after getting pricing quotes—this was our main point of comparison for the datacenter.
" data-number="3">
<sup data-sidenote="sidenote-2">[3]</sup>
<span id="sidenote-2">3. Cloudflare has a more reasonable estimate for the 30 PB, placing it at an overall monthly cost of $270k without egress fees. We also have bulk-discounted pricing estimates after getting pricing quotes—this was our main point of comparison for the datacenter.</span>
</span></td>
<td>$0.009/GB/month</td>
<td>$270,000</td>
<td>Estimated rate for &gt;20 PB scale</td>
</tr>
</tbody>
</table>
<p>That brings monthly costs to $38/TB/month for AWS, $10/TB/month for Cloudflare, and $1/TB/month for our datacenter—about 38x lower and 10x lower respectively. (At the very cheapest end of the spectrum, Backblaze has a $6/TB product that is unsuitable for model training due to egress speed limitations; their $15/TB Overdrive AI-specific storage product is closer to Cloudflare’s in price &amp; performance)</p>
<p>While we use Cloudflare as a comparison point, we’ve sometimes done too much load for their R2 servers. In particular, in the past we’ve done enough load during large model training runs that they rate-limited us, later confirming we were saturating their metadata layer and the rate limit wasn’t synthetic. Because our metadata on the heap is so simple, and we have a 100Gbps DIA connection, we haven’t ran into any issues there. 

<span data-note-content=" We love Cloudflare and use many of their products often; we include this anecdote as a fact about our scale being difficult to handle, not as a dig! " data-number="4">
<sup data-sidenote="sidenote-3">[4]</sup>
<span id="sidenote-3">4. We love Cloudflare and use many of their products often; we include this anecdote as a fact about our scale being difficult to handle, not as a dig!</span>
</span></p>
<p>This setup was and is necessary for our video data pipelines, and we’re extremely happy that we made this investment. By gathering large scale data at low costs, we can be competitive with frontier labs with billions of dollars in capital.</p>
<h2 id="setupthe-process">Setup/The Process</h2>
<p>We cared a lot about getting this built <em>fast</em>, because this kind of project can easily stretch on for months if not careful. Hence Storage Stacking Saturday, or S3. We threw a hard drive stacking party in downtown SF and got our friends to come, offering food and custom-engraved hard drives to all who helped. The hard drive stacking started at 6am and continued for 36 hours (with a break to sleep), and by the end of that time we had 30 PB of functioning hardware racked and wired up. We brought in contractors for additional help and professional installation later on in the event.</p>
<p><img src="https://si.inc/the-heap/server-people.png" alt="hard drive stacking party">
<em>People at the hard drive stacking party!</em>
<img src="https://si.inc/the-heap/server.png" alt="hard drive stacking party">
<em>Cool shots of the servers</em></p>
<p>Our software is 200 lines of Rust code for writing (to determine the drive to write data onto) and a nginx webserver for reading data, with a simple SQLite db for tracking metadata like which heap node each file is on and what data split it belongs to. We kept this obsessively simple instead of using MinIO or Ceph because we didn’t need <em>any</em> of the features they provided; it’s much, much simpler to debug a 200-line program than to debug Ceph, and we weren’t worried about redundancy or sharding. All our drives were formatted with XFS.</p>
<p>The storage software landscape offers many options, but every option available comes with drawbacks. People experienced with Ceph strongly warned us to avoid it unless we were willing to hire dedicated Ceph specialists—our research confirmed this advice. Ceph appears far more complex than justified for most use cases, only worthwhile for companies that absolutely need maximum performance and customizability and are prepared to invest heavily in tuning. Minio presents an interesting option if S3 compatibility is essential, but otherwise remains a bit too fancy for us and similar use-cases. Weka and Vast are absurdly expensive at 2k / TB / year or so and are primarily designed for NVMEs, not spinning disks.</p>
<h2 id="post-mortem">Post-Mortem</h2>
<p>Building the datacenter was a large endeavor and we definitely learned lessons, both good and bad.</p>
<h3 id="things-that-we-got-correct">Things That We Got Correct</h3>
<ul>
<li>We think the redundancy &amp; capability tradeoffs we made are very reasonable at our disk speeds. We’re able to approximately saturate our 100G network for both read &amp; write.</li>
<li>Doing this locally a couple blocks away was well worth it because of the amount of debugging and manual work needed.</li>
<li>Ebay is good to find vendors but bad to actually buy things with. After finding vendors, they can often individually supply all the parts we need and provide warranties, which are extremely valuable.</li>
<li>100G dedicated internet is pretty important, and much much easier to debug issues with than using cloud products.</li>
<li>Having high-quality cable management during the racking process saved us a ton of time debugging in the long run; making it easy to switch up the networking saved us a lot of headache.</li>
<li>We had a very strong simplicity prior, and this saved an immense amount of effort. We are quite happy that we didn’t use ceph or minio. Unlike e.g. nginx, they do not work out of the box. We were willing to write a simple Rust script and roughly saturated our network read &amp; write at 100 Gbps without any fancy code.</li>
<li>We were basically right about the price and advantages this offered, and did not substantially overestimate the amount of time / effort it would take. While the improvements list is longer than this, <em>most of those are minor; fundamentally we built a cluster rivaling massive clouds for 40x cheaper.</em></li>
</ul>
<h3 id="difficult-bits">Difficult Bits</h3>
<p>A map of reality only gets you so far—while setting up the datacenter we ran into a couple problems and unexpected challenges. We’ll include a list:</p>
<ul>
<li>We used frontloaders instead of toploaders for our server rack. This meant we had to screw every single individual drive in—tedious for 2.4k HDDs</li>
<li>Our storage was not dense—we could have saved 5x the work on physical placement and screwing by having a denser array of hard drives</li>
<li>Shortcuts like daisy-chaining are usually a bad idea. We could have gotten substantially higher read/write speeds without daisy chaining networked nodes, giving each chassis its own HBA (Host Bus Adapter, not a significant cost).</li>
<li>Compatibility is key—specifically in networking functionally everything is locked to a specific brand. We had many pain points here. Fiber transceivers will ~never work unless used with the right brand, but copper cables are much more forgiving. <a href="http://fs.com/">FS.com</a> is pretty good and well priced (though their speed estimates were pretty inconsistent); Amazon will also often have the parts you need rapidly.</li>
<li>Networking was a substantial cost and required experimentation. We did not use DHCP as most enterprise switches don’t support it and we wanted public IPs for the nodes for convenient and performant access from our servers. While this is an area where we would have saved time with a cloud solution, we had our networking up within days and kinks ironed out within ~3 weeks.</li>
<li>We were often bottlenecked by easy access to servers via monitor/keyboard; idle crash carts during setup are helpful.</li>
</ul>
<h3 id="ideas-worth-trying">Ideas Worth Trying</h3>
<ul>
<li>Working KVMs are extremely useful, and you shouldn’t go without them or good IPMI. Physically going to a datacenter is really inconvenient, even if it’s a block away. IPMI is good, but only if you have pretty consistent machines.</li>
<li>Think through your management Ethernet network as much as your real network - it’s really nice to be able to SSH into servers while configuring the network, and IPMI is great!</li>
<li>Overprovision your network—e.g. if doable it’s worth having 400 Gigabit internally (you can use 100G cards etc for this!)</li>
<li>We could have substantially increased density at additional upfront cost by buying 90-drive SuperMicro SuperServers and putting 20TB drives into them. This would allow us to use 2 racks instead of 10, given us had about the equivalent of 20 AMD 9654s in total CPU capacity, and used less total power.</li>
</ul>
<h2 id="how-you-can-build-this-yourself">How You Can Build This Yourself</h2>
<p>Here’s what you need to replicate our setup.</p>
<h3 id="storage">Storage</h3>
<ul>
<li>
<p>10 CPU head nodes.</p>
<ul>
<li>We used Intel Rr2000 with Dual Intel Gold 6148 and 128GB of DDR4 ECC RAM per server (which are incredibly cheap and roughly worked for our use cases) but you have a lot of flexibility in what you use.</li>
<li>If you use the above configuration you likely won’t be able to do anything at all CPU-intensive on the servers (like on-device data processing or ZFS data compression / deduplication / etc, which is valuable if you’re storing non-video data).</li>
<li>Our CPU nodes cost $600 each—it seems quite reasonable to us to spend up to $3k each if you want ZFS / compression or the abiliy to do data processing on-CPU.</li>
</ul>
</li>
<li>
<p>100 DS4246 chassis—each can hold 24 hard drives.</p>
</li>
<li>
<p>2,400 3.5 inch HDDs—need to be all SATA or all SAS in each chassis.</p>
<ul>
<li><em>We would recommend SAS hard drives if possible</em>

<span data-note-content="if you use SAS drives you’ll need to deal with or disable mulipathing, which is reasonably simple" data-number="5">
<sup data-sidenote="sidenote-4">[5]</sup>
<span id="sidenote-4">5. if you use SAS drives you’ll need to deal with or disable mulipathing, which is reasonably simple</span>
</span> as they roughly double speed over similar SATA drives.</li>
<li>We used a mix of 12TB and 14TB drives—basically any size should work, roughly the larger the better holding price constant (density makes stacking easier + in general increases resale value).</li>
</ul>
</li>
<li>
<p>Physical parts to mount the chassis—you’ll need rails or l-brackets. We used l-brackets which worked well, as we haven’t needed to take the chassis out to slot hard drives. If you buy toploaders, you’ll need rails.</p>
</li>
<li>
<p>Multiple “crash carts” with monitors and keyboards that allow you to physically connect to your CPU head nodes and configure them—this is invaluable when you’re debugging network issues.</p>
</li>
</ul>
<h3 id="network">Network</h3>
<ul>
<li>
<p>A 100 GbE switch</p>
<ul>
<li>a used Arista is fine, should be QSFP28, should cost about $1-2k</li>
</ul>
</li>
<li>
<p>HBAs (Host Bus Adapters), which connect your head nodes to your DS4246 chassis.</p>
<ul>
<li>The best configuration we tried was with Broadcom 9305-16E HBAs, with 3x HBAs per server (make sure your server has physical space for them!) with SFF-8644 to QSFP mini SAS cables.</li>
<li>There are 4 slots per HBA, so you can cable each DS4246 chassis directly to the HBA.


<span data-note-content="The option we ended up going with for convenience was putting LSI SAS9207-8e HBAs, which have 2 ports each, into the CPU head nodes- then daisy-chaining the DS4246s together with QSFP+ to QSFP+ DACs.. We deployed this on Storage Stacking Saturday, then while debugging speeds tried the above method on one of the servers and got to \~4 Gbps per chassis-but didn’t find it worth it to swap everything out in pure labor because of the way we had set up some of our head nodes such that they were difficult to take out. Insofar as it is reasonably cheap to just do the above thing to start and we’ve tested it to work, you should probably do as we say, not as we did in this case\!" data-number="6">
<sup data-sidenote="sidenote-5">[6]</sup>
<span id="sidenote-5">6. The option we ended up going with for convenience was putting LSI SAS9207-8e HBAs, which have 2 ports each, into the CPU head nodes- then daisy-chaining the DS4246s together with QSFP+ to QSFP+ DACs.. We deployed this on Storage Stacking Saturday, then while debugging speeds tried the above method on one of the servers and got to ~4 Gbps per chassis-but didn’t find it worth it to swap everything out in pure labor because of the way we had set up some of our head nodes such that they were difficult to take out. Insofar as it is reasonably cheap to just do the above thing to start and we’ve tested it to work, you should probably do as we say, not as we did in this case!</span>
</span></li>
</ul>
</li>
<li>
<p>Network cards (NICs).</p>
<ul>
<li>We used Mellanox ConnectX-4 100GbE. Make sure they come in Ethernet mode and not Infiniband mode for ease of config.</li>
</ul>
</li>
<li>
<p>DAC (Direct Attach Copper) or AOC (Active Optical) cables, to connect the NICs in your head nodes to your switch and therefore the internet. You almost certainly want DACs if your racks are close together, as they are far more compatible with arbitrary networking equipment than AOCs.</p>
</li>
</ul>
<p>We would recommend that you find a supplier to sell you the CPU head nodes with the HBAs and NICs installed—there are a number of used datacenter / enterprise parts suppliers who are willing to do this. This is a substantial positive because it means that you don’t have to spend hours installing the HBAs/NICs yourself and can have a substantially higher degree of confidence in your operations.</p>
<ul>
<li>
<p>Serial cables—you’ll need these to connect to your switch!</p>
</li>
<li>
<p><strong>Optional but recommended:</strong> an Ethernet management network of some kind. If you can’t easily get ethernet, we’d recommend getting a wifi adapter <a href="https://www.amazon.com/BrosTrend-600Mbps-Adapter-Wireless-WNA016/dp/B0118SPFCK">like this</a> and then a ethernet switch <a href="https://www.amazon.com/Ethernet-Splitter-Optimization-Unmanaged-TL-SG105/dp/B00A128S24">like this</a> —it’s substantially easier to set up than the 100GbE, is a great backup for when that’s not working, and will allow you to do ~everything over SSH from the comfort of the office instead of in the datacenter.</p>
</li>
</ul>
<h3 id="datacenter-requirements">Datacenter Requirements</h3>
<ul>
<li>3.5 kW of usable power per cabinet, with 10 4U chassis + 1 2U (cabinets are 42U tall)</li>
<li>1 spare cabinet for the 1U or 2U 100GbE switch (you can obviously also just swap out one of the 4U chassis in another cabinet for the switch).</li>
<li>1 42U cabinet per 3 PB of storage</li>
<li>A dedicated 100G connection (will come in as a fiber pair probably via <a href="https://www.fs.com/products/104860.html">QSFP28 LR4</a>, but confirm with your datacenter provider before buying parts here!)</li>
<li>Ideally physically near your office—there is a lot of value in being able to walk over and debug issues instead of e.g. dealing with remote hands services to get internet to the nodes.</li>
</ul>
<p><strong>Some setup tips:</strong></p>
<ul>
<li>Make sure to first properly configure your switch. Depending on your switch model this should be relatively straightforward—you’ll need to physically connect to the switch and then configure the specific port that your 100GbE is connected to (you’ll get a fiber cross-connect from your datacenter that you should plug into a QSFP28 transceiver. <strong>Make sure that you get a transceiver that is compatible in form with the ISP, probably LR4, and specifically branded with your switch brand, otherwise it is very unlikely to work).</strong> Depending on your ISP you might have to talk to them to make sure that you can get “light” through the fiber cables from both ends, which might involve <a href="https://www.youtube.com/watch?v=OKtF97VT8ts">rolling the fiber</a> and otherwise making sure it’s working properly.
<ul>
<li>If your switch isn’t working / you haven’t configured one before, I’d suggest trying to directly plug the fiber cable from the ISP into one of your 10 heap servers, making sure to buy a transceiver that is compatible with your NIC brand (e.g. Mellanox). Once you get it working from there, move over to your switch and get it working.</li>
</ul>
</li>
<li>Once you can connect to the internet from your switch (simply ping 1.1.1.1 to check) you are ready to set up the netplans for the individual nodes. <strong>this is most easily done during the Ubuntu setup process, which will walk you through setting up internet for your CPU head nodes</strong>, but is also doable outside of that</li>
</ul>
<p>Once you have internet access to your nodes and have properly connected 1 cable to each DS4246, you should format &amp; mount the drives on each node, test that all of them are properly working, and then you are ready to deploy any software you want.</p>
<hr>
<p>If you end up building a similar storage cluster based on this writeup we’d love to hear from you—we’re very curious what can be improved, both in our guidance and in the object-level process. You can reach us at <a href="https://si.inc/cdn-cgi/l/email-protection#4d2e2223392c2e390d3e246324232e"><span data-cfemail="73101c1d0712100733001a5d1a1d10">[email&nbsp;protected]</span></a></p>
<p>If you came away from this post excited about our work, we’d love to chat. We’re a research lab currently focused on pretraining models to use computers, with the long-term goal of building general models that can learn in-context and do arbitrary tasks while aligned with human values; we’re hiring top researchers and engineers to help us train these. If you’re interested in chatting, shoot us an email at <a href="https://si.inc/cdn-cgi/l/email-protection#a2c8cdc0d1e2d1cb8ccbccc1"><span data-cfemail="63090c011023100a4d0a0d00">[email&nbsp;protected]</span></a>.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Autism Simulator (415 pts)]]></title>
            <link>https://autism-simulator.vercel.app/</link>
            <guid>45438346</guid>
            <pubDate>Wed, 01 Oct 2025 14:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://autism-simulator.vercel.app/">https://autism-simulator.vercel.app/</a>, See on <a href="https://news.ycombinator.com/item?id=45438346">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Unix philosophy and filesystem access makes Claude Code amazing (165 pts)]]></title>
            <link>https://www.alephic.com/writing/the-magic-of-claude-code</link>
            <guid>45437893</guid>
            <pubDate>Wed, 01 Oct 2025 14:05:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alephic.com/writing/the-magic-of-claude-code">https://www.alephic.com/writing/the-magic-of-claude-code</a>, See on <a href="https://news.ycombinator.com/item?id=45437893">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>If you've talked to me lately about AI, you've almost certainly been subject to a long soliloquy about the wonders of Claude Code. What started as a tool I ran in parallel with other tools to aid coding has turned into my full-fledged agentic operating system, supporting all kinds of workflows.</p><div><p>Most notably, <a href="https://obsidian.md/"><span>Obsidian</span></a>, the tool I use for note-taking. The difference between Obsidian and Notion or Evernote is that all the files are just plain old Markdown files stored on your computer. You can sync, style, and save them, but ultimately, it's still a text file on your hard drive. A few months ago, I realized that this fact made my Obsidian notes and research a particularly interesting target for AI coding tools. What first started with trying to open my vault in <a href="https://cursor.com/"><span>Cursor</span></a> quickly moved to a sort of note-taking operating system that I grew so reliant on, I ended up standing up a server in my house so I could connect via SSH from my phone into my Claude Code + Obsidian setup and take notes, read notes, and think through things on the go.</p><p><img alt="CleanShot 2025-09-30 at 09.48.05@2x.png" height="2010" src="https://www.alephic.com/api/media/file/CleanShot%202025-09-30%20at%2009.48.05%402x.png" width="3248"></p><p>A few weeks ago, I went on <a href="https://every.to/podcast/how-to-use-claude-code-as-a-thinking-partner"><span>Dan Shipper's AI &amp; I Podcast</span></a> to wax poetic about my love for this setup. I did a pretty deep dive into the system I use, how it works, why it works, etc. I won't retread all those details—you can read the transcript or listen to the podcast—but I want to talk about a few other things related to Claude Code that I've come to realize since the conversation.</p><h2>Why is Claude Code special? What makes it better than Cursor?</h2><p>I've really struggled to answer this question. I'm also not sure it's better than Cursor for all things, but I do think there are a set of fairly exceptional pieces that work together in concert to make me turn to Claude Code whenever I need to build anything these days. Increasingly, that's not even about applying it to existing codebases as much as it's building entirely new things on top of its functionality (more on that in a bit).</p><p>So what's the secret? Part of it lies in how Claude Code approaches tools. As a terminal-based application, it trades accessibility for something powerful: native Unix command integration. While I typically avoid long blockquotes, the <a href="https://en.wikipedia.org/wiki/Unix_philosophy"><span>Unix Philosophy</span></a> deserves an exception—Doug McIlroy's original formulation captures it perfectly:</p><p>The Unix philosophy is documented by <a href="https://en.wikipedia.org/wiki/Doug_McIlroy"><span>Doug McIlroy</span></a> in the <a href="https://en.wikipedia.org/wiki/Bell_System_Technical_Journal"><span>Bell System Technical Journal</span></a> from 1978:</p><ol><li value="1"><ol><li value="1">Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new "features".</li><li value="2">Expect the output of every program to become the input to another, as yet unknown, program. Don't clutter output with extraneous information. Avoid stringently columnar or binary input formats. Don't insist on interactive input.</li><li value="3">Design and build software, even operating systems, to be tried early, ideally within weeks. Don't hesitate to throw away the clumsy parts and rebuild them.</li><li value="4">Use tools in preference to unskilled help to lighten a programming task, even if you have to detour to build the tools and expect to throw some of them out after you've finished using them.</li></ol></li></ol><p>It was later summarized by <a href="https://en.wikipedia.org/wiki/Peter_H._Salus"><span>Peter H. Salus</span></a> in A Quarter-Century of Unix (1994):</p><ul><li value="1"><ul><li value="1">Write programs that do one thing and do it well.</li><li value="2">Write programs to work together.</li><li value="3">Write programs to handle text streams, because that is a universal interface.</li></ul></li></ul><p>These fifty-year-old principles are exactly how LLMs want to use tools. If you look at how these models actually use the tools they're given, they are constantly "piping" output to input (albeit using their own fuzziness in between). (As an aside, the Unix | command allows you to string the output from one command into the input of another.) When models fail to weld their tools effectively, it is almost always because the tools are overly complex.</p><p><img alt="CleanShot 2025-09-30 at 09.49.30.gif" height="628" src="https://www.alephic.com/api/media/file/CleanShot%202025-09-30%20at%2009.49.30.gif" width="800"></p><p>So part one of why Claude Code can be so mind-blowing is that the commands that power Unix happen to be perfectly suited for use by LLMs. This is both because they're simple and also incredibly well-documented, meaning the models had ample source material to teach them the literal ins and outs.</p><p>But that still wasn't the whole thing. The other piece was obviously Claude Code's ability to write code initially and, more recently, prose (for me, at least). But while other applications like ChatGPT and Claude can write output, there was something different going on here. Last week, while reading <a href="https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built"><span>The Pragmatic Engineer's deep dive into how Claude Code is built</span></a>. The answer was staring me in the face: filesystem access.&nbsp;</p><p>The filesystem changes everything. ChatGPT and Claude in the browser have two fatal flaws: no memory between conversations and a cramped context window. A filesystem solves both. Claude Code writes notes to itself, accumulates knowledge, and keeps running tallies. It has state and memory. It can think beyond a single conversation.</p><h2>AI Overhang</h2><p>Back in 2022, when I first played with the GPT-3 API, I said that even if models never got better than they were in that moment, we would still have a decade to discover the use cases. They did get better—reasoning models made tool calling reliable—but the filesystem discovery proves my point.</p><p>I bring this up because <a href="https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built">in the Pragmatic Engineer interview</a>, Boris Cherney, who built the initial version of Claude Code, uses it to describe the aha:</p><p>In AI, we talk about “product overhang”, and this is what we discovered with the prototype.&nbsp;Product overhang means that a model is able to do a specific thing, but the product that the AI runs in isn’t built in a way that captures this capability. What I discovered about Claude exploring the filesystem was pure product overhang. The model could already do this, but there wasn’t a product built around this capability!</p><p>Again, I'd argue it's filesystem + Unix commands, but the point is that the capability was there in the model just waiting to be woken up, and once it was, we were off to the races. Claude Code works as a blueprint for building reliable agentic systems because it captures model capabilities instead of limiting them through over-engineered interfaces.</p><h2>Going Beyond Code</h2><p>I talked about my Claude Code + Obsidian setup, and I've actually taken it a step further by open-sourcing "<a href="https://github.com/heyitsnoah/claudesidian"><span>Claudesidian</span></a>," which pulls in a bunch of the tools and commands I use in my own Claude Code + Obsidian setup. It also goes beyond that and was a fun experimental ground for me. Most notably, I built an initial upgrade tool so that if changes are made centrally, you can pull them into your own Claudesidian, and the AI will help you check to see if you've made changes to the files being updated and, if so, attempt to smartly merge your changes with the new updates. Both projects follow the same Unix philosophy principles—simple, composable tools that do one thing well and work together. This is the kind of stuff that Claude Code makes possible, and why it's so exciting for me as a new way of building applications.</p><p>Speaking of which, one I'm not quite ready to release, but hopefully will be soon, is something I've been calling "Inbox Magic," though I'll surely come up with a better name. It's a Claude Code repo with access to a set of Gmail tools and a whole bunch of prompts and commands to effectively start operating like your own email EA. Right now, the functionality is fairly simple: it can obviously run searches or send emails on your behalf, but it can also do things like triage and actually run a whole training run on how you sound over email so it can more effectively draft emails for you. While Claude Code and ChatGPT both have access to my emails, they mostly grab one or two at a time. This system, because it can write things out to files and do lots of other fancy tricks, can perform a task like “find every single travel-related email in my inbox and use that to build a profile of my travel habits that I can use as a prompt to help ChatGPT/Claude do travel research that's actually aligned with my preferences.” Anyway, more on this soon, and if it's something you want to try out, ping me with your GitHub username, and as soon as I feel like I have something ready to test, I'll happily share it.</p><h2>A Few Takeaways</h2><p>While I generally shy away from conclusions, I think there are a few here worth reiterating.</p><ol><li value="1">The filesystem is a great tool to get around the lack of memory and state in LLMs and should be used more often.</li><li value="2">If you're trying to get tool calling working, focus on following the Unix philosophy.</li><li value="3">Claude Code represents a blueprint for future agentic systems—filesystem + Unix philosophy should be the template for building reliable, debuggable AI agents rather than complex multi-agent stuff that's floating around today. Tactically, this means when you’re building tool calling into your own projects, keeping them simple and letting the main model thread “pipe” them is the key. (As an aside, one big problem that needs to be solved in all these agents/chatbots is the ability to pipe things without it going through the context window.)</li><li value="4">Anyone who can't find use cases for LLMs isn't trying hard enough</li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cursor 1.7 (132 pts)]]></title>
            <link>https://cursor.com/changelog/1-7</link>
            <guid>45437735</guid>
            <pubDate>Wed, 01 Oct 2025 13:51:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cursor.com/changelog/1-7">https://cursor.com/changelog/1-7</a>, See on <a href="https://news.ycombinator.com/item?id=45437735">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3 id="autocomplete-for-agent"><a href="#autocomplete-for-agent">Autocomplete for Agent</a></h3><p>When writing prompts, autocomplete suggestions will appear based on recent changes. Tab to accept suggestions and attach files to context.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/c59180ab6509a4c8cc6fe61d3cf7c36dd7ad4148.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="hooks-beta"><a href="#hooks-beta">Hooks (beta)</a></h3><p>You can now observe, control, and extend the Agent loop using custom scripts. Hooks give you a way to customize and influence Agent behavior at runtime.</p><p>Use Hooks to audit Agent usage, block commands, or redact secrets from context. It's still in beta and we'd love to hear your feedback.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/6bfb19e08fdc2162242aa94642df48cff1d7e680.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="team-rules"><a href="#team-rules">Team rules</a></h3><p>Teams can now define and share global rules from the dashboard that will be applied to all projects. We’ve also shipped team rules for <a href="https://cursor.com/bugbot">Bugbot</a>, so behavior is consistent across repos.</p><figure></figure><p>Generate shareable deeplinks for reusable prompts. Useful for setup instructions in documentation, team resources, and sharing workflows. See our <a href="https://cursor.com/docs/integrations/deeplinks">documentation</a> for how to create them.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/8df68e08d1ec72cb5c16b9e29580c1e8be1a10dd.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="sandboxed-terminals"><a href="#sandboxed-terminals">Sandboxed terminals</a></h3><p>Commands now execute in a secure, sandboxed environment. If you’re on allowlist mode, non-allowlisted commands will automatically run in a sandbox with read/write access to your workspace and no internet access.</p><p>If a command fails and we detect the sandbox was the cause, you’ll be prompted to retry outside of the sandbox.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/988f922156ea31ea5c4defb3f9d4a049e359b252.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><p>Quickly check the status of Cursor Agents right from your menubar.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/eb50983a08b4878f422c8fb6166e04453dd5a58f.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure><h3 id="image-file-support-for-agent"><a href="#image-file-support-for-agent">Image file support for Agent</a></h3><p>Agent can now read image files directly from your workspace and include them in context. Previously, only pasted images were supported.</p><figure><video src="https://cdn.sanity.io/files/2hv88549/production/0d33834548eb1bbe7aae74f2e749b7d2b9d6d45d.mp4" autoplay="" loop="" muted="" playsinline=""></video></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ChartDB Agent – Cursor for DB schema design (101 pts)]]></title>
            <link>https://app.chartdb.io/ai</link>
            <guid>45437594</guid>
            <pubDate>Wed, 01 Oct 2025 13:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.chartdb.io/ai">https://app.chartdb.io/ai</a>, See on <a href="https://news.ycombinator.com/item?id=45437594">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Minimal files and config for a PWA (131 pts)]]></title>
            <link>https://github.com/chr15m/minimal-pwa</link>
            <guid>45437326</guid>
            <pubDate>Wed, 01 Oct 2025 13:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/chr15m/minimal-pwa">https://github.com/chr15m/minimal-pwa</a>, See on <a href="https://news.ycombinator.com/item?id=45437326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      



    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>

      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p>

<react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  
  
</react-partial>





      

          

              




<header role="banner" data-is-top="true" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      

      <div>
        <div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>
          GitHub Copilot

        </p><p>

        Write better code with AI
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
        <p>
          GitHub Spark

            <span>
              New
            </span>
        </p><p>

        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
        <p>
          GitHub Models

            <span>
              New
            </span>
        </p><p>

        Manage and compare prompts
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>
          GitHub Advanced Security

        </p><p>

        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>
          Actions

        </p><p>

        Automate any workflow
      </p></div>

    
</a></li>

                  </ul>
                </div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>
          Codespaces

        </p><p>

        Instant dev environments
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>
          Issues

        </p><p>

        Plan and track work
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>
          Code Review

        </p><p>

        Manage code changes
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>
          Discussions

        </p><p>

        Collaborate outside of code
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>
          Code Search

        </p><p>

        Find more, search less
      </p></div>

    
</a></li>

                  </ul>
                </div>
            
        </div>

          <p>
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              
</a>          </p>
      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>

                      <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                      <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://github.com/partners">
      Partners

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
      

      <div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>
          GitHub Sponsors

        </p><p>

        Fund open source developers
      </p></div>

    
</a></li>

                  </ul>
                </div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>
          The ReadME Project

        </p><p>

        GitHub community articles
      </p></div>

    
</a></li>

                  </ul>
                </div>
                
            </div>
</li>


                <li>
      

      <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>
          Enterprise platform

        </p><p>

        AI-powered developer platform
      </p></div>

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:chr15m/minimal-pwa" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="m1iT7lo9LlWcjZIU5mQgCKXl1-KrcgGuINf6XNpLMWXY0tKmv0w-I64Xn52PlAeH99xzGeJX3_8yqNKtDaAcpg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="chr15m/minimal-pwa" data-current-org="" data-current-owner="chr15m" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=chr15m%2Fminimal-pwa" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/chr15m/minimal-pwa&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d26cbfff95843f3710249c937aee2c8e38ec6ac3f667c6f5be2db9c37918a046" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-f197728f-3b54-4d92-82b1-03a5c5de041b" for="icon-button-ed09aa16-7e48-41bb-9455-f3380047c5bd" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div>
</header>

      
    </div>

  








    


    






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-project-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  





    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div data-view-component="true" id="repo-content-pjax-container">      

<react-partial partial-name="repos-overview" data-ssr="true" data-attempted-ssr="true" data-react-profiling="false">
  
  
  <div data-target="react-partial.reactRoot"><div itemscope="" itemtype="https://schema.org/abstract"><h2>Repository files navigation</h2><nav aria-label="Repository files" data-variant="inset"><ul role="list"><li><a href="#" aria-current="page"><span data-component="icon"></span><span data-component="text" data-content="README">README</span></a></li></ul></nav></div><div data-hpc="true"><article itemprop="text"><p dir="auto">This is the minimal set of files for a "progressive web app" to be installable on Android and iOS.</p>
<p dir="auto">It contains the smallest possible <code>manifest.json</code> and service worker to trigger the install flow on Chrome.</p>
<p dir="auto">An even smaller implementation that fits in a single HTML file is in <a href="https://github.com/chr15m/minimal-pwa/blob/main/single-file-pwa.html">single-file-pwa.html</a>. It has a manifest.json that is dynamically generated from JavaScript, and it is installable without a service worker.</p>
</article></div></div>
</react-partial>


      </div>

</turbo-frame>


    </main>
  </div>

          



    <ghcc-consent id="ghcc" data-locale="en" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>




  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Detect Electron apps on Mac that hasn't been updated to fix the system wide lag (148 pts)]]></title>
            <link>https://gist.github.com/tkafka/e3eb63a5ec448e9be6701bfd1f1b1e58</link>
            <guid>45437112</guid>
            <pubDate>Wed, 01 Oct 2025 12:54:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/tkafka/e3eb63a5ec448e9be6701bfd1f1b1e58">https://gist.github.com/tkafka/e3eb63a5ec448e9be6701bfd1f1b1e58</a>, See on <a href="https://news.ycombinator.com/item?id=45437112">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Detect Electron apps on mac where the Electron hasn't yet been updated to fix the system wide lag
  </p><div id="file-readme-md" tabindex="0" role="region" aria-label="README.md content, created by tkafka on 12:53PM today.">
    <article itemprop="text"><p dir="auto"><h2 dir="auto">Electron Apps Causing System-Wide Lag on Tahoe</h2><a id="user-content-electron-apps-causing-system-wide-lag-on-tahoe" aria-label="Permalink: Electron Apps Causing System-Wide Lag on Tahoe" href="#electron-apps-causing-system-wide-lag-on-tahoe"></a></p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><a data-error-text="Failed to load title" data-id="3412185866" data-permission-text="Title is private" data-url="https://github.com/electron/electron/issues/48311" data-hovercard-type="issue" data-hovercard-url="/electron/electron/issues/48311/hovercard?comment_id=3332181420&amp;comment_type=issue_comment" href="https://github.com/electron/electron/issues/48311#issuecomment-3332181420">electron/electron#48311 (comment)</a></li>
<li><a href="https://mjtsai.com/blog/2025/09/30/electron-apps-causing-system-wide-lag-on-tahoe/" rel="nofollow">https://mjtsai.com/blog/2025/09/30/electron-apps-causing-system-wide-lag-on-tahoe/</a></li>
</ul>
<p dir="auto">Fixed versions:</p>
<ul dir="auto">
<li>36.9.2</li>
<li>37.6.0</li>
<li>38.2.0</li>
<li>39.0.0</li>
<li>and all above 39</li>
</ul>
<p dir="auto">This script detects apps with not yet updated versions of Electron.</p>
<p dir="auto"><h2 dir="auto">Temporary workaround:</h2><a id="user-content-temporary-workaround" aria-label="Permalink: Temporary workaround:" href="#temporary-workaround"></a></p>
<p dir="auto">Run</p>
<div dir="auto"><pre>launchctl setenv CHROME_HEADLESS 1</pre></div>
<p dir="auto">on every system start. The CHROME_HEADLESS flag has a side effect of disabling Electron app window shadows, which makes them ugly, but also stops triggering the issue.</p>
<p dir="auto"><h2 dir="auto">Example output</h2><a id="user-content-example-output" aria-label="Permalink: Example output" href="#example-output"></a></p>
<p dir="auto">(as of 1st oct 2025 - it lists all electron apps, but none shows the ✅ checkmark so far)</p>
<pre><code>❌ OpenMTP.app: Electron 18.3.15 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ DaVinci Resolve.app: Electron 36.3.2 (Contents/Applications/Electron.app/Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Electron.app: Electron 36.3.2 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Visual Studio Code.app: Electron 37.3.1 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Cursor.app: Electron 34.5.8 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Windsurf.app: Electron 34.4.0 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Claude.app: Electron 36.4.0 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Signal.app: Electron 38.1.2 (Contents/Frameworks/Electron Framework.framework/Electron Framework)
❌ Figma Beta.app: Electron 37.5.1 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Beeper Desktop.app: Electron 33.2.0 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
❌ Slack.app: Electron 38.1.2 (Contents/Frameworks/Electron Framework.framework/Versions/A/Electron Framework)
</code></pre>
<p dir="auto"><h2 dir="auto">A bit of promo</h2><a id="user-content-a-bit-of-promo" aria-label="Permalink: A bit of promo" href="#a-bit-of-promo"></a></p>
<p dir="auto">If you'd appreciate a visual (Tufte-like) hour by hour forecast for iOS/Apple Watch/mac with nice widgets, I made one - check out 🌦️ <a href="https://apps.apple.com/app/apple-store/id1501958576" rel="nofollow">Weathergraph</a>.</p>
<p dir="auto">Thanks! Tomas</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TigerBeetle is a most interesting database (282 pts)]]></title>
            <link>https://www.amplifypartners.com/blog-posts/why-tigerbeetle-is-the-most-interesting-database-in-the-world</link>
            <guid>45436534</guid>
            <pubDate>Wed, 01 Oct 2025 11:33:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amplifypartners.com/blog-posts/why-tigerbeetle-is-the-most-interesting-database-in-the-world">https://www.amplifypartners.com/blog-posts/why-tigerbeetle-is-the-most-interesting-database-in-the-world</a>, See on <a href="https://news.ycombinator.com/item?id=45436534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>By many measures it’s safe to say that TigerBeetle is the most interesting database in the world. Like Costanza in Seinfeld, they seem to do the <em>opposite</em> of everyone else:</p><ul role="list"><li>Most teams write code fast. TigerBeetle tries to <strong>write code slow</strong>.</li><li>Most teams treat testing as a necessary evil. TigerBeetle is <strong>built entirely on Deterministic Simulation Testing (DST)</strong>.</li><li>Most teams build their software on top of loads of other software. TigerBeetle <strong>has zero dependencies</strong>.</li></ul><p>There’s even more. TigerBeetle enforces static memory allocation. They keep assertions enabled in production. They chose Viewstamped Replication over Raft, and even Zig instead of Rust!</p><p>This read is going to go behind the scenes of how TigerBeetle came to be, the incredibly novel software they’ve built, and all of the wacky, wonderful things that make them so special. Based on extensive interviews with the TigerBeetle team, we’re going to cover a few topics in technical detail:</p><ul role="list"><li>Why transactional databases should think in debits and credits, not SQL</li><li>An (actually) modern database: distributed by default, handling storage faults, and why TigerBeetle uses Zig</li><li>VOPR, TigerBeetle’s Deterministic Simulation Testing cluster</li><li>TigerStyle, and why you should use assertions</li></ul><p>Click on any section to jump straight there, if you’re curious.&nbsp;&nbsp;</p><h2><strong>Why we need a database that thinks in debits and credits</strong></h2><p>TigerBeetle’s website calls it “The Financial Transactions Database.” Its primitives are <strong>debits and credits</strong>, which are things you may be familiar with from your accounting requirement in college. And if you’re not a bank, you’re probably thinking this whole thing isn’t really for you. But Joran (TigerBeetle’s creator) would tell you otherwise: financial transactions, i.e. debits and credits, are actually <em>exactly</em> what transactional SQL was originally designed for.&nbsp;</p><p>Way back in 1985, Jim Gray (who would later win a Turing Award) wrote a seminal paper on transactions, titled <a href="https://jimgray.azurewebsites.net/papers/AMeasureOfTransactionProcessingPower.pdf">A Measure of Transaction Processing Power</a>. If you’ve heard of it before, it’s because in it, Gray defined a metric that 40 years later is <em>still</em> the most important measure for a database: <strong>TPS</strong>, or transactions per second. This would end up leading to such a fervent benchmark war among databases that an objective <em>council</em> – <a href="https://www.tpc.org/information/about/history5.asp">the TPC</a> – needed to be formed to moderate.</p><figure><p><img src="https://cdn.prod.website-files.com/67ebc022dbceaf64bee0f5c6/68daca1c7780ffd190f23346_3d394e75.png" loading="lazy" alt=""></p><figcaption><em>The TPC in action, deciding on whether a young database had gone to the Dark Side (Oracle).</em>&nbsp;</figcaption></figure><p>But what does the “T” in TPS actually mean? What is a transaction?</p><p>Your first guess might be a SQL transaction, but that’s not it. Gray actually defined it as a <strong>business transaction</strong> derived from the real world. Which is the reason databases were invented in the first place: to power businesses. And indeed, <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2005/04/tr-2005-39.doc">20 years later</a>, Gray continued to see the standard measure of transaction processing as a “DebitCredit:”</p><blockquote><em>“A database system to debit a bank account, do the standard double-entry bookkeeping and then reply to the terminal.”</em></blockquote><p>Mind you, SQL had already been around since the 70s at this point. And yet the luminary Gray still chose the debit/credit model – because it was the <em>canonical example</em> of an everyday transaction. Debit/credit is the lingua franca of <a href="https://www.youtube.com/watch?v=lGyMiW6PnKI&amp;ab_channel=TuringAwardeeClips"><strong>what it means to transact</strong></a>. It is <em>not</em> just for accounting and banks. It’s the reason for a database to provide guarantees like ACID in the first place.</p><p>And yet, if you want to use a SQL database to implement debits and credits today, you are probably going to have a bad time. To handle one debit/credit, a typical system – like the <a href="https://mojaloop.io/">central bank switch</a> that Joran consulted on in 2020 – needs to query account balances, lock those rows, wait for decisions in code, then write back and record the debit/credit. All in all, you’re looking at <strong>10-20 SQL queries</strong> back and forth, while holding row locks across the network roundtrip time, <em>for each transaction</em>. This gets even worse when you consider the problem of hot rows, where many transactions often need to touch the same set of “house accounts”.&nbsp;</p><p>All the while (for better or worse), the world is moving faster and faster towards an “everything is a transaction” model. Countries like India and Brazil are doing billions of transactions per month in instant payments. With <a href="https://www.frbservices.org/financial-services/fednow">FedNow</a> in the U.S., we’re not far away from that reality either. Meanwhile, other sectors like energy, gaming, and cloud are all moving towards real-time billing. In less than a decade, the world has become at least three orders of magnitude more transactional. And yet the SQL databases we still use to power this are 20-30 years old. Can they hold up?</p><p><strong>This is where TigerBeetle comes in</strong>. They designed a state-of-the-art database, from the ground up, to power the next era of transactions. In TigerBeetle, a debit/credit is a first class primitive and 8,190 of them can pack into a single 1MiB query via a one solitary roundtrip to the database. They call it <a href="https://www.youtube.com/watch?v=yKgfk8lTQuE">“The 1000x Performance Idea,”</a> but in Joran’s words it’s “nothing special”.</p><p>They say databases take a decade to build. But TigerBeetle is complete and pretty much <a href="https://jepsen.io/analyses/tigerbeetle-0.16.11">Jepsen-proof</a> after just 3 and a half years. In June 2025, Kyle Kingsbury showed he was unable to break TigerBeetle’s foundations (he found 1 correctness bug in the read query engine, not affecting durability), even while corrupting the whole thing on every machine in various places.&nbsp;</p><p>The obvious question here – <strong>how</strong>? How did TigerBeetle ship a production-ready, Jepsen-passing consensus and storage engine in 3.5 years when it typically takes a decade or more?</p><h2><strong>An (actually) modern database: distributed by default, why TigerBeetle uses Zig, and handling storage faults</strong></h2><p>Imagine you wake up today and wisely decide to build a database from scratch. Instead of investing in the technology of 30 years ago – when the most popular relational databases today were built – you can pick <em>any</em> advancements in architecture, hardware, language, or research since then to implement. How would you build it? What would you utilize?</p><h3><strong>Distributed by default</strong></h3><p>One thing you’d probably start with is the deployment model.&nbsp;</p><p>When Postgres and MySQL were built, in a world of big iron (on-prem hardware), the dominant paradigm was <strong>single node</strong>. Now, in a world of shared cloud hardware, it’s <strong>distributed</strong>. It’s not safe enough to store your transactions only on a single disk or server. A modern database needs to replicate your transactions, with strict serializability, across machines, for redundancy, fault tolerance and high availability. And yet some of the most popular OLTP databases in the world today are still highly dependent on a single node architecture. Automated failover, at least with zero data loss in the cut over, is not always baked in by default.</p><p>So TigerBeetle built their database to be distributed by default. Doing that comes with some of the obvious things you need to do, like consensus. But the developer experience for running TigerBeetle distributed is very simple: you just install the binary on however many machines you want in the cluster. No async replication, no Zookeeper, etc. To make this possible, TigerBeetle invested heavily in their consensus protocol implementation, adopting the pioneering <a href="https://pmg.csail.mit.edu/papers/vr.pdf">Viewstamped Replication</a> from MIT. This is part of why TigerBeetle has zero dependencies, apart from the Zig toolchain — they literally invested in all their core dependencies.</p><h3><strong>Clock fault tolerance</strong></h3><p>Distributed by default also shows up in some unlikely places. For example: have you ever thought of a clock fault model?&nbsp;</p><p>Though it’s not technically required or advised for consensus – which uses logical clocks and not physical clocks – remember that TigerBeetle is a <em>transactions</em> database. The physical timestamps of transactions need to be accurate and comparable across different financial systems for auditing and compliance.</p><p>And here, readers will note that Linux has several clocks: <code>CLOCK_MONOTONIC_RAW</code>, <code>CLOCK_MONOTONIC</code> and <code>CLOCK_BOOTTIME</code>. All have slight but important differences. Which is the best monotonic clock to use? (clue: It doesn’t say <code>MONOTONIC</code> on the tin)</p><p>The challenge is that physical imperfections in hardware clocks cause clocks to tick at different speeds, so that time passes faster or slower than it should. These kinds of “drift” errors eventually add up to significant “skew” errors within a short space of time. Most of the time, Network Time Protocol (NTP) would correct for these errors. But if NTP silently stops working because of a partial network outage, then a highly available consensus cluster might otherwise be running blind, in the dark.</p><p>But even this is something TigerBeetle thought about. They combine <em>the majority of clocks</em> in the cluster to construct a fault-tolerant clock called “cluster time”. This cluster time then gets used to bring a server’s system time back into line if necessary, or shut down safely if TigerBeetle detects that there are too many faulty clocks (e.g. TigerBeetle can actually detect when something like Chrony, PTP, or NTP have stopped working and alert the operator).&nbsp;</p><p>They do this by tracking offset clock times between different TigerBeetle servers, sampling them, and passing them through <a href="https://en.wikipedia.org/wiki/Marzullo%27s_algorithm">Marzullo’s algorithm</a> to estimate the most accurate possible interval (again, just to get a sense of whether clocks are being synced by the underlying clock sync protocol correctly).</p><p>Small things like this are exactly why distributed by default is hard, and doesn’t work as an add-on for older database models. You can read more about this in TigerBeetle's <a href="https://tigerbeetle.com/blog/2021-08-30-three-clocks-are-better-than-one/">3 clocks are better than one</a> blog post.</p><p>‍</p><h3><strong>Handling storage faults</strong></h3><p>Another piece of “distributed by default” that deserves its own header is how TigerBeetle handles <strong>storage faults</strong> (or even the fact it handles them at all). Traditional databases assume that if disks fail, they do so predictably with a nice error message. For example, even <a href="https://www.sqlite.org/atomiccommit.html">SQLite’s docs</a> are clear that:</p><blockquote><em>SQLite does not add any redundancy to the database file for the purpose of detecting corruption or I/O errors. SQLite assumes that the data it reads is exactly the same data that it previously wrote.</em></blockquote><p>In reality, there are many more sinister possibilities: disks can silently return corrupt data, misdirect I/O (on the read or write path), or just suddenly get really slow (called <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/paper-1.pdf">gray failure</a> in the research), all without returning error codes.&nbsp;</p><p>TigerBeetle is built to be storage fault tolerant:</p><ul role="list"><li>TigerBeetle uses <a href="https://www.usenix.org/conference/fast18/presentation/alagappan">Protocol Aware Recovery</a> to remain available unless all copies of a piece of data get corrupted on every single replica.</li><li>All data in TigerBeetle is immutable, checksummed, and hash-chained, providing a strong guarantee that no corruption or tampering happened.</li><li>TigerBeetle puts as little software as possible between itself and the disk, including a custom page cache, writing data to disk with O_DIRECT, and even running on a raw block device directly (no filesystem necessary — to sidestep filesystem bugs <a href="https://news.ycombinator.com/item?id=36113828">which do tend to happen</a> from time to time).</li><li>They built their own implementation of LSM instead of using an off-the-shelf one – they call it an <a href="https://www.youtube.com/watch?v=yBBpUMR8dHw">LSM Forest</a>, which is something like 20 different LSM trees.</li></ul><p>As far as I’m aware TigerBeetle is the only distributed database that not only claims to be storage fault tolerant, but was also tested pretty hard and validated by Jepsen to be. If you have a local machine failure where even just a disk sector fails, then that storage engine is connected to the global consensus, and it can use the cluster to self heal. This is also a great example of why the modern database having access to modern research matters: <a href="https://www.usenix.org/conference/fast18/presentation/alagappan">Protocol-Aware Recovery</a>, which enables TigerBeetle to survive disk failures like this, is fairly recent (2018) research.</p><figure><p><img src="https://cdn.prod.website-files.com/67ebc022dbceaf64bee0f5c6/68daca1c7780ffd190f23349_629bea61.png" loading="lazy" alt=""></p></figure><h3><strong>TigerBeetle in Zig</strong></h3><p>Another thing you’d think about when building a modern database from scratch is your choice of <strong>programming language</strong>. Postgres is written in C (c. 1970s), MySQL in C and C++ (1979), and MSSQL as well in C and C++. But programming languages have come a long way in the past 40 years. If you had your choice, what would you build a database in today?</p><p>The answer would probably be Rust or Zig. And indeed, TigerBeetle is built 100% in Zig:&nbsp;</p><ul role="list"><li>You get the whole C ecosystem available to you, extended with a phenomenal toolchain and compiler.</li><li>It’s easy to write, and especially easy to read, in some cases as easy as TypeScript (just a lot faster).</li><li>Zig lets you statically allocate memory, which is a core principle of TigerBeetle.</li><li>Zig has a great developer experience and you can learn it quickly (which ergo means you can get into the TigerBeetle src quickly).</li></ul><p>Of course, as new systems languages, Zig and Rust are related, and some of the early Rust team now work at TigerBeetle, including <a href="https://matklad.github.io/">Matklad</a> (creator of <a href="https://rust-analyzer.github.io/">Rust Analyzer</a>) and <a href="https://brson.github.io/">Brian Anderson</a> (co-creator of Rust with Graydon). They’ve <a href="https://matklad.github.io/2023/03/26/zig-and-rust.html">written extensively</a> about these languages and why Joran chose Zig in particular for TigerBeetle, given their design goals.</p><p>And here, of course, TigerBeetle is fanatical about static memory allocation, which I’ll talk more about in the next section. Not using dynamic memory allocation is “hard mode” in Rust (as matklad wrote about <a href="https://matklad.github.io/2022/10/06/hard-mode-rust.html">here</a>), but a breeze in Zig.</p><p>‍</p><h2><strong>Deterministic Simulation Testing and the VOPR</strong></h2><p>Sometimes, Deterministic Simulation Testing (DST) feels like the most transformational technology that the fewest developers know about. It’s a <a href="https://notes.eatonphil.com/2024-08-20-deterministic-simulation-testing.html">novel testing technique</a> made popular by the <a href="https://www.foundationdb.org/">FoundationDB</a> team (which now belongs to Apple); they used it to develop a more secure, bug-free distributed database in a shorter time span than arguably anyone had done before.&nbsp;</p><p>The <a href="https://www.youtube.com/watch?v=cHA8vyZvkCs">fundamentals of DST</a> go something like this. In distributed systems, there are essentially infinite combinations of concurrency issues: anything from lost messages to unpredictable thread execution order. You simply cannot use old-school unit and integration tests, or your system will suck. Formal verification, a more academic discipline that works on formulaic proofs that a program runs as intended, is too expensive and slow. So what are you to do?</p><p>The answer is a simulator that deterministically runs almost every possible scenario your system will face on a specific chronological timeline. The simulator accounts for external factors too, like issues with the OS, network, or disk, or simply different latencies. All in all, DST can give you the equivalent of years’ worth of testing in a very short time period (because time itself becomes deterministic—a while true loop); and DST is particularly well suited towards databases (I/O intensive, not compute intensive). If you’re familiar with Jepsen testing, think of it as <a href="https://antithesis.com/blog/is_something_bugging_you/">a subset of what DST can do</a>.&nbsp;</p><p>TigerBeetle is one of the most pioneering startups on the planet when it comes to DST. They’ve developed their own testing cluster – it’s nicknamed VOPR, short for Viewstamped Operation Replicator (<a href="https://www.youtube.com/watch?v=iRsycWRQrc8">after the WOPR simulator in the movie WarGames</a>). The VOPR constantly (and tirelessly) tests TigerBeetle under countless different conditions, covering everything from how nodes elect a leader to individual states and network faults. But it can simulate a whole distributed cluster virtually, all on a single thread.</p><p>As far as your author is aware, TigerBeetle’s VOPR is the single largest DST cluster on the planet. <a href="https://us13.campaign-archive.com/?u=32cd932058e988b44c838f7bc&amp;id=0c749f7b07">It runs on</a> 1,000 CPU cores, a number so unusually large that Hetzner sent them a special email asking if they were sure they wanted that many cores. The so-called VOPR-1000 is running 24x7x365, to catch rare conditions as far as possible before production. With time abstracted deterministically, and accelerated in the simulator by a factor of (roughly) 700x, this adds up to nearly 2 millennia of simulated runtime per day.</p><p>‍</p><h3><strong>But what if DST was fun?</strong></h3><p>Yea, distributed systems are cool. But you know what’s even cooler? Video games.</p><p>TigerBeetle turned DST into a game that lets you play through different failure scenarios in how the system reacts. You can play it <a href="https://sim.tigerbeetle.com/">here</a>.</p><figure><p><img src="https://cdn.prod.website-files.com/67ebc022dbceaf64bee0f5c6/68daca1c7780ffd190f2334c_13e94615.png" loading="lazy" alt=""></p></figure><p>What’s perhaps even cooler is that this game is running an actual instance of the VOPR, simulating TigerBeetle…in your browser. It’s compiled to WebAssembly, and then TigerBeetle’s own engineers built a gaming frontend on top to visualize the real system</p><p>You can read more about how and why TigerBeetle built the simulator in <a href="https://tigerbeetle.com/blog/2023-07-11-we-put-a-distributed-database-in-the-browser/">this blog post</a>.</p><p>‍</p><h2><strong>TigerStyle and The Power of Ten</strong></h2><p>As you will continue to see with TigerBeetle, it is often not just the <em>what</em> they’ve built that catches the eye but also the <em>how</em>. There’s no better example than <strong>TigerStyle</strong>.</p><p><a href="https://github.com/tigerbeetle/tigerbeetle/blob/main/docs/TIGER_STYLE.md">TigerStyle</a> is TigerBeetle’s engineering methodology, public on GitHub for all to see. Here’s how they describe it:</p><blockquote><em>“TigerBeetle's coding style is evolving. A collective give-and-take at the intersection of engineering and art. Numbers and human intuition. Reason and experience. First principles and knowledge. Precision and poetry. Just like music. A tight beat. A rare groove. Words that rhyme and rhymes that break. Biodigital jazz. This is what we've learned along the way. The best is yet to come.”</em></blockquote><p>Biodigital jazz is a term from <a href="https://en.wikipedia.org/wiki/Tron:_Legacy">Tron: Legacy</a>. In the context of the film, it represents the intertwining of human and digital elements, the chaotic yet structured nature of the “Grid” (the digital world), and the improvisational spirit of human potential within the confines of technology (I copied this from AI). For TigerBeetle, it’s an ethos of code; remembering to infuse everything they do with not just science, but art too.</p><p>More practically, TigerStyle lays out engineering and code principles for TigerBeetle, many derived from the original <a href="https://spinroot.com/gerard/pdf/P10.pdf">Power of Ten</a>, NASA’s tenets for writing foolproof code. TigerStyle spans from the thematic, like simplicity and elegance, to the applied, like how to name things. It’s even starting to impact other companies like Resonate and Turso; and <a href="https://youtu.be/tNZnLkRBYA8?t=11167">TigerStyle has even been discussed on Lex Fridman</a>. Here are a few highlights.</p><h3><strong>Using assertions, and the Power of Ten</strong></h3><p>Speaking of the Power of Ten…one of them (Rule 5) is about <strong>assertions</strong>. The idea is simple: explicitly encode your expectations of code behavior <em>while</em> you are writing it, not after the fact. You write them simply in a single line as booleans: assert(a &gt; b). TigerStyle calls for:</p><ul role="list"><li>Asserting all function arguments, return values, preconditions, and invariants. On average there should be at least 2 assertions per function.</li><li>Using assertions <em>instead</em> of comments when the assertion is both important and surprising.</li><li>Asserting the relationships between compile-time constants, so you can check a program’s design integrity before it even runs.</li><li>Not just assert what <em>should</em> happen, but also the negative space that you don’t expect – where interesting bugs can show up.</li></ul><p><a href="https://spinroot.com/gerard/pdf/P10.pdf">The Power of Ten</a> is an amazing artifact that covers so much more than just assertions…it’s a great resource for any modern programmer (and maybe we should train some LLMs on it too).</p><h3><strong>Thinking about performance</strong></h3><p>Much of TigerStyle centers around the idea that <em>writing</em> code is not the most important part of the cycle; instead, it’s <strong>reasoning about</strong> and <strong>designing</strong> the code. When it comes to performance, TigerStyle implores you to think about it from the start:&nbsp;</p><blockquote><em>“The best time to solve performance, to get the huge 1000x wins, is in the design phase, which is precisely when we can't measure or profile.”</em></blockquote><p>You should be doing basic napkin math on what TigerStyle calls “the four primary colors” – network, storage, memory, CPU – and how they’ll perform with respect to (“the two textures” — art!) bandwidth and latency. Then, there are a few more tactical tips, like distinguishing between the control plane and data plane, batching accesses, and extracting hot loops into stand-alone functions to reduce dependence on the compiler.&nbsp;</p><p>For more about TigerStyle, watch <a href="https://www.youtube.com/watch?v=w3WYdYyjek4&amp;t=5s&amp;ab_channel=TigerBeetle">Joran’s talk at Systems Distributed</a>.</p><h2>Try it out for yourself</h2><p>So is TigerBeetle a database? Yes. But it’s not much like any other database I’ve seen. They’ve taken modern research and applied it to an age-old form, giving their database unprecedented performance and stability guarantees. They’ve developed an art form around systems and storage engineering, and they haven’t forgotten to have fun along the way. And thanks to their clever use of DST, they were able to build this thing to Jepsen standards in only a few years.&nbsp;</p><p>You can get started with TigerBeetle <a href="https://tigerbeetle.com/#install">here</a> using a simple curl command.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Our efforts, in part, define us (242 pts)]]></title>
            <link>https://weakty.com/posts/efforts/</link>
            <guid>45435825</guid>
            <pubDate>Wed, 01 Oct 2025 09:22:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://weakty.com/posts/efforts/">https://weakty.com/posts/efforts/</a>, See on <a href="https://news.ycombinator.com/item?id=45435825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>What happens when something we enjoy doing that took effort becomes effortless? And what happens if that original effort was a foundation on which we saw value in ourselves?</p>
<p>If our efforts, in part, define us, then our efforts have intrinsic value. Our efforts may help us understand a position we want to occupy, an identity we carry, or an outlook we present. This value contributes to an internal economy of joy, self-respect, fulfillment, happiness. When effortful things become effortless, what becomes of our position in these economies?</p>
<p>As you can see, I have a few questions here.</p>
<hr>
<p>I know someone who spent a part of their adult life taking beautiful photographs, developing them by hand, framing them, cataloging them. Along came the ubiquity of digital cameras and smartphones, and "film" became infinitely available. Offhandedly, one day, this person mentioned that with the proliferation of smart phone cameras, and the ease with which one can take photos, they had found that some days their desire to continue was diminishing, and their work had lost meaning.</p>
<p>Technology has a history of making effortful things effortless, and there is sometimes a hidden loss in that advancement.</p>
<p>I figure people are continually being left behind in a similar manner day-to-day. Technology continues advancing (for the most part), and more things that remain effortful will become effortless. And "we" (ie, the populations who can afford to sit around and have crises of identity on these topics) will be further pushed to re-evaluate certain parts of our definitions of self.</p>
<p>For myself, in the last 10 years, my work of writing code has largely defined what I do with my working time. Now I experience large swaths of that work being created and done by AI (sometimes amazingly well, sometimes poorly), and I find myself thinking of the photographer above. It's not my wish that people can't have access to a more effortless way to write code, but I feel a strange sadness that there is less left to the act of the craft.</p>
<p>I have had this note in a draft state for several weeks now because I still can’t quite come to terms with how I’m feeling about things. There are so many nuances and unclear thoughts rolling around in my head about this shift. I think the only thing that is vaguely clear is that none of this would matter if making money wasn’t at play. If I was just writing code, (or taking film photographs) for fun in my free time because I enjoyed it, well, I don’t think I’d be feeling so conflicted.</p>
<p>Being paid to work and presenting my capacities through my craft is an exchange that I have been able to derive value from in its effortful-ness. Often times I've worked on utterly boring tasks that I would have loved to have a tool that could automate. But I didn't. And even in those menial moments I did derive some pleasure in my capacities. Of course, when it came to the real challenges, that was where I felt a pleasure and value in putting forth effort.</p>
<p>As a consultant, I work in a lot of different places, often for brief stints of time. And at many of these places, I see a large push, top-down, to encourage people to use AI. These employees, previously having entered an employment agreement where their capacities and experience would be exchanged for money, are now being asked that their abilities be augmented. In this way, the level continues to skew toward privileging production, often without understanding and people using their own perspectives.</p>
<p>When I see sentiments similar to mine, I often see reactions where people say that AI is simply a tool and that you must learn to use it and incorporate it into your toolbox. That's fine. That's well and good. But all I'm trying to say here is that I feel a lack and a loss for something. I don't understand it yet.</p>
<p>The title of this post, <em>our efforts, in part, define us</em>, is just a phrase that popped into my head. I'm not really sure if I even believe it or if I've fully fleshed out this single statement. But some part of it rings true to me. I wonder what will happen to us and our efforts. Will we be driven into further niches that are effortful, that we can derive value from? Will we become vague blobs that are formless, ill-defined, and despondent?</p>
<p>All of this presupposes a few things —that one can (and/or <em>should</em>) aim to derive value from work, that a meaningful identity is constructed by doing effortful things, that people generally are happier when they can use their skills and experiences to make something. And what’s more, there is a fine-line here between glorifying people with experience deriving value, and sounding like a shitty gatekeeper.</p>
<p>I will continue working for various clients. I suspect I will continue hearing leadership push AI on employees. And I will continue observing how people respond to this. Of course, for many people a job is <em>just a job</em>, as they say, and they'll do whatever they can to get it done more quickly (or work several jobs at once). Those very same people might find more value from their efforts now that AI is making their jobs easier. They can turn to better supporting their family, following other interests outside of work, finding other meaningful things, etc.</p>
<p>But at this time, I don't really see how this won’t further trample people’s spirits in the realm of work, unless we also reshape our expectations of work itself.</p>
<p>Is it worth the effort?</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I only use Google Sheets (275 pts)]]></title>
            <link>https://mayberay.bearblog.dev/why-i-only-use-google-sheets/</link>
            <guid>45435463</guid>
            <pubDate>Wed, 01 Oct 2025 08:06:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mayberay.bearblog.dev/why-i-only-use-google-sheets/">https://mayberay.bearblog.dev/why-i-only-use-google-sheets/</a>, See on <a href="https://news.ycombinator.com/item?id=45435463">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <header>
    <a href="https://mayberay.bearblog.dev/">
      <h2>
        Maybe-Ray
      </h2>
    </a>
    <nav>
      <p><a href="https://mayberay.bearblog.dev/">Home</a> <a href="https://mayberay.bearblog.dev/blog/">Blog</a></p>

    </nav>
  </header>
  <main>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-09-30T13:10Z">
                    30 Sep, 2025
                </time>
            </i>
        </p>
    

    <p>To cut things short, always use the easiest solution to solve a particular problem and once that solution does not work for the business anymore reassess what the new requirements are and either try enhance the current solution or find an alternative that better solve the problem. In my case the easiest solution is often creating a new Google sheet.</p>
<p>I entered the workforce about 9 months ago and my optimism for building new tools and services that help the small starting up business I work for has all vanished. I work in an environment that changes every 2 months or so, as my boss finds a new business venture she wants to enter. This has me starting and stopping quite a few projects that could have been solved in an afternoon with a quick Google Sheet.</p>
<p>I have listed a few examples below of some of the projects I have wasted time on instead of making a Google Sheet:</p>
<ol>
<li><p>I spent 2 months designing and making an admin panel to manage and track incoming cargo for the business. This panel was supposed to help the business categorise and better manage packages and customer data. This admin panel was used twice and never again. A Google Sheet could have been easily used for this and is currently being used for this task.</p>
</li>
<li><p>Three weeks were spent creating an MVP for a quote system that automatically calculated the duty and taxes for people ordering certain goods. Zimbabwean taxes and duties are often very complex and having our customers know exactly what to pay would create a better customer journey and make the process faster since we would not have to wait on our third party duty processing company to reply to us on every customer inquiry. In the end, we saw one of our competitors tax and duty breakdown table and we just copied it and put it in a Google Sheet.</p>
</li>
<li><p>Spent 2 months researching, having meetings (often &gt; 1hr long) and looking for a good CRM to use for the business. I would sit down compare and contrast different feature`s and prices for all the different CRMs we were looking into. We ended up using the free version of Oddo, that is not used that much anyway within the business. To my surprise a few weeks ago i noticed that Google Sheets has a CRM template built into it.</p>
</li>
</ol>
<p>I'm not saying that making a Google Sheet is the best solution to every problem but often times in my situation it is. I usually end up in situations were I never know the full scope of the problem until we start doing the actual work.</p>
<p>This is not to say that we do not need to plan out a project. The team should discuss workflows and information they might need but until we start doing the actual work we do not know full scope of the problem.</p>
<p>Once the full scope of the problem is known then we can start creating or enhancing the solutions we have. This helps because you do not end up being stuck with an extra workload that in the best case does not require all the features you are adding and in the worst case spending time on a project that will fail. So it is in your best interest to use the most basic solution to solve a problem.</p>
<p>Doing the smallest and easiest solution to a problem as a way to get to know the full scope and then iterating after that if needs be is by far the best solution (for me).</p>
<p>There are some caveats to this approach, I know a few organisation that have a thousand row spreadsheets that keep track of all their business transactions and employee information.</p>
<p>Creating a Google Sheet only works in situations were we do not know the full scope of the problem. Personally, I'm still new to this and learning when the best solution is making a Google Sheet or not. I just want to save people's time and effort and not have them build something that will never be used. But like all advice, think carefully about your own situation before committing a lot of time and effort especially in a business setting. It is perfectly fine for you to build useless programs and software in your spare time, that's the whole fun of it.</p>


    

    
        

        
            


        
    


  </main>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Category Theory Illustrated – Natural Transformations (174 pts)]]></title>
            <link>https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/</link>
            <guid>45435422</guid>
            <pubDate>Wed, 01 Oct 2025 08:00:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/">https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/</a>, See on <a href="https://news.ycombinator.com/item?id=45435422">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!--<h1>Natural transformations</h1> -->
        
        

        

<blockquote>
  <p>I didn’t invent categories to study functors; I invented them to study natural transformations. — Saunders Mac Lane</p>
</blockquote>

<p>In this chapter, we will introduce the concept of a morphism between functors, or <em>natural transformation</em>. Understanding natural transformations will enable us to define category equality and some other advanced concepts.</p>

<p>Natural transformations really are at the heart of category theory, however, their importance is not obvious at first. So, before introducing them, I like to talk, once more, about the body of knowledge that this heart maintains (I am good with metaphors… in principle).</p>

<h2 id="equivalent-categories">Equivalent categories</h2>

<p>Our first section aims to introduce natural transformation as a motivating example for creating a way to say that two categories are equal. But for that, we need to understand what equal categories are and should be.</p>

<p>So, are you ready to hear about equivalent categories and natural transformations? Actually it is my opinion that you are not (no offence, they are just very hard!). So, we will take a longer route. I can put this next section anywhere in this book, and it would always be neither here nor there. But anyway, if you are studying math, you are probably interested in the <em>nature of the universe</em>. “What is the quintessential characteristic of all things in this world?” I hear you ask…</p>

<h2 id="objects-are-overrated-aka-heraclitus-was-right">Objects are overrated AKA Heraclitus was right!</h2>

<blockquote>
  <p>The world is the collection of facts, not of things. — Ludwig Wittgenstein</p>
</blockquote>

<p>What is the quintessential characteristic of all things in this world? Some 2500 years ago, the philosopher Parmenides gave an answer to this question, postulating that the nature of the universe is permanence, stasis. According to his view, what we perceive as processes/transformations/change is merely illusory appearances (“Whatever is is, and what is not cannot be”). He said that that things never really change, they only <em>appear</em> to change, or (another way to put it), only appearances change, but the <em>essence</em> does not (I think this is pretty much how the word “essence” came to exist).</p>

<p>Although far from obviously true, his view is easy for people to relate to — objects are all around us, everything we “see”, both literally (in real life), or metaphorically (in mathematics and other disciplines), can be viewed as <em>objects</em>, persisting through space and time. If we subscribe to this view, then we would think that the key to understanding the world is understanding <em>what objects are</em>. In my opinion, this is what set theory does, to some extent, as well as classical logic (Plato was influenced by Parmenides when he created his theory of forms).</p>

<p>However, there is another way to approach the question about the nature of the universe, which is equally compelling. Because, what is an object, when viewed by itself? Can we study an object in isolation? And will there anything left to study about it, once it is detached from its environment? If a given object undergoes a process to get all of it’s part replaced, is it still the same object?</p>

<p>Asking such questions might lead us to suspect that, although what we <em>see</em> when we look at the universe are the objects, it is the processes/relations/transitions or <em>morphisms</em> between the objects that are the real key to understanding it. For example, when we think hard about everyday objects we realize that each of them has a specific <em>functions</em> (note the term) without which, a thing would not be itself e.g. is a lamp that doesn’t glow, still a lamp? Is there food that is non-edible (or an edible item that isn’t food)? And this is even more valid for mathematical objects, which, without the functions that go between them, are not objects at all.</p>

<p>So, instead of thinking about objects that just happen to have some morphisms between them, we might take the opposite view and say <em>that objects are only interesting as sources and targets of morphisms.</em></p>

<p>Although old, dating back to Parmenides’ alleged rival Heraclitus, this view has been largely unexplored, until the 20th century, when a real mathematical revolution happened: Bertrand Russell created type theory, his student Ludwig Wittgenstein wrote a little book, from which the above quote comes, and this book inspired a group of mathematicians and logicians, known as the “Vienna circle”. Part of this group was Rudolph Carnap who coined the word “functor”…</p>

<h2 id="isomorphism-invariance">Isomorphism invariance</h2>

<p>An embodiment of Heraclitus’ view in the realm of category theory is the concept of <em>isomorphism invariance</em> that we implicitly touched several times.</p>

<p>All categorical constructions that we covered (products/coproducts, initial/terminal objects, functional objects in logic) are <em>isomorphism-invariant</em>. Or, equivalently, they define an objects <em>up to an isomorphism</em>. Or, in other words, if there are two or more objects that are isomorphic to one another, and one of them has a given property, then the rest of them would to also have this property as well.</p>

<p>In short, in category theory <strong>isomorphism = equality</strong>.</p>

<p>The key to understanding category theory lies in understanding isomorphism invariance. And the key to understanding isomorphism invariance are natural transformations.</p>

<h2 id="categorical-isomorphisms-are-not-isomorphism-invariant">Categorical isomorphisms are <em>not</em> isomorphism-invariant</h2>

<p>Let’s return to the question that we were pondering at the beginning of the previous chapter — what does it mean for two categories to be equal?</p>

<p>In the prev chapter, we talked a lot about how great isomorphisms are and how important they are for defining the concept of equality in category theory, but at the same time we said that <em>categorical isomorphisms</em> do not capture the concept of equality of categories.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/isomorphic_categories.svg" alt="Isomorphic categories"></p>

<p>This is because (though it may seem contradictory at first) <em>categorical isomorphisms are not isomorphism invariant</em>, i.e. categories that only differ by having some additional isomorphic objects aren’t isomorphic themselves.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equal_categories.svg" alt="Isomorphic categories"></p>

<p>For this reason, we need a new concept of equality of categories. A concept that would elucidate the <em>differences</em> between categories with different structure, but also the <em>sameness</em> of categories that have the same categorical structures, disregarding the differences that are irrelevant for category-theoretic standpoint. That concept is <em>equivalence</em>.</p>

<!--comic-->
<p><strong>Parmenides:</strong> This category surely cannot be equal to the other one — it has a different amount of objects!</p>

<p><strong>Heraclitus:</strong> Who cares bro, they are isomorphic.</p>

<h2 id="equivalences-are-isomorphism-invariant">Equivalences are isomorphism invariant</h2>

<p>To understand equivalent categories better, let’s go back to the functor between a given map and the area it represents (we will only consider the thin categories (AKA orders) for now). This functor would be invertible (and the categories — isomorphic) when the map should represent the area completely i.e. there should be arrow for each road and a point for each little place.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/isomorphic_map.svg" alt="Isomorphic categories"></p>

<p>Such a map is necessary if your goal is to know about all <em>places</em>, however, like we said, when working with category theory, we are not so interested in <em>places</em>, but in the <em>routes</em> that connect them i.e. we focus not on <em>objects</em> but on <em>morphisms</em>.</p>

<p>For example, if there are intersections that are positioned in such a way that there are routes from one and to the other and vice-versa a map may collapse them into one intersection and still show all routes that exist (the tree routes would be represented by the “identity route”).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_map.svg" alt="Equivalent categories"></p>

<p>These two categories are <em>not isomorphic</em> — going from one of them to the other and back again doesn’t lead you to the same object.</p>

<p>However, going from one of them to the other would lead you at least to an <em>isomorphic object</em>.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_map_equivalence.svg" alt="Equivalent categories"></p>

<p>In this case we say that the orders are <em>equivalent</em>.</p>

<h2 id="defining-equivalence-in-terms-of-objects">Defining equivalence in terms of objects</h2>

<p>We know that two orders are isomorphic if there are two functors, such that going from one to the other and back again leads you to the same object.</p>

<p>And two orders are equivalent if going from one of them to the other and back again leads you to the same object, <em>or to an object that is isomorphic to the one you started with.</em></p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders.svg" alt="Equivalent orders"></p>

<p>But when does this happen? To understand this, we plot the orders as a Hasse diagram.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders_hasse.svg" alt="Equivalent orders"></p>

<p>You can see that, although not all objects are connected one-to-one, <em>all objects at a given level are connected to objects of the corresponding level</em>.</p>

<p>To formalize that notion, we remember the concept of <em>equivalence classes</em> that we covered in the chapter about orders. Let’s visualize the relationship of the equivalence classes of the two orders that we saw above.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_order_classes.svg" alt="Orders with isomorphic equivalence classes"></p>

<p>You can see that they are isomorphic. And that is no coincidence: two orders are equivalent precisely when the orders made of their equivalence classes are isomorphic.</p>

<p>This is a definition for equivalence of orders, but unfortunately, it does not hold for all categories — when we are working with orders, we can get away by just thinking about <em>objects</em>, but categories demands that we think about morphisms i.e. to prove two categories are equivalent, we should establish an isomorphism between their <em>morphisms</em>.</p>

<p>For example, the following two categories are <em>not</em> equivalent, although their equivalence classes are isomorphic — the category on the left has just one morphism, but the category on the right has two.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/unequal_categories.svg" alt="Non-equivalent categories"></p>

<p>One way of defining equivalence of categories is by generalizing the notion of equivalence classes of orders to what we call <em>skeletons</em> of categories, a skeleton of a category being a subcategory in which all objects that are isomorphic to one another are “merged” into one object (isomorphic objects are necessarily identical).</p>

<p>However, we will leave this (pardon my French) as an <em>exercise for the reader</em>. Why? We already did this when we generalized the notion of normal set-theoretic functions to <em>functors</em>, and so it makes more sense to build up on that notion. Also, we need a motivating example for introducing natural transformations, remember?</p>

<h2 id="defining-equivalence-in-terms-of-morphisms">Defining equivalence in terms of morphisms</h2>

<p>In the chapter about orders, we presented a definition of order <em>isomorphisms</em>, that is based on <em>objects</em>:</p>

<blockquote>
  <p>An order isomorphism is essentially an isomorphism  between the orders’ underlying sets (invertible function). However, besides their underlying sets, orders also have the arrows that connect them, so there is one more condition: in order for an invertible function to constitute an order isomorphism it has to <em>respect those arrows</em>, in other words it should be <em>order preserving</em>. More specifically, applying this function (let’s call it $F$) to any two elements in one set ($a$ and $b$) should result in two elements that have the same corresponding order in the other set (so $a ≤ b$ if and only if $F(a) ≤ F(b)$).</p>
</blockquote>

<p>That a way to define them, but it is not the best way. Now that we know about functors (which, as we said, serve as functions between the orders and other categories), we can devise a new, simpler definition, which would also be valid for all categories, not just orders, and for all forms of equality (isomorphism and equivalence).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/isomorphic_orders.svg" alt="isomorphic orders"></p>

<p>We begin with the definition of <strong>set isomorphism</strong>:</p>

<blockquote>
  <p>Two <strong>sets</strong> $A$ and $B$ are <strong>isomorphic</strong> (or $A ≅ B$) if there exist functions $f: A \to B$ and its reverse $g: B \to A$, such that $f \circ g = ID_{B}$ and $g \circ f = ID_{A}$.</p>
</blockquote>

<p>To amend it so it is valid for all categories  by just replacing the word “function” with “functor” and “set” with “category”:</p>

<blockquote>
  <p>Two <strong>categories</strong> $A$ and $B$ are <strong>isomorphic</strong> (or $A \cong B$) if there exist <em>functors</em> $f: A \to B$ and its reverse $g: B \to A$, such that $f \circ g = ID_{B}$ and $g \circ f = ID_{A}$.</p>
</blockquote>

<p><strong>Task 1:</strong> Check if that definition is valid.</p>

<p>Believe it or not, this definition, is just one find-and-replace operation away from the definition of <em>equivalence</em>. We get there only by replace equality with isomorphism (so, $=$ with $\cong$).</p>

<blockquote>
  <p>Two <strong>categories</strong> $A$ and $B$ are <strong>equivalent</strong> (or $A \simeq B$) if there exist <em>functors</em> $f: A \to B$ and its reverse $g: B \to A$, such that $f \circ g \cong ID_{B}$ and $g \circ f \cong ID_{A}$.</p>
</blockquote>

<p>Like we said at the beginning, with isomorphisms, going back and forth brings us to the same object, while with equivalence the object is just <em>isomorphic</em> to the original one. This is truly all there is to it.</p>

<p>There is only one problem, though — <em>we never said what it means for functors to be isomorphic</em>.</p>

<h2 id="natural-transformations-natural-isomorphisms-and-categorical-equivalence">Natural transformations, natural isomorphisms and categorical equivalence</h2>

<p>So, how can we make the above definition “come to life”? The title of this chapter outlines the things we need to define:</p>

<ol>
  <li><em>Morphisms between functors</em> (called <em>natural transformations</em>).</li>
  <li><em>Functor isomorphisms</em> (called <em>natural isomorphisms</em>).</li>
  <li>Finally <em>categorical equivalences</em>.</li>
</ol>

<p>If this sounds complicated, remember that we are doing the same thing we always did — talking about isomorphisms.</p>

<p>In the very first chapter of this book, we introduced <em>set isomorphisms</em>, which are quite easy, and now we reached the point to examine <em>functor isomorphisms</em>. So, we are doing the same thing. 
<!--comic-->
Although actually…</p>

<p>But actually, natural transformations are quite different from morphisms and functors, (the definition is not “recursive”, like the definitions of functor and morphism are). This is because functions and functors are both morphisms between objects (or <em>1-morphisms</em>), while natural transformations are <em>morphisms between morphisms</em> (known as <em>2-morphisms</em>).</p>

<p>But enough talking, let’s draw some diagrams. We know that natural transformations are morphisms between functors, so let’s draw two functors.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_functors_objects.svg" alt="Two functors"></p>

<p>The functors have the same signature. Naturally. How else can there be morphisms between them?</p>

<p>Now, a functor is comprised of two mappings (object mapping and morphism mapping) so a mapping between functors, would consist of “object mapping mapping” and “morphism mapping mapping” (yes, I often do get in trouble with my choice of terminology, why do you ask?).</p>

<h2 id="object-mapping-mapping">Object mapping mapping</h2>

<p>Let’s first connect the object mappings of the two functors, creating what we called “object mapping mapping”.</p>

<p>It is simpler than it sounds when we realize that we only need to connect the object in functors’ <em>target category</em> — the objects in the source category would just always be the same for both functors, as both functors would include <em>all</em> object from the source category (as that is what functors (and morphisms in general) do). In other words, mapping the two functors’ object components involves nothing more than specifying a bunch of morphisms in the target category: one morphism for each object in the source category i.e. each object from the image of the first functor, should have one arrow coming from it (and to an object of the second functor, so, for example, our current source category has two objects and we specify two morphisms.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_transformation.svg" alt="Two functors and a natural transformation"></p>

<p>Note that this mapping does not map every object from the target category,  i.e. not all objects have arrows coming from them (e.g. here the black and blue square do not have arrows), although, in some cases, it <em>might</em>.</p>

<p><strong>Task 2:</strong> When exactly would the mapping encompass all objects?</p>

<h2 id="morphism-mapping-mapping">Morphism mapping mapping</h2>

<p>The morphism part might seem hard… until we realize that, once the connections between the object mappings are already established, there is only one way to connect the morphisms — we take each morphism of the source category and connect the two morphisms given by the two functors, in the target category. And that’s all there is to it.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_functors.svg" alt="Two functors"></p>

<p>Oh, actually, there is also this condition that the above diagram should commute (the naturality condition), but that happens pretty much automatically.</p>

<h2 id="the-naturality-condition">The naturality condition</h2>

<p>Just like anything else in category theory, natural transformations have some laws that they are required to pass. In this case it’s one law, typically called the naturality law, or the naturality condition.</p>

<p>Before we state this law, let’s recap where are we now: We have two functors $F$ and $G$ that have the same type signature (so $F : C \to D$ and $G : C \to D$ for some categories $C$ and $D$), and a family of morphisms in the target category $D$ (denoted $\alpha : F \Rightarrow G$) one for each object in $C$, that map each object of the target of the functor $F$ (or the image of $F$ in $D$ as it is also called) to some objects of the image of $G$. This is a <em>transformation</em>, but not necessarily a <em>natural</em> one. A transformation is natural, when this diagram commutes for all morphisms in $C$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_transformation_square.svg" alt="The commuting square of a natural transformation"></p>

<p>i.e. a transformation is natural when every morphism $f$ in $C$ is mapped to morphisms $F(f)$ by $F$ and to $G(f)$ by $G$ (not very imaginative names, I know), in such a way, that we have $\alpha \circ F(f) = G(f) \circ \alpha$ i.e. when starting from the white square, when going right and then down (via the yellow square) is be equivalent to going down and then right (via the black one).</p>

<p>We may view a natural transformation is a mapping between morphisms and commutative squares: two functors and a natural transformation between two categories means that for each morphism in the source category of the functors, there exist one commutative square at the target category.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_transformation_squares.svg" alt="Commuting squares of a natural transformation"></p>

<p>When we fully understand this, we realize that commutative squares are made of morphisms too, so, like morphisms, they compose — for any two morphisms with appropriate type signatures that have we can compose to get a third one, we have two naturality squares which compose the same way.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_transformation_squares_composition.svg" alt="Composition of commuting squares of a natural transformation"></p>

<p>Which means natural transformation make up a…</p>

<p>(Oh wait, it’s too early for that, is it?)</p>

<h2 id="natural-isomorphisms">Natural isomorphisms</h2>

<p>After understanding natural transformations, natural isomorphisms, are a no-brainer: a natural transformation is just a family of morphisms in a given category that satisfy certain criteria, then what would a natural <em>isomorphism</em> be? That’s right — it is a family of <em>isomorphisms</em> that satisfy the same criteria. The diagram is the same as the one for ordinary natural transformation, except that $\alpha$ are not just ordinary morphisms, but isomorphisms.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_isomorphism.svg" alt="Two functors and a natural transformation"></p>

<p>And the turning those morphisms into isomorphisms makes the diagram commute in more than one way i.e. if we have the naturality condition</p>

<p>$\alpha \circ F(f) = G(f) \circ \alpha$ i.e. the two paths going from <strong>white</strong> to <strong>blue</strong> are equivalent.</p>

<p>We also have:</p>

<p>$F(f) \circ  \alpha  =   \alpha  \circ G(f)$ i.e. the two paths going from <strong>black</strong> to <strong>yellow</strong> are also equivalent.</p>

<h2 id="constructing-categorical-equivalences">Constructing categorical equivalences</h2>

<p>I am sorry, what were we talking about again? Oh yeah — categorical equivalence. Remember that categorical equivalence is the reason why we tackle natural transformations and isomorphisms? Or perhaps it was the other way around? Never mind, let’s recap what we discussed so far:</p>

<ol>
  <li>
    <p>At the beginning of the section we introduced the notion of equivalence as two functors, such that going from one of them to the other and back again leads you to the same object, or to an <em>object that is isomorphic</em> to the one you started with.</p>
  </li>
  <li>
    <p>And then, we discussed that for categories that are not thin (thick?) the situation is a bit more complex since they can have more than one morphism between two objects, and we should worry not only about isomorphic objects, but about <em>isomorphic morphisms</em>.</p>
  </li>
</ol>

<p>Now, we will show how these two notions are formalized by the definition that we presented.</p>

<blockquote>
  <p>Two <strong>categories</strong> $A$ and $B$ are <strong>equivalent</strong> (or $A \simeq B$) if there exist <em>functors</em> $f: A \to B$ and its reverse $g: B \to A$, such that $f \circ g \cong ID_{A}$ and $g \circ f \cong ID_{A}$.</p>
</blockquote>

<p>To understand, this how are the two related, let’s construct the identity functor of the category that we have been using as an example all this time. Note that we are drawing the one and the same category two times (as opposed to just drawing an arrow coming from each object to itself), to make the diagrams more readable.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders_identity.svg" alt="The identity functor"></p>

<p>Then, we draw the composite of the two functors that establish an equivalence between the two categories, highlighting the 3 “interesting” objects, i.e. the ones due to which the categories aren’t isomorphic.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders_composite.svg" alt="The composite functor between the two functors that make up the equivalence"></p>

<p>Now, we ask ourselves, in which cases does there exist an isomorphism between those two functors?</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders_functors.svg" alt="An equivalence diagram"></p>

<p>The answer becomes trivial if we draw the isomorphism arrows connecting the three “interesting” objects in a different way (remember, this is the same category on the top and the bottom) — we can see that these are exactly the arrows that enable us to construct an isomorphism between the two functors (the others are just identity arrows).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders_transformation.svg" alt="An equivalence diagram, showing a transformation"></p>

<p>And when would this isomorphism be such that preserves the structure of the category (so that each morphism from the output of the composite functor has an equivalent one in the output of the identity)? Exactly when the isomorphism is <em>natural</em> i.e. when every morphism is mapped to a commuting square, e.g. here is the commuting square of the morphism that is marked in red.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/equivalent_orders_natural_transformation.svg" alt=" An equivalence diagram, showing a natural transformation"></p>

<p>i.e. naturality condition assures us that the morphisms in the target of the functor behave in the same way as their counterparts in the source.</p>

<p>With this, we are finished with categorical equivalence, but not with natural transformations — natural transformations are a very general concept, and categorical equivalences are only a very narrow case of them.</p>

<h2 id="natural-transformations-in-programming-natural-transformations-on-the-list-functor">Natural transformations in programming. Natural transformations on the list functor</h2>

<p>In the course of this book, we learned that programming/computer science is the study of the category of types in programming languages. However (in order to avoid this being too obvious) in the computer science context, we use different terms for the standard category-theoretic concepts.</p>

<p>We learned that objects are known as <em>types</em>, products and coproducts are, respectively, <em>objects/tuple</em> types and <em>sum</em> types. And, in the last chapter, we learned that functors are known as <em>generic types</em>. Now it’s the time to learn what natural transformations are in this context. They are known as <em>(parametrically) polymorphic functions</em>.</p>

<h2 id="pointed-functors-again">Pointed functors again</h2>

<p>Now, suppose this sounds a bit vague. If only we had some example of a natural transformation in programming, that we can use… But wait, we did show a natural transformation in the previous chapter, when we talked about pointed functors.</p>

<p>That’s right, a functor is pointed when there is a natural transformation between it and the identity functor i.e. to have one green arrow for every object/type.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/pointed_functor.svg" alt="Pointed functor"></p>

<p>And this clearly is a natural transformation. As a matter of fact, if we get down to the nitty-gritty, we would see that it resembles a lot the equivalence diagram that we saw earlier — both transformations involve the identity functor, and both transformations have the same category as source and target, that’s why we can put everything in one circle (we don’t do that in the equivalence diagram, but that’s just a matter of presentation).</p>

<p>Actually, the only difference between the two transformations is that an equivalence is defined by a natural <em>natural isomorphism</em> of a given functors to the identity functor ( $ID \cong f \circ g $ and $ID \cong g \circ f$), while a pointed functor is defined by a one-way <em>natural transformation</em> from the identity functor ($ID \to f $)  i.e. the equivalence functor is pointed, but not the other way around).</p>

<h2 id="polymorphic-functions-as-natural-transformations">Polymorphic functions as natural transformations</h2>

<p>We said that a natural transformation is equivalent to a (parametrically) polymorphic function in programming. But wait, wasn’t natural transformation something else (and much more complicated):</p>

<blockquote>
  <p>Two functors $F$ and $G$ that have the same type signature (so $F : C \to D$ and $G : C \to D$ for some categories $C$ and $D$), and a family of morphisms in the target category $D$ (denoted $\alpha : F \Rightarrow G$) one for each object in $C$. Morphisms that map each object of the target of $F$ (or the image of $F$ in $D$ as it is also called) to some object in the target of $G$.</p>
</blockquote>

<p>Indeed it is (I wasn’t lying to you, in case you are wondering), however, in the case of programming, the source and target categories of both functors are the same category ($Set$), so the whole condition regarding the functors’ type signatures can be dropped.</p>

<blockquote>
  <p>Two <del>functors</del> generic types $F$ and $G$ <del>that have the same type signature</del> and a family of morphisms in $Set$ (denoted $\alpha : Set \Rightarrow Set$) one for each object in $Set$, that map each target object of the functor $F$ (or the image of $F$ in $D$ as it is also called) to some target objects of functor $G$.</p>
</blockquote>

<p>As we know from the last chapter, a functor in programming is a generic type (which, has to have the <code>map</code> function with the appropriate signature).</p>

<p>And what is a “family of morphisms in $Set$ one for each object in $Set$”? Well, the morphisms in the category $Set$ are functions, so that’s just a bunch of functions, one for each type.  In Haskell notation, if we denote a random type by the letter \(a\)), it is $alpha : \forall a. F a \to G a$.  But that’s exactly what polymorphic functions are.</p>

<p>Here is how would we write the above definition in a more traditional language  (we use capital <code>&lt;A&gt;</code> instead of $a$, as customary.</p>

<div><pre><code>
<span>function</span> <span>alpha</span><span>&lt;</span><span>A</span><span>&gt;</span><span>(</span><span>a</span><span>:</span> <span>F</span><span>&lt;</span><span>A</span><span>&gt;</span><span>)</span> <span>:</span> <span>G</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>{</span>
<span>}</span>

</code></pre></div>

<p>Generic types work by replacing the <code>&lt;A&gt;</code> with some concrete type, like <code>string</code>, <code>int</code> etc. Specifically, the natural transformation from the identity functor to the list functor that puts each value in a singleton list looks like this $alpha :: \forall\ a. a \to List\ a$. Or in TypeScript:</p>

<div><pre><code>
<span>function</span> <span>array</span><span>&lt;</span><span>A</span><span>&gt;</span><span>(</span><span>a</span><span>:</span> <span>A</span><span>)</span> <span>:</span> <span>Array</span><span>&lt;</span><span>A</span><span>&gt;</span> <span>{</span>
    <span>return</span> <span>[</span><span>a</span><span>]</span>
<span>}</span>
</code></pre></div>

<h2 id="some-examples-of-natural-transformations">Some examples of natural transformations</h2>

<p>Once we rid ourselves of the feeling of confusion, that such an excessive amount of new terminology and concepts impose upon us (which can take years, by the way), we realize that there are, of course, many polymorphic functions/natural transformations that programmers use.</p>

<p>For example, in the previous chapter, we discussed one natural transformation/polymorphic function the function $\forall a.a \to [a]$ which puts every value in a singleton list. This function is a natural transformation between the identity functor and the list functor.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/pointed_functor_set_transformation.svg" alt="Natural transformation, defining a pointed functor in Set"></p>

<p>This is pretty much the only one that is useful with <em>this</em> signature (the others being $a \to [a, a]$, $a \to [a, a, a]$ etc.), but there are many examples with signature $list\ a \to list\ a$, such as the function to <em>reverse</em> a list.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/reverse_set_transformation.svg" alt="The natural transformation, for reversing a list in Set"></p>

<p>…or <em>take1</em> that retrieves the first element of a list</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/take_set_transformation.svg" alt="The natural transformation, for taking the first element of a list in Set"></p>

<p>or <em>flatten</em> a list of lists of things to a regular list of things (the signature of this one is a little different, it’s $list\ list\ a \to list\ a$).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/flatten_set_transformation.svg" alt="The natural transformation, for flattening a list in Set"></p>

<hr>

<p><strong>Task 3:</strong> Draw example naturality squares of the $reverse$ natural transformation.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/reverse_set_transformation_task.svg" alt="The natural transformation, for reversing a list in Set">
Do the same for the rest of the transformations.</p>

<hr>

<h2 id="the-naturality-condition-1">The naturality condition</h2>

<p>Before, we said that we shouldn’t worry too much about naturality, as it is satisfied every time. Statistically, however, this is not true — as far as I am concerned, about 99.999 percent of transformations aren’t really natural (I wonder if you can compute that percentage properly?). But at the same time, it just so happens (my favourite phrase when writing about maths) that all transformations that we care about <em>are</em> natural.</p>

<p>So, what does the naturality condition entail, in programming? To understand this, we construct some naturality squares of the transformations that we presented.</p>

<p>We choose two types that play the role of $a$, in our case $string$ and $num$ and one natural transformation, like the transformation between the identity functor and the list functor.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/pointed_functor_set.svg" alt="Pointed functor in Set"></p>

<p>The diagram commute when for all functions $f$, applying the $Ff$, the mapped/lifted version of $f$ with one functor (in our case this is just $F f : string \to num$ cause it is the identity functor), followed by ($alpha :: F b \to G\ b$), is equivalent to applying ($alpha:: F a \to G\ a$), and then the mapped version of $f$ with the other functor (in our case $G f :: List\ a \to List\ b$) i.e.</p><p>

\[\alpha \circ F\ f \cong G\ f \circ \alpha\]

</p><p>(in the programming world, you would also see it as something like  $\alpha (map\ f x) = map\ f (\alpha x)$, but note that here $map$ function means two different things on the two sides, Haskell is just smart enough to deduce which $fmap$ to use).</p>

<p>And in TypeScript, when we are talking specifically about the identity functor and the list functor, the equality is expressed as:</p>



<p>So, is this equation true in our case? To verify it, we take one last peak at the world of values.</p>

<p>We acquire an $f$, that is, we a function that acts on simple values (not lists), such as the function $length : string \to num$, which returns the number of characters a string has and convert it, (or <em>lift</em> it, as the terminology goes) to a function that acts on more complex values, using the list functor, (and the higher-order function $map$).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/lifted_function_f.svg" alt="A lifted function"></p>

<p>Then, we take the input and output types for this function (in this case $string$ and $num$), and the two morphisms of a natural transformation (e.g the abstract function $\forall a.a \to [a]$) that correspond to those two types.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/pointed_functor_set_transformations.svg" alt="Pointed functor in Set"></p>

<p>When we compose these two pairs of morphisms we observe that they indeed commute — we get two morphisms that are actually one and the same function.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/pointed_functor_set_internal.svg" alt="Pointed functor in Set"></p>

<p>The above square shows the transformation $\forall a.a \to [a]$ (which is between the identity functor and the list functor, here is another one, this time between the list functor and itself ($\forall a.[a] \to [a]$) — $reverse$</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/reverse_set_internal.svg" alt="Pointed functor in Set"></p>

<p>(and you can see that this would work not just for $length$, but for any other function).</p>

<p>So, why does this happen? Why do these particular transformations make up a commuting square for each and every morphism?</p>

<p>The answer is simple, at least in our specific case: the original, unlifted function $f :: a \to b$ (like our $length :: string \to num$) can only work on the individual values (not with structure), while the natural transformation functions, i.e. ones with signature  $list :: a \to list\ a$ only alter the structure, and not individual values. The naturality condition just says that these two types of functions can be applied in any order that we please, without changing the end result.</p>

<p>This means that if you have a sequence of natural transformations that you want to apply, (such as $reverse$ , $take$, $flatten$ etc) and some lifted functions ($F f$, $F g$), you can mix and match between the two sequences in any way you like and you will get the same result e.g.</p><p>

\[take1 \circ reverse \circ F\ f \circ F\ g\]

</p><p>is the same as</p><p>

\[take1 \circ F\ f \circ reverse \circ F\ g\]

</p><p>…or…</p><p>

\[F\ f \circ F\ g \circ take1 \circ reverse\]

</p><p>…or any other such sequence (the only thing that isn’t permitted is to flip the members of the two sequences — ($take1 \circ reverse$ is of course different from $reverse \circ take1$and if you have $F\ f \circ F\ g$, then $F\ g \circ F\ f$ won’t be permitted at all due to the different type signatures).</p>

<p><strong>Task 4:</strong> Prove the above results, using the formula of the naturality condition.</p>

<h2 id="non-natural-transformations">Non-natural transformations</h2>

<p>“Unnatural”, or “non-natural” transformations (let’s call them just <em>transformations</em>) are mentioned so rarely, that we might be inclined to ask if they exist. The answer is “yes and no”. Why yes? On one hand, transformations, consist of an innumerable amount of morphisms, forming an ever more innumerable amount of squares and obviously nothing stops some of these squares to be non-commuting.</p>

<p>For example, if we substitute one morphism from the family of morphisms that make up the natural transformation with some other random morphism that has the same signature, all squares that have this morphism as a component would stop commuting.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/unnatural_transformation_squares.svg" alt="Unnatural transformation"></p>

<p>This would result in something like an “almost-natural” transformation (e.g. an abstract function that reverses all lists, except lists of integers).</p>

<p>And in the category of sets, where morphisms are functions i.e. mappings between values, it is enough to move just one arrow of just one of those values in order to make the transformation “unnatural” (e.g. a function which reverses all lists, but one specific list).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/reverse_set_unnatural.svg" alt="Unnatural transformation in set --- like reverse, but one arrow is off"></p>

<p>Finally, if can just gather a bunch of random morphisms, one for each object, that fit the criteria, we get what I would call a “perfectly unnatural transformation” (but this is my terminology).</p>

<p>But, although they do exist, it is very hard to define non-natural transformations. For example, for categories that are <em>infinite</em>, there is no way to specify such “perfectly unnatural transformation” (ones where none of the squares commute) without resorting to randomness. And even transformations on finite categories, or the “semi-natural” transformations which we described above (the ones that include a single condition for a single value or type), are not possible to specify in some languages e.g. you can define such a transformation in Typescript, but not in Haskell.</p>

<p>To see why, let’s see what the type of a natural transformation is.</p><p>

\[\forall\ a.\ F a \to G a\]

</p><p>The key is that the definition should be valid <em>for all</em> types a. For this reason, there is no way for us to specify a different arrows for different types, without resorting to type downcasting, which is not permitted in languages like Haskell (as it breaks the principle of parametricity).</p>

<!--

-->

<h2 id="natural-transformations-again">Natural transformations again</h2>

<p>Now, after we saw the definition of natural transformations, it is time to see the definition of natural transformations (and if you feel that the quality of the humour in this book is deteriorating, that’s only because <em>things are getting serious</em>).</p>

<p>Let’s review again the commuting diagram that represents a natural transformation.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_functors.svg" alt="Two functors"></p>

<p>This diagram might prompt us into viewing natural transformations as some kind of “two-arrow functors” that have not one but two arrows coming from each of their morphisms — this notion, can be formalized, by using <em>product categories</em>.</p>

<p>Oh wait, I just realized we never covered product categories… but don’t worry, we will cover them now.</p>

<h2 id="product-groups-and-product-categories">Product groups and product categories</h2>

<p>We haven’t covered product categories, however some pages ago, when we covered monoids and groups, we talked about the concept of a <em>product group</em>. The good news is that product <em>categories</em> are a generalization of product <em>groups</em>…</p>

<p>The bad news is that you probably don’t remember much about product groups, as covered them briefly.</p>

<p>But don’t worry, we will do a more in-depth treatment now:</p>

<h2 id="product-groups">Product groups</h2>

<p>Given two groups $G$ and $H$, whose sets of elements can also be denoted $G$ and $H$…</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/groups_product.svg" alt="The Klein four as a product group"></p>

<p>(in this example we use two boolean groups, which we visualize as the groups of horizontal and vertical rotation of a square)</p>

<p>…the <em>product group</em> of these two groups is a group that has the cartesian product of these two sets $G \times H$ as its set of elements.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/klein_four_underlying_set.svg" alt="The Klein four as a product group"></p>

<p>And what can the group operation of such a group be? Well, I would say that out of the few possible groups operations for this set that <em>exist</em>, this is the <em>only</em> operation that is <em>natural</em> (I didn’t intend to involve natural transformation at this section, but they really do appear everywhere). So, let’s try to derive the operation of this group.</p>

<p>We know what a group operation is, in principle: A group operation combines two elements from the group into a third element i.e. it is a function with the following type signature:</p><p>

\[\circ :  (A, A) \to A\]

</p><p>or equivalently</p><p>

\[\circ :  A \to A \to A\]

</p><p>And for product groups, we said that the underlying set of the group (which we dubbed $A$ above) is a cartesian product of some other two sets which we dubbed $G$ and $H$. So, when we swap $A$ for $G \times H$ the definition becomes:</p><p>

\[\circ : G \times H \to G \times H \to G \times H\]

</p><p>i.e. the group operation takes one pair of elements from $G$ and $H$ and another pair of elements from $G$ and $H$, only to return — guess what — a pair of elements $G$ and $H$.</p>

<p>Let’s take an example. To avoid confusion, we take two totally different groups — the color-mixing group and the group of integers under addition. That would mean that a value of $G \times H$ would be a pair, containing a random color and a random number, and the operation would combine two combine two such pairs and produce another one.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_group_equations.svg" alt="Equations of the product of numbers and colors"></p>

<p>Now, the operation must produce a pair, containing a number and a color. Furthermore, it would be good if it produces a number <em>by using those two numbers</em>, not just picking one at random, and likewise for colors. And furthermore, we want it to work not just for monoids of numbers and colors, but all other monoids that can be given to us. It is obvious that there is only one solution, to get the elements of the new pair by combining the elements of the pairs given.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_group_solutions.svg" alt="Solutions of the product of numbers and colors"></p>

<p>And the operation of the product group of the two boolean groups which we presented earlier is the combination of the two operations</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/klein_four_as_product.svg" alt="The Klein four as a product group"></p>

<p>So, the general definition of the operation is the following ($g1$, $g2$ are elements of $G$ and $h1$ and $h2$ elements of $H$).</p><p>

\[(g1, h1) \circ (g2, h2) = ( (g1 \circ g2), (h1 \circ h2))\]

</p><p>And that are product groups.</p>

<h2 id="product-categories">Product categories</h2>

<p>We are back at tackling product <em>categories</em>.</p>

<p>Since we know what product <em>groups</em> are, and we know that groups are nothing but categories with just one object (and the group objects are the category’s morphisms, remember?), we are already almost there.</p>

<p>Here is a way to make a product category.</p>

<p>Take any two categories:</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_components.svg" alt="Product category - components"></p>

<p>Then take the set of all possible pairs of the objects of these categories.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_set.svg" alt="Product category - objects"></p>

<p>And, finally, we make a category out of that set by taking all morphisms coming from any of the two categories and replicate them to all pairs that feature some objects from their type signature, in the same way as we did for product groups (in this example, only one of the categories has morphisms).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_category.svg" alt="Product category"></p>

<p>This is the <em>product category</em> of the two categories.</p>

<h2 id="natural-transformations-as-functors-of-product-categories">Natural transformations as functors of product categories</h2>

<p>In this section we are interested with the products of one particular category, namely the category we called $2$, containing two objects and one morphism (stylishly represented in black and white).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/category_two.svg" alt="The category 2"></p>

<p>This category is the key to constructing a functor that is equivalent to a natural transformation:</p>

<ul>
  <li>Because it has two objects, it produces two copies of the source category.</li>
  <li>because the two objects are connected, the two copies are connected in the same way as the two “images” in the target category are connected.</li>
</ul>

<p>So, given a product category of $2$ and some other category $C$…</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_category_target_category.svg" alt="The category 2"></p>

<p>…there exist a natural transformation between $C$ and the product category $2\times C$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/product_category_natural_transformation.svg" alt="Product category"></p>

<p>Furthermore, this connection is two-way: any natural transformation from $C$ to some other category (call it $D$, as it is customary) can be represented as a functor $2 \times C \to D$.</p>

<p>That is, if we have a natural transformations $\alpha : F \Rightarrow G$ (where  $F: C \to D$ and  $G: C \to D$), then, we also have a functor  $2 \times C \to D$, such that if we take the subcategory of $2 \times C$ comprised of just those objects that have the $0$ object as part of the pair, and the morphisms between them, we get a functor that is equivalent to $F$, and if we consider the subcategory that contains $1$, then the functor is equivalent to $G$ (we write $\alpha(-,0)=F$ and $\alpha(-,1)=G$). Et voilà!</p>

<p><strong>Task 5:</strong> Show that the two definitions are equivalent.</p>

<p>This perspective helps us realize that a natural transformation can be viewed as a collection of commuting squares. The source functor defines the left-hand side of each square, the target functor — the right-hand side, and the transformation morphisms join these two sides.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/natural_transformation_notation.svg" alt="Notation for natural transformation"></p>

<p>We can even retrieve the structure of the source category of these functors, which (as categories are by definition structure and nothing more) is equivalent to retrieving the category itself.</p>

<!--

-->

<h2 id="composing-natural-transformations">Composing natural transformations</h2>

<p>Natural transformations are surely a different beast than normal morphisms and functors and so they don’t compose in the same way. However, they do compose and here we will show how.</p>

<h2 id="the-identity-natural-transformation">The identity natural transformation</h2>

<p>Let’s first get one trivial definition out of the way: for each functor, we have the identity natural transformation (actually a natural isomorphism) between it and itself.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/identity_natural_transformation.svg" alt="The identity natural transformation"></p>

<h2 id="horizontal-composition">Horizontal composition</h2>

<p>The setup for composing natural transformations may look complicated the first time you see it: we need three categories $C$, $D$ and $E$ (just as composition of morphisms requires three objects). We need a total of four functors, distributed on two pairs, one pair of functors that goes from $C$ to $D$ and one that goes from $D$ to $E$ (so we can compose these two pairs of functors together, to get a new pair of functors that go $C \to E$). However, we will try to keep it simple and we will treat the natural transformation as a map from a morphism to a commuting square. As we showed above, this mapping already contains the two functors in itself.</p>

<p>So, let’s say that we have the natural transformation $\alpha$ involving the $C \to D$ functors (which we usually call $F$ and $G$).</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/horizontal_composition_notation.svg" alt="Notation for natural transformation"></p>

<p>So, what will happen if we have one more transformation $\bar\alpha$ involving the functors that go $D \to E$ (which are labelled $F’$ and $G’$)? Well, since a natural transformation maps each morphism to a square, and a square contains four morphisms (two projections by the two functors and two components of the transformation), a square would be mapped to four squares.</p>

<p>Let’s start by drawing two of them for each projection of the morphism in $C$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/horizontal_composition_squares.svg" alt="Horizontal composition of natural transformation"></p>

<p>We have to have two more squares, corresponding to the two morphisms that are the components of the $\alpha$ natural transformation. However, these morphisms connect the objects that are the target of the two functors, objects that we already have on our diagram, so we just have to draw the connections between them.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/horizontal_composition.svg" alt="Horizontal composition of natural transformation"></p>

<p>The result is an interesting structure which is sometimes visualized as a cube.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/horizontal_composition_cube.svg" alt="Horizontal composition of natural transformation"></p>

<p>More interestingly, when we compose the commuting squares from the sides of the cube horizontally, we see that it contains not one, but two bigger commuting squares (they look like <em>rectangles</em> in this diagram), visualized in grey and red. Both of them connect morphisms $F’Ff$ and $G’Gf$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/horizontal_composition_cube_commuting.svg" alt="Horizontal composition of natural transformation"></p>

<p>So, there is a natural transformation between the composite functor $F’ \circ F : C \to E$ and $G’ \circ G : C \to E$ — a natural transformation that is usually marked $\bar\alpha \bullet \alpha$ (with a black dot).</p>

<p><strong>Task 6:</strong> Show that natural transformations indeed compose i.e. that if you have natural transformations $F’Ff \Rightarrow F’Gf$  and  $F’Gf \Rightarrow G’Gf$ you have $F’Ff \Rightarrow G’Gf$.</p>

<h2 id="whiskering">Whiskering</h2>

<p>And an interesting special case of horizontal composition is horizontal composition involving the identity natural transformation: given a natural transformation $\bar\alpha$ involving functors with signature $D \to E$ and some functor with signature $F : C \to D$, we can take $\alpha$ to be the identity natural transformation between functor $F$ and itself and compose it with $\bar\alpha$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/horizontal_composition_whiskering.svg" alt="Horizontal composition of natural transformation"></p>

<p>We get a new natural transformation $\bar\alpha \bullet \alpha$, that is practically the same as the one we started with (i.e. the same as $\bar\alpha$) so what’s the deal? We just found a way to <em>extend</em> natural transformations, using functors: i.e   we can use a functor with signature $C \to D$ to extend a $D \to E$ natural transformation and make it $C \to E$.</p>

<p><strong>Task 7</strong>: Try to extend the natural transformation in the other direction (by taking $\bar\alpha$ to be identity).</p>

<p>So, this is how you compose natural transformations. It’s too bad that this is form of composition is different from the standard categorical composition. So, I guess natural transformations do not form a category, like we hoped they would…</p>

<p>Well, OK, there is actually another way of composing categories, which might actually work.</p>

<h2 id="vertical-composition">Vertical composition</h2>

<p>Recall that categorical composition involves three objects and two successive arrows between them. For vertical composition of natural transformations, we will need three (or more) <em>functors</em> with the same type signature, say $F, G, H: C \to D$ i.e. (same source and target category) and two successive <em>natural transformations</em> between those functors i.e. $\alpha: F \to G$ and $\beta: G \to H$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/vertical_composition.svg" alt="Vertical composition of natural transformations"></p>

<p>We can combine each morphism of the natural transformation $\alpha$ (e.g. $a: F \to G$) and the corresponding morphism of the natural transformation $\beta$ (say $b:G \to H$) to get a new morphism, which we call $b \circ a : F \to H$ (the composition operator is the  usual white circle, as opposed to the black one, which denotes horizontal composition). And the set of all such morphisms are precisely the components of a new natural transformation: $\beta \circ \alpha : F \to H$.</p>

<h2 id="categories-of-functors">Categories of functors</h2>

<p>Now, we are approaching the end of the chapter, we will introduce our category and call it quits. To do that, we first introduce a more compressed notation for vertical composition of natural transformations (where they do indeed look vertical).</p>

<p>We started this chapter by looking at category of sets and using internal diagrams, displaying the set elements as points and the sets/objects as collections.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/vertical_composition_internal.svg" alt="Vertical composition of natural transformations - internal diagram"></p>

<p><strong>Task 8:</strong> identify the function, the three functors, and the two natural transformations used in this diagram.</p>

<!--
answer
(A little note, if you want to understand the diagram better: $F$ and $G$ are the $List$ functor, $H$ is the $ID$ functor, $\alpha$ is  $reverse: List \to List$ and $\beta$ is $head : List \to ID$ and $f$ is $length : string \to int$)
-->

<p>Then, we quickly passed to normal external diagrams, where objects are points and categories are collections.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/vertical_composition.svg" alt="Vertical composition of natural transformations"></p>

<p>And now we go one more level further, and show the category of categories, where categories are points and functors are morphisms.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/vertical_composition_cat.svg" alt="Vertical composition of natural transformations in Cat"></p>

<p>In this notation, we display natural transformations as (double) arrows between morphisms.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/vertical_composition_cat_2.svg" alt="Vertical composition of natural transformations in Cat"></p>

<p>And you can already see the new category that is formed: For each two categories (like $C$ and $D$ in this case), there exists a category which has functors for objects and natural transformations as morphisms.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/functor_category.svg" alt="Vertical composition of natural transformations in Cat"></p>

<p>Natural transformations compose with vertical compositions, and, of course, the identity natural transformation is the identity morphism.</p>

<h2 id="interchange-law">Interchange law</h2>

<p>Vertical and horizontal composition of natural transformations are related to each other in the following way:</p>

<p>If we have (as we had) two successive natural transformations, in the vertical sense, like $\alpha: F \to G$ and $\beta: G \to H$.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/interchange_law_horizontal.svg" alt="The interchange law -- horizontal component"></p>

<p>And two successive ones, this time in horizontal sense e.g. $\bar\alpha: F’ \to G’$ and $\bar\beta: G’ \to H’$. (note that $\alpha$ has nothing to do with $\bar\alpha$ as $\beta$ has nothing to do with $\bar\beta$, we just call them that way to avoid using too many letters)</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/interchange_law_vertical.svg" alt="The interchange law -- vertical component"></p>

<p>And if the two pairs of natural transformations both start from the same category and the same functor, then the compositions of the two pairs of natural transformations obey the following law</p><p>

\[(β \circ α) \bullet (\bar β \circ \bar α) = (β \bullet \bar β) \circ (α \bullet \bar α)\]

</p><hr>

<p><strong>Task 9:</strong> Draw the paths of the two compositions of the transformations (on the two sides of the equation) and ensure that they indeed lead to the same place.</p>

<p><img src="https://abuseofnotation.github.io/category-theory-illustrated/11_natural_transformations/interchange_law.svg" alt="The interchange law"></p>

<hr>

<h2 id="2-categories">2-Categories</h2>

<p>At this point you might be wondering the following (although statistically you are more likely to wonder what the heck is all this about): We know that all categories are objects of $Cat$, the category of small categories, in which functors play the role of morphisms.</p>

<p>But, functors between given categories also form a category, under vertical composition. Which means that $Cat$ not only has (as any other category) morphisms between objects, <em>but</em> also has <em>morphisms between morphisms</em>. And furthermore, those two types of morphisms compose in this very interesting way.</p>

<p>So, what does that make of $Cat$? I don’t know, perhaps we can call natural transformations “2-morphisms” and $Cat$ is some kind of “2-category”?</p>

<p>But wait, actually it’s way too early for you to find out. We haven’t even covered limits…</p>

<!--

-->


        
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Type Theory and Functional Programming (1999) [pdf] (172 pts)]]></title>
            <link>https://www.cs.cornell.edu/courses/cs6110/2015sp/textbook/Simon%20Thompson%20textbook.pdf</link>
            <guid>45435100</guid>
            <pubDate>Wed, 01 Oct 2025 07:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.cornell.edu/courses/cs6110/2015sp/textbook/Simon%20Thompson%20textbook.pdf">https://www.cs.cornell.edu/courses/cs6110/2015sp/textbook/Simon%20Thompson%20textbook.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45435100">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[High-resolution efficient image generation from WiFi Mapping (123 pts)]]></title>
            <link>https://arxiv.org/abs/2506.10605</link>
            <guid>45434941</guid>
            <pubDate>Wed, 01 Oct 2025 06:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2506.10605">https://arxiv.org/abs/2506.10605</a>, See on <a href="https://news.ycombinator.com/item?id=45434941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2506.10605">View PDF</a>
    <a href="https://arxiv.org/html/2506.10605v3">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We present LatentCSI, a novel method for generating images of the physical environment from WiFi CSI measurements that leverages a pretrained latent diffusion model (LDM). Unlike prior approaches that rely on complex and computationally intensive techniques such as GANs, our method employs a lightweight neural network to map CSI amplitudes directly into the latent space of an LDM. We then apply the LDM's denoising diffusion model to the latent representation with text-based guidance before decoding using the LDM's pretrained decoder to obtain a high-resolution image. This design bypasses the challenges of pixel-space image generation and avoids the explicit image encoding stage typically required in conventional image-to-image pipelines, enabling efficient and high-quality image synthesis. We validate our approach on two datasets: a wide-band CSI dataset we collected with off-the-shelf WiFi devices and cameras; and a subset of the publicly available MM-Fi dataset. The results demonstrate that LatentCSI outperforms baselines of comparable complexity trained directly on ground-truth images in both computational efficiency and perceptual quality, while additionally providing practical advantages through its unique capacity for text-guided controllability.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Eshan Ramesh [<a href="https://arxiv.org/show-email/ba45c6b6/2506.10605" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2506.10605v1" rel="nofollow">[v1]</a></strong>
        Thu, 12 Jun 2025 11:47:23 UTC (6,672 KB)<br>
            <strong><a href="https://arxiv.org/abs/2506.10605v2" rel="nofollow">[v2]</a></strong>
        Fri, 4 Jul 2025 12:27:28 UTC (6,672 KB)<br>
    <strong>[v3]</strong>
        Fri, 5 Sep 2025 11:39:36 UTC (9,960 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intelligent Kubernetes Load Balancing at Databricks (105 pts)]]></title>
            <link>https://www.databricks.com/blog/intelligent-kubernetes-load-balancing-databricks</link>
            <guid>45434417</guid>
            <pubDate>Wed, 01 Oct 2025 05:06:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.databricks.com/blog/intelligent-kubernetes-load-balancing-databricks">https://www.databricks.com/blog/intelligent-kubernetes-load-balancing-databricks</a>, See on <a href="https://news.ycombinator.com/item?id=45434417">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Introduction</h2><p>At Databricks, Kubernetes is at the heart of our internal systems. Within a single Kubernetes cluster, the default networking primitives like ClusterIP services, CoreDNS, and kube-proxy are often sufficient. They offer a simple abstraction to route service traffic. But when performance and reliability matter, these defaults begin to show their limits.</p><p>In this post, we’ll share how we built an intelligent, client-side load balancing system to improve traffic distribution, reduce tail latencies, and make service-to-service communication more resilient.</p><p>If you are a Databricks user, you don’t need to understand this blog to be able to use the platform to its fullest. But if you’re interested in taking a peek under the hood, read on to hear about some of the cool stuff we’ve been working on!</p><h2>Problem statement</h2><p>High-performance service-to-service communication in Kubernetes has several challenges, especially when using persistent HTTP/2 connections, as we do at Databricks with gRPC.</p><h3>How Kubernetes Routes Requests by Default</h3><ul><li>The client resolves the service name (e.g., my-service.default.svc.cluster.local) via CoreDNS, which returns the service’s ClusterIP (a virtual IP).</li><li>The client sends the request to the ClusterIP, assuming it's the destination.</li><li>On the node, iptables, IPVS, or eBPF rules (configured by kube-proxy) intercept the packet. The kernel rewrites the destination IP to one of the backend Pod IPs based on basic load balancing, such as round-robin, and forwards the packet.</li><li>The selected pod handles the request, and the response is sent back to the client.</li></ul><p>While this model generally works, it quickly breaks down in performance-sensitive environments, leading to significant limitations.</p><h3>Limitations</h3><p>At Databricks, we operate hundreds of stateless services communicating over gRPC within each Kubernetes cluster. These services are often high-throughput, latency-sensitive, and run at significant scale.</p><p>The default load balancing model falls short in this environment for several reasons:</p><ul><li><strong>High tail latency</strong>: gRPC uses HTTP/2, which maintains long-lived TCP connections between clients and services. Since Kubernetes load balancing happens at Layer 4, the backend pod is chosen only once per connection. This leads to traffic skew, where some pods receive significantly more load than others. As a result, tail latencies increase and performance becomes inconsistent under load.</li><li><strong>Inefficient resource usage</strong>: When traffic is not evenly spread, it becomes hard to predict capacity requirements. Some pods get CPU or memory starved while others sit idle. This leads to over-provisioning and waste.</li><li><strong>Limited load balancing strategies</strong>: kube-proxy supports only basic algorithms like round-robin or random selection. There's no support for strategies like:<ul><li><a data-external-link="true" href="https://sre.google/sre-book/load-balancing-datacenter/" target="_blank" rel="noopener noreferrer">Weighted round robin</a></li><li>Error-aware routing</li><li>Zone-aware traffic routing</li></ul></li></ul><p>These limitations pushed us to rethink how we handle service-to-service communication within a Kubernetes cluster.</p><h2>Our Approach: Client-Side Load Balancing with Real-Time Service Discovery</h2><p>To address the limitations of kube-proxy and default service routing in Kubernetes, we built a proxyless, fully client-driven load balancing system backed by a custom service discovery control plane.</p><p>The fundamental requirement we had was to support load balancing at the application layer, and removing dependency on the DNS on a critical path. A Layer 4 load balancer, like kube-proxy, cannot make intelligent per-request decisions for Layer 7 protocols (such as gRPC) that utilize persistent connections. This architectural constraint creates bottlenecks, necessitating a more intelligent approach to traffic management.</p><p>The following table summarizes the key differences and the advantages of a client-side approach:</p><p>Table 1: Default Kubernetes LB vs. Databricks' Client-Side LB</p><div><table><thead><tr><th>Feature/Aspect</th><th>Default Kubernetes Load Balancing (kube-proxy)</th><th>Databricks' Client-Side Load Balancing</th></tr></thead><tbody><tr><td>Load Balancing Layer</td><td>Layer 4 (TCP/IP)</td><td>Layer 7 (Application/gRPC)</td></tr><tr><td>Decision Frequency</td><td>Once per TCP connection</td><td>Per-request</td></tr><tr><td>Service Discovery</td><td>CoreDNS + kube-proxy (virtual IP)</td><td>xDS-based Control Plane + Client Library</td></tr><tr><td>Supported Strategies</td><td>Basic (Round-robin, Random)</td><td>Advanced (P2C, Zone-affinity, Pluggable)</td></tr><tr><td>Tail Latency Impact</td><td>High (due to traffic skew on persistent connections)</td><td>Reduced (even distribution, dynamic routing)</td></tr><tr><td>Resource Utilization</td><td>Inefficient (over-provisioning)</td><td>Efficient (balanced load)</td></tr><tr><td>Dependency on DNS/Proxy</td><td>High</td><td>Minimal/Minimal, not on a critical path</td></tr><tr><td>Operational Control</td><td>Limited</td><td>Fine-grained</td></tr></tbody></table></div><p>This system enables intelligent, up-to-date request routing with minimal dependency on DNS or Layer 4 networking. It gives clients the ability to make informed decisions based on live topology and health data.</p><!--/$--><p>The figure shows our custom Endpoint Discovery Service in action. It reads service and endpoint data from the Kubernetes API and translates it into xDS responses. Both Armeria clients and API proxies stream requests to it and receive live endpoint metadata, which is then used by application servers for intelligent routing with fallback clusters as backup.”</p><h3>Custom Control Plane (Endpoint discovery service)</h3><p>We run a lightweight control plane that continuously monitors the Kubernetes API for changes to Services and EndpointSlices. It maintains an up-to-date view of all backend pods for every service, including metadata like zone, readiness, and shard labels.</p><h3>RPC Client Integration</h3><p>A strategic advantage for Databricks was the widespread adoption of a common framework for service communication across most of its internal services, which are predominantly written in Scala. This shared foundation allowed us to embed client-side service discovery and load balancing logic directly into the framework, making it easy to adopt across teams without requiring custom implementation effort.</p><p>Each service integrates with our custom client, which subscribes to updates from the control plane for the services it depends on during the connection setup. The client maintains a dynamic list of healthy endpoints, including metadata like zone or shard, and updates automatically as the control plane pushes changes.</p><p>Because the client bypasses both DNS resolution and kube-proxy entirely, it always has a live, accurate view of service topology. This allows us to implement consistent and efficient load balancing strategies across all internal services.</p><h3>Advanced Load Balancing in Clients</h3><p>The rpc client performs request-aware load balancing using strategies like:</p><ul><li><strong>Power of Two Choices (P2C):</strong> For the majority of services, a simple Power of Two Choices (P2C) <a data-external-link="true" href="https://www.eecs.harvard.edu/~michaelm/postscripts/handbook2001.pdf" target="_blank" rel="noopener noreferrer">algorithm</a> has proven remarkably effective. This strategy involves randomly selecting two backend servers and then choosing the one with fewer active connections or lower load. Databricks' experience indicates that P2C strikes a strong balance between performance and implementation simplicity, consistently leading to uniform traffic distribution across endpoints.</li><li><strong>Zone-affinity-based:</strong> The system also supports more advanced strategies, such as zone-affinity-based routing. This capability is vital for minimizing cross-zone network hops, which can significantly reduce network latency and associated data transfer costs, especially in geographically distributed Kubernetes clusters.<p>The system also accounts for scenarios where a zone lacks sufficient capacity or becomes overloaded. In such cases, the routing algorithm intelligently spills traffic over to other healthy zones, balancing load while still preferring local affinity whenever possible. This ensures high availability and consistent performance, even under uneven capacity distribution across zones.</p></li><li><strong>Pluggable Support:</strong> The architecture's flexibility allows for pluggable support for additional load balancing strategies as needed.</li></ul><p>More advanced strategies, like zone-aware routing, required careful tuning and deeper context about service topology, traffic patterns, and failure modes; a topic to explore in a dedicated follow-up post.</p><p>To ensure the effectiveness of our approach, we ran extensive simulations, experiments, and real-world metric analysis. We validated that load remained evenly distributed and that key metrics like tail latency, error rate, and cross-zone traffic cost stayed within target thresholds. The flexibility to adapt strategies per-service has been valuable, but in practice, keeping it simple (and consistent) has worked best.</p><h3>xDS Integration with Envoy</h3><p>Our control plane extends its utility beyond the internal service-to-service communication. It plays a crucial role in managing external traffic by speaking the <a data-external-link="true" href="https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol" aria-label="Envoy's xDS API documentation" target="_blank" rel="noopener noreferrer">xDS</a> API to Envoy, the discovery protocol that lets clients fetch up-to-date configuration (like clusters, endpoints, and routing rules) dynamically. Specifically, it implements Endpoint Discovery Service (EDS) to provide Envoy with consistent and up-to-date metadata about backend endpoints by programming <a data-external-link="true" href="https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/endpoint/v3/endpoint.proto#config-endpoint-v3-clusterloadassignment" target="_blank" rel="noopener noreferrer">ClusterLoadAssignment</a> resources. This ensures that gateway-level routing (e.g., for ingress or public-facing traffic) aligns with the same source of truth used by internal clients.</p><h3>Summary</h3><p>This architecture gives us fine-grained control over routing behavior while decoupling service discovery from the limitations of DNS and kube-proxy. The key takeaways are:</p><ol><li>clients always have a live, accurate view of endpoints and their health,</li><li>load balancing strategies can be tailored per-service, improving efficiency and tail latency, and</li><li>both internal and external traffic share the same source of truth, ensuring consistency across the platform.</li></ol></div><div><h2>Impact</h2><p>After deploying our client-side load balancing system, we observed significant improvements across both performance and efficiency:</p><ul><li><strong>Uniform Request Distribution</strong><br>Server-side QPS became evenly distributed across all backend pods. Unlike the prior setup, where some pods were overloaded while others remained underutilized, traffic now spreads predictably. The top chart shows the distribution <em>before EDS,</em> while the bottom chart shows the balanced distribution <em>after EDS</em>.<br><!--$--><!--/$--></li><li><strong>Stable Latency Profiles</strong><br>The variation in latency across pods dropped noticeably. Latency metrics improved and stabilized across pods, reducing long-tail behavior in gRPC workloads. The diagram below shows how P90 latency became more stable after client-side load balancing was enabled.<br><img src="https://www.databricks.com/sites/default/files/inline-images/2025-09-blog-intelligent-kubernetes-load-balancing-databricks-inline-1200x628-2x_0.png" data-entity-uuid="608b5540-e67d-4022-92fb-46141ae12d20" data-entity-type="file" alt="stable latency profiles" width="2400" height="1256" loading="lazy" data-ot-ignore="1"></li><li><strong>Resource Efficiency</strong><br>With more predictable latency and balanced load, we were able to reduce over-provisioned capacity. Across several services, this resulted in approximately a 20% reduction in pod count, freeing up compute resources without compromising reliability.</li></ul><h3>Challenges and Lessons Learned</h3><p>While the rollout delivered clear benefits, we also uncovered several challenges and insights along the way:</p><ul><li><strong>Server cold starts:</strong> Before client-side load balancing, most requests were sent over long-lived connections, so new pods were rarely hit until existing connections were recycled. After the shift, new pods began receiving traffic immediately, which surfaced cold-start issues where they handled requests before being fully warmed up. We addressed this by introducing slow-start ramp-up and biasing traffic away from pods with higher observed error rates. These lessons also reinforced the need for a dedicated warmup framework.</li><li><strong>Metrics-based routing:</strong> We initially experimented with skewing traffic based on resource usage signals such as CPU. Although conceptually attractive, this approach proved unreliable: monitoring systems had different SLOs than serving workloads, and metrics like CPU were often trailing indicators rather than real-time signals of capacity. We ultimately moved away from this model and chose to rely on more dependable signals such as server health.</li><li><strong>Client-library integration:</strong> Building load balancing directly into client libraries brought strong performance benefits, but it also created some unavoidable gaps. Languages without the library, or traffic flows that still depend on infrastructure load balancers, remain outside the scope of client-side balancing.</li></ul><h2>Alternatives Considered</h2><p>While developing our client-side load balancing approach, we evaluated other alternative solutions. Here’s why we ultimately decided against these:</p><h3>Headless Services</h3><p>Kubernetes headless services (clusterIP: None) provide direct pod IPs via DNS, allowing clients and proxies (like Envoy) to perform their own load balancing. This approach bypasses the limitation of connection-based distribution in kube-proxy and enables advanced load balancing strategies offered by Envoy (such as round robin, consistent hashing, and least-loaded round robin).</p><p>In theory, switching existing ClusterIP services to headless services (or creating additional headless services using the same selector) would mitigate connection reuse issues by providing clients direct endpoint visibility. However, this approach comes with practical limitations:</p><ul><li><strong>Lack of Endpoint Weights:</strong> Headless services alone don't support assigning weights to endpoints, restricting our ability to implement fine-grained load distribution control.</li><li><strong>DNS Caching and Staleness:</strong> Clients frequently cache DNS responses, causing them to send requests to stale or unhealthy endpoints.</li><li><strong>No Support for Metadata:</strong> DNS records do not carry any additional metadata about the endpoints (e.g., zone, region, shard). This makes it difficult or impossible to implement strategies like zone-aware or topology-aware routing.</li></ul><p>Although headless services can offer a temporary improvement over ClusterIP services, the practical challenges and limitations made them unsuitable as a long-term solution at Databricks' scale.</p><h3>Service Meshes (e.g., Istio)</h3><p>Istio provides powerful Layer 7 load balancing features using Envoy sidecars injected into every pod. These proxies handle routing, retries, circuit breaking, and more - all managed centrally through a control plane.</p><p>While this model offers many capabilities, we found it unsuitable for our environment at Databricks for a few reasons:</p><ul><li><strong>Operational complexity:</strong> Managing thousands of sidecars and control plane components adds significant overhead, particularly during upgrades and large-scale rollouts.</li><li><strong>Performance overhead:</strong> Sidecars introduce additional CPU, memory, and latency costs per pod — which becomes substantial at our scale.</li><li><strong>Limited client flexibility:</strong> Since all routing logic is handled externally, it’s difficult to implement request-aware strategies that rely on application-layer context.</li></ul><p>We also evaluated Istio’s Ambient Mesh. Since Databricks already had proprietary systems for functions like certificate distribution, and our routing patterns were relatively static, the added complexity of adopting a full mesh outweighed the benefits. This was especially true for a small infra team supporting a predominantly Scala codebase.</p><p>It is worth noting that one of the biggest advantages of sidecar-based meshes is language-agnosticism: teams can standardize resiliency and routing across polyglot services without maintaining client libraries everywhere. At Databricks, however, our environment is heavily Scala-based, and our monorepo plus fast CI/CD culture make the proxyless, client-library approach far more practical. Rather than introducing the operational burden of sidecars, we invested in building first-class load balancing directly into our libraries and infrastructure components.</p><h2>Future directions and Areas of exploration</h2><p>Our current client-side load balancing approach has significantly improved internal service-to-service communication. Yet, as Databricks continues to scale, we’re exploring several advanced areas to further enhance our system:</p><p><strong>Cross-Cluster and Cross-Region Load Balancing:</strong> As we manage thousands of Kubernetes clusters across multiple regions, extending intelligent load balancing beyond individual clusters is critical. We are exploring technologies like flat L3 networking and service-mesh solutions, integrating seamlessly with multi-region Endpoint Discovery Service (EDS) clusters. This will enable robust cross-cluster traffic management, fault tolerance, and globally efficient resource utilization.</p><p><strong>Advanced Load Balancing Strategies for AI Use Cases:</strong> We plan to introduce more sophisticated strategies, such as weighted load balancing, to better support advanced AI workloads. These strategies will enable finer-grained resource allocation and intelligent routing decisions based on specific application characteristics, ultimately optimizing performance, resource consumption, and cost efficiency.</p><p>If you're interested in working on large-scale distributed infrastructure challenges like this, we're hiring. Come build with us — explore <a data-external-link="true" href="https://www.databricks.com/company/careers">open roles at Databricks</a>!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US government shuts down after Senate fails to pass last-ditch funding plan (162 pts)]]></title>
            <link>https://www.bbc.com/news/live/clylje0rmp2t</link>
            <guid>45434146</guid>
            <pubDate>Wed, 01 Oct 2025 04:05:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/live/clylje0rmp2t">https://www.bbc.com/news/live/clylje0rmp2t</a>, See on <a href="https://news.ycombinator.com/item?id=45434146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="list" spacing="6" tabindex="0" data-testid="postList"><li><div><article data-testid="content-post" id="asset:616adca4-cb19-483b-9d2f-1bd5ea2db538"><header><span><h3 type="normal"><span role="text"><span>What about the mail?</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 11:17 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="United States Postal Service delivery vehicle" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/2e247a53-d5ab-4d6e-acec-0858bf7ae774.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/2e247a53-d5ab-4d6e-acec-0858bf7ae774.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/2e247a53-d5ab-4d6e-acec-0858bf7ae774.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/2e247a53-d5ab-4d6e-acec-0858bf7ae774.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/2e247a53-d5ab-4d6e-acec-0858bf7ae774.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/2e247a53-d5ab-4d6e-acec-0858bf7ae774.jpg.webp 800w" width="1024" height="576"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure><p>The US Postal Service has previously been unaffected by government shutdowns, and it says this time it will be no different.</p><p>In a statement posted on its website earlier this week, the US Postal Service says all post offices will remain open for business as usual. </p><p>This is because it's an independent entity that is generally funded through the sale of its products and services, and not by tax dollars.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:0c56d807-2e0e-4888-9890-0b596bc88755"><header><span><h3 type="normal"><span role="text"><span>How long could this shutdown last?</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:42 BST</span></span></span></span></h3></span></header>
      <p>We don't know exactly how long this government shutdown will last as it will only be resolved once Congress passes a funding bill.</p><p>As we've been reporting, this is not the first time such a shutdown has happened. </p><p>The longest in American history lasted 35 days and took place during Trump's first term in office.</p><p>In the past, shutdowns have ranged in length:</p><ul><li spacing="rich-text">
      The second longest shutdown was in December 1995 - <b>it lasted 21 days </b>
    </li><li spacing="rich-text">
      During Barack Obama's presidency, a shutdown <b>lasted 16 days</b> 
    </li></ul><ul><li spacing="rich-text">
      Between 1982 and 1987, four government shutdowns lasted <b>just one day each</b>
    </li><li spacing="rich-text">
      Under former President Bill Clinton, a federal shutdown <b>lasted 5 days</b>
    </li></ul>
    </article></div></li><li><div><article data-testid="content-post" id="asset:4a2940eb-82df-4826-9eab-2281f0bc8db5"><header><span><h3 type="normal"><span role="text"><span>Are you a federal worker in the US? Get in touch</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:41 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="Banner reading 'Your Voice Your BBC News', with headshots of three people" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/411ada14-5fe3-4dc2-a80d-29ed2668bb92.png.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/411ada14-5fe3-4dc2-a80d-29ed2668bb92.png.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/411ada14-5fe3-4dc2-a80d-29ed2668bb92.png.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/411ada14-5fe3-4dc2-a80d-29ed2668bb92.png.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/411ada14-5fe3-4dc2-a80d-29ed2668bb92.png.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/411ada14-5fe3-4dc2-a80d-29ed2668bb92.png.webp 800w" width="1510" height="110"></span></p></figure><p>If you're a federal worker in the US, and feel comfortable sharing your experience about the government shutdown, please consider reaching out.</p><p>You can get in touch in the following ways:   </p><ul><li spacing="rich-text">
      <a href="https://www.bbc.co.uk/send/u218210015">Use this form</a>
    </li></ul><ul><li spacing="rich-text">
      Email: <a href="mailto:bbcyourvoice@bbc.co.uk?subject=USGovernmentShutdown">bbcyourvoice@bbc.co.uk, external<span>, <!-- -->external</span></a>  
    </li></ul><ul><li spacing="rich-text">
      WhatsApp: <a href="https://api.whatsapp.com/send?phone=+447756165803">+44 7756 165803 , external<span>, <!-- -->external</span></a>  
    </li></ul><ul><li spacing="rich-text">
      <a href="https://www.bbc.co.uk/send/u16904890">Upload your pictures and video</a>   
    </li></ul><p> Please read our <a href="http://www.bbc.co.uk/usingthebbc/terms/">terms &amp; conditions</a> and <a href="http://www.bbc.co.uk/usingthebbc/privacy-policy/">privacy policy</a>.</p><p><i>In some cases a selection of your comments and questions will be published, displaying your name and location as you provide it unless you state otherwise. Your contact details will never be published.   </i></p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:e93cff57-e3a2-44c0-b2a6-e5694af145ef"><header><span><h3 type="normal"><span role="text"><span>Democrats call for 'credible' bipartisan action to end shutdown</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 10:09 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="Two men in suits at a podium" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/f0635c76-8333-4615-be75-3c848aa02660.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/f0635c76-8333-4615-be75-3c848aa02660.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/f0635c76-8333-4615-be75-3c848aa02660.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/f0635c76-8333-4615-be75-3c848aa02660.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/f0635c76-8333-4615-be75-3c848aa02660.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/f0635c76-8333-4615-be75-3c848aa02660.jpg.webp 800w" width="997" height="561"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>Chuck Schumer, the US Senate's top Democrat, on the right, and House Minority Leader Hakeem Jeffries, on the left, address the press</p></figcaption></figure><p>Two senior Democrats have released a joint statement calling for a bipartisan effort to end the government shutdown. </p><p>"Democrats remain ready to find a bipartisan path forward to reopen the government," says the statement, signed by Chuck Schumer, the US Senate's top Democrat, and House Minority Leader Hakeem Jeffries. </p><p>Continuing <a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3A3b25b328-e9ea-41ed-83e7-fdad872cd031#post">the finger-pointing we've seen so far</a>, the statement places the blame for the shutdown on the Republicans. </p><p>"Donald Trump and the Republicans have now shut down the federal government because they do not want to protect the healthcare of the American people," it continues. </p><p>The Republicans, however, blame the Democrats for the impasse, with House Speaker Mike Johnson calling the party's demand to extend Obamacare tax credits a "red herring". </p><ul><li spacing="rich-text">
      <i>For more details on how we got here, read our </i><a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3Ac912b3a0-5b46-4fd6-a7d7-028abc122bdb#post">explainer post from earlier today</a>
    </li></ul>
    </article></div></li><li><div><article data-testid="content-post" id="asset:c832e9fc-4982-4f5b-9fd8-3309dfce1318"><header><span><h3 type="normal"><span role="text"><span>Are flights still taking off - and three other big questions answered</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:47 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="TSA agents inspect security goods at an airport" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/15827c37-cbd5-438b-86b0-aa6f27c8b7c3.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/15827c37-cbd5-438b-86b0-aa6f27c8b7c3.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/15827c37-cbd5-438b-86b0-aa6f27c8b7c3.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/15827c37-cbd5-438b-86b0-aa6f27c8b7c3.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/15827c37-cbd5-438b-86b0-aa6f27c8b7c3.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/15827c37-cbd5-438b-86b0-aa6f27c8b7c3.jpg.webp 800w" width="1024" height="576"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Transportation Safety Administration (TSA) employees will continue working during the government shutdown</p></figcaption></figure><p><b>Will flights take off?</b></p><ul><li spacing="rich-text">
      Air traffic control and Transportation Safety Administration (TSA) workers are considered "essential" - <a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3A7a1e9d35-5e8b-460e-811a-b9bbdceaad23#post">so will continue to work</a> 
    </li><li spacing="rich-text">
      But during the last shutdown, these workers increasingly began to call in sick, leading to delays in security checks at major airports
    </li><li spacing="rich-text">
      Flight systems might also "need to slow down, reducing efficiency" - according to airline representative Airlines for America
    </li></ul><p><b>Will government employees be paid?</b></p><ul><li spacing="rich-text">
      Around 750,000 federal workers will be taking unpaid leave each day, according to an estimate from the Congressional Budget Office (CBO)
    </li><li spacing="rich-text">
      The total daily cost of their compensation will be roughly $400m (£297m), the CBO says 
    </li><li spacing="rich-text">
      Members of Congress, <a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3Adb4d8c3b-668e-4c19-b907-f5e16949903f#post">as we just reported</a>, will continue getting paid as its required by the US Constitution
    </li></ul><p><b>Will mail be delivered?</b></p><ul><li spacing="rich-text">
      The US Postal Service would be unaffected because it does not depend on Congress for funding
    </li><li spacing="rich-text">
      Post offices will stay open
    </li></ul><p><b>What about law enforcement services?</b></p><ul><li spacing="rich-text">
      Law enforcement officers will continue to work through the government shutdown - though over <a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3Acacac2a3-9891-47f2-8e13-fe74c7248dff#post">200,000 of them will do so unpaid</a>
    </li><li spacing="rich-text">
      Also continuing their work as usual are those in border protection, in-hospital medical care, and air-traffic control
    </li></ul>
    </article></div></li><li><div><article data-testid="content-post" id="asset:d02da3fd-29da-4bd1-bf26-c8d155332105"><header><span><img src="https://static.files.bbci.co.uk/core/website/assets/static/news/incident-types/analysis.77b314ef10.svg" alt="Analysis" draggable="false"><h3 type="normal"><span role="text"><span>Why government shutdowns seem to be a uniquely American problem</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:28 BST</span></span></span></span></h3></span></header><p><span><strong>Robert Levinson King and Anthony Zurcher</strong><br>BBC News</span></p>
      <figure><p><span><img alt="The US Capitol building" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/befab3e5-be76-4123-bc17-dfb79f2b5f14.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/befab3e5-be76-4123-bc17-dfb79f2b5f14.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/befab3e5-be76-4123-bc17-dfb79f2b5f14.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/befab3e5-be76-4123-bc17-dfb79f2b5f14.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/befab3e5-be76-4123-bc17-dfb79f2b5f14.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/befab3e5-be76-4123-bc17-dfb79f2b5f14.jpg.webp 800w" width="1024" height="683"></span><span role="text"><span>Image source, </span>Getty Images</span></p></figure><p>The US government has now shut down eleven times over the past 40-plus years. </p><p>Meanwhile, in other countries, governments keep functioning, even in the midst of wars and constitutional crises. </p><p>So why does this uniquely American phenomenon keep happening?</p><p>America's federal system of government allows different branches of government to be controlled by different parties - a structure devised by the nation's founders to encourage deliberation.</p><p>That was until 1980. A narrow interpretation of the 1884 Anti-Deficiency Act, during Jimmy Carter's presidency, banned the government from entering into contracts without congressional approval. This took took a much stricter view: no budget, no spending.</p><p>That interpretation has set the US apart from other non-parliamentary democracies. </p><p>Now in the US, warring political parties seem all-too willing to use the day-to-day functioning of the government as a bargaining chip to extract demands from the other side.</p><ul><li spacing="rich-text">
      <i>Read more on </i><a href="https://www.bbc.co.uk/news/world-us-canada-66965637">how US government shutdowns have become a perennial phenomenon</a>
    </li></ul>
    </article></div></li><li><div><article data-testid="content-post" id="asset:db4d8c3b-668e-4c19-b907-f5e16949903f"><header><span><h3 type="normal"><span role="text"><span>Are people working for free now?</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 09:01 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="A man with glasses, a shirt and black jacket" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/524721f8-2629-4114-98d4-a1534e9be20e.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/524721f8-2629-4114-98d4-a1534e9be20e.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/524721f8-2629-4114-98d4-a1534e9be20e.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/524721f8-2629-4114-98d4-a1534e9be20e.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/592/cpsprodpb/vivo/live/images/2025/10/1/524721f8-2629-4114-98d4-a1534e9be20e.jpg.webp 592w" width="592" height="333"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Senator Andy Kim said he would forgo pay in the event of a government shutdown</p></figcaption></figure><p>As we just mentioned, there are thousands of essential workers who will still have to show up for work during the government shutdown. </p><p>While that is happening, federal workers will not receive new payslips.</p><p>So, depending on when their payday falls and how long the shutdown lasts for, many workers may not get paid on time. </p><p>Furloughed and essential employees will instead receive backpay when the government opens up again.</p><p>There is an exception to this: members of Congress, whose pay is protected under the US Constitution. </p><p>It's a convention that's been opposed by some lawmakers.</p><p>Andy Kim, a Democratic senator for New Jersey, said in a statement yesterday that he would forgo pay in the event of a shutdown, saying "government leaders shouldn't be playing with other people's chips".</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:59225d2e-11b7-46b6-ac27-4f80cb30e87c"><header><span><h3 type="normal"><span role="text"><span>Who has to show up for work, and who is staying home</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 08:48 BST</span></span></span></span></h3></span></header>
      <p>Ahead of the government shutdown, federal agencies began sharing their plans on their respective websites. </p><p>Some departments, like the Department Homeland Security, are <b>retaining</b> the majority of their staff - this means they are required to come to work as normal. </p><p>Many others, however, are <b>furloughing</b> their staff - this means they are not required to show up to work. </p><p>According to our partner, CBS News, the five government departments furloughing the most staff are:</p><ul><li spacing="rich-text">
      <b>Department of Defense (civilian staff)</b>: 334,904 furloughed, with 406,573 retained
    </li><li spacing="rich-text">
      <b>Department of Health: </b>32,460 furloughed, with 47,257 retained
    </li><li spacing="rich-text">
      <b>Department of Commerce:</b> 34,711 furloughed, with 8,273 retained
    </li><li spacing="rich-text">
      <b>Department of State:</b> 16,651 furloughed, with 10,344 retained
    </li><li spacing="rich-text">
      <b>Nasa: </b>15,094 furloughed, with 3,124 retained
    </li></ul>
    </article></div></li><li><div><article data-testid="content-post" id="asset:7a1e9d35-5e8b-460e-811a-b9bbdceaad23"><header><span><h3 type="normal"><span role="text"><span>Travelling to the US this week? Here's what you need to know</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 08:28 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="A man walks along the side of a building with a sign reading &quot;Smithsonian&quot;" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/c9d55870-f926-4527-b512-62a75aa8d32e.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/c9d55870-f926-4527-b512-62a75aa8d32e.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/c9d55870-f926-4527-b512-62a75aa8d32e.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/c9d55870-f926-4527-b512-62a75aa8d32e.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/c9d55870-f926-4527-b512-62a75aa8d32e.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/c9d55870-f926-4527-b512-62a75aa8d32e.jpg.webp 800w" width="4806" height="2703"></span><span role="text"><span>Image source, </span>EPA</span></p><figcaption><span>Image caption, </span><p>The Smithsonian Institution has said it has enough funds to remain open for a week</p></figcaption></figure><p>Federal services will be affected in different ways by the shutdown. So if you're planning to visit the US soon, you should plan ahead as it's very possible you'll encounter some disruptions.</p><p><b>Your flight plans may be affected</b></p><p>Air traffic control and Transportation Safety Administration (TSA) workers are considered "essential" - so will continue to work. However, as with other essential workers, they won't be paid until the shutdown resolves.</p><p>During the last shutdown, these workers increasingly began to call in sick, leading to airport delays.</p><p>The US Department of Transportation's shutdown plans outline that hiring and training of air traffic controllers will continue.</p><p><b>Public transport within the US should continue as normal</b></p><p>The Rail Passengers Association said last week that Amtrak, and transit systems, should not be affected in the short term. </p><p>Most other forms of public transit in the US - like city buses, subways, light rails, trams, and ferries - are not federally funded and so will run as normal.</p><p><b>Attractions and landmarks will be affected differently</b></p><p>An Interior Department contingency plan has outlined that national parks will remain partially open. </p><p>In Washington DC and New York, the Smithsonian Institution which owns many museums as well as the National Zoo has <a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3A46077ee4-e49a-4f80-ac1f-7bab62937a27#post">said it has enough funds to remain open for a week</a>. </p><p>According to the American Alliance of Museums - the Smithsonian's museums lost an estimated one million visitors during the last government shutdown in late 2018.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:aac584f5-7b6a-4706-8fe3-38865b70918a"><header><span><h3 type="normal"><span role="text"><span>Trump threatens mass layoffs as government shutdown starts</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 08:07 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="Donald Trump is seen in closeup" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/0640eb30-663d-408e-ae50-8837bcecab39.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/0640eb30-663d-408e-ae50-8837bcecab39.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/0640eb30-663d-408e-ae50-8837bcecab39.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/0640eb30-663d-408e-ae50-8837bcecab39.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/0640eb30-663d-408e-ae50-8837bcecab39.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/0640eb30-663d-408e-ae50-8837bcecab39.jpg.webp 800w" width="1000" height="563"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>Ahead of the government shutdown, President Trump suggested that "vast numbers of people" could be laid off - something that he said would be "irreversible".</p><p>Threats like that, says Eric Ham, a political analyst and former congressional staffer, could initially be viewed as a "tool" to try to get the Democrats to back down from their ongoing demands.</p><p>But now the government has shut down, more layoffs are "certainly something that could be on the table", he tells BBC News Channel. </p><ul><li spacing="rich-text">
      <b><i>For context:</i></b><i> The US president is the head of the executive branch of government, and was not involved in the Senate vote leading to the shutdown. </i>
    </li></ul><p>Trump, Ham says, could see this as an opportunity, as the US president has previously "made it clear" he wants to streamline the government.</p><p>Since taking office, Trump has fired thousands of federal workers through his cost-cutting initiative with the Department of Government Efficiency (Doge).</p><p>And then in a memo circulated by the White House last Thursday, it also <a href="https://www.bbc.co.uk/news/articles/c5y4de02x3wo">warned agencies to prepare for mass firings</a> in the event of a shutdown.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:384f0717-b51c-4b47-a064-53159b52109e"><header><span><h3 type="normal"><span role="text"><span>From missed wages, to potential layoffs - here's how the shutdown can affect people</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 07:42 BST</span></span></span></span></h3></span></header><p><span><strong>Emer Moreau</strong><br>BBC News</span></p>
      <p>Wayne Winegarden has been speaking to BBC Radio 4’s Today programme, and he says the first place you're going to see an impact is on workers.</p><p>“If you work for the federal government, you’re not going to go to work, you're not going to get paid,” the senior fellow in business and economics at the Pacific Research Institute says.</p><p>“If you’re a contractor, again, you’re not going to get your payments.”</p><p>The longer the shutdown goes on, the more people will feel it - when the cash for social security payments runs out, families receiving those payments will take a hit.</p><p>If it goes on longer again, services like the US national parks could see their funding streams dry up.</p><p>Winegarden also notes that it's difficult to know if President Trump will use this shutdown as an excuse to accelerate his plans to make large cuts to the number of federal workers.</p><p>"We’ve seen that in past cuts where they’ve fired people and then realised ‘whoops, we need those people', and then hire them back."</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:f636dfa2-0f3f-42eb-a2f4-e9a32ea72bf5"><header><span><h3 type="normal"><span role="text"><span>Jobs, travel, national parks - what remains open, and what is now closed</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 07:33 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="A sign in front of the National Park Service reads: Because of the Federal Government SHUTDOWN, All National Parks Are CLOSED" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/76f35197-6075-491c-91d8-d290faaff71e.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/76f35197-6075-491c-91d8-d290faaff71e.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/76f35197-6075-491c-91d8-d290faaff71e.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/76f35197-6075-491c-91d8-d290faaff71e.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/76f35197-6075-491c-91d8-d290faaff71e.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/76f35197-6075-491c-91d8-d290faaff71e.jpg.webp 800w" width="974" height="548"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>During the last shutdown in late 2018, the Trump administration made the decision to leave parks open, with few to no federal workers there to staff them</p></figcaption></figure><p>A memo released by the White House yesterday warned agencies that would be affected by the shutdown to "execute their plans for an orderly shutdown".</p><p>It explained that the duration of a shutdown is difficult to predict. Many agencies will be affected by the situation - but some services will continue.</p><p>Previous shutdowns have resulted in federal lands, including <b>National Parks and National Forests</b>, being closed to the public. This time around, however, national parks will remain partially open, according to an <a href="https://www.doi.gov/sites/default/files/documents/2025-09/doi-nps-lapse-plan2025930508.pdf">Interior Department contingency plan posted Tuesday evening.<span>, <!-- -->external</span></a></p><p>The Coalition to Protect America's National Parks penned a letter last week pushing for parks to close in the event of a shutdown for fear of damage to the landscapes and visitor safety.</p><p><b>Medicare and Medicaid,</b> social health programmes for the elderly and poor, will continue, but staffing shortages could lead to some interruptions to services.</p><p>The <b>National Flood Insurance Program</b> will be closed, which will affect property sales.</p><p><b>Food assistance programmes </b>will also be impacted, with the Supplemental Nutrition Program for Women, Infants, and Children (WIC) expected to rapidly run out of funds.</p><p><b>Border protection</b>, <b>in-hospital medical care</b>, <b>law enforcement </b>and <b>air-traffic control </b>should all continue.</p><p>A federal shutdown is likely to impact flyers, as there could potentially be long security queues, and delays caused by unpaid air traffic controllers choosing to stay home rather than work for free.</p><p>We've got <a href="https://www.bbc.co.uk/news/articles/cgj1p485p0no">more on this in our explainer</a>.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:cacac2a3-9891-47f2-8e13-fe74c7248dff"><header><span><h3 type="normal"><span role="text"><span>Some law enforcement officers will continue working - but without pay</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 07:11 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="A woman with long brunette hair" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/43f2c9b6-829e-43bb-897b-3b225f223dba.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/43f2c9b6-829e-43bb-897b-3b225f223dba.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/43f2c9b6-829e-43bb-897b-3b225f223dba.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/43f2c9b6-829e-43bb-897b-3b225f223dba.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/43f2c9b6-829e-43bb-897b-3b225f223dba.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/43f2c9b6-829e-43bb-897b-3b225f223dba.jpg.webp 800w" width="997" height="561"></span><span role="text"><span>Image source, </span>Reuters</span></p></figure><p>Law enforcement officers will continue to work through the government shutdown, says Kristi Noem, who heads up the Department of Homeland Security (DHS). </p><p>"More than 200,000 of these patriots will go without pay," she writes on X.</p><p>Noem goes on to blame the Democrats for the shutdown, saying it's "forcing over 150,000 officers and nearly 50,000 members of the military - our frontline of defense - to continue protecting our nation without pay". </p><p>Her statement follows reporting by CBS News, the BBC's US partner, which found the DHS expected about 258,000 Homeland Security workers would be exempt from furlough in the event of a government shutdown. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:c912b3a0-5b46-4fd6-a7d7-028abc122bdb"><header><span><h3 type="normal"><span role="text"><span>How did we get here?</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 06:46 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="An empty Senate hallway with ornate flooring" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/7765dcaa-6d12-43dd-bc62-2011b76f127e.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/7765dcaa-6d12-43dd-bc62-2011b76f127e.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/7765dcaa-6d12-43dd-bc62-2011b76f127e.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/7765dcaa-6d12-43dd-bc62-2011b76f127e.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/7765dcaa-6d12-43dd-bc62-2011b76f127e.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/7765dcaa-6d12-43dd-bc62-2011b76f127e.jpg.webp 800w" width="5000" height="2814"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>The Senate emptied out overnight as lawmakers failed to find an agreement</p></figcaption></figure><p>As we've been reporting, the US government shut down almost two hours ago.</p><p>The Republican-controlled Senate failed to pass a last-minute government spending bill yesterday, which could have averted the shutdown.</p><p>The Republicans were pushing to pass a bill to extend government funding without other initiatives attached - known as a clean CR - or continuing resolution.</p><p>But they only have <b>53 seats</b> in the Senate - and need <b>60 votes</b> to pass such a bill.</p><p>This meant they needed the Democrats support to pass the bill - and the Democrats knew that.</p><p>The Democrats sought to capitalise on that leverage to try and advance their policy goals in health care, which included: </p><ul><li spacing="rich-text">
      Ensuring subsidies for health insurance for low-income individuals do not expire 
    </li><li spacing="rich-text">
      Reversing the Trump administration's cuts to Medicaid
    </li></ul><p>So they came to a standoff - with each party subsequently blaming the other for the shutdown - and one which won't be resolved until Congress passes a funding bill.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:f4faada1-b971-4936-a262-d0d808ddb544"><header><span><h3 type="normal"><span role="text"><span>White House starts tracking length of government shutdown</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 06:25 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="A black screen shows a timer that reads 00:00:00 in orange" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/463464f8-773c-4a88-a7d7-d791ebf79a8a.png.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/463464f8-773c-4a88-a7d7-d791ebf79a8a.png.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/463464f8-773c-4a88-a7d7-d791ebf79a8a.png.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/463464f8-773c-4a88-a7d7-d791ebf79a8a.png.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/463464f8-773c-4a88-a7d7-d791ebf79a8a.png.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/463464f8-773c-4a88-a7d7-d791ebf79a8a.png.webp 800w" width="1252" height="646"></span><span role="text"><span>Image source, </span>White House</span></p></figure><p>A bit earlier, <a href="https://www.bbc.co.uk/news/live/clylje0rmp2t?post=asset%3Abdd03316-22d4-4050-aae6-133d03ef694c#post">we brought you the details</a> about how the White House had launched a shutdown countdown clock on its website.</p><p>That clock has now been swapped out for a timer that is now tracking how long the government remains shutdown.</p><p>The website now reads "Democrats have shutdown the government".</p><p><b><i>For context:</i></b><i> Both </i><a href="https://www.bbc.com/news/live/clylje0rmp2t?post=asset%3Aafcd4d58-a036-48f9-a361-b2c82a1e2508#post">Democrats and Republicans are laying blame on each other</a><i> when it comes to the shutdown. While Republicans control both chambers of Congress, they fall short of the 60 votes needed in the Senate to pass a spending bill.</i></p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:3b25b328-e9ea-41ed-83e7-fdad872cd031"><header><span><h3 type="normal"><span role="text"><span>Republicans and Democrats point fingers as shutdown comes into effect</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 06:04 BST</span></span></span></span></h3></span></header>
      <p>As the US federal government shutdown started an hour ago, members of both parties are laying the blame on one another. </p><p>From the Democrats: </p><ul><li spacing="rich-text">
      <b>Congressman Bill Foster</b> issues a statement saying Republicans bear responsibility for the shutdown, given they control the House, the Senate and the White House. Families across the country will "continue to pay the price" unless the Republicans come to the table, he adds.
    </li><li spacing="rich-text">
      <b>Representative Joe Morelle</b> says he's "deeply frustrated", and the shutdown was a direct result of "a brutal and incompetent administration" 
    </li><li spacing="rich-text">
      <b>California Governor  Gavin Newsom</b> shares on X a photo of Trump in his office, calling the president  a "very weak man who can't even do stairs"
    </li></ul><figure><p><span><img alt="Gavin Newsom" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/fb151098-f90f-4b7d-9fa1-dff519aff6f9.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/fb151098-f90f-4b7d-9fa1-dff519aff6f9.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/fb151098-f90f-4b7d-9fa1-dff519aff6f9.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/fb151098-f90f-4b7d-9fa1-dff519aff6f9.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/fb151098-f90f-4b7d-9fa1-dff519aff6f9.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/fb151098-f90f-4b7d-9fa1-dff519aff6f9.jpg.webp 800w" width="2024" height="1139"></span><span role="text"><span>Image source, </span>Reuters</span></p><figcaption><span>Image caption, </span><p>"Trump and his lapdog Republicans just shut down the federal government after refusing to protect Americans from an imminent spike in health insurance costs," Newsom adds.</p></figcaption></figure><p>And on the Republicans' side:</p><ul><li spacing="rich-text">
      The <b>Republican Conference</b> in the US House of Representatives shares on X a video of lights in the Capitol Building turning out, saying the Democrats are "putting illegal aliens first and hurting hardworking Americans in the process"
    </li></ul><ul><li spacing="rich-text">
      <b>Representative Dusty Johnson</b> says "shutdowns are stupid", adding that Democrats are "putting American workers' paychecks at risk"
    </li><li spacing="rich-text">
      Fellow <b>Representative Chuck Fleischmann</b> says that Democrats have "officially shut down our government", and "hardworking taxpayers will have to pay the bill"
    </li></ul><figure><p><span><img alt="Rep. Chuck Fleischmann" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/682c016a-fbb3-4dd3-a741-21ed4d163d4f.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/682c016a-fbb3-4dd3-a741-21ed4d163d4f.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/682c016a-fbb3-4dd3-a741-21ed4d163d4f.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/682c016a-fbb3-4dd3-a741-21ed4d163d4f.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/682c016a-fbb3-4dd3-a741-21ed4d163d4f.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/682c016a-fbb3-4dd3-a741-21ed4d163d4f.jpg.webp 800w" width="892" height="502"></span><span role="text"><span>Image source, </span>CQ-Roll Call, Inc via Getty Images</span></p><figcaption><span>Image caption, </span><p>Rep. Chuck Fleischmann</p></figcaption></figure><p>This is in line with the trend we <a href="https://www.bbc.com/news/live/clylje0rmp2t?post=asset%3Aafcd4d58-a036-48f9-a361-b2c82a1e2508#post">saw in the lead up</a> to the midnight deadline.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:a1d8f109-4372-4baf-a906-4ea40a58e660"><header><span><h3 type="normal"><span role="text"><span>How investors around the world view the shutdown</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 05:45 BST</span></span></span></span></h3></span></header><p><span><span><img alt="" loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/128/cpsprodpb//vivo/live/images/2025/6/13/35ebb458-a432-413f-b20e-4555510f2113.jpg.webp" width="64" height="64"></span></span><span><strong>Peter Hoskins</strong><br>Business reporter, Singapore</span></p>
      <p>As I reported earlier in the morning, global financial markets seem to be broadly taking the shutdown in their stride.</p><p>Investors appear to be mostly looking past the widely expected stoppage, as they see it as a temporary blip.</p><p>Here in the Asia-Pacific region, stock markets are mixed as investors focus on issues closer to home rather than the politics of Washington DC.</p><p>Japan's Nikkei 225 is about 1% lower after a business sentiment report disappointed, while the Nifty 50 in India is higher as the country's central bank kept interest rates on hold.</p><p>Back in the US, the main stock indexes closed higher on Tuesday, with the Dow Jones Industrial Average hitting a record high.</p><p>But there are some signs that that jitters may be creeping into Wall Street.</p><p>US stock futures are pointing to a lower open on Wednesday. Futures are contracts to buy or sell an underlying asset at a future date and are an indication of how markets will trade when they open.</p><p>Gold - which is seen as a safe haven for investments during times of uncertainty - has hit a new record high of more than $3,872 an ounce.</p><p>At the same time, the US dollar is hovering near a one-week low against other major currencies.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:70339e26-1d76-432b-a419-24f736588b48"><header><span><h3 type="normal"><span role="text"><span>Federal furlough payments could cost $400m a day - official estimates</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 05:30 BST</span></span></span></span></h3></span></header>
      <p>A letter issued by the director of the Congressional Budget Office prior to the shutdown has given more details over the potential financial implications.</p><p>In the letter from Phillip Swagel, the office estimates 750,000 <b>federal employees</b> could be furloughed each day, with a total daily cost of around $400m (£297m).</p><p>It adds that this projected number of furloughed employees could vary daily, as some agencies might furlough more employees the longer the shutdown persists, while others might recall some initially furloughed
employees.</p><p><b>Members of Congress</b> will still be paid as their pay is required by the American constitution, the letter adds. </p><p>As for the <b>military</b>, they are required to work during a shutdown but won't be paid until after. </p><p>"The effects of a government shutdown on <b>business activity</b> are uncertain, and
their magnitude would depend on the duration of a shutdown and on decisions
made by the Administration," the letter adds. </p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:b7363eca-2950-4f61-b37d-ba0534860ceb"><header><span><h3 type="normal"><span role="text"><span>How long have previous shutdowns lasted?</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 05:07 BST</span></span></span></span></h3></span></header>
      <figure><p><span><img alt="A graph that shows US government shutdowns since 1980, marking the duration of each funding gap in days" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/161846a2-33f9-4327-89d0-47d2117f580d.png.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/161846a2-33f9-4327-89d0-47d2117f580d.png.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/161846a2-33f9-4327-89d0-47d2117f580d.png.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/161846a2-33f9-4327-89d0-47d2117f580d.png.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/161846a2-33f9-4327-89d0-47d2117f580d.png.webp 624w, https://ichef.bbci.co.uk/ace/standard/683/cpsprodpb/vivo/live/images/2025/10/1/161846a2-33f9-4327-89d0-47d2117f580d.png.webp 683w" width="683" height="682"></span></p></figure><p>Government shutdowns in the US are becoming more common, with <b>Donald Trump</b>'s first presidential term seeing three such instances. This included the longest shutdown in American history, lasting 35 days.</p><p>Before Trump, <b>Bill Clinton</b> held the previous record, with a 21-day shutdown in 1995 towards the end of his first term as president. Republicans had won control of both the House and the Senate halfway through Clinton's first term, and wanted to pass a budget that, among other things, limited spending for Medicare. </p><p>Similarly,<b> Barack Obama</b> endured a 16-day shutdown in 2013 over the then-president's proposed health care legislation.</p><p><b>Ronald Reagan</b>, a Republican president, oversaw the most shutdowns during his presidency - with eight recorded across his two terms in the 1980s. However, all of them were relatively short - the longest funding gap lasted a mere three days.</p>
    </article></div></li><li><div><article data-testid="content-post" id="asset:2af17150-0384-4372-b50b-d93c26f94ab7"><header><span><h3 type="normal"><span role="text"><span>US federal government shutdown officially begins</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 05:00 BST</span><p><span>Breaking</span></p></span></span></span></h3></span></header>
      <figure><p><span><img alt="The Ohio Clock outside the Senate Chamber strikes midnight at the U.S. Capitol" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/10/1/13ce39ed-d1d2-4b77-b4ee-f26110321ef6.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/10/1/13ce39ed-d1d2-4b77-b4ee-f26110321ef6.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/10/1/13ce39ed-d1d2-4b77-b4ee-f26110321ef6.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/10/1/13ce39ed-d1d2-4b77-b4ee-f26110321ef6.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/10/1/13ce39ed-d1d2-4b77-b4ee-f26110321ef6.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/10/1/13ce39ed-d1d2-4b77-b4ee-f26110321ef6.jpg.webp 800w" width="1024" height="576"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>The Ohio Clock outside the Senate Chamber strikes midnight at the US Capitol</p></figcaption></figure><p>It's midnight in Washington DC, and the US federal government shutdown has officially begun.</p><p>This would now likely leave hundreds of thousands of workers on unpaid leave and halt many government programs and services. </p><p>The shutdown comes hours after the Republican-controlled Senate failed to pass a government spending bill. </p><p>This is the first government shutdown since 2018 and will see non-essential workers placed on unpaid leave. </p><p>You can read more about how we got to this point <a href="https://www.bbc.com/news/live/clylje0rmp2t?post=asset%3A5104dfec-d564-4a0f-bc73-2487a6846a00#post">here</a> - and stay with us as we bring you more updates.</p>
    </article></div></li></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An informational website about why I went to prison (168 pts)]]></title>
            <link>https://prison.josh.mn/</link>
            <guid>45434062</guid>
            <pubDate>Wed, 01 Oct 2025 03:44:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prison.josh.mn/">https://prison.josh.mn/</a>, See on <a href="https://news.ycombinator.com/item?id=45434062">Hacker News</a></p>
Couldn't get https://prison.josh.mn/: Error: getaddrinfo ENOTFOUND prison.josh.mn]]></description>
        </item>
        <item>
            <title><![CDATA[The gaslit asset class (156 pts)]]></title>
            <link>https://blog.dshr.org/2025/09/the-gaslit-asset-class.html</link>
            <guid>45433866</guid>
            <pubDate>Wed, 01 Oct 2025 02:59:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.dshr.org/2025/09/the-gaslit-asset-class.html">https://blog.dshr.org/2025/09/the-gaslit-asset-class.html</a>, See on <a href="https://news.ycombinator.com/item?id=45433866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-6556465880306785878" itemprop="description articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgZX0fqPMMdG3KevN5anuO0O4Vzb2gPpCV0ipAxDl6iQODtpgJd_HhpF6M4tb9Oojlb1IkT-FtLa9nhxLbY7TcXMNJnYuLCS6yvxYcDiolSXwKHPTZ11bB-hr55RJYBwR9NM3q-7rdr8z_jgxed293EUpeU89cbjBJpPfy9NTbAlJgsOJg-_hxSrqFEs2bV/s2048/Grants.png"><img data-original-height="593" data-original-width="2048" height="58" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgZX0fqPMMdG3KevN5anuO0O4Vzb2gPpCV0ipAxDl6iQODtpgJd_HhpF6M4tb9Oojlb1IkT-FtLa9nhxLbY7TcXMNJnYuLCS6yvxYcDiolSXwKHPTZ11bB-hr55RJYBwR9NM3q-7rdr8z_jgxed293EUpeU89cbjBJpPfy9NTbAlJgsOJg-_hxSrqFEs2bV/w200-h58/Grants.png" width="200"></a>
James Grant invited me to address the annual conference of <a href="https://www.grantspub.com/"><i>Grant's Interest Rate Observer</i></a>. This was an intimidating prospect, the previous year's conference featured billionaires <a href="https://en.wikipedia.org/wiki/Scott_Bessent">Scott Bessent</a> and <a href="https://en.wikipedia.org/wiki/Bill_Ackman">Bill Ackman</a>. As usual, below the fold is the text of my talk, with the slides, links to the sources, and additional material in footnotes. Yellow background indicates textual slides.<br>
<span><a name="more"></a></span></p><h3>The Gaslit Asset Class</h3><p>
Before I explain that much of what you have been told about cryptocurrency technology is gaslighting, I should stress that I hold no long or short positions in cryptocurrencies, their derivatives or related companies. Unlike most people discussing them, I am not "<a href="https://blog.dshr.org/2022/02/talking-their-book.html">talking my book</a>".</p><p>

To fit in the allotted time, this talk focuses mainly on Bitcoin and omits many of the finer points. My text, with links to the sources and additional material in footnotes, will go up on my blog later today.</p><h3>Why Am I Here?</h3><p>
I imagine few of you would understand why a retired software engineer with more than forty years in Silicon Valley  was asked to address you on cryptocurrencies<sup><a href="#Footnote1">[1]</a></sup>.</p><p>
I was an early employee at <a href="https://en.wikipedia.org/wiki/Sun_Microsystems">Sun Microsystems</a> then <a href="https://blog.dshr.org/2025/05/the-dawn-of-nvidias-technology.html">employee #4 at Nvidia</a>, so I have been long Nvidia for more than 30 years. It has been a <a href="https://blog.dshr.org/2024/07/accelerated-computing.html">wild ride</a>. I quit after 3 years as part of fixing Nvidia's first near-death experience and immediately did 3 years as employee #12 at another startup, which also IPO-ed. If you do two in six years in your late 40s you get seriously burnt out.</p><p>

So my wife and I started a program at Stanford that is still running 27 years later. She was a career librarian at the Library of Congress and the Stanford Library. She was part of the team that, 30 years ago, pioneered the transition of academic publishing to the Web. She was also the person who <a href="https://blog.dshr.org/2024/02/the-stanford-digital-library-project.html">explained citation indices to Larry and Sergey</a>, which led to Page Rank.</p><p>

The academic literature has archival value. Multiple libraries hold complete runs on paper of the <a href="https://royalsocietypublishing.org/journal/rstl"><i>Philosophical Transactions of the Royal Society</i></a> starting 360 years ago<sup><a href="#Footnote1">[2]</a></sup>.
The interesting engineering problem we faced was how to enable libraries to deliver comparable longevity to Web-published journals.</p><h3>Five Years Before Satoshi Nakamoto</h3>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAPQ7O6lmB4paIa0yCsHim_SMJlYGWMWTdq1uYsdAJE7jubDbPJBWg-7jOC-mBYLX_G4NUSJKhJy3CW4bGU2rNoY3y2PsrU6_Icb5ELT5-ZfX8jR7jef16hRSYAfrRMJ_DqLZL5lIdfKS2-O0USJoK2lSnhaesAytJk_BesD_Z6ggub-rHsprp2zHuP5SB/s151/LOCKSS.logo.png"><img data-original-height="151" data-original-width="151" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAPQ7O6lmB4paIa0yCsHim_SMJlYGWMWTdq1uYsdAJE7jubDbPJBWg-7jOC-mBYLX_G4NUSJKhJy3CW4bGU2rNoY3y2PsrU6_Icb5ELT5-ZfX8jR7jef16hRSYAfrRMJ_DqLZL5lIdfKS2-O0USJoK2lSnhaesAytJk_BesD_Z6ggub-rHsprp2zHuP5SB/s16000/LOCKSS.logo.png"></a>
I worked with a group of outstanding Stanford CS Ph.D. students to design and implement <a href="http://dx.doi.org/10.1145/945445.945451">a system for stewardship of Web content</a> modeled on the paper library system. The goal was to make it extremely difficult for even a powerful adversary to delete or modify content without detection. It is called <a href="https://lockss.org/">LOCKSS</a>, for Lots Of Copies Keep Stuff Safe; a decentralized peer-to-peer system secured by Proof-of-Work. We won a <a href="http://dx.doi.org/10.1145/945445.945451">"Best Paper" award</a> for it five years before Satoshi Nakamoto published his <a href="https://bitcoin.org/bitcoin.pdf">decentralized peer-to-peer system</a> secured by Proof-of-Work.  When he did, LOCKSS had been in production for a few years and we had learnt a lot about how difficult decentralization is in the online world.</p><p>

Bitcoin built on more than <a href="https://queue.acm.org/detail.cfm?id=3136559">two decades of research</a>. Neither we nor Nakamoto invented Proof-of-Work, <a href="https://doi.org/10.1007/3-540-48071-4_10">Cynthia Dwork and Moni Naor</a> published it in 1992. Nakamoto didn't invent blockchains, <a href="https://doi.org/10.1007/3-540-38424-3_32">Stuart Haber and W. Scott Stornetta</a> patented them in 1991. He was extremely clever in assembling well-known techniques into a cryptocurrency, but his only major innovation was the <a href="https://doi.org/10.1007/978-3-642-27739-9_1804-1">Longest Chain Rule</a>.</p><h3>Digital cash</h3><p>
The fundamental problem of representing cash in digital form is that a digital coin can be endlessly copied, thus you need some means to prevent each of the copies being spent. When you withdraw cash from an ATM, turning digital cash in your account into physical cash in your hand, the bank performs an atomic transaction against the database mapping account numbers to balances. The bank is trusted to prevent multiple spending.</p><p>

There had been several attempts at a cryptocurrency before Bitcoin.  The primary goals of the <a href="https://search.worldcat.org/title/1099341012">libertarians and cypherpunks</a> were that a cryptocurrency be as anonymous as physical cash, and that it not have a central point of failure that had to be trusted.  The only one to get any traction was David Chaum's <a href="https://en.wikipedia.org/wiki/DigiCash">DigiCash</a>; it was anonymous but it was centralized to prevent multiple spending and it involved banks.</p><h3>Nakamoto's <i>magnum opus</i></h3>
<div><p>
Bitcoin claims:
</p><ul>
<li>The system was <i>trustless</i> because it was <i>decentralized</i>.</li>
<li>It was a <i>medium of exchange</i> for buying and selling in the real world.</li>
<li>Transactions were <i>faster</i> and <i>cheaper</i> than in the existing financial system.</li>
<li>It was secured by <i>Proof-of-Work</i> and <i>cryptography</i>.</li>
<li>It was <i>privacy-preserving</i>.</li>
</ul>
</div><p>
When in November 2008 Nakamoto published <a href="https://bitcoin.org/bitcoin.pdf"><i>Bitcoin: A Peer-to-Peer Electronic Cash System</i></a> it was the peak of the <a href="https://en.wikipedia.org/wiki/2008_financial_crisis">Global Financial Crisis</a> and people were very aware that the financial system was broken (and it still is). Because it solved many of the problems that had dogged <a href="https://davidgerard.co.uk/blockchain/book/">earlier attempts at electronic cash</a>, it rapidly attracted a clique of enthusiasts. When Nakamoto went silent in 2010 they took over proseltyzing the system. The main claims they made were:</p><ul>
<li>The system was <i>trustless</i> because it was <i>decentralized</i>.</li>
<li>It was a <i>medium of exchange</i> for buying and selling in the real world.</li>
<li>Transactions were <i>faster</i> and <i>cheaper</i> than in the existing financial system.</li>
<li>It was secured by <i>Proof-of-Work</i> and <i>cryptography</i>.</li>
<li>It was <i>privacy-preserving</i>.</li>
</ul><p>
They are all either false or misleading. In most cases Nakamoto's own writings show he knew this. His acolytes were gaslighting.</p><h3>Trustless because decentralized (1)</h3><p>
Assuming that the Bitcoin network consists of a large number of roughly equal nodes, it randomly selects a node to determine the transactions that will form the next block. There is no need to trust any particular node because the chance that they will be selected is small.<sup><a href="#Footnote3">[3]</a></sup></p><div><p>
At first, most users would run network nodes, but as the network grows beyond a certain point, it would be left more and more to specialists with server farms of specialized hardware. A server farm would only need to have one node on the network and the rest of the LAN connects with that one node.
</p><blockquote>
<small>
Satoshi Nakamoto 2<sup>nd</sup> November 2008
</small>
</blockquote><p>
The current system where every user is a network node is not the intended configuration for large scale. ... The design supports letting users just be users. The more burden it is to run a node, the fewer nodes there will be. Those few nodes will be big server farms. The rest will be client nodes that only do transactions and don’t generate.
</p><blockquote>
<small>
Satoshi Nakamoto: 29<sup>th</sup> July 2010
</small>
</blockquote>
</div><p>
But only three days after publishing his white paper, Nakamoto understood that this assumption would become false:</p><blockquote>
At first, most users would run network nodes, but as the network grows beyond a certain point, it would be left more and more to specialists with server farms of specialized hardware.
</blockquote><p>
He didn't change his mind. On 29<sup>th</sup> July 2010, less than five months before he went silent, he made the same point:</p><blockquote>
The current system where every user is a network node is not the intended configuration for large scale. ... The design supports letting users just be users. The more burden it is to run a node, the fewer nodes there will be. Those few nodes will be big server farms.
</blockquote><p>
"Letting users be users" necessarily means that the "users" have to trust the "few nodes" to include their transactions in blocks.  The very strong economies of scale of technology in general and "big server farms" in particular meant that the centralizing force described in W. Brian Arthur's 1994 book <a href="http://www.amazon.com/Increasing-Returns-Dependence-Economics-Cognition/dp/0472064967"><i>Increasing Returns and Path Dependence in the Economy</i></a> resulted in there being "fewer nodes". Indeed, on 13<sup>th</sup> June 2014 a single node controlled 51% of Bitcoin's mining, the <a href="https://hackingdistributed.com/p/2014/06/13/in-ghash-bitcoin-trusts/">GHash pool</a>.<sup><a href="#Footnote4">[4]</a></sup></p><h3>Trustless because decentralized (2)</h3><p>
In June 2022 <a href="https://aidenlab.org/bitcoin.pdf"><i>Cooperation among an anonymous group protected Bitcoin during failures of decentralization</i></a> by Alyssa Blackburn <i>et al</i> showed that it had not been decentralized from the very start. The same month a DARPA-sponsored report entitled <a href="https://assets-global.website-files.com/5fd11235b3950c2c1a3b6df4/62af6c641a672b3329b9a480_Unintended_Centralities_in_Distributed_Ledgers.pdf"><i>Are Blockchains Decentralized?</i></a> by a large team from the <a href="https://www.trailofbits.com/">Trail of Bits</a> security company examined the economic and many other centralizing forces affecting a wide range of blockchain implementations and concluded that the answer to their question is "No".<sup><a href="#Footnote5">[5]</a></sup></p><p>

The same centralizing economic forces apply to Proof-of-Stake blockchains such as Ethereum. Grant's <i>Memo to the bitcoiners</i> explained the process last February.</p><h3>Trustless because decentralized (3)</h3><p>
Another centralizing force drives pools like GHash. The network creates a new block and rewards the selected node about every ten minutes.  Assuming they're all state-of-the-art, there are currently about 15M rigs mining Bitcoin<sup><a href="#Footnote6">[6]</a></sup>. Their <a href="https://doi.org/10.1016/j.resconrec.2021.105901">economic life is around 18 months</a>, so only 0.5%% of them will ever earn a reward.  The owners of mining rigs pool their efforts, converting a small chance of a huge reward into a steady flow of smaller rewards. On average GHash was getting three rewards an hour.</p><h3>A medium of exchange (1)</h3>
<div><p>
Quote from: Insti, July 17, 2010, 02:33:41 AM</p><blockquote>
How would a Bitcoin snack machine work?<br>
<ol>
<li>You want to walk up to the machine. Send it a bitcoin.</li>
<li>?</li>
<li>Walk away eating your nice sugary snack. (Profit!)</li>
</ol>
You don’t want to have to wait an hour for you transaction to be confirmed.<p>

The vending machine company doesn’t want to give away lots of free candy.</p><p>

How does step 2 work?
</p></blockquote><p>
I believe it’ll be possible for a payment processing company to provide as a service the rapid distribution of transactions with good-enough checking in something like 10 seconds or less.
</p><blockquote>
<small>
Satoshi Nakamoto: 17<sup>th</sup> July 2010
</small>
</blockquote>
</div><p>
Bitcoin's ten-minute block time is a problem for real-world buying and selling<sup><a href="#Footnote7">[7]</a></sup>, but the problem is even worse. Network delays mean a transaction isn't final when you see it in a block. Assuming no-one controlled more than 10% of the hashing power, Nakamoto required another 5 blocks to have been added to the chain, so 99.9% finality would take an hour.  With a more realistic 30%, the rule should have been 23 blocks, with finality taking 4 hours<sup><a href="#Footnote8">[8]</a></sup>.</p><p>

Nakamoto's 17<sup>th</sup> July 2010 exchange with Insti shows he understood that the Bitcoin network couldn't be used for ATMs, vending machines, buying drugs or other face-to-face transactions because he went on to describe how a payment processing service layered on top of it would work.</p><h3>A medium of exchange (2)</h3>
<div><p>
assuming that the two sides are rational actors and the smart contract language is Turing-complete, there is no escrow smart contract that can facilitate this exchange without either relying on third parties or enabling at least one side to extort the other.</p><p>

two-party escrow smart contracts are ...  simply a game of who gets to declare their choice ﬁrst and commit it on the blockchain sooner, hence forcing the other party to concur with their choice. The order of transactions on a blockchain is essentially decided by the miners. Thus, the party with better connectivity to the miners or who is willing to pay higher transaction fees, would be able to declare their choice to the smart contract ﬁrst and extort the other party.
</p><blockquote>
<small>
Amir Kafshdar Goharshady, <a href="https://arxiv.org/abs/2110.09857"><i>Irrationality, Extortion, or Trusted Third-parties: Why it is Impossible to Buy and Sell Physical Goods Securely on the Blockchain</i></a>
</small>
</blockquote>
</div><p>
The situation is even worse when it comes to buying and selling real-world objects via programmable blockchains such as Ethereum<sup><a href="#Footnote9">[9]</a></sup>. In 2021 <a href="https://arxiv.org/abs/2110.09857">Amir Kafshdar Goharshady showed that</a><sup><a href="#Footnote10">[10]</a></sup>:</p><blockquote>
assuming that the two sides are rational actors and the smart contract language is Turing-complete, there is no escrow smart contract that can facilitate this exchange without either relying on third parties or enabling at least one side to extort the other.<br>
</blockquote><p>
Goharshady <a href="https://arxiv.org/abs/2110.09857">noted that</a>:</p><blockquote>
on the Ethereum blockchain escrows with trusted third-parties are used more often than two-party escrows, presumably because they allow dispute resolution by a human.
</blockquote><p>
And goes on to show that in practice trusted third-party escrow services are essential because two-party escrow smart contracts are:</p><blockquote>
simply a game of who gets to declare their choice ﬁrst and commit it on the blockchain sooner, hence forcing the other party to concur with their choice. The order of transactions on a blockchain is essentially decided by the miners. Thus, the party with better connectivity to the miners or who is willing to pay higher transaction fees, would be able to declare their choice to the smart contract ﬁrst and extort the other party.
</blockquote><p>
The choice being whether or not the good had been delivered. Given the current enthusiasm for <i>tokenization</i> of physical goods the market for trusted escrow services looks bright.</p><h3>Fast transactions</h3><p>
Actually the delay between submitting a transaction and finality is unpredictable and can be much longer than an hour. Transactions are validated by miners then added to the <a href="https://wiki.bitcoinsv.io/index.php/Transaction_Pools">mempool</a> of pending transactions where they wait until either:</p><ul>
<li>The selected network node chooses it as one of the most profitable to include in its block.</li>
<li>It reaches either its specified timeout or the default of 2 weeks.</li>
</ul>
<p>
This year the demand for transactions has been low, typically under 4 per second, so the backlog has been low, around 40K or under three hours. Last October it peaked at around 14 hours worth.</p><p>

The distribution of transaction wait times is highly skewed.  The median wait is typically around a block time. The proportion of low-fee transactions means the average wait is normally around 10 times that. But when everyone wants to transact the <a href="https://blog.dshr.org/2025/03/bitcoins-fee-spikes.html">ratio spikes</a> to over 40 times.</p><h3>Cheap transactions</h3>
<p>
There are two ways miners can profit from including a transaction in a block:</p><ul>
<li>The fee to be paid to the miner which the user chose to include in the transaction. In effect, transaction slots are auctioned off.</li>
<li>The transactions the miner included in the block to front- and back-run the user's transaction, called <a href="https://ethereum.org/en/developers/docs/mev/">Maximal Extractable Value</a><sup><a href="#Footnote11">[11]</a></sup>:<br>
<blockquote>
Maximal extractable value (MEV) refers to the maximum value that can be extracted from block production in excess of the standard block reward and gas fees by including, excluding, and changing the order of transactions in a block.
</blockquote></li>
</ul><p>
The block size limit means there is a fixed supply of transaction slots, about 7 per second, but the demand for them varies, and thus so does the price.  In normal times the auction for transaction fees means they are much smaller than the block reward. But when everyone wants to transact they suffer <a href="https://blog.dshr.org/2025/03/bitcoins-fee-spikes.html">massive spikes</a>.</p><h3>Secured by Proof-of-Work (1)</h3><p>
In cryptocurrencies "secured" means that the cost of an attack exceeds the potential loot.  The security provided by Proof-of-Work is linear in its cost, unlike techniques such as encryption, whose security is exponential in cost.  It is generally believed that it is impractical to reverse a Bitcoin transaction after about an hour because the miners are wasting such immense sums on Proof-of-Work.  Bitcoin pays these immense sums, but it doesn't get the decentralization they ostensibly pay for.</p><div><p>
Monero, a privacy-focused blockchain network, has been undergoing an attempted 51% attack — an existential threat to any blockchain. In the case of a successful 51% attack, where a single entity becomes responsible for 51% or more of a blockchain's mining power, the controlling entity could reorganize blocks, attempt to double-spend, or censor transactions.</p><p>

A company called Qubic has been waging the 51% attack by offering economic rewards for miners who join the Qubic mining pool. They claim to be "stress testing" Monero, though many in the Monero community have condemned Qubic for what they see as a malicious attack on the network or a marketing stunt.
</p><blockquote>
<small>
Molly White: <a href="https://www.web3isgoinggreat.com/?id=monero-51-attack"><i>Monero faces 51% attack</i></a>
</small>
</blockquote>
</div><p>
The advent of "mining as a service" about 7 years ago made 51% attacks against smaller Proof-of-Work alt-coin such as <a href="https://qz.com/1287701/bitcoin-golds-51-attack-is-every-cryptocurrencys-nightmare-scenario/">Bitcoin Gold</a> endemic. In August <a href="https://www.niemanlab.org/2025/08/independent-journalist-molly-white-knows-how-to-follow-the-memecoin/">Molly White</a> reported that <a href="https://www.web3isgoinggreat.com/?id=monero-51-attack"><i>Monero faces 51% attack</i></a>:</p><p>

In 2018's <a href="http://www.nber.org/papers/w24717"><i>The Economic Limits Of Bitcoin And The Blockchain</i></a> Eric Budish of the Booth School analyzed two versions of the 51% attack. I summarized his analysis of the classic multiple spend attack <a href="https://blog.dshr.org/2018/06/cryptocurrencies-have-limits.html">thus</a>:</p><blockquote>
Note that only Bitcoin and Ethereum among cryptocurrencies with "market cap" over $100M would cost more than $100K to attack. The total "market cap" of these 8 currencies is $271.71B and the total cost to 51% attack them is $1.277M or 4.7E-6 of their market cap.
</blockquote><p>
His key insight was that to ensure that 51% attacks were uneconomic, the reward for a block, implicitly the transaction tax, plus the fees had to be greater than the maximum value of the transactions in it. The total transaction cost (reward + fee) typically peaks around 1.8% but is normally between 0.6% and 0.8%, or around 150 times less than Budish's safety criterion.  The result is that a conspiracy between a few large pools could find it economic to mount a 51% attack.</p><h3>Secured by Proof-of-Work (2)</h3>
<div><p>
However, ∆<sub>attack</sub> is something of a “pick your poison” parameter. If ∆<sub>attack</sub> is small, then the system is vulnerable to the double-spending attack ... and the implicit transactions tax on economic activity using the blockchain has to be high. If ∆<sub>attack</sub> is large, then a short time period of access to a large amount of computing power can sabotage the blockchain.
</p><blockquote>
<small>
Eric Budish: <a href="http://www.nber.org/papers/w24717"><i>The Economic Limits Of Bitcoin And The Blockchain</i></a>
</small>
</blockquote>
</div><p>
But everyone assumes the pools won't do that. Budish further analyzed the effects of a multiple spend attack. It would be public, so it would in effect be sabotage, decreasing the Bitcoin price by a factor ∆<sub>attack</sub>. He <a href="http://www.nber.org/papers/w24717">concludes</a> that if the decrease is small, then double-spending attacks are feasible and the per-block reward plus fee must be large, whereas if it is large then access to the hash power of a few large pools can quickly sabotage the currency.</p><p>

The implication is that miners, motivated to keep fees manageable, believe ∆<sub>attack</sub> is large. Thus Bitcoin is secure because those who could kill the golden goose don't want to.</p><h3>Secured by Proof-of-Work (3)</h3>
<p>
The following year, in <a href="https://www.bis.org/publ/work765.pdf"><i>Beyond the doomsday economics of “proof-of-work” in cryptocurrencies</i></a>, Raphael Auer of the Bank for International Settlements showed that the problem Budish identified was inevitable<sup><a href="#Footnote12">[12]</a></sup>:</p><blockquote>
proof-of-work can only achieve payment security if mining income is high, but the transaction market cannot generate an adequate level of income. ... the economic design of the transaction market fails to generate high enough fees.
</blockquote><p>
In other words, the security of Bitcoin's blockchain depends upon inflating the currency with block rewards.  This problem is excerbated by Bitcoin's regular "halvenings" reducing the block reward. To maintain miner's current income after the next halvening in less than three years the "price" would need to be over $200K; security depends upon the "price" appreciating faster than 20%/year.</p><p>

Once the block reward gets small, safety requires the fees in a block to be worth more than the value of the transactions in it.  But everybody has decided to ignore Budish and Auer.</p><h3>Secured by Proof-of-Work (4)</h3>
<p>
In 2024 Soroush Farokhnia &amp; Amir Kafshdar Goharshady's <a href="https://hal.science/hal-04616643/"><i>Options and Futures Imperil Bitcoin's Security</i></a>:</p><blockquote>
showed that (i) a successful block-reverting attack does not necessarily require ... a majority of the hash power; (ii) obtaining a majority of the hash power ... costs roughly 6.77 billion ...  and (iii) Bitcoin derivatives, i.e. options and futures, imperil Bitcoin’s security by creating an incentive for a block-reverting/majority attack.
</blockquote><p>
They assume that an attacker would purchase enough state-of-the-art hardware for the attack. Given Bitmain's dominance in mining ASICs, such a purchase is unlikely to be feasible.</p><h3>Secured by Proof-of-Work (5)</h3>
<p>
But it would not be necessary. Mining is a very competitive business, and power is the major cost<sup><a href="#Footnote13">[13]</a></sup>. Making a profit requires both cheap power and early access to the latest, most efficient chips. So it wasn't a surprise that Ferreira <i>et al</i>'s <a href="https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=3320437"><i>Corporate capture of blockchain governance</i></a> showed that:</p><blockquote>
As of March 2021, the pools in Table 1 collectively accounted for 86% of the total hash rate employed. All but one pool (Binance) have known links to Bitmain Technologies, the largest mining ASIC producer.
<sup><a href="#Footnote14">[14]</a></sup>
</blockquote>
<h3>Secured by Proof-of-Work (6)</h3>
<p>
Bitmain, a Chinese company, exerts significant control of Bitcoin. China has firmly suppressed domestic use of cryptocurrencies, whereas the current administration seems intent on integrating them (and their inevitable grifts) into the US financial system. Except for Bitmain, no-one in China gets eggs from the golden goose.  This asymmetry provides China with an way to disrupt the US financial system.</p><p>
It would be important to prevent the disruption being attributed to China. A necessary precursor would therefore be to obscure the extent of Bitmain-affiliated pools' mining power. This has been a significant trend in the past year, note the change in the "unknown" in the graphs from 38 to 305. There could be other explanations, but whether or not intentionally this is creating a weapon.<sup><a href="#Footnote15">[15]</a></sup></p><h3>Secured by cryptography (1)</h3><p>
The dollars in your bank account are simply an entry in the bank's private ledger tagged with your name. You control this entry, but what you own is a claim on the bank<sup><a href="#Footnote16">[16]</a></sup>.  Similarly, your cryptocurrency coins are effectively an entry in a public ledger tagged with the public half of a key pair. The two differences are that:</p><ul>
<li>No ownership is involved, so you have no recourse if something goes wrong.</li>
<li>Anyone who knows the secret half of the key pair controls the entry. Since it is extremely difficult to stop online secrets leaking, something is likely to go wrong<sup><a href="#Footnote17">[17]</a></sup>.</li>
</ul>
<p>
The secret half of your key can leak via what Randall Munro depicted as a "<a href="https://xkcd.com/538/">wrench attack</a>", via phishing, social engineering, <a href="https://blog.dshr.org/2025/03/software-supply-chain-attack.html">software supply chain attacks</a><sup><a href="#Footnote18">[18]</a></sup>, and other forms of malware.  Preventing these risks requires you to maintain an <a href="https://blog.dshr.org/2022/02/inadequate-opsec.html">extraordinary level of operational security</a>.</p><h3>Secured by cryptography (2)</h3><p>
Even <i>perfect</i> opsec may not be enough. Bitcoin and most cryptocurrencies use two cryptographic algorithms, <a href="https://www.kraken.com/learn/how-do-cryptocurrencies-use-cryptography">SHA256 for hashing and ECDSA for signatures</a>.</p><div><p>
Quote from: llama on July 01, 2010, 10:21:47 PM</p><blockquote>
Satoshi, That would indeed be a solution if SHA was broken (certainly the more likely meltdown), because we could still recognize valid money owners by their signature (their private key would still be secure).<p>

However, if something happened and the signatures were compromised (perhaps integer factorization is solved, quantum computers?), then even agreeing upon the last valid block would be worthless.
</p></blockquote><p>
True, if it happened suddenly. If it happens gradually, we can still transition to something stronger. When you run the upgraded software for the first time, it would re-sign all your money with the new stronger signature algorithm. (by creating a transaction sending the money to yourself with the stronger sig)
</p><blockquote>
<small>
Satoshi Nakamoto: 10<sup>th</sup> July 2010
</small>
</blockquote>
</div><p>
On 10<sup>th</sup> July 2010 Nakamoto addressed the issue of what would happen if either of these algorithms were compromised.  There are three problems with his response; that compromise is likely in the near future, when it does Nakamoto's fix is inadequate, and there is a huge incentive for it to happen suddenly:</p><h3>Secured by cryptography (3)</h3><p>
Divesh Aggarwal <i>et al</i>'s 2019 paper <a href="https://arxiv.org/abs/1710.10377"><i>Quantum attacks on Bitcoin, and how to protect against them</i></a> noted that:
</p><blockquote>
the elliptic curve signature scheme used by Bitcoin is much more at risk, and could be completely broken by a quantum computer as early as 2027, by the most optimistic estimates.
</blockquote><p>
Their "most optimistic estimates" are likely to be correct; <a href="https://www.psiquantum.com/blueprint">PsiQuantum</a> expects to have two 1M qubit computers operational in 2027<sup><a href="#Footnote19">[19]</a></sup>. Each should be capable of breaking an ECDSA key in under a week.</p><p>

Bitcoin's transition to post-quantum cryptography faces a major problem because, to transfer coins from an ECDSA wallet to a post-quantum wallet, you need the key for the ECDSA wallet. Chainalysis <a href="https://blog.chainalysis.com/reports/money-supply">estimates that</a>:
</p><blockquote>
about 20% of all Bitcoins have been "lost", or in other words are sitting in wallets whose keys are inaccessible
</blockquote><p>
An example is the notorious <a href="https://en.wikipedia.org/wiki/Bitcoin_buried_in_Newport_landfill">hard disk in the garbage dump</a>. A sufficiently powerful quantum computer could recover the lost keys.</p><p>

The incentive for it to happen suddenly is that, even if Nakamoto's fix were in place, someone with access to the first sufficiently powerful quantum computer could transfer 20% of all Bitcoin, currently worth $460B, to <a href="https://blog.dshr.org/2025/05/the-740b-prize.html">post-quantum wallets they controlled</a>. This would be a 230x return on the investment in PsiQuantum.</p><h3>Privacy-preserving</h3>
<div><p>
privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous. The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone.</p><p>

As an additional firewall, a new key pair should be used for each transaction to keep them from being linked to a common owner.</p><p>

Some linking is still unavoidable with multi-input transactions, which necessarily reveal that their inputs were owned by the same owner. The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.</p><blockquote>
<small>
Satoshi Nakamoto: <a href="https://bitcoin.org/bitcoin.pdf"><i>Bitcoin: A Peer-to-Peer Electronic Cash System</i></a>
</small>
</blockquote>
</div><p>
Nakamoto addressed the concern that, unlike DigiCash, because Bitcoin's blockchain was public it wasn't <a href="https://bitcoin.org/bitcoin.pdf">anonymous</a>:</p><blockquote>
privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous. The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone.
</blockquote><p>
This is true but misleading. In practice, users need to use exchanges and other services that can tie them to a public key.
There is a flourishing ecosystem of companies that deanonymize wallets by <a href="https://search.worldcat.org/title/1298713583">tracing the web of transactions</a>. Nakamoto <a href="https://bitcoin.org/bitcoin.pdf">added</a>:</p><blockquote>
As an additional firewall, a new key pair should be used for each transaction to keep them from being linked to a common owner.
</blockquote><p>
This advice is just unrealistic. As <a href="https://blog.mollywhite.net/abuse-and-harassment-on-the-blockchain/">Molly White wrote</a><sup><a href="#Footnote20">[20]</a></sup>:</p><blockquote>
funds in a wallet have to come from somewhere, and it’s not difficult to infer what might be happening when your known wallet address suddenly transfers money off to a new, empty wallet. 
</blockquote><p>
Nakamoto <a href="https://bitcoin.org/bitcoin.pdf">acknowledged</a>:</p><blockquote>
Some linking is still unavoidable with multi-input transactions, which necessarily reveal that their inputs were owned by the same owner. The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.
</blockquote><p>
For more than a decade <a href="https://github.com/jlopp/physical-bitcoin-attacks/blob/master/README.md">Jamison Lopp</a> has been tracking what happens when a wallet with significant value is deanonymized, and it is a <a href="https://blog.dshr.org/2025/05/the-risks-of-hodl-ing.html">serious risk to life and limbs</a><sup><a href="#Footnote21">[21]</a></sup>.</p><h3>One more risk</h3><p>
I have steered clear of the financial risks of cryptocurrencies. It  may appear that the endorsement of the current administration has effectively removed their financial risk. But the technical and operational risks remain, and I should note another technology-related risk.</p><p>
Equities are currently being <a href="https://www.bloodinthemachine.com/p/the-ai-bubble-is-so-big-its-propping">inflated by the AI bubble</a>. The AI platforms are <a href="https://blog.dshr.org/2025/08/the-drugs-are-taking-hold.html">running the drug-dealer's algorithm</a>, "the first one's free", burning cash by offering their product free or massively under-priced. This cannot last; only <a href="https://www.zdnet.com/article/only-8-of-americans-would-pay-extra-for-ai-according-to-zdnet-aberdeen-research/">8% of their users would pay</a> even the current price. <a href="https://garymarcus.substack.com/p/openais-waterloo">OpenAI's August launch of GPT-5</a>, which was about <a href="https://www.theregister.com/2025/08/13/gpt_5_cost_cutting/">cost-cutting not better functionality</a>, and <a href="https://ethanding.substack.com/p/ai-subscriptions-get-short-squeezed">Anthropic's cost increases</a> were both panned by the customers who do pay.  AI may deliver some value, but it doesn't come close to the cost of delivering it<sup><a href="#Footnote22">[22]</a></sup>.</p><p>

There is likely to be an epic AI equity bust. <a href="https://www.ft.com/content/7052c560-4f31-4f45-bed0-cbc84453b3ce">Analogies</a> are being drawn to the <a href="https://www.noahpinion.blog/p/will-data-centers-crash-the-economy">telecom boom</a>, but <a href="https://www.economist.com/finance-and-economics/2025/09/07/what-if-the-ai-stockmarket-blows-up"><i>The Economist</i> reckons</a><sup><a href="#Footnote23">[23]</a></sup>:</p><blockquote>
the potential AI bubble lags behind only the three gigantic railway busts of the 19th century.
</blockquote>
<p>
History shows a fairly strong and increasing correlation between equities and cryptocurrencies, so they will get dragged down too. The automatic liquidation of leveraged long positions in DeFi will start, causing a self-reinforcing downturn. Periods of heavy load such as this tend to reveal bugs in IT systems, and especially in "smart contracts", as their assumptions of adequate resources and timely responses are violated.</p><p>
Experience shows that Bitcoin's limited transaction rate and the fact that the Ethereum computer that runs all the "smart contracts" is 1000 times slower than a $50 Raspberry Pi 4<sup><a href="#Footnote24">[24]</a></sup> lead to major slow-downs and fee spikes during panic selling, exacerbated by the fact that the panic sales are public<sup><a href="#Footnote25">[25]</a></sup>.</p><h3>Conclusion</h3><p>
The fascinating thing about cryptocurrency technology is the number of ways people have developed and how much they are willing to pay to avoid actually using it.  What other transformative technology has had people desperate not to use it?</p><p>

The whole of TradFi has been erected on this much worse infrastructure, including exchanges, <a href="https://blog.dshr.org/2022/04/grayscale-bitcoin-trust.html">closed-end funds</a>, ETFs, <a href="https://en.wikipedia.org/wiki/Hypothec#Hypothecation_and_rehypothecation">rehypothecation</a>, and derivatives.  Clearly, the only reason for doing so is to escape regulation and extract excess profits from what would otherwise be crimes.</p><h3>Footnotes</h3>
<ol start="1">
<li id="Footnote1">
The cause was the <a href="https://www.youtube.com/watch?v=twrduL8aNGE">video</a> of a talk I gave at Stanford in 2022 entitled <a href="https://blog.dshr.org/2022/02/ee380-talk.html"><i>Can We Mitigate The Externalities Of Cryptocurrencies?</i></a>. It was an updated version of a talk at the 2021 <a href="https://blog.dshr.org/2021/12/talk-at-ttivanguard-conference.html">TTI/Vanguard conference</a>. The talk conformed to <a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines">Betteridge's Law of Headlines</a> in that the answer was "no".<br>
</li>
<li id="Footnote2">
Paper libraries form a model fault-tolerant system. It is highly replicated and decentralized. Libraries cooperate via inter-library loan and copy to deliver a service that is far more reliable than any individual library. 
</li>
<li id="Footnote3">
The importance Satoshi Nakamoto attached to trustlessness can be seen from his <a href="https://web.archive.org/web/20110822150926/https://p2pfoundation.ning.com/forum/topics/bitcoin-open-source">release note for Bitcoin 0.1</a>:
<blockquote>
The root problem with conventional currency is all the trust that's required to make it work. The central bank must be trusted not to debase the currency, but the history of fiat currencies is full of breaches of that trust. Banks must be trusted to hold our money and transfer it electronically, but they lend it out in waves of credit bubbles with barely a fraction in reserve. We have to trust them with our privacy, trust them not to let identity thieves drain our accounts. Their massive overhead costs make micropayments impossible.
</blockquote>
The problem with this ideology is that trust (but verify) is an incredibly effective optimization in almost any system. For example, Robert Putnam <i>et al</i>'s <a href="https://search.worldcat.org/title/52234023"><i>Making Democracy Work: Civic Traditions in Modern Italy</i></a> shows that the difference between the economies of Northern and Southern Italy is driven by the much higher level of trust in the North.<p>

Bitcoin's massive cost is a result of its lack of trust. Users pay this massive cost but they don't get a trustless system, they just get a system that makes the trust a bit harder to see.</p><p>

In response to Nakamoto's diatribe, note that:</p><ul>
<li>"trusted not to debase the currency", but Bitcoin's security depends upon debasing the currency.</li>
<li>"waves of credit bubbles", is a pretty good description of the cryptocurrency market.</li>
<li>"not to let identity thieves drain our accounts", see Molly White's <a href="https://www.web3isgoinggreat.com/"><i>Web3 is Going Just Great</i></a>.</li>
<li>"massive overhead costs". The current cost per transaction is <a href="https://www.blockchain.com/explorer/charts/cost-per-transaction">around $100</a>.</li>
</ul>
I rest my case.
</li>
<li id="Footnote4">
The problem of trusting mining pools is actually much worse. There is nothing to stop pools <strike>conspiring</strike> coordinating. In 2017 <a href="https://en.wikipedia.org/wiki/Vitalik_Buterin">Vitalik Buterin</a>, co-founder of Ethereum, published <a href="https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274"><i>The Meaning of Decentralization</i></a>:<br>
<blockquote>
In the case of blockchain protocols, the mathematical and economic reasoning behind the safety of the consensus often relies crucially on the uncoordinated choice model, or the assumption that the game consists of many small actors that make decisions independently. If any one actor gets more than 1/3 of the mining power in a proof of work system, they can gain outsized profits by selfish-mining. However, can we really say that the uncoordinated choice model is realistic when 90% of the Bitcoin network’s mining power is well-coordinated enough to show up together at the same conference? 
</blockquote>
See <a href="https://blog.dshr.org/2024/05/sufficiently-decentralized.html"><i>"Sufficiently Decentralized"</i></a> for a review of evidence from a Protos article entitled <a href="https://protos.com/new-research-suggests-bitcoin-mining-centralized-around-bitmain/"><i>New research suggests Bitcoin mining centralized around Bitmain</i></a> that concludes:<br>
<blockquote>
In all, it seems unlikely that up to nine major bitcoin mining pools use a shared custodian for coinbase rewards unless a single entity is behind all of their operations. 
</blockquote>
The "single entity" is clearly Bitmain.
</li>
<li id="Footnote5">
Peter Ryan, a reformed Bitcoin enthusiast, noted another form of centralization in <a href="https://www.compactmag.com/article/money-by-vile-means/"><i>Money by Vile Means</i></a>:<br>
<blockquote>
Bitcoin is anything but decentralized: Its functionality is maintained by a small and privileged clique of software developers who are funded by a centralized cadre of institutions. If they wanted to change Bitcoin’s 21 million coin finite supply, they could do it with the click of a keyboard.
</blockquote>
His account of the politics behind the argument over raising the Bitcoin block size should dispel any idea of Bitcoin's decentralized nature.  He also <a href="https://www.compactmag.com/article/money-by-vile-means/">notes</a>:<br>
<blockquote>
By one estimate from Hashrate Index, Foundry USA and Singapore-based AntPool control more than 50 percent of computing power, and the top ten mining pools control over 90 percent. Bitcoin blogger 0xB10C, who <a href="https://b10c.me/blog/015-bitcoin-mining-centralization/">analyzed</a> mining data as of April 15, 2025, found that centralization has gone even further than this, “with only six pools mining more than 95 percent of the blocks.”
</blockquote>
</li>
<li id="Footnote6">
The <a href="https://perfecthashrate.com/asics/antminer-s17-mining-hashrate/">Bitmain S17</a> comes in 4 versions with hash rates from 67 to 76 TH/s. Lets assume 70TH/s. As I write the Bitcoin hash rate is about 1 billion TH/s. So if they were all mid-range S17s there would be around 15M mining. If their economic life were 18 months, there would be 77,760 rewards. Thus only 0.5% of them would earn a reward.<p>

In December 2021 Alex de Vries and Christian Stoll <a href="https://doi.org/10.1016/j.resconrec.2021.105901">estimated that</a>:</p><blockquote>
The average time to become unprofitable sums up to less than 1.29 years. 
</blockquote>
It has been obvious since mining ASICs first hit the market that, apart from access to cheap or free electricity, there were two keys to profitable mining:<br>
<ol>
<li>Having close enough ties to Bitmain to get the latest chips early in their 18-month economic life.</li>
<li>Having the scale to buy Bitmain chips in the large quantities that get you early access.</li>
</ol>
</li>
<li id="Footnote7">
See David Gerard's account of Steve Early's experiences accepting Bitcoin in his chain of pubs in <a href="https://davidgerard.co.uk/blockchain/book/"><i>Attack of the 50 Foot Blockchain</i></a> Page 94.
<a href="https://www.kansascityfed.org/research/payments-system-research-briefings/us-consumers-use-of-cryptocurrency-for-payments/"><i>U.S. Consumers’ Use of Cryptocurrency for Payments</i></a> by Fumiko Hayashi and Aditi Routh of the Kansas City Fed reports that:<br>
<blockquote>
The share of U.S. consumers who report using cryptocurrency for payments—purchases, money transfers, or both—has been very small and has declined slightly in recent years. The light blue line in Chart 1 shows that this share declined from nearly 3 percent in 2021 and 2022 to less than 2 percent in 2023 and 2024.
</blockquote>
</li>
<li id="Footnote8">
User DeathAndTaxes on Stack Exchange explains the <a href="https://bitcoin.stackexchange.com/questions/1170/why-is-6-the-number-of-confirms-that-is-considered-secure">6 block rule</a>:<br>
<blockquote>
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-Rdlmwa4wUnJuwPrbjcs9qy3a6vTGf343LjXoHcyTkQBs3zce4FdNsSC__zKbwanXirtqHq4QW2CI_urbBybfLi3LunH-ol3nPsIky49xE1UI6-vMCEFTS7C-DvBe3_l4_I-lZ46rO54i4a-B4nKrwSzNcM18CmvRMZOZY025NJNtyo5pAC_fondpV7wb/s416/SatoshiTable.png"><img data-original-height="416" data-original-width="380" height="200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-Rdlmwa4wUnJuwPrbjcs9qy3a6vTGf343LjXoHcyTkQBs3zce4FdNsSC__zKbwanXirtqHq4QW2CI_urbBybfLi3LunH-ol3nPsIky49xE1UI6-vMCEFTS7C-DvBe3_l4_I-lZ46rO54i4a-B4nKrwSzNcM18CmvRMZOZY025NJNtyo5pAC_fondpV7wb/w183-h200/SatoshiTable.png" width="183"></a>
p is the chance of attacker eventually getting longer chain and reversing a transaction (0.1% in this case). q is the % of the hashing power the attacker controls. z is the number of blocks to put the risk of a reversal below p (0.1%).<p>

So you can see if the attacker has a small % of the hashing power 6 blocks is sufficient. Remember 10% of the network at the time of writing is ~100GH/s. However if the attacker had greater % of hashing power it would take increasingly longer to be sure a transaction can't be reversed.</p><p>

If the attacker had significantly more hashpower say 25% of the network it would require 15 confirmation to be sure (99.9% probability) that an attacker can't reverse it.
</p></blockquote>
For example, last May Foundry USA had more than 30% of the hash power, so the rule should have been 24 not 6, and finality should have taken 4 hours.
</li>
<li id="Footnote9">
To be fair, Ethereum has introduced at least one genuine innovation, <a href="https://blog.dshr.org/2023/06/flash-loans.html"><i>Flash Loans</i></a>. In <a href="https://bankunderground.co.uk/2023/05/25/flash-loans-flash-attacks-and-the-future-of-defi/"><i>Flash loans, flash attacks, and the future of DeFi</i></a> Aidan Saggers, Lukas Alemu and Irina Mnohoghitnei of the Bank of England provide an excellent overview of them.
Back in 2021 Kaihua Qin, Liyi Zhou, Benjamin Livshits, and Arthur Gervais from Imperial College posted <a href="https://arxiv.org/pdf/2003.03810.pdf"><i>Attacking the defi ecosystem with flash loans for fun and profit</i></a>, analyzing and optimizing two early flash loan attacks:<br>
<blockquote>
We show quantitatively how transaction atomicity increases the arbitrage revenue. We moreover analyze two existing attacks with ROIs beyond 500k%. We formulate finding the attack parameters as an optimization problem over the state of the underlying Ethereum blockchain and the state of the DeFi ecosystem. We show how malicious adversaries can efficiently maximize an attack profit and hence damage the DeFi ecosystem further. Specifically, we present how two previously executed attacks can be “boosted” to result in a profit of 829.5k USD and 1.1M USD, respectively, which is a boost of 2.37× and 1.73×, respectively. 
</blockquote>
They predicted an upsurge in attacks since "flash loans democratize the attack, opening this strategy to the masses". They were right, as you can see from Molly White's <a href="https://www.web3isgoinggreat.com/?collection=flash-loan-attack">list of flash loan attacks</a>.
</li>
<li id="Footnote10">
This is one of a whole series of <a href="https://blog.dshr.org/2022/09/impossibilities.html"><i>Impossibilities</i></a>, many imposed on Ethereum by fundamental results in computer science because it is a Turing-complete programming environment.
</li>
<li id="Footnote11">
For details of the story behind Miners' Extractable Value (MEV), see these posts:<br>
<ol>
<li><a href="https://blog.dshr.org/2020/11/the-order-flow.html"><i>The Order Flow</i></a> from November 2020.</li>
<li><a href="https://blog.dshr.org/2022/04/ethereum-has-issues.html"><i>Ethereum Has Issues</i></a> from April 2022.</li>
<li><a href="https://blog.dshr.org/2022/09/miners-extractable-value.html"><i>Miners' Extractable Value</i></a> From September 2022.</li>
</ol>

The first links to two must-read posts. The first is from Dan Robinson and Georgios Konstantopoulos, <a href="https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff"><i>Ethereum is a Dark Forest</i></a>:<br>
<blockquote>
It’s no secret that the Ethereum blockchain is a highly adversarial environment. If a smart contract can be exploited for profit, it eventually will be. The frequency of new hacks indicates that some very smart people spend a lot of time examining contracts for vulnerabilities.<p>

But this unforgiving environment pales in comparison to the mempool (the set of pending, unconfirmed transactions). If the chain itself is a battleground, the mempool is something worse: a dark forest. 
</p></blockquote>
The second is from Samczsun, <a href="https://samczsun.com/escaping-the-dark-forest/"><i>Escaping the Dark Forest</i></a>. It is an account of how:<br>
<blockquote>
On September 15, 2020, a small group of people worked through the night to rescue over 9.6MM USD from a vulnerable smart contract.
</blockquote>
Note in particular that MEV poses a risk to the integrity of blockchains. In <a href="https://doi.org/10.48550/arXiv.2203.15930"><i>Extracting Godl [sic] from the Salt Mines: Ethereum Miners Extracting Value</i></a> Julien Piet, Jaiden Fairoze and Nicholas Weaver examine the use of transactions that avoid the mempool, finding that:<br>
<blockquote>
(i) 73% of private transactions hide trading activity or re-distribute miner rewards, and 87.6% of MEV collection is accomplished with privately submitted transactions, (ii) our algorithm finds more than $6M worth of MEV profit in a period of 12 days, two thirds of which go directly to miners, and (iii) MEV represents 9.2% of miners' profit from transaction fees.<p>

Furthermore, in those 12 days, we also identify four blocks that contain enough MEV profits to make time-bandit forking attacks economically viable for large miners, undermining the security and stability of Ethereum as a whole. 
</p></blockquote>
When they say "large miners" they mean more than 10% of the power.
</li>
<li id="Footnote12">
Back in 2016 Arvind Narayanan's group at Princeton had published a related instability in Carlsten <i>et al</i>'s <a href="http://randomwalker.info/publications/mining_CCS.pdf"><i>On the instability of bitcoin without the block reward</i></a>. Narayanan summarized the paper in a <a href="https://freedom-to-tinker.com/2016/10/21/bitcoin-is-unstable-without-the-block-reward/">blog post</a>:<br>
<blockquote>
Our key insight is that with only transaction fees, the variance of the miner reward is very high due to the randomness of the block arrival time, and it becomes attractive to fork a “wealthy” block to “steal” the rewards therein. 
</blockquote>
</li>
<li id="Footnote13">
The leading source of data on which to base Bitcoin's carbon footprint is the <a href="https://cbeci.org/"><i>Cambridge Bitcoin Energy Consumption Index</i></a>. As I write their central estimate is that Bitcoin consumes 205TWh/year, or between Thailand and Vietnam.
</li>
<li id="Footnote14">
Ferreira <i>et al</i> <a href="https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=3320437">write</a>:<br>
<blockquote>
AntPool and BTC.com are fully-owned subsidiaries of Bitmain. Bitmain is the largest investor in ViaBTC. Both F2Pool and BTC.TOP are partners of BitDeer, which is a Bitmain-sponsored cloud-mining service. The parent companies of Huobi.pool and OkExPool are strategic partners of Bitmain. Jihan Wu, Bitmain’s founder and chairman, is also an adviser of Huobi (one of the largest cryptocurrency exchanges in the world and the owner of Huobi.pool).
</blockquote>
This makes economic sense. Because mining rigs depreciate quickly, profit depends upon <a href="https://blog.dshr.org/2018/05/asics-and-mining-centralization.html">early access to the latest chips</a>.
</li>
<li id="Footnote15">
See <a href="https://blog.dshr.org/2025/05/who-is-mining-bitcoin.html"><i>Who Is Mining Bitcoin?</i></a> for more detail on the state of mining and its gradual obfuscation.
</li>
<li id="Footnote16">
In this context to say you "control" your entry in the bank's ledger is an oversimplification. You can instruct the bank to perform transactions against your entry (and no-one else's) but the bank can reject your instructions. For example if they would overdraw your account, or send money to a sanctioned account. The key point is that your ownership relationship with the bank comes with a dispute resolution system and the ability to reverse transactions. Your cryptocurrency wallet has neither.
</li><li id="Footnote17">
<a href="https://www.web3isgoinggreat.com/"><i>Web3 is Going Just Great</i></a> is Molly White's list of things that went wrong. The cumulative losses she tracks currently stand at over $79B.
</li>
<li id="Footnote18">
Your secrets are especially at risk if anyone in your software supply chain use a build system implemented using AI "vibe coding". David Gerard's <a href="https://pivot-to-ai.com/2025/08/29/vibe-coded-build-system-nx-gets-hacked-steals-vibe-coders-crypto/"><i>Vibe-coded build system NX gets hacked, steals vibe-coders’ crypto</i></a> details a truly beautiful example of the extraordinary level of incompetence this reveals.
</li>
<li id="Footnote19">
<a href="https://en.wikipedia.org/wiki/IBM_Heron">IBM's Heron</a>, which HSBC recently used to <a href="https://www.bloomberg.com/news/articles/2025-09-24/hsbc-says-it-s-beaten-wall-street-rivals-with-new-quantum-trial">grab headlines</a>, has 156 qubits.
</li>
<li id="Footnote20">
Molly White's <a href="https://blog.mollywhite.net/abuse-and-harassment-on-the-blockchain/"><i>Abuse and harassment on the blockchain</i></a> is an excellent overview of the privacy risks inherent to real-world transactions on public blockchain ledgers:<br>
<blockquote>
Imagine if, when you Venmo-ed your Tinder date for your half of the meal, they could now see every other transaction you’d ever made—and not just on Venmo, but the ones you made with your credit card, bank transfer, or other apps, and with no option to set the visibility of the transfer to “private”. The split checks with all of your previous Tinder dates? That monthly transfer to your therapist? The debts you’re paying off (or not), the charities to which you’re donating (or not), the amount you’re putting in a retirement account (or not)? The location of that corner store right by your apartment where you so frequently go to grab a pint of ice cream at 10pm? Not only would this all be visible to that one-off Tinder date, but also to your ex-partners, your estranged family members, your prospective employers. An abusive partner could trivially see you siphoning funds to an account they can’t control as you prepare to leave them.
</blockquote>
</li>
<li id="Footnote21">
In <a href="https://blog.dshr.org/2025/05/the-risks-of-hodl-ing.html"><i>The Risks Of HODL-ing</i></a> I go into the details of the attack on the <a href="https://www.nytimes.com/2025/04/24/magazine/crybercrime-crypto-minecraft.html">parents of Veer Chetal</a>, who had unwisely live-streamed the social engineering that stole $243M from a resident of DC.<p>

Anyone with significant cryptocurrency wallets needs to follow Jamison Lopp's <a href="https://github.com/jlopp/physical-bitcoin-attacks/blob/master/README.md">Known Physical Bitcoin Attacks</a>.
</p></li>
<li id="Footnote22">

Torsten Sløk's <a href="https://www.apolloacademy.com/ai-has-moved-from-a-niche-sector-to-the-primary-driver-of-all-vc-investment/"><i>AI Has Moved From a Niche Sector to the Primary Driver of All VC Investment</i></a> leads with this graph, one of the clearest signs that we're in a bubble.<p>

Whether AI delivers net value in most cases is debatable. "Vibe coding" is touted as the example of increasing productivity, but the <a href="https://pivot-to-ai.com/2025/07/11/ai-coders-think-theyre-20-faster-but-theyre-actually-19-slower/">experimental</a> <a href="https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding">evidence</a> is that it decreases productivity. Kate Niederhoffer <i>et al</i>'s <i>Harvard Business Review</i> article <a href="https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity"><i>AI-Generated "Workslop” Is Destroying Productivity</i></a> explains one effect:</p><blockquote>
Employees are using AI tools to create low-effort, passable looking work that ends up creating more work for their coworkers. On social media, which is increasingly clogged with low-quality AI-generated posts, this content is often referred to as “AI slop.” In the context of work, we refer to this phenomenon as “<a href="https://www.betterup.com/workslop">workslop</a>.” We define workslop as <i>AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task</i>.<p>

Here’s how this happens. As AI tools become more accessible, workers are increasingly able to quickly produce polished output: well-formatted slides, long, structured reports, seemingly articulate summaries of academic papers by non-experts, and usable code. But while some employees are using this ability to polish good work, others use it to create content that is actually unhelpful, incomplete, or missing crucial context about the project at hand. The insidious effect of workslop is that it shifts the burden of the work downstream, requiring the receiver to interpret, correct, or redo the work. In other words, it transfers the effort from creator to receiver.
</p></blockquote>
David Gerard's <a href="https://pivot-to-ai.com/2025/09/23/workslop-bad-study-but-an-excellent-word/"><i>Workslop: bad ‘study’, but an excellent word</i></a> points out that:<br>
<blockquote>
<i>Unfortunately</i>, this article pretends to be a writeup of a study — but it’s actually a promotional brochure for enterprise AI products. It’s an unlabeled advertising feature.
</blockquote>
And goes on to explain where the workslop comes from:<br>
<blockquote>
Well, you know how you get workslop — it’s when your boss mandates you use AI. He can’t say what he wants you to use it for. But you’ve been told. You’ve got metrics on how much AI you use. They’re watching and they’re measuring.
</blockquote>
Belle Lin and Steven Rosenbush's <a href="https://www.wsj.com/articles/stop-worrying-about-ais-return-on-investment-d5cbc822"><i>Stop Worrying About AI’s Return on Investment</i></a> describes goalposts being moved:<br>
<blockquote>
Return on investment has evaded chief information officers since AI started <a href="https://www.wsj.com/articles/companies-had-fun-experimenting-with-ai-now-they-have-to-show-the-returns-2a683592">moving from early experimentation to more mature implementations</a> last year. But while AI is still rapidly evolving, CIOs are recognizing that traditional ways of recognizing gains from the technology aren’t cutting it.<p>

Tech leaders at the WSJ Leadership Institute’s Technology Council Summit on Tuesday said racking up a few minutes of efficiency here and there don’t add up to a meaningful way of measuring ROI.
</p></blockquote>
Given the hype and the massive sunk costs, admitting that there is no there there would be a career-limiting move.<p>

None of this takes account of the productivity externalities of AI, such as <a href="https://www.404media.co/librarians-are-being-asked-to-find-ai-hallucinated-books/"><i>Librarians Are Being Asked to Find AI-Hallucinated Books</i></a>, <a href="https://pivot-to-ai.com/2025/02/15/how-ai-slop-generators-started-talking-about-vegetative-electron-microscopy/">academic journals' reviewers' time wasted by AI slop papers</a>, <a href="https://pivot-to-ai.com/2025/06/07/uk-high-court-to-lawyers-cut-the-chatgpt-or-else/">judges' time wasted with hallucinated citations</a>, a flood of generated <a href="https://www.theguardian.com/technology/2025/jul/10/ai-generated-child-sexual-abuse-videos-surging-online-iwf">child sex abuse videos</a>, <a href="https://www.noemamag.com/the-last-days-of-social-media/">the death of social media</a> and a <a href="https://www.washingtonpost.com/technology/2025/09/20/ai-hacking-cybersecurity-cyberthreats/">vast new cyberthreat landscape</a>.
</p></li>
<li id="Footnote23">
<i>The Economist</i> writes in <a href="https://www.economist.com/finance-and-economics/2025/09/07/what-if-the-ai-stockmarket-blows-up"><i>What if the AI stockmarket blows up?</i></a>:<br>
<blockquote>
we picked ten historical bubbles and assessed them on factors including spark, cumulative capex, capex durability and investor group. By our admittedly rough-and-ready reckoning, the potential AI bubble lags behind only the three gigantic railway busts of the 19th century.
</blockquote>
They <a href="https://www.economist.com/finance-and-economics/2025/09/07/what-if-the-ai-stockmarket-blows-up">note that</a>:<br>
<blockquote>
For now, the splurge looks fairly modest by historical standards. According to our most generous estimate, American AI firms have invested 3-4% of current American GDP over the past four years. British railway investment during the 1840s was around 15-20% of GDP. But if forecasts for data-centre construction are correct, that will change. What is more, an unusually large share of capital investment is being devoted to assets that depreciate quickly. Nvidia’s cutting-edge chips will look clunky in a few years’ time. We estimate that the average American tech firm’s assets have a shelf-life of just nine years, compared with 15 for telecoms assets in the 1990s.
</blockquote>
I think they are over-estimating the shelf-life. Like Bitcoin mining, power is a major part of AI opex. Thus the incentive to (a) retire older, less power-efficient hardware, and (b) adopt the latest data-center power technology, is overwhelming. Note that Nvidia is moving to a one-year product cadence, and even when they were on a two-year cadence Jensen claimed it wasn't worth running chips from the previous cycle. Note also that the current generation of AI systems is incompatible with the power infrastructure of older data centers, and this may well happen again in a future product generation.  For example, Caiwei Chen reports in <a href="https://www.technologyreview.com/2025/03/26/1113802/china-ai-data-centers-unused/"><i>China built hundreds of AI data centers to catch the AI boom. Now many stand unused</i></a>:<br>
<blockquote>
The local Chinese outlets <i>Jiazi Guangnian</i> and <i>36Kr</i> report that up to 80% of China’s newly built computing resources remain unused. 
</blockquote>
Rogé Karma makes the same point as <i>The Economist</i> in <a href="https://www.theatlantic.com/economy/archive/2025/09/ai-bubble-us-economy/684128/"><i>Just How Bad Would an AI Bubble Be?</i></a>:<br>
<blockquote>
An AI-bubble crash could be different. AI-related investments have already <a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/">surpassed</a> the level that telecom hit at the peak of the dot-com boom as a share of the economy. In the first half of this year, business spending on AI added more to GDP growth than all consumer spending <i>combined</i>. Many experts believe that a major reason the U.S. economy has been able to weather tariffs and mass deportations without a recession is because all of this AI spending is acting, in the <a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/">words</a> of one economist, as a “massive private sector stimulus program.” An AI crash could lead broadly to less spending, fewer jobs, and slower growth, potentially dragging the economy into a recession.
</blockquote>
</li>
<li id="Footnote24">
In 2021 Nicholas Weaver estimated that the Ethereum computer was 5000 times slower than a <a href="https://www.usenix.org/publications/loginonline/web3-fraud">Raspberry Pi 4</a>. Since then the gas limit has been raised making his current estimate only 1000 times slower.
</li>
<li id="Footnote25">
Prof. Hilary Allen writes in <a href="https://fintechdystopia.com/chapters/chapter4.html"><i>Fintech Dystopia</i></a> that:<br>
<blockquote>
if people do start dumping blockchain-based assets in fire sales, everyone will know immediately because the blockchain is publicly visible. This level of transparency will only add to the panic (at least, that’s what happened during the <a href="https://corpgov.law.harvard.edu/2023/05/22/anatomy-of-a-run-the-terra-luna-crash/">run on the Terra stablecoin</a> in 2022).<br>
...<br>
We also saw ... that assets on a blockchain can be pre-programmed to execute transactions without the intervention of any human being. In good times, this makes things more efficient – but the code will execute just as quickly in bad situations, even if everyone would be better off if it didn’t. 
</blockquote>
She <a href="https://fintechdystopia.com/chapters/chapter4.html">adds</a>:<br>
<blockquote>
When things are spiraling out of control like this, sometimes the best medicine is a pause. Lots of traditional financial markets close at the end of the day and on weekends, which provides a natural opportunity for a break (and if things are really bad, for emergency government intervention). But one of blockchain-based finance’s claims to greater efficiency is that operations continue 24/7. We may end up missing the pauses once they’re gone.
</blockquote>
In the 26<sup>th</sup> September <i>Grant's</i>, Joel Wallenberg notes that:<br>
<blockquote>
Lucrative though they may be, the problem with stablecoin deposits is that exposure to the crypto-trading ecosystem makes them inherently correlated to it and subject to runs in a new “crypto winter,” like that of 2022–23.  Indeed, since as much as 70% of gross stablecoin-transaction volume derives from automated arbitrage bots and high-speed trading algorithms, runs may be rapid and without human over-sight. What may be worse, the insured banks that could feed a stablecoin boom are the very ones that are likely to require taxpayer support if liquidity dries up, and Trump-style regulation is likely to be light.
</blockquote>
So the loophole in the GENIUS act for banks is likely to cause contagion from cryptocurrencies via stablecoins to the US banking system.
</li>
</ol>
<h3>Acknowledgments</h3><p>
This talk benefited greatly from critiques of drafts by Hilary Allen, David Gerard, Jon Reiter, Joel Wallenberg, and Nicholas Weaver.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CDC File Transfer (354 pts)]]></title>
            <link>https://github.com/google/cdc-file-transfer</link>
            <guid>45433768</guid>
            <pubDate>Wed, 01 Oct 2025 02:38:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google/cdc-file-transfer">https://github.com/google/cdc-file-transfer</a>, See on <a href="https://news.ycombinator.com/item?id=45433768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">CDC File Transfer</h2><a id="user-content-cdc-file-transfer" aria-label="Permalink: CDC File Transfer" href="#cdc-file-transfer"></a></p>
<p dir="auto">Born from the ashes of Stadia, this repository contains tools for syncing and
streaming files from Windows to Windows or Linux. The tools are based on Content
Defined Chunking (CDC), in particular
<a href="https://www.usenix.org/conference/atc16/technical-sessions/presentation/xia" rel="nofollow">FastCDC</a>,
to split up files into chunks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">History</h2><a id="user-content-history" aria-label="Permalink: History" href="#history"></a></p>
<p dir="auto">At Stadia, game developers had access to Linux cloud instances to run games.
Most developers wrote their games on Windows, though. Therefore, they needed a
way to make them available on the remote Linux instance.</p>
<p dir="auto">As developers had SSH access to those instances, they could use <code>scp</code> to copy
the game content. However, this was impractical, especially with the shift to
working from home during the pandemic with sub-par internet connections. <code>scp</code>
always copies full files, there is no "delta mode" to copy only the things that
changed, it is slow for many small files, and there is no fast compression.</p>
<p dir="auto">To help this situation, we developed two tools, <code>cdc_rsync</code> and <code>cdc_stream</code>,
which enable developers to quickly iterate on their games without repeatedly
incurring the cost of transmitting dozens of GBs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">CDC RSync</h2><a id="user-content-cdc-rsync" aria-label="Permalink: CDC RSync" href="#cdc-rsync"></a></p>
<p dir="auto"><code>cdc_rsync</code> is a tool to sync files from a Windows machine to a Linux device,
similar to the standard Linux <a href="https://linux.die.net/man/1/rsync" rel="nofollow">rsync</a>. It is
basically a copy tool, but optimized for the case where there is already an old
version of the files available in the target directory.</p>
<ul dir="auto">
<li>It quickly skips files if timestamp and file size match.</li>
<li>It uses fast compression for all data transfer.</li>
<li>If a file changed, it determines which parts changed and only transfers the
differences.</li>
</ul>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/cdc_rsync_recursive_upload_demo.gif"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/cdc_rsync_recursive_upload_demo.gif" alt="cdc_rsync demo" width="688" data-animated-image=""></a>
</p>
<p dir="auto">The remote diffing algorithm is based on CDC. In our tests, it is up to 30x
faster than the one used in <code>rsync</code> (1500 MB/s vs 50 MB/s).</p>
<p dir="auto">The following chart shows a comparison of <code>cdc_rsync</code> and Linux <code>rsync</code> running
under Cygwin on Windows. The test data consists of 58 development builds
of some game provided to us for evaluation purposes. The builds are 40-45 GB
large. For this experiment, we uploaded the first build, then synced the second
build with each of the two tools and measured the time. For example, syncing
from build 1 to build 2 took 210 seconds with the Cygwin <code>rsync</code>, but only 75
seconds with <code>cdc_rsync</code>. The three outliers are probably feature drops from
another development branch, where the delta was much higher. Overall,
<code>cdc_rsync</code> syncs files about <strong>3 times faster</strong> than Cygwin <code>rsync</code>.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/cdc_rsync_vs_cygwin_rsync.png"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/cdc_rsync_vs_cygwin_rsync.png" alt="Comparison of cdc_rsync and Linux rsync running in Cygwin" width="753"></a>
</p>
<p dir="auto">We also ran the experiment with the native Linux <code>rsync</code>, i.e syncing Linux to
Linux, to rule out issues with Cygwin. Linux <code>rsync</code> performed on average 35%
worse than Cygwin <code>rsync</code>, which can be attributed to CPU differences. We did
not include it in the figure because of this, but you can find it
<a href="https://github.com/google/cdc-file-transfer/blob/main/docs/cdc_rsync_vs_cygwin_rsync_vs_linux_rsync.png">here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How does it work and why is it faster?</h3><a id="user-content-how-does-it-work-and-why-is-it-faster" aria-label="Permalink: How does it work and why is it faster?" href="#how-does-it-work-and-why-is-it-faster"></a></p>
<p dir="auto">The standard Linux <code>rsync</code> splits a file into fixed-size chunks of typically
several KB.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/fixed_size_chunks.png"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/fixed_size_chunks.png" alt="Linux rsync uses fixed size chunks" width="258"></a>
</p>
<p dir="auto">If the file is modified in the middle, e.g. by inserting <code>xxxx</code> after <code>567</code>,
this usually means that <span>the modified chunks as well as
all subsequent chunks</span> change.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/fixed_size_chunks_inserted.png"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/fixed_size_chunks_inserted.png" alt="Fixed size chunks after inserting data" width="301"></a>
</p>
<p dir="auto">The standard <code>rsync</code> algorithm hashes the chunks of the remote "old" file
and sends the hashes to the local device. The local device then figures out
which parts of the "new" file matches known chunks.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/linux_rsync_animation.gif"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/linux_rsync_animation.gif" alt="Syncing a file with the standard Linux rsync" width="855" data-animated-image=""></a>
  <br>
  Standard rsync algorithm
</p>
<p dir="auto">This is a simplification. The actual algorithm is more complicated and uses
two hashes, a weak rolling hash and a strong hash, see
<a href="https://rsync.samba.org/tech_report/" rel="nofollow">here</a> for a great overview. What makes
<code>rsync</code> relatively slow is the "no match" situation where the rolling hash does
not match any remote hash, and the algorithm has to roll the hash forward and
perform a hash map lookup for each byte. <code>rsync</code> goes to
<a href="https://github.com/librsync/librsync/blob/master/src/hashtable.h">great lengths</a>
optimizing lookups.</p>
<p dir="auto"><code>cdc_rsync</code> does not use fixed-size chunks, but instead variable-size,
content-defined chunks. That means, chunk boundaries are determined by the
<em>local content</em> of the file, in practice a 64 byte sliding window. For more
details, see
<a href="https://www.usenix.org/conference/atc16/technical-sessions/presentation/xia" rel="nofollow">the FastCDC paper</a>
or take a look at <a href="https://github.com/google/cdc-file-transfer/blob/main/fastcdc/fastcdc.h">our implementation</a>.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/variable_size_chunks.png"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/variable_size_chunks.png" alt="cdc_rsync uses variable, content-defined size chunks" width="260"></a>
</p>
<p dir="auto">If the file is modified in the middle, only <span>the modified
chunks</span>, but not <span>subsequent chunks</span>
change (unless they are less than 64 bytes away from the modifications).</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/variable_size_chunks_inserted.png"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/variable_size_chunks_inserted.png" alt="Content-defined chunks after inserting data" width="314"></a>
</p>
<p dir="auto">Computing the chunk boundaries is cheap and involves only a left-shift, a memory
lookup, an <code>add</code> and an <code>and</code> operation for each input byte. This is cheaper
than the hash map lookup for the standard <code>rsync</code> algorithm.</p>
<p dir="auto">Because of this, the <code>cdc_rsync</code> algorithm is faster than the standard
<code>rsync</code>. It is also simpler. Since chunk boundaries move along with insertions
or deletions, the task to match local and remote hashes is a trivial set
difference operation. It does not involve a per-byte hash map lookup.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/cdc_rsync_animation.gif"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/cdc_rsync_animation.gif" alt="Syncing a file with cdc_rsync" width="857" data-animated-image=""></a>
  <br>
  cdc_rsync algorithm
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">CDC Stream</h2><a id="user-content-cdc-stream" aria-label="Permalink: CDC Stream" href="#cdc-stream"></a></p>
<p dir="auto"><code>cdc_stream</code> is a tool to stream files and directories from a Windows machine to
a Linux device. Conceptually, it is similar to
<a href="https://github.com/libfuse/sshfs">sshfs</a>, but it is optimized for read speed.</p>
<ul dir="auto">
<li>It caches streamed data on the Linux device.</li>
<li>If a file is re-read on Linux after it changed on Windows, only the
differences are streamed again. The rest is read from the cache.</li>
<li>Stat operations are very fast since the directory metadata (filenames,
permissions etc.) is provided in a streaming-friendly way.</li>
</ul>
<p dir="auto">To efficiently determine which parts of a file changed, the tool uses the same
CDC-based diffing algorithm as <code>cdc_rsync</code>. Changes to Windows files are almost
immediately reflected on Linux, with a delay of roughly (0.5s + 0.7s x total
size of changed files in GB).</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/cdc_stream_demo.gif"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/cdc_stream_demo.gif" alt="cdc_stream demo" width="688" data-animated-image=""></a>
</p>
<p dir="auto">The tool does not support writing files back from Linux to Windows; the Linux
directory is readonly.</p>
<p dir="auto">The following chart compares times from starting a game to reaching the menu.
In one case, the game is streamed via <code>sshfs</code>, in the other case we use
<code>cdc_stream</code>. Overall, we see a <strong>2x to 5x speedup</strong>.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/google/cdc-file-transfer/blob/main/docs/cdc_stream_vs_sshfs.png"><img src="https://github.com/google/cdc-file-transfer/raw/main/docs/cdc_stream_vs_sshfs.png" alt="Comparison of cdc_stream and sshfs" width="752"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Platforms</h2><a id="user-content-supported-platforms" aria-label="Permalink: Supported Platforms" href="#supported-platforms"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><code>cdc_rsync</code></th>
<th>From</th>
<th>To</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows x86_64</td>
<td>✓</td>
<td>✓ <sup>1</sup></td>
</tr>
<tr>
<td>Ubuntu 22.04 x86_64</td>
<td>✗ <sup>2</sup></td>
<td>✓</td>
</tr>
<tr>
<td>Ubuntu 22.04 aarch64</td>
<td>✗</td>
<td>✗</td>
</tr>
<tr>
<td>macOS 13 x86_64 <sup>3</sup></td>
<td>✗</td>
<td>✗</td>
</tr>
<tr>
<td>macOS 13 aarch64 <sup>3</sup></td>
<td>✗</td>
<td>✗</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><code>cdc_stream</code></th>
<th>From</th>
<th>To</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows x86_64</td>
<td>✓</td>
<td>✗</td>
</tr>
<tr>
<td>Ubuntu 22.04 x86_64</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr>
<td>Ubuntu 22.04 aarch64</td>
<td>✗</td>
<td>✗</td>
</tr>
<tr>
<td>macOS 13 x86_64 <sup>3</sup></td>
<td>✗</td>
<td>✗</td>
</tr>
<tr>
<td>macOS 13 aarch64 <sup>3</sup></td>
<td>✗</td>
<td>✗</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<span>
<p dir="auto"><sup>1</sup> Only local syncs, e.g. <code>cdc_rsync C:\src\* C:\dst</code>. Support for
remote syncs is being added, see
<a href="https://github.com/google/cdc-file-transfer/issues/61" data-hovercard-type="issue" data-hovercard-url="/google/cdc-file-transfer/issues/61/hovercard">#61</a>.<br>
<sup>2</sup> See <a href="https://github.com/google/cdc-file-transfer/issues/56" data-hovercard-type="issue" data-hovercard-url="/google/cdc-file-transfer/issues/56/hovercard">#56</a>.<br>
<sup>3</sup> See <a href="https://github.com/google/cdc-file-transfer/issues/62" data-hovercard-type="issue" data-hovercard-url="/google/cdc-file-transfer/issues/62/hovercard">#62</a>.</p>
</span>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Download the precompiled binaries from the
<a href="https://github.com/google/cdc-file-transfer/releases">latest release</a> to a
Windows device and unzip them. The Linux binaries are automatically deployed
to <code>~/.cache/cdc-file-transfer</code> by the Windows tools. There is no need to manually
deploy them. We currently provide Linux binaries compiled on
<a href="https://github.com/actions/runner-images">Github's latest Ubuntu</a> version.
If the binaries work for you, you can skip the following two sections.</p>
<p dir="auto">Alternatively, the project can be built from source. Some binaries have to be
built on Windows, some on Linux.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prerequisites for Building</h2><a id="user-content-prerequisites-for-building" aria-label="Permalink: Prerequisites for Building" href="#prerequisites-for-building"></a></p>
<p dir="auto">To build the tools from source, the following steps have to be executed on
<strong>both Windows and Linux</strong>.</p>
<ul dir="auto">
<li>Download and install Bazel from <a href="https://bazel.build/install" rel="nofollow">here</a>. See
<a href="https://github.com/google/cdc-file-transfer/actions">workflow logs</a> for the
currently used version.</li>
<li>Clone the repository.
<div data-snippet-clipboard-copy-content="git clone https://github.com/google/cdc-file-transfer"><pre><code>git clone https://github.com/google/cdc-file-transfer
</code></pre></div>
</li>
<li>Initialize submodules.
<div data-snippet-clipboard-copy-content="cd cdc-file-transfer
git submodule update --init --recursive"><pre><code>cd cdc-file-transfer
git submodule update --init --recursive
</code></pre></div>
</li>
</ul>
<p dir="auto">Finally, install an SSH client on the Windows machine if not present.
The file transfer tools require <code>ssh.exe</code> and <code>sftp.exe</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">The two tools CDC RSync and CDC Stream can be built and used independently.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">CDC RSync</h3><a id="user-content-cdc-rsync-1" aria-label="Permalink: CDC RSync" href="#cdc-rsync-1"></a></p>
<ul dir="auto">
<li>On a Linux device, build the Linux components
<div data-snippet-clipboard-copy-content="bazel build --config linux --compilation_mode=opt --linkopt=-Wl,--strip-all --copt=-fdata-sections --copt=-ffunction-sections --linkopt=-Wl,--gc-sections //cdc_rsync_server"><pre><code>bazel build --config linux --compilation_mode=opt --linkopt=-Wl,--strip-all --copt=-fdata-sections --copt=-ffunction-sections --linkopt=-Wl,--gc-sections //cdc_rsync_server
</code></pre></div>
</li>
<li>On a Windows device, build the Windows components
<div data-snippet-clipboard-copy-content="bazel build --config windows --compilation_mode=opt --copt=/GL //cdc_rsync"><pre><code>bazel build --config windows --compilation_mode=opt --copt=/GL //cdc_rsync
</code></pre></div>
</li>
<li>Copy the Linux build output file <code>cdc_rsync_server</code> from
<code>bazel-bin/cdc_rsync_server</code> to <code>bazel-bin\cdc_rsync</code> on the Windows machine.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">CDC Stream</h3><a id="user-content-cdc-stream-1" aria-label="Permalink: CDC Stream" href="#cdc-stream-1"></a></p>
<ul dir="auto">
<li>On a Linux device, build the Linux components
<div data-snippet-clipboard-copy-content="bazel build --config linux --compilation_mode=opt --linkopt=-Wl,--strip-all --copt=-fdata-sections --copt=-ffunction-sections --linkopt=-Wl,--gc-sections //cdc_fuse_fs"><pre><code>bazel build --config linux --compilation_mode=opt --linkopt=-Wl,--strip-all --copt=-fdata-sections --copt=-ffunction-sections --linkopt=-Wl,--gc-sections //cdc_fuse_fs
</code></pre></div>
</li>
<li>On a Windows device, build the Windows components
<div data-snippet-clipboard-copy-content="bazel build --config windows --compilation_mode=opt --copt=/GL //cdc_stream"><pre><code>bazel build --config windows --compilation_mode=opt --copt=/GL //cdc_stream
</code></pre></div>
</li>
<li>Copy the Linux build output files <code>cdc_fuse_fs</code> and <code>libfuse.so</code> from
<code>bazel-bin/cdc_fuse_fs</code> to <code>bazel-bin\cdc_stream</code> on the Windows machine.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">The tools require a setup where you can use SSH and SFTP from the Windows
machine to the Linux device without entering a password, e.g. by using key-based
authentication.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuring SSH and SFTP</h3><a id="user-content-configuring-ssh-and-sftp" aria-label="Permalink: Configuring SSH and SFTP" href="#configuring-ssh-and-sftp"></a></p>
<p dir="auto">By default, the tools search <code>ssh.exe</code> and <code>sftp.exe</code> from the path environment
variable. If you can run the following commands in a Windows cmd without
entering your password, you are all set:</p>
<div data-snippet-clipboard-copy-content="ssh user@linux.device.com
sftp user@linux.device.com"><pre><code>ssh user@linux.device.com
sftp user@linux.device.com
</code></pre></div>
<p dir="auto">Here, <code>user</code> is the Linux user and <code>linux.device.com</code> is the Linux host to
SSH into or copy the file to.</p>
<p dir="auto">If additional arguments are required, it is recommended to provide an SSH config
file. By default, both <code>ssh.exe</code> and <code>sftp.exe</code> use the file at
<code>%USERPROFILE%\.ssh\config</code> on Windows, if it exists. A possible config file
that sets a username, a port, an identity file and a known host file could look
as follows:</p>
<div data-snippet-clipboard-copy-content="Host linux_device
	HostName linux.device.com
	User user
	Port 12345
	IdentityFile C:\path\to\id_rsa
	UserKnownHostsFile C:\path\to\known_hosts"><pre><code>Host linux_device
	HostName linux.device.com
	User user
	Port 12345
	IdentityFile C:\path\to\id_rsa
	UserKnownHostsFile C:\path\to\known_hosts
</code></pre></div>
<p dir="auto">If <code>ssh.exe</code> or <code>sftp.exe</code> cannot be found, you can specify the full paths via
the command line arguments <code>--ssh-command</code> and <code>--sftp-command</code> for <code>cdc_rsync</code>
and <code>cdc_stream start</code> (see below), or set the environment variables
<code>CDC_SSH_COMMAND</code> and <code>CDC_SFTP_COMMAND</code>, e.g.</p>
<div data-snippet-clipboard-copy-content="set CDC_SSH_COMMAND=&quot;C:\path with space\to\ssh.exe&quot;
set CDC_SFTP_COMMAND=&quot;C:\path with space\to\sftp.exe&quot;"><pre><code>set CDC_SSH_COMMAND="C:\path with space\to\ssh.exe"
set CDC_SFTP_COMMAND="C:\path with space\to\sftp.exe"
</code></pre></div>
<p dir="auto">Note that you can also specify SSH configuration via the environment variables
instead of using a config file:</p>
<div data-snippet-clipboard-copy-content="set CDC_SSH_COMMAND=C:\path\to\ssh.exe -p 12345 -i C:\path\to\id_rsa -oUserKnownHostsFile=C:\path\to\known_hosts
set CDC_SFTP_COMMAND=C:\path\to\sftp.exe -P 12345 -i C:\path\to\id_rsa -oUserKnownHostsFile=C:\path\to\known_hosts"><pre><code>set CDC_SSH_COMMAND=C:\path\to\ssh.exe -p 12345 -i C:\path\to\id_rsa -oUserKnownHostsFile=C:\path\to\known_hosts
set CDC_SFTP_COMMAND=C:\path\to\sftp.exe -P 12345 -i C:\path\to\id_rsa -oUserKnownHostsFile=C:\path\to\known_hosts
</code></pre></div>
<p dir="auto">Note the small <code>-p</code> for <code>ssh.exe</code> and the capital <code>-P</code> for <code>sftp.exe</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Google Specific</h4><a id="user-content-google-specific" aria-label="Permalink: Google Specific" href="#google-specific"></a></p>
<p dir="auto">For Google internal usage, set the following environment variables to enable SSH
authentication using a Google security key:</p>
<div data-snippet-clipboard-copy-content="set CDC_SSH_COMMAND=C:\gnubby\bin\ssh.exe
set CDC_SFTP_COMMAND=C:\gnubby\bin\sftp.exe"><pre><code>set CDC_SSH_COMMAND=C:\gnubby\bin\ssh.exe
set CDC_SFTP_COMMAND=C:\gnubby\bin\sftp.exe
</code></pre></div>
<p dir="auto">Note that you will have to touch the security key multiple times during the
first run. Subsequent runs only require a single touch.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">CDC RSync</h3><a id="user-content-cdc-rsync-2" aria-label="Permalink: CDC RSync" href="#cdc-rsync-2"></a></p>
<p dir="auto"><code>cdc_rsync</code> is used similar to <code>scp</code> or the Linux <code>rsync</code> command. To sync a
single Windows file <code>C:\path\to\file.txt</code> to the home directory <code>~</code> on the Linux
device <code>linux.device.com</code>, run</p>
<div data-snippet-clipboard-copy-content="cdc_rsync C:\path\to\file.txt user@linux.device.com:~"><pre><code>cdc_rsync C:\path\to\file.txt user@linux.device.com:~
</code></pre></div>
<p dir="auto"><code>cdc_rsync</code> understands the usual Windows wildcards <code>*</code> and <code>?</code>.</p>
<div data-snippet-clipboard-copy-content="cdc_rsync C:\path\to\*.txt user@linux.device.com:~"><pre><code>cdc_rsync C:\path\to\*.txt user@linux.device.com:~
</code></pre></div>
<p dir="auto">To sync the contents of the Windows directory <code>C:\path\to\assets</code> recursively to
<code>~/assets</code> on the Linux device, run</p>
<div data-snippet-clipboard-copy-content="cdc_rsync C:\path\to\assets\* user@linux.device.com:~/assets -r"><pre><code>cdc_rsync C:\path\to\assets\* user@linux.device.com:~/assets -r
</code></pre></div>
<p dir="auto">To get per file progress, add <code>-v</code>:</p>
<div data-snippet-clipboard-copy-content="cdc_rsync C:\path\to\assets\* user@linux.device.com:~/assets -vr"><pre><code>cdc_rsync C:\path\to\assets\* user@linux.device.com:~/assets -vr
</code></pre></div>
<p dir="auto">The tool also supports local syncs:</p>
<div data-snippet-clipboard-copy-content="cdc_rsync C:\path\to\assets\* C:\path\to\destination -vr"><pre><code>cdc_rsync C:\path\to\assets\* C:\path\to\destination -vr
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CDC Stream</h3><a id="user-content-cdc-stream-2" aria-label="Permalink: CDC Stream" href="#cdc-stream-2"></a></p>
<p dir="auto">To stream the Windows directory <code>C:\path\to\assets</code> to <code>~/assets</code> on the Linux
device, run</p>
<div data-snippet-clipboard-copy-content="cdc_stream start C:\path\to\assets user@linux.device.com:~/assets"><pre><code>cdc_stream start C:\path\to\assets user@linux.device.com:~/assets
</code></pre></div>
<p dir="auto">This makes all files and directories in <code>C:\path\to\assets</code> available on
<code>~/assets</code> immediately, as if it were a local copy. However, data is streamed
from Windows to Linux as files are accessed.</p>
<p dir="auto">To stop the streaming session, enter</p>
<div data-snippet-clipboard-copy-content="cdc_stream stop user@linux.device.com:~/assets"><pre><code>cdc_stream stop user@linux.device.com:~/assets
</code></pre></div>
<p dir="auto">The command also accepts wildcards. For instance,</p>

<p dir="auto">stops all existing streaming sessions for the given user.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto">On first run, <code>cdc_stream</code> starts a background service, which does all the work.
The <code>cdc_stream start</code> and <code>cdc_stream stop</code> commands are just RPC clients that
talk to the service.</p>
<p dir="auto">The service logs to <code>%APPDATA%\cdc-file-transfer\logs</code> by default. The logs are
useful to investigate issues with asset streaming. To pass custom arguments, or
to debug the service, create a JSON config file at
<code>%APPDATA%\cdc-file-transfer\cdc_stream.json</code> with command line flags.
For instance,</p>

<p dir="auto">instructs the service to log debug messages. Try <code>cdc_stream start-service -h</code>
for a list of available flags. Alternatively, run the service manually with</p>

<p dir="auto">and pass the flags as command line arguments. When you run the service manually,
the flag <code>--log-to-stdout</code> is particularly useful as it logs to the console
instead of to the file.</p>
<p dir="auto"><code>cdc_rsync</code> always logs to the console. To increase log verbosity, pass <code>-vvv</code>
for debug logs or <code>-vvvv</code> for verbose logs.</p>
<p dir="auto">For both sync and stream, the debug logs contain all SSH and SFTP commands that
are attempted to run, which is very useful for troubleshooting. If a command
fails unexpectedly, copy it and run it in isolation. Pass <code>-vv</code> or <code>-vvv</code> for
additional debug output.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>