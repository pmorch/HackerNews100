<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 06 Apr 2025 03:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple's Darwin OS and XNU Kernel Deep Dive (167 pts)]]></title>
            <link>https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/</link>
            <guid>43597778</guid>
            <pubDate>Sat, 05 Apr 2025 23:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/">https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=43597778">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-gjtny2mx="">    <article data-astro-cid-gjtny2mx="">  <p>This post is the result of me going down a several week long XNU rabbit-hole
after reading <a href="https://www.theregister.com/2025/03/08/kernel_sanders_apple_rearranges_xnu/">this post by Thomas Claburn on
Exclaves</a>,
more on that later. I’ve tried my best to condense all the information into a
single blog post. I’ve also tried to keep sections self-contained so you can
skip around using the table of contents, this does come at the cost of
repeating myself in some places, so thanks in advance for your patience. While
I’m confident of my understanding on this topic, some errors are inevitable
when dealing with content this dense, if you spot any errors, assume them to be
mine and please reach out so I can correct it, also let me know your thoughts
by reaching out via email or mastodon. Thanks in advance and let’s begin!</p>
<h2 id="introduction">Introduction</h2>
<p>Apple’s Darwin operating system is the Unix-like core underpinning macOS, iOS,
and all of Apple’s modern OS platforms. At its heart lies the XNU kernel – an
acronym humorously standing for “X is Not Unix.” XNU is a unique <strong>hybrid
kernel</strong> that combines a Mach microkernel core with components of BSD Unix.
This design inherits the rich legacy of Mach (originating from 1980s
microkernel research) and the robust stability and POSIX compliance of BSD. The
result is a kernel architecture that balances modularity and performance by
blending microkernel message-passing techniques with a monolithic Unix kernel
structure. We’ll go through a chronological exploration of Darwin and XNU’s
evolution – from Mach and BSD origins to the modern kernel features in macOS on
Apple Silicon and iOS on iPhones. We’ll follow this with a deep dive into the
architectural milestones, analyze XNU’s internal design (Mach-BSD interaction,
IPC, scheduling, memory management, virtualization), and examine how the kernel
and key user-space components have adapted to new devices and requirements over
time.</p>
<h2 id="darwin-and-xnu-development-history">Darwin and XNU Development History</h2>
<h3 id="mach-microkernel-origins-19851996">Mach Microkernel Origins (1985–1996)</h3>
<p>Darwin’s story begins with <strong>Mach</strong>, a project at Carnegie Mellon University
(1985) led by Richard Rashid and Avie Tevanian. Mach was envisioned as a
next-generation <strong>microkernel</strong> to address the growing complexity of UNIX
kernels. Instead of a single large kernel binary, Mach provided only
fundamental low-level functions – <strong>memory management</strong> (virtual memory,
address spaces), <strong>CPU scheduling</strong> (threads and tasks), and <strong>inter-process
communication</strong> (IPC via message passing). Higher-level services (file systems,
networking, device drivers, etc.) were intended to run as user-space <em>servers</em>
on top of Mach. This separation promised improved reliability (a crashed driver
wouldn’t crash the whole system) and flexibility (multiple OS personalities
could run concurrently). In fact, Mach’s design allowed running several
“personalities” – for example, UNIX and another OS – on one microkernel, a
concept analogous to modern virtualization.</p>
<p>By 1990, Mach had progressed to <strong>Mach 2.5</strong>, which was a microkernel but still
co-located some BSD kernel code in kernel space for performance. The true
microkernel version, <strong>Mach 3.0</strong>, arrived in 1991–1994. Mach’s <strong>virtual
memory (VM) system</strong> was influential beyond the project – it was adopted by
4.4BSD and later FreeBSD as their memory management subsystem. Importantly,
Mach introduced the concept of <strong>tasks</strong> (encapsulating an address space and
resources, roughly equivalent to a process) and <strong>threads</strong> (unit of CPU
execution) as first-class kernel objects. It also implemented an efficient VM
with copy-on-write and memory object abstractions, and a message-based IPC
mechanism using <strong>Mach ports</strong>.</p>
<p>Parallel to Mach’s development, <strong>NeXT Computer</strong> (founded by Steve Jobs in
1985) needed a modern OS for its workstations. NeXT adopted Mach early:
<strong>NeXTSTEP</strong>, released in 1989, was built on a Mach 2.5 kernel with a 4.3BSD
Unix subsystem layered on top. Crucially, NeXTSTEP’s kernel (later named
<strong>XNU</strong>) was not a pure microkernel system with user-space servers; instead, it
took Mach and <strong>integrated the BSD code into the kernel address space</strong> for
speed. In other words, NeXT used Mach’s abstractions (tasks, threads, IPC, VM)
and ran a BSD kernel <em>in kernel mode</em> on top of Mach primitives. This hybrid
approach sacrificed some of Mach’s extreme modularity in favor of performance:
it avoided the heavy context-switching and messaging overhead that plagued
fully microkernel systems of the era. NeXTSTEP’s kernel also included an
object-oriented driver framework called <strong>DriverKit</strong> (written in Objective-C)
to develop device drivers as objects, reflecting NeXT’s preference for
higher-level languages.</p>
<p>By the mid-1990s, Apple’s original Mac OS (classic Mac OS) was aging and lacked
modern OS features like proper multitasking and memory protection. In 1996,
Apple sought an existing OS as its foundation for the future. The company
acquired NeXT in December 1996, choosing NeXTSTEP as the core of the new <strong>Mac
OS X</strong>. With this acquisition, NeXT’s Mach/BSD hybrid kernel came to Apple,
bringing along the engineering leadership of Avie Tevanian (Mach co-author) as
Apple’s VP of Software. Apple named the new OS project <strong>Rhapsody</strong>, which
would later become Mac&nbsp;OS&nbsp;X.</p>
<h3 id="rhapsody-to-mac-os-x-integrating-mach-30-and-bsd-19972005">Rhapsody to Mac OS X: Integrating Mach 3.0 and BSD (1997–2005)</h3>
<p>After acquiring NeXT, Apple set out to merge the NeXTSTEP kernel with
additional features and hardware support needed for Macs. The kernel was
further updated with newer Mach and BSD technology. Notably, Apple incorporated
code from <strong>OSFMK 7.3</strong>, the Open Software Foundation’s Mach 3.0 kernel, into
XNU. This meant the Mach portion of XNU now drew from Mach 3.0’s true
microkernel lineage (including contributions from University of Utah’s Mach 4
research). On the BSD side, the NeXTSTEP kernel’s 4.3BSD subsystem was upgraded
with <strong>4.4BSD and FreeBSD</strong> code. This brought in a more modern BSD
implementation with features like improved networking and a robust filesystems
infrastructure. By combining Mach 3.0 and FreeBSD elements, Apple shaped XNU
into a powerful hybrid: Mach provided the low-level kernel architecture and
abstractions, while BSD provided the <strong>Unix APIs and services</strong> on top.</p>
<p>Apple also replaced NeXT’s old DriverKit with a new driver framework called
<strong>I/O Kit</strong>, written in a subset of C++. I/O Kit introduced a object-oriented
device driver model within the kernel, supporting features like dynamic device
matching and hot-plugging in a robust way. The choice of C++ (minus exceptions
and multiple inheritance, using Embedded C++ subset) for I/O Kit was likely to
improve performance and avoid the runtime overhead of Objective-C in the
kernel. By the late 1990s, XNU was thus composed of three core parts: the Mach
microkernel layer (now OSFMK 7.3 based), the BSD layer (largely
FreeBSD-derived), and the I/O Kit for drivers.</p>
<p>Apple delivered the first developer previews of Mac OS X in 1999, and in 2000
released the open source Darwin 1.0, which exposed the XNU kernel and basic
Unix userland to developers. The commercial debut, <strong>Mac&nbsp;OS&nbsp;X 10.0 (Cheetah)</strong>,
came in early 2001 (Darwin 1.3.1). While the initial releases were rough in
performance, they cemented the architectural paradigm. Key early milestones
included:</p>
<ul>
<li><strong>Mac OS X 10.1 (Puma, 2001)</strong> – Improved performance in threading and added
missing Unix features. Darwin 1.4.1 in 10.1 introduced faster thread
management and real-time threads support.</li>
<li><strong>Mac OS X 10.2 (Jaguar, 2002)</strong> – Darwin 6.0 brought the synchronicity of
the BSD layer with FreeBSD 4.4/5, plus large new features: IPv6 and IPSec
networking, the new <code>mDNSResponder</code> service for discovery
(Bonjour/Rendezvous), and journaling in HFS+ file system. It also upgraded
the toolchain (GCC3) and added modern Unix utilities.</li>
<li><strong>Mac OS X 10.3 (Panther, 2003)</strong> – Darwin 7.0/7.1 integrated <strong>FreeBSD 5</strong>
kernel improvements. This brought <strong>fine-grained kernel locking</strong> (moving
away from the earlier giant-lock model) to better utilize multiprocessors.
Panther’s kernel also introduced <strong>integrated BFS</strong> (basic firewall) and
other performance tuning like improved VM and I/O.</li>
</ul>
<p>Throughout these releases, XNU remained a 32-bit kernel (with limited 64-bit
user process support introduced in 10.4 for specific tasks). Apple maintained
support for PowerPC the Mac CPU architecture of choice in the early days while
also quietly keeping the Intel x86 compatibility (inherited from NeXTSTEP’s x86
support) in the source, preparing for future transitions.</p>
<p>A major architectural change arrived in <strong>Mac&nbsp;OS&nbsp;X 10.4 (Tiger, 2005)</strong>. This
was the first version where Apple declared OS&nbsp;X to be <strong>UNIX&nbsp;03 certified</strong>,
meaning the system conformed to the Single UNIX Specification and could legally
use the UNIX name. Darwin 8 (Tiger’s core) achieved this UNIX certification by
virtue of the robust BSD layer integrated in XNU. Tiger also introduced new
kernel features like <strong>kqueue/kevent</strong> (from FreeBSD, for scalable event
handling), and laid groundwork for Intel Macs by keeping XNU cross-platform.
Apple then announced in 2005 the switch to Intel x86 processors for Macs. XNU’s
Mach foundations made such platform adaptability easier, as Mach abstracted
many low-level hardware details behind a portability layer. In early 2006,
Apple released <strong>Mac&nbsp;OS&nbsp;X 10.4.4 for Intel</strong>, demonstrating XNU running on
x86_32 with much of the code shared with the PowerPC build.</p>
<h3 id="transition-to-64-bit-multi-core-and-iphone-os-20052010">Transition to 64-bit, Multi-Core and iPhone OS (2005–2010)</h3>
<p>By the mid-2000s, computing had shifted to multi-core 64-bit architectures, and
Apple’s OS had to evolve accordingly. <strong>Mac&nbsp;OS&nbsp;X 10.5 Leopard (2007)</strong>, based
on Darwin 9, was a landmark release for XNU. It introduced extensive 64-bit
support: while earlier versions could run 64-bit user applications in limited
form, Leopard’s kernel itself could run in 64-bit mode on appropriate hardware
(x86-64) and support 64-bit drivers. Leopard also dropped official support for
older architectures like PowerPC G3 and brought in stronger security and
performance features: <strong>address space layout randomization (ASLR)</strong> to thwart
exploits, an advanced <strong>sandbox</strong> facility for restricting processes, and the
<strong>DTrace</strong> instrumentation framework from Solaris for low-level tracing.
Notably, Leopard was the last Mac OS X version to fully support PowerPC – Apple
was transitioning its entire lineup to Intel by this time.</p>
<p>In 2007, Apple also debuted the <strong>iPhone</strong> with “iPhone OS” (later named iOS),
which was built on Darwin as well. The first iPhone OS was based on Darwin 9
(same core as Leopard). This demonstrated the versatility of XNU: within the
same kernel version, Apple could target high-end PowerPC and x86 servers,
consumer Intel laptops, and resource-constrained ARM mobile devices. The kernel
gained support for the ARM architecture and tailor-made modifications for
mobile. For example, because early iPhones had very limited RAM and no swap,
the kernel’s memory management had to incorporate aggressive <strong>memory-pressure
handling</strong>. Apple introduced a <strong>Jetsam</strong> mechanism in iPhone OS, which
monitored low-memory conditions and killed background apps to free memory
(since traditional swapping to disk was not feasible on flash storage). iPhone
OS also ran all third-party apps in a <em>sandbox</em> by design and required strict
code signing for binaries – security measures facilitated by XNU’s Mach and BSD
layers (Mach’s task port and codesign enforcement in the kernel, with help from
user-space daemons like <code>amfid</code> for signature validation).</p>
<p><strong>Mac&nbsp;OS&nbsp;X 10.6 Snow Leopard (2009)</strong> marked the maturation of XNU on 64-bit
Intel. Snow Leopard (Darwin 10) discontinued support for PowerPC entirely,
making XNU a dual-architecture kernel (x86_64 and i386 for Intel Macs). It
also was the first to ship with an <em>optional</em> fully 64-bit kernel on capable
Macs (most defaulted to 32-bit kernel with 64-bit userland, except Xserve).
Snow Leopard brought major concurrency advances: the introduction of <strong>Grand
Central Dispatch (libdispatch)</strong> for user-space task parallelization and kernel
support for <strong>dispatch queues</strong>. While <code>libdispatch</code> is a user-space library,
it works closely with the kernel, which provides the underlying thread pools
and scheduling for dispatch queues. Another addition was <strong>OpenCL</strong> for GPU
computing, again requiring tight integration between user frameworks and kernel
drivers. Snow Leopard’s streamlined focus on Intel and multi-core optimizations
made XNU more efficient.</p>
<p>On the mobile side, <strong>iPhone OS 3 (2009)</strong> and <strong>iOS 4 (2010)</strong> (renamed “iOS”
in 2010) evolved alongside, adding support for the Apple A4/A5 ARM chips and
features like multitasking. XNU’s scheduler was adapted in iOS 4 to handle the
concept of background apps with different priority bands (foreground,
background, etc.), and to support <strong>multi-core ARM SoCs</strong> as they appeared
(e.g., the Apple A5 in 2011 was dual-core). iOS and macOS kernels remained
largely unified, with conditional code for platform differences. By <strong>OS&nbsp;X 10.7
Lion (2011)</strong>, XNU dropped support for 32-bit Intel kernels entirely – it
required a 64-bit CPU on Mac, reflecting the industry’s move beyond 32-bit.
Lion (Darwin 11) also improved sandboxing and added full support for new
features like <strong>Automatic Reference Counting (ARC)</strong> in Obj-C (with compiler
and runtime changes reflected in the system).</p>
<h3 id="modern-macos-and-ios-evolution-20112020">Modern macOS and iOS Evolution (2011–2020)</h3>
<p>From 2011 onward, Apple’s OS releases came in a yearly cadence, and Darwin
continued to get incremental but significant enhancements to support new
hardware and features:</p>
<ul>
<li><strong>OS&nbsp;X 10.8 Mountain Lion (2012)</strong> and <strong>10.9 Mavericks (2013)</strong> (Darwin 12
and 13) introduced power- and memory-optimizations in the kernel. Mavericks
added <strong>Compressed Memory</strong>, a kernel feature where inactive pages are
compressed in RAM to avoid swapping to disk. This was in line with iOS
techniques to cope with low RAM, and it benefited Macs by improving
responsiveness under memory pressure. Mavericks also implemented <strong>Timer
Coalescing</strong>, where the kernel aligns wake-ups from idle to reduce CPU power
usage. These changes show how the kernel adapted to energy-efficiency
demands, influenced by mobile design philosophies. Additionally, around this
time, Apple introduced <strong>App Nap</strong> and increased use of Quality-of-Service
(QoS) classes for threads, which required kernel scheduling awareness to
throttle or prioritize threads based on QoS hints (e.g., background vs
user-initiated tasks). XNU’s scheduler evolved to support these multiple
priority bands and energy-efficient scheduling.</li>
<li><strong>OS&nbsp;X 10.10 Yosemite (2014)</strong> and <strong>10.11 El Capitan (2015)</strong> (Darwin 14 and
15) continued the trend. A major security addition in El Capitan was <strong>System
Integrity Protection (SIP)</strong>. SIP (also called “rootless”) is enforced by the
kernel’s security framework, preventing even root user processes from
tampering with critical system files and processes. Implemented via the BSD
layer’s Mandatory Access Control (MAC) framework, SIP hardened the OS by
moving more trust into the kernel and away from user space. For iOS (iOS 9 in
2015), similar “rootless” concepts were applied. Darwin 15 also saw Apple
unifying the code base for OS X and iOS further, as they introduced
<strong>watchOS</strong> and <strong>tvOS</strong> (both also Darwin-based) – XNU had to accommodate
running on tiny Apple Watch hardware (S1 chip) up to powerful Mac Pros, with
scalable scheduling, memory, and I/O capabilities. By now, XNU supported
ARM64 (64-bit ARMv8, first used in iPhone 5s in 2013) and would go on to drop
32-bit ARM support for iOS by <strong>iOS 11 (2017)</strong>.</li>
<li><strong>macOS 10.12 Sierra (2016)</strong>, <strong>10.13 High Sierra (2017)</strong>, <strong>10.14 Mojave
(2018)</strong> (Darwin 16–18) brought filesystem evolution and further security.
High Sierra introduced <strong>APFS (Apple File System)</strong> as the new default
filesystem, replacing HFS+. APFS required kernel support for snapshots,
cloning, and encryption at the container level. XNU’s VFS layer (in the BSD
component) was extended to accommodate APFS’s advanced features and
performance characteristics. During this era, kext (kernel extension)
security was tightened – macOS High Sierra requires user approval for loading
third-party kexts, and macOS Mojave introduced stricter code signing checks
and hardened runtime for user-space processes that also influence how the
kernel validates and allows certain operations. Another adaptation was
graphics and external device support, High Sierra’s eGPU support via
Thunderbolt required hot-plug handling improvements in I/O Kit and scheduling
of external PCIe devices.</li>
<li><strong>macOS 10.15 Catalina (2019)</strong> (Darwin 19) was a significant modernization
step for XNU. Catalina was the first to <strong>deprecate most 32-bit code</strong> (only
64-bit apps, and the kernel had been 64-bit only for years already). More
notably, Apple introduced a new approach for device drivers: <strong>DriverKit</strong>,
reviving the name of NeXT’s old driver framework but with a new design.
DriverKit in modern macOS allows many drivers to run in user space as
<strong>Driver Extensions (dexts)</strong>, outside of the kernel. This is a shift towards
microkernel philosophy for third-party code – by moving drivers (USB,
network, etc.) to user-space processes, Apple improved system stability and
security (a buggy driver can’t crash the kernel if it’s outside it). XNU was
adapted to facilitate this: the kernel provides user-space drivers with
controlled access to hardware (via IPC and shared memory) instead of loading
their code as kexts. At the same time, Catalina split the OS filesystem into
a read-only system volume, reinforcing the kernel’s SIP protections (the
kernel now treats system files as immutable during runtime). These changes
show how even decades after its birth, XNU’s architecture can pivot to
incorporate more user-space responsibilities when beneficial, leveraging the
Mach IPC mechanisms to do so safely.</li>
</ul>
<h3 id="apple-silicon-era-2020present">Apple Silicon Era (2020–Present)</h3>
<p>In 2020, Apple undertook another monumental transition: moving the Mac lineup
from Intel CPUs to Apple’s custom <strong>ARM64 SoCs</strong> (the <strong>Apple Silicon</strong> chips,
starting with M1). Darwin had long supported ARM due to iOS, but running macOS
on ARM64 introduced new challenges and opportunities. <strong>macOS 11 Big Sur
(2020)</strong>, corresponding to Darwin 20, was the first release for Apple Silicon
Macs. XNU was already cross-platform, but it now had to support a heterogeneous
<strong>big.LITTLE CPU architecture</strong>: Apple Silicon chips combine high-performance
cores and energy-efficient cores. The scheduler was enhanced to be
<strong>heterogeneity-aware</strong>, ensuring high-priority and heavy threads run on
performance cores, while background and low-QoS threads can be scheduled on
efficiency cores to save power. Apple likely utilizes the thread <strong>QoS
classes</strong> (which had been introduced in earlier macOS/iOS) to map threads to
appropriate core types – this is an extension of Mach scheduling concepts to a
new domain of asymmetric multiprocessing.</p>
<p>Another aspect of Apple Silicon is the unified memory architecture (shared
memory between CPU/GPU). While largely abstracted by frameworks, the kernel’s
memory manager works with the GPU drivers (which are now Apple’s own,
integrated via I/O Kit) to manage buffer sharing without expensive copies. The
Mach VM abstraction fits well here – memory objects can be shared between
user-space and the GPU with VM remapping rather than duplication. Additionally,
Apple Silicon brought hardware features like <strong>Pointer Authentication (PAC)</strong>
and <strong>Memory Tagging Extension (MTE)</strong> for security. XNU’s ARM64 backend had to
support PAC (which it does by using PAC keys in exception frames and system
pointers to mitigate ROP<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> attacks) and potentially MTE to detect memory
errors – these are deep architecture-specific enhancements in the kernel to
improve security on new hardware.</p>
<p>On the virtualization front, Apple Silicon prompted a reevaluation of
virtualization strategy. On Intel Macs, XNU has long supported virtualization
via the <strong>Hypervisor framework</strong> (introduced in macOS 10.10 Yosemite) which
allows user-space programs to run VMs using hardware VT-x support. With Apple
Silicon, macOS 11 introduced a new <strong>Virtualization framework</strong> built on top of
an in-kernel hypervisor for ARM64 (taking advantage of the ARM VMM features).
Notably, while the <strong>open-source XNU</strong> code does not include the Apple Silicon
hypervisor, the shipped kernel does initialize hypervisor support if running on
the appropriate Apple chip. This allows macOS on M1/M2 to run lightweight
virtual machines (for Linux, macOS guests, etc.) entirely from user-space
controllers, similar to Linux KVM. On iOS devices, Apple has kept the
hypervisor disabled or restricted (no public API), but the hardware capability
appeared with A14 chips. Enthusiasts quickly found that on jailbroken A14
devices, the hypervisor could be enabled to run Linux VMs<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>.</p>
<p>Beyond CPU and virtualization, Apple Silicon Macs run many of the same daemons
and services as iOS, indicating a convergence in system architecture. The XNU
kernel now powers everything from servers (macOS), personal computers, phones,
watches, TVs, and even the <strong>bridgeOS</strong> (a variant of Darwin running on the
Apple T2/M1 auxiliary processors for device management). Darwin’s <strong>flexibility
and scalability</strong> stem from the Mach foundation: it abstracts hardware
specifics in a platform layer, so adding a new CPU architecture (PowerPC → x86
→ ARM64) or scaling down to limited hardware largely requires implementing the
Mach low-level interfaces (like pmap for MMU, thread context switches, etc.)
and leaving higher-level kernel logic untouched. This design has paid dividends
in Apple’s transitions.</p>
<p>In summary, over two decades, XNU has undergone major transformations while
retaining its core identity. <strong>Table 1</strong> highlights a timeline of Darwin/XNU
milestones and architectural changes:</p>































































































<table><thead><tr><th><strong>Year</strong></th><th><strong>Release (Darwin ver.)</strong></th><th><strong>Key Kernel Developments</strong></th></tr></thead><tbody><tr><td><strong>1989</strong></td><td>NeXTSTEP 1.0 (Mach 2.5 + 4.3BSD)</td><td>NeXT’s XNU kernel hybrid introduced: Mach microkernel with BSD in kernel space for performance. Drivers via Obj-C DriverKit.</td></tr><tr><td><strong>1996</strong></td><td>NeXT acquired by Apple</td><td>Rhapsody OS development begins, based on OpenStep. Mach 2.5 + 4.3BSD XNU to be upgraded with Mach 3 and FreeBSD.</td></tr><tr><td><strong>1999</strong></td><td>Mac&nbsp;OS&nbsp;X Server 1.0 (Darwin 0.x)</td><td>First Darwin releases (0.1–0.3) as Apple integrates OSFMK Mach 3.0 (OSF/1) and FreeBSD into XNU.</td></tr><tr><td><strong>2001</strong></td><td>Mac&nbsp;OS&nbsp;X 10.0 (Darwin 1.3)</td><td>Darwin 1.x: Core OS X launched with hybrid kernel, BSD userland, Cocoa APIs. Early performance tuning of Mach/BSD integration.</td></tr><tr><td><strong>2003</strong></td><td>Mac&nbsp;OS&nbsp;X 10.3 (Darwin 7)</td><td>XNU sync with FreeBSD 5, bringing SMP scalability (fine-grained locking).</td></tr><tr><td><strong>2005</strong></td><td>Mac&nbsp;OS&nbsp;X 10.4 (Darwin 8)</td><td>UNIX&nbsp;03 certified kernel. Intel x86 support readied (Mach portability layer leveraged).</td></tr><tr><td><strong>2006</strong></td><td>Mac&nbsp;OS&nbsp;X on Intel (Darwin 8.x)</td><td>Apple transitions Macs to x86. XNU supports <strong>Universal Binary</strong> drivers and Rosetta translation (user-space emulation of PowerPC on x86).</td></tr><tr><td><strong>2007</strong></td><td>Mac&nbsp;OS&nbsp;X 10.5 (Darwin 9)</td><td>64-bit support in kernel (on x86_64); last PowerPC support. Security: NX support, ASLR, code signing, sandbox introduced. <strong>iPhone OS 1</strong> (Darwin 9) released on ARM, with XNU scaled to mobile (no swap, sandbox always on).</td></tr><tr><td><strong>2009</strong></td><td>Mac&nbsp;OS&nbsp;X 10.6 (Darwin 10)</td><td>Intel-only (drops PowerPC). Fully 64-bit kernel on capable Macs; Grand Central Dispatch (kernel task queues); OpenCL support. iPhone OS -&gt; <strong>iOS 3</strong> (Darwin 10) adds improved power management.</td></tr><tr><td><strong>2011</strong></td><td>Mac&nbsp;OS&nbsp;X 10.7 (Darwin 11)</td><td>Drops 32-bit kernel support on Mac; Requires x86_64. Expands sandboxing, FileVault 2 encryption (kernel crypto). <strong>iOS 5</strong> brings dual-core scheduling.</td></tr><tr><td><strong>2013</strong></td><td>OS&nbsp;X 10.9 (Darwin 13)</td><td>Power optimizations: compressed memory, timer coalescing in kernel. Improved multicore scheduling with QoS introduction.</td></tr><tr><td><strong>2015</strong></td><td>OS&nbsp;X 10.11 (Darwin 15)</td><td><strong>System Integrity Protection</strong> (kernel-enforced security). Enhanced AMFI (Apple Mobile File Integrity) for code signing in kernel and user helper (amfid). iOS 9 / watchOS debut (Darwin 15) on new device categories, kernel runs on Apple Watch (ARM Cortex-A7).</td></tr><tr><td><strong>2017</strong></td><td>macOS 10.13 (Darwin 17)</td><td>New APFS filesystem default on Mac (already in iOS 10). Kernel changes for cloning, snapshots. Kext loading requires user approval. iOS 11 drops 32-bit ARM, fully 64-bit kernel.</td></tr><tr><td><strong>2019</strong></td><td>macOS 10.15 (Darwin 19)</td><td>Legacy I/O Kit model shifts: <strong>DriverKit</strong> introduced for user-space drivers. System extensions modularize networking and endpoint security features out of kernel. macOS split system volume (read-only) to strengthen kernel’s protection of OS files.</td></tr><tr><td><strong>2020</strong></td><td><strong>macOS 11.0 (Darwin 20)</strong></td><td><strong>Apple Silicon support</strong> – XNU on ARM64 Mac (M1). Kernel adapts to heterogeneous cores, unified memory. Rosetta 2 translation tier (user-space JIT, with kernel enforcing memory protections for translated code). <strong>iOS 14</strong> – exposes new virtualization features for developers (e.g., running lightweight VMs on iPadOS).</td></tr><tr><td><strong>2022</strong></td><td>macOS 13 (Darwin 22)</td><td>Continued refinement for Apple Silicon (e.g., high-power mode on M1 Max, kernel scheduling tweaks). <strong>iOS 16</strong> – XNU adds support for virtualizing iOS/macOS guests (used in Xcode Simulator and Developer Mode features).</td></tr><tr><td><strong>2024</strong></td><td>macOS 14 (Darwin 23)</td><td>Ongoing improvements (Memory tagging support and fine-tuning for M2/M3 chips). Darwin remains the common core for <strong>visionOS</strong> (Apple Vision Pro AR headset) as well.</td></tr></tbody></table>
<p><strong>Table 1:</strong> Timeline of Darwin/XNU evolution with selected kernel milestones and architectural changes.</p>
<p>This timeline shows how XNU’s Mach/BSD core proved to be a stable foundation
that Apple could incrementally enhance: adding 64-bit support, embracing
multicore, tightening security, and porting to new architectures, all while
retaining backward compatibility. Next, we delve into the internal architecture
of XNU – the hybrid kernel design that made all of this possible.</p>
<h2 id="xnu-kernel-architecture-and-design">XNU Kernel Architecture and Design</h2>
<p><img alt="MacOS-Architecture.png" width="2169" height="2048" loading="lazy" decoding="async" src="https://tansanrao.com/_astro/MacOS-Architecture.B0qOydhL_Z1GQHHd.webp"></p>
<blockquote>
<p>File: Diagram of Mac OS X architecture.svg. (2024, December 29). <em>Wikimedia
Commons</em>. Retrieved 22:59, April 3, 2025 from
<a href="https://commons.wikimedia.org/w/index.php?title=File:Diagram_of_Mac_OS_X_architecture.svg&amp;oldid=976998015">https://commons.wikimedia.org</a>.</p>
</blockquote>
<h3 id="hybrid-kernel-design-mach--bsd-integration">Hybrid Kernel Design: Mach + BSD Integration</h3>
<p>XNU’s kernel design is often described as a <strong>hybrid kernel</strong>, because it
merges characteristics of microkernels (Mach) and monolithic kernels (BSD). In
a traditional microkernel, the kernel provides minimal services (IPC,
scheduling, VM) and everything else runs as user-space servers. In a monolithic
UNIX kernel, all OS services run in kernel mode as one large program. XNU
attempts to get “the best of both”: it uses Mach to modularize and abstract
low-level functions, but co-locates the critical BSD services in kernel space
for efficiency.</p>
<p>In XNU, the Mach component and the BSD component <strong>run as a single kernel
entity</strong> – they are linked into one binary and share the same address space.
There is no Mach vs BSD protection boundary; Mach functions and BSD functions
call each other via normal function calls within the kernel, not via IPC
messages. This co-location avoids the significant context-switch overhead that
a pure Mach system would incur (where a Unix system call would require
messaging a user-space BSD server). As a result, standard UNIX system calls
(file I/O, socket operations, etc.) in XNU perform comparably to other
monolithic Unix kernels, since the BSD code executes directly in kernel mode.
For instance, when a process calls <code>read()</code>, it traps into the kernel and the
BSD file system code is invoked directly; there’s no Mach message to a separate
process as would happen in a Mach 3.0 microkernel with an external BSD server.</p>
<p><strong>Mach’s Role:</strong> Mach in XNU provides the core kernel <strong>infrastructure and
abstractions</strong>. Mach manages CPU <em>threads</em> and task address spaces, implements
low-level scheduling, and handles virtual memory management (memory mapping,
paging). It also provides the fundamental <strong>IPC mechanism</strong> – Mach messages
sent over Mach <em>ports</em> (communication endpoints). In XNU, every process (BSD
process) is backed by a Mach <strong>task</strong> and every thread by a Mach thread. The
Mach layer is responsible for creating and terminating tasks/threads, context
switching threads on the CPU, and implementing primitives like locks, timers,
and scheduling queues. It also implements the VM system: each task has a
virtual address map, memory regions are backed by Mach <strong>memory objects</strong>, and
Mach can perform copy-on-write copy optimizations and map propagation. Notably,
Mach supports <strong>IPC-based memory sharing</strong> – one task can send a memory object
(or a port right to it) to another, enabling efficient shared memory or
transfer of large buffers without copying.</p>
<p><strong>BSD’s Role:</strong> The BSD component sits logically “on top” of Mach and provides
the traditional <strong>OS personality</strong> and services. This includes managing
<strong>processes</strong> (the BSD process table, PID allocation, user IDs, signals, etc.),
<strong>POSIX threads</strong> (which are mapped to Mach threads), and the entire set of
UNIX system calls (file systems, networking, IPC, device I/O, etc.). The BSD
kernel in XNU is derived primarily from FreeBSD (with substantial
OpenBSD/NetBSD influences and custom Apple modifications). It handles things
like:</p>
<ul>
<li><strong>VFS and File Systems:</strong> XNU’s BSD layer implements a VFS (Virtual File
System) and supports many file systems (HFS+, APFS, NFS, etc.). The file
system code runs in the kernel and interacts with storage drivers via I/O
Kit. Mach VM and BSD file systems meet when implementing memory-mapped files
– Mach calls into BSD to fetch pages from files on disk (via the vnode
pager).</li>
<li><strong>Network Stack:</strong> The entire TCP/IP stack (and other protocols like UDP,
ICMP, as well as higher-level sockets API) is in the BSD kernel. This code
came from BSD and is updated with modern standards. It interfaces with
network drivers (in I/O Kit) for packet send/receive.</li>
<li><strong>UNIX IPC:</strong> Besides Mach IPC, XNU provides traditional Unix IPC (signals,
pipes, SysV IPC, POSIX message queues, etc.) through the BSD layer. Signals,
for example, are implemented by the BSD kernel, but interestingly signals are
delivered using Mach exceptions under the hood – Mach exceptions are the
low-level mechanism, and the BSD code translates them to Unix signals for
processes as needed.</li>
<li><strong>Security and Credentials:</strong> The BSD layer manages user IDs, permissions,
access control, and integrates several security frameworks. For instance,
<strong>KAuth</strong> (Kernel Authorization) and the MAC Framework (Mandatory Access
Control) operate in the BSD layer. Features like the Sandbox, SIP, code
signing enforcement involve cooperation between BSD security modules and Mach
task port restrictions. The sandbox (Seatbelt) in macOS/iOS uses the
TrustedBSD MAC framework – when a system call is made, the MAC policy can vet
it. This happens in the BSD layer, though the sandbox’s configuration is set
from user space by launchd or other daemons.</li>
<li><strong>POSIX APIs and Environment:</strong> The BSD layer is what makes Darwin a UNIX. It
provides <code>/dev</code> management (which often links to I/O Kit devices), system
call table for standard C library calls, process forking (<code>fork()</code> is
implemented partly by Mach (VM copy-on-write) and partly by BSD (duplicating
file descriptors, etc.), and execve (loading binaries, setting up Mach task
states and BSD process states).</li>
</ul>
<p>In essence, one can think of Mach as the <strong>core kernel supervisor</strong> in XNU, and
BSD as a high-level kernel server that depends on Mach. The two are tightly
coupled – e.g., when a new BSD process is created via <code>fork()</code>, the kernel
internally calls Mach to create a new task and thread, then BSD code populates
the process structure and file descriptors. The BSD code calls Mach kernel
functions directly (not via message) using an internal API. Conversely, Mach
relies on some BSD services; for example, Mach has an abstraction called
“default pager” for managing swap. In XNU, the default pager is implemented
partly in user space (the <code>dynamic_pager</code> daemon) which uses Mach VM APIs to
create and manage swap files, but the BSD layer is involved in the actual file
I/O to the swap file. This shows a cooperative multi-tier design rather than
strictly separated layers.</p>
<p><strong>I/O Kit:</strong> The third pillar of XNU is the <strong>I/O Kit</strong>, Apple’s
object-oriented driver framework. I/O Kit runs in kernel space (as part of the
XNU kernel), but it is written in a restricted form of C++ for type-safety and
code reuse. The I/O Kit defines a class hierarchy for devices (buses, storage,
network, display, etc.) and drivers subclass these to implement support for
specific hardware. Drivers in I/O Kit live as C++ objects within the kernel,
but they interact with user space through well-defined interfaces. For
instance, an I/O Kit driver can publish properties accessible via the I/O
Registry, and can provide <strong>user client</strong> interfaces that allow user-space
applications or daemons to call into the driver in a controlled way. I/O Kit
also supports limited <strong>user-space drivers</strong> historically (via user clients),
but in practice, until recent DriverKit, most drivers ran in kernel. The Mach
component provides threading and synchronization primitives used by I/O Kit
(like locks and workloops), while the BSD component interacts with I/O Kit for
networking and disk I/O (e.g., the BSD filesystem code calls an I/O Kit disk
driver to read a block). The decision to use C++ in kernel (contrary to the
“not written in C++” myth; the core kernel logic is C, but drivers are C++
classes) was made to improve extensibility. By eliminating multiple inheritance
and exceptions, Apple ensured the kernel would not suffer C++ runtime overhead.
Many drivers can be loaded and unloaded dynamically as <strong>Kexts</strong> (kernel
extensions), which are essentially loadable bundles of I/O Kit C++ classes or
additional BSD/Mach code. XNU’s modularity in this sense is reminiscent of
other OS kernels that allow loadable modules, but Mach’s abstractions also help
here (each kext is essentially a Mach-O image loaded into kernel memory and
linked).</p>
<p><strong>Mach IPC and Message Passing:</strong> Even though XNU does not use Mach messages
for Unix <em>system calls</em>, Mach IPC is still heavily used throughout the system
for what we might call “RPC”-style interactions and for connecting
user-space services to kernel or to each other. Mach ports are the
foundation of various high-level features:</p>
<ul>
<li>Many kernel abstractions are represented as Mach ports to user space. For
example, each task (process) has a Mach port (the task port) that represents
its control handle. The kernel holds the rights, but certain privileged tasks
(like <code>launchd</code> or debugging tools) can obtain send rights to manipulate
other tasks (to start/stop them, inspect memory, etc.).</li>
<li>Mach <strong>notifications</strong> are used for event delivery. The WindowServer
(graphics system) receives user input events from the kernel via Mach
messages. Likewise, higher-level APIs like Grand Central Dispatch under the
hood use Mach ports to sleep threads waiting for events, leveraging Mach’s
port-set and message mechanism. The <code>kqueue/kevent</code> mechanism in BSD is
integrated: an event queue can wait on Mach port messages as well as file
descriptors, unifying the event sources.</li>
<li><strong>Inter-process Communication</strong> for system services: Apple’s entire <strong>XPC</strong>
framework (used by modern macOS/iOS for lightweight IPC between apps and
services) is built on Mach messages. Each XPC connection is essentially a
Mach port behind the scenes. The reason Mach IPC is chosen is its security
model – Mach ports have an associated rights system and live in the kernel,
so the kernel mediates who can send to whom. This allows checks like “is the
sender task entitled to send this message?” which is used in services like
the Keychain (securityd) to validate callers. Mach messages also support
carrying out-of-line memory (shared memory regions) and port rights, which is
extremely powerful for building higher-level RPC: you can send a file
descriptor (which is a BSD concept) as a Mach port right in a message,
enabling UNIX domain socket semantics via Mach. Under the hood, the file
descriptor send uses a Mach port representing that file in the receiving
task’s space.</li>
<li><strong>Remote Procedure Calls:</strong> Mach introduced MIG (Mach Interface Generator),
which is used to define interfaces where one side is in kernel and the other
in user. For example, the bootstrap server (launchd) and various system
servers use MIG to auto-generate code for sending/receiving messages. The
macOS <code>notify</code> system (for system-wide notifications) and many daemon APIs
are implemented with MIG definitions.</li>
</ul>
<p>Therefore, Mach IPC is a backbone for the macOS/iOS architecture beyond the
kernel boundary. It’s how user-space components talk to each other and to the
kernel in many cases. Even certain device drivers use Mach port notifications
(e.g., I/O Kit user clients might deliver an asynchronous event to a client via
a Mach message). The hybrid kernel thus uses Mach messaging where appropriate
(for asynchronous, out-of-band communication), and uses direct function calls
for in-kernel interactions. This hybrid approach retains Mach’s <strong>modularity</strong>
benefits – for instance, one can imagine refactoring a component to run in
user space with Mach messages without changing the other parts, since they
might already use a Mach port interface to talk to it. In fact, Apple did
exactly this with DriverKit: they moved certain drivers to user space and
replaced their in-kernel part with a Mach IPC conduit. The
performance-critical path (e.g., actual packet sending) might still be in
kernel, but higher-level policy or USB logic can be in a user process
communicating via Mach.</p>
<h3 id="scheduler-and-thread-management">Scheduler and Thread Management</h3>
<p>XNU’s scheduling is rooted in Mach’s scheduler, which was originally a
priority-based round-robin scheduler with support for threads and processor
sets. Over time, Apple has modified the scheduler significantly to meet the
needs of desktop and mobile. The scheduler manages threads (Mach threads)
across CPU cores (XNU supports SMP and on Apple Silicon, asymmetric cores). Key
points of XNU scheduling:</p>
<ul>
<li><strong>Priority Levels:</strong> Mach defines a range of thread priorities (0–127,
historically) with certain bands reserved for real-time, kernel, and normal
threads. Apple uses these priorities along with abstractions called
<strong>“sched_pri”</strong> and <strong>“base_pri”</strong> for each thread. Time-sharing threads have
priorities that can float based on usage (to implement favoring I/O-bound
threads), whereas real-time threads have fixed priorities. The highest
priorities are for critical kernel threads or timers.</li>
<li><strong>Run Queues:</strong> In classic Mach, each processor or processor-set had a run
queue for threads. XNU has per-CPU run queues for efficiency. It also has
mechanisms for <strong>scheduler interrupts</strong> to load-balance or preempt when
necessary.</li>
<li><strong>Extended Policies:</strong> Apple added features like <strong>container-level
prioritization</strong>. When iOS introduced App Sandbox with backgrounding, the
scheduler got a concept of a “task role” or “priority group”. In Darwin 9
(Leopard/iPhone OS), an “improved hierarchical process scheduling model” was
noted, which suggests that threads were grouped by tasks or by “workload”,
possibly to enforce limits on background tasks. This is likely the origin of
<strong>boosts and throttles</strong> that iOS uses to ensure the foreground app gets more
CPU than background apps.</li>
<li><strong>Quality of Service (QoS):</strong> In iOS 8 / OS X 10.10 and beyond, Apple
introduced QoS classes (user-interactive, user-initiated, default, utility,
background, etc.) for threads. The kernel scheduler integrates QoS by mapping
them to priority bands and scheduling deadlines. Threads created by Grand
Central Dispatch or NSThreads inherit a QoS that influences their scheduling
priority and which core they run on. This was further refined on Apple
Silicon where the scheduler might steer “background QoS” threads to
efficiency cores. Internally, XNU’s <code>sched_prim.c</code> and <code>sched_perf.c</code> (for
performance controller) handle these decisions. There is also an interface
for the kernel to ask the power management firmware about energy vs
performance (used in macOS’s power management QoS).</li>
<li><strong>Realtime and Multimedia:</strong> macOS supports realtime threads for audio or
critical tasks. The scheduler has a realtime queue and will preempt other
work to run RT threads to meet latency requirements. Also, since Mac OS X
10.4, XNU has <strong>scheduler deadlines</strong> for real-time threads (used for audio
playback, etc.), which is an EDF-like (Earliest deadline first) feature.</li>
<li><strong>Idle and Power:</strong> On mobile devices, the scheduler cooperates with the
power management to aggressively idle cores. Mach scheduler invokes an idle
thread when no work is available, and in iOS, if all cores are idle, the
system can enter low-power states quickly. Timer coalescing (10.9 Mavericks)
means the scheduler tries to batch wakeups – effectively, if several threads
have timers expiring, it aligns them to let CPU sleep longer intervals.</li>
</ul>
<p>Overall, XNU’s scheduler has evolved from Mach’s general-purpose design to one
aware of <strong>multi-core</strong> and <strong>heterogeneous</strong> cores, <strong>energy vs performance</strong>
trade-offs, and <strong>workload groupings</strong> (like apps vs system daemons vs kernel
threads). It still uses Mach’s thread data structures, but many scheduling
algorithms have been tuned by Apple (sometimes influenced by developments in
FreeBSD or other OSes).</p>
<h3 id="memory-management-and-virtual-memory">Memory Management and Virtual Memory</h3>
<p>Memory management in XNU is primarily handled by Mach’s VM subsystem, which is
one of Mach’s strongest components. Key aspects:</p>
<ul>
<li><strong>Virtual Address Space:</strong> Each Mach task has a virtual address space
represented by a set of <strong>VM maps</strong> and <strong>VM regions</strong>. When a process (task)
is created, it starts with a copy of the parent’s address space. Mach’s VM is
inherently copy-on-write – <code>fork()</code> doesn’t duplicate all memory immediately;
instead, both parent and child share pages marked copy-on-write until either
writes, then a fault triggers an actual copy. This makes <code>fork()</code> efficient
despite potentially large processes.</li>
<li><strong>Memory Objects and Pagers:</strong> Mach introduces the concept of <em>memory
objects</em> to represent a backing store for memory (like a file or the swap
area) and <em>pagers</em> which supply data to those memory objects on demand. In
XNU, the <strong>default pager</strong> (for anonymous memory) is implemented by the
<code>dynamic_pager</code> user-space daemon which manages swap files. That is, when the
kernel decides to evict a page from RAM, Mach will send a message to the
default pager indicating the page should be written to swap. The
<code>dynamic_pager</code> then writes to the swap file (via normal file I/O). This is a
classic microkernel design: the <strong>pager runs in user space</strong>, meaning the
policy of how to manage swap space is not fixed in kernel. By adjusting or
replacing dynamic_pager, one could change swapping behavior (e.g., macOS’s
dynamic_pager can create multiple swap files on demand). File memory is
managed by a different pager: the <strong>vnode pager</strong> inside the kernel (this one
is not user-space, but part of XNU’s BSD layer) which interacts with file
system code to read/write file data for memory mapped files. Having this
modular pager design made features like <strong>compressed memory</strong> feasible to
implement – in Mavericks, an in-kernel compression pager was added: when
pressure is high, instead of immediately paging to disk, XNU can compress
inactive pages and keep them in a reserved VM object (the “compressor pool”)
in RAM. The VM considers that as a form of pseudo-swapping (faster than
disk). Only if compression is insufficient does it resort to disk swap via
dynamic_pager.</li>
<li><strong>Physical Memory Management:</strong> XNU abstracts physical memory operations in a
machine-dependent layer called <strong>pmap</strong> (physical map). The pmap manages page
tables or equivalent structures on each architecture. When Mach allocates a
new VM region, it uses pmap to map virtual pages to physical frames. On
ARM64, pmap also integrates with security features (like marking pages with
the appropriate permission keys for PAC, or handling aliasing issues with
caches). The kernel uses a <strong>zone allocator</strong> for many kernel memory
structures (zones are pools for objects of fixed size, like VM map entries,
IPC port structures, etc.). There’s also a general-purpose <strong>kernel malloc</strong>
(kmem) for variable sizes. Notably, the XNU kernel employs strategies to
mitigate fragmentation and has guard pages for certain allocations to detect
overruns (on debug kernels, typically).</li>
<li><strong>Shared Memory and Map Inheritance:</strong> Mach VM allows tasks to share regions
– either explicitly via Mach IPC (sending a port for a memory object) or via
inheritance (a child can inherit memory from parent on fork with
copy-on-write or shared semantics). This is how the dynamic linker works in
macOS: the shared cache of frameworks is mapped into every process at launch
via a shared memory region provided by <code>dyld</code>. Mach makes this efficient by
mapping the same physical pages into all tasks read-only.</li>
<li><strong>Kernel Virtual Memory:</strong> The kernel itself has a virtual address space.
Mach manages kernel memory similarly to user memory, but there are
differences: the kernel uses a single map for all of kernel space, and some
regions are wired (non-pageable). XNU historically had a 32-bit kernel for
which it used tricky schemes like a shared address space with user processes
(in early OS X on 32-bit, kernel and user shared space to avoid costly
segment switches, but on 64-bit this was not an issue). Modern XNU (64-bit)
uses a separate address space for kernel, with portions (like the shared
cache, comm page) mapped into user for communication.</li>
<li><strong>Memory Protection:</strong> Mach’s design enforces that one task cannot access
another task’s memory unless explicitly allowed. This is basic memory
protection via separate address spaces. The only controlled sharing is via
Mach VM APIs or if the kernel (or a privileged daemon) maps memory into
another task (used by things like the debugger or by the system frameworks to
implement features like XPC shared memory). The kernel also zero-fills memory
on allocation to avoid leakage between processes.</li>
<li><strong>Evolution for Apple Silicon:</strong> On Apple Silicon, with large physical memory
and unified memory, XNU’s VM had to consider not having distinct GPU memory.
Instead, I/O Kit drivers for GPU allocate from general memory with certain
attributes (e.g., contiguous, protected). The pmap might have optimizations
for the extremely large virtual address space (ARMv8.5 supports 52-bit VA).
Also, memory tagging (MTE) if used would mean the kernel must manage tag
bits in pointers and memory; Apple hasn’t announced using it, but the
hardware is there on M2. If enabled, the kernel would tag allocations and
check tags on load/store, catching use-after-free or overflow.</li>
</ul>
<p>XNU’s VM is regarded as quite advanced due to its Mach heritage – it was built
for 64-bit from the start (Mach had 64-bit addressing on 32-bit hardware via
abstractions), and it’s relatively decoupled from the rest of kernel logic,
which is why Apple could plug in new features (compressor, different
pagers) without massive overhaul.</p>
<h3 id="virtualization-support">Virtualization Support</h3>
<p>While Mach’s original vision could be seen as a form of virtualization
(multiple OS personalities on one kernel), modern hardware virtualization is a
different beast. XNU did not originally include a hypervisor in early releases,
but as virtualization became important, Apple added support. On <strong>Intel Macs</strong>,
XNU gained the ability to manage the hardware virtualization extensions (Intel
VT-x) around 2014. Apple provided a <strong>Hypervisor.framework</strong> API to developers
from OS&nbsp;X 10.10 onward, enabling user-space virtualization without third-party
kernel extensions. Under the hood, a kernel extension (or part of XNU) would
configure VMX operations, allowing a user-space process to act as a virtual
machine monitor. This was used by tools like <strong>xhyve</strong> (a port of FreeBSD’s
bhyve to macOS), and by virtualization apps when running without their own
drivers.</p>
<p>On <strong>Apple Silicon (ARM64)</strong>, the approach is similar conceptually: XNU on
these devices can act as a Type-2 hypervisor using ARM’s virtualization
extensions (EL2 on ARM). Apple introduced a more full-featured
<strong>Virtualization.framework</strong> in macOS 11, which builds on an in-kernel
hypervisor to let developers run Linux or even macOS VMs in user space. One
design decision on Apple Silicon was to not allow arbitrary third-party
hypervisors in kernel; instead, the hypervisor is part of XNU but only
accessible via Apple’s frameworks with proper entitlements (to maintain
security).</p>
<p>From a kernel perspective, the XNU hypervisor functionality includes: managing
<strong>guest physical memory</strong>, handling <strong>trap and emulate</strong> for sensitive
instructions, and exposing virtual CPU interfaces to user space (for instance,
allowing a user program to set register state and run a vCPU until the next VM
exit). The Mach scheduling is leveraged to schedule vCPUs (which are just
threads from the host’s point of view). The memory subsystem is used to map
guest memory. On Apple Silicon, features like Stage 2 page tables for guests
are managed likely by an in-kernel hypervisor module.</p>
<p>Additionally, XNU supports containers and emulation in various ways (not full
virtualization but worth noting): the <strong>XNU kernel supports multiple user-space
“personalities”</strong> only in a limited sense now (for example, the Rosetta 2
x86_64 code translator on ARM is not a separate OS but it does require the
kernel to manage alternate CPU context for x86 state). The kernel includes an
<strong>x86 emulator</strong> or at least support for handling x86 code segmentation, etc.,
when Rosetta translates x86 code to ARM64 – primarily done in user space by
Rosetta’s JIT, the kernel might assist e.g. with syscall translation or by
providing an x86_64 syscall ABI on ARM.</p>
<p>The design choices around virtualization emphasize security and performance:
Apple’s approach is to keep the hypervisor simple and lean and to strongly
isolate guest OSes from the host (different Mach task, limited communication).
As of iOS 15, Apple even allows <strong>virtualization on iOS</strong> (to run Linux inside
an iPad app, for example, which some developers have demoed), indicating the
XNU hypervisor is capable on mobile as well, though subject to entitlement.</p>
<p>In summary, virtualization in XNU spans from the conceptual Mach
multi-personality support (not widely used in products outside early Classic
environment on OS&nbsp;X which ran Mac OS 9 in a para-virtualized setup), to robust
hardware-assisted virtualization on modern Macs.</p>
<h3 id="secure-computing">Secure Computing</h3>
<p>MacOS uses two complementary but distinct isolation mechanisms—<strong>Secure
Enclaves</strong> and the more recently introduced <strong>exclaves</strong>—to protect sensitive
operations and data.</p>
<p>The <strong>Secure Enclave</strong> is a dedicated, hardened subsystem integrated into
Apple’s SoCs (found in iPhones, iPads, Macs with T2 or Apple Silicon, etc.). It
runs its own microkernel‐based operating system (historically a variant of L4
called sepOS) and is used to manage and protect cryptographic keys, biometric
data, and other sensitive information. Its design isolates critical data even
if the main application processor or kernel is compromised. In short, it’s a
“trusted box” built into the hardware that handles security‑critical tasks
independently.</p>
<p><strong>Exclaves</strong>, by contrast, are a newer security innovation (first appearing in
macOS 14.4 and iOS 17) that further subdivide the operating system’s
privileges. Instead of having all sensitive operations run in the same
privileged domain as the main XNU kernel, Apple is now isolating key resources
into separate, “externally located” domains. These resources—such as Apple ID
services for virtual machines, audio buffers, sensor data, and even components
that manage indicator lights—are pre‑configured at boot and are managed by
specialized kernel extensions (e.g., ExclaveKextClient.kext,
ExclaveSEPManagerProxy.kext, and ExclavesAudioKext.kext) along with private
frameworks.</p>
<p>In geographical terms, an enclave is a territory entirely enclosed within
another, which aptly describes the Secure Enclave’s containment within the SoC.
An exclave, on the other hand, is a fragment that is separated from the main
territory yet still associated with it—mirroring how these isolated resources
exist outside the main XNU kernel while remaining tightly integrated with the
overall system. This separation means that even if the main kernel is
compromised, the operations running in exclaves remain insulated, offering
additional defense in depth.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Darwin and XNU offer a fascinating case study of an operating system that is
<em>neither fully microkernel nor monolithic</em>, but a judicious mix. Its evolution
illustrates trade-offs in OS design: performance vs. modularity, generality vs.
specialization. XNU’s Mach-based core, once considered a performance liability,
has proven to be a strength in adapting to new architectures and enabling
system-wide features (like seamless multi-OS integration on Apple Silicon, or
fine-grained sandboxing). Meanwhile, the BSD layer ensured that developers and
applications have a rich, POSIX-compliant environment, with all the expected
UNIX tools and APIs, greatly smoothing the adoption and software portability
for the platform.</p>
<p>In the modern era, as hardware trends move towards specialized processors and
increased parallelism, XNU continues to incorporate new techniques (e.g.,
dispatch queues, QoS scheduling, and direct support for machine learning
accelerators through drivers) while maintaining robustness. The Darwin OS,
through open source releases, also provides researchers a window into a
commercial-grade hybrid kernel (albeit not a very good window), inspiring
efforts in OS architecture that blend ideas from both camps of the classic
microkernel debate.</p>
<p>Apple’s Darwin has thus grown from a niche NeXTSTEP OS to the core of millions
of devices, all the while <strong>tracing a line of continuity back to Mach and
BSD</strong>. Each major transition – be it new CPU architectures (PowerPC→Intel→ARM),
new device categories, or new security paradigms – has been met by XNU with an
architectural answer: <em>extend</em> (not rewrite) the kernel, <em>integrate</em> components
tightly when needed, and <em>isolate</em> through Mach IPC when possible. This
balanced evolution of Darwin’s kernel showcases a successful long-term OS
design, one that remains at the forefront of commercial operating systems while
rooted in decades of operating systems research.</p>
<p><strong>References:</strong></p>
<ul>
<li>Singh, Amit. <em>Mac OS X Internals: A Systems Approach</em>. Addison-Wesley, 2006
(for historical and architectural insights).</li>
<li>Apple Developer Documentation – Kernel Architecture Overview (<a href="https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/Architecture/Architecture.html">Kernel
Architecture
Overview</a>).</li>
<li>Wikipedia: <em>XNU Kernel</em> (<a href="https://en.wikipedia.org/wiki/XNU">XNU -
Wikipedia</a>), <em>Darwin OS</em> release history
(<a href="https://en.wikipedia.org/wiki/Darwin_(operating_system)">Darwin (operating system) -
Wikipedia</a>).</li>
<li>Chisnall, David. “What Is Mac OS X?” InformIT (2010) (<a href="https://www.informit.com/articles/article.aspx?p=1552774">What Is Mac OS X? | A
Mach-O System |
InformIT</a>).</li>
<li>24C3: <em>Inside the Mac OS X Kernel</em> (Ilja van Sprundel, 2007) (<a href="https://fahrplan.events.ccc.de/congress/2007/Fahrplan/attachments/986_inside_the_mac_osx_kernel.pdf">Inside the Mac
OS X
Kernel</a>).</li>
<li>Mazurek, Karol. “Snake&amp;Apple X.NU” Medium (2024) (<a href="https://karol-mazurek.medium.com/snake-apple-x-nu-0bc5c36170da">Snake&amp;Apple X.NU |
Medium</a>).
(Security-focused kernel internals series).</li>
</ul>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p><a href="https://en.wikipedia.org/wiki/Return-oriented_programming">Return-oriented
programming</a> is
a computer security exploit technique that allows an attacker to execute
code in the presence of security defenses such as executable-space
protection and code signing. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://worthdoingbadly.com/hv/">Hardware-accelerated virtual machines on jailbroken iPhone 12 / iOS 14.1
| Worth Doing Badly</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section>   </article> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ten Rules for Negotiating a Job Offer (224 pts)]]></title>
            <link>https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/</link>
            <guid>43596864</guid>
            <pubDate>Sat, 05 Apr 2025 21:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/">https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/</a>, See on <a href="https://news.ycombinator.com/item?id=43596864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>When <a href="https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/">the story of how I landed a job at Airbnb</a> went viral, I was surprised at how infatuated people were with my negotiations. Media stories portrayed me as some kind of master negotiator—a wily ex-poker-player who was able to con the tech giants into a lucrative job offer.</p>

<p>This is silly. It’s silly for a lot of reasons, but one of the main ones is that in reality, my negotiation skills are nothing special. There are lots of job candidates who are better negotiators than I, to speak nothing of recruiters and other professional negotiators.</p>

<p>It just so happens that most people don’t negotiate at all, or if they do, they just negotiate just enough to satisfy themselves that they did.</p>

<p>Worse yet, most of the advice out there on negotiation is borderline useless. Almost anything you read on the subject will be a vague and long-winded exhortation to “make sure you negotiate” and “never say the first number.” Beyond those two morsels of advice, you’re pretty much on your own.</p>

<p>I thought to myself: why is there so little actionable advice out there about negotiation? I suspect it’s because deep down, many people believe that negotiation is inexplicable, that it’s something some people can do and others can’t, and that there’s no real way to break it down so anyone can learn it.</p>

<p>I say that’s bullshit. Negotiation is a skill that can be learned just like any other, and I don’t believe it’s particularly elusive or hard to understand. So I’m going to try to explain how anyone can do it.</p>

<p>Three caveats.</p>

<p>First: I’m not an expert. There are people who really are experts at this, and when my advice contradicts theirs, you should assume I’m wrong.</p>

<p>Second: negotiation is tricky to generalize about because it’s deeply intertwined with social dynamics and power. The appropriate advice for an Asian male in Silicon Valley may not be appropriate for a black woman in Birmingham, Alabama. Racial, sexual, and political dynamics accompany you to the negotiating table.</p>

<p>At the same time, I want to caution against overemphasizing these factors. Being afraid to negotiate out of fear of discrimination can often be just as deleterious as discrimination itself.</p>

<p>Ceteris paribus, negotiate aggressively.</p>

<p>Third: I’m the first to admit that negotiation is stupid. It’s a practice that inherently benefits those who are good at it, and is an absurd axis on which to reward people. But it’s a reality of our economic system. And like most collective action problems, we’re probably not going to be able to abolish it any time soon. In which case, you might as well improve at it.</p>

<p>So here’s my guide to negotiation. It’s going to be split into two parts: this first part will be about conceptualizing the negotiating process, about how to begin the process and set yourself up for maximal success. The second part will be advice on the actual back-and-forth portion of negotiating and how to ask for what you want.</p>

<p>Let’s take it from the top.</p>

<h2 id="what-it-means-to-get-a-job">What it means to “get a job”</h2>

<p>In our culture we call entering the employment market “trying to get a job.” This is an unfortunate turn of phrase. “Getting a job” implies that jobs are a resource out in the world, and you’re attempting to secure one of these resources. But that’s completely backwards. What you are actually doing is selling your labor, and a company is bidding for it.</p>

<p><strong>Employment is just striking a mutual deal in the labor market.</strong></p>

<p>Like any market, the labor market only functions well if it’s competitive. This is the only way to ensure fair and equitable pricing. Imagine you were a farmer selling watermelons. Would you just sell your watermelons to the first buyer who agreed to purchase them? Or would you survey the marketplace of buyers, see the best price (and business partner) you could get, and then make an informed decision on which buyer to sell to?</p>

<p>And yet, when people talk about the labor market, they think “oh, a company wants to <em>give me a job</em>! What a relief!” As though having a job were in itself some special privilege for which a company is the gatekeeper.</p>

<p>Dispel yourself of this mindset.</p>

<p>A job is just a deal. It is a deal between you and a company to exchange labor for money (and other things you value).</p>

<p>This might sound like an abstract point, but you should absolutely approach negotiation from this perspective.</p>

<h2 id="the-role-of-negotiation">The role of negotiation</h2>

<p>Negotiating is a natural and expected part of the process of trying to make a deal. It’s also a signal of competence and seriousness. Companies generally respect candidates who negotiate, and most highly attractive candidates negotiate (if for no other reason, because they often have too many options to choose from).</p>

<p>At the risk of spouting truisms: always, always negotiate. Doesn’t matter how good or bad you think you are. You never damage a relationship by negotiating.</p>

<p>In all my time as an instructor at App Academy, out of hundreds of offers negotiated, only once or twice were offers ever rescinded in negotiations. It basically never happens. And when it does, usually the candidate was being an unconscionable asshole, or the company was imploding and needed an excuse to rescind the offer.</p>

<p>You might think to yourself: “<em>well, I don’t want to set high expectations, and the offer is already generous, so I ought to just take it.</em>“</p>

<p><strong>No. Negotiate.</strong></p>

<p>Or maybe: “<em>I don’t want to start off on the wrong foot and look greedy with my future employer.</em>“</p>

<p><strong>No. Negotiate.</strong></p>

<p>“<em>But this company is small and—</em>“</p>

<p><strong>No. Shut up. Negotiate.</strong></p>

<p>We’ll talk more in the next section about why a lot of these objections are bullshit, and fundamentally misapprehend the dynamics of hiring. But for now, just trust me that you should always negotiate.</p>



<p>I’ve tried to boil down negotiation to ten rules. The rules, in order of appearance, are:</p>

<ol>
  <li>Get everything in writing</li>
  <li>Always keep the door open</li>
  <li>Information is power</li>
  <li>Always be positive</li>
  <li>Don’t be the decision maker</li>
  <li>Have alternatives</li>
  <li>Proclaim reasons for everything</li>
  <li>Be motivated by more than just money</li>
  <li>Understand what they value</li>
  <li>Be winnable</li>
</ol>

<p>We’ll only get through some of these in this blog post, and the rest will appear in the second part. But I’ll explain each rule as we get to it.</p>

<p>So let’s start from the top and try to walk through a negotiation process from the very beginning. For most, that starts when you receive an offer.</p>

<h2 id="the-offer-conversation">The offer conversation</h2>

<p>You’ve just received the phone call: your interview went well, and after much deliberation they decided they like you. They want to make you an offer. Congratulations!</p>

<p>Don’t get too excited though. The fun is just getting started.</p>

<p>Thank your recruiter. Sound excited—hopefully this won’t be hard. Before jumping into details, try to ask for specific feedback on your interview performance. If they give it to you, this will help you gauge how much they want you, as well as tell you things you can improve on in your next interview(s).</p>

<p>Now time to explore the offer.</p>

<p><strong>Rule #1 of negotiating: have everything in writing.</strong></p>

<p>Eventually, they’ll give you information about the offer. Write it all down. Doesn’t matter if they’re going to send you a written version later, <strong>write everything down</strong>. Even if there are things that are not directly monetary, if they relate to the job, write them down. If they tell you “we’re working on porting the front-end to Angular,” write that down. If they say they have 20 employees, write that down. You want as much information as you can. You’ll forget a lot of this stuff, and it’s going to be important in informing your final decision.</p>

<p>Depending on the company, they’ll also tell you about the equity package. We’ll look more specifically at equity in part II, but be sure to write everything down.</p>

<p>The rule from here on out is that everything significant you discuss will have some kind of a paper trail. Often, the company won’t even send you an official offer letter until a deal is finalized. So it falls to you to confirm all of the important details in subsequent e-mails.</p>

<p>So yadda yadda, lots of details, writing stuff down, oh there’s a joke, time to laugh. Now the recruiter is done talking and you’re done asking all of your questions.</p>

<p>Your recruiter will now say something along the lines of “<em>so what do you think?</em>“</p>

<p>This seems innocuous, but your reply here is critical, because there’s a lot you can say to weaken your position. This is your first decision point.</p>

<p>A decision point is a moment in the negotiation where your interlocutor wants to compel you to make a decision. If they succeed in tying you to a position, they will close the door on further negotiating. Of course “what do you think?” is a subtle prod. But it is the beginning of many attempts to get you to make a premature commitment.</p>

<p><strong>This leads to rule #2 of negotiating: always keep the door open.</strong> Never give up your negotiating power until you’re absolutely ready to make an informed, deliberate final decision.</p>

<p>This means your job is to traverse as many of these decision points as possible without giving up the power to continue negotiating. Very frequently, your interlocutor will try to trick you into making a decision, or tie you to a decision you didn’t commit to. You must keep verbally jiu-jitsu-ing out of these antics until you’re actually ready to make your final decision.</p>

<h2 id="protecting-information">Protecting information</h2>

<p>There’s an uncomfortable silence by now, and their “<em>what do you think?</em>” is hanging in the air.</p>

<p>If you say “<em>yes, that sounds amazing, when do I start?</em>” you implicitly accept the offer and completely close the door on the negotiation. This is your recruiter’s number one favorite thing to hear. It stands to reason you probably shouldn’t do this.</p>

<p>But their second favorite thing to hear you say is “<em>can you do 90K instead of 85K?</em>” This also closes the door, but for a different and more subtle reason. And it’s the number one reason why most people suck at negotiation.</p>

<p><strong>Rule #3 of negotiating: information is power.</strong> To protect your power in the negotiation, you must protect information as much as possible.</p>

<p>A company doesn’t give you insight into what it’s thinking. It doesn’t tell you its price range, how much it paid the previous candidate with your experience, or anything like that. It intentionally obfuscates those things. But it wants you not to do the same.</p>

<p>A company wants to be like a bidder in a secret auction. But unlike the other bidders, it wants to know exactly how high all of the other bids are. It then openly intends to exploit that knowledge, often by bidding one cent more than the second highest bid.</p>

<p>Yeah, no. Screw that. It’s a silent auction, and to keep it that way, you must protect information.</p>

<p>In many situations, the only reason why you have any negotiating power at all is because the employer doesn’t actually know what you’re thinking. They might not know how good your other offers are, or how much you were making in your last job, or how you weigh salary vs equity, or even how rational you are as a decision-maker. Bottom line, you want them to be uncertain on exactly what it would take to sign you.</p>

<p>When you say “<em>can you do 90K instead of 85K,</em>” you’ve told them exactly what it will take to make you sign. The sheet’s pulled back, the secret auction is up, and they’re going to bid 90K (or more likely, 87K). And they know there’s almost no risk in doing so, because you’ll probably accept.</p>

<p>What if you were the kind of person who wouldn’t even consider an offer below 110K? Or the kind of person who wouldn’t consider an offer below 120K? If you were, you wouldn’t ask for 90K, and if they offered it as conciliation, you’d tell them to stop wasting your time.</p>

<p>By staying silent, <em>they don’t actually know which of those kinds of people you are.</em> In their mind, you could be any of the three.</p>

<p>A corollary of this rule is that you should not reveal to companies what you’re currently making. There are some exceptions, but as a rule you should assume this. If you must divulge what you’re making, you should be liberal in noting the total value of your package (incorporate bonuses, unvested stock, nearness to promotion etc.), and always mention it in a context like “<em>[XYZ] is what I’m currently making, and I’m definitely looking for a step up in my career for my next role.</em>“</p>

<p>Companies will ask about your current compensation at different stages in the process—some before they ever interview you, some after they decide to make you an offer. But be mindful of this, and protect information.</p>

<p>So given this offer, don’t ask for more money or equity or anything of the sort. Don’t comment on any specific details of the offer except to clarify them.</p>

<p>Give away nothing. Retain your power.</p>

<p>Say instead: “<em>Yeah, [COMPANY_NAME] sounds great! I really thought this was a good fit, and I’m glad that you guys agree. Right now I’m talking with a few other companies so I can’t speak to the specific details of the offer until I’m done with the process and get closer to making a decision. But I’m sure we’ll be able to find a package that we’re both happy with, because I really would love to be a part of the team.</em>“</p>

<p>Think like the watermelon farmer. This offer is just is the first businessman who’s stopped by your watermelon patch, glanced over your crops, and announced “I’ll take all of these right now for $2 a melon.”</p>

<p>Cool. It’s a big market, and you’re patient—you’re a farmer after all. Just smile and tell them you’ll keep their offer in mind.</p>

<p>And this is super important: always be unequivocally positive.</p>

<h2 id="the-importance-of-positivity">The importance of positivity</h2>

<p><strong>Staying positive is rule #4 of negotiation</strong>. Even if the offer is shit, it’s extremely important to remain positive and excited about the company. This is because <em>your excitement is one of your most valuable assets in a negotiation.</em></p>

<p>A company is making you an offer because they think you’ll do hard work for them if they pay you. If you lose your excitement for the company during the interview process, then they’ll lose confidence that you’ll actually want to work hard or stay there for a long time. Each of those makes you less attractive as an investment. Remember, you are the product! If you become less excited, then the product you’re selling actually loses value.</p>

<p>Imagine you were negotiating with someone over buying your watermelons, but the negotiation took so long that by the time you’d reached an agreement, your watermelons had gone bad.</p>

<p>Companies are terrified of that. They don’t want their candidates to go bad during a negotiation. Hence why they hire professional recruiters to manage the process and make sure they remain amicable. You and the recruiter share the same interest in that regard. If a company feels like you’ve gone bad, suddenly they’re a lot less willing to pay for you.</p>

<p>So despite whatever is happening in the negotiation, give the company the impression that 1) you still like the company, and that 2) you’re still excited to work there, even if the numbers or the money or the timing is not working out. Generally the most convincing thing to signal this is to reiterate you love the mission, the team, or the problem they’re working on, and really want to see things work out.</p>

<h2 id="dont-be-the-decision-maker">Don’t be the decision-maker</h2>

<p>You can wrap up the conversation now by saying:</p>

<blockquote>
  <p>I’ll look over some of these details and discuss it with my [FAMILY/CLOSE_FRIENDS/SIGNIFICANT_OTHER]. I’ll reach out to you if I have any questions. Thanks so much for sharing the good news with me, and I’ll be in touch!</p>
</blockquote>

<p>So not only are you ending the conversation with the power all in your hands, but note there’s another important move here: you’re roping in other decision-makers.</p>

<p><strong>Rule #5 of negotiation: don’t be the decision-maker.</strong> Even if you don’t particularly care what your friends/family/husband/mother thinks, by mentioning them, you’re no longer the only person the recruiter needs to win over. There’s no point in them trying to bully and intimidate you; the “true decision-maker” is beyond their reach.</p>

<p>This is a classic technique in customer support and remediation. It’s never the person on the phone’s fault, they’re just some poor schmuck doing their job. It’s not their decision to make. This helps to defuse tension and give them more control of the situation.</p>

<p>It’s much harder to pressure someone if they’re not the final decision-maker. So take advantage of that.</p>

<p>Okay!</p>

<p>We have our first offer. Send a follow-up e-mail confirming all of the details you discussed with your recruiter so you have a paper trail. Just say “<em>just wanted to confirm I had all the details right.</em>“</p>

<p>Groovy. Next step is to leverage this to land other offers and find the best deal we can find in the job market.</p>

<h2 id="getting-other-offers">Getting other offers</h2>

<p>Turns out, it doesn’t matter that much where your first offer is from, or even how much they’re offering you. Just having an offer in hand will get the engine running.</p>

<p>If you’re already in the pipeline with other companies (which you should be if you’re doing it right), you should proactively reach out and let them know that you’ve just received an offer. Try to build a sense of urgency. Regardless of whether you know the expiration date, all offers expire at some point, so take advantage of that.</p>

<blockquote>
  <p>Hello [PERSON],</p>

  <p>I just wanted to update you on my own process. I’ve just received an offer from [COMPANY] which is quite strong. That said, I’m really excited about [YOUR AMAZING COMPANY] and really want to see if we can make it work. Since my timeline is now compressed, is there anything you can do to expedite the process?</p>
</blockquote>

<p>Should you specifically mention the company that gave you an offer? Depends. If it’s a well-known company or a competitor, then definitely mention it. If it’s a no-name or unsexy company, you should just say you received an offer. If it’s expiring soon, you should mention that as well.</p>

<p>Either way, send out a letter like this to every single company you’re talking to. No matter how hopeless or pointless you think your application is, you want to send this signal to everyone who is considering you in the market.</p>

<p>Second, if there are any other companies you are looking to apply to (whether through referral or cold application), or even companies at which you’ve already applied but haven’t heard back, I would also follow up with a similar e-mail.</p>

<p>So why do this? Isn’t this tacky, annoying, or even desperate?</p>

<p>None of the above. It is the oldest method in history to galvanize a marketplace—show that supplies are limited and build urgency. Demand breeds demand. Not every company will respond to this, but many will.</p>

<p>Isn’t it stupid that companies respond to this though?</p>

<h2 id="why-companies-care-about-other-offers">Why companies care about other offers</h2>

<p><a href="https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/">When I wrote about the story of my own job search</a>, I mentioned how having an offer from Google made companies turn around and expedite me through their funnels. Many commentators lamented at the capriciousness of these companies. If Uber or Twitch only talked to me because of Google and until then weren’t willing to look at me, what did that say about their hiring processes? What legitimately are they evaluating, if anything at all?</p>

<p>I think this response is totally backwards. The behavior of tech companies here is actually very rational, and you would do well to understand it.</p>

<p>First, you must realize what a company’s goal is. A company’s goal is to hire someone who will become an effective employee and produce more value than their cost. How do you figure out who will do that? Well, you can’t know for certain without actually hiring them, but there are a few proxies. Pedigree is the strongest signal; if they did it at other companies, they can probably do it at yours. And if someone trusted within the organization can vouch for them, that’s often a strong signal as well.</p>

<p>But turns out, almost everything else is a weak signal. Weak in the sense that it’s just not very reliable. Interviews, if you think about it, are long, sweaty, uncomfortable affairs that only glancingly resemble actual employment. They’re weird and can’t tell you that much about whether an individual will be a good at their job. There’s no way around this. There are a few stronger signals, like bringing someone in for a week or two on a contract-to-hire position, but strong candidates won’t consider this. So candidates as a whole have effectively forced companies to assume almost all of the risk in hiring.</p>

<p>The truth is, knowing that someone has passed your interview just doesn’t say <em>that much</em> about whether they’ll be a good employee. It’s as though you knew nothing about a student other than their SAT score. It’s just not a lot of data to go off.</p>

<p>Nobody has solved this problem. Not Google nor anyone else.</p>

<p>And this is precisely why it’s rational for companies to care that you’ve received other offers. They care because each company knows that their own process is noisy, and the processes of most other companies are also noisy. But a candidate having multiple offers means that they have multiple weak signals in their favor. Combined, these converge into a much stronger signal than any single interview. It’s like knowing that a student has a strong SAT score, and GPA, and won various scholarships. Sure, it’s still possible that they’re a dunce, but it’s much harder for that to be true.</p>

<p>This is not to say that companies respond proportionally to these signals, or that they don’t overvalue credentials and brands. They do. But caring about whether you have other offers and valuing you accordingly is completely rational.</p>

<p>So this is all to say—tell other companies that you’ve received offers. Give them more signal so that they know you’re a valued and compelling candidate. And understand why this changes their mind about whether to interview you.</p>

<p>As you continue interviewing, remember to keep practicing your interview skills. The single strongest determinant of your final offer will be the number and strength of offers that you receive.</p>

<h2 id="some-advice-on-timing">Some advice on timing</h2>

<p>You want to be strategic about the timing of your offers. Generally, you should try to start interviewing at larger companies earlier. Their processes are slower and their offer windows are wider (meaning they allow you more time to decide). Startups are the other way around.</p>

<p>Your goal should be to have as many offers overlapping at the same time as possible. This will maximize your window for negotiating.</p>

<p>When you receive an offer, often the first thing you should ask for is more time to make your decision. Especially in your first offer, more time is by far the most valuable thing you can ask for. It’s time that enables you to activate other companies and end up with the strongest possible offer. So be prepared to fight for time.</p>

<h2 id="how-to-approach-exploding-offers">How to approach exploding offers</h2>

<p>Hoo boy.</p>

<p>Exploding offers are offers that expire within 24-72 hours. You won’t see this much at big companies, but they’re becoming increasingly common among startups and mid-sized companies.</p>

<p>Exploding offers suck, and I share most people’s disdain for this practice. But I do understand it. Exploding offers are a natural weapon for employers to combat a strong hiring market for tech workers. Companies know exactly what they’re doing with exploding offers—they play on fear and limit your ability to seek out counteroffers.</p>

<p>In a sense, it’s unsurprising that if startups have more difficulty attracting and securing talent, they’d resort to this practice. What I don’t like is the dishonesty about it. Employers often justify this by saying “<em>If you need more time than this, then that’s a sign you’re not the kind of person we’re looking for.</em>“</p>

<p>Please don’t buy this crap or feel guilty over it. They’re simply doing this to improve their chance of closing candidates. Needing more than three days to make a life decision isn’t a sign of anything other than thoughtfulness.</p>

<p>So what should you do if you receive an exploding offer?</p>

<p>Exploding offers are anathema to your ability to effectively navigate the labor market. Thus, there is only one thing to do. Treat the offer as a non-offer unless the expiration window is widened.</p>

<p>In no uncertain terms, convey that if the offer is exploding, it’s useless to you.</p>

<p>Example conversation:</p>

<blockquote>
  <p>I have one big concern. You mentioned that this offer explodes in 48 hours. I’m afraid this doesn’t work at all for me. There’s no way that I can make a decision on this offer within a 48 hour window. I’m currently wrapping up my interview process at a few other companies, which is likely to take me another week or so. So I’m going to need more time to make an informed decision.</p>
</blockquote>

<p>If they push back and say this is the best they can do, then politely reply:</p>

<blockquote>
  <p>That’s really unfortunate. I like [YOUR COMPANY] and was really excited about the team, but like I said, there’s no way I can consider this offer. 48 hours just too unreasonable of a window. The next company I join will be a big life decision for me, and I take my commitments very seriously. I also need to consult with my [EXTERNAL_DECISION_MAKER]. There’s no way that I can make a decision I’m comfortable with in this short an amount of time.</p>
</blockquote>

<p>Pretty much any company will relent at this point. If they persist, don’t be afraid to walk away over it. (They probably won’t let that happen, and will come grab you as you’re walking out the door. But if they don’t, then honestly, screw ‘em.)</p>

<p>I was given several exploding offers during my job search. And every time, I did essentially this. Every single offer immediately widened to become more reasonable, sometimes by several weeks.</p>

<p>I want to emphasize, lest I be misunderstood here—what I’m saying is not to just silently let an exploding offer expire, and assume that everything will be fine and they’ll still hire you. They won’t. For exploding offers to be a credible weapon, a company has to have a reputation of enforcing them. I’m saying explicitly call this out as an issue when they make the offer.</p>

<p>Don’t let a company bully you into giving away your negotiating power.</p>

<h2 id="the-negotiating-mindset">The Negotiating Mindset</h2>

<p>Before we enter into the actual back-and-forth, I want to examine the mindset you should have as a negotiator. This applies not just to how you approach the conversation, but also to how you think about the company.</p>

<p>Do not fall into the trap of valuing companies solely along one dimension. That means don’t just value companies based on salary, equity, or even on prestige. Those are all important dimensions, but so are cultural fit, the challenge of the work, learning potential, later career options, quality of life, growth potential, and just overall happiness. None of these inherently trump any of the other. Anyone who tells you “just choose wherever you think you’ll be happiest” is being just as simplistic than someone who says “just choose the one that offers the most money.” All of these things matter, and your decision should be genuinely multi-dimensional.</p>

<p>Be open to being surprised as you explore different companies.</p>

<p>It’s also important to understand that companies don’t all value you along the same dimension either. That is, different companies are genuinely looking for different skills, and there are some companies at which you will be more and less valuable. Even at peer companies this is true, especially so if you have a specialized skill-set.</p>

<p>The more companies you talk to, the more likely you are to find a company to which you are significantly more valuable than the rest. Chances are this is where you’ll be able to negotiate your strongest offer. It might surprise you which company this turns out to be; keep an open mind, and remember that a job search is a 2-sided process.</p>

<p>One of the most valuable things you can do for yourself in this process is to really try to understand how employers think and what motivates them. Understanding your interlocutor is extremely important in negotiation, and we’ll be exploring that a lot in the next blog post.</p>

<p>But most of all I want to emphasize: be curious about the other side. Try to understand why employers think the way they do. Be sympathetic toward them. Care about what they want and help them try to get it. Adopting this mindset will make you a much stronger negotiator, and accordingly, a much better employee and team member.</p>

<p>Okay. That’s as far as we’re going for today. In the next blog post, I’m going to cover the last four rules of negotiation. I’ll also go over the actual back-and-forth process—how to ask for what you want, how to strengthen offers, and how to dismantle the tricks that companies will try to pull on you. Also a lot more on the theory of negotiation, which I really dig.</p>

<p>Do share this post if you found it useful! And <a href="https://twitter.com/intent/follow?original_referer=http%3A%2F%2Fhaseebq.com%2F%3Fp%3D2393%26preview%3Dtrue&amp;ref_src=twsrc%5Etfw&amp;region=follow_link&amp;screen_name=hosseeb&amp;tw_p=followbutton">follow me on Twitter</a>.</p>

<p><a href="https://haseebq.com/how-not-to-bomb-your-offer-negotiation/">You can read part 2 here!</a></p>

<p>Until next time,</p>

    <p>Haseeb</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 4 Now Live on Groq (103 pts)]]></title>
            <link>https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/</link>
            <guid>43596470</guid>
            <pubDate>Sat, 05 Apr 2025 20:13:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/">https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/</a>, See on <a href="https://news.ycombinator.com/item?id=43596470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="63e34e6" data-element_type="container" data-elementor-type="wp-post" data-elementor-id="6435" data-elementor-post-type="post" data-widget_type="theme-post-content.default">
				<div data-id="722ca0c" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Meta’s Llama 4 Scout and Maverick models are live today on GroqCloud™, giving developers and enterprises day-zero access to the most advanced open-source AI models available.<br></span></h4>								</p>
				</div>
				<div data-id="1ab7589" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Today, Meta released the first models in the Llama 4 herd, which will enable people to build more personalized multimodal experiences. With Llama 4 Scout and Llama 4 Maverick available on GroqCloud today to its free users and paid customers, developers can run cutting-edge multimodal workloads while keeping costs low and latency predictable.</p>
				</div>
				
				<div data-id="345d7c5" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Groq Performance &amp; Pricing<br></span></h4>								</p>
				</div>
				<div data-id="3568efc" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span>Our vertically integrated GroqCloud and inference-first architecture deliver unmatched performance and price. With Llama 4 models, developers can run cutting-edge multimodal workloads while keeping costs low and latency predictable.</span></p>
<p><span>Llama 4 Scout is currently running at over 460</span><span>&nbsp;tokens/s</span><span> while Llama 4 Maverick is coming today</span><span>.&nbsp;</span><span>Stay tuned for official 3rd party benchmarks from Artificial Analysis.&nbsp;</span></p>
<p><span>Groq is offering the first of the Llama 4 model herd at the following pricing:</span></p>								</div>
				<div data-id="355d301" data-element_type="widget" data-widget_type="text-editor.default">
									<ul><li aria-level="1"><b>Llama 4 Scout: </b><span>$0.11 / M input tokens and $0.34 / M output tokens</span></li><li aria-level="1"><strong>Llama 4 Maverick:</strong> $0.50 / M input tokens and $0.77 / M output tokens</li></ul>								</div>
				
				<div data-id="1ee4919" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>About Llama 4 <br></span></h4>								</p>
				</div>
				<div data-id="f519fef" data-element_type="widget" data-widget_type="text-editor.default">
				<p>The new Llama 4 models are Meta’s first models that use a Mixture of Experts (MoE) architecture. In MoE models, a single token activates only a fraction of the total parameters. MoE architectures are more compute efficient for model training and inference and, given a fixed training FLOPs budget, deliver higher quality models compared to dense architectures.<br>Llama 4 models are designed with native multimodality, incorporating early fusion to seamlessly integrate text and vision tokens into a unified model backbone. <br>Meta aims to develop the most helpful, useful models for developers while protecting against and mitigating the most severe risks. This includes integrating mitigations at each layer of model development from pre-training to post training and tunable system-level mitigations that shield developers from adversarial users. In doing so, Meta is helping empower developers to create helpful, safe, and adaptable experiences for their Llama supported applications.</p>
				</div>
				
				<div data-id="e9fc04b" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Llama 4 Scout &amp; Maverick<br></span></h4>								</p>
				</div>
				<div data-id="9a49798" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span>These latest Llama models from Meta include smaller and larger options to accommodate a range of use cases and developer needs.</span></p><p><span>Llama 4 Scout is a leading multimodal model and is more powerful than the Llama 3 models. It contains 17 billion active parameters, 16 experts, and 109 billion total parameters; it delivers state-of-the-art performance for its class.&nbsp;</span></p><p><span>Llama 4 Maverick contains 17 billion active parameters, 128 experts, and 400 billion total parameters, offering high quality at a lower price compared to Llama 3.3 70B. It offers unparalleled, industry-leading performance in image and text understanding with support for 12 languages, enabling the creation of sophisticated AI applications that bridge language barriers. As the workhorse model for general assistant and chat use cases, Llama 4 Maverick is great for precise image understanding and creative writing. For developers, it offers state-of-the-art intelligence with high speed, optimized for best response quality on tone, and refusals.</span></p>								</div>
				
				<div data-id="531d7d8" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Build Fast with Llama 4 on GroqCloud<br></span></h4>								</p>
				</div>
				
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama4 (882 pts)]]></title>
            <link>https://www.llama.com/llama4/</link>
            <guid>43595585</guid>
            <pubDate>Sat, 05 Apr 2025 18:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.llama.com/llama4/">https://www.llama.com/llama4/</a>, See on <a href="https://news.ycombinator.com/item?id=43595585">Hacker News</a></p>
Couldn't get https://www.llama.com/llama4/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: iPhone 2005 weird "Blob Keyboard" simulator (109 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43595442</link>
            <guid>43595442</guid>
            <pubDate>Sat, 05 Apr 2025 18:20:49 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43595442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="43595442">
      <td><span></span></td>      <td><center><a id="up_43595442" href="https://news.ycombinator.com/vote?id=43595442&amp;how=up&amp;goto=item%3Fid%3D43595442"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=43595442">Show HN: iPhone 2005 weird "Blob Keyboard" simulator</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_43595442">101 points</span> by <a href="https://news.ycombinator.com/user?id=juliendorra">juliendorra</a> <span title="2025-04-05T18:20:49 1743877249"><a href="https://news.ycombinator.com/item?id=43595442">8 hours ago</a></span> <span id="unv_43595442"></span> | <a href="https://news.ycombinator.com/hide?id=43595442&amp;goto=item%3Fid%3D43595442">hide</a> | <a href="https://hn.algolia.com/?query=Show%20HN%3A%20iPhone%202005%20weird%20%22Blob%20Keyboard%22%20simulator&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=43595442&amp;auth=73eff720157eb1fabbb5a96d6d3aa1dc7ef9a0e8">favorite</a> | <a href="https://news.ycombinator.com/item?id=43595442">34&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hi HN,</p><p>I teach tech design history, and one of the key stories I cover is the development of the original iPhone keyboard by Ken Kocienda. Reading about it in his book "Creative Selection" is great, but I wanted my students (and now you!) to actually <i>feel</i> this step in the process.</p><p>So, I built a web simulator of the "Blob Keyboard", Kocienda's very first attempt at a touchscreen keyboard that actually works, from September 2005:</p><p>Try the Blob Keyboard: <a href="https://juliendorra.github.io/blob-keyboard-simulator/blob-keyboard-simulator.html" rel="nofollow">https://juliendorra.github.io/blob-keyboard-simulator/blob-k...</a></p><p>- Tap for the middle letter</p><p>- Swipe left or right for the side letters</p><p>More on the github repo: <a href="https://github.com/juliendorra/blob-keyboard-simulator">https://github.com/juliendorra/blob-keyboard-simulator</a></p><p>The Blob Keyboard prototype emerged during a UX crisis for iPhone team (their software keyboard just didn't work at all, fingers being too big, and the Newton failure loomed over them), highlighting how innovation is rarely a straight path. It was developed on a tethered touchscreen display codenamed "Wallaby".</p><p>To make this simulator as authentic as possible, I referenced images from Kocienda's book and even got direct feedback and guidance from Ken Kocienda himself on Bluesky.</p><p>What to expect (or… what not to expect):</p><p>This is a reconstruction of a very early prototype with limitations reflecting that specific moment. The goal was to test first if typing with accuracy was even possible, as all the rest was moot if it failed!</p><p>It's NOT QWERTY: They were still hoping to get us out of QWERTY, but then familiarity won.</p><p>No Backspace: You can't delete.</p><p>No Cursor Movement: The text field is just a simple display.</p><p>No Caps or Numbers: Only lowercase letters.</p><p>No Smooth Animations: Keys just "pop" instantly when pressed. Kocienda noted that your eye fills in the gaps, giving a sense of movement.</p><p>Best Experience:</p><p>While it works with a mouse/trackpad on desktop, it's designed for touchscreens to better replicate the original Wallaby hardware interaction. Use it on your phone!</p><p>This project aims to provide a tangible glimpse into a turning point moment in iPhone development and the iterative nature of design. It's like stepping back in time and trying out that early demo on Kocienda's desk.</p><p>I would love to hear your reactions and thoughts on experiencing this piece of UI history! What other significant prototype do you wish you could experience?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Faster interpreters in Go: Catching up with C++ (120 pts)]]></title>
            <link>https://planetscale.com/blog/faster-interpreters-in-go-catching-up-with-cpp</link>
            <guid>43595283</guid>
            <pubDate>Sat, 05 Apr 2025 17:59:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://planetscale.com/blog/faster-interpreters-in-go-catching-up-with-cpp">https://planetscale.com/blog/faster-interpreters-in-go-catching-up-with-cpp</a>, See on <a href="https://news.ycombinator.com/item?id=43595283">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>By <!-- -->Vicent Martí<!-- --> | <time datetime="2025-03-20">March 20, 2025</time></p><p>The SQL evaluation engine that ships with Vitess, <a href="https://github.com/vitessio/vitess">the open-source database that powers PlanetScale</a>, was originally implemented as an AST evaluator that used to operate directly on the SQL AST generated by our parser. Over this past year, we've gradually replaced it with a Virtual Machine which, despite being written natively in Go, performs similarly to the original C++ evaluation code in MySQL. Most remarkably, the new Virtual Machine has repeatedly proven itself easier to maintain than the original Go interpreter, even though it's orders of magnitude faster. Let's review the implementation choices we've made to get these surprising results.</p><h2 id="whats-a-sql-evaluation-engine"><a href="#whats-a-sql-evaluation-engine">What's a SQL evaluation engine?</a></h2><p>Vitess has been designed for unlimited horizontal scaling. To accomplish this, all queries to a Vitess cluster must go through a <code>vtgate</code>. Since you can deploy as many <code>vtgate</code> instances as you want, because they’re essentially stateless, this allows you to grow the capacity of your cluster linearly.  The job of each gate is the most complex part of the whole distributed system. It parses the SQL of the incoming queries and creates a shard-aware query plan, which we evaluate in one or many of the shards of the cluster. Then, we aggregate the results of these evaluations, and return them to the user.</p><p>One of the reasons why Vitess works so well in practice (in both performance and in ease of adoption) is that every shard in a cluster is backed by a real MySQL instance. Even the more complex SQL queries can be decomposed into simpler statements that are evaluated in the underlying MySQL database. Hence, the results of these queries always match what you’d expect from querying MySQL directly.</p><p>However, SQL queries in the real world can get <em>really wild</em>. We need to support pretty much every kind of query that a normal MySQL instance supports, but we need to evaluate it across several MySQL instances. This means that sometimes, we don’t get to fall back to MySQL to evaluate all our SQL expressions.</p><p>Think of a rather simple query such as this:</p><pre data-language="sql">SELECT inventory.item_id, SUM(inventory.count), AVG(inventory.price) AS avg_price
FROM inventory
WHERE inventory.state = 'available' AND inventory.warehouse IN ? 
GROUP BY inventory.item_id
HAVING  avg_price &gt; 100;
</pre><p>Assuming this query is executed in a sharded Vitess cluster, the inventoried items can exist in any of the shards. Hence, our query planner will prepare a plan that queries all shards in parallel, <a href="https://planetscale.com/blog/grouping-and-aggregations-on-vitess">pushing down part of the aggregation to MySQL</a>, and then we'll perform the aggregations (<code>SUM</code> and <code>AVG</code>) locally in the <code>vtgate</code>. The <code>state</code> and <code>warehouse</code> checks in the <code>WHERE</code> clause can and will be executed directly on the MySQL instance that powers each shard. But the last expression, <code>avg_price &gt; 100</code>, applies to the result of the aggregation, which is only available inside Vitess. This is where the Vitess evaluation engine comes in.</p><p>Our evaluation engine is an interpreter that supports the majority of the scalar expressions in the SQL dialect used by MySQL. This does not include high level constructs such as performing a <code>JOIN</code>,  the grouping of a <code>GROUP BY</code>, etc (these are performed directly by the planner, as we’ve seen), but the actual sub-expressions that you’d see as the condition of a <code>WHERE</code> clause, or a <code>GROUP BY</code> clause. Any piece of SQL that cannot be lowered to be executed in MySQL by the planner is evaluated locally in Go by the engine.</p><p>Of course, these SQL sub-expressions are not arbitrarily complex. They are not even Turing complete (as they cannot loop!), so you may think that a statement like <code>avg_price &gt; ?</code> would be trivial to evaluate, but as in most engineering problems, there’s a wealth of nuance when doing these things in the real world.</p><p>SQL is an incredibly dynamic language full of quirks, and the SQL in MySQL, doubly so. We have spent an inordinate amount of time getting every single corner case of SQL evaluation to match exactly MySQL’s behavior. In fact, our <a href="https://github.com/vitessio/vitess/blob/main/go/vt/vtgate/evalengine/testcases/cases.go">test</a> <a href="https://github.com/vitessio/vitess/blob/main/go/vt/vtgate/evalengine/testcases/inputs.go">suite</a> and <a href="https://github.com/vitessio/vitess/tree/main/go/vt/vtgate/evalengine/integration">fuzzer</a> are so comprehensive that we routinely find bugs in the original MySQL evaluation engine, which we have to fix upstream (<a href="https://github.com/mysql/mysql-server/pull/602">like this collation bug</a>, <a href="https://github.com/mysql/mysql-server/pull/517">this issue in the <code>insert</code> SQL function</a> or <a href="https://github.com/mysql/mysql-server/pull/515">this bug when searching substrings</a>). Nonetheless, being fully accurate is not enough. For most queries, these expressions are evaluated once or even more than once <em>for every returned row</em>, so in order to not introduce additional overhead, evaluation needs to be as quick as possible.</p><p>As discussed earlier, the first version of the evaluation engine in Vitess was an AST-based interpreter, operating directly on top of the SQL AST generated by our parser. This was a very straightforward design that allowed us to focus on <em>accuracy</em>, at the expense of performance. Let's discuss our new design for replacing this interpreter with a fully fledged virtual machine which is both faster and easier to maintain. Starting with the basics.</p><h2 id="the-shapes-of-an-interpreter"><a href="#the-shapes-of-an-interpreter">The shapes of an interpreter</a></h2><p>For those new to programming language implementations, there are roughly 3 ways to execute a <em>dynamic</em> language at runtime. In increasing level of complexity <em>and</em> performance:</p><ol><li>An AST-based interpreter, where the syntax of the language is parsed into an AST and evaluation is performed by recursively walking each node of the AST and computing the results. <em>(this is the way the <code>evalengine</code> in Vitess used to work!)</em></li><li>A bytecode VM, where the AST is compiled into binary bytecode that can be evaluated by a virtual machine — a piece of code that simulates a CPU, but with higher-level instructions. <em>(this is what we've recently shipped!)</em></li><li>A JIT compiler, in which the bytecode is compiled directly into the host platform's native instructions, so it can be executed directly by the CPU without being interpreted by a Virtual Machine. <em>(we'll talk about this later!)</em></li></ol><p>The first thing to consider here is whether the upgrade from an AST interpreter to a virtual machine makes sense from a performance point of view. Here’s an intuition: SQL expressions are incredibly dynamic (when it comes to typing), very high level (when it comes to each primitive operation), and with very little control flow (when it comes to evaluation -- SQL expressions don't really loop, and conditionals are rare; their flow is always lineal!). This can lead us to believe that there's no performance to be squeezed from translating the AST-based evaluation engine into bytecode. The AST is already well suited for high level operations and type-switching!</p><p>This is only <em>superficially</em> true. Lots of programming languages are highly dynamic and they manage to run in bytecode VMs much more efficiently than with an AST interpreter. A clear example of this is the now ancient transition that Ruby did from its original AST interpreter in MRI to YARV, a bytecode VM. Python also did a similar switch very early on. And you can bet that literally no JavaScript engines are using AST evaluation: even though the goal of these engines is to start running JS as soon as possible, they still compile to (very efficient) bytecode interpreters before JIT compilation kicks in.</p><p>So where’s the advantage of a virtual machine versus an AST interpreter? A lot of it boils down to instruction dispatching, which can be made very fast (more on this later!). But it is true that for SQL expressions, we’re actually going to execute very few instructions. Hence, to squeeze performance out of the VM, we’re going to have to come up with new tricks.</p><p>The initial approach I had in mind for our SQL virtual machine was based on <a href="https://publications.sba-research.org/publications/dls10.pdf">Efficient Interpretation using Quickening</a> by Stefan Brunthaler. The idea behind this paper is that dynamic programming languages are very hard to execute efficiently because of the lack of information about types. A simple expression such as <code>a + 1</code> must be interpreted in a completely different way depending on whether <code>a</code> is an integer, a floating point number of even a string. To optimize these operations in practice, the paper suggests rewriting the bytecode from more generic instructions (e.g. the sum operator that needs to figure out the types of the two operands to know how to sum them) into specific static instructions which are specialized for the types they operate on at runtime (e.g. the sum operator that knows that both operands are integers and can sum them right away).</p><p>To do that, a quickening VM needs to figure out <em>at runtime</em> the types of the expressions being evaluated and incrementally rewrite the bytecode into instructions that operate on them. This is very hard to do in practice! But after implementing a good chunk of specialized instructions for the different types of operators in SQL and attempting to runtime rewrite them, I noticed an opportunity to take the idea even further by making it more efficient and, crucially, simpler.</p><p>It turns out that the semantic analysis we perform in Vitess is advanced enough that, through careful integration with the upstream MySQL server and its information schema, it can be used to <em>statically type the AST of the SQL expressions we were executing</em>. This took a lot of effort to implement, but resulted in a big win: since the planner knows the types of the actual inputs that will be used to evaluate each SQL expression, we can derive from those the types of all sub-expressions at compilation time, resulting in byte-code that is already specialized without requiring runtime rewriting.</p><p>Now we just need to implement a Virtual Machine to efficiently interpret the specialized bytecode!</p><h2 id="an-efficient-virtual-machine-in-go"><a href="#an-efficient-virtual-machine-in-go">An efficient Virtual Machine in Go</a></h2><p>Implementing a VM usually involves a lot of complexity. As we’ve explained, you have to write a compiler that processes the input expression AST and generates the corresponding binary instructions (you have to come up with an encoding even!) and <em>afterwards</em> you have to implement the actual VM, which decodes each instruction and performs the corresponding operation. And you have to constantly keep these in sync! Any mismatches between the compiler that emits the bytecode and the VM that executes it are often catastrophic and very hard to debug.</p><p>Historically, a bytecode VM has always been implemented the same way: a big-ass switch statement. You decode an instruction, and switch on its type to jump to the operation that needs to be performed. This is often a performance advantage against AST interpreters, because switching in practice is quite fast (particularly when implemented in C or C++ like most VMs are), and allows execution to happen linearly, without recursion.</p><p>This design, however, also has its fair share of shortcomings. Mike Pall, JIT-master extraordinaire and author of LuaJIT, gives a very insightful rundown of these issues on <a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html">this mailing list post from 2011</a>. Allow me to summarize for this blog: Besides the fact that the VM's instructions need to be kept in-sync with the compiler, the actual performance of the main VM loop in a language with many instructions is not great in practice because compilers usually struggle when compiling massive functions, and these functions <em>are</em> massive. They spill registers all over the place on each branch of the switch, because it's hard to tell which branches are hot and which ones are cold. With all the pushing and popping, the jump into the switch's branch often looks more like a function call, so a lot of the performance benefits of the virtual machine dissipate.</p><p>Mike was discussing C compilers in that post, but it's safe to assume that these problems are the same for a virtual machine implemented in Go. After a lot of testing, I can assure you that they are actually <em>much worse</em> because the Go compiler is not great at optimization. There’s always a trade-off between optimization and fast compile times, and the Go authors have historically opted for the latter.</p><p>One key issue for Go is that often the different branches of the switch statement are jumped to via <em>binary search</em> instead of a jump table. Switch jump table optimization was <a href="https://go-review.googlesource.com/c/go/+/357330">implemented surprisingly late on the compiler</a>, and in practice it is <em>very fiddly</em>, without any way to enforce it. You have to tweak the way the VM's instructions are encoded carefully to ensure that you're jumping in the VM's main loop, and you have no way to reliably check whether your virtual machine’s dispatch code has been properly optimized besides reviewing the generated assembly yourself.</p><p>Clearly, switch-based VM loops are not the state of the art for writing efficient interpreters, neither in Go nor in any other programming language. So what <em>is</em> the state of the art then? Well, when it comes to Go it turns out that there's nobody doing fast interpreters right now (at least nobody I can find). The people who are doing interesting work here, such as the <a href="https://github.com/tetratelabs/wazero"><code>wazero</code> WASM implementation</a> are focusing their performance efforts on JIT. So we’re going to have to innovate!</p><p>Outside of Go, the most interesting approach for interpreters implemented in C or C++ is <strong>continuation-style evaluation loops</strong>, as seen <a href="https://blog.reverberate.org/2021/04/21/musttail-efficient-interpreters.html">in this report from 2021 that implements this technique for parsing Protocol Buffers</a>. This involves implementing all the opcodes for the VM as freestanding functions that operate on the VM as an argument, with the return of the function being <em>a callback to the next step of the computation</em>. It does sound like something expensive and, huh, recursive, but the trick is that newer versions of LLVM allow us to mark functions as <em>forcefully</em> tail-called (see: https://en.wikipedia.org/wiki/Tail_call), so the resulting code is not recursively calling the VM loop but instead <em>jumping</em> between the operations and using the free-standing functions as an abstraction to control register placement and spillage. The most recent release of Python 3.14 actually <a href="https://docs.python.org/3.14/whatsnew/3.14.html#whatsnew314-tail-call">ships an interpreter based on this design</a>, boasting up to 30% improvement when executing Python code.</p><p>Unfortunately, this is not something we can do in Go because as we discussed earlier, the Go compiler is allergic to optimization. It <em>can</em> sometimes emit tail calls, but it needs to be tickled in just the right way, and this implementation simply does not work in practice unless the tail-calls are guaranteed at compilation time. But what if we keep the same design with free-standing functions for each instruction and instead of tail-calling, we forcefully return control to the evaluation loop after each one? This could be implemented very easily by not emitting our compiled program as “byte code”, but instead emitting <strong>a slice of function pointers to each instruction</strong>. The design may be a bit counter-intuitive, but it has a lot of very interesting properties.</p><p>First, the VM becomes trivial! It's just a few lines of code, and it doesn't have to worry about optimizing any large switch statements. It's just repeatedly calling functions one after the other! Here’s a simplified example, but if you check <a href="https://github.com/vitessio/vitess/blob/b05df12741adf1314839694e489e687e7ec6c6ea/go/vt/vtgate/evalengine/vm.go#L73-L98">the actual implementation in Vitess</a> you’ll see that a real virtual machine implementation is hardly more complicated than this.</p><pre data-language="go">func (vm *VirtualMachine) execute(p *Program) (eval, error) {
	code := p.code
	ip := 0

	for ip &lt; len(code) {
		ip += code[ip](vm)
		if vm.err != nil {
			return nil, vm.err
		}
	}
	if vm.sp == 0 {
		return nil, nil
	}
	return vm.stack[vm.sp-1], nil
}
</pre><p>All we need to return when executing each instruction is the offset for the instruction pointer <code>ip</code>. Most functions return <code>1</code>, which causes the next instruction to be executed, but by returning negative or positive values, you can implement all control flow, including loops and conditionals.</p><p>Besides the greatly simplified virtual machine, the second advantage of this approach is that the compiler <em>also</em> becomes trivial, because there is no bytecode! Instead, the compiler emits the individual instructions directly by pushing "callbacks" into a slice. There are no instruction opcodes to keep track off, no encoding to perform and nothing to keep in sync with the VM. <strong>Developing the compiler means developing the VM simultaneously</strong>, which greatly improves iteration speed and prevents a whole class of bugs that happen often when developing virtual machines.</p><pre data-language="go">func (c *compiler) emitPushNull() {
	c.emit(func(vm *VirtualMachine) int {
		vm.stack[vm.sp] = nil
		vm.sp++
		return 1
	})
}
</pre><p>As you may notice, there’s a bit of a hiccup here when it comes to modeling the instructions for a non-trivial language: if there's no instruction encoding, then we cannot have instructions with arguments.</p><p>This is a big problem in a language like C (traditionally used to implement most programming language interpreters), which is why this technique is never seen there. But it’s actually not a problem for us,  because the Go compiler actually supports <em>closures</em>! We can emit any instruction we want and the Go compiler will automatically capture its arguments inside the callback. We don't have to think about how to encode our arguments in the bytecode, and in fact, our arguments can be as complex as they need to be: the resulting callback will contain a copy of them created by the Go compiler. It's essentially a poor man's JIT, aided by the compiler, and it works amazingly well in practice, both performance-wise and for ergonomics.</p><p>Check out this compiler method that generates an instruction to push a <code>TEXT</code> SQL object from the input rows into the stack:</p><pre data-language="go">func (c *compiler) emitPushColumn_text(offset int, col collations.TypedCollation) {
	c.emit(func(vm *VirtualMachine) int {
		vm.stack[vm.sp] = newEvalText(vm.row[offset].Raw(), col)
		vm.sp++
		return 1
	})
}
</pre><p>Both the offset in the input <code>rows</code> array <em>and</em> the collation for the text are statically baked into the generated instruction!</p><h2 id="almost-statically-typed"><a href="#almost-statically-typed">Almost statically typed</a></h2><p>With the fully static typing for SQL expressions (derived from the type information in the planner) we get to design an extremely efficient virtual machine where every single instruction is specialized for the type of the operands it executes on. This is both the optimal and the simplest design for a VM because we never have to do type switching during evaluation. But we’re dealing with SQL here (or, more accurately, the SQL dialect of MySQL), so not everything is rainbows and unicorns. Very often it’s quite the opposite.</p><p>Let’s consider this wildly complex SQL expression: <code>-inventory.price</code>. That is, the negation of each of the values in the <code>inventory.price</code> column of our query. We know (thanks to our semantic analysis, and the schema tracker) that the type of the <code>inventory.price</code> column is <code>BIGINT</code>. So what could be the type of <code>-inventory.price</code>? Naive readers without experience in the magical world of SQL may believe the resulting type is <code>BIGINT</code>, but that’s not the case in practice!</p><p>The vast majority of the time, the negation of a <code>BIGINT</code> yields indeed another <code>BIGINT</code> value. But when the actual value of the <code>BIGINT</code> is -9223372036854775808 (i.e. the smallest value that can be represented in 64 bits), negating it promotes the value into a <code>DECIMAL</code>, instead of silently truncating it, or returning an error. You can see how this can easily throw a wrench in our statically compiled instructions for our virtual machine. Suddenly the static type checking we’ve computed is no longer valid because the types of the expression no longer depend on the types of the inputs, but on the actual <em>values</em> of the inputs. In order to continue evaluating the result of this negation, we’d always have to type-check again at runtime, defeating the whole point of static typing to begin with.</p><p>To work around this issue, we’re <em>not</em> introducing more type switches at runtime. We’re using a classic trick which can be seen all the time in JIT compiled code and very rarely, if ever, in virtual machines: <strong>de-optimization</strong>. There’s a small list of expressions where corner cases (e.g. overflow) can result in dynamic typing at runtime. Whenever this happens, we simply bail out of executing in our virtual machine and fall back to executing on the old AST evaluator, which has always performed type switching at runtime. This is very similar to what JIT compilers do when they detect that the runtime type of a value no longer matches the generated code they’ve emitted; they fall back from the native code to the virtual machine. In our case, we’re one step behind, falling back from the virtual machine to the AST interpreter, but the performance implications are the same. This design allows us to keep our interpreter executing statically typed code without any type switches at runtime. Here's an example of what integer negation looks like when compiled:</p><pre data-language="go">func (c *compiler) emitNeg_i() {
	c.emit(func(vm *VirtualMachine) int {
		arg := vm.stack[env.vm.sp-1].(*evalInt64)
		if arg.i == math.MinInt64 {
			vm.err = errDeoptimize
		} else {
			arg.i = -arg.i
		}
		return 1
	})
}
</pre><p>There is one significant drawback with this approach, however: the code for the AST interpreter can never be removed from Vitess. But this is, overall, not a bad thing. Just like most advanced language runtimes keep their virtual machine interpreter despite having a JIT compiler, having access to our classic AST interpreter gives us versatility. It can be used when we detect that an expression will be evaluated just <em>once</em> (e.g. when we use the evaluation engine to perform constant folding on a SQL expression). In those cases, the overhead of compiling and then executing on the VM trumps a single-pass evaluation on the AST. Lastly, when it comes to accuracy, being able to fuzz both the AST interpreter and the VM against each other has resulted in an invaluable tool for detecting bugs and corner cases.</p><h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2><p>This technique for virtual machine implementation is not fully novel (I’ve seen it used before for a rules-based authorization engine in the wild!), but as far as I can tell it has never been used in Go. Given the constraints of the language and the compiler, the technique yields spectacular results: the new SQL interpreter in Vitess is just <em>faster</em>. Faster to write, faster to maintain and faster to execute. The benchmarks speak for themselves:</p><h3 id="evalengine-performance-in-vitess-over-time"><a href="#evalengine-performance-in-vitess-over-time">Evalengine performance in Vitess over time</a></h3><p><picture><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-D588Aj2C.png?auto=compress%2Cformat" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-darkmode-BmvxW3Md.png?auto=compress%2Cformat" media="(prefers-color-scheme: dark)"><img alt="Benchmark results" height="1295" loading="lazy" src="https://planetscale-images.imgix.net/assets/benchmark-results-D588Aj2C.png?auto=compress%2Cformat" width="2361"></picture></p><p>Here we have a performance comparison of 5 different queries (ranging from very complex to very simple) between three implementations:</p><ol><li><strong>old</strong>, which is the original AST-based dynamic implementation of the <code>evalengine</code>.</li><li><strong>ast</strong>, which is the result of adding static type checking to the virtual machine and using them to partially optimize the AST evaluator.</li><li><strong>vm</strong>, which is the callback-based virtual machine implementation as discussed in this post.</li></ol><h3 id="recent-results-compared-with-mysql"><a href="#recent-results-compared-with-mysql">Recent results compared with MySQL</a></h3><p><picture><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-with-mysql-CvMaQMIM.png?auto=compress%2Cformat" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><source srcset="https://planetscale-images.imgix.net/assets/benchmark-results-with-mysql-darkmode-CDCX_2gs.png?auto=compress%2Cformat" media="(prefers-color-scheme: dark)"><img alt="Benchmark results With MySQL" height="1295" loading="lazy" src="https://planetscale-images.imgix.net/assets/benchmark-results-with-mysql-CvMaQMIM.png?auto=compress%2Cformat" width="2361"></picture></p><p>This is the current performance of our evaluation engine pitted against the native C++ implementation in MySQL. Note that measuring the time that MySQL spends in evaluation is very tricky; these are not the total reponse times for a query, but the result of manual instrumentation in the <code>mysqld</code> server to ensure a fair comparison.</p><details><summary>Raw benchmark data</summary><div><pre>                                      │     ast      │                 vm                  │                  mysql                   │
                                      │    sec/op    │   sec/op     vs base                │    sec/op     vs base                    │
CompilerExpressions/complex_arith-32    162.75n ± 1%   50.77n ± 1%  -68.81% (p=0.000 n=10)   49.40n ±  5%  -69.64% (p=0.000 n=10+184)
CompilerExpressions/comparison_i64-32    30.30n ± 2%   16.95n ± 1%  -44.08% (p=0.000 n=10)   26.93n ± 22%  -11.12% (p=0.000 n=10+11)
CompilerExpressions/comparison_u64-32    30.57n ± 3%   17.49n ± 1%  -42.78% (p=0.000 n=10)   18.80n ±  9%  -38.53% (p=0.000 n=10+16)
CompilerExpressions/comparison_dec-32    70.75n ± 1%   52.58n ± 2%  -25.68% (p=0.000 n=10)   46.59n ±  5%  -34.14% (p=0.000 n=10+14)
CompilerExpressions/comparison_f-32      53.05n ± 1%   25.65n ± 1%  -51.64% (p=0.000 n=10)   27.75n ± 23%  -47.69% (p=0.000 n=10)
geomean                                  56.30n        28.94n       -48.60%                  31.76n        -43.58%

                                      │    ast     │                   vm                    │
                                      │    B/op    │    B/op     vs base                     │
CompilerExpressions/complex_arith-32    96.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_i64-32   16.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_u64-32   16.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_dec-32   64.00 ± 0%   40.00 ± 0%   -37.50% (p=0.000 n=10)
CompilerExpressions/comparison_f-32     16.00 ± 0%    0.00 ± 0%  -100.00% (p=0.000 n=10)

                                      │    ast     │                   vm                    │
                                      │ allocs/op  │ allocs/op   vs base                     │
CompilerExpressions/complex_arith-32    9.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_i64-32   1.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_u64-32   1.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
CompilerExpressions/comparison_dec-32   3.000 ± 0%   2.000 ± 0%   -33.33% (p=0.000 n=10)
CompilerExpressions/comparison_f-32     2.000 ± 0%   0.000 ± 0%  -100.00% (p=0.000 n=10)
</pre></div></details><p>The results are stark: the pre-compiled SQL expressions when ran in the new VM are up to 20x times faster than the first implementation of SQL evaluation in Vitess, and for most cases, we've caught up with the performance of the C++ implementation in MySQL. One further detail which is not shown on the graphs, but can be seen on the raw benchmark data, is that the new virtual machine <strong>does not allocate memory</strong> to perform evaluation — a very nice side effect of the fully specialized instructions thanks to the static type checking.</p><p>Overall, we consider getting in the same performance ballpark as MySQL's C++ evaluation engine as a huge engineering success, particularly when the resulting implementation is so easy to maintain.<!-- --> <!-- -->There will always be a performance gap between Go and C++, arising from the trade-off of quality vs compilation speed in the Go compiler, and from the semantics of the language itself, but as we show here, this gap is not insurmountable. With expertise and careful design, it is possible to reap the many benefits of developing and deploying Go services without paying the performance penalty inherent in the language. In this specific case, we got there by having the capacity to perform semantic analysis and statically typing SQL expressions (something which MySQL does not do), and by choosing an efficient virtual machine design that uses the strengths of Go instead of fighting its limitations.</p><h3 id="addendum-so-why-not-jit"><a href="#addendum-so-why-not-jit">Addendum: So why not JIT?</a></h3><p>Inquiring minds may be wondering: what's next? Are we doing JIT compilation next? The answer is no. Although this design for a compiler and VM looks like an exceptional starting point for implementing a full JIT compiler <em>in theory</em>, in practice the trade-off between optimization and complexity doesn't make sense. JIT compilers are important for programming languages where their bytecode operations can be optimized into a very low level of abstraction (e.g. where an "add" operator only has to perform a native x64 <code>ADD</code>). In these cases, the overhead of dispatching instructions becomes so dominant that replacing the VM's loop with a block of JITted code makes a significant performance difference. However, for SQL expressions, and even after our specialization pass, most of the operations remain extremely high level (things like "match this JSON object with a path" or "add two fixed-width decimals together"). The overhead of instruction dispatch, as measured in our benchmarks, is less than 20% (and can possibly be optimized further in the VM's loop). 20% is not the number you're targetting before you start messing around with raw assembly for a JIT. So at this point my intuition is that JIT compilation would be a needlessly complex dead optimization.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What If We Made Advertising Illegal? (815 pts)]]></title>
            <link>https://simone.org/advertising/</link>
            <guid>43595269</guid>
            <pubDate>Sat, 05 Apr 2025 17:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simone.org/advertising/">https://simone.org/advertising/</a>, See on <a href="https://news.ycombinator.com/item?id=43595269">Hacker News</a></p>
Couldn't get https://simone.org/advertising/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Exeter's unassuming co-op worker leads double life as 'Lord of the Logos' (114 pts)]]></title>
            <link>https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941</link>
            <guid>43594396</guid>
            <pubDate>Sat, 05 Apr 2025 15:54:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941">https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941</a>, See on <a href="https://news.ycombinator.com/item?id=43594396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><!-- Article Start--><p>The famous saying 'never judge a book by its cover' couldn't be more fitting for part-time Exeter Co-op worker <a data-content-type="news" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/news/devon-news/meet-christophe-szpajdel-exeter-co-410444" rel="Follow" target="_self">Christophe Szpajdel.</a> Behind the nondescript uniform and happy and warm welcoming smile lies a hidden talent that has seen the 54-year-old award-winning artist produce outstanding work for the likes of pop star Rihanna alongside renowned names in the world of the heavy metal scene, as well as fashion and films.</p> <p>The common thread between them all is striking logos which Belgium-born Christophe produces using the old school method of just a piece of paper and a pencil. You'll be more likely to find him sitting in the outdoors as that's where he feels most at ease and creative.</p> <p>My first encounter with Christophe - nickname Lord of the Logos i is at Heavitree Pleasure Ground in Exeter. The <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/weather">weather</a> is unusually warm for a March day, so Christophe has found himself a sunny spot outside the front of the Parklife Cafe.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044178" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg" alt="Christophe Szpajdel, aka Lord of the Logos, working on his designs at Heavitree Pleasure Ground in Exeter" content="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel, aka Lord of the Logos, working on his designs at Heavitree Pleasure Ground in Exeter</span>
<span itemprop="author"> (Image: DevonLive)</span>
</figcaption>
</figure> <p>As I approach, he is busy working on a new logo called Exe'uber'ances which is the title of an exhibition he is participating in Exeter this summer.</p> <p>Knowing that his speciality is heavy metal, I expect to see him dressed in a black t-shirt brandishing a fearsome gothic inspired design. To my surprise, he is wearing a bright blue t-shirt emblazoned with yellow lettering. On closer inspection, it becomes apparent that Christophe is turning his talents to political protest t-shirts as the front reads 'make Russia small again', with an anti-Trump and vice-president JD Vance.</p> <p>He explains it was created in a 'moment of anger' and that he has Ukrainian heritage in his family. For his own personal satisfaction creates controversial drawings of American president Donald Trump that can only ever be kept under wraps to limit any damage to his career that has earned him the nickname 'Lord of the Logos'.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044199" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg" alt="The work of Christophe Szpajdel, aka Lord of the Logos" content="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The work of Christophe Szpajdel, aka Lord of the Logos</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe's life-long passion for art started when he was a schoolboy drawing wildlife. His art then turned in a new direction when he discovered English rock band Motörhead, much to the disapproval of his mum whose favourite artist was Barbara Streisand and his dad's being Elvis.</p> <p>It led to a love of heavy metal, particularly the black and death metal sub-genres. His two passions have since taken him all over the world. His work first came to wider international attention in the mid '90s off of the back of logos for the likes of Emperor, Old Man's Child and Enthroned. </p> <p>Since then he has continued to make a significant contribution to the extreme metal scene having drawn logos for hundreds of bands including Melechesh, Falkenbach, Aborted, Abigail Williams and Bloodshot Dawn. For 'fun', he has designed unofficial logos for the likes of Ed Sheeran and Bruno Mars.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044203" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg" alt="The work of Christophe Szpajdel, aka Lord of the Logos, on stage" content="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The work of Christophe Szpajdel, aka Lord of the Logos, on stage</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe created his first logo at the tender age of 17 for a Polish band called Totustus back in 1987. Unfortunately, the band never achieved fame. </p> <p>The first 'important' logo he says he designed was in 1989 for Finland band Disgrace, but what he credits for getting his name out there was creating logos for Germany band Endseeker, a well-known death metal band, and Enthroned from Belgium.</p> <p>But his biggest claim to fame remains the global recognition he gained after designing a show-stopping logo for pop star Rihanna in 2016. One of his visually striking designs was projected onto a 100ft backdrop at the MTV VMA awards during a live performance of her single B*tch Better Have My Money.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="410479" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="411">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg" alt="Belgium-born Christophe Szpajdel's logo was projected onto a 100ft backdrop at the MTV VMA awards" content="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Belgium-born Christophe Szpajdel's logo was projected onto a 100ft backdrop at the MTV VMA awards</span>
</figcaption>
</figure> <p>Nothing can be more grounding than the fact he designed it at <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/sidmouth">Sidmouth</a> Library in between shifts at the Co-op in the town. The opportunity came following a chance encounter with a member of Rihanna's management team on the tube between Canada Water and London Paddington.</p> <p>But it isn't the logo he is the most proud of. Instead he says it is the one he designed for Norwegian black metal band Emperor, simply because it is 'readable and iconic'.</p> <p>"If I could create a logo for anyone it would be Muse. I would also like to do ones for Ed Sheeran, Calvin Harris and also Elbow who are one of my favourite bands.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044201" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="435">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg" alt="The Emperor logo created by Christophe Szpajdel" content="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The Emperor logo created by Christophe Szpajdel</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Explaining how to make the perfect logo, Christophe, who lives in the Stoke Hill area of Exeter, said: "They have to be fluid to the eye. You need harmony, flow, symmetry and for it to be pleasant to the eye and very stylish.</p> <p>"If something is off centre it looks distracting; I'm a bit of a perfectionist! I love the aesthetics of an arched logo.</p> <p>"I prefer my logos to be simple, but have a kick. They also need to have a certain readability. Using a calligraphy style means the letters blend together rather than letters in existing fonts."</p> <figure data-mod="image" data-orientation="portrait" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044202" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="642">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg" alt="The Exe'uber'ances logo created by Christophe Szpajdel" content="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The Exe'uber'ances logo created by Christophe Szpajdel</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe's reputation for designing logos means he receives commissions from all over the world. His finalised sketches are then digitised by graphic designer Faye Burn to speed up the process for clients. </p> <p>However, the industry is fiercely competitive which is a constant struggle for Christophe to battle against.</p> <p>He said: "Within the past 10 years, the industry has been ruined by cheap designers using a computer and changing existing logos into a different name. Stealing intellectual property is something I have experienced extremely frequently.</p> <p>"You can tell when all the detail has been done by hand rather than by a computer, and those 'designers' charge a much cheaper price which makes people more inclined to use them."</p> <figure data-mod="image" data-orientation="portrait" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044200" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="820">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg" alt="Christophe Szpajdel in his Co-op uniform" content="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel in his Co-op uniform</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>It means that Christophe relies on the steady income of his job at the Co-op serving customers. He is contracted to do 12 to 20 hours a week, currently at its store in Queen Street, but also can occasionally be seen doing shifts in Heavitree.</p> <p>He said: "The reason I will never be able to fulfil my dream to be living exclusively off my art is because of the competition there now is so I have to have two sources of income.</p> <p>"Working at the Co-op also helps me maintain contact with the outside world as otherwise you can be immersed in your own art world. As long as my tummy is full and I have a roof over my head, that is the most important thing."</p> <p>Being part-time at the Co-op enables Christophe to spend as much time as he can abroad exhibiting his work and also attending events and award ceremonies. In January, he was awarded the prestigious Artist of the Year 2025 International Prize at the Palazzo Pucci in Italy. </p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044179" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg" alt="Christophe Szpajdel, aka Lord of the Logos, with his latest award" content="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel, aka Lord of the Logos, with his latest award</span>
<span itemprop="author"> (Image: DevonLive)</span>
</figcaption>
</figure> <p>The award is presented to a select group of artists who have distinguished themselves through their aesthetic research and the stylistic values of their artwork. Additionally, he has been nominated as one of the top 60 masters by the internationally renowned ArtTour International Magazine which will be a red carpet event.</p> <p>Significant clients Christophe have worked with recently include producing a logo for short film Framed in Blood by Chris Sheeran, an alternative logo design for band The Pretty Wild, a logo for Italian alternative model and designer Amigdala, and a t-shirt design to be a potentially worn at the film premiere of Turkish movie Pavlonya by Kadir Uzun. In May, Christophe will be hosting his first exhibition in Chile during the Metal Fest at the Movistar Arena.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044222" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg" alt="Christophe Szpajdel presenting a logo to death metal band Heksen" content="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel presenting a logo to death metal band Heksen</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>However, he also remains true to his long-established Devon roots. From June 9 to 15, he will be among three artists taking part in an exhibition at Tabac Taphouse in <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/exeter">Exeter</a>, as part of Art Week Exeter. He will also be participating in annual art event Devon Open Studios.</p> <p>Again with other local artists, he will be showcasing his work at Café Momus, located within Manor Street Galleries in <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/plymouth">Plymouth</a>, from September 1 to 30. Christophe has also written books about his work, the first titled under his nickname Lord of the Logos with limited copies now available. His work has also featured in other books among other prestigious artists.rtists.</p><!-- Article End--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a word game. My mom thinks it's great. What do you think? (302 pts)]]></title>
            <link>https://www.whatsit.today/</link>
            <guid>43593789</guid>
            <pubDate>Sat, 05 Apr 2025 14:26:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whatsit.today/">https://www.whatsit.today/</a>, See on <a href="https://news.ycombinator.com/item?id=43593789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Loading daily challenge...</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Vision for WebAssembly Support in Swift (170 pts)]]></title>
            <link>https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060</link>
            <guid>43593596</guid>
            <pubDate>Sat, 05 Apr 2025 13:58:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060">https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060</a>, See on <a href="https://news.ycombinator.com/item?id=43593596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>As WebAssembly support has been developed by the Swift community and significantly improved over the years, I would like to put up a pitch for a vision describing WebAssembly support in Swift. Your feedback would be highly appreciated! Full vision text is included below, while <a href="https://github.com/swiftlang/swift-evolution/pull/2590">the corresponding PR is also available on GitHub</a>.</p>
<h2><a name="p-362448-introduction-1" href="#p-362448-introduction-1"></a>Introduction</h2>
<p>WebAssembly (abbreviated <a href="https://webassembly.github.io/spec/core/intro/introduction.html#wasm">Wasm</a>) is a virtual machine instruction set focused on portability, security, and high performance. It is vendor-neutral, designed and developed by <a href="https://w3.org/">W3C</a>. An implementation of a WebAssembly virtual machine is usually called a <strong>WebAssembly runtime</strong>.</p>
<p>One prominent spec-compliant implementation of a Wasm runtime in Swift is <a href="https://github.com/swiftwasm/WasmKit">WasmKit</a>. It is available as a Swift package, supports multiple host platforms, and has a simple API for interaction with guest Wasm modules.</p>
<p>An application compiled to a Wasm module can run on any platform that has a Wasm runtime available. Despite its origins in the browser, it is a general-purpose technology that has use cases in client-side and server-side applications and services. WebAssembly support in Swift makes the language more appealing in those settings, and also brings it to the browser where it previously wasn't available at all<sup><a href="#footnote-362448-1" id="footnote-ref-362448-1">[1]</a></sup>. It facilitates a broader adoption of Swift in more environments and contexts.</p>
<p>The WebAssembly instruction set has useful properties from a security perspective, as it has no interrupts or peripheral access instructions. Access to the underlying system is always done by calling explicitly imported functions, implementations for which are provided by an imported WebAssembly module or a WebAssembly runtime itself. The runtime has full control over interactions of the virtual machine with the outside world.</p>
<p>WebAssembly code and data live in completely separate address spaces, with all executable code in a given module loaded and validated by the runtime upfront. Combined with the lack of "jump to address" and a limited set of control flow instructions that require explicit labels in the same function body, this makes a certain class of attacks impossible to execute in a correctly implemented spec-compliant WebAssembly runtime.</p>
<h3><a name="p-362448-webassembly-system-interface-and-the-component-model-2" href="#p-362448-webassembly-system-interface-and-the-component-model-2"></a>WebAssembly System Interface and the Component Model</h3>
<p>The WebAssembly virtual machine has no in-built support for I/O; instead, a Wasm module's access to I/O is dependent entirely upon the runtime that executes it.</p>
<p>A standardized set of APIs implemented by a Wasm runtime for interaction with the host operating system is called <a href="https://wasi.dev/">WebAssembly System Interface (WASI)</a>. <a href="https://github.com/WebAssembly/wasi-libc">WASI libc</a> is a layer on top of WASI that Swift apps compiled to Wasm can already use thanks to C interop. The current implementation of Swift stdlib and runtime for <code>wasm32-unknown-wasi</code> triple is based on this C library. It is important for WASI support in Swift to be as complete as possible to ensure portability of Swift code in the broader Wasm ecosystem.</p>
<p>In the last few years, the W3C WebAssembly Working Group considered multiple proposals for improving the WebAssembly <a href="https://github.com/webassembly/interface-types">type system</a> and <a href="https://github.com/webassembly/module-linking">module linking</a>. These were later subsumed into a combined <a href="https://component-model.bytecodealliance.org/">Component Model</a> proposal thanks to the ongoing work on <a href="https://github.com/WebAssembly/WASI/blob/main/wasip2/README.md">WASI Preview 2</a>, which served as playground for the new design.</p>
<p>The Component Model defines these core concepts:</p>
<ul>
<li>
<p>A <strong>component</strong> is a composable container for one or more WebAssembly modules that have a predefined interface;</p>
</li>
<li>
<p><strong>WebAssembly Interface Types (WIT) language</strong> allows defining contracts between components;</p>
</li>
<li>
<p><strong>Canonical ABI</strong> is an ABI for types defined by WIT and used by component interfaces in the Component Model.</p>
</li>
</ul>
<p>Preliminary support for WIT has been implemented in <a href="https://github.com/swiftwasm/WasmKit/blob/0.0.3/Sources/WITTool/WITTool.swift">the <code>wit-tool</code> subcommand</a> of the WasmKit CLI. Users of this tool can generate <code>.wit</code> files from Swift declarations, and vice versa: Swift bindings from <code>.wit</code> files.</p>
<h2><a name="p-362448-use-cases-3" href="#p-362448-use-cases-3"></a>Use Cases</h2>
<p>We can't anticipate every possible application Swift developers are going to create with Wasm, but we can provide a few examples of its possible adoption in the Swift toolchain itself. To quote <a href="https://www.swift.org/gsoc2024/#building-swift-macros-with-webassembly">a GSoC 2024 idea</a>:</p>
<blockquote>
<p>WebAssembly could provide a way to build Swift macros into binaries that can be distributed and run anywhere, eliminating the need to rebuild them continually.</p>
</blockquote>
<p>This can be applicable not only to Swift macros, but also for the evaluation of SwiftPM manifests and plugins.</p>
<p>In the context of Swift developer tools, arbitrary code execution during build time can be virtualized with Wasm. While Swift macros, SwiftPM manifests, and plugins are sandboxed on Darwin platforms, with Wasm we can provide stronger security guarantees on other platforms that have a compatible Wasm runtime available.</p>
<p>The WebAssembly instruction set is designed with performance in mind. A WebAssembly module can be JIT-compiled or compiled on a client machine to an optimized native binary ahead of time. With recently accepted proposals to the Wasm specification it now supports features such as SIMD, atomics, multi-threading, and more. A WebAssembly runtime can generate a restricted subset of native binary code that implements these features with little performance overhead.</p>
<p>Adoption of Wasm in developer tools does not imply unavoidable performance overhead. With security guarantees that virtualization brings, there's no longer a need to spawn a separate process for each Swift compiler and SwiftPM plugin/manifest invocation. Virtualized Wasm binaries can run in the host process of a Wasm runtime, removing the overhead of new process setup and IPC infrastructure.</p>
<h2><a name="p-362448-goals-4" href="#p-362448-goals-4"></a>Goals</h2>
<p>As of March 2024 all patches necessary for basic Wasm and WASI Preview 1 support have been merged to the Swift toolchain and core libraries. Based on this, we propose a high-level roadmap for WebAssembly support and adoption in the Swift ecosystem:</p>
<ol>
<li>
<p>Make it easier to evaluate and adopt Wasm with increased API coverage for this platform in the Swift core libraries. Main prerequisite for that is setting up CI jobs for those libraries that run tests for WASI and also Embedded Wasm, where possible. As a virtualized embeddable platform, not all system APIs are always available or easy to port to WASI. For example, multi-threading, file system access, networking and localization need special support in Wasm runtimes and a certain amount of consideration from a developer adopting these APIs.</p>
</li>
<li>
<p>Improve support for cross-compilation in Swift and SwiftPM. We can simplify versioning, installation, and overall management of Swift SDKs for cross-compilation in general, which is beneficial not only for WebAssembly, but for all platforms.</p>
</li>
<li>
<p>Continue work on Wasm Component Model support in Swift as the Component Model proposal is stabilized. Ensure that future versions of WASI are available to Swift developers targeting Wasm.</p>
</li>
<li>
<p>Make interoperability with Wasm components as smooth as C and C++ interop already is for Swift. With a formal specification for Canonical ABI progressing, this will become more achievable with time. This includes consuming components from, and building components with Swift.</p>
</li>
<li>
<p>Improve debugging experience of Swift code compiled to Wasm. While rudimentary support for debugging exists in some Wasm runtimes, we aim to improve it and, where possible, make it as good as debugging Swift code compiled to other platforms.</p>
</li>
</ol>
<h3><a name="p-362448-proposed-language-features-5" href="#p-362448-proposed-language-features-5"></a>Proposed Language Features</h3>
<p>In our work on Wasm support in Swift, we experimented with a few function attributes that could be considered as pitches and eventually Swift Evolution proposals, if the community is interested in their wider adoption. These attributes allow easier interoperation between Swift code and other Wasm modules linked with it by a Wasm runtime.</p>
<h2><a name="p-362448-platform-specific-considerations-6" href="#p-362448-platform-specific-considerations-6"></a>Platform-specific Considerations</h2>
<h3><a name="p-362448-debugging-7" href="#p-362448-debugging-7"></a>Debugging</h3>
<p>Debugging Wasm modules is challenging because Wasm does not expose ways to introspect and control the execution of a Wasm module instance, so a debugger cannot be built on top of Wasm itself. Special support from the Wasm execution engine is necessary for debugging.</p>
<p>The current state of debugging tools in the Wasm ecosystem is not as mature as other platforms, but there are two main directions:</p>
<ol>
<li>
<p><a href="https://github.com/llvm/llvm-project/pull/77949">LLDB debugger with Wasm runtime</a> supporting GDB Remote Serial Protocol;</p>
</li>
<li>
<p><a href="https://book.swiftwasm.org/getting-started/debugging.html#enhanced-dwarf-extension-for-swift">Wasm runtime with a built-in debugger</a>.</p>
</li>
</ol>
<p>The first approach provides an almost equivalent experience to existing debugging workflows on other platforms. It can utilize LLDB's Swift support, remote metadata inspection, and serialized Swift module information. However, since Wasm is a Harvard architecture and has no way to allocate executable memory space at runtime, implementing expression evaluation with JIT in user space is challenging. In other words, GDB stub in Wasm engines need tricky implementations or need to extend the GDB Remote Serial Protocol.</p>
<p>The second approach embeds the debugger within the Wasm engine. In scenarios where the Wasm engine is embedded as a guest in another host engine (e.g. within a Web Browser), this approach allows seamless debugging experiences with the host language by integrating with the host debugger. For example, in cases where JavaScript and Wasm call frames are interleaved, the debugger works well in both contexts without switching tools. Debugging tools like Chrome DevTools can use DWARF information embedded in Wasm file to provide debugging support. However, supporting Swift-specific metadata information and JIT-based expression evaluation will require integrating LLDB's Swift plugin with these debuggers in some way.</p>
<p>In summary, debugging in the browser and outside of the browser context are sufficiently different activities to require separate implementation approaches.</p>
<h3><a name="p-362448-multi-threading-and-concurrency-8" href="#p-362448-multi-threading-and-concurrency-8"></a>Multi-threading and Concurrency</h3>
<p>WebAssembly has <a href="https://github.com/WebAssembly/threads">atomic operations in the instruction set</a> (only sequential consistency is supported), but it does not have a built-in way to create threads. Instead, it relies on the host environment to provide multi-threading support. This means that multi-threading in Wasm is dependent on the Wasm runtime that executes a module. There are two proposals to standardize ways to create threads in Wasm:</p>
<p>(1) <a href="https://github.com/WebAssembly/wasi-threads">wasi-threads</a>, which is already supported by some toolchains, runtimes, and libraries but has been superseded;</p>
<p>(2) The new <a href="https://github.com/WebAssembly/shared-everything-threads">shared-everything-threads</a> proposal is still in the early stages, but is expected to be the future of multi-threading in Wasm.</p>
<p>Swift currently supports two threading models in Wasm: single-threaded (<code>wasm32-unknown-wasi</code>) and multi-threaded using wasi-threads (<code>wasm32-unknown-wasip1-threads</code>). Despite the latter supporting multi-threading, Swift Concurrency defaults to a cooperative single-threaded executor due to the lack of wasi-threads support in libdispatch. Preparing for the shared-everything-threads proposal is crucial to ensure that Swift Concurrency can adapt to future multi-threading standards in Wasm.</p>
<h3><a name="p-362448-h-64-bit-address-space-9" href="#p-362448-h-64-bit-address-space-9"></a>64-bit address space</h3>
<p>WebAssembly currently uses a 32-bit address space, but <a href="https://github.com/WebAssembly/memory64/">64-bit address space</a> proposal is already in the implementation phase.</p>
<p>Swift supports 64-bit pointers on other platforms where available, however WebAssembly is the first platform where relative reference from data to code is not allowed. Alternative solutions like image-base relative addressing or "small code model" for fitting 64-bit pointer in 32-bit are unavailable, at least for now. This means that we need cooperation from the WebAssembly toolchain side or different memory layout in Swift metadata to support 64-bit linear memory support in WebAssembly.</p>
<h3><a name="p-362448-shared-libraries-10" href="#p-362448-shared-libraries-10"></a>Shared libraries</h3>
<p>There are two approaches to using shared libraries in the WebAssembly ecosystem:</p>
<ol>
<li>
<p><a href="https://emscripten.org/docs/compiling/Dynamic-Linking.html">Emscripten-style dynamic linking</a></p>
</li>
<li>
<p><a href="https://github.com/WebAssembly/component-model/blob/main/design/mvp/Linking.md">Component Model-based "ahead-of-time" linking</a></p>
</li>
</ol>
<p>Emscripten-style dynamic linking is a traditional way to use shared libraries in WebAssembly, where the host environment provides non-standard dynamic loading capabilities.</p>
<p>The latter approach cannot fully replace the former, as it is unable to handle dynamic loading of shared libraries at runtime, but it is more portable way to distribute programs linked with shared libraries, as it does not require the host environment to provide any special capabilities except for Component Model support.</p>
<p>Support for shared libraries in Swift means ensuring that Swift programs can be compiled in position-independent code mode and linked with shared libraries by following the corresponding dynamic linking ABI.</p>
<hr>

<ol>
<li id="footnote-362448-1"><p>Browser-specific use cases remain to be addressed in a separate document. <a href="#footnote-ref-362448-1">↩︎</a></p>
</li>
</ol>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compilers: Incrementally and Extensibly (2024) (110 pts)]]></title>
            <link>https://okmij.org/ftp/tagless-final/Compiler/index.html</link>
            <guid>43593088</guid>
            <pubDate>Sat, 05 Apr 2025 12:55:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://okmij.org/ftp/tagless-final/Compiler/index.html">https://okmij.org/ftp/tagless-final/Compiler/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43593088">Hacker News</a></p>
Couldn't get https://okmij.org/ftp/tagless-final/Compiler/index.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Earth's clouds are shrinking, boosting global warming (151 pts)]]></title>
            <link>https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming</link>
            <guid>43592756</guid>
            <pubDate>Sat, 05 Apr 2025 12:08:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming">https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming</a>, See on <a href="https://news.ycombinator.com/item?id=43592756">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Europe needs its own social media platforms to safeguard sovereignty (104 pts)]]></title>
            <link>https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/</link>
            <guid>43592454</guid>
            <pubDate>Sat, 05 Apr 2025 11:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/">https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/</a>, See on <a href="https://news.ycombinator.com/item?id=43592454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Social media has emerged as the central nervous system of global communication, shaping politics, culture, and identity. Yet, Europe’s digital public square is not its own. Over 80% of the continent’s social media activity flows through platforms headquartered in the United States—Meta (Facebook, Instagram), Alphabet (YouTube), and X (Twitter)—creating a dependency that undermines Europe’s autonomy.</p>



<p>Recently, it has become increasingly clear that European companies urgently need to build Europe’s own sovereign social media ecosystem to counter disinformation, protect democratic integrity, preserve cultural diversity, and reclaim control from US corporate and geopolitical interests. Europe’s sovereignty in the 21st century is at stake.</p>



<h2>The threat of US interference: Disinformation as a geopolitical weapon</h2>



<p>The 2016 Brexit referendum exposed how US-based actors exploited European vulnerabilities. For example, Cambridge Analytica harvested data from 87 million Facebook users—including millions of Europeans—to micro-target voters with divisive ads. Leaked documents revealed campaigns designed to inflame anti-EU sentiment, demonstrating how US corporate tools can destabilize European unity.</p>



<p>Moreover, false narratives about voter fraud propagated by US politicians on Twitter and Facebook flooded European networks, bolstering extreme movements. In Germany, the “Querdenker” movement leveraged these claims to protest COVID-19 measures, while in other countries, several disinformation groups backed by US billionaires amplified baseless accusations about election rigging.</p>



<p>It is important to understand that US platforms optimize for engagement and their owners interests, not truth. During France’s 2022 presidential race, YouTube’s algorithm disproportionately recommended far-right candidate Éric Zemmour, boosting his visibility despite his marginal polling. Researchers found that 60% of French-language election content on YouTube contained misinformation, much of it algorithmically amplified.</p>



<h2>US billionaire oligarchy problem</h2>



<p>American billionaires, including tech billionaires, wield outsized influence over European discourse. Elon Musk’s acquisition of Twitter (rebranded as X) led to the reinstatement of 62,000 banned accounts, including extremists, far-right figures like Germany’s Nikolai Nerling, who had spread anti-vaccine conspiracies, persons who committed several serious crimes in Europe, and persons who promote illegal activities such as rape and dehumanization of others. Meanwhile, Meta’s content moderation policies routinely ignore EU directives; in 2023, the European Commission accused Meta of failing to curb disinformation campaigns. Recently, several disinformation campaigns linked to US billionaires attacked EU officials on social media platforms, spreading false narratives and encouraging committing crimes (e.g., murdering officials or overthrowing governments in the EU). It has become clear that these platforms operate as extensions of US corporate power and the new US administration, prioritizing profit and political gains over Europe’s stability and safety.</p>



<h2>Data colonialism: US platforms exploit Europe</h2>



<h3><strong>GDPR vs the US surveillance state</strong></h3>



<p>While the EU’s <a href="https://mediascope.group/what-is-the-general-data-protection-regulation-gdpr/" title="GDPR. What is the General Data Protection Regulation?">General Data Protection Regulation (GDPR)</a> enshrines privacy as a fundamental right, US platforms remain bound by laws like the <a href="https://mediascope.group/the-us-cloud-act-and-risks-for-european-asian-and-african-companies/" title="The US CLOUD Act and risks for European, Asian and African companies">CLOUD Act</a>, which grants American authorities access to data stored anywhere in the world. In 2022, the European Data Protection Board fined Meta for transferring EU user data to US servers, citing risks of NSA surveillance. Despite the EU-US Data Privacy Framework, experts warn that European data remains vulnerable to US intelligence overreach.</p>



<h3><strong>Economic extraction</strong></h3>



<p>US platforms siphon billions from Europe’s digital economy. In 2022, Meta reported €4.3 billion in EU revenue but paid an effective tax rate of 8.5% through Irish loopholes—€2.5 billion less than standard EU corporate rates. Google and Apple similarly route profits through tax havens, depriving European governments of funds needed for tech innovation. This financial drain perpetuates Europe’s dependency, stifling homegrown competitors.</p>



<h3><strong>Erasing Europe’s diversity</strong></h3>



<p>US platforms homogenize culture by privileging English-language content aligning with the worldview of the current US presidential administration and US billionaires. More than 70% of trends on social media originate in the US, overshadowing local creators. European journalists and influencers struggle to compete with US influencers, while platforms like Instagram algorithmically promote American beauty standards, marginalizing Europe’s diverse cultural identities. The shrinking visibility of local users and their regional languages also threatens linguistic heritage of Europe.</p>



<h2>Europe is facing digital sovereignty crisis</h2>



<p>The US tech cold war has turned data into a strategic asset, yet Europe remains a digital colony. US platforms dominate critical infrastructure: 92% of European governments use Facebook for public communication, while Google’s search monopoly shapes access to information. This dependency leaves Europe exposed to geopolitical coercion. For instance, US platforms are involved in limiting and censoring pro-European content but promoting anti-European narratives that are aligned with US interests. Developing sovereign European platforms, including social media platforms and search engines, would ensure the sovereignty in technology, economy, information space, security and defense.</p>



<h2>Building on European strengths: The fediverse and beyond</h2>



<p>European companies and communities already host decentralized alternatives like Mastodon, a federated network powered by the homegrown Mastodon software. These GDPR-compliant tools allow users to control data and interconnect across servers—a model echoing the EU’s federalist values. However, fragmentation, lack of user-friendly UI and underfunding limit their reach. A unified EU initiative could fund these projects while the alliance of European companies and communities could merge these projects into a public-private platform.</p>



<p>It is in the best interest of the European Union to provide funding for European-owned social media platforms to ensure their development and European digital sovereignty.</p>



<h2>Network effects and innovation</h2>



<p>Critics often argue that Silicon Valley’s dominance is insurmountable, citing global statistics of Meta-owned platforms (Facebook, Instagram, Threads) and X. Yet Europe’s 450 million affluent users offer a critical mass. Moreover, Europe attracts people from other regions such as Asia, Africa and South America. Case studies from China (WeChat, Weibo, Xiaohongshu) show that sovereign platforms can thrive and expand globally.</p>



<p>Moreover, the EU is a regulatory superpower which can use legislation to support homegrown social media platforms. For example, the EU can mandate US “gatekeeper” platforms (per the Digital Markets Act) to interconnect with European alternatives, allowing cross-platform interactions. In addition, the EU could introduce EU-wide tax breaks for creators using European platforms in the form of “cultural exceptions”.</p>



<h2>Europe’s digital destiny</h2>



<p>The choice is stark: continue as a digital colony of US tech giants or forge a sovereign future. European social media platforms are not just a tool—they shield against disinformation, act as guardian of cultural diversity, and a pillar of strategic autonomy. By combining support and strategic interests with cutting-edge innovation, the EU can support the development of the homegrown social media ecosystem. The time to act is now, before the algorithms of Meta and X platforms write Europe’s next chapter for it.</p>



<hr>



<p>You can read more writings of Dawid Wiktor on his&nbsp;<a href="https://mediascope.group/?page_id=2567">Exec Profile</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emulating an iPhone in QEMU (194 pts)]]></title>
            <link>https://eshard.com/posts/emulating-ios-14-with-qemu</link>
            <guid>43592409</guid>
            <pubDate>Sat, 05 Apr 2025 10:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshard.com/posts/emulating-ios-14-with-qemu">https://eshard.com/posts/emulating-ios-14-with-qemu</a>, See on <a href="https://news.ycombinator.com/item?id=43592409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Start of the journey</h2>
<p>We started our journey with iOS emulation by looking at existing open-source solutions. We had successfully run <a href="https://github.com/alephsecurity/xnu-qemu-arm64">alephsecurity/xnu-qemu-arm64</a> before, but the project being read-only was concerning.</p>
<p>Then we tried <a href="https://github.com/TrungNguyen1909/qemu-t8030">TrungNguyen1909/qemu-t8030</a> and it had quite a few interesting features:</p>
<ul>
<li>the ability to actually restore iOS (using a second "companion" QEMU for USB connectivity)</li>
<li>running iOS 14</li>
<li>a more recent version of QEMU</li>
<li>a nice wiki on how to bring up the emulator</li>
</ul>
<p>With that project, we quickly managed to get a shell and ssh by modifying <code>System/Library/xpc/launchd.plist</code> so it was a great starting point.</p>
<p><img src="https://cms.eshard.com/uploads/image_16_ff7341d07a.png" alt="image (16).png"></p>
<p>We set our long term objective on getting a functional iOS emulated, with UI and at least the ability to execute some apps.</p>
<p>The first thing that bothered us with the <code>t8030</code> project was the fact that they added code in QEMU itself to patch the xnu kernel. We knew we were going to probably need more patching and wanted a cleaner way to do this.
As we had some experience with a jailbroken real iPhone, we looked into using <a href="https://github.com/palera1n/PongoOS">Pongo</a> to apply checkra1n patches, as this would allow us to remove any patching done in QEMU.</p>
<p>In a jailbreaking scenario, after getting pwned by checkmate, PongoOS is injected in SRAM and the checkra1n-kpf module is sent through USB.
Rather than bothering with early USB we chose to increase the SRAM on our emulated phone, and use PongoOS with checkra1n’s KPF module.</p>
<p>Executing PongoOS, first, was not without its issues, any boot code usually done by the bootrom or iboot would be missing, such as setting up the FPU before performing any double/float instructions. Skimming through <a href="https://developer.arm.com/documentation/dai0527/latest/">ARM documentation (section 5.4)</a> and a some <a href="https://github.com/citruz/pongoOS-QEMU/commit/033413bfaa6ebc4e1b8680b7548a3505fabe808b#diff-94255394208544c1bce0ef3fc2b955262dc6f5e8ed391005a521f28a0440a042L109-R117">Googling</a> helped.</p>
<p>Features introduced with A13 and later devices, not supported by Pongo, broke the pattern-matching of some patches. For example Pointer Authentication (PAC) instructions added <code>autda</code> / <code>xpacd</code> and Apple used a different slide.</p>
<p>Example with the infamous <a href="https://theapplewiki.com/wiki/Tfp0_patch">task_for_pid (tfp0)</a></p>
<pre><p><code><span>% ipsw macho info kernelcache.release.iphone10b.decompressed
</span>000: LC_SEGMENT_64 sz=0x006d8000 off=0x00000000-0x006d8000 addr=0xfffffff007004000-0xfffffff0076dc000 r-x/r-x   __TEXT
<!-- -->
<!-- -->Previous version (iphone-X (14.0_18A373_GM))
<!-- --> - tfp0 address 0xfffffff0076e9e70
<!-- -->   0xfffffff0076e9e70 - 0ffffffff007004000 = 0x6e5e70
<!-- --> - binary
<!-- -->   % hexdump -s 0x6e5e70 -n 8 kernelcache.release.iphone10b.decompressed
<!-- -->   06e5e70 7f70 07ec fff0 0017
<!-- -->
<!-- --> 	Raw: 	0x0017_fff0_07ec_7f70
<!-- --> 	Ghidra:  0xffff_fff0_70ec_7f70
<!-- -->
<!-- -->Later version (iphone-11 (14.0_18A5351d))
<!-- --> - tfp0 address 0x0xfffffff0076c9e40
<!-- -->   0xfffffff0076c9e40 - 0ffffffff007004000 = 0x6c5e40
<!-- --> - binary
<!-- -->   % hexdump -s 0x6c5e40 -n 8 kernelcache.research.iphone12b.decompressed
<!-- -->   06c5e40 1d70 00f0 307a 8010
<!-- -->	 
<!-- -->	Raw:	0x8010_307a_00f0_1d70
<!-- -->	Ghidra: 0xffff_fff0_07f0_5d70
</code></p></pre>
<p><img src="https://cms.eshard.com/uploads/unnamed2_cb01bfe271.png" alt="unnamed2.png"></p>

<p>Pongo allowed us to get access to existing checkra1n patches for multiple iOS versions, and although the dynamic application was interesting, it wasn't easy to read, modify or share. We wanted a more declarative approach, just like actual code patches.</p>
<p>So we made tools allowing us to diff between two <code>Mach-O</code>, and generate a text patch file with the assembly differences. The other program would take this patch file and simply apply to a binary.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250224_174126_cde0ed3bb5.png" alt="Screenshot_20250224_174126.png"></p>

<p>We then booted with Pongo, and used QEMU monitor to dump the memory sections patched by Pongo, then reassembled a patched kernel and finally generated a patch file with all the modifications.
The big patch was then split and commented properly, allowing us to review and control exactly what was patched in the kernel.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed_e4a4ff90f0.png" alt="unnamed.png"></p>

<h2>It’s dark in there</h2>
<p>We knew that on modern iPhones every graphical rendering ends up going through their <a href="https://developer.apple.com/documentation/metal"><code>Metal</code></a> API, which then needs an actual GPU. We believed emulating the Apple Silicon GPU would be way too complex and so we had two solutions in mind:</p>
<ul>
<li>Use software rendering: it seemed it was possible in older versions of iOS (using the gpu=0 bootarg)</li>
<li>Forwarding the Metal calls to a device capable of doing the rendering such as real iPhone or maybe a Mac with OSX</li>
</ul>
<p><img src="https://cms.eshard.com/uploads/graphic_architecture_8d6484c452.png" alt="graphic_architecture.png"></p>

<p>The software rendering seemed much easier, so we first looked into that. Unfortunately, the <code>XNU</code> kernel bootarg option was gone in iOS 14. After looking at the <code>QuartzCore</code> framework with Ghidra it seemed that the software rendering would only be called as a fallback if no <code>Metal</code> renderer was available.</p>
<p>In order to confirm that software rendering was indeed usable we worked on a real jailbroken iPhone, and patched <code>Quartzcore</code> to use software rendering. And indeed we confirmed it was possible! With these modifications, the UI was much slower, and had artifacts on parts which probably directly required <code>Metal</code> for rendering.</p>
<p><img src="https://cms.eshard.com/uploads/iphonex_sw_rendering_fae74d73b1.png" alt="iphonex_sw_rendering.png"></p>

<p>After these experiments, we knew we could get software rendering on QEMU, for anything not using <code>Metal</code> or <code>OpenGL</code> directly (so basically all <code>UIKit</code> apps).</p>
<p>We also explored the alternative of proxying the metal calls, working with 2 physical iPhones. What we did was:</p>
<ul>
<li>Parse all iOS headers with LLVM</li>
<li>All pointers to objective C object on the server is a stub pointer on the client</li>
<li>Generate automatic code to exchange structs and pointers</li>
<li>Hook all functions and methods</li>
<li>Forward every call to a server, executing them and returning the result</li>
</ul>
<p>We got some basic calls to go back and forth for Metal initialization, but we realized the road was still very long to get something to actually work. The Objetive C language and the <code>Metal</code> API are quite complex and have many features making this endeavor very complex.</p>
<p><img src="https://cms.eshard.com/uploads/metal_hook_da83384ee9.png" alt="metal_hook.png"></p>

<p>We ended up postponing this solution for a later time and thought starting with software rendering, even though it’s more restrictive, would help us advance with other problems faster.</p>
<p>Furthermore, we found out, iOS frameworks actually expose private APIs not present in the public headers. Although there are some ways to parse these and generate headers, they are most of the time not usable directly and complicate things further.</p>

<h2>IOSurface hunting</h2>
<p>After trying to make software rendering work, we decided we still needed at least a framebuffer device and the original t8030 QEMU didn’t implement one. However, we found <a href="https://github.com/ChefKissInc/QEMUAppleSilicon">a fork of the project</a> which was apparently working on IOMFB support, and decided to try debugging the display with it.</p>
<p><img src="https://cms.eshard.com/uploads/image_2_2c83473f84.png" alt="image (2).png"></p>

<p>And indeed while restoring iOS with that version, we could see the Apple logo and progress bar. However on normal boot the display would remain completely black so it was time for debugging!</p>
<p>Looking at the IOMFB kext in Ghidra and the framebuffer implementation in QEMU, it seemed that two modes were possible:</p>
<ul>
<li>A raw framebuffer at fixed hardware address was available (we guessed for early display)</li>
<li>A more complex API using registers to configure multiple planes and using dma to write surfaces data</li>
</ul>
<p>We first started experimenting with the raw framebuffer (which we later found out was how <code>Pongo</code> displayed stuff). Using it, we could display arbitrary ARGB surfaces, but when booting, that framebuffer was never written to by the system.</p>
<p>Therefore, we started looking into the second display mode. By enabling traces in the framebuffer implementation in QEMU, we could see that the kernel would set up graphical planes using registers but then nothing happened.</p>
<p>At this point we needed to debug why nothing was displayed after boot, even though the framebuffer seemed implemented and detected by the kernel.</p>

<h2>Address randomization</h2>
<p>Even though we had SSH access, we quickly got limited on what we could observe on the running system. We needed to be able to debug the kernel and userspace components with GDB.</p>
<p>For the kernel randomization, it was actually set up in the t8030 board initialization and allowed to turn it off entirely, so it was easy enough.</p>
<p>For userland we had two cases, randomization for executables and for dynamic libraries inside the dyld cache. For executables, simply patching the _load_machfile kernel function was enough to disable it.</p>
<p><img src="https://cms.eshard.com/uploads/image_20_ec79b11511.png" alt="image (20).png"></p>

<p>For the dynamic libraries we ended up handling it a bit differently.  The first thing to know is that every library is contained in a big binary blob called the dyld cache (located at <code>/System/Library/Caches/com.apple.dyld/dyld_shared_cache_arm64e</code>).</p>
<p>All libraries from this cache (called frameworks) are loaded once at boot and then mapped into processes memory space, even though dlopen is called with a path on the filesystem (like <code>/System/Library/Frameworks/QuartzCore</code>).</p>
<p>We noticed that address randomization actually happened only once at boot, and then a library was always loaded by every executable at the same address later on.</p>
<p>So all we had to do was to write some C tool which would dlopen every framework library and then use the <code>_dyld*</code> functions to list the loaded images and get their offset.</p>
<p>Using this solution (and also the reverse process while debugging with addresses coming from GDB), we could easily debug any library from the dyld cache. We were particularly interested with the <code>IOMFB</code> kext, the <code>backboardd</code> and <code>SpringBoard</code> daemons and the <code>QuartzCore</code> framework.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed5_ad1129e037.png" alt="unnamed5.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed4_1148ce717f.png" alt="unnamed4.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed3_6dc57084e9.png" alt="unnamed3.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed6_1acb33616d.png" alt="unnamed6.png"></p>

<pre><p><code><span>debugserver localhost:1111 –attach backboardd
</span>iproxy 1111:1111
<!-- -->gdb-multiarch -x "set architecture arch" -x "target remote localhost:1111"
</code></p></pre>
<p><strong>Note2:</strong> we later found out how to disable the dyld  cache by patching the kernel. Doing so allows to get look for virtual address directly in the dyld cache on the host (which we did using the great <a href="https://github.com/gimli-rs/object">object</a> Rust library from the Gimli project).</p>
<p><strong>Note1:</strong> to debug userspace you need to have a gdb server on the guest (see the debugserver package from <a href="https://github.com/ProcursusTeam">Procursus</a> for example). We started using gdb on the host but it’s somehow limited or bugged, and lldb seemed better.</p>

<h2>Please talk to me</h2>
<p>Armed with a working GDB we could see that  <code>backboardd</code> appeared to be starting properly, but we realized system logs would be a great help to know what was or wasn’t happening.</p>
<p>On a real iPhone, you can get the system logs (after pairing with you computer in USB) with the tool <code>idevicesyslog</code>. This pairing process involves the generation of key pair with the private key being stored on the phone. <code>lockdownd</code> uses this to verify the identity of the computer (after the user has authorized it once in the UI).</p>
<p>In our case, although we could interact with the phone through USB, <code>lockdownd</code> would not work properly. After some Ghidra sessions we realized that <code>lockdownd</code> was trying to use the <code>keybag</code> to store the private key, which would require the SEP we are lacking.</p>
<p>In order to go further, we created a shellcode injected in place of some presumably useless existing function. The code reads a pre-generated pair of private/public keys from the filesystem, and basically loads them every time <code>lockdownd</code> tries to get them from the <code>keybag</code>.</p>
<p>After much debugging (and some more patching to simulate the user trusting the computer and the phone being unlocked), we finally got it to work, and could pair with the emulated iPhone from our companion QEMU.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed7_d7cd518551.png" alt="unnamed7.png"></p>
<p>We found out later on you can also use a tool called oslog on the iphone directly to show the logs (didn’t seem to work at the time), although having the ability would give us much more than just the logs afterwards.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed8_a1c58cc9ab.png" alt="unnamed8.png"></p>
<p>Unfortunately, the logs revealed that <code>QuartzCore</code> seemed to be initializing properly, detecting the size of the display. It also showed that software rendering was being used as a fallback. So everything was working properly but still no display!</p>
<p>Note:  a single error about pixel format was showing and we worked around it by forcing RGBA (we’ll talk later about patching userspace), although this was removed later on.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed9_675d25af99.png" alt="unnamed9.png"></p>

<h2>PAC or not PAC</h2>
<p>Modifying <code>backboardd</code> to fix a pixel format error showed us we were going to have issues with multiple aspects of iOS security.</p>
<p>The signature check at load and runtime were fixed with kernel patches, however we still had issues with pointer authentication failure interrupting our modified <code>backboardd</code> execution.</p>
<p>Pointer authentication is a feature added with ARM8.3 which is used on the <code>t8030</code> board we were emulating and not on t8015 which we used before, so this was new to us.</p>
<p>Since we had foreseen a lot more patching in the future, we decided to tackle that issue at that moment, and try to find a way to bypass this to make our life easier.</p>
<p><img src="https://cms.eshard.com/uploads/esr_pac_2e382a4e6a.png" alt="esr_pac.png"></p>
<p><img src="https://cms.eshard.com/uploads/esr_pac_decoded_8ec8ba3ab6.png" alt="esr_pac_decoded.png"></p>
<p>At the time, we first thought we could just replace all the PAC instructions with either NOP or equivalent non PAC instructions.</p>
<p>Although this would have probably worked, it was a bit invasive and we later found out that you can build an ARM64 PAC binary two ways:</p>
<ul>
<li>Either use a dedicated PAC instruction set, which can only be executed on ARM8.3+ CPU</li>
<li>Or an “unused” instruction set which will be interpreted as PAC on ARM8.3+ or non and non PAC equivalent on earlier ARM versions</li>
</ul>
<p>After running some tests with buildroot and an ARM64 linux system, we verified this to be true and also verified that the binaries compiled for our t8030, used the backward compatible instruction set (architecture called arm64e).</p>
<p>So basically, all we had to do was to disable PAC enforcing in QEMU, and it would just run like non PAC code. Unfortunately this didn’t work, and at the time we were using QEMU 7, and found out that QEMU 8 didn’t have the same behavior.</p>
<p>So we did the natural thing, and started porting the current code base to QEMU 8.2.1. This was painful as a lot of code modified QEMU generic code, particularly the code handling the apple specific instructions <code>genter</code>/<code>gexit</code> and the GL exception levels.</p>
<p>After countless xnu panics, gdb attaching to the kernel, gdb attaching to qemu itself, and a desperate git bisect to find our last bug, we finally got iOS booting again on QEMU 8!
And with it, the ability to disable PAC, and modify any executable code, anywhere as we want it.</p>

<h2>The light at the end of the tunnel</h2>
<p>Since <code>backboardd</code> appeared to be working properly in the system logs, we had no choice but to dig further into backboard behavior to try and understand why it still wasn’t displaying anything.</p>
<p>Writing raw ARGB frames on these addresses allowed us to actually modify the display and write on the different graphical planes, so we knew that the display part was actually working properly.</p>
<p>We were left with a few possibilities, either:</p>
<ul>
<li><code>backboardd</code> was not writing anything for some reason</li>
<li>or it wasn’t writing at the proper addresses</li>
<li>or what was written was not valid</li>
</ul>
<p>To investigate, we started by trying to dump physical DMA memory, where <code>backboardd</code> was supposed to write, maybe it was written to but not displayed properly.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250225_092231_cf2b7f405a.png" alt="Screenshot_20250225_092231.png"></p>

<p>To do this, we used a QEMU monitor to get the non contiguous addresses, and then a crude script to dump the physical memory and merge it all in a single file.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250225_092657_bec571344d.png" alt="Screenshot_20250225_092657.png"></p>

<p>Finally using ffplay we tried interpreting that data as an ARGB frame but unfortunately we didn’t get anything interesting.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed10_1e6630e287.png" alt="unnamed10.png"></p>

<p>The second idea was to play with the surfaces allocated by iOS, getting the mapped address in <code>backboardd</code> memory with GDB (by breaking in iosurface_lock).</p>
<p>Searching for all these addresses for some clue, even though we had no idea what was being displayed or if something was even supposed to be displayed. We sometimes found strange things shaped apple an logo, but clearly something was wrong about the way the frames were being written.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed11_5f113d14b2.png" alt="unnamed11.png"></p>

<p>We did the same thing on a real iPhone 10, and we easily dumped perfect raw ARGB frames of the current display. It turned out that with iPhone 11 (so t8030) and later, surfaces appear to be passed compressed to the GPU which knows how to handle it.</p>
<p>But since this doesn’t happen on iPhone X (t8015), we tried modifying the DTB in the QEMU to pass 8015 as <code>chip-id</code> instead of 8030. And finally, we got some apple logo showing on screen after the boot!</p>
<p><img src="https://cms.eshard.com/uploads/unnamed12_7806fbaf2d.png" alt="unnamed12.png"></p>

<h2>Some progress…bar</h2>
<p>At this point, we were happy to finally get a logo displayed but that’s all it did, and the system logs were quite verbose with many system daemons and different libraries we didn’t know about.</p>
<p>All we could do at this point is guess which of the many errors shown in the logs were related to the current issue and fix them one by one until the behavior of the UI changed.</p>
<p>We noticed issues about user authentication and found the errors originated from the daemon <code>mobileactivationd</code> and the framework <code>SpringBoardFoundation</code>.</p>
<p>After patching these, the UI started to display a white progress bar similar to what is shown during the restore phase. The bar seemed to progress indeed but seemed stuck at 90% even after waiting for hours :\</p>

<h2>Patching them all</h2>
<p>Patching the userspace and the framework of the dyld cache was made possible by disabling address randomization. The same way we patched the kernel, we created textual patch files split for each binary / library that we applied with our internal tools.</p>
<p>However, we quickly realized we were going to patch the dyld cache quite often, and while trying modifications it was very painful to handle the 2GB binary file.</p>
<p>Patching it directly was not realistic, we all work on Linux so we cannot modify the nvme directly, and copying the 2GB back and forth through SSH would take forever.</p>
<p>So what we did was to update our internal diffing/patching tool to work with dyld, search the offset of the framework in the dyld cache blob.</p>
<p>Furthermore, we added an option to allow generating simple “dd” commands (and their revert), which can be applied directly on the iPhone (after remounting the fs in rw).</p>
<p>This method allowed us to test many iterations of modifications, and only required a reboot of iOS to have modifications of the dyld cache taken into account.</p>
<p><strong>Note:</strong> a few extra modifications of signature checks in the kernel were necessary for these to work.</p>

<h2>It’s alive!</h2>
<p>Before finding out how to fix the stuck progress bar, we had a little experiment with a system process called <code>PreBoard</code>. It appears to be normally only shown to the user if something goes wrong (like an update interrupting).</p>
<p>Because it’s a system application which draws directly using <code>backboardd</code> (just like <code>SpringBoard</code> would do), it can be started directly from the command line. And with it we get a white screen asking us to swipe to upgrade!</p>

<p><img src="https://cms.eshard.com/uploads/unnamed13_35a54c70e0.png" alt="unnamed13.png"></p>

<p>Armed with knowledge of a past project about using a VNC server on a physical iPhone, we tried adding it, and after quite a few failed attempts, managed to actually unlock that white screen (not by swiping but with a keyboard key).</p>
<p>Right after unlocking, QEMU would stop the execution because iOS was apparently using an illegal instruction. After some digging into <code>backboardd</code>, we found out that it uses the <code>vImage</code> framework to do some hardware accelerated graphical operations (like _vHorizontal_Scale_ARGB_8888_Accelerate).</p>
<p>These operations rely on AMX (Apple Matrix Coprocessor) which have a set of proprietary instructions which are not implemented in the emulated ARM CPU running in QEMU. Fortunately, the <code>vImage</code> framework provides alternative software versions for these calls which only use generic ARM instructions, so we did yet again some patching.</p>
<p>The result is a new screen with an actual <code>IOKit</code> window asking us to enter the passcod and working textbox, in which we can type with the VNC injected keyboard events.</p>

<p><img src="https://cms.eshard.com/uploads/unnamed14_9319700bbb.png" alt="unnamed14.png"></p>

<p>At this point we knew everything was ready for <code>SpringBoard</code> to display properly and it was only a matter of time before we got it to start.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nebula Sans (335 pts)]]></title>
            <link>https://nebulasans.com/</link>
            <guid>43591225</guid>
            <pubDate>Sat, 05 Apr 2025 06:03:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nebulasans.com/">https://nebulasans.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43591225">Hacker News</a></p>
<div id="readability-page-1" class="page">

<section>
  <img src="https://nebulasans.com/img/star_120.png" alt="Nebula star">
  <div>
    <p>Introducing</p>
    <h2>Nebula<span>Sans</span></h2>
    <p>A versatile, modern, humanist sans-serif with a neutral aesthetic, designed for legibility in both digital and print applications.</p>
    <p>Based on <em>Source Sans</em> by Paul D. Hunt for Adobe Fonts.</p>
  </div>
</section>

<div>
    <p>Nebula Sans is the new brand typeface for <a href="https://nebula.tv/">Nebula</a>, the premium streaming service from independent creators. Based on <a href="https://adobe-fonts.github.io/source-sans/" rel="noopener noreferrer"><em>Source Sans</em></a> and designed to be a drop-in alternative to <a href="https://www.typography.com/fonts/whitney/styles/screensmart" rel="noopener noreferrer"><em>Whitney SSm</em></a>, Nebula Sans is available for anyone to use under the SIL Open Font License.</p>
      
    <a href="https://nebula.tv/videos/nebula-sans">
      <img src="https://nebulasans.com/img/NebulaSans-thumbnail.jpg" alt="">
      <svg viewBox="0 0 96 111" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M93.9694 52.0324C96.6442 53.5704 96.6442 57.4296 93.9693 58.9676L5.99388 109.554C3.32722 111.087 1.68452e-07 109.162 3.03461e-07 106.086L4.7439e-06 4.91411C4.87891e-06 1.83804 3.32723 -0.0868459 5.99389 1.44648L93.9694 52.0324Z" fill="white"></path>
        </svg>
    </a>
    <p>
      Watch our short documentary film about the story behind Nebula&nbsp;Sans, written &amp; directed by David Friedman.
    </p>  
    
    <p>Featuring two styles in six weights, Nebula Sans is well-suited for use in interfaces, print, and for any other graphical, digital, physical, metaphysical, metaphorical, or allegorical typeface needs.</p>
 


    <p><a href="https://nebulasans.com/download/NebulaSans-1.010.zip">Download</a> 
      <a href="https://nebulasans.com/license">View font license</a>
    </p>
  </div>



<div data-theme="light">
    <div>
      <p>Nebula Sans Light</p>
      <p>I’d take the awe of understanding over the awe of ignorance any day</p>
    </div>
    <div>
      <p>Nebula Sans Book</p>
      <p>The “tv” in nebula.tv stands for “Taylor’s Version”</p>
    </div>
    <div>
      <p>Nebula Sans Medium</p>
      <p>Don’t use seven words when four will do</p>
    </div>
    <div>
      <p>Nebula Sans Semibold</p>
      <p>Introducing: Facts and fiction</p>
    </div>
    <div>
      <p>Nebula Sans Bold</p>
      <p id="test2">An indie streaming service</p>
    </div>
    <div>
      <p>Nebula Sans Black</p>
      <p id="test">Powered by humans</p>
    </div>
  </div>

<div data-theme="dark">
    <div>
      <p>Nebula Sans Black Italic</p>
      <p id="test">Enter the Snack Zone</p>
    </div>
    <div>
      <p>Nebula Sans Bold Italic</p>
      <p id="test2">There’s no place like home</p>
    </div>
    <div>
      <p>Nebula Sans Semibold Italic</p>
      <p>Charl is the key to our success</p>
    </div>
    <div>
      <p>Nebula Sans Medium Italic</p>
      <p>We’re assembling a crew for a heist</p>
    </div>
    <div>
      <p>Nebula Sans Book Italic</p>
      <p>We believe in facts, science, and human rights</p>
    </div>
    <div>
      <p>Nebula Sans Light Italic</p>
      <p>I’ve been navigating based on cardinal directions…and vibes</p>
    </div>
  </div>



<section>
    <h2>Why we made this</h2>
  
    <p>We built our own typeface for a few key reasons:</p>
    
    <ol>
      <li><strong>Personalization</strong>: we can customize the fonts to align with our preferences.</li>
      <li><strong>Features</strong>: we can integrate advanced typography features tailored to our use cases.</li>
      <li><strong>Sustainability</strong>: the cost of licensing commercial typefaces increases as we grow.</li>
    </ol>

    <p>Source Sans was the perfect foundation for Nebula Sans because it shares many primary characteristics with <em>Whitney SSm</em>, our previous brand typeface — both were designed to bridge the gap between American gothic and European humanist typefaces, with a strong emphasis on readability. The majority of the adjustments we made were to adapt the metrics of <em>Source Sans</em> to better match those of <em>Whitney SSm</em>, since <em>Source Sans</em> is smaller and narrower by default.</p>

    <figure>
      <img src="https://nebulasans.com/img/handgloves.png" alt="The word 'handgloves' in both fonts, overlayed on each other to show the differences.">
      <figcaption>Comparison of Nebula Sans versus <em>Whitney SSm</em></figcaption>
    </figure>

</section>


<section>
  <img src="https://nebulasans.com/img/upright-italic.png" alt="Nebual Sans upright and italic examples.">
  <img src="https://nebulasans.com/img/centaurus.png" alt="Text about a literal nebula, showcasing the font's capital letters and numbers.">
  <img src="https://nebulasans.com/img/standard-alternates.png" alt="Alternate glyphs for the letters 'A', 'L', and 'G'.">
</section>


<section>

  <h2>Typographical Details</h2>

  <h3>Punctuation</h3>
  <p>The default punctuation marks in <em>Whitney SSm</em> were, to our taste, too straight. Nebula Sans uses beautiful curly glyphs from <em>Source Sans</em>.</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/curly-quotes.svg" alt="Curly, or smart, quotes.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/comma-period.svg" alt="Comma and period.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/colon-semicolon.svg" alt="Colon and semicolon.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/at-sign.svg" alt="At sign.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/ampersand.svg" alt="Ampersand.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/parentheses.svg" alt="Parentheses.">
    </figure>
    <figcaption>Whitney SSm vs Nebula Sans</figcaption>
  </figure>

  <h3>Stylistic Alternates</h3>
  <p>Nebula Sans features the same stylistic alternates as <em>Source Sans</em>, with the defaults aligned with those of <em>Whitney SSm</em>.</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/alternate_a.svg" alt="">
      <figcaption>
        Single storey a
        <pre>font-feature-settings: 'ss01';</pre>
      </figcaption>
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/alternate_g.svg" alt="">
      <figcaption>
        Open g
        <pre>font-feature-settings: 'ss02';</pre>
      </figcaption>
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/alternate_l.svg" alt="">
      <figcaption>
        Tailed l
        <pre>font-feature-settings: 'ss03';</pre>
      </figcaption>
    </figure>
  </figure>


  <h3>Asterisk</h3>
  <p>In typography, the asterisk symbol was named as such because it resembles a star. We love stars, so how could we not put our own spin on this little glyph?</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/star.svg" alt="An upside-down star.">
      <figcaption>Nebula logo</figcaption>
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/asterisk.svg" alt="An upside-down five-pointed asterisk.">
      <figcaption>Nebula Sans asterisk</figcaption>
    </figure>
  </figure>


  <h3>Tabular Figures</h3>
  <p>The default version of <em>Whitney SSm</em> lacks support for tabular lining figures, so we were thrilled to be able to include them in Nebula Sans. Tabular figures (or monospaced numerals) allow us to do things like increment the timestamp in the video player while keeping the digits from jumping around as they change.</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/tabular-2.svg" alt="Proportional versus tabular figures. With tabular figures, every digit is the same width.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/img/timestamps-2.png" alt="The timestamp on a Nebula video player.">
    </figure>
  </figure>

</section>


<div>
      <p>Wait now it’s working</p>
      <p>Why did it not work <em>5 minutes ago</em></p>
      <p>Internet weather</p>
      <p>Sent 2:57pm</p>
      <p>@&amp;%!$#?!*</p>
      <p>Sent 3:06pm</p>
    </div>



<section>
  
  <p contenteditable="true" spellcheck="false">Lorem ipsum dolor sit amet, consectetur adipiscing elit.</p>

   
</section>









</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recreating Daft Punk's Something About Us (258 pts)]]></title>
            <link>https://thoughts-and-things.ghost.io/recreating-daft-punks-something-about-us/</link>
            <guid>43591050</guid>
            <pubDate>Sat, 05 Apr 2025 05:31:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoughts-and-things.ghost.io/recreating-daft-punks-something-about-us/">https://thoughts-and-things.ghost.io/recreating-daft-punks-something-about-us/</a>, See on <a href="https://news.ycombinator.com/item?id=43591050">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><strong>Marca Tatem</strong><em>&nbsp;</em>—&nbsp;San Francisco, April 3rd, 2025</p><p>After years of finding it confusing and unintuitive, I finally gave <a href="https://www.ableton.com/en/live/?ref=thoughts-and-things.ghost.io"><strong>Ableton Live</strong></a> another shot. With <strong>version 12</strong> (current as of this writing), it feels significantly more refined—so much so that it's officially become my DAW of choice.</p><p>When learning a new music production software, recreating a cover track is always a smart move. You don't have to worry too much about the songwriting itself, which frees you up to focus on the tools and the production process.</p><p>For this project, I picked a track that's emblematic of the<strong> French Touch</strong> movement and now nearing its 25th anniversary: <strong>Daft Punk's </strong><a href="https://www.youtube.com/watch?v=sOS9aOIXPEk&amp;ref=thoughts-and-things.ghost.io"><strong><em>Something About Us</em></strong></a>. Rebuilding it in a modern production environment turned out to be trickier than I expected, but here's how it went, track by track.</p><figure></figure><h2 id="wait-whats-the-french-touch-anyway">Wait... What's the French Touch, Anyway?</h2><p>To me, <strong>French Touch</strong> isn't just a genre—it's a <em>cultural artifact</em> born from a very specific time and place: France in the late <strong>'70s</strong> and <strong>'80s</strong>. Its distinct sound is the product of a generation raised on <em>analog dreams of the digital future</em>.</p><p>These artists—<strong>Daft Punk</strong>, <strong>Justice</strong>, <strong>Kavinsky</strong>, and others—grew up immersed in a bizarre and colorful media landscape. Japanese TV shows like <a href="https://www.youtube.com/watch?v=rV2yjpuPjaU&amp;ref=thoughts-and-things.ghost.io"><em>X-OR</em></a>, <a href="https://www.youtube.com/watch?v=amrDS3CvrNI&amp;ref=thoughts-and-things.ghost.io"><em>Sankukai</em></a>, and <a href="https://www.youtube.com/watch?v=ROXpxDtKv7o&amp;ref=thoughts-and-things.ghost.io"><em>Albator 84</em></a> filled French screens with space corsairs, robotic heroes, and mythological remixes set in futuristic worlds. Their themes were packed with synths, arpeggiators, and digitized voices—sounds that now echo, with a grown-up edge, in the textures of <strong>French Touch</strong> music.</p><p>At the same time, France was pushing into the future: science museums, open-air <a href="https://www.youtube.com/watch?v=NRO2EtDQ_nA&amp;ref=thoughts-and-things.ghost.io">electronic concerts by pioneers like <strong>Jean-Michel Jarre</strong></a>, and a sense that the 21st century was just around the corner. Yet beneath that techno-utopian veneer, cities like Paris remained gritty and raw. That tension—between the shiny and the grimy—runs deep in the DNA of <strong>French Touch</strong>. You hear it, especially in the darker, distorted edges of <strong>Justice</strong> and <strong>Kavinsky</strong>.</p><p>Let's also not forget the artists who laid the groundwork long before the <strong>French Touch</strong> became a thing. Quirky French electronic pioneers like <a href="https://www.youtube.com/watch?v=Gv3wVHiqP9g&amp;ref=thoughts-and-things.ghost.io"><strong>Jacno</strong></a>, the retro-futurist charm of <a href="https://www.youtube.com/watch?v=6OpnRuooGfw&amp;ref=thoughts-and-things.ghost.io"><strong>Telex</strong></a> from Belgium, and, of course,<strong> </strong><a href="https://www.youtube.com/watch?v=V-HqE1VdPgA&amp;ref=thoughts-and-things.ghost.io"><strong>Giorgio Moroder</strong></a>, the godfather of <strong>Italo Disco</strong>—all contributed textures, tones, and sensibilities that would echo decades later. Even mainstream pop acts like <a href="https://www.youtube.com/watch?v=sJZ1G0e5bWU&amp;ref=thoughts-and-things.ghost.io"><strong>Lio</strong></a>, <a href="https://www.youtube.com/watch?v=EqeJUGzvnq0&amp;ref=thoughts-and-things.ghost.io"><strong>Étienne Daho</strong></a>, or the orchestral-synth hybrids of <a href="https://www.youtube.com/watch?v=Y4FrnrD7jCA&amp;ref=thoughts-and-things.ghost.io"><strong>Rondo Veneziano</strong></a> were constantly spinning on French FM radio, which in the '80s was a chaotic, genre-blurring space. This eclectic mix quietly wired an entire generation of young listeners with an appetite for melody, groove, and synthetic textures—key ingredients in what would later become <strong>French Touch</strong>.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/outrun.png" alt="" loading="lazy" width="1536" height="1024" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/outrun.png 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/outrun.png 1000w, https://thoughts-and-things.ghost.io/content/images/2025/04/outrun.png 1536w" sizes="(min-width: 720px) 720px"><figcaption><span>Outrun never looked as good as in your dreams</span></figcaption></figure><p>There's also a certain <em>California dreamin</em>g that runs through much of <strong>French Touch</strong>. The imagery of Los Angeles—<em>endless boulevards flanked by towering palm trees and that golden sunset light</em>—is a romanticized vision of America that influenced the aesthetic, especially in later works. This fusion of European electronic sensibilities with American dream imagery created something uniquely transportive.</p><p>What started as a movement became a signature sound: <em>nostalgic, futuristic, cinematic, dirty, emotional.</em></p><h2 id="why-it-was-so-hard-to-recreate">Why It Was So Hard to Recreate</h2><p>Part of what makes <strong>French Touch</strong> so compelling is also what makes it hard to replicate today. Those<em> lush, imperfect textures</em> weren't just stylistic choices—they were the natural result of a specific time, place, and set of tools. Many of these tracks were recorded in a single take, often in cramped Parisian apartments or modest studios, using vintage analog gear and early digital samplers.</p><p>There's a rawness and spontaneity to that process. The <em>hiss of a dusty synth</em>, the <em>unquantized groove of a looped disco break</em>, the warmth of <em>tape compression</em>—all of it baked into the DNA of those tracks. Today’s high-resolution digital tools are often too clean, too precise. When you remove the imperfections, you also risk scrubbing out the soul.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg" alt="" loading="lazy" width="2000" height="1125" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 2364w" sizes="(min-width: 720px) 720px"><figcaption><span>The Ableton Live's session</span></figcaption></figure><p>So when I set out to recreate <em>Something About Us</em> using modern software, I knew that recreating this track would be more than just copying notes or layering samples—I’d have to <em>chase a feeling</em>.</p><h2 id="the-keys">The Keys</h2><p>In the original track, the keyboard part is likely played on a <a href="https://en.wikipedia.org/wiki/Wurlitzer_electronic_piano?ref=thoughts-and-things.ghost.io"><strong>Wurlitzer</strong></a><strong> electric piano</strong>—its <em>signature bite and warmth</em> are unmistakable. For my version, I opted for something slightly different: a warmer, more rounded tone using the excellent <a href="https://www.skystudiosplugins.com/?ref=thoughts-and-things.ghost.io"><strong>S.K.Y.&nbsp;Keys plugin</strong></a>, specifically the <em>Everything Right</em> preset. It doesn't try to mimic the original exactly but brings a vibe that fits the song's emotional core.</p><p>I kept the processing minimal: just a gentle midrange boost (mainly to make the part shine a bit more on <a href="https://en.wikipedia.org/wiki/Smiley_face_curve?ref=thoughts-and-things.ghost.io"><strong>AirPods</strong></a>), a touch of Ableton's stock <strong>Vinyl Distortion</strong> for added warmth, and <strong>side-chain compression</strong> tied to the kick for subtle movement in the mix. After the intro section, I remove the bass note from the keys to carve out space for the actual bassline to enter cleanly.</p><p>Here's what that part sounds like, dry and uncompressed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/keys_thumb.png" alt="audio-thumbnail"></p></div><h2 id="drums">Drums</h2><p>The drum part in <em>Something About Us</em> is deceptively simple. For this project, I built a custom kit: the <strong>kick</strong> comes from a <a href="https://en.wikipedia.org/wiki/Roland_TR-505?ref=thoughts-and-things.ghost.io"><strong>Roland TR-505</strong></a>, the <strong>closed hi-hats</strong> are from a <a href="https://en.wikipedia.org/wiki/Roland_TR-808?ref=thoughts-and-things.ghost.io"><strong>TR-808</strong></a>, and I kept the <strong>open hi-hat</strong> from the stock<strong> TR-505</strong> sounds. It’s a classic combo that delivers the crisp, laid-back groove the track needs.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1131-1.jpeg" alt="" loading="lazy" width="2000" height="1381" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/IMG_1131-1.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/IMG_1131-1.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/IMG_1131-1.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1131-1.jpeg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>My Arturia Beatstep Pro</span></figcaption></figure><p>Now—the <strong>snare</strong>. This one was tough. I spent a long time trying to recreate it, convinced it was a processed acoustic snare layered with something synthetic. After too many failed attempts, I caved and sampled the original. Yes, the snare is the only part I couldn’t fully replicate.</p><p>To isolate it, I used an AI stem-splitting tool called <a href="https://www.landr.com/plugins/landr-stems?ref=thoughts-and-things.ghost.io"><strong>LANDR Stems</strong>,</a> which did a surprisingly clean job of pulling the drum track apart from the rest of the mix.</p><p>Here's the full drum pattern:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Drums_thumb.png" alt="audio-thumbnail"></p></div><p>Here's the final snare sample, isolated:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Snare_thumb.png" alt="audio-thumbnail"></p></div><p>In terms of processing, I applied <strong>compression</strong> to give the groove some punch and then ran the whole drum track through a <strong>tape emulation</strong> plugin (<a href="https://www.ikmultimedia.com/products/trtapemac24/?ref=thoughts-and-things.ghost.io"><strong>Tape Machine 24</strong></a> from IK Multimedia) to smooth out the transients and give it that slightly worn-in warmth.</p><h2 id="bassline">Bassline</h2><p>Like the drums, the bassline in <em>Something About Us</em> is incredibly minimal—just a straightforward <strong>octave pattern</strong>, no ghost notes. It's tightly quantized and split across two layers that work together to form the full tone.</p><p>The <strong>low octave</strong> is a simple synth—nothing fancy. I used Ableton's stock <strong>Operator</strong> with the <em>Guitar Bass</em> preset as a starting point. A bit of EQ boosts the low mids and rolls off everything below 40Hz, and it sits nicely in the mix.</p><p>The <strong>high octave</strong>, on the other hand, comes from a sampled electric bass. I recorded a single plucked note on my own bass, loaded it into <strong>Simpler</strong>, activated Warping, and that was enough to get the right texture.</p><p>I grouped both tracks and ran them through a <strong>Glue Compressor</strong>, side-chained to the drum track for a bit of breathing and bounce. It's clean, tight, and fits under the keys without stepping on anything.</p><p>Here's the bassline coupled with drums:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Drums-and-Bass_thumb.png" alt="audio-thumbnail"></p></div><p>Here's the bassline soloed.</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Bass_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-cocotte">The Cocotte</h2><p>One of the more unique textures in <em>Something About Us</em> is what we in France call a <em>"cocotte"</em>—a muted, rhythmic funk guitar riff, aka <strong>chicken guitar</strong>. In this case, it's processed through a <strong>Talkbox</strong>, which gives it that vocal, filtered tone.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 2048w" sizes="(min-width: 720px) 720px"><figcaption><span>My old, beaten Talkbox</span></figcaption></figure><p>If you're unfamiliar with a <strong>Talkbox</strong>, it's essentially a tiny speaker pushing sound through a plastic tube into your mouth. You shape the sound using your mouth movements, almost like playing a <em>mouth harp</em>, and that modulated sound is then picked up by a microphone. It's been famously used by artists like <a href="https://youtu.be/L_CBZkd2tGE?t=31&amp;ref=thoughts-and-things.ghost.io"><strong>Zapp &amp; Roger</strong></a>, <a href="https://www.youtube.com/watch?v=-c3N_0a_WJc&amp;ref=thoughts-and-things.ghost.io"><strong>Stevie Wonder</strong></a>, and of course, <strong>Daft Punk</strong>.</p><p>I must admit something: while I consider <strong>Daft Punk's</strong> first two albums absolute masterpieces, I've never been a huge fan of their guitar tones—especially their later collaborations with <strong>Nile Rodgers</strong>. There's nothing technically wrong with them, but I prefer funk guitars that are punchier, more percussive, and full-bodied. <a href="https://www.youtube.com/watch?v=FtzBduHNol8&amp;ref=thoughts-and-things.ghost.io"><strong>Yarol Poupaud’s</strong></a> work with <strong>FFF</strong> is more my jam—or, even closer to home, <a href="https://www.youtube.com/watch?v=EzjJQs9jHBY&amp;ref=thoughts-and-things.ghost.io"><strong>Nicolas Bogue</strong></a>, <strong>Breakbot's</strong> guitarist, who taught me everything I know about <strong>funk guitar</strong> when I was a teenager.</p><p>In <em>Something About Us,</em> the cocotte is very subdued—the ghost notes are barely there, almost unnaturally so. That may have been intentional, but I wanted to bring a little more texture and bounce into my version.</p><p>I recorded the part using a <strong>Les Paul</strong> through <a href="https://www.native-instruments.com/en/products/komplete/guitar/guitar-rig-7-pro/amps-and-cabinets/?ref=thoughts-and-things.ghost.io"><strong>Guitar Rig's</strong></a><strong> "High White"</strong> amp sim (a <strong>Hiwatt</strong> emulation), with a touch of cabinet (around 5%) to keep it from sounding too boxy. The space and depth come mostly from reverb, sent through a bus using <a href="https://www.wavealchemy.co.uk/product/magic7/?ref=thoughts-and-things.ghost.io"><strong>Wave Alchemy's Magic 7</strong></a> (a lush emulation of the <a href="https://www.bricasti.com/en/pro/m7.php?ref=thoughts-and-things.ghost.io"><strong>Bricasti M7</strong></a>).</p><p>Here's the cocotte soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Cocotte_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-wakawak">The Wakawak</h2><p>Okay, I couldn't think of a better name for this one—<em>Wakawak</em> just fits. It's a synthetic take on a trimmed <strong>funk guitar chord</strong>, dripping in <strong>reverb</strong> and slapped with a tightly <strong>synced, panned echo</strong>. It's playful and rhythmic and adds a little magic sparkle in the background.</p><p>This sound was one of the trickiest to get right. It took quite a bit of back-and-forth. At its core, it's a <strong>synth patch</strong> designed to mimic that snappy, vocal-like quality you'd get from a well-timed guitar chop.</p><p>The patch starts with a simple waveform in Ableton Live's <strong>Wavetable</strong>, shaped by a smooth, triangle-like <strong>LFO</strong> that modulates both the amplitude and filter cutoff frequency, creating the signature pulsing movement. To add a bit more funk character, I ran it through an <strong>envelope filter stompbox</strong> emulation, which gave it a gritty, slightly overdriven sweep—more like a dusty analog auto-wah you'd find on an old pedalboard than a pristine digital effect.</p><p>The spacey vibe comes from a stock Ableton <strong>Delay</strong> on a send bus, <strong>panned hard right</strong> and set to <strong>tempo-sync</strong>. Tons of reverb helps it blend into the background without losing presence.</p><p>Here's the Wakawaka soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Wakawaka_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-theme">The Theme</h2><p>This lead sound—<em>silly, playful, and deceptively simple</em>—was surprisingly difficult to pin down. After quite a bit of experimenting, I landed on something pretty close using <a href="https://www.arturia.com/products/software-instruments/jun-6-v/overview?ref=thoughts-and-things.ghost.io"><strong>Arturia's Jun-6V</strong></a>, their emulation of the iconic <a href="https://en.wikipedia.org/wiki/Roland_Juno-60?ref=thoughts-and-things.ghost.io"><strong>Roland Juno-6</strong></a>.</p><p>That<em> soft, rubbery tone</em> with just a hint of analog instability is key to the emotional feel of <em>Something About Us</em>. While you can approximate it using Ableton Live's <strong>Operator</strong> with the <em>Analog Bouquet</em> preset, it still lacks the warmth and nuance of a proper analog emulation.</p><p>Here's the theme soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Theme_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-guitar-solo">The Guitar Solo</h2><p>The <em>silky, melancholic guitar solo</em> is one of the emotional peaks of <em>Something About Us</em>. While I can't say for sure, I'd wager the original was played on a <strong>hollow or semi-hollow body guitar</strong>—you can hear that smooth resonance and airy tone in the phrasing.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1128.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/IMG_1128.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/IMG_1128.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/IMG_1128.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/size/w2400/2025/04/IMG_1128.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>My humble Honey burst Les Paul ❤️</span></figcaption></figure><p>For my version, I recorded the solo <em>ad-lib</em> on my <strong>Les Paul</strong>, and I was lucky enough to stumble upon a preset in <strong>Guitar Rig</strong> that felt just right. I gave it a few subtle tweaks, adding in simulated hum and noise via the <strong>Noise Machine</strong> rack to inject a bit of vintage character and imperfection.</p><p>I ran it through a <strong>compressor</strong> to even out dynamics and used <strong>Raum</strong>, also in <strong>Guitar Rig</strong>, for some warm, spacey reverb that lets the notes breathe without feeling too polished.</p><p>Here's the guitar solo (with the keys):</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Solo_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-vocals">The Vocals</h2><h3 id="lead">Lead</h3><p>Ah yes—the vocals. Now<em> that's</em> a big one. First, I genuinely believe you can't fully replicate the vocal texture of the original unless you're <em>slightly sick</em>—it's got that warm, congested, <strong>Vick Vaporub feel</strong>.</p><p>I tried a few approaches, including a <strong>vocoder</strong>, but it ended up sounding too synthetic. Even with careful dry/wet blending, it was either too robotic or too clean—and in both cases, it lost clarity.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1129.jpeg" alt="" loading="lazy" width="2000" height="2000" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/IMG_1129.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/IMG_1129.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/IMG_1129.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/size/w2400/2025/04/IMG_1129.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>A dreamy vocal booth</span></figcaption></figure><p>In the end, I went with a more organic solution: I tracked the vocals in my apartment in the Mission, San Francisco, and used Ableton's <strong>Auto Filter</strong> to sculpt the tone dynamically. I automated the filter to <strong>gradually open</strong> during the second half of each phrase, and <strong>close it sharply</strong> at the start of the next one—giving the vocal that breathing, evolving texture. I also played around with the filter automation on specific words like<em> "do"</em> and <em>"you"</em> in the phrase <em>"I've got to do/share with you."</em> It's not perfect, but it captures the vibe.</p><h3 id="harmonies">Harmonies</h3><p>There's a beautiful, super-typical Daft Punk harmony on <em>"right one"</em> and <em>"right time"</em> in the second verse—possibly vocoded in the original. It took me a while to figure out the voicings (I'm no music theory wizard), but after some trial and error, I got something I'm really happy with. <em>"Right one"</em> might still be a little off, but I think I nailed <em>"right time"</em>—and let's be honest, that's <strong>the pretty one</strong>.</p><p>I filtered the harmonies using <strong>Auto Filter</strong> again, bounced them down to a stereo track, and used the <em>Wide Stereo</em> preset in Ableton's <strong>Utility</strong> plugin to give them that spread. Add a bit of <strong>Magic 7 reverb</strong> on a bus, and boom—they melt right into the mix.</p><p>Here are the harmonies soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Harmonies_thumb.png" alt="audio-thumbnail"></p></div><p>Here they are with the lead vocals:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Harmonies-and-Main_thumb.png" alt="audio-thumbnail"></p></div><h3 id="vocoder">Vocoder</h3><p>For the final section, I went <em>full robot</em>. I used a stock <strong>Operator</strong> synth as the carrier, routed it into Ableton's stock <strong>Vocoder</strong>, and processed the output with a <strong>high-pass filter</strong> and the <strong>Chorus-Ensemble</strong> plugin to give it more dimension and movement.</p><p>The vocoder is mixed in with the dry vocal until the balance feels just right—enough to sound synthetic but emotionally grounded. Basically, it ends up sounding like <em>a little robot backing me up with its heart on its sleeve.</em></p><p>Here's the vocoder soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Vocoder_thumb.png" alt="audio-thumbnail"></p></div><p>And here's the vocoder blended with the lead:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Vocoder-and-Main_thumb.png" alt="audio-thumbnail"></p></div><h2 id="from-paris-to-san-francisco-a-personal-note">From Paris to San Francisco: A Personal Note</h2><p>This project was as much about nostalgia as it was about production techniques. Born and raised in <strong>Paris in the '80s</strong>, I grew up surrounded by the cultural influences that would eventually shape <strong>French Touch</strong>. Now, having lived in California for the past seven years, reconstructing this track felt like building a <em>sonic bridge</em> between my past and present.</p><p>This recreation isn't perfect—nor was it meant to be. It's a <em>personal interpretation</em> filtered through my musical sensibilities and the tools available to me. What mattered more than technical precision was <em>capturing the emotional essence</em> that made the original so affecting.</p><p>A huge part of the joy came from working in <strong>Ableton Live 12</strong>, which now feels like an extension of how I think:</p><ul><li>The <strong>keyboard shortcuts</strong> and editing feel almost like using a great text editor—<strong>Sublime Text</strong> for music.</li><li><strong>Audio editing</strong> has improved dramatically. Where <a href="https://www.avid.com/pro-tools?ref=thoughts-and-things.ghost.io" rel="noreferrer"><strong>Pro Tools</strong></a> was once the undisputed champion, it now feels more like <a href="https://www.barebones.com/products/bbedit/?ref=thoughts-and-things.ghost.io"><strong>BBEdit</strong></a>. Still powerful, but clunky. <a href="https://www.apple.com/logic-pro/?ref=thoughts-and-things.ghost.io"><strong>Logic</strong></a>, meanwhile, still lags behind.</li><li>The <strong>stock effects</strong> and instruments are incredibly well-designed. The built-in <strong>Sampler</strong> and <strong>Wavetable</strong> synths are top-notch. For certain sounds, sure, I still reach for plugins (especially analog emulations like <strong>Arturia’s</strong>), but the native tools are more than enough to create something great.</li><li>Every module shares a <strong>consistent user interface</strong>, which really helps you stay in the flow.</li><li><strong>It’s <em>fast</em>.</strong> Projects load quickly, startup is near-instant, and it handles plugins like a champ. (Seriously, how does Logic still take so long?)</li><li>Even under load, <strong>Live</strong> stays snappy. It never gets in the way of the creative process.</li><li>The <strong>Drum Rack</strong> is beautifully intuitive—a joy to use and <em>miles ahead</em> of <strong>Logic’s</strong> equivalent.</li></ul><p>After bouncing the session, I moved to <a href="https://www.ikmultimedia.com/products/tr6/?ref=thoughts-and-things.ghost.io"><strong>T-Racks</strong></a> for mastering, putting the final polish on a project that was as educational as it was enjoyable.</p><p>This is a personal interpretation, not a definitive one. But I <em>hope you enjoyed reading it</em>, and maybe even listening along&nbsp;❤️</p><p>Here's my <a href="https://marca.fyi/?ref=thoughts-and-things.ghost.io" rel="noreferrer">personal page</a> and my <a href="https://www.instagram.com/marcatatem/?ref=thoughts-and-things.ghost.io" rel="noreferrer">Instagram account</a>.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: OCR pipeline for ML training (tables, diagrams, math, multilingual) (154 pts)]]></title>
            <link>https://github.com/ses4255/Versatile-OCR-Program</link>
            <guid>43590998</guid>
            <pubDate>Sat, 05 Apr 2025 05:22:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ses4255/Versatile-OCR-Program">https://github.com/ses4255/Versatile-OCR-Program</a>, See on <a href="https://news.ycombinator.com/item?id=43590998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">OCR System Optimized for Machine Learning: Figures, Diagrams, Tables, Math &amp; Multilingual Text</h2><a id="user-content-ocr-system-optimized-for-machine-learning-figures-diagrams-tables-math--multilingual-text" aria-label="Permalink: OCR System Optimized for Machine Learning: Figures, Diagrams, Tables, Math &amp; Multilingual Text" href="#ocr-system-optimized-for-machine-learning-figures-diagrams-tables-math--multilingual-text"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">This OCR system is specifically designed to extract structured data from complex educational materials—such as exam papers—in a format optimized for machine learning (ML) training.
It supports multilingual text, mathematical formulas, tables, diagrams, and charts, making it ideal for creating high-quality training datasets.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<p dir="auto">– Optimized for ML Training: Extracted elements such as diagrams, tables, and figures are semantically annotated with contextual explanations.
This includes automatic generation of natural language descriptions for visual content (e.g., “This figure shows the process of mitosis in four stages”) to enhance downstream model training.</p>
<p dir="auto">– Multilingual Support: Works with Japanese, Korean, and English, and can be easily customized for additional languages.</p>
<p dir="auto">– Structured Output: Generates AI-ready outputs in JSON or Markdown, including human-readable descriptions of mathematical expressions, table summaries, and figure captions.</p>
<p dir="auto">– High Accuracy: Achieves over 90–95% accuracy on real-world academic datasets such as EJU Biology and UTokyo Math.</p>
<p dir="auto">– Complex Layout Support: Accurately processes exam-style PDFs with dense scientific content, formula-heavy paragraphs, and rich visual elements.</p>
<p dir="auto">– Built With: DocLayout-YOLO, Google Vision API, Gemini Pro Vision, MathPix OCR, OpenAI API, OpenCV, and more.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sample Outputs</h2><a id="user-content-sample-outputs" aria-label="Permalink: Sample Outputs" href="#sample-outputs"></a></p>
<p dir="auto">Below are actual examples of outputs generated by this system using real-world materials (2017 EJU Biology &amp; 2014 University of Tokyo Math), including English-translated semantic context and extracted data.</p>
<p dir="auto"><strong>Math Input</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Math_Original.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Math_Original.jpeg" alt="Math Original"></a>
<strong>Output</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Math_Converted.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Math_Converted.jpeg" alt="Math Converted"></a></p>
<p dir="auto"><strong>English-translated outputs</strong></p>
<p dir="auto">Question 1. Consider the rectangular prism OABC–DEFG with a square base of side length 1. Points P, Q, R are on the segments AE, BF, and CG, respectively, and four points O, P, Q, and R lie on the same plane. Let S be the area of quadrilateral OPQR. Also, let ∠AOP be α and ∠COR be β. (2) If α + β = 1 and S = S, find the value of tan α + tan β. Also, if α ≤ β, find the value of tan α.</p>
<p dir="auto">[Image Start]</p>
<p dir="auto">Image description:
This image shows the rectangular prism OAB–CDEFGQ. Each vertex is labeled with alphabets. The angle α is marked on face OAB. The plane ORPQ intersects the prism and is highlighted. Line RC lies on face ODCG, and line PB lies on face ABFQ.</p>
<p dir="auto">Educational value:
This image enhances spatial reasoning by visualizing 3D geometry and cross-sections. It helps learners understand concepts such as plane geometry, solid shapes, spatial visualization, and angles.</p>
<p dir="auto">Related topics:
Solid geometry, cross-sections, prism faces, triangle, spatial reasoning</p>
<p dir="auto">Exam relevance:
This type of question appears in entrance exams like:</p>
<ol dir="auto">
<li>Calculate the area of ORPQ using angle α</li>
<li>Find the lengths of OR, RP, PQ, QO</li>
<li>Determine the angle between ORPQ and the prism's face</li>
<li>Locate points P, Q, R in coordinate space</li>
<li>Calculate volume/area of the prism parts</li>
<li>Predict shapes based on constraints</li>
<li>Sketch the shape of the prism</li>
</ol>
<p dir="auto">[Image End]</p>
<p dir="auto"><strong>Biology Input</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Biology_Original.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Biology_Original.jpeg" alt="Biology Original"></a>
<strong>Output</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Biology_Converted.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Biology_Converted.jpeg" alt="Biology Converted"></a></p>
<p dir="auto"><strong>English-translated outputs</strong></p>
<p dir="auto">Question 39. The photo shows the mitotic cell division process (somatic cell division) of an onion root tip. Cells A–D are in different stages of division. Match the stages (prophase, metaphase, anaphase, telophase) to each cell and select the correct combination from options ①–⑧.</p>
<p dir="auto">[Image Start]</p>
<p dir="auto">Image description:
This image shows the process of plant cell division observed under a microscope. Various cells are in different mitotic phases, including chromosomes aligned at the center (metaphase), separating to poles (anaphase), or forming daughter nuclei (telophase).</p>
<p dir="auto">A – appears to be in anaphase<br>
B – possibly telophase<br>
C – prophase or prometaphase<br>
D – metaphase</p>
<p dir="auto">Educational value:
This helps students visually understand the process of mitosis, reinforcing knowledge of cell division phases and their characteristics. It connects to biology concepts like DNA replication, cancer biology, and genetics.</p>
<p dir="auto">Related topics:
Mitosis, Cell cycle, Prophase, Metaphase, Anaphase, Telophase, DNA replication</p>
<p dir="auto">Exam relevance:
This image is used in questions such as:</p>
<ol dir="auto">
<li>Match A, B, C, D to appropriate mitotic phases</li>
<li>Describe characteristics of each phase</li>
<li>Explain the significance of mitosis</li>
<li>Discuss how errors in mitosis lead to genetic diseases</li>
</ol>
<p dir="auto">[Image End]</p>
<p dir="auto">[Table Start]</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>前期</th>
<th>中期</th>
<th>後期</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>C</td>
<td>D</td>
</tr>
<tr>
<td>A</td>
<td>D</td>
<td>B</td>
</tr>
<tr>
<td>B</td>
<td>C</td>
<td>C</td>
</tr>
<tr>
<td>B</td>
<td>D</td>
<td>C</td>
</tr>
<tr>
<td>C</td>
<td>A</td>
<td>D</td>
</tr>
<tr>
<td>C</td>
<td>D</td>
<td>A</td>
</tr>
<tr>
<td>D</td>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td>D</td>
<td>C</td>
<td>A</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Summary:
Each option (①–⑧) corresponds to a specific mapping of A, B, C, D to prophase, metaphase, and anaphase.</p>
<p dir="auto">Educational value:
Understanding time-based transition in mitosis and data organization in tables. Enhances data interpretation, pattern recognition, and analysis skills.</p>
<p dir="auto">Related topics:
Data analysis, table interpretation, biological data classification</p>
<p dir="auto">[Table End]</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage Workflow</h2><a id="user-content-usage-workflow" aria-label="Permalink: Usage Workflow" href="#usage-workflow"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Step 1 – Initial OCR Extraction
Run ocr_stage1.py to extract raw elements (text, tables, figures, etc.) from input PDFs.
This step performs layout detection and stores intermediate results (e.g., coordinates, cropped images, raw content).</p>
</li>
<li>
<p dir="auto">Step 2 – Semantic Interpretation &amp; Final Output
Run ocr_stage2.py to process the intermediate data and convert it into structured, human-readable output.
This includes generating natural-language explanations, summaries, and organizing content into AI-ready formats (JSON/Markdown).</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical Implementation</h2><a id="user-content-technical-implementation" aria-label="Permalink: Technical Implementation" href="#technical-implementation"></a></p>
<p dir="auto">– Table Processing OptimizationTable regions are detected using DocLayout-YOLO</p>
<p dir="auto">– Google Vision OCR is used for table processing instead of MathPix for better accuracy with Japanese text</p>
<p dir="auto">– Table structures are preserved in structured JSON format (maintaining row/column structure)</p>
<p dir="auto">– Y-coordinate information is maintained to ensure contextual continuity</p>
<p dir="auto">– Original layout information is preserved alongside structured data for ML training</p>
<p dir="auto">– Image and Special Region ProcessingImage regions are processed using Google Vision API's image analysis features (imageProperties, labelDetection, textDetection)</p>
<p dir="auto">– Image descriptions are generated using Google Cloud Vision API</p>
<p dir="auto">– Graphs/charts are processed using Google Cloud Vision API's document analysis features with data point extraction</p>
<p dir="auto">– Special region processing results are stored in structured JSON format for ML training</p>
<p dir="auto">– Original coordinate information and region type metadata are added to maintain contextual continuity</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Purpose and Contact</h2><a id="user-content-purpose-and-contact" aria-label="Permalink: Purpose and Contact" href="#purpose-and-contact"></a></p>
<p dir="auto">This OCR system is an open project, and I’d love to see others improve or build upon it. Continuous updates and community-driven enhancements are the goal.</p>
<p dir="auto">If you’re interested in custom AI tools or would like to collaborate on an AI-related project, feel free to reach out via email:</p>
<p dir="auto"><strong>Email</strong>: <a href="mailto:ses425500000@gmail.com">ses425500000@gmail.com</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the <strong>MIT License</strong>.<br>
You are free to use, modify, distribute, and sublicense this software for any purpose, including commercial use.</p>
<p dir="auto">See the <a href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/LICENSE">LICENSE</a> file for full terms.
⸻
<em>Note: The English translations in the examples were manually reformatted for clarity and consistency. Please treat them as reference only, as structure and layout may differ slightly from the original.</em>
_Keywords: OCR, exam OCR, table recognition, diagram OCR, AI education tools, OpenAI, Gemini Pro Vision, multilingual OCR, DocLayout-YOLO, Machine Learning, educational ML dataset, research OCR, paper OCR, document AI</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>