<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 13 Jul 2024 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: I made a drag and drop CSS grid generator (146 pts)]]></title>
            <link>https://cssgridgenerator.io/</link>
            <guid>40952509</guid>
            <pubDate>Sat, 13 Jul 2024 07:44:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cssgridgenerator.io/">https://cssgridgenerator.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40952509">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>CSS grid generator is a tool that helps developers create custom CSS grid layouts more easily. The generator allows users to specify the number of columns, rows, the gutter size.</p><div><h2>How to use CSS grid generator?</h2><ul><li><span>1.</span> Customize the number of columns, rows, and gaps to fit your needs.</li><li><span>2.</span> Click the square with + sign to add a new element to the grid.</li><li><span>3.</span> Resize the DIV using the<!-- --> <b>handle in the bottom right corner.</b></li><li><span>4.</span> Drag and drop the DIV to reposition it as desired.</li><li><span>5.</span> Finally, copy the generated HTML and CSS code and paste it into your project.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ad-tech setting 'Privacy-Preserving Attribution' is opt-out in Firefox 128 (134 pts)]]></title>
            <link>https://gladtech.social/@cuchaz/112775302929069283</link>
            <guid>40952330</guid>
            <pubDate>Sat, 13 Jul 2024 06:56:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gladtech.social/@cuchaz/112775302929069283">https://gladtech.social/@cuchaz/112775302929069283</a>, See on <a href="https://news.ycombinator.com/item?id=40952330">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Introduction to Calvin and Hobbes: Sunday Pages 1985-1995 (2001) (165 pts)]]></title>
            <link>http://timhulsizer.com/cwords/cintro.html</link>
            <guid>40951800</guid>
            <pubDate>Sat, 13 Jul 2024 04:37:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://timhulsizer.com/cwords/cintro.html">http://timhulsizer.com/cwords/cintro.html</a>, See on <a href="https://news.ycombinator.com/item?id=40951800">Hacker News</a></p>
<div id="readability-page-1" class="page">

<b>
<center>
Back To the <a href="http://timhulsizer.com/cwords/calvin.html">Calvin &amp; Hobbes Page</a><br>
Back To the <a href="http://timhulsizer.com/cwords/cbooks.html">C&amp;H Books Page</a><br>
Back To the <a href="http://timhulsizer.com/cwords/index.html">Main Page</a><br>

<hr>

<h3>Introduction</h3>
<b>By Bill Watterson (C)2001
</b><p>From the book, "Calvin and Hobbes - Sunday Pages 1985 - 1995"</p></center>

</b>

<p>It's been five years since the end of <i>Calvin and Hobbes</i>, 
 the longest time I can remember in which I haven't drawn cartoons. 
 <i>Calvin and Hobbes</i> was a wonderful experience, but it was an 
 all-consuming career. When I quit the strip, I put my cartoons in 
 boxes, and jumped into other interests. I haven't really considered 
 the strip since, so at the invitation to do this show, I thought 
 it might be time to look back at some of my work. 

</p><p>My first reaction in going through my old cartoons was some 
 amazement at the size and weight of the pile. For most successful 
 comic strips, ten years is just a drop in the bucket, but even that 
 amount of time yields a huge amount of material. It's no wonder 
 that decade seems like a blur. 

</p><p>Going through my old strips is sort of like looking at old 
 photographs of myself: they're personal and familiar, yet somewhat 
 bizarre at the same time. There are cartoons I've drawn that are 
 the equivalent of pictures of my younger self wearing yellow 
 pants: I know I'm responsible for that, but what on earth was I 
 thinking? As my tastes have changed, and as I've learned more, I 
 imagine that I would do many strips quite differently today. Not 
 better necessarily, but certainly differently. I was twenty-eight 
 when <i>Calvin and Hobbes</i> was first published, and, of course, I would 
 make other choices now at age forty-three. 

</p><p>It's also sort of strange to see a record of my own learning 
 curve. Pick up a given strip, and I see how I struggled with 
 various writing and drawing problems, or how I finally surmounted 
 one. I remember sometimes feeling that the strip was better written 
 than I could actually write, and better drawn than I could actually 
 draw. I learned a great deal over the years by trying to push the 
 strip beyond my own abilities, and I'm very proud that <i>Calvin and 
 Hobbes</i> explored and developed all the way to the end. By the final 
 years, I see naturalness or a sense of inevitability to the drawing 
 and writing that is very satisfying. 


</p><p>I'm more appreciative of this kind of grace since returning to 
 the awkward stages of new learning curves. Of course, I'd also say 
 the times have caught up with some of my strips. It's frankly a 
 little discouraging to see how ordinary some of them look now. When 
 <i>Calvin and Hobbes</i> first appeared, it was somewhat surprising to 
 treat reality as subjective, and to draw a strip with multiple 
 viewpoints, juxtaposing Calvin's vision with what others saw. I did  
 this simply as a way to put the reader in Calvin's head and to 
 reveal his imaginative personality. Now these juxtapositions are a 
 visual game for many comic strips, and after all these years, I 
 suspect readers know where this sort of joke is headed as soon as 
 they see it. The novelty cannot be recaptured. 

</p><p>Novelty, however, is probably overrated anyway. The <i>Calvin and 
 Hobbes</i> strips that hold up best, to my eye anyway, are the ones 
 where the characters seem big, vivid, and full of life, and where 
 the strip's world seems genuine and inviting. Punchlines come and 
 go, but something in the friendship between Calvin and Hobbes seems  
 to hold a small piece of truth. Expressing something real and 
 honest is, for me, the joy and the importance of cartooning. 

</p><p>The Sunday strips were usually the cartoons I had the most fun 
 with, and for this show I've chosen a few Sunday strips from each 
 year that I think show off the strip's strengths. 

</p><p>I have fond memories of reading the Sunday comics when I was a 
 kid. As far as I was concerned, the Sunday comics were the whole 
 reason for newspapers to exist. On weekdays, I read only the strips 
 I liked; but on Sundays, I read them all, and often several times. 
 The Sunday comics were always the most fun to look at, so when I 
 finally got the chance to draw my own comic strip, I knew I wanted 
 to make the Sunday Calvin and Hobbes something special. It took me 
 a little while to learn to use the larger Sunday space effectively. 
 It requires a somewhat different pace for the humor, and, of 
 course, a big color panel is no place to find out that you don't 
 know how to draw the back of your character's head. The Sunday 
 strip shows off both strengths and weaknesses. 

</p><p>Occasionally I would see that an idea I'd written for a Sunday 
 strip was not as substantial as I'd hoped it would be, and I'd 
 realize that some of the panels and dialogue weren't adding 
 anything significant to the story. If that were the case, I'd 
 remove everything extraneous and use the trimmed idea for a daily 
 strip instead. I held the Sundays to a different standard: any idea 
 for the Sunday strip had to need the extra space. I felt a Sunday 
 strip should do something that was impossible the rest of the week. 

</p><p>Over the years, I learned that daily strips are better suited for 
 certain kinds of ideas, while Sunday strips are better for others. 
 The daily strip is quick and to the point, perfect for a simple 
 observation, or a short exchange between characters. Daily strips 
 are also better for long stories, where a certain suspense can be 
 fostered by continuing the story day after day, and the reader can 
 remember what happened previously. 

</p><p>Extended conversations with real back and forth dialogue, however, 
 don't work very well in four tiny panels - the dialogue balloons 
 crowd out the drawings and the strip loses its grace. In a Sunday 
 strip, you can spread out, and let the characters yap a bit. This 
 is often funny in itself, and it's a wonderful way to let the 
 characters' personalities emerge. It also lets you explore a topic 
 a bit more fully. 

</p><p>You can talk about things without reducing them to one-liners 
 right away. And, of course, in today's minuscule comics, if an idea 
 requires any real drawing, the Sunday strip is the only possible 
 place for it. Likewise, any complex storytelling problem-a strip 
 illustrating a long expanse of time, for example, or an event 
 depicted in a succession of very tiny moments-is futile in the 
 daily format. Calvin's fantasies generally migrated to the Sunday 
 page for this reason. 

</p><p>In short, the Sunday page offered unique opportunities, and I 
 deliberately tried to come up with ideas that could take advantage 
 of them. 

</p><p>I usually wrote the Sunday strips separately from the dailies. 
 For the daily strips, I tried to write an entire month's worth of 
 ideas before inking any of them. This allowed a long period for 
 editing and rewriting. I was less able to do this for the Sunday 
 strips because the Sundays need to be drawn weeks further in 
 advance and because the strips took so much longer to draw. If at 
 all possible, however, I would try to keep two or three Sunday 
 ideas ahead of the deadlines. I always wanted to reserve the option 
 of abandoning an idea that didn't stand up to a few weeks of 
 scrutiny. 

</p><p>For those who are interested in technical matters, the early 
 strips were drawn on any cheap pad of Bristol board the local art 
 supply store happened to stock. The paper was usually rather thin 
 and sometimes the sheet wouldn't accept the ink consistently (bad 
 sizing or something), which would make drawing aggravating and time 
 consuming. Eventually I switched to heavier Strathmore Bristol 
 board, which was much nicer. I used a 2H pencil to rough in the 
 drawing, and then inked with a small sable brush and India ink. I 
 did as little pencil work as possible in order to keep the inking 
 more spontaneous, although the more elaborate panels required more 
 preliminary drawing. For lettering, I used a Rapidograph cartridge 
 pen. I drew the dialogue balloons and a few odds and ends with a 
 crow quill pen. To cover up unwanted marks, I used various brands 
 of Wite-Out, and in the early days, typewriter correction fluid. 
 (Remember typewriters?) No doubt this stuff will eat through the 
 paper or turn green in a few years, but as the original cartoons 
 were intended for reproduction, not picture frames and gallery 
 walls, I did not overly concern myself with archival issues or, for 
 that matter, neatness. At some point along the way, however, I did 
 ask the syndicate to send the printers a quality reproduction of 
 the Sunday cartoon, rather than the original drawing, in order to 
 reduce the amount of tape, registration marks, and general 
 crunchings and manglings to which the drawings had previously been 
 subjected. 

</p><p>Coloring the strips was a slow and tedious process. My 
 syndicate gave me a printed sheet showing numbered squares of color, 
 each a mixture of various percentages of red, yellow, and blue. 
 Using this sheet as a guide, I taped some tracing paper over the 
 finished cartoon, and painted watercolor approximations of the 
 available colors in the areas I wanted. This would give me a very 
 rough idea of what the newspaper version might look like. Then I 
 numbered each little spot of color. As the Sunday strips became 
 more visually complex, and as I started to use color more 
 deliberately for effects, this process became a real chore. These 
 days, I believe much of it can be done with a few clicks of a mouse. 

</p><p>Colors take on different characteristics when placed next to 
 other colors (a neutral-seeming gray might look greenish and dark 
 next to one color, but brownish and pale in relation to another). 
 Because of this, I came up with one little trick for coloring the 
 strip. I cut out each of the color squares provided by the printer, 
 so I had a stack of colors (like paint chips), rather than a sheet. 
 By laying out the cut squares and physically placing one color next 
 to the others I expected to use, I could see exactly how each color 
 behaved in that particular context. As I got better at this, I was 
 able to choose approprial "palettes" for each strip, and create 
 moods with color. One strip might call for contrasting, bright 
 colors; another strip might be done with a limited group of soft, 
 warm colors; another idea might call for a close range of grays and 
 darks, and so on. If I made Calvin's skin a dull pink-gray to 
 suggest dim lighting at night, I would have to find a dull 
 yellow-gray that would suggest his hair in the same light. These 
 challenges took an inordinate amount of time for work on deadline, 
 but I was often quite proud of the results. A comic strip should 
 always be fun to look at, and good use of color can contribute to 
 that appeal More than that, color creates its own emotional impact, 
 which can make the drawing more expressive. 

</p><p>The half-page Sunday format required certain guaranteed panel 
 divisions. The strip had to be drawn in three rows of equal height, 
 and there was one unmovable panel division within each row. This 
 allowed editors to reduce and reconfigure the strip to suit their 
 particular space needs. The same strip could run in several shapes 
 by restacking the panels. 

</p><p>Editors commonly removed the entire top row altogether, so in 
 essence, a third of the strip had to be wasted on "throwaway 
 panels" that many readers would never see. The fixed panel divisions 
 were also annoying because they limited my ability to compose the 
 strip to best suit the idea. For example, they often forced a small 
 panel where I needed more space for words. 

</p><p>Of course, a big part of cartooning is learning to work 
 effectively within tight space constraints. Much of cartooning's 
 power comes from its ability to do more with less: when the 
 drawings and ideas are distilled to their essences, the result can 
 be more beautiful and powerful for having eliminated the clutter. 
 That said, there is a point at which simplification thwarts good 
 storytelling. You can't condense Moby Dick into a paragraph and get 
 the same effect. Over the years, my frustration increased and I 
 became convinced that I could draw a better comic strip than the 
 current newspaper format was permitting. Looking at examples of 
 comics from the 1930s, when a Sunday strip could fill an entire 
 page, I was amazed by the long-forgotten possibilities out there. 

</p><p>I took a sabbatical after resolving a long and emotionally 
 draining fight to prevent <i>Calvin and Hobbes</i> from being 
 merchandised. Looking for a way to rekindle my enthusiasm for the 
 duration of a new contract term, I proposed a redesigned Sunday 
 format that would permit more panel flexibility. To my surprise and 
 delight, Universal responded with an offer to market the strip as 
 an unbreakable half page (more space than I'd dared to ask for), 
 despite the expected resistance of editors. 

</p><p>To this day, my syndicate assures me that some editors liked the 
 new format, appreciated the difference, and were happy to run the 
 larger strip, but I think it's fair to say that this was not the 
 most common reaction. The syndicate had warned me to prepare for 
 numerous cancellations of the Sunday feature, but after a few weeks 
 of dealing with howling, purple-faced editors, the syndicate 
 suggested that papers could reduce the strip to the size tabloid 
 newspapers used for their smaller sheets of paper. Another strip 
 could then run vertically down the side. Consequently, while some 
 papers, primarily in larger markets, ran the strip as a half page, 
 other papers reduced it. In some of the latter papers (including 
 the one I read at the time), I actually lost ground: the new Sunday 
 strip was printed even smaller than before. I was in no mood to 
 take on new fights, so I focused on the bright side: I had complete 
 freedom of design and there were virtually no cancellations. 

</p><p>For all the yelling and screaming by outraged editors, I remain 
 convinced that the larger Sunday strip gave newspapers a better 
 product and made the comics section more fun for readers. Comics 
 are a visual medium. A strip with a lot of drawing can be exciting 
 and add some variety. Proud as I am that I was able to draw a 
 larger strip, I don't expect to see it happen again any time soon. 
 In the newspaper business, space is money, and I suspect most 
 editors would still say that the difference is not worth the cost. 
 Sadly, the situation is a vicious circle: because there's no room 
 for better artwork, the comics are simply drawn; because they're 
 simply drawn, why should they have more room? 

</p><p>Business controversies aside, the new format opened up new ways 
 to tell stories, and I drew different kinds of strips as a result. 
 I could write and draw the strip exactly as I imagined it, so it 
 truly challenged my abilities. Whereas Sunday strips had previously 
 taken me a full day to draw and color, a complex strip would now 
 take me well into a second day to finish. Deadlines discourage this 
 kind of indulgence, and I had to steal that extra time from what 
 would have been some semblance of an ordinary life, but I was 
 thrilled to expand the strip's world. 

</p><p>Laying out the panels became a job in itself, now that I was no 
 longer confined to horizontal rows. could place boxes anywhere and 
 any size, but the reader's eye needs to flow naturally to the 
 proper panels without confusion, and big panels need to be designed 
 in such a way that they don't divert attention and spoil surprises. 
 The graphic needs of each panel must be accommodated and the panels 
 themselves should form a pleasing arrangement so the entire page is 
 attractive, balanced, and unified as well. Here again I looked for 
 guidance in the gorgeous Sunday pages of George Herriman's <i>Krazy Kat.</i>
 
</p><p>The new Sunday format necessitated a change in the format of my 
 book collections as well. Having won a bigger strip in newspapers, 
 I wanted the book reproductions to reflect the strip's new impact 
 as much as possible by printing the Sunday strips large. This 
 resulted in the rather awkward horizontal format of my later books. 
 They stick out of bookshelves, but the strips look nice. From this 
 point on, the Sunday strips were reproduced in color with each 
 collection, not just in the "treasury" collections, as before. 
 (Here's a piece of trivia: because of the timing of the book format 
 change, the cartoons from the <i>Snow Goons</i> collection were 
 never put in a treasury book, so those Sunday strips have been 
 reprinted only in black-and-white.)
 
</p><p>Ten years after starting <i>Calvin and Hobbes</i>, I ended the 
 strip. As much as I knew I'd miss the characters, the decision was 
 long anticipated on my part. Professionally, I had accomplished far 
 more than I'd ever set out to do and there were no more mountains I 
 wanted to climb. Creatively, my interests were shifting away from 
 cartooning toward painting, where I could develop my drawing skills 
 further. And personally, I wanted to restore some balance to my 
 life. I had given the strip all my time and energy for a decade 
 (and was happy to do so), but now I was that much older and I 
 wanted to work at a more thoughtful pace, out of the limelight, and 
 without the pressures and restrictions of newspapers. 

</p><p>The final Calvin and Hobbes strip was a Sunday strip. The 
 deadline for Sunday strips being early, I drew it well before 
 writing the daily strips that would eventually precede it in the 
 newspaper. I very much wanted to hit the right note for this final 
 strip. I think it worked, but it was a bittersweet strip to draw. 

</p><p>Since <i>Calvin and Hobbes</i>, I've been teaching myself how to 
 paint, and trying to learn something about music. I have no 
 background in either subject, and there are certainly days when I 
 wonder what made me trade proficiency and understanding in one 
 field for clumsiness and ignorance in these others. On better 
 days, I enjoy having so many new challenges and surprises. Even so, 
 these new endeavors have only deepened my appreciation for comics. 
 I no longer take quite so much for granted the versatility of 
 comics and their ability to depict complex ideas in a beautiful, 
 accessible, and entertaining form. For all their seeming simplicity, 
 the expressive possibilities of comics rival those of any other art 
 form. Five years after <i>Calvin and Hobbes</i>, I love the comics 
 as much as ever. 

</p><p>Bill Watterson
<br>Summer 2001 

</p><center><hr><b>
Back To the <a href="http://timhulsizer.com/cwords/calvin.html">Calvin &amp; Hobbes Page</a><br>
Back To the <a href="http://timhulsizer.com/cwords/cbooks.html">C&amp;H Books Page</a><br>
Back To the <a href="http://timhulsizer.com/cwords/index.html">Main Page</a><br>

</b>
<hr>



</center></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Use a Work Journal to Recover Focus Faster and Clarify Your Thoughts (675 pts)]]></title>
            <link>https://fev.al/posts/work-journal/</link>
            <guid>40950584</guid>
            <pubDate>Sat, 13 Jul 2024 00:05:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fev.al/posts/work-journal/">https://fev.al/posts/work-journal/</a>, See on <a href="https://news.ycombinator.com/item?id=40950584">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    
    <p>You’re working on the most complex problem in computer science: fixing permissions on a deployment pipeline. It’s been 4 days you started on that simple task already. Your manager explained to you in no uncertain terms that your performance on the subject is well below the expectations she has from a midterm intern. Your colleagues stay as far away as possible from you to avoid getting tainted by your shameful failure. 4 days of sleepless afternoons, seeing that freaking status turning to “build failed” everytime, bringing you to tears. The weather is shit, rain taping on the window of your overpriced basement suite, reflecting the state of your soul. You never felt so alone. Even your partner left you, you loser!</p>

<p>But this time you got it. This time you have a strategy beyond clicking on “retry failed steps” again and again. You finally read the logs, and you have an idea. You think you finely grasped what might be wrong. It’s a long shot: you’re gonna clear the credential cache, get an elevation you’re missing, force a permission sync, reset the service connection to the cluster, then downgrade the stupid auth library you’re using to a version that was hacked 6y ago but still works, setup everything again, then rollback. Your brain is making the connections, you got it, you’re better than that. You’re sorting through 23 different documentation tabs, waiting for the elevation to succeed, summoning all precious focus you got.</p>

<p>A red bubble shows up on IM. Conditioned by years of desperately reading your texts as soon as they arrived to create yourself what passes for a social life, your hand doesn’t even consults the sentient part of your cortex, and just moves to the little icon. <em>click</em>. It’s Mitch, your PM. He’s asking the url for a doc he wrote, and complains that it’s so complex to find doc in this organization.</p>

<p>This is a trap meant to get your focus out. Not this time. <strong>You’re better than that</strong>. You ignore his message, look at the elevation command, trigger it. Copy the id of the request that you need to preciously keep to finish the elevation to your clipboard.</p>

<p>4 minutes later you get a call request from your manager. You answer.</p>

<blockquote>
  <p>Hey, Mitch is saying he needs a doc urgently and you’re not answering his IM. Can you get to it?</p>
</blockquote>

<p><em>poof</em></p>

<p>Where the freak was I?</p>

<p><img src="https://fev.al/img/2024/focus.png" alt="poof"> 
<em>Credit: <a href="https://monkeyuser.com/">monkeyuser.com</a>. notice how much better it conveys my story.</em></p>

<p>Like everyone, I sometimes struggle to maintain focus. This was particularly true when I was a manager switching context all day long, this is also true as a  dev working on three antagonistic projects, including one that’s very consultory in nature, and working with processes that sometimes take hours to complete.</p>

<p>The typical situation is that I start something, switch to something else, get into a meeting, forget the very essence of what I was doing. Turn on autopilot, read all my emails, all my IMs. Then it’s 5PM, I’m exhausted, and I realize I’m at the same stage I was at 8AM, tell myself I should really achieve something that day, and open HN.</p>

<p>It was so bad at the beginning of this year that I seriously started wondering if I had ADHD<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>. I started working on something badly documented. As in: there’s no documentation, the people who built that thing are halfway across the world and they don’t even really work for the company anymore. It wasn’t even just interruption, but also procrastination. I felt so frustrated by the situation that I started writing that in my daily notes on Obsidian.</p>

<blockquote>
  <p>I asked Berna how to turn on super-compression 5000, and she’s not answering again! I tried it with the <code>--yo-compress-shit really-well-like-5000-or-something</code> and it didn’t work. It still spits me that <code>yo is not proper English, be civilized</code> error. What the hell can I do about that.</p>
</blockquote>

<p>Mitch called me to ask for that doc again, which I gave him, not without mentioning that little “star” icon in the url bar. And then got back at it.</p>

<p>And boy oh boy did that help! I just re-read what I was doing, and boom! I was back in.</p>

<p>I started listing all the commands I was running, and their results. Writing down my train of thoughts, the things I was doing and what I wanted to do next. And I have been doing that for the past 3-4 months. I feel like I invented something new. It helps me think more clearly, and restore the context so, so much faster when I switch between things. I’m almost looking forward to an interruption to get a chance to marvel again at my genius!</p>

<p>Except that it’s nothing new, right? “Writing helps you organize your thoughts more clearly”: everyone and their grandmother know that! Writing a plan, writing a diary? People keep listing how transformative that’s been for them. I’m not proposing a new framework. I’m just saying - every movie has a scientist recording themselves on one of these shitty little cassette recorders. They might be onto something. Write notes of what you’re doing and what you’re thinking. When you drop the pen and get back at it, read the last bit. That’s it.</p>

<p>I’ve just been too lazy to ever do it. Or not necessarily lazy, but more: I didn’t trust the tool enough to think it was a good use of my time, and instead just mash on the keyboard till it works. After all, I’m writing pages of text, of which I will never read more than a fraction. But that’s not the point. The point is structure, and the point is caching.</p>

<p>I guess that’s kind of it: if you’re having trouble switching between things or getting focused, try writing what you’re doing, and read the last couple sentences when you resume. Maybe it will help you. Maybe it won’t. Or maybe I’m an idiot who needs crutches. But hey, who knows!</p>

<h2 id="notes">notes</h2>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Crafting Interpreters (327 pts)]]></title>
            <link>https://craftinginterpreters.com/</link>
            <guid>40950235</guid>
            <pubDate>Fri, 12 Jul 2024 23:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://craftinginterpreters.com/">https://craftinginterpreters.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40950235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><em>Crafting Interpreters</em> contains everything you need to implement a
full-featured, efficient scripting language. You’ll learn both high-level
concepts around parsing and semantics and gritty details like bytecode
representation and garbage collection. Your brain will light up with new ideas,
and your hands will get dirty and calloused. It’s a blast.</p>

<p>Starting from <code>main()</code>, you build a language that features rich
syntax, dynamic typing, garbage collection, lexical scope, first-class
functions, closures, classes, and inheritance. All packed into a few thousand
lines of clean, fast code that you thoroughly understand because you write each
one yourself.</p>

<p>The book is available in four delectable formats:</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing the Lichess Tablebase Server (103 pts)]]></title>
            <link>https://lichess.org/@/revoof/blog/optimizing-the-tablebase-server/MetV0ZQd</link>
            <guid>40949943</guid>
            <pubDate>Fri, 12 Jul 2024 22:14:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lichess.org/@/revoof/blog/optimizing-the-tablebase-server/MetV0ZQd">https://lichess.org/@/revoof/blog/optimizing-the-tablebase-server/MetV0ZQd</a>, See on <a href="https://news.ycombinator.com/item?id=40949943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Recently our <a href="https://lichess.org/@/lichess/blog/7-piece-syzygy-tablebases-are-complete/W3WeMyQA">our 7 piece Syzygy tablebase server</a> was struggling to complete its periodic RAID integrity check while being hammered with tablebase requests. We decided to try a new approach, using <a href="https://man7.org/linux/man-pages/man7/lvmraid.7.html#DATA_INTEGRITY">dm-integrity on LVM</a>. Now, instead of periodically checking every data block, we passively check blocks whenever they are read.</p>
<p>17 TiB of tablebases are unwieldy, so to do this migration without hours of downtime, we set up a second server with the new approach. This also allowed us to run controlled benchmarks on the full set of tablebases, before finally doing the switch and retiring the old server.</p>
<p>We're trying to get the most out of the following new hardware:</p>
<ul>
<li>32 GiB RAM unchanged</li>
<li>2 x 201 GiB NVMe, where the previous server didn't have any SSD space. The rest of the 476 GiB disks is reserved for OS and working space</li>
<li>6 x 5.46 TiB HDD, where the previous server had only 5 disks</li>
</ul>
<p>The current operating system is Debian bookworm with default I/O schedulers:</p>
<pre><code>root@bwrdd:~# uname -a
Linux bwrdd 6.1.0-21-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.90-1 (2024-05-03) x86_64 GNU/Linux
root@bwrdd:~# cat /sys/class/block/nvme0n1/queue/scheduler
[none] mq-deadline
root@bwrdd:~# cat /sys/class/block/sda/queue/scheduler
[mq-deadline] none
</code></pre>
<h2>Monitoring important as ever</h2>
<p>RAID 5 is a good fit here, allowing recovery from any single disk failure, and distributing random reads across all disks. My first attempt was:</p>
<pre><code>$ lvcreate --type raid5 --raidintegrity y --raidintegrityblocksize 512 --name tables --size 21T vg-hdd # Oops
</code></pre>
<p>Peformance numbers in initial tests were decent, but we would have left a lot on the table if we didn't have monitoring to catch that not all disks were indeed participating equally.</p>
<p><img src="https://image.lichess1.org/display?h=0&amp;op=resize&amp;path=revoof:ublogBody:0yd54XyjtR2R:VUTWHQqX.png&amp;w=800&amp;sig=3fc8b923017ef07ac43342d38a06c1665b34d092" alt="Reads not distributed evenly"><br>Physical disk read activity with bad raid setup</p>
<p>That's because omitting <code>--stripes</code> does <em>not</em> default to use all physical volumes.</p>
<h2>Benchmark results (overview)</h2>
<p>In normal conditions the server receives between 10 and 35 requests per second. We record 1 million requests in the production environment to replay them in a controlled benchmark. In the chosen scenario, 12 parallel clients each sequentially submit requests from the production log.</p>
<p>Tables are lazily opened, and application and OS caches are lazily populated. So the first 800k response times are ignored as a warmup. We analyse the response times for the remaining 200k requests.</p>
<p>On average, response times are plenty fast, but tail latencies are high. So this is our focus for any optimizations. We'll unpack the results in a moment, but here are the empirical distribution functions (ECDFs) with 30ms added to each response time for an overview.</p>
<p><img src="https://image.lichess1.org/display?h=0&amp;op=resize&amp;path=revoof:ublogBody:KfbJv0yt3hyH:W2HFO1ha.png&amp;w=800&amp;sig=324cebd8631a951e7a67b9ec74831391dfcbca1e" alt="ECDFs with 30ms offset"><br>ECDFs</p>
<p>For a given response time on the x axis (log scale!) you can see which proportion of requests is faster. Or for a given proportion on the y axis (think percentile), you can read off the corresponding response time on the x axis.</p>
<p>The added constant seems artificial, but it's just viewing the results from the point of view of a client with 30ms ping time. Otherwise the log scaled x-axis would overemphasize the importance of a few milliseconds at the low end.</p>
<h2>mmap with higher tail latencies than pread</h2>
<p>Our Syzygy tablebase implementation <a href="https://github.com/niklasf/shakmaty-syzygy">shakmaty-syzygy</a> now offers an interface to plug in different ways of opening and reading from table files. The main contenders are:</p>
<ul>
<li><a href="https://man7.org/linux/man-pages/man2/mmap.2.html">Map</a> table files into memory. After the file has been mapped, disk reads happen transparently when accessing the respective memory region, so no further system calls are needed. Unfortunately, that also means reads look just as infallible as normal memory accesses, so that errors can only be handled out of band, via signals.</li>
<li><a href="https://man7.org/linux/man-pages/man2/pwrite.2.html">pread(2)</a>, one system call per read, with read error reporting via the return value.</li>
</ul>
<p>More robust error handling would probably be enough to justify using <code>pread</code> for a server implementation, but surprisingly, the diagram above shows that <code>pread</code> also peforms <em>better</em> in the scenario we care about. Perhaps that is because sometimes transparently reading a single memory-mapped data block across page boundaries may end up issuing two disk reads</p>
<pre><code>while (...)
{
    uint8_t d = *ptr++;
}
</code></pre>
<p>whereas</p>
<pre><code>uint8_t buf[MAX_BLOCK_SIZE];
ssize_t res = pread(fd, buf, block_size, offset);
</code></pre>
<p>immediately reveals how much data will be read.</p>
<p>Now, before you change your chess engine to use <code>pread</code>: Tablebases in engine matches are typically used only if enough fast storage for all WDL tables is available. The typical range of response times is not even visible in the graph above. Here, the saved syscall overhead is significant, so that memory mapping performs better.</p>
<p><img src="https://image.lichess1.org/display?h=0&amp;op=resize&amp;path=revoof:ublogBody:TLBrF0isfFgq:FbA5f9fq.png&amp;w=800&amp;sig=8aa103c6da4a742e53ed5e78949542a0231afb79" alt="ECDFs without offset"><br>Zoom on ECDFs: mmap saves syscall overhead</p>
<h2><code>MADV_RANDOM</code> / <code>POSIX_FADV_RANDOM</code> counter-productive</h2>
<p>The next surprise looking at the results above, is that <a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise(fd, 0, 0, POSIX_FADV_RANDOM)</code></a> or its equivalent for memory maps are actually mostly counter-productive. <code>POSIX_FADV_RANDOM</code> is intended to alleviate pressure on the page cache, by hinting to the operating system that file accesses are going to be random and automatic read-ahead is likely pointless.</p>
<p>Perhaps tablebase access patterns when people are analysing endgames are not so random afterall.</p>
<p>Again, this may differ for chess engines, where probes may be more likely to be scattered across different possible endgames.</p>
<h2>Table prefixes on limited SSD space</h2>
<p>To decide how to use the limited SSD space, let's have a look at the anatomy of a single table probe. The position will be encoded as an integer index, based on encoding information from the table header. Then we need to find the compressed data block that contains the result for the particular index. Syzygy provides a "sparse" block length list, which points close to the correct entry in the block length list, which is then used to find the relevant data block.</p>
<div>
<table>
<thead>
<tr><th>Table section sizes</th><th>WDL</th><th>DTZ</th><th>Total</th></tr>
</thead>
<tbody>
<tr><td>Headers and sparse block length lists</td><td>38 GiB</td><td>9 GiB</td><td>47 GiB</td></tr>
<tr><td>Block length lists</td><td>274 GiB</td><td>64 GiB</td><td>339 GiB</td></tr>
<tr><td>Compressed data blocks</td><td>8433 GiB</td><td>8458 GiB</td><td>16891 GiB</td></tr>
</tbody>
</table>
</div>
<p>We could certainly use the SSD space for an additional layer of adaptive caching, to cache hot list entries and data blocks. But since we're trying to improve tail latencies in particular, it makes sense to think about the worst case. By putting the sparse block length lists and the block length lists on SSD storage, hot or cold, we can guarantee a maximum of 1 slow disk read per table probe.</p>
<p>In our case that doesn't quite fit when using the SSD space in RAID 1 (mirrored), but since this optimization is optional, we can give up redundancy and use RAID 0.</p>
<h2>Parallelizing reads</h2>
<p>In chess engines, a typical tablebase request will be for a single WDL value. But for the user interface we instead want to display DTZ values for all moves.</p>
<p><img src="https://image.lichess1.org/display?h=0&amp;op=resize&amp;path=revoof:ublogBody:JGE5DJVrlUwR:VQu8XPZu.png&amp;w=800&amp;sig=66061784df25478d0e120a193664ce6dbd2ee481" alt="Screenshot of tablebase response"><br>Tablebase explorer</p>
<p>That, together with Syzygy's internal resolution of captures, will cause the average request to issue 23 WDL probes and 70 DTZ probes. In the initial implementation handling of requests was parallelized, but probes within each request were executed sequentially.</p>
<p>In the benchmark results we can see that using more fine grained parallelism has some overhead at the low end, but significantly reduces tail latencies. Of course the disks can not really physically handle that many parallel reads, but now the I/O scheduler is more likely to plan them in a way that will finish each request as soon as possible, and can better plan the order of all involved disk accesses (minimizing time until the disk's read head is at the next requested sector).</p>
<h2>Performance in production</h2>
<p>Finally, it's good to confirm that optimizations in the benchmark scenario actually help in production. Here are response time charts sliced together.</p>
<p><img src="https://image.lichess1.org/display?h=0&amp;op=resize&amp;path=revoof:ublogBody:hil5PjrHZMoy:Hc1Y8NLW.png&amp;w=800&amp;sig=fd4b864738e2060844341e192d20cfd51fa86efd" alt="Standard chess response times significantly reduced in production"><br>Standard chess response times</p>
<hr>
<p>Raw data at <a href="https://github.com/niklasf/lila-tablebase-bench-tool">https://github.com/niklasf/lila-tablebase-bench-tool</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things I know about Git commits (106 pts)]]></title>
            <link>https://www.jvt.me/posts/2024/07/12/things-know-commits/</link>
            <guid>40949229</guid>
            <pubDate>Fri, 12 Jul 2024 20:42:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jvt.me/posts/2024/07/12/things-know-commits/">https://www.jvt.me/posts/2024/07/12/things-know-commits/</a>, See on <a href="https://news.ycombinator.com/item?id=40949229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>Written by</span>
Jamie Tanna<br><span>on&nbsp;</span><time datetime="2024-07-12T20:01:09+0100">July 12, 2024</time><br><span><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"><i></i> CC-BY-NC-SA-4.0</a>
<a href="http://www.apache.org/licenses/LICENSE-2.0"><i></i> Apache-2.0</a></span><br><span>7 mins</span></p></div><div><p>This is an article that's been swimming around in my head for ~5 weeks now, and may become a "living post" that I keep updated over time.</p><p>In no particular order, some things I've learned about Git commits and commit history, over the last 12 years. This is a mix of experience in companies with teams of 2-12 people, as well as in Open Source codebases with a vast range of contributors.</p><ol><li>Git has different uses - a collaboration tool, a backup tool, a documentation tool</li><li>Git commit messages are excellent</li><li>I've never met anyone who likes reading commit messages as much as me</li><li>Finding out why a change was made is easier sorting through commits than it is through an issue/bug tracker</li><li>It's better to have a commit that says "Various fixes. DEV-123" than it is to have "Various fixes"</li><li>It's worse to have a commit that says "Various fixes. DEV-123" when the issue itself has no useful information</li><li>Rebase-merging is my preference. Then squash-merge, then merge</li><li>If you don't learn how to rebase, you're missing out on a good skill</li><li>People who say "just delete the repo" when things go wrong really frustrate me</li><li>Learn how to use <code>git reflog</code>, and it'll save you deleting a repo and work that was recoverable</li><li>Learn how to use <code>git reflog</code>, and you'll be able to save yourself from mistakes that aren't that bad</li><li>No amount of learning fancy tools and commands saves you from fucking up every once in a while</li><li>My most recent botched rebase was last week, and I needed <code>git reflog</code> to help un-fuck it</li><li>Learn how to <a href="https://www.jvt.me/posts/2021/10/23/undo-force-push/">undo a force push</a> and then how to <a href="https://www.jvt.me/posts/2018/09/18/safely-force-git-push/">more safely force push</a> (remember the <code>=ref</code>!!)</li><li>Squashing is a waste of well-written atomic commits</li><li>Squashing is better than 100 crap commits</li><li>Squashing, and writing a good commit message at the time of merge is good</li><li>Squashing, and then not re-editing the message is the worst</li><li>Squashing, when you have 100 crap commits, and then not re-editing the message is <strong>a crime</strong></li><li>Squashing, and then not re-editing the message is worse than a merge commit from a branch with 100 crap commits</li><li>Writing a well documented PR/MR description but not using that to inform the squash-merge message is a waste of time</li><li>Writing commit messages have helped me pick up on missing test cases, missing documentation, or invalid thought processes, as it helps me rewrite <em>why</em> the changes are being made</li><li>Using your <code>git log</code> as an indication for standup updates is valid</li><li>I can't be bothered to sign my commits (unless I'm forced to)</li><li>If I have to sign my commits, SSH key signing makes it almost not awful</li><li>If you're moving files between repos, you need to keep the history intact, <a href="https://www.jvt.me/posts/2018/06/01/git-subtree-monorepo/">using <code>git subtree</code></a></li><li>Commits should be atomic - all the code and tests, and configuration changes should all be in there</li><li>I spend a good chunk of time ensuring that each commit passes CI checks atomically</li><li>Some people do horrific things, like split their implementation and test code from each other</li><li>It's OK to put documentation in a separate commit - we don't have to have a whole end-to-end feature delivery in a single commit</li><li>Repos that use squash-merges suck</li><li>As a maintainer of Open Source projects, I like squash-merge, so I can rewrite contributors' commit messages</li><li>Sometimes it's not worth coaching how to write a given commit message</li><li>The people around you shape the way you write commits</li><li>Do the work up front to make your history atomic</li><li>It's much more painful to split a mega-commit into atomic commits after the fact</li><li>Splitting work atomically can be good for improving your reward drive - you can get many more things done</li><li>Atomic commits work really well with <a href="https://www.jvt.me/posts/2022/04/12/prefactor/">prefactoring</a></li><li>Sometimes prefactor commits can go into separate PRs (especially if squash-merge is used)</li><li>Writing commit messages can take longer than the implementation</li><li>The commit message can be an order of magnitude larger than the number of lines changed in a commit</li><li>If you end up writing a lot of "and"s or "also" in a commit message, you may be trying to do too many things</li><li>Trawling through Git commit history in the past has helped unlock a number of cases where I could then understand the <em>why</em> without the original authors there to answer my questions</li><li>Commit messages are a great point to reflect on not just what you've done, but <strong>why</strong></li><li>Why is more important than what - anyone can look at the diff and generally work out what changes were made, but the intent behind it is the special sauce</li><li>If you only write what changed, you're annoying, and I dislike you</li><li>A commit that explains what is better than a commit that just has "fixes"</li><li><span><a href="https://cbea.ms/">Chris Beams</a></span>' article, <a href="https://cbea.ms/git-commit/"><em>How to Write a Git Commit Message</em></a> is still an excellent post and a great place to start, just under 10 years later!</li><li>Commits are a point-in-time explanation of the assumptions and the state of the world for the committer. Don't be too hard on them</li><li>I don't want to read AI/LLM rewrites of your changes - either write it yourself, or call it <code>Various fixes</code></li><li>There needs to be a way to add an annotation (maybe using <code>git notes</code>) to a previous message to correct assumptions</li><li>I won't write perfect commit messages up front - they'll sometimes be as much as <code>rew! add support for SBOMs</code> or <code>sq</code>, or <a href="https://www.jvt.me/posts/2019/01/10/git-commit-fixup/">use <code>git commit --fixup</code></a></li><li>I will, generally, break off very good atomic chunks of work into commits</li><li>I will split atomic commits into multiple commits, sometimes</li><li>Make sure you <a href="https://www.jvt.me/posts/2019/01/12/self-code-review/">review your own code changes</a> before you send it out for review to your collaborators</li><li>Reviewing your commit messages should be as important as reviewing the code changes</li><li>Getting all your contributors to invest the same amount of care into the commit history is a losing battle</li><li>Trying to police commit history is going to be painful</li><li>Trying to mandate reviews of commit messages as part of code review is going to be painful</li><li>Trying to police commit history does lead to a greater level of documentation and consideration around changes int he codebase</li><li>Making implicit assumptions explicit is really useful</li><li>Introducing <code>commitlint</code> can be useful, but also frustrating</li><li>It's nicer to have your collaborators want to write good commit messages than you having to force them</li><li>Some people don't write, and that's alright</li><li>Writing is a skill</li><li>I'm not perfect at writing (commit messages)</li><li>Sometimes I can't be arsed to write the perfect message</li><li>Sometimes I write some really great commit messages, and impress myself</li><li>Using a <a href="https://www.jvt.me/posts/2017/04/17/commit-templates/">template for your Git commit messages</a> is a good nudge to doing it right</li><li><a href="https://www.jvt.me/posts/2019/01/10/git-commit-fixup/"><code>fixup</code> commits</a> and <code>git rebase --autosquash</code> has been one of the best Git tips I've learned</li><li>I value working on a team with a diverse set of perspectives, skills and approaches to work</li><li>But I also really value having a team who writes atomic commits with well-written commit messages</li><li>Commit message writing is as useful as writing well-refined user stories/tickets</li><li><code>git commit -m sq</code> is probably my most-run command</li><li>Using <code>git add -p</code> and <code>git commit -p</code> are hugely important for atomic commits</li><li>Never use <code>git add -u</code> or <code>git add .</code></li><li>Learn when you can use <code>git add -u</code> or <code>git add .</code></li><li>I really need to look into tools like Graphite, <code>git-branchless</code> and other means to provide a stacked PR setup</li><li>Using <a href="https://www.conventionalcommits.org/en/v1.0.0/">conventional commits</a> with <a href="https://github.com/semantic-release/semantic-release">semantic-release</a> or <a href="https://github.com/go-semantic-release/semantic-release">go-semantic-release</a> can make a huge difference when wanting to release automagically and often</li><li>Using <a href="https://www.conventionalcommits.org/en/v1.0.0/">conventional commits</a> as a framework for your commits can be really useful</li><li>Using <a href="https://www.conventionalcommits.org/en/v1.0.0/">conventional commits</a>, as someone with ADHD, reduces the need for thinking at times and can allow you to focus more on what the changes are</li><li>Using <a href="https://www.conventionalcommits.org/en/v1.0.0/">conventional commits</a> helps you work out when you're trying to do too much in a commit</li><li>I <a href="https://www.jvt.me/posts/2023/10/04/blogging-neurodiversity/">think through writing</a> so commit messages help understand <a href="https://www.youtube.com/watch?v=1qdyNoe3q2A">why I did the thing</a></li><li>It can be better to write a good commit message than a piece of documentation, stored elsewhere</li><li>It can be better to write a good commit message than a code comment</li><li>Give people space to learn</li><li>Give people space to fail</li><li>Remember you weren't so great at one point in time</li><li>Documentation is rad. Do more of it</li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["GitHub" Is Starting to Feel Like Legacy Software (114 pts)]]></title>
            <link>https://www.mistys-internet.website/blog/blog/2024/07/12/github-is-starting-to-feel-like-legacy-software/</link>
            <guid>40949034</guid>
            <pubDate>Fri, 12 Jul 2024 20:19:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mistys-internet.website/blog/blog/2024/07/12/github-is-starting-to-feel-like-legacy-software/">https://www.mistys-internet.website/blog/blog/2024/07/12/github-is-starting-to-feel-like-legacy-software/</a>, See on <a href="https://news.ycombinator.com/item?id=40949034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I’ve used a lot of tools over the years, which means I’ve seen a lot of tools hit a plateau. That’s not always a problem; sometimes something is just “done” and won’t need any changes. Often, though, it’s a sign of what’s coming. Every now and then, something will pull back out of it and start improving again, but it’s often an early sign of long-term decline. I can’t always tell if something’s just coasting along or if it’s actually started to get worse; it’s easy to be the boiling frog. That changes for me when something that <em>really</em> matters to me breaks.</p>

<p>To me, one of GitHub’s killer power user features is its <code>blame</code> view. <code>git blame</code> on the commandline is useful but hard to read; it’s not the interface I reach for every day. GitHub’s web UI is not only convenient, but the ease by which I can click through to older versions of the blame view on a line by line basis is uniquely powerful. It’s one of those features that anchors me to a product: I stopped using offline graphical git clients because it was just that much nicer.</p>

<p>The other day though, I tried to use the blame view on a large file and ran into an issue I don’t remember seeing before: I just <em>couldn’t find</em> the line of code I was searching for. I threw various keywords from that line into the browser’s command+F search box, and nothing came up. I was stumped until a moment later, while I was idly scrolling the page while doing the search again, and it finally found the line I was looking for. I realized what must have happened.</p>

<p>I’d heard rumblings that GitHub’s in the middle of shipping a frontend rewrite in React, and I realized this must be it. The problem wasn’t that the line I wanted wasn’t on the page—it’s that the whole document wasn’t being rendered at once, so my browser’s builtin search bar just <em>couldn’t find it</em>. On a hunch, I tried disabling JavaScript entirely in the browser, and suddenly it started working again. GitHub is <em>able</em> to send a fully server-side rendered version of the page, which actually works like it should, but doesn’t do so unless JavaScript is completely unavailable.</p>

<p>I’m hardly anti-JavaScript, and I’m not anti-React either. Any tool’s perfectly fine when used in the right place. The problem: this <em>isn’t the right place</em>, and what is to me personally a key feature suddenly doesn’t work right all the time anymore. This isn’t the only GitHub feature that’s felt subtly worse in the past few years—the once-industry-leading status page no longer reports minor availability issues in an even vaguely timely manner; Actions runs randomly drop network connections to GitHub’s own APIs; hitting the merge button sometimes scrolls the page to the wrong position—but this is the first moment where it really hit me that GitHub’s probably not going to get better again from here.</p>

<p>The corporate branding, the new “AI-powered developer platform” slogan, makes it clear that what I think of as “GitHub”—the traditional website, what are to me the core features—simply isn’t Microsoft’s priority at this point in time. I know many talented people at GitHub who care, but the company’s priorities just don’t seem to value what I value about the service. This isn’t an anti-AI statement so much as a recognition that the tool I still need to use every day is past its prime. Copilot isn’t navigating the website for me, replacing my need to the website as it exists today. I’ve had tools hit this phase of decline and turn it around, but I’m not optimistic. It’s still plenty usable now, and probably will be for some years to come, but I’ll want to know what other options I have <em>now</em> rather than when things get worse than this.</p>

<p>And in the meantime, well… I still need to use GitHub everyday, but maybe it’s time to start exploring new platforms—and find a good local <code>blame</code> tool that works as well as the GitHub web interface used to. (Got a fave? Send it to me at <a href="https://digipres.club/@misty">misty@digipres.club</a> / <a href="https://bsky.app/profile/cdrom.ca">@cdrom.ca</a>. Please!)</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Responsive bar charts in HTML and CSS (114 pts)]]></title>
            <link>https://9elements.com/blog/responsive-bar-charts-in-html-and-css/</link>
            <guid>40949021</guid>
            <pubDate>Fri, 12 Jul 2024 20:17:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9elements.com/blog/responsive-bar-charts-in-html-and-css/">https://9elements.com/blog/responsive-bar-charts-in-html-and-css/</a>, See on <a href="https://news.ycombinator.com/item?id=40949021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Building flexible data visualizations for international sites</strong></p><p>For our international clients, we have created dynamic charts and data visualizations for the web. Charts typically render shapes like lines and paths, rectangles and circles. They contain text for titles, axis labels, numerical values and legends.</p><p>SVG is the good fit for this purpose. It embeds directly into HTML and pairs well with CSS. However, for dynamic data visualizations on the web, SVG poses a challenge.</p><h2 id="Responsive-charts-and-the-problems-of-SVG">Responsive charts and the problems of SVG</h2><p>The websites we build feature responsive layouts and fluid typography. We employ CSS Flexbox and Grid together with media and container queries to fit in the content. There is not one single fixed presentation, but many possible presentations depending on the content and the reading environment.</p><p>In contrast, SVG does not have layout techniques like Flexbox, Grid or even <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_flow_layout">Normal Flow</a>. In SVG, all shapes are absolutely positioned. Text does not wrap automatically. The shapes and text need to be laid out manually by the code that generates the SVG.</p><p>SVG does scale continuously, as the name says – but for charts on the web, we usually do not want that. A small chart should not look like a downscaled big chart. Text would become unreadable, shapes would become tiny pixel mush – even with techniques that <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/vector-effect#non-scaling-stroke">prevent the scaling of some graphical features</a>.</p><p>For charts on the web, we want quantitative and qualitative responsive scaling. A small and a large chart should be designed and laid out differently. A small chart should focus on clear, distinguishable marks that represent the data. A large chart should take advantage of the screen estate to show more items and details as well as provide context.</p><p>For example, a line chart with multiple lines may switch to small multiples on smaller viewports or containers.</p><figure><picture><source type="image/avif" srcset="https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-352w-embedded.avif 352w, https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-704w-embedded.avif 704w, https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-1408w-embedded.avif 1408w" sizes="(min-width: 176em) 176rem, 100vw"><source type="image/jpeg" srcset="https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-352w-embedded.jpeg 352w, https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-704w-embedded.jpeg 704w, https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-1408w-embedded.jpeg 1408w" sizes="(min-width: 176em) 176rem, 100vw"><img alt="Line chart with six lines representing six world regions (Western Pacific, Europe, Americas, South-East Asia, Eastern Mediterranean, Africa). Lines are colored differently and sometimes overlap." loading="lazy" decoding="async" src="https://9elements.com/images/ctfl/6GQrENkrcOjoCMIY8TZIQO-352w-embedded.jpeg" width="1408" height="1051"></picture></figure><figure><picture><source type="image/avif" srcset="https://9elements.com/images/ctfl/1IqU5V32yN34rKj2RNREFi-352w-embedded.avif 352w, https://9elements.com/images/ctfl/1IqU5V32yN34rKj2RNREFi-704w-embedded.avif 704w" sizes="(min-width: 176em) 176rem, 100vw"><source type="image/jpeg" srcset="https://9elements.com/images/ctfl/1IqU5V32yN34rKj2RNREFi-352w-embedded.jpeg 352w, https://9elements.com/images/ctfl/1IqU5V32yN34rKj2RNREFi-704w-embedded.jpeg 704w" sizes="(min-width: 176em) 176rem, 100vw"><img alt="Two-column grid of six small line charts, one line chart for each world region. All lines are colored blue. The y axes are aligned so the lines are comparable." loading="lazy" decoding="async" src="https://9elements.com/images/ctfl/1IqU5V32yN34rKj2RNREFi-352w-embedded.jpeg" width="704" height="960"></picture></figure><p>We have typically implemented this responsiveness with client-side JavaScript logic. JavaScript is able to read the container size and measure text in order to compute all shape coordinates and sizes. This often involves decollision with <a href="https://d3js.org/d3-force">force simulations</a>.</p><p>This approach has severe disadvantages. The cycle of forcing the browser to compute the style, reading sizes and setting positions leads to <a href="https://web.dev/articles/avoid-large-complex-layouts-and-layout-thrashing">layout thrashing</a> and slows down the chart rendering.</p><p>When the container size changes, for example due to a browser resize or orientation change, the JavaScript needs to compute all SVG positions and sizes from scratch. Assuming this takes 50-100ms per chart, a page with 20 charts freezes the browser for 1-2 seconds.</p><h2 id="HTML-CSS-and-SVG-hybrid">HTML, CSS and SVG hybrid</h2><p>Horizontal bar charts are simple yet effective, intuitive and accessible visualizations. They are versatile regarding the bar design, labeling, value placement and axes. And they can be highly flexible regarding the container size.</p><p>We have a pretty solid implementation of a responsive bar chart. In narrow containers, the row label is shown on top of the bar. In wide containers, it is shown next to the bar.</p><figure><picture><source type="image/avif" srcset="https://9elements.com/images/ctfl/5Sulbp7D4VfW4YXX4s1hKD-352w-embedded.avif 352w, https://9elements.com/images/ctfl/5Sulbp7D4VfW4YXX4s1hKD-704w-embedded.avif 704w" sizes="(min-width: 176em) 176rem, 100vw"><source type="image/jpeg" srcset="https://9elements.com/images/ctfl/5Sulbp7D4VfW4YXX4s1hKD-352w-embedded.jpeg 352w, https://9elements.com/images/ctfl/5Sulbp7D4VfW4YXX4s1hKD-704w-embedded.jpeg 704w" sizes="(min-width: 176em) 176rem, 100vw"><img alt="Horizontal bar chart for four countries. The country names are placed on top of the bars. The vertical x axis lines span the whole height. Next to each bar, there is a label with the value for the country." loading="lazy" decoding="async" src="https://9elements.com/images/ctfl/5Sulbp7D4VfW4YXX4s1hKD-352w-embedded.jpeg" width="704" height="357"></picture></figure><figure><picture><source type="image/avif" srcset="https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-352w-embedded.avif 352w, https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-704w-embedded.avif 704w, https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-1408w-embedded.avif 1408w" sizes="(min-width: 176em) 176rem, 100vw"><source type="image/jpeg" srcset="https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-352w-embedded.jpeg 352w, https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-704w-embedded.jpeg 704w, https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-1408w-embedded.jpeg 1408w" sizes="(min-width: 176em) 176rem, 100vw"><img alt="Horizontal bar chart for four countries. The country names are placed in a column on the left side. The bars as well as the x axis ticks and labels are placed in a column on the right side. Next to each bar, there is a label with the value for the country." loading="lazy" decoding="async" src="https://9elements.com/images/ctfl/22MPkZRNittq3duJ5JAx2X-352w-embedded.jpeg" width="1408" height="359"></picture></figure><p>This chart is a hybrid of HTML, CSS and SVG. We wanted to use essential CSS layout methods like Flexbox instead of re-implementing layout algorithms in JavaScript. However, the synchronization with the SVG parts is still slow, complex client-side JavaScript code.</p><h2 id="lessstronggreaterBar-chart-in-plain-HTML-andamp-CSSlessstronggreater"><strong>Bar chart in plain HTML &amp; CSS</strong></h2><p>We were wondering: Can we achieve this with HTML and CSS alone, preferably without SVG and with less JavaScript logic? We fiddled around, but never finished this idea.</p><p>Then we saw the <a href="https://2023.stateofjs.com/en-US/features/#syntax_features">beautiful responsive bar charts of State of JS</a>, made with HTML &amp; CSS only. On narrow viewports, they use a two-column grid:</p><figure><picture><source type="image/avif" srcset="https://9elements.com/images/ctfl/7xQa0or3SZ1lXzbFdIfGs8-352w-embedded.avif 352w, https://9elements.com/images/ctfl/7xQa0or3SZ1lXzbFdIfGs8-704w-embedded.avif 704w" sizes="(min-width: 176em) 176rem, 100vw"><source type="image/jpeg" srcset="https://9elements.com/images/ctfl/7xQa0or3SZ1lXzbFdIfGs8-352w-embedded.jpeg 352w, https://9elements.com/images/ctfl/7xQa0or3SZ1lXzbFdIfGs8-704w-embedded.jpeg 704w" sizes="(min-width: 176em) 176rem, 100vw"><img alt="Bar chart from &quot;State of JS&quot; showing how many people have used a certain JavaScript features. X axis values on the top, lines spanning the whole chart. Three rows, one for each JavaScript feature. Feature label and number of users on top of the bar." loading="lazy" decoding="async" src="https://9elements.com/images/ctfl/7xQa0or3SZ1lXzbFdIfGs8-352w-embedded.jpeg" width="704" height="506"></picture></figure><p>On wide viewports, this is a three-column grid with subgrids that inherit the column setup:</p><figure><picture><source type="image/avif" srcset="https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-352w-embedded.avif 352w, https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-704w-embedded.avif 704w, https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-1408w-embedded.avif 1408w" sizes="(min-width: 176em) 176rem, 100vw"><source type="image/jpeg" srcset="https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-352w-embedded.jpeg 352w, https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-704w-embedded.jpeg 704w, https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-1408w-embedded.jpeg 1408w" sizes="(min-width: 176em) 176rem, 100vw"><img alt="Bar chart from &quot;State of JS&quot; showing usage percentage of JavaScript features. X axis values on the top and bottom, lines spanning the whole height. Left column contains feature name, middle column the bar, right column the absolute user number." loading="lazy" decoding="async" src="https://9elements.com/images/ctfl/3Psc17pbAY5Zyd8WZZ61dx-352w-embedded.jpeg" width="1408" height="588"></picture></figure><p>These well-made charts encouraged us to try to migrate our bar charts to HTML &amp; CSS.</p><h2 id="lessstronggreaterGrid-setuplessstronggreater"><strong>Grid setup</strong></h2><p>For a start, we <a href="https://codepen.io/molily/pen/gOJVQgB?editors=1100">rebuild the basic structure</a>:</p><figure><p data-height="300" data-default-tab="html,result" data-slug-hash="gOJVQgB" data-pen-title="Responsive bar chart with ticks" data-preview="true" data-editable="true" data-user="molily"><span>See the Pen <a href="https://codepen.io/molily/pen/gOJVQgB">Responsive bar chart with ticks</a> by molily (<a href="https://codepen.io/molily">@molily</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p></figure><p>In the narrow version, the each row (<code>li</code> element) is a two-column grid:</p><pre><span>css</span><code><span>display</span><span>:</span> grid<span>;</span>
<span>grid-template-columns</span><span>:</span> <span>minmax</span><span>(</span>0<span>,</span> 1fr<span>)</span> min-content<span>;</span>
<span>grid-template-areas</span><span>:</span>
  <span>"dimension value"</span>
  <span>"bar bar"</span><span>;</span>
<span>position</span><span>:</span> relative<span>;</span></code></pre><p>In the wide version, the wrapper (<code>ol</code> element) is a three-column grid:</p><pre><span>css</span><code><span>display</span><span>:</span> grid<span>;</span>
<span>grid-template-areas</span><span>:</span> <span>"dimension bar value"</span><span>;</span>
<span>grid-template-columns</span><span>:</span> <span>fit-content</span><span>(</span>10rem<span>)</span> 1fr min-content<span>;</span></code></pre><p>The row (<code>li</code>) is a subgrid that spans all columns:</p><pre><span>css</span><code><span>display</span><span>:</span> grid<span>;</span>
<span>grid-template-columns</span><span>:</span> subgrid<span>;</span>
<span>grid-template-areas</span><span>:</span> none<span>;</span>
<span>grid-column</span><span>:</span> 1 / -1<span>;</span></code></pre><h2 id="lessstronggreaterReal-world-requirementslessstronggreater"><strong>Real-world requirements</strong></h2><p>Our real bar chart, however, is much more complex and has the following requirements:</p><ul><li><strong>Internationalization with bidirectional text</strong>: We're building charts for sites in six languages and two text directions: Left-to-right (LTR, like English and Russian) and right-to-left (RTL, like Arabic and Hebrew).</li><li><strong>Positive and negative values</strong>. Bars grow to both sides.</li><li><strong>Row labels</strong> may have an arbitrary length and should wrap and align nicely.</li><li><strong>Value labels</strong> should be positioned at the end of the bars, not inside them or in a separate column.</li><li><strong>Do not repeat the axis tick lines</strong> for each row if it's avoidable.</li></ul><p>This is the solution we came up with:</p><p><strong></strong><a href="https://codepen.io/molily/pen/JjqgxVR?editors=1100"><strong>Responsive bar chart in HTML &amp; CSS</strong></a></p><p><i>This is version 2 which implements essential feedback from </i><a href="https://vesa.piittinen.name/"><i>Vesa Piitiinen</i></a><i>.</i></p><figure><p data-height="300" data-default-tab="html,result" data-slug-hash="JjqgxVR" data-pen-title="Bar chart version 2" data-preview="true" data-editable="true" data-user="molily"><span>See the Pen <a href="https://codepen.io/molily/pen/JjqgxVR">Bar chart</a> by molily (<a href="https://codepen.io/molily">@molily</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p></figure><p>Let's dive into the implementation.</p><h3><strong>Responsive grid setup</strong></h3><p>The HTML structure looks like this:</p><pre><span>html</span><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>bar-chart<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>ticks<span>"</span></span> <span>aria-hidden</span><span><span>=</span><span>"</span>true<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>tick<span>"</span></span> <span><span>style</span><span><span>=</span><span>"</span><span><span>inset-inline-start:</span> <span>{</span>percent<span>}</span>%</span><span>"</span></span></span><span>&gt;</span></span>{tick value}<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span>&lt;!-- … more ticks … --&gt;</span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>ol</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>li</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>dimension<span>"</span></span><span>&gt;</span></span>
        <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>dimension-label<span>"</span></span><span>&gt;</span></span>{dimension label}<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>bar<span>"</span></span> <span><span>style</span><span><span>=</span><span>"</span><span><span>margin-inline-start:</span> <span>{</span>bar start<span>}</span>%<span>;</span> <span>width:</span> <span>{</span>bar width<span>}</span>%</span><span>"</span></span></span><span>&gt;</span></span>
        <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>bar-label<span>"</span></span><span>&gt;</span></span>{ bar label }<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>value<span>"</span></span> <span>aria-hidden</span><span><span>=</span><span>"</span>true<span>"</span></span><span>&gt;</span></span>{ bar label again }<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>li</span><span>&gt;</span></span>
    <span>&lt;!-- Bars with negative values require a class is-negative: --&gt;</span>
    <span><span><span>&lt;</span>li</span> <span>class</span><span><span>=</span><span>"</span>is-negative<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>dimension<span>"</span></span><span>&gt;</span></span>
        <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>dimension-label<span>"</span></span><span>&gt;</span></span>{dimension label}<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
      <span>&lt;!-- And the value need to placed before the bar: --&gt;</span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>value<span>"</span></span> <span>aria-hidden</span><span><span>=</span><span>"</span>true<span>"</span></span><span>&gt;</span></span>{bar label again}<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>bar<span>"</span></span> <span><span>style</span><span><span>=</span><span>"</span><span><span>margin-inline-start:</span> <span>{</span>bar start<span>}</span>%<span>;</span> <span>width:</span> <span>{</span>bar width<span>}</span>%</span><span>"</span></span></span><span>&gt;</span></span>
        <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>bar-label<span>"</span></span><span>&gt;</span></span>{bar label}<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>li</span><span>&gt;</span></span>
    <span>&lt;!-- … more li elements … --&gt;</span>
  <span><span><span>&lt;/</span>ol</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>In the narrow version, the <code>.bar-chart</code> wrapper is a three-column grid:</p><pre><span>css</span><code><span>display</span><span>:</span> grid<span>;</span>
<span>grid-template-columns</span><span>:</span> min-content 1fr min-content<span>;</span>
<span>grid-template-areas</span><span>:</span>
  <span>"dimension dimension dimension"</span>
  <span>"valuePaddingStart bar valuePaddingEnd"</span><span>;</span></code></pre><p>The <code>ol</code> element and <code>li</code> elements are subgrids:</p><pre><span>css</span><code><span>display</span><span>:</span> grid<span>;</span>
<span>grid-column</span><span>:</span> 1 / -1<span>;</span>
<span>grid-template-columns</span><span>:</span> subgrid<span>;</span></code></pre><p>In the wide version, the wrapper becomes a four-column grid:</p><pre><span>css</span><code><span>grid-template-areas</span><span>:</span> <span>"dimension valuePaddingStart bar valuePaddingEnd"</span><span>;</span>
<span>grid-template-columns</span><span>:</span> <span>fit-content</span><span>(</span>10rem<span>)</span> min-content 1fr min-content<span>;</span>
</code></pre><p>Each row remains a subgrid.</p><h2 id="lessstronggreaterBidirectional-textlessstronggreater"><strong>Bidirectional text</strong></h2><p>Internationalization is where HTML and CSS shine compared to SVG.</p><p>Our JavaScript code that generates SVG charts is full or <code>if (isLTR) {…} else {…}</code> conditionals. In SVG, the origin of the coordinate system is always top left. X coordinates need to be calculated using those LTR/RTL switches.</p><p>In HTML and CSS, we can simply use <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_logical_properties_and_values">logical properties</a> like <code>inset-inline-start/-end</code>, <code>margin-inline-start/-end</code> as well as <code>padding-inline-start/-end</code> to solve most left-to-right vs. right-to-left differences. When laying out the boxes in CSS, we can work with the text direction.</p><p>For example, each bar is a Flexbox container with the value label nested inside. Then the label is positioned next to the bar: For positive values, we add a box with <code>::before</code> plus <code>content: ''</code> with a <code>padding-inline-start</code> of 100%. For negative values, we add a box with <code>::after</code> plus <code>content: ''</code> with a <code>padding-inline-end: 100%</code>. These boxes push the label out of the bar so it sits right next to it.</p><p>We still need to handle positive and negative values differently, but by using Flexbox, logical properties and the current text direction, we don't need to handle left-to-right and right-to-left differently.</p><p>The bar labels are <i>also</i> rendered into the columns named <code>valuePaddingStart</code> and <code>valuePaddingEnd</code>. These invisible placeholders ensure the columns have the correct width to accommodate the absolutely positioned value labels. So the labels appear twice in the DOM. The placeholders have <code>aria-hidden="true"</code> and <code>visibility: hidden</code> though.</p><h2 id="lessstronggreaterTick-lines-spanning-the-full-heightlessstronggreater"><strong>Tick lines spanning the full height</strong></h2><p>Our goal to put the axis tick lines in the DOM only once instead of repeating them for each row complicates the grid. The challenge is to constrain the tick lines in the bar column horizontally, but let them span the whole grid vertically.</p><p>This is possible with <code>grid-row: 1 / -1</code> given the grid has <strong>explicit rows</strong>. It does not work with an arbitrary number of implicitly-created rows.</p><p>So we defined an outer grid that <strong>has two fixed rows</strong>. The ticks are then positioned in the first row, spanning two rows.</p><pre><span>css</span><code><span>.ticks</span> <span>{</span>
  <span>grid-column</span><span>:</span> bar<span>;</span>
  <span>grid-row</span><span>:</span> 1 / span 2<span>;</span>
<span>}</span></code></pre><p>The list of bars is then positioned in the second row and spans all columns of the parent grid. It creates a subgrid that inherits the grid configuration from the parent grid.</p><pre><span>css</span><code><span>ol</span> <span>{</span>
  <span>display</span><span>:</span> grid<span>;</span>
  <span>grid-row</span><span>:</span> 2<span>;</span>
  <span>grid-column</span><span>:</span> 1 / -1<span>;</span>
  <span>grid-template-columns</span><span>:</span> subgrid<span>;</span>
<span>}</span></code></pre><p>The subgrid may then create an arbitrary number of implicit rows. It remains nested in the second row of the outer grid.</p><p><a href="https://codepen.io/molily/pen/wvbVNbY?editors=1100">Minimal example on CodePen</a>:</p><figure><p data-height="300" data-default-tab="html,result" data-slug-hash="wvbVNbY" data-pen-title="Grid: Span whole grid" data-preview="true" data-editable="true" data-user="molily"><span>See the Pen <a href="https://codepen.io/molily/pen/wvbVNbY">Grid: Span whole grid</a> by molily (<a href="https://codepen.io/molily">@molily</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p></figure><h2 id="lessstronggreaterAccessibility-considerationslessstronggreater"><strong>Accessibility considerations</strong></h2><p>Accessibility of data visualizations is a top priority for us and our clients. In our SVG charts and HTML / SVG hybrids, we have assigned ARIA roles and accessible labels so graphical shapes have proper semantics and textual representation. In the accessibility tree, these charts appear either as lists (like <code>ul</code> or <code>ol</code> elements) or tables (like the <code>table</code> element) so users can read and navigate the chart in a familiar way.</p><p>While we have made SVG charts accessible, it is simpler and more robust to use semantic HTML directly. The shown HTML &amp; CSS bar chart uses plain <code>ol</code> and <code>li</code> elements with built-in ARIA roles. Screen readers and other assistive tools read out the labels and values.</p><p>Edge with JAWS on Windows:</p><p><video controls=""><source src="https://videos.ctfassets.net/bo3k2i3mbg0o/2vLU4rEGRrRvviFPMB0GqU/b9a0d2171b17072ca3995c4c95532e11/jaws-edge.mp4" type="video/mp4">Reading the bar chart with JAWS and Edge. Navigating through the labels and values by keyboard. <a href="https://videos.ctfassets.net/bo3k2i3mbg0o/2vLU4rEGRrRvviFPMB0GqU/b9a0d2171b17072ca3995c4c95532e11/jaws-edge.mp4">jaws-edge.mp4</a></video></p><p>Chrome with VoiceOver on MacOS:</p><p><video controls=""><source src="https://videos.ctfassets.net/bo3k2i3mbg0o/1TaiDq3atkiGPaZqVFWSFc/6aafd1a35f5931061420cbd171daa94b/voiceover-chrome.mp4" type="video/mp4">Reading the bar chart with VoiceOver and Chrome. Navigating through the labels and values by keyboard. <a href="https://videos.ctfassets.net/bo3k2i3mbg0o/1TaiDq3atkiGPaZqVFWSFc/6aafd1a35f5931061420cbd171daa94b/voiceover-chrome.mp4">voiceover-chrome.mp4</a></video></p><h2 id="lessstronggreaterRecaplessstronggreater"><strong>Recap</strong></h2><p>Today's websites feature responsive layout and fluid typography. Data visualizations should adapt these design techniques.</p><p>While responsive and accessible SVGs are possible, they require manual client-side JavaScript logic. HTML and CSS allow us to create charts using declarative layouts and bidirectional positioning without computing positions and preventing overlap manually.</p><p>We've demonstrated this for a bar chart. We've also created HTML, CSS and SVG hybrids where each technology does what it is good at.</p><h2 id="Building-your-next-data-visualizations">Building your next data visualizations</h2><p>At 9elements, we have been visualizing data for our clients for more than 10 years. In 2013, we developed <a href="https://9elements.com/blog/ged-viz-an-html5-data-visualization-tool/">GED VIZ</a> for the Bertelsmann Foundation, visualizing global economic relations. From 2014 on, we developed the front-end and the chart rendering of the <a href="https://9elements.com/blog/new-project-oecd-data-portal/">OECD Data Portal</a>. In 2015, we contributed to the <a href="https://9elements.com/blog/project-launched-wef-inclusive-growth-report-2015/">World Economic Forum Inclusive Growth Report</a>. The bar charts described in this article are part of a long-term work for an international organization in the public health sector.</p><p>Let us discuss how we can help you to explore, present and visualize the data of your organization or business! <a href="https://9elements.com/contact/">Contact us</a>.</p><h2 id="Acknowledgements">Acknowledgements</h2><p>Thanks to my colleagues <a href="https://9elements.com/blog/author/nils-binder/">Nils Binder</a>, <a href="https://9elements.com/blog/author/julian-laubstein/">Julian Laubstein</a> and Matthias von Schmettow for this collaboration.</p><p>Thanks to <a href="https://vesa.piittinen.name/">Vesa Piittinen</a> for substantial feedback and many valuable ideas on how to improve and simplify the HTML and CSS. Please have a look at <a href="https://codepen.io/Merri/pen/RwzwbdV">Vesa's version of the bar chart</a> which demonstrates more clever optimizations.</p><p>Thanks to the data visualization designers <a href="https://www.alicethudt.de/">Alice Thudt</a>, <a href="https://christianlaesser.com/">Christian Laesser</a> and <a href="https://truth-and-beauty.net/">Moritz Stefaner</a> for their stellar work on the <a href="https://truth-and-beauty.net/projects/who">Data Design Language</a>.</p><p>Thanks to the <a href="https://www.devographics.com/">Devographics</a> team behind the “State of HTML/CSS/JS“ surveys for the inspiration.</p><p>Thanks to our client for the opportunity to work on ambitious data visualizations.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Goldman Sachs: AI Is overhyped, expensive, and unreliable (129 pts)]]></title>
            <link>https://www.404media.co/goldman-sachs-ai-is-overhyped-wildly-expensive-and-unreliable/</link>
            <guid>40948971</guid>
            <pubDate>Fri, 12 Jul 2024 20:12:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/goldman-sachs-ai-is-overhyped-wildly-expensive-and-unreliable/">https://www.404media.co/goldman-sachs-ai-is-overhyped-wildly-expensive-and-unreliable/</a>, See on <a href="https://news.ycombinator.com/item?id=40948971">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>Investment giant Goldman Sachs published a research paper about the economic viability of generative AI which notes that there is “little to show for” the huge amount of spending on generative AI infrastructure and questions “whether this large spend will ever pay off in terms of AI benefits and returns.”&nbsp;</p><p>The paper, called “<a href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf?ref=404media.co"><u>Gen AI: too much spend, too little benefit?</u></a>” is based on a series of interviews with Goldman Sachs economists and researchers, MIT professor Daron Acemoglu, and infrastructure experts. The paper ultimately questions whether generative AI will ever become the transformative technology that Silicon Valley and large portions of the stock market are currently betting on, but says investors may continue to get rich anyway. “Despite these concerns and constraints, we still see room for the AI theme to run, either because AI starts to deliver on its promise, or because bubbles take a long time to burst,” the paper notes.&nbsp;</p><p>Goldman Sachs researchers also say that AI optimism is driving large growth in stocks like Nvidia and other S&amp;P 500 companies (the largest companies in the stock market), but say that the stock price gains we’ve seen are based on the assumption that generative AI is going to lead to higher productivity (which necessarily means automation, layoffs, lower labor costs, and higher efficiency). These stock gains are already baked in, Goldman Sachs argues in the paper: “Although the productivity pick-up that AI promises could benefit equities via higher profit growth, we find that stocks often anticipate higher productivity growth before it materializes, raising the risk of overpaying. And using our new long-term return forecasting framework, we find that a very favorable AI scenario may be required for the S&amp;P 500 to deliver above-average returns in the coming decade.”&nbsp;(Ed Zitron also has a <a href="https://www.wheresyoured.at/pop-culture/?ref=404media.co" rel="noreferrer">thorough writeup of the Goldman Sachs report</a> over at Where's Your Ed At.)</p><p>It adds that “outside of the most bullish AI scenario that includes a material improvement to the structural growth/inflation mix and peak US corporate profitability, we forecast that S&amp;P 500 returns would be below their post-1950 average. AI’s impact on corporate profitability will matter critically.”</p><blockquote>"Despite its expensive price tag, the technology is nowhere near where it needs to be in order to be useful for even such basic tasks"</blockquote><p>What this means in plain English is that one of the largest financial institutions in the world is seeing what people who are paying attention are seeing with their eyes: Companies are acting like generative AI is going to change the world and are acting as such, while the reality is that this is a technology that is currently deeply unreliable and may not change much of anything at all. Meanwhile, their stock prices are skyrocketing based on all of this hype and investment, which may not ultimately change much of anything at all.</p><p>Acemoglu, the MIT professor, told Goldman that the industry is banking on the idea that largely scaling the amount of AI training data—which may not actually be possible given the massive amount of training data already ingested—is going to solve some of generative AI’s growing pains and problems. But there is no evidence that this will actually be the case: “What does a doubling of data really mean, and what can it achieve? Including twice as much data from Reddit into the next version of GPT may improve its ability to predict the next word when engaging in an informal conversation, but it won't necessarily improve a customer service representative’s ability to help a customer troubleshoot problems with their video service,” he said. “The quality of the data also matters, and it’s not clear where more high-quality data will come from and whether it will be easily and cheaply available to AI models.” He also posits that large language models themselves “may have limitations” and that the current architecture of today’s AI products may not get measurably better.&nbsp;</p><p>Jim Covello, who is Goldman Sachs’ head of global equity research, meanwhile, said that he is skeptical about both the cost of generative AI and its “ultimate transformative potential.”&nbsp;</p><p>“AI technology is exceptionally expensive, and to justify those costs, the technology must be able to solve complex problems, which it isn’t designed to do,” he said. “People generally substantially overestimate what the technology is capable of today. In our experience, even basic summarization tasks often yield illegible and nonsensical results. This is not a matter of just some tweaks being required here and there; despite its expensive price tag, the technology is nowhere near where it needs to be in order to be useful for even such basic tasks.” He added that Goldman Sachs has tested AI to “update historical data in our company models more quickly than doing so manually, but at six times the cost.”&nbsp;</p><p>Covello then likens the “AI arms race” to “virtual reality, the metaverse, and blockchain,” which are “examples of technologies that saw substantial spend but have few—if any—real world applications today.”&nbsp;</p><p>The Goldman Sachs report comes on the heels of a piece by David Cahn, partner at the venture capital firm Sequoia Capital, which is one of the largest investors in generative AI startups, titled “<a href="https://www.sequoiacap.com/article/ais-600b-question/?ref=404media.co"><u>AI’s $600 Billion Question</u></a>,” which attempts to analyze how much revenue the AI industry as a whole needs to make in order to simply pay for the processing power and infrastructure costs being spent on AI right now.&nbsp;</p><p>To break even on what they’re spending on AI compute infrastructure, companies need to vastly scale their revenue, which Sequoia argues is not currently happening anywhere near the scale these companies need to break even. OpenAI’s annualized revenue has doubled from $1.6 billion in late 2023 to $3.4 billion, but Sequoia’s Cahn asks in his piece: “Outside of ChatGPT, how many AI products are consumers really using today? Consider how much value you get from Netflix for $15.49/month or Spotify for $11.99. Long term, AI companies will need to deliver significant value for consumers to continue opening their wallets.”</p><p>This is all to say that journalists, artists, workers, and even people who <em>use</em> generative AI are not the only ones who are skeptical about the transformative potential of it. The very financial institutions that have funded and invested in the AI frenzy, and are responsible for billions of dollars in investment decisions are starting to wonder what this is all for. </p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

                    <div>
    <div>
      <p>About the author</p>
      <p>Jason is a cofounder of 404 Media. He was previously the editor-in-chief of Motherboard. He loves the Freedom of Information Act and surfing.</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/404-jason-01-copy.jpeg" alt="Jason Koebler" src="https://www.404media.co/content/images/2023/08/404-jason-01-copy.jpeg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Free-threaded CPython is ready to experiment with (416 pts)]]></title>
            <link>https://labs.quansight.org/blog/free-threaded-python-rollout</link>
            <guid>40948806</guid>
            <pubDate>Fri, 12 Jul 2024 19:52:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://labs.quansight.org/blog/free-threaded-python-rollout">https://labs.quansight.org/blog/free-threaded-python-rollout</a>, See on <a href="https://news.ycombinator.com/item?id=40948806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>First, a few announcements:</p>
<p>Yesterday, <a href="https://py-free-threading.github.io/">py-free-threading.github.io</a> launched!
It's both a resource with documentation around adding support for free-threaded
Python, and a status tracker for the rollout across open source projects in the
Python ecosystem. We hope and expect both of these to be very useful, with the
status tracker providing a one-stop-shop to check the support status of the
dependencies of your project (e.g., "what was the first release of a package on
PyPI to support free-threaded Python?" or "are there nightly wheels and where
can I find them?") and get an overview of ecosystem-wide progress:</p>
<p><img alt="Tracking website for package compatibility with free-threaded CPython." src="https://labs.quansight.org/posts/free-threaded-python-rollout/py_free_threading_tracker.png" width="60%"></p>
<p>Later today, the Birds-of-a-Feather session
<a href="https://cfp.scipy.org/2024/talk/HDR7WZ/">"Supporting free-threaded Python"</a>
will be held at the SciPy 2024 conference (co-organized by one of our team
members, Nathan Goldbaum, together with Madicken Munck), focusing on knowledge
and experience sharing.</p>
<h2 id="free-threaded-cpython---what-why-how">Free-threaded CPython - what, why, how?</h2>
<p>You may be wondering by now what "free threading" or "free-threaded CPython"
is, and why you should care. In summary: it is a major change to CPython that
allows running multiple threads in parallel within the same interpreter. It is
becoming available as an experimental feature in CPython 3.13. A free-threaded
interpreter can run with the global interpreter lock (GIL) disabled - a
capability that is finally arriving as a result of the efforts that went into
<a href="https://peps.python.org/pep-0703/">PEP 703 - Making the Global Interpreter Lock Optional in CPython</a>.</p>
<p>Why? Performance. Multi-threaded performance. It makes it significantly easier
to write code that efficiently runs in parallel and will utilize multiple CPU
cores effectively. The core counts in modern CPUs continue to grow, while clock
speeds do not grow, so multi-threaded performance will continue to grow in
importance.</p>
<p>How? It's now <a href="https://py-free-threading.github.io/installing_cpython/">easy to get started by installing a free-threaded interpreter</a>:
macOS/Linux/Windows &amp; python.org/pyenv/apt/yum/conda - your preferred option is
probably available now.</p>
<h2 id="sounds-awesome---whats-the-catch">Sounds awesome - what's the catch?</h2>
<p>Implementing free-threading in CPython itself is a massive effort already, and
worthy of its own (series of) blog post(s). For the wider ecosystem, there's
also a ton of work involved, mainly due to two problems:</p>
<ol>
<li>Thread-safety. While pure Python code should work unchanged, code written in
other languages or using the CPython C API may not. The GIL was implicitly
protecting a lot of thread-unsafe C, C++, Cython, Fortran, etc. code - and
now it no longer does. Which may lead to all sorts of fun outcomes (crashes,
intermittent incorrect behavior, etc.).</li>
<li>ABI incompatibility between the default and free-threaded CPython builds.
The result of a free-threaded interpreter having a different ABI is that
each package that has extension modules must now build extra wheels.</li>
</ol>
<p>Out of these two, the thread-safety one is the more hairy problem. Having to
implement and maintain extra wheel build jobs is not ideal, but the work itself
is well-understood - it just needs doing for each project with extension
modules. Thread-safety on the other hand is harder to understand, improve,
and even test reliably. Because multithreaded code is usually sensitive to the
timing of how multiple threads run and access shared state, bugs may manifest
rarely. And a crash or failure that is hard to reproduce locally is
harder to fix then one that is always reproducible.</p>
<p>Here are a couple of examples of such intermittent failures:</p>
<p><a href="https://github.com/numpy/numpy/issues/26690">numpy#26690</a> shows an example
where a simple call to the <code>.sum()</code> method of a numpy array fails with a
fairly mysterious</p>
<div data-ch-theme="solarized-dark"><p><code><br><div><p><span>RuntimeError: Identity cache already includes the item.</span></p></div><br></code></p></div>
<p>when used with the Python <code>threading</code> and <code>queue</code> modules. This was noticed
in a scikit-learn CI job - it never failed in NumPy's own CI (scikit-learn has
more tests involving parallelism). After the bug report with a reproducer was
submitted, the fix to a numpy-internal cache wasn't that hard.</p>
<p><a href="https://github.com/PyWavelets/pywt/issues/758">pywavelets#758</a> was a report
of another fairly obscure failure in a test using <code>concurrent.futures</code>:</p>
<div data-ch-theme="solarized-dark"><p><code><br><div><p><span>TypeError: descriptor '__enter__' for '_thread.RLock' objects doesn't apply to a '_thread.lock' object</span></p></div><br></code></p></div>
<p>That looked a lot like a problem in CPython, and after some investigating it
was found there as well <a href="https://github.com/python/cpython/issues/121368">cpython#121368</a>
and fixed fairly quickly (the fix required some deep expertise in both CPython
internals and multithreaded programming in C though).</p>
<p>There are a fair amount of examples like that, e.g. <a href="https://github.com/PyWavelets/pywt/pull/753#issuecomment-2190335170">undefined behavior in
Cython code</a> that
no longer worked due to changes in CPython 3.13, a <a href="https://github.com/scipy/scipy/issues/21142">crash from C code in
<code>scipy.signal</code></a> that hadn't been
touched for 24 years (it was always buggy, but the GIL offered enough
protection), and a <a href="https://github.com/hugovk/Pillow/pull/123">crash in Pillow</a>
due to <a href="https://github.com/python/cpython/issues/121403">Python C API usage that wasn't
supported</a>.</p>
<p>It's encouraging though that issues like the ones above do get understood and
resolved fairly quickly. With a good test strategy, and over time also test
suites of libraries that cover Python-level threading better (such tests are
largely non-existent now in most packages), detecting or guarding against
thread-safety issues does seem doable. That test strategy will have to be
multi-pronged: from writing new tests and running tests in loops with <code>pytest-repeat</code> &amp;
co., to getting <a href="https://clang.llvm.org/docs/ThreadSanitizer.html">ThreadSanitizer</a>
to work in CI and doing integration-level and real-world testing with users.</p>
<h2 id="the-road-ahead--what-our-team-will-be-working-on">The road ahead &amp; what our team will be working on</h2>
<p>Free-threaded CPython becoming the default, and eventually the only, build of
CPython is several years away. What we're hoping to see, and help accomplish,
is that for Python 3.13 many projects will work on compatibility and start
releasing <code>cp313t</code> wheels on PyPI (and possibly nightly builds too, for projects
with a lot of dependencies), so users and packages further downstream can start
experimenting as well. After a full year of maturing support in the ecosystem
and further improvements in performance in CPython itself, we should have a
good picture of both the benefits and the remaining challenges with robustness.</p>
<p>Our team (currently <a href="https://github.com/ngoldbaum">Nathan</a>,
<a href="https://github.com/Fidget-Spinner">Ken Jin</a>,
<a href="https://github.com/lysnikolaou/">Lysandros</a>,
<a href="https://github.com/andfoy/">Edgar</a>, and
<a href="https://github.com/rgommers/">myself</a>) has now been working on this topic for
a few months, starting at the bottom of the PyData stack (most effort so far
has gone to NumPy, Cython, and CPython), and slowly working our way up from
there.</p>
<p>For each package, the approach has been similar so far - and a lot of that can
be used as a template by others we think. The steps are roughly:</p>
<ol>
<li>Add a first CI job, usually Linux x86-64 with the latest Python 3.13
pre-release candidate, and ensure the test suite passes,</li>
<li>Based on knowledge from maintainers, fix known issues with thread-safety and
shared/global state in native code,</li>
<li>Add free-threaded support to the wheel build CI jobs, and start uploading
nightly wheels (if appropriate for the project),</li>
<li>Do some stress testing locally and monitor CI jobs, and fix failures that
are observed (take the opportunity to add regression tests using <code>threading</code>
or <code>concurrent.futures.ThreadPoolExecutor</code>)</li>
<li>Mark extension modules as supporting running without the GIL</li>
<li>Move on to a next package (e.g., a key dependency) and using its test suite
to exercise the first package more, circling back to fix issues or address
follow-up actions as needed.</li>
</ol>
<p>Our main takeaway so far: it's challenging, but tractable! And fun as well:)</p>
<p>We've only just scratched the surface, there'll be a lot to do - from key
complex packages like PyO3 (important for projects using Rust) and
PyTorch, to the sheer volume of smaller packages with extension modules.
The lessons we are learning, as far as they are reusable, are going into the
documentation at
<a href="https://py-free-threading.github.io/">py-free-threading.github.io</a>.
The <a href="https://github.com/Quansight-Labs/free-threaded-compatibility/">repository</a>
that contains the sources for that website also has an issue tracker that is used
to link to the relevant project-specific tracking issues for free-threaded support,
as well as for ecosystem-wide issues and tasks (contributions and ideas are
very welcome here!).</p>
<p>Furthermore, we'd like to spend time on whatever may be impactful in helping
the ecosystem adopt free-threaded CPython, from answering questions
to helping with debugging - please don't hesitate to reach out or ping one of
us directly on GitHub!</p>
<h2 id="conclusion--acknowledgements">Conclusion &amp; acknowledgements</h2>
<p>We're really excited about what is becoming possible with free-threaded CPython!
While our team is busy with implementing CI jobs and fixing thread-safety issues,
we are as curious as anyone to see what performance improvements and
interesting experiments are going to show up with real-world code soon.</p>
<p>It's hard to acknowledge and thank everyone involved in moving free-threaded
CPython forward, because so much activity is happening. First of all we have
to thank Meta for funding the efforts of our team to help the ecosystem adopt
free-threaded CPython at the pace that will be needed to make this whole
endeavour a success, and Sam Gross and the whole Python Runtime team at Meta
for the close collaboration. Then the list is long - from the Python Steering
Council, for its thoughtful approach to (and acceptance of) PEP 703, to the
many library maintainers and community members who are proactively adding
support to their own projects or guide and review our contributions whenever we
work on projects we are not ourselves maintainers of.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beating the Compiler (158 pts)]]></title>
            <link>https://www.mattkeeter.com/blog/2024-07-12-interpreter/</link>
            <guid>40948353</guid>
            <pubDate>Fri, 12 Jul 2024 18:54:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mattkeeter.com/blog/2024-07-12-interpreter/">https://www.mattkeeter.com/blog/2024-07-12-interpreter/</a>, See on <a href="https://news.ycombinator.com/item?id=40948353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<!-- End header -->






<p>In modern times, everyone knows that writing assembly is a fool's errand:
compilers are the result of literal engineer-centuries of work, and they know
the processor much better than you do.</p>
<p>And yet – one hears <em>rumors</em>.</p>
<p>Written in <a href="https://jilp.org/vol5/v5paper12.pdf">ancient tomes</a>,
muttered in <a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html">quiet watering holes</a>,
scrawled on the walls of
<a href="https://www.reddit.com/r/programming/comments/badl2/luajit_2_beta_3_is_out_support_both_x32_x64/c0lrus0/">bygone temples</a>,
hinted at by
<a href="https://llvm.org/docs/LangRef.html#calling-conventions">mysterious texts</a>;
the rumors paint a specific picture:</p>
<blockquote>
<p>Compilers are bad at generating code for interpreters, and it's possible to
outperform them by writing your interpreter in assembly.</p>
</blockquote>
<p>I recently <a href="https://www.mattkeeter.com/projects/raven">wrote a fast interpreter</a> for the
<a href="https://wiki.xxiivv.com/site/uxn.html">Uxn CPU</a>,
a stack-based architecture with 256 opcodes.  The interpreter is a simple loop
which reads a byte from RAM then selects the appropriate instruction:</p>
<pre><code>impl Uxn {
    /// Runs the VM starting at the given address until it terminates
    #[inline]
    pub fn run&lt;D: Device&gt;(&amp;mut self, dev: &amp;mut D, mut pc: u16) {
        loop {
            let op = self.ram[usize::from(pc)];
            pc = pc.wrapping_add(1);
            let Some(next) = self.op(op, dev, pc) else {
                break;
            };
            pc = next;
        }
    }

    /// Executes a single operation
    #[inline]
    fn op&lt;D: Device&gt;(&amp;mut self, op: u8, dev: &amp;mut D, pc: u16) -&gt; Option&lt;u16&gt; {
        match op {
            0x00 =&gt; op::brk(self, dev, pc),
            0x01 =&gt; op::inc::&lt;0b000&gt;(self, dev, pc),
            0x02 =&gt; op::pop::&lt;0b000&gt;(self, dev, pc),
            0x03 =&gt; op::nip::&lt;0b000&gt;(self, dev, pc),
            0x04 =&gt; op::swp::&lt;0b000&gt;(self, dev, pc),
            0x05 =&gt; op::rot::&lt;0b000&gt;(self, dev, pc),
            0x06 =&gt; op::dup::&lt;0b000&gt;(self, dev, pc),
            0x07 =&gt; op::ovr::&lt;0b000&gt;(self, dev, pc),
            0x08 =&gt; op::equ::&lt;0b000&gt;(self, dev, pc),
            0x09 =&gt; op::neq::&lt;0b000&gt;(self, dev, pc),
            0x0a =&gt; op::gth::&lt;0b000&gt;(self, dev, pc),
            0x0b =&gt; op::lth::&lt;0b000&gt;(self, dev, pc),
            0x0c =&gt; op::jmp::&lt;0b000&gt;(self, dev, pc),
            0x0d =&gt; op::jcn::&lt;0b000&gt;(self, dev, pc),
            0x0e =&gt; op::jsr::&lt;0b000&gt;(self, dev, pc),
            // ... etc
        }
    }
}
</code></pre>
<p>All of the opcode implementations end up monomorphized and inlined into the body
of <code>Uxn::run(..)</code>, and the compiler is smart enough to keep key values in
registers.  This makes it relatively fast; I see 10-20% speedup over the
<a href="https://git.sr.ht/%7Erabbits/uxn/">reference implementation</a>.</p>
<p>Let's look at the assembly and see what the compiler is doing – and whether we
can do any better.  For context, the Uxn CPU has four different memories:</p>
<ul>
<li>The data stack, which is a <code>[u8; 256]</code> along with a <code>u8</code> index</li>
<li>The return stack, which has the same format</li>
<li>RAM, which is a <code>[u8; 65535]</code></li>
<li>Device memory, which we'll ignore for the moment (along with the <code>D: Device</code>
argument)</li>
</ul>
<p>During evaluation, we also track the program counter <code>pc</code>, which is a <code>u16</code> used
to index into the RAM.  In each cycle, we load a byte from RAM, then call the
appropriate opcode.  Some opcodes can also read and write to RAM, so
self-modifying code is possible!</p>
<p>By examining the <a href="https://www.mattkeeter.com/projects/raven/disassembly.html">assembly</a>, we can
reverse-engineer which values are stored where.  Consider the <code>INC</code> operation,
which loads a value from the top of the data stack and increments it:</p>
<pre><code>; INC
0x100002d4c: ldrb w8, [x25]     ; read the current data stack index
0x100002d50: ldrb w9, [x24, x8] ; read a byte from the data stack
0x100002d54: add w9, w9, #1     ; increment that byte
0x100002d58: strb w9, [x24, x8] ; write that byte back to the stack
0x100002d5c: b 0x100002d1c      ; jump back to the dispatch loop
</code></pre>
<p>From this assembly, we learn the following:</p>
<ul>
<li><code>x25</code> is the <em>address</em> of the data stack index (not its value!)</li>
<li><code>x24</code> is the address of the data stack array</li>
<li><code>w9</code> is used as a temporary register</li>
</ul>
<p>Similarly, <code>INCr</code> – increment the top value in the <strong>return</strong> stack – teaches us
that <code>x22</code> and <code>x23</code> are the return stack's data and index addresses.</p>
<p><code>JMP</code> shows that our program counter is stored in <code>w27</code>:</p>
<pre><code>; JMP
0x100002eac: ldrb w8, [x25]      ; read the current data stack index
0x100002eb0: ldrsb w9, [x24, x8] ; read a signed jump offset from the data stack
0x100002eb4: sub w8, w8, #1      ; decrement the data stack index
0x100002eb8: strb w8, [x25]      ; write back the data stack index
0x100002ebc: add w27, w27, w9    ; apply the jump to our program counter
0x100002ec0: b 0x100002d1c       ; jump back to the dispatch loop
</code></pre>
<p>Finally, the dispatch loop itself is worth examining:</p>
<pre><code>0x100002d1c: and x10, x27, #0xffff          ; mask pc to a u16
0x100002d20: ldr x8, [x20, #256]            ; load RAM base from *mut Uxn
0x100002d24: ldrb w10, [x8, x10]            ; load opcode byte from RAM
0x100002d28: add w27, w27, #1               ; increment pc
0x100002d2c: adr x11, #-96                  ; load base for jump
0x100002d30: ldrh w12, [x27, x10, lsl  #1]  ; load per-opcode jump amount
0x100002d34: add x11, x11, x12, lsl #2      ; compute jump location
0x100002d38: br x11                         ; jump into opcode implementation
</code></pre>
<p>The compiler has generated a jump table of 256 offsets (each a 2-byte value,
indicated by <code>lsl #1</code>).  It reads an opcode-specific value from this table to
compute a jump target, then performs an indirect branch to jump into the
opcode's implementation.</p>
<p>We can run this in a debugger and dump the actual jump table:</p>
<pre><code>(lldb) disas -p -c3
raven-cli`raven_uxn::Uxn::run::had9dba0d7d1b5105:
-&gt;  0x100002d30 &lt;+236&gt;: ldrh   w12, [x27, x10, lsl  #1]
    0x100002d34 &lt;+240&gt;: add    x11, x11, x12, lsl #2
    0x100002d38 &lt;+244&gt;: br     x11
(lldb) reg read x27
     x27 = 0x0000000100170b10
(lldb) memory read -s2 -fu -c256 0x0000000100170b10
0x100170b10: 2923
0x100170b12: 31
0x100170b14: 36
0x100170b16: 40
0x100170b18: 44
0x100170b1a: 52
0x100170b1c: 28
0x100170b1e: 64
0x100170b20: 70
0x100170b22: 78
0x100170b24: 86
0x100170b26: 94
0x100170b28: 119
0x100170b2a: 102
0x100170b2c: 110
0x100170b2e: 125
; etc...
</code></pre>
<p>(indeed, this is how I generated the <a href="https://www.mattkeeter.com/projects/raven/disassembly.html">per-opcode instruction listing</a>)</p>
<hr>
<p>Having looked at the assembly, there are two things that stick out as possible
inefficiencies:</p>
<ul>
<li>Some critical values (stack indices, the base address of RAM) are kept in
memory instead of registers; for example, <code>INC</code> has an extra load operation to
get the current data stack index.</li>
<li>The dispatch loop takes a single indirect branch to the opcode-specific
implementation.  This means that the branch will be nigh unpredictable!</li>
</ul>
<p>Profiling the code, the hottest instructions are all in the dispatch loop; the
<code>ldrh</code> takes over 1/3 of the total runtime!</p>
<p><img src="https://www.mattkeeter.com/blog/2024-07-12-interpreter/profile.png" alt="screenshot of profiling info"></p>
<p>(I'm not confident that the profiler is attributing the time to the correct
specific instruction here, but the vibes definitely indicate that dispatch is
expensive)</p>
<hr>
<p><a href="http://luajit.org/">LuaJIT</a> is the fast interpreter <em>par excellence</em>, and it's
written in assembly.  Mike Pall
<a href="https://www.reddit.com/r/programming/comments/badl2/luajit_2_beta_3_is_out_support_both_x32_x64/c0lrus0/">specifically calls out</a>
keeping state in registers and indirect threading as two contributors to its
speed, which can only be
<a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html">accomplished reliably</a>
in assembly.</p>
<p>Since persuading our compiler to generate extremely specific patterns is hard,
let's get started writing some assembly of our own.  My home machine is an M1
Macbook, so all of the assembly will be AArch64-flavored. The implementation
uses general-purpose registers; be aware that <code>w*</code> and <code>x*</code> refer to 32-bit and
64-bit views of the same register.</p>
<hr>
<h3>Register assignment</h3>
<p>Our first optimization is to store <strong>all</strong> important data in registers, to avoid
superfluous loads and stores.  My implementation ends up using 9 registers
(<code>x0-x8</code>), along with a handful of scratch registers:</p>
<pre><code>; x0 - stack pointer (&amp;mut [u8; 256])
; x1 - stack index (u8)
; x2 - return stack pointer (&amp;mut [u8; 256])
; x3 - return stack index (u8)
; x4 - RAM pointer (&amp;mut [u8; 65536])
; x5 - program counter (u16), offset of the next value in RAM
; x6 - VM pointer (&amp;mut Uxn)
; x7 - Device handle pointer (&amp;DeviceHandle)
; x8 - Jump table pointer
; x9-15 - scratch registers
</code></pre>
<p>The <a href="https://en.wikipedia.org/wiki/Calling_convention#ARM_(A64)">AArch64 calling convention</a>
only gives you 8 input arguments, so we can't call a function directly with all
of these values in registers;
we'll need a C ABI-flavored entry point (<a href="#shims">discussed below</a>).</p>
<h3>Indirect threading</h3>
<p>Our second optimization is using
<a href="https://en.wikipedia.org/wiki/Threaded_code">threaded code</a>
to eliminate the dispatch loop.
Each opcode's implementation will end with a jump to the next opcode's
implementation.</p>
<p>Opcodes are stored as single bytes in VM RAM, with a base address of <code>x4</code>.  I'll
build a separate jump table of function pointers, then pass its address in
register <code>x8</code>.  On the Rust side, here's what that table looks like:</p>
<pre><code>extern "C" {
    fn BRK();
    fn INC();
    fn POP();
    fn NIP();
    fn SWP();
    fn ROT();
    fn DUP();
    fn OVR();
    fn EQU();
    // ...etc
}

const JUMP_TABLE: [unsafe extern "C" fn(); 256] = [
    (BRK as unsafe extern "C" fn()),
    (INC as unsafe extern "C" fn()),
    (POP as unsafe extern "C" fn()),
    (NIP as unsafe extern "C" fn()),
    (SWP as unsafe extern "C" fn()),
    (ROT as unsafe extern "C" fn()),
    (DUP as unsafe extern "C" fn()),
    (OVR as unsafe extern "C" fn()),
    (EQU as unsafe extern "C" fn()),
    (NEQ as unsafe extern "C" fn()),
    // ... etc
];
</code></pre>
<p>In assembly, we want to read the current byte from VM RAM (<code>x4</code>), use it to pick
an address in the jump table (<code>x8</code>), then jump to that address.  I defined a
macro to do this dispatch:</p>
<pre><code>.macro next
    ldrb w9, [x4, x5]          ; load the byte from RAM
    add x5, x5, #1             ; increment the program counter
    and x5, x5, #0xffff        ; wrap the program counter
    ldr x10, [x8, x9, lsl #3]  ; load the opcode implementation address
    br x10                     ; jump to the opcode's implementation
.endm
</code></pre>
<p>Notice that this is a <strong>macro</strong>, not a function; we'll add <code>next</code> to the end of
each opcode, which will expand into this text.</p>
<p>For example, here's <code>INC</code>:</p>
<pre><code>.global _INC
_INC:
    ldrb w9, [x0, x1]   ; read the byte from the top of the stack
    add w9, w9, #1      ; increment it
    strb w9, [x0, x1]   ; write it back
    next                ; jump to the next opcode
</code></pre>
<p>Unlike LuaJIT, there's no <strong>decoding</strong> step for instructions; there are no
register arguments, and the single-byte opcode uniquely defines program
behavior.</p>
<h3>Implementation</h3>
<p>Implementing the other 255 opcodes is mostly just turning the crank;
there's nothing particularly exotic here, just good honest assembly.</p>
<p>In many cases, I'll use helper macros to generate code for a group of
instructions:</p>
<pre><code>.macro binary_op op
    ldrb w10, [x0, x1]  ; read the top value from the data stack
    pop                 ; decrement the data stack index (this is a macro!)
    ldrb w11, [x0, x1]  ; read the next value from the data stack
    \op w10, w11, w10   ; do the actual math operation
    strb w10, [x0, x1]  ; write the result into the data stack
    next
.endm

.global _ADD
_ADD:
    binary_op add

.global _SUB
_SUB:
    binary_op sub

.global _MUL
_MUL:
    binary_op mul

.global _DIV
_DIV:
    binary_op udiv
</code></pre>
<p>The whole implementation ends up being about
<a href="https://github.com/mkeeter/raven/blob/main/raven-uxn/src/native/aarch64.s">2400 lines</a>.
It sounds like a lot, but only about half of that is unique:
most opcodes come in two flavors (with and without the <code>RET</code> flag),
which only differ in which stack is used.</p>
<h3>C Shims</h3>
<p>Of course, my whole program isn't hand-written in assembly.  We need a way to
call our assembly function from the rest of our (Rust) implementation.  This
looks like a (Rust) <code>entry</code> function, which calls into an (assembly)
<code>aarch64_entry</code> point (which is compatible with the C ABI):</p>
<p><img src="https://www.mattkeeter.com/blog/2024-07-12-interpreter/entry.png" alt="diagram showing entry points"></p>
<p>What do we actually pass into <code>aarch64_entry</code>?  We have too much state to pass
in function argument registers (<code>x0-x7</code>), so I defined a helper object which
contains everything we need:</p>
<pre><code>#[repr(C)]
pub(crate) struct EntryHandle {
    stack_data: *mut u8,
    stack_index: *mut u8,
    ret_data: *mut u8,
    ret_index: *mut u8,
    ram: *mut u8,
    vm: *mut core::ffi::c_void,  // *Uxn
    dev: *mut core::ffi::c_void, // *DeviceHandle
}

struct DeviceHandle&lt;'a&gt;(&amp;'a mut dyn Device);
</code></pre>
<p>The <code>DeviceHandle</code> is needed because <code>&amp;mut dyn Device</code> is a fat pointer, and is
therefore not safe to pass into a C function.  Like all computer problems, we
solve this with an extra level of indirection: put the <code>&amp;mut dyn Device</code> into a
<code>DeviceHandle</code>, then pass <em>its</em> address instead.</p>
<p>Calling into assembly is a simple matter of populating an <code>EntryHandle</code> object,
then branching into the danger zone:</p>
<pre><code>// Declaration of our entry point, written in assembly
extern "C" {
    pub fn aarch64_entry(
        h: *const EntryHandle,
        pc: u16,
        table: *const unsafe extern "C" fn(),
    ) -&gt; u16;
}

pub fn entry(vm: &amp;mut Uxn, dev: &amp;mut dyn Device, pc: u16) -&gt; u16 {
    let mut h = DeviceHandle(dev);
    let mut e = EntryHandle {
        stack_data: vm.stack.data.as_mut_ptr(),
        stack_index: &amp;mut vm.stack.index as *mut _,
        ret_data: vm.ret.data.as_mut_ptr(),
        ret_index: &amp;mut vm.ret.index as *mut _,
        ram: (*vm.ram).as_mut_ptr(),
        vm: vm as *mut _ as *mut _,
        dev: &amp;mut h as *mut _ as *mut _,
    };

    // SAFETY: do you trust me?
    unsafe {
        aarch64::aarch64_entry(&amp;mut e as *mut _, pc, JUMP_TABLE.as_ptr())
    }
}
</code></pre>
<p><code>aarch64_entry</code> is a hand-written entry point in the assembly code.  It shuffles
around registers to put everything in the right place for our opcodes, then
begins execution with the usual <code>next</code> macro:</p>
<pre><code>.global _aarch64_entry
_aarch64_entry:
    sub sp, sp, #0x200  ; make room in the stack
    stp   x29, x30, [sp, 0x0]   ; store stack and frame pointer
    mov   x29, sp

    // Unpack from EntryHandle into registers
    mov x5, x1 ; move PC (before overwriting x1)
    mov x8, x2 ; jump table (before overwriting x2)
    ldr x1, [x0, 0x8]  ; stack index pointer
    ldr x2, [x0, 0x10] ; ret data pointer
    ldr x3, [x0, 0x18] ; ret index pointer
    ldr x4, [x0, 0x20] ; RAM pointer
    ldr x6, [x0, 0x28] ; *mut Uxn
    ldr x7, [x0, 0x30] ; *mut DeviceHandle
    ldr x0, [x0, 0x00] ; stack data pointer (overwriting *EntryHandle)

    ; Convert from index pointers to index values in w1 / w3
    stp x1, x3, [sp, 0x10]      ; save stack index pointers
    ldrb w1, [x1]               ; load stack index
    ldrb w3, [x3]               ; load ret index

    ; Jump into the instruction list
    next
</code></pre>
<p>Finally, when exiting (via the <code>BRK</code> opcode), we need to update the data and
return stack indices, moving values from registers into the appropriate memory
addresses:</p>
<pre><code>.global _BRK
_BRK:
    ; Write index values back through index pointers
    ldp x9, x10, [sp, 0x10]     ; restore stack index pointers
    strb w1, [x9]               ; save data stack index
    strb w3, [x10]              ; save return stack index

    ldp   x29, x30, [sp, 0x0]   ; restore stack and frame pointer
    add sp, sp, #0x200          ; undo our stack offset

    mov x0, x5 ; return PC from function
    ret
</code></pre>
<h3>Device IO</h3>
<p>The <code>DEI</code> and <code>DEO</code> opcodes perform "device I/O", which lets you attach
arbitrary peripherals to the system.  The most common set of peripherals is the
<a href="https://wiki.xxiivv.com/site/varvara.html">Varvara system</a>,
which adds everything you need to make the CPU into an actual computer: a
screen, keyboard and mouse input, audio, etc.</p>
<p>To keep the Uxn implementation generic, I defined a trait for a device:</p>
<pre><code>/// Trait for a Uxn-compatible device
pub trait Device {
    /// Performs the `DEI` operation for the given target
    ///
    /// This function must write its output byte to `vm.dev[target]`; the CPU
    /// evaluation loop will then copy this value to the stack.
    fn dei(&amp;mut self, vm: &amp;mut Uxn, target: u8);

    /// Performs the `DEO` operation on the given target
    ///
    /// The input byte will be written to `vm.dev[target]` before this function
    /// is called, and can be read by the function.
    ///
    /// Returns `true` if the CPU should keep running, `false` if it should
    /// exit.
    #[must_use]
    fn deo(&amp;mut self, vm: &amp;mut Uxn, target: u8) -&gt; bool;
}
</code></pre>
<p>The opcode implementation takes a <code>&amp;mut dyn Device</code>, i.e. something implementing
this trait, and calls trait methods on it:</p>
<pre><code>pub fn deo&lt;const FLAGS: u8&gt;(
    vm: &amp;mut Uxn,
    dev: &amp;mut dyn Device,
    pc: u16,
) -&gt; Option&lt;u16&gt; {
    let mut s = vm.stack_view::&lt;FLAGS&gt;();
    let i = s.pop_byte();
    let mut run = true;
    match s.pop() {
        Value::Short(v) =&gt; {
            let [lo, hi] = v.to_le_bytes();
            let j = i.wrapping_add(1);
            vm.dev[usize::from(i)] = hi;
            run &amp;= dev.deo(vm, i);
            vm.dev[usize::from(j)] = lo;
            run &amp;= dev.deo(vm, j);
        }
        Value::Byte(v) =&gt; {
            vm.dev[usize::from(i)] = v;
            run &amp;= dev.deo(vm, i);
        }
    }
    if run {
        Some(pc)
    } else {
        None
    }
}
</code></pre>
<p>However, this function is not compatible with the C ABI – it's both generic
<em>and</em> takes a trait object – so it can't be called directly from the <code>DEO</code>
opcode in assembly.</p>
<p>To let my opcodes call <code>DEO</code> and <code>DEI</code> functions, I again wrote a bunch of
shims:</p>
<pre><code>#[no_mangle]
extern "C" fn deo_entry(vm: &amp;mut Uxn, dev: &amp;mut DeviceHandle) -&gt; bool {
    vm.deo::&lt;0b000&gt;(dev.0, 0).is_some()
}

#[no_mangle]
extern "C" fn deo_2_entry(vm: &amp;mut Uxn, dev: &amp;mut DeviceHandle) -&gt; bool {
    vm.deo::&lt;0b001&gt;(dev.0, 0).is_some()
}

#[no_mangle]
extern "C" fn deo_r_entry(vm: &amp;mut Uxn, dev: &amp;mut DeviceHandle) -&gt; bool {
    vm.deo::&lt;0b010&gt;(dev.0, 0).is_some()
}

// etc, 16 functions in total for all DEI / DEO variants
</code></pre>
<p>The full path of the function looks something like this:</p>
<p><img src="https://www.mattkeeter.com/blog/2024-07-12-interpreter/deo.png" alt="diagram showing deo calls"></p>
<p>On the assembly side, there's one subtlety: during our normal opcode processing,
we keep data and return stack index values in <code>x1</code> and <code>x3</code> (leaving the
original values in the <code>&amp;mut Uxn</code> unchanged).  We have to write those registers
back into the appropriate memory locations in the <code>&amp;mut Uxn</code> <em>before</em> calling a
function that expects those values to be correct.</p>
<p>Here's the assembly code to call into our shim functions:</p>
<pre><code>.global _DEI
_DEI:
    ; We have to write our stack index pointers back into the &amp;mut Uxn
    ldp x11, x12, [sp, 0x10] ; restore stack index pointers
    strb w1, [x11]   ; modify stack index pointer
    strb w3, [x12]   ; modify return stack index pointer

    ; We're using caller-saved registers, so we have to back them up
    stp x0, x1, [sp, #0x20] ; store register state
    stp x2, x3, [sp, #0x30]
    stp x5, x4, [sp, #0x40]
    stp x6, x7, [sp, #0x50]
    str x8,     [sp, #0x60]

    ; set up our arguments, then call the shim function:
    mov x0, x6 ; x0 = Uxn pointer
    mov x1, x7 ; x1 = DeviceHandle pointer
    bl _dei_entry

    ldp x0, x1, [sp, #0x20] ; restore register state
    ldp x2, x3, [sp, #0x30]
    ldp x5, x4, [sp, #0x40]
    ldp x6, x7, [sp, #0x50]
    ldr x8,     [sp, #0x60]

    ; The DEO operation may have changed stack pointers, so reload them here 
    ldp x11, x12, [sp, 0x10]
    ldrb w1, [x11]  ; update stack index pointer
    ldrb w3, [x12]  ; update return stack index pointer
    next
</code></pre>
<h3>Performance</h3>
<p>I used two CPU-heavy workloads to test interpreter performance:</p>
<ul>
<li><a href="https://git.sr.ht/%7Erabbits/uxn/tree/main/item/projects/examples/exercises/fib.tal"><code>fib.tal</code></a>,
modified to print the first <strong>35</strong> numbers of the Fibonacci sequence</li>
<li><a href="https://git.sr.ht/%7Erabbits/uxn/tree/main/item/projects/examples/demos/mandelbrot.tal"><code>mandelbrot.tal</code></a>,
with <code>%SCALE</code> set to <code>#0020</code> (rendering a 672 × 512 image)</li>
</ul>
<p>Both of these programs do all of their computation at startup, so I added
instrumentation to print time spent in the entry vector (at <code>0x100</code>).</p>
<p>There are four different implementations being tested here:</p>
<ul>
<li>The <a href="https://git.sr.ht/%7Erabbits/uxn/"><code>uxnemu</code></a> reference implementation,
running natively on my laptop</li>
<li>The baseline <code>raven-uxn</code> interpreter, running natively on my laptop</li>
<li>The optimized <code>raven-uxn</code> interpreter (hand-written in assembly), running
natively on my laptop</li>
<li>The baseline <code>raven-uxn</code> interpreter, running in my browser (compiled to
WebAsembly)</li>
</ul>
<p>Here are the performance numbers that you've been waiting for:</p>
<table>
    <tbody><tr><th>Interpreter</th><th>Target</th><th>Fibonacci</th><th>Mandelbrot
    </th></tr><tr><td><code>uxnemu</code> (reference)</td><td><code>AArch64</code></td><td>1.57 s</td><td>2.03 s
    </td></tr><tr><td><code>raven-uxn</code> (baseline)</td><td><code>AArch64</code></td><td>1.38 s</td><td>1.56 s
    </td></tr><tr><td><code>raven-uxn</code> (assembly)</td><td><code>AArch64</code></td><td>1.00 s</td><td>1.10 s
    </td></tr><tr><td><code>raven-uxn</code> (baseline)</td><td><code>wasm32</code></td><td>2.54 s</td><td>2.82 s
</td></tr></tbody></table>
<p>There are three clear trends:</p>
<ul>
<li><code>raven-uxn</code>'s baseline interpreter (written in safe Rust) is faster than the
reference implementation; we already knew that from previous work</li>
<li>The assembly implementation is about <strong>30% faster</strong> than the baseline!</li>
<li>WebAssembly encurs a roughly 1.8× slowdown compared to the baseline</li>
</ul>
<h3>Ablation testing</h3>
<p>It's not obvious whether the speedup is due to keeping values in registers, or
adding dispatch to the end of each opcode (instead of a central branch).</p>
<p>We can easily test for the latter by changing our <code>next</code> macro:</p>
<pre><code>.macro next
    b next_dispatch
.endm
next_dispatch:
    ldrb w9, [x4, x5]
    add x5, x5, #1
    and x5, x5, #0xffff
    ldr x10, [x8, x9, lsl #3]
    br x10
</code></pre>
<p>Adding these new results to the chart( as "assembly*"), here's what I see:</p>
<table>
    <tbody><tr><th>Interpreter</th><th>Target</th><th>Fibonacci</th><th>Mandelbrot
    </th></tr><tr><td><code>raven-uxn</code> (baseline)</td><td><code>AArch64</code></td><td>1.38 s</td><td>1.56 s
    </td></tr><tr><td><code>raven-uxn</code> (assembly)</td><td><code>AArch64</code></td><td>1.00 s</td><td>1.10 s
    </td></tr><tr><td><code>raven-uxn</code> (assembly*)</td><td><code>AArch64</code></td><td>1.34 s</td><td>1.41 s
</td></tr></tbody></table>
<p>Centralized dispatch is a significant slowdown, and is nearly as slow as the
baseline interpreter!
It just goes to show:
<a href="https://www.mattkeeter.com/blog/2023-01-25-branch/">do not taunt happy fun branch predictor</a>.</p>
<h3>Things that didn't work</h3>
<p>I did a bunch of other experiments, which didn't make things faster:</p>
<ul>
<li>Expanding RAM to store both user bytes and the jump targets (i.e. making RAM a
<code>[u64; 65536]</code>).  The user byte is stored in bits 48-54 of the pointer, since
those are unused, and I added masking + shifting depending on whether we were
using the data or pointer component.  This was noticeably slower, probably
because it's less cache-friendly (512 KiB, rather than 64 KiB + 1 KiB of jump
table)</li>
<li>Making all of the opcode implementations the same size (padding to the size of
the largest opcode implementation with <code>.balign 256</code>), then removing the jump
table entirely.  This was also slower, also probably because of cache
friendliness: the opcode implementations go from 16.6 KiB total to 64 KiB.</li>
</ul>
<h3>Conclusion</h3>
<p>I've proven to my satisfaction that writing an interpreter in assembly is both
fun and performant!</p>
<p>There are strategies to get similar performance in high-level languages:
<a href="https://eli.thegreenplace.net/2012/07/12/computed-goto-for-efficient-dispatch-tables">using computed goto</a>
and the <a href="https://github.com/wasm3/wasm3/blob/main/docs/Interpreter.md#m3-massey-meta-machine">Massey Meta Machine</a>
are both relevant prior art.</p>
<p>However, neither of these are feasible in Rust; to quote
<a href="https://pliniker.github.io/post/dispatchers/">this excellent writeup</a>.</p>
<blockquote>
<p>At this time there is no portable way to produce computed gotos or tail call
optimization in compiled machine code from Rust.</p>
</blockquote>
<p>On a brighter note, it should be relatively easy to port all of the assembly
code to x86-64, but I'll leave that as a challenge for someone else!</p>
<p>All of the relevant code is <a href="https://github.com/mkeeter/raven">on Github</a>, gated
by the <code>native</code> feature.  The <code>uxn-cli</code> and <code>uxn-gui</code> executables both accept a
<code>--native</code> flag to select the assembly interpreter backend.</p>
<p>Have fun!</p>

<!-- Begin footer -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What could explain the gallium anomaly? (180 pts)]]></title>
            <link>https://www.quantamagazine.org/what-could-explain-the-gallium-anomaly-20240712/</link>
            <guid>40948202</guid>
            <pubDate>Fri, 12 Jul 2024 18:35:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/what-could-explain-the-gallium-anomaly-20240712/">https://www.quantamagazine.org/what-could-explain-the-gallium-anomaly-20240712/</a>, See on <a href="https://news.ycombinator.com/item?id=40948202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody"><div><p>Physicists have ruled out a mundane explanation for the strange findings of an old Soviet experiment, leaving open the possibility that the results point to a new fundamental particle.</p></div><figure><div><p><img alt="" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/07/GalliumAnomaly-crNicoRoper-Lede-scaled.webp"></p></div><figcaption><div><p>Gallium occasionally converts into germanium, but not as often as expected.</p><p>Nico Roper/<em>Quanta Magazine</em></p></div></figcaption></figure><div><h2>Introduction</h2><div><p>Deep in the Caucasus Mountains, on the border between Russia and Georgia, an unusual experiment is taking place. In an underground lab shielded by a mountain of rock, highly radioactive material sits inside a vat of liquid gallium, blasting out particles called neutrinos that break the gallium down into atoms of germanium.</p>
<p>The goal is to resolve a little-known mystery of physics: the gallium anomaly. “I think it’s one of the most compelling anomalies in neutrino physics that we have today,” said <a href="https://www.uta.edu/academics/faculty/profile?username=jonesb">Ben Jones</a>, a neutrino physicist at the University of Texas, Arlington. Some three decades ago, in a previous version of the current experiment, scientists first detected a dearth of the expected germanium atoms that still can’t be explained.</p>
<p>Since then, physicists have worked to rule out possible mismeasurements or inaccuracies that could explain the anomaly. Now they’ve eliminated another one. <a href="https://nuc.berkeley.edu/people/eric-norman/">Eric Norman</a>, a nuclear physicist at the University of California, Berkeley, and colleagues <a href="https://journals.aps.org/prc/abstract/10.1103/PhysRevC.109.055501#fulltext">have announced</a> that one possible solution, an incorrect calculation of the half-life of germanium, can’t be the cause.</p>
<p>“The half-life is correct,” Norman said. “This is not the explanation for the gallium anomaly.”</p>
<p>That leaves few possibilities. One is that some still-unknown experimental defect caused the anomaly. Perhaps a different mismeasurement is throwing things off, or a misunderstanding of nuclear physics. Or maybe, just maybe, the anomaly points to a monumental discovery, the existence of a new type of elementary particle called a sterile neutrino. Sterile neutrinos were initially proposed to explain why the masses of the three known neutrinos are so tiny, but they could also account for at least some of the invisible “dark matter” that fills the cosmos.</p>
<p>“We cannot find some huge uncertainty in our experimental procedures,” said Vladislav Barinov, a particle physicist at the Institute for Nuclear Research of the Russian Academy of Sciences who works on the experiment in the Caucasus. “Is it a new type of neutrino? We don’t know.”</p>
<h2><strong>Neutrino Village</strong></h2>
<p>At the height of the Cold War, before the fall of the Berlin Wall in 1989 and the subsequent dissolution of the Soviet Union, an unlikely partnership arose in the form of an experiment called SAGE, the Soviet-American Gallium Experiment. “The Soviet Union had a phenomenal group of theoretical scientists,” said Steven Elliott, a nuclear physicist at Los Alamos National Laboratory who worked on the project. But they lacked money and access to certain technologies that would make SAGE possible, he said. “Los Alamos was able to provide those types of resources.”</p>
</div></div><figure><div><p><img alt="" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/07/BaksanNeutrinoObservatory-crMaximBabenko_TheNewYorkTimes_Diptych-scaled.webp"></p></div><figcaption><div><p>For the last half-century, physicists have studied neutrinos in experiments deep underground at the Baksan Neutrino Observatory in Russia’s Caucasus Mountains. In the lab that houses the BEST experiment, fish serve as an early warning system about any leaking radiation.</p><p>Maxim Babenko/The New York Times</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>SAGE was constructed at the Baksan Neutrino Observatory, a <a href="https://cerncourier.com/a/baksan-scales-new-neutrino-heights/">neutrino physics facility</a> built in the 1960s and 1970s inside a mountain in Russia’s Baksan Valley, about 3 miles from the Georgian border. The 13,000-foot-tall Mount Andyrchi shielded the facility from cosmic rays and other sources of noise, allowing precise neutrino experiments to take place.</p>
<p>A nearby residential area called Neutrino Village housed the families of the scientists who worked at the facility, as well as visiting international scientists like Elliott. “I did go out for a number of trips,” he said. “I found it an adventure.”</p>
<p>SAGE began in 1989 and continued for more than 20 years despite attempts by the Russian government to <a href="https://www.science.org/content/article/new-twist-gallium-struggle">sell its gallium</a>, a precious metal that’s liquid at room temperature. The project was designed to investigate the solar neutrino problem, a measured deficit of neutrinos streaming from the sun. Specifically, scientists were finding a shortage of electron neutrinos, one of three known types, or “flavors.” That problem was ultimately resolved in the 2000s with the <a href="https://www.symmetrymagazine.org/article/nobel-prize-awarded-for-discovery-of-neutrino-oscillations">Nobel Prize-winning discovery</a> that neutrinos oscillate between flavors as they travel. By the time many of the electron neutrinos from the sun reach Earth, they have become something else.</p>
<p>SAGE used a tank of 57 metric tons of gallium. Incoming electron neutrinos would occasionally combine with a neutron inside a gallium atom and convert it into a proton, turning the gallium into germanium. The scientists counted the germanium atoms in a monthlong extraction process. They chose gallium for the experiment because it has a “low threshold for this reaction,” Elliott said. A similar experiment began in Italy in 1991, called Gallex.</p>
</div></div><figure><div><p><img alt="" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/07/GALLAXExperimentAtGranSassoLab-crTommasoGuicciardini_INFN_ScienceSource.webp"></p></div><figcaption><div><p>A researcher with the Gallex experiment, which ran in the 1990s at Gran Sasso National Laboratory in Italy, is shown holding a device called a proportional counter that was used for detecting germanium atoms.</p><p>Tommaso Guicciardini/INFN/ScienceSource</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>In the mid-1990s, researchers tweaked both experiments to use neutrinos from radioactive elements. They hoped to avoid unknown errors related to the solar neutrino problem. But both experiments generated roughly 20% less germanium than expected — surprise results that couldn’t have been caused by the solar neutrino problem. “They exactly knew the source activity and how many neutrinos are produced,” said Inwook Kim, a nuclear physicist at Los Alamos. Soon, the puzzling discrepancy had a name: the gallium anomaly. “It was really surprising,” Barinov said.</p>
<p>A follow-up experiment that began at Baksan in 2014, called the Baksan Experiment on Sterile Transitions (BEST), uses two gallium chambers instead of one, to determine whether the anomaly could be explained by the distance from the source of the neutrinos. “BEST was constructed to resolve this tension,” said Barinov, who has worked on the experiment since 2015. But both chambers have continued to show a shortfall relative to what models predict. “It’s a really unusual result,” he said.</p>
<h2><strong>Half-Life Theory</strong></h2>
<p>Repeated results from BEST continue to show the anomaly <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.128.232501">as recently as 2022</a>. One chamber contained only 79% of the expected amount of germanium, the other only 77%. “Everybody was hoping that anomaly would go away,” said Wick Haxton, a theoretical physicist at Berkeley. “There is still not any clean understanding of what’s going on.”</p>
<p>A possible explanation was floated: that the half-life of germanium-71 (the specific isotope produced in the experiment), <a href="https://journals.aps.org/prc/abstract/10.1103/PhysRevC.31.666">measured</a> in 1985 to be 11.43 days, was actually longer. The same constant controls germanium-71’s decay rate and the rate at which gallium captures neutrinos to produce that germanium. That means a longer germanium-71 half-life would imply a lower rate of neutrino capture and hence germanium production, which could explain the lack of germanium seen by SAGE, Gallex and BEST.</p>
</div></div><figure><div><p><img alt="A young man wearing a red scarf stands in front of a mountain." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/07/VladislavBarinov-crSviatoslavBorisov.webp"></p></div><figcaption><div><p>Vladislav Barinov, a particle physicist at the Institute for Nuclear Research of the Russian Academy of Sciences, is part of the team that reported the anomalous results of the BEST experiment.</p><p>Sviatoslav Borisov</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>Norman and colleagues published a reinvestigation of this half-life in <a href="https://journals.aps.org/prc/abstract/10.1103/PhysRevC.109.055501"><em>Physical Review C</em></a> in late May. Using a nuclear reactor at the McClellan Nuclear Research Center at the University of California, Davis, they irradiated “very pure germanium material,” Norman said, producing germanium-71. They then analyzed the samples over 80 days to see how long it took the atoms to decay.</p>
<p>They arrived at a half-life of 11.468 days, extremely close to the 1985 measurement, ruling the half-life out as the explanation for the gallium anomaly. While no one ever quite believed the original half-life measurement to be wildly incorrect, researchers still considered it worth checking. “It was a measurement that needed to be done,” Jones said.</p>
<p>Another proposed explanation was that physicists had miscalculated the probability of neutrinos from the source interacting with the gallium. But in September 2023, Haxton and his colleagues <a href="https://journals.aps.org/prc/abstract/10.1103/PhysRevC.108.035502">also ruled out this possibility</a>. “You can’t get rid of the anomaly,” he said.</p>
<p>That leaves physicists in an uncomfortable position. Either there is still some error that no one has thought of, or, as Haxton put it, “something unusual is going on with neutrinos.” For instance, the experiments might point to a controversial additional type of neutrino, undetected by most other experiments, that might also help to explain dark matter.</p>
<h2><strong>Sterile Neutrinos</strong></h2>
<p>The three known flavors of neutrinos, which are all millions of times lighter than electrons, interact with other elementary particles via the weak force, which makes them detectable. Sterile neutrinos, on the other hand, would interact only via gravity. If they’re much heavier than the known neutrinos, their existence could explain why the known neutrinos are so light, through an inverse relationship hypothesized around 1980 called the seesaw mechanism.</p>
</div></div><figure><div><p><img alt="A yellow-lit laboratory crammed with equipment, including a set of 10 chemical reactors with red caps." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/07/Gallium%E2%80%93Germanium_Neutrino_Telescope_main_room_-_2010-07-19_-_DSC_0764.webp"></p></div><figcaption><div><p>The experimental apparatus used in the SAGE and BEST experiments at the Baksan Neutrino Observatory.</p><p>Konstantin Malanchev</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>The gallium anomaly, however, would point toward a lighter-weight sterile neutrino, with the electron neutrinos emitted by the radioactive source sometimes oscillating into a sterile neutrino that wouldn’t interact with the gallium.</p>
<p>In some models, lightweight sterile neutrinos could comprise a fraction of the universe’s dark matter, though not all of it because they would be too light to gravitationally shape the universe in the way dark matter does. “They could be a small subset of it,” said <a href="https://physics.mit.edu/faculty/lindley-winslow/">Lindley Winslow</a>, an experimental nuclear and particle physicist at the Massachusetts Institute of Technology.</p>
<p>Other attempts to find sterile neutrinos by studying neutrino oscillation patterns, however, have been largely unsuccessful. The number of researchers who support the light sterile neutrino “is sort of shrinking,” Winslow said. <a href="https://sites.uci.edu/abazajian/">Kevork Abazajian</a>, an astrophysicist at the University of California, Irvine, said they are the “underdogs of the particle physics community.”</p>
<p>If they do exist, light sterile neutrinos will “wreak havoc” on our current understanding of cosmology, Abazajian said, including ideas of how atoms formed in the minutes following the Big Bang and the theory of the cosmic microwave background, the remnant heat from the initial expansion of the universe. “You would expect to see the presence of this extra neutrino,” Abazajian said. However, he added that <a href="https://arxiv.org/abs/2205.09777">recent work has shown</a> that alternative models of the sequence of events in those first minutes “can accommodate light sterile neutrinos.”</p>

<p>In lieu of other explanations for the gallium anomaly, light sterile neutrinos remain a possibility that we just can’t eradicate. “I’ve been a bit skeptical of the sterile neutrino hypothesis, but I can’t tell you why it’s not right,” Elliott said. “There’s never been a convincing explanation of why the experiment might be wrong.”</p>
<p>While Russia’s invasion of Ukraine “has complicated things,” Elliott said, the collaboration between the U.S. and Russia on BEST is still ongoing, for now. Barinov says the team at Baksan is considering using a new source of neutrinos, such as zinc, to further test the result. They may even construct a third chamber of gallium around the source. For now, the anomaly remains unsolved, with no sign of a resolution on the horizon. “It has us all puzzled,” Haxton said.</p>
</div></div></div><div><h2>Next article</h2><p>How America’s Fastest Swimmers Use Math to Win Gold</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CISA broke into a US federal agency, and no one noticed for a full 5 months (172 pts)]]></title>
            <link>https://www.theregister.com/2024/07/12/cisa_broke_into_fed_agency/</link>
            <guid>40948064</guid>
            <pubDate>Fri, 12 Jul 2024 18:19:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/07/12/cisa_broke_into_fed_agency/">https://www.theregister.com/2024/07/12/cisa_broke_into_fed_agency/</a>, See on <a href="https://news.ycombinator.com/item?id=40948064">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The US Cybersecurity and Infrastructure Security Agency (CISA) says a red team exercise at a certain unnamed federal agency in 2023 revealed a string of security failings that exposed its most critical assets.</p>
<p>CISA calls these SILENTSHIELD assessments. The agency's dedicated red team picks a federal civilian executive branch (FCEB) agency to probe and does so without prior notice – all the while trying to simulate the maneuvers of a long term hostile nation-state threat group.</p>
<p>According to the agency's account of the exercise, the red team was able to gain initial access by exploiting an unpatched vulnerability (<a target="_blank" href="https://www.theregister.com/2024/02/27/manufacturing_sector_malware/">CVE-2022-21587</a> - 9.8) in the target agency's Oracle Solaris enclave, leading to what it said was a full compromise.</p>

    

<p>It's worth noting that CVE-2022-21587, an unauthenticated remote code execution (RCE) bug carrying a near-maximum 9.8 CVSS rating, was added to CISA's known exploited vulnerability (KEV) catalog in February 2023. The initial intrusion by CISA's red team was made on January 25, 2023.</p>

        


        

<p>"After gaining access, the team promptly informed the organization's trusted agents of the unpatched device, but the organization took over two weeks to apply the available patch," CISA's report reads. "Additionally, the organization did not perform a thorough investigation of the affected servers, which would have turned up IOCs and should have led to a full incident response.&nbsp;</p>
<p>"About two weeks after the team obtained access, exploit code was released publicly into a popular open source exploitation framework. CISA identified that the vulnerability was exploited by an unknown third party. CISA added this CVE to its Known Exploited Vulnerabilities Catalog on February 2, 2023."</p>

        

<p>Vulnerabilities added to the KEV catalog mean a few things. First, they are serious, known to be exploited by cybercriminals, and can lead to serious consequences. Second, when bugs are added to the catalog, they also come with deadlines by which FCEB agencies have to patch them.</p>
<p>Since introducing the KEV catalog, CISA has always been cagey about the degree to which federal agencies meet these deadlines, but this case shows they aren't always being met.</p>
<p><em>The Register</em> fielded a question about deadline compliance to CISA's director Jen Easterly at the <a href="https://www.theregister.com/2024/07/01/cisa_big_tech_security/">Oxford Cyber Forum</a> last month who said, without referring to specific figures she didn't have access to at the time, that "compliance is very high." Plus, a recent survey showed the catalog is <a href="https://www.theregister.com/2024/05/07/cisas_vulnerability_deadlines/">helping the private sector too</a>.</p>

        

<p>After gaining access to the Solaris enclave, the red team discovered they couldn't pivot into the Windows part of the network because missing credentials blocked their path, despite enjoying months of access to sensitive web apps and databases.</p>
<p>Undeterred, CISA managed to make its way into the Windows network after carrying out <a href="https://www.theregister.com/2024/05/23/google_phishing_tests/">phishing attacks</a> on unidentified members of the target agency, one of which was successful.</p>
<p>It said real adversaries may have instead used prolonged password-praying attacks rather than phishing at this stage, given that several service accounts were identified as having <a href="https://www.theregister.com/2024/04/29/uk_lays_password_legislation/">weak passwords</a>.</p>
<p>After gaining that access, the red team injected a persistent RAT and later discovered unsecured admin credentials, which essentially meant it was game over for the agency being assessed.&nbsp;</p>
<p>"None of the accessed servers had any noticeable additional protections or network access restrictions despite their sensitivity and critical functions in the network," CISA said.</p>
<p>CISA described this as a "full domain compromise" that gave the attackers access to tier zero assets – the most highly privileged systems.</p>
<p>"The team found a password file left from a previous employee on an open, administrative IT share, which contained plaintext usernames and passwords for several privileged service accounts," the report reads. "With the harvested Lightweight Directory Access Protocol (LDAP) information, the team identified one of the accounts had system center operations manager (SCOM) administrator privileges and domain administrator privileges for the parent domain.&nbsp;</p>
<p>"They identified another account that also had administrative permissions for most servers in the domain. The passwords for both accounts had not been updated in over eight years and were not enrolled in the organization's identity management (IDM)."</p>
<p>From here, the red team realized the victim organization had trust relationships with multiple external FCEB organizations, which CISA's team then pivoted into using the access they already had.</p>
<p>The team "kerberoasted" one partner organization. Kerberoasting is an attack on the Kerberos authentication protocol typically used in Windows networks to authenticate users and devices. However, it wasn't able to move laterally with the account due to low privileges, so it instead used those credentials to exploit a second trusted partner organization. Kerberoasting yielded a more privileged account at the second external org, the password for which was crackable.</p>
<p>CISA said that due to network ownership, legal agreements, and/or vendor opacity, these kinds of cross-organizational attacks are rarely tested during assessments.</p>
<p>However, SILENTSHIELD assessments are able to be carried out following new-ish powers afforded to CISA by the FY21 National Defense Authorization Act (NDAA), the same powers that also allow CISA's Federal Attack Surface Testing (FAST) pentesting program to operate.</p>
<p>It's crucial that these avenues are able to be explored in such exercises because they're routes into systems adversaries will have no reservations about exploring in a real-world scenario.</p>
<h3>Disclosure time</h3>
<p>For the first five months of the assessment, the target FCEB agency failed to detect or remediate any of the SILENTSHIELD activity, raising concerns over its ability to spot genuine malicious activity.</p>
<p>Detection issues were suspected earlier in the proceedings. The RAT, which was injected in the Solaris phase of the exercise, caused 8GB of network traffic to flow through its C2 seemingly without alerting anyone at the agency, for example.</p>
<p>After CISA eventually put the agency out of its misery, weekly meetings were held with its security team and sysadmins which led to "measurable improvements in response times for known techniques and behavior-based detections that uncovered previously unknown tradecraft."</p>
<p>One of the main issues discussed in the post mortem was the agency's log collection, which was deemed to be "ineffective and inefficient." Various issues impeded the agency's ability to collect logs, which you can read about in the <a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa24-193a" rel="nofollow">full writeup</a>, but CISA's compromise of Solaris and Windows hosts had a big impact as packet capturing happened here, and so CISA was able to disrupt the process.</p>
<ul>

<li><a href="https://www.theregister.com/2024/07/02/supreme_court_chevron/">Brace for new complications in big tech takedowns after Supreme Court upended regulatory rules</a></li>

<li><a href="https://www.theregister.com/2024/06/28/cisa_open_source/">CISA looked at C/C++ projects and found a lot of C/C++ code. Wanna redo any of it in Rust?</a></li>

<li><a href="https://www.theregister.com/2024/06/27/congress_china_drones/">US lawmakers wave red flags over Chinese drone dominance</a></li>

<li><a href="https://www.theregister.com/2024/07/11/fcc_warns_yet_again_of/">FCC: US telcos a long way off, several billions short of removing Chinese kit</a></li>
</ul>
<p>The assessed agency also placed too great a reliance on known indicators of compromise (IoCs) for detecting intrusions, plus various system misconfigurations and procedural issues hindered the analysis of network activity.&nbsp;</p>
<p>CISA said the exercise demonstrated the need for FCEB agencies to apply defense-in-depth principles – multiple layers of detection and analysis measures for maximum effectiveness. Network segmentation was recommended and the red team wanted to stress the danger of over-relying on known IOCS.</p>
<p>It also wouldn't be a CISA communiqué without a plug for its <a href="https://www.theregister.com/2024/05/09/68_tech_firms_sign_cisas/">secure-by-design</a> push. It said that insecure software contributes to the issues faced by the target agency and re-upped its call to stamp out default passwords, provide free logging to customers, and for vendors to work with SIEM and SOAR providers to make better use of those logs. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hackers Steal Phone, SMS Records for Nearly All AT&T Customers (309 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/07/hackers-steal-phone-sms-records-for-nearly-all-att-customers/</link>
            <guid>40948035</guid>
            <pubDate>Fri, 12 Jul 2024 18:15:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/07/hackers-steal-phone-sms-records-for-nearly-all-att-customers/">https://krebsonsecurity.com/2024/07/hackers-steal-phone-sms-records-for-nearly-all-att-customers/</a>, See on <a href="https://news.ycombinator.com/item?id=40948035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p><strong>AT&amp;T Corp.</strong> disclosed today that a new data breach has exposed phone call and text message records for roughly 110 million people — nearly all of its customers. AT&amp;T said it delayed disclosing the incident in response to “national security and public safety concerns,” noting that some of the records included data that could be used to determine where a call was made or text message sent. AT&amp;T also acknowledged the customer records were exposed in a cloud database that was protected only by a username and password (no multi-factor authentication needed).</p>
<p><img decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2023/03/attbldg.png" alt="" width="749" height="497"></p>
<p>In <a href="https://www.sec.gov/Archives/edgar/data/732717/000073271724000046/t-20240506.htm" target="_blank" rel="noopener">a regulatory filing</a> with the <strong>U.S. Securities and Exchange Commission</strong> today, AT&amp;T said cyber intruders accessed an AT&amp;T workspace on a third-party cloud platform in April, downloading files containing customer call and text interactions between May 1 and October 31, 2022, as well as on January 2, 2023.</p>
<p>The company said the stolen data includes records of calls and texts for mobile providers that resell AT&amp;T’s service, but that it does not include the content of calls or texts, Social Security numbers, dates of birth, or any other personally identifiable information.</p>
<p>However, the company said a subset of stolen records included information about the location of cellular communications towers closest to the subscriber, data that could be used to determine the approximate location of the customer device initiating or receiving those text messages or phone calls.</p>
<p>“While the data does not include customer names, there are often ways, using publicly available online tools, to find the name associated with a specific telephone number,” AT&amp;T allowed.</p>
<p>AT&amp;T’s said it learned of the breach on April 19, but delayed disclosing it at the request of federal investigators. The company’s SEC disclosure says at least one individual has been detained by the authorities in connection with the breach.</p>
<p>In a written statement shared with KrebsOnSecurity, the FBI confirmed that it asked AT&amp;T to delay notifying affected customers.</p>
<p>“Shortly after identifying a potential breach to customer data and before making its materiality decision, AT&amp;T contacted the FBI to report the incident,” the FBI statement reads. “In assessing the nature of the breach, all parties discussed a potential delay to public reporting under Item 1.05(c) of the SEC Rule, due to potential risks to national security and/or public safety. AT&amp;T, FBI, and DOJ worked collaboratively through the first and second delay process, all while sharing key threat intelligence to bolster FBI investigative equities and to assist AT&amp;T’s incident response work.”</p>
<p><a href="https://techcrunch.com/2024/07/12/att-phone-records-stolen-data-breach/?guccounter=1" target="_blank" rel="noopener">Techcrunch</a> quoted an AT&amp;T spokesperson saying the customer data was stolen as a result of a still-unfolding data breach involving more than 160 customers of the cloud data provider <strong>Snowflake</strong>.</p>
<p>Earlier this year, malicious hackers figured out that many major companies have uploaded massive amounts of valuable and sensitive customer data to Snowflake servers, all the while protecting those Snowflake accounts with little more than a username and password.<span id="more-68041"></span></p>
<p><a href="https://www.wired.com/story/epam-snowflake-ticketmaster-breach-shinyhunters/" target="_blank" rel="noopener">Wired reported</a> last month how the hackers behind the Snowflake data thefts purchased stolen Snowflake credentials from dark web services that sell access to usernames, passwords and authentication tokens that are siphoned by information-stealing malware. For its part, Snowflake says it now requires all new customers to use multi-factor authentication.</p>
<p>Other companies with millions of customer records stolen from Snowflake servers include <strong>Advance Auto Parts</strong>, <strong>Allstate</strong>, <strong>Anheuser-Busch</strong>, <strong>Los Angeles Unified</strong>, <strong>Mitsubishi</strong>, <strong>Neiman Marcus</strong>, <strong>Progressive</strong>, <strong>Pure Storage</strong>, <strong>Santander Bank</strong>, <strong>State Farm</strong>, and <strong>Ticketmaster</strong>.</p>
<p>Earlier this year, AT&amp;T <a href="https://techcrunch.com/2024/03/30/att-reset-account-passcodes-customer-data/" target="_blank" rel="noopener">reset passwords for millions of customers</a> after the company <a href="https://krebsonsecurity.com/2022/08/it-might-be-our-data-but-its-not-our-breach/" target="_blank" rel="noopener">finally acknowledged a data breach from 2018</a> involving approximately 7.6 million current AT&amp;T account holders and roughly 65.4 million former account holders.</p>
<p><strong>Mark Burnett</strong> is an application security architect, consultant and author. Burnett said the only real use for the data stolen in the most recent AT&amp;T breach is to know who is contacting whom and how many times.</p>
<p>“The most concerning thing to me about this AT&amp;T breach of ALL customer call and text records is that this isn’t one of their main databases; it is metadata on who is contacting who,” Burnett <a href="https://infosec.exchange/@zcutlip@hachyderm.io/112774443764622821" target="_blank" rel="noopener">wrote</a> on Mastodon. “Which makes me wonder what would call logs without timestamps or names have been used for.”</p>
<p>It remains unclear why so many major corporations persist in the belief that it is somehow acceptable to store so much sensitive customer data with so few security protections. For example, Advance Auto Parts said the data exposed included full names, Social Security numbers, drivers licenses and government issued ID numbers on <a href="https://www.bleepingcomputer.com/news/security/advance-auto-parts-data-breach-impacts-23-million-people/" target="_blank" rel="noopener">2.3 million people</a> who were former employees or job applicants.</p>
<p>That may be because, apart from the class-action lawsuits that invariably ensue after these breaches, there is little holding companies accountable for sloppy security practices. AT&amp;T told the SEC it does not believe this incident is likely to materially impact AT&amp;T’s financial condition or results of operations. AT&amp;T reported revenues of more than $30 billion in its most recent quarter.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-Meta scientists debut gigantic AI protein design model (117 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-02214-x</link>
            <guid>40947540</guid>
            <pubDate>Fri, 12 Jul 2024 17:22:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-02214-x">https://www.nature.com/articles/d41586-024-02214-x</a>, See on <a href="https://news.ycombinator.com/item?id=40947540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-02214-x/d41586-024-02214-x_27319756.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-02214-x/d41586-024-02214-x_27319756.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Molecular model of the bright green fluorescent protein StayGold from Cytaeis uchidae." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-02214-x/d41586-024-02214-x_27319756.jpg">
  <figcaption>
   <p><span>A structural model of green fluorescent protein, a workhorse of biotechnology.</span><span>Credit: Laguna Design/Science Photo Library</span></p>
  </figcaption>
 </picture>
</figure><p>An <a href="https://www.nature.com/subjects/machine-learning" data-track="click" data-label="https://www.nature.com/subjects/machine-learning" data-track-category="body text link">artificial intelligence</a> (AI) model that speaks the <a href="https://www.nature.com/subjects/protein-design" data-track="click" data-label="https://www.nature.com/subjects/protein-design" data-track-category="body text link">language of proteins</a> — one of the largest yet developed for biology — has been used to create new fluorescent molecules.</p><p>The proof-of-principle demonstration was announced this month by EvolutionaryScale in New York City, alongside US$142 million in new funding to apply its model to <a href="https://www.nature.com/articles/d41586-023-02227-y" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02227-y" data-track-category="body text link">drug development</a>, sustainability and other pursuits. The company, launched by scientists who previously worked at tech giant Meta, is the latest entrant in an increasingly crowded field that is applying cutting-edge machine-learning models trained on language and images to biological data.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02227-y" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02214-x/d41586-024-02214-x_26069432.jpg"><p>AI tools are designing entirely new proteins that could transform medicine</p></a>
 </article><p>“We want to build tools that can make biology programmable,” says Alex Rives, the company’s chief scientist, who was part of Meta’s efforts to apply AI to biological data.</p><p>EvolutionaryScale’s AI tool, called ESM3, is what’s known as a protein language model. It was trained on more than 2.7 billion protein sequences and structures, as well as information about these proteins’ functions. The model can be used to <a href="https://www.nature.com/articles/d41586-023-02227-y" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02227-y" data-track-category="body text link">create proteins</a> to specifications provided by users, akin to the text spit out by chatbots such as ChatGPT.</p><p>“It’s going to be one of the AI models in biology that everybody’s paying attention to,” says Anthony Gitter, a computational biologist at the University of Wisconsin–Madison.</p><h2>Glowing up</h2><p>Rives and his colleagues worked on earlier iterations of the ESM model at Meta, but struck out on their own last year, after Meta ended its work in this area. They had previously used the model ESM-2 to create a <a href="https://www.nature.com/articles/d41586-022-03539-1" data-track="click" data-label="https://www.nature.com/articles/d41586-022-03539-1" data-track-category="body text link">freely available database of 600 million predicted protein structures</a><sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>. Other teams have since used versions of ESM-1 to <a href="https://www.nature.com/articles/d41586-023-01516-w" data-track="click" data-label="https://www.nature.com/articles/d41586-023-01516-w" data-track-category="body text link">design antibodies with improved activity against pathogens</a> including SARS-CoV-2<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> and to re-engineer ‘anti-CRISPR’ proteins to improve the efficiency of gene-editing tools<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup>.</p><p>This year, another biology AI company, Profluent in Berkeley, California, used its own protein language model to <a href="https://www.nature.com/articles/d41586-024-01243-w" data-track="click" data-label="https://www.nature.com/articles/d41586-024-01243-w" data-track-category="body text link">create new CRISPR-inspired gene-editing proteins</a>, and made one such molecule freely available for use.</p><p>To demonstrate its latest model, Rives’ team set out to overhaul another biotechnology workhorse: the green fluorescent protein (GFP), which absorbs blue light and glows green. Researchers isolated GFP in the 1960s, from the bioluminescent jellyfish <i>Aequorea victoria</i>. Later work — which, with the discovery, was recognized with a Nobel prize — showed how GFP could label other proteins viewed under a microscope, explained the molecular basis for its fluorescence and developed synthetic versions of the protein that glowed much more brightly and in different colours.</p><p>Researchers have since identified other similarly shaped fluorescent proteins, all sharing a light-absorbing and -emitting ‘chromophore’ core surrounded by a barrel-shaped scaffold. Rives’ team asked ESM3 to create examples of GFP-like proteins that contained a set of key amino acids found in GFP’s chromophore.</p><p>The researchers synthesized 88 of the most promising designs and measured their ability to fluoresce. Most were duds, but one design, dissimilar to known fluorescent proteins, glowed faintly — about 50 times weaker than natural forms of GFP. Using this molecule’s sequence as a starting point, the researchers tasked ESM3 with improving on its work. When the researchers made around 100 of the resulting designs, several were as bright as natural GFPs, which are still vastly dimmer than lab-engineered variants.</p><p>One of the brightest ESM3-designed proteins, dubbed esmGFP, is predicted to have a structure resembling those of natural fluorescent proteins. However, its amino-acid sequence is vastly different, matching less than 60% of the sequence of the most closely related fluorescent protein in its training data set. In a preprint posted on the server bioRxiv<sup><a href="#ref-CR4" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">4</a></sup>, Rives and his colleagues say that on the basis of natural mutation rates, this level of sequence difference equates to “over 500 million years of evolution”.</p><p>But Gitter worries that this comparison is an unhelpful, and potentially misleading, way of describing the product of a cutting-edge AI model. “It sounds scary when you think about AI and accelerating evolution,” he says. “I feel like overhyping what a model does can hurt the field and it can be dangerous for the public.”</p><p>Rives sees ESM3’s generation of new proteins by iterating through various sequences as analogous to evolution. “We think the perspective of what it would take for nature to generate something like this is an interesting one,” he adds.</p><h2>Risk threshold</h2><p>ESM3 is among the first biological AI models to use enough computing power during its training to require developers to notify the US government and report <a href="https://www.nature.com/articles/d41586-024-00699-0" data-track="click" data-label="https://www.nature.com/articles/d41586-024-00699-0" data-track-category="body text link">risk-mitigation measures</a>, under a 2023 presidential executive order. EvolutionaryScale says it has already been in touch with the US Office of Science and Technology Policy.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-00699-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02214-x/d41586-024-02214-x_26828914.jpg"><p>Could AI-designed proteins be weaponized? Scientists lay out safety guidelines</p></a>
 </article><p>The version of ESM3 that eclipsed that threshold — comprising nearly 100 billion parameters, or variables the model uses to represent relationships between sequences — is not publicly available. For a smaller open-source version, certain sequences, such as those from viruses and a US government list of worrying pathogens and toxins, were excluded from training. Neither can ESM3-open — which scientists anywhere can download and run independently — be prompted to generate such proteins.</p><p>Martin Pacesa, a structural biologist at the Swiss Federal Institute of Technology in Lausanne, is excited to begin working with ESM3. It is one of the first biological models to allow researchers to specify designs using natural-language descriptions of its properties and functions, he notes, and he is eager to see how this and other features perform experimentally.</p><p>Pacesa is impressed that EvolutionaryScale released an open-source version of ESM3, and a clear description of how the largest version was trained. But the largest model would take immense computing resources to develop independently, he says. “No academic lab will be able to replicate it.”</p><p>Rives is eager to apply ESM3 to other designs. Pacesa, who was part of the team that used a different protein language model to make new CRISPR proteins, says it will be interesting to see how ESM3 does at this. Rives envisions applications in sustainability — a video on the company’s website shows the design of plastic-eating enzymes — and in the development of antibodies and other protein-based drugs. “It’s really a model at the frontier,” he says.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Dropbase AI – A Prompt-Based Python Web App Builder (122 pts)]]></title>
            <link>https://github.com/DropbaseHQ/dropbase</link>
            <guid>40947415</guid>
            <pubDate>Fri, 12 Jul 2024 17:08:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/DropbaseHQ/dropbase">https://github.com/DropbaseHQ/dropbase</a>, See on <a href="https://news.ycombinator.com/item?id=40947415">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://www.dropbase.io/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/aeb3a756b72f99981f6265cba4f5f607a4c6ffbd265266bc65756b70756fe1a3/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3566326338373234366231376663663636323238323539342f3631323561316661313136303539326664333733643333625f44726f70626173652532306c6f676f253230776562736974652e737667" width="200px" alt="Dropbase logo" data-canonical-src="https://assets-global.website-files.com/5f2c87246b17fcf662282594/6125a1fa1160592fd373d33b_Dropbase%20logo%20website.svg">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prompt-Based Python Web App Builder</h2><a id="user-content-prompt-based-python-web-app-builder" aria-label="Permalink: Prompt-Based Python Web App Builder" href="#prompt-based-python-web-app-builder"></a></p>
<p dir="auto">
<a href="https://dropbase.io/" rel="nofollow">Website</a> · <a href="https://docs.dropbase.io/" rel="nofollow">Docs</a> · <a href="https://discord.gg/K4Hys7Czzp" rel="nofollow">Discord</a></p>
<p dir="auto">
  <a href="https://dropbase.io/" rel="nofollow">
      <img src="https://camo.githubusercontent.com/ca9c447690ada75cbecab748e5f13c660ae7c404545812f0f39a719c326b3c5b/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3566326338373234366231376663663636323238323539342f3636316630626131336162306262383961313864653032395f61646d696e70616e656c2d6865726f2e77656270" alt="Dropbase hero" data-canonical-src="https://cdn.prod.website-files.com/5f2c87246b17fcf662282594/661f0ba13ab0bb89a18de029_adminpanel-hero.webp">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">Dropbase helps you build and prototype web apps faster with AI. Developers can quickly build anything from admin panels, back-office tools, billing dashboards, and internal engineering tools that can fetch data and trigger action across any internal or external service.</p>
<p dir="auto">Existing low-code/no code tools lack flexibility, confine devs to building app logic by filling up UI forms, and have big learning curves. Dropbase uses AI to generate app code that you can verify and/or edit. We combine the convenience of a drag-and-drop app builder with the flexibility of code, making it easy to build and customize, while learning to use the product as you see how the AI generates code using the Dropbase web framework.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Dropbase?</h2><a id="user-content-why-dropbase" aria-label="Permalink: Why Dropbase?" href="#why-dropbase"></a></p>
<ol dir="auto">
<li>Write any custom business logic with code.</li>
<li>Built-in web framework with pre-built UI components - no need to hassle with frontend libraries/code.</li>
<li>Local-first, self-hosted. No creds are shared with us.</li>
<li>Dropbase lives in your codebase, making it easy to import or resuse custom scripts/libraries.</li>
<li>It's built on Python and you can import any PyPI package.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build a simple app to search for customer orders and send slack messages</h3><a id="user-content-build-a-simple-app-to-search-for-customer-orders-and-send-slack-messages" aria-label="Permalink: Build a simple app to search for customer orders and send slack messages" href="#build-a-simple-app-to-search-for-customer-orders-and-send-slack-messages"></a></p>
<a href="https://youtu.be/RaxHOjhy3hY" rel="nofollow">
  <img src="https://camo.githubusercontent.com/4f3ea18038e1001a81b5f33c04cb2763b2849448b08e4354bff1578840e41d02/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f526178484f6a68793368592f6d617872657364656661756c742e6a7067" data-canonical-src="https://img.youtube.com/vi/RaxHOjhy3hY/maxresdefault.jpg">
</a>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build an orders app that uses charts</h3><a id="user-content-build-an-orders-app-that-uses-charts" aria-label="Permalink: Build an orders app that uses charts" href="#build-an-orders-app-that-uses-charts"></a></p>
<a href="https://youtu.be/YWtdD7THTxE" rel="nofollow">
  <img src="https://camo.githubusercontent.com/1ff9cd713661b57143185f14d4f126f21718f48d613b47ef8cc530538055ec90/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f59577464443754485478452f6d617872657364656661756c742e6a7067" data-canonical-src="https://img.youtube.com/vi/YWtdD7THTxE/maxresdefault.jpg">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">0. Pre-requisites</h3><a id="user-content-0-pre-requisites" aria-label="Permalink: 0. Pre-requisites" href="#0-pre-requisites"></a></p>
<ul dir="auto">
<li>Install Docker. We strongly recommend using <a href="https://www.docker.com/products/docker-desktop/" rel="nofollow">Docker Desktop</a>, especially if you're on Apple M chips. Alternatively, you can install <code>docker</code> and <code>docker-compose</code>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Clone the <code>dropbase</code> repo</h3><a id="user-content-1-clone-the-dropbase-repo" aria-label="Permalink: 1. Clone the dropbase repo" href="#1-clone-the-dropbase-repo"></a></p>
<p dir="auto">Clone the Dropbase repository</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/DropbaseHQ/dropbase.git"><pre><span>git</span> <span>clone</span> <span>https</span>:<span>//</span><span>github</span>.<span>com</span><span>/</span><span>DropbaseHQ</span><span>/</span><span>dropbase</span>.<span>git</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Start the server</h3><a id="user-content-2-start-the-server" aria-label="Permalink: 2. Start the server" href="#2-start-the-server"></a></p>
<p dir="auto">Start the server by running start.sh</p>
<p dir="auto"><strong>NOTE:</strong> When starting the server for the first time, make <code>start.sh</code> executable.</p>

<p dir="auto">You can start the server by running</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">3. Create your first Dropbase app</h3><a id="user-content-3-create-your-first-dropbase-app" aria-label="Permalink: 3. Create your first Dropbase app" href="#3-create-your-first-dropbase-app"></a></p>
<p dir="auto">Go to the Dropbase App <code>http://localhost:3030/apps</code> from your browser and click on the <code>Create app</code> button to create your first Dropbase app.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Enabling AI features</h2><a id="user-content-enabling-ai-features" aria-label="Permalink: Enabling AI features" href="#enabling-ai-features"></a></p>
<p dir="auto">Dropbase uses LLM (gpt, sonnet) to provide AI Developer feature. To enable it, add your OpenAI or Anthropic api key into <code>server.toml</code>. Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[llm.openai]
api_key = &quot;YOUR_API_KEY&quot;
model = &quot;gpt-4o&quot;"><pre>[llm.openai]
api_key = <span><span>"</span>YOUR_API_KEY<span>"</span></span>
model = <span><span>"</span>gpt-4o<span>"</span></span></pre></div>
<p dir="auto"><strong>IMPORTANT:</strong> If you add additional environmental variables, make sure to add them before LLM configurations (at the top-level table), since LLM configurations are defined as <a href="https://toml.io/en/v1.0.0#table" rel="nofollow">table</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuring Worker</h2><a id="user-content-configuring-worker" aria-label="Permalink: Configuring Worker" href="#configuring-worker"></a></p>
<p dir="auto"><code>worker.toml</code> contains environmental variables for the worker. This includes database sources, API keys, or access token to third party services.</p>
<p dir="auto">To include API keys or tokens, add a name for the token and enter your string token. Though not required, adding a descriptive name helps Dropbase AI infer the key to use.</p>
<div dir="auto" data-snippet-clipboard-copy-content="stripe_key=&quot;rk_test_123&quot;
mailgun_api_key=&quot;abc123&quot;"><pre>stripe_key=<span><span>"</span>rk_test_123<span>"</span></span>
mailgun_api_key=<span><span>"</span>abc123<span>"</span></span></pre></div>
<p dir="auto">To include database sources, use the following format: <code>database</code>.<code>database_type</code>.<code>database_nickname</code></p>
<p dir="auto">For example, if you want to add a <code>postgres</code> database to a list of sources and use <code>my_source</code> as its nickname, add the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[database.postgres.my_source]
host = &quot;localhost&quot;
database = &quot;postgres&quot;
username = &quot;username&quot;
password = &quot;password&quot;
port = 5432"><pre>[database.postgres.my_source]
host = <span><span>"</span>localhost<span>"</span></span>
database = <span><span>"</span>postgres<span>"</span></span>
username = <span><span>"</span>username<span>"</span></span>
password = <span><span>"</span>password<span>"</span></span>
port = 5432</pre></div>
<p dir="auto"><strong>NOTE:</strong> The built-in demo requires <code>database.sqlite.demo</code> to be present in <code>worker.toml</code>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini Pro refuses to acknowledge yt-dlp (124 pts)]]></title>
            <link>https://twitter.com/adocomplete/status/1811802857022324904</link>
            <guid>40947378</guid>
            <pubDate>Fri, 12 Jul 2024 17:03:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/adocomplete/status/1811802857022324904">https://twitter.com/adocomplete/status/1811802857022324904</a>, See on <a href="https://news.ycombinator.com/item?id=40947378">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Intel is selling defective 13-14th Gen CPUs (137 pts)]]></title>
            <link>https://alderongames.com/intel-crashes</link>
            <guid>40946644</guid>
            <pubDate>Fri, 12 Jul 2024 15:46:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alderongames.com/intel-crashes">https://alderongames.com/intel-crashes</a>, See on <a href="https://news.ycombinator.com/item?id=40946644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>My team at Alderon Games, working on the multiplayer dinosaur survival game <a href="https://pathoftitans.com/">Path of Titans</a>, has been encountering significant problems with Intel CPU stability. These issues, including crashes, instability, and memory corruption, are confined to the 13th and 14th generation processors. Despite all released microcode, BIOS, and firmware updates, the problem remains unresolved.</p>
<p>We have identified failures in five main areas:</p>
<ul>
<li>
<strong>End Customers:</strong> Thousands of crashes on Intel CPUs on 13th and 14th Gen CPUs in our crash reporting tools.</li>
<li>
<strong>Official Dedicated Game Servers:</strong> Experiencing constant crashes, taking entire servers down.</li>
<li>
<strong>Development Team:</strong> Developers using these CPUs face frequent instability while building and working on the game. It can also cause SSD and memory corruption.</li>
<li>
<strong>Game Server Providers:</strong> Hosting community servers with persistent crashing issues.</li>
<li>
<strong>Benchmarking Tools:</strong> Decompression and memory tests unrelated to Path of Titans also fail.</li>
</ul>
<p>Over the last 3–4 months, we have observed that CPUs initially working well deteriorate over time, eventually failing. The failure rate we have observed from our own testing is nearly 100%, indicating it's only a matter of time before affected CPUs fail. This issue is gaining attention from news outlets and has been noted by Fortnite and RAD Game Tools, which powers decompression behind Unreal Engine.</p>
<p>Users are also receiving misleading error messages about running out of video driver memory, despite having sufficient memory.</p>
<h2>Actions We Are Taking</h2>
<p>To prevent further harm to our game, we are implementing the following measures:</p>
<ul>
<li>
<strong>Server Migration:</strong> We are swapping all our servers to AMD, which experience 100 times fewer crashes compared to Intel CPUs that were found to be defective.</li>
<li>
<strong>Hosting Recommendations:</strong> We advise anyone hosting Path of Titans servers or selling game servers to avoid purchasing or using 13th and 14th gen Intel CPUs.</li>
<li>
<strong>In-Game Notifications:</strong> We are adding a popup message in-game to inform users with these processors about the issue. Many users are currently unaware of why their game is crashing and what they can do about it.</li>
</ul>
<h2>Resources</h2>
<ul>
<li>
<a href="https://www.epicgames.com/help/en-US/c-Category_Fortnite/c-Fortnite_TechnicalSupport/frequent-crashes-in-fortnite-on-i9-13900k-kf-ks-or-i9-14900k-kf-ks-cpus-a000086852?sessionInvalidated=true">Frequent Crashes in Fortnite on i9-13900K/KF/KS or i9-14900K/KF/KS CPUs</a>
</li>
<li>
<a href="https://www.radgametools.com/oodleintel.htm">RAD Game Tools Intel CPU Issues</a>
</li>
<li>
<a href="https://hardwaretimes.com/pc-gamers-amd-ryzen-intel-13900k-14900k-crash-fail/">PC Gamers are Switching to AMD Ryzen as Intel 13900K/14900K Chips Continue to Crash &amp; Fail</a>
</li>
<li>
<a href="https://www.techspot.com/review/2836-intel-cpu-crash-baseline-spec/">Intel CPUs Are Crashing and It's Intel's Fault: Intel Baseline Profile Benchmark</a>
</li>
</ul>
<p>We look forward to more information becoming available about these problems.</p>
<p>For Intel's sake, we hope they recall these CPUs and refund consumers. This post isn't a endorsement of AMD CPUs or any other PC company. Keep in mind any product can have defects and issues, we just want to let you know where these crashes are coming from and what is going on.</p>
<p>By Matthew Cassells</p>
<p>Founder of Alderon Games</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>